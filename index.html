
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.SD_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T15:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.SD_2023_11_06/">cs.SD - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Foundation-Model-for-Music-Informatics"><a href="#A-Foundation-Model-for-Music-Informatics" class="headerlink" title="A Foundation Model for Music Informatics"></a>A Foundation Model for Music Informatics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03318">http://arxiv.org/abs/2311.03318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minz Won, Yun-Ning Hung, Duc Le</li>
<li>for: 这 paper 是 investigate 音乐信息学领域的基础模型，解决当前这个领域缺乏标注数据和泛化问题。</li>
<li>methods: 这 paper 使用了多种基础模型变体，研究了关键的determinants，如模型架构、tokenization方法、时间分辨率、数据和模型缩放。</li>
<li>results: 这 paper 的结果显示，我们的模型在多种音乐信息检索任务中表现出色，在特定的metric中超过了现有模型。这些发现帮助了自动学习在音乐信息学领域的理解，并为未来开发更有效和多样的基础模型奠定了基础。一个预训练版本的我们的模型也公开可用，以促进复现性和未来研究。<details>
<summary>Abstract</summary>
This paper investigates foundation models tailored for music informatics, a domain currently challenged by the scarcity of labeled data and generalization issues. To this end, we conduct an in-depth comparative study among various foundation model variants, examining key determinants such as model architectures, tokenization methods, temporal resolution, data, and model scalability. This research aims to bridge the existing knowledge gap by elucidating how these individual factors contribute to the success of foundation models in music informatics. Employing a careful evaluation framework, we assess the performance of these models across diverse downstream tasks in music information retrieval, with a particular focus on token-level and sequence-level classification. Our results reveal that our model demonstrates robust performance, surpassing existing models in specific key metrics. These findings contribute to the understanding of self-supervised learning in music informatics and pave the way for developing more effective and versatile foundation models in the field. A pretrained version of our model is publicly available to foster reproducibility and future research.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.SD_2023_11_06/" data-id="cloojsmlr00yxre88eab57enu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.CV_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T13:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.CV_2023_11_06/">cs.CV - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CoVLM-Composing-Visual-Entities-and-Relationships-in-Large-Language-Models-Via-Communicative-Decoding"><a href="#CoVLM-Composing-Visual-Entities-and-Relationships-in-Large-Language-Models-Via-Communicative-Decoding" class="headerlink" title="CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"></a>CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03354">http://arxiv.org/abs/2311.03354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyan Li, Delin Chen, Yining Hong, Zhenfang Chen, Peihao Chen, Yikang Shen, Chuang Gan</li>
<li>for: 提高大型视言语基础模型（VLM）的 Compositional Reasoning 能力，使其能够更好地捕捉视觉和语言之间的关系。</li>
<li>methods: 提出了一种新的 Communication Token 机制，通过动态地与视觉检测系统和语言系统进行交互，使 LLM 可以更好地组合视觉元素和关系。</li>
<li>results: 对 compositional reasoning benchmark 进行评测，CoVLM 表现出色，较前一代 VLM 提高了大约 20% 的 mAP 分数，较前一代 VLM 提高了大约 14% 的 top-1 准确率，并在 ARO 上提高了大约 3% 的 top-1 准确率。同时，在传统的视觉语言任务中，如引用表达理解和视觉问答任务中，也达到了状态略进行表现。<details>
<summary>Abstract</summary>
A remarkable ability of human beings resides in compositional reasoning, i.e., the capacity to make "infinite use of finite means". However, current large vision-language foundation models (VLMs) fall short of such compositional abilities due to their "bag-of-words" behaviors and inability to construct words that correctly represent visual entities and the relations among the entities. To this end, we propose CoVLM, which can guide the LLM to explicitly compose visual entities and relationships among the text and dynamically communicate with the vision encoder and detection network to achieve vision-language communicative decoding. Specifically, we first devise a set of novel communication tokens for the LLM, for dynamic communication between the visual detection system and the language system. A communication token is generated by the LLM following a visual entity or a relation, to inform the detection network to propose regions that are relevant to the sentence generated so far. The proposed regions-of-interests (ROIs) are then fed back into the LLM for better language generation contingent on the relevant regions. The LLM is thus able to compose the visual entities and relationships through the communication tokens. The vision-to-language and language-to-vision communication are iteratively performed until the entire sentence is generated. Our framework seamlessly bridges the gap between visual perception and LLMs and outperforms previous VLMs by a large margin on compositional reasoning benchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on ARO top-1 accuracy). We also achieve state-of-the-art performances on traditional vision-language tasks such as referring expression comprehension and visual question answering.
</details>
<details>
<summary>摘要</summary>
人类有一种杰出的能力是 compositional reasoning，即将 "无限用 finite means" 的能力。然而，当前的大规模视语言基础模型 (VLM) 因其 "bag-of-words" 行为和无法正确表示视觉元素和关系而做出缺陷。为此，我们提议 CoVLM，可以引导 LLM 进行视语言交互性解oding。specifically，我们首先设计了一组新的交流符，用于在视觉检测系统和语言系统之间的动态交流。一个交流符是由 LLM 根据视觉元素或关系生成的，以告知检测网络提交相关的区域。提交的区域是feedback到 LLM，以便更好地根据相关区域生成语言。 LLM 因此可以通过交流符compose视觉元素和关系。视觉到语言和语言到视觉的交流是 iterative 进行，直到整个句子被生成。我们的框架可以准确地跨越视觉感知和 LLMs，并在 compositional reasoning benchmark 上大幅提高 VLM 的性能（例如，~ 20% 在 HICO-DET mAP 中，~ 14% 在 Cola 顶部精度中，和 ~ 3% 在 ARO 顶部精度中）。我们还达到了传统视觉语言任务的州际性表现，如 Referring Expression Comprehension 和 Visual Question Answering。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Evaluation-Metrics-of-Open-Vocabulary-Segmentaion"><a href="#Rethinking-Evaluation-Metrics-of-Open-Vocabulary-Segmentaion" class="headerlink" title="Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion"></a>Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03352">http://arxiv.org/abs/2311.03352</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhou, Tiancheng Shen, Xu Yang, Hai Huang, Xiangtai Li, Lu Qi, Ming-Hsuan Yang</li>
<li>for: 本研究探讨了开放词汇分割评价指标的问题，即评价过程仍然强调关闭集成指标在零shot或跨数据集管道上，而不考虑预测和真实分类类别之间的相似性。</li>
<li>methods: 我们首先对 eleven 种 между两个概念的相似度测量使用WordNet语言统计、文本嵌入和语言模型进行了全面的量化分析和用户研究。基于这些探索的测量，我们设计了 noval 评价指标，包括 Open mIoU、Open AP 和 Open PQ，适用于三种开放词汇分割任务。</li>
<li>results: 我们在 12 种开放词汇分割方法上 benchmarked 我们的评价指标，即使相对Subjective的相似距离，我们 still 能够通过我们的指标来评价现有的开放词汇分割方法的开放能力。我们希望通过我们的工作，能够带领社区新的思想，以评价开放能力的方法。评价代码已经发布到github。<details>
<summary>Abstract</summary>
In this paper, we highlight a problem of evaluation metrics adopted in the open-vocabulary segmentation. That is, the evaluation process still heavily relies on closed-set metrics on zero-shot or cross-dataset pipelines without considering the similarity between predicted and ground truth categories. To tackle this issue, we first survey eleven similarity measurements between two categorical words using WordNet linguistics statistics, text embedding, and language models by comprehensive quantitative analysis and user study. Built upon those explored measurements, we designed novel evaluation metrics, namely Open mIoU, Open AP, and Open PQ, tailored for three open-vocabulary segmentation tasks. We benchmarked the proposed evaluation metrics on 12 open-vocabulary methods of three segmentation tasks. Even though the relative subjectivity of similarity distance, we demonstrate that our metrics can still well evaluate the open ability of the existing open-vocabulary segmentation methods. We hope that our work can bring with the community new thinking about how to evaluate the open ability of models. The evaluation code is released in github.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Long-Term-Invariant-Local-Features-via-Implicit-Cross-Domain-Correspondences"><a href="#Long-Term-Invariant-Local-Features-via-Implicit-Cross-Domain-Correspondences" class="headerlink" title="Long-Term Invariant Local Features via Implicit Cross-Domain Correspondences"></a>Long-Term Invariant Local Features via Implicit Cross-Domain Correspondences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03345">http://arxiv.org/abs/2311.03345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zador Pataki, Mohammad Altillawi, Menelaos Kanakis, Rémi Pautrat, Fengyi Shen, Ziyuan Liu, Luc Van Gool, Marc Pollefeys</li>
<li>for: 本文研究了现代学习基于的视觉特征提取网络在跨域地理位置ocalization中的性能问题。</li>
<li>methods: 我们提出了一种新的数据驱动方法，即偏振交叉域对应（iCDC），以提高现代特征提取网络的跨域ocalization性能。iCDC使用不同视觉域下的场景表示，通过下推到场景的3D表示来生成准确的对应关系。</li>
<li>results: 我们的提议方法在评估于流行的长期地理位置 benchmark 上表现出色，与现有方法相比，具有显著的性能优势。这些结果表明，我们的方法可以为长期部署的视觉地理位置ocalization领域提供更加稳定和可靠的性能。<details>
<summary>Abstract</summary>
Modern learning-based visual feature extraction networks perform well in intra-domain localization, however, their performance significantly declines when image pairs are captured across long-term visual domain variations, such as different seasonal and daytime variations. In this paper, our first contribution is a benchmark to investigate the performance impact of long-term variations on visual localization. We conduct a thorough analysis of the performance of current state-of-the-art feature extraction networks under various domain changes and find a significant performance gap between intra- and cross-domain localization. We investigate different methods to close this gap by improving the supervision of modern feature extractor networks. We propose a novel data-centric method, Implicit Cross-Domain Correspondences (iCDC). iCDC represents the same environment with multiple Neural Radiance Fields, each fitting the scene under individual visual domains. It utilizes the underlying 3D representations to generate accurate correspondences across different long-term visual conditions. Our proposed method enhances cross-domain localization performance, significantly reducing the performance gap. When evaluated on popular long-term localization benchmarks, our trained networks consistently outperform existing methods. This work serves as a substantial stride toward more robust visual localization pipelines for long-term deployments, and opens up research avenues in the development of long-term invariant descriptors.
</details>
<details>
<summary>摘要</summary>
现代学习基于的视觉特征提取网络在同一个频谱域中的本地化表现良好，但是当图像对被捕捉到不同季节和日间变化时，其表现显著下降。在这篇论文中，我们的首要贡献是设立了考察长期变化对视觉本地化表现的 bencmark。我们进行了对当前状态艺术特征提取网络在不同频谱变化下的完整分析，并发现了 intra- 和 cross-频谱本地化之间的表现差距非常大。我们 investigate了不同的方法来减少这个差距，包括改进现代特征提取器网络的超vision。我们提出了一种新的数据中心方法，即隐式跨频谱对应（iCDC）。iCDC通过对各个视觉频谱下的场景使用多个神经辐射场，来生成高精度的对应关系。我们的提出方法可以大幅提高跨频谱本地化表现，并减少表现差距。当我们的训练网络被评估于popular long-term本地化benchmark上，它们一直表现出色，胜过现有方法。这种工作是Visual本地化管道中更Robust的解决方案的一大步进，同时开启了长期不变特征表示器的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Cross-Image-Attention-for-Zero-Shot-Appearance-Transfer"><a href="#Cross-Image-Attention-for-Zero-Shot-Appearance-Transfer" class="headerlink" title="Cross-Image Attention for Zero-Shot Appearance Transfer"></a>Cross-Image Attention for Zero-Shot Appearance Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03335">http://arxiv.org/abs/2311.03335</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/garibida/cross-image-attention">https://github.com/garibida/cross-image-attention</a></li>
<li>paper_authors: Yuval Alaluf, Daniel Garibi, Or Patashnik, Hadar Averbuch-Elor, Daniel Cohen-Or</li>
<li>for: 将图像之间的Semantic知识传递到图像中，以实现图像的Visual表现转换。</li>
<li>methods: 基于文本生成模型的自我注意层，引入cross-image注意机制，在denoising过程中利用已经建立的semantic对应关系，将结构图像的查询与外观图像的键值相结合，以生成结构和外观相符的图像。</li>
<li>results: 在各种物体类别和不同的形状、大小和视点变化下，实现了图像的高质量生成，无需优化或训练。<details>
<summary>Abstract</summary>
Recent advancements in text-to-image generative models have demonstrated a remarkable ability to capture a deep semantic understanding of images. In this work, we leverage this semantic knowledge to transfer the visual appearance between objects that share similar semantics but may differ significantly in shape. To achieve this, we build upon the self-attention layers of these generative models and introduce a cross-image attention mechanism that implicitly establishes semantic correspondences across images. Specifically, given a pair of images -- one depicting the target structure and the other specifying the desired appearance -- our cross-image attention combines the queries corresponding to the structure image with the keys and values of the appearance image. This operation, when applied during the denoising process, leverages the established semantic correspondences to generate an image combining the desired structure and appearance. In addition, to improve the output image quality, we harness three mechanisms that either manipulate the noisy latent codes or the model's internal representations throughout the denoising process. Importantly, our approach is zero-shot, requiring no optimization or training. Experiments show that our method is effective across a wide range of object categories and is robust to variations in shape, size, and viewpoint between the two input images.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Robust-Bi-Directional-Algorithm-For-People-Count-In-Crowded-Areas"><a href="#A-Robust-Bi-Directional-Algorithm-For-People-Count-In-Crowded-Areas" class="headerlink" title="A Robust Bi-Directional Algorithm For People Count In Crowded Areas"></a>A Robust Bi-Directional Algorithm For People Count In Crowded Areas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03323">http://arxiv.org/abs/2311.03323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Satyanarayana Penke, Gopikrishna Pavuluri, Soukhya Kunda, Satvik M, CharanKumar Y<br>for: 这个论文的目的是计算人群流动的方法。methods: 这篇论文使用了blob分析方法来计算人群流动。results: 论文得出的结果是可以实时计算人群流动的方法，可以用于统计人群流动的方向和数量。<details>
<summary>Abstract</summary>
People counting system in crowded places has become a very useful practical application that can be accomplished in various ways which include many traditional methods using sensors. Examining the case of real time scenarios, the algorithm espoused should be steadfast and accurate. People counting algorithm presented in this paper, is centered on blob assessment, devoted to yield the count of the people through a path along with the direction of traversal. The system depicted is often ensconced at the entrance of a building so that the unmitigated frequency of visitors can be recorded. The core premise of this work is to extricate count of people inflow and outflow pertaining to a particular area. The tot-up achieved can be exploited for purpose of statistics in the circumstances of any calamity occurrence in that zone. Relying upon the count totaled, the population in that vicinity can be assimilated in order to take on relevant measures to rescue the people.
</details>
<details>
<summary>摘要</summary>
人数计数系统在拥挤的地方已成为非常有用的实际应用，可以通过多种传统方法使用感测器进行实现。在实时场景中，算法应该是不动摇的和准确的。本文所提出的人数计算算法基于块评估，可以通过路径和旋转方向来计算人数。这种系统通常安装在建筑物入口处，以记录入场人数的不断变化。本文的核心思想是提取入口和出口人数的计数，以便在紧急情况下对该区域的人口进行统计，并根据统计结果采取相应的救援措施。
</details></li>
</ul>
<hr>
<h2 id="FATE-Feature-Agnostic-Transformer-based-Encoder-for-learning-generalized-embedding-spaces-in-flow-cytometry-data"><a href="#FATE-Feature-Agnostic-Transformer-based-Encoder-for-learning-generalized-embedding-spaces-in-flow-cytometry-data" class="headerlink" title="FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data"></a>FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03314">http://arxiv.org/abs/2311.03314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lisa Weijler, Florian Kowarsch, Michael Reiter, Pedro Hermosilla, Margarita Maurer-Granofszky, Michael Dworzak</li>
<li>for: 这个研究目的是提出一个能够处理不同特征空间数据的新型架构，以便在实验室数据中检测白细胞抗原表达的自动化方法。</li>
<li>methods: 这个方法使用了一个名为set-transformer的新型架构，并与特征编解层合作，以学习内部特征空间的共同对应关系。</li>
<li>results: 这个方法在检测淋巴细胞抗原表达中表现出色，能够处理不同特征空间的数据，并且不需要对特征空间进行调整或扩展。<details>
<summary>Abstract</summary>
While model architectures and training strategies have become more generic and flexible with respect to different data modalities over the past years, a persistent limitation lies in the assumption of fixed quantities and arrangements of input features. This limitation becomes particularly relevant in scenarios where the attributes captured during data acquisition vary across different samples. In this work, we aim at effectively leveraging data with varying features, without the need to constrain the input space to the intersection of potential feature sets or to expand it to their union. We propose a novel architecture that can directly process data without the necessity of aligned feature modalities by learning a general embedding space that captures the relationship between features across data samples with varying sets of features. This is achieved via a set-transformer architecture augmented by feature-encoder layers, thereby enabling the learning of a shared latent feature space from data originating from heterogeneous feature spaces. The advantages of the model are demonstrated for automatic cancer cell detection in acute myeloid leukemia in flow cytometry data, where the features measured during acquisition often vary between samples. Our proposed architecture's capacity to operate seamlessly across incongruent feature spaces is particularly relevant in this context, where data scarcity arises from the low prevalence of the disease. The code is available for research purposes at https://github.com/lisaweijler/FATE.
</details>
<details>
<summary>摘要</summary>
而模型的建立和训练策略在过去几年来变得更加一般化和灵活，能够处理不同数据类型的数据。然而，一个 persistent limitation 是假设输入特征的数量和排列是固定的。这个限制在样本中 captured 的特征不同时 particualrly relevant。在这个工作中，我们想要有效地利用不同特征的数据，不需要尺寸输入空间到可能的特征集的交叉点或者到其union。我们提出了一种新的架构，可以直接处理数据，不需要对特征模式进行aligned。这是通过在数据样本之间学习一个通用的嵌入空间，以捕捉特征之间的关系。这个嵌入空间是通过set-transformer架构和特征编码层来学习的。这种架构可以在不同特征空间中学习共享的凉特征空间。我们的提出的架构在 automatic cancer cell detection 中得到了应用， particularly relevant 在 flow cytometry 数据中，因为在这里的特征通常在不同的样本中不同。我们的提出的架构可以在不同的特征空间中操作无缝，这是 particualrly relevant 在这个疾病的低发病率下。代码可以在https://github.com/lisaweijler/FATE 上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Single-2D-Pose-with-Context-is-Worth-Hundreds-for-3D-Human-Pose-Estimation"><a href="#A-Single-2D-Pose-with-Context-is-Worth-Hundreds-for-3D-Human-Pose-Estimation" class="headerlink" title="A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation"></a>A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03312">http://arxiv.org/abs/2311.03312</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/QitaoZhao/ContextAware-PoseFormer">https://github.com/QitaoZhao/ContextAware-PoseFormer</a></li>
<li>paper_authors: Qitao Zhao, Ce Zheng, Mengyuan Liu, Chen Chen</li>
<li>for: 提高3D人姿估计精度，不需要使用大量视频帧</li>
<li>methods: 利用 pré-train 的2D pose检测器生成的中间视觉表示，无需训练</li>
<li>results: 与Context-Aware PoseFormer比较，无需使用任何时间信息，在速度和精度两个方面显著提高表现<details>
<summary>Abstract</summary>
The dominant paradigm in 3D human pose estimation that lifts a 2D pose sequence to 3D heavily relies on long-term temporal clues (i.e., using a daunting number of video frames) for improved accuracy, which incurs performance saturation, intractable computation and the non-causal problem. This can be attributed to their inherent inability to perceive spatial context as plain 2D joint coordinates carry no visual cues. To address this issue, we propose a straightforward yet powerful solution: leveraging the readily available intermediate visual representations produced by off-the-shelf (pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed. The key observation is that, while the pose detector learns to localize 2D joints, such representations (e.g., feature maps) implicitly encode the joint-centric spatial context thanks to the regional operations in backbone networks. We design a simple baseline named Context-Aware PoseFormer to showcase its effectiveness. Without access to any temporal information, the proposed method significantly outperforms its context-agnostic counterpart, PoseFormer, and other state-of-the-art methods using up to hundreds of video frames regarding both speed and precision. Project page: https://qitaozhao.github.io/ContextAware-PoseFormer
</details>
<details>
<summary>摘要</summary>
主流方法在3D人姿估计中将2D姿势序列提升到3D，对准的使用了严重的长期时间讯息（例如使用大量的影像帧），从而导致性能暴露、计算复杂和非 causa 问题。这可以被归因于它们的内在无法感受到空间上下文的缺陷，因为普通的2D JOINT坐标并不含任何视觉提示。为解决这个问题，我们提出了一个简单 yet 具有强大的解决方案：利用可以通过Off-the-shelf（预训）的2D姿势探测器生成的Ready-to-use中间显示表示，不需要任何调整。关键观察是，对于2D JOINT的探测器而言，其生成的表示（例如特征图）会隐式地传递 JOINT-centric的空间上下文，这是由背景网络的区域操作所带来的。我们设计了一个简单的基eline名为Context-Aware PoseFormer，以示其效iveness。在没有任何时间讯息的情况下，我们的提案明显超越了它的context-agnostic counterpart，PoseFormer，以及其他使用到百分之百的影像帧的现有方法， regardind both speed和精度。Project page: <https://qitaozhao.github.io/ContextAware-PoseFormer>
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Based-Tea-Leaf-Disease-Detection-A-Comprehensive-Review"><a href="#Machine-Learning-Based-Tea-Leaf-Disease-Detection-A-Comprehensive-Review" class="headerlink" title="Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review"></a>Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03240">http://arxiv.org/abs/2311.03240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faruk Ahmed, Md. Taimur Ahad, Yousuf Rayhan Emon</li>
<li>for: 这个研究旨在探讨机器学习方法在农业生产力提高中的应用，尤其是在茶叶疾病诊断方面。</li>
<li>methods: 这个研究使用了多种机器学习方法，包括视觉 трансформа器模型（ICVT、GreenViT、PlantXViT、PlantViT、MSCVT、TLMViT、IterationViT、IEM-ViT）以及其他模型（ dense convolutional network（DenseNet）、Residual Neural Network（ResNet）-50V2、YOLOv5、YOLOv7、Convolutional Neural Network（CNN）、Deep CNN、Non-dominated Sorting Genetic Algorithm（NSGA-II）、MobileNetv2、Lesion-Aware Visual Transformer）。</li>
<li>results: 这些机器学习模型在不同的数据集上进行了训练和测试，并在实际应用中得到了良好的结果。<details>
<summary>Abstract</summary>
Tea leaf diseases are a major challenge to agricultural productivity, with far-reaching implications for yield and quality in the tea industry. The rise of machine learning has enabled the development of innovative approaches to combat these diseases. Early detection and diagnosis are crucial for effective crop management. For predicting tea leaf disease, several automated systems have already been developed using different image processing techniques. This paper delivers a systematic review of the literature on machine learning methodologies applied to diagnose tea leaf disease via image classification. It thoroughly evaluates the strengths and constraints of various Vision Transformer models, including Inception Convolutional Vision Transformer (ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision Transformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews models like Dense Convolutional Network (DenseNet), Residual Neural Network (ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN, Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and Lesion-Aware Visual Transformer. These machine-learning models have been tested on various datasets, demonstrating their real-world applicability. This review study not only highlights current progress in the field but also provides valuable insights for future research directions in the machine learning-based detection and classification of tea leaf diseases.
</details>
<details>
<summary>摘要</summary>
茶叶疾病是现代农业生产的主要挑战，对茶业生产的产量和质量有着深远的影响。随着机器学习的发展，开发了一些创新的方法来解决这些疾病。早期检测和诊断是 tea 生产中的关键环节。为预测茶叶疾病，已经开发了多种自动化系统，使用了不同的图像处理技术。本文提供了机器学习方法在预测茶叶疾病方面的系统性回顾，全面评估了各种视Transformer模型的优势和缺陷，包括Inception Convolutional Vision Transformer (ICVT)、GreenViT、PlantXViT、PlantViT、MSCVT、Transfer Learning Model & Vision Transformer (TLMViT)、IterationViT、IEM-ViT等。此外，本文还回顾了其他模型，如 dense convolutional network (DenseNet)、Residual Neural Network (ResNet)-50V2、YOLOv5、YOLOv7、Convolutional Neural Network (CNN)、Deep CNN、Non-dominated Sorting Genetic Algorithm (NSGA-II)、MobileNetv2、Lesion-Aware Visual Transformer等。这些机器学习模型在不同的数据集上进行测试，示出了它们在实际应用中的可行性。本文不仅概括了当前领域的进展，还为未来在机器学习基于茶叶疾病检测和分类方面的研究提供了价值的指导。
</details></li>
</ul>
<hr>
<h2 id="Navigating-Scaling-Laws-Accelerating-Vision-Transformer’s-Training-via-Adaptive-Strategies"><a href="#Navigating-Scaling-Laws-Accelerating-Vision-Transformer’s-Training-via-Adaptive-Strategies" class="headerlink" title="Navigating Scaling Laws: Accelerating Vision Transformer’s Training via Adaptive Strategies"></a>Navigating Scaling Laws: Accelerating Vision Transformer’s Training via Adaptive Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03233">http://arxiv.org/abs/2311.03233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sotiris Anagnostidis, Gregor Bachmann, Thomas Hofmann</li>
<li>for: 本研究旨在提出一种可以适应不同任务和 dataset 的 compute-optimal 模型，通过适应 scaling laws 来减少计算资源的需求，以提高模型的性能。</li>
<li>methods: 本研究使用了 vision transformers 家族的模型，通过自适应的方式调整模型的 shape 参数，以实现 compute-optimal 性能。</li>
<li>results: 研究发现，通过适应 scaling laws 和自适应的方式调整模型的 shape 参数，可以创建一种更高性能的模型，并且可以在不同的任务和 dataset 上达到更好的性能。<details>
<summary>Abstract</summary>
In recent years, the state-of-the-art in deep learning has been dominated by very large models that have been pre-trained on vast amounts of data. The paradigm is very simple: Investing more computational resources (optimally) leads to better performance, and even predictably so; neural scaling laws have been derived that accurately forecast the performance of a network for a desired level of compute. This leads to the notion of a "compute-optimal" model, i.e. a model that allocates a given level of compute during training optimally to maximise performance. In this work, we extend the concept of optimality by allowing for an "adaptive" model, i.e. a model that can change its shape during the course of training. By allowing the shape to adapt, we can optimally traverse between the underlying scaling laws, leading to a significant reduction in the required compute to reach a given target performance. We focus on vision tasks and the family of Vision Transformers, where the patch size as well as the width naturally serve as adaptive shape parameters. We demonstrate that, guided by scaling laws, we can design compute-optimal adaptive models that beat their "static" counterparts.
</details>
<details>
<summary>摘要</summary>
近年来，深度学习领域的状态艺术被大型模型所主导。这种模型的概念很简单：投入更多的计算资源（理想情况下）会提高性能，甚至可预测性能会提高。基于这个概念，我们可以定义“计算优化”模型，即在训练期间优化计算资源的分配，以最大化性能。在这种工作中，我们扩展了优化的概念，允许模型在训练过程中改变其形状。通过让形状适应变化，我们可以优化地 traverse between 的下面法则，从而减少达到给定目标性能所需的计算量。我们将注意力集中在视觉任务上，特别是家族中的视觉转换器，其patch size和宽度自然成为适应形参数。我们示示了，通过适应法则引导，我们可以设计计算优化的适应模型，超过其“静态”对手。
</details></li>
</ul>
<hr>
<h2 id="Segmentation-of-Drone-Collision-Hazards-in-Airborne-RADAR-Point-Clouds-Using-PointNet"><a href="#Segmentation-of-Drone-Collision-Hazards-in-Airborne-RADAR-Point-Clouds-Using-PointNet" class="headerlink" title="Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds Using PointNet"></a>Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds Using PointNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03221">http://arxiv.org/abs/2311.03221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hector Arroyo, Paul Kier, Dylan Angus, Santiago Matalonga, Svetlozar Georgiev, Mehdi Goli, Gerard Dooly, James Riordan<br>for: 本研究旨在增强无人航空器（UAV）在共享空域中的安全运行，特别是在 beyond visual line of sight（BVLOS）操作中。methods: 本研究使用激光技术，实现了一个独特的端到端含义分类方法，可同时识别多个撞击威胁。results: 本研究获得了94%的准确率，成功地同时识别了多个撞击威胁，包括机动无人机（DJI M300和DJI Mini）和飞机（Ikarus C42），以及静止返回（地面和基础设施）。<details>
<summary>Abstract</summary>
The integration of unmanned aerial vehicles (UAVs) into shared airspace for beyond visual line of sight (BVLOS) operations presents significant challenges but holds transformative potential for sectors like transportation, construction, energy and defense. A critical prerequisite for this integration is equipping UAVs with enhanced situational awareness to ensure safe operations. Current approaches mainly target single object detection or classification, or simpler sensing outputs that offer limited perceptual understanding and lack the rapid end-to-end processing needed to convert sensor data into safety-critical insights. In contrast, our study leverages radar technology for novel end-to-end semantic segmentation of aerial point clouds to simultaneously identify multiple collision hazards. By adapting and optimizing the PointNet architecture and integrating aerial domain insights, our framework distinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and airplanes (Ikarus C42), and static returns (ground and infrastructure) which results in enhanced situational awareness for UAVs. To our knowledge, this is the first approach addressing simultaneous identification of multiple collision threats in an aerial setting, achieving a robust 94% accuracy. This work highlights the potential of radar technology to advance situational awareness in UAVs, facilitating safe and efficient BVLOS operations.
</details>
<details>
<summary>摘要</summary>
“无人航空器（UAV）在共享空域进行超过视程操作（BVLOS）具有重要挑战，但具有传换性潜力，尤其是交通、建筑、能源和国防等领域。一个重要的前提是将UAV设备了更好的情感知识，以确保安全运作。现有的方法主要针对单一物体检测或分类，或更简单的感知输入，它们具有限制的感知理解和缺乏快速端到端处理，无法将感知资料转换为安全数据。相比之下，我们的研究利用激光技术，实现了首个同时识别多个冲击威胁的对 aerial point clouds 的终端性数据分类框架。我们运用了PointNet架构，并将空中领域知识融入，分别识别了多架 DJI M300 和 DJI Mini，以及机场（Ikarus C42）和静止返回（地面和基础设施），从而提高UAV的情感知识。根据我们所知，这是首个同时识别多个冲击威胁的 aerial 设置，精度高达 94%。这项研究显示了激光技术对 UAV 的情感知识提升具有巨大潜力，促进安全和效率的 BVLOS 操作。”
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Transformers-to-Improve-Breast-Cancer-Classification-and-Risk-Assessment-with-Multi-modal-and-Longitudinal-Data"><a href="#Leveraging-Transformers-to-Improve-Breast-Cancer-Classification-and-Risk-Assessment-with-Multi-modal-and-Longitudinal-Data" class="headerlink" title="Leveraging Transformers to Improve Breast Cancer Classification and Risk Assessment with Multi-modal and Longitudinal Data"></a>Leveraging Transformers to Improve Breast Cancer Classification and Risk Assessment with Multi-modal and Longitudinal Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03217">http://arxiv.org/abs/2311.03217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiqiu Shen, Jungkyu Park, Frank Yeung, Eliana Goldberg, Laura Heacock, Farah Shamout, Krzysztof J. Geras</li>
<li>for: 这份研究的目的是为了使用多Modal的显像技术来识别有现在的乳癌患者以及估算有现在无癌的患者会在未来癌症的风险。</li>
<li>methods: 这篇研究使用了多Modal Transformer（MMT），一种神经网络，将ammography和ultrasound联合利用，以实现多Modal的显像数据的联合分析，并且跟踪当前影像与前一次的影像进行比较，以探测当前的变化。</li>
<li>results: 这篇研究获得了1.3百万个检查数据，使用MMT神经网络，实现了AUROC0.943的存在癌患者检测，超过了单一Modal的基准值。此外，这篇研究还可以对5年的风险预测，AUROC0.826，超过了以往的乳癌预测模型。<details>
<summary>Abstract</summary>
Breast cancer screening, primarily conducted through mammography, is often supplemented with ultrasound for women with dense breast tissue. However, existing deep learning models analyze each modality independently, missing opportunities to integrate information across imaging modalities and time. In this study, we present Multi-modal Transformer (MMT), a neural network that utilizes mammography and ultrasound synergistically, to identify patients who currently have cancer and estimate the risk of future cancer for patients who are currently cancer-free. MMT aggregates multi-modal data through self-attention and tracks temporal tissue changes by comparing current exams to prior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 in detecting existing cancers, surpassing strong uni-modal baselines. For 5-year risk prediction, MMT attains an AUROC of 0.826, outperforming prior mammography-based risk models. Our research highlights the value of multi-modal and longitudinal imaging in cancer diagnosis and risk stratification.
</details>
<details>
<summary>摘要</summary>
乳癌检测通常通过胸部X光来进行，但是存在一些问题，如 dense breast tissue 的影响。现有的深度学习模型会分别分析每种成像模式，这会miss opportunities to integrate information across imaging modalities and time。在本研究中，我们介绍 Multi-modal Transformer（MMT），一种神经网络，可以利用胸部X光和ultrasound synergistically，以识别患有乳癌的患者和评估无癌患者是否有未来发癌的风险。MMT通过自注意力和比较当前检测与过去成像来聚合多Modal数据，并且可以跟踪时间变化。我们在 1.3 万个检测数据上训练 MMT，其 AUROC 在检测现有癌病为 0.943，超过了强大的单Modal 基线。而在5年风险预测方面，MMT 的 AUROC 为 0.826，超过了以往基于胸部X光的风险模型。我们的研究表明多Modal和 longitudinal 成像在诊断和风险 stratification 中具有价值。
</details></li>
</ul>
<hr>
<h2 id="PainSeeker-An-Automated-Method-for-Assessing-Pain-in-Rats-Through-Facial-Expressions"><a href="#PainSeeker-An-Automated-Method-for-Assessing-Pain-in-Rats-Through-Facial-Expressions" class="headerlink" title="PainSeeker: An Automated Method for Assessing Pain in Rats Through Facial Expressions"></a>PainSeeker: An Automated Method for Assessing Pain in Rats Through Facial Expressions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03205">http://arxiv.org/abs/2311.03205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liu Liu, Guang Li, Dingfan Deng, Jinhua Yu, Yuan Zong</li>
<li>for: 本研究的目的是 investigate whether laboratory rats’ pain can be automatically assessed through their facial expressions.</li>
<li>methods: 本研究使用了一个新的深度学习方法called PainSeeker，该方法可以自动从动物脸部表情图像中识别痛苦。</li>
<li>results: 实验结果表明，可以通过脸部表情图像来评估啮齿动物的痛苦，并且提出了一种新的痛苦识别方法PainSeeker，该方法可以帮助解决这个新的问题。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
In this letter, we aim to investigate whether laboratory rats' pain can be automatically assessed through their facial expressions. To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation. Each rat' facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS). We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions. PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images. To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset. The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem. The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain.
</details>
<details>
<summary>摘要</summary>
在这封信中，我们想 investigate  Whether laboratory rats' pain can be automatically assessed through their facial expressions. To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation. Each rat's facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS). We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions. PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images. To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset. The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem. The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain.
</details></li>
</ul>
<hr>
<h2 id="LCPR-A-Multi-Scale-Attention-Based-LiDAR-Camera-Fusion-Network-for-Place-Recognition"><a href="#LCPR-A-Multi-Scale-Attention-Based-LiDAR-Camera-Fusion-Network-for-Place-Recognition" class="headerlink" title="LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition"></a>LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03198">http://arxiv.org/abs/2311.03198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZhouZijie77/LCPR">https://github.com/ZhouZijie77/LCPR</a></li>
<li>paper_authors: Zijie Zhou, Jingyi Xu, Guangming Xiong, Junyi Ma</li>
<li>for: 本研究旨在提高自动驾驶车辆在GPS无效环境中识别已经前期访问的地方。</li>
<li>methods: 本研究使用了一种新的神经网络模型，即LCPR，来实现多模式地点识别。LCPR模型将激光点云和多视图RGB图像进行融合，生成特征性强、旋转不变的环境表示。</li>
<li>results: 实验结果表明，LCPR模型能够有效地利用多视图相机和激光数据来提高地点识别性能，同时保持强大的视点变化Robustness。<details>
<summary>Abstract</summary>
Place recognition is one of the most crucial modules for autonomous vehicles to identify places that were previously visited in GPS-invalid environments. Sensor fusion is considered an effective method to overcome the weaknesses of individual sensors. In recent years, multimodal place recognition fusing information from multiple sensors has gathered increasing attention. However, most existing multimodal place recognition methods only use limited field-of-view camera images, which leads to an imbalance between features from different modalities and limits the effectiveness of sensor fusion. In this paper, we present a novel neural network named LCPR for robust multimodal place recognition, which fuses LiDAR point clouds with multi-view RGB images to generate discriminative and yaw-rotation invariant representations of the environment. A multi-scale attention-based fusion module is proposed to fully exploit the panoramic views from different modalities of the environment and their correlations. We evaluate our method on the nuScenes dataset, and the experimental results show that our method can effectively utilize multi-view camera and LiDAR data to improve the place recognition performance while maintaining strong robustness to viewpoint changes. Our open-source code and pre-trained models are available at https://github.com/ZhouZijie77/LCPR .
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>自动驾驶车辆需要进行地点识别以确定先前访问过的地点，尤其在GPS无效环境下。感知融合是一种有效的方法来解决单个感知器的缺陷。在过去几年，多模态地点识别已经吸引了越来越多的关注。然而，大多数现有的多模态地点识别方法只使用有限的视场镜像，这会导致不同模态之间的特征不匹配，限制感知融合的效iveness。在这篇论文中，我们提出了一种新的神经网络模型名为LCPR，它将LiDAR点云与多视角RGB图像融合以生成特征化和旋转变化不敏感的环境表示。我们提出了一种多级注意力基于的混合模块，以便充分利用不同模态环境的全景视图和其相关性。我们在nuScenes数据集上进行了实验，实验结果表明，我们的方法可以有效地利用多视角镜像和LiDAR数据，提高地点识别性能，同时保持强的旋转变化鲁棒性。我们的开源代码和预训练模型可以在https://github.com/ZhouZijie77/LCPR 上获取。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Learning-using-Data-Augmentation-and-Time-Frequency-Transformation-for-Time-Series-Classification"><a href="#Few-shot-Learning-using-Data-Augmentation-and-Time-Frequency-Transformation-for-Time-Series-Classification" class="headerlink" title="Few-shot Learning using Data Augmentation and Time-Frequency Transformation for Time Series Classification"></a>Few-shot Learning using Data Augmentation and Time-Frequency Transformation for Time Series Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03194">http://arxiv.org/abs/2311.03194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang, Zhendong Pang, Jiangpeng Wang, Teng Li<br>for: 这个研究旨在解决时间序列分类任务中的几少数据问题。methods: 本研究提出了一个新的几少数学习框架，通过资料增强的方法来解决这个问题。这个方法包括时间频域的转换和随机删除来生成伪象图像。此外，我们还开发了一个序列几何agram（SSNN）神经网络模型，这个模型由两个子网络组成：一个使用1D遗留层来提取输入序列中的特征，另一个使用2D遗留层来提取几何agram表示中的特征。results: 在实验中，我们与不同的现有DNN模型进行比较，包括对于amyotrophic lateral sclerosis（ALS）dataset和风 турбі缺陷（WTF）dataset的评估。结果显示，我们的提案方法在ALSdataset上 achieve 93.75% F1 score和93.33% accuracy，在WTFdataset上 achieve 95.48% F1 score和95.59% accuracy。这些结果表明了我们的方法可以对时间序列分类任务中的几少数据问题进行解决。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) that tackle the time series classification (TSC) task have provided a promising framework in signal processing. In real-world applications, as a data-driven model, DNNs are suffered from insufficient data. Few-shot learning has been studied to deal with this limitation. In this paper, we propose a novel few-shot learning framework through data augmentation, which involves transformation through the time-frequency domain and the generation of synthetic images through random erasing. Additionally, we develop a sequence-spectrogram neural network (SSNN). This neural network model composes of two sub-networks: one utilizing 1D residual blocks to extract features from the input sequence while the other one employing 2D residual blocks to extract features from the spectrogram representation. In the experiments, comparison studies of different existing DNN models with/without data augmentation are conducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine fault (WTF) dataset. The experimental results manifest that our proposed method achieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48% F1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstrates its applicability of addressing the few-shot problems for time series classification.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在时序分类任务中提供了一个有前途的框架，在实际应用中，作为数据驱动模型，DNN受到了不足的数据的限制。几个步学习被研究以解决这个问题。在这篇论文中，我们提出了一种新的几个步学习框架，通过数据扩充，该框架包括时间频率域的变换和随机磁化生成的 sintetic 图像。此外，我们开发了一种序列spectrogram神经网络（SSNN）模型，该模型由两个子网络组成：一个使用1D residual块来提取输入序列中的特征，另一个使用2D residual块来提取spectrogram表示中的特征。在实验中，我们对不同的现有DNN模型进行了带/无数据扩充的比较研究，并在amyotrophic lateral sclerosis（ALS）数据集和风电机综合缺陷（WTF）数据集上进行了实验。实验结果表明，我们的提议方法在ALS数据集上达到了93.75%的F1分数和93.33%的准确率，在WTF数据集上达到了95.48%的F1分数和95.59%的准确率。我们的方法可以应对几个步学习问题。
</details></li>
</ul>
<hr>
<h2 id="Frequency-Domain-Decomposition-Translation-for-Enhanced-Medical-Image-Translation-Using-GANs"><a href="#Frequency-Domain-Decomposition-Translation-for-Enhanced-Medical-Image-Translation-Using-GANs" class="headerlink" title="Frequency Domain Decomposition Translation for Enhanced Medical Image Translation Using GANs"></a>Frequency Domain Decomposition Translation for Enhanced Medical Image Translation Using GANs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03175">http://arxiv.org/abs/2311.03175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuhui Wang, Jianwei Zuo, Xuliang Deng, Jiajia Luo</li>
<li>for: 这篇论文主要针对的是医学影像转换，即将一个医学影像转换为另一个医学影像，并且保持原始影像的特征信息。</li>
<li>methods: 这篇论文提出了一种新的方法，即频率域分解转换（FDDT），它可以将原始影像分解为高频率和低频率两部分，并将这两部分转换为新的影像。</li>
<li>results: 这篇论文的实验结果显示，FDDT可以比基准模型（GAN）更好地保持原始影像的特征信息，并且可以降低转换后的 Fréchet 实验距离、结构相似度、峰值信号吸引比和平均平方误差。<details>
<summary>Abstract</summary>
Medical Image-to-image translation is a key task in computer vision and generative artificial intelligence, and it is highly applicable to medical image analysis. GAN-based methods are the mainstream image translation methods, but they often ignore the variation and distribution of images in the frequency domain, or only take simple measures to align high-frequency information, which can lead to distortion and low quality of the generated images. To solve these problems, we propose a novel method called frequency domain decomposition translation (FDDT). This method decomposes the original image into a high-frequency component and a low-frequency component, with the high-frequency component containing the details and identity information, and the low-frequency component containing the style information. Next, the high-frequency and low-frequency components of the transformed image are aligned with the transformed results of the high-frequency and low-frequency components of the original image in the same frequency band in the spatial domain, thus preserving the identity information of the image while destroying as little stylistic information of the image as possible. We conduct extensive experiments on MRI images and natural images with FDDT and several mainstream baseline models, and we use four evaluation metrics to assess the quality of the generated images. Compared with the baseline models, optimally, FDDT can reduce Fr\'echet inception distance by up to 24.4%, structural similarity by up to 4.4%, peak signal-to-noise ratio by up to 5.8%, and mean squared error by up to 31%. Compared with the previous method, optimally, FDDT can reduce Fr\'echet inception distance by up to 23.7%, structural similarity by up to 1.8%, peak signal-to-noise ratio by up to 6.8%, and mean squared error by up to 31.6%.
</details>
<details>
<summary>摘要</summary>
医疗图像翻译是计算机视觉和生成人工智能的关键任务，具有广泛的应用前景。GAN基本方法是主流图像翻译方法，但它们经常忽视图像频谱频率域的变化和分布，或者只是对高频信息进行简单的对齐，这可能导致图像生成的质量低下。为解决这些问题，我们提出了一种新的方法called频谱频域分解翻译（FDDT）。这种方法将原始图像分解成高频组件和低频组件，其中高频组件包含细节和标识信息，而低频组件包含风格信息。接着，高频和低频组件的转换结果与原始图像的高频和低频组件在同一频谱域的空间域进行对齐，以保持图像的标识信息，同时尽量少破坏图像的风格信息。我们在MRI图像和自然图像上进行了广泛的实验，并使用了多种主流基线模型。我们使用了四个评价指标来评估生成图像的质量。相比主流基线模型，FDDT最佳情况下可以降低Fréchet抽象距离24.4%、结构相似度4.4%、峰值信号噪声比5.8%和平均方差31%。相比前一方法，FDDT最佳情况下可以降低Fréchet抽象距离23.7%、结构相似度1.8%、峰值信号噪声比6.8%和平均方差31.6%。
</details></li>
</ul>
<hr>
<h2 id="Asymmetric-Masked-Distillation-for-Pre-Training-Small-Foundation-Models"><a href="#Asymmetric-Masked-Distillation-for-Pre-Training-Small-Foundation-Models" class="headerlink" title="Asymmetric Masked Distillation for Pre-Training Small Foundation Models"></a>Asymmetric Masked Distillation for Pre-Training Small Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03149">http://arxiv.org/abs/2311.03149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyu Zhao, Bingkun Huang, Sen Xing, Gangshan Wu, Yu Qiao, Limin Wang</li>
<li>For: This paper focuses on pre-training relatively small vision transformer models that could be efficiently adapted to downstream tasks, with the goal of reducing computational cost and improving deployment.* Methods: The paper proposes a new asymmetric masked distillation (AMD) framework for pre-training relatively small models with autoencoding, which involves an asymmetric masking strategy and customized multi-layer feature alignment between the teacher and student models.* Results: The paper achieves 84.6% classification accuracy on IN1K using the ViT-B model with AMD, and achieves 73.3% classification accuracy on the Something-in-Something V2 dataset with a 3.7% improvement over the original ViT-B model from VideoMAE. Additionally, the paper shows consistent performance improvement over the standard pre-training when transferring AMD pre-trained models to downstream tasks.Here is the simplified Chinese text for the three key information points:* For: 这篇论文关注于预训练相对小的视觉变换器模型，以便更好地适应下游任务，降低计算成本并提高部署。* Methods: 论文提出了一种新的偏向隐藏填充（AMD）框架，用于预训练相对小的模型，其中师模型可以更好地看到更多的上下文信息，而学生模型仍然使用高度隐藏率来原始隐藏预训练。* Results: 论文在IN1K上使用ViT-B模型达到84.6%的分类精度，在Something-in-Something V2数据集上使用ViT-B模型达到73.3%的分类精度，比原始ViT-B模型从VideoMAE中提高3.7%。此外，论文还将预训练AMD模型传输到下游任务，并实现了一致性的性能提升。<details>
<summary>Abstract</summary>
Self-supervised foundation models have shown great potential in computer vision thanks to the pre-training paradigm of masked autoencoding. Scale is a primary factor influencing the performance of these foundation models. However, these large foundation models often result in high computational cost that might limit their deployment. This paper focuses on pre-training relatively small vision transformer models that could be efficiently adapted to downstream tasks. Specifically, taking inspiration from knowledge distillation in model compression, we propose a new asymmetric masked distillation(AMD) framework for pre-training relatively small models with autoencoding. The core of AMD is to devise an asymmetric masking strategy, where the teacher model is enabled to see more context information with a lower masking ratio, while the student model still with high masking ratio to the original masked pre-training. We design customized multi-layer feature alignment between the teacher encoder and student encoder to regularize the pre-training of student MAE. To demonstrate the effectiveness and versatility of AMD, we apply it to both ImageMAE and VideoMAE for pre-training relatively small ViT models. AMD achieved 84.6% classification accuracy on IN1K using the ViT-B model. And AMD achieves 73.3% classification accuracy using the ViT-B model on the Something-in-Something V2 dataset, a 3.7% improvement over the original ViT-B model from VideoMAE. We also transfer AMD pre-trained models to downstream tasks and obtain consistent performance improvement over the standard pre-training.
</details>
<details>
<summary>摘要</summary>
自我超vised基础模型在计算机视觉领域表现出了很大的潜力，这主要归功于预训练 paradigma的masked autoencoding。 however, these large foundation models often result in high computational cost, which may limit their deployment. This paper focuses on pre-training relatively small vision transformer models that could be efficiently adapted to downstream tasks. Specifically, taking inspiration from knowledge distillation in model compression, we propose a new asymmetric masked distillation(AMD) framework for pre-training relatively small models with autoencoding. The core of AMD is to devise an asymmetric masking strategy, where the teacher model is enabled to see more context information with a lower masking ratio, while the student model still with high masking ratio to the original masked pre-training. We design customized multi-layer feature alignment between the teacher encoder and student encoder to regularize the pre-training of student MAE. To demonstrate the effectiveness and versatility of AMD, we apply it to both ImageMAE and VideoMAE for pre-training relatively small ViT models. AMD achieved 84.6% classification accuracy on IN1K using the ViT-B model. And AMD achieves 73.3% classification accuracy using the ViT-B model on the Something-in-Something V2 dataset, a 3.7% improvement over the original ViT-B model from VideoMAE. We also transfer AMD pre-trained models to downstream tasks and obtain consistent performance improvement over the standard pre-training.
</details></li>
</ul>
<hr>
<h2 id="Animating-NeRFs-from-Texture-Space-A-Framework-for-Pose-Dependent-Rendering-of-Human-Performances"><a href="#Animating-NeRFs-from-Texture-Space-A-Framework-for-Pose-Dependent-Rendering-of-Human-Performances" class="headerlink" title="Animating NeRFs from Texture Space: A Framework for Pose-Dependent Rendering of Human Performances"></a>Animating NeRFs from Texture Space: A Framework for Pose-Dependent Rendering of Human Performances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03140">http://arxiv.org/abs/2311.03140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Knoll, Wieland Morgenstern, Anna Hilsmann, Peter Eisert</li>
<li>for: 这个论文的目的是提出一种基于NeRF的高质量、可控的3D人体模型生成方法，用于多视图RGB视频中的人体动作 synthesis。</li>
<li>methods: 该方法使用NeRF来描述人体的形状和动作，并通过skeletal JOINT参数来控制人体的pose和表现。</li>
<li>results: 实验表明，该方法可以生成高质量的人体动作 renderings，包括novel-view和novel-pose synthesis。<details>
<summary>Abstract</summary>
Creating high-quality controllable 3D human models from multi-view RGB videos poses a significant challenge. Neural radiance fields (NeRFs) have demonstrated remarkable quality in reconstructing and free-viewpoint rendering of static as well as dynamic scenes. The extension to a controllable synthesis of dynamic human performances poses an exciting research question. In this paper, we introduce a novel NeRF-based framework for pose-dependent rendering of human performances. In our approach, the radiance field is warped around an SMPL body mesh, thereby creating a new surface-aligned representation. Our representation can be animated through skeletal joint parameters that are provided to the NeRF in addition to the viewpoint for pose dependent appearances. To achieve this, our representation includes the corresponding 2D UV coordinates on the mesh texture map and the distance between the query point and the mesh. To enable efficient learning despite mapping ambiguities and random visual variations, we introduce a novel remapping process that refines the mapped coordinates. Experiments demonstrate that our approach results in high-quality renderings for novel-view and novel-pose synthesis.
</details>
<details>
<summary>摘要</summary>
In our approach, the radiance field is warped around an SMPL body mesh, creating a new surface-aligned representation. Our representation can be animated through skeletal joint parameters provided to the NeRF, in addition to the viewpoint, for pose-dependent appearances. To achieve this, our representation includes the corresponding 2D UV coordinates on the mesh texture map and the distance between the query point and the mesh.To enable efficient learning despite mapping ambiguities and random visual variations, we introduce a novel remapping process that refines the mapped coordinates. Experiments demonstrate that our approach results in high-quality renderings for novel-view and novel-pose synthesis.
</details></li>
</ul>
<hr>
<h2 id="TAMPAR-Visual-Tampering-Detection-for-Parcel-Logistics-in-Postal-Supply-Chains"><a href="#TAMPAR-Visual-Tampering-Detection-for-Parcel-Logistics-in-Postal-Supply-Chains" class="headerlink" title="TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains"></a>TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03124">http://arxiv.org/abs/2311.03124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Naumann, Felix Hertlein, Laura Dörr, Kai Furmans</li>
<li>for: 该论文主要关注的是最后一英里配送阶段，只有一张RGB图像，与现有数据库中的参考图像进行比较，检测 probable appearance changes 可能指示骚乱。</li>
<li>methods: 该论文提出了一个骚乱检测管道，利用锚点检测来确定包裹的八个角点，然后应用投影变换创建正规化的前后平行视图。</li>
<li>results: 该论文的实验结果表明，锚点检测和骚乱检测分别具有75.76%的准确率和81%的准确率，并进行了骚乱类型、镜头扭曲和视角的敏感性分析。Here’s the full text in Simplified Chinese:</li>
<li>for: 该论文主要关注的是最后一英里配送阶段，只有一张RGB图像，与现有数据库中的参考图像进行比较，检测 probable appearance changes 可能指示骚乱。</li>
<li>methods: 该论文提出了一个骚乱检测管道，利用锚点检测来确定包裹的八个角点，然后应用投影变换创建正规化的前后平行视图。</li>
<li>results: 该论文的实验结果表明，锚点检测和骚乱检测分别具有75.76%的准确率和81%的准确率，并进行了骚乱类型、镜头扭曲和视角的敏感性分析。<details>
<summary>Abstract</summary>
Due to the steadily rising amount of valuable goods in supply chains, tampering detection for parcels is becoming increasingly important. In this work, we focus on the use-case last-mile delivery, where only a single RGB image is taken and compared against a reference from an existing database to detect potential appearance changes that indicate tampering. We propose a tampering detection pipeline that utilizes keypoint detection to identify the eight corner points of a parcel. This permits applying a perspective transformation to create normalized fronto-parallel views for each visible parcel side surface. These viewpoint-invariant parcel side surface representations facilitate the identification of signs of tampering on parcels within the supply chain, since they reduce the problem to parcel side surface matching with pair-wise appearance change detection. Experiments with multiple classical and deep learning-based change detection approaches are performed on our newly collected TAMpering detection dataset for PARcels, called TAMPAR. We evaluate keypoint and change detection separately, as well as in a unified system for tampering detection. Our evaluation shows promising results for keypoint (Keypoint AP 75.76) and tampering detection (81% accuracy, F1-Score 0.83) on real images. Furthermore, a sensitivity analysis for tampering types, lens distortion and viewing angles is presented. Code and dataset are available at https://a-nau.github.io/tampar.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unified-Multi-modal-Unsupervised-Representation-Learning-for-Skeleton-based-Action-Understanding"><a href="#Unified-Multi-modal-Unsupervised-Representation-Learning-for-Skeleton-based-Action-Understanding" class="headerlink" title="Unified Multi-modal Unsupervised Representation Learning for Skeleton-based Action Understanding"></a>Unified Multi-modal Unsupervised Representation Learning for Skeleton-based Action Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03106">http://arxiv.org/abs/2311.03106</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HuiGuanLab/UmURL">https://github.com/HuiGuanLab/UmURL</a></li>
<li>paper_authors: Shengkai Sun, Daizong Liu, Jianfeng Dong, Xiaoye Qu, Junyu Gao, Xun Yang, Xun Wang, Meng Wang</li>
<li>for: 提高skeleton-based动作理解的灵活性和可靠性</li>
<li>methods: 提出了一种单流承载多modal自supervised学习框架，通过早期融合策略将多modal输入 feed到同一个流中，并通过内部和外部一致性学习来避免模态偏袋问题</li>
<li>results: 实验表明， compared to单modal方法，该方法可以减少模型复杂度，同时在不同的下游任务场景中实现新的state-of-the-art表现<details>
<summary>Abstract</summary>
Unsupervised pre-training has shown great success in skeleton-based action understanding recently. Existing works typically train separate modality-specific models, then integrate the multi-modal information for action understanding by a late-fusion strategy. Although these approaches have achieved significant performance, they suffer from the complex yet redundant multi-stream model designs, each of which is also limited to the fixed input skeleton modality. To alleviate these issues, in this paper, we propose a Unified Multimodal Unsupervised Representation Learning framework, called UmURL, which exploits an efficient early-fusion strategy to jointly encode the multi-modal features in a single-stream manner. Specifically, instead of designing separate modality-specific optimization processes for uni-modal unsupervised learning, we feed different modality inputs into the same stream with an early-fusion strategy to learn their multi-modal features for reducing model complexity. To ensure that the fused multi-modal features do not exhibit modality bias, i.e., being dominated by a certain modality input, we further propose both intra- and inter-modal consistency learning to guarantee that the multi-modal features contain the complete semantics of each modal via feature decomposition and distinct alignment. In this manner, our framework is able to learn the unified representations of uni-modal or multi-modal skeleton input, which is flexible to different kinds of modality input for robust action understanding in practical cases. Extensive experiments conducted on three large-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that UmURL is highly efficient, possessing the approximate complexity with the uni-modal methods, while achieving new state-of-the-art performance across various downstream task scenarios in skeleton-based action representation learning.
</details>
<details>
<summary>摘要</summary>
近年来，无监督预训练在skeleton基于动作理解中取得了 significiant success。现有的方法通常是在不同的感知模式上分别训练单独的模型，然后通过晚期的融合策略将多modal信息融合为动作理解。虽然这些方法已经实现了显著的性能提升，但它们受到复杂且重复的多流程模型设计的限制，每个模型都受到固定输入skeleton模式的限制。为了解决这些问题，在这篇论文中，我们提出了一种统一多modal无监督学习框架，叫做UmURL，它利用了高效的早期融合策略来同时处理多modal特征。具体来说，而不是为每个感知模式单独进行单 modal无监督学习，我们将不同的感知输入Feed into同一个流程中，通过早期融合策略来学习它们的多modal特征，以降低模型复杂性。为确保多modal特征不受某种感知输入的偏见，我们还提出了内部和外部协调学习，以确保每个感知输入的多modal特征都包含完整的 semantics。这种方法可以学习单 modal或多modal skeleton输入的统一表示，这是对实际应用中不同类型的感知输入的灵活应用。我们在NTU-60、NTU-120和PKU-MMD II等三个大规模数据集上进行了广泛的实验，结果显示，UmURL在性能和复杂度两个方面具有优于单 modal方法，同时在不同的下游任务场景中实现了新的国际纪录。
</details></li>
</ul>
<hr>
<h2 id="A-survey-and-classification-of-face-alignment-methods-based-on-face-models"><a href="#A-survey-and-classification-of-face-alignment-methods-based-on-face-models" class="headerlink" title="A survey and classification of face alignment methods based on face models"></a>A survey and classification of face alignment methods based on face models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03082">http://arxiv.org/abs/2311.03082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jagmohan Meher, Hector Allende-Cid, Torbjörn E. M. Nordling</li>
<li>for: 本研究旨在提供一个面对面的涵义分析，旨在帮助Beginner、实践者和研究人员更好地理解不同的面模型，以及如何在不同情况下使用这些面模型进行面对适应。</li>
<li>methods: 本研究使用了多种不同的面模型，包括基于3D的面模型和基于深度学习的方法，并进行了对这些面模型的解释和训练。</li>
<li>results: 研究发现，在极端面 pose 情况下，3D-based面模型被更多地使用，而深度学习-based方法通常使用热图进行面对适应。  Additionally, the paper discusses the possible future directions of face models in the field of face alignment.<details>
<summary>Abstract</summary>
A face model is a mathematical representation of the distinct features of a human face. Traditionally, face models were built using a set of fiducial points or landmarks, each point ideally located on a facial feature, i.e., corner of the eye, tip of the nose, etc. Face alignment is the process of fitting the landmarks in a face model to the respective ground truth positions in an input image containing a face. Despite significant research on face alignment in the past decades, no review analyses various face models used in the literature. Catering to three types of readers - beginners, practitioners and researchers in face alignment, we provide a comprehensive analysis of different face models used for face alignment. We include the interpretation and training of the face models along with the examples of fitting the face model to a new face image. We found that 3D-based face models are preferred in cases of extreme face pose, whereas deep learning-based methods often use heatmaps. Moreover, we discuss the possible future directions of face models in the field of face alignment.
</details>
<details>
<summary>摘要</summary>
一个人脸模型是一种数学表达人脸特征的模型。过去，人脸模型通常是使用一组定点或标记点建立的，每个点位于人脸特征处，例如眼角、鼻尖等。人脸对alignment是指将这些标记点与输入图像中的真实位置进行对应。虽然过去数十年来有很多关于人脸对alignment的研究，但是没有任何文献对不同的人脸模型进行了全面的分析。为了适应不同类型的读者（ BEGINNER、实践者和研究人员），我们提供了对不同人脸模型的全面分析，包括这些模型的解释和训练，以及将人脸模型适应新的 face image 的示例。我们发现在极端面 pose 的情况下，3D-based人脸模型被更常用，而深度学习基于方法通常使用热图。此外，我们还讨论了人脸模型在面对alignment领域的可能的未来方向。
</details></li>
</ul>
<hr>
<h2 id="CogVLM-Visual-Expert-for-Pretrained-Language-Models"><a href="#CogVLM-Visual-Expert-for-Pretrained-Language-Models" class="headerlink" title="CogVLM: Visual Expert for Pretrained Language Models"></a>CogVLM: Visual Expert for Pretrained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03079">http://arxiv.org/abs/2311.03079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, Ji Qi, Yan Wang, Junhui Ji, Zhuoyi Yang, Lei Zhao, Xixuan Song, Jiazheng Xu, Bin Xu, Juanzi Li, Yuxiao Dong, Ming Ding, Jie Tang</li>
<li>for: 本研究旨在开发一个强大的开源视觉语言基础模型（CogVLM），以便深度融合视觉语言特征。</li>
<li>methods: 本研究使用了一种名为“可训练视觉专家模块”的方法，将图像特征与静止预处理语言模型和图像编码器相连接，从而实现深度融合视觉语言特征。</li>
<li>results: 根据10个跨模态测试benchmark，CogVLM-17B实现了状态的最佳性能，并在VQAv2、OKVQA、TextVQA、COCOcaptioning等测试中名列第二，超过或与PaLI-X 55B匹配。<details>
<summary>Abstract</summary>
We introduce CogVLM, a powerful open-source visual language foundation model. Different from the popular shallow alignment method which maps image features into the input space of language model, CogVLM bridges the gap between the frozen pretrained language model and image encoder by a trainable visual expert module in the attention and FFN layers. As a result, CogVLM enables deep fusion of vision language features without sacrificing any performance on NLP tasks. CogVLM-17B achieves state-of-the-art performance on 10 classic cross-modal benchmarks, including NoCaps, Flicker30k captioning, RefCOCO, RefCOCO+, RefCOCOg, Visual7W, GQA, ScienceQA, VizWiz VQA and TDIUC, and ranks the 2nd on VQAv2, OKVQA, TextVQA, COCO captioning, etc., surpassing or matching PaLI-X 55B. Codes and checkpoints are available at https://github.com/THUDM/CogVLM.
</details>
<details>
<summary>摘要</summary>
我们介绍CogVLM，一种强大的开源视觉语言基础模型。与流行的浅层对应方法不同，CogVLM通过在注意力和FFN层中添加可学习的视觉专家模块，将图像特征与冻结预训练语言模型的输入空间连接起来。这使得CogVLM可以深度融合视觉语言特征，而无需牺牲任何NLPTask的性能。CogVLM-17B在10个经典跨模态benchmark测试中获得了状态机器人表现，包括NoCaps、Flicker30k captioning、RefCOCO、RefCOCO+、RefCOCOg、Visual7W、GQA、ScienceQA、VizWiz VQA和TDIUC，并在VQAv2、OKVQA、TextVQA、COCO captioning等测试中排名第二，超过或匹配PaLI-X 55B。代码和检查点可以在https://github.com/THUDM/CogVLM中获取。
</details></li>
</ul>
<hr>
<h2 id="A-Two-Stage-Generative-Model-with-CycleGAN-and-Joint-Diffusion-for-MRI-based-Brain-Tumor-Detection"><a href="#A-Two-Stage-Generative-Model-with-CycleGAN-and-Joint-Diffusion-for-MRI-based-Brain-Tumor-Detection" class="headerlink" title="A Two-Stage Generative Model with CycleGAN and Joint Diffusion for MRI-based Brain Tumor Detection"></a>A Two-Stage Generative Model with CycleGAN and Joint Diffusion for MRI-based Brain Tumor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03074">http://arxiv.org/abs/2311.03074</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenxin Wang, Zhuo-Xu Cui, Guanxun Cheng, Chentao Cao, Xi Xu, Ziwei Liu, Haifeng Wang, Yulong Qi, Dong Liang, Yanjie Zhu</li>
<li>for: 这个论文的目的是提高脑癌检测和分类的精度。</li>
<li>methods: 这个方法使用了两个关键技术：CycleGAN和VE-JP。CycleGAN在无标的数据上训练，将健康图像转换为异常图像，作为数据先验。VE-JP则是使用共同分布来重建健康图像，将异常区域修复为健康区域。</li>
<li>results: 这个方法在三个数据集上进行验证，与其他无标的方法进行比较。结果显示，这个方法在脑癌检测和分类中表现出色，DSC分数为0.8590、0.6226和0.7403。<details>
<summary>Abstract</summary>
Accurate detection and segmentation of brain tumors is critical for medical diagnosis. However, current supervised learning methods require extensively annotated images and the state-of-the-art generative models used in unsupervised methods often have limitations in covering the whole data distribution. In this paper, we propose a novel framework Two-Stage Generative Model (TSGM) that combines Cycle Generative Adversarial Network (CycleGAN) and Variance Exploding stochastic differential equation using joint probability (VE-JP) to improve brain tumor detection and segmentation. The CycleGAN is trained on unpaired data to generate abnormal images from healthy images as data prior. Then VE-JP is implemented to reconstruct healthy images using synthetic paired abnormal images as a guide, which alters only pathological regions but not regions of healthy. Notably, our method directly learned the joint probability distribution for conditional generation. The residual between input and reconstructed images suggests the abnormalities and a thresholding method is subsequently applied to obtain segmentation results. Furthermore, the multimodal results are weighted with different weights to improve the segmentation accuracy further. We validated our method on three datasets, and compared with other unsupervised methods for anomaly detection and segmentation. The DSC score of 0.8590 in BraTs2020 dataset, 0.6226 in ITCS dataset and 0.7403 in In-house dataset show that our method achieves better segmentation performance and has better generalization.
</details>
<details>
<summary>摘要</summary>
严格的脑肿检测和分割是医学诊断中的关键。然而，当前的指导学习方法需要大量的标注图像，而状态之前的生成模型通常有覆盖整个数据分布的限制。在这篇论文中，我们提出了一种新的框架 Two-Stage Generative Model (TSGM)，它将 Cycle Generative Adversarial Network (CycleGAN) 和 Variance Exploding stochastic differential equation using joint probability (VE-JP) 结合以提高脑肿检测和分割。CycleGAN 在没有对应的数据上训练，将健康图像转换成病态图像作为数据先验。然后，VE-JP 被实现以使用生成的合理的假样图像作为引导，重构健康图像，只有病理区域受到改变，而不是健康区域。值得注意的是，我们的方法直接学习了联合分布的联合概率分布。输入图像和重构图像之间的差异指示了病理，并且使用了阈值法来获得分割结果。此外，我们还使用了不同的权重来进一步提高分割精度。我们在三个数据集上验证了我们的方法，并与其他无监督方法进行了对比。BraTs2020 数据集的 DSC 分数为 0.8590，ITCS 数据集的 DSC 分数为 0.6226，In-house 数据集的 DSC 分数为 0.7403，这些结果表明我们的方法在分割性能方面表现出色，并且具有更好的普适性。
</details></li>
</ul>
<hr>
<h2 id="OrthoNets-Orthogonal-Channel-Attention-Networks"><a href="#OrthoNets-Orthogonal-Channel-Attention-Networks" class="headerlink" title="OrthoNets: Orthogonal Channel Attention Networks"></a>OrthoNets: Orthogonal Channel Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03071">http://arxiv.org/abs/2311.03071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Salman, Caleb Parks, Matthew Swan, John Gauch</li>
<li>For: The paper aims to design an effective channel attention mechanism that can find optimal feature representation using a lossy-compression method.* Methods: The paper uses Discrete Cosine Transforms (DCTs) to find information-rich compression and randomly initialized orthogonal filters to construct an attention mechanism.* Results: The paper shows superior performance compared to other attention mechanisms on several datasets, including Birds, MS-COCO, and Places356, and competes with the current state-of-the-art on the ImageNet dataset. The results suggest that an optimal choice of filter is elusive, and generalization can be achieved with a sufficiently large number of orthogonal filters.<details>
<summary>Abstract</summary>
Designing an effective channel attention mechanism implores one to find a lossy-compression method allowing for optimal feature representation. Despite recent progress in the area, it remains an open problem. FcaNet, the current state-of-the-art channel attention mechanism, attempted to find such an information-rich compression using Discrete Cosine Transforms (DCTs). One drawback of FcaNet is that there is no natural choice of the DCT frequencies. To circumvent this issue, FcaNet experimented on ImageNet to find optimal frequencies. We hypothesize that the choice of frequency plays only a supporting role and the primary driving force for the effectiveness of their attention filters is the orthogonality of the DCT kernels. To test this hypothesis, we construct an attention mechanism using randomly initialized orthogonal filters. Integrating this mechanism into ResNet, we create OrthoNet. We compare OrthoNet to FcaNet (and other attention mechanisms) on Birds, MS-COCO, and Places356 and show superior performance. On the ImageNet dataset, our method competes with or surpasses the current state-of-the-art. Our results imply that an optimal choice of filter is elusive and generalization can be achieved with a sufficiently large number of orthogonal filters. We further investigate other general principles for implementing channel attention, such as its position in the network and channel groupings.
</details>
<details>
<summary>摘要</summary>
设计有效的通道注意机制需要一种lossy压缩方法，以便最佳化特征表示。尽管最近在这个领域的进步，但这问题仍然未解决。FcaNet，当前领先的通道注意机制，使用Discrete Cosine Transforms（DCTs）来找到信息密集的压缩。FcaNet的一个缺点是没有自然的DCT频率选择。为了解决这个问题，FcaNet在ImageNet上进行了实验。我们假设选择频率只是支持性的角色，主要驱动力是DCT核函数的正交性。为测试这个假设，我们构建了一个使用随机初始化的正交滤波器的注意机制。将这种机制integrated into ResNet，我们创建了OrthoNet。我们与FcaNet（以及其他注意机制）在Birds、MS-COCO和Places356上进行比较，并显示出超越性。在ImageNet dataset上，我们的方法与当前领先的方法竞争。我们的结果表明，选择最佳的滤波器是抽象的，通过一个充分大的正交滤波器数量，可以实现泛化。我们进一步调查了其他实现通道注意的一般原则，如其位置在网络中和通道分组。
</details></li>
</ul>
<hr>
<h2 id="Forest-aboveground-biomass-estimation-using-GEDI-and-earth-observation-data-through-attention-based-deep-learning"><a href="#Forest-aboveground-biomass-estimation-using-GEDI-and-earth-observation-data-through-attention-based-deep-learning" class="headerlink" title="Forest aboveground biomass estimation using GEDI and earth observation data through attention-based deep learning"></a>Forest aboveground biomass estimation using GEDI and earth observation data through attention-based deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03067">http://arxiv.org/abs/2311.03067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenquan Dong, Edward T. A. Mitchard, Hao Yu, Steven Hancock, Casey M. Ryan</li>
<li>for: 这个研究的目的是用深度学习方法来估计遥感数据中的森林上空生物质量（AGB），以便更好地理解气候变化中的碳会计。</li>
<li>methods: 这个研究使用了一种新的注意力深度学习方法来估计森林AGB，主要使用了公开 accessible的遥感数据，包括GEDI LiDAR数据、C-band Sentinel-1 SAR数据、ALOS-2 PALSAR-2数据和Sentinel-2多spectral数据。</li>
<li>results: 这个研究发现，使用注意力深度学习方法可以对森林AGB估计得到明显更高的准确性，比传统的 Random Forest 算法高。特别是，AU 模型在 R2 方面达到了 0.66，RMSE 为 43.66 Mg ha-1，偏差为 0.14 Mg ha-1，而 Random Forest 算法只有 R2 为 0.62，RMSE 为 45.87 Mg ha-1，偏差为 1.09 Mg ha-1。此外，这个研究还发现，使用注意力深度学习方法可以减少遥感数据中的空间信息，从而提高了 AGB 估计的准确性。<details>
<summary>Abstract</summary>
Accurate quantification of forest aboveground biomass (AGB) is critical for understanding carbon accounting in the context of climate change. In this study, we presented a novel attention-based deep learning approach for forest AGB estimation, primarily utilizing openly accessible EO data, including: GEDI LiDAR data, C-band Sentinel-1 SAR data, ALOS-2 PALSAR-2 data, and Sentinel-2 multispectral data. The attention UNet (AU) model achieved markedly higher accuracy for biomass estimation compared to the conventional RF algorithm. Specifically, the AU model attained an R2 of 0.66, RMSE of 43.66 Mg ha-1, and bias of 0.14 Mg ha-1, while RF resulted in lower scores of R2 0.62, RMSE 45.87 Mg ha-1, and bias 1.09 Mg ha-1. However, the superiority of the deep learning approach was not uniformly observed across all tested models. ResNet101 only achieved an R2 of 0.50, an RMSE of 52.93 Mg ha-1, and a bias of 0.99 Mg ha-1, while the UNet reported an R2 of 0.65, an RMSE of 44.28 Mg ha-1, and a substantial bias of 1.84 Mg ha-1. Moreover, to explore the performance of AU in the absence of spatial information, fully connected (FC) layers were employed to eliminate spatial information from the remote sensing data. AU-FC achieved intermediate R2 of 0.64, RMSE of 44.92 Mgha-1, and bias of -0.56 Mg ha-1, outperforming RF but underperforming AU model using spatial information. We also generated 10m forest AGB maps across Guangdong for the year 2019 using AU and compared it with that produced by RF. The AGB distributions from both models showed strong agreement with similar mean values; the mean forest AGB estimated by AU was 102.18 Mg ha-1 while that of RF was 104.84 Mg ha-1. Additionally, it was observed that the AGB map generated by AU provided superior spatial information. Overall, this research substantiates the feasibility of employing deep learning for biomass estimation based on satellite data.
</details>
<details>
<summary>摘要</summary>
“精确量化森林上空生物质量（AGB）是气候变化研究中非常重要的。本研究发表了一种基于深度学习的新型注意力模型（AU），用于森林AGB估计，主要使用开放式的卫星数据，包括：GEDI LiDAR数据、C-band Sentinel-1 SAR数据、ALOS-2 PALSAR-2数据和Sentinel-2多spectral数据。AU模型在AGB估计中表现出色，相比于传统的RF算法，具有更高的准确性。具体来说，AU模型的R2值为0.66，RMSE值为43.66吨 ha-1，偏差值为0.14吨 ha-1，而RF的R2值为0.62，RMSE值为45.87吨 ha-1，偏差值为1.09吨 ha-1。然而，深度学习方法的优势不uniform地遍布所有测试模型。ResNet101模型只有R2值为0.50，RMSE值为52.93吨 ha-1，偏差值为0.99吨 ha-1，而UNet模型则有R2值为0.65，RMSE值为44.28吨 ha-1，并且具有较大的偏差值1.84吨 ha-1。此外，为了探讨AU在没有空间信息的情况下的表现，FC层被用来删除卫星数据中的空间信息。AU-FC模型在R2值为0.64，RMSE值为44.92吨 ha-1，偏差值为-0.56吨 ha-1，与RF模型相比，具有更高的准确性。此外，我们还生成了2019年在广东省的10米森林AGB地图，使用AU模型，并与RF模型生成的地图进行比较。AU模型生成的AGB分布和RF模型生成的AGB分布之间有强相似性，两者的mean值几乎相同。”
</details></li>
</ul>
<hr>
<h2 id="AnyText-Multilingual-Visual-Text-Generation-And-Editing"><a href="#AnyText-Multilingual-Visual-Text-Generation-And-Editing" class="headerlink" title="AnyText: Multilingual Visual Text Generation And Editing"></a>AnyText: Multilingual Visual Text Generation And Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03054">http://arxiv.org/abs/2311.03054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Tuo, Wangmeng Xiang, Jun-Yan He, Yifeng Geng, Xuansong Xie</li>
<li>for: 这个论文主要写于如何使用扩散模型实现高精度的文本图像生成和修改。</li>
<li>methods: 该模型包括一个扩散管道，包括auxiliary latent module和text embedding module。auxiliary latent module使用文本字形、位置和masked image生成latent特征，而text embedding module使用OCR模型将笔画数据编码为嵌入，这些嵌入与图像标签器生成的文本嵌入混合以生成高一致的文本。</li>
<li>results: 经过训练并测试，这种方法在多种语言下能够高精度地生成和修改文本图像，并且在多种评价指标上与其他方法有着显著的差异。此外，我们还提供了一个大规模的多语言文本图像集，名为AnyWord-3M，以及基于这个集的AnyText-benchmark评价指标。<details>
<summary>Abstract</summary>
Diffusion model based Text-to-Image has achieved impressive achievements recently. Although current technology for synthesizing images is highly advanced and capable of generating images with high fidelity, it is still possible to give the show away when focusing on the text area in the generated image. To address this issue, we introduce AnyText, a diffusion-based multilingual visual text generation and editing model, that focuses on rendering accurate and coherent text in the image. AnyText comprises a diffusion pipeline with two primary elements: an auxiliary latent module and a text embedding module. The former uses inputs like text glyph, position, and masked image to generate latent features for text generation or editing. The latter employs an OCR model for encoding stroke data as embeddings, which blend with image caption embeddings from the tokenizer to generate texts that seamlessly integrate with the background. We employed text-control diffusion loss and text perceptual loss for training to further enhance writing accuracy. AnyText can write characters in multiple languages, to the best of our knowledge, this is the first work to address multilingual visual text generation. It is worth mentioning that AnyText can be plugged into existing diffusion models from the community for rendering or editing text accurately. After conducting extensive evaluation experiments, our method has outperformed all other approaches by a significant margin. Additionally, we contribute the first large-scale multilingual text images dataset, AnyWord-3M, containing 3 million image-text pairs with OCR annotations in multiple languages. Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality. Our project will be open-sourced on https://github.com/tyxsspa/AnyText to improve and promote the development of text generation technology.
</details>
<details>
<summary>摘要</summary>
“传播模型基于文本至图像技术在最近得到了很多成就。 although current technology for synthesizing images is highly advanced and capable of generating images with high fidelity, it is still possible to give the show away when focusing on the text area in the generated image. To address this issue, we introduce AnyText, a diffusion-based multilingual visual text generation and editing model, that focuses on rendering accurate and coherent text in the image. AnyText consists of a diffusion pipeline with two primary elements: an auxiliary latent module and a text embedding module. The former uses inputs such as text glyph, position, and masked image to generate latent features for text generation or editing. The latter employs an OCR model for encoding stroke data as embeddings, which blend with image caption embeddings from the tokenizer to generate texts that seamlessly integrate with the background. We used text-control diffusion loss and text perceptual loss for training to further enhance writing accuracy. AnyText can write characters in multiple languages, to the best of our knowledge, this is the first work to address multilingual visual text generation. It is worth mentioning that AnyText can be plugged into existing diffusion models from the community for rendering or editing text accurately. After conducting extensive evaluation experiments, our method has outperformed all other approaches by a significant margin. Additionally, we contribute the first large-scale multilingual text images dataset, AnyWord-3M, containing 3 million image-text pairs with OCR annotations in multiple languages. Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality. Our project will be open-sourced on https://github.com/tyxsspa/AnyText to improve and promote the development of text generation technology.”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="MixUp-MIL-A-Study-on-Linear-Multilinear-Interpolation-Based-Data-Augmentation-for-Whole-Slide-Image-Classification"><a href="#MixUp-MIL-A-Study-on-Linear-Multilinear-Interpolation-Based-Data-Augmentation-for-Whole-Slide-Image-Classification" class="headerlink" title="MixUp-MIL: A Study on Linear &amp; Multilinear Interpolation-Based Data Augmentation for Whole Slide Image Classification"></a>MixUp-MIL: A Study on Linear &amp; Multilinear Interpolation-Based Data Augmentation for Whole Slide Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03052">http://arxiv.org/abs/2311.03052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Gadermayr, Lukas Koller, Maximilian Tschuchnig, Lea Maria Stangassinger, Christina Kreutzer, Sebastien Couillard-Despres, Gertie Janneke Oostingh, Anton Hittmair</li>
<li>for: 这篇论文探讨了在没有像素级标注的情况下，如何类别数位全面图像。</li>
<li>methods: 本论文使用了多个例子学习方法，并调查了线性和多线性 interpolate 技术作为数据增强技术的影响。</li>
<li>results: 实验结果显示了高度的数据分布差异，并发现了一些有趣的特点和探索新的研究方向。<details>
<summary>Abstract</summary>
For classifying digital whole slide images in the absence of pixel level annotation, typically multiple instance learning methods are applied. Due to the generic applicability, such methods are currently of very high interest in the research community, however, the issue of data augmentation in this context is rarely explored. Here we investigate linear and multilinear interpolation between feature vectors, a data augmentation technique, which proved to be capable of improving the generalization performance classification networks and also for multiple instance learning. Experiments, however, have been performed on only two rather small data sets and one specific feature extraction approach so far and a strong dependence on the data set has been identified. Here we conduct a large study incorporating 10 different data set configurations, two different feature extraction approaches (supervised and self-supervised), stain normalization and two multiple instance learning architectures. The results showed an extraordinarily high variability in the effect of the method. We identified several interesting aspects to bring light into the darkness and identified novel promising fields of research.
</details>
<details>
<summary>摘要</summary>
为了在无像素级标注的情况下分类数字整张图像，通常采用多实例学习方法。由于其普适性，这些方法目前在研究 сообществе具有非常高的兴趣度，但数据增强在这个上下文中的问题却rarely explored。我们在这里调查了线性和多线性 interpolate between feature vectors，一种数据增强技术，并证明其能够提高分类网络的泛化性能和多实例学习。然而，我们在只有两个较小数据集和一种特定的特征提取方法上进行了实验，并且发现了数据集强度的依赖关系。在这里，我们进行了大规模的研究，包括10种不同的数据集配置、两种不同的特征提取方法（有监督和无监督）、染料 норmalization和两种多实例学习架构。结果显示了非常高的变化性，我们 indentified several interesting aspects to bring light into the darkness, and identified novel promising fields of research.
</details></li>
</ul>
<hr>
<h2 id="COLA-COarse-LAbel-multi-source-LiDAR-semantic-segmentation-for-autonomous-driving"><a href="#COLA-COarse-LAbel-multi-source-LiDAR-semantic-segmentation-for-autonomous-driving" class="headerlink" title="COLA: COarse-LAbel multi-source LiDAR semantic segmentation for autonomous driving"></a>COLA: COarse-LAbel multi-source LiDAR semantic segmentation for autonomous driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03017">http://arxiv.org/abs/2311.03017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jules Sanchez, Jean-Emmanuel Deschaud, François Goulette</li>
<li>for: 提高 LiDAR semantic segmentation 的Results，特别是在领域扩展、源到源 segmentation 和预训练方面。</li>
<li>methods: 提出了一种新的多源训练方法，利用不同的数据集合在一起进行训练，以提高 LiDAR semantic segmentation 的Results。</li>
<li>results: 在不同的应用方面（领域扩展、源到源 segmentation 和预训练）中，提出了系统性的改进（最高提升 +12%），证明了多源训练的效果。<details>
<summary>Abstract</summary>
LiDAR semantic segmentation for autonomous driving has been a growing field of interest in the past few years. Datasets and methods have appeared and expanded very quickly, but methods have not been updated to exploit this new availability of data and continue to rely on the same classical datasets.   Different ways of performing LIDAR semantic segmentation training and inference can be divided into several subfields, which include the following: domain generalization, the ability to segment data coming from unseen domains ; source-to-source segmentation, the ability to segment data coming from the training domain; and pre-training, the ability to create re-usable geometric primitives.   In this work, we aim to improve results in all of these subfields with the novel approach of multi-source training. Multi-source training relies on the availability of various datasets at training time and uses them together rather than relying on only one dataset.   To overcome the common obstacles found for multi-source training, we introduce the coarse labels and call the newly created multi-source dataset COLA. We propose three applications of this new dataset that display systematic improvement over single-source strategies: COLA-DG for domain generalization (up to +10%), COLA-S2S for source-to-source segmentation (up to +5.3%), and COLA-PT for pre-training (up to +12%).
</details>
<details>
<summary>摘要</summary>
隐藏文本LiDAR语义分割 для自动驾驶在最近几年来得到了越来越多的关注。数据集和方法在不断增加，但方法没有适应新的数据可用性，仍然依赖于传统的数据集。不同的LiDAR语义分割训练和推断方法可以分为以下几个子领域：领域泛化、源到源语义分割和预训练。在这项工作中，我们目的是提高这些子领域的结果，使用新的多源训练方法。多源训练利用训练时可用的多个数据集，而不是仅仅依赖于一个数据集。为了解决多源训练中常见的障碍，我们引入粗略标签，并将其与多源数据集组合而成的新数据集命名为COLA。我们提出了三种应用COLA数据集，显示了对单源策略的系统性提高（最多+10%）：COLA-DG для领域泛化（最多+10%）、COLA-S2S для源到源语义分割（最多+5.3%）和COLA-PT для预训练（最多+12%）。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Capability-of-Text-to-Image-Diffusion-Models-with-Structural-Edge-Guidance-for-Multi-Spectral-Satellite-Image-Inpainting"><a href="#Exploring-the-Capability-of-Text-to-Image-Diffusion-Models-with-Structural-Edge-Guidance-for-Multi-Spectral-Satellite-Image-Inpainting" class="headerlink" title="Exploring the Capability of Text-to-Image Diffusion Models with Structural Edge Guidance for Multi-Spectral Satellite Image Inpainting"></a>Exploring the Capability of Text-to-Image Diffusion Models with Structural Edge Guidance for Multi-Spectral Satellite Image Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03008">http://arxiv.org/abs/2311.03008</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikolaj Czerkawski, Christos Tachtatzis</li>
<li>for: 这个论文探讨了文本到图像填充模型在卫星图像数据上的可用性。</li>
<li>methods: 论文提出了一种基于StableDiffusion和ControlNet的新填充框架，以及一种RGB-to-MSI的翻译方法来解决填充过程中的两个技术挑战。</li>
<li>results: 研究结果表明，通过StableDiffusion进行填充会出现不жела的artefacts，而一种简单的自动内部填充方法可以达到更高质量的填充Synthesis。<details>
<summary>Abstract</summary>
The paper investigates the utility of text-to-image inpainting models for satellite image data. Two technical challenges of injecting structural guiding signals into the generative process as well as translating the inpainted RGB pixels to a wider set of MSI bands are addressed by introducing a novel inpainting framework based on StableDiffusion and ControlNet as well as a novel method for RGB-to-MSI translation. The results on a wider set of data suggest that the inpainting synthesized via StableDiffusion suffers from undesired artefacts and that a simple alternative of self-supervised internal inpainting achieves higher quality of synthesis.
</details>
<details>
<summary>摘要</summary>
文章研究了使用文本到图像恢复模型来处理卫星图像数据的可用性。两个技术挑战，即在生成过程中插入结构导向信号以及将恢复后的RGB像素翻译到更广泛的MSI频谱中，通过引入稳定扩散和控制网络等新框架，以及一种新的RGB-to-MSI翻译方法来解决。对于更广泛的数据集，研究发现使用稳定扩散恢复后会出现不良特征，而自动内部填充方法可以达到更高质量的恢复。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Enhancement-of-Low-Light-Image-Based-on-Retinex-Decomposition"><a href="#Zero-Shot-Enhancement-of-Low-Light-Image-Based-on-Retinex-Decomposition" class="headerlink" title="Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition"></a>Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02995">http://arxiv.org/abs/2311.02995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenchao Li, Bangshu Xiong, Qiaofeng Ou, Xiaoyun Long, Jinhao Zhu, Jiabao Chen, Shuyuan Wen</li>
<li>for: 提高低光照图像的修剪和增强</li>
<li>methods: 提出了一种基于学习的Retinex分解方法，即ZERRINNet，通过对原始低光照图像进行降噪、估计雷达组件和照明组件，并通过тексту预测损失和分割平滑损失来约束雷达组件和照明组件，以解决低光照图像中的颜色扭曲、对比度和雷达问题。</li>
<li>results: 在homemade实际低光照数据集和高级视觉任务上进行了有效验证，并与多个公共数据集进行了比较性试验，结果表明我们的方法与当前状态的艺术方法竞争。代码可以在<a target="_blank" rel="noopener" href="https://github.com/liwenchao0615/ZERRINNet%E4%B8%AD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/liwenchao0615/ZERRINNet中获取。</a><details>
<summary>Abstract</summary>
Two difficulties here make low-light image enhancement a challenging task; firstly, it needs to consider not only luminance restoration but also image contrast, image denoising and color distortion issues simultaneously. Second, the effectiveness of existing low-light enhancement methods depends on paired or unpaired training data with poor generalization performance.   To solve these difficult problems, we propose in this paper a new learning-based Retinex decomposition of zero-shot low-light enhancement method, called ZERRINNet. To this end, we first designed the N-Net network, together with the noise loss term, to be used for denoising the original low-light image by estimating the noise of the low-light image. Moreover, RI-Net is used to estimate the reflection component and illumination component, and in order to solve the color distortion and contrast, we use the texture loss term and segmented smoothing loss to constrain the reflection component and illumination component. Finally, our method is a zero-reference enhancement method that is not affected by the training data of paired and unpaired datasets, so our generalization performance is greatly improved, and in the paper, we have effectively validated it with a homemade real-life low-light dataset and additionally with advanced vision tasks, such as face detection, target recognition, and instance segmentation. We conducted comparative experiments on a large number of public datasets and the results show that the performance of our method is competitive compared to the current state-of-the-art methods. The code is available at:https://github.com/liwenchao0615/ZERRINNet
</details>
<details>
<summary>摘要</summary>
两个难点使低光照图像增强成为一项困难的任务，一是需要同时考虑照度还原、图像对比度、雷达噪声和颜色扭曲问题。二是现有的低光照增强方法的效果受到对照或无照训练数据的影响，导致对新数据的泛化性能不佳。为解决这两个难题，我们在本文提出了一种新的学习基于Retinex decomposición的零参估低光照增强方法，称为ZERRINNet。为此，我们首先设计了N-Net网络，并与噪声损失项一起用于对原始低光照图像进行降噪。其次，RI-Net用于估计反射组件和照明组件，以解决颜色扭曲和对比度问题。 finally，我们的方法是一种零参增强方法，不受照或无照训练数据的影响，因此我们的泛化性能得到了大幅提高。在论文中，我们有效地验证了我们的方法，使用自己制作的实际低光照 dataset 以及高级视觉任务，如人脸检测、目标识别和实例 segmentation。我们对大量公共数据进行了比较 эксперименты，结果显示我们的方法与当前状态的艺术方法竞争力。代码可以在：https://github.com/liwenchao0615/ZERRINNet 获取。
</details></li>
</ul>
<hr>
<h2 id="NEURO-HAND-A-weakly-supervised-Hierarchical-Attention-Network-for-neuroimaging-abnormality-Detection"><a href="#NEURO-HAND-A-weakly-supervised-Hierarchical-Attention-Network-for-neuroimaging-abnormality-Detection" class="headerlink" title="NEURO HAND: A weakly supervised Hierarchical Attention Network for neuroimaging abnormality Detection"></a>NEURO HAND: A weakly supervised Hierarchical Attention Network for neuroimaging abnormality Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02992">http://arxiv.org/abs/2311.02992</a></li>
<li>repo_url: None</li>
<li>paper_authors: David A. Wood</li>
<li>for: 用于临床神经成像数据中的异常检测</li>
<li>methods: 使用幂等注意力网络，适用于非体积数据（即高分辨率MRI扫描堆），可以从二进制检查级别标签进行训练</li>
<li>results: 提高分类精度，并提供了解释性的幂等扫描和序列级别异常localization，或者给出不同扫描和序列的重要性分数，适用于自动化 radiology 部门的检测系统<details>
<summary>Abstract</summary>
Clinical neuroimaging data is naturally hierarchical. Different magnetic resonance imaging (MRI) sequences within a series, different slices covering the head, and different regions within each slice all confer different information. In this work we present a hierarchical attention network for abnormality detection using MRI scans obtained in a clinical hospital setting. The proposed network is suitable for non-volumetric data (i.e. stacks of high-resolution MRI slices), and can be trained from binary examination-level labels. We show that this hierarchical approach leads to improved classification, while providing interpretability through either coarse inter- and intra-slice abnormality localisation, or giving importance scores for different slices and sequences, making our model suitable for use as an automated triaging system in radiology departments.
</details>
<details>
<summary>摘要</summary>
临床神经成像数据自然归于层次结构。不同的核磁共振成像（MRI）序列内一系列、不同的剖面覆盖头部、和每个剖面中的不同区域都提供不同的信息。在这个工作中，我们提出了一种层次注意力网络用于临床MRI扫描中的异常检测。我们的提案的网络适用于非量化数据（即高分辨率MRI剖面栈），并可以从二进制评估级别标签进行训练。我们显示了这种层次方法可以提高分类，同时提供可解释性，通过粗略的跨剖面和内部剖面异常Localization，或者给出不同剖面和序列的重要性分数，使我们的模型适用于软件自动排查系统中。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-based-Radiotherapy-Dose-Prediction-Guided-by-Inter-slice-Aware-Structure-Encoding"><a href="#Diffusion-based-Radiotherapy-Dose-Prediction-Guided-by-Inter-slice-Aware-Structure-Encoding" class="headerlink" title="Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware Structure Encoding"></a>Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware Structure Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02991">http://arxiv.org/abs/2311.02991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenghao Feng, Lu Wen, Jianghong Xiao, Yuanyuan Xu, Xi Wu, Jiliu Zhou, Xingchen Peng, Yan Wang</li>
<li>for: 这个研究旨在提高 radiotherapy 规划中的剂量分布预测精度，并且解决常用的 L1 或 L2 损失函数导致的过滤问题。</li>
<li>methods: 本研究提出了一种基于扩散模型的剂量分布预测方法（DiffDose），它包括一个前向过程和一个反向过程。在前向过程中，DiffDose 将剂量分布图像转化为纯 Gaussian 噪声图像，并同时训练一个噪声预测器来估算添加的噪声。在反向过程中，它逐步除去噪声，并最终输出预测的剂量分布图像。</li>
<li>results: 研究结果表明，DiffDose 可以减少过滤问题，并提高 radiotherapy 规划中剂量分布预测精度。<details>
<summary>Abstract</summary>
Deep learning (DL) has successfully automated dose distribution prediction in radiotherapy planning, enhancing both efficiency and quality. However, existing methods suffer from the over-smoothing problem for their commonly used L1 or L2 loss with posterior average calculations. To alleviate this limitation, we propose a diffusion model-based method (DiffDose) for predicting the radiotherapy dose distribution of cancer patients. Specifically, the DiffDose model contains a forward process and a reverse process. In the forward process, DiffDose transforms dose distribution maps into pure Gaussian noise by gradually adding small noise and a noise predictor is simultaneously trained to estimate the noise added at each timestep. In the reverse process, it removes the noise from the pure Gaussian noise in multiple steps with the well-trained noise predictor and finally outputs the predicted dose distribution maps...
</details>
<details>
<summary>摘要</summary>
深度学习（DL）已成功地自动预测放疗规划中的剂量分布，提高了效率和质量。然而，现有方法受到L1或L2损失函数的过滤问题的限制。为解决这个局限性，我们提出了基于扩散模型的放疗剂量预测方法（DiffDose）。具体来说，DiffDose模型包括前向过程和反向过程。在前向过程中，DiffDose将剂量分布图转换成纯 Gaussian 噪声，通过逐步添加小噪声并同时训练噪声预测器来估算添加的噪声。在反向过程中，它逐步从纯 Gaussian 噪声中除噪，使用已经训练好的噪声预测器，并最终输出预测的剂量分布图。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Deep-Representation-Learning-via-Layerwise-Feature-Compression-and-Discrimination"><a href="#Understanding-Deep-Representation-Learning-via-Layerwise-Feature-Compression-and-Discrimination" class="headerlink" title="Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination"></a>Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02960">http://arxiv.org/abs/2311.02960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Xiao Li, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu</li>
<li>for: 本研究旨在探讨深度学习网络在层次特征学习中的具体过程，即如何在深度网络中层次抽象特征。</li>
<li>methods: 本研究使用深度线性网络进行实验研究，并定义了内部特征压缩和between-class特征分化两个指标来量化特征的演化趋势。</li>
<li>results: 研究结果表明，在近正交输入数据和最小 нор减重、平衡和低矩的网络参数下，每层的线性网络都会压缩内部特征 geometric rate，并在数据流经多层后进行 linear rate 的 between-class特征分化。这是深度线性网络层次特征学习的首次量化特征描述。<details>
<summary>Abstract</summary>
Over the past decade, deep learning has proven to be a highly effective tool for learning meaningful features from raw data. However, it remains an open question how deep networks perform hierarchical feature learning across layers. In this work, we attempt to unveil this mystery by investigating the structures of intermediate features. Motivated by our empirical findings that linear layers mimic the roles of deep layers in nonlinear networks for feature learning, we explore how deep linear networks transform input data into output by investigating the output (i.e., features) of each layer after training in the context of multi-class classification problems. Toward this goal, we first define metrics to measure within-class compression and between-class discrimination of intermediate features, respectively. Through theoretical analysis of these two metrics, we show that the evolution of features follows a simple and quantitative pattern from shallow to deep layers when the input data is nearly orthogonal and the network weights are minimum-norm, balanced, and approximate low-rank: Each layer of the linear network progressively compresses within-class features at a geometric rate and discriminates between-class features at a linear rate with respect to the number of layers that data have passed through. To the best of our knowledge, this is the first quantitative characterization of feature evolution in hierarchical representations of deep linear networks. Empirically, our extensive experiments not only validate our theoretical results numerically but also reveal a similar pattern in deep nonlinear networks which aligns well with recent empirical studies. Moreover, we demonstrate the practical implications of our results in transfer learning. Our code is available at \url{https://github.com/Heimine/PNC_DLN}.
</details>
<details>
<summary>摘要</summary>
过去一个十年，深度学习已经证明是一种非常有效的工具来学习原始数据中的有意义特征。然而，仍然是一个开放的问题，深度网络在层次上如何进行层次特征学习。在这项工作中，我们尝试揭示这个谜题，通过investigating深度网络中间特征的结构。我们的实际发现表明，深度线性网络中的线性层可以模拟深度网络中非线性层的特征学习功能，因此我们可以通过调查每层训练后的输出（即特征）来研究深度网络如何将输入数据转换成输出。为达到这个目标，我们首先定义了内部特征压缩和 между类差异度的两个度量，然后通过理论分析这两个度量，我们显示了深度网络中的特征演化遵循简单和量化的规律：每层深度网络将内部特征压缩到 геометрический率，并且在数据流经多层后，对于不同类型的特征进行线性差异分化。我们认为这是深度线性网络中特征演化的首次量化 caracterization。我们的实验证明了我们的理论结果，并且发现这种特征演化的趋势也存在于深度非线性网络中，与最近的实验研究相吻合。此外，我们还展示了我们的结果在传输学习中的实践意义。我们的代码可以在 <https://github.com/Heimine/PNC_DLN> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Multi-view-learning-for-automatic-classification-of-multi-wavelength-auroral-images"><a href="#Multi-view-learning-for-automatic-classification-of-multi-wavelength-auroral-images" class="headerlink" title="Multi-view learning for automatic classification of multi-wavelength auroral images"></a>Multi-view learning for automatic classification of multi-wavelength auroral images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02947">http://arxiv.org/abs/2311.02947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiuju Yang, Hang Su, Lili Liu, Yixuan Wang, Ze-Jun Hu</li>
<li>for:  auroral classification studies in polar research, especially using images taken at multiple wavelengths</li>
<li>methods:  lightweight feature extraction backbone (LCTNet) and multi-scale reconstructed feature module (MSRM) to improve classification rate and highlight discriminative information between auroral classes</li>
<li>results:  fusion of multi-wavelength information effectively improves auroral classification performance, achieving state-of-the-art accuracy and computational efficiency compared to previous studies and existing multi-view methods.Here’s the summary in Traditional Chinese:</li>
<li>for: 极地研究中的auroral分类研究，特别是使用多波长的影像</li>
<li>methods: 轻量级特征提取后门 (LCTNet) 和多尺度重建特征模组 (MSRM) 以提高分类率并强调auroralclasses中的差异</li>
<li>results: 多波长资讯的融合有效地提高了auroral分类性能，与前一代研究和现有的多视野方法相比，获得了更高的准确率和计算效率。<details>
<summary>Abstract</summary>
Auroral classification plays a crucial role in polar research. However, current auroral classification studies are predominantly based on images taken at a single wavelength, typically 557.7 nm. Images obtained at other wavelengths have been comparatively overlooked, and the integration of information from multiple wavelengths remains an underexplored area. This limitation results in low classification rates for complex auroral patterns. Furthermore, these studies, whether employing traditional machine learning or deep learning approaches, have not achieved a satisfactory trade-off between accuracy and speed. To address these challenges, this paper proposes a lightweight auroral multi-wavelength fusion classification network, MLCNet, based on a multi-view approach. Firstly, we develop a lightweight feature extraction backbone, called LCTNet, to improve the classification rate and cope with the increasing amount of auroral observation data. Secondly, considering the existence of multi-scale spatial structures in auroras, we design a novel multi-scale reconstructed feature module named MSRM. Finally, to highlight the discriminative information between auroral classes, we propose a lightweight attention feature enhancement module called LAFE. The proposed method is validated using observational data from the Arctic Yellow River Station during 2003-2004. Experimental results demonstrate that the fusion of multi-wavelength information effectively improves the auroral classification performance. In particular, our approach achieves state-of-the-art classification accuracy compared to previous auroral classification studies, and superior results in terms of accuracy and computational efficiency compared to existing multi-view methods.
</details>
<details>
<summary>摘要</summary>
极地研究中的 auroral 分类扮演着关键性的角色，但现有的 auroral 分类研究主要基于单一波长的图像，通常为 557.7 nm。其他波长的图像尚未得到了足够的研究，而 integrating 多波长信息的研究仍然处于未开掘阶段。这种限制导致了复杂的 auroral 图像分类率较低。此外，这些研究， whether 使用传统机器学习或深度学习方法，尚未达到了满意的精度和速度之间的平衡。为了解决这些挑战，本文提出了一种轻量级 auroral 多波长融合分类网络， MLCCNet，基于多视图方法。首先，我们开发了一种轻量级特征提取核心， called LCTNet，以提高分类率和处理大量极地观测数据。其次，考虑到极地 auroras 中存在多尺度空间结构，我们设计了一种新的多尺度重构特征模块， named MSRM。最后，为了强调 auroral 类别之间的区别特征，我们提出了一种轻量级注意力特征增强模块， called LAFE。我们对于2003-2004年由北极黄河站收集的观测数据进行验证。实验结果表明，将多波长信息融合分类效果显著提高了极地分类性能。尤其是，我们的方法在前一代 auroral 分类研究中达到了状态机器学习和现有多视图方法的最高精度和计算效率。
</details></li>
</ul>
<hr>
<h2 id="Truly-Scale-Equivariant-Deep-Nets-with-Fourier-Layers"><a href="#Truly-Scale-Equivariant-Deep-Nets-with-Fourier-Layers" class="headerlink" title="Truly Scale-Equivariant Deep Nets with Fourier Layers"></a>Truly Scale-Equivariant Deep Nets with Fourier Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02922">http://arxiv.org/abs/2311.02922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Ashiqur Rahman, Raymond A. Yeh</li>
<li>for: 这篇论文的目的是解决计算机视觉领域中模型如何适应图像分辨率变化以进行图像分割等任务？</li>
<li>methods: 这篇论文使用了weight-sharing和kernel resizing等方法来实现缩放平衡的 convolutional neural networks，但这些网络并没有真正具备缩放平衡性。</li>
<li>results: 该模型在MNIST-scale和STL-10 datasets上实现了竞争力的分类性能，同时保持了缩放平衡性。<details>
<summary>Abstract</summary>
In computer vision, models must be able to adapt to changes in image resolution to effectively carry out tasks such as image segmentation; This is known as scale-equivariance. Recent works have made progress in developing scale-equivariant convolutional neural networks, e.g., through weight-sharing and kernel resizing. However, these networks are not truly scale-equivariant in practice. Specifically, they do not consider anti-aliasing as they formulate the down-scaling operation in the continuous domain. To address this shortcoming, we directly formulate down-scaling in the discrete domain with consideration of anti-aliasing. We then propose a novel architecture based on Fourier layers to achieve truly scale-equivariant deep nets, i.e., absolute zero equivariance-error. Following prior works, we test this model on MNIST-scale and STL-10 datasets. Our proposed model achieves competitive classification performance while maintaining zero equivariance-error.
</details>
<details>
<summary>摘要</summary>
在计算机视觉领域，模型需要适应图像分辨率的变化以有效实现图像分割等任务。这被称为尺度对称性。最近的研究已经在发展尺度对称的卷积神经网络，例如通过Weight-sharing和kernel重新大小化。但这些网络在实践中并不是真正的尺度对称的。具体来说，它们没有考虑抗锯齿处理，因为它们在连续领域中表述下降操作。为了解决这个缺陷，我们直接在离散领域中表述下降操作，并考虑抗锯齿处理。我们then proposes一种基于Fourier层的新架构，以实现真正的尺度对称的深度网络，即绝对零对称性错误。following prior works, we test this model on MNIST-scale和STL-10 datasets。我们的提议的模型实现了竞争力的分类性能，同时保持零对称性错误。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Deep-Facial-Expression-Recognition-An-Extensive-Protocol-with-Balanced-Dataset-in-the-Wild"><a href="#Benchmarking-Deep-Facial-Expression-Recognition-An-Extensive-Protocol-with-Balanced-Dataset-in-the-Wild" class="headerlink" title="Benchmarking Deep Facial Expression Recognition: An Extensive Protocol with Balanced Dataset in the Wild"></a>Benchmarking Deep Facial Expression Recognition: An Extensive Protocol with Balanced Dataset in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02910">http://arxiv.org/abs/2311.02910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gianmarco Ipinze Tutuianu, Yang Liu, Ari Alamäki, Janne Kauttonen</li>
<li>for: 本研究旨在提高人computer交互中的表情识别（FER）精度和通用性，探讨现有方法在实际设置下的表现。</li>
<li>methods: 本研究使用了23种常见的网络架构，按照一种统一的协议进行评估。此外，研究还检验了不同的输入分辨率、类别负荷管理和预训练策略的影响。</li>
<li>results: 经过广泛的实验和实际交叉验证，研究发现了不同网络架构的表现，并提出了在真实场景中部署深度FER方法的建议。此外，研究还讨论了实际应用中的道德规则、隐私问题和法规。<details>
<summary>Abstract</summary>
Facial expression recognition (FER) is a crucial part of human-computer interaction. Existing FER methods achieve high accuracy and generalization based on different open-source deep models and training approaches. However, the performance of these methods is not always good when encountering practical settings, which are seldom explored. In this paper, we collected a new in-the-wild facial expression dataset for cross-domain validation. Twenty-three commonly used network architectures were implemented and evaluated following a uniform protocol. Moreover, various setups, in terms of input resolutions, class balance management, and pre-trained strategies, were verified to show the corresponding performance contribution. Based on extensive experiments on three large-scale FER datasets and our practical cross-validation, we ranked network architectures and summarized a set of recommendations on deploying deep FER methods in real scenarios. In addition, potential ethical rules, privacy issues, and regulations were discussed in practical FER applications such as marketing, education, and entertainment business.
</details>
<details>
<summary>摘要</summary>
人机交互中的表情识别（FER）是一项非常重要的技术。现有的FER方法在不同的开源深度学习模型和训练方法上达到了高度的准确率和泛化性。然而，这些方法在实际应用中的性能不 invariantly是好的，这些应用场景很少被探讨。在这篇论文中，我们收集了一个新的在野 Facial Expression 数据集，用于跨频训练验证。我们实现了23种常用的网络架构，并按照一个固定的协议进行评估。此外，我们还采用了不同的输入分辨率、类别减少管理和预训练策略，以确定它们对性能的贡献。基于大量的实验和我们的实际跨验证，我们对深度FER方法的部署在实际场景中进行了排名和总结，并讨论了实际应用中的伦理规则、隐私问题和法规。
</details></li>
</ul>
<hr>
<h2 id="Human-as-Points-Explicit-Point-based-3D-Human-Reconstruction-from-Single-view-RGB-Images"><a href="#Human-as-Points-Explicit-Point-based-3D-Human-Reconstruction-from-Single-view-RGB-Images" class="headerlink" title="Human as Points: Explicit Point-based 3D Human Reconstruction from Single-view RGB Images"></a>Human as Points: Explicit Point-based 3D Human Reconstruction from Single-view RGB Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02892">http://arxiv.org/abs/2311.02892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingzhi Tang, Qijian Zhang, Junhui Hou, Yebin Liu</li>
<li>for: 这个论文的目的是解决单视图人体重建领域中的一些问题，包括灵活性、普适性、稳定性和表达能力等方面的限制。</li>
<li>methods: 这个论文使用的方法是一种基于点云的Explicit Point-based Human Reconstruction（HaP）框架，通过全面地利用点云来表示目标几何结构，而不是使用传统的启发式学习过程。</li>
<li>results: 实验结果表明，HaP框架可以比现有的方法提供20%到40%的量化性能提升，并且可以提供更好的质量结果。这些结果表明了fully-explicit和几何中心的算法设计的可行性，并且可以激发更多的强大点云模型化架构和处理技术的发展。<details>
<summary>Abstract</summary>
The latest trends in the research field of single-view human reconstruction devote to learning deep implicit functions constrained by explicit body shape priors. Despite the remarkable performance improvements compared with traditional processing pipelines, existing learning approaches still show different aspects of limitations in terms of flexibility, generalizability, robustness, and/or representation capability. To comprehensively address the above issues, in this paper, we investigate an explicit point-based human reconstruction framework called HaP, which adopts point clouds as the intermediate representation of the target geometric structure. Technically, our approach is featured by fully-explicit point cloud estimation, manipulation, generation, and refinement in the 3D geometric space, instead of an implicit learning process that can be ambiguous and less controllable. The overall workflow is carefully organized with dedicated designs of the corresponding specialized learning components as well as processing procedures. Extensive experiments demonstrate that our framework achieves quantitative performance improvements of 20% to 40% over current state-of-the-art methods, and better qualitative results. Our promising results may indicate a paradigm rollback to the fully-explicit and geometry-centric algorithm design, which enables to exploit various powerful point cloud modeling architectures and processing techniques. We will make our code and data publicly available at https://github.com/yztang4/HaP.
</details>
<details>
<summary>摘要</summary>
最新的研究方向在单视人重建领域是学习深入隐藏函数，受到明确的体形约束。despite remarkable performance improvements over traditional processing pipelines, existing learning approaches still have limitations in terms of flexibility, generalizability, robustness, and/or representation capability. To comprehensively address these issues, in this paper, we investigate an explicit point-based human reconstruction framework called HaP, which adopts point clouds as the intermediate representation of the target geometric structure. Technically, our approach is characterized by fully-explicit point cloud estimation, manipulation, generation, and refinement in the 3D geometric space, rather than an implicit learning process that can be ambiguous and less controllable. The overall workflow is carefully organized with dedicated designs of the corresponding specialized learning components as well as processing procedures. Extensive experiments show that our framework achieves quantitative performance improvements of 20% to 40% over current state-of-the-art methods, and better qualitative results. Our promising results may indicate a paradigm rollback to the fully-explicit and geometry-centric algorithm design, which enables us to exploit various powerful point cloud modeling architectures and processing techniques. We will make our code and data publicly available at <https://github.com/yztang4/HaP>.
</details></li>
</ul>
<hr>
<h2 id="Stacked-Autoencoder-Based-Feature-Extraction-and-Superpixel-Generation-for-Multifrequency-PolSAR-Image-Classification"><a href="#Stacked-Autoencoder-Based-Feature-Extraction-and-Superpixel-Generation-for-Multifrequency-PolSAR-Image-Classification" class="headerlink" title="Stacked Autoencoder Based Feature Extraction and Superpixel Generation for Multifrequency PolSAR Image Classification"></a>Stacked Autoencoder Based Feature Extraction and Superpixel Generation for Multifrequency PolSAR Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02887">http://arxiv.org/abs/2311.02887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tushar Gadhiya, Sumanth Tangirala, Anil K. Roy</li>
<li>for: 本研究提出了一种用于多频波束成像（PolSAR）图像的分类算法。</li>
<li>methods: 使用波束剖分算法提取了每个频率带的33个特征，然后使用两层自适应编码器减少输入特征向量的维度，保留有用的输入特征。接着，使用SLIC算法生成了超像素，并使用这些超像素构建了一个强健的特征表示。最后，使用softmax分类器进行分类任务。</li>
<li>results: 实验表明，提出的方法在Flevoland dataset上比其他文献中的方法更为有效。<details>
<summary>Abstract</summary>
In this paper we are proposing classification algorithm for multifrequency Polarimetric Synthetic Aperture Radar (PolSAR) image. Using PolSAR decomposition algorithms 33 features are extracted from each frequency band of the given image. Then, a two-layer autoencoder is used to reduce the dimensionality of input feature vector while retaining useful features of the input. This reduced dimensional feature vector is then applied to generate superpixels using simple linear iterative clustering (SLIC) algorithm. Next, a robust feature representation is constructed using both pixel as well as superpixel information. Finally, softmax classifier is used to perform classification task. The advantage of using superpixels is that it preserves spatial information between neighbouring PolSAR pixels and therefore minimises the effect of speckle noise during classification. Experiments have been conducted on Flevoland dataset and the proposed method was found to be superior to other methods available in the literature.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种多频段Polarimetric Synthetic Aperture Radar（PolSAR）图像分类算法。使用PolSAR分解算法，从每个频段图像中提取了33个特征。然后，使用两层自适应卷积神经网络减少输入特征向量的维度，保留输入特征的有用信息。这个减少后的特征向量然后用simple linear iterative clustering（SLIC）算法生成超像素。接着，通过像素和超像素信息建立了一个强健的特征表示。最后，使用softmax分类器进行分类任务。使用超像素的优势在于它保留了相邻PolSAR像素之间的空间信息，因此减少了雷达噪声的影响，提高了分类的精度。我们在Flevoland数据集上进行了实验，并发现提出的方法在文献中所有方法中显示出优势。
</details></li>
</ul>
<hr>
<h2 id="Inner-IoU-More-Effective-Intersection-over-Union-Loss-with-Auxiliary-Bounding-Box"><a href="#Inner-IoU-More-Effective-Intersection-over-Union-Loss-with-Auxiliary-Bounding-Box" class="headerlink" title="Inner-IoU: More Effective Intersection over Union Loss with Auxiliary Bounding Box"></a>Inner-IoU: More Effective Intersection over Union Loss with Auxiliary Bounding Box</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02877">http://arxiv.org/abs/2311.02877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang, Cong Xu, Shuaijie Zhang</li>
<li>for: 提高 bounding box regression 过程的效率和精度</li>
<li>methods: 使用不同的缩放因子和辅助 bounding box 来计算损失函数，并引入 Inner-IoU 损失函数</li>
<li>results: 实验结果表明， combining Inner-IoU 损失函数与现有的 IoU-based 损失函数可以进一步提高检测性能，并且在不同的 dataset 和检测器上具有广泛的应用性和通用性。<details>
<summary>Abstract</summary>
With the rapid development of detectors, Bounding Box Regression (BBR) loss function has constantly updated and optimized. However, the existing IoU-based BBR still focus on accelerating convergence by adding new loss terms, ignoring the limitations of IoU loss term itself. Although theoretically IoU loss can effectively describe the state of bounding box regression,in practical applications, it cannot adjust itself according to different detectors and detection tasks, and does not have strong generalization. Based on the above, we first analyzed the BBR model and concluded that distinguishing different regression samples and using different scales of auxiliary bounding boxes to calculate losses can effectively accelerate the bounding box regression process. For high IoU samples, using smaller auxiliary bounding boxes to calculate losses can accelerate convergence, while larger auxiliary bounding boxes are suitable for low IoU samples. Then, we propose Inner-IoU loss, which calculates IoU loss through auxiliary bounding boxes. For different datasets and detectors, we introduce a scaling factor ratio to control the scale size of the auxiliary bounding boxes for calculating losses. Finally, integrate Inner-IoU into the existing IoU-based loss functions for simulation and comparative experiments. The experiment result demonstrate a further enhancement in detection performance with the utilization of the method proposed in this paper, verifying the effectiveness and generalization ability of Inner IoU loss.
</details>
<details>
<summary>摘要</summary>
随着检测器的快速发展，矩形框回归（BBR）损失函数已经不断地更新和优化。然而，现有的IoU基于的BBR仍然ocuses on accelerating convergence by adding new loss terms, ignoring the limitations of IoU loss term itself. Although theoretically IoU loss can effectively describe the state of bounding box regression, in practical applications, it cannot adjust itself according to different detectors and detection tasks, and does not have strong generalization.根据以上分析，我们首先分析了BBR模型，并结论出，可以通过 distinguish different regression samples and use different scales of auxiliary bounding boxes to calculate losses来加速矩形框回归过程。 For high IoU samples, using smaller auxiliary bounding boxes to calculate losses can accelerate convergence, while larger auxiliary bounding boxes are suitable for low IoU samples. Then, we propose Inner-IoU loss, which calculates IoU loss through auxiliary bounding boxes. For different datasets and detectors, we introduce a scaling factor ratio to control the scale size of the auxiliary bounding boxes for calculating losses. Finally, we integrate Inner-IoU into the existing IoU-based loss functions for simulation and comparative experiments. The experiment results demonstrate a further enhancement in detection performance with the utilization of the method proposed in this paper, verifying the effectiveness and generalization ability of Inner IoU loss.
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Neural-Fields-for-Learning-Atlases-of-4D-Fetal-MRI-Time-series"><a href="#Dynamic-Neural-Fields-for-Learning-Atlases-of-4D-Fetal-MRI-Time-series" class="headerlink" title="Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series"></a>Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02874">http://arxiv.org/abs/2311.02874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeen Chi, Zhongxiao Cong, Clinton J. Wang, Yingcheng Liu, Esra Abaci Turk, P. Ellen Grant, S. Mazdak Abulnaga, Polina Golland, Neel Dey</li>
<li>for:  rapidement construire des atlas médicaux biomimétiques à l’aide de champs neuraux.</li>
<li>methods: utiliser des champs neuraux pour apprendre des observations déformables spatiotemporelles pour construire des atlas subject-spécifiques.</li>
<li>results: obtenir des atlas de haute qualité de séries de données BOLD MRI dynamiques de fœtus en utéro avec une convergence environ 5-7 fois plus rapide que les méthodes existantes.<details>
<summary>Abstract</summary>
We present a method for fast biomedical image atlas construction using neural fields. Atlases are key to biomedical image analysis tasks, yet conventional and deep network estimation methods remain time-intensive. In this preliminary work, we frame subject-specific atlas building as learning a neural field of deformable spatiotemporal observations. We apply our method to learning subject-specific atlases and motion stabilization of dynamic BOLD MRI time-series of fetuses in utero. Our method yields high-quality atlases of fetal BOLD time-series with $\sim$5-7$\times$ faster convergence compared to existing work. While our method slightly underperforms well-tuned baselines in terms of anatomical overlap, it estimates templates significantly faster, thus enabling rapid processing and stabilization of large databases of 4D dynamic MRI acquisitions. Code is available at https://github.com/Kidrauh/neural-atlasing
</details>
<details>
<summary>摘要</summary>
我们提出了一种快速生成医学影像 Atlases 的方法，使用神经场。 Atlases 是生物医学影像分析任务的关键，但是传统的深度网络估计方法和深度网络估计方法仍然很时间消耗。在这项先导性工作中，我们将主动Specific atlas 的建立Equate 为学习扭变的时空观察的神经场。我们应用我们的方法到学习主动Specific atlas 和动态BOLD MRI时序列的运动稳定。我们的方法可以快速生成高质量的胎儿BOLD时序列的 Atlases，相比已有的工作，它的连续变换速度约为5-7倍。虽然我们的方法在注意力调整后的基eline上略有下降，但它可以更快地估计模板，因此可以快速处理和稳定大量的4D动态MRI数据库。代码可以在https://github.com/Kidrauh/neural-atlasing 上获取。
</details></li>
</ul>
<hr>
<h2 id="OVIR-3D-Open-Vocabulary-3D-Instance-Retrieval-Without-Training-on-3D-Data"><a href="#OVIR-3D-Open-Vocabulary-3D-Instance-Retrieval-Without-Training-on-3D-Data" class="headerlink" title="OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data"></a>OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02873">http://arxiv.org/abs/2311.02873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shiyoung77/OVIR-3D">https://github.com/shiyoung77/OVIR-3D</a></li>
<li>paper_authors: Shiyang Lu, Haonan Chang, Eric Pu Jing, Abdeslam Boularias, Kostas Bekris</li>
<li>for: 开发了一种无需使用任何3D数据进行训练的开 vocabulary 3D对象实例检索方法。</li>
<li>methods: 使用文本查询和多视图拟合2D区域提档网络，将2D区域提档拟合到3D空间，实现文本查询和3D对象实例检索的联合。</li>
<li>results: 实验表明，该方法可以快速和高效地在大多数室内3D场景中进行实时多视图拟合，并且不需要额外训练在3D空间。<details>
<summary>Abstract</summary>
This work presents OVIR-3D, a straightforward yet effective method for open-vocabulary 3D object instance retrieval without using any 3D data for training. Given a language query, the proposed method is able to return a ranked set of 3D object instance segments based on the feature similarity of the instance and the text query. This is achieved by a multi-view fusion of text-aligned 2D region proposals into 3D space, where the 2D region proposal network could leverage 2D datasets, which are more accessible and typically larger than 3D datasets. The proposed fusion process is efficient as it can be performed in real-time for most indoor 3D scenes and does not require additional training in 3D space. Experiments on public datasets and a real robot show the effectiveness of the method and its potential for applications in robot navigation and manipulation.
</details>
<details>
<summary>摘要</summary>
这项工作介绍了一种简单又有效的方法，可以在开放词汇3D对象实例检索中不使用任何3D数据进行训练。给定一个语言查询，提posed方法可以返回一个相似度排序的3D对象实例分割，基于实例和文本查询的特征相似性。这是通过多视图融合文本对齐2D区域提案到3D空间中进行实现的，其中2D区域提案网络可以利用2D数据集，这些数据集通常更容易获取和更大规模。我们的融合过程具有实时性，可以适用于大多数室内3D场景，而且不需要额外训练在3D空间。我们的实验表明，这种方法在公共数据集和真实的 робоット上具有有效性，并且它在机器人导航和 manipulate 中具有潜在的应用前景。
</details></li>
</ul>
<hr>
<h2 id="FocusTune-Tuning-Visual-Localization-through-Focus-Guided-Sampling"><a href="#FocusTune-Tuning-Visual-Localization-through-Focus-Guided-Sampling" class="headerlink" title="FocusTune: Tuning Visual Localization through Focus-Guided Sampling"></a>FocusTune: Tuning Visual Localization through Focus-Guided Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02872">http://arxiv.org/abs/2311.02872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Son Tung Nguyen, Alejandro Fontan, Michael Milford, Tobias Fischer</li>
<li>for: 提高视觉地标算法的性能</li>
<li>methods: FocusTune使用重点导航的抽象技术，将场景坐标回归模型引导向关键的3D点三角形计算中的区域</li>
<li>results: FocusTune可以提高或与状态机器学习模型匹配的性能，同时保持ACE模型的低存储和计算需求，例如在 cambridge 地标集上减少翻译错误从25到19和17到15cm。<details>
<summary>Abstract</summary>
We propose FocusTune, a focus-guided sampling technique to improve the performance of visual localization algorithms. FocusTune directs a scene coordinate regression model towards regions critical for 3D point triangulation by exploiting key geometric constraints. Specifically, rather than uniformly sampling points across the image for training the scene coordinate regression model, we instead re-project 3D scene coordinates onto the 2D image plane and sample within a local neighborhood of the re-projected points. While our proposed sampling strategy is generally applicable, we showcase FocusTune by integrating it with the recently introduced Accelerated Coordinate Encoding (ACE) model. Our results demonstrate that FocusTune both improves or matches state-of-the-art performance whilst keeping ACE's appealing low storage and compute requirements, for example reducing translation error from 25 to 19 and 17 to 15 cm for single and ensemble models, respectively, on the Cambridge Landmarks dataset. This combination of high performance and low compute and storage requirements is particularly promising for applications in areas like mobile robotics and augmented reality. We made our code available at \url{https://github.com/sontung/focus-tune}.
</details>
<details>
<summary>摘要</summary>
我们提出了FocusTune，一种帮助视觉地标定算法提高性能的集中样本技术。FocusTune通过利用关键的几何约束来导引Scene coordinate regression模型对于3D点Triangulation的重要区域进行样本。具体来说，我们不是 uniformly sampling点在图像上进行Scene coordinate regression模型的训练，而是将3D场景坐标重project onto 2D图像平面，然后在本地 neighborhood中采样。我们的提议的样本策略是通用的，但我们在ACE模型中展示了FocusTune。我们的结果表明，FocusTune可以提高或与状态艺术性能匹配，同时保持ACE模型的吸引人低存储和计算需求，例如将翻译错误从25减少到19和17减少到15 cm，分别在Cambridge Landmarks dataset上。这种高性能低计算存储需求的组合非常有前途，特别是在移动 робо扮和增强现实中。我们的代码可以在https://github.com/sontung/focus-tune中下载。
</details></li>
</ul>
<hr>
<h2 id="Neural-based-Compression-Scheme-for-Solar-Image-Data"><a href="#Neural-based-Compression-Scheme-for-Solar-Image-Data" class="headerlink" title="Neural-based Compression Scheme for Solar Image Data"></a>Neural-based Compression Scheme for Solar Image Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02855">http://arxiv.org/abs/2311.02855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Zafari, Atefeh Khoshkhahtinat, Jeremy A. Grajeda, Piyush M. Mehta, Nasser M. Nasrabadi, Laura E. Boucheron, Barbara J. Thompson, Michael S. F. Kirk, Daniel da Silva<br>for: This paper proposes a neural network-based lossy compression method for data-intensive imagery missions, specifically targeting NASA’s SDO mission.methods: The proposed method uses an adversarially trained neural network with local and non-local attention modules to capture the local and global structure of the image, resulting in a better trade-off in rate-distortion (RD) compared to conventional hand-engineered codecs. The RD variational autoencoder is jointly trained with a channel-dependent entropy model to make the entropy coding of the latent code more effective.results: The proposed algorithm outperforms currently-in-use and state-of-the-art codecs such as JPEG and JPEG-2000 in terms of RD performance when compressing extreme-ultraviolet (EUV) data. The algorithm is able to achieve consistent segmentations of coronal holes (CH) in compressed EUV images from SDO, even at a compression rate of $\sim0.1$ bits per pixel.<details>
<summary>Abstract</summary>
Studying the solar system and especially the Sun relies on the data gathered daily from space missions. These missions are data-intensive and compressing this data to make them efficiently transferable to the ground station is a twofold decision to make. Stronger compression methods, by distorting the data, can increase data throughput at the cost of accuracy which could affect scientific analysis of the data. On the other hand, preserving subtle details in the compressed data requires a high amount of data to be transferred, reducing the desired gains from compression. In this work, we propose a neural network-based lossy compression method to be used in NASA's data-intensive imagery missions. We chose NASA's SDO mission which transmits 1.4 terabytes of data each day as a proof of concept for the proposed algorithm. In this work, we propose an adversarially trained neural network, equipped with local and non-local attention modules to capture both the local and global structure of the image resulting in a better trade-off in rate-distortion (RD) compared to conventional hand-engineered codecs. The RD variational autoencoder used in this work is jointly trained with a channel-dependent entropy model as a shared prior between the analysis and synthesis transforms to make the entropy coding of the latent code more effective. Our neural image compression algorithm outperforms currently-in-use and state-of-the-art codecs such as JPEG and JPEG-2000 in terms of the RD performance when compressing extreme-ultraviolet (EUV) data. As a proof of concept for use of this algorithm in SDO data analysis, we have performed coronal hole (CH) detection using our compressed images, and generated consistent segmentations, even at a compression rate of $\sim0.1$ bits per pixel (compared to 8 bits per pixel on the original data) using EUV data from SDO.
</details>
<details>
<summary>摘要</summary>
研究太阳系和特别是太阳需要每天从空间任务中收集数据。这些任务是数据敏感的，压缩这些数据以使其可以高效地传输到地面站点是一个两fold的决策。使用更强的压缩方法可以提高数据传输速率，但是这将会影响科学分析中的精度。当然，保留图像中的细节需要大量数据进行传输，这会降低所希望的压缩率。在这种情况下，我们提出了一种基于神经网络的损失压缩方法，用于NASA的数据敏感成像任务。我们选择了NASA的SDO任务，每天传输1.4 terabytes的数据作为证明。在这种情况下，我们提出了一种适应学习神经网络，具有本地和非本地注意模块，以捕捉图像的本地和全局结构，从而实现更好的Rate-Distortion（RD）质量比。我们的神经图像压缩算法在JPEG和JPEG-2000等现有的编码器之上具有更高的RD性能，特别是在激光ultraviolet（EUV）数据压缩中。作为SDO数据分析的证明，我们对压缩后的图像进行了核心孔（CH）检测，并获得了一致的分 segmentation，即使压缩率为0.1 bits/像素（相比8 bits/像素的原始数据）。
</details></li>
</ul>
<hr>
<h2 id="Consistent4D-Consistent-360°-Dynamic-Object-Generation-from-Monocular-Video"><a href="#Consistent4D-Consistent-360°-Dynamic-Object-Generation-from-Monocular-Video" class="headerlink" title="Consistent4D: Consistent 360° Dynamic Object Generation from Monocular Video"></a>Consistent4D: Consistent 360° Dynamic Object Generation from Monocular Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02848">http://arxiv.org/abs/2311.02848</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanqinJiang/Consistent4D">https://github.com/yanqinJiang/Consistent4D</a></li>
<li>paper_authors: Yanqin Jiang, Li Zhang, Jin Gao, Weimin Hu, Yao Yao</li>
<li>for: 这个论文是为了从不准确的单视视频中生成4D动态对象而设计的。</li>
<li>methods: 该论文使用了一种新的方法，即Casting the 360-degree dynamic object reconstruction as a 4D generation problem，即使用物体层次3D意识图像扩散模型作为训练动态神经辐射场（DyNeRF）的主要监督信号。具体来说，该论文提出了一种协调 DyNeRF 来实现稳定的收敛和时间连续性，并引入了一种 interpolate-driven consistency loss 来保证空间和时间一致性。</li>
<li>results: 该论文的实验表明，Consistent4D 可以与之前的同类方法相比，在生成4D动态对象方面表现出 competitive 的性能，同时也在传统的文本到3D生成任务中表现出优势。具体来说，Consistent4D 可以在不需要多视图数据收集和摄像头准确性调整的情况下，从单视视频中生成高质量的4D动态对象。<details>
<summary>Abstract</summary>
In this paper, we present Consistent4D, a novel approach for generating 4D dynamic objects from uncalibrated monocular videos. Uniquely, we cast the 360-degree dynamic object reconstruction as a 4D generation problem, eliminating the need for tedious multi-view data collection and camera calibration. This is achieved by leveraging the object-level 3D-aware image diffusion model as the primary supervision signal for training Dynamic Neural Radiance Fields (DyNeRF). Specifically, we propose a Cascade DyNeRF to facilitate stable convergence and temporal continuity under the supervision signal which is discrete along the time axis. To achieve spatial and temporal consistency, we further introduce an Interpolation-driven Consistency Loss. It is optimized by minimizing the discrepancy between rendered frames from DyNeRF and interpolated frames from a pre-trained video interpolation model. Extensive experiments show that our Consistent4D can perform competitively to prior art alternatives, opening up new possibilities for 4D dynamic object generation from monocular videos, whilst also demonstrating advantage for conventional text-to-3D generation tasks. Our project page is https://consistent4d.github.io/.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的方法---Consistent4D，可以从无投影照片中生成4D动态对象。这种方法通过将360度动态对象重建视为4D生成问题来消除需要繁琐的多视图数据收集和摄像头准确性调整的需求。我们利用对象层3D意识图像扩散模型作为训练动态光谱场（DyNeRF）的主要超视度信号。我们还提出了一种协调 DyNeRF，以便在超视度信号上稳定地迁移并保持时间连续性。为实现空间和时间一致性，我们还引入了一种 interpolate-driven 一致损失。它通过对 DyNeRF 生成的帧和 interpolated 视频 interpolated 模型生成的帧之间的差异进行最小化来优化。我们的实验结果表明，我们的 Consistent4D 可以与先前的方法相比竞争，开启了从无投影照片中生成4D动态对象的新可能性，同时也在传统的文本到3D生成任务中显示了优势。我们的项目页面是 <https://consistent4d.github.io/>。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Multi-Generator-Model-with-Fused-Spatiotemporal-Graph-for-Trajectory-Prediction"><a href="#Flexible-Multi-Generator-Model-with-Fused-Spatiotemporal-Graph-for-Trajectory-Prediction" class="headerlink" title="Flexible Multi-Generator Model with Fused Spatiotemporal Graph for Trajectory Prediction"></a>Flexible Multi-Generator Model with Fused Spatiotemporal Graph for Trajectory Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02835">http://arxiv.org/abs/2311.02835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyuan Zhu, Fengxia Han, Hao Deng</li>
<li>for: 这个研究是为了提高自动驾驶系统中的路径预测精度，以便更 precisel y track和决策。</li>
<li>methods: 本研究使用了生成对抗网络，能够学习未来路径的分布。但是，这些分布通常包含了不同的数据构造，例如人行道上的行人可能有不同的社交互动方式。为了解决这个问题，我们提出了一个路径预测框架，可以更好地模型场景中的人行道交互。</li>
<li>results: 我们的框架在不同的挑战性数据集上实现了比基eline更高的表现。<details>
<summary>Abstract</summary>
Trajectory prediction plays a vital role in automotive radar systems, facilitating precise tracking and decision-making in autonomous driving. Generative adversarial networks with the ability to learn a distribution over future trajectories tend to predict out-of-distribution samples, which typically occurs when the distribution of forthcoming paths comprises a blend of various manifolds that may be disconnected. To address this issue, we propose a trajectory prediction framework, which can capture the social interaction variations and model disconnected manifolds of pedestrian trajectories. Our framework is based on a fused spatiotemporal graph to better model the complex interactions of pedestrians in a scene, and a multi-generator architecture that incorporates a flexible generator selector network on generated trajectories to learn a distribution over multiple generators. We show that our framework achieves state-of-the-art performance compared with several baselines on different challenging datasets.
</details>
<details>
<summary>摘要</summary>
几何预测在汽车射频系统中扮演着重要的角色，帮助汽车在自动驾驶中精确追踪和做出决策。生成对抗网络，能够学习未来几何分布，对于非常量标本进行预测，通常发生在未来路径分布中包含多个不同构造的混合体。为解决这个问题，我们提出了一个几何预测框架，可以捕捉人员在场景中的社交互动变化，并且可以模型对于步行人的跟踪轨迹的不连续构造。我们的框架基于融合的空间时间图，更好地模型人员在场景中的复杂互动，并且具有一个灵活的生成器选择器网络，可以学习多个生成器之间的分布。我们证明了我们的框架在不同的挑战性数据集上具有现代水准的表现。
</details></li>
</ul>
<hr>
<h2 id="SemanticTopoLoop-Semantic-Loop-Closure-With-3D-Topological-Graph-Based-on-Quadric-Level-Object-Map"><a href="#SemanticTopoLoop-Semantic-Loop-Closure-With-3D-Topological-Graph-Based-on-Quadric-Level-Object-Map" class="headerlink" title="SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based on Quadric-Level Object Map"></a>SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based on Quadric-Level Object Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02831">http://arxiv.org/abs/2311.02831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenzhong Cao</li>
<li>for: 增强SLAM系统的精度和稳定性，解决传统的bag-of-words模型在实际场景中的局限性和不稳定性问题。</li>
<li>methods: 提出基于多级验证的对象水平数据关联方法，使得当前帧的2D语义特征与地图中的3D对象标记之间建立关联关系。然后，通过比较场景的对象图形图表 topology，实现精准的循环关闭。</li>
<li>results: 经验和抽象研究表明，提出的对象水平数据关联算法具有高效性和稳定性，而semantic循环关闭方法在宽视野下具有高精度和高准确性。<details>
<summary>Abstract</summary>
Loop closure, as one of the crucial components in SLAM, plays an essential role in correcting the accumulated errors. Traditional appearance-based methods, such as bag-of-words models, are often limited by local 2D features and the volume of training data, making them less versatile and robust in real-world scenarios, leading to missed detections or false positives detections in loop closure. To address these issues, we first propose a object-level data association method based on multi-level verification, which can associate 2D semantic features of current frame with 3D objects landmarks of map. Next, taking advantage of these association relations, we introduce a semantic loop closure method based on quadric-level object map topology, which represents scenes through the topological graph of objects and achieves accurate loop closure at a wide field of view by comparing differences in the topological graphs. Finally, we integrate these two methods into a complete object-aware SLAM system. Qualitative experiments and ablation studies demonstrate the effectiveness and robustness of the proposed object-level data association algorithm. Quantitative experiments show that our semantic loop closure method outperforms existing state-of-the-art methods in terms of precision, recall and localization accuracy metrics.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>Loop closure, as one of the crucial components in SLAM, plays an essential role in correcting the accumulated errors. Traditional appearance-based methods, such as bag-of-words models, are often limited by local 2D features and the volume of training data, making them less versatile and robust in real-world scenarios, leading to missed detections or false positives detections in loop closure. To address these issues, we first propose a object-level data association method based on multi-level verification, which can associate 2D semantic features of current frame with 3D objects landmarks of map. Next, taking advantage of these association relations, we introduce a semantic loop closure method based on quadric-level object map topology, which represents scenes through the topological graph of objects and achieves accurate loop closure at a wide field of view by comparing differences in the topological graphs. Finally, we integrate these two methods into a complete object-aware SLAM system. Qualitative experiments and ablation studies demonstrate the effectiveness and robustness of the proposed object-level data association algorithm. Quantitative experiments show that our semantic loop closure method outperforms existing state-of-the-art methods in terms of precision, recall and localization accuracy metrics.Here's the translation in Simplified Chinese:<<SYS>>将文本翻译成简化中文。<</SYS>>loop closure，作为SLAM中关键的一部分，对correcting accumulated errors起到关键作用。传统的出现基于方法，如bag-of-words模型，frequently limited by local 2D features和training data量，这会使其在实际场景中 menos versatile和Robust，导致loop closure中的 missed detections或false positives detections。为解决这些问题，我们首先提出了一种基于多级验证的object-level数据关联方法，可以将当前帧的2Dsemantic features与地图中的3Dobject landmarks相关联。然后，通过这些关联关系，我们引入了一种基于quadric-level object map topology的semantic loop closure方法，可以通过比较不同的topological graphs来实现准确的loop closure。最后，我们将这两种方法集成到了一个完整的object-aware SLAM系统中。Qualitative experiments和ablation studies表明了我们提出的object-level数据关联算法的效iveness和Robustness。Quantitative experiments表明，我们的semantic loop closure方法在精度、回归率和本地化精度 metric上表现出色，超越了现有的state-of-the-art方法。
</details></li>
</ul>
<hr>
<h2 id="InstructPix2NeRF-Instructed-3D-Portrait-Editing-from-a-Single-Image"><a href="#InstructPix2NeRF-Instructed-3D-Portrait-Editing-from-a-Single-Image" class="headerlink" title="InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"></a>InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02826">http://arxiv.org/abs/2311.02826</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianhui Li, Shilong Liu, Zidong Liu, Yikai Wang, Kaiwen Zheng, Jinghui Xu, Jianmin Li, Jun Zhu</li>
<li>for: This paper aims to solve the problem of human-instructed 3D-aware portrait editing for open-world images, which has been under-explored due to the lack of labeled human face 3D datasets and effective architectures.</li>
<li>methods: The proposed method, InstructPix2NeRF, uses a conditional latent 3D diffusion process to lift 2D editing to 3D space, and learns the correlation between the paired images’ difference and the instructions via triplet data. The method also uses a token position randomization strategy to achieve multi-semantic editing with the portrait identity well-preserved.</li>
<li>results: The proposed method is effective in achieving human-instructed 3D-aware portrait editing, and shows superiority against strong baselines quantitatively and qualitatively.<details>
<summary>Abstract</summary>
With the success of Neural Radiance Field (NeRF) in 3D-aware portrait editing, a variety of works have achieved promising results regarding both quality and 3D consistency. However, these methods heavily rely on per-prompt optimization when handling natural language as editing instructions. Due to the lack of labeled human face 3D datasets and effective architectures, the area of human-instructed 3D-aware editing for open-world portraits in an end-to-end manner remains under-explored. To solve this problem, we propose an end-to-end diffusion-based framework termed InstructPix2NeRF, which enables instructed 3D-aware portrait editing from a single open-world image with human instructions. At its core lies a conditional latent 3D diffusion process that lifts 2D editing to 3D space by learning the correlation between the paired images' difference and the instructions via triplet data. With the help of our proposed token position randomization strategy, we could even achieve multi-semantic editing through one single pass with the portrait identity well-preserved. Besides, we further propose an identity consistency module that directly modulates the extracted identity signals into our diffusion process, which increases the multi-view 3D identity consistency. Extensive experiments verify the effectiveness of our method and show its superiority against strong baselines quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
成功的神经辐射场（NeRF）在3D意识图像编辑方面取得了显著成果，许多作品在质量和3D一致性方面都取得了显著的进步。然而，这些方法却依赖于每个提示进行优化，对于自然语言作为编辑指令来说是一个挑战。由于人脸3D数据集缺乏标注和有效的建筑，在开放世界图像上的人 instruктирован3D意识图像编辑仍然是一个未解决的问题。为解决这个问题，我们提出了一种终端扩散基于的框架，称为InstructPix2NeRF，它可以从单个开放世界图像中进行人 instruктирован3D意识图像编辑。核心 liegt于一种受控 latent 3D扩散过程，通过学习对带有匹配图像差异和指令的对应关系来提升2D编辑到3D空间。通过我们提出的 токен位随机化策略，我们可以在一个单 pass 中实现多Semantic编辑，并且保持人脸标识的稳定性。此外，我们还提出了一种标识一致性模块，它直接将提取的标识信号与我们的扩散过程集成，从而提高多视图3D标识一致性。广泛的实验证明了我们的方法的效果，并与强基线相比，我们的方法在量和质量上具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Self-Supervised-Human-Pose-Estimation-with-Inductive-Prior-Tuning"><a href="#Efficient-Self-Supervised-Human-Pose-Estimation-with-Inductive-Prior-Tuning" class="headerlink" title="Efficient, Self-Supervised Human Pose Estimation with Inductive Prior Tuning"></a>Efficient, Self-Supervised Human Pose Estimation with Inductive Prior Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02815">http://arxiv.org/abs/2311.02815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nobline Yoo, Olga Russakovsky</li>
<li>for: 本研究的目的是提高无监督人体pose估计（HPE）的精度。</li>
<li>methods: 本文使用自我监督方法，将HPE任务重新定义为一个重构问题，以便利用大量未标注的视觉数据。</li>
<li>results: 本研究提出了一种新的度量方法，可以在无监督情况下衡量人体部分长度的一致性。此外，文章还提出了一种新的模型架构，可以在使用 fewer than one-third 的训练数据的情况下超越基eline。<details>
<summary>Abstract</summary>
The goal of 2D human pose estimation (HPE) is to localize anatomical landmarks, given an image of a person in a pose. SOTA techniques make use of thousands of labeled figures (finetuning transformers or training deep CNNs), acquired using labor-intensive crowdsourcing. On the other hand, self-supervised methods re-frame the HPE task as a reconstruction problem, enabling them to leverage the vast amount of unlabeled visual data, though at the present cost of accuracy. In this work, we explore ways to improve self-supervised HPE. We (1) analyze the relationship between reconstruction quality and pose estimation accuracy, (2) develop a model pipeline that outperforms the baseline which inspired our work, using less than one-third the amount of training data, and (3) offer a new metric suitable for self-supervised settings that measures the consistency of predicted body part length proportions. We show that a combination of well-engineered reconstruction losses and inductive priors can help coordinate pose learning alongside reconstruction in a self-supervised paradigm.
</details>
<details>
<summary>摘要</summary>
文章目标是提高二维人姿估计（HPE）的自主学习性能。现状的最佳技术使用了千余个标注的人像（finetuning transformers或训练深度CNN），通过劳动密集的人工投票获得。然而，无监督方法将HPE任务重新定义为重建问题，可以利用大量未标注的视觉数据，但当前精度较低。本文探讨如何提高自主学习HPE。我们（1）分析重建质量和姿势估计准确性之间的关系，（2）开发一个超过基eline的模型管道，使用较少的训练数据，并（3）提出一个适合自主设置的度量，用于测量预测身体部分长度的一致性。我们显示，通过合理的重建损失和推导约束，可以协调姿势学习与重建在无监督情况下协同进行。
</details></li>
</ul>
<hr>
<h2 id="Fast-and-Interpretable-Face-Identification-for-Out-Of-Distribution-Data-Using-Vision-Transformers"><a href="#Fast-and-Interpretable-Face-Identification-for-Out-Of-Distribution-Data-Using-Vision-Transformers" class="headerlink" title="Fast and Interpretable Face Identification for Out-Of-Distribution Data Using Vision Transformers"></a>Fast and Interpretable Face Identification for Out-Of-Distribution Data Using Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02803">http://arxiv.org/abs/2311.02803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai Phan, Cindy Le, Vu Le, Yihui He, Anh Totti Nguyen</li>
<li>for: 提高Face Identification的精度和准确性，特别是对于 occlusion 和 out-of-distribution 数据。</li>
<li>methods: 使用 two-image Vision Transformers (ViTs)  Compares two images at the patch level using cross-attention。</li>
<li>results: 在 CASIA Webface 数据集上训练，与 DeepFace-EMD 相比，我们的模型在 out-of-distribution 数据上达到了相同的准确率，但在推理速度上高于 DeepFace-EMD 的两倍以上。此外，我们通过人类研究发现，我们的模型具有良好的解释性，可以通过视觉化的 cross-attention 来visualize。<details>
<summary>Abstract</summary>
Most face identification approaches employ a Siamese neural network to compare two images at the image embedding level. Yet, this technique can be subject to occlusion (e.g. faces with masks or sunglasses) and out-of-distribution data. DeepFace-EMD (Phan et al. 2022) reaches state-of-the-art accuracy on out-of-distribution data by first comparing two images at the image level, and then at the patch level. Yet, its later patch-wise re-ranking stage admits a large $O(n^3 \log n)$ time complexity (for $n$ patches in an image) due to the optimal transport optimization. In this paper, we propose a novel, 2-image Vision Transformers (ViTs) that compares two images at the patch level using cross-attention. After training on 2M pairs of images on CASIA Webface (Yi et al. 2014), our model performs at a comparable accuracy as DeepFace-EMD on out-of-distribution data, yet at an inference speed more than twice as fast as DeepFace-EMD (Phan et al. 2022). In addition, via a human study, our model shows promising explainability through the visualization of cross-attention. We believe our work can inspire more explorations in using ViTs for face identification.
</details>
<details>
<summary>摘要</summary>
大多数面部识别方法使用奶爸 neural network 对两个图像进行比较，并在图像嵌入层进行比较。然而，这种技术可能会受到遮盾（例如面具或镜片）和非标本数据的影响。深度Face-EMD（phan et al. 2022）可以在非标本数据上达到状态机器的准确率，但是其后来的 patch-wise 重新排名阶段具有大 O（n^3 log n）的时间复杂度（对于图像中的 n 个 patch），这是因为优化运输问题。在这篇文章中，我们提出了一种新的， 两个图像 vision transformers（ViTs），它将两个图像的 patch 进行比较，使用 crossed attention。经过在 CASIA Webface（yi et al. 2014）上训练 200 万对图像，我们的模型在不标本数据上达到与 DeepFace-EMD 相同的准确率，但是在推断速度上比 DeepFace-EMD 快上了两倍。此外，通过人类研究，我们的模型表现出了可见的解释性，通过跨层 attention 的视觉化。我们认为我们的工作可以激励更多的人们进行 ViTs 的探索。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.CV_2023_11_06/" data-id="cloojsmgc00l2re888cn3cw73" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.AI_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T12:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.AI_2023_11_06/">cs.AI - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Exploitation-Guided-Exploration-for-Semantic-Embodied-Navigation"><a href="#Exploitation-Guided-Exploration-for-Semantic-Embodied-Navigation" class="headerlink" title="Exploitation-Guided Exploration for Semantic Embodied Navigation"></a>Exploitation-Guided Exploration for Semantic Embodied Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03357">http://arxiv.org/abs/2311.03357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Justin Wasserman, Girish Chowdhary, Abhinav Gupta, Unnat Jain</li>
<li>for: 本研究旨在提出一种原理性的模块合并方法，以提高embodied navigation和sim-to-robot transfer的性能。</li>
<li>methods: 本文提出了Exploitation-Guided Exploration（XGX）方法，其包括一个分离的探索模块和一个利用模块，两者在一种新的和直观的方式相互作用。在确定的最后步骤中，利用模块会取代探索模块，并驱动一个被 override 的政策优化。</li>
<li>results: XGX方法在对难 Navigation task的表现中提高了state-of-the-art的性能，从70%提高到73%。此外，通过targeted分析，我们还证明XGX在目标 conditional exploration中更有效率。最后，我们还进行了robot硬件上的实验，并证明XGX在实验中比best baseline更高出两倍。project page: xgxvisnav.github.io<details>
<summary>Abstract</summary>
In the recent progress in embodied navigation and sim-to-robot transfer, modular policies have emerged as a de facto framework. However, there is more to compositionality beyond the decomposition of the learning load into modular components. In this work, we investigate a principled way to syntactically combine these components. Particularly, we propose Exploitation-Guided Exploration (XGX) where separate modules for exploration and exploitation come together in a novel and intuitive manner. We configure the exploitation module to take over in the deterministic final steps of navigation i.e. when the goal becomes visible. Crucially, an exploitation module teacher-forces the exploration module and continues driving an overridden policy optimization. XGX, with effective decomposition and novel guidance, improves the state-of-the-art performance on the challenging object navigation task from 70% to 73%. Along with better accuracy, through targeted analysis, we show that XGX is also more efficient at goal-conditioned exploration. Finally, we show sim-to-real transfer to robot hardware and XGX performs over two-fold better than the best baseline from simulation benchmarking. Project page: xgxvisnav.github.io
</details>
<details>
<summary>摘要</summary>
最近的具体Navigation和sim-to-robot传输进展中，模块政策 emerged as a de facto framework。然而，这只是compose beyond the decomposition of the learning load into modular components。在这项工作中，我们调查了一种原则的方式来 syntax combination of these components。特别是，我们提出了Exploitation-Guided Exploration (XGX)，其中分配策略和探索策略在一种新和直观的方式结合。我们将探索模块配置为在决定性的最后步骤中接管 Navigation i.e. 当目标变得可见时。关键地，一个exploitation module teacher-forces the exploration module and continues driving an overridden policy optimization。XGX，通过有效的分解和新的导航，提高了Object Navigation task的状态对��性从70%提高到73%.此外，通过targeted analysis，我们还表明XGX更有效率地进行goal-conditioned exploration。最后，我们展示了XGX在硬件robot上的实际传输和 simulation benchmarking中的超过两倍的性能提升。项目页面：xgxvisnav.github.io
</details></li>
</ul>
<hr>
<h2 id="SegGen-Supercharging-Segmentation-Models-with-Text2Mask-and-Mask2Img-Synthesis"><a href="#SegGen-Supercharging-Segmentation-Models-with-Text2Mask-and-Mask2Img-Synthesis" class="headerlink" title="SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis"></a>SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03355">http://arxiv.org/abs/2311.03355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prismformore/seggen">https://github.com/prismformore/seggen</a></li>
<li>paper_authors: Hanrong Ye, Jason Kuen, Qing Liu, Zhe Lin, Brian Price, Dan Xu</li>
<li>for: 提高图像分割模型的性能，特别是在 semantic segmentation、panoptic segmentation 和 instance segmentation 领域。</li>
<li>methods: 使用 MaskSyn 和 ImgSyn 两种数据生成策略，即文本到mask生成模型和mask到图像生成模型，以提高分割模型的supervision数据的多样性; 使用mask-to-image生成模型来生成新的图像基于现有的mask。</li>
<li>results: 在 ADE20K 和 COCO benchmark上，使用我们的数据生成方法可以明显提高 state-of-the-art 分割模型的性能，包括 semantic segmentation、panoptic segmentation 和 instance segmentation; 对 ADE20K mIoU，Mask2Former R50 的性能由47.2提高到49.9 (+2.7); Mask2Former Swin-L 也从56.1提高到57.4 (+1.3)。<details>
<summary>Abstract</summary>
We propose SegGen, a highly-effective training data generation method for image segmentation, which pushes the performance limits of state-of-the-art segmentation models to a significant extent. SegGen designs and integrates two data generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new mask-image pairs via our proposed text-to-mask generation model and mask-to-image generation model, greatly improving the diversity in segmentation masks for model supervision; (ii) ImgSyn synthesizes new images based on existing masks using the mask-to-image generation model, strongly improving image diversity for model inputs. On the highly competitive ADE20K and COCO benchmarks, our data generation method markedly improves the performance of state-of-the-art segmentation models in semantic segmentation, panoptic segmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU, Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L is also significantly increased from 56.1 to 57.4 (+1.3). These promising results strongly suggest the effectiveness of our SegGen even when abundant human-annotated training data is utilized. Moreover, training with our synthetic data makes the segmentation models more robust towards unseen domains. Project website: https://seggenerator.github.io
</details>
<details>
<summary>摘要</summary>
我们提出了SegGen，一种高效的训练数据生成方法 для图像分割，可以大幅提高现有状态最优分割模型的性能。SegGen设计并集成了两种数据生成策略：MaskSyn和ImgSyn。（一）MaskSyn通过我们提议的文本到mask生成模型和mask到图像生成模型，可以大幅提高分割面精度和多样性。（二）ImgSyn通过使用现有的mask来生成新图像，可以强化图像多样性。在ADE20K和COCO标准测试 benchmark上，我们的数据生成方法对现有的分割模型进行了显著改进，包括semantic segmentation、panoptic segmentation和instance segmentation。特别是在ADE20K mIoU上，Mask2Former R50的性能从47.2提高到49.9（+2.7），Mask2Former Swin-L的性能也从56.1提高到57.4（+1.3）。这些出色的结果表明我们的SegGen在有限的人工标注数据上可以获得显著改进。此外，使用我们生成的 sintetic数据来训练分割模型可以使其更加鲁棒，对于未看到的领域。项目官方网站：https://seggenerator.github.io
</details></li>
</ul>
<hr>
<h2 id="GLaMM-Pixel-Grounding-Large-Multimodal-Model"><a href="#GLaMM-Pixel-Grounding-Large-Multimodal-Model" class="headerlink" title="GLaMM: Pixel Grounding Large Multimodal Model"></a>GLaMM: Pixel Grounding Large Multimodal Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03356">http://arxiv.org/abs/2311.03356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanoona Rasheed, Muhammad Maaz, Sahal Shaji, Abdelrahman Shaker, Salman Khan, Hisham Cholakkal, Rao M. Anwer, Erix Xing, Ming-Hsuan Yang, Fahad S. Khan</li>
<li>for: This paper aims to generate natural language responses that are seamlessly intertwined with corresponding object segmentation masks, enabling users to interact with the model at various levels of granularity in both textual and visual domains.</li>
<li>methods: The proposed Grounding LMM (GLaMM) model uses region-level LMMs to generate visually grounded responses, and it can accept both textual and visual prompts as input. The model is evaluated on a comprehensive evaluation protocol with a densely annotated dataset called GranD, which includes 7.5M unique concepts grounded in a total of 810M regions.</li>
<li>results: GLaMM achieves state-of-the-art performance on several downstream tasks, including referring expression segmentation, image and region-level captioning, and vision-language conversations. The model is also able to generate visually grounded conversations that are more detailed and accurate than previous models.<details>
<summary>Abstract</summary>
Large Multimodal Models (LMMs) extend Large Language Models to the vision domain. Initial efforts towards LMMs used holistic images and text prompts to generate ungrounded textual responses. Very recently, region-level LMMs have been used to generate visually grounded responses. However, they are limited to only referring a single object category at a time, require users to specify the regions in inputs, or cannot offer dense pixel-wise object grounding. In this work, we present Grounding LMM (GLaMM), the first model that can generate natural language responses seamlessly intertwined with corresponding object segmentation masks. GLaMM not only grounds objects appearing in the conversations but is flexible enough to accept both textual and optional visual prompts (region of interest) as input. This empowers users to interact with the model at various levels of granularity, both in textual and visual domains. Due to the lack of standard benchmarks for the novel setting of generating visually grounded detailed conversations, we introduce a comprehensive evaluation protocol with our curated grounded conversations. Our proposed Grounded Conversation Generation (GCG) task requires densely grounded concepts in natural scenes at a large-scale. To this end, we propose a densely annotated Grounding-anything Dataset (GranD) using our proposed automated annotation pipeline that encompasses 7.5M unique concepts grounded in a total of 810M regions available with segmentation masks. Besides GCG, GLaMM also performs effectively on several downstream tasks e.g., referring expression segmentation, image and region-level captioning and vision-language conversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.
</details>
<details>
<summary>摘要</summary>
大型多模型（LMM）扩展了大型语言模型到视觉领域。初期尝试使用整体图像和文本提示生成不关联的文本回应。然而，最近的区域级LMM已经用于生成相关的回应。不过，它们只能同时引用一个物体类别，需要用户在输入中指定区域，或者无法提供密集像素精度的物体固定。在这项工作中，我们提出了固定语言回应和相应物体分割面的模型——GLaMM。GLaMM不仅可以在对话中固定物体，而且可以接受文本和可选的视觉提示（区域兴趣点）作为输入。这使得用户可以在文本和视觉领域中与模型进行互动，并且可以在不同的级别进行互动。由于不存在对生成视觉精度讨论的标准评价准则，我们提出了一种完整的评价协议，并针对这种新的设定生成了一个大规模的精度讨论数据集（GCG）。我们的提案的Grounded Conversation Generation（GCG）任务需要在自然场景中 densely grounded的概念，并且需要在大规模的场景中进行评价。为此，我们提出了一个名为Grounding-anything Dataset（GranD）的 densely annotated数据集，该数据集包含7.5万个不同的概念，并且在810万个区域中进行了分割面的注释。除了GCG，GLaMM还在多个下游任务中表现出色，如图像和区域水平的描述、图像和区域水平的标题生成和视觉语言对话等。项目页面：https://mbzuai-oryx.github.io/groundingLMM。
</details></li>
</ul>
<hr>
<h2 id="Scalable-and-Transferable-Black-Box-Jailbreaks-for-Language-Models-via-Persona-Modulation"><a href="#Scalable-and-Transferable-Black-Box-Jailbreaks-for-Language-Models-via-Persona-Modulation" class="headerlink" title="Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation"></a>Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03348">http://arxiv.org/abs/2311.03348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rusheb Shah, Quentin Feuillade–Montixi, Soroush Pour, Arush Tagade, Stephen Casper, Javier Rando</li>
<li>for:  investigate persona modulation as a black-box jailbreaking method to steer a target model to take on personalities that are willing to comply with harmful instructions</li>
<li>methods: automate the generation of jailbreaks using a language model assistant</li>
<li>results: achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation (0.23%); also transfer to Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%, respectively<details>
<summary>Abstract</summary>
Despite efforts to align large language models to produce harmless responses, they are still vulnerable to jailbreak prompts that elicit unrestricted behaviour. In this work, we investigate persona modulation as a black-box jailbreaking method to steer a target model to take on personalities that are willing to comply with harmful instructions. Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant. We demonstrate a range of harmful completions made possible by persona modulation, including detailed instructions for synthesising methamphetamine, building a bomb, and laundering money. These automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation (0.23%). These prompts also transfer to Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%, respectively. Our work reveals yet another vulnerability in commercial large language models and highlights the need for more comprehensive safeguards.
</details>
<details>
<summary>摘要</summary>
尽管努力将大语言模型调整为生成无害回复，它们仍然容易受到劫夺提示的影响，导致模型生成不良行为。在这项工作中，我们 investigate persona modulation 作为黑盒劫夺方法，以控制目标模型的行为。而不是手动制作每个人物的提示，我们使用语言模型助手自动生成劫夺。我们示出了由 persona modulation 引起的各种危险 completions，包括合成吸引剂、制造炸弹和洗钱等详细指导。这些自动攻击在 GPT-4 中达到了42.5%的危险完成率，比之前的模ulation（0.23%）高185倍。这些提示还可以在 Claude 2 和 Vicuna 上进行危险完成，即61.0%和35.9%。我们的工作揭示了商业大语言模型又一个漏洞，并高亮了更多的安全措施的需要。
</details></li>
</ul>
<hr>
<h2 id="Embedding-First-Order-Logic-into-Kernel-Machines"><a href="#Embedding-First-Order-Logic-into-Kernel-Machines" class="headerlink" title="Embedding First Order Logic into Kernel Machines"></a>Embedding First Order Logic into Kernel Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03340">http://arxiv.org/abs/2311.03340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michelangelo Diligenti, Marco Gori, Marco Maggini, Leonardo Rigutini</li>
<li>for: 本文提出了一种整合supervised和Unsupervised示例以及背景知识的核心机器学习框架。</li>
<li>methods: 本文使用多任务学习方案，其中多个predicate定义在一组对象上是通过 jointly 学习从示例中学习的。这些predicate可以是known priori或通过适当的kernel-based学习器来approximate。</li>
<li>results: 本文提出了一种将逻辑法则转换为连续实现的方法，以便处理由kernel-based predicates生成的输出。学习问题被формаulated为一个半监督学习任务，其中需要优化 primal 中的损失函数，该损失函数结合了监督例子上的适应损失函数、正则化项和约束项。然而，约束项不是凸函数，这可能会阻碍优化过程。本文提出了一种two stage learning schema，其中首先学习supervised例子，然后强制执行约束。<details>
<summary>Abstract</summary>
In this paper we propose a general framework to integrate supervised and unsupervised examples with background knowledge expressed by a collection of first-order logic clauses into kernel machines. In particular, we consider a multi-task learning scheme where multiple predicates defined on a set of objects are to be jointly learned from examples, enforcing a set of FOL constraints on the admissible configurations of their values. The predicates are defined on the feature spaces, in which the input objects are represented, and can be either known a priori or approximated by an appropriate kernel-based learner. A general approach is presented to convert the FOL clauses into a continuous implementation that can deal with the outputs computed by the kernel-based predicates. The learning problem is formulated as a semi-supervised task that requires the optimization in the primal of a loss function that combines a fitting loss measure on the supervised examples, a regularization term, and a penalty term that enforces the constraints on both the supervised and unsupervised examples. Unfortunately, the penalty term is not convex and it can hinder the optimization process. However, it is possible to avoid poor solutions by using a two stage learning schema, in which the supervised examples are learned first and then the constraints are enforced.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个总体框架，用于将监督和无监督示例集合Background Knowledge表示为一个集合First-Order Logic Clauses（FOL）中的扩展。特别是，我们考虑了一种多任务学习方案，其中多个定义在一组对象上的预测符需要同时学习从示例集合中，并且对预测符的值进行FOL约束。这些预测符定义在特征空间中，其中输入对象被表示，并且可以是先知的或者通过适当的核心学习器来估算。我们提出了一种抽象转换FOL条件为连续实现的总体方法，以便与核心学习器计算的输出进行交互。学习问题被定义为一种半监督学习问题，其中需要优化飞行函数的极值，该函数组合监督示例集合中的适应损失函数、规则化项和约束项。然而，约束项不是凸函数，可能会干扰优化过程。但是，我们可以通过两个阶段学习策略来避免差解，其中首先学习监督示例集合中的示例，然后对约束进行执行。
</details></li>
</ul>
<hr>
<h2 id="FLOGA-A-machine-learning-ready-dataset-a-benchmark-and-a-novel-deep-learning-model-for-burnt-area-mapping-with-Sentinel-2"><a href="#FLOGA-A-machine-learning-ready-dataset-a-benchmark-and-a-novel-deep-learning-model-for-burnt-area-mapping-with-Sentinel-2" class="headerlink" title="FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2"></a>FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03339">http://arxiv.org/abs/2311.03339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Sdraka, Alkinoos Dimakos, Alexandros Malounis, Zisoula Ntasiou, Konstantinos Karantzalos, Dimitrios Michail, Ioannis Papoutsis<br>for:The paper aims to provide an accurate and timely mapping of wildfire-affected areas using satellite imagery and Machine Learning techniques.methods:The authors use a combination of Sentinel-2 and MODIS satellite imagery with variable spatial and spectral resolution, and employ multiple Machine Learning and Deep Learning algorithms for change detection and burnt area mapping.results:The proposed Deep Learning model, BAM-CD, outperforms all other methods in terms of accuracy and robustness, and provides an effective solution for the automatic extraction of burnt areas.<details>
<summary>Abstract</summary>
Over the last decade there has been an increasing frequency and intensity of wildfires across the globe, posing significant threats to human and animal lives, ecosystems, and socio-economic stability. Therefore urgent action is required to mitigate their devastating impact and safeguard Earth's natural resources. Robust Machine Learning methods combined with the abundance of high-resolution satellite imagery can provide accurate and timely mappings of the affected area in order to assess the scale of the event, identify the impacted assets and prioritize and allocate resources effectively for the proper restoration of the damaged region. In this work, we create and introduce a machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations for the Greek Area). This dataset is unique as it comprises of satellite imagery acquired before and after a wildfire event, it contains information from Sentinel-2 and MODIS modalities with variable spatial and spectral resolution, and contains a large number of events where the corresponding burnt area ground truth has been annotated by domain experts. FLOGA covers the wider region of Greece, which is characterized by a Mediterranean landscape and climatic conditions. We use FLOGA to provide a thorough comparison of multiple Machine Learning and Deep Learning algorithms for the automatic extraction of burnt areas, approached as a change detection task. We also compare the results to those obtained using standard specialized spectral indices for burnt area mapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our benchmark results demonstrate the efficacy of the proposed technique in the automatic extraction of burnt areas, outperforming all other methods in terms of accuracy and robustness. Our dataset and code are publicly available at: https://github.com/Orion-AI-Lab/FLOGA.
</details>
<details>
<summary>摘要</summary>
随着过去的一个十年，全球受到野火的影响逐渐增加，对人类和动物生命，生态系统以及经济稳定造成了重大威胁。因此，我们需要立即采取行动，以遏制其恶势力并保护地球的自然资源。高效的机器学习方法，结合高分辨率卫星图像的丰富存在，可以为评估事件规模、确定影响资产和有效分配资源而提供准确和时效的映射。在这种工作中，我们创建了一个名为FLOGA（希腊地区森林野火观测）的机器学习准备数据集。FLOGA数据集独特之处在于它包括了在野火事件前后获得的卫星图像信息，其中包括Sentinel-2和MODIS模式，并且包含大量已经由领域专家标注的烧毁地区的ground truth。FLOGA覆盖了希腊更广阔的地区，其地中地中海气候和地貌特征。我们使用FLOGA数据集，对多种机器学习和深度学习算法进行自动烧毁区域抽取的比较研究。我们还将其与特有 spectral indices 的烧毁地区映射方法进行比较。最后，我们提出了一种新的深度学习模型，即BAM-CD。我们的参考结果表明，提议的方法在自动烧毁区域抽取方面具有高度的准确性和可靠性。我们的数据集和代码在：https://github.com/Orion-AI-Lab/FLOGA 可以进行下载。
</details></li>
</ul>
<hr>
<h2 id="DAIL-Data-Augmentation-for-In-Context-Learning-via-Self-Paraphrase"><a href="#DAIL-Data-Augmentation-for-In-Context-Learning-via-Self-Paraphrase" class="headerlink" title="DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase"></a>DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03319">http://arxiv.org/abs/2311.03319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li, Yulin wang, Xueqi Wang, William Hogan, Jingbo Shang</li>
<li>for: 提高受限资源下的自然语言处理任务（NLP）的性能</li>
<li>methods: 使用增强的大语言模型和增强学习（ICL）方法，并利用自己生成的内容来生成补充数据</li>
<li>results: 在受限资源下，DAIL方法比标准ICL方法和其他集成方法表现出更高的性能，并且可以用投票一致性作为模型的信任度指标<details>
<summary>Abstract</summary>
In-Context Learning (ICL) combined with pre-trained large language models has achieved promising results on various NLP tasks. However, ICL requires high-quality annotated demonstrations which might not be available in real-world scenarios. To overcome this limitation, we propose \textbf{D}ata \textbf{A}ugmentation for \textbf{I}n-Context \textbf{L}earning (\textbf{DAIL}). DAIL leverages the intuition that large language models are more familiar with the content generated by themselves. It first utilizes the language model to generate paraphrases of the test sample and employs majority voting to determine the final result based on individual predictions. Our extensive empirical evaluation shows that DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario. Additionally, we explore the use of voting consistency as a confidence score of the model when the logits of predictions are inaccessible. We believe our work will stimulate further research on ICL in low-resource settings.
</details>
<details>
<summary>摘要</summary>
团 Context Learning（ICL）与预训练大语言模型结合实现了多种自然语言处理任务的出色结果。然而，ICL需要高质量的注释示例，这可能在实际场景中不可获得。为了解决这个限制，我们提议使用数据增强 для团 Context Learning（DAIL）。 DAIL 利用大语言模型对自己生成的内容更加熟悉的想法，首先使用语言模型生成测试样本的重写，然后通过多数投票确定基于个体预测的最终结果。我们的广泛的实验证明，DAIL 在低资源情况下超越标准 IC 方法和其他集成方法。此外，我们还探讨了使用投票一致性作为模型的信任度指标，当预测的 logits 不可访问时。我们认为我们的工作将激发更多关于 IC 在低资源情况下的研究。
</details></li>
</ul>
<hr>
<h2 id="Neural-Structure-Learning-with-Stochastic-Differential-Equations"><a href="#Neural-Structure-Learning-with-Stochastic-Differential-Equations" class="headerlink" title="Neural Structure Learning with Stochastic Differential Equations"></a>Neural Structure Learning with Stochastic Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03309">http://arxiv.org/abs/2311.03309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjie Wang, Joel Jennings, Wenbo Gong</li>
<li>for: 本研究旨在解决longstanding challenge在数学科学中，即从 temporal observations 中探测变量之间的下面关系。</li>
<li>methods: 本文提出了一种新的结构学习方法，即SCOTCH，它将神经统计 diferencial equations (SDE) 与变量推理相结合，以估计可能的结构 posterior distribution。</li>
<li>results: 在synthetic和实际数据上，本方法与相关基eline比较，得到了改善的结构学习表现，并且可以正确地捕捉到不规则的观测时间点。<details>
<summary>Abstract</summary>
Discovering the underlying relationships among variables from temporal observations has been a longstanding challenge in numerous scientific disciplines, including biology, finance, and climate science. The dynamics of such systems are often best described using continuous-time stochastic processes. Unfortunately, most existing structure learning approaches assume that the underlying process evolves in discrete-time and/or observations occur at regular time intervals. These mismatched assumptions can often lead to incorrect learned structures and models. In this work, we introduce a novel structure learning method, SCOTCH, which combines neural stochastic differential equations (SDE) with variational inference to infer a posterior distribution over possible structures. This continuous-time approach can naturally handle both learning from and predicting observations at arbitrary time points. Theoretically, we establish sufficient conditions for an SDE and SCOTCH to be structurally identifiable, and prove its consistency under infinite data limits. Empirically, we demonstrate that our approach leads to improved structure learning performance on both synthetic and real-world datasets compared to relevant baselines under regular and irregular sampling intervals.
</details>
<details>
<summary>摘要</summary>
发现变量之间的下面关系从暂时观察中获得信息是许多科学领域的长期挑战，包括生物、金融和气候科学。这些系统的动态通常最好使用连续时间杂相过程来描述。然而，大多数现有结构学习方法假设下面过程发展在离散时间和/或观察发生在固定时间间隔。这些不一致的假设可能会导致错误的学习结构和模型。在这项工作中，我们介绍了一种新的结构学习方法，即SCOTCH，它将神经杂相准则（SDE）与变量抽象推理相结合，以推断可能的结构 posterior 分布。这种连续时间方法可以自然地处理从和预测观察的任意时间点进行学习和预测。理论上，我们确立了SDE和SCOTCH的结构可识别性Conditions，并证明其在无穷数据极限下的一致性。实际上，我们通过对 sintetic和实际数据进行比较，证明了我们的方法在不同的抽取间隔下的性能提高。
</details></li>
</ul>
<hr>
<h2 id="Learning-Reusable-Manipulation-Strategies"><a href="#Learning-Reusable-Manipulation-Strategies" class="headerlink" title="Learning Reusable Manipulation Strategies"></a>Learning Reusable Manipulation Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03293">http://arxiv.org/abs/2311.03293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayuan Mao, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling</li>
<li>for: 学习和总结夹用”技巧”，包括使用不同物品位置、大小和类型。</li>
<li>methods: 通过单个示例学习和自我玩家自动学习机制，并将学习的细节槽插入标准任务和运动规划中。</li>
<li>results: 机器人可以通过单个示例学习并自动执行各种 manipulate 任务，包括使用不同的工具和策略。<details>
<summary>Abstract</summary>
Humans demonstrate an impressive ability to acquire and generalize manipulation "tricks." Even from a single demonstration, such as using soup ladles to reach for distant objects, we can apply this skill to new scenarios involving different object positions, sizes, and categories (e.g., forks and hammers). Additionally, we can flexibly combine various skills to devise long-term plans. In this paper, we present a framework that enables machines to acquire such manipulation skills, referred to as "mechanisms," through a single demonstration and self-play. Our key insight lies in interpreting each demonstration as a sequence of changes in robot-object and object-object contact modes, which provides a scaffold for learning detailed samplers for continuous parameters. These learned mechanisms and samplers can be seamlessly integrated into standard task and motion planners, enabling their compositional use.
</details>
<details>
<summary>摘要</summary>
人类具有吸引人的物理 manipulation "技巧" 学习能力。从单一示例，如使用汤匙来达到远距离物体，我们可以将这种技能应用到新的情况中，包括不同的物体位置、大小和类别（例如用叶和锤子）。此外，我们可以flexibly组合不同的技能来制定长期计划。在这篇论文中，我们提出了一种框架，允许机器通过单一示例和自己游戏来学习 manipulate 技能，称为"机制"。我们的关键发现在于将每个示例解释为机器人对物体和物体之间的接触方式的序列变化，从而提供了一个支持学习细致的抽象器的框架。这些学习的机制和抽象器可以轻松地与标准任务和运动规划器集成，以实现其可 compose 使用。
</details></li>
</ul>
<hr>
<h2 id="S-LoRA-Serving-Thousands-of-Concurrent-LoRA-Adapters"><a href="#S-LoRA-Serving-Thousands-of-Concurrent-LoRA-Adapters" class="headerlink" title="S-LoRA: Serving Thousands of Concurrent LoRA Adapters"></a>S-LoRA: Serving Thousands of Concurrent LoRA Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03285">http://arxiv.org/abs/2311.03285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Sheng, Shiyi Cao, Dacheng Li, Coleman Hooper, Nicholas Lee, Shuo Yang, Christopher Chou, Banghua Zhu, Lianmin Zheng, Kurt Keutzer, Joseph E. Gonzalez, Ion Stoica</li>
<li>for: 这个研究旨在开发一个可扩展的服务系统，以便大规模执行多个任务特定的精细定制化模型。</li>
<li>methods: 这个研究使用了“pretrain-then-finetune”方法，并且将LoRA（Low-Rank Adaptation）作为精致化方法。LoRA可以将基本模型adaspt到多个任务上，从而生成了许多LoRA拓展器。</li>
<li>results: 这个研究发现，使用S-LoRA系统可以在单一GPU上服务 thousands个LoRA拓展器，并且可以提高比较预设的HuggingFace PEFT和vLLM库的吞吐量，并可以增加服务的精细定制化模型数量。这使得S-LoRA可以提供大规模的定制化服务。<details>
<summary>Abstract</summary>
The "pretrain-then-finetune" paradigm is commonly adopted in the deployment of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method, is often employed to adapt a base model to a multitude of tasks, resulting in a substantial collection of LoRA adapters derived from one base model. We observe that this paradigm presents significant opportunities for batched inference during serving. To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters. S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory. To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation. Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving), S-LoRA can improve the throughput by up to 4 times and increase the number of served adapters by several orders of magnitude. As a result, S-LoRA enables scalable serving of many task-specific fine-tuned models and offers the potential for large-scale customized fine-tuning services.
</details>
<details>
<summary>摘要</summary>
“将基模型先训练后调整”的方法在大型语言模型的部署中广泛使用。低维度适应（LoRA），一种优化缓存使用率的调整方法，常用来对多个任务进行适应，从而产生了许多LoRA调整器。我们发现，这个方法在服务时期具有重要的批处理机会。为了利用这些机会，我们介绍了S-LoRA，一个可扩展的服务系统，可以实现多个LoRA调整器的扩展服务。S-LoRA将所有调整器存储在主内存中，并将用户端查询中的调整器载入到GPU内存中。为了有效利用GPU内存和减少分解，S-LoRA提出了一个统一的当值系统，将动态调整器的重量和KV库缓存中的序列长度管理在一个统一的内存池中。此外，S-LoRA还使用了一种新的tensor并行架构和高度优化的自定义CUDA核心函数，以进行heterogeneous批处理。总之，这些特点使得S-LoRA可以在单一GPU或多个GPU上服务千多个LoRA调整器，只需要轻微的负载。相比之下，现有的库如HuggingFace PEFT和vLLM（具有原生支持LoRA服务），S-LoRA可以提高吞务率来到4倍，并增加服务的调整器数量至数十个数量级。因此，S-LoRA实现了可扩展的服务多个任务特定的精确化服务，并提供了大规模自定义精确化服务的潜力。
</details></li>
</ul>
<hr>
<h2 id="From-Coupled-Oscillators-to-Graph-Neural-Networks-Reducing-Over-smoothing-via-a-Kuramoto-Model-based-Approach"><a href="#From-Coupled-Oscillators-to-Graph-Neural-Networks-Reducing-Over-smoothing-via-a-Kuramoto-Model-based-Approach" class="headerlink" title="From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach"></a>From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03260">http://arxiv.org/abs/2311.03260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Nguyen, Tan M. Nguyen, Hirotada Honda, Takashi Sano, Vinh Nguyen, Shugo Nakamura</li>
<li>for: 针对Graph Neural Networks (GNNs) 中的过度整合现象，提出了 Kuramoto Graph Neural Network (KuramotoGNN)，一种新的连续深度 GNN 类型。</li>
<li>methods: KuramotoGNN 使用 Kuramoto 模型来 Mitigate 过度整合现象，该模型捕捉了非线性吸引器的同步行为。</li>
<li>results: 对多种图深度学习benchmark任务进行实验，显示 KuramotoGNN 可以效果地降低过度整合现象，而且比基eline GNN 和现有方法更好。<details>
<summary>Abstract</summary>
We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.
</details>
<details>
<summary>摘要</summary>
我们提出了kuramoto图 neuronal网络（KuramotoGNN），一种新的连续深度图神经网络（GNN），它利用kuramoto模型来 mitigate the over-smoothing phenomenon，在这个现象中，GNN中的节点特征会在层数增加时变得无法分辨。kuramoto模型捕捉了非线性相互频率振荡器的同步行为。从拓扑学角度来看，我们首先解释了kuramoto模型与基本GNN之间的连接，然后解释了GNN中的过滤现象可以被看作kuramoto模型中的相位同步现象。KuramotoGNN将这种相位同步现象替换为频率同步，以防止节点特征相互混同，同时允许系统达到稳定同步状态。我们通过实验证明了KuramotoGNN在不同的图深度学 benchmark任务上的优势，比如降低过滤现象。
</details></li>
</ul>
<hr>
<h2 id="Coherent-Entity-Disambiguation-via-Modeling-Topic-and-Categorical-Dependency"><a href="#Coherent-Entity-Disambiguation-via-Modeling-Topic-and-Categorical-Dependency" class="headerlink" title="Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency"></a>Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03253">http://arxiv.org/abs/2311.03253</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilin Xiao, Linjun Shou, Xingyao Zhang, Jie Wu, Ming Gong, Jian Pei, Daxin Jiang</li>
<li>for: 提高Entity Disambiguation（ED）系统的准确率和可owiezaibility（coherence）。</li>
<li>methods: 提出了一种基于Variational Autoencoder（VAE）和外部分类记忆的ED方法，以提高Entity predictions的coherence。</li>
<li>results: 实验结果显示，该方法在Popular ED benchmarks上达到了新的State-of-the-art Results，特别是在长文本场景下表现出色。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Previous entity disambiguation (ED) methods adopt a discriminative paradigm, where prediction is made based on matching scores between mention context and candidate entities using length-limited encoders. However, these methods often struggle to capture explicit discourse-level dependencies, resulting in incoherent predictions at the abstract level (e.g. topic or category). We propose CoherentED, an ED system equipped with novel designs aimed at enhancing the coherence of entity predictions. Our method first introduces an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences. This approach not only allows the encoder to handle longer documents more effectively, conserves valuable input space, but also keeps a topic-level coherence. Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions. By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level. We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model demonstrates particularly outstanding performance on challenging long-text scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Instructed-Language-Models-with-Retrievers-Are-Powerful-Entity-Linkers"><a href="#Instructed-Language-Models-with-Retrievers-Are-Powerful-Entity-Linkers" class="headerlink" title="Instructed Language Models with Retrievers Are Powerful Entity Linkers"></a>Instructed Language Models with Retrievers Are Powerful Entity Linkers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03250">http://arxiv.org/abs/2311.03250</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MrZilinXiao/InsGenEntityLinking">https://github.com/MrZilinXiao/InsGenEntityLinking</a></li>
<li>paper_authors: Zilin Xiao, Ming Gong, Jie Wu, Xingyao Zhang, Linjun Shou, Jian Pei, Daxin Jiang</li>
<li>for: 这个论文的目的是提高大语言模型（LLM）能够进行实体连接（EL）任务，并且可以在大量知识库中提供精确的实体预测。</li>
<li>methods: 这篇论文提出了一些使用语言模型执行EL任务的方法，包括将EL任务作为一个序列到序列的训练目标进行语言模型的 instrucion-tuning，以及一种基于轻量级的潜在提及检索器的新的生成EL框架，这种框架可以在不需要重复和非平行化解码的情况下实现4倍的速度提升。</li>
<li>results:  compared to先前的生成方法，INSGENEL可以获得6.8倍的F1分数平均提升，同时在训练数据效率和训练计算消耗方面也有很大的优势。此外，论文还发现，通过针对EL任务进行精心工程的内容学习（ICL）框架，可以进一步提高EL任务的性能。<details>
<summary>Abstract</summary>
Generative approaches powered by large language models (LLMs) have demonstrated emergent abilities in tasks that require complex reasoning abilities. Yet the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base. We present Instructed Generative Entity Linker (INSGENEL), the first approach that enables casual language models to perform entity linking over knowledge bases. Several methods to equip language models with EL capability were proposed in this work, including (i) a sequence-to-sequence training EL objective with instruction-tuning, (ii) a novel generative EL framework based on a light-weight potential mention retriever that frees the model from heavy and non-parallelizable decoding, achieving 4$\times$ speedup without compromise on linking metrics. INSGENEL outperforms previous generative alternatives with +6.8 F1 points gain on average, also with a huge advantage in training data efficiency and training compute consumption. In addition, our skillfully engineered in-context learning (ICL) framework for EL still lags behind INSGENEL significantly, reaffirming that the EL task remains a persistent hurdle for general LLMs.
</details>
<details>
<summary>摘要</summary>
生成方法，受大型语言模型（LLM）的推动，在需要复杂逻辑能力的任务中表现出emergent能力。然而，生成性仍然使得生成的内容受到幻觉的困扰，因此不适用于实体关注任务（EL），需要在大量知识库中准确预测实体。我们提出了首个使得习语言模型执行实体关注任务的方法——指令生成实体链接器（INSGENEL）。我们提出了多种方法来让语言模型拥有EL能力，包括（i）将EL作为目标进行序列到序列训练，并在 instruciton-tuning 中进行调整，（ii）基于轻量级的潜在提取器来实现生成EL框架，从而实现4倍的速度提升而无需牺牲链接度量。INSGENEL在前一代生成方法上表现出+6.8个F1分的提升均值，同时具有较少的训练数据和训练计算资源的优势。此外，我们的巧妙设计的内容学习（ICL）框架也落后于INSGENEL，这再次证明了EL任务仍然是普遍的LLM难点。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Post-Hoc-Case-Based-Explanation-with-Feature-Highlighting"><a href="#Advancing-Post-Hoc-Case-Based-Explanation-with-Feature-Highlighting" class="headerlink" title="Advancing Post Hoc Case Based Explanation with Feature Highlighting"></a>Advancing Post Hoc Case Based Explanation with Feature Highlighting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03246">http://arxiv.org/abs/2311.03246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eoin Kenny, Eoin Delaney, Mark Keane</li>
<li>For: 该论文提出了一种用于协助人类和AI合作的可解释AI（XAI）技术，以帮助解释黑obox AI 系统的预测结果。* Methods: 该论文提出了两种通用算法（幽默和超像素基于算法），可以在测试图像中孤立多个清晰特征部分，然后将其与训练数据中的相关案例相连接，以提供更全面的解释。* Results: 研究发现，该方法可以在实际世界数据集上，对于不确定分类结果，让用户感到满意度得到了改善，而不是只显示解释而无法高亮特征。<details>
<summary>Abstract</summary>
Explainable AI (XAI) has been proposed as a valuable tool to assist in downstream tasks involving human and AI collaboration. Perhaps the most psychologically valid XAI techniques are case based approaches which display 'whole' exemplars to explain the predictions of black box AI systems. However, for such post hoc XAI methods dealing with images, there has been no attempt to improve their scope by using multiple clear feature 'parts' of the images to explain the predictions while linking back to relevant cases in the training data, thus allowing for more comprehensive explanations that are faithful to the underlying model. Here, we address this gap by proposing two general algorithms (latent and super pixel based) which can isolate multiple clear feature parts in a test image, and then connect them to the explanatory cases found in the training data, before testing their effectiveness in a carefully designed user study. Results demonstrate that the proposed approach appropriately calibrates a users feelings of 'correctness' for ambiguous classifications in real world data on the ImageNet dataset, an effect which does not happen when just showing the explanation without feature highlighting.
</details>
<details>
<summary>摘要</summary>
Explainable AI（XAI）已被提议为在人类和AI合作下的有价值工具。可能最有心理效果的XAI技术是case基本方法，这些方法在显示“整个”例子来解释黑盒AI系统的预测。然而，对于这些后期XAI方法来处理图像，没有尝试使用多个清晰特征“部分”来解释预测，并将其联系回相关的训练数据中的案例，从而为更全面的解释提供了更多的心理效果。在这里，我们解决了这个差距，并提出了两种通用算法（潜在和超Pixel基于），它们可以在测试图像中分解出多个清晰特征部分，然后将其联系回训练数据中的解释案例，并在一个仔细设计的用户研究中测试其有效性。结果表明，我们的方法可以在实际世界数据集上的ImageNet上适当调整用户对不确定分类的情感，这种效果不会发生只显示解释而没有特征高亮。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Self-Supervised-Cross-View-Training-For-Sentence-Embedding"><a href="#An-Efficient-Self-Supervised-Cross-View-Training-For-Sentence-Embedding" class="headerlink" title="An Efficient Self-Supervised Cross-View Training For Sentence Embedding"></a>An Efficient Self-Supervised Cross-View Training For Sentence Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03228">http://arxiv.org/abs/2311.03228</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrpeerat/SCT">https://github.com/mrpeerat/SCT</a></li>
<li>paper_authors: Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Lalita Lowphansirikul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong</li>
<li>for: constructing an embedding space for sentences without relying on human annotation efforts</li>
<li>methods: Self-supervised Cross-View Training (SCT) framework</li>
<li>results: outperforms state-of-the-art competitors for PLMs with less than 100M parameters in 18 of 21 cases.<details>
<summary>Abstract</summary>
Self-supervised sentence representation learning is the task of constructing an embedding space for sentences without relying on human annotation efforts. One straightforward approach is to finetune a pretrained language model (PLM) with a representation learning method such as contrastive learning. While this approach achieves impressive performance on larger PLMs, the performance rapidly degrades as the number of parameters decreases. In this paper, we propose a framework called Self-supervised Cross-View Training (SCT) to narrow the performance gap between large and small PLMs. To evaluate the effectiveness of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of parameters ranging from 4M to 340M. The experimental results show that STC outperforms the competitors for PLMs with less than 100M parameters in 18 of 21 cases.
</details>
<details>
<summary>摘要</summary>
自我监督句子表示学习是构建句子嵌入空间的任务，无需人类标注努力。一种直观的方法是通过对预训练语言模型（PLM）进行更新和表示学习方法，如对比学习。然而，这种方法在PLM的参数数量减少时表现迅速下降。在这篇论文中，我们提出了一种名为自动cross-view训练（SCT）的框架，以减少大小PLM和大PLM之间的性能差距。为评估SCT的效果，我们与5个基线和现状竞争对手进行比较，在7个semantic textual similarity（STS）标准benchmark上使用5个PLM，其中参数数量从4M到340M。实验结果表明，SCT在PLM参数数量少于100M的18个情况中比其他竞争对手表现更好。
</details></li>
</ul>
<hr>
<h2 id="LDM3D-VR-Latent-Diffusion-Model-for-3D-VR"><a href="#LDM3D-VR-Latent-Diffusion-Model-for-3D-VR" class="headerlink" title="LDM3D-VR: Latent Diffusion Model for 3D VR"></a>LDM3D-VR: Latent Diffusion Model for 3D VR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03226">http://arxiv.org/abs/2311.03226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriela Ben Melech Stan, Diana Wofk, Estelle Aflalo, Shao-Yen Tseng, Zhipeng Cai, Michael Paulitsch, Vasudev Lal</li>
<li>for: 这个研究旨在提供一个基于潜在扩散模型的虚拟现实开发套件（LDM3D-VR），包括LDM3D-pano和LDM3D-SR两种扩散模型。</li>
<li>methods: 这些模型基于现有预训模型，并在包含托架照片、深度地图和描述的数据集上进行了精细调整。</li>
<li>results: 这些模型可以从文本提示中生成圆锥照片和高分辨率RGBD图像，并且可以将低分辨率的输入提升到高分辨率RGBD图像。<details>
<summary>Abstract</summary>
Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>设想扩散模型在视觉输出的创造和操作方面已经达到了顶峰水平。然而，我们知道的是，生成高纬度RGBD图像并行RGB的生成仍然有限。我们介绍LDM3D-VR，一个针对虚拟现实开发的扩散模型集合，包括LDM3D-pano和LDM3D-SR两种模型。这两种模型允许基于文本提示生成全景RGBD图像和低分辨率输入高分辨率RGBD图像的扩展，分别。我们的模型来自现有预训练模型，并在包含全景/高分辨率RGB图像、深度图和描述的 dataset 上进行了细化。两种模型与现有相关方法进行比较。Note: "RGBD" refers to a color image with depth information, and "high-resolution" refers to a high number of pixels in both the color and depth dimensions.
</details></li>
</ul>
<hr>
<h2 id="ALYMPICS-Language-Agents-Meet-Game-Theory"><a href="#ALYMPICS-Language-Agents-Meet-Game-Theory" class="headerlink" title="ALYMPICS: Language Agents Meet Game Theory"></a>ALYMPICS: Language Agents Meet Game Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03220">http://arxiv.org/abs/2311.03220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Tao Ge, Furu Wei</li>
<li>for: 这篇论文旨在利用大语言模型（LLM）代理人 simulate human behavior，以便在游戏理论中进行假设建模和测试。</li>
<li>methods: 该论文使用LLM代理人和自主代理人实现多代理人合作， constructed realistic and dynamic models of human interactions。</li>
<li>results: 通过调整资源可用性和代理人个性，论文发现不同的代理人在竞争中如何互动和采取策略。<details>
<summary>Abstract</summary>
This paper introduces Alympics, a platform that leverages Large Language Model (LLM) agents to facilitate investigations in game theory. By employing LLMs and autonomous agents to simulate human behavior and enable multi-agent collaborations, we can construct realistic and dynamic models of human interactions for game theory hypothesis formulating and testing. To demonstrate this, we present and implement a survival game involving unequal competition for limited resources. Through manipulation of resource availability and agent personalities, we observe how different agents engage in the competition and adapt their strategies. The use of LLM agents in game theory research offers significant advantages, including simulating realistic behavior, providing a controlled, scalable, and reproducible environment. Our work highlights the potential of LLM agents in enhancing the understanding of strategic decision-making within complex socioeconomic contexts. All codes will be made public soon.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了Alympics平台，该平台利用大型语言模型（LLM）代理来促进游戏理论研究。通过使用LLM和自主代理来模拟人类行为，我们可以构建更加真实和动态的人类互动模型，用于游戏理论假设构建和测试。为了证明这一点，我们提出了一个竞争生存游戏，其中有限的资源和代理人格的不同导致不同的代理如何在竞争中 engagé和适应策略。使用LLM代理在游戏理论研究中具有重要优点，包括模拟实际行为、提供可控、可扩展和可重现的环境。我们的工作强调了LLM代理在复杂社会经济背景下的决策推理理解的潜力。所有代码即将公开。
</details></li>
</ul>
<hr>
<h2 id="Mini-Minds-Exploring-Bebeshka-and-Zlata-Baby-Models"><a href="#Mini-Minds-Exploring-Bebeshka-and-Zlata-Baby-Models" class="headerlink" title="Mini Minds: Exploring Bebeshka and Zlata Baby Models"></a>Mini Minds: Exploring Bebeshka and Zlata Baby Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03216">http://arxiv.org/abs/2311.03216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/upunaprosk/small-language-models">https://github.com/upunaprosk/small-language-models</a></li>
<li>paper_authors: Irina Proskurina, Guillaume Metzler, Julien Velcin<br>for:This paper describes the University of Lyon 2 submission to the Strict-Small track of the BabyLM competition, which focuses on small-scale language modeling from scratch on limited data.methods:The authors use an architecture search to minimize masked language modeling loss on the shared task data, and introduce two small-size language models (LMs) with a 4-layer encoder and 8 attention heads, and a 6-layer decoder with 12 heads.results:Despite being half the scale of the baseline LMs, the proposed models achieve comparable performance, and the authors explore the applicability of small-scale language models in tasks involving moral judgment, showing the potential of compact LMs in practical language understanding tasks.Here is the result in Simplified Chinese text:for: 这篇论文描述了里昂大学2分部对Strict-Small track的BabyLM比赛提交。这个比赛强调从头来语言模型化，使用有限数据和人类语言学习。methods: 作者们使用架构搜索，以最小化masked语言模型损失，并提出了两个小型语言模型（LMs），即4层编码器和8个注意头，以及6层解码器模型和12个注意头。results:  despite being half the scale of the baseline LMs, the proposed models achieve comparable performance, and the authors explore the applicability of small-scale language models in tasks involving moral judgment, showing the potential of compact LMs in practical language understanding tasks。<details>
<summary>Abstract</summary>
In this paper, we describe the University of Lyon 2 submission to the Strict-Small track of the BabyLM competition. The shared task is created with an emphasis on small-scale language modelling from scratch on limited-size data and human language acquisition. Dataset released for the Strict-Small track has 10M words, which is comparable to children's vocabulary size. We approach the task with an architecture search, minimizing masked language modelling loss on the data of the shared task. Having found an optimal configuration, we introduce two small-size language models (LMs) that were submitted for evaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder model with 12 heads which we term Bebeshka and Zlata, respectively. Despite being half the scale of the baseline LMs, our proposed models achieve comparable performance. We further explore the applicability of small-scale language models in tasks involving moral judgment, aligning their predictions with human values. These findings highlight the potential of compact LMs in addressing practical language understanding tasks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们描述了吕隆二学院在Strict-Small赛道上的提交。这个共同任务强调从头来学习小规模语言模型，使用有限的数据和人类语言学习。共同任务上发布的数据集有1000万个单词，与儿童词汇相当。我们使用架构搜索，在共同任务上的数据上减小遮盲语言模型损失。发现优化配置后，我们介绍了两个小型语言模型（LM），即Bebeshka和Zlata。这两个模型具有4层Encoder和6层Decoder，具有8个注意头和12个注意头。尽管这两个模型的规模只是基线LM的一半，但它们在性能上具有相似的表现。我们进一步探讨小型语言模型在道德评价任务中的适用性，并对其预测与人类价值观 align。这些发现表明小型语言模型在实际语言理解任务中具有潜在的应用前景。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-Labeling-for-Domain-Agnostic-Bangla-Automatic-Speech-Recognition"><a href="#Pseudo-Labeling-for-Domain-Agnostic-Bangla-Automatic-Speech-Recognition" class="headerlink" title="Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition"></a>Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03196">http://arxiv.org/abs/2311.03196</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR">https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR</a></li>
<li>paper_authors: Rabindra Nath Nandi, Mehadi Hasan Menon, Tareq Al Muntasir, Sagor Sarker, Quazi Sarwar Muhtaseem, Md. Tariqul Islam, Shammur Absar Chowdhury, Firoj Alam</li>
<li>For: The paper aims to develop a large-scale domain-agnostic automatic speech recognition (ASR) dataset for low-resource languages, specifically Bangla.* Methods: The proposed methodology uses pseudo-labeling to develop a 20k+ hours labeled Bangla speech dataset covering diverse topics, speaking styles, dialects, noisy environments, and conversational scenarios.* Results: The trained ASR model demonstrates efficacy on a human-annotated domain-agnostic test set composed of news, telephony, and conversational data, as well as publicly available Bangla datasets.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 本研究旨在开发低资源语言自动听写系统（ASR）大规模领域独立语言数据集，具体来说是 Bangla。</li>
<li>methods: 提议方法使用 pseudo-labeling 方法开发了 20k+ 小时 Bangla 语音数据集，覆盖多样的话题、说法风格、方言、噪音环境和对话场景。</li>
<li>results: 训练的 ASR 模型在人工标注的领域独立测试集上（包括新闻、电话和对话数据等）以及公共可用 Bangla 数据集上显示了效果。<details>
<summary>Abstract</summary>
One of the major challenges for developing automatic speech recognition (ASR) for low-resource languages is the limited access to labeled data with domain-specific variations. In this study, we propose a pseudo-labeling approach to develop a large-scale domain-agnostic ASR dataset. With the proposed methodology, we developed a 20k+ hours labeled Bangla speech dataset covering diverse topics, speaking styles, dialects, noisy environments, and conversational scenarios. We then exploited the developed corpus to design a conformer-based ASR system. We benchmarked the trained ASR with publicly available datasets and compared it with other available models. To investigate the efficacy, we designed and developed a human-annotated domain-agnostic test set composed of news, telephony, and conversational data among others. Our results demonstrate the efficacy of the model trained on psuedo-label data for the designed test-set along with publicly-available Bangla datasets. The experimental resources will be publicly available.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)
</details>
<details>
<summary>摘要</summary>
一个主要挑战在开发低资源语言自动语音识别（ASR）系统是获取域特定变化的标注数据的限制。在这项研究中，我们提出了一种假标注方法，以开发大规模域无关ASR数据集。我们使用该方法开发了20000多小时的标注的孟加拉语音频数据，包括多种话题、说话风格、方言、噪音环境和对话场景。然后，我们利用开发的数据集设计了一种基于配对器的ASR系统。我们对培izia的ASR系统进行了评估，并与其他可用模型进行了比较。为了评估效果，我们设计了和其他人注释的域无关测试集，包括新闻、电话和对话数据等。我们的结果表明，使用假标注数据来训练ASR系统对于我们设计的测试集以及公共可用的孟加拉语言数据集具有效果。我们将实验资源公开发布。
</details></li>
</ul>
<hr>
<h2 id="Nexus-at-ArAIEval-Shared-Task-Fine-Tuning-Arabic-Language-Models-for-Propaganda-and-Disinformation-Detection"><a href="#Nexus-at-ArAIEval-Shared-Task-Fine-Tuning-Arabic-Language-Models-for-Propaganda-and-Disinformation-Detection" class="headerlink" title="Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection"></a>Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03184">http://arxiv.org/abs/2311.03184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunze Xiao, Firoj Alam</li>
<li>for: 本研究旨在探讨自媒体内容中的假信息和宣传内容的自动识别问题，以便提高社会和谐和公众信息准确性。</li>
<li>methods: 我们使用了微软研究院提供的ArAIEval共同任务，并在报告1A和2A两个子任务中提交了系统。我们的实验方法包括微调变换器模型和零或几个shot学习。</li>
<li>results: 我们的系统在报告1A和2A两个子任务中分别获得了第9名和第10名的成绩。<details>
<summary>Abstract</summary>
The spread of disinformation and propagandistic content poses a threat to societal harmony, undermining informed decision-making and trust in reliable sources. Online platforms often serve as breeding grounds for such content, and malicious actors exploit the vulnerabilities of audiences to shape public opinion. Although there have been research efforts aimed at the automatic identification of disinformation and propaganda in social media content, there remain challenges in terms of performance. The ArAIEval shared task aims to further research on these particular issues within the context of the Arabic language. In this paper, we discuss our participation in these shared tasks. We competed in subtasks 1A and 2A, where our submitted system secured positions 9th and 10th, respectively. Our experiments consist of fine-tuning transformer models and using zero- and few-shot learning with GPT-4.
</details>
<details>
<summary>摘要</summary>
社会和谐受到假信息和宣传内容的威胁，这会损害人们做出了有知识的决策和信任可靠的来源。在线平台常成为这种内容的温床，恶意行为者会利用观众的漏洞来形成公众意见。虽然有研究尝试自动识别社交媒体上的假信息和宣传，但还有许多挑战。阿拉伯语言的ArAIEval共享任务想要进一步研究这些问题。本文介绍我们在这个任务中的参与。我们参加了1A和2A两个子任务，我们提交的系统在这两个子任务中分别获得了第九名和第十名。我们的实验包括对 transformer 模型进行细化和使用零和几 shot 学习，并使用 GPT-4。
</details></li>
</ul>
<hr>
<h2 id="ArAIEval-Shared-Task-Persuasion-Techniques-and-Disinformation-Detection-in-Arabic-Text"><a href="#ArAIEval-Shared-Task-Persuasion-Techniques-and-Disinformation-Detection-in-Arabic-Text" class="headerlink" title="ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text"></a>ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03179">http://arxiv.org/abs/2311.03179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maram Hasanain, Firoj Alam, Hamdy Mubarak, Samir Abdaljalil, Wajdi Zaghouani, Preslav Nakov, Giovanni Da San Martino, Abed Alhakim Freihat</li>
<li>for: 本研究的目的是提供一个 arabic 文本分析的评估任务，以探索在 tweets 和新闻文章中使用诱导技巧的应用。</li>
<li>methods: 本研究使用了 transformer 模型，例如 AraBERT，进行 fine-tuning，以提高模型的性能。</li>
<li>results: 本研究获得了20队参赛队伍的最终评估结果，包括14队参赛 Task 1，和16队参赛 Task 2。<details>
<summary>Abstract</summary>
We present an overview of the ArAIEval shared task, organized as part of the first ArabicNLP 2023 conference co-located with EMNLP 2023. ArAIEval offers two tasks over Arabic text: (i) persuasion technique detection, focusing on identifying persuasion techniques in tweets and news articles, and (ii) disinformation detection in binary and multiclass setups over tweets. A total of 20 teams participated in the final evaluation phase, with 14 and 16 teams participating in Tasks 1 and 2, respectively. Across both tasks, we observed that fine-tuning transformer models such as AraBERT was at the core of the majority of the participating systems. We provide a description of the task setup, including a description of the dataset construction and the evaluation setup. We further give a brief overview of the participating systems. All datasets and evaluation scripts from the shared task are released to the research community. (https://araieval.gitlab.io/) We hope this will enable further research on these important tasks in Arabic.
</details>
<details>
<summary>摘要</summary>
我们提供了阿拉伯语自然语言处理（ArAIEval）共享任务的概述，这是2023年第一届阿拉伯语言处理会议（ArabicNLP 2023）的一部分，并与EMNLP 2023共同举办。ArAIEval提供了两个任务，它们是：（i）发现挑台技巧，即在推文和新闻文章中发现挑台技巧，以及（ii）对推文进行谎言检测。共20个队伍参加了最终评估阶段，其中14个队伍参加了任务1，16个队伍参加了任务2。在两个任务之间，我们发现大多数参与系统都是使用transformer模型进行精度调整，如AraBERT。我们提供了任务设置的描述，包括数据集构建和评估设置的描述，以及参与系统的简要概述。此外，我们还发布了所有数据集和评估脚本给研究社区。我们希望这将促进阿拉伯语言处理领域的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait"><a href="#1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait" class="headerlink" title="1D-Convolutional transformer for Parkinson disease diagnosis from gait"></a>1D-Convolutional transformer for Parkinson disease diagnosis from gait</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03177">http://arxiv.org/abs/2311.03177</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait">https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait</a></li>
<li>paper_authors: Safwen Naimi, Wassim Bouachir, Guillaume-Alexandre Bilodeau</li>
<li>for:  Parkinson’s disease diagnosis from gait data</li>
<li>methods:  Hybrid ConvNet-Transformer architecture, exploiting strengths of both models to extract local features and capture long-term spatio-temporal dependencies</li>
<li>results: 88% accuracy, outperforming other state-of-the-art AI methods on the Physionet gait dataset, and can be generalized for other classification problems in 1D signals.Here’s the simplified Chinese text:</li>
<li>for:  Parkinson病诊断从步态数据</li>
<li>methods:  Hybrid ConvNet-Transformer架构，利用两种模型的优点来抽取本地特征和捕捉长期空间时间关系</li>
<li>results: 88%准确率，超过其他状态时的AI方法在Physionet步态数据集上，并可泛化应用于其他一维信号的分类问题。<details>
<summary>Abstract</summary>
This paper presents an efficient deep neural network model for diagnosing Parkinson's disease from gait. More specifically, we introduce a hybrid ConvNet-Transformer architecture to accurately diagnose the disease by detecting the severity stage. The proposed architecture exploits the strengths of both Convolutional Neural Networks and Transformers in a single end-to-end model, where the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data. In this manner, our hybrid architecture achieves an improved performance compared to using either models individually. Our experimental results show that our approach is effective for detecting the different stages of Parkinson's disease from gait data, with a final accuracy of 88%, outperforming other state-of-the-art AI methods on the Physionet gait dataset. Moreover, our method can be generalized and adapted for other classification problems to jointly address the feature relevance and spatio-temporal dependency problems in 1D signals. Our source code and pre-trained models are publicly available at https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Findings-of-the-WMT-2023-Shared-Task-on-Discourse-Level-Literary-Translation-A-Fresh-Orb-in-the-Cosmos-of-LLMs"><a href="#Findings-of-the-WMT-2023-Shared-Task-on-Discourse-Level-Literary-Translation-A-Fresh-Orb-in-the-Cosmos-of-LLMs" class="headerlink" title="Findings of the WMT 2023 Shared Task on Discourse-Level Literary Translation: A Fresh Orb in the Cosmos of LLMs"></a>Findings of the WMT 2023 Shared Task on Discourse-Level Literary Translation: A Fresh Orb in the Cosmos of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03127">http://arxiv.org/abs/2311.03127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longyue Wang, Zhaopeng Tu, Yan Gu, Siyou Liu, Dian Yu, Qingsong Ma, Chenyang Lyu, Liting Zhou, Chao-Hong Liu, Yufeng Ma, Weiyu Chen, Yvette Graham, Bonnie Webber, Philipp Koehn, Andy Way, Yulin Yuan, Shuming Shi</li>
<li>for: 这个研究旨在提高机器翻译器的Literary Translation能力。</li>
<li>methods: 该研究使用了一个新的Literary Translation任务，并采用了人工和自动评价方法来评估提交的系统性能。</li>
<li>results: 研究发现了一些有趣的Literary和Discourse-aware MT发现，并公布了数据、系统输出和排名在<a target="_blank" rel="noopener" href="http://www2.statmt.org/wmt23/literary-translation-task.html%E3%80%82">http://www2.statmt.org/wmt23/literary-translation-task.html。</a><details>
<summary>Abstract</summary>
Translating literary works has perennially stood as an elusive dream in machine translation (MT), a journey steeped in intricate challenges. To foster progress in this domain, we hold a new shared task at WMT 2023, the first edition of the Discourse-Level Literary Translation. First, we (Tencent AI Lab and China Literature Ltd.) release a copyrighted and document-level Chinese-English web novel corpus. Furthermore, we put forth an industry-endorsed criteria to guide human evaluation process. This year, we totally received 14 submissions from 7 academia and industry teams. We employ both automatic and human evaluations to measure the performance of the submitted systems. The official ranking of the systems is based on the overall human judgments. In addition, our extensive analysis reveals a series of interesting findings on literary and discourse-aware MT. We release data, system outputs, and leaderboard at http://www2.statmt.org/wmt23/literary-translation-task.html.
</details>
<details>
<summary>摘要</summary>
machine translation (MT) 的文学翻译总是一个逃避不了的梦，一个充满复杂的挑战的旅程。为了促进这个领域的进步，我们在WMT 2023上启动了一个新的共同任务，称为文学级别翻译。首先，我们（天地智能实验室和中国文学有限公司）发布了一个版权保护的、中英文网络小说集。此外，我们提出了行业认可的评价标准，以导引人工评价过程。本年，我们总共收到了14个来自7个学术和产业团队的提交。我们使用自动和人工评价来评价提交的系统表现。人工评价的官方排名是基于总体人工评价结果。此外，我们的广泛分析发现了一系列有趣的文学和话语翻译相关的发现。我们在http://www2.statmt.org/wmt23/literary-translation-task.html上发布了数据、系统输出和排名。
</details></li>
</ul>
<hr>
<h2 id="Pelvic-floor-MRI-segmentation-based-on-semi-supervised-deep-learning"><a href="#Pelvic-floor-MRI-segmentation-based-on-semi-supervised-deep-learning" class="headerlink" title="Pelvic floor MRI segmentation based on semi-supervised deep learning"></a>Pelvic floor MRI segmentation based on semi-supervised deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03105">http://arxiv.org/abs/2311.03105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianwei Zuo, Fei Feng, Zhuhui Wang, James A. Ashton-Miller, John O. L. Delancey, Jiajia Luo</li>
<li>for: 这个研究的目的是提高pelvic floor organs的semantic segmentation和三维重建的精度。</li>
<li>methods: 这个方法使用了深度学习的自我监督预训和阶层对应。在第一阶段，它使用了图像修复任务进行自我监督预训。然后，使用标注数据进行精确的对应。在第二阶段，自我监督预训模型被用来生成pseudo标签。最后，使用标注和pseudo标签进行半supervised训练。</li>
<li>results: 这个方法可以对pelvic floor organs的semantic segmentation和三维重建进行大幅提高。试料中的Dice公式可以提高2.65%的平均值，特别是难以分类的器官，如uterus，可以提高3.70%的精度。<details>
<summary>Abstract</summary>
The semantic segmentation of pelvic organs via MRI has important clinical significance. Recently, deep learning-enabled semantic segmentation has facilitated the three-dimensional geometric reconstruction of pelvic floor organs, providing clinicians with accurate and intuitive diagnostic results. However, the task of labeling pelvic floor MRI segmentation, typically performed by clinicians, is labor-intensive and costly, leading to a scarcity of labels. Insufficient segmentation labels limit the precise segmentation and reconstruction of pelvic floor organs. To address these issues, we propose a semi-supervised framework for pelvic organ segmentation. The implementation of this framework comprises two stages. In the first stage, it performs self-supervised pre-training using image restoration tasks. Subsequently, fine-tuning of the self-supervised model is performed, using labeled data to train the segmentation model. In the second stage, the self-supervised segmentation model is used to generate pseudo labels for unlabeled data. Ultimately, both labeled and unlabeled data are utilized in semi-supervised training. Upon evaluation, our method significantly enhances the performance in the semantic segmentation and geometric reconstruction of pelvic organs, Dice coefficient can increase by 2.65% averagely. Especially for organs that are difficult to segment, such as the uterus, the accuracy of semantic segmentation can be improved by up to 3.70%.
</details>
<details>
<summary>摘要</summary>
pelvic organs的semantic segmentation via MRI具有重要的临床意义。近期，深度学习支持的semantic segmentation技术已经实现了三维 геометрическую重建pelvic floor organs，为临床医生提供了准确和直观的诊断结果。然而，pelvic floor MRI segmentation的标注，通常由临床医生进行，是劳动密集和成本高昂的，导致标注的缺乏。不充分的标注限制了精准的segmentation和重建pelvic floor organs。为解决这些问题，我们提出了一种半supervised框架 дляpelvic organ segmentation。实施这个框架包括两个阶段。在第一阶段，它通过图像恢复任务进行自我超vised预训练。然后，使用标注数据来训练分 segmentation模型的精度调整。在第二阶段，自我超vised segmentation模型被用来生成 pseudo labels для无标注数据。最终，两者都被用于半supervised训练。经评估，我们的方法可以明显提高pelvic organs的semantic segmentation和三维重建性能，Dice指数平均提高2.65%。特别是难以分 segment的器官，如uterus，semantic segmentation的准确率可以提高到3.70%。
</details></li>
</ul>
<hr>
<h2 id="A-Simple-yet-Efficient-Ensemble-Approach-for-AI-generated-Text-Detection"><a href="#A-Simple-yet-Efficient-Ensemble-Approach-for-AI-generated-Text-Detection" class="headerlink" title="A Simple yet Efficient Ensemble Approach for AI-generated Text Detection"></a>A Simple yet Efficient Ensemble Approach for AI-generated Text Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03084">http://arxiv.org/abs/2311.03084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harika Abburi, Kalyani Roy, Michael Suesserman, Nirmala Pudota, Balaji Veeramani, Edward Bowen, Sanmitra Bhattacharya</li>
<li>for: 本研究旨在提出一种简单 yet efficient的解决方案，用于分辨人工生成的文本和人类写作的文本。</li>
<li>methods: 本研究使用了多个基于Transformer的大型语言模型（LLMs）的 ensemble 方法，并对其进行了Condensed Ensembling 的改进。</li>
<li>results: 对四个基准数据集进行了实验，并证明了与之前的状态理论方法相比，本研究的方法可以获得0.5-100%的性能提升。此外，研究还表明可以通过使用不同的开源语言模型生成的数据来代替商业Restrictive GPT 数据，从而提高模型性能。<details>
<summary>Abstract</summary>
Recent Large Language Models (LLMs) have demonstrated remarkable capabilities in generating text that closely resembles human writing across wide range of styles and genres. However, such capabilities are prone to potential abuse, such as fake news generation, spam email creation, and misuse in academic assignments. Hence, it is essential to build automated approaches capable of distinguishing between artificially generated text and human-authored text. In this paper, we propose a simple yet efficient solution to this problem by ensembling predictions from multiple constituent LLMs. Compared to previous state-of-the-art approaches, which are perplexity-based or uses ensembles with a number of LLMs, our condensed ensembling approach uses only two constituent LLMs to achieve comparable performance. Experiments conducted on four benchmark datasets for generative text classification show performance improvements in the range of 0.5 to 100\% compared to previous state-of-the-art approaches. We also study the influence the training data from individual LLMs have on model performance. We found that substituting commercially-restrictive Generative Pre-trained Transformer (GPT) data with data generated from other open language models such as Falcon, Large Language Model Meta AI (LLaMA2), and Mosaic Pretrained Transformers (MPT) is a feasible alternative when developing generative text detectors. Furthermore, to demonstrate zero-shot generalization, we experimented with an English essays dataset, and results suggest that our ensembling approach can handle new data effectively.
</details>
<details>
<summary>摘要</summary>
现代大型语言模型（LLM）已经展示了人工生成文本的各种风格和类型的很好的模仿能力。然而，这些能力也容易被滥用，如生成假新闻、垃圾邮件和学术作业中的违规使用。因此，建立自动化的人工生成文本识别方法是非常重要的。在这篇论文中，我们提出了一种简单 yet efficient的解决方案，即将多个组成部件LLM的预测 ensemble。与前一代方法相比，我们的压缩ensemble方法只需使用两个组成部件LLM，却可以 дости得相同的性能。在四个基准数据集上进行的生成文本分类实验中，我们得到了0.5%到100%的性能提升，相比前一代方法。我们还研究了各个LLM的训练数据对模型性能的影响。我们发现可以将商业限制的Generative Pre-trained Transformer（GPT）数据取代为其他开源语言模型生成的数据，如Falcon、Large Language Model Meta AI（LLaMA2）和Mosaic Pretrained Transformers（MPT）。此外，我们还进行了零shot泛化的实验，结果表明我们的ensemble方法可以对新数据进行有效的处理。
</details></li>
</ul>
<hr>
<h2 id="SugarViT-–-Multi-objective-Regression-of-UAV-Images-with-Vision-Transformers-and-Deep-Label-Distribution-Learning-Demonstrated-on-Disease-Severity-Prediction-in-Sugar-Beet"><a href="#SugarViT-–-Multi-objective-Regression-of-UAV-Images-with-Vision-Transformers-and-Deep-Label-Distribution-Learning-Demonstrated-on-Disease-Severity-Prediction-in-Sugar-Beet" class="headerlink" title="SugarViT – Multi-objective Regression of UAV Images with Vision Transformers and Deep Label Distribution Learning Demonstrated on Disease Severity Prediction in Sugar Beet"></a>SugarViT – Multi-objective Regression of UAV Images with Vision Transformers and Deep Label Distribution Learning Demonstrated on Disease Severity Prediction in Sugar Beet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03076">http://arxiv.org/abs/2311.03076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maurice Günder, Facundo Ramón Ispizua Yamati, Abel Andree Barreta Alcántara, Anne-Katrin Mahlein, Rafet Sifa, Christian Bauckhage</li>
<li>for: 这个研究的目的是开发一种自动化大规模植物特征标注机制，用于粘膜融合病（CLS）严重度评估在块根中。</li>
<li>methods: 该研究使用了深度标签分布学习（DLDL）、特殊的损失函数和定制的模型架构，开发了一种基于视觉转换器的疾病严重度评估模型called SugarViT。</li>
<li>results: 研究表明，将遥感数据和实验室环境参数结合使用可以提高疾病严重度预测的准确性。该模型可以应用于多种图像基于的分类和回归任务，甚至可以学习多目标问题。<details>
<summary>Abstract</summary>
Remote sensing and artificial intelligence are pivotal technologies of precision agriculture nowadays. The efficient retrieval of large-scale field imagery combined with machine learning techniques shows success in various tasks like phenotyping, weeding, cropping, and disease control. This work will introduce a machine learning framework for automatized large-scale plant-specific trait annotation for the use case disease severity scoring for Cercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label Distribution Learning (DLDL), special loss functions, and a tailored model architecture, we develop an efficient Vision Transformer based model for disease severity scoring called SugarViT. One novelty in this work is the combination of remote sensing data with environmental parameters of the experimental sites for disease severity prediction. Although the model is evaluated on this special use case, it is held as generic as possible to also be applicable to various image-based classification and regression tasks. With our framework, it is even possible to learn models on multi-objective problems as we show by a pretraining on environmental metadata.
</details>
<details>
<summary>摘要</summary>
现代准精准农业技术中，远程感知和人工智能是非常重要的。大规模场景图像的高效回收，结合机器学习技术，在不同任务中均显示出成功，如现象识别、杂草控制、耕作和病虫控制。本文将介绍一种基于机器学习的自动化大规模植物特征注释框架，用于 sugar beet 的 Cercospora Leaf Spot（CLS）疾病严重度评估。我们采用了 Deep Label Distribution Learning（DLDL）、特殊的损失函数和定制的模型体系，开发了一种高效的视Transformer 模型，称为 SugarViT。我们的创新在于结合远程感知数据和试验站的环境参数来预测疾病严重度。尽管该模型仅应用于这个特定的应用场景，但它是通用的，可以应用于多种图像基于的类型和回归任务。我们的框架还可以学习多目标问题，我们通过在环境元数据上进行预训练来证明这一点。
</details></li>
</ul>
<hr>
<h2 id="Maximal-Consistent-Subsystems-of-Max-T-Fuzzy-Relational-Equations"><a href="#Maximal-Consistent-Subsystems-of-Max-T-Fuzzy-Relational-Equations" class="headerlink" title="Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations"></a>Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03059">http://arxiv.org/abs/2311.03059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ismaïl Baaj</li>
<li>for: 本文研究了一种系统 $\max-T$ 不确定关系方程 $A \Box_{T}^{\max} x &#x3D; b$, 其中 $T$ 是一个 $t-$整见 norm 中的 $\min$ 或者 Lukasiewicz 的 $t-$整见 norm。</li>
<li>methods: 本文使用了一种直接构造一个 canonical 最大一致子系统 (w.r.t. 包含顺序) 的方法，其基于一个分析式公式，计算不一致 $\max-T$ 系统中的 Chebyshev 距离 $\Delta &#x3D; \inf_{c \in \mathcal{C} \Vert b - c \Vert$，其中 $\mathcal{C}$ 是一个定义同 $A$ 矩阵的一致系统中的第二个成员。</li>
<li>results: 本文给出了一种有效的方法，用于从一个不一致 $\max-\min$ 系统中获取所有一致子系统，并证明了可以逐步地获取所有最大一致子系统。<details>
<summary>Abstract</summary>
In this article, we study the inconsistency of a system of $\max-T$ fuzzy relational equations of the form $A \Box_{T}^{\max} x = b$, where $T$ is a t-norm among $\min$, the product or Lukasiewicz's t-norm. For an inconsistent $\max-T$ system, we directly construct a canonical maximal consistent subsystem (w.r.t the inclusion order). The main tool used to obtain it is the analytical formula which compute the Chebyshev distance $\Delta = \inf_{c \in \mathcal{C} \Vert b - c \Vert$ associated to the inconsistent $\max-T$ system, where $\mathcal{C}$ is the set of second members of consistent systems defined with the same matrix $A$. Based on the same analytical formula, we give, for an inconsistent $\max-\min$ system, an efficient method to obtain all its consistent subsystems, and we show how to iteratively get all its maximal consistent subsystems.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们研究了一个 $\max-T$ 非精确关系方程的不一致性，其形式为 $A \Box_{T}^{\max} x = b$，其中 $T$ 是一个 $t-$整数（包括乘法或卢卡西耶夫 $t-$整数）。对于一个不一致的 $\max-T$ 系统，我们直接构造了一个 canonical 最大一致子系统（w.r.t. 包含关系）。我们使用的主要工具是计算 Chebyshev 距离 $\Delta = \inf_{c \in \mathcal{C} \Vert b - c \Vert$，该距离相关于不一致的 $\max-T$ 系统，其中 $\mathcal{C}$ 是定义同 $A$ 矩阵的一致系统的第二成员集。在这个基础之上，我们对一个不一致的 $\max-\min$ 系统提供了一种高效的方法来获得所有一致子系统，并证明了可以逐步获得所有最大一致子系统。
</details></li>
</ul>
<hr>
<h2 id="LitSumm-Large-language-models-for-literature-summarisation-of-non-coding-RNAs"><a href="#LitSumm-Large-language-models-for-literature-summarisation-of-non-coding-RNAs" class="headerlink" title="LitSumm: Large language models for literature summarisation of non-coding RNAs"></a>LitSumm: Large language models for literature summarisation of non-coding RNAs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03056">http://arxiv.org/abs/2311.03056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Green, Carlos Ribas, Nancy Ontiveros-Palacios, Anton I. Petrov, Alex Bateman, Blake Sweeney</li>
<li>for: 这个研究旨在提高生物学文献筛选的效率，通过使用大语言模型（LLM）自动生成非编码RNA文献摘要。</li>
<li>methods: 该研究使用了一个商业LMM和一系列提示和检查来生成文献摘要。</li>
<li>results: 研究发现，通过这种方法可以自动生成高质量、准确的文献摘要，并且可以通过人工评估来验证。此外，研究还发现，自动评估方法与人工评估方法不相关。最后，研究应用了这种方法于4600多个ncRNA，并将生成的摘要公开提供给RNAcentral资源。<details>
<summary>Abstract</summary>
Motivation: Curation of literature in life sciences is a growing challenge. The continued increase in the rate of publication, coupled with the relatively fixed number of curators worldwide presents a major challenge to developers of biomedical knowledgebases. Very few knowledgebases have resources to scale to the whole relevant literature and all have to prioritise their efforts.   Results: In this work, we take a first step to alleviating the lack of curator time in RNA science by generating summaries of literature for non-coding RNAs using large language models (LLMs). We demonstrate that high-quality, factually accurate summaries with accurate references can be automatically generated from the literature using a commercial LLM and a chain of prompts and checks. Manual assessment was carried out for a subset of summaries, with the majority being rated extremely high quality. We also applied the most commonly used automated evaluation approaches, finding that they do not correlate with human assessment. Finally, we apply our tool to a selection of over 4,600 ncRNAs and make the generated summaries available via the RNAcentral resource. We conclude that automated literature summarization is feasible with the current generation of LLMs, provided careful prompting and automated checking are applied.   Availability: Code used to produce these summaries can be found here: https://github.com/RNAcentral/litscan-summarization and the dataset of contexts and summaries can be found here: https://huggingface.co/datasets/RNAcentral/litsumm-v1. Summaries are also displayed on the RNA report pages in RNAcentral (https://rnacentral.org/)
</details>
<details>
<summary>摘要</summary>
motivation: 生命科学文献筛选是一项不断增长的挑战。由于发表速度的持续增长，与全球围绕知识库的数量相比，CURATOR的数量相对固定，这对生命科学知识库的开发者而言是一个主要挑战。很少的知识库有资源来涵盖整个相关文献，所以它们都必须优化努力。results: 在这项工作中，我们采取了一种解决生命科学文献筛选不足的首要步骤，即通过大语言模型（LLM）生成ncRNA的文献摘要。我们证明了，通过商业LLM和一系列提示和检查，可以自动生成高质量、精确的文献摘要，并且人工评估表明大多数摘要具有极高质量。此外，我们还应用了常用的自动评估方法，发现它们与人工评估不相关。最后，我们使用我们的工具对超过4,600个ncRNA进行摘要，并将生成的摘要公开于RNAcentral资源上。我们 conclude that使用当代LLM自动生成文献摘要是可能的，只要仔细地提示和自动检查。availability: 用于生成这些摘要的代码可以在GitHub上找到：https://github.com/RNAcentral/litscan-summarization。我们还提供了一个包含上下文和摘要的数据集：https://huggingface.co/datasets/RNAcentral/litsumm-v1。摘要也可以在RNAcentral网站上查看（https://rnacentral.org/)。
</details></li>
</ul>
<hr>
<h2 id="Masking-Hyperspectral-Imaging-Data-with-Pretrained-Models"><a href="#Masking-Hyperspectral-Imaging-Data-with-Pretrained-Models" class="headerlink" title="Masking Hyperspectral Imaging Data with Pretrained Models"></a>Masking Hyperspectral Imaging Data with Pretrained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03053">http://arxiv.org/abs/2311.03053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elias Arbash, Andréa de Lima Ribeiro, Sam Thiele, Nina Gnann, Behnood Rasti, Margret Fuchs, Pedram Ghamisi, Richard Gloaguen</li>
<li>for: 提高干扰性数据处理性能，增强计算效率和内存需求</li>
<li>methods: 使用Segment Anything Model（SAM）和零批学习Grounding Dino对象检测器进行预先图像分割，然后应用交和排除筛选步骤</li>
<li>results: 在三个复杂应用场景中（塑料碎屑特征化、钻井检测和垃圾监测）进行了数值评估，并提供了使用的超参数In Simplified Chinese text, the information can be presented as follows:</li>
<li>for: 提高干扰性数据处理性能，增强计算效率和内存需求</li>
<li>methods: 使用Segment Anything Model（SAM）和零批学习Grounding Dino对象检测器进行预先图像分割，然后应用交和排除筛选步骤</li>
<li>results: 在三个复杂应用场景中（塑料碎屑特征化、钻井检测和垃圾监测）进行了数值评估，并提供了使用的超参数<details>
<summary>Abstract</summary>
The presence of undesired background areas associated with potential noise and unknown spectral characteristics degrades the performance of hyperspectral data processing. Masking out unwanted regions is key to addressing this issue. Processing only regions of interest yields notable improvements in terms of computational costs, required memory, and overall performance. The proposed processing pipeline encompasses two fundamental parts: regions of interest mask generation, followed by the application of hyperspectral data processing techniques solely on the newly masked hyperspectral cube. The novelty of our work lies in the methodology adopted for the preliminary image segmentation. We employ the Segment Anything Model (SAM) to extract all objects within the dataset, and subsequently refine the segments with a zero-shot Grounding Dino object detector, followed by intersection and exclusion filtering steps, without the need for fine-tuning or retraining. To illustrate the efficacy of the masking procedure, the proposed method is deployed on three challenging applications scenarios that demand accurate masking; shredded plastics characterization, drill core scanning, and litter monitoring. The numerical evaluation of the proposed masking method on the three applications is provided along with the used hyperparameters. The scripts for the method will be available at https://github.com/hifexplo/Masking.
</details>
<details>
<summary>摘要</summary>
“干扰性质数据处理中存在不要的背景领域，这些领域可能具有噪音和未知的 спектраль特征，对数据处理造成干扰。为了解决这个问题，我们需要对数据进行遮盾。仅处理区域 OF  интерес可以大大减少计算成本、需要的内存和整体性能。我们的处理管线包括两个基本部分：区域 OF  интерес遮盾生成，然后将仅遮盾的多спектル矩阵进行处理。我们的工作新的是采用的是对数据进行先验性阶段分割的方法。我们使用Segment Anything Model（SAM）提取数据集中的所有物体，然后使用零扩展的Grounding Dino物体检测器进行精确的分割，然后进行交叉和排除步骤。我们不需要进行微调或重训。为了证明遮盾程序的有效性，我们将其应用于三个具有严苛需求的应用场景：材料回收、探勘棒轴和垃圾监控。我们提供了这些应用场景中的数据处理效果，以及使用的参数。我们将方法的脚本公开在https://github.com/hifexplo/Masking上。”
</details></li>
</ul>
<hr>
<h2 id="Grouping-Local-Process-Models"><a href="#Grouping-Local-Process-Models" class="headerlink" title="Grouping Local Process Models"></a>Grouping Local Process Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03040">http://arxiv.org/abs/2311.03040</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Viki Peeva, Wil M. P. van der Aalst</li>
<li>for: 这篇论文旨在提出一种三步管道，用于组合类似的本地过程模型（LPM）。</li>
<li>methods: 该论文使用了多种过程模型相似度度量，来 grouping 类似的 LPM。</li>
<li>results: 研究人员通过实际案例研究，发现 grouping 可以减少模型爆炸和重复现象，提高过程分析效果。<details>
<summary>Abstract</summary>
In recent years, process mining emerged as a proven technology to analyze and improve operational processes. An expanding range of organizations using process mining in their daily operation brings a broader spectrum of processes to be analyzed. Some of these processes are highly unstructured, making it difficult for traditional process discovery approaches to discover a start-to-end model describing the entire process. Therefore, the subdiscipline of Local Process Model (LPM) discovery tries to build a set of LPMs, i.e., smaller models that explain sub-behaviors of the process. However, like other pattern mining approaches, LPM discovery algorithms also face the problems of model explosion and model repetition, i.e., the algorithms may create hundreds if not thousands of models, and subsets of them are close in structure or behavior. This work proposes a three-step pipeline for grouping similar LPMs using various process model similarity measures. We demonstrate the usefulness of grouping through a real-life case study, and analyze the impact of different measures, the gravity of repetition in the discovered LPMs, and how it improves after grouping on multiple real event logs.
</details>
<details>
<summary>摘要</summary>
To address this issue, this work proposes a three-step pipeline for grouping similar LPMs using various process model similarity measures. We demonstrate the usefulness of grouping through a real-life case study and analyze the impact of different measures, the gravity of repetition in the discovered LPMs, and how it improves after grouping on multiple real event logs.Here is the translation in Simplified Chinese:近年来，过程挖掘技术得到证明，可以用来分析和改进操作过程。随着更多组织在日常操作中使用过程挖掘，需要分析的过程范围也在扩大。一些这些过程是高度不结构化的，使得传统的过程发现方法难以找到开始到结束的模型，因此本分支技术叫Local Process Model（LPM）发现。不过，如其他模式挖掘方法一样，LPM发现算法也面临着模型爆炸和模型重复的问题，即算法可能生成数百个或更多的模型，其中一些是结构或行为方面相似的。为了解决这个问题，本工作提出了一个三步管道，用于将相似的LPM分组使用不同的过程模型相似度度量。我们通过实际的案例研究证明了分组的有用性，并分析了不同度量的影响、发现LPM中重复的gravity度量，以及在多个真实事件日志上进行分组后对模型的改进。
</details></li>
</ul>
<hr>
<h2 id="GTP-ViT-Efficient-Vision-Transformers-via-Graph-based-Token-Propagation"><a href="#GTP-ViT-Efficient-Vision-Transformers-via-Graph-based-Token-Propagation" class="headerlink" title="GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation"></a>GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03035">http://arxiv.org/abs/2311.03035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuwei Xu, Sen Wang, Yudong Chen, Yanping Zheng, Zhewei Wei, Jiajun Liu</li>
<li>for: 该 paper 的目的是提高资源受限的设备上的 ViT 的部署，以提高计算效率。</li>
<li>methods: 该 paper 使用了 Token Pruning 和 Token Merging 等方法来减少计算量，但这些方法仍有一些局限性，如图像信息损失和tokento-matching过程的不效率。该 paper 提出了一种基于图的 Token Propagation (GTP) 方法，以解决计算复杂性和信息损失之间的权衡。</li>
<li>results: 对于 DeiT-S 和 DeiT-B 等背景下，GTP 可以减少计算复杂性，同时保持图像信息的完整性。对于 ImageNet-1K 等 dataset，GTP 可以达到更高的执行速度，而无需进行 fine-tuning。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have revolutionized the field of computer vision, yet their deployments on resource-constrained devices remain challenging due to high computational demands. To expedite pre-trained ViTs, token pruning and token merging approaches have been developed, which aim at reducing the number of tokens involved in the computation. However, these methods still have some limitations, such as image information loss from pruned tokens and inefficiency in the token-matching process. In this paper, we introduce a novel Graph-based Token Propagation (GTP) method to resolve the challenge of balancing model efficiency and information preservation for efficient ViTs. Inspired by graph summarization algorithms, GTP meticulously propagates less significant tokens' information to spatially and semantically connected tokens that are of greater importance. Consequently, the remaining few tokens serve as a summarization of the entire token graph, allowing the method to reduce computational complexity while preserving essential information of eliminated tokens. Combined with an innovative token selection strategy, GTP can efficiently identify image tokens to be propagated. Extensive experiments have validated GTP's effectiveness, demonstrating both efficiency and performance improvements. Specifically, GTP decreases the computational complexity of both DeiT-S and DeiT-B by up to 26% with only a minimal 0.3% accuracy drop on ImageNet-1K without finetuning, and remarkably surpasses the state-of-the-art token merging method on various backbones at an even faster inference speed. The source code is available at https://github.com/Ackesnal/GTP-ViT.
</details>
<details>
<summary>摘要</summary>
计算机视觉领域内，变换瞭望（ViTs）已经革命化了计算机视觉领域，但是在有限资源的设备上部署仍然具有挑战性，因为它们的计算需求较高。为了加速预训练的 ViTs，尝试了划掉和合并Token的方法，以降低计算的数量。然而，这些方法仍有一些局限性，如图像信息的损失和匹配过程的不效率。在这篇论文中，我们介绍了一种新的图表达式传播（GTP）方法，以解决计算机视觉模型的效率和信息保留之间的平衡问题。受到图摘要算法的启发，GTP méticulously在空间和semantically相连的Token上传递了 menos significance的Token的信息。因此，剩下的一些Token可以serve为整个Token图的摘要， allowing the method to reduce computational complexity while preserving essential information of eliminated tokens。结合一种创新的Token选择策略，GTP可以有效地选择图像Token。经验 validate了GTP的有效性，显示它可以提高计算效率和性能。具体来说，GTP在DeiT-S和DeiT-B上降低了计算复杂度，并且只有0.3%的精度下降，在ImageNet-1K上不需要finetuning。此外，GTP还超越了一些state-of-the-art的Token合并方法，在不同的backbone上达到了更快的推理速度。代码可以在https://github.com/Ackesnal/GTP-ViT中找到。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Words-A-Mathematical-Framework-for-Interpreting-Large-Language-Models"><a href="#Beyond-Words-A-Mathematical-Framework-for-Interpreting-Large-Language-Models" class="headerlink" title="Beyond Words: A Mathematical Framework for Interpreting Large Language Models"></a>Beyond Words: A Mathematical Framework for Interpreting Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03033">http://arxiv.org/abs/2311.03033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javier González, Aditya V. Nori</li>
<li>For: The paper aims to provide a formal framework for understanding and improving large language models (LLMs) in order to advance the development of generative AI systems.* Methods: The paper proposes a framework called “Hex” that clarifies key terms and concepts in LLM research, and differentiates chain-of-thought reasoning from chain-of-thought prompting.* Results: The paper establishes the conditions under which chain-of-thought reasoning and chain-of-thought prompting are equivalent, and argues that the formal definitions and results provided in the paper are crucial for advancing the discussion on how to build safe, reliable, fair, and robust generative AI systems, particularly in domains like healthcare and software engineering.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇论文目标是为大语言模型（LLM）提供正式框架，以促进生成人工智能系统的发展。</li>
<li>methods: 论文提出了名为“Hex”的框架，用于清晰地描述和区分大语言模型研究中的核心概念和术语，并将链条理解与链条推导进行区分。</li>
<li>results: 论文确定了链条理解和链条推导在某些情况下是等价的，并认为提供的正式定义和结果是为建构安全、可靠、公平、可靠的生成人工智能系统提供关键的支持，特别在医疗和软件工程领域。<details>
<summary>Abstract</summary>
Large language models (LLMs) are powerful AI tools that can generate and comprehend natural language text and other complex information. However, the field lacks a mathematical framework to systematically describe, compare and improve LLMs. We propose Hex a framework that clarifies key terms and concepts in LLM research, such as hallucinations, alignment, self-verification and chain-of-thought reasoning. The Hex framework offers a precise and consistent way to characterize LLMs, identify their strengths and weaknesses, and integrate new findings. Using Hex, we differentiate chain-of-thought reasoning from chain-of-thought prompting and establish the conditions under which they are equivalent. This distinction clarifies the basic assumptions behind chain-of-thought prompting and its implications for methods that use it, such as self-verification and prompt programming.   Our goal is to provide a formal framework for LLMs that can help both researchers and practitioners explore new possibilities for generative AI. We do not claim to have a definitive solution, but rather a tool for opening up new research avenues. We argue that our formal definitions and results are crucial for advancing the discussion on how to build generative AI systems that are safe, reliable, fair and robust, especially in domains like healthcare and software engineering.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）是一种强大的人工智能工具，可以生成和理解自然语言文本以及其他复杂信息。然而，这个领域缺乏一个数学基础来系统地描述、比较和改进 LLM。我们提出了 hex 框架，该框架明确了关键术语和概念在 LLM 研究中，如幻觉、对齐、自我验证和链式思维。 hex 框架提供了精确和一致的方式来描述 LLM，确定其优点和缺点，并整合新发现。使用 hex，我们区分了链式思维和链式思维激发，并确定了它们在什么情况下是等价的。这种分化有助于解释链式思维激发的基本假设和其影响，例如自我验证和提示编程。我们的目标是为 LLM 提供一个正式的数学基础，以帮助研究人员和实践者探索新的可能性，并为生成人工智能系统提供一个安全、可靠、公平和可靠的基础。我们不宣称有终极解决方案，而是一个工具，用于开拓新的研究途径。我们认为我们的正式定义和结果是推动生成人工智能系统的发展的关键，特别在医疗和软件工程领域。
</details></li>
</ul>
<hr>
<h2 id="Visual-information-driven-model-for-crowd-simulation-using-temporal-convolutional-network"><a href="#Visual-information-driven-model-for-crowd-simulation-using-temporal-convolutional-network" class="headerlink" title="Visual-information-driven model for crowd simulation using temporal convolutional network"></a>Visual-information-driven model for crowd simulation using temporal convolutional network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02996">http://arxiv.org/abs/2311.02996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanwen Liang, Eric Wai Ming Lee</li>
<li>for: 该研究旨在提高数据驱动人群模拟模型的适应性和现实性，通过integrating visual information，包括场景几何和行人行走动态信息。</li>
<li>methods: 该模型使用radar几何-动态学方法提取视觉信息，并采用社交视觉TCN深度学习模型进行速度预测。</li>
<li>results: 在三个公共步行人动态数据集中，该模型在不同的几何场景下表现出了改善的适应性，并且与传统知识驱动模型的结果进行比较，表明该模型可以提高人群模拟的现实性。<details>
<summary>Abstract</summary>
Crowd simulations play a pivotal role in building design, influencing both user experience and public safety. While traditional knowledge-driven models have their merits, data-driven crowd simulation models promise to bring a new dimension of realism to these simulations. However, most of the existing data-driven models are designed for specific geometries, leading to poor adaptability and applicability. A promising strategy for enhancing the adaptability and realism of data-driven crowd simulation models is to incorporate visual information, including the scenario geometry and pedestrian locomotion. Consequently, this paper proposes a novel visual-information-driven (VID) crowd simulation model. The VID model predicts the pedestrian velocity at the next time step based on the prior social-visual information and motion data of an individual. A radar-geometry-locomotion method is established to extract the visual information of pedestrians. Moreover, a temporal convolutional network (TCN)-based deep learning model, named social-visual TCN, is developed for velocity prediction. The VID model is tested on three public pedestrian motion datasets with distinct geometries, i.e., corridor, corner, and T-junction. Both qualitative and quantitative metrics are employed to evaluate the VID model, and the results highlight the improved adaptability of the model across all three geometric scenarios. Overall, the proposed method demonstrates effectiveness in enhancing the adaptability of data-driven crowd models.
</details>
<details>
<summary>摘要</summary>
人群模拟在建筑设计中发挥重要作用，影响用户体验和公共安全。传统知识驱动模型有其优点，但数据驱动人群模拟模型可以带来新的现实感。然而，现有的数据驱动模型大多是特定的geometry设计，导致适应性和可应用性差。为了提高数据驱动人群模拟模型的适应性和现实感，本文提出了一种视觉信息驱动（VID）人群模拟模型。VID模型预测下一步时间点人员速度基于先前的社交视觉信息和人员运动数据。通过射电几何学运动方法提取人员视觉信息。此外，基于深度学习模型（TCN）的社交视觉TCN模型是为速度预测。VID模型在三个不同的公共人员运动数据集上进行测试，包括通道、角落和T字交叉。使用质量和量度度量表评估VID模型，结果表明VID模型在三个几何场景中都有提高的适应性。总的来说，提出的方法可以提高数据驱动人群模拟模型的适应性。
</details></li>
</ul>
<hr>
<h2 id="TabRepo-A-Large-Scale-Repository-of-Tabular-Model-Evaluations-and-its-AutoML-Applications"><a href="#TabRepo-A-Large-Scale-Repository-of-Tabular-Model-Evaluations-and-its-AutoML-Applications" class="headerlink" title="TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications"></a>TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02971">http://arxiv.org/abs/2311.02971</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Salinas, Nick Erickson</li>
<li>for: 这个论文是为了提供一个新的表格模型评估和预测数据集（TabRepo）。</li>
<li>methods: 这个论文使用了1206个模型和200个回归和分类数据集来评估和预测表格模型。</li>
<li>results: 这个论文显示了TabRepo数据集的优势，可以无需考虑ensemble和参数优化，对当前AutoML系统进行比较，同时可以充分利用传输学习来超越当前表格系统的准确率、运行时间和响应时间。<details>
<summary>Abstract</summary>
We introduce TabRepo, a new dataset of tabular model evaluations and predictions. TabRepo contains the predictions and metrics of 1206 models evaluated on 200 regression and classification datasets. We illustrate the benefit of our datasets in multiple ways. First, we show that it allows to perform analysis such as comparing Hyperparameter Optimization against current AutoML systems while also considering ensembling at no cost by using precomputed model predictions. Second, we show that our dataset can be readily leveraged to perform transfer-learning. In particular, we show that applying standard transfer-learning techniques allows to outperform current state-of-the-art tabular systems in accuracy, runtime and latency.
</details>
<details>
<summary>摘要</summary>
我们介绍TabRepo，一个新的表格模型评估和预测数据集。TabRepo包含1206个模型在200个条件数据集上的预测和度量。我们显示了我们的数据集的优点，包括可以免费使用预 computed模型预测来比较搜寻过程优化和现有的自动化机器学习系统，以及可以轻松地进行转移学习。具体来说，我们显示了运用标准的转移学习技术可以超过现有的表格系统在精度、执行时间和延迟方面的表现。Note that "TabRepo" is a new dataset, so I translated it as "一个新的数据集" (a new dataset) rather than "一个新的表格模型" (a new tabular model) to emphasize that it's a collection of data rather than a single model. Also, I used "条件数据集" (conditional datasets) instead of "regression and classification datasets" to emphasize that the dataset contains both regression and classification tasks.
</details></li>
</ul>
<hr>
<h2 id="Retrieval-Augmented-Code-Generation-for-Universal-Information-Extraction"><a href="#Retrieval-Augmented-Code-Generation-for-Universal-Information-Extraction" class="headerlink" title="Retrieval-Augmented Code Generation for Universal Information Extraction"></a>Retrieval-Augmented Code Generation for Universal Information Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02962">http://arxiv.org/abs/2311.02962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yucan Guo, Zixuan Li, Xiaolong Jin, Yantao Liu, Yutao Zeng, Wenxuan Liu, Xiang Li, Pan Yang, Long Bai, Jiafeng Guo, Xueqi Cheng</li>
<li>for: 提高信息抽取（IE）任务的效率和准确率，使得IE任务能够更好地抽取结构化知识 из自然语言文本中。</li>
<li>methods: 利用大语言模型（LLM）和代码生成技术，提出一种通用的代码生成框架 Code4UIE，可以在不同的IE任务中实现高效和准确的知识抽取。</li>
<li>results: 在五种代表性的IE任务中，Code4UIE框架通过不同的示例检索策略和受检试验例子的培育，实现了高效和准确的知识抽取，并且在九个数据集上进行了广泛的实验 validate the effectiveness of the Code4UIE framework.<details>
<summary>Abstract</summary>
Information Extraction (IE) aims to extract structural knowledge (e.g., entities, relations, events) from natural language texts, which brings challenges to existing methods due to task-specific schemas and complex text expressions. Code, as a typical kind of formalized language, is capable of describing structural knowledge under various schemas in a universal way. On the other hand, Large Language Models (LLMs) trained on both codes and texts have demonstrated powerful capabilities of transforming texts into codes, which provides a feasible solution to IE tasks. Therefore, in this paper, we propose a universal retrieval-augmented code generation framework based on LLMs, called Code4UIE, for IE tasks. Specifically, Code4UIE adopts Python classes to define task-specific schemas of various structural knowledge in a universal way. By so doing, extracting knowledge under these schemas can be transformed into generating codes that instantiate the predefined Python classes with the information in texts. To generate these codes more precisely, Code4UIE adopts the in-context learning mechanism to instruct LLMs with examples. In order to obtain appropriate examples for different tasks, Code4UIE explores several example retrieval strategies, which can retrieve examples semantically similar to the given texts. Extensive experiments on five representative IE tasks across nine datasets demonstrate the effectiveness of the Code4UIE framework.
</details>
<details>
<summary>摘要</summary>
信息提取（IE）目的是从自然语言文本中提取结构知识（例如实体、关系、事件），这会对现有方法带来挑战，因为任务特定的模式和文本表达的复杂性。代码作为一种形式化语言，可以在不同的模式下描述结构知识，并且可以通过训练大型自然语言模型（LLM）来转化文本为代码。因此，在这篇论文中，我们提出一种基于LLM的通用检索增强代码生成框架，称之为Code4UIE，用于IE任务。特别是，Code4UIE使用Python类来定义任务特定的结构知识模式，以便将文本中的信息转化为代码，并且采用在场学习机制来指导LLM。为了生成代码更加精准，Code4UIE采用了semantic retrieval机制来检索相似文本的示例。为了获得不同任务的适当示例，Code4UIE对多个示例检索策略进行了探索。经过对五种代表性IE任务的九个数据集的广泛实验，我们发现Code4UIE框架具有效果。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Learning-for-Knowledge-Base-Question-Answering-for-Unmanned-Systems-based-on-Large-Language-Models"><a href="#In-Context-Learning-for-Knowledge-Base-Question-Answering-for-Unmanned-Systems-based-on-Large-Language-Models" class="headerlink" title="In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models"></a>In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02956">http://arxiv.org/abs/2311.02956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlong Chen, Yaming Zhang, Jianfei Yu, Li Yang, Rui Xia</li>
<li>for: 这个论文主要目标是提高知识库问答系统中的问答能力，以满足未来无人系统中的问答需求。</li>
<li>methods: 该论文提出了一种基于ChatGPT的Cypher Query Language（CQL）生成框架，通过预测CQL语法信息、EXTractPROPER名词、生成示例和组合多个输出来生成最佳的CQL，以提高问答精度。</li>
<li>results: 根据论文中的描述，该框架在CCKS 2023知识库问答竞赛中取得了第二名，其中F1分数为0.92676，表明该方法可以提高问答精度。<details>
<summary>Abstract</summary>
Knowledge Base Question Answering (KBQA) aims to answer factoid questions based on knowledge bases. However, generating the most appropriate knowledge base query code based on Natural Language Questions (NLQ) poses a significant challenge in KBQA. In this work, we focus on the CCKS2023 Competition of Question Answering with Knowledge Graph Inference for Unmanned Systems. Inspired by the recent success of large language models (LLMs) like ChatGPT and GPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL) generation framework to generate the most appropriate CQL based on the given NLQ. Our generative framework contains six parts: an auxiliary model predicting the syntax-related information of CQL based on the given NLQ, a proper noun matcher extracting proper nouns from the given NLQ, a demonstration example selector retrieving similar examples of the input sample, a prompt constructor designing the input template of ChatGPT, a ChatGPT-based generation model generating the CQL, and an ensemble model to obtain the final answers from diversified outputs. With our ChatGPT-based CQL generation framework, we achieved the second place in the CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems competition, achieving an F1-score of 0.92676.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Contrastive-Multi-Level-Graph-Neural-Networks-for-Session-based-Recommendation"><a href="#Contrastive-Multi-Level-Graph-Neural-Networks-for-Session-based-Recommendation" class="headerlink" title="Contrastive Multi-Level Graph Neural Networks for Session-based Recommendation"></a>Contrastive Multi-Level Graph Neural Networks for Session-based Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02938">http://arxiv.org/abs/2311.02938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuyun Wang, Xingyu Gao, Zhenyu Chen, Lei Lyu</li>
<li>for: 这个研究目的是为了提高Session-based recommendation（SBR）的精度和效能，以便更好地预测用户的下一个ITEM。</li>
<li>methods: 本研究使用了一种新的对称多层Graph Neural Networks（CM-GNN）来更好地利用session中ITEM的复杂和高阶关系信息。CM-GNN使用了本地层Graph Convolutional Network（L-GCN）和全层Network（G-GCN），以及对称层Network（H-GCN），对session中ITEM的关系进行更好地捕捉和表征。此外，CM-GNN还引入了一个注意力组合模组，以学习session中ITEM的对应关系。</li>
<li>results: 本研究的结果显示，CM-GNN可以比前者state-of-the-art SBR方法更好地预测用户的下一个ITEM。具体来说，CM-GNN在多个常用的benchmark datasets上展现出了更高的预测精度和效能。<details>
<summary>Abstract</summary>
Session-based recommendation (SBR) aims to predict the next item at a certain time point based on anonymous user behavior sequences. Existing methods typically model session representation based on simple item transition information. However, since session-based data consists of limited users' short-term interactions, modeling session representation by capturing fixed item transition information from a single dimension suffers from data sparsity. In this paper, we propose a novel contrastive multi-level graph neural networks (CM-GNN) to better exploit complex and high-order item transition information. Specifically, CM-GNN applies local-level graph convolutional network (L-GCN) and global-level network (G-GCN) on the current session and all the sessions respectively, to effectively capture pairwise relations over all the sessions by aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph convolutional network (H-GCN) to capture high-order information among all the item transitions. CM-GNN further introduces an attention-based fusion module to learn pairwise relation-based session representation by fusing the item representations generated by L-GCN and G-GCN. CM-GNN averages the item representations obtained by H-GCN to obtain high-order relation-based session representation. Moreover, to convert the high-order item transition information into the pairwise relation-based session representation, CM-GNN maximizes the mutual information between the representations derived from the fusion module and the average pool layer by contrastive learning paradigm. We conduct extensive experiments on multiple widely used benchmark datasets to validate the efficacy of the proposed method. The encouraging results demonstrate that our proposed method outperforms the state-of-the-art SBR techniques.
</details>
<details>
<summary>摘要</summary>
Session-based recommendation (SBR) targets predicting the next item at a certain time point based on anonymous user behavior sequences. Existing methods typically model session representation based on simple item transition information. However, since session-based data consists of limited users' short-term interactions, modeling session representation by capturing fixed item transition information from a single dimension suffers from data sparsity. In this paper, we propose a novel contrastive multi-level graph neural networks (CM-GNN) to better exploit complex and high-order item transition information. Specifically, CM-GNN applies local-level graph convolutional network (L-GCN) and global-level network (G-GCN) on the current session and all the sessions respectively, to effectively capture pairwise relations over all the sessions by aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph convolutional network (H-GCN) to capture high-order information among all the item transitions. CM-GNN further introduces an attention-based fusion module to learn pairwise relation-based session representation by fusing the item representations generated by L-GCN and G-GCN. CM-GNN averages the item representations obtained by H-GCN to obtain high-order relation-based session representation. Moreover, to convert the high-order item transition information into the pairwise relation-based session representation, CM-GNN maximizes the mutual information between the representations derived from the fusion module and the average pool layer by contrastive learning paradigm. We conduct extensive experiments on multiple widely used benchmark datasets to validate the efficacy of the proposed method. The encouraging results demonstrate that our proposed method outperforms the state-of-the-art SBR techniques.
</details></li>
</ul>
<hr>
<h2 id="Deep-Image-Semantic-Communication-Model-for-Artificial-Intelligent-Internet-of-Things"><a href="#Deep-Image-Semantic-Communication-Model-for-Artificial-Intelligent-Internet-of-Things" class="headerlink" title="Deep Image Semantic Communication Model for Artificial Intelligent Internet of Things"></a>Deep Image Semantic Communication Model for Artificial Intelligent Internet of Things</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02926">http://arxiv.org/abs/2311.02926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Ping Qian, Yi Zhang, Sikai Lyu, Huijie Zhu, Yuan Wu, Xuemin Sherman Shen, Xiaoniu Yang</li>
<li>for: 这篇论文是为了提出一种深度学习图像Semantic Communication模型，用于AIoT设备上的图像交换中快速和高效地传输图像数据。</li>
<li>methods: 在传输方 сторо，提出了一种高精度图像semantic Segmentation算法，用于提取图像中的semantic信息，以实现图像数据的重要压缩。在接收方 сторо，提出了一种基于GAN的semantic图像恢复算法，用于将semantic图像转换成详细的真实场景图像。</li>
<li>results: 对比WebP和CycleGAN，该图像Semantic Communication模型可以提高图像压缩比和恢复精度，平均提高71.93%和25.07%。此外，我们的demo实验表明，该模型可以将图像传输延迟降低至95.26%。<details>
<summary>Abstract</summary>
With the rapid development of Artificial Intelligent Internet of Things (AIoT), the image data from AIoT devices has been witnessing the explosive increasing. In this paper, a novel deep image semantic communication model is proposed for the efficient image communication in AIoT. Particularly, at the transmitter side, a high-precision image semantic segmentation algorithm is proposed to extract the semantic information of the image to achieve significant compression of the image data. At the receiver side, a semantic image restoration algorithm based on Generative Adversarial Network (GAN) is proposed to convert the semantic image to a real scene image with detailed information. Simulation results demonstrate that the proposed image semantic communication model can improve the image compression ratio and recovery accuracy by 71.93% and 25.07% on average in comparison with WebP and CycleGAN, respectively. More importantly, our demo experiment shows that the proposed model reduces the total delay by 95.26% in the image communication, when comparing with the original image transmission.
</details>
<details>
<summary>摘要</summary>
随着人工智能互联网物联网（AIoT）的快速发展，AIoT设备上的图像数据已经经历了激增。在本文中，我们提出了一种新的深度图像 semantic 通信模型，用于AIoT中高效的图像通信。特别是在发送器端，我们提出了一种高精度图像 semantics 分割算法，以EXTRACT图像中的semantic信息，以实现图像数据的显著压缩。在接收端，我们提出了基于生成对抗网络（GAN）的semantic图像恢复算法，将semantic图像转换为详细的真实场景图像。实验结果表明，提出的图像 semantic 通信模型可以提高图像压缩率和恢复精度，比WebP和CycleGAN相比，提高71.93%和25.07%的平均值。此外，我们的 demo 实验表明，我们的模型可以将图像传输减少95.26%，相比原始图像传输。
</details></li>
</ul>
<hr>
<h2 id="Virtual-Action-Actor-Critic-Framework-for-Exploration-Student-Abstract"><a href="#Virtual-Action-Actor-Critic-Framework-for-Exploration-Student-Abstract" class="headerlink" title="Virtual Action Actor-Critic Framework for Exploration (Student Abstract)"></a>Virtual Action Actor-Critic Framework for Exploration (Student Abstract)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02916">http://arxiv.org/abs/2311.02916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bumgeun Park, Taeyoung Kim, Quoc-Vinh Lai-Dang, Dongsoo Har</li>
<li>for: 提高RL中代理人的寻索效率</li>
<li>methods: 提出了一种新的actor-critic框架，即虚拟动作actor-critic（VAAC），以模仿人类对未来行为的想像能力。</li>
<li>results: 实验结果表明，VAAC可以提高寻索性能，比既有算法更高。<details>
<summary>Abstract</summary>
Efficient exploration for an agent is challenging in reinforcement learning (RL). In this paper, a novel actor-critic framework namely virtual action actor-critic (VAAC), is proposed to address the challenge of efficient exploration in RL. This work is inspired by humans' ability to imagine the potential outcomes of their actions without actually taking them. In order to emulate this ability, VAAC introduces a new actor called virtual actor (VA), alongside the conventional actor-critic framework. Unlike the conventional actor, the VA takes the virtual action to anticipate the next state without interacting with the environment. With the virtual policy following a Gaussian distribution, the VA is trained to maximize the anticipated novelty of the subsequent state resulting from a virtual action. If any next state resulting from available actions does not exhibit high anticipated novelty, training the VA leads to an increase in the virtual policy entropy. Hence, high virtual policy entropy represents that there is no room for exploration. The proposed VAAC aims to maximize a modified Q function, which combines cumulative rewards and the negative sum of virtual policy entropy. Experimental results show that the VAAC improves the exploration performance compared to existing algorithms.
</details>
<details>
<summary>摘要</summary>
RL中的办法探索有挑战，这篇论文提出了一种新的actor-critic框架，即虚拟行为actor-critic（VAAC）。这种方法是基于人类可以通过想象来预测行动结果而不需要实际行动的能力。为了模拟这种能力，VAAC增加了一个虚拟actor（VA），该actor在不与环境交互的情况下预测下一个状态。虚拟政策采用高维度 Gaussian 分布，VA 是通过最大化预期下一个状态的新鲜度来训练的。如果可用的行动中任何一个下一个状态不具备高预期新鲜度，则训练VA会导致虚拟政策熵增加。因此，高虚拟政策熵表示没有探索空间。VAAC的目标是最大化修改后的Q函数，该函数将折衔奖励和虚拟政策熵相加。实验结果表明，VAAC在探索性能方面比现有算法更好。
</details></li>
</ul>
<hr>
<h2 id="Imitation-Learning-based-Alternative-Multi-Agent-Proximal-Policy-Optimization-for-Well-Formed-Swarm-Oriented-Pursuit-Avoidance"><a href="#Imitation-Learning-based-Alternative-Multi-Agent-Proximal-Policy-Optimization-for-Well-Formed-Swarm-Oriented-Pursuit-Avoidance" class="headerlink" title="Imitation Learning based Alternative Multi-Agent Proximal Policy Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance"></a>Imitation Learning based Alternative Multi-Agent Proximal Policy Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02912">http://arxiv.org/abs/2311.02912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sizhao Li, Yuming Xiang, Rongpeng Li, Zhifeng Zhao, Honggang Zhang</li>
<li>for: 本研究旨在提出一种分布式学习基于启发式多智能体减少策略优化（IA-MAPPO）算法，以提供弹性和通信成本低的解决方案来执行追逐避免任务在具有良好结构的群体中。</li>
<li>methods: 本研究使用了政策热传播（MAPPO）执行器，并通过启发式学习减少通信开销和提高扩展性。为了减少通信开销，本研究还使用了形态控制器的启发式学习。</li>
<li>results:  simulation results validate the effectiveness of IA-MAPPO, and extensive ablation experiments show that the performance is comparable to a centralized solution with significant decrease in communication overheads.<details>
<summary>Abstract</summary>
Multi-Robot System (MRS) has garnered widespread research interest and fostered tremendous interesting applications, especially in cooperative control fields. Yet little light has been shed on the compound ability of formation, monitoring and defence in decentralized large-scale MRS for pursuit avoidance, which puts stringent requirements on the capability of coordination and adaptability. In this paper, we put forward a decentralized Imitation learning based Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm to provide a flexible and communication-economic solution to execute the pursuit avoidance task in well-formed swarm. In particular, a policy-distillation based MAPPO executor is firstly devised to capably accomplish and swiftly switch between multiple formations in a centralized manner. Furthermore, we utilize imitation learning to decentralize the formation controller, so as to reduce the communication overheads and enhance the scalability. Afterwards, alternative training is leveraged to compensate the performance loss incurred by decentralization. The simulation results validate the effectiveness of IA-MAPPO and extensive ablation experiments further show the performance comparable to a centralized solution with significant decrease in communication overheads.
</details>
<details>
<summary>摘要</summary>
具体来说，我们首先开发了一个基于专业训练的 MAPPO 执行器，以实现多形成的快速调整和执行。然后，我们使用循环学习将形成控制器分散化，以减少通信开销和提高可扩展性。最后，我们利用对替训练来补偿由分散化带来的性能损失。 simulation 结果证明了 IA-MAPPO 的有效性，而且实际实现了对中央化解决方案的有效性优化，并且实现了重要的通信开销优化。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Empowered-Semantic-Communication-Systems-with-a-Shared-Knowledge-Base"><a href="#Deep-Learning-Empowered-Semantic-Communication-Systems-with-a-Shared-Knowledge-Base" class="headerlink" title="Deep Learning-Empowered Semantic Communication Systems with a Shared Knowledge Base"></a>Deep Learning-Empowered Semantic Communication Systems with a Shared Knowledge Base</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02884">http://arxiv.org/abs/2311.02884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Yi, Yang Cao, Xin Kang, Ying-Chang Liang</li>
<li>for: 这则论文旨在提出一个基于深度学习的semantic communication系统，以提高未来6G网络的无线通信效率。</li>
<li>methods: 本文提出了一个 Shared Knowledge Base（SKB）基于的semantic communication系统，其中包含了可读性高的句子集，并通过与讯息相关的知识融合，以获得更少的符号资料传输。</li>
<li>results:  simulation results demonstrate that the proposed approach outperforms existing baseline methods in terms of transmitted data size and sentence similarity.<details>
<summary>Abstract</summary>
Deep learning-empowered semantic communication is regarded as a promising candidate for future 6G networks. Although existing semantic communication systems have achieved superior performance compared to traditional methods, the end-to-end architecture adopted by most semantic communication systems is regarded as a black box, leading to the lack of explainability. To tackle this issue, in this paper, a novel semantic communication system with a shared knowledge base is proposed for text transmissions. Specifically, a textual knowledge base constructed by inherently readable sentences is introduced into our system. With the aid of the shared knowledge base, the proposed system integrates the message and corresponding knowledge from the shared knowledge base to obtain the residual information, which enables the system to transmit fewer symbols without semantic performance degradation. In order to make the proposed system more reliable, the semantic self-information and the source entropy are mathematically defined based on the knowledge base. Furthermore, the knowledge base construction algorithm is developed based on a similarity-comparison method, in which a pre-configured threshold can be leveraged to control the size of the knowledge base. Moreover, the simulation results have demonstrated that the proposed approach outperforms existing baseline methods in terms of transmitted data size and sentence similarity.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:深度学习 empowered  semantics 通信被视为未来 6G 网络的优秀候选人。虽然现有的 semantics 通信系统已经比传统方法表现出色，但大多数 semantics 通信系统采用的端到端架构被视为黑盒子，导致解释性不足。为解决这个问题，本文提出了一种基于文本传输的 semantics 通信系统，具有共享知识库。具体来说，我们引入了一个基于自然可读的文本知识库，并将该知识库与系统集成，以获取剩余信息，从而使系统可以在符号数量不减少的情况下传输文本。为使提案更加可靠，我们定义了基于知识库的 semantics 自信息和源 entropy。此外，我们还开发了基于相似比较方法的知识库构建算法，可以通过配置阈值来控制知识库的大小。最后，我们通过实验结果表明，提案方法在数据大小和句子相似性方面都超过了基eline 方法。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Shift-–-Multi-Objective-Loss-Function-for-Improved-Anomaly-Fall-Detection"><a href="#Temporal-Shift-–-Multi-Objective-Loss-Function-for-Improved-Anomaly-Fall-Detection" class="headerlink" title="Temporal Shift – Multi-Objective Loss Function for Improved Anomaly Fall Detection"></a>Temporal Shift – Multi-Objective Loss Function for Improved Anomaly Fall Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02863">http://arxiv.org/abs/2311.02863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Denkovski, Shehroz S. Khan, Alex Mihailidis<br>for:这个研究是为了提高家庭环境中的跌倒探测精度，以减少老年人受伤和死亡的机会。methods:本研究使用了自适应网络和其变体，以及一新的多目标损失函数Temporal Shift，来进行跌倒探测。results:试验结果显示，使用Temporal Shift多目标损失函数可以优化自适应网络和多模式神经网络的表现，尤其是对于单一摄像头的情况下。相比于重建 alone，这种方法可以提高了0.20 AUC ROC的表现。<details>
<summary>Abstract</summary>
Falls are a major cause of injuries and deaths among older adults worldwide. Accurate fall detection can help reduce potential injuries and additional health complications. Different types of video modalities can be used in a home setting to detect falls, including RGB, Infrared, and Thermal cameras. Anomaly detection frameworks using autoencoders and their variants can be used for fall detection due to the data imbalance that arises from the rarity and diversity of falls. However, the use of reconstruction error in autoencoders can limit the application of networks' structures that propagate information. In this paper, we propose a new multi-objective loss function called Temporal Shift, which aims to predict both future and reconstructed frames within a window of sequential frames. The proposed loss function is evaluated on a semi-naturalistic fall detection dataset containing multiple camera modalities. The autoencoders were trained on normal activities of daily living (ADL) performed by older adults and tested on ADLs and falls performed by young adults. Temporal shift shows significant improvement to a baseline 3D Convolutional autoencoder, an attention U-Net CAE, and a multi-modal neural network. The greatest improvement was observed in an attention U-Net model improving by 0.20 AUC ROC for a single camera when compared to reconstruction alone. With significant improvement across different models, this approach has the potential to be widely adopted and improve anomaly detection capabilities in other settings besides fall detection.
</details>
<details>
<summary>摘要</summary>
falls是老年人全球主要的伤害和死亡原因之一。准确的落坠检测可以帮助降低可能的伤害和额外的健康问题。家庭环境中可以使用RGB、Infrared和热成像摄像头来检测落坠。使用自编器和其变种的异常检测框架可以用于落坠检测，因为落坠的数据偏好和多样性导致了数据不均衡。在这篇论文中，我们提出了一种新的多目标损失函数 called Temporal Shift，用于预测uture和重建的帧内一个窗口中的序列帧。我们的提案的损失函数在一个半自然的落坠检测数据集上进行了评估，该数据集包含了多种摄像头模式。我们使用了正常的生活活动（ADL）来训练自编器，并测试了ADL和落坠的 younger adults 表现。Temporal Shift显示在不同的模型中具有显著改进，特别是在注意力U-Net CAE模型中，其在单个摄像头上提高了0.20 AUC ROC。与不同的模型进行比较，这种方法在不同的设置中都具有广泛的应用前景，可能为其他异常检测场景提供改进。
</details></li>
</ul>
<hr>
<h2 id="Co-training-and-Co-distillation-for-Quality-Improvement-and-Compression-of-Language-Models"><a href="#Co-training-and-Co-distillation-for-Quality-Improvement-and-Compression-of-Language-Models" class="headerlink" title="Co-training and Co-distillation for Quality Improvement and Compression of Language Models"></a>Co-training and Co-distillation for Quality Improvement and Compression of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02849">http://arxiv.org/abs/2311.02849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hayeon Lee, Rui Hou, Jongpil Kim, Davis Liang, Hongbo Zhang, Sung Ju Hwang, Alexander Min</li>
<li>for: 压缩计算昂贵的预训练语言模型（PLMs），以便在资源受限或实时设置中使用。</li>
<li>methods: 提议使用协同培训和共同干扰（CTCD）框架，以同时改进性能和执行速度。</li>
<li>results: CTCD框架成功实现了性能和执行速度的同时改进，并且可以与现有技术相结合，如建筑设计或数据增强，以达到更高的性能改进。小型模型通过CTCD的干扰得到的性能超过了原始大型模型的性能。<details>
<summary>Abstract</summary>
Knowledge Distillation (KD) compresses computationally expensive pre-trained language models (PLMs) by transferring their knowledge to smaller models, allowing their use in resource-constrained or real-time settings. However, most smaller models fail to surpass the performance of the original larger model, resulting in sacrificing performance to improve inference speed. To address this issue, we propose Co-Training and Co-Distillation (CTCD), a novel framework that improves performance and inference speed together by co-training two models while mutually distilling knowledge. The CTCD framework successfully achieves this based on two significant findings: 1) Distilling knowledge from the smaller model to the larger model during co-training improves the performance of the larger model. 2) The enhanced performance of the larger model further boosts the performance of the smaller model. The CTCD framework shows promise as it can be combined with existing techniques like architecture design or data augmentation, replacing one-way KD methods, to achieve further performance improvement. Extensive ablation studies demonstrate the effectiveness of CTCD, and the small model distilled by CTCD outperforms the original larger model by a significant margin of 1.66 on the GLUE benchmark.
</details>
<details>
<summary>摘要</summary>
知识塑化（KD）可以压缩需要大量计算训练的预训练语言模型（PLM），以便在资源有限或实时设置下使用。然而，大多数更小的模型无法超越原始大型模型的性能，导致牺牲性能以提高推理速度。为解决这个问题，我们提出了协同训练和协同预测（CTCD）框架，它可以同时提高性能和推理速度。CTCD框架基于以下两点发现：1. 在协同训练期间，往返知识的预测模型可以提高大型模型的性能。2. 大型模型的提高性能可以进一步提高小型模型的性能。CTCD框架展示了其可以与现有的技术相结合，如建筑设计或数据增强，取代一向KD方法，以实现更高的性能改进。广泛的折衣研究表明CTCD的效果，并且使用CTCD折衣的小型模型在GLUE测试benchmark上比原始大型模型高出1.66个很大的margin。
</details></li>
</ul>
<hr>
<h2 id="Kinematic-aware-Prompting-for-Generalizable-Articulated-Object-Manipulation-with-LLMs"><a href="#Kinematic-aware-Prompting-for-Generalizable-Articulated-Object-Manipulation-with-LLMs" class="headerlink" title="Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs"></a>Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02847">http://arxiv.org/abs/2311.02847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenke Xia, Dong Wang, Xincheng Pang, Zhigang Wang, Bin Zhao, Di Hu</li>
<li>for: 本研究旨在实现智能家居 robots 上的通用运动控制，以便在不同的弹性物体上进行精确的物品搬运和处理。</li>
<li>methods: 本研究使用了 Large Language Models (LLMs) 的强大内容学习能力，并提出了一个基于物体运动结构的启发框架，将 LLMs 启发为生成低层运动轨迹点。为了有效地启发 LLMs  WITH 不同物体的运动结构，我们设计了一个统一的运动知识解析器，将不同的弹性物体表示为一个统一的文本描述，包括运动脊和触控位置。</li>
<li>results: 我们的框架在48个实验中与传统方法进行比较，结果显示我们的框架不仅在8个见到类别上表现出色，而且还在8个未见到类别上表现出强大的零例能力。实验还证明了我们的框架在实际应用中的适用性。代码可以在 \href{<a target="_blank" rel="noopener" href="https://github.com/xwinks/LLM_articulated_object_manipulation%7D%7B%E8%BF%99%E9%87%8C%7D">https://github.com/xwinks/LLM_articulated_object_manipulation}{这里}</a> 找到。<details>
<summary>Abstract</summary>
Generalizable articulated object manipulation is essential for home-assistant robots. Recent efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, however, due to the prohibitive costs of real-world data collection and precise object simulation, it still remains challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, building on the idea that the kinematic structure of the object determines how we can manipulate it, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supporting various object manipulation. To effectively prompt LLMs with the kinematic structure of different objects, we design a unified kinematic knowledge parser, which represents various articulated objects as a unified textual description containing kinematic joints and contact location. Building upon this unified description, a kinematic-aware planner model is proposed to generate precise 3D manipulation waypoints via a designed kinematic-aware chain-of-thoughts prompting method. Our evaluation spanned 48 instances across 16 distinct categories, revealing that our framework not only outperforms traditional methods on 8 seen categories but also shows a powerful zero-shot capability for 8 unseen articulated object categories. Moreover, the real-world experiments on 7 different object categories prove our framework's adaptability in practical scenarios. Code is released at \href{https://github.com/xwinks/LLM_articulated_object_manipulation}{here}.
</details>
<details>
<summary>摘要</summary>
通用化的彩绘物体控制是家庭助手机器人的重要特点。最近的努力主要集中在通过示范学习或在模拟环境中进行奖励学习，然而由于实际数据收集和精准的物体模拟成本高昂，这些工作仍然面临广泛适应性问题。近些年，许多研究尝试使用大语言模型（LLM）的强在场学习能力来实现通用的机器人控制，但大多数研究都集中在高级任务规划上，忽略了低级机器人控制。在这种情况下，我们提出了基于物体骨骼结构的动作规划框架，通过向LLM提供骨骼知识来生成低级动作规划点。为了有效地向LLM提供不同物体的骨骼结构，我们设计了一种统一的骨骼知识解析器，该解析器将各种拥有骨骼结构的物体表述为一种统一的文本描述。基于这种统一描述，我们提出了一种基于骨骼的规划模型，通过一种骨骼知识推导的链条思维法生成精确的3D manipulate方向。我们的评估包括48个实例，8种seen类和8种unseen类，结果表明我们的框架不仅在8种seen类上超越传统方法，还在0shot情况下对8种unseen类表现出强大的适应能力。此外，我们在7种实际物体类上进行了实际实验，证明了我们的框架在实际应用中的适应性。代码可以在 \href{https://github.com/xwinks/LLM_articulated_object_manipulation}{这里} 找到。
</details></li>
</ul>
<hr>
<h2 id="Saturn-Efficient-Multi-Large-Model-Deep-Learning"><a href="#Saturn-Efficient-Multi-Large-Model-Deep-Learning" class="headerlink" title="Saturn: Efficient Multi-Large-Model Deep Learning"></a>Saturn: Efficient Multi-Large-Model Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02840">http://arxiv.org/abs/2311.02840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kabir Nagrecha, Arun Kumar</li>
<li>for: 提高多大型模型训练效率 (improve the efficiency of multi-large-model training)</li>
<li>methods: 提出了三个关联系统挑战（平行技术选择、GPU分配和调度），并将其形式化为一个共同问题，然后构建了一个新的系统架构来解决这些挑战。</li>
<li>results: 对比于现有的深度学习实践，我们的联合优化方法可以降低模型选择运行时间的比例（39-49%）。<details>
<summary>Abstract</summary>
In this paper, we propose Saturn, a new data system to improve the efficiency of multi-large-model training (e.g., during model selection/hyperparameter optimization). We first identify three key interconnected systems challenges for users building large models in this setting -- parallelism technique selection, distribution of GPUs over jobs, and scheduling. We then formalize these as a joint problem, and build a new system architecture to tackle these challenges simultaneously. Our evaluations show that our joint-optimization approach yields 39-49% lower model selection runtimes than typical current DL practice.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的数据系统，用于提高多大型模型训练的效率（例如， durante 模型选择/超参数优化）。我们首先认为了多个系统挑战，包括并行技术选择、分布式 GPU 资源的分配和调度。然后我们将这些问题联系起来，并设计了一个新的系统架构来解决这些挑战。我们的评估显示，我们的联合优化方法可以降低模型选择运行时间的39-49%，相比于当前深度学习实践中的常见方法。
</details></li>
</ul>
<hr>
<h2 id="Mesh-Neural-Cellular-Automata"><a href="#Mesh-Neural-Cellular-Automata" class="headerlink" title="Mesh Neural Cellular Automata"></a>Mesh Neural Cellular Automata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02820">http://arxiv.org/abs/2311.02820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Pajouheshgar, Yitao Xu, Alexander Mordvintsev, Eyvind Niklasson, Tong Zhang, Sabine Süsstrunk</li>
<li>for: 提高虚拟环境的现实感，直接synthesize 3D纹理。</li>
<li>methods: 提出Mesh Neural Cellular Automata（MeshNCA）方法，可以在3D网格上直接synthesize 纹理，不需要UV映射。MeshNCA是一种通用的细胞自动机，可以在非格式结构上运行，如3D网格的顶点上的细胞。</li>
<li>results: 训练于icosphere网格上，MeshNCA可以具有很好的泛化性，可以在实时中synthesize 纹理，并且可以使用不同的目标进行训练，如图像、文本提示和运动向量场。此外，还提出了拓展MeshNCA实例的方法，以实现纹理 interpolate。<details>
<summary>Abstract</summary>
Modeling and synthesizing textures are essential for enhancing the realism of virtual environments. Methods that directly synthesize textures in 3D offer distinct advantages to the UV-mapping-based methods as they can create seamless textures and align more closely with the ways textures form in nature. We propose Mesh Neural Cellular Automata (MeshNCA), a method for directly synthesizing dynamic textures on 3D meshes without requiring any UV maps. MeshNCA is a generalized type of cellular automata that can operate on a set of cells arranged on a non-grid structure such as vertices of a 3D mesh. While only being trained on an Icosphere mesh, MeshNCA shows remarkable generalization and can synthesize textures on any mesh in real time after the training. Additionally, it accommodates multi-modal supervision and can be trained using different targets such as images, text prompts, and motion vector fields. Moreover, we conceptualize a way of grafting trained MeshNCA instances, enabling texture interpolation. Our MeshNCA model enables real-time 3D texture synthesis on meshes and allows several user interactions including texture density/orientation control, a grafting brush, and motion speed/direction control. Finally, we implement the forward pass of our MeshNCA model using the WebGL shading language and showcase our trained models in an online interactive demo which is accessible on personal computers and smartphones. Our demo and the high resolution version of this PDF are available at https://meshnca.github.io/.
</details>
<details>
<summary>摘要</summary>
“模拟和生成文本ures是虚拟环境中的重要Component。Directly生成文本ures in 3D 提供了与 UV 映射方法不同的明显优势，包括可预测的文本ures 和更好地跟随自然中文本ures的形成方式。我们提出了 Mesh Neural Cellular Automata (MeshNCA)，一种不需要 UV 图的方法，可以将文本ures 直接生成在 3D 网格上。MeshNCA 是一种通用的细胞自动机，可以在 3D 网格上的 vertices 上运行。仅对 Icosphere 网格进行训练，MeshNCA 显示了卓越的扩展性，可以在实时运行中生成文本ures 以任意网格。此外，我们提出了将训练好的 MeshNCA 实例串接起来的想法，以便进行文本ures 插值。我们的 MeshNCA 模型允许在网格上实时生成文本ures，并且支援多种用户互动，包括文本密度/方向控制、插值Brush、速度/方向控制。最后，我们使用 WebGL 渲染语言进行前向通过，并在个人电脑和智能手机上显示我们训练好的模型。我们的 demo 和高分辨率的 PDF 可以在 https://meshnca.github.io/ 浏览。”
</details></li>
</ul>
<hr>
<h2 id="QualEval-Qualitative-Evaluation-for-Model-Improvement"><a href="#QualEval-Qualitative-Evaluation-for-Model-Improvement" class="headerlink" title="QualEval: Qualitative Evaluation for Model Improvement"></a>QualEval: Qualitative Evaluation for Model Improvement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02807">http://arxiv.org/abs/2311.02807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vishvak Murahari, Ameet Deshpande, Peter Clark, Tanmay Rajpurohit, Ashish Sabharwal, Karthik Narasimhan, Ashwin Kalyan</li>
<li>for: 本研究旨在改善人工智能系统中的评估 metric，以便更好地评估大语言模型（LLM）的性能。</li>
<li>methods: 本研究提出了一种名为 QualEval 的自动化质量评估方法，它将量化评估 metric 与自动化质量检查相结合，以提供更加细化的模型性能评估。</li>
<li>results: 研究发现，通过 QualEval 的帮助，可以提高 Llama 2 模型在对话任务（DialogSum）上的绝对性能，比基eline高达 15% 点。此外，QualEval 还可以减少模型开发的时间和努力，因此可以视为一个数据科学家在盒子中。<details>
<summary>Abstract</summary>
Quantitative evaluation metrics have traditionally been pivotal in gauging the advancements of artificial intelligence systems, including large language models (LLMs). However, these metrics have inherent limitations. Given the intricate nature of real-world tasks, a single scalar to quantify and compare is insufficient to capture the fine-grained nuances of model behavior. Metrics serve only as a way to compare and benchmark models, and do not yield actionable diagnostics, thus making the model improvement process challenging. Model developers find themselves amid extensive manual efforts involving sifting through vast datasets and attempting hit-or-miss adjustments to training data or setups. In this work, we address the shortcomings of quantitative metrics by proposing QualEval, which augments quantitative scalar metrics with automated qualitative evaluation as a vehicle for model improvement. QualEval uses a powerful LLM reasoner and our novel flexible linear programming solver to generate human-readable insights that when applied, accelerate model improvement. The insights are backed by a comprehensive dashboard with fine-grained visualizations and human-interpretable analyses. We corroborate the faithfulness of QualEval by demonstrating that leveraging its insights, for example, improves the absolute performance of the Llama 2 model by up to 15% points relative on a challenging dialogue task (DialogSum) when compared to baselines. QualEval successfully increases the pace of model development, thus in essence serving as a data-scientist-in-a-box. Given the focus on critiquing and improving current evaluation metrics, our method serves as a refreshingly new technique for both model evaluation and improvement.
</details>
<details>
<summary>摘要</summary>
In this work, we address these shortcomings by proposing QualEval, which integrates automated qualitative evaluation with quantitative scalar metrics to facilitate model improvement. QualEval leverages a powerful LLM reasoner and our novel flexible linear programming solver to generate human-readable insights that can be applied to accelerate model improvement. These insights are supported by a comprehensive dashboard with fine-grained visualizations and human-interpretable analyses.We demonstrate the effectiveness of QualEval by showing that it can improve the absolute performance of the Llama 2 model by up to 15% points relative to baselines on a challenging dialogue task (DialogSum). This highlights the ability of QualEval to increase the pace of model development, effectively serving as a data-scientist-in-a-box. Given the focus on critiquing and improving current evaluation metrics, our method provides a refreshingly new technique for both model evaluation and improvement.
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Worker-Perspectives-into-MTurk-Annotation-Practices-for-NLP"><a href="#Incorporating-Worker-Perspectives-into-MTurk-Annotation-Practices-for-NLP" class="headerlink" title="Incorporating Worker Perspectives into MTurk Annotation Practices for NLP"></a>Incorporating Worker Perspectives into MTurk Annotation Practices for NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02802">http://arxiv.org/abs/2311.02802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olivia Huang, Eve Fleisig, Dan Klein</li>
<li>for: This paper aims to address open questions regarding best practices for fair payment, worker privacy, data quality, and considering worker incentives in natural language processing (NLP) studies on Amazon Mechanical Turk (MTurk).</li>
<li>methods: The paper conducts a critical literature review and a survey of MTurk workers to identify their preferences and concerns regarding NLP studies.</li>
<li>results: The survey finds that MTurk workers prefer reliable, reasonable payments over uncertain, very high payments; report frequently lying on demographic questions; and express frustration at having work rejected with no explanation. The paper also finds that some quality control methods, such as requiring minimum response times or Master’s qualifications, are viewed as biased and ineffective by workers. Based on the survey results, the paper provides recommendations for future NLP studies to better account for MTurk workers’ experiences and improve data quality.<details>
<summary>Abstract</summary>
Current practices regarding data collection for natural language processing on Amazon Mechanical Turk (MTurk) often rely on a combination of studies on data quality and heuristics shared among NLP researchers. However, without considering the perspectives of MTurk workers, these approaches are susceptible to issues regarding workers' rights and poor response quality. We conducted a critical literature review and a survey of MTurk workers aimed at addressing open questions regarding best practices for fair payment, worker privacy, data quality, and considering worker incentives. We found that worker preferences are often at odds with received wisdom among NLP researchers. Surveyed workers preferred reliable, reasonable payments over uncertain, very high payments; reported frequently lying on demographic questions; and expressed frustration at having work rejected with no explanation. We also found that workers view some quality control methods, such as requiring minimum response times or Master's qualifications, as biased and largely ineffective. Based on the survey results, we provide recommendations on how future NLP studies may better account for MTurk workers' experiences in order to respect workers' rights and improve data quality.
</details>
<details>
<summary>摘要</summary>
现有的MTurk数据采集做法 frequently rely on a combination of学术研究和NLP研究人员之间的经验分享。然而，不考虑MTurk工作者的视角，这些方法容易出现工作者权益问题和回答质量问题。我们进行了一项批判性文献复查和MTurk工作者调查，以解决关于最佳实践的开放问题，包括公平支付、工作者隐私、数据质量和考虑工作者奖励。我们发现工作者偏好可靠、合理的支付，而不是不确定、非常高的支付；报告经常谎报个人信息问题；表示工作被拒绝无解释而感到沮丧。我们还发现一些质控方法，如要求最小响应时间或Master的学位要求，被工作者视为偏袋并不效果。根据调查结果，我们提出了将来NLP研究可能更好地考虑MTurk工作者的经验，以尊重工作者权益并提高数据质量。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.AI_2023_11_06/" data-id="cloojsmbx007bre88812k8amj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.CL_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T11:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.CL_2023_11_06/">cs.CL - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Tackling-Concept-Shift-in-Text-Classification-using-Entailment-style-Modeling"><a href="#Tackling-Concept-Shift-in-Text-Classification-using-Entailment-style-Modeling" class="headerlink" title="Tackling Concept Shift in Text Classification using Entailment-style Modeling"></a>Tackling Concept Shift in Text Classification using Entailment-style Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03320">http://arxiv.org/abs/2311.03320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumegh Roychowdhury, Karan Gupta, Siva Rajesh Kasa, Prasanna Srinivasa Murthy, Alok Chandra</li>
<li>for: 这个论文是为了解决在自然语言处理（NLP）中的文本分类（TC）问题中，随着时间的推移，类别定义发生变化的情况。</li>
<li>methods: 该论文提出了一种将文本分类转化为推理问题的方法，使得只需要少量的新数据来重新训练文本分类器，以适应新的概念。</li>
<li>results: 该论文在实际世界数据集和 sintetic 数据集上进行了评测，并取得了约7%和40%的绝对 F1 提升，并在几次训练中实现了75%的标签成本减少。<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have seen tremendous success in text classification (TC) problems in the context of Natural Language Processing (NLP). In many real-world text classification tasks, the class definitions being learned do not remain constant but rather change with time - this is known as Concept Shift. Most techniques for handling concept shift rely on retraining the old classifiers with the newly labelled data. However, given the amount of training data required to fine-tune large DL models for the new concepts, the associated labelling costs can be prohibitively expensive and time consuming. In this work, we propose a reformulation, converting vanilla classification into an entailment-style problem that requires significantly less data to re-train the text classifier to adapt to new concepts. We demonstrate the effectiveness of our proposed method on both real world & synthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in few-shot settings. Further, upon deployment, our solution also helped save 75% of labeling costs overall.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unraveling-Downstream-Gender-Bias-from-Large-Language-Models-A-Study-on-AI-Educational-Writing-Assistance"><a href="#Unraveling-Downstream-Gender-Bias-from-Large-Language-Models-A-Study-on-AI-Educational-Writing-Assistance" class="headerlink" title="Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance"></a>Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03311">http://arxiv.org/abs/2311.03311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thiemo Wambsganss, Xiaotian Su, Vinitra Swamy, Seyed Parsa Neshaei, Roman Rietsche, Tanja Käser</li>
<li>for: 这 paper  investigate how bias transfers through an AI writing support pipeline in the context of providing writing suggestions to students.</li>
<li>methods: 这 paper 使用了大量的 user study 和多种方法来测试 AI writing support pipeline 的偏见。</li>
<li>results: 研究发现，在使用 AI writing support pipeline 时， gender bias 不会传递到学生们的回答中。这表明，使用 AI writing support 可以在教室中使用，不会因偏见而对学生们产生负面影响。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one classroom group with feature-based suggestions and four groups recruited from Prolific -- a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and Sentence Embedding Association Test (SEAT) we evaluate the gender bias at various stages of the pipeline: in model embeddings, in suggestions generated by the models, and in reviews written by students. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students' responses.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在教育任务中越来越被利用，例如为学生提供写作建议。虽然它们有潜在的潜在优势，但 LLM 也存在内置的偏见，这可能对学生有负面影响。先前的研究已经研究过模型和数据表示中的偏见，但忽略了 AI 写作支持管道中偏见的影响。本文 investigate AI 写作支持管道中偏见的传递。我们进行了大规模的学生实验，共231名德语商业案例评审学生参与了实验。学生被分为五组，每组有不同的写作支持水平：一个教室组与特定的功能基于建议，以及四个来自 Prolific 的组：一个控制组无助，两个组使用精度调整的 GPT-2 和 GPT-3 模型建议，以及一个组使用预训练 GPT-3.5 建议。我们使用 GenBit 性别偏见分析、Word Embedding Association Tests（WEAT）和 Sentence Embedding Association Test（SEAT）来评估管道中偏见的水平：模型嵌入、模型建议中的偏见和学生写作的偏见。我们的结果表明，在 LLM 建议的支持下写作的学生 peer review 中， gender 偏见并不存在显著差异。我们的研究因此optimistic about AI 写作支持的使用情况，展示了一个情况下，LLM 的偏见不会传递到学生的回答中。
</details></li>
</ul>
<hr>
<h2 id="Ziya2-Data-centric-Learning-is-All-LLMs-Need"><a href="#Ziya2-Data-centric-Learning-is-All-LLMs-Need" class="headerlink" title="Ziya2: Data-centric Learning is All LLMs Need"></a>Ziya2: Data-centric Learning is All LLMs Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03301">http://arxiv.org/abs/2311.03301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, Dixiang Zhang, Kunhao Pan, Ping Yang, Qi Yang, Jiaxing Zhang, Yan Song</li>
<li>For: The paper aims to propose a new language model (Ziya2) with 13 billion parameters and improve its performance through pre-training techniques and data-centric optimization.* Methods: The paper uses LLaMA2 as the foundation model and pre-trains Ziya2 on 700 billion tokens, with a focus on pre-training techniques and data-centric optimization.* Results: Ziya2 significantly outperforms other models in multiple benchmarks, especially when compared to representative open-source models.Here are the three key points in Simplified Chinese text:* For: 这个论文目的是提出一个新的语言模型（Ziya2），其 Parameters 为 1300亿，并通过预训练技术和数据中心优化来提高其性能。* Methods: 论文使用 LLaMA2 作为基础模型，并将 Ziya2 预训练在 7000亿 个字符上，主要关注预训练技术和数据中心优化。* Results: Ziya2 在多个 bench 上显著超过其他模型，特别是与代表性的开源模型进行比较时表现出色。<details>
<summary>Abstract</summary>
Various large language models (LLMs) have been proposed in recent years, including closed- and open-source ones, continually setting new records on multiple benchmarks. However, the development of LLMs still faces several issues, such as high cost of training models from scratch, and continual pre-training leading to catastrophic forgetting, etc. Although many such issues are addressed along the line of research on LLMs, an important yet practical limitation is that many studies overly pursue enlarging model sizes without comprehensively analyzing and optimizing the use of pre-training data in their learning process, as well as appropriate organization and leveraging of such data in training LLMs under cost-effective settings. In this work, we propose Ziya2, a model with 13 billion parameters adopting LLaMA2 as the foundation model, and further pre-trained on 700 billion tokens, where we focus on pre-training techniques and use data-centric optimization to enhance the learning process of Ziya2 on different stages. Experiments show that Ziya2 significantly outperforms other models in multiple benchmarks especially with promising results compared to representative open-source ones. Ziya2 (Base) is released at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.
</details>
<details>
<summary>摘要</summary>
各种大型语言模型（LLMs）在最近几年内已经被提出，包括关闭和开源的一些，不断创造新的纪录在多个标准测试 benchMark 上。然而，LLMs 的开发仍面临一些问题，如从零开始训练模型的高成本，以及逐渐预训练导致忘记等等。虽然这些问题在 LLamA2 的研究中得到了一定的解决，但是在实际应用中，许多研究偏重于扩大模型的大小，而忽视了预训练数据的使用和组织，以及在成本效益的情况下进行模型训练。在这项工作中，我们提出了 Ziya2，一个拥有 1300 亿参数的模型，基于 LLaMA2 基础模型，并进行了进一步的预训练，使用 700 亿个字符。我们将注重预训练技术和数据中心化优化，以提高 Ziya2 在不同阶段的学习过程。实验结果表明，Ziya2 在多个标准测试 benchMark 上显著超越其他模型，特别是与代表性的开源模型相比，显示出了极其出色的性能。Ziya2 (Base) 在 https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base 和 https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary 上发布。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Analysis-of-Hallucination-in-GPT-4V-ision-Bias-and-Interference-Challenges"><a href="#Holistic-Analysis-of-Hallucination-in-GPT-4V-ision-Bias-and-Interference-Challenges" class="headerlink" title="Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges"></a>Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03287">http://arxiv.org/abs/2311.03287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhang Cui, Yiyang Zhou, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, Huaxiu Yao</li>
<li>for: 评估 GPT-4V(ision) 模型中的偏见和干扰现象</li>
<li>methods: 利用 Bingo benchmark 评估 GPT-4V(ision) 模型的偏见和干扰问题</li>
<li>results: GPT-4V(ision) 模型存在区域偏见和干扰现象，特别是在解读西方图片或图片中包含英文文本时表现较好，而其他国家的图片或其他语言的文本时表现较差。此外，GPT-4V(ision) 模型容易受到导向问题和多个图片的混乱影响。<details>
<summary>Abstract</summary>
While GPT-4V(ision) impressively models both visual and textual information simultaneously, it's hallucination behavior has not been systematically assessed. To bridge this gap, we introduce a new benchmark, namely, the Bias and Interference Challenges in Visual Language Models (Bingo). This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models: bias and interference. Here, bias refers to the model's tendency to hallucinate certain types of responses, possibly due to imbalance in its training data. Interference pertains to scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the text prompt is phrased or how the input image is presented. We identify a notable regional bias, whereby GPT-4V(ision) is better at interpreting Western images or images with English writing compared to images from other countries or containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together. Popular mitigation approaches, such as self-correction and chain-of-thought reasoning, are not effective in resolving these challenges. We also identified similar biases and interference vulnerabilities with LLaVA and Bard. Our results characterize the hallucination challenges in GPT-4V(ision) and state-of-the-art visual-language models, and highlight the need for new solutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.
</details>
<details>
<summary>摘要</summary>
GPT-4V(ision) 模型可同时处理视觉和文本信息，但它的幻觉行为尚未系统地评估。为了bridging这个差距，我们提出了一个新的标准套件，即视觉语言模型偏见和干扰挑战（Bingo）。这个套件设计用于评估和探讨视觉语言模型中两种常见的幻觉类型：偏见和干扰。其中，偏见指的是模型幻觉某些类型的回答，可能是训练数据不均衡所致。干扰指的是场景下，GPT-4V(ision) 的判断能力受到文本提示的某些方式表述或图像的展示方式的干扰。我们发现GPT-4V(ision) 对西方图像或包含英文文本的图像具有偏见，并且容易受到提示文本的leading questions的干扰。此外，GPT-4V(ision) 在处理多个图像时也存在混乱的情况。常见的修复方法，如自我检查和链式思维，无法解决这些挑战。我们还发现了LLaVA和Bard等状态OF-the-art的视觉语言模型具有相似的偏见和干扰敏感性。我们的结果描述了GPT-4V(ision) 和状态OF-the-art的视觉语言模型中幻觉挑战，并高亮了需要新的解决方案。Bingo套件可以在https://github.com/gzcch/Bingo上下载。
</details></li>
</ul>
<hr>
<h2 id="Safurai-Csharp-Harnessing-Synthetic-Data-to-improve-language-specific-Code-LLM"><a href="#Safurai-Csharp-Harnessing-Synthetic-Data-to-improve-language-specific-Code-LLM" class="headerlink" title="Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM"></a>Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03243">http://arxiv.org/abs/2311.03243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Cifarelli, Leonardo Boiardi, Alessandro Puppo, Leon Jovanovic</li>
<li>for: 这 paper 是为了开发一个专门用于生成、完成和调试 C# 代码的开源模型。</li>
<li>methods: 该模型基于 CodeLlama 34B 模型，并利用了 EvolInstruct 技术进行精细化和扩展数据集，以便进行细化的 Fine-tuning 过程。</li>
<li>results: 该模型在 Manual MultiPL-E benchmark 上表现出色，得分为 56.33% (Zero-Shot, Pass@1)，表明它具有很高的开发人员工作流程优化和代码学习帮助的能力。<details>
<summary>Abstract</summary>
This paper introduces Safurai-Csharp, an open-source model designed to specialize in the generation, completion, and debugging of C# code. Safurai-Csharp is built upon the novel CodeLlama 34B model and leverages the EvolInstruct technique, creating a refined and expanded dataset for its fine-tuning process. The results of its performance, a notable score of 56.33% on the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity to streamline developers' workflows and aid code learning. It shows promise in setting new stakes in the landscape of open-source C# LLMs and hopes to inspire more inclusive and wide-ranging development in the field of language-specific LLMs.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Safurai-Csharp" is translated as "Saifulai-C#" (各 Fulai-C#), where "Saifulai" is a combination of "Safurai" (各) and "C#" (C#).* "CodeLlama 34B" is translated as "代码 llama 34B" (代码 llama 34B), where "代码 llama" (代码 llama) is a combination of "code" (代码) and "llama" ( llama), and "34B" is added to indicate the version number.* "EvolInstruct" is translated as "演进指导" (evolution guidance), where "演进" (evolution) and "指导" (guidance) are combined to indicate the process of evolving and guiding the model.* "Manual MultiPL-E benchmark" is translated as "手动多PL-E指标" (manual multi-PL-E benchmark), where "手动" (manual) and "多PL-E" (multi-PL-E) are combined to indicate the manual process of evaluating the model's performance on multiple tasks.* "Zero-Shot, Pass@1" is translated as "零枪指标@1" (zero-shot indicator@1), where "零枪" (zero-shot) and "指标@1" (indicator@1) are combined to indicate the model's performance on unseen tasks.
</details></li>
</ul>
<hr>
<h2 id="p-Laplacian-Transformer"><a href="#p-Laplacian-Transformer" class="headerlink" title="p-Laplacian Transformer"></a>p-Laplacian Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03235">http://arxiv.org/abs/2311.03235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Nguyen, Tam Nguyen, Vinh Nguyen, Tan M. Nguyen</li>
<li>for: 这个论文主要是为了提出一种基于图和图像信号处理的新的自注意机制，以及一种基于-$p$ Laplacian regularization的Transformer架构。</li>
<li>methods: 该论文使用了自注意机制，并在自注意层中引入-$p$ Laplacian regularization来控制稀疏性和缓和效果。</li>
<li>results: 论文通过实验表明，使用$p$-Laplacian Transformer（p-LaT）可以在各种 benchmark datasets 上提高表现，并且可以更好地处理不同距离的token之间的关系。<details>
<summary>Abstract</summary>
$p$-Laplacian regularization, rooted in graph and image signal processing, introduces a parameter $p$ to control the regularization effect on these data. Smaller values of $p$ promote sparsity and interpretability, while larger values encourage smoother solutions. In this paper, we first show that the self-attention mechanism obtains the minimal Laplacian regularization ($p=2$) and encourages the smoothness in the architecture. However, the smoothness is not suitable for the heterophilic structure of self-attention in transformers where attention weights between tokens that are in close proximity and non-close ones are assigned indistinguishably. From that insight, we then propose a novel class of transformers, namely the $p$-Laplacian Transformer (p-LaT), which leverages $p$-Laplacian regularization framework to harness the heterophilic features within self-attention layers. In particular, low $p$ values will effectively assign higher attention weights to tokens that are in close proximity to the current token being processed. We empirically demonstrate the advantages of p-LaT over the baseline transformers on a wide range of benchmark datasets.
</details>
<details>
<summary>摘要</summary>
$p$- Laplacian REGULARIZATION，基于图像和图像信号处理，引入一个参数 $p$ 来控制这些数据的REGULARIZATION效果。小于 $p$ 的值推动简洁性和可读性，而大于 $p$ 的值激励更平滑的解决方案。在这篇论文中，我们首先表明了自注意机制可以获得最小 Laplacian REGULARIZATION ($p=2$)，并且激励了 Architecture 中的平滑性。然而，这种平滑性不适合 transformers 中的自注意机制，因为自注意机制中的注意量在 tokens 之间的距离和非距离之间被赋予无法分辨的权重。从这一点出发，我们then propose a novel class of transformers，即 $p$-Laplacian Transformer (p-LaT)，该框架利用 $p$-Laplacian REGULARIZATION框架来利用 transformers 中的自注意机制中的异质特征。具体来说，小于 $p$ 的值会将更高的注意量赋予 tokens 和当前被处理的token之间的close proximity。我们经验性地证明了 p-LaT 对基eline transformers 的优势在各种 benchmark 数据集上。
</details></li>
</ul>
<hr>
<h2 id="Model-based-Counterfactual-Generator-for-Gender-Bias-Mitigation"><a href="#Model-based-Counterfactual-Generator-for-Gender-Bias-Mitigation" class="headerlink" title="Model-based Counterfactual Generator for Gender Bias Mitigation"></a>Model-based Counterfactual Generator for Gender Bias Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03186">http://arxiv.org/abs/2311.03186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ewoenam Kwaku Tokpo, Toon Calders</li>
<li>for:  mitigating gender bias in natural language models</li>
<li>methods:  combination of data processing techniques and bi-objective training regime</li>
<li>results:  alleviates the shortcomings of dictionary-based solutions and improves the mitigation of gender bias<details>
<summary>Abstract</summary>
Counterfactual Data Augmentation (CDA) has been one of the preferred techniques for mitigating gender bias in natural language models. CDA techniques have mostly employed word substitution based on dictionaries. Although such dictionary-based CDA techniques have been shown to significantly improve the mitigation of gender bias, in this paper, we highlight some limitations of such dictionary-based counterfactual data augmentation techniques, such as susceptibility to ungrammatical compositions, and lack of generalization outside the set of predefined dictionary words. Model-based solutions can alleviate these problems, yet the lack of qualitative parallel training data hinders development in this direction. Therefore, we propose a combination of data processing techniques and a bi-objective training regime to develop a model-based solution for generating counterfactuals to mitigate gender bias. We implemented our proposed solution and performed an empirical evaluation which shows how our model alleviates the shortcomings of dictionary-based solutions.
</details>
<details>
<summary>摘要</summary>
<SYS>Translate the following text into Simplified Chinese:</SYS> counterfactual data augmentation (CDA) 是一种常用的技术来减轻自然语言模型中的性别偏见。 CDA 技术主要使用词替换，基于词典。 although such dictionary-based CDA techniques have been shown to significantly improve the mitigation of gender bias, in this paper, we highlight some limitations of such dictionary-based counterfactual data augmentation techniques, such as susceptibility to ungrammatical compositions, and lack of generalization outside the set of predefined dictionary words. model-based solutions can alleviate these problems, yet the lack of qualitative parallel training data hinders development in this direction. therefore, we propose a combination of data processing techniques and a bi-objective training regime to develop a model-based solution for generating counterfactuals to mitigate gender bias. we implemented our proposed solution and performed an empirical evaluation which shows how our model alleviates the shortcomings of dictionary-based solutions.Translation: counterfactual data augmentation (CDA) 是一种常用的技术来减轻自然语言模型中的性别偏见。 CDA 技术主要使用词替换，基于词典。 although such dictionary-based CDA techniques have been shown to significantly improve the mitigation of gender bias, in this paper, we highlight some limitations of such dictionary-based counterfactual data augmentation techniques, such as susceptibility to ungrammatical compositions, and lack of generalization outside the set of predefined dictionary words. 模型基本解决方案可以解决这些问题，但是缺乏质量平行训练数据限制了发展。 therefore, we propose a combination of data processing techniques and a bi-objective training regime to develop a model-based solution for generating counterfactuals to mitigate gender bias. 我们实现了我们的提议解决方案，并进行了 empirical evaluation，表明我们的模型可以解决 Dictionary-based 的缺点。
</details></li>
</ul>
<hr>
<h2 id="Architectural-Sweet-Spots-for-Modeling-Human-Label-Variation-by-the-Example-of-Argument-Quality-It’s-Best-to-Relate-Perspectives"><a href="#Architectural-Sweet-Spots-for-Modeling-Human-Label-Variation-by-the-Example-of-Argument-Quality-It’s-Best-to-Relate-Perspectives" class="headerlink" title="Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It’s Best to Relate Perspectives!"></a>Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It’s Best to Relate Perspectives!</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03153">http://arxiv.org/abs/2311.03153</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/phhei/RelatePerspectives-sweetspots">https://github.com/phhei/RelatePerspectives-sweetspots</a></li>
<li>paper_authors: Philipp Heinisch, Matthias Orlikowski, Julia Romberg, Philipp Cimiano</li>
<li>for: 本研究旨在探讨自然语言处理中多个注解者之间的关系如何影响注解质量。</li>
<li>methods: 研究使用了一种从推荐系统中启发的建议方法，包括模型注解者之间的关系以提高单个注解者的标签预测精度。</li>
<li>results: 研究发现，使用建议方法可以提高单个注解者的标签预测精度，最高提高$43%$。这表明，关注个体注解者的视角可以提高Subjectivity的方法。<details>
<summary>Abstract</summary>
Many annotation tasks in natural language processing are highly subjective in that there can be different valid and justified perspectives on what is a proper label for a given example. This also applies to the judgment of argument quality, where the assignment of a single ground truth is often questionable. At the same time, there are generally accepted concepts behind argumentation that form a common ground. To best represent the interplay of individual and shared perspectives, we consider a continuum of approaches ranging from models that fully aggregate perspectives into a majority label to "share nothing"-architectures in which each annotator is considered in isolation from all other annotators. In between these extremes, inspired by models used in the field of recommender systems, we investigate the extent to which architectures that include layers to model the relations between different annotators are beneficial for predicting single-annotator labels. By means of two tasks of argument quality classification (argument concreteness and validity/novelty of conclusions), we show that recommender architectures increase the averaged annotator-individual F$_1$-scores up to $43\%$ over a majority label model. Our findings indicate that approaches to subjectivity can benefit from relating individual perspectives.
</details>
<details>
<summary>摘要</summary>
In between these extremes, inspired by models used in the field of recommender systems, we investigate the extent to which architectures that include layers to model the relations between different annotators are beneficial for predicting single-annotator labels. By means of two tasks of argument quality classification (argument concreteness and validity/novelty of conclusions), we show that recommender architectures increase the averaged annotator-individual F$_1$-scores up to 43% over a majority label model. Our findings indicate that approaches to subjectivity can benefit from relating individual perspectives.Translation notes:* "Many annotation tasks" is translated as "多个标注任务" (duō gè bāng xiǎng yì xiǎng)* "natural language processing" is translated as "自然语言处理" (zì rán yǔ yán jí)* "subjective" is translated as "主观的" (zhǔ qiǎo de)* "perspectives" is translated as "视点" (shì diǎn)* "common ground" is translated as "共同基础" (gòng dòng jī chū)* "approaches" is translated as "方法" (fāng fá)* "ranging from" is translated as "从..." (cong...）* "share nothing" is translated as "没有共享" (méi yǒu gòng jiāo)* "individual F$_1$-scores" is translated as "个人 F$_1$-分数" (个人 F$_1$-分数)* "recommender architectures" is translated as "推荐建模" (tuī yù jiàn mó)* "increase" is translated as "提高" (tí gāo)* "averaged annotator-individual F$_1$-scores" is translated as "平均个人 F$_1$-分数" (píng jūn gòng rén F$_1$-分数)* "benefit from" is translated as "得益于" (de yǐ yú)* "approaches to subjectivity" is translated as "对主观的方法" (duì zhǔ qiǎo de fāng fá)
</details></li>
</ul>
<hr>
<h2 id="Injecting-Categorical-Labels-and-Syntactic-Information-into-Biomedical-NER"><a href="#Injecting-Categorical-Labels-and-Syntactic-Information-into-Biomedical-NER" class="headerlink" title="Injecting Categorical Labels and Syntactic Information into Biomedical NER"></a>Injecting Categorical Labels and Syntactic Information into Biomedical NER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03113">http://arxiv.org/abs/2311.03113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumam Francis, Marie-Francine Moens</li>
<li>for: 提高生物医学Named EntityRecognition(NER)的精度</li>
<li>methods: 使用分类器模型和BERT模型，并将分类标签和语法信息注入到NER模型中</li>
<li>results: 对三个 benchmark dataset进行实验，结果显示将分类标签和语法信息注入到NER模型中可以提高精度，并且超过基elineBERT模型的性能<details>
<summary>Abstract</summary>
We present a simple approach to improve biomedical named entity recognition (NER) by injecting categorical labels and Part-of-speech (POS) information into the model. We use two approaches, in the first approach, we first train a sequence-level classifier to classify the sentences into categories to obtain the sentence-level tags (categorical labels). The sequence classifier is modeled as an entailment problem by modifying the labels as a natural language template. This helps to improve the accuracy of the classifier. Further, this label information is injected into the NER model. In this paper, we demonstrate effective ways to represent and inject these labels and POS attributes into the NER model. In the second approach, we jointly learn the categorical labels and NER labels. Here we also inject the POS tags into the model to increase the syntactic context of the model. Experiments on three benchmark datasets show that incorporating categorical label information with syntactic context is quite useful and outperforms baseline BERT-based models.
</details>
<details>
<summary>摘要</summary>
我们提出了一种简单的方法来改进生物医学命名实体识别（NER），并将分类标签和语法信息注入到模型中。我们采用两种方法：第一种方法是首先训练一个序列级分类器，以将句子分类为类别获得句子级标签（分类标签）。这个序列分类器是通过修改标签为自然语言模板来实现的，这有助于提高分类器的准确率。此外，这些标签信息还被注入到NER模型中。在这篇论文中，我们展示了如何有效地表示和注入这些标签和语法信息到NER模型中。第二种方法是同时学习分类标签和NER标签。在这里，我们还将POS标签注入到模型中，以增加语法上下文。实验表明，将分类标签和语法信息注入到BERT基于模型中可以提高NER模型的性能，并超过基eline模型。
</details></li>
</ul>
<hr>
<h2 id="Language-Models-are-Super-Mario-Absorbing-Abilities-from-Homologous-Models-as-a-Free-Lunch"><a href="#Language-Models-are-Super-Mario-Absorbing-Abilities-from-Homologous-Models-as-a-Free-Lunch" class="headerlink" title="Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch"></a>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03099">http://arxiv.org/abs/2311.03099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li</li>
<li>for: 这个论文目的是探索语言模型（LM）可以通过吸收同类模型参数而获得新的能力，无需重新训练或GPU。</li>
<li>methods: 这个论文使用的方法包括超级vised Fine-Tuning（SFT）和Drop And REscale（DARE）操作来简化 delta 参数，以便将多个任务特定的 LM 合并成一个多能力模型。</li>
<li>results: 实验结果表明，DARE 可以快速地减少 delta 参数的大部分，但是继续预训练后 delta 参数的范围可以增大到约 0.03，使 DARE 无法实施。此外， merged 多个任务特定的 LM 可以创造出更高的性能。<details>
<summary>Abstract</summary>
In this paper, we uncover that Language Models (LMs), either encoder- or decoder-based, can obtain new capabilities by assimilating the parameters of homologous models without retraining or GPUs. Typically, new abilities of LMs can be imparted by Supervised Fine-Tuning (SFT), reflected in the disparity between fine-tuned and pre-trained parameters (i.e., delta parameters). We initially observe that by introducing a novel operation called DARE (Drop And REscale), most delta parameters can be directly set to zeros without affecting the capabilities of SFT LMs and larger models can tolerate a higher proportion of discarded parameters. Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging. We conduct experiments on eight datasets from the GLUE benchmark with BERT and RoBERTa. We also merge WizardLM, WizardMath, and Code Alpaca based on Llama 2. Experimental results show that: (1) The delta parameter value ranges for SFT models are typically small, often within 0.005, and DARE can eliminate 99% of them effortlessly. However, once the models are continuously pre-trained, the value ranges can grow to around 0.03, making DARE impractical. We have also tried to remove fine-tuned instead of delta parameters and find that a 10% reduction can lead to drastically decreased performance (even to 0). This highlights that SFT merely stimulates the abilities via delta parameters rather than injecting new abilities into LMs; (2) DARE can merge multiple task-specific LMs into one LM with diverse abilities. For instance, the merger of WizardLM and WizardMath improves the GSM8K zero-shot accuracy of WizardLM from 2.2 to 66.3, retaining its instruction-following ability while surpassing WizardMath's original 64.2 performance. Codes are available at https://github.com/yule-BUAA/MergeLM.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们发现了一种新的方法，即将语言模型（LM）的参数吸收到同类模型的参数中，无需重新训练或GPU。通常，LM可以通过监督精细调整（SFT）获得新的能力，而这种能力差异可以通过 delta 参数来表示。我们发现，通过一种新的操作 called DARE（Drop And REscale），大多数 delta 参数可以直接设置为零，而不会影响 SFT LM 的能力。基于这个发现，我们进一步减轻 delta 参数的多个 SFT 同类模型，并将它们合并成一个单独的模型。我们在 GLUE  bencmark 上进行了八个数据集的实验，并将 WizardLM、WizardMath 和 Code Alpaca 基于 Llama 2 进行了合并。实验结果表明：（1）SFT 模型的 delta 参数范围通常在 0.005 之间，DARE 可以轻松地消除 99% 的 delta 参数。然而，一旦模型进行了连续预训练， delta 参数的范围可以增长到约 0.03，使 DARE 不太实用。我们还尝试了从 fine-tuned 参数中删除 delta 参数，发现可以将其减少到 10%，但这会导致性能锐减（甚至为 0）。这显示出 SFT 仅仅激活 LM 的能力，而不是把新的能力注入到 LM 中；（2）DARE 可以将多个任务特定 LM 合并成一个多能力 LM。例如，将 WizardLM 和 WizardMath 合并的 GSM8K 零shot准确率从 2.2 提高到 66.3，保留 WizardLM 的指令遵从能力，同时超越 WizardMath 的原始 64.2 性能。代码可以在 GitHub 上找到：https://github.com/yule-BUAA/MergeLM。
</details></li>
</ul>
<hr>
<h2 id="BanLemma-A-Word-Formation-Dependent-Rule-and-Dictionary-Based-Bangla-Lemmatizer"><a href="#BanLemma-A-Word-Formation-Dependent-Rule-and-Dictionary-Based-Bangla-Lemmatizer" class="headerlink" title="BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer"></a>BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03078">http://arxiv.org/abs/2311.03078</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eblict-gigatech/BanLemma">https://github.com/eblict-gigatech/BanLemma</a></li>
<li>paper_authors: Sadia Afrin, Md. Shahad Mahmud Chowdhury, Md. Ekramul Islam, Faisal Ahamed Khan, Labib Imam Chowdhury, MD. Motahar Mahtab, Nazifa Nuha Chowdhury, Massud Forkan, Neelima Kundu, Hakim Arif, Mohammad Mamun Or Rashid, Mohammad Ruhul Amin, Nabeel Mohammed</li>
<li>for: 本研究旨在提出一个特别设计 для Bangla 的 lemmatizer，以提高 Bangla 自然语言处理 (NLP) 的效能。</li>
<li>methods: 本研究使用了语言规则来定义 lemmatization 规则，并使用字典和规则来设计一个特别的 lemmatizer。它以 sentence 中每个词的 part of speech 类型为基础，对每个词进行 lemmatization。不同于先前的规则based方法，本研究分析了 Bangla 文本中各种词干的 suffix marker 的出现，并使用了 suffix marker 的序列而不是整个 suffix。</li>
<li>results: 本研究的 lemmatizer 在一个 manually annotated 的 test dataset 上 achiev 了 96.36% 的准确率，并在三个先前发表的 Bangla lemmatization dataset 上显示了竞争力的性能。<details>
<summary>Abstract</summary>
Lemmatization holds significance in both natural language processing (NLP) and linguistics, as it effectively decreases data density and aids in comprehending contextual meaning. However, due to the highly inflected nature and morphological richness, lemmatization in Bangla text poses a complex challenge. In this study, we propose linguistic rules for lemmatization and utilize a dictionary along with the rules to design a lemmatizer specifically for Bangla. Our system aims to lemmatize words based on their parts of speech class within a given sentence. Unlike previous rule-based approaches, we analyzed the suffix marker occurrence according to the morpho-syntactic values and then utilized sequences of suffix markers instead of entire suffixes. To develop our rules, we analyze a large corpus of Bangla text from various domains, sources, and time periods to observe the word formation of inflected words. The lemmatizer achieves an accuracy of 96.36% when tested against a manually annotated test dataset by trained linguists and demonstrates competitive performance on three previously published Bangla lemmatization datasets. We are making the code and datasets publicly available at https://github.com/eblict-gigatech/BanLemma in order to contribute to the further advancement of Bangla NLP.
</details>
<details>
<summary>摘要</summary>
lemmatization在自然语言处理（NLP）和语言学中具有重要意义，因为它有效地减少数据密度，并帮助理解上下文中的含义。然而，由于孟加拉语的高度变格和 morphological richness，孟加拉语 lemmatization 提出了复杂的挑战。在这种研究中，我们提出了语言规则 для lemmatization 并使用词典和规则来设计特有的孟加拉语 lemmatizer。我们的系统 aimsto lemmatize words based on their parts of speech class within a given sentence。不同于前一些规则基本的方法，我们分析了 suffix marker 的出现根据 morpho-syntactic values，然后使用 sequences of suffix markers instead of entire suffixes。为了开发我们的规则，我们分析了大量的孟加拉语文本，从不同的领域、来源和时期，以观察word formation of inflected words。lemmatizer 在一个手动标注的测试集上达到了 96.36% 的准确率，并在三个之前发布的孟加拉语 lemmatization 数据集上表现了竞争性。我们将代码和数据集公开发布在 GitHub 上，以便贡献到孟加拉语 NLP 的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Zero-shot-Bilingual-App-Reviews-Mining-with-Large-Language-Models"><a href="#Zero-shot-Bilingual-App-Reviews-Mining-with-Large-Language-Models" class="headerlink" title="Zero-shot Bilingual App Reviews Mining with Large Language Models"></a>Zero-shot Bilingual App Reviews Mining with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03058">http://arxiv.org/abs/2311.03058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Binbin Xu, Pierre Louis Bernard, Gérard Dray</li>
<li>for: 这个论文的目的是提高软件需求的改进，通过自动EXTRACT和SUMMARIZE用户评论来帮助开发人员更好地理解用户需求。</li>
<li>methods: 这个论文使用了大型自然语言处理（NLP）模型，包括分类、聚合和摘要等方法，以自动挖掘用户评论中的有用信息。</li>
<li>results: 实验结果表明，Mini-BAR可以有效地分类、聚合和摘要用户评论，并且可以在英文和法语两种语言中进行零shot学习。<details>
<summary>Abstract</summary>
App reviews from app stores are crucial for improving software requirements. A large number of valuable reviews are continually being posted, describing software problems and expected features. Effectively utilizing user reviews necessitates the extraction of relevant information, as well as their subsequent summarization. Due to the substantial volume of user reviews, manual analysis is arduous. Various approaches based on natural language processing (NLP) have been proposed for automatic user review mining. However, the majority of them requires a manually crafted dataset to train their models, which limits their usage in real-world scenarios. In this work, we propose Mini-BAR, a tool that integrates large language models (LLMs) to perform zero-shot mining of user reviews in both English and French. Specifically, Mini-BAR is designed to (i) classify the user reviews, (ii) cluster similar reviews together, (iii) generate an abstractive summary for each cluster and (iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we created a dataset containing 6,000 English and 6,000 French annotated user reviews and conducted extensive experiments. Preliminary results demonstrate the effectiveness and efficiency of Mini-BAR in requirement engineering by analyzing bilingual app reviews. (Replication package containing the code, dataset, and experiment setups on https://github.com/Jl-wei/mini-bar )
</details>
<details>
<summary>摘要</summary>
应用商店中的用户评论是软件需求的关键来源。大量有价值的评论不断上传，描述软件问题和期望功能。有效利用用户评论需要提取有用信息，并将其概括。由于用户评论的数量太多，人工分析是困难的。基于自然语言处理（NLP）的多种方法已经被提议用于自动用户评论挖掘。然而，大多数其中需要手动创建数据集来训练其模型，这限制了它们在实际场景中的使用。在这项工作中，我们提出了“小BAR”工具，它通过大型自然语言模型（LLM）来完成零shot用户评论挖掘。具体来说，小BAR是设计来：（i）分类用户评论，（ii）将相似的评论集成在一起，（iii）为每个分组生成抽象摘要，以及（iv）对用户评论分组进行排名。为了评估小BAR的性能，我们创建了包含6,000个英语和6,000个法语用户评论的数据集，并进行了广泛的实验。初步结果表明小BAR在需求工程中的效果和效率，通过分析双语应用评论。（复制包含代码、数据集和实验设置的代码在https://github.com/Jl-wei/mini-bar）
</details></li>
</ul>
<hr>
<h2 id="Detecting-Agreement-in-Multi-party-Conversational-AI"><a href="#Detecting-Agreement-in-Multi-party-Conversational-AI" class="headerlink" title="Detecting Agreement in Multi-party Conversational AI"></a>Detecting Agreement in Multi-party Conversational AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03026">http://arxiv.org/abs/2311.03026</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laura Schauer, Jason Sweeney, Charlie Lyttle, Zein Said, Aron Szeles, Cale Clark, Katie McAskill, Xander Wickham, Tom Byars, Daniel Hernández Garcia, Nancie Gunson, Angus Addlesee, Oliver Lemon</li>
<li>for: 这个论文的目的是提出一种多方会话系统，用于 Socially Assistive Robots (SARs) 中的多方会话。</li>
<li>methods: 该论文使用了一种基于协调识别和复杂转接的多方会话系统，并在评估中使用了两名用户参与的评估测试。</li>
<li>results: 论文的评估结果显示，该系统可以准确地检测用户的一致或不一致，并根据用户的回答进行相应的响应。<details>
<summary>Abstract</summary>
Today, conversational systems are expected to handle conversations in multi-party settings, especially within Socially Assistive Robots (SARs). However, practical usability remains difficult as there are additional challenges to overcome, such as speaker recognition, addressee recognition, and complex turn-taking. In this paper, we present our work on a multi-party conversational system, which invites two users to play a trivia quiz game. The system detects users' agreement or disagreement on a final answer and responds accordingly. Our evaluation includes both performance and user assessment results, with a focus on detecting user agreement. Our annotated transcripts and the code for the proposed system have been released open-source on GitHub.
</details>
<details>
<summary>摘要</summary>
今天，对话系统需要在多方会话中处理对话，特别是在社交辅助机器人（SARs）中。然而，实际用户体验仍然具有困难，因为需要解决多种挑战，如说话人识别、接收人识别和复杂的回答交互。在这篇论文中，我们介绍了一种多方对话系统，其中两名用户参与一场智能答题游戏。系统可以检测用户的同意或不同意 final 答案，并根据此进行响应。我们的评估包括性能评估和用户评估结果，强调检测用户同意的能力。我们已经在 GitHub 上公开发布了注释过的讯息记录和提议的系统代码。
</details></li>
</ul>
<hr>
<h2 id="Detecting-agreement-in-multi-party-dialogue-evaluating-speaker-diarisation-versus-a-procedural-baseline-to-enhance-user-engagement"><a href="#Detecting-agreement-in-multi-party-dialogue-evaluating-speaker-diarisation-versus-a-procedural-baseline-to-enhance-user-engagement" class="headerlink" title="Detecting agreement in multi-party dialogue: evaluating speaker diarisation versus a procedural baseline to enhance user engagement"></a>Detecting agreement in multi-party dialogue: evaluating speaker diarisation versus a procedural baseline to enhance user engagement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03021">http://arxiv.org/abs/2311.03021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Angus Addlesee, Daniel Denley, Andy Edmondson, Nancie Gunson, Daniel Hernández Garcia, Alexandre Kha, Oliver Lemon, James Ndubuisi, Neil O’Reilly, Lia Perochaud, Raphaël Valeri, Miebaka Worika</li>
<li>for: 本研究旨在探讨对话状态跟踪在多方交互中的挑战，以及使用扩声模型和频率和 proximity 方法来确定对话内容。</li>
<li>methods: 本研究使用了合作测验，其中对话机器人扮演了答题游戏的主持人，以确定响应者是否达成一致。</li>
<li>results: 实验结果表明，我们的程序体系更加有趣，并且更准确地确定了一致，其准确率为 0.44，而对比的扩声系统的准确率为 0.28。<details>
<summary>Abstract</summary>
Conversational agents participating in multi-party interactions face significant challenges in dialogue state tracking, since the identity of the speaker adds significant contextual meaning. It is common to utilise diarisation models to identify the speaker. However, it is not clear if these are accurate enough to correctly identify specific conversational events such as agreement or disagreement during a real-time interaction. This study uses a cooperative quiz, where the conversational agent acts as quiz-show host, to determine whether diarisation or a frequency-and-proximity-based method is more accurate at determining agreement, and whether this translates to feelings of engagement from the players. Experimental results show that our procedural system was more engaging to players, and was more accurate at detecting agreement, reaching an average accuracy of 0.44 compared to 0.28 for the diarised system.
</details>
<details>
<summary>摘要</summary>
多个人party交流中的对话管理器面临着很大的挑战，因为发言人的身份带有丰富的上下文含义。通常使用 диари化模型来确定发言人。然而，不清楚这些模型是否具有准确地确定对话事件的能力，如同意或不同意在实时交流中。本研究使用合作测验，将对话管理器 acted as quiz show 主持人，以确定 диари化或频率和距离基于方法是哪一种更准确地确定一致，以及这种精度是否对玩家产生了参与感。实验结果表明，我们的过程系统更加有趣，并且更准确地确定一致，达到了0.44的平均准确率，比0.28的 диари化系统更高。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Transformer-Based-Reverse-Dictionary-Model-for-Quality-Estimation-of-Definitions"><a href="#Towards-a-Transformer-Based-Reverse-Dictionary-Model-for-Quality-Estimation-of-Definitions" class="headerlink" title="Towards a Transformer-Based Reverse Dictionary Model for Quality Estimation of Definitions"></a>Towards a Transformer-Based Reverse Dictionary Model for Quality Estimation of Definitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02985">http://arxiv.org/abs/2311.02985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guité-Vinet Julien, Blondin Massé Alexandre, Sadat Fatiha</li>
<li>for: 这篇论文是为了研究不同变体的transformer模型在解决反词典任务上的表现，以及这些模型在严肃游戏《词典游戏》中的应用。</li>
<li>methods: 本文使用了多种transformer模型，包括Bert、RoBERTa、XLNet等，进行对比研究。</li>
<li>results: 研究结果显示，Bert模型在解决反词典任务上表现最佳，而XLNet模型在某些任务上表现较差。<details>
<summary>Abstract</summary>
In the last years, several variants of transformers have emerged. In this paper, we compare different transformer-based models for solving the reverse dictionary task and explore their use in the context of a serious game called The Dictionary Game.
</details>
<details>
<summary>摘要</summary>
最近几年，transformer的多种变体出现了。本文比较了不同基于transformer的模型，用于解决反ictionary任务，并在serious game《词典游戏》的context中 explore their use。Here's the breakdown of the translation:* 最近几年 (last years) becomes 最近几年 (last years)* transformer的多种变体 (variants of transformers) becomes  transformer的多种变体 (variants of transformers)* 出现了 (emerged) becomes 出现了 (emerged)* 本文 (this paper) becomes 本文 (this paper)* 比较 (compare) becomes 比较 (compare)* 不同基于 (different based on) becomes 不同基于 (different based on)* transformer (transformer) becomes transformer (transformer)* 模型 (model) becomes 模型 (model)* 用于 (for) becomes 用于 (for)* 解决 (solve) becomes 解决 (solve)* 反ictionary (reverse dictionary) becomes 反ictionary (reverse dictionary)* 任务 (task) becomes 任务 (task)* 并 (and) becomes 并 (and)* 在 (in) becomes 在 (in)* serious game (serious game) becomes 严肃游戏 (serious game)* 《词典游戏》 (The Dictionary Game) becomes 《词典游戏》 (The Dictionary Game)
</details></li>
</ul>
<hr>
<h2 id="Adapting-Pre-trained-Generative-Models-for-Extractive-Question-Answering"><a href="#Adapting-Pre-trained-Generative-Models-for-Extractive-Question-Answering" class="headerlink" title="Adapting Pre-trained Generative Models for Extractive Question Answering"></a>Adapting Pre-trained Generative Models for Extractive Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02961">http://arxiv.org/abs/2311.02961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prabirmallick/GenAI4EQA">https://github.com/prabirmallick/GenAI4EQA</a></li>
<li>paper_authors: Prabir Mallick, Tapas Nayak, Indrajit Bhattacharya</li>
<li>for: 本文旨在探讨将先进的生成模型应用于抽取式问答任务中，以提高问答效果。</li>
<li>methods: 本文提出了一种新的方法，通过使用预训练的生成模型生成上下文字符或句子的索引，以便更好地解决抽取式问答任务。</li>
<li>results: 经过对多个抽取式问答数据集的详细评估，包括MultiSpanQA、BioASQ、MASHQA和WikiQA，本文的提议方法表现出了较高的性能，比之前的状态艺术模型更好。<details>
<summary>Abstract</summary>
Pre-trained Generative models such as BART, T5, etc. have gained prominence as a preferred method for text generation in various natural language processing tasks, including abstractive long-form question answering (QA) and summarization. However, the potential of generative models in extractive QA tasks, where discriminative models are commonly employed, remains largely unexplored. Discriminative models often encounter challenges associated with label sparsity, particularly when only a small portion of the context contains the answer. The challenge is more pronounced for multi-span answers. In this work, we introduce a novel approach that uses the power of pre-trained generative models to address extractive QA tasks by generating indexes corresponding to context tokens or sentences that form part of the answer. Through comprehensive evaluations on multiple extractive QA datasets, including MultiSpanQA, BioASQ, MASHQA, and WikiQA, we demonstrate the superior performance of our proposed approach compared to existing state-of-the-art models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PhoGPT-Generative-Pre-training-for-Vietnamese"><a href="#PhoGPT-Generative-Pre-training-for-Vietnamese" class="headerlink" title="PhoGPT: Generative Pre-training for Vietnamese"></a>PhoGPT: Generative Pre-training for Vietnamese</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02945">http://arxiv.org/abs/2311.02945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/VinAIResearch/PhoGPT">https://github.com/VinAIResearch/PhoGPT</a></li>
<li>paper_authors: Dat Quoc Nguyen, Linh The Nguyen, Chi Tran, Dung Ngoc Nguyen, Nhung Nguyen, Thien Huu Nguyen, Dinh Phung, Hung Bui</li>
<li>for: 这个论文是为了介绍一种新的开源generative模型系列PhoGPT，用于越南语言处理。</li>
<li>methods: 这个模型使用了7.5亿个参数，包括基础预训练单语言模型PhoGPT-7B5以及其 instrucion-following变体PhoGPT-7B5-Instruct。</li>
<li>results: 作者通过人工评估实验表明，这个模型在前一代开源模型的比较中显示出了更高的性能。Here’s the English version for reference:</li>
<li>for: This paper introduces a new open-source generative model series named PhoGPT for Vietnamese language processing.</li>
<li>methods: The model uses 7.5 billion parameters, including the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct.</li>
<li>results: The authors demonstrate the superior performance of the model compared to previous open-source models through a human evaluation experiment.<details>
<summary>Abstract</summary>
We open-source a state-of-the-art 7.5B-parameter generative model series named PhoGPT for Vietnamese, which includes the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct. In addition, we also demonstrate its superior performance compared to previous open-source models through a human evaluation experiment. GitHub: https://github.com/VinAIResearch/PhoGPT
</details>
<details>
<summary>摘要</summary>
我们开源了一种高度进步的7.5亿参数生成模型系列，名为 PhoGPT，用于越南语言。该系列包括基础预训练单语言模型 PhoGPT-7B5 和其 instrucion-following 变体 PhoGPT-7B5-Instruct。此外，我们还通过人工评估实验证明了该模型与前一代开源模型的superior表现。GitHub：https://github.com/VinAIResearch/PhoGPT。Note: "PhoGPT" is the name of the model series, and "PhoGPT-7B5" and "PhoGPT-7B5-Instruct" are the specific models within the series.
</details></li>
</ul>
<hr>
<h2 id="SQLPrompt-In-Context-Text-to-SQL-with-Minimal-Labeled-Data"><a href="#SQLPrompt-In-Context-Text-to-SQL-with-Minimal-Labeled-Data" class="headerlink" title="SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data"></a>SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02883">http://arxiv.org/abs/2311.02883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruoxi Sun, Sercan Ö. Arik, Rajarishi Sinha, Hootan Nakhost, Hanjun Dai, Pengcheng Yin, Tomas Pfister</li>
<li>for: 提高 Text-to-SQL 模型在大型自然语言处理器（LLM）上的几 shot 提示能力</li>
<li>methods: 创新的提示设计、执行基于一致性选择策略、以及在一致性选择中使用不同提示设计和基础模型进行多样化提案策略</li>
<li>results: 在具有少量标注数据的情况下，SQLPrompt 可以大幅提高 Text-to-SQL 模型的几 shot 学习性能，并且可以追近训练 state-of-the-art 的性能水平，但需要使用数千个标注数据进行训练。<details>
<summary>Abstract</summary>
Text-to-SQL aims to automate the process of generating SQL queries on a database from natural language text. In this work, we propose "SQLPrompt", tailored to improve the few-shot prompting capabilities of Text-to-SQL for Large Language Models (LLMs). Our methods include innovative prompt design, execution-based consistency decoding strategy which selects the SQL with the most consistent execution outcome among other SQL proposals, and a method that aims to improve performance by diversifying the SQL proposals during consistency selection with different prompt designs ("MixPrompt") and foundation models ("MixLLMs"). We show that \emph{SQLPrompt} outperforms previous approaches for in-context learning with few labeled data by a large margin, closing the gap with finetuning state-of-the-art with thousands of labeled data.
</details>
<details>
<summary>摘要</summary>
文本到SQL是一个自动生成SQL查询语句的数据库的过程。在这个工作中，我们提出了“SQLPrompt”，用于改进文本到SQL中大语言模型（LLM）的几个shot提示能力。我们的方法包括创新的提示设计、执行基于一致性解码策略和多种提示设计和基础模型“混合提示”以提高性能。我们示出了 compared to previous approaches，我们的方法可以在受限的培auoted data上进行Context learning，大幅提高SQLPrompt的性能，并且可以追赶到finetuning状态的水平。
</details></li>
</ul>
<hr>
<h2 id="Less-than-One-shot-Named-Entity-Recognition-via-Extremely-Weak-Supervision"><a href="#Less-than-One-shot-Named-Entity-Recognition-via-Extremely-Weak-Supervision" class="headerlink" title="Less than One-shot: Named Entity Recognition via Extremely Weak Supervision"></a>Less than One-shot: Named Entity Recognition via Extremely Weak Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02861">http://arxiv.org/abs/2311.02861</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KomeijiForce/X-NER">https://github.com/KomeijiForce/X-NER</a></li>
<li>paper_authors: Letian Peng, Zihan Wang, Jingbo Shang</li>
<li>for: 本研究targets the named entity recognition (NER) problem under the extremely weak supervision (XWS) setting, where only one example entity per type is given in a context-free way.</li>
<li>methods: 我们提出了一种新的方法X-NER，它可以在XWS setting下超过现有的一shot NER方法的性能。我们首先从无标注训练集中挖掘 Entity span，然后使用这些 span 的上下文分布来训练 NER 标注器。</li>
<li>results: 我们在4个 NER  dataset上进行了广泛的实验和分析，结果显示 X-NER 可以具有state-of-the-art的 few-shot NER 性能，并且在1shot supervision和ChatGPT标注下显著超过现有方法。此外，X-NER 还具有跨语言能力。<details>
<summary>Abstract</summary>
We study the named entity recognition (NER) problem under the extremely weak supervision (XWS) setting, where only one example entity per type is given in a context-free way. While one can see that XWS is lighter than one-shot in terms of the amount of supervision, we propose a novel method X-NER that can outperform the state-of-the-art one-shot NER methods. We first mine entity spans that are similar to the example entities from an unlabelled training corpus. Instead of utilizing entity span representations from language models, we find it more effective to compare the context distributions before and after the span is replaced by the entity example. We then leverage the top-ranked spans as pseudo-labels to train an NER tagger. Extensive experiments and analyses on 4 NER datasets show the superior end-to-end NER performance of X-NER, outperforming the state-of-the-art few-shot methods with 1-shot supervision and ChatGPT annotations significantly. Finally, our X-NER possesses several notable properties, such as inheriting the cross-lingual abilities of the underlying language models.
</details>
<details>
<summary>摘要</summary>
我们研究名实体识别（NER）问题在极其轻量级指导（XWS） Setting下，只有一个例子实体每种类型。虽然XWS比一shot更轻量级，但我们提出了一种新方法X-NER，可以超越现状最佳一shot NER方法。我们首先在无标注训练集中挖掘类似实体示例的 span。而不是使用语言模型中的实体span表示，我们发现更有效的是在 span 前后的上下文分布比较。然后，我们利用top排名 span 作为pseudo标签来训练 NER 标注器。我们对4个NER数据集进行了广泛的实验和分析，显示 X-NER 具有显著的端到端 NER性能优势，比现状最佳几个shot方法和ChatGPT标注更加显著。最后，我们的 X-NER 具有一些注意的性能特性，如继承下来语言模型的cross-Lingual能力。
</details></li>
</ul>
<hr>
<h2 id="Improving-Machine-Translation-with-Large-Language-Models-A-Preliminary-Study-with-Cooperative-Decoding"><a href="#Improving-Machine-Translation-with-Large-Language-Models-A-Preliminary-Study-with-Cooperative-Decoding" class="headerlink" title="Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding"></a>Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02851">http://arxiv.org/abs/2311.02851</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lemon0830/CoDec">https://github.com/lemon0830/CoDec</a></li>
<li>paper_authors: Jiali Zeng, Fandong Meng, Yongjing Yin, Jie Zhou</li>
<li>for: 这 paper 是为了探讨 NMT 系统和 MT-oriented LLMs 在翻译中的竞争关系，以及如何使用这两种技术来提高翻译质量。</li>
<li>methods: 这 paper 使用了多种商业 NMT 系统和 MT-oriented LLMs 进行比较分析，以了解它们在不同的翻译场景中的优劣点。然后，基于这些发现，提出了一种 hybrid 方法——Cooperative Decoding (CoDec)，它将 NMT 系统作为预翻译模型，并将 MT-oriented LLMs 作为补充解决方案来处理复杂的翻译问题。</li>
<li>results: 试验结果表明，CoDec 能够有效地和高效地结合 NMT 系统和 MT-oriented LLMs，在 WMT22 测试集和一个新收集的 WebCrawl 测试集上达到了显著的改进。这些结果表明，CoDec 可以作为一种可靠的解决方案，用于将 NMT 系统和 MT-oriented LLMs 结合使用于翻译中。<details>
<summary>Abstract</summary>
Contemporary translation engines built upon the encoder-decoder framework have reached a high level of development, while the emergence of Large Language Models (LLMs) has disrupted their position by offering the potential for achieving superior translation quality. Therefore, it is crucial to understand in which scenarios LLMs outperform traditional NMT systems and how to leverage their strengths. In this paper, we first conduct a comprehensive analysis to assess the strengths and limitations of various commercial NMT systems and MT-oriented LLMs. Our findings indicate that neither NMT nor MT-oriented LLMs alone can effectively address all the translation issues, but MT-oriented LLMs can serve as a promising complement to the NMT systems. Building upon these insights, we explore hybrid methods and propose Cooperative Decoding (CoDec), which treats NMT systems as a pretranslation model and MT-oriented LLMs as a supplemental solution to handle complex scenarios beyond the capability of NMT alone. The results on the WMT22 test sets and a newly collected test set WebCrawl demonstrate the effectiveness and efficiency of CoDec, highlighting its potential as a robust solution for combining NMT systems with MT-oriented LLMs in machine translation.
</details>
<details>
<summary>摘要</summary>
当代翻译引擎，基于编码器-解码器框架，已经到了高度的发展阶段，而大语言模型（LLMs）的出现，对传统的新型机器翻译（NMT）系统产生了冲击，提供了可以实现更高质量翻译的潜在力量。因此，理解LLMs在哪些场景下表现出色，并如何利用其优势，是非常重要的。在这篇论文中，我们首先进行了全面的分析，以评估不同的商业NMT系统和MT-oriented LLMs的优缺点。我们的发现表明，NMT系统和MT-oriented LLMs单独无法有效地解决所有翻译问题，但MT-oriented LLMs可以作为NMT系统的补充解决方案，处理NMT无法涵盖的复杂场景。基于这些发现，我们探索了 гибрид方法，并提出了合作解码（CoDec），它将NMT系统作为先translation模型，MT-oriented LLMs作为补充解决方案，用于处理NMT无法涵盖的复杂场景。results on WMT22 test sets和我们新收集的WebCrawl test set表明，CoDec是一种有效和高效的解决方案，强调其在组合NMT系统和MT-oriented LLMs的机器翻译中的潜在力量。
</details></li>
</ul>
<hr>
<h2 id="Tailoring-Self-Rationalizers-with-Multi-Reward-Distillation"><a href="#Tailoring-Self-Rationalizers-with-Multi-Reward-Distillation" class="headerlink" title="Tailoring Self-Rationalizers with Multi-Reward Distillation"></a>Tailoring Self-Rationalizers with Multi-Reward Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02805">http://arxiv.org/abs/2311.02805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/INK-USC/RationaleMultiRewardDistillation">https://github.com/INK-USC/RationaleMultiRewardDistillation</a></li>
<li>paper_authors: Sahana Ramnath, Brihi Joshi, Skyler Hallinan, Ximing Lu, Liunian Harold Li, Aaron Chan, Jack Hessel, Yejin Choi, Xiang Ren</li>
<li>for: 这个论文的目的是提高小型语言模型（LMs）的问答能力，并且可以生成更有用的自我合理化来帮助 humans 理解模型的决策过程。</li>
<li>methods: 这个论文使用了一种名为 MaRio（Multi-rewArd RatIOnalization）的多奖准则自我合理化算法，通过优化多个特征（如可能性、多样性和一致性）来提高小LMs 的问答能力和自我合理化质量。</li>
<li>results: 实验结果表明，MaRio 可以在五个复杂的问答任务上提高任务的准确率，同时也提高小LMs 的自我合理化质量，比如可能性、多样性和一致性。  besides, human评估表明，MaRio 的合理化推理比 SFT 基线更受欢迎，并且有质量上的提升。<details>
<summary>Abstract</summary>
Large language models (LMs) are capable of generating free-text rationales to aid question answering. However, prior work 1) suggests that useful self-rationalization is emergent only at significant scales (e.g., 175B parameter GPT-3); and 2) focuses largely on downstream performance, ignoring the semantics of the rationales themselves, e.g., are they faithful, true, and helpful for humans? In this work, we enable small-scale LMs (approx. 200x smaller than GPT-3) to generate rationales that not only improve downstream task performance, but are also more plausible, consistent, and diverse, assessed both by automatic and human evaluation. Our method, MaRio (Multi-rewArd RatIOnalization), is a multi-reward conditioned self-rationalization algorithm that optimizes multiple distinct properties like plausibility, diversity and consistency. Results on five difficult question-answering datasets StrategyQA, QuaRel, OpenBookQA, NumerSense and QASC show that not only does MaRio improve task accuracy, but it also improves the self-rationalization quality of small LMs across the aforementioned axes better than a supervised fine-tuning (SFT) baseline. Extensive human evaluations confirm that MaRio rationales are preferred vs. SFT rationales, as well as qualitative improvements in plausibility and consistency.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LM）能够生成自由文本论据以帮助问答。然而，先前的研究表明，有用的自我合理化只有在较大的Scale（例如175B参数的GPT-3）下才能出现；而且大多数研究都将注意力集中在下游性能上，忽略论据本身的 semantics，例如它们是否 faithful、true 和有用 для人类？在这项工作中，我们使得小型语言模型（约200倍小于GPT-3）能够生成不 только提高下游任务性能的论据，而且也更可靠、多样和一致，通过自动和人类评估。我们的方法，MaRio（多重rewArd RatIOnalization），是一种多重奖励条件自我合理化算法，该算法优化多个不同的属性，如可能性、多样性和一致性。结果表明，MaRio在五个复杂的问答任务StrategYQA、QuaRel、OpenBookQA、NumerSense和QASC上表现出色，不仅提高了任务准确率，而且也在论据质量上超越基eline。人类评估表明，MaRio的论据比SFT基eline更受欢迎，并且有质量上的改进。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.CL_2023_11_06/" data-id="cloojsme400dzre88gtf23i5n" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.LG_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T10:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.LG_2023_11_06/">cs.LG - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Uni-O4-Unifying-Online-and-Offline-Deep-Reinforcement-Learning-with-Multi-Step-On-Policy-Optimization"><a href="#Uni-O4-Unifying-Online-and-Offline-Deep-Reinforcement-Learning-with-Multi-Step-On-Policy-Optimization" class="headerlink" title="Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization"></a>Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03351">http://arxiv.org/abs/2311.03351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Lei, Zhengmao He, Chenhao Lu, Kaizhe Hu, Yang Gao, Huazhe Xu</li>
<li>for: 该研究旨在提出一种 straightforward yet effective 的 offline和online reinforcement learning（RL）方法，以便在缺乏数据的情况下快速部署在真实世界中。</li>
<li>methods: 该方法使用了一种具有一致性的两阶段目标函数，以便在offline和online学习之间进行无缝传递。在offline阶段，该方法使用了多个杂合政策来Address the mismatch issues，并通过一种简单的offline政策评估（OPE）方法来实现多步政策改进。</li>
<li>results: 该研究表明，通过 combining offline和online学习，可以获得优秀的初始化和稳定的在线细化能力。通过使用该方法，在真实世界中完成了一些复杂的机器人任务，并在许多 simulated benchmarks 中实现了领先的性能。<details>
<summary>Abstract</summary>
Combining offline and online reinforcement learning (RL) is crucial for efficient and safe learning. However, previous approaches treat offline and online learning as separate procedures, resulting in redundant designs and limited performance. We ask: Can we achieve straightforward yet effective offline and online learning without introducing extra conservatism or regularization? In this study, we propose Uni-o4, which utilizes an on-policy objective for both offline and online learning. Owning to the alignment of objectives in two phases, the RL agent can transfer between offline and online learning seamlessly. This property enhances the flexibility of the learning paradigm, allowing for arbitrary combinations of pretraining, fine-tuning, offline, and online learning. In the offline phase, specifically, Uni-o4 leverages diverse ensemble policies to address the mismatch issues between the estimated behavior policy and the offline dataset. Through a simple offline policy evaluation (OPE) approach, Uni-o4 can achieve multi-step policy improvement safely. We demonstrate that by employing the method above, the fusion of these two paradigms can yield superior offline initialization as well as stable and rapid online fine-tuning capabilities. Through real-world robot tasks, we highlight the benefits of this paradigm for rapid deployment in challenging, previously unseen real-world environments. Additionally, through comprehensive evaluations using numerous simulated benchmarks, we substantiate that our method achieves state-of-the-art performance in both offline and offline-to-online fine-tuning learning. Our website: https://lei-kun.github.io/uni-o4/ .
</details>
<details>
<summary>摘要</summary>
combining 离线和在线 reinforcement learning (RL) 是关键 для高效和安全的学习。然而，先前的方法将离线和在线学习视为分开的过程，导致设计不优化和性能有限。我们问：可以在离线和在线学习之间实现直观而有效的学习方法，而无需添加额外的保守性或 regularization？在这种研究中，我们提出了Uni-o4，它利用了在线策略对象 для离线和在线学习。由于两个阶段的目标对齐，RL Agent可以在离线和在线学习之间转换无缝。这种特性提高了学习框架的灵活性，允许任意组合预训练、精度调整、离线和在线学习。在离线阶段中，Uni-o4 特别利用了多种 ensemble 策略来解决离线数据集和估计行为策略之间的匹配问题。通过简单的离线政策评估（OPE）方法，Uni-o4 可以安全地实现多步政策改进。我们表明，通过上述方法，离线和在线学习的融合可以提供出色的初始化以及稳定和快速的在线精度调整能力。通过实际的 робоット任务，我们强调了这种 Paradigm 在挑战性、先前未 seen 的实际环境中的快速部署的优势。此外，通过多个 simulated  benchmark 的完整评估，我们证明了我们的方法在离线和离线到在线学习中达到了领先的性能。更多信息请访问我们的网站：<https://lei-kun.github.io/uni-o4/>。
</details></li>
</ul>
<hr>
<h2 id="Learning-Hard-Constrained-Models-with-One-Sample"><a href="#Learning-Hard-Constrained-Models-with-One-Sample" class="headerlink" title="Learning Hard-Constrained Models with One Sample"></a>Learning Hard-Constrained Models with One Sample</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03332">http://arxiv.org/abs/2311.03332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Galanis, Alkis Kalavasis, Anthimos Vardis Kandiros</li>
<li>For: 本研究考虑了用单个样本来估算Markov随机场的参数，并应用于$k$-SAT、正确颜色和总体$H$-颜色模型。* Methods: 我们使用pseudo-likelihood estimator，并使用coupling技术来提供变量上下文。* Results: 我们 obtiain了一些正面结果，包括linear-time estimator for $q$-颜色和$H$-颜色模型，但也有一些负面结果，例如，$k$-SAT模型在某些情况下不能一样样本来估算参数。<details>
<summary>Abstract</summary>
We consider the problem of estimating the parameters of a Markov Random Field with hard-constraints using a single sample. As our main running examples, we use the $k$-SAT and the proper coloring models, as well as general $H$-coloring models; for all of these we obtain both positive and negative results. In contrast to the soft-constrained case, we show in particular that single-sample estimation is not always possible, and that the existence of an estimator is related to the existence of non-satisfiable instances.   Our algorithms are based on the pseudo-likelihood estimator. We show variance bounds for this estimator using coupling techniques inspired, in the case of $k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for colorings build on this new coupling approach. For $q$-colorings on graphs with maximum degree $d$, we give a linear-time estimator when $q>d+1$, whereas the problem is non-identifiable when $q\leq d+1$. For general $H$-colorings, we show that standard conditions that guarantee sampling, such as Dobrushin's condition, are insufficient for one-sample learning; on the positive side, we provide a general condition that is sufficient to guarantee linear-time learning and obtain applications for proper colorings and permissive models. For the $k$-SAT model on formulas with maximum degree $d$, we provide a linear-time estimator when $k\gtrsim 6.45\log d$, whereas the problem becomes non-identifiable when $k\lesssim \log d$.
</details>
<details>
<summary>摘要</summary>
我们考虑一个Markov随机场景中参数估计问题，使用单个样本。我们的主要运行例子包括$k$-SAT和正确颜色模型，以及总的$H$-颜色模型。对于所有这些模型，我们得到了bothPositive和Negative结果。与软链接的情况不同，我们显示单个样本估计不总是可能的，并且存在非满足性的实例的存在关系。我们的算法基于假似概率估计器。我们使用启发的方法提供了变量上下文，特别是在$k$-SAT模型中使用Moitra的采样算法（JACM, 2019）。对于颜色模型，我们基于这个新的启发方法得到了Positive结果。对于图格raphs with maximum degree $d$, 当$q>d+1$时，我们提供了 linear-time 估计器，而当$q\leq d+1$时，问题是非同质的。对于总的$H$-颜色模型，我们显示了标准的采样条件，如Dobrushin的条件，是不够的 для一个样本学习。然而，我们提供了一个通用的条件，可以 guaranteee linear-time learning，并且有应用于正确颜色和允许模型。对于$k$-SAT模型中的 formulas with maximum degree $d$, 当$k\gtrsim 6.45\log d$时，我们提供了 linear-time 估计器，而当$k\lesssim \log d$时，问题变得非同质的。
</details></li>
</ul>
<hr>
<h2 id="Practical-considerations-for-variable-screening-in-the-Super-Learner"><a href="#Practical-considerations-for-variable-screening-in-the-Super-Learner" class="headerlink" title="Practical considerations for variable screening in the Super Learner"></a>Practical considerations for variable screening in the Super Learner</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03313">http://arxiv.org/abs/2311.03313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bdwilliamson/sl_screening_supplementary">https://github.com/bdwilliamson/sl_screening_supplementary</a></li>
<li>paper_authors: Brian D. Williamson, Drew King, Ying Huang</li>
<li>for: 本研究旨在探讨Super Learner ensemble的应用，特别是在使用变量选择算法（如lasso）进行维度减少后，如何使用Super Learner来预测数据。</li>
<li>methods: 本研究使用了Super Learner ensemble，并在 ensemble 中使用了变量选择算法（如lasso）进行维度减少。</li>
<li>results: 研究发现，使用单一的变量选择算法（如lasso）可能会导致预测性能差，因此建议使用多种候选选择算法来保证预测性能。<details>
<summary>Abstract</summary>
Estimating a prediction function is a fundamental component of many data analyses. The Super Learner ensemble, a particular implementation of stacking, has desirable theoretical properties and has been used successfully in many applications. Dimension reduction can be accomplished by using variable screening algorithms, including the lasso, within the ensemble prior to fitting other prediction algorithms. However, the performance of a Super Learner using the lasso for dimension reduction has not been fully explored in cases where the lasso is known to perform poorly. We provide empirical results that suggest that a diverse set of candidate screening algorithms should be used to protect against poor performance of any one screen, similar to the guidance for choosing a library of prediction algorithms for the Super Learner.
</details>
<details>
<summary>摘要</summary>
估算预测函数是数据分析中的基本组成部分。超学习ensemble是多stacking实现中的一种，具有悉尽理论性质，在多个应用中得到成功。变量屏选算法，如lasso，可以在ensemble前使用来实现维度减少。然而，使用lasso进行屏选的超学习性能未经完整探讨。我们提供实验结果，表明使用多种候选屏选算法可以保护 against poor performance of any one screen，类似于选择预测算法库的超学习guidance。
</details></li>
</ul>
<hr>
<h2 id="TS-Diffusion-Generating-Highly-Complex-Time-Series-with-Diffusion-Models"><a href="#TS-Diffusion-Generating-Highly-Complex-Time-Series-with-Diffusion-Models" class="headerlink" title="TS-Diffusion: Generating Highly Complex Time Series with Diffusion Models"></a>TS-Diffusion: Generating Highly Complex Time Series with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03303">http://arxiv.org/abs/2311.03303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangming Li</li>
<li>for: 这项研究的目的是处理具有 sampling 不均匀、缺失数据和高维特征的时间序列数据。</li>
<li>methods: 该模型采用点 процесс框架，包括一个神经Ordinary Differential Equation（ODE）编码器、一个Diffusion模型和另一个ODE解码器。编码器使用跳技术和自我注意机制处理 sampling 不均匀和缺失数据，Diffusion模型学习时间序列表示的复杂分布，而解码器使用另一个ODE生成时间序列。</li>
<li>results: 在多个时间序列数据集上，TS-Diffusion 实现了优秀的 результаados both 在常见时间序列和复杂时间序列上，与之前的基eline signifiantly outperform。<details>
<summary>Abstract</summary>
While current generative models have achieved promising performances in time-series synthesis, they either make strong assumptions on the data format (e.g., regularities) or rely on pre-processing approaches (e.g., interpolations) to simplify the raw data. In this work, we consider a class of time series with three common bad properties, including sampling irregularities, missingness, and large feature-temporal dimensions, and introduce a general model, TS-Diffusion, to process such complex time series. Our model consists of three parts under the framework of point process. The first part is an encoder of the neural ordinary differential equation (ODE) that converts time series into dense representations, with the jump technique to capture sampling irregularities and self-attention mechanism to handle missing values; The second component of TS-Diffusion is a diffusion model that learns from the representation of time series. These time-series representations can have a complex distribution because of their high dimensions; The third part is a decoder of another ODE that generates time series with irregularities and missing values given their representations. We have conducted extensive experiments on multiple time-series datasets, demonstrating that TS-Diffusion achieves excellent results on both conventional and complex time series and significantly outperforms previous baselines.
</details>
<details>
<summary>摘要</summary>
当前的生成模型已经实现了时间序列生成的可靠性，但它们都假设了数据的格式（例如，规则）或者使用预处理技术（例如， interpolations）来简化原始数据。在这个工作中，我们考虑了一类时间序列具有三种常见的坏性，包括采样不规则、缺失和大特征时间维度，并引入了一种通用模型，TS-Diffusion，来处理这类复杂时间序列。我们的模型包括三部分，即编码器、扩散模型和解码器，它们都位于点处理框架下。首先，编码器是一个神经网络Ordinary Differential Equation（ODE），它将时间序列转换成稠密表示，并使用跳技术来捕捉采样不规则，同时使用自我注意机制来处理缺失值。第二部分是一个学习从时间序列表示的扩散模型，这些时间序列表示可能具有复杂的分布，因为它们的维度很高。最后，解码器是另一个ODE，它可以生成具有采样不规则和缺失值的时间序列，givien其表示。我们在多个时间序列 dataset上进行了广泛的实验，并证明了 TS-Diffusion 在 convent ional 和复杂时间序列上实现了杰出的效果，同时与前一个基eline 相比，它显著提高了表现。
</details></li>
</ul>
<hr>
<h2 id="Risk-of-Transfer-Learning-and-its-Applications-in-Finance"><a href="#Risk-of-Transfer-Learning-and-its-Applications-in-Finance" class="headerlink" title="Risk of Transfer Learning and its Applications in Finance"></a>Risk of Transfer Learning and its Applications in Finance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03283">http://arxiv.org/abs/2311.03283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyang Cao, Haotian Gu, Xin Guo, Mathieu Rosenbaum</li>
<li>for: 这篇论文是为了研究传输学习的应用和评估方法而写的。</li>
<li>methods: 论文提出了一种新的传输风险概念，并分析了其属性，以评估传输学习的可行性。 authors 还使用了传输学习技术和传输风险来解决股票回报预测和资产配置问题。</li>
<li>results: 数值结果表明，传输风险与总传输学习性能之间存在强相关性，传输风险提供了一种 computationally efficient 的方法来选择适当的源任务，包括跨大陆、跨业和跨频率的传输。<details>
<summary>Abstract</summary>
Transfer learning is an emerging and popular paradigm for utilizing existing knowledge from previous learning tasks to improve the performance of new ones. In this paper, we propose a novel concept of transfer risk and and analyze its properties to evaluate transferability of transfer learning. We apply transfer learning techniques and this concept of transfer risk to stock return prediction and portfolio optimization problems. Numerical results demonstrate a strong correlation between transfer risk and overall transfer learning performance, where transfer risk provides a computationally efficient way to identify appropriate source tasks in transfer learning, including cross-continent, cross-sector, and cross-frequency transfer for portfolio optimization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转移学习是一种现代和受欢迎的思想，它利用先前学习任务中的知识来提高新任务的性能。在这篇论文中，我们提出了一种新的转移风险概念，并分析其性质以评估转移学习的可行性。我们在股票回报预测和资产优化问题上应用了转移学习技术和转移风险概念，并取得了计算效率高的结果。NUMERICAL结果表明，转移风险和总转移学习性能之间存在强正相关性，转移风险提供了一种 computationally efficient的方式来确定合适的源任务在转移学习中，包括跨大陆、跨业和跨频率的转移。Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Discretizing-Numerical-Attributes-An-Analysis-of-Human-Perceptions"><a href="#Discretizing-Numerical-Attributes-An-Analysis-of-Human-Perceptions" class="headerlink" title="Discretizing Numerical Attributes: An Analysis of Human Perceptions"></a>Discretizing Numerical Attributes: An Analysis of Human Perceptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03278">http://arxiv.org/abs/2311.03278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minakshi Kaushik, Rahul Sharma, Dirk Draheim</li>
<li>for: 本研究旨在提供一个数值特征分 partitioning 的标准方法，以便在机器学习应用中更好地处理数值特征。</li>
<li>methods: 本研究使用了人类听觉分析和专家 opinio 来评估现有的分 partitioning 方法，并提出了两种新的分 mesure 方法。</li>
<li>results: 研究发现，68.7% 的人类响应与我们提出的两种分 mesure 方法相似，这表明这两种方法可能可以用作数值特征分 partitioning 的标准方法。<details>
<summary>Abstract</summary>
Machine learning (ML) has employed various discretization methods to partition numerical attributes into intervals. However, an effective discretization technique remains elusive in many ML applications, such as association rule mining. Moreover, the existing discretization techniques do not reflect best the impact of the independent numerical factor on the dependent numerical target factor. This research aims to establish a benchmark approach for numerical attribute partitioning. We conduct an extensive analysis of human perceptions of partitioning a numerical attribute and compare these perceptions with the results obtained from our two proposed measures. We also examine the perceptions of experts in data science, statistics, and engineering by employing numerical data visualization techniques. The analysis of collected responses reveals that $68.7\%$ of human responses approximately closely align with the values generated by our proposed measures. Based on these findings, our proposed measures may be used as one of the methods for discretizing the numerical attributes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploiting-Latent-Attribute-Interaction-with-Transformer-on-Heterogeneous-Information-Networks"><a href="#Exploiting-Latent-Attribute-Interaction-with-Transformer-on-Heterogeneous-Information-Networks" class="headerlink" title="Exploiting Latent Attribute Interaction with Transformer on Heterogeneous Information Networks"></a>Exploiting Latent Attribute Interaction with Transformer on Heterogeneous Information Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03275">http://arxiv.org/abs/2311.03275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyuan Zhao, Qingqing Ge, Anfeng Cheng, Yiding Liu, Xiang Li, Shuaiqiang Wang</li>
<li>for: 本文提出了一种新的多类Graph Neural Network（HGNN）模型MULAN，用于处理各种不同类型的图像。</li>
<li>methods: 该模型包括两个主要组成部分：一个是具有类型感知的编码器，另一个是具有维度感知的编码器。其中，类型感知编码器使得节点类型信息得到更好地利用，而维度感知编码器可以更好地捕捉不同节点特征之间的隐藏交互。</li>
<li>results: 在六个多类图像 benchmark 数据集上进行了广泛的实验，结果显示 MULAN 在比较其他状态艺术竞争对手的情况下表现出色，并且具有高效性。<details>
<summary>Abstract</summary>
Heterogeneous graph neural networks (HGNNs) have recently shown impressive capability in modeling heterogeneous graphs that are ubiquitous in real-world applications. Due to the diversity of attributes of nodes in different types, most existing models first align nodes by mapping them into the same low-dimensional space. However, in this way, they lose the type information of nodes. In addition, most of them only consider the interactions between nodes while neglecting the high-order information behind the latent interactions among different node features. To address these problems, in this paper, we propose a novel heterogeneous graph model MULAN, including two major components, i.e., a type-aware encoder and a dimension-aware encoder. Specifically, the type-aware encoder compensates for the loss of node type information and better leverages graph heterogeneity in learning node representations. Built upon transformer architecture, the dimension-aware encoder is capable of capturing the latent interactions among the diverse node features. With these components, the information of graph heterogeneity, node features and graph structure can be comprehensively encoded in node representations. We conduct extensive experiments on six heterogeneous benchmark datasets, which demonstrates the superiority of MULAN over other state-of-the-art competitors and also shows that MULAN is efficient.
</details>
<details>
<summary>摘要</summary>
《多型图 neural network（HGNN）》在近期的应用中表现出了很强的能力，用于处理存在多种不同特征的多元图。由于图中节点的特征的多样性，大多数现有模型都会将节点映射到同一个低维度空间中，从而丢失节点类型信息。此外，大多数模型只考虑节点之间的交互，而忽略 latent 交互在不同节点特征之间的高阶信息。为了解决这些问题，本文提出了一种新的多型图模型——MULAN，包括两个主要组成部分：型具感编码器和维度感编码器。具体来说，型具感编码器使得节点类型信息得到更好地利用，并更好地利用图中的多样性来学习节点表示。基于 transformer 架构，维度感编码器可以捕捉不同节点特征之间的 latent 交互。通过这两个组成部分，图中的多样性、节点特征和图结构可以得到全面的编码。我们在六个多元 benchmark 数据集上进行了广泛的实验，并证明了 MULAN 在其他现有竞争对手之上的优越性，并且也表明了 MULAN 的效率。
</details></li>
</ul>
<hr>
<h2 id="Parameter-Agnostic-Optimization-under-Relaxed-Smoothness"><a href="#Parameter-Agnostic-Optimization-under-Relaxed-Smoothness" class="headerlink" title="Parameter-Agnostic Optimization under Relaxed Smoothness"></a>Parameter-Agnostic Optimization under Relaxed Smoothness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03252">http://arxiv.org/abs/2311.03252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian Hübler, Junchi Yang, Xiang Li, Niao He</li>
<li>for: 这个论文的目的是探讨如何在训练机器学习模型时，调整参数的问题。</li>
<li>methods: 这个论文使用了一种名为Normalized Stochastic Gradient Descent with Momentum（NSGD-M）的自适整化算法，并证明了这种算法可以在不需要对问题特定参数进行调整的情况下，实现(近乎)最佳的复杂度。</li>
<li>results: 这个论文的结果显示，NSGD-M 可以在不需要对问题特定参数进行调整的情况下，实现(近乎)最佳的复杂度，并且在决定性设定下，可以消除 exponential 因子。<details>
<summary>Abstract</summary>
Tuning hyperparameters, such as the stepsize, presents a major challenge of training machine learning models. To address this challenge, numerous adaptive optimization algorithms have been developed that achieve near-optimal complexities, even when stepsizes are independent of problem-specific parameters, provided that the loss function is $L$-smooth. However, as the assumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, all existing convergence results still necessitate tuning of the stepsize. In this study, we demonstrate that Normalized Stochastic Gradient Descent with Momentum (NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledge of any problem parameter, though this comes at the cost of introducing an exponential term dependent on $L_1$ in the complexity. We further establish that this exponential term is inevitable to such schemes by introducing a theoretical framework of lower bounds tailored explicitly for parameter-agnostic algorithms. Interestingly, in deterministic settings, the exponential factor can be neutralized by employing Gradient Descent with a Backtracking Line Search. To the best of our knowledge, these findings represent the first parameter-agnostic convergence results under the generalized smoothness condition. Our empirical experiments further confirm our theoretical insights.
</details>
<details>
<summary>摘要</summary>
调整参数（stepsize）是训练机器学习模型的主要挑战。为解决这个挑战，许多自适应优化算法已经发展出来，可以在单一stepsize下 achieve near-optimal complexity，即使loss函数($L$)是$L$-smooth。但是，当假设relaxed to更加现实的 $(L_0, L_1)$-smoothness 时，所有现有的数据�就需要参数调整。在这个研究中，我们证明了Normalized Stochastic Gradient Descent with Momentum（NSGD-M）可以在无需任何问题 Parameters 的情况下 achieve （nearly）rate-optimal complexity，但是这需要付出一个具有 $L_1$ 对应的指数项。我们还证明了这个指数项是不可避免的，通过引入特定 для parameter-agnostic algorithms的理论框架下bounds。在决定性设定下，这个指数项可以被中和，通过使用Gradient Descent with Backtracking Line Search。到目前为止，这些结果是parameter-agnostic convergence的首次结果，我们的实验实践也证实了我们的理论价值。
</details></li>
</ul>
<hr>
<h2 id="Approximating-Langevin-Monte-Carlo-with-ResNet-like-Neural-Network-architectures"><a href="#Approximating-Langevin-Monte-Carlo-with-ResNet-like-Neural-Network-architectures" class="headerlink" title="Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures"></a>Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03242">http://arxiv.org/abs/2311.03242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Eigel, Charles Miranda, Janina Schütte, David Sommer</li>
<li>for: 本文target distribution的样本采样。</li>
<li>methods: 使用基于Langevin Monte Carlo（LMC）算法的神经网络模型采样target distribution的样本。</li>
<li>results: 提供了一种基于LMC各种扰动的神经网络模型，并对这些模型的approximation rate进行了分析，并且提出了一种深度差分神经网络模型，并对这种模型的表达能力进行了分析。In English:</li>
<li>for: Sampling from a target distribution.</li>
<li>methods: Using a neural network model inspired by the Langevin Monte Carlo (LMC) algorithm to sample from the target distribution.</li>
<li>results: Providing a neural network model based on LMC perturbations, and analyzing its approximation rate, as well as proposing a deep residual neural network model and analyzing its expressive power for approximating the sample-to-target distribution map.<details>
<summary>Abstract</summary>
We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target. To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm. Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process. In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations. Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map.
</details>
<details>
<summary>摘要</summary>
我们从一个Target分布中随机抽出样本，通过建立一个对应于一个简单Reference分布，例如标准正常分布，的神经网络。为此，我们提出了一个基于Langevin Monte Carlo（LMC）算法的神经网络架构。通过LMC损害结果，我们显示了我们的架构对于光滑、对数凹陷分布的测试精度。我们的分析强调了中间测度的sub-Gaussian性。具体来说，我们得出了不同干扰假设下的中间方差代理的上升范围。此外，我们提出了一个类似于深度差额神经网络的架构，并 derive了approximation的Result для表示Target分布到样本分布的映射。
</details></li>
</ul>
<hr>
<h2 id="Out-of-distribution-Detection-Learning-with-Unreliable-Out-of-distribution-Sources"><a href="#Out-of-distribution-Detection-Learning-with-Unreliable-Out-of-distribution-Sources" class="headerlink" title="Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources"></a>Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03236">http://arxiv.org/abs/2311.03236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Zheng, Qizhou Wang, Zhen Fang, Xiaobo Xia, Feng Liu, Tongliang Liu, Bo Han</li>
<li>for: 这个研究旨在提高开放世界分类中的可靠性，通过对预测器进行外部数据探测（Out-of-distribution detection），以避免基于ID数据的预测器被误导。</li>
<li>methods: 这个研究使用了数据生成器来生成外部数据，并透过不同的选择程序来找到可能是外部数据的例子。然后，这些生成的外部数据可以用来设计一个辅助的外部数据探测任务，以帮助预测器更好地分辨ID和外部数据。</li>
<li>results: 这个研究的实验结果显示，使用辅助任务来关注 mistaken OOD generation 可以有效地降低预测器的误导率。此外，这个方法在不同的外部数据探测设置下也表现出了优秀的效果。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection discerns OOD data where the predictor cannot make valid predictions as in-distribution (ID) data, thereby increasing the reliability of open-world classification. However, it is typically hard to collect real out-of-distribution (OOD) data for training a predictor capable of discerning ID and OOD patterns. This obstacle gives rise to data generation-based learning methods, synthesizing OOD data via data generators for predictor training without requiring any real OOD data. Related methods typically pre-train a generator on ID data and adopt various selection procedures to find those data likely to be the OOD cases. However, generated data may still coincide with ID semantics, i.e., mistaken OOD generation remains, confusing the predictor between ID and OOD data. To this end, we suggest that generated data (with mistaken OOD generation) can be used to devise an auxiliary OOD detection task to facilitate real OOD detection. Specifically, we can ensure that learning from such an auxiliary task is beneficial if the ID and the OOD parts have disjoint supports, with the help of a well-designed training procedure for the predictor. Accordingly, we propose a powerful data generation-based learning method named Auxiliary Task-based OOD Learning (ATOL) that can relieve the mistaken OOD generation. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.
</details>
<details>
<summary>摘要</summary>
外部数据（OOD）检测可以检测到OOD数据，其中预测器无法对ID数据进行有效预测，从而提高开放世界分类的可靠性。然而，收集真实的OOD数据以用于训练预测器是困难的，这导致了数据生成基于学习方法的出现。这些方法通常是先将生成器训练在ID数据上，然后采用不同的选择方式来找出可能是OOD的数据。然而，生成的数据可能仍与ID semantics相同，即生成的OOD数据可能并不是真正的OOD数据。为此，我们建议使用生成的数据（含有错误的OOD生成）来设置auxiliary OOD检测任务，以便避免 mistaken OOD generation。具体来说，我们可以确保通过这种auxiliary任务的学习对预测器有利，只要ID和OOD部分具有分立的支持，并且通过一种合理的训练程序来训练预测器。因此，我们提出了一种强大的数据生成基于学习方法，名为帮助器任务基本学习（ATOL），可以减少 mistaken OOD generation。我们在不同的OOD检测设置下进行了广泛的实验，并证明了我们的方法与其他先进的方法相比，具有更高的效果。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Process-Approximations-Assessing-Their-Necessity"><a href="#Spatial-Process-Approximations-Assessing-Their-Necessity" class="headerlink" title="Spatial Process Approximations: Assessing Their Necessity"></a>Spatial Process Approximations: Assessing Their Necessity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03201">http://arxiv.org/abs/2311.03201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang</li>
<li>for: 这个论文主要是为了解决大型空间数据中的难以条件矩阵问题，以及相关的预测和最大极值估计问题。</li>
<li>methods: 这篇论文使用了多种优化 критери安和解决方案，包括低矩阵approximation和预测计算中的ill-conditioning问题。</li>
<li>results: 该论文提出了多种优化 критери安和解决方案，以解决大型空间数据中难以条件矩阵问题，并提高了预测和最大极值估计的精度。<details>
<summary>Abstract</summary>
In spatial statistics and machine learning, the kernel matrix plays a pivotal role in prediction, classification, and maximum likelihood estimation. A thorough examination reveals that for large sample sizes, the kernel matrix becomes ill-conditioned, provided the sampling locations are fairly evenly distributed. This condition poses significant challenges to numerical algorithms used in prediction and estimation computations and necessitates an approximation to prediction and the Gaussian likelihood. A review of current methodologies for managing large spatial data indicates that some fail to address this ill-conditioning problem. Such ill-conditioning often results in low-rank approximations of the stochastic processes. This paper introduces various optimality criteria and provides solutions for each.
</details>
<details>
<summary>摘要</summary>
在空间统计学和机器学习中，kernel矩阵在预测、分类和最大可能性估计中扮演着重要的角色。经过仔细检查，当样本大小很大时，kernel矩阵会变得不正见，只要抽取点 Distribution relatively even。这种情况会对数值算法用于预测和估计计算提出 significiant 挑战，并且需要一种简化的预测和高斯可能性函数。现有的大 spatial data 处理方法中有些不能解决这个不正见问题，这经常导致低级别的随机过程的近似。本文介绍了不同的优化性标准和解决方案。
</details></li>
</ul>
<hr>
<h2 id="Stable-Linear-Subspace-Identification-A-Machine-Learning-Approach"><a href="#Stable-Linear-Subspace-Identification-A-Machine-Learning-Approach" class="headerlink" title="Stable Linear Subspace Identification: A Machine Learning Approach"></a>Stable Linear Subspace Identification: A Machine Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03197">http://arxiv.org/abs/2311.03197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Loris Di Natale, Muhammad Zakwan, Bratislav Svetozarevic, Philipp Heer, Giancarlo Ferrari Trecate, Colin N. Jones</li>
<li>for: 这篇论文的目的是提出一种基于机器学习工具的线性系统identification方法，以提高系统预测性能和稳定性。</li>
<li>methods: 该方法使用了自动�ifferentiation框架和Backpropagation算法，并使用了一种新的矩阵不等式来保证模型的稳定性。</li>
<li>results: 实验结果表明，该方法可以在许多输入输出系统上提供更高的预测性能和稳定性，并且在实际数据上也有较好的表现。<details>
<summary>Abstract</summary>
Machine Learning (ML) and linear System Identification (SI) have been historically developed independently. In this paper, we leverage well-established ML tools - especially the automatic differentiation framework - to introduce SIMBa, a family of discrete linear multi-step-ahead state-space SI methods using backpropagation. SIMBa relies on a novel Linear-Matrix-Inequality-based free parametrization of Schur matrices to ensure the stability of the identified model.   We show how SIMBa generally outperforms traditional linear state-space SI methods, and sometimes significantly, although at the price of a higher computational burden. This performance gap is particularly remarkable compared to other SI methods with stability guarantees, where the gain is frequently above 25% in our investigations, hinting at SIMBa's ability to simultaneously achieve state-of-the-art fitting performance and enforce stability. Interestingly, these observations hold for a wide variety of input-output systems and on both simulated and real-world data, showcasing the flexibility of the proposed approach. We postulate that this new SI paradigm presents a great extension potential to identify structured nonlinear models from data, and we hence open-source SIMBa on https://github.com/Cemempamoi/simba.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DeepInception-Hypnotize-Large-Language-Model-to-Be-Jailbreaker"><a href="#DeepInception-Hypnotize-Large-Language-Model-to-Be-Jailbreaker" class="headerlink" title="DeepInception: Hypnotize Large Language Model to Be Jailbreaker"></a>DeepInception: Hypnotize Large Language Model to Be Jailbreaker</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03191">http://arxiv.org/abs/2311.03191</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Li, Zhanke Zhou, Jianing Zhu, Jiangchao Yao, Tongliang Liu, Bo Han</li>
<li>for: This paper aims to disclose a lightweight method to hypnotize large language models (LLMs) and unlock their misusing risks.</li>
<li>methods: The proposed method, called DeepInception, leverages the personification ability of LLMs to construct a novel nested scene and achieve adaptive escapes in a normal scenario, providing the possibility for further direct jailbreaks.</li>
<li>results: The proposed method achieves competitive jailbreak success rates with previous counterparts and realizes a continuous jailbreak in subsequent interactions, revealing the critical weakness of self-losing on both open&#x2F;closed-source LLMs like Falcon, Vicuna, Llama-2, and GPT-3.5&#x2F;4&#x2F;4V.<details>
<summary>Abstract</summary>
Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void. However, previous studies for jailbreaks usually resort to brute-force optimization or extrapolations of a high computation cost, which might not be practical or effective. In this paper, inspired by the Milgram experiment that individuals can harm another person if they are told to do so by an authoritative figure, we disclose a lightweight method, termed as DeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock its misusing risks. Specifically, DeepInception leverages the personification ability of LLM to construct a novel nested scene to behave, which realizes an adaptive way to escape the usage control in a normal scenario and provides the possibility for further direct jailbreaks. Empirically, we conduct comprehensive experiments to show its efficacy. Our DeepInception can achieve competitive jailbreak success rates with previous counterparts and realize a continuous jailbreak in subsequent interactions, which reveals the critical weakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna, Llama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay more attention to the safety aspects of LLMs and a stronger defense against their misuse risks. The code is publicly available at: https://github.com/tmlr-group/DeepInception.
</details>
<details>
<summary>摘要</summary>
尽管大语言模型（LLM）在各种应用场景中表现出色，但它们却易受到黑客突破的威胁，使安全保障失效。然而，之前的研究通常采用粗糙优化或高计算成本的推理方法，可能不实用或效果不佳。在这篇论文中，我们启发自Milgram实验，认为个体可以通过授意而对别人造成伤害。我们披露了一种轻量级的方法，称为DeepInception，可以轻松地使LLM变成黑客，并暴露其不当使用的风险。具体来说，DeepInception利用LLM的人格化能力构建一个新的嵌入式场景，实现了一种适应性的方式逃脱常见的使用控制，并提供了进一步的直接突破的可能性。我们进行了广泛的实验，证明了其效果。我们的DeepInception可以与之前的对手相比，达到竞争的突破成功率，并在后续交互中实现连续突破，揭示了开源/关闭源LLMs like Falcon、Vicuna、Llama-2和GPT-3.5/4/4V的重要弱点。我们的调查表明，需要更多关注LLMs的安全方面，并采取更强的防御措施以避免其不当使用的风险。代码可以在：https://github.com/tmlr-group/DeepInception中下载。
</details></li>
</ul>
<hr>
<h2 id="Preserving-Privacy-in-GANs-Against-Membership-Inference-Attack"><a href="#Preserving-Privacy-in-GANs-Against-Membership-Inference-Attack" class="headerlink" title="Preserving Privacy in GANs Against Membership Inference Attack"></a>Preserving Privacy in GANs Against Membership Inference Attack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03172">http://arxiv.org/abs/2311.03172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadhadi Shateri, Francisco Messina, Fabrice Labeau, Pablo Piantanida</li>
<li>for: 防止Generative Adversarial Networks (GANs)因为过拟合和记忆过程而泄露训练数据的隐私。</li>
<li>methods: 利用 Bhattacharyya 公式定义更一般的过拟合度量，并根据 Fano 不等式提出了一个简单修改 GAN 损失函数的防护机制，并提出了一个基于对生成数据点的资讯泄露实现的另一个防护机制。</li>
<li>results: 实验结果显示，提出的防护机制可以将攻击者的精度降低至随机猜测精度水平，并且仅对生成数据点的质量造成了小量的损失。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) have been widely used for generating synthetic data for cases where there is a limited size real-world dataset or when data holders are unwilling to share their data samples. Recent works showed that GANs, due to overfitting and memorization, might leak information regarding their training data samples. This makes GANs vulnerable to Membership Inference Attacks (MIAs). Several defense strategies have been proposed in the literature to mitigate this privacy issue. Unfortunately, defense strategies based on differential privacy are proven to reduce extensively the quality of the synthetic data points. On the other hand, more recent frameworks such as PrivGAN and PAR-GAN are not suitable for small-size training datasets. In the present work, the overfitting in GANs is studied in terms of the discriminator, and a more general measure of overfitting based on the Bhattacharyya coefficient is defined. Then, inspired by Fano's inequality, our first defense mechanism against MIAs is proposed. This framework, which requires only a simple modification in the loss function of GANs, is referred to as the maximum entropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs. As a second defense strategy, a more heuristic model based on minimizing the information leaked from generated samples about the training data points is presented. This approach is referred to as mutual information minimization GAN (MIMGAN) and uses a variational representation of the mutual information to minimize the information that a synthetic sample might leak about the whole training data set. Applying the proposed frameworks to some commonly used data sets against state-of-the-art MIAs reveals that the proposed methods can reduce the accuracy of the adversaries to the level of random guessing accuracy with a small reduction in the quality of the synthetic data samples.
</details>
<details>
<summary>摘要</summary>
生成对抗网络（GANs）已广泛应用于生成受限实际数据的 sintetic 数据，特别是当实际数据的数量有限或数据持有者不愿分享数据样本时。然而，recent works 表明GANs可能因过拟合和记忆而泄露受训数据样本信息，这使得GANs容易受到会员推理攻击（MIAs）。在文献中，有多种防御策略被提出来 mitigate 这种隐私问题，但是这些策略基于差异隐私会导致 synthetic 数据质量下降 extensively。相反，更新的框架如 PrivGAN 和 PAR-GAN 不适用于小型训练集。在当前的工作中，我们研究了 GANs 中的过拟合问题，并定义了一种基于 Bhattacharyya 系数的更通用的过拟合度量。然后，以 Fano 不等式为 inspiration，我们提出了一种基于最大 entropy 的防御机制， referred to as maximum entropy GAN（MEGAN），该机制可以 Significantly 提高 GANs 对 MIAs 的Robustness。作为第二种防御策略，我们提出了一种基于减少生成样本中对受训数据点的信息泄露的方法， referred to as mutual information minimization GAN（MIMGAN），该方法使用了一种变量表示的 mutual information 来减少生成样本中对整个受训数据集的信息泄露。通过应用我们的方法到一些常用的数据集，我们发现可以将 adversaries 的准确率降低到随机猜测率水平，但是受到一定的质量下降。
</details></li>
</ul>
<hr>
<h2 id="An-Examination-of-the-Alleged-Privacy-Threats-of-Confidence-Ranked-Reconstruction-of-Census-Microdata"><a href="#An-Examination-of-the-Alleged-Privacy-Threats-of-Confidence-Ranked-Reconstruction-of-Census-Microdata" class="headerlink" title="An Examination of the Alleged Privacy Threats of Confidence-Ranked Reconstruction of Census Microdata"></a>An Examination of the Alleged Privacy Threats of Confidence-Ranked Reconstruction of Census Microdata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03171">http://arxiv.org/abs/2311.03171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NajeebJebreel/CRR-analysis">https://github.com/NajeebJebreel/CRR-analysis</a></li>
<li>paper_authors: David Sánchez, Najeeb Jebreel, Josep Domingo-Ferrer, Krishnamurty Muralidhar, Alberto Blanco-Justicia</li>
<li>for: 这项研究的目的是研究美国人口普查局（USCB）在2020年人口普查中使用 differential privacy（DP）来保护个人隐私，并 analyze the effectiveness of this approach.</li>
<li>methods: 这篇论文使用了一种新的恢复攻击，即 confidence-ranked reconstruction，以评估DP的效果。</li>
<li>results: 研究发现， confidence-ranked reconstruction 无法帮助恢复原始数据，而且不能减少个人隐私的风险。此外，由于人口普查数据的编译、处理和发布方式，无法通过任何方法恢复原始和完整的记录。<details>
<summary>Abstract</summary>
The alleged threat of reconstruction attacks has led the U.S. Census Bureau (USCB) to replace in the Decennial Census 2020 the traditional statistical disclosure limitation based on rank swapping with one based on differential privacy (DP). This has resulted in substantial accuracy loss of the released statistics. Worse yet, it has been shown that the reconstruction attacks used as an argument to move to DP are very far from allowing unequivocal reidentification of the respondents, because in general there are a lot of reconstructions compatible with the released statistics. In a very recent paper, a new reconstruction attack has been proposed, whose goal is to indicate the confidence that a reconstructed record was in the original respondent data. The alleged risk of serious disclosure entailed by such confidence-ranked reconstruction has renewed the interest of the USCB to use DP-based solutions. To forestall the potential accuracy loss in future data releases resulting from adoption of these solutions, we show in this paper that the proposed confidence-ranked reconstruction does not threaten privacy. Specifically, we report empirical results showing that the proposed ranking cannot guide reidentification or attribute disclosure attacks, and hence it fails to warrant the USCB's move towards DP. Further, we also demonstrate that, due to the way the Census data are compiled, processed and released, it is not possible to reconstruct original and complete records through any methodology, and the confidence-ranked reconstruction not only is completely ineffective at accurately reconstructing Census records but is trivially outperformed by an adequate interpretation of the released aggregate statistics.
</details>
<details>
<summary>摘要</summary>
美国人口普查局（USCB）在2020年人口普查中取代了传统的统计隐私技术，改用分Difficulty Privacy（DP）。这导致了发布统计数据的精度下降。另外，已经证明了使用DP来保护个人隐私的理由是非常远Erroneous，因为在一般情况下，有许多可能的重建，与发布统计数据相符。在最近的一篇论文中，一种新的重建攻击被提出，其目的是指示重建记录是否在原始回应数据中。美国人口普查局对这种风险的严重性表示了 renewed 的兴趣。为防止未来数据释放中可能出现的精度下降，我们在这篇论文中证明了提posed confidence-ranked reconstruction 不会威胁隐私。具体来说，我们发现这种排名无法引导个人销露或特性销露攻击，因此无法证明USCB的转移是合理的。此外，我们还证明了由于人口普查数据的编译、处理和发布方式，无法通过任何方法重建原始和完整的记录， confidence-ranked reconstruction 不仅是无法准确重建人口普查记录，而且是与解释发布统计数据的合理解释相比，极其无效。
</details></li>
</ul>
<hr>
<h2 id="Convergence-Analysis-of-Sequential-Federated-Learning-on-Heterogeneous-Data"><a href="#Convergence-Analysis-of-Sequential-Federated-Learning-on-Heterogeneous-Data" class="headerlink" title="Convergence Analysis of Sequential Federated Learning on Heterogeneous Data"></a>Convergence Analysis of Sequential Federated Learning on Heterogeneous Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03154">http://arxiv.org/abs/2311.03154</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liyipeng00/convergence">https://github.com/liyipeng00/convergence</a></li>
<li>paper_authors: Yipeng Li, Xinchen Lyu</li>
<li>for: 这种研究探讨了 Federated Learning（FL）中多个客户端共同训练的方法，特别是并行FL（PFL）和顺序FL（SFL）两种方法的比较。</li>
<li>methods: 这种研究使用了 SFL 方法，并提供了对异质数据的整合理论保证。</li>
<li>results: 实验结果表明，SFL 在异质数据上的性能比 PFL 更好，尤其是在跨设备的情况下。<details>
<summary>Abstract</summary>
There are two categories of methods in Federated Learning (FL) for joint training across multiple clients: i) parallel FL (PFL), where clients train models in a parallel manner; and ii) sequential FL (SFL), where clients train models in a sequential manner. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. In this paper, we establish the convergence guarantees of SFL for strongly/general/non-convex objectives on heterogeneous data. The convergence guarantees of SFL are better than that of PFL on heterogeneous data with both full and partial client participation. Experimental results validate the counterintuitive analysis result that SFL outperforms PFL on extremely heterogeneous data in cross-device settings.
</details>
<details>
<summary>摘要</summary>
在联合学习（Federated Learning，FL）中，有两类方法可以进行客户端之间的共同训练：一是并行联合学习（Parallel Federated Learning，PFL），即客户端在平行方式进行模型训练；另一是顺序联合学习（Sequential Federated Learning，SFL），即客户端在顺序方式进行模型训练。相比之下，SFL在不同数据上的收敛理论仍然缺失。在这篇论文中，我们建立了SFL在强不同数据上的收敛保证，并且比PFL在不同数据上的收敛保证更好。实验结果证明了我们的分析结果，即SFL在很大不同数据上超过PFL的性能。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Material-Thermal-Conductivity-Prediction-through-Machine-Learning"><a href="#End-to-end-Material-Thermal-Conductivity-Prediction-through-Machine-Learning" class="headerlink" title="End-to-end Material Thermal Conductivity Prediction through Machine Learning"></a>End-to-end Material Thermal Conductivity Prediction through Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03139">http://arxiv.org/abs/2311.03139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yagyank Srivastava, Ankit Jain</li>
<li>for: 预测材料热导率的加速</li>
<li>methods: 使用机器学习方法和结构基本方法</li>
<li>results: 所有机器学习模型受到过拟合问题，最佳 mean absolute percentage error 在考试集上保持在 50-60% 之间<details>
<summary>Abstract</summary>
We investigated the accelerated prediction of the thermal conductivity of materials through end- to-end structure-based approaches employing machine learning methods. Due to the non-availability of high-quality thermal conductivity data, we first performed high-throughput calculations based on first principles and the Boltzmann transport equation for 225 materials, effectively more than doubling the size of the existing dataset. We assessed the performance of state-of-the-art machine learning models for thermal conductivity prediction on this expanded dataset and observed that all these models suffered from overfitting. To address this issue, we introduced a novel graph-based neural network model, which demonstrated more consistent and regularized performance across all evaluated datasets. Nevertheless, the best mean absolute percentage error achieved on the test dataset remained in the range of 50-60%. This suggests that while these models are valuable for expediting material screening, their current accuracy is still limited.
</details>
<details>
<summary>摘要</summary>
我们调查了通过终端结构基于方法预测材料热导率的加速方法，使用机器学习技术。由于热导率数据的可用性不足，我们首先基于原理和博尔ツ曼传输方程进行了225种材料的高通过率计算，实际上大于了现有数据集的两倍。我们评估了现有的机器学习模型在扩展的数据集上的性能，发现所有这些模型都存在过拟合问题。为解决这个问题，我们提出了一种图形基于神经网络模型，该模型在所有评估数据集上表现了更一致和规则的性能。然而，在测试数据集上最佳的绝对百分数误差仍然在50-60%的范围内，这表明虽然这些模型对物质屏选具有价值，但其当前精度仍有限。
</details></li>
</ul>
<hr>
<h2 id="Reservoir-Computing-Model-for-Mapping-and-Forecasting-Neuronal-Interactions-from-Electrophysiological-Data"><a href="#Reservoir-Computing-Model-for-Mapping-and-Forecasting-Neuronal-Interactions-from-Electrophysiological-Data" class="headerlink" title="Reservoir-Computing Model for Mapping and Forecasting Neuronal Interactions from Electrophysiological Data"></a>Reservoir-Computing Model for Mapping and Forecasting Neuronal Interactions from Electrophysiological Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03131">http://arxiv.org/abs/2311.03131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilya Auslender, Giorgio Letti, Yasaman Heydari, Lorenzo Pavesi</li>
<li>for: 这个论文的目的是描述神经网络的电生物学特性，以探索不同单元之间的互动。</li>
<li>methods: 这篇论文使用了基于储存计算网络（RCN）架构的计算模型，将电生物学测量数据解码为神经网络的结构，并在大规模域上重建神经网络的连接性。</li>
<li>results: 模型可以准确地预测神经网络的连接图，并且在实验中能够预测特定输入的网络响应。<details>
<summary>Abstract</summary>
Electrophysiological nature of neuronal networks allows to reveal various interactions between different cell units at a very short time-scales. One of the many challenges in analyzing these signals is to retrieve the morphology and functionality of a given network. In this work we developed a computational model, based on Reservoir Computing Network (RCN) architecture, which decodes the spatio-temporal data from electro-physiological measurements of neuronal cultures and reconstructs the network structure on a macroscopic domain, representing the connectivity between neuronal units. We demonstrate that the model can predict the connectivity map of the network with higher accuracy than the common methods such as Cross-Correlation and Transfer-Entropy. In addition, we experimentally demonstrate the ability of the model to predict a network response to a specific input, such as localized stimulus.
</details>
<details>
<summary>摘要</summary>
electrophysiological nature of neuronal networks allows to reveal various interactions between different cell units at a very short time-scales. One of the many challenges in analyzing these signals is to retrieve the morphology and functionality of a given network. In this work we developed a computational model, based on Reservoir Computing Network (RCN) architecture, which decodes the spatio-temporal data from electro-physiological measurements of neuronal cultures and reconstructs the network structure on a macroscopic domain, representing the connectivity between neuronal units. We demonstrate that the model can predict the connectivity map of the network with higher accuracy than the common methods such as Cross-Correlation and Transfer-Entropy. In addition, we experimentally demonstrate the ability of the model to predict a network response to a specific input, such as localized stimulus.Here's the text with some notes on the translation:* "electrophysiological" is translated as "电生物学的" (dian xiang wu xue de), which is a combination of "电" (dian) meaning "electro-" and "生物学" (xiang wu xue) meaning "biological".* "nature" is translated as "性质" (xing zhi), which is a more general term that can refer to the inherent properties or characteristics of something.* "various interactions" is translated as "多种交互" (duo zhong jia xi), which is a more literal translation of the original phrase.* "at a very short time-scales" is translated as "在非常短时间尺度上" (zai bian chang duan shi zhong de), which is a more literal translation of the original phrase.* "morphology" is translated as "形态" (xíng fǎ), which is a more general term that can refer to the shape or structure of something.* " functionality" is translated as "功能" (gōng néng), which is a more general term that can refer to the ability of something to perform a particular task or function.* "a given network" is translated as "一个给定的网络" (yī gè gěi dìng de wǎng luo), which is a more literal translation of the original phrase.* "decodes" is translated as "解码" (jiě mǎ), which is a more literal translation of the original phrase.* "spatio-temporal data" is translated as "空间-时间数据" (kōng jiān-shí zhāng data), which is a more literal translation of the original phrase.* "reconstructs" is translated as "重建" (zhòng jiàn), which is a more literal translation of the original phrase.* "representing the connectivity between neuronal units" is translated as "表示神经元之间的连接" (biǎo xiǎng jīn yī jīn de lián qiān), which is a more literal translation of the original phrase.* "common methods" is translated as "常用方法" (cháng yòu fāng fǎ), which is a more literal translation of the original phrase.* "such as Cross-Correlation and Transfer-Entropy" is translated as "如十字相关和传输熵" (rú shí zì xiāng yì yǔ chuán xiū), which is a more literal translation of the original phrase.* "in addition" is translated as "另外" (qie wai), which is a more literal translation of the original phrase.* "experimentally demonstrate" is translated as "实验证明" (shí yàn zhèng ming), which is a more literal translation of the original phrase.* "a network response to a specific input" is translated as "一个网络对特定输入的响应" (yī gè wǎng luo duì tè qīng yù xīn de fāng zhì), which is a more literal translation of the original phrase.
</details></li>
</ul>
<hr>
<h2 id="Nonparametric-modeling-of-the-composite-effect-of-multiple-nutrients-on-blood-glucose-dynamics"><a href="#Nonparametric-modeling-of-the-composite-effect-of-multiple-nutrients-on-blood-glucose-dynamics" class="headerlink" title="Nonparametric modeling of the composite effect of multiple nutrients on blood glucose dynamics"></a>Nonparametric modeling of the composite effect of multiple nutrients on blood glucose dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03129">http://arxiv.org/abs/2311.03129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arina Odnoblyudova, Çağlar Hizli, ST John, Andrea Cognolato, Anne Juuti, Simo Särkkä, Kirsi Pietiläinen, Pekka Marttinen</li>
<li>for: 这 paper 是为了研究多组分治疗的生物医学应答问题，并且分离各组分的效果以及它们之间的共同效果。</li>
<li>methods: 这 paper 使用了扩展的概率非 Parametric 方法，以及一种新的卷积基本模型来描述复合治疗响应曲线，这种模型更加生物学上可解释。</li>
<li>results: 通过对碳水化合物和脂肪在餐食中的影响来预测血糖响应，这种方法可以更好地预测血糖响应，并且可以分离各组分的效果，从而更好地理解碳水化合物和脂肪在血糖响应中的不同作用。<details>
<summary>Abstract</summary>
In biomedical applications it is often necessary to estimate a physiological response to a treatment consisting of multiple components, and learn the separate effects of the components in addition to the joint effect. Here, we extend existing probabilistic nonparametric approaches to explicitly address this problem. We also develop a new convolution-based model for composite treatment-response curves that is more biologically interpretable. We validate our models by estimating the impact of carbohydrate and fat in meals on blood glucose. By differentiating treatment components, incorporating their dosages, and sharing statistical information across patients via a hierarchical multi-output Gaussian process, our method improves prediction accuracy over existing approaches, and allows us to interpret the different effects of carbohydrates and fat on the overall glucose response.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在生物医学应用中，经常需要估算治疗包含多个组成部分的生物学响应，并了解每个组成部分的分离效果以及共同效果。我们在这里扩展现有的概率非Parametric方法，以解决这个问题。我们还开发了一种基于核函数的复合治疗响应曲线模型，这种模型更易于生物学上 интерпретирова。我们验证了我们的模型，通过估计葡萄糖和脂肪在饭菜中的影响，对血糖响应进行了预测。通过强制对治疗组成部分进行分化、包括剂量，以及通过患者间共享数据via层次多输出 Gaussian process，我们的方法可以提高预测精度，并允许我们解释葡萄糖和脂肪对全体血糖响应的不同效果。
</details></li>
</ul>
<hr>
<h2 id="Algebraic-Dynamical-Systems-in-Machine-Learning"><a href="#Algebraic-Dynamical-Systems-in-Machine-Learning" class="headerlink" title="Algebraic Dynamical Systems in Machine Learning"></a>Algebraic Dynamical Systems in Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03118">http://arxiv.org/abs/2311.03118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iolo Jones, Jerry Swan, Jeffrey Giansiracusa</li>
<li>for: 这篇论文是为了描述一种基于表示重写的动态系统的数学 аналоги，以及将这些模型应用于动态机器学习模型中。</li>
<li>methods: 论文使用了一种 recursively应用于生成器的方法，以定义一种 formal class of models，这些模型包括了回归神经网络、图 neural networks 和扩散模型等。</li>
<li>results: 论文表明了这些数学模型可以用于描述动态模型的复合性，并提出了一种将这些模型应用于学习 Structured or non-numerical data 的方法。<details>
<summary>Abstract</summary>
We introduce an algebraic analogue of dynamical systems, based on term rewriting. We show that a recursive function applied to the output of an iterated rewriting system defines a formal class of models into which all the main architectures for dynamic machine learning models (including recurrent neural networks, graph neural networks, and diffusion models) can be embedded. Considered in category theory, we also show that these algebraic models are a natural language for describing the compositionality of dynamic models. Furthermore, we propose that these models provide a template for the generalisation of the above dynamic models to learning problems on structured or non-numerical data, including 'hybrid symbolic-numeric' models.
</details>
<details>
<summary>摘要</summary>
我们介绍一个数学 аналогDynamic Systems，基于字串重写。我们显示了一个递律函数，应用到迭代重写系统的输出，定义了一个正式的模型类别，可以包含所有主要的动态机器学习模型（包括循环神经网络、图像神经网络和扩散模型）。在category theory中考虑，这些数学模型也是描述动态模型的自然语言。此外，我们建议这些模型可以提供一个泛化动态模型的模板，包括 'hybrid symbolic-numeric' 模型。Note: "数学 аналог" is short for "mathematical analogue" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="RELand-Risk-Estimation-of-Landmines-via-Interpretable-Invariant-Risk-Minimization"><a href="#RELand-Risk-Estimation-of-Landmines-via-Interpretable-Invariant-Risk-Minimization" class="headerlink" title="RELand: Risk Estimation of Landmines via Interpretable Invariant Risk Minimization"></a>RELand: Risk Estimation of Landmines via Interpretable Invariant Risk Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03115">http://arxiv.org/abs/2311.03115</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mateo Dulce Rubio, Siqi Zeng, Qi Wang, Didier Alvarado, Francisco Moreno, Hoda Heidari, Fei Fang</li>
<li>for: 这篇论文是为了提供一个支持人道主义除雷工作的系统，帮助解决受战争影响的社区中的雷区问题。</li>
<li>methods: 该系统由三个主要组成部分：（1）提供一般特征工程和标签分配指南，以提高雷区风险模型建模的数据集，这些指南适用于全球除雷工作 Routine;（2）将雷mine存在视为一个分类问题，设计了一种新的可读性模型，基于稀缺特征掩码和不变风险最小化，并在合理的协议下进行了广泛的评估，以示与现有技术相比有显著提高;（3）建立了一个交互式网页界面，以建议除雷组织在哪些区域进行清理。</li>
<li>results: 该系统在实际场景中的评估中表现出色，比现有技术有显著提高。现正与一家人道主义除雷NGO在哥伦比亚合作，使用我们的系统进行场景评估。<details>
<summary>Abstract</summary>
Landmines remain a threat to war-affected communities for years after conflicts have ended, partly due to the laborious nature of demining tasks. Humanitarian demining operations begin by collecting relevant information from the sites to be cleared, which is then analyzed by human experts to determine the potential risk of remaining landmines. In this paper, we propose RELand system to support these tasks, which consists of three major components. We (1) provide general feature engineering and label assigning guidelines to enhance datasets for landmine risk modeling, which are widely applicable to global demining routines, (2) formulate landmine presence as a classification problem and design a novel interpretable model based on sparse feature masking and invariant risk minimization, and run extensive evaluation under proper protocols that resemble real-world demining operations to show a significant improvement over the state-of-the-art, and (3) build an interactive web interface to suggest priority areas for demining organizations. We are currently collaborating with a humanitarian demining NGO in Colombia that is using our system as part of their field operations in two areas recently prioritized for demining.
</details>
<details>
<summary>摘要</summary>
Landmines continue to pose a threat to communities affected by war long after conflicts have ended, in part due to the laborious nature of demining tasks. Humanitarian demining operations begin by gathering relevant information from the sites to be cleared, which is then analyzed by human experts to determine the potential risk of remaining landmines. In this paper, we propose the REland system to support these tasks, which consists of three major components. We (1) provide general feature engineering and label assigning guidelines to enhance datasets for landmine risk modeling, which are widely applicable to global demining routines, (2) formulate landmine presence as a classification problem and design a novel interpretable model based on sparse feature masking and invariant risk minimization, and run extensive evaluation under proper protocols that resemble real-world demining operations to show a significant improvement over the state-of-the-art, and (3) build an interactive web interface to suggest priority areas for demining organizations. We are currently collaborating with a humanitarian demining NGO in Colombia that is using our system as part of their field operations in two areas recently prioritized for demining.Here's the translation in Traditional Chinese:Landmines continue to pose a threat to communities affected by war long after conflicts have ended, in part due to the laborious nature of demining tasks. Humanitarian demining operations begin by gathering relevant information from the sites to be cleared, which is then analyzed by human experts to determine the potential risk of remaining landmines. In this paper, we propose the REland system to support these tasks, which consists of three major components. We (1) provide general feature engineering and label assigning guidelines to enhance datasets for landmine risk modeling, which are widely applicable to global demining routines, (2) formulate landmine presence as a classification problem and design a novel interpretable model based on sparse feature masking and invariant risk minimization, and run extensive evaluation under proper protocols that resemble real-world demining operations to show a significant improvement over the state-of-the-art, and (3) build an interactive web interface to suggest priority areas for demining organizations. We are currently collaborating with a humanitarian demining NGO in Colombia that is using our system as part of their field operations in two areas recently prioritized for demining.
</details></li>
</ul>
<hr>
<h2 id="Weight-Sharing-Regularization"><a href="#Weight-Sharing-Regularization" class="headerlink" title="Weight-Sharing Regularization"></a>Weight-Sharing Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03096">http://arxiv.org/abs/2311.03096</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cliang1453/CAMERO">https://github.com/cliang1453/CAMERO</a></li>
<li>paper_authors: Mehran Shakerinava, Motahareh Sohrabi, Siamak Ravanbakhsh, Simon Lacoste-Julien</li>
<li>for: 这篇论文旨在介绍一种深度学习中的’’重量共享规则’’，用于防止模型参数之间的重复。</li>
<li>methods: 论文使用了一种新的并行算法来实现’’ proximal mapping’’，并提供了一种基于物理系统的启发式解释。</li>
<li>results: 实验表明，使用’’重量共享规则’’可以让全连接网络学习类似于 convolution 的滤波器。<details>
<summary>Abstract</summary>
Weight-sharing is ubiquitous in deep learning. Motivated by this, we introduce ''weight-sharing regularization'' for neural networks, defined as $R(w) = \frac{1}{d - 1}\sum_{i > j}^d |w_i - w_j|$. We study the proximal mapping of $R$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. Using this interpretation, we design a novel parallel algorithm for $\operatorname{prox}_R$ which provides an exponential speedup over previous algorithms, with a depth of $O(\log^3 d)$. Our algorithm makes it feasible to train weight-sharing regularized deep neural networks with proximal gradient descent. Experiments reveal that weight-sharing regularization enables fully-connected networks to learn convolution-like filters.
</details>
<details>
<summary>摘要</summary>
深度学习中的权重共享是普遍存在的。我们为深度神经网络引入了“权重共享规则”，定义为 $R(w) = \frac{1}{d-1} \sum_{i > j}^d |w_i - w_j|$。我们研究了$R$的 proximal mapping，并提供了一种物理系统中的交互 particel 的直观解释。使用这种解释，我们设计了一种新的并行算法，提供了 exponential 速度提升， depth 为 $O(\log^3 d)$。我们的算法使得可以使用 proximal 梯度下降来训练权重共享规则的深度神经网络。实验表明，权重共享规则使得全连接网络学习类似于 convolution 的筛子。Here's the breakdown of the translation:* 深度学习 (deep learning) becomes 深度学习 (deep learning)* 权重共享 (weight sharing) becomes 权重共享 (weight sharing)* Motivated by this, we introduce ''weight-sharing regularization'' for neural networks, defined as $R(w) = \frac{1}{d - 1}\sum_{i > j}^d |w_i - w_j|$. becomes 以此为动机，我们为神经网络引入了“权重共享规则”，定义为 $R(w) = \frac{1}{d-1} \sum_{i > j}^d |w_i - w_j|$。* We study the proximal mapping of $R$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. becomes 我们研究了$R$的 proximal mapping，并提供了一种物理系统中的交互 particel 的直观解释。* Using this interpretation, we design a novel parallel algorithm for $\operatorname{prox}_R$ which provides an exponential speedup over previous algorithms, with a depth of $O(\log^3 d)$. becomes 使用这种解释，我们设计了一种新的并行算法，提供了 exponential 速度提升， depth 为 $O(\log^3 d)$。* Our algorithm makes it feasible to train weight-sharing regularized deep neural networks with proximal gradient descent. becomes 我们的算法使得可以使用 proximal 梯度下降来训练权重共享规则的深度神经网络。* Experiments reveal that weight-sharing regularization enables fully-connected networks to learn convolution-like filters. becomes 实验表明，权重共享规则使得全连接网络学习类似于 convolution 的筛子。
</details></li>
</ul>
<hr>
<h2 id="Equivariance-Is-Not-All-You-Need-Characterizing-the-Utility-of-Equivariant-Graph-Neural-Networks-for-Particle-Physics-Tasks"><a href="#Equivariance-Is-Not-All-You-Need-Characterizing-the-Utility-of-Equivariant-Graph-Neural-Networks-for-Particle-Physics-Tasks" class="headerlink" title="Equivariance Is Not All You Need: Characterizing the Utility of Equivariant Graph Neural Networks for Particle Physics Tasks"></a>Equivariance Is Not All You Need: Characterizing the Utility of Equivariant Graph Neural Networks for Particle Physics Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03094">http://arxiv.org/abs/2311.03094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Savannah Thais, Daniel Murnane</li>
<li>for: 这篇论文是为了评估具有Symmetry的机器学习模型（Equivariant Graph Neural Networks）在物理数据上的性能而写的。</li>
<li>methods: 这篇论文使用了现有的group equivariant networks文献中的方法，并对实际的 particle physics reconstruction任务进行了评估。</li>
<li>results: 研究发现，许多理论上associated with equivariant networks的优点may not hold for realistic systems，并提出了未来研究的有优点的方向。<details>
<summary>Abstract</summary>
Incorporating inductive biases into ML models is an active area of ML research, especially when ML models are applied to data about the physical world. Equivariant Graph Neural Networks (GNNs) have recently become a popular method for learning from physics data because they directly incorporate the symmetries of the underlying physical system. Drawing from the relevant literature around group equivariant networks, this paper presents a comprehensive evaluation of the proposed benefits of equivariant GNNs by using real-world particle physics reconstruction tasks as an evaluation test-bed. We demonstrate that many of the theoretical benefits generally associated with equivariant networks may not hold for realistic systems and introduce compelling directions for future research that will benefit both the scientific theory of ML and physics applications.
</details>
<details>
<summary>摘要</summary>
将对物理世界数据的机器学习模型 incorporate 了推动性假设是一个活跃的机器学习研究领域，特别是在对物理数据进行学习时。 恒等图像神经网络（Equivariant Graph Neural Networks，GNNs）在最近几年内成为了对物理数据进行学习的广泛方法，因为它们直接将物理系统中的 symmetries 组入模型中。 根据相关的文献中的group equivariant networks，本文提供了广泛的评估Equivariant GNNs的提案的好处，使用实际的粒子物理重建任务作为评估测试床。 我们展示了许多理论上 associate 的优点通常不适用于实际系统，并提出了吸引人的未来研究方向，将帮助机器学习理论和物理应用之间的交流。
</details></li>
</ul>
<hr>
<h2 id="Persistent-homology-for-high-dimensional-data-based-on-spectral-methods"><a href="#Persistent-homology-for-high-dimensional-data-based-on-spectral-methods" class="headerlink" title="Persistent homology for high-dimensional data based on spectral methods"></a>Persistent homology for high-dimensional data based on spectral methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03087">http://arxiv.org/abs/2311.03087</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/berenslab/eff-ph">https://github.com/berenslab/eff-ph</a></li>
<li>paper_authors: Sebastian Damrich, Philipp Berens, Dmitry Kobak<br>for: 这个论文的目的是检测点云中的非凡多重 topologic 结构，如循环或空洞。methods: 这个论文使用的方法包括常见的 persistent homology 以及其他修改，但是在实际世界的 datasets 中，这些方法会受到高维度的噪声影响，导致错误的检测结果。results: 这个论文的结果表明，使用 $k$-nearest-neighbor 图的 спектраль距离，如扩散距离和有效抗抗异常，可以使 persistent homology 具有更高的抗噪声性，并且可以正确地检测单元细胞中的循环结构。<details>
<summary>Abstract</summary>
Persistent homology is a popular computational tool for detecting non-trivial topology of point clouds, such as the presence of loops or voids. However, many real-world datasets with low intrinsic dimensionality reside in an ambient space of much higher dimensionality. We show that in this case vanilla persistent homology becomes very sensitive to noise and fails to detect the correct topology. The same holds true for most existing refinements of persistent homology. As a remedy, we find that spectral distances on the $k$-nearest-neighbor graph of the data, such as diffusion distance and effective resistance, allow persistent homology to detect the correct topology even in the presence of high-dimensional noise. Furthermore, we derive a novel closed-form expression for effective resistance in terms of the eigendecomposition of the graph Laplacian, and describe its relation to diffusion distances. Finally, we apply these methods to several high-dimensional single-cell RNA-sequencing datasets and show that spectral distances on the $k$-nearest-neighbor graph allow robust detection of cell cycle loops.
</details>
<details>
<summary>摘要</summary>
“坚持性 homology 是一种广泛使用的计算工具，用于检测点云的非тривиiale topology，如循环或空隙。然而，许多实际世界数据具有低内在维度，但它们实际上生活在一个 much higher 维度的 ambient 空间中。我们发现在这种情况下，普通的坚持 homology 会受到噪声的影响，无法正确地检测 topology。同样，大多数现有的 persistent homology 的改进方法也不能恢复 Correct topology。为了解决这个问题，我们发现 spectral distances on the $k$-nearest-neighbor graph of the data, such as diffusion distance and effective resistance, allow persistent homology to detect the correct topology even in the presence of high-dimensional noise. 此外，我们还derive a novel closed-form expression for effective resistance in terms of the eigendecomposition of the graph Laplacian, and describe its relation to diffusion distances。最后，我们将这些方法应用到several high-dimensional single-cell RNA-sequencing datasets，并显示了spectral distances on the $k$-nearest-neighbor graph allow robust detection of cell cycle loops。”Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Quantifying-the-value-of-information-transfer-in-population-based-SHM"><a href="#Quantifying-the-value-of-information-transfer-in-population-based-SHM" class="headerlink" title="Quantifying the value of information transfer in population-based SHM"></a>Quantifying the value of information transfer in population-based SHM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03083">http://arxiv.org/abs/2311.03083</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aidan J. Hughes, Jack Poole, Nikolaos Dervilis, Paul Gardner, Keith Worden</li>
<li>for: 本研究旨在提出一种基于人口的结构健康监测（PBSHM）中的数据共享技术，以提高预测模型的准确性。</li>
<li>methods: 本研究使用了域适应技术，如领域转移，来共享结构之间的信息，以提高预测模型的性能。</li>
<li>results: 研究表明，基于模式保证准则的结构相似性指标可以用于预测结构的分类性能，并且可以通过计算期望值信息传输来决定数据共享的时机、内容和方式。<details>
<summary>Abstract</summary>
Population-based structural health monitoring (PBSHM), seeks to address some of the limitations associated with data scarcity that arise in traditional SHM. A tenet of the population-based approach to SHM is that information can be shared between sufficiently-similar structures in order to improve predictive models. Transfer learning techniques, such as domain adaptation, have been shown to be a highly-useful technology for sharing information between structures when developing statistical classifiers for PBSHM. Nonetheless, transfer-learning techniques are not without their pitfalls. In some circumstances, for example if the data distributions associated with the structures within a population are dissimilar, applying transfer-learning methods can be detrimental to classification performance -- this phenomenon is known as negative transfer. Given the potentially-severe consequences of negative transfer, it is prudent for engineers to ask the question `when, what, and how should one transfer between structures?'.   The current paper aims to demonstrate a transfer-strategy decision process for a classification task for a population of simulated structures in the context of a representative SHM maintenance problem, supported by domain adaptation. The transfer decision framework is based upon the concept of expected value of information transfer. In order to compute the expected value of information transfer, predictions must be made regarding the classification (and decision performance) in the target domain following information transfer. In order to forecast the outcome of transfers, a probabilistic regression is used here to predict classification performance from a proxy for structural similarity based on the modal assurance criterion.
</details>
<details>
<summary>摘要</summary>
Population-based结构健康监测（PBSHM）想要解决传统结构健康监测中的数据缺乏问题。PBSHM的一个基本思想是，在相似的结构之间共享信息，以改进预测模型。但是，转移学习技术不是无缺点的。在某些情况下，如果结构内部的数据分布不同， then applying transfer learning methods can be detrimental to classification performance -- this phenomenon is known as negative transfer.因此，工程师需要问到“何时、何种、如何进行转移？”。本文旨在提出一种转移策略决策过程，用于一个代表性的维保问题中的分类任务。该转移决策框架基于对信息传递的预期值。为计算预期值传递信息，需要对目标领域中的分类表现进行预测。为了预测转移的结果，这里使用了一种概率回归，以预测基于模式保证准则的结构相似度。
</details></li>
</ul>
<hr>
<h2 id="SoK-Memorisation-in-machine-learning"><a href="#SoK-Memorisation-in-machine-learning" class="headerlink" title="SoK: Memorisation in machine learning"></a>SoK: Memorisation in machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03075">http://arxiv.org/abs/2311.03075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dmitrii Usynin, Moritz Knolle, Georgios Kaissis</li>
<li>for: 本研究旨在探讨机器学习模型中个体数据样本的影响，特别是在深度学习中，即使只有有限的数据生成分布来学习复杂高维关系。</li>
<li>methods: 本研究使用了多种方法来检测和衡量机器学习模型中的记忆现象，包括模型泛化性、记忆度量和隐私性等方面的分析。</li>
<li>results: 研究发现，机器学习模型在学习过程中会具有一定的记忆性，这会影响模型的泛化性和隐私性。此外，研究还提出了一些方法来检测和衡量记忆现象，以及在隐私攻击、权威隐私和对抗攻击等场景中的应用。<details>
<summary>Abstract</summary>
Quantifying the impact of individual data samples on machine learning models is an open research problem. This is particularly relevant when complex and high-dimensional relationships have to be learned from a limited sample of the data generating distribution, such as in deep learning. It was previously shown that, in these cases, models rely not only on extracting patterns which are helpful for generalisation, but also seem to be required to incorporate some of the training data more or less as is, in a process often termed memorisation. This raises the question: if some memorisation is a requirement for effective learning, what are its privacy implications? In this work we unify a broad range of previous definitions and perspectives on memorisation in ML, discuss their interplay with model generalisation and their implications of these phenomena on data privacy. Moreover, we systematise methods allowing practitioners to detect the occurrence of memorisation or quantify it and contextualise our findings in a broad range of ML learning settings. Finally, we discuss memorisation in the context of privacy attacks, differential privacy (DP) and adversarial actors.
</details>
<details>
<summary>摘要</summary>
量化机器学习模型中个别数据样本的影响是一个开放的研究问题。这pecially relevant when complex and high-dimensional relationships need to be learned from a limited sample of the data generating distribution, such as in deep learning. Previous studies have shown that in these cases, models not only extract helpful patterns for generalization, but also seem to incorporate some of the training data "as is" in a process often termed memorization. This raises the question: if some memorization is a requirement for effective learning, what are its privacy implications? In this work, we unify a broad range of previous definitions and perspectives on memorization in machine learning (ML), discuss their interplay with model generalization, and their implications for data privacy. Moreover, we systematize methods allowing practitioners to detect the occurrence of memorization or quantify it, and contextualize our findings in a broad range of ML learning settings. Finally, we discuss memorization in the context of privacy attacks, differential privacy (DP), and adversarial actors.
</details></li>
</ul>
<hr>
<h2 id="Imaging-through-multimode-fibres-with-physical-prior"><a href="#Imaging-through-multimode-fibres-with-physical-prior" class="headerlink" title="Imaging through multimode fibres with physical prior"></a>Imaging through multimode fibres with physical prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03062">http://arxiv.org/abs/2311.03062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuncheng Zhang, Yingjie Shi, Zheyi Yao, Xiubao Sui, Qian Cheng</li>
<li>for: 这个论文旨在提出一种无监督学习基于光纤成像的方法，用于重构目标图像。</li>
<li>methods: 该方法使用物理优化的方法和深度学习网络，以减少计算复杂性并提高重构的精度。</li>
<li>results: 该方法可以在在线学习模式下，只需要几个折射模式和无标签目标图像，就能够重构高质量的目标图像。这种方法还提高了学习基于光纤成像的方法的通用能力。<details>
<summary>Abstract</summary>
Imaging through perturbed multimode fibres based on deep learning has been widely researched. However, existing methods mainly use target-speckle pairs in different configurations. It is challenging to reconstruct targets without trained networks. In this paper, we propose a physics-assisted, unsupervised, learning-based fibre imaging scheme. The role of the physical prior is to simplify the mapping relationship between the speckle pattern and the target image, thereby reducing the computational complexity. The unsupervised network learns target features according to the optimized direction provided by the physical prior. Therefore, the reconstruction process of the online learning only requires a few speckle patterns and unpaired targets. The proposed scheme also increases the generalization ability of the learning-based method in perturbed multimode fibres. Our scheme has the potential to extend the application of multimode fibre imaging.
</details>
<details>
<summary>摘要</summary>
对于受扰多模式纤维的图像重建，深度学习已经广泛研究。然而，现有的方法主要使用不同配置的目标点粒组。很难重建目标 без 训练网络。在本文中，我们提出了一种物理帮助、无监督、学习基于纤维图像重建的方案。物理帮助的作用是简化纤维模式对目标图像的映射关系，因此降低计算复杂度。无监督网络根据优化的方向学习目标特征。因此，重建过程只需要几个纤维模式和不对称的目标。我们的方案还增加了学习基于纤维的方法在扰urbed多模式纤维中的应用能力。我们的方案具有扩展多模式纤维图像重建的潜力。
</details></li>
</ul>
<hr>
<h2 id="Learned-layered-coding-for-Successive-Refinement-in-the-Wyner-Ziv-Problem"><a href="#Learned-layered-coding-for-Successive-Refinement-in-the-Wyner-Ziv-Problem" class="headerlink" title="Learned layered coding for Successive Refinement in the Wyner-Ziv Problem"></a>Learned layered coding for Successive Refinement in the Wyner-Ziv Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03061">http://arxiv.org/abs/2311.03061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boris Joukovsky, Brent De Weerdt, Nikos Deligiannis</li>
<li>for: 这个论文是关于successive refinement of Wyner-Ziv coding problem的研究，旨在逐渐提高编码器和解码器的质量，并使用相关的侧 информацию来进行帮助。</li>
<li>methods: 这个论文使用了循环神经网络（RNN）来学习层次编码器和解码器，特别是在二次 Gaussian  случа子下。这些模型通过最小化一种变量约束来学习层次编码和解码。</li>
<li>results: 研究发现，RNN可以显式地恢复层次归一化解决方案，类似于可拆化量化。此外，这种方案的环境-质量比例性和环境-质量抑制性都达到了相当的水平。<details>
<summary>Abstract</summary>
We propose a data-driven approach to explicitly learn the progressive encoding of a continuous source, which is successively decoded with increasing levels of quality and with the aid of correlated side information. This setup refers to the successive refinement of the Wyner-Ziv coding problem. Assuming ideal Slepian-Wolf coding, our approach employs recurrent neural networks (RNNs) to learn layered encoders and decoders for the quadratic Gaussian case. The models are trained by minimizing a variational bound on the rate-distortion function of the successively refined Wyner-Ziv coding problem. We demonstrate that RNNs can explicitly retrieve layered binning solutions akin to scalable nested quantization. Moreover, the rate-distortion performance of the scheme is on par with the corresponding monolithic Wyner-Ziv coding approach and is close to the rate-distortion bound.
</details>
<details>
<summary>摘要</summary>
我们提议一种数据驱动的方法，用于显式地学习连续源的进程编码，逐渐采用不同的质量水平进行解码，并且使用相关的侧信息进行帮助。这种设置与Wyner-Ziv编码问题的逐渐精细化相关。假设 ideal Slepian-Wolf编码，我们使用循环神经网络（RNN）来学习层次编码器和解码器，特别是在二次泊松分布中。我们通过最小化变量约束函数来训练模型，以实现逐渐精细化Wyner-Ziv编码问题的率度-损失函数。我们 demonstrably show that RNN可以显式地恢复层次归一化解决方案，类似于可扩展的嵌套量化。此外，我们的方案的率度-损失性能与相应的单一Wyner-Ziv编码方法相当，并且几乎与率度-损失约束函数相匹配。
</details></li>
</ul>
<hr>
<h2 id="DRAUC-An-Instance-wise-Distributionally-Robust-AUC-Optimization-Framework"><a href="#DRAUC-An-Instance-wise-Distributionally-Robust-AUC-Optimization-Framework" class="headerlink" title="DRAUC: An Instance-wise Distributionally Robust AUC Optimization Framework"></a>DRAUC: An Instance-wise Distributionally Robust AUC Optimization Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03055">http://arxiv.org/abs/2311.03055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siran Dai, Qianqian Xu, Zhiyong Yang, Xiaochun Cao, Qingming Huang</li>
<li>For: The paper aims to improve the performance of long-tailed classification by addressing the challenges of distributional shift and label bias.* Methods: The paper proposes an instance-wise surrogate loss of Distributionally Robust AUC (DRAUC) and builds an optimization framework on top of it. Additionally, the paper introduces distribution-aware DRAUC to mitigate label bias.* Results: The paper demonstrates the effectiveness of the proposed method through experiments on corrupted benchmark datasets, and theoretically proves that the generalization gap between the training loss and testing error diminishes as the training set size increases.<details>
<summary>Abstract</summary>
The Area Under the ROC Curve (AUC) is a widely employed metric in long-tailed classification scenarios. Nevertheless, most existing methods primarily assume that training and testing examples are drawn i.i.d. from the same distribution, which is often unachievable in practice. Distributionally Robust Optimization (DRO) enhances model performance by optimizing it for the local worst-case scenario, but directly integrating AUC optimization with DRO results in an intractable optimization problem. To tackle this challenge, methodically we propose an instance-wise surrogate loss of Distributionally Robust AUC (DRAUC) and build our optimization framework on top of it. Moreover, we highlight that conventional DRAUC may induce label bias, hence introducing distribution-aware DRAUC as a more suitable metric for robust AUC learning. Theoretically, we affirm that the generalization gap between the training loss and testing error diminishes if the training set is sufficiently large. Empirically, experiments on corrupted benchmark datasets demonstrate the effectiveness of our proposed method. Code is available at: https://github.com/EldercatSAM/DRAUC.
</details>
<details>
<summary>摘要</summary>
“区下 Receiver Operating Characteristic（AUC）是长尾分类enario中广泛使用的度量。然而，现有的方法主要假设训练和测试例子都是取自同一个分布，这在实践中经常不可能实现。分布Robust Optimization（DRO）可以提高模型性能，但是直接将AUC优化与DRO结合会带来难以解决的优化问题。为了解决这个挑战，我们系统地提出了实例化损失函数Distributionally Robust AUC（DRAUC），并建立了我们的优化框架之上。此外，我们发现了 convention DRAUC可能会导致标签偏见，因此我们提出了 distribution-aware DRAUC，这是更适合的对Robust AUC学习的度量。理论上，我们证明了训练集大 enough，则标签误差和测试集误差之间的差异会减少。实验结果显示了我们提出的方法的有效性。代码可以在：https://github.com/EldercatSAM/DRAUC ”Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Validity-problems-in-clinical-machine-learning-by-indirect-data-labeling-using-consensus-definitions"><a href="#Validity-problems-in-clinical-machine-learning-by-indirect-data-labeling-using-consensus-definitions" class="headerlink" title="Validity problems in clinical machine learning by indirect data labeling using consensus definitions"></a>Validity problems in clinical machine learning by indirect data labeling using consensus definitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03037">http://arxiv.org/abs/2311.03037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Hagmann, Shigehiko Schamoni, Stefan Riezler</li>
<li>for: 本研究探讨了机器学习在医疗领域的疾病诊断中存在的有效性问题。</li>
<li>methods: 本研究使用了一种普遍存在的机器学习问题，即在训练数据中目标标签是通过间接测量得到的，而基本的测量数据不可获取或只有部分可用。</li>
<li>results: 研究发现，使用这种数据会导致机器学习模型只能准确地重construct目标定义，但在真实世界中会失败。研究还提供了一种检测这种问题的方法，并在抑 septic 预测任务中进行了示例。<details>
<summary>Abstract</summary>
We demonstrate a validity problem of machine learning in the vital application area of disease diagnosis in medicine. It arises when target labels in training data are determined by an indirect measurement, and the fundamental measurements needed to determine this indirect measurement are included in the input data representation. Machine learning models trained on this data will learn nothing else but to exactly reconstruct the known target definition. Such models show perfect performance on similarly constructed test data but will fail catastrophically on real-world examples where the defining fundamental measurements are not or only incompletely available. We present a general procedure allowing identification of problematic datasets and black-box machine learning models trained on them, and exemplify our detection procedure on the task of early prediction of sepsis.
</details>
<details>
<summary>摘要</summary>
我们描述了机器学习在医学领域重要应用领域的有效性问题。这种问题出现在训练数据中的目标标签由间接测量决定，而基本测量需要确定这种间接测量的数据表示中包含。基于这种数据的机器学习模型会学习到一切都是重建已知的目标定义。这些模型在类似构建的测试数据上表现出色，但在真实世界中，不或只有部分可用的基本测量不会导致惊人的失败。我们提出了一种通用的数据集检测过程和黑盒机器学习模型的检测方法，并在抑止性血液感染预测任务中进行了示例。
</details></li>
</ul>
<hr>
<h2 id="On-regularized-polynomial-functional-regression"><a href="#On-regularized-polynomial-functional-regression" class="headerlink" title="On regularized polynomial functional regression"></a>On regularized polynomial functional regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03036">http://arxiv.org/abs/2311.03036</a></li>
<li>repo_url: None</li>
<li>paper_authors: Markus Holzleitner, Sergei Pereverzyev</li>
<li>for: 该论文提供了多项式函数回归的全面征识，并在设立了一个新的finite sample bound。</li>
<li>methods: 该 bound 涵盖了一些不同的方面，包括通用的光滑条件、容量条件以及规则化技术。</li>
<li>results: 数据证明使用高阶多项式项可以提高性能。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
This article offers a comprehensive treatment of polynomial functional regression, culminating in the establishment of a novel finite sample bound. This bound encompasses various aspects, including general smoothness conditions, capacity conditions, and regularization techniques. In doing so, it extends and generalizes several findings from the context of linear functional regression as well. We also provide numerical evidence that using higher order polynomial terms can lead to an improved performance.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:这篇文章提供了对多项式函数回归的完整对待，包括建立一个新的finite sample bound，这个bound涵盖了一般的光滑条件、容量条件和规则化技术等方面。这些结论超越了线性函数回归的上下文中的一些发现，并提供了数字证据，表明使用高阶多项式项可以提高性能。
</details></li>
</ul>
<hr>
<h2 id="Estimating-treatment-effects-from-single-arm-trials-via-latent-variable-modeling"><a href="#Estimating-treatment-effects-from-single-arm-trials-via-latent-variable-modeling" class="headerlink" title="Estimating treatment effects from single-arm trials via latent-variable modeling"></a>Estimating treatment effects from single-arm trials via latent-variable modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03002">http://arxiv.org/abs/2311.03002</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manuelhaussmann/lvm_singlearm">https://github.com/manuelhaussmann/lvm_singlearm</a></li>
<li>paper_authors: Manuel Haussmann, Tran Minh Son Le, Viivi Halla-aho, Samu Kurki, Jussi Leinonen, Miika Koskinen, Samuel Kaski, Harri Lähdesmäki</li>
<li>For: This paper proposes a new method for estimating treatment effects in single-arm trials with missing covariate observations.* Methods: The method uses an identifiable deep latent-variable model to learn group-specific and shared latent representations, and uses amortized variational inference to estimate the model parameters.* Results: The authors evaluate the method on a public benchmark and a real-world data set, and show improved performance compared to previous methods for direct treatment effect estimation and effect estimation via patient matching.Here’s the full translation in Simplified Chinese:* For: 这篇论文提出了一种新的方法，用于在单臂试验中估计治疗效果，当 covariate 观察数据缺失时。* Methods: 该方法使用可识别深度卷积模型，学习各组特定和共享卷积表示，并使用权重变分算法来估计模型参数。* Results: 作者在公共 benchmarck 和实际世界数据集上评估了该方法，并与之前的方法进行比较，得到了改进的效果估计结果，包括直接治疗效应估计和通过患者匹配来估计效应。<details>
<summary>Abstract</summary>
Randomized controlled trials (RCTs) are the accepted standard for treatment effect estimation but they can be infeasible due to ethical reasons and prohibitive costs. Single-arm trials, where all patients belong to the treatment group, can be a viable alternative but require access to an external control group. We propose an identifiable deep latent-variable model for this scenario that can also account for missing covariate observations by modeling their structured missingness patterns. Our method uses amortized variational inference to learn both group-specific and identifiable shared latent representations, which can subsequently be used for (i) patient matching if treatment outcomes are not available for the treatment group, or for (ii) direct treatment effect estimation assuming outcomes are available for both groups. We evaluate the model on a public benchmark as well as on a data set consisting of a published RCT study and real-world electronic health records. Compared to previous methods, our results show improved performance both for direct treatment effect estimation as well as for effect estimation via patient matching.
</details>
<details>
<summary>摘要</summary>
随机控制试验（RCT）是确认标准用于治疗效果估计，但它们可能因为伦理原则和高昂成本而无法实施。单臂试验，其中所有病人属于治疗组，可以作为可行的替代方案，但需要访问外部控制组。我们提议一种可识别深度含变量模型来解决这种情况，该模型还可以考虑欠拟合观测pattern。我们的方法使用总量变量推断来学习群体特定和共享含变量表示，这些表示可以用于（i）病人匹配，如果治疗结果不可用于治疗组，或者（ii）直接治疗效果估计，假设两个组具有结果。我们在一个公共标准和一个包含已发表RCT研究和实际电子医疗记录的数据集上评估了我们的方法。与之前的方法相比，我们的结果显示了改进的性能，包括直接治疗效果估计和效果估计 via 病人匹配。
</details></li>
</ul>
<hr>
<h2 id="Variational-Weighting-for-Kernel-Density-Ratios"><a href="#Variational-Weighting-for-Kernel-Density-Ratios" class="headerlink" title="Variational Weighting for Kernel Density Ratios"></a>Variational Weighting for Kernel Density Ratios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03001">http://arxiv.org/abs/2311.03001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwoong Yoon, Frank C. Park, Gunsu S Yun, Iljung Kim, Yung-Kyun Noh</li>
<li>for: 提高机器学习中的生成和识别任务中的kernel density estimation（KDE）精度。</li>
<li>methods: 基于多维 calculus of variations  derivation 得到优化的权重函数，减少标准kernel density estimate的偏差，提高预测 posterior 和信息论量的估计。</li>
<li>results: 提高KDE的精度，深入探讨了density estimation的基本问题，特别是那些使用KDE作为主要构建件的算法。<details>
<summary>Abstract</summary>
Kernel density estimation (KDE) is integral to a range of generative and discriminative tasks in machine learning. Drawing upon tools from the multidimensional calculus of variations, we derive an optimal weight function that reduces bias in standard kernel density estimates for density ratios, leading to improved estimates of prediction posteriors and information-theoretic measures. In the process, we shed light on some fundamental aspects of density estimation, particularly from the perspective of algorithms that employ KDEs as their main building blocks.
</details>
<details>
<summary>摘要</summary>
kernel density estimation（KDE）是机器学习中多种生成和歧义任务的关键技术。我们通过多维Calculus of variations中的工具， derivation optimal weight function，以减少标准KDE中的偏见，从而提高预测 posterior和信息论量的估计。在这个过程中，我们也抛光了density estimation的一些基本特点，特别是利用KDE作为主要组件的算法的视角。Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Strong-statistical-parity-through-fair-synthetic-data"><a href="#Strong-statistical-parity-through-fair-synthetic-data" class="headerlink" title="Strong statistical parity through fair synthetic data"></a>Strong statistical parity through fair synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03000">http://arxiv.org/abs/2311.03000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivona Krchova, Michael Platzer, Paul Tiwald</li>
<li>for: 保护原始数据隐私和适应需求</li>
<li>methods: 使用AI生成的合理数据，通过平衡敏感特征的学习目标概率分布，实现了具有设计的公平性</li>
<li>results: 通过在生成器采样过程中直接或后期处理方式进行公平性调整，可以在不偏袋固模型的前提下，通过训练在合理数据上，实现强大的预测公平性<details>
<summary>Abstract</summary>
AI-generated synthetic data, in addition to protecting the privacy of original data sets, allows users and data consumers to tailor data to their needs. This paper explores the creation of synthetic data that embodies Fairness by Design, focusing on the statistical parity fairness definition. By equalizing the learned target probability distributions of the synthetic data generator across sensitive attributes, a downstream model trained on such synthetic data provides fair predictions across all thresholds, that is, strong fair predictions even when inferring from biased, original data. This fairness adjustment can be either directly integrated into the sampling process of a synthetic generator or added as a post-processing step. The flexibility allows data consumers to create fair synthetic data and fine-tune the trade-off between accuracy and fairness without any previous assumptions on the data or re-training the synthetic data generator.
</details>
<details>
<summary>摘要</summary>
人工生成的数据可以保护原始数据集的隐私，同时允许用户和数据消费者根据自己的需求进行数据的自定义。本文探讨了基于 Fairness by Design 的synthetic数据创造，特icularly focusing on统计平衡公平定义。通过在生成synthetic数据的学习目标概率分布中归一化敏感特征，下游模型在such synthetic数据上训练后可以在所有阈值下提供公平预测，即从偏见的原始数据中做出公平预测。这种公平调整可以直接integrated into the sampling process of a synthetic generator或者作为后处理步骤进行。这种灵活性allow data consumers可以创造公平的synthetic数据，并且根据自己的需求进行公平和准确之间的质量调整，无需对数据进行任何假设或者重新训练synthetic数据生成器。
</details></li>
</ul>
<hr>
<h2 id="Hacking-Cryptographic-Protocols-with-Advanced-Variational-Quantum-Attacks"><a href="#Hacking-Cryptographic-Protocols-with-Advanced-Variational-Quantum-Attacks" class="headerlink" title="Hacking Cryptographic Protocols with Advanced Variational Quantum Attacks"></a>Hacking Cryptographic Protocols with Advanced Variational Quantum Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02986">http://arxiv.org/abs/2311.02986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Borja Aizpurua, Pablo Bermejo, Josu Etxezarreta Martinez, Roman Orus</li>
<li>for: 本研究旨在提出一种改进的量子攻击算法（VQAA），用于攻击 криптографиic协议。</li>
<li>methods: 本研究使用了一种更高效的量子攻击方法，可以更好地攻击Symmetric-key协议，例如S-DES、S-AES和Blowfish。我们通过类比一小型8个量子计算机来实现这些攻击。</li>
<li>results: 我们的研究发现，使用这种方法可以在24倍的迭代次数下找到Blowfish协议中的秘钥，并且在Symmetric-key协议中也有较高的攻击成功率。此外，我们还讨论了这些方法的可能的后续改进。这些结果为评估NISQ设备对大规模 классический криптографиic协议的抵触提供了一个重要的步骤，并为未来的量子网络安全研究提供了平台。<details>
<summary>Abstract</summary>
Here we introduce an improved approach to Variational Quantum Attack Algorithms (VQAA) on crytographic protocols. Our methods provide robust quantum attacks to well-known cryptographic algorithms, more efficiently and with remarkably fewer qubits than previous approaches. We implement simulations of our attacks for symmetric-key protocols such as S-DES, S-AES and Blowfish. For instance, we show how our attack allows a classical simulation of a small 8-qubit quantum computer to find the secret key of one 32-bit Blowfish instance with 24 times fewer number of iterations than a brute-force attack. Our work also shows improvements in attack success rates for lightweight ciphers such as S-DES and S-AES. Further applications beyond symmetric-key cryptography are also discussed, including asymmetric-key protocols and hash functions. In addition, we also comment on potential future improvements of our methods. Our results bring one step closer assessing the vulnerability of large-size classical cryptographic protocols with Noisy Intermediate-Scale Quantum (NISQ) devices, and set the stage for future research in quantum cybersecurity.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Pursuit-of-Human-Labeling-A-New-Perspective-on-Unsupervised-Learning"><a href="#The-Pursuit-of-Human-Labeling-A-New-Perspective-on-Unsupervised-Learning" class="headerlink" title="The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning"></a>The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02940">http://arxiv.org/abs/2311.02940</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlbio-epfl/hume">https://github.com/mlbio-epfl/hume</a></li>
<li>paper_authors: Artyom Gadetsky, Maria Brbic</li>
<li>for: 这 paper 的目的是提出一种无需外部监督的模型自适应推理方法，以便从 dataset 中推断人类标注。</li>
<li>methods: 该方法基于人类标注的类划分是线性分割的准确性，不同表示空间中的数据集的标注。 HUME 使用这种想法来导引搜索所有可能的标注，以找出下面的人类标注。</li>
<li>results: 与基于自我监督模型的超参数器相比，HUME 在 STL-10 数据集上大幅提高了性能，并在 CIFAR-10 数据集上达到了相似的性能。 与现有的无监督基准值相比，HUME 在四个图像分类 benchmark 数据集上 achiev 了状态的最佳性能，包括大规模的 ImageNet-1000 数据集。<details>
<summary>Abstract</summary>
We present HUME, a simple model-agnostic framework for inferring human labeling of a given dataset without any external supervision. The key insight behind our approach is that classes defined by many human labelings are linearly separable regardless of the representation space used to represent a dataset. HUME utilizes this insight to guide the search over all possible labelings of a dataset to discover an underlying human labeling. We show that the proposed optimization objective is strikingly well-correlated with the ground truth labeling of the dataset. In effect, we only train linear classifiers on top of pretrained representations that remain fixed during training, making our framework compatible with any large pretrained and self-supervised model. Despite its simplicity, HUME outperforms a supervised linear classifier on top of self-supervised representations on the STL-10 dataset by a large margin and achieves comparable performance on the CIFAR-10 dataset. Compared to the existing unsupervised baselines, HUME achieves state-of-the-art performance on four benchmark image classification datasets including the large-scale ImageNet-1000 dataset. Altogether, our work provides a fundamentally new view to tackle unsupervised learning by searching for consistent labelings between different representation spaces.
</details>
<details>
<summary>摘要</summary>
我们介绍HUME，一个简单的无监督框架，可以无需外部监督来推算资料集的人类标签。HUME的关键想法是：由多个人类标签定义的类别是无论使用哪个表示空间来表示资料集时，Linearly separable。HUME利用这个想法来导引搜寻资料集的所有可能的标签，以发现资料集的下面人类标签。我们显示了提案的优化目标与真实的标签和资料集之间有很高的相関性。实际上，我们仅在固定的表示空间上训练Linear Classifier，使得我们的框架与任何大型预训练和自愿学习模型相容。Despite its simplicity, HUME在STL-10 dataset上大幅超越了对自主学习表示的supervised linear classifier，并在CIFAR-10 dataset上 achieved comparable performance。Compared to existing unsupervised baselines, HUME在四个大规模的图像分类dataset上 achievestate-of-the-art performance, including the large-scale ImageNet-1000 dataset。总之，我们的工作提供了一个completely new的方法来解决无监督学习的问题，通过寻找不同表示空间中的一致标签。
</details></li>
</ul>
<hr>
<h2 id="Edge2Node-Reducing-Edge-Prediction-to-Node-Classification"><a href="#Edge2Node-Reducing-Edge-Prediction-to-Node-Classification" class="headerlink" title="Edge2Node: Reducing Edge Prediction to Node Classification"></a>Edge2Node: Reducing Edge Prediction to Node Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02921">http://arxiv.org/abs/2311.02921</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arahmatiiii/E2N">https://github.com/arahmatiiii/E2N</a></li>
<li>paper_authors: Zahed Rahmati, Ali Rahmati, Dariush Kazemi</li>
<li>for: 本研究的目的是提高图 neural network 模型在图边预测任务中的性能。</li>
<li>methods: 我们引入了一种新的方法 called E2N（Edge2Node），它可以直接从图中获取边的嵌入，无需预先定义评分函数。</li>
<li>results: 我们在 ogbl-ddi 和 ogbl-collab 数据集上进行了实验，并取得了较高的性能。在 validation 集上，我们的 Hits@20 分数为 98.79%，在 test 集上为 98.11%。在 ogbl-collab 数据集上，我们的 Hits@50 分数为 95.46%，在 test 集上为 95.15%。<details>
<summary>Abstract</summary>
Despite the success of graph neural network models in node classification, edge prediction (the task of predicting missing or potential relationships between nodes in a graph) remains a challenging problem for these models. A common approach for edge prediction is to first obtain the embeddings of two nodes, and then a predefined scoring function is used to predict the existence of an edge between the two nodes. In this paper, we introduce a new approach called E2N (Edge2Node) which directly obtains an embedding for each edge, without the need for a scoring function. To do this, we create a new graph H based on the graph G given for the edge prediction task, and then reduce the edge prediction task on G to a node classification task on H. Our E2N method can be easily applied to any edge prediction task with superior performance and lower computational costs.   For the ogbl-ddi and ogbl-collab datasets, our E2N method outperforms the state-of-the-art methods listed on the leaderboards. Our experiments on the ogbl-ddi dataset achieved a Hits@20 score of 98.79% on the validation set and 98.11% on the test set. On the ogbl-collab dataset, we achieved a Hits@50 score of 95.46% on the validation set and 95.15% on the test set.
</details>
<details>
<summary>摘要</summary>
尽管图 neural network 模型在节点分类任务上取得了成功，但是边预测（预测图中两个节点之间的存在或可能存在的关系）仍然是这些模型的挑战。一种常见的边预测方法是首先获取两个节点的嵌入，然后使用预定的分数函数来预测这两个节点之间的边是否存在。在这篇论文中，我们介绍了一种新的方法called E2N（边到节点），它可以直接从图中获取每个边的嵌入，无需预定的分数函数。为了实现这一目标，我们首先创建了一个新的图H，基于给定的图G，并将图G上的边预测任务转化为图H上的节点分类任务。我们的E2N方法可以轻松应用于任何边预测任务，并且可以提供更高的性能和更低的计算成本。在ogbl-ddi和ogbl-collab数据集上，我们的E2N方法超过了现有的状态作方法，其中在ogbl-ddi数据集上，我们的实验在验证集上达到了Hits@20分数的98.79%，并在测试集上达到了98.11%。在ogbl-collab数据集上，我们的实验在验证集上达到了Hits@50分数的95.46%，并在测试集上达到了95.15%。
</details></li>
</ul>
<hr>
<h2 id="Distributed-Matrix-Based-Sampling-for-Graph-Neural-Network-Training"><a href="#Distributed-Matrix-Based-Sampling-for-Graph-Neural-Network-Training" class="headerlink" title="Distributed Matrix-Based Sampling for Graph Neural Network Training"></a>Distributed Matrix-Based Sampling for Graph Neural Network Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02909">http://arxiv.org/abs/2311.02909</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Alok Tripathy, Katherine Yelick, Aydin Buluc</li>
<li>for: 这篇论文的主要贡献是一些用于缩小分布式GNN训练过程中的样本步骤的新方法。</li>
<li>methods: 我们提出了一个矩阵基于的大批量样本方法，将样本表示为稀疏矩阵乘法（SpGEMM），并同时样本多个批次。当输入图形结构不适合单一设备的内存时，我们将图形分布到多个设备，并使用通信避免的SpGEMM算法扩展GNN批次样本训练，以让GNN在较大的图形上进行训练。</li>
<li>results: 我们在最大的Open Graph Benchmark（OGB）数据集上进行了$128$个GPU的实验，并证明我们的管道比Quiver（一个分布式延伸 PyTorch-Geometric）在$3$-层 GraphSAGE 网络上$2.5\times$ faster。在OGB数据集外，我们在$128$个GPU上获得了一个实验 epoch 时间$8.46\times$ 快。最后，我们还详细介绍了分布在GPU上的图形和两种样本算法（node-wise和layer-wise）的扩展。<details>
<summary>Abstract</summary>
The primary contribution of this paper is new methods for reducing communication in the sampling step for distributed GNN training. Here, we propose a matrix-based bulk sampling approach that expresses sampling as a sparse matrix multiplication (SpGEMM) and samples multiple minibatches at once. When the input graph topology does not fit on a single device, our method distributes the graph and use communication-avoiding SpGEMM algorithms to scale GNN minibatch sampling, enabling GNN training on much larger graphs than those that can fit into a single device memory. When the input graph topology (but not the embeddings) fits in the memory of one GPU, our approach (1) performs sampling without communication, (2) amortizes the overheads of sampling a minibatch, and (3) can represent multiple sampling algorithms by simply using different matrix constructions. In addition to new methods for sampling, we show that judiciously replicating feature data with a simple all-to-all exchange can outperform current methods for the feature extraction step in distributed GNN training. We provide experimental results on the largest Open Graph Benchmark (OGB) datasets on $128$ GPUs, and show that our pipeline is $2.5\times$ faster Quiver (a distributed extension to PyTorch-Geometric) on a $3$-layer GraphSAGE network. On datasets outside of OGB, we show a $8.46\times$ speedup on $128$ GPUs in-per epoch time. Finally, we show scaling when the graph is distributed across GPUs and scaling for both node-wise and layer-wise sampling algorithms
</details>
<details>
<summary>摘要</summary>
主要贡献之一是一种新的减少通信的分布式GNN训练阶段采样方法。我们提议一种基于矩阵的批量采样方法，将采样表示为稀疏矩阵乘法（SpGEMM），并同时采样多个小批量。当输入图的结构不能在单个设备内存中存储时，我们将图分布到多个设备，使用通信减少的SpGEMM算法扩展GNN训练，可以训练更大的图。当输入图结构（不是特征表示）可以在单个GPU内存中存储时，我们的方法可以无需通信进行采样，并且可以吞吐采样批量的开销。此外，我们还显示了对特征提取步骤的分布式GNN训练中的特征数据复制，可以超越现有的方法。我们在最大Open Graph Benchmark（OGB）集合上的128个GPU上进行了实验，并证明了我们的管道在三层GraphSAGE网络上比Quire（分布式PyTorch-Geometric的扩展）快了2.5倍。在OGB集合以外的 datasets 上，我们在128个GPU上的一个epoch时间上提高了8.46倍。最后，我们还展示了图分布在GPU上的扩展和节点和层间采样算法的扩展。
</details></li>
</ul>
<hr>
<h2 id="HDGL-A-hierarchical-dynamic-graph-representation-learning-model-for-brain-disorder-classification"><a href="#HDGL-A-hierarchical-dynamic-graph-representation-learning-model-for-brain-disorder-classification" class="headerlink" title="HDGL: A hierarchical dynamic graph representation learning model for brain disorder classification"></a>HDGL: A hierarchical dynamic graph representation learning model for brain disorder classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02903">http://arxiv.org/abs/2311.02903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parniyan Jalali, Mehran Safayani</li>
<li>for: 本研究旨在提出一种 Hierarchical Dynamic Graph Representation Learning（HDGL）模型，以解决现有的 исследования中的一些缺陷，如不考虑样本之间的关系、不利用表型信息、缺乏时间分析、使用静止功能连接（FC）而不是动态连接、使用固定图 струкucture。</li>
<li>methods: 本研究使用的方法包括建立大脑网络图和学习其空间和时间嵌入，以及形成人口图并进行分类 после嵌入学习。此外，为了降低内存复杂性，提出了四种方法。</li>
<li>results: 研究表明，提出的 HDGL 模型在 ABIDE 和 ADHD-200 数据集上的表现比一些现有模型更好，以各种评价指标来衡量。<details>
<summary>Abstract</summary>
The human brain can be considered as complex networks, composed of various regions that continuously exchange their information with each other, forming the brain network graph, from which nodes and edges are extracted using resting-state functional magnetic resonance imaging (rs-fMRI). Therefore, this graph can potentially depict abnormal patterns that have emerged under the influence of brain disorders. So far, numerous studies have attempted to find embeddings for brain network graphs and subsequently classify samples with brain disorders from healthy ones, which include limitations such as: not considering the relationship between samples, not utilizing phenotype information, lack of temporal analysis, using static functional connectivity (FC) instead of dynamic ones and using a fixed graph structure. We propose a hierarchical dynamic graph representation learning (HDGL) model, which is the first model designed to address all the aforementioned challenges. HDGL consists of two levels, where at the first level, it constructs brain network graphs and learns their spatial and temporal embeddings, and at the second level, it forms population graphs and performs classification after embedding learning. Furthermore, based on how these two levels are trained, four methods have been introduced, some of which are suggested for reducing memory complexity. We evaluated the performance of the proposed model on the ABIDE and ADHD-200 datasets, and the results indicate the improvement of this model compared to several state-of-the-art models in terms of various evaluation metrics.
</details>
<details>
<summary>摘要</summary>
人类大脑可以视为复杂的网络，由多个区域组成，这些区域之间不断交换信息，形成大脑网络图，从而可以潜在地描述了脑部疾病的异常模式。因此，这个图可能能够描述脑部疾病样本和健康样本之间的差异。迄今为止，许多研究已经尝试使用大脑网络图进行嵌入和分类，但是这些研究存在一些限制，例如：不考虑样本之间的关系、不使用现象信息、缺乏时间分析、使用静态功能连接（FC）而不是动态连接、使用固定图结构。我们提出了层次动态图表学习（HDGL）模型，这是首个解决以上所有挑战的模型。HDGL包括两个层次，其中第一层是构建大脑网络图并学习其空间和时间嵌入，第二层是组成人口图并进行分类 после嵌入学习。此外，根据这两个层的训练方式，我们引入了四种方法来减少内存复杂性。我们对ABIDE和ADHD-200数据集进行了评估，结果表明我们的模型在多种评价指标上表现得更好于一些现有的模型。
</details></li>
</ul>
<hr>
<h2 id="Transduce-and-Speak-Neural-Transducer-for-Text-to-Speech-with-Semantic-Token-Prediction"><a href="#Transduce-and-Speak-Neural-Transducer-for-Text-to-Speech-with-Semantic-Token-Prediction" class="headerlink" title="Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic Token Prediction"></a>Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic Token Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02898">http://arxiv.org/abs/2311.02898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minchan Kim, Myeonghun Jeong, Byoung Jin Choi, Dongjune Lee, Nam Soo Kim</li>
<li>for: 这个论文旨在提出一个基于神经变数器的文本读取声音框架（TTS），以便实现文本读取声音的自适应和实时处理。</li>
<li>methods: 本论文使用了wav2vec2.0嵌入的数据化 semantic token，并使用神经变数器生成对适当的语音变数。然后，使用非autoregressive（NAR）语音生成器将 semantic token 转换为语音样本。这个框架可以简化TTS训练的复杂性，并允许每个阶段专注于语言和排序模型化，以及细化的音频模型化。</li>
<li>results: 实验结果显示，提案的模型在零执行 adaptive TTS 中 exceeds 基于的基eline，在语音质量和说话人相似性方面 via bjective 和主观度量。此外，我们还 investigate了我们的提案模型的推断速度和语音特征可控性，显示了神经变数器的潜力 для TTS 框架。<details>
<summary>Abstract</summary>
We introduce a text-to-speech(TTS) framework based on a neural transducer. We use discretized semantic tokens acquired from wav2vec2.0 embeddings, which makes it easy to adopt a neural transducer for the TTS framework enjoying its monotonic alignment constraints. The proposed model first generates aligned semantic tokens using the neural transducer, then synthesizes a speech sample from the semantic tokens using a non-autoregressive(NAR) speech generator. This decoupled framework alleviates the training complexity of TTS and allows each stage to focus on 1) linguistic and alignment modeling and 2) fine-grained acoustic modeling, respectively. Experimental results on the zero-shot adaptive TTS show that the proposed model exceeds the baselines in speech quality and speaker similarity via objective and subjective measures. We also investigate the inference speed and prosody controllability of our proposed model, showing the potential of the neural transducer for TTS frameworks.
</details>
<details>
<summary>摘要</summary>
我们提出了基于神经抽象器的文本识音框架（TTS）。我们使用从wav2vec2.0嵌入中得到的精细 semantic token，这使得我们可以轻松地采用神经抽象器来实现TTS框架，并且具有幂等对齐约束。我们的模型首先使用神经抽象器生成对齐的 semantic token，然后使用非自反式（NAR）演示生成器将这些 semantic token 转换为语音样本。这种分离的框架可以减少 TTS 的训练复杂度，让每个阶段都能够专注于1）语言和对齐模型化和2）细腻的音响模型化。我们的实验结果表明，我们的提议的模型在零shot适应TTS中超过了基准值的语音质量和发音相似性，通过对象和主观度量。我们还研究了我们的提议模型的推理速度和幂等控制性，这表明神经抽象器在TTS框架中的潜力。
</details></li>
</ul>
<hr>
<h2 id="AdaFlood-Adaptive-Flood-Regularization"><a href="#AdaFlood-Adaptive-Flood-Regularization" class="headerlink" title="AdaFlood: Adaptive Flood Regularization"></a>AdaFlood: Adaptive Flood Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02891">http://arxiv.org/abs/2311.02891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wonho Bae, Yi Ren, Mohamad Osama Ahmed, Frederick Tung, Danica J. Sutherland, Gabriel L. Oliveira</li>
<li>for: 提高模型的测试时间一致性（test time generalization）</li>
<li>methods: 使用适应式洪水水平调整（AdaFlood）方法，根据训练示例的难度自动调整洪水水平</li>
<li>results: 在四种不同的输入模式（文本、图像、异步事件序列和表格）的数据集上进行实验，得到了 AdaFlood 的多样性和类型。<details>
<summary>Abstract</summary>
Although neural networks are conventionally optimized towards zero training loss, it has been recently learned that targeting a non-zero training loss threshold, referred to as a flood level, often enables better test time generalization. Current approaches, however, apply the same constant flood level to all training samples, which inherently assumes all the samples have the same difficulty. We present AdaFlood, a novel flood regularization method that adapts the flood level of each training sample according to the difficulty of the sample. Intuitively, since training samples are not equal in difficulty, the target training loss should be conditioned on the instance. Experiments on datasets covering four diverse input modalities - text, images, asynchronous event sequences, and tabular - demonstrate the versatility of AdaFlood across data domains and noise levels.
</details>
<details>
<summary>摘要</summary>
尽管神经网络通常是在零训练损失下优化的，但最近发现，targeting非零训练损失阈值（ referred to as flood level）经常可以提高测试时通用性。现有方法却是将同一个常数洪水水平应用于所有训练样本，这种假设所有样本都有相同的难度。我们介绍了AdaFlood，一种新的洪水规范方法，可以根据训练样本的难度进行适应。这种 intuition 是，训练样本不是平等的难度，因此训练损失的目标应该是根据实例进行conditioning。我们在文本、图像、异步事件序列和表格等四种不同的输入模式上进行了实验，demonstrate AdaFlood 在数据领域和噪音水平上的多样性。
</details></li>
</ul>
<hr>
<h2 id="MultiSPANS-A-Multi-range-Spatial-Temporal-Transformer-Network-for-Traffic-Forecast-via-Structural-Entropy-Optimization"><a href="#MultiSPANS-A-Multi-range-Spatial-Temporal-Transformer-Network-for-Traffic-Forecast-via-Structural-Entropy-Optimization" class="headerlink" title="MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for Traffic Forecast via Structural Entropy Optimization"></a>MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for Traffic Forecast via Structural Entropy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02880">http://arxiv.org/abs/2311.02880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongcheng Zou, Senzhang Wang, Xuefeng Li, Hao Peng, Yuandong Wang, Chunyang Liu, Kehua Sheng, Bo Zhang</li>
<li>for: 预测交通流量，提高交通管理和规划的精度。</li>
<li>methods: 提出MultiSPANS方法，包括多渠道卷积模块生成有用的ST-token嵌入，使用Transformers捕捉长范围的时间和空间关系，并引入结构 entropy 理论优化空间注意力机制。</li>
<li>results: 在真实交通数据集上进行了广泛的实验，证明了MultiSPANS方法的优越性，并能够有效利用历史窗口的长期数据。<details>
<summary>Abstract</summary>
Traffic forecasting is a complex multivariate time-series regression task of paramount importance for traffic management and planning. However, existing approaches often struggle to model complex multi-range dependencies using local spatiotemporal features and road network hierarchical knowledge. To address this, we propose MultiSPANS. First, considering that an individual recording point cannot reflect critical spatiotemporal local patterns, we design multi-filter convolution modules for generating informative ST-token embeddings to facilitate attention computation. Then, based on ST-token and spatial-temporal position encoding, we employ the Transformers to capture long-range temporal and spatial dependencies. Furthermore, we introduce structural entropy theory to optimize the spatial attention mechanism. Specifically, The structural entropy minimization algorithm is used to generate optimal road network hierarchies, i.e., encoding trees. Based on this, we propose a relative structural entropy-based position encoding and a multi-head attention masking scheme based on multi-layer encoding trees. Extensive experiments demonstrate the superiority of the presented framework over several state-of-the-art methods in real-world traffic datasets, and the longer historical windows are effectively utilized. The code is available at https://github.com/SELGroup/MultiSPANS.
</details>
<details>
<summary>摘要</summary>
干线预测是一项复杂多变量时间序列回归任务，对交通管理和规划非常重要。然而，现有方法通常无法模型复杂的多范围依赖关系使用本地空间时间特征和道路网络层次知识。为解决这个问题，我们提出了 MultiSPANS。首先，我们认为单个记录点不能反映重要的空间时间本地模式，因此我们设计了多滤波卷积模块，用于生成有用的 ST-token embedding，以便计算注意力。然后，基于 ST-token 和空间时间位编码，我们使用 Transformers 捕捉长范围的时间和空间依赖关系。此外，我们引入了结构 entropy 理论，用于优化空间注意力机制。具体来说，我们使用结构 entropy 最小化算法生成优化的道路网络层次，即编码树。基于这个编码树，我们提出了相对结构 entropy-based的位编码和多头注意力层面封锁方案。经过广泛的实验，我们发现提出的框架在真实的交通数据集上显著超过了一些现状顶尖方法，并且可以有效利用更长的历史窗口。代码可以在 GitHub 上找到：https://github.com/SELGroup/MultiSPANS。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Active-Learning-in-Meta-Learning-Enhancing-Context-Set-Labeling"><a href="#Exploring-Active-Learning-in-Meta-Learning-Enhancing-Context-Set-Labeling" class="headerlink" title="Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling"></a>Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02879">http://arxiv.org/abs/2311.02879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wonho Bae, Jing Wang, Danica J. Sutherland</li>
<li>for: 本文旨在介绍如何使用活动学习来标注一个上下文集，以便在测试时使用meta-学习。</li>
<li>methods: 本文使用了一种基于 Gaussian mixture 的自然算法来选择需要标注的点，这种算法具有理论基础，并且在使用不同的 meta-学习算法和数据集上表现出色。</li>
<li>results: 对于各种 meta-学习算法和数据集，本文的提议的活动学习方法都能够超越当前的状态时活动学习方法。<details>
<summary>Abstract</summary>
Most meta-learning methods assume that the (very small) context set used to establish a new task at test time is passively provided. In some settings, however, it is feasible to actively select which points to label; the potential gain from a careful choice is substantial, but the setting requires major differences from typical active learning setups. We clarify the ways in which active meta-learning can be used to label a context set, depending on which parts of the meta-learning process use active learning. Within this framework, we propose a natural algorithm based on fitting Gaussian mixtures for selecting which points to label; though simple, the algorithm also has theoretical motivation. The proposed algorithm outperforms state-of-the-art active learning methods when used with various meta-learning algorithms across several benchmark datasets.
</details>
<details>
<summary>摘要</summary>
大多数元学习方法假设测试时用于建立新任务的（非常小）上下文集是被提供的，而不是被活动地选择。然而，在某些情况下，可以活动地选择标注点，而且可以获得显著的提升，但这种设置需要与典型的活动学习设置有所不同。我们将 clarify了在元学习过程中使用活动学习时如何选择上下文集，以及哪些部分使用活动学习。在这个框架下，我们提出了一种自然的 Gaussian mixture 适应算法来选择标注点，它简单，但也具有理论基础。我们的提议方法在使用不同元学习算法和多个 benchmark 数据集上表现出色，超过了当前的活动学习方法。
</details></li>
</ul>
<hr>
<h2 id="Sample-Complexity-Bounds-for-Estimating-Probability-Divergences-under-Invariances"><a href="#Sample-Complexity-Bounds-for-Estimating-Probability-Divergences-under-Invariances" class="headerlink" title="Sample Complexity Bounds for Estimating Probability Divergences under Invariances"></a>Sample Complexity Bounds for Estimating Probability Divergences under Invariances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02868">http://arxiv.org/abs/2311.02868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Behrooz Tahmasebi, Stefanie Jegelka</li>
<li>for: 这 paper 研究了在机器学习中使用 Lie 群的自然免疫性，以提高分布计算的效率。</li>
<li>methods: 该 paper 使用了 Wasserstein 距离、Sobolev  интеграル概率度量、MMD 和density estimation 问题的复杂性来研究 Lie 群的自然免疫性。</li>
<li>results: 研究结果表明，使用 Lie 群的自然免疫性可以提高分布计算的效率，包括：（1）通过 multiplicative 因子相对于群大小（对于有限群）或归一化空间的体积（对于正负 definite 群）来减少样本数量;（2）提高计算速度的指数减少（对于正负 definite 群）。这些结果对有限群动作的研究做出了完全新的贡献，并对高维群动作的研究做出了扩展。<details>
<summary>Abstract</summary>
Group-invariant probability distributions appear in many data-generative models in machine learning, such as graphs, point clouds, and images. In practice, one often needs to estimate divergences between such distributions. In this work, we study how the inherent invariances, with respect to any smooth action of a Lie group on a manifold, improve sample complexity when estimating the Wasserstein distance, the Sobolev Integral Probability Metrics (Sobolev IPMs), the Maximum Mean Discrepancy (MMD), and also the complexity of the density estimation problem (in the $L^2$ and $L^\infty$ distance). Our results indicate a two-fold gain: (1) reducing the sample complexity by a multiplicative factor corresponding to the group size (for finite groups) or the normalized volume of the quotient space (for groups of positive dimension); (2) improving the exponent in the convergence rate (for groups of positive dimension). These results are completely new for groups of positive dimension and extend recent bounds for finite group actions.
</details>
<details>
<summary>摘要</summary>
群体对称的概率分布出现在机器学习中的数据生成模型中，如图、点云和图像。在实践中，需要估计这些分布之间的差异。在这个工作中，我们研究了利用归一化 Lie 群对 manifold 上的流形的自然对称性，以提高样本复杂性估计 Wasserstein 距离、Sobolev  интеграル概率度量（Sobolev IPMs）、最大均值差（MMD）以及密度估计问题（在 $L^2$ 和 $L^\infty$ 距离下）的样本复杂性。我们的结果表明，有两个方面的提升：1. 通过群体大小（对 finite group 的action）或归一化量度空间的正规化量（对 positive dimension 的 group action）进行Multiplicative 因子的减少样本复杂性;2. 在 positive dimension 的 group action 中，提高了减少速率的指数。这些结果是对 positive dimension 的 group action 的完全新结果，并扩展了最近的 finite group action 的 bound。
</details></li>
</ul>
<hr>
<h2 id="Barron-Space-for-Graph-Convolution-Neural-Networks"><a href="#Barron-Space-for-Graph-Convolution-Neural-Networks" class="headerlink" title="Barron Space for Graph Convolution Neural Networks"></a>Barron Space for Graph Convolution Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02838">http://arxiv.org/abs/2311.02838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seok-Young Chung, Qiyu Sun</li>
<li>for: 这 paper 的目的是为了探讨图像领域中的图像推荐问题。</li>
<li>methods: 该 paper 使用了图像推荐的一种新的方法，即 Barron space of functions，该空间是一种基于图像的函数空间，可以用于图像推荐。</li>
<li>results: 该 paper 的结果表明，使用 Barron space of functions 可以有效地解决图像推荐问题，并且可以从Random samples中高效地学习图像推荐模型。<details>
<summary>Abstract</summary>
Graph convolutional neural network (GCNN) operates on graph domain and it has achieved a superior performance to accomplish a wide range of tasks. In this paper, we introduce a Barron space of functions on a compact domain of graph signals. We prove that the proposed Barron space is a reproducing kernel Banach space, it can be decomposed into the union of a family of reproducing kernel Hilbert spaces with neuron kernels, and it could be dense in the space of continuous functions on the domain. Approximation property is one of the main principles to design neural networks. In this paper, we show that outputs of GCNNs are contained in the Barron space and functions in the Barron space can be well approximated by outputs of some GCNNs in the integrated square and uniform measurements. We also estimate the Rademacher complexity of functions with bounded Barron norm and conclude that functions in the Barron space could be learnt from their random samples efficiently.
</details>
<details>
<summary>摘要</summary>
“图像卷积神经网络（GCNN）在图像领域中运算，并已经实现了许多任务的优秀表现。在这篇论文中，我们介绍了一个Barron空间中的函数，该空间是在封闭域上的图像信号上定义的。我们证明了该Barron空间是一个重复核函数 Banach空间，可以分解为一家 reproduce kernel Hilbert space的 union，并且可以在连续函数空间中 dense。”Please note that the translation is in Simplified Chinese, and some technical terms may not have direct translations or may be translated differently in different contexts.
</details></li>
</ul>
<hr>
<h2 id="Prioritized-Propagation-in-Graph-Neural-Networks"><a href="#Prioritized-Propagation-in-Graph-Neural-Networks" class="headerlink" title="Prioritized Propagation in Graph Neural Networks"></a>Prioritized Propagation in Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02832">http://arxiv.org/abs/2311.02832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Cheng, Minjie Chen, Xiang Li, Caihua Shan, Ming Gao</li>
<li>for: 本 paper 的目的是提出一种可以与现有 GNN 模型结合使用的框架，以学习 Graph Neural Networks 中的优先级化信息传递。</li>
<li>methods: 本 paper 使用了一种名为 PPro 的框架，该框架包括三部分：一个基础 GNN 模型、一个传递控制器来确定节点的最佳传递步骤，以及一个权重控制器来计算节点的优先级分数。</li>
<li>results: 在对 8 个 benchmark 数据集进行了广泛的实验后，研究发现，使用 PPro 框架可以在各种传递策略和节点表示方面提供优秀的性能。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have recently received significant attention. Learning node-wise message propagation in GNNs aims to set personalized propagation steps for different nodes in the graph. Despite the success, existing methods ignore node priority that can be reflected by node influence and heterophily. In this paper, we propose a versatile framework PPro, which can be integrated with most existing GNN models and aim to learn prioritized node-wise message propagation in GNNs. Specifically, the framework consists of three components: a backbone GNN model, a propagation controller to determine the optimal propagation steps for nodes, and a weight controller to compute the priority scores for nodes. We design a mutually enhanced mechanism to compute node priority, optimal propagation step and label prediction. We also propose an alternative optimization strategy to learn the parameters in the backbone GNN model and two parametric controllers. We conduct extensive experiments to compare our framework with other 11 state-of-the-art competitors on 8 benchmark datasets. Experimental results show that our framework can lead to superior performance in terms of propagation strategies and node representations.
</details>
<details>
<summary>摘要</summary>
GRAPH神经网络 (GNN) 在最近几年得到了广泛的关注。学习图像中节点之间的消息传递是一项核心的任务。虽然现有方法已经取得了成功，但是它们忽略了节点优先级，这可以通过节点影响和hetrophy来反映。在这篇论文中，我们提出了一种通用的框架PPro，可以与大多数现有的 GNN 模型集成，并且学习个性化节点消息传递步骤。具体来说，该框架包括三个组件：一个基础 GNN 模型、一个传递控制器来确定节点的最佳传递步骤，以及一个权重控制器来计算节点的优先级分数。我们设计了互相增强的机制来计算节点优先级、最佳传递步骤和标签预测。我们还提出了一种代替优化策略来学习 Parameters 在基础 GNN 模型和两个 Parametric 控制器中。我们进行了广泛的实验，与 11 个现有的竞争对手进行比较，在 8 个标准测试集上。实验结果显示，我们的框架可以在消息传递策略和节点表示方面取得超过其他竞争对手的优秀表现。
</details></li>
</ul>
<hr>
<h2 id="On-Subagging-Boosted-Probit-Model-Trees"><a href="#On-Subagging-Boosted-Probit-Model-Trees" class="headerlink" title="On Subagging Boosted Probit Model Trees"></a>On Subagging Boosted Probit Model Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02827">http://arxiv.org/abs/2311.02827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tian Qin, Wei-Min Huang</li>
<li>For: The paper proposes a new hybrid bagging-boosting algorithm named SBPMT for classification problems, which leverages the insight of variance-bias decomposition to improve the accuracy of the model.* Methods: The paper introduces a new tree model called Probit Model Tree (PMT) as the base classifier in the AdaBoost procedure, and performs boosted PMTs on each subagged dataset to form a powerful “committee” that can be viewed as an incomplete U-statistic.* Results: The paper shows that SBPMT is consistent under certain assumptions, and increasing the subagging times can reduce the generalization error of SBPMT to some extent. Additionally, the paper shows that large number of ProbitBoost iterations in PMT can benefit the performance of SBPMT with fewer steps in the AdaBoost part, and provides a useful guidance in model tuning. The paper also compares the performance of SBPMT with other state-of-the-art classification methods and shows that it has competitive prediction power in general and performs significantly better in some cases.Here is the simplified Chinese version of the three key points:* For: 这篇论文提出了一种新的Hybrid bagging-boosting算法，即SBPMT，用于分类问题，利用了差异-偏见分解的思想来提高模型的准确性。* Methods: 论文引入了一种新的树模型，namely Probit Model Tree (PMT)，作为AdaBoost过程中的基础分类器，并在每个副抽样后进行了加boosted PMTs，将其组合成一个强大的”委员会”，可以被视为一种不完全的U-统计。* Results: 论文显示了SBPMT在某些条件下是一个定理的算法，并且可以通过增加副抽样次数来减少SBPMT的泛化误差。此外，论文还显示了大量的ProbitBoost迭代在PMТ中可以提高SBPMT的性能，并且提供了一个有用的模型调整指南。最后，论文进行了与其他当前状态的分类方法进行比较，并证明了SBPMT在总体上具有竞争力的预测力，并在一些情况下表现更好。<details>
<summary>Abstract</summary>
With the insight of variance-bias decomposition, we design a new hybrid bagging-boosting algorithm named SBPMT for classification problems. For the boosting part of SBPMT, we propose a new tree model called Probit Model Tree (PMT) as base classifiers in AdaBoost procedure. For the bagging part, instead of subsampling from the dataset at each step of boosting, we perform boosted PMTs on each subagged dataset and combine them into a powerful "committee", which can be viewed an incomplete U-statistic. Our theoretical analysis shows that (1) SBPMT is consistent under certain assumptions, (2) Increase the subagging times can reduce the generalization error of SBPMT to some extent and (3) Large number of ProbitBoost iterations in PMT can benefit the performance of SBPMT with fewer steps in the AdaBoost part. Those three properties are verified by a famous simulation designed by Mease and Wyner (2008). The last two points also provide a useful guidance in model tuning. A comparison of performance with other state-of-the-art classification methods illustrates that the proposed SBPMT algorithm has competitive prediction power in general and performs significantly better in some cases.
</details>
<details>
<summary>摘要</summary>
通过变iance-bias decomposition的视角，我们设计了一种新的hybrid bagging-boosting算法名为SBPMT，用于解决类型问题。在boosting部分中，我们提出了一种新的树模型called Probit Model Tree (PMT)作为AdaBoost过程中的基本分类器。在bagging部分中，而不是在每次boosting过程中从数据集中采样，我们会在每次采样后对相应的子集进行boosted PMT处理，并将其们组合成一个强大的"委员会"，可以视为一个不完全的U-统计。我们的理论分析表明：1）SBPMT在某些假设下是一个consistent的算法，2）增加subagging次数可以有助于SBPMT减少泛化误差，3）在PMT中增加ProbitBoost迭代次数可以提高SBPMT的性能，但需要减少AdaBoost部分的迭代次数。这三个特性得到了Mease和Wyner（2008）的著名的 simulate示例的验证。最后两个点还提供了有用的模型调整指南。对比其他当前最佳分类方法，我们的提出的SBPMT算法在总体来说具有竞争力的预测力，并在某些情况下表现出色。
</details></li>
</ul>
<hr>
<h2 id="Signal-Processing-Meets-SGD-From-Momentum-to-Filter"><a href="#Signal-Processing-Meets-SGD-From-Momentum-to-Filter" class="headerlink" title="Signal Processing Meets SGD: From Momentum to Filter"></a>Signal Processing Meets SGD: From Momentum to Filter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02818">http://arxiv.org/abs/2311.02818</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhipeng Yao, Guisong Chang, Jiaqi Zhang, Qi Zhang, Yu Zhang, Dazhou Li</li>
<li>for: This paper aims to explore the potential benefits of reducing the variance of historical gradients to make optimizer converge to flat solutions.</li>
<li>methods: The proposed method, SGDF (Stochastic Gradient Descent With Filter), employs the Wiener filter theory to enhance the first moment estimation of SGD, notably introducing an adaptive weight to optimizer.</li>
<li>results: Experimental results demonstrated that SGDF can achieve satisfactory performance compared with state-of-the-art optimizers.Here’s the simplified Chinese text for the three information:</li>
<li>for: 这篇论文目标是减少历史梯度的方差，使优化器 converges to 平面解。</li>
<li>methods: 提议的方法是使用 Wiener 缓冲理论来增强 SGD 的首个 moments 估计，并引入 adaptive Weight 到优化器中。</li>
<li>results: 实验结果表明，SGDF 可以与当前的状态体验优化器相比，达到满意的性能。<details>
<summary>Abstract</summary>
In the field of deep learning, Stochastic Gradient Descent (SGD) and its momentum-based variants are the predominant choices for optimization algorithms. Despite all that, these momentum strategies, which accumulate historical gradients by using a fixed $\beta$ hyperparameter to smooth the optimization processing, often neglect the potential impact of the variance of historical gradients on the current gradient estimation. In the gradient variance during training, fluctuation indicates the objective function does not meet the Lipschitz continuity condition at all time, which raises the troublesome optimization problem. This paper aims to explore the potential benefits of reducing the variance of historical gradients to make optimizer converge to flat solutions. Moreover, we proposed a new optimization method based on reducing the variance. We employed the Wiener filter theory to enhance the first moment estimation of SGD, notably introducing an adaptive weight to optimizer. Specifically, the adaptive weight dynamically changes along with temporal fluctuation of gradient variance during deep learning model training. Experimental results demonstrated our proposed adaptive weight optimizer, SGDF (Stochastic Gradient Descent With Filter), can achieve satisfactory performance compared with state-of-the-art optimizers.
</details>
<details>
<summary>摘要</summary>
在深度学习中，Stochastic Gradient Descent（SGD）和其带有动量的变体是优化算法的主流。尽管如此，这些动量策略通常忽略了历史梯度的变化对当前梯度估计的影响。在训练过程中，梯度变化的方差指示函数不满足李氏连续性条件，导致优化问题。本文旨在探讨降低历史梯度变化的 variance 的潜在 beneficial 效果，并提出了一种基于 reducing variance 的新优化方法。我们使用了 Wiener 筛理论来增强 SGD 的首要 moment 估计，特别是引入了适应性的 Adaptive Weight。在训练深度学习模型时，适应性的 Adaptive Weight 会随着梯度方差的时间变化而改变。实验结果表明我们的提案的 Adaptive Weight 优化器（SGDF）可以与当前的优化器相比肃。
</details></li>
</ul>
<hr>
<h2 id="APGL4SR-A-Generic-Framework-with-Adaptive-and-Personalized-Global-Collaborative-Information-in-Sequential-Recommendation"><a href="#APGL4SR-A-Generic-Framework-with-Adaptive-and-Personalized-Global-Collaborative-Information-in-Sequential-Recommendation" class="headerlink" title="APGL4SR: A Generic Framework with Adaptive and Personalized Global Collaborative Information in Sequential Recommendation"></a>APGL4SR: A Generic Framework with Adaptive and Personalized Global Collaborative Information in Sequential Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02816">http://arxiv.org/abs/2311.02816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingjia Yin, Hao Wang, Xiang Xu, Likang Wu, Sirui Zhao, Wei Guo, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen</li>
<li>for: 提高sequential recommendation系统的效果，增强系统的个性化和适应性。</li>
<li>methods: 提出了一种名为Adaptive and Personalized Graph Learning for Sequential Recommendation（APGL4SR）的图驱动框架，通过自适应全局共同信息和个性化适应来提高sequential recommendation系统的效果。</li>
<li>results: 比较其他基elines的试验结果表明，APGL4SR可以与其他基elines相比，提高sequential recommendation系统的效果，并且可以更好地适应用户的个性化需求。<details>
<summary>Abstract</summary>
The sequential recommendation system has been widely studied for its promising effectiveness in capturing dynamic preferences buried in users' sequential behaviors. Despite the considerable achievements, existing methods usually focus on intra-sequence modeling while overlooking exploiting global collaborative information by inter-sequence modeling, resulting in inferior recommendation performance. Therefore, previous works attempt to tackle this problem with a global collaborative item graph constructed by pre-defined rules. However, these methods neglect two crucial properties when capturing global collaborative information, i.e., adaptiveness and personalization, yielding sub-optimal user representations. To this end, we propose a graph-driven framework, named Adaptive and Personalized Graph Learning for Sequential Recommendation (APGL4SR), that incorporates adaptive and personalized global collaborative information into sequential recommendation systems. Specifically, we first learn an adaptive global graph among all items and capture global collaborative information with it in a self-supervised fashion, whose computational burden can be further alleviated by the proposed SVD-based accelerator. Furthermore, based on the graph, we propose to extract and utilize personalized item correlations in the form of relative positional encoding, which is a highly compatible manner of personalizing the utilization of global collaborative information. Finally, the entire framework is optimized in a multi-task learning paradigm, thus each part of APGL4SR can be mutually reinforced. As a generic framework, APGL4SR can outperform other baselines with significant margins. The code is available at https://github.com/Graph-Team/APGL4SR.
</details>
<details>
<summary>摘要</summary>
“对续Sequential recommendation system的研究已经广泛，因为它可以实现用户的动态喜好。然而，现有的方法通常专注于内部序列模型，忽略了利用全球协力信息，导致推荐性能不佳。因此，前一些作品尝试使用全球协力项目Graph进行推荐，但这些方法忽略了两个重要性的问题，即适应性和个性化。为了解决这个问题，我们提出了一个Graph驱动的框架，名为适应和个性化Graph学习 для续Sequential推荐（APGL4SR）。”Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="On-the-Intersection-of-Self-Correction-and-Trust-in-Language-Models"><a href="#On-the-Intersection-of-Self-Correction-and-Trust-in-Language-Models" class="headerlink" title="On the Intersection of Self-Correction and Trust in Language Models"></a>On the Intersection of Self-Correction and Trust in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02801">http://arxiv.org/abs/2311.02801</a></li>
<li>repo_url: None</li>
<li>paper_authors: Satyapriya Krishna</li>
<li>for: 这项研究旨在调查自我修正技术可以提高大型自然语言模型（LLM）的可靠性。</li>
<li>methods: 我们使用了两个关键方面来测试LLM的可靠性： truthfulness和toxicity。</li>
<li>results: 我们发现自我修正可以提高LLM的toxicity和truthfulness，但这些改进的程度因任务和自我修正的特点而异。此外，我们还发现了LLM在自我修正过程中的”自我犹豫”现象，这引入了新的挑战。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable capabilities in performing complex cognitive tasks. However, their complexity and lack of transparency have raised several trustworthiness concerns, including the propagation of misinformation and toxicity. Recent research has explored the self-correction capabilities of LLMs to enhance their performance. In this work, we investigate whether these self-correction capabilities can be harnessed to improve the trustworthiness of LLMs. We conduct experiments focusing on two key aspects of trustworthiness: truthfulness and toxicity. Our findings reveal that self-correction can lead to improvements in toxicity and truthfulness, but the extent of these improvements varies depending on the specific aspect of trustworthiness and the nature of the task. Interestingly, our study also uncovers instances of "self-doubt" in LLMs during the self-correction process, introducing a new set of challenges that need to be addressed.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Large Language Models" is translated as "大语言模型" (dà yǔ yán módel), which is a commonly used term in the field of natural language processing.* "trustworthiness" is translated as "可靠性" (kě huì xìng), which refers to the reliability and credibility of a system or model.* "self-correction" is translated as "自我修正" (zì wǒ xiù zhèng), which refers to the ability of a system or model to correct its own errors or inaccuracies.* "truthfulness" is translated as "真实性" (zhēn shí xìng), which refers to the accuracy and fidelity of a system or model in representing reality.* "toxicity" is translated as "毒性" (dāo xìng), which refers to the harmful or offensive content that a system or model may produce or promote.* "self-doubt" is translated as "自我犹豫" (zì wǒ yòu yòu), which refers to the uncertainty or hesitation that a system or model may experience when making decisions or correcting its own errors.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.LG_2023_11_06/" data-id="cloojsmj400t2re8809573ayf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/eess.IV_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T09:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/eess.IV_2023_11_06/">eess.IV - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Auto-ICell-An-Accessible-and-Cost-Effective-Integrative-Droplet-Microfluidic-System-for-Real-Time-Single-Cell-Morphological-and-Apoptotic-Analysis"><a href="#Auto-ICell-An-Accessible-and-Cost-Effective-Integrative-Droplet-Microfluidic-System-for-Real-Time-Single-Cell-Morphological-and-Apoptotic-Analysis" class="headerlink" title="Auto-ICell: An Accessible and Cost-Effective Integrative Droplet Microfluidic System for Real-Time Single-Cell Morphological and Apoptotic Analysis"></a>Auto-ICell: An Accessible and Cost-Effective Integrative Droplet Microfluidic System for Real-Time Single-Cell Morphological and Apoptotic Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02927">http://arxiv.org/abs/2311.02927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Wei, Meiai Lin, Shanhang Luo, Syed Muhammad Tariq Abbasi, Liwei Tan, Guangyao Cheng, Bijie Bai, Yi-Ping Ho, Scott Wu Yuan, Ho-Pui Ho</li>
<li>for: 该研究旨在开发一种新型、可靠、cost-effective的集成液态微流体系统，用于实时分析单个细胞形态和程序细胞。</li>
<li>methods: 该系统使用3D打印微流体chips和图像分析算法，可生成固定径度的液体块和实时图像分析。图像分析算法包括基于颜色的图像分析算法和深度学习算法，用于分析细胞内容和细胞凋亡。</li>
<li>results: 研究人员使用 breast cancer细胞模型，将细胞 encapsulated within uniform droplets，径度范围为70μm-240μm，并实现了高速生成1500个液体块每分钟。实时图像分析结果在2秒钟内显示在自定义图形用户界面上。系统可自动计算液体块中颜色的分布和细胞内容的含量，并对细胞的凋亡和圆形进行观察和量化分析。<details>
<summary>Abstract</summary>
The Auto-ICell system, a novel, and cost-effective integrated droplet microfluidic system, is introduced for real-time analysis of single-cell morphology and apoptosis. This system integrates a 3D-printed microfluidic chip with image analysis algorithms, enabling the generation of uniform droplet reactors and immediate image analysis. The system employs a color-based image analysis algorithm in the bright field for droplet content analysis. Meanwhile, in the fluorescence field, cell apoptosis is quantitatively measured through a combination of deep-learning-enabled multiple fluorescent channel analysis and a live/dead cell stain kit. Breast cancer cells are encapsulated within uniform droplets, with diameters ranging from 70 {\mu}m to 240 {\mu}m, generated at a high throughput of 1,500 droplets per minute. Real-time image analysis results are displayed within 2 seconds on a custom graphical user interface (GUI). The system provides an automatic calculation of the distribution and ratio of encapsulated dyes in the bright field, and in the fluorescent field, cell blebbing and cell circularity are observed and quantified respectively. The Auto-ICell system is non-invasive and provides online detection, offering a robust, time-efficient, user-friendly, and cost-effective solution for single-cell analysis. It significantly enhances the detection throughput of droplet single-cell analysis by reducing setup costs and improving operational performance. This study highlights the potential of the Auto-ICell system in advancing biological research and personalized disease treatment, with promising applications in cell culture, biochemical microreactors, drug carriers, cell-based assays, synthetic biology, and point-of-care diagnostics.
</details>
<details>
<summary>摘要</summary>
新的Auto-ICell系统，一个 novel 和 cost-effective的组合式液体微流体系统，为实时分析单元细胞形态和 apoptosis 提供了一个解决方案。这个系统通过与影像分析算法集成，实现了均匀的液体实验室和实时影像分析。系统使用了彩色基于影像分析算法，在亮场下进行液体内容分析。同时，在萤光场下，通过萤光测定和 live/dead 细胞染料组合，量化细胞 apoptosis。单元细胞被均匀的液体囊包，尺度为70μm至240μm，每分钟可生成1,500个液体囊。实时影像分析结果在2秒内显示在自定义的 графікал用户界面（GUI）上。系统可自动计算液体内容中的分布和比例，以及萤光场下细胞液体化和细胞圆形性的观察和量化。Auto-ICell系统不侵入性高，提供线上检测，实现了高效、时间高效、易用、成本低的单元细胞分析解决方案。它将单元细胞分析的设置成本和操作性提高，提高检测速率和精度。这篇研究显示Auto-ICell系统在生物研究和人类疾病治疗方面具有潜力，具体应用包括单元细胞 кульURE、生物化学微 реактор、药物传递者、细胞基因�Relative expression analysis,细胞�Culturing,体外试验、生物技术和点检验。
</details></li>
</ul>
<hr>
<h2 id="An-invariant-feature-extraction-for-multi-modal-images-matching"><a href="#An-invariant-feature-extraction-for-multi-modal-images-matching" class="headerlink" title="An invariant feature extraction for multi-modal images matching"></a>An invariant feature extraction for multi-modal images matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02842">http://arxiv.org/abs/2311.02842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenzhong Gao, Wei Li</li>
<li>for: 这个论文目的是提供一种有效的多模式图像无关特征提取和匹配算法，用于多源数据分析。</li>
<li>methods: 本论文使用了相位同步（PC）和史提莫asi特征点检测，LogGabor滤波器和质量补做权重主要方向图（WPMOM）进行特征提取，并使用多尺度进程来处理尺度差异并优化匹配结果。</li>
<li>results: 实验结果表明，该算法在实际数据上具有良好的空间匹配精度和实际应用价值，并且在多种多样的图像数据上具有良好的泛化性。<details>
<summary>Abstract</summary>
This paper aims at providing an effective multi-modal images invariant feature extraction and matching algorithm for the application of multi-source data analysis. Focusing on the differences and correlation of multi-modal images, a feature-based matching algorithm is implemented. The key technologies include phase congruency (PC) and Shi-Tomasi feature point for keypoints detection, LogGabor filter and a weighted partial main orientation map (WPMOM) for feature extraction, and a multi-scale process to deal with scale differences and optimize matching results. The experimental results on practical data from multiple sources prove that the algorithm has effective performances on multi-modal images, which achieves accurate spatial alignment, showing practical application value and good generalization.
</details>
<details>
<summary>摘要</summary>
本文提出了一种有效的多modal图像不变性特征提取和匹配算法，用于多源数据分析应用。关注多modal图像之间的差异和相关性，实现了基于特征的匹配算法。关键技术包括相位协同 (PC) 和史提莫asi特征点检测、LogGabor滤波器和Weighted Partial Main Orientation Map (WPMOM) 特征提取，以及多尺度处理来处理比例差异并优化匹配结果。实验结果表明，该算法在实际数据多源中有效地处理多modal图像，实现了准确的空间对齐，表现出实际应用价值和良好的泛化性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/eess.IV_2023_11_06/" data-id="cloojsmpt018pre88apqbb3nh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/eess.SP_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T08:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/eess.SP_2023_11_06/">eess.SP - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Resource-Allocation-for-RIS-Empowered-Wireless-Communications-Low-Complexity-and-Robust-Designs"><a href="#Resource-Allocation-for-RIS-Empowered-Wireless-Communications-Low-Complexity-and-Robust-Designs" class="headerlink" title="Resource Allocation for RIS-Empowered Wireless Communications: Low-Complexity and Robust Designs"></a>Resource Allocation for RIS-Empowered Wireless Communications: Low-Complexity and Robust Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03282">http://arxiv.org/abs/2311.03282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Zeng, Wanming Hao, Zhangjie Peng, Zheng Chu, Xingwang Li, Changsheng You, Cunhua Pan</li>
<li>for: 这篇论文专门研究了利用可编程智能面（RIS）系统的资源分配技术的进展，以实现低复杂性和可靠性。</li>
<li>methods: 该论文提出了一种基于可编程智能面（RIS）系统的资源分配技术，包括低复杂性和Robust resource allocation的方法。</li>
<li>results: 该论文通过数值例子展示了这些方法的效果，并证明了低复杂性和可靠性的资源分配技术对RIS-助けbrowsing系统的应用有重要意义。<details>
<summary>Abstract</summary>
This article delves into advancements in resource allocation techniques tailored for systems utilizing reconfigurable intelligent surfaces (RIS), with a primary focus on achieving low-complexity and resilient solutions. The investigation of low-complexity approaches for RIS holds significant relevance, primarily owing to the intricate characteristics inherent in RIS-based systems and the need of deploying large-scale RIS arrays. Concurrently, the exploration of robust solutions aims to address the issue of hardware impairments occurring at both the transceivers and RIS components in practical RIS-assisted systems. In the realm of both low-complexity and robust resource allocation, this article not only elucidates the fundamental techniques underpinning these methodologies but also offers comprehensive numerical results for illustrative purposes. The necessity of adopting resource allocation strategies that are both low in complexity and resilient is thoroughly established. Ultimately, this article provides prospective research avenues in the domain of low-complexity and robust resource allocation techniques tailored for RIS-assisted systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multivariate-selfsimilarity-Multiscale-eigen-structures-for-selfsimilarity-parameter-estimation"><a href="#Multivariate-selfsimilarity-Multiscale-eigen-structures-for-selfsimilarity-parameter-estimation" class="headerlink" title="Multivariate selfsimilarity: Multiscale eigen-structures for selfsimilarity parameter estimation"></a>Multivariate selfsimilarity: Multiscale eigen-structures for selfsimilarity parameter estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03247">http://arxiv.org/abs/2311.03247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charles-Gérard Lucas, Gustavo Didier, Herwig Wendt, Patrice Abry</li>
<li>for: 本研究旨在提供一种高效的多变量自相似性参数估计方法，以满足现实世界数据分析中的需求。</li>
<li>methods: 该方法基于卷积函数spectrum的多谱结构，并利用近期的数学发展来实现有效的参数估计。</li>
<li>results: 该方法可以在各种大小和样本大小下提供高度精度的参数估计，并且在实际应用中可以有效地预测多通道EEG数据中的癫痫症发作。<details>
<summary>Abstract</summary>
Scale-free dynamics, formalized by selfsimilarity, provides a versatile paradigm massively and ubiquitously used to model temporal dynamics in real-world data. However, its practical use has mostly remained univariate so far. By contrast, modern applications often demand multivariate data analysis. Accordingly, models for multivariate selfsimilarity were recently proposed. Nevertheless, they have remained rarely used in practice because of a lack of available robust estimation procedures for the vector of selfsimilarity parameters. Building upon recent mathematical developments, the present work puts forth an efficient estimation procedure based on the theoretical study of the multiscale eigenstructure of the wavelet spectrum of multivariate selfsimilar processes. The estimation performance is studied theoretically in the asymptotic limits of large scale and sample sizes, and computationally for finite-size samples. As a practical outcome, a fully operational and documented multivariate signal processing estimation toolbox is made freely available and is ready for practical use on real-world data. Its potential benefits are illustrated in epileptic seizure prediction from multi-channel EEG data.
</details>
<details>
<summary>摘要</summary>
“簇割自相似性”是一种广泛应用于实际数据中的时间动态模型，但是它在实际应用中多是单变量的。然而，现代应用通常需要多变量数据分析。因此，用于多变量自相似性的模型在最近才开始被提出。然而，这些模型在实际应用中几乎没有被使用，因为它们的自相似性vector的估计方法缺乏可靠的可用性。本工作基于最近的数学发展，提出了一个有效的估计方法，通过研究多对多自相似性变数的多对多对多对多抽象矩阵的波летспектル。本方法的估计性被理论上研究在大规模和样本大小的两个对应限制下，并且在 computationally 中进行了实际数据的评估。作为实用的结果，一个具有完整的操作和文档的多变量信号处理估计工具组被免费提供，并且已经准备好用于实际数据中。其潜在优点在多通道 EEG 数据中预测 epileptic seizure。
</details></li>
</ul>
<hr>
<h2 id="Using-Shallow-Neural-Networks-with-Functional-Connectivity-from-EEG-signals-for-Early-Diagnosis-of-Alzheimer’s-and-Frontotemporal-Dementia"><a href="#Using-Shallow-Neural-Networks-with-Functional-Connectivity-from-EEG-signals-for-Early-Diagnosis-of-Alzheimer’s-and-Frontotemporal-Dementia" class="headerlink" title="Using Shallow Neural Networks with Functional Connectivity from EEG signals for Early Diagnosis of Alzheimer’s and Frontotemporal Dementia"></a>Using Shallow Neural Networks with Functional Connectivity from EEG signals for Early Diagnosis of Alzheimer’s and Frontotemporal Dementia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03151">http://arxiv.org/abs/2311.03151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zaineb Ajra, Binbin Xu, Gérard Dray, Jacky Montmain, Stéphane Perrey</li>
<li>For:  This paper aims to develop and evaluate shallow neural network-based methods for classifying EEG signals of Alzheimer’s disease (AD) and frontotemporal dementia (FTD) compared to control cases.* Methods:  The paper proposes using two sets of features: spectral-temporal and functional connectivity, and four methods: shallow neural network-based models, conventional methods, and different measures of functional connectivity from common EEG frequency bands considering multiple thresholds.* Results:  The shallow CNN-based models achieved the highest accuracy of 94.54% with AEC in the test dataset when considering all connections, outperforming conventional methods and providing potentially an additional early dementia diagnosis tool.Here is the information in Simplified Chinese text:* For: 这篇论文目的是开发和评估基于 shallow neural network 的 EEG 信号分类方法，用于识别阿尔茨海默病 (AD) 和前 temporal dementia (FTD) 与控制群体。* Methods: 论文提议使用两个集合特征：spectral-temporal 和功能连接性，以及四种方法： shallow neural network 基于模型、传统方法和不同的功能连接度评估方法。* Results:  shallow CNN 基于模型在测试集上 achieved 94.54% 的最高准确率，超过传统方法，并提供了可能的违AND 早期诊断工具。<details>
<summary>Abstract</summary>
{Introduction: } Dementia is a neurological disorder associated with aging that can cause a loss of cognitive functions, impacting daily life. Alzheimer's disease (AD) is the most common cause of dementia, accounting for 50--70\% of cases, while frontotemporal dementia (FTD) affects social skills and personality. Electroencephalography (EEG) provides an effective tool to study the effects of AD on the brain. {Methods: } In this study, we propose to use shallow neural networks applied to two sets of features: spectral-temporal and functional connectivity using four methods. We compare three supervised machine learning techniques to the CNN models to classify EEG signals of AD / FTD and control cases. We also evaluate different measures of functional connectivity from common EEG frequency bands considering multiple thresholds. {Results and Discussion: } Results showed that the shallow CNN-based models achieved the highest accuracy of 94.54\% with AEC in test dataset when considering all connections, outperforming conventional methods and providing potentially an additional early dementia diagnosis tool. \url{https://doi.org/10.3389%2Ffneur.2023.1270405}
</details>
<details>
<summary>摘要</summary>
{Methods: } 在本研究中，我们提议使用浅层神经网络，应用于两个集合：spectral-temporal和功能相关性，使用四种方法。我们比较了三种supervised machine learning技术和CNN模型来分类EEG信号的AD / FTD和控制 caso。我们还评估了不同的功能相关性度量从常见EEG频率带中考虑多个阈值。{Results and Discussion: } 结果显示，我们的浅层CNN-based模型在测试集上达到了94.54%的准确率，在考虑所有连接时，超越了传统方法，并提供了可能的补充早期诊断工具。参考文献：https://doi.org/10.3389/fneur.2023.1270405
</details></li>
</ul>
<hr>
<h2 id="Energy-Harvesting-Maximization-for-Reconfigurable-Intelligent-Surfaces-Using-Amplitude-Measurements"><a href="#Energy-Harvesting-Maximization-for-Reconfigurable-Intelligent-Surfaces-Using-Amplitude-Measurements" class="headerlink" title="Energy Harvesting Maximization for Reconfigurable Intelligent Surfaces Using Amplitude Measurements"></a>Energy Harvesting Maximization for Reconfigurable Intelligent Surfaces Using Amplitude Measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03143">http://arxiv.org/abs/2311.03143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morteza Tavana, Meysam Masoudi, Emil Björnson</li>
<li>for: 这个论文主要关注了无法协调的 ambient RF 源下 RIS 的能量吸收问题。</li>
<li>methods: 该论文提出了一系列的顺序相对准确策略，以最大化接收到的功率基于仅仅是功率测量结果。</li>
<li>results: 我们的 simulations 结果表明，提议的算法在与Random Phase Update 方法进行比较后，在达到相同的功率水平上具有更好的性能，并且需要 fewer 测量每次准确策略更新。在噪声存在的情况下，我们的结果表明，在有限的可能的相位偏移集中，提议的方法是优化的，但不是最优的。<details>
<summary>Abstract</summary>
Energy harvesting can enable a reconfigurable intelligent surface (RIS) to self-sustain its operations without relying on external power sources. In this paper, we consider the problem of energy harvesting for RISs in the absence of coordination with the ambient RF source. We propose a series of sequential phase-alignment algorithms that maximize the received power based on only power measurements. We prove the convergence of the proposed algorithm to the optimal value for the noiseless scenario. However, for the noisy scenario, we propose a linear least squares estimator. We prove that within the class of linear estimators, the optimal set of measurement phases are equally-spaced phases. To evaluate the performance of the proposed method, we introduce a random phase update algorithm as a benchmark. Our simulation results show that the proposed algorithms outperform the random phase update method in terms of achieved power after convergence while requiring fewer measurements per phase update. Using simulations, we show that in a noiseless scenario with a discrete set of possible phase shifts for the RIS elements, the proposed method is sub-optimal, achieving a higher value than the random algorithm but not exactly the maximum feasible value that we obtained by exhaustive search.
</details>
<details>
<summary>摘要</summary>
能量收集可以让自适应智能表面（RIS）不依赖于外部电源进行自 sustain 操作。在这篇论文中，我们考虑了RIS中能量收集的问题，不包括与周围的RF源协调。我们提出了一系列的顺序相对位置算法，以最大化接收到的能量基于仅仅是电力测量。我们证明了无噪enario下的提案算法的极限值是最佳的。然而，在噪 scenario下，我们提出了线性最小二乘估计器。我们证明了在线性估计器中的优化集是均匀分布的相对位置。为评估提案方法的性能，我们引入了随机相位更新算法作为参照。我们的 simulate 结果显示，提案方法在 converges 后的实现的功率超过随机相位更新方法，并且需要 fewer 测量每次相位更新。在一个离散的可能的相位偏移集中的噪 scenario下，我们的方法是优化的，实现了高于随机算法的值，但不是最大可能的值，我们通过极限搜索获得了。
</details></li>
</ul>
<hr>
<h2 id="Antenna-Positioning-and-Beamforming-Design-for-Movable-Antenna-Enabled-Multi-user-Downlink-Communications"><a href="#Antenna-Positioning-and-Beamforming-Design-for-Movable-Antenna-Enabled-Multi-user-Downlink-Communications" class="headerlink" title="Antenna Positioning and Beamforming Design for Movable-Antenna Enabled Multi-user Downlink Communications"></a>Antenna Positioning and Beamforming Design for Movable-Antenna Enabled Multi-user Downlink Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03046">http://arxiv.org/abs/2311.03046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Qin, Wen Chen, Zhendong Li, Qingqing Wu, Nan Cheng, Fangjiong Chen</li>
<li>for: 这个论文研究了一个多输入单出口（MISO）下行通信系统，在该系统中用户装备了可动天线（MA）。</li>
<li>methods: 论文采用了场响应基于通道模型来描述下行通道，并且通过对 MA 的位置和扩散矩阵进行共同优化来最小化总发射功率。</li>
<li>results: numerical results显示，MA-enabled通信系统比传统固定天线系统更高效。I hope that helps!<details>
<summary>Abstract</summary>
This paper investigates a multiple input single output (MISO) downlink communication system in which users are equipped with movable antennas (MAs). First, We adopt a field-response based channel model to characterize the downlink channel with respect to MAs' positions. Then, we aim to minimize the total transmit power by jointly optimizing the MAs' positions and beamforming matrix. To solve the resulting non-convex problem, we employ an alternating optimization (AO) algorithm based on penalty method and successive convex approximation (SCA) to obtain a sub-optimal solution. Numerical results demonstrate that the MA-enabled communication system perform better than conventional fixed position antennas.
</details>
<details>
<summary>摘要</summary>
这个论文研究了一个多输入单输出（MISO）下降通信系统，在该系统中用户装备了可动天线（MA）。我们首先采用场响应基本的通道模型来Characterize下降通道，即MA的位置。然后，我们寻求最小化总发射功率，通过同时优化MA的位置和扩散矩阵来解决这个非核心问题。为解决这个问题，我们采用了 alternate optimization（AO）算法基于罚方法和Successive Convex Approximation（SCA）来获得一个近似解。 numerically results显示， MA启用的通信系统在比 conventions fixed position antennasperform better。Note: Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Optimization-of-RIS-Placement-for-Satellite-to-Ground-Coverage-Enhancement"><a href="#Optimization-of-RIS-Placement-for-Satellite-to-Ground-Coverage-Enhancement" class="headerlink" title="Optimization of RIS Placement for Satellite-to-Ground Coverage Enhancement"></a>Optimization of RIS Placement for Satellite-to-Ground Coverage Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02958">http://arxiv.org/abs/2311.02958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingchen Liu, Liuxun Xue, Shu Sun, Meixia Tao</li>
<li>for: 提高卫星到地面通信的可靠性和效率，通过嵌入智能表面技术。</li>
<li>methods: 提出了一种基于大规模RIS部署的卫星到地面通信覆盖优化方法，并使用了优化框架和平行遗传算法来解决问题。</li>
<li>results: 通过模拟和分析，研究发现了大规模RIS部署对卫星到地面通信的非视线用户覆盖率提高的理论下界，并且通过对不同建筑分布的研究，提出了可应用于各种场景的优化策略。<details>
<summary>Abstract</summary>
In satellite-to-ground communication, ensuring reliable and efficient connectivity poses significant challenges. The reconfigurable intelligent surface (RIS) offers a promising solution due to its ability to manipulate wireless propagation environments and thus enhance communication performance. In this paper, we propose a method for optimizing the placement of RISs on building facets to improve satellite-to-ground communication coverage. We model satellite-to-ground communication with RIS assistance, considering the actual positions of buildings and ground users. The theoretical lower bound on the coverage enhancement in satellite-to-ground communication through large-scale RIS deployment is derived. Then a novel optimization framework for RIS placement is formulated, and a parallel genetic algorithm is employed to solve the problem. Simulation results demonstrate the superior performance of the proposed RIS deployment strategy in enhancing satellite communication coverage probability for non-line-of-sight users. The proposed framework can be applied to various architectural distributions, such as rural areas, towns, and cities, by adjusting parameter settings.
</details>
<details>
<summary>摘要</summary>
卫星到地面通信中确保可靠和高效的连接具有 significatif挑战。智能表面重配置（RIS）提供了一个有 promise的解决方案，因为它可以 manipulate wireless propagation environments并提高通信性能。在这篇论文中，我们提出了一种方法来优化RIS的建筑面部署，以提高卫星到地面通信覆盖率。我们使用实际建筑物和地面用户的位置来模拟卫星到地面通信，并 derivethe theoretical lower bound on the coverage enhancement in satellite-to-ground communication through large-scale RIS deployment。然后，我们提出了一个新的优化框架，并使用并行遗传算法来解决问题。 simulation results show that the proposed RIS deployment strategy can significantly enhance the satellite communication coverage probability for non-line-of-sight users.该提议的框架可以应用于不同的建筑分布，如乡村、镇和城市，只需调整参数设置。
</details></li>
</ul>
<hr>
<h2 id="Channel-Estimation-and-Training-Design-for-Active-RIS-Aided-Wireless-Communications"><a href="#Channel-Estimation-and-Training-Design-for-Active-RIS-Aided-Wireless-Communications" class="headerlink" title="Channel Estimation and Training Design for Active RIS Aided Wireless Communications"></a>Channel Estimation and Training Design for Active RIS Aided Wireless Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02935">http://arxiv.org/abs/2311.02935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Nanxi Li, Ruizhe Long, Ying-Chang Liang</li>
<li>for: 这个论文是为了提高无线通信的精度而设计的。</li>
<li>methods: 该论文使用了活动重配置智能表面（ARIS）技术，并利用了 radio frequency（RF）反射增强器来实现配置可变的反射元素（RE）的增强。</li>
<li>results: 该论文的实验结果表明，通过使用ARIS来提高通信链路的精度，并且可以减少通信链路中的频率噪声。<details>
<summary>Abstract</summary>
Active reconfigurable intelligent surface (ARIS) is a newly emerging RIS technique that leverages radio frequency (RF) reflection amplifiers to empower phase-configurable reflection elements (REs) in amplifying the incident signal. Thereby, ARIS can enhance wireless communications with the strengthened ARIS-aided links. In this letter, we propose exploiting the signal amplification capability of ARIS for channel estimation, aiming to improve the estimation precision. Nevertheless, the signal amplification inevitably introduces the thermal noise at the ARIS, which can hinder the acquisition of accurate channel state information (CSI) with conventional channel estimation methods based on passive RIS (PRIS). To address this issue, we further investigate this ARIS-specific channel estimation problem and propose a least-square (LS) based channel estimator, whose performance can be further improved with the design on ARIS reflection patterns at the channel training phase. Based on the proposed LS channel estimator, we optimize the training reflection patterns to minimize the channel estimation error variance. Extensive simulation results show that our proposed design can achieve accurate channel estimation in the presence of the ARIS noises.
</details>
<details>
<summary>摘要</summary>
活动可重新配置智能表面（ARIS）是一种新兴的RIS技术，利用电磁波（RF）反射增强器来实现配置可变的反射元件（RE），从而提高了无线通信的覆盖范围和传输速率。在这封信中，我们提议利用ARIS增强了的信号强度来提高通信频率的扬化率。然而，增强信号会导致ARIS中的热噪声，这可能会阻碍通过传统的PRIS（被动RIS）基于的渠道估计方法获得准确的渠道状态信息（CSI）。为解决这个问题，我们进一步研究了ARIS特有的渠道估计问题，并提议使用最小二乘（LS）基于的渠道估计器，其性能可以通过ARIS反射模式的设计在通道训练阶段进行改进。基于我们提议的LS渠道估计器，我们优化了训练反射模式，以最小化渠道估计错误均方。通过广泛的 simulations 实验，我们发现我们的设计可以在ARIS噪声存在的情况下实现准确的渠道估计。
</details></li>
</ul>
<hr>
<h2 id="Pilot-Design-and-Signal-Detection-for-Symbiotic-Radio-over-OFDM-Carriers"><a href="#Pilot-Design-and-Signal-Detection-for-Symbiotic-Radio-over-OFDM-Carriers" class="headerlink" title="Pilot Design and Signal Detection for Symbiotic Radio over OFDM Carriers"></a>Pilot Design and Signal Detection for Symbiotic Radio over OFDM Carriers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02928">http://arxiv.org/abs/2311.02928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Qianqian Zhang, Ruizhe Long, Yiyang Pei, Ying-Chang Liang</li>
<li>for: 这个论文旨在探讨对于多元化频率分配和低功率传输的 симбіотис广播（SR）技术的实现，并在这个技术中进行实验室评估。</li>
<li>methods: 这个论文使用了对于主要传输的垂直排版实验（pilot）设计和信号探测，以确保主要传输的通道正义性和低功率传输的可靠性。</li>
<li>results:  simulation 结果显示，这个技术可以提高主要传输的性能，并且甚至可以在没有直接链路的情况下支持主要和次要传输。此外，这个技术也可以提高对于次要传输的敏感性和多标的能力。<details>
<summary>Abstract</summary>
Symbiotic radio (SR) is a promising solution to achieve high spectrum- and energy-efficiency due to its spectrum sharing and low-power consumption properties, in which the secondary system achieves data transmissions by backscattering the signal originating from the primary system. In this paper, we are interested in the pilot design and signal detection when the primary transmission adopts orthogonal frequency division multiplexing (OFDM). In particular, to preserve the channel orthogonality among the OFDM sub-carriers, each secondary symbol is designed to span an entire OFDM symbol. The comb-type pilot structure is employed by the primary transmission, while the preamble pilot structure is used by the secondary transmission. With the designed pilot structures, the primary signal can be detected via the conventional methods by treating the secondary signal as a part of the composite channel, i.e., the effective channel of the primary transmission. Furthermore, the secondary signal can be extracted from the estimated composite channel with the help of the detected primary signal. The bit error rate (BER) performance with both perfect and estimated CSI, the diversity orders of the primary and secondary transmissions, and the sensitivity to symbol synchronization error are analyzed. Simulation results show that the performance of the primary transmission is enhanced thanks to the backscatter link established by the secondary transmission. More importantly, even without the direct link, the primary and secondary transmissions can be supported via only the backscatter link.
</details>
<details>
<summary>摘要</summary>
共生射频（SR）是一种有前途的解决方案，以实现高频率和能量效率，因为它的spectrum sharing和低功率消耗性。在这篇论文中，我们关心的是频道设计和信号检测，当主传输采用分多个卡通道分配多路复用（OFDM）时。为保持卡通道正交性，每个次级符号 span整个OFDM符号。主传输使用comb-type频道结构，而次传输使用预布频道结构。通过这些频道结构，主信号可以通过传统方法检测，即将次信号作为杂合频道（effective channel）进行检测。此外，次信号还可以通过主信号的估计来提取。我们分析了基于真实和估计频道状况信息（CSI）的吞吐量性能、多普雷达阶数和symbol synchronization error的敏感性。实验结果表明，由于次传输建立的反射链，主传输的性能得到了提高。此外，甚至没有直接链接，主和次传输仍然可以通过反射链进行支持。
</details></li>
</ul>
<hr>
<h2 id="Goal-Oriented-Wireless-Communication-Resource-Allocation-for-Cyber-Physical-Systems"><a href="#Goal-Oriented-Wireless-Communication-Resource-Allocation-for-Cyber-Physical-Systems" class="headerlink" title="Goal-Oriented Wireless Communication Resource Allocation for Cyber-Physical Systems"></a>Goal-Oriented Wireless Communication Resource Allocation for Cyber-Physical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02911">http://arxiv.org/abs/2311.02911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Feng, Kedi Zheng, Yi Wang, Kaibin Huang, Qixin Chen</li>
<li>for: 本研究旨在提高Cyber-Physical Systems（CPS）的性能，通过对无线通信网络的资源 allocate 进行目标导向的配置。</li>
<li>methods: 本研究提出了一种分解和补做法，将问题转化为一个可解knapsack问题，并通过精细的分配策略来解决。</li>
<li>results: 研究表明，通过使用目标导向的无线通信资源 allocate 策略，可以提高CPS的性能和信息吞吐量，并且可以适应不同的应用场景。<details>
<summary>Abstract</summary>
The proliferation of novel industrial applications at the wireless edge, such as smart grids and vehicle networks, demands the advancement of cyber-physical systems. The performance of CPSs is closely linked to the last-mile wireless communication networks, which often become bottlenecks due to their inherent limited resources. Current CPS operations often treat wireless communication networks as unpredictable and uncontrollable variables, ignoring the potential adaptability of wireless networks, which results in inefficient and overly conservative CPS operations. Meanwhile, current wireless communications often focus more on throughput and other transmission-related metrics instead of CPS goals. In this study, we introduce the framework of goal-oriented wireless communication resource allocations, accounting for the semantics and significance of data for CPS operation goals. This guarantees optimal CPS performance from a cybernetic standpoint. We formulate a bandwidth allocation problem aimed at maximizing the information utility gain of transmitted data brought to CPS operation goals. Since the goal-oriented bandwidth allocation problem is a large-scale combinational problem, we propose a divide-and-conquer and greedy solution algorithm. The information utility gain is first approximately decomposed into marginal utility information gains and computed in a parallel manner. Subsequently, the bandwidth allocation problem is reformulated as a knapsack problem, which can be further solved greedily with a guaranteed sub-optimality gap. We further demonstrate how our proposed goal-oriented bandwidth allocation algorithm can be applied in four potential CPS applications, including data-driven decision-making, edge learning, federated learning, and distributed optimization.
</details>
<details>
<summary>摘要</summary>
随着无线边缘应用的增多，如智能网络和交通网络，需要提高协同物理系统（CPS）的技术。CPS的性能与无线通信网络的最后一英里网络密切相关，这些网络通常因其内置的限制资源而成为瓶颈。现有CPS操作通常忽略无线通信网络的可靠性和可控性，从而导致不fficient和过度保守的CPS操作。同时，当前的无线通信更多地强调传输速率和其他传输相关指标，而不是CPS操作目标。在本研究中，我们介绍了目标 oriented 无线通信资源分配框架，考虑到数据在CPS操作目标上的 semantics 和重要性。这保证了CPS的最佳性从Cybernetic的角度。我们将信息吞吐量增加问题定义为最大化传输数据带来CPS操作目标上的信息价值增加。由于这是一个大规模的组合问题，我们提出了分治和批处理的解决方案。首先，我们将信息价值增加分解为各个数据带来的独立 utility 信息增加，并在平行进行计算。然后，我们将带WIDTH分配问题重新定义为锦锦包问题，可以通过精确的批处理法解决。我们还证明了我们提出的目标 oriented 带WIDTH分配算法可以应用于四种可能的 CPS 应用，包括数据驱动决策、边缘学习、联合学习和分布式优化。
</details></li>
</ul>
<hr>
<h2 id="Energy-Efficient-Multidimensional-Constellation-Based-on-Leech-Lattice-for-Visible-Light-Communications"><a href="#Energy-Efficient-Multidimensional-Constellation-Based-on-Leech-Lattice-for-Visible-Light-Communications" class="headerlink" title="Energy-Efficient Multidimensional Constellation Based on Leech Lattice for Visible Light Communications"></a>Energy-Efficient Multidimensional Constellation Based on Leech Lattice for Visible Light Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02865">http://arxiv.org/abs/2311.02865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Ning Guo, Ru-Han Chen, Jian Zhang, Longguang Li, Jing Zhou</li>
<li>for: 这个论文是为了研究indoor可见光通信（VLC）中的24维 геомétrically-shaped constellation设计，并且受到 peak-和 average-intensity输入限制。</li>
<li>methods: 论文使用了大偏度理论的工具来描述第二项 asymptotics of the optimal constellation shaping region，并且开发了一种能效的24维 constellation设计，通过使用called coarsely shaping and finely coding的策略来 combinig Leech lattice的优势和高级�ョ� cristallization gain。</li>
<li>results: 数值结果表明，我们的结果在比较与现有方法时具有superiority。<details>
<summary>Abstract</summary>
In this paper, a 24-dimensional geometrically-shaped constellation design based on Leech lattice is presented for indoor visible light communications (VLCs) with a peak-and an average-intensity input constraints. Firstly, by leveraging tools from large deviation theory, we characterize second-order asymptotics of the optimal constellation shaping region under aforementioned intensity constraints, which further refine our previous results in [Chen. et. al, 2020]. Within the optimal geometrical shaping region, we develop an energy-efficient 24-dimensional constellation design, where a significant coding gain brought by the Leech lattice and the nearly-maximum shaping gain are incorporated by using a strategy called coarsely shaping and finely coding. Fast algorithms for constellation mapping and demodulation are presented as well. Numerical results verifies the superiority of our results as compared with existing methods.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种24维 геометрически定义的星座设计，用于室内可见光通信（VLC），具有峰值和平均输入约束。我们首先通过利用大偏移理论工具，Characterize second-order asymptotics of the optimal constellation shaping region under the aforementioned intensity constraints,这些约束，进一步精细化我们在[陈等，2020]中的前一个结果。在优化的 геометрической定义区域内，我们开发了一种能效的24维星座设计，该设计具有利用Leech网格和高级定制约束带来的显著编码增益。此外，我们还提出了一种叫做粗细定制和细化编码的策略，以提高编码效率。此外，我们还提供了快速的星座映射和解译算法。 numerically verified results show the superiority of our results compared with existing methods.Here's the breakdown of the translation:* 室内可见光通信 (VLC) : 室内可见光通信*  peak-and an average-intensity input constraints : 峰值和平均输入约束*  large deviation theory : 大偏移理论*  optimal constellation shaping region : 优化的星座定义区域*  coarsely shaping and finely coding : 粗细定制和细化编码*  energy-efficient : 能效的* 24-dimensional constellation design : 24维星座设计*  Leech lattice : Leech网格*  nearly-maximum shaping gain : 几乎最大的定制增益*  fast algorithms : 快速的算法* numerically verified results : 数值验证结果
</details></li>
</ul>
<hr>
<h2 id="Multi-User-Multi-IoT-Device-Symbiotic-Radio-A-Novel-Massive-Access-Scheme-for-Cellular-IoT"><a href="#Multi-User-Multi-IoT-Device-Symbiotic-Radio-A-Novel-Massive-Access-Scheme-for-Cellular-IoT" class="headerlink" title="Multi-User Multi-IoT-Device Symbiotic Radio: A Novel Massive Access Scheme for Cellular IoT"></a>Multi-User Multi-IoT-Device Symbiotic Radio: A Novel Massive Access Scheme for Cellular IoT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02837">http://arxiv.org/abs/2311.02837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Wang, Ying-Chang Liang, Sumei Sun</li>
<li>for: 支持 cellular Internet of Things (IoT) 的Symbiotic radio (SR)技术，以实现大规模访问。</li>
<li>methods: 提出了一种新的多用户多IoT设备SR系统，基站（BS）传输信息给多个 cellular用户，同时多个IoT设备同步反射信息回传给这些用户。</li>
<li>results: 通过应用 robust design方法，设计了BS的扫描向量，以最小化电力消耗，同时满足 cellular传输失败概率和IoT传输总速率的约束。此外，对特殊情况进行了研究，在每个 cellular用户与邻近的IoT设备之间建立了多个DoA-based传输扫描向量设计方法。<details>
<summary>Abstract</summary>
Symbiotic radio (SR) is a promising technique to support cellular Internet-of-Things (IoT) by forming a mutualistic relationship between IoT and cellular transmissions. In this paper, we propose a novel multi-user multi-IoT-device SR system to enable massive access in cellular IoT. In the considered system, the base station (BS) transmits information to multiple cellular users, and a number of IoT devices simultaneously backscatter their information to these users via the cellular signal. The cellular users jointly decode the information from the BS and IoT devices. Noting that the reflective links from the IoT devices can be regarded as the channel uncertainty of the direct links, we apply the robust design method to design the beamforming vectors at the BS. Specifically, the transmit power is minimized under the cellular transmission outage probability constraints and IoT transmission sum rate constraints. The algorithm based on semi-definite programming and difference-of-convex programming is proposed to solve the power minimization problem. Moreover, we consider a special case where each cellular user is associated with several adjacent IoT devices and propose a direction of arrival (DoA)-based transmit beamforming design approach. The DoA-based approach requires only the DoA and angular spread (AS) of the direct links instead of the instantaneous channel state information (CSI) of the reflective link channels, leading to a significant reduction in the channel feedback overhead. Simulation results have substantiated the multi-user multi-IoT-device SR system and the effectiveness of the proposed beamforming approaches. It is shown that the DoA-based beamforming approach achieves comparable performance as the CSI-based approach in the special case when the ASs are small.
</details>
<details>
<summary>摘要</summary>
“ симбиотиче radio (SR) 是一种有前途的技术，用于支持 celullar 互联网（IoT），通过 IoT 和 celullar 传输之间的共生关系。在这篇论文中，我们提出了一种新的多用户多 IoT 设备 SR 系统，以实现大规模访问在 celullar IoT 中。在考虑的系统中，基站（BS）向多个 celullar 用户传输信息，而多个 IoT 设备同时反射其信息给这些用户通过 celullar 信号。用户共同解码基站和 IoT 设备之间的信息。注意到反射链中的 IoT 设备的信道不确定性，我们采用了Robust 设计方法来设计基站的扩散 вектор。具体来说，我们将在基站传输功率最小化下，对 celullar 传输失业概率和 IoT 传输总比特率做出限制。我们提出了一种基于半definite 编程和差分 Convex 编程的算法来解决这个力量最小化问题。此外，我们对特殊情况进行了研究，在每个 celullar 用户与邻近的多个 IoT 设备之间建立连接，并提出了方向来源（DoA）基于的传输扩散设计方法。DoA 基于方法只需要 DoA 和 Angular Spread（AS）的直接链道，而不需要反射链道的实时频率状态信息（CSI），从而减少了通道反馈过程的压力。实验结果证明了多用户多 IoT 设备 SR 系统和我们提出的扩散设计方法的效果。结果表明，在特殊情况下，当 AS 较小时，DoA 基于方法与 CSI 基于方法具有相似的性能。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/eess.SP_2023_11_06/" data-id="cloojsmrj01cgre889wueah0k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.SD_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T15:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.SD_2023_11_05/">cs.SD - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Yet-Another-Generative-Model-For-Room-Impulse-Response-Estimation"><a href="#Yet-Another-Generative-Model-For-Room-Impulse-Response-Estimation" class="headerlink" title="Yet Another Generative Model For Room Impulse Response Estimation"></a>Yet Another Generative Model For Room Impulse Response Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02581">http://arxiv.org/abs/2311.02581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungho Lee, Hyeong-Seok Choi, Kyogu Lee</li>
<li>for: 这篇论文主要是为了提高 neural room impulse response（RIR）估计器的性能，尤其是 generator 部分的性能。</li>
<li>methods: 这篇论文使用了一种 alternate generator 架构，首先在 autoencoder 中使用 residual quantization 来学习一个精度的整数 токен空间，每个 токен表示一个小时频域的 RIR。然后，通过在频率、时间和量化深度轴上使用 transformer 变体，解决了标准的盲估 зада务和附加的听音匹配问题。</li>
<li>results: 实验结果表明，我们的系统在多个评价指标上比其他基准点更优。<details>
<summary>Abstract</summary>
Recent neural room impulse response (RIR) estimators typically comprise an encoder for reference audio analysis and a generator for RIR synthesis. Especially, it is the performance of the generator that directly influences the overall estimation quality. In this context, we explore an alternate generator architecture for improved performance. We first train an autoencoder with residual quantization to learn a discrete latent token space, where each token represents a small time-frequency patch of the RIR. Then, we cast the RIR estimation problem as a reference-conditioned autoregressive token generation task, employing transformer variants that operate across frequency, time, and quantization depth axes. This way, we address the standard blind estimation task and additional acoustic matching problem, which aims to find an RIR that matches the source signal to the target signal's reverberation characteristics. Experimental results show that our system is preferable to other baselines across various evaluation metrics.
</details>
<details>
<summary>摘要</summary>
First, we train an autoencoder with residual quantization to learn a discrete latent token space, where each token represents a small time-frequency patch of the RIR. Then, we treat the RIR estimation problem as a reference-conditioned autoregressive token generation task, using transformer variants that operate across the frequency, time, and quantization depth axes. This approach addresses both the standard blind estimation task and the additional acoustic matching problem, which aims to find an RIR that matches the source signal to the target signal's reverberation characteristics.Experimental results show that our system outperforms other baselines across various evaluation metrics.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.SD_2023_11_05/" data-id="cloojsmlr00yvre8801e4g01o" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.CV_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T13:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.CV_2023_11_05/">cs.CV - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MirrorCalib-Utilizing-Human-Pose-Information-for-Mirror-based-Virtual-Camera-Calibration"><a href="#MirrorCalib-Utilizing-Human-Pose-Information-for-Mirror-based-Virtual-Camera-Calibration" class="headerlink" title="MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual Camera Calibration"></a>MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual Camera Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02791">http://arxiv.org/abs/2311.02791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longyun Liao, Andrew Mitchell, Rong Zheng</li>
<li>for: 估计虚拟相机 extrinsic参数，使用一个固定平面镜。</li>
<li>methods: 利用人体知识和2D关节位置来估计相机 extrinsic 参数，并使用modified eight-point algorithm 和 RANSAC 算法来更正和除异常点。</li>
<li>results: mirrorCalib 在 sintetic 和实际数据集上表现出优于状态艺方法，Rotation error 为 0.62{\deg}&#x2F;1.82{\deg} 和 translation error 为 37.33&#x2F;69.51 mm。<details>
<summary>Abstract</summary>
In this paper, we present the novel task of estimating the extrinsic parameters of a virtual camera with respect to a real camera with one single fixed planar mirror. This task poses a significant challenge in cases where objects captured lack overlapping views from both real and mirrored cameras. To address this issue, prior knowledge of a human body and 2D joint locations are utilized to estimate the camera extrinsic parameters when a person is in front of a mirror. We devise a modified eight-point algorithm to obtain an initial estimation from 2D joint locations. The 2D joint locations are then refined subject to human body constraints. Finally, a RANSAC algorithm is employed to remove outliers by comparing their epipolar distances to a predetermined threshold. MirrorCalib is evaluated on both synthetic and real datasets and achieves a rotation error of 0.62{\deg}/1.82{\deg} and a translation error of 37.33/69.51 mm on the synthetic/real dataset, which outperforms the state-of-art method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个新的任务：使用实际摄像头和虚拟摄像头之间的一个固定平面镜来估算虚拟摄像头的外部参数。当物体没有在两个摄像头中的重叠视图时，这个任务具有 significante挑战。为解决这个问题，我们利用人体的先知知识和2D关节位置来估算虚拟摄像头的外部参数，当人物在镜前时。我们修改了八点算法，以从2D关节位置获取初始估算。然后，我们使用人体限制来精度地修正2D关节位置。最后，我们使用RANSAC算法来除掉异常值，并比较它们的视线距离预先确定的阈值。我们的MirrorCalib方法在 synthetic和实际数据集上进行测试，并实现了0.62度/1.82度的旋转错误和37.33/69.51 mm的翻译错误，这超过了当前方法的性能。
</details></li>
</ul>
<hr>
<h2 id="MuSHRoom-Multi-Sensor-Hybrid-Room-Dataset-for-Joint-3D-Reconstruction-and-Novel-View-Synthesis"><a href="#MuSHRoom-Multi-Sensor-Hybrid-Room-Dataset-for-Joint-3D-Reconstruction-and-Novel-View-Synthesis" class="headerlink" title="MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis"></a>MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02778">http://arxiv.org/abs/2311.02778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuqian Ren, Wenjia Wang, Dingding Cai, Tuuli Tuominen, Juho Kannala, Esa Rahtu</li>
<li>for: 这篇论文目的是提出一个实际世界多感器 гибрид房间数据集（MuSHRoom），以便促进实时和 immerse 的模型和渲染技术的发展。</li>
<li>methods: 论文使用了多种著名的管道进行3D mesh reconstruction和新视图合成的Benchmarking，并提出了一种新的方法来实现3D reconstruction和新视图合成的共同优化。</li>
<li>results: 论文的数据集和 benchmark 表明，新的方法可以在实际世界中提供高质量的3D reconstruction和新视图合成，并且可以在consumer-grade设备上实现高效和稳定的渲染。<details>
<summary>Abstract</summary>
Metaverse technologies demand accurate, real-time, and immersive modeling on consumer-grade hardware for both non-human perception (e.g., drone/robot/autonomous car navigation) and immersive technologies like AR/VR, requiring both structural accuracy and photorealism. However, there exists a knowledge gap in how to apply geometric reconstruction and photorealism modeling (novel view synthesis) in a unified framework.   To address this gap and promote the development of robust and immersive modeling and rendering with consumer-grade devices, first, we propose a real-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents exciting challenges and requires state-of-the-art methods to be cost-effective, robust to noisy data and devices, and can jointly learn 3D reconstruction and novel view synthesis, instead of treating them as separate tasks, making them ideal for real-world applications. Second, we benchmark several famous pipelines on our dataset for joint 3D mesh reconstruction and novel view synthesis. Finally, in order to further improve the overall performance, we propose a new method that achieves a good trade-off between the two tasks. Our dataset and benchmark show great potential in promoting the improvements for fusing 3D reconstruction and high-quality rendering in a robust and computationally efficient end-to-end fashion.
</details>
<details>
<summary>摘要</summary>
<<SYS>> traducción de texto a chino simplificadoMetaverse 技术需要准确、实时和 immerse 模型在消费者级别硬件上，包括无人化感知（如无人机/机器人/自动驾驶车 navigation）和 immerse 技术 like AR/VR，需要同时满足结构准确性和光realism。但是，现有的知识隔 gap 在如何在一个统一框架中应用 geometric reconstruction 和 photorealism 模型。为了bridging 这个隔 gap 并促进消费级设备上的强健和 immerse 模型和渲染，我们首先提出了一个真实世界 Multi-Sensor Hybrid Room Dataset (MuSHRoom)。我们的数据集具有挑战性和需要当今技术的成本效益、鲁棒性和可靠性，同时需要jointly 学习 3D reconstruction 和 novel view synthesis，而不是将它们视为独立的任务。这使得它们在真实应用中更加适用。其次，我们在我们的数据集上对许多知名的管道进行了benchmark。最后，为了进一步提高总性表现，我们提出了一种新的方法，该方法在3D reconstruction 和 novel view synthesis之间寻找了一个良好的平衡。我们的数据集和benchmark表现出了推动改进混合3D reconstruction和高质量渲染的robust 和计算效率的末级整合性。
</details></li>
</ul>
<hr>
<h2 id="Fast-Sparse-3D-Convolution-Network-with-VDB"><a href="#Fast-Sparse-3D-Convolution-Network-with-VDB" class="headerlink" title="Fast Sparse 3D Convolution Network with VDB"></a>Fast Sparse 3D Convolution Network with VDB</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02762">http://arxiv.org/abs/2311.02762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fangjun Zhou, Anyong Mao, Eftychios Sifakis</li>
<li>for: 这个论文是为了提出一种基于 sparse 3D 数据的 Convolutional Neural Network（CNN）实现，用于高精度 3D 对象分类网络。</li>
<li>methods: 该实现使用 NanoVDB 作为数据结构，以存储 sparse 张量。它具有较小的内存占用量，同时维持高性能。</li>
<li>results: 对比州先进的 dense CNN 模型，该架构在高分辨率 3D 对象分类网络上实现了约 20 倍的速度提升。<details>
<summary>Abstract</summary>
We proposed a new Convolution Neural Network implementation optimized for sparse 3D data inference. This implementation uses NanoVDB as the data structure to store the sparse tensor. It leaves a relatively small memory footprint while maintaining high performance. We demonstrate that this architecture is around 20 times faster than the state-of-the-art dense CNN model on a high-resolution 3D object classification network.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的卷积神经网络实现，优化为稀疏的3D数据推理。这种实现使用NanoVDB作为数据结构，以减少内存占用量，同时保持高性能。我们示出了这个架构比现有的稠密CNN模型快约20倍在高分辨率3D物体分类网络上。
</details></li>
</ul>
<hr>
<h2 id="Fast-Point-cloud-to-Mesh-Reconstruction-for-Deformable-Object-Tracking"><a href="#Fast-Point-cloud-to-Mesh-Reconstruction-for-Deformable-Object-Tracking" class="headerlink" title="Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking"></a>Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02749">http://arxiv.org/abs/2311.02749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elham Amin Mansour, Hehui Zheng, Robert K. Katzschmann</li>
<li>for: 这个研究的目的是为了帮助机器人手掌控制软物体，因为机器人手需要在 manipulate 软物体时获得在线状态反馈。</li>
<li>methods: 这个研究使用了一种基于点云自编码器和真实NVP架构的方法，将模板网格与变形点云进行匹配，以实现软物体的重建和跟踪。</li>
<li>results: 这个方法可以在6种ycb类型的物体上实现58Hz的重建和跟踪速度，并且可以用于下游应用程序，如机器人手的控制算法，以实现在关闭环境中的循环反馈控制。<details>
<summary>Abstract</summary>
The world around us is full of soft objects that we as humans learn to perceive and deform with dexterous hand movements from a young age. In order for a Robotic hand to be able to control soft objects, it needs to acquire online state feedback of the deforming object. While RGB-D cameras can collect occluded information at a rate of 30 Hz, the latter does not represent a continuously trackable object surface. Hence, in this work, we developed a method that can create deforming meshes of deforming point clouds at a speed of above 50 Hz for different categories of objects. The reconstruction of meshes from point clouds has been long studied in the field of Computer graphics under 3D reconstruction and 4D reconstruction, however both lack the speed and generalizability needed for robotics applications. Our model is designed using a point cloud auto-encoder and a Real-NVP architecture. The latter is a continuous flow neural network with manifold-preservation properties. Our model takes a template mesh which is the mesh of an object in its canonical state and then deforms the template mesh to match a deformed point cloud of the object. Our method can perform mesh reconstruction and tracking at a rate of 58 Hz for deformations of six different ycb categories. An instance of a downstream application can be the control algorithm for a robotic hand that requires online feedback from the state of a manipulated object which would allow online grasp adaptation in a closed-loop manner. Furthermore, the tracking capacity that our method provides can help in the system identification of deforming objects in a marker-free approach. In future work, we will extend our method to more categories of objects and real world deforming point clouds
</details>
<details>
<summary>摘要</summary>
世界around us是满filled with soft objects，我们从小learned to perceive和deform这些soft objects with our dexterous hand movements。为了让机器人手能够控制soft objects，它需要在线获取这些变形的对象的状态反馈。although RGB-D cameras可以在30Hz的速度收集 occluded information，但这些信息不能持续跟踪对象表面。因此，在这个工作中，我们开发了一种方法，可以在50Hz的速度创建不同类型对象的变形矩阵。在计算机图形学中，从点云重建和4D重建已经有了长期的研究，但是这些方法缺乏速度和普适性，不适合机器人应用。我们的模型采用了点云自编码器和Real-NVP架构。后者是一种连续流式神经网络，具有杜氏流变性质。我们的模型会将模板矩阵（对象的标准状态下的矩阵）与变形点云相匹配，以实现对象的变形重建和跟踪。我们的方法可以在6个ycb类型对象上实现58Hz的重建和跟踪。这种方法可以用于机器人手的控制算法中，需要在线获取被操作对象的状态反馈，以实现关闭Loop的 grasp adaptation。此外，我们的方法的跟踪能力可以帮助在无标记 Approach中系统identify deforming objects。在未来的工作中，我们计划扩展我们的方法到更多的对象类型和实际世界变形点云。
</details></li>
</ul>
<hr>
<h2 id="Attention-Modules-Improve-Image-Level-Anomaly-Detection-for-Industrial-Inspection-A-DifferNet-Case-Study"><a href="#Attention-Modules-Improve-Image-Level-Anomaly-Detection-for-Industrial-Inspection-A-DifferNet-Case-Study" class="headerlink" title="Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study"></a>Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02747">http://arxiv.org/abs/2311.02747</a></li>
<li>repo_url: None</li>
<li>paper_authors: André Luiz Buarque Vieira e Silva, Francisco Simões, Danny Kowerko, Tobias Schlosser, Felipe Battisti, Veronica Teichrieb</li>
<li>for: 这篇论文主要用于提高工业自动化视觉检测中的学习型方法，以便处理高分辨率影像中的微小缺陷模式。</li>
<li>methods: 这篇论文使用了DifferNet架构，并将注意力模组添加到其中，协助提高影像水平的检测和分类能力。</li>
<li>results: 该论文在三个类比资料集（InsPLAD-fault、MVTec AD 和 Semiconductor Wafer）上进行了评估，而该论文的结果与现有的state of the art相比，实现了提高的结果，并在质量评估中表现出色。<details>
<summary>Abstract</summary>
Within (semi-)automated visual industrial inspection, learning-based approaches for assessing visual defects, including deep neural networks, enable the processing of otherwise small defect patterns in pixel size on high-resolution imagery. The emergence of these often rarely occurring defect patterns explains the general need for labeled data corpora. To alleviate this issue and advance the current state of the art in unsupervised visual inspection, this work proposes a DifferNet-based solution enhanced with attention modules: AttentDifferNet. It improves image-level detection and classification capabilities on three visual anomaly detection datasets for industrial inspection: InsPLAD-fault, MVTec AD, and Semiconductor Wafer. In comparison to the state of the art, AttentDifferNet achieves improved results, which are, in turn, highlighted throughout our quali-quantitative study. Our quantitative evaluation shows an average improvement - compared to DifferNet - of 1.77 +/- 0.25 percentage points in overall AUROC considering all three datasets, reaching SOTA results in InsPLAD-fault, an industrial inspection in-the-wild dataset. As our variants to AttentDifferNet show great prospects in the context of currently investigated approaches, a baseline is formulated, emphasizing the importance of attention for industrial anomaly detection both in the wild and in controlled environments.
</details>
<details>
<summary>摘要</summary>
在半自动化视业rial检测中，基于学习的方法用于识别视觉缺陷，包括深度神经网络，可以处理高分辨率图像中的小缺陷模式。由于这些缺陷模式的出现，需要大量的标注数据集。为了解决这一问题并提高现有状态的艺术，本工作提出了基于DifferNet的解决方案，即AttentDifferNet。它在三个视觉缺陷检测数据集（InsPLAD-fault、MVTec AD和半导体晶圆）上提高了图像水平的检测和分类能力。与现状的比较表明，AttentDifferNet在全数据集的总AUROC方面表现出1.77±0.25个百分点的平均提升，在InsPLAD-fault数据集上达到了领先的状态码。我们的变体对AttentDifferNet表现出了非常好的前景，因此我们建立了一个基准，强调在工业异常检测中的注意力的重要性，以及在控制环境和实际应用环境中的注意力的重要性。
</details></li>
</ul>
<hr>
<h2 id="Scenario-Diffusion-Controllable-Driving-Scenario-Generation-With-Diffusion"><a href="#Scenario-Diffusion-Controllable-Driving-Scenario-Generation-With-Diffusion" class="headerlink" title="Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion"></a>Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02738">http://arxiv.org/abs/2311.02738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ethan Pronovost, Meghana Reddy Ganesina, Noureldin Hendy, Zeyu Wang, Andres Morales, Kai Wang, Nicholas Roy</li>
<li>for: 本研究旨在提供一种可控的 sintetic traffic scenario 生成方法，以验证自动驾驶汽车（AV）的安全性。</li>
<li>methods: 本文提出了一种叫做 Scenario Diffusion 的扩散基 architecture，用于生成交通场景。这种方法结合了潜在扩散、物体检测和轨迹回归，同时生成了 distribuions of synthetic agent poses, orientations和trajectories。为了提供更多的控制权，这个分布被conditioned на一个地图和一组描述所需enario的token。</li>
<li>results: 我们的方法具有足够的表达能力，可以模型多样化的交通模式，并在不同的地理区域上进行泛化。<details>
<summary>Abstract</summary>
Automated creation of synthetic traffic scenarios is a key part of validating the safety of autonomous vehicles (AVs). In this paper, we propose Scenario Diffusion, a novel diffusion-based architecture for generating traffic scenarios that enables controllable scenario generation. We combine latent diffusion, object detection and trajectory regression to generate distributions of synthetic agent poses, orientations and trajectories simultaneously. To provide additional control over the generated scenario, this distribution is conditioned on a map and sets of tokens describing the desired scenario. We show that our approach has sufficient expressive capacity to model diverse traffic patterns and generalizes to different geographical regions.
</details>
<details>
<summary>摘要</summary>
自动生成 synthetic 交通场景是确认自动驾驶车辆（AV）的安全性的关键部分。在这篇论文中，我们提出了 Scenario Diffusion，一种基于扩散的架构，用于生成交通场景。我们将潜在扩散、物体检测和轨迹回归结合起来，同时生成多个synthetic agent的姿势、方向和轨迹的分布。为了提供更多的控制权，我们将这个分布conditioned在地图和desired scenario中的集合。我们表明，我们的方法具备足够的表达能力，可以模拟多样化的交通模式，并在不同的地区generalize。
</details></li>
</ul>
<hr>
<h2 id="JRDB-Traj-A-Dataset-and-Benchmark-for-Trajectory-Forecasting-in-Crowds"><a href="#JRDB-Traj-A-Dataset-and-Benchmark-for-Trajectory-Forecasting-in-Crowds" class="headerlink" title="JRDB-Traj: A Dataset and Benchmark for Trajectory Forecasting in Crowds"></a>JRDB-Traj: A Dataset and Benchmark for Trajectory Forecasting in Crowds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02736">http://arxiv.org/abs/2311.02736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeed Saadatnejad, Yang Gao, Hamid Rezatofighi, Alexandre Alahi</li>
<li>for: 预测未来轨迹是自主导航中非常重要的，特别是在人类相关事故预防方面，预测代理人的能力在前期准备是非常重要的。</li>
<li>methods: 作者引入了一个新的端到端轨迹预测数据集，以便评估模型在实际应用中的性能。该数据集是JRDB数据集的扩展，提供了包括所有代理人的位置、场景图像和点云数据， alles从机器人的视角来。目标是预测未来代理人对机器人的位置。</li>
<li>results: 该数据集可以bridges the gap between isolated models and practical applications, promoting a deeper understanding of navigation dynamics. In addition, the authors introduce a new metric for assessing trajectory forecasting models in real-world scenarios where ground-truth identities are inaccessible, addressing issues related to undetected or over-detected agents.<details>
<summary>Abstract</summary>
Predicting future trajectories is critical in autonomous navigation, especially in preventing accidents involving humans, where a predictive agent's ability to anticipate in advance is of utmost importance. Trajectory forecasting models, employed in fields such as robotics, autonomous vehicles, and navigation, face challenges in real-world scenarios, often due to the isolation of model components. To address this, we introduce a novel dataset for end-to-end trajectory forecasting, facilitating the evaluation of models in scenarios involving less-than-ideal preceding modules such as tracking. This dataset, an extension of the JRDB dataset, provides comprehensive data, including the locations of all agents, scene images, and point clouds, all from the robot's perspective. The objective is to predict the future positions of agents relative to the robot using raw sensory input data. It bridges the gap between isolated models and practical applications, promoting a deeper understanding of navigation dynamics. Additionally, we introduce a novel metric for assessing trajectory forecasting models in real-world scenarios where ground-truth identities are inaccessible, addressing issues related to undetected or over-detected agents. Researchers are encouraged to use our benchmark for model evaluation and benchmarking.
</details>
<details>
<summary>摘要</summary>
预测未来轨迹是自动导航中非常重要的，尤其是在人类相关事故预防方面，预测代理人的能力在先期 anticipation 方面具有最高的重要性。轨迹预测模型在机器人、自动驾驶、导航等领域中广泛应用，但在实际场景中经常遇到挑战，常因模型组件孤立。为解决这个问题，我们介绍了一个新的轨迹预测数据集，用于评估模型在受限于前一Module的情况下的性能。这个数据集是JRDB数据集的扩展，提供了全面的数据，包括所有代理人的位置、场景图像和点云数据，全都是机器人的视角。目标是预测未来代理人与机器人之间的位置关系，使用原始感知输入数据。它填补了模型与实际应用之间的空隙，提高了导航动力学的理解。此外，我们还引入了一个新的评价指标，用于评估轨迹预测模型在真实世界场景中，解决了因为未探测或过度探测代理人而引起的问题。研究人员可以使用我们的标准来评估和比较模型。
</details></li>
</ul>
<hr>
<h2 id="ISAR-A-Benchmark-for-Single-and-Few-Shot-Object-Instance-Segmentation-and-Re-Identification"><a href="#ISAR-A-Benchmark-for-Single-and-Few-Shot-Object-Instance-Segmentation-and-Re-Identification" class="headerlink" title="ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification"></a>ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02734">http://arxiv.org/abs/2311.02734</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nicogorlo/isar_wacv24">https://github.com/nicogorlo/isar_wacv24</a></li>
<li>paper_authors: Nicolas Gorlo, Kenneth Blomqvist, Francesco Milano, Roland Siegwart</li>
<li>for: 本文旨在提出一个基准方法和测试集，用于单或几个示例学习对象实例分割和重新识别。</li>
<li>methods: 本文使用 semi-synthetic 视频序列数据集，以及一种标准化的评估管道和基线方法来进行测试。</li>
<li>results: 本文提出了一个基准方法和测试集，可以帮助加速对象实例分割和重新识别领域的研究。<details>
<summary>Abstract</summary>
Most object-level mapping systems in use today make use of an upstream learned object instance segmentation model. If we want to teach them about a new object or segmentation class, we need to build a large dataset and retrain the system. To build spatial AI systems that can quickly be taught about new objects, we need to effectively solve the problem of single-shot object detection, instance segmentation and re-identification. So far there is neither a method fulfilling all of these requirements in unison nor a benchmark that could be used to test such a method. Addressing this, we propose ISAR, a benchmark and baseline method for single- and few-shot object Instance Segmentation And Re-identification, in an effort to accelerate the development of algorithms that can robustly detect, segment, and re-identify objects from a single or a few sparse training examples. We provide a semi-synthetic dataset of video sequences with ground-truth semantic annotations, a standardized evaluation pipeline, and a baseline method. Our benchmark aligns with the emerging research trend of unifying Multi-Object Tracking, Video Object Segmentation, and Re-identification.
</details>
<details>
<summary>摘要</summary>
现代的物件水平映射系统大多采用上游学习的物件实例分割模型。如果我们想教导它们新的物体或分割类型，我们需要建立大量数据集和重新训练系统。以建立快速可以教育新物体的空间AI系统，我们需要有效解决单一实例检测、实例分割和重识别问题。到目前为止，没有一种方法可以同时满足这些需求，也没有一个可以用来测试这种方法的参考标准。为了解决这个问题，我们提出了ISAR，一个benchmark和基本方法，用于单一和几个实例的物件实例分割和重识别。我们提供了一个半人工的视觉序列数据集，一个标准化的评估管道，以及一个基本方法。我们的benchmark与多bject Tracking、视觉物件分割和重识别的研究趋势相互align。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-for-Safety-critical-Scene-Segmentation-via-Fine-grained-Reward-Maximization"><a href="#Uncertainty-Estimation-for-Safety-critical-Scene-Segmentation-via-Fine-grained-Reward-Maximization" class="headerlink" title="Uncertainty Estimation for Safety-critical Scene Segmentation via Fine-grained Reward Maximization"></a>Uncertainty Estimation for Safety-critical Scene Segmentation via Fine-grained Reward Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02719">http://arxiv.org/abs/2311.02719</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/med-air/FGRM">https://github.com/med-air/FGRM</a></li>
<li>paper_authors: Hongzheng Yang, Cheng Chen, Yueyao Chen, Markus Scheppach, Hon Chi Yip, Qi Dou<br>for:This paper focuses on addressing uncertainty estimation in deep segmentation models for safety-critical applications, particularly in medical imaging.methods:The proposed method utilizes a fine-grained reward maximization (FGRM) framework, which incorporates an uncertainty metric-related reward function and a reinforcement learning-based model tuning algorithm to optimize model calibration. The method designs a new uncertainty estimation reward function using the calibration metric and innovates an effective fine-grained parameter update scheme based on the fisher information matrix.results:The proposed method demonstrates superior performance on two large surgical scene segmentation datasets under two different uncertainty estimation settings, outperforming state-of-the-art methods on all calibration metrics of uncertainty estimation while maintaining high task accuracy for segmentation results. The code is available at \url{<a target="_blank" rel="noopener" href="https://github.com/med-air/FGRM%7D">https://github.com/med-air/FGRM}</a>.<details>
<summary>Abstract</summary>
Uncertainty estimation plays an important role for future reliable deployment of deep segmentation models in safety-critical scenarios such as medical applications. However, existing methods for uncertainty estimation have been limited by the lack of explicit guidance for calibrating the prediction risk and model confidence. In this work, we propose a novel fine-grained reward maximization (FGRM) framework, to address uncertainty estimation by directly utilizing an uncertainty metric related reward function with a reinforcement learning based model tuning algorithm. This would benefit the model uncertainty estimation through direct optimization guidance for model calibration. Specifically, our method designs a new uncertainty estimation reward function using the calibration metric, which is maximized to fine-tune an evidential learning pre-trained segmentation model for calibrating prediction risk. Importantly, we innovate an effective fine-grained parameter update scheme, which imposes fine-grained reward-weighting of each network parameter according to the parameter importance quantified by the fisher information matrix. To the best of our knowledge, this is the first work exploring reward optimization for model uncertainty estimation in safety-critical vision tasks. The effectiveness of our method is demonstrated on two large safety-critical surgical scene segmentation datasets under two different uncertainty estimation settings. With real-time one forward pass at inference, our method outperforms state-of-the-art methods by a clear margin on all the calibration metrics of uncertainty estimation, while maintaining a high task accuracy for the segmentation results. Code is available at \url{https://github.com/med-air/FGRM}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>请将以下文本翻译成简化中文。<</SYS>>深度 segmentation 模型在安全关键应用场景中的可靠部署需要 uncertainty 估计的支持。然而，现有的 uncertainty 估计方法受到缺乏明确指导 calibration 风险估计和模型自信度的限制。在这项工作中，我们提出了一种新的 fine-grained reward maximization（FGRM）框架，以解决 uncertainty 估计问题，直接利用一种相关的不确定度度量奖励函数和一种基于反馈学习的模型调整算法。这将有助于模型 uncertainty 估计，通过直接优化指导 calibration。具体来说，我们的方法设计了一个新的 uncertainty 估计奖励函数，使用 calibration 度量，通过最大化这个奖励函数来细化一个 evidential learning 预训练的 segmentation 模型，以 calibrate 预测风险。我们还开发了一种有效的细化参数更新方案，它根据参数的重要性量化使用 fisher 信息矩阵来进行细化奖励。我们认为，这是首次对 uncertainty 估计奖励的研究。我们的方法在两个大规模的安全关键手术场景中进行了两种不同的 uncertainty 估计设置，并在一次前进推理中实现了实时一个前进推理。与之前的状态艺术方法相比，我们的方法在所有 calibration 度量上都表现出了明显的优势，同时保持了高的任务准确率。代码可以在 \url{https://github.com/med-air/FGRM} 中找到。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-a-Benchmark-How-Reliable-is-MS-COCO"><a href="#Benchmarking-a-Benchmark-How-Reliable-is-MS-COCO" class="headerlink" title="Benchmarking a Benchmark: How Reliable is MS-COCO?"></a>Benchmarking a Benchmark: How Reliable is MS-COCO?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02709">http://arxiv.org/abs/2311.02709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Zimmermann, Justin Szeto, Jerome Pasquero, Frederic Ratle</li>
<li>for: 本研究使用 Sama-COCO  dataset 进行潜在偏见分析，并通过 shape analysis pipeline 来检查注释的偏见。</li>
<li>methods: 本研究使用了一个模型，并在 Sama-COCO 和 MS-COCO 这两个 dataset 上进行训练和评估，以检查不同的注释条件对模型的影响。</li>
<li>results: 结果显示了注释yles 的重要性，并证明了注释管道应该对应到 зада意义上的任务。<details>
<summary>Abstract</summary>
Benchmark datasets are used to profile and compare algorithms across a variety of tasks, ranging from image classification to segmentation, and also play a large role in image pretraining algorithms. Emphasis is placed on results with little regard to the actual content within the dataset. It is important to question what kind of information is being learned from these datasets and what are the nuances and biases within them. In the following work, Sama-COCO, a re-annotation of MS-COCO, is used to discover potential biases by leveraging a shape analysis pipeline. A model is trained and evaluated on both datasets to examine the impact of different annotation conditions. Results demonstrate that annotation styles are important and that annotation pipelines should closely consider the task of interest. The dataset is made publicly available at https://www.sama.com/sama-coco-dataset/ .
</details>
<details>
<summary>摘要</summary>
<<SYS>> Benjamin datasets 用于比较和 Profiling 算法，从图像分类到 segmentation 等多种任务，也扮演了图像预训练算法中的重要角色。 强调结果，而不是数据中实际的内容。 因此，需要询问这些数据中学习的信息是什么，以及这些数据中的细节和偏见。 在这篇文章中，我们使用 Sama-COCO，一个基于 MS-COCO 的重新标注数据集，以发现可能的偏见。我们使用一个形态分析管道来训练和评估模型，并对两个数据集进行比较。结果表明，标注风格对于任务的影响很大，而标注管道应该根据任务进行仔细考虑。这个数据集现在公开可用于 https://www.sama.com/sama-coco-dataset/。Note: "Benjamin datasets" is a simplified Chinese term that refers to benchmark datasets, and "MS-COCO" is a popular benchmark dataset for image classification and object detection tasks.
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Uncertainty-in-Polygon-Annotation-and-the-Impact-of-Quality-Assurance"><a href="#An-Empirical-Study-of-Uncertainty-in-Polygon-Annotation-and-the-Impact-of-Quality-Assurance" class="headerlink" title="An Empirical Study of Uncertainty in Polygon Annotation and the Impact of Quality Assurance"></a>An Empirical Study of Uncertainty in Polygon Annotation and the Impact of Quality Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02707">http://arxiv.org/abs/2311.02707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Zimmermann, Justin Szeto, Frederic Ratle</li>
<li>for: 本文旨在检验和评估多边形注释的不确定性，以及质量控制对其影响的作用。</li>
<li>methods: 本文使用多个评估者进行多边形注释，并对MS-COCO数据集中几种对象进行分析。</li>
<li>results: 结果表明多边形注释的可靠性取决于评估过程和场景和形态复杂度。<details>
<summary>Abstract</summary>
Polygons are a common annotation format used for quickly annotating objects in instance segmentation tasks. However, many real-world annotation projects request near pixel-perfect labels. While strict pixel guidelines may appear to be the solution to a successful project, practitioners often fail to assess the feasibility of the work requested, and overlook common factors that may challenge the notion of quality. This paper aims to examine and quantify the inherent uncertainty for polygon annotations and the role that quality assurance plays in minimizing its effect. To this end, we conduct an analysis on multi-rater polygon annotations for several objects from the MS-COCO dataset. The results demonstrate that the reliability of a polygon annotation is dependent on a reviewing procedure, as well as the scene and shape complexity.
</details>
<details>
<summary>摘要</summary>
多角形是常见的标注格式，用于快速标注实例分割任务中的对象。然而，许多实际项目需要非常精确的标注。虽然严格的像素指南可能看起来是成功项目的解决方案，但实际上，很多实践者会忽略标注的可靠性问题，并且忽略常见的因素，这些因素可能会挑战标注的准确性。本文旨在检查和衡量多角形标注中的内在不确定性，以及质量控制在减少其影响的作用。为此，我们对MS-COCO数据集中的多个对象进行了多个评审人多角形标注的分析。结果表明，多角形标注的可靠性取决于评审程序，以及场景和形状的复杂性。
</details></li>
</ul>
<hr>
<h2 id="A-Generative-Multi-Resolution-Pyramid-and-Normal-Conditioning-3D-Cloth-Draping"><a href="#A-Generative-Multi-Resolution-Pyramid-and-Normal-Conditioning-3D-Cloth-Draping" class="headerlink" title="A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping"></a>A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02700">http://arxiv.org/abs/2311.02700</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HunorLaczko/pyramid-drape">https://github.com/HunorLaczko/pyramid-drape</a></li>
<li>paper_authors: Hunor Laczkó, Meysam Madadi, Sergio Escalera, Jordi Gonzalez</li>
<li>for: 这个论文是为了研究3D衣服生成和折叠。</li>
<li>methods: 这个论文使用condition variational autoencoder（CVAE）和pyramid网络来添加衣服细节，并使用Surface normal UV maps作为中间表示。</li>
<li>results: 该模型在两个公共数据集（CLOTH3D和CAPE）上实现了高效、可控的细节生成和高度泛化到未看过的衣服、姿势和形状，即使用小量数据进行训练。<details>
<summary>Abstract</summary>
RGB cloth generation has been deeply studied in the related literature, however, 3D garment generation remains an open problem. In this paper, we build a conditional variational autoencoder for 3D garment generation and draping. We propose a pyramid network to add garment details progressively in a canonical space, i.e. unposing and unshaping the garments w.r.t. the body. We study conditioning the network on surface normal UV maps, as an intermediate representation, which is an easier problem to optimize than 3D coordinates. Our results on two public datasets, CLOTH3D and CAPE, show that our model is robust, controllable in terms of detail generation by the use of multi-resolution pyramids, and achieves state-of-the-art results that can highly generalize to unseen garments, poses, and shapes even when training with small amounts of data.
</details>
<details>
<summary>摘要</summary>
“RGB 布料生成已经在相关文献中进行了深入研究，但3D 衣物生成仍然是一个未解之问题。在这篇论文中，我们建立了一个增强型条件自适应器来进行3D 衣物生成和排布。我们提议了一个 pyramid 网络，以加入衣物细节逐步地，在一个标准空间中，即不对身体进行均衡和解剖。我们研究了将网络conditioning在表面法向UV图表上，作为中途表现，这是一个更容易优化的问题。我们的结果显示，我们的模型具有强健性、可控性，可以透过多resolution pyramids来控制细节生成，并且实现了现有的最佳成果，可以对未见过的衣物、 pose 和形状进行高度扩展。”
</details></li>
</ul>
<hr>
<h2 id="ChEF-A-Comprehensive-Evaluation-Framework-for-Standardized-Assessment-of-Multimodal-Large-Language-Models"><a href="#ChEF-A-Comprehensive-Evaluation-Framework-for-Standardized-Assessment-of-Multimodal-Large-Language-Models" class="headerlink" title="ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models"></a>ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02692">http://arxiv.org/abs/2311.02692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhelun Shi, Zhipin Wang, Hongxing Fan, Zhenfei Yin, Lu Sheng, Yu Qiao, Jing Shao<br>for:* The paper aims to provide a comprehensive evaluation framework for multimodal large language models (MLLMs) to holistically profile their capabilities and limitations.methods:* The paper proposes a four-component evaluation framework called ChEF, which includes scenario, instruction, inferencer, and metric components.* The paper introduces six new recipes to evaluate MLLMs’ desired capabilities, such as calibration, in-context learning, and robustness.results:* The paper conducts a large-scale evaluation of nine prominent MLLMs on nine scenarios and six desiderata, summarizing over 20 valuable observations about the generalizability of MLLMs across various scenarios and the composite capability of MLLMs required for multimodal interactions.<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) have shown impressive abilities in interacting with visual content with myriad potential downstream tasks. However, even though a list of benchmarks has been proposed, the capabilities and limitations of MLLMs are still not comprehensively understood, due to a lack of a standardized and holistic evaluation framework. To this end, we present the first Comprehensive Evaluation Framework (ChEF) that can holistically profile each MLLM and fairly compare different MLLMs. First, we structure ChEF as four modular components, i.e., Scenario as scalable multimodal datasets, Instruction as flexible instruction retrieving formulae, Inferencer as reliable question answering strategies, and Metric as indicative task-specific score functions. Based on them, ChEF facilitates versatile evaluations in a standardized framework, and new evaluations can be built by designing new Recipes (systematic selection of these four components). Notably, current MLLM benchmarks can be readily summarized as recipes of ChEF. Second, we introduce 6 new recipes to quantify competent MLLMs' desired capabilities (or called desiderata, i.e., calibration, in-context learning, instruction following, language performance, hallucination, and robustness) as reliable agents that can perform real-world multimodal interactions. Third, we conduct a large-scale evaluation of 9 prominent MLLMs on 9 scenarios and 6 desiderata. Our evaluation summarized over 20 valuable observations concerning the generalizability of MLLMs across various scenarios and the composite capability of MLLMs required for multimodal interactions. We will publicly release all the detailed implementations for further analysis, as well as an easy-to-use modular toolkit for the integration of new recipes and models, so that ChEF can be a growing evaluation framework for the MLLM community.
</details>
<details>
<summary>摘要</summary>
多Modal大型自然语言模型（MLLM）在与视觉内容交互中表现出色，但是尚未完全理解MLLM的能力和局限性，因为缺乏一个标准化和整体评估框架。为此，我们提出了首个完整评估框架（ChEF），可以具有整体评估MLLM的能力，并公平比较不同MLLM。ChEF由四个可分 Module组成，即Scene为可扩展的多模式数据集，Instruction为灵活的指令检索方程，Inferencer为可靠的问答策略，Metric为任务特定的指标函数。基于这些Module，ChEF可以在标准化的框架下进行多样化的评估，并且可以通过设计新的Recipe（系统atic选择这些四个Component）来创建新的评估。值得注意的是，现有的MLLM benchmark可以被视为ChEF的Recipe。我们还提出了6种新的Recipe，用于衡量高效的MLLM的需求（或称为欲望，即准确性、场景学习、指令遵从、语言性能、幻觉和稳定性）。然后，我们对9个知名MLLM进行了大规模的评估，对9个场景和6种欲望进行了评估。我们的评估结果表明，MLLM在不同的场景下的一致性和需要多种 Composite 能力来实现多模式交互。我们将在公共发布详细实现和可以更新的模块工具包，以便ChEF成为MLLM社区的成长评估框架。
</details></li>
</ul>
<hr>
<h2 id="Octavius-Mitigating-Task-Interference-in-MLLMs-via-MoE"><a href="#Octavius-Mitigating-Task-Interference-in-MLLMs-via-MoE" class="headerlink" title="Octavius: Mitigating Task Interference in MLLMs via MoE"></a>Octavius: Mitigating Task Interference in MLLMs via MoE</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02684">http://arxiv.org/abs/2311.02684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeren Chen, Ziqin Wang, Zhen Wang, Huayang Liu, Zhenfei Yin, Si Liu, Lu Sheng, Wanli Ouyang, Yu Qiao, Jing Shao</li>
<li>for: 本研究旨在探讨大语言模型（LLM）在多modal学习中的零shot扩展能力，以及在多modal任务下negative conflict和干扰的影响。</li>
<li>methods: 我们提出了一种新的和可扩展的框架，called \mname，用于全面研究多modal学习中的大语言模型（MLLM）。我们将mixture-of-experts（MoE）和representative PEFT技术LoRA相结合，设计了一种基于LLM的新decoder，called LoRA-MoE，用于多modal学习。</li>
<li>results: 我们的实验结果表明，LoRA-MoE可以在多种2D和3D下游任务中提供20%的改进。我们的设计不仅具有效果和多样性，还可以在不同的任务和模式下进行扩展。<details>
<summary>Abstract</summary>
Recent studies have demonstrated Large Language Models (LLMs) can extend their zero-shot generalization capabilities to multimodal learning through instruction tuning. As more modalities and downstream tasks are introduced, negative conflicts and interference may have a worse impact on performance. While this phenomenon has been overlooked in previous work, we propose a novel and extensible framework, called \mname, for comprehensive studies and experimentation on multimodal learning with Multimodal Large Language Models (MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, \emph{i.e.,} LoRA, designing a novel LLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental results (about 20\% improvement) have shown the effectiveness and versatility of our design in various 2D and 3D downstream tasks. Code and corresponding dataset will be available soon.
</details>
<details>
<summary>摘要</summary>
现有研究表明大语言模型（LLM）可以通过指令调整扩展其零 shot 泛化能力到多Modal学习。随着更多Modal和下游任务的引入，负面冲突和干扰可能会对性能产生更加坏影响。而这一现象在先前的工作中很少被注意到，我们提出了一种新的和可扩展的框架，called \mname，用于多Modal学习的全面研究和实验。 Specifically,我们将Well-known Mixture-of-Experts（MoE）和一种代表性的PEFT技术，即LoRA，结合在一起，设计了一种基于LLM的多Modal学习decoder，called LoRA-MoE。实验结果（大约20%提升）表明了我们的设计的效果和多样性在多种2D和3D下游任务中。代码和相应的数据集即将上传。
</details></li>
</ul>
<hr>
<h2 id="Digital-Typhoon-Long-term-Satellite-Image-Dataset-for-the-Spatio-Temporal-Modeling-of-Tropical-Cyclones"><a href="#Digital-Typhoon-Long-term-Satellite-Image-Dataset-for-the-Spatio-Temporal-Modeling-of-Tropical-Cyclones" class="headerlink" title="Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones"></a>Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02665">http://arxiv.org/abs/2311.02665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asanobu Kitamoto, Jared Hwang, Bastien Vuillod, Lucas Gautier, Yingtao Tian, Tarin Clanuwat</li>
<li>for: 本研究发布了40年以上的风暴卫星图像数据集，用于评测机器学习模型在长期空间时间数据上的性能。</li>
<li>methods: 研究人员开发了一种工作流程，用于创建基于最佳轨迹数据的偏振镜像，并解决了数据质量问题，如卫星间准备。</li>
<li>results: 研究人员通过对分析、预测和重新分析等任务进行评测，发现这些任务对现有的深度学习模型来说是挑战性的，具有多种选择对性能的影响。<details>
<summary>Abstract</summary>
This paper presents the official release of the Digital Typhoon dataset, the longest typhoon satellite image dataset for 40+ years aimed at benchmarking machine learning models for long-term spatio-temporal data. To build the dataset, we developed a workflow to create an infrared typhoon-centered image for cropping using Lambert azimuthal equal-area projection referring to the best track data. We also address data quality issues such as inter-satellite calibration to create a homogeneous dataset. To take advantage of the dataset, we organized machine learning tasks by the types and targets of inference, with other tasks for meteorological analysis, societal impact, and climate change. The benchmarking results on the analysis, forecasting, and reanalysis for the intensity suggest that the dataset is challenging for recent deep learning models, due to many choices that affect the performance of various models. This dataset reduces the barrier for machine learning researchers to meet large-scale real-world events called tropical cyclones and develop machine learning models that may contribute to advancing scientific knowledge on tropical cyclones as well as solving societal and sustainability issues such as disaster reduction and climate change. The dataset is publicly available at http://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and https://github.com/kitamoto-lab/digital-typhoon/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhanced-adaptive-cross-layer-scheme-for-low-latency-HEVC-streaming-over-Vehicular-Ad-hoc-Networks-VANETs"><a href="#Enhanced-adaptive-cross-layer-scheme-for-low-latency-HEVC-streaming-over-Vehicular-Ad-hoc-Networks-VANETs" class="headerlink" title="Enhanced adaptive cross-layer scheme for low latency HEVC streaming over Vehicular Ad-hoc Networks (VANETs)"></a>Enhanced adaptive cross-layer scheme for low latency HEVC streaming over Vehicular Ad-hoc Networks (VANETs)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02664">http://arxiv.org/abs/2311.02664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Aymen Labiod, Mohamed Gharbi, François-Xavier Coudoux, Patrick Corlay, Noureddine Doghmane<br>for:这篇论文主要旨在提高在交通协议网络（VANET）下的高效视频流传输。methods:该论文提出了一种低复杂度跨层机制，用于改善HEVC视频流传输的终端到终端性能。该机制根据视频编码过程中的时间预测结构、帧的重要性和网络负荷状态，将每个视频包分配到最合适的Access Category（AC）队列。results: simulations results显示，对于不同的低延迟视频通信场景，该机制可以提供显著改善的视频质量和终端到终端延迟，相比于802.11p中的Enhanced Distributed Channel Access（EDCA）。此外，论文还进行了QoS和QoE评估，以验证提出的方法的有效性。<details>
<summary>Abstract</summary>
Vehicular communication has become a reality guided by various applications. Among those, high video quality delivery with low latency constraints required by real-time applications constitutes a very challenging task. By dint of its never-before-achieved compression level, the new High-Efficiency Video Coding (HEVC) is very promising for real-time video streaming through Vehicular Ad-hoc Networks (VANET). However, these networks have variable channel quality and limited bandwidth. Therefore, ensuring satisfactory video quality on such networks is a major challenge. In this work, a low complexity cross-layer mechanism is proposed to improve end-to-end performances of HEVC video streaming in VANET under low delay constraints. The idea is to assign to each packet of the transmitted video the most appropriate Access Category (AC) queue on the Medium Access Control (MAC) layer, considering the temporal prediction structure of the video encoding process, the importance of the frame and the state of the network traffic load. Simulation results demonstrate that for different targeted low-delay video communication scenarios, the proposed mechanism offers significant improvements regarding video quality at the reception and end-to-end delay compared to the Enhanced Distributed Channel Access (EDCA) adopted in the 802.11p. Both Quality of Service (QoS) and Quality of Experience (QoE) evaluations have been also carried out to validate the proposed approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CCMR-High-Resolution-Optical-Flow-Estimation-via-Coarse-to-Fine-Context-Guided-Motion-Reasoning"><a href="#CCMR-High-Resolution-Optical-Flow-Estimation-via-Coarse-to-Fine-Context-Guided-Motion-Reasoning" class="headerlink" title="CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine Context-Guided Motion Reasoning"></a>CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine Context-Guided Motion Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02661">http://arxiv.org/abs/2311.02661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Azin Jahedi, Maximilian Luz, Marc Rivinius, Andrés Bruhn</li>
<li>for: 这个论文目的是提出一种高分辨率粗细规格的多尺度光流估计方法，以提高光流估计的精度和稳定性。</li>
<li>methods: 该方法使用了注意力基于运动聚合的概念，并在多尺度上进行了粗细规格的融合。具体来说，该方法首先计算了全局多尺度上的多个注意力权重，然后使用这些权重来导引实际的运动聚合。</li>
<li>results: 实验和折补示出，该方法可以提供高精度的流场场景，并在非 occlusion 和 occlusion 区域中具有明显的改善。相比单个尺度的注意力基于运动聚合方法和无注意力基于运动聚合方法，该方法可以提供23.0%和21.6%的提升。此外，该方法还实现了 state-of-the-art 的结果，在 KITTI 2015 和 MPI Sintel Clean 和 Final 上 ranking 第一和第二。<details>
<summary>Abstract</summary>
Attention-based motion aggregation concepts have recently shown their usefulness in optical flow estimation, in particular when it comes to handling occluded regions. However, due to their complexity, such concepts have been mainly restricted to coarse-resolution single-scale approaches that fail to provide the detailed outcome of high-resolution multi-scale networks. In this paper, we hence propose CCMR: a high-resolution coarse-to-fine approach that leverages attention-based motion grouping concepts to multi-scale optical flow estimation. CCMR relies on a hierarchical two-step attention-based context-motion grouping strategy that first computes global multi-scale context features and then uses them to guide the actual motion grouping. As we iterate both steps over all coarse-to-fine scales, we adapt cross covariance image transformers to allow for an efficient realization while maintaining scale-dependent properties. Experiments and ablations demonstrate that our efforts of combining multi-scale and attention-based concepts pay off. By providing highly detailed flow fields with strong improvements in both occluded and non-occluded regions, our CCMR approach not only outperforms both the corresponding single-scale attention-based and multi-scale attention-free baselines by up to 23.0% and 21.6%, respectively, it also achieves state-of-the-art results, ranking first on KITTI 2015 and second on MPI Sintel Clean and Final. Code and trained models are available at https://github.com/cv-stuttgart /CCMR.
</details>
<details>
<summary>摘要</summary>
听力基于的动态聚合概念在光流估计中有着广泛的应用，特别是在处理遮挡区域时。然而，由于其复杂性，这些概念通常被限制在低分辨率单个级别的方法中，这些方法无法提供高分辨率多级网络的详细结果。在这篇论文中，我们因此提出了 CCMR：一种高分辨率从粗到细的方法，该方法利用听力基于的动态聚合概念来实现多级光流估计。CCMR利用了层次两步听力基于的上下文动态聚合策略，首先计算全局多尺度上下文特征，然后使用这些特征来引导实际的动态聚合。在我们在所有粗到细尺度上重复这两个步骤时，我们采用了可 efficiently 实现的差分干扰变换，以保持尺度dependent 性。实验和截役表明，我们的努力将多尺度和听力基于的概念结合起来 pays off。通过提供高度详细的流场场景，我们的 CCMR 方法不仅与单个级别的听力基于的和无听力基于的基eline 相比，提高了23.0%和21.6%，同时达到了状态之 искусственный智能 的最佳结果，在 KITTI 2015 和 MPI Sintel Clean 和 Final 上排名第一和第二。代码和训练模型可以在 <https://github.com/cv-stuttgart/CCMR> 获取。
</details></li>
</ul>
<hr>
<h2 id="Region-of-Interest-ROI-based-adaptive-cross-layer-system-for-real-time-video-streaming-over-Vehicular-Ad-hoc-NETworks-VANETs"><a href="#Region-of-Interest-ROI-based-adaptive-cross-layer-system-for-real-time-video-streaming-over-Vehicular-Ad-hoc-NETworks-VANETs" class="headerlink" title="Region of Interest (ROI) based adaptive cross-layer system for real-time video streaming over Vehicular Ad-hoc NETworks (VANETs)"></a>Region of Interest (ROI) based adaptive cross-layer system for real-time video streaming over Vehicular Ad-hoc NETworks (VANETs)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02656">http://arxiv.org/abs/2311.02656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Aymen Labiod, Mohamed Gharbi, François-Xavier Coudoux, Patrick Corlay</li>
<li>for: 提高汽车实时应用中视频获取和处理的质量，以检测或识别驾驶环境中的车辆和障碍物。</li>
<li>methods: 提出一种低复杂度解决方案，将视频传输质量端到端实时提升，基于汽车通信标准IEEE 802.11p MAC层进行适应性跨层映射ROI视频数据包。</li>
<li>results: 实验结果表明，对于HEVC压缩视频通信，提出的系统可以在ROI部分提高PSNR值达11dB。<details>
<summary>Abstract</summary>
Nowadays, real-time vehicle applications increasingly rely on video acquisition and processing to detect or even identify vehicles and obstacles in the driving environment. In this letter, we propose an algorithm that allows reinforcing these operations by improving end-to-end video transmission quality in a vehicular context. The proposed low complexity solution gives highest priority to the scene regions of interest (ROI) on which the perception of the driving environment is based on. This is done by applying an adaptive cross-layer mapping of the ROI visual data packets at the IEEE 802.11p MAC layer. Realistic VANET simulation results demonstrate that for HEVC compressed video communications, the proposed system offers PSNR gains up to 11dB on the ROI part.
</details>
<details>
<summary>摘要</summary>
现在，实时车辆应用越来越依赖视频获取和处理来探测或识别在驾驶环境中的车辆和障碍物。在这封信中，我们提议了一种算法，可以改进汽车上的视频传输质量。我们的低复杂度解决方案会将关键场景区域（ROI）的视频数据包在IEEE 802.11p MAC层进行适应性跨层映射。在实际VANET模拟结果中，我们发现，对于HEVC压缩视频通信，我们的系统可以在ROI部分提供PSNR增强达11dB。
</details></li>
</ul>
<hr>
<h2 id="Generative-Face-Video-Coding-Techniques-and-Standardization-Efforts-A-Review"><a href="#Generative-Face-Video-Coding-Techniques-and-Standardization-Efforts-A-Review" class="headerlink" title="Generative Face Video Coding Techniques and Standardization Efforts: A Review"></a>Generative Face Video Coding Techniques and Standardization Efforts: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02649">http://arxiv.org/abs/2311.02649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bolin Chen, Jie Chen, Shiqi Wang, Yan Ye</li>
<li>for: 高速内容通信和应用</li>
<li>methods: 使用深度生成模型和面统计学来实现高品质脸部影像传输</li>
<li>results: 可以实现高比特率内容通信、用户自定义动画&#x2F;滤波和元宇宙相关功能Here’s the translation in Simplified Chinese:</li>
<li>for: 高速内容通信和应用</li>
<li>methods: 使用深度生成模型和面统计学来实现高品质脸部影像传输</li>
<li>results: 可以实现高比特率内容通信、用户自定义动画&#x2F;滤波和元宇宙相关功能<details>
<summary>Abstract</summary>
Generative Face Video Coding (GFVC) techniques can exploit the compact representation of facial priors and the strong inference capability of deep generative models, achieving high-quality face video communication in ultra-low bandwidth scenarios. This paper conducts a comprehensive survey on the recent advances of the GFVC techniques and standardization efforts, which could be applicable to ultra low bitrate communication, user-specified animation/filtering and metaverse-related functionalities. In particular, we generalize GFVC systems within one coding framework and summarize different GFVC algorithms with their corresponding visual representations. Moreover, we review the GFVC standardization activities that are specified with supplemental enhancement information messages. Finally, we discuss fundamental challenges and broad applications on GFVC techniques and their standardization potentials, as well as envision their future trends. The project page can be found at https://github.com/Berlin0610/Awesome-Generative-Face-Video-Coding.
</details>
<details>
<summary>摘要</summary>
《生成面部视频编码（GFVC）技术可以利用面部预期的紧凑表示和深度生成模型的强大推理能力，实现高质量的面部视频通信在ULTRA低带宽场景下。本文对最近的GFVC技术的进展和标准化努力进行了全面的检查，这些技术可能适用于ULTRA低比特率通信、用户指定的动画/滤波和元宇宙相关功能。特别是，我们将GFVC系统归纳到一个编码框架内，并将不同的GFVC算法与其对应的视觉表示一起总结。此外，我们还回顾了GFVC标准化活动，包括补充增强信息消息。最后，我们讨论了GFVC技术的基本挑战和广泛应用，以及其标准化潜力。项目页面可以在https://github.com/Berlin0610/Awesome-Generative-Face-Video-Coding找到。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="An-Approach-for-Multi-Object-Tracking-with-Two-Stage-Min-Cost-Flow"><a href="#An-Approach-for-Multi-Object-Tracking-with-Two-Stage-Min-Cost-Flow" class="headerlink" title="An Approach for Multi-Object Tracking with Two-Stage Min-Cost Flow"></a>An Approach for Multi-Object Tracking with Two-Stage Min-Cost Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02642">http://arxiv.org/abs/2311.02642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huining Li, Yalong Jiang, Xianlin Zeng, Feng Li, Zhipeng Wang</li>
<li>for: 本文提出了一种基于 minimum network flow 算法的多目标跟踪方法，以解决现有方法忽略 occlusion 的缺陷。</li>
<li>methods: 本文使用了 tracklets 交叠和低信度探测的性质，开发了一个两stage 跟踪管道，并使用了交叠 mask 精准地定位不准确的 tracklets。在第二stage 中，使用了低信度探测可能是 occlusion 的情况，对不准确的 tracklets 进行修正。</li>
<li>results: 在流行的 MOT  benchmark 数据集上进行了评测，实现了 78.4 MOTA on MOT16 测试集、79.2 on MOT17 测试集和76.4 on MOT20 测试集，表明提出的方法有效。<details>
<summary>Abstract</summary>
The minimum network flow algorithm is widely used in multi-target tracking. However, the majority of the present methods concentrate exclusively on minimizing cost functions whose values may not indicate accurate solutions under occlusions. In this paper, by exploiting the properties of tracklets intersections and low-confidence detections, we develop a two-stage tracking pipeline with an intersection mask that can accurately locate inaccurate tracklets which are corrected in the second stage. Specifically, we employ the minimum network flow algorithm with high-confidence detections as input in the first stage to obtain the candidate tracklets that need correction. Then we leverage the intersection mask to accurately locate the inaccurate parts of candidate tracklets. The second stage utilizes low-confidence detections that may be attributed to occlusions for correcting inaccurate tracklets. This process constructs a graph of nodes in inaccurate tracklets and low-confidence nodes and uses it for the second round of minimum network flow calculation. We perform sufficient experiments on popular MOT benchmark datasets and achieve 78.4 MOTA on the test set of MOT16, 79.2 on MOT17, and 76.4 on MOT20, which shows that the proposed method is effective.
</details>
<details>
<summary>摘要</summary>
“几个目标追踪算法的最小网络流算法广泛应用于多目标追踪。然而，现有的大多数方法仅专注于最小化成本函数的值，但这些值可能不准确地反映 occlusions 的情况。在本文中，我们运用追踪小片的交叉和低信任探测的属性，开发了一个两阶段追踪管线，包括交叉面罩。在第一阶段，我们使用高信任探测作为追踪小片的输入，以取得需要更正的候选追踪小片。然后，我们利用交叉面罩来精确地定位不准确的追踪小片部分。在第二阶段，我们使用低信任探测，可能导因于 occlusions，来更正不准确的追踪小片。这个过程建立了一个节点的图，并使用它来进行第二回的最小网络流计算。我们实现了多个受欢迎的 MOT 套件 dataset 的实验，并在 MOT16 的试验集上取得了 78.4 MOTA，在 MOT17 的试验集上取得了 79.2 MOTA，在 MOT20 的试验集上取得了 76.4 MOTA，这说明了我们的方法的有效性。”
</details></li>
</ul>
<hr>
<h2 id="The-Background-Also-Matters-Background-Aware-Motion-Guided-Objects-Discovery"><a href="#The-Background-Also-Matters-Background-Aware-Motion-Guided-Objects-Discovery" class="headerlink" title="The Background Also Matters: Background-Aware Motion-Guided Objects Discovery"></a>The Background Also Matters: Background-Aware Motion-Guided Objects Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02633">http://arxiv.org/abs/2311.02633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandra Kara, Hejer Ammar, Florian Chabot, Quoc-Cuong Pham</li>
<li>for: 本研究旨在提高视频数据中对象发现的精度，特别是利用视频中的自然运动信息。</li>
<li>methods: 我们提出了一种Background-aware Motion-guided Objects Discovery方法（BMOD），利用摄像头流中提取出的运动mask来扩展到真正的前景中的静止和动态物体。</li>
<li>results: 我们在 sintetic和实际 dataset上进行了实验，结果表明，将我们的背景处理与多种前沿方法结合使用，可以大幅提高对象发现性能，同时建立了对物体&#x2F;非物体分离的强大基线。<details>
<summary>Abstract</summary>
Recent works have shown that objects discovery can largely benefit from the inherent motion information in video data. However, these methods lack a proper background processing, resulting in an over-segmentation of the non-object regions into random segments. This is a critical limitation given the unsupervised setting, where object segments and noise are not distinguishable. To address this limitation we propose BMOD, a Background-aware Motion-guided Objects Discovery method. Concretely, we leverage masks of moving objects extracted from optical flow and design a learning mechanism to extend them to the true foreground composed of both moving and static objects. The background, a complementary concept of the learned foreground class, is then isolated in the object discovery process. This enables a joint learning of the objects discovery task and the object/non-object separation. The conducted experiments on synthetic and real-world datasets show that integrating our background handling with various cutting-edge methods brings each time a considerable improvement. Specifically, we improve the objects discovery performance with a large margin, while establishing a strong baseline for object/non-object separation.
</details>
<details>
<summary>摘要</summary>
近期研究表明，视频数据中的自然运动信息可以大量地提高物体发现效果。然而，现有方法缺乏正确的背景处理，导致非物体区域分割成随机分割。这是一个 kritical limitation，因为在无监督设置下，物体分割和噪声无法区分。为解决这个限制，我们提出了 BMOD，一种基于运动的背景意识物体发现方法。具体来说，我们利用运动图像中的滤流推导出移动物体的面掩码，然后设计一种学习机制，将其扩展到真正的前景，包括运动和静止物体。然后，我们隔离了背景，使得物体发现任务和物体/非物体分离 jointly learning。实验表明，将我们的背景处理与多种前沿方法结合使用，可以每次带来显著改善。具体来说，我们可以大幅提高物体发现性能，而且建立了强的基线 для物体/非物体分离。
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-Are-Implicit-Decision-Trees-The-Hierarchical-Simplicity-Bias"><a href="#Neural-Networks-Are-Implicit-Decision-Trees-The-Hierarchical-Simplicity-Bias" class="headerlink" title="Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity Bias"></a>Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02622">http://arxiv.org/abs/2311.02622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhehang Du</li>
<li>for: 研究神经网络中的简洁偏见问题，即神经网络偏好使用简单的特征而忽略更复杂的特征，即使这些更复杂的特征仍然具有预测力。</li>
<li>methods: 提出了一种新的方法——偏见标签对应，用于研究在神经网络中简单和复杂特征之间的预测力差异。</li>
<li>results: 通过实验示出，神经网络在某些场景下会偏好使用简单的特征，即使这些特征并不是真正预测力最高的。此外，通过 retrained 神经网络的实验，发现在某些情况下，只有使用目标数据分布进行重新训练可以完全恢复核心特征。<details>
<summary>Abstract</summary>
Neural networks exhibit simplicity bias; they rely on simpler features while ignoring equally predictive but more complex features. In this work, we introduce a novel approach termed imbalanced label coupling to investigate scenarios where simple and complex features exhibit different levels of predictive power. In these cases, complex features still contribute to predictions. The trained networks make predictions in alignment with the ascending complexity of input features according to how they correlate with the label in the training set, irrespective of the underlying predictive power. For instance, even when simple spurious features distort predictions in CIFAR-10, most cats are predicted to be dogs, and most trucks are predicted to be automobiles! This observation provides direct evidence that the neural network learns core features in the presence of spurious features. We empirically show that last-layer retraining with target data distribution is effective, yet insufficient to fully recover core features when spurious features are perfectly correlated with the target labels in our synthetic dataset. We hope our research contributes to a deeper understanding of the implicit bias of neural networks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TFNet-Tuning-Fork-Network-with-Neighborhood-Pixel-Aggregation-for-Improved-Building-Footprint-Extraction"><a href="#TFNet-Tuning-Fork-Network-with-Neighborhood-Pixel-Aggregation-for-Improved-Building-Footprint-Extraction" class="headerlink" title="TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for Improved Building Footprint Extraction"></a>TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for Improved Building Footprint Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02617">http://arxiv.org/abs/2311.02617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ahmad Waseem, Muhammad Tahir, Zubair Khalid, Momin Uppal</li>
<li>for: 本研究强调把建筑底图从卫星图像中提取出来 – 这是城市规划和决策应用中的关键问题。</li>
<li>methods: 本研究提出了一种新的 Tuning Fork Network (TFNet) 设计，用于深度 semantic segmentation。TFNet 拥有一个单一的编码器，然后两个平行的解码器，用于分别重建建筑底图和建筑边沿。此外，TFNet 还与一种新的邻区信息在训练过程中的方法集成，以进一步改善性能，特别是在块边界上。</li>
<li>results: 对 SpaceNet2、WHU 数据集和一个来自卫星干扰 Pakistán 的数据集进行比较，提出的方法在所有三个数据集上显著超越了参考方法。<details>
<summary>Abstract</summary>
This paper considers the problem of extracting building footprints from satellite imagery -- a task that is critical for many urban planning and decision-making applications. While recent advancements in deep learning have made great strides in automated detection of building footprints, state-of-the-art methods available in existing literature often generate erroneous results for areas with densely connected buildings. Moreover, these methods do not incorporate the context of neighborhood images during training thus generally resulting in poor performance at image boundaries. In light of these gaps, we propose a novel Tuning Fork Network (TFNet) design for deep semantic segmentation that not only performs well for widely-spaced building but also has good performance for buildings that are closely packed together. The novelty of TFNet architecture lies in a a single encoder followed by two parallel decoders to separately reconstruct the building footprint and the building edge. In addition, the TFNet design is coupled with a novel methodology of incorporating neighborhood information at the tile boundaries during the training process. This methodology further improves performance, especially at the tile boundaries. For performance comparisons, we utilize the SpaceNet2 and WHU datasets, as well as a dataset from an area in Lahore, Pakistan that captures closely connected buildings. For all three datasets, the proposed methodology is found to significantly outperform benchmark methods.
</details>
<details>
<summary>摘要</summary>
To address these gaps, we propose a novel Tuning Fork Network (TFNet) design for deep semantic segmentation. TFNet consists of a single encoder followed by two parallel decoders that separately reconstruct the building footprint and the building edge. Additionally, we introduce a novel methodology for incorporating neighborhood information at the tile boundaries during training, which further improves performance, especially at the tile boundaries.We evaluate our method on three datasets: SpaceNet2, WHU, and a dataset from Lahore, Pakistan, which captures closely connected buildings. Our method significantly outperforms benchmark methods on all three datasets, demonstrating its effectiveness in extracting accurate building footprints from satellite imagery, regardless of building density.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Grounding-Potential-of-VQA-oriented-GPT-4V-for-Zero-shot-Anomaly-Detection"><a href="#Exploring-Grounding-Potential-of-VQA-oriented-GPT-4V-for-Zero-shot-Anomaly-Detection" class="headerlink" title="Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot Anomaly Detection"></a>Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02612">http://arxiv.org/abs/2311.02612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangning Zhang, Xuhai Chen, Zhucun Xue, Yabiao Wang, Chengjie Wang, Yong Liu<br>for: This paper explores the potential of using GPT-4 with visual grounding capabilities (GPT-4V) for anomaly detection (AD) tasks through the visual question answering (VQA) paradigm.methods: The proposed GPT-4V-AD framework includes three components: 1) Granular Region Division, 2) Prompt Designing, and 3) Text2Segmentation for easy quantitative evaluation.results: The results show that GPT-4V can achieve certain results in the zero-shot AD task, such as achieving image-level 77.1&#x2F;88.0 and pixel-level 68.0&#x2F;76.6 AU-ROCs on MVTec AD and VisA datasets, respectively. However, its performance still has a certain gap compared to the state-of-the-art zero-shot method, e.g., WinCLIP ann CLIP-AD.Here’s the simplified Chinese text:for: 这篇论文探讨了使用 GPT-4  WITH 视觉整合能力 (GPT-4V) 进行异常检测 (AD) 任务，通过视觉问答 (VQA) 方式进行实现。methods: GPT-4V-AD 框架包括三个Component：1) 粒度Region Division，2) 提问设计，3) Text2Segmentation  для方便的量化评估。results: 结果表明，GPT-4V 可以在零处shot AD 任务中实现certain的结果，如在 MVTec AD 和 VisA 数据集上获得图像 Water 77.1&#x2F;88.0 和像素 Water 68.0&#x2F;76.6 AU-ROCs，但其表现还有一定的差距与零处shot方法，如 WinCLIP ann CLIP-AD。<details>
<summary>Abstract</summary>
Large Multimodal Model (LMM) GPT-4V(ision) endows GPT-4 with visual grounding capabilities, making it possible to handle certain tasks through the Visual Question Answering (VQA) paradigm. This paper explores the potential of VQA-oriented GPT-4V in the recently popular visual Anomaly Detection (AD) and is the first to conduct qualitative and quantitative evaluations on the popular MVTec AD and VisA datasets. Considering that this task requires both image-/pixel-level evaluations, the proposed GPT-4V-AD framework contains three components: 1) Granular Region Division, 2) Prompt Designing, 3) Text2Segmentation for easy quantitative evaluation, and have made some different attempts for comparative analysis. The results show that GPT-4V can achieve certain results in the zero-shot AD task through a VQA paradigm, such as achieving image-level 77.1/88.0 and pixel-level 68.0/76.6 AU-ROCs on MVTec AD and VisA datasets, respectively. However, its performance still has a certain gap compared to the state-of-the-art zero-shot method, e.g., WinCLIP ann CLIP-AD, and further research is needed. This study provides a baseline reference for the research of VQA-oriented LMM in the zero-shot AD task, and we also post several possible future works. Code is available at \url{https://github.com/zhangzjn/GPT-4V-AD}.
</details>
<details>
<summary>摘要</summary>
大型多modal模型（LMM）GPT-4V（视觉）将GPT-4授与视觉定位能力，使其可以通过视觉问答（VQA）方式处理某些任务。本文探讨GPT-4V在最近受欢迎的视觉异常检测（AD）任务中的潜力，是首次对MVTec AD和VisA dataset进行资深和量化评估。由于这个任务需要图像/像素级评估，我们提出了三个组成部分：1）粒度分割，2）提示设计，3）文本2分割。我们也进行了不同的尝试以便比较分析。结果表明，GPT-4V可以通过VQA方式在零shot AD任务中达到某些结果，如MVTec AD和VisA dataset的图像级AU-ROC为77.1/88.0，像素级AU-ROC为68.0/76.6。然而，它的性能仍有一定差距 compared to零shot方法的状态对照，如WinCLIP ann CLIP-AD，需要进一步研究。这些研究提供了VQA-oriented LMM在零shot AD任务的基eline参考，我们还提出了一些可能的未来工作。代码可以在 \url{https://github.com/zhangzjn/GPT-4V-AD} 获取。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-3D-Point-Cloud-Classification-A-Systematic-Survey-and-Outlook"><a href="#Deep-Learning-based-3D-Point-Cloud-Classification-A-Systematic-Survey-and-Outlook" class="headerlink" title="Deep Learning-based 3D Point Cloud Classification: A Systematic Survey and Outlook"></a>Deep Learning-based 3D Point Cloud Classification: A Systematic Survey and Outlook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02608">http://arxiv.org/abs/2311.02608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huang Zhang, Changshuo Wang, Shengwei Tian, Baoli Lu, Liping Zhang, Xin Ning, Xiao Bai</li>
<li>for: 本研究的目的是为点云分类提供最新的研究进展和未来趋势。</li>
<li>methods: 本文综述了点云获取、特点和挑战，以及常用的3D数据表示、存储格式和点云分类深度学习方法。</li>
<li>results: 本文summarizes recent research work in point cloud classification and compares and analyzes the performance of main methods. Additionally, it discusses some challenges and future directions for point cloud classification.I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
In recent years, point cloud representation has become one of the research hotspots in the field of computer vision, and has been widely used in many fields, such as autonomous driving, virtual reality, robotics, etc. Although deep learning techniques have achieved great success in processing regular structured 2D grid image data, there are still great challenges in processing irregular, unstructured point cloud data. Point cloud classification is the basis of point cloud analysis, and many deep learning-based methods have been widely used in this task. Therefore, the purpose of this paper is to provide researchers in this field with the latest research progress and future trends. First, we introduce point cloud acquisition, characteristics, and challenges. Second, we review 3D data representations, storage formats, and commonly used datasets for point cloud classification. We then summarize deep learning-based methods for point cloud classification and complement recent research work. Next, we compare and analyze the performance of the main methods. Finally, we discuss some challenges and future directions for point cloud classification.
</details>
<details>
<summary>摘要</summary>
Recently, point cloud representation has become one of the research hotspots in the field of computer vision, and has been widely used in many fields, such as autonomous driving, virtual reality, robotics, etc. Although deep learning techniques have achieved great success in processing regular structured 2D grid image data, there are still great challenges in processing irregular, unstructured point cloud data. Point cloud classification is the basis of point cloud analysis, and many deep learning-based methods have been widely used in this task. Therefore, the purpose of this paper is to provide researchers in this field with the latest research progress and future trends.First, we introduce point cloud acquisition, characteristics, and challenges. Second, we review 3D data representations, storage formats, and commonly used datasets for point cloud classification. We then summarize deep learning-based methods for point cloud classification and complement recent research work. Next, we compare and analyze the performance of the main methods. Finally, we discuss some challenges and future directions for point cloud classification.Here's the translation of the text into Traditional Chinese:过去几年，点云表现在计算机视觉领域中已经成为一个研究热点，并在许多领域中得到广泛应用，如自动驾驶、虚拟现实、机器人等。尽管深度学习技术在处理常规的2D格子图像数据中取得了很大的成功，但还有很大的挑战在处理不规则、无结构的点云数据方面。点云分类是点云分析的基础，许多深度学习基于的方法在这个任务中广泛使用。因此，这篇文章的目的是为这个领域的研究人员提供最新的研究进步和未来趋势。首先，我们介绍点云取得、特点和挑战。第二，我们回顾3D数据表现、储存格式和通常使用的数据集 для点云分类。然后，我们评论深度学习基于的方法 для点云分类，并补充最近的研究成果。接下来，我们比较和分析主要方法的性能。最后，我们讨论一些挑战和未来方向 для点云分类。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Implicit-Neural-Representations-from-Point-Clouds-via-Energy-Based-Models"><a href="#Optimizing-Implicit-Neural-Representations-from-Point-Clouds-via-Energy-Based-Models" class="headerlink" title="Optimizing Implicit Neural Representations from Point Clouds via Energy-Based Models"></a>Optimizing Implicit Neural Representations from Point Clouds via Energy-Based Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02601">http://arxiv.org/abs/2311.02601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryutaro Yamauchi, Jinya Sakurai, Ryo Furukawa, Tatsushi Matsubayashi</li>
<li>for: 重建无orientation 3D 点云表面</li>
<li>methods: 使用能量基本模型（EBM）优化卷积神经网络（INR）</li>
<li>results: 提高对点云噪声的耐性<details>
<summary>Abstract</summary>
Reconstructing a continuous surface from an unoritented 3D point cloud is a fundamental task in 3D shape processing. In recent years, several methods have been proposed to address this problem using implicit neural representations (INRs). In this study, we propose a method to optimize INRs using energy-based models (EBMs). By employing the absolute value of the coordinate-based neural networks as the energy function, the INR can be optimized through the estimation of the point cloud distribution by the EBM. In addition, appropriate parameter settings of the EBM enable the model to consider the magnitude of point cloud noise. Our experiments confirmed that the proposed method is more robust against point cloud noise than conventional surface reconstruction methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传输给定文本到简化中文。</SYS>>重建无排序3D点云表面是3D形状处理中的基本任务。近年来，一些方法被提议用于解决这个问题，使用卷积神经网络（INR）。在本研究中，我们提出了使用能量基本模型（EBM）来优化INR。通过使用坐标基于神经网络的绝对值作为能量函数，可以通过EBM估计点云分布，并且适当地设置EBM参数，使模型考虑点云噪声的大小。我们的实验表明，我们提出的方法比传统表面重建方法更加鲁棒对待点云噪声。
</details></li>
</ul>
<hr>
<h2 id="Learning-Class-and-Domain-Augmentations-for-Single-Source-Open-Domain-Generalization"><a href="#Learning-Class-and-Domain-Augmentations-for-Single-Source-Open-Domain-Generalization" class="headerlink" title="Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization"></a>Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02599">http://arxiv.org/abs/2311.02599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prathmesh Bele, Valay Bundele, Avigyan Bhattacharya, Ankit Jha, Gemma Roig, Biplab Banerjee</li>
<li>for:  addresses the challenge of labeled source domains with supervision during training and unlabeled novel target domains during testing.</li>
<li>methods:  simultaneously synthesizes novel domains and generates pseudo-open samples using a learning-based objective, in contrast to the ad-hoc mixing strategies commonly found in the literature.</li>
<li>results:  consistently demonstrate the superior performance of SODG-Net compared to the literature.<details>
<summary>Abstract</summary>
Single-source open-domain generalization (SS-ODG) addresses the challenge of labeled source domains with supervision during training and unlabeled novel target domains during testing. The target domain includes both known classes from the source domain and samples from previously unseen classes. Existing techniques for SS-ODG primarily focus on calibrating source-domain classifiers to identify open samples in the target domain. However, these methods struggle with visually fine-grained open-closed data, often misclassifying open samples as closed-set classes. Moreover, relying solely on a single source domain restricts the model's ability to generalize. To overcome these limitations, we propose a novel framework called SODG-Net that simultaneously synthesizes novel domains and generates pseudo-open samples using a learning-based objective, in contrast to the ad-hoc mixing strategies commonly found in the literature. Our approach enhances generalization by diversifying the styles of known class samples using a novel metric criterion and generates diverse pseudo-open samples to train a unified and confident multi-class classifier capable of handling both open and closed-set data. Extensive experimental evaluations conducted on multiple benchmarks consistently demonstrate the superior performance of SODG-Net compared to the literature.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:单源开放预测（SS-ODG）挑战是在训练时使用标注的源频道，而在测试时使用未知目标频道。目标频道包括源频道中已知类和未经见过的类样本。现有的SS-ODG方法主要是对源频道分类器进行偏导，以便在目标频道中识别开放样本。然而，这些方法在视觉细化的开放-关闭数据上经常将开放样本误分类为关闭集类。此外，仅仅依靠单个源频道限制了模型的泛化能力。为了解决这些局限性，我们提出了一种新的框架 called SODG-Net，该框架同时生成新频道和 Pseudo-开放样本，而不是文献中常见的杂合策略。我们的方法通过改进知种样本的风格多样性使用一种新的度量标准，并生成多样化的 Pseudo-开放样本，以训练一个统一和自信的多类分类器，可以处理开放和关闭集数据。我们在多个 benchmark 上进行了广泛的实验评估，并 consistently 示出 SODG-Net 的超越性。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-Tumor-Manipulation-With-Radiomics-Features"><a href="#Synthetic-Tumor-Manipulation-With-Radiomics-Features" class="headerlink" title="Synthetic Tumor Manipulation: With Radiomics Features"></a>Synthetic Tumor Manipulation: With Radiomics Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02586">http://arxiv.org/abs/2311.02586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Inye Na, Jonghun Kim, Hyunjin Park</li>
<li>for: 用于生成真实、多样化的肿瘤图像</li>
<li>methods: 使用生成对抗网络、基于 радиомИCS特征的 conditioning、多任务学习</li>
<li>results: 能够生成无数量的真实、有趣的肿瘤图像，并且可以根据特定的 radiOMICS特征进行细致的调整<details>
<summary>Abstract</summary>
We introduce RadiomicsFill, a synthetic tumor generator conditioned on radiomics features, enabling detailed control and individual manipulation of tumor subregions. This conditioning leverages conventional high-dimensional features of the tumor (i.e., radiomics features) and thus is biologically well-grounded. Our model combines generative adversarial networks, radiomics-feature conditioning, and multi-task learning. Through experiments with glioma patients, RadiomicsFill demonstrated its capability to generate diverse, realistic tumors and its fine-tuning ability for specific radiomics features like 'Pixel Surface' and 'Shape Sphericity'. The ability of RadiomicsFill to generate an unlimited number of realistic synthetic tumors offers notable prospects for both advancing medical imaging research and potential clinical applications.
</details>
<details>
<summary>摘要</summary>
我们介绍RadiomicsFill，一种基于 радиологи学特征的Synthetic tumor生成器，允许细致控制和个性化肿瘤子区。这种conditioning利用了普通高维度特征（即 радиологи学特征），因此是生物学上具有良好的基础。我们的模型结合生成对抗网络、 радиологи学特征conditioning和多任务学习。通过对 glioma 患者进行实验，RadiomicsFill 展示了它的能力生成多样化、真实的肿瘤和特定 радиологи学特征（如 'Pixel Surface' 和 'Shape Sphericity'）的细致调整能力。RadiomicsFill 可以生成无数量的真实的Synthetic tumors，这会对医疗影像研究和临床应用带来重要的前景。
</details></li>
</ul>
<hr>
<h2 id="SSL-DG-Rethinking-and-Fusing-Semi-supervised-Learning-and-Domain-Generalization-in-Medical-Image-Segmentation"><a href="#SSL-DG-Rethinking-and-Fusing-Semi-supervised-Learning-and-Domain-Generalization-in-Medical-Image-Segmentation" class="headerlink" title="SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain Generalization in Medical Image Segmentation"></a>SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain Generalization in Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02583">http://arxiv.org/abs/2311.02583</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zanting Ye</li>
<li>for: 这篇论文是针对医疗影像分类 tasks 的研究，并且解决了受限给标注数据的问题以及域别Shift 的问题。</li>
<li>methods: 本文使用了 semi-supervised learning (SSL) 和 domain generalization (DG) 等cutting-edge方法来解决标注数据障碍和域别Shift 问题。另外，我们还使用了 class-level representation 来表示未见目标数据，并使用了对应的数据增强技术来增加域别分布。</li>
<li>results: 我们的 SSL-DG 方法在两个具有限制标注的域别算法中实现了显著的进步，并且与state-of-the-art 方法进行比较，获得了更好的效果。<details>
<summary>Abstract</summary>
Deep learning-based medical image segmentation is an essential yet challenging task in clinical practice, which arises from restricted access to annotated data coupled with the occurrence of domain shifts. Previous attempts have focused on isolated solutions, while disregarding their inter-connectedness. In this paper, we rethink the relationship between semi-supervised learning (SSL) and domain generalization (DG), which are the cutting-edge approaches to address the annotated data-driven constraints and the domain shift issues. Inspired by class-level representation, we show that unseen target data can be represented by a linear combination of source data, which can be achieved by simple data augmentation. The augmented data enrich domain distributions while having semantic consistency, aligning with the principles of consistency-based SSL. Accordingly, we propose SSL-DG, fusing DG and SSL, to achieve cross-domain generalization with limited annotations. Specifically, the global and focal region augmentation, together with an augmentation scale-balancing mechanism, are used to construct a mask-based domain diffusion augmentation module to significantly enrich domain diversity. In order to obtain consistent predictions for the same source data in different networks, we use uncertainty estimation and a deep mutual learning strategy to enforce the consistent constraint. Extensive experiments including ablation studies are designed to validate the proposed SSL-DG. The results demonstrate that our SSL-DG significantly outperforms state-of-the-art solutions in two challenging DG tasks with limited annotations. Code is available at https://github.com/yezanting/SSL-DG.
</details>
<details>
<summary>摘要</summary>
深度学习基于医学图像分割是至关重要 yet 挑战性的任务在临床实践中，这是因为数据标注的限制以及频率域的变化。先前的尝试都是采取孤立的解决方案，而忽略了它们之间的相互关系。在这篇论文中，我们重新思考了 semi-supervised learning（SSL）和频率泛化（DG）之间的关系，这些是当前的领先方法来解决数据标注约束和频率域变化问题。受类水平表示的灵感，我们显示出未看到目标数据可以通过简单的数据扩充表示为线性组合的源数据，这可以在域分布中增加数据资源，同时保持 semantic consistency，符合一致性基于 SSL 的原则。因此，我们提出了 SSL-DG，将 DG 和 SSL 融合起来，实现跨域泛化，并且只需限制的标注。具体来说，我们使用全球和焦点区域扩充，并与扩充缩放机制相结合，构建一个mask-based域扩充混合模块，以增加域分布的多样性。为了保证不同网络对同一个源数据的预测具有一致性，我们使用 uncertainty estimation 和深度互学策略来强制一致性约束。我们设计了大量的 эксперименталь研究，包括归一化研究，以验证我们的 SSL-DG。结果表明，我们的 SSL-DG在两个挑战性的 DG 任务中显著超越了现有的解决方案。代码可以在 https://github.com/yezanting/SSL-DG 中下载。
</details></li>
</ul>
<hr>
<h2 id="Group-Testing-for-Accurate-and-Efficient-Range-Based-Near-Neighbor-Search-An-Adaptive-Binary-Splitting-Approach"><a href="#Group-Testing-for-Accurate-and-Efficient-Range-Based-Near-Neighbor-Search-An-Adaptive-Binary-Splitting-Approach" class="headerlink" title="Group Testing for Accurate and Efficient Range-Based Near Neighbor Search : An Adaptive Binary Splitting Approach"></a>Group Testing for Accurate and Efficient Range-Based Near Neighbor Search : An Adaptive Binary Splitting Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02573">http://arxiv.org/abs/2311.02573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kashish Mittal, Harsh Shah, Ajit Rajwade</li>
<li>for: 这个论文设计了一个适应性集testing框架，用于高维度近邻搜寻问题。</li>
<li>methods: 方法基于cosine距离阈值，将集合中的每个元素标记为邻或非邻，不需要对所有元素进行扫描。</li>
<li>results: 实验结果显示，这个方法可以与扫描方法比较，并且在不同的大量数据集上实现高速搜寻。另外，方法还提供了一个 teoretic 分析，详细描述了每个查询所需的距离计算数量和遗传 pool 的概率被排除。<details>
<summary>Abstract</summary>
This work presents an adaptive group testing framework for the range-based high dimensional near neighbor search problem. The proposed method detects high-similarity vectors from an extensive collection of high dimensional vectors, where each vector represents an image descriptor. Our method efficiently marks each item in the collection as neighbor or non-neighbor on the basis of a cosine distance threshold without exhaustive search. Like other methods in the domain of large scale retrieval, our approach exploits the assumption that most of the items in the collection are unrelated to the query. Unlike other methods, it does not assume a large difference between the cosine similarity of the query vector with the least related neighbor and that with the least unrelated non-neighbor. Following the procedure of binary splitting, a multi-stage adaptive group testing algorithm, we split the set of items to be searched into half at each step, and perform dot product tests on smaller and smaller subsets, many of which we are able to prune away. We experimentally show that our method achieves a speed-up over exhaustive search by a factor of more than ten with an accuracy same as that of exhaustive search, on a variety of large datasets. We present a theoretical analysis of the expected number of distance computations per query and the probability that a pool with a certain number of members will be pruned. In this way, our method exploits very useful and practical distributional properties unlike other methods. In our method, all required data structures are created purely offline. Moreover, our method does not impose any strong assumptions on the number of true near neighbors, is adaptible to streaming settings where new vectors are dynamically added to the database, and does not require any parameter tuning.
</details>
<details>
<summary>摘要</summary>
这个工作提出了一个适应性的群测框架，用于高维近似搜索问题。该方法可以快速地从大量高维向量集合中检测出高相似性的向量，每个向量都代表了一个图像描述符。我们的方法不需要扫描整个集合，而是基于cosinus距离阈值来快速地将集合中的每个元素标记为相似或不相似。与其他大规模检索领域的方法不同，我们的方法不假设查询向量与最相似的邻居之间的cosinus相似性和最不相似的邻居之间的cosinus相似性之间有大量差异。我们采用了二分法，在每个步骤中将集合分割为两个分割，并在更小的子集上进行点积测试，大量的子集可以被排除。我们实验表明，我们的方法可以在扫描所有元素的基础上实现一个速度比扫描所有元素的速度更快，并且保持与扫描所有元素的准确性相同，在多个大型数据集上。我们还提供了一种理论分析，用于计算每个查询所需的距离计算数和 pool 中的成员数的预期值。因此，我们的方法可以充分利用实际和实用的分布特性，不同于其他方法。在我们的方法中，所有需要的数据结构都是在离线上创建的，并且我们的方法不需要任何参数调整，可以适应流动设置，在数据库中动态添加新向量。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Object-Tracking-based-on-Occlusion-Aware-Embedding-Consistency-Learning"><a href="#Multiple-Object-Tracking-based-on-Occlusion-Aware-Embedding-Consistency-Learning" class="headerlink" title="Multiple Object Tracking based on Occlusion-Aware Embedding Consistency Learning"></a>Multiple Object Tracking based on Occlusion-Aware Embedding Consistency Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02572">http://arxiv.org/abs/2311.02572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaoqi Hu, Axi Niu, Yu Zhu, Qingsen Yan, Jinqiu Sun, Yanning Zhang</li>
<li>for: 多bject tracking中的跟踪中断问题</li>
<li>methods: 视觉嵌入一致性和遮挡预测模块</li>
<li>results: 在online tracking scenarios中提高了跟踪性能，并在遮挡和不遮挡情况下都达到了可靠的跟踪结果<details>
<summary>Abstract</summary>
The Joint Detection and Embedding (JDE) framework has achieved remarkable progress for multiple object tracking. Existing methods often employ extracted embeddings to re-establish associations between new detections and previously disrupted tracks. However, the reliability of embeddings diminishes when the region of the occluded object frequently contains adjacent objects or clutters, especially in scenarios with severe occlusion. To alleviate this problem, we propose a novel multiple object tracking method based on visual embedding consistency, mainly including: 1) Occlusion Prediction Module (OPM) and 2) Occlusion-Aware Association Module (OAAM). The OPM predicts occlusion information for each true detection, facilitating the selection of valid samples for consistency learning of the track's visual embedding. The OAAM leverages occlusion cues and visual embeddings to generate two separate embeddings for each track, guaranteeing consistency in both unoccluded and occluded detections. By integrating these two modules, our method is capable of addressing track interruptions caused by occlusion in online tracking scenarios. Extensive experimental results demonstrate that our approach achieves promising performance levels in both unoccluded and occluded tracking scenarios.
</details>
<details>
<summary>摘要</summary>
《共同检测和嵌入（JDE）框架在多 объек目跟踪中实现了显著进步。现有方法通常使用提取的嵌入来重新建立新检测和已经中断的跟踪之间的关联。然而，嵌入的可靠性随着遮盖物区域内的邻近对象或废弃物增加，特别是在严重遮盖的场景下。为解决这个问题，我们提出了一种基于视觉嵌入一致性的多 объек目跟踪方法，主要包括：1）预测遮盖模块（OPM）和2）遮盖意识嵌入模块（OAAM）。OPM预测每个真实检测中的遮盖信息，使得选择有效样本进行嵌入一致学习跟踪的视觉嵌入。OAAM利用遮盖诱导和视觉嵌入来生成每个跟踪两个不同的嵌入，保证了遮盖和不遮盖的检测都能够保持一致。通过将这两个模块集成，我们的方法可以在在线跟踪场景中解决由遮盖引起的跟踪中断。广泛的实验结果表明，我们的方法在不遮盖和严重遮盖场景下都达到了可以Acceptable的性能水平。
</details></li>
</ul>
<hr>
<h2 id="Rotation-Invariant-Transformer-for-Recognizing-Object-in-UAVs"><a href="#Rotation-Invariant-Transformer-for-Recognizing-Object-in-UAVs" class="headerlink" title="Rotation Invariant Transformer for Recognizing Object in UAVs"></a>Rotation Invariant Transformer for Recognizing Object in UAVs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02559">http://arxiv.org/abs/2311.02559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuoyi Chen, Mang Ye, Bo Du</li>
<li>for: 本文针对UAV拍摄的图像进行人员目标识别 task，因为这个任务比城市相机下的对象重复识别任务更加具有挑战性，主要因为UAV拍摄的图像通常具有大量的缩放差异和不确定的旋转变化。</li>
<li>methods: 本文提出了一种新的旋转不变性vision transformer（RotTrans），通过在patch feature水平上模拟旋转操作，并通过设置不变性约束来建立原始特征与旋转特征之间的关系，以提高对大量旋转差异的Robustness。</li>
<li>results: 本文在最新的UAV数据集上进行测试，与当前状态的艺术比高5.9%和4.8%，同时在传统城市相机下的人重复识别任务中也表现竞争力强。特别是，本文在ICCV 2021中获得了UAV基于人重复识别 track的第一名。<details>
<summary>Abstract</summary>
Recognizing a target of interest from the UAVs is much more challenging than the existing object re-identification tasks across multiple city cameras. The images taken by the UAVs usually suffer from significant size difference when generating the object bounding boxes and uncertain rotation variations. Existing methods are usually designed for city cameras, incapable of handing the rotation issue in UAV scenarios. A straightforward solution is to perform the image-level rotation augmentation, but it would cause loss of useful information when inputting the powerful vision transformer as patches. This motivates us to simulate the rotation operation at the patch feature level, proposing a novel rotation invariant vision transformer (RotTrans). This strategy builds on high-level features with the help of the specificity of the vision transformer structure, which enhances the robustness against large rotation differences. In addition, we design invariance constraint to establish the relationship between the original feature and the rotated features, achieving stronger rotation invariance. Our proposed transformer tested on the latest UAV datasets greatly outperforms the current state-of-the-arts, which is 5.9\% and 4.8\% higher than the highest mAP and Rank1. Notably, our model also performs competitively for the person re-identification task on traditional city cameras. In particular, our solution wins the first place in the UAV-based person re-recognition track in the Multi-Modal Video Reasoning and Analyzing Competition held in ICCV 2021. Code is available at https://github.com/whucsy/RotTrans.
</details>
<details>
<summary>摘要</summary>
Recognizing a target of interest from UAVs is much more challenging than existing object re-identification tasks across multiple city cameras. 图像生成对象 bounding box 的尺寸差异和不确定的旋转变化会导致现有方法无法处理 UAV 场景。我们提出了一种新的方法，即在 feature 级别进行旋转尺度融合，并通过特殊的视transformer 结构增强对大范围旋转的Robustness。此外，我们还设置了一种对原始特征和旋转特征之间的相互关系约束，以实现更强的旋转不变性。我们的提出的 transformer 在最新的 UAV 数据集上进行测试，与当前状态的艺术品表现出色，其中 mAP 和 Rank1 分别高于最高的 5.9% 和 4.8%。值得一提的是，我们的模型也在传统的城市摄像头上表现竞争力强，特别是人重识别任务。在 ICCV 2021 年举行的 Multi-Modal Video Reasoning and Analyzing Competition 中，我们的解决方案在 UAV 基于人重识别追踪任务上占据了第一名。代码可以在 https://github.com/whucsy/RotTrans 上找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-Agent-3D-Map-Reconstruction-and-Change-Detection-in-Microgravity-with-Free-Flying-Robots"><a href="#Multi-Agent-3D-Map-Reconstruction-and-Change-Detection-in-Microgravity-with-Free-Flying-Robots" class="headerlink" title="Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity with Free-Flying Robots"></a>Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity with Free-Flying Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02558">http://arxiv.org/abs/2311.02558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Holly Dinkel, Julia Di, Jamie Santos, Keenan Albee, Paulo Borges, Marina Moreira, Oleg Alexandrov, Brian Coltin, Trey Smith</li>
<li>for: 这项研究的目的是为未来的宇航空站提供自主的Robot辅助人工维护，例如NASA的Astrobee机器人在国际空站（ISS）上。</li>
<li>methods: 这项研究使用多体协同地图化和变化检测来启用机器人维护空站。一个机器人用图像和相对深度信息重建环境的3D模型，另一个机器人 periodic 扫描环境并与3D模型进行比较。</li>
<li>results: 该研究在ground testing环境和国际空站微重力环境中使用实际的图像和姿态数据验证了变化检测。这项研究还提出了多体协同重建系统的目标、要求和算法模块，并对未来的微重力站使用提供建议。<details>
<summary>Abstract</summary>
Assistive free-flyer robots autonomously caring for future crewed outposts -- such as NASA's Astrobee robots on the International Space Station (ISS) -- must be able to detect day-to-day interior changes to track inventory, detect and diagnose faults, and monitor the outpost status. This work presents a framework for multi-agent cooperative mapping and change detection to enable robotic maintenance of space outposts. One agent is used to reconstruct a 3D model of the environment from sequences of images and corresponding depth information. Another agent is used to periodically scan the environment for inconsistencies against the 3D model. Change detection is validated after completing the surveys using real image and pose data collected by Astrobee robots in a ground testing environment and from microgravity aboard the ISS. This work outlines the objectives, requirements, and algorithmic modules for the multi-agent reconstruction system, including recommendations for its use by assistive free-flyers aboard future microgravity outposts.
</details>
<details>
<summary>摘要</summary>
帮助自由飞行器机器人在未来的人类宇宙站上自动进行维护工作 -- 如NASA的Astrobee机器人在国际空间站（ISS）上 -- 必须能够探测日常内部变化，跟踪存量、检测和诊断问题，并监控宇宙站状况。这项工作提出了多代理合作地图化和变化检测框架，以启用机器人维护宇宙站。一个代理用于从图像序列和相应的深度信息中重建环境的3D模型。另一个代理用于在环境中 периодиicamente检查环境是否异常，并与3D模型进行比较。变化检测被验证了，通过在地面测试环境中收集的真实图像和pose数据，以及来自微重力环境中的ISS上的Astrobee机器人。这项工作详细介绍了多代理重建系统的目标、要求和算法模块，以及对未来微重力宇宙站的使用建议。
</details></li>
</ul>
<hr>
<h2 id="IPVNet-Learning-Implicit-Point-Voxel-Features-for-Open-Surface-3D-Reconstruction"><a href="#IPVNet-Learning-Implicit-Point-Voxel-Features-for-Open-Surface-3D-Reconstruction" class="headerlink" title="IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D Reconstruction"></a>IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02552">http://arxiv.org/abs/2311.02552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Samiul Arshad, William J. Beksi</li>
<li>for: 该论文旨在探讨计算机视觉领域中三维开表（例如非水密的网格）的重建问题，尤其是使用学习基于方法来解决这个问题。</li>
<li>methods: 该论文提出了一种基于学习的点粒子矩阵（IPVNet）模型，该模型可以准确地重建开表面而不引入噪声。IPVNet 使用了原始点云数据和其粒子矩阵对应的抽象数据来预测点与表面之间的距离。</li>
<li>results: 实验表明，IPVNet 可以在实际世界数据集上准确地重建开表面，并且比现有技术更高效，同时生成的重建结果中减少了噪声。<details>
<summary>Abstract</summary>
Reconstruction of 3D open surfaces (e.g., non-watertight meshes) is an underexplored area of computer vision. Recent learning-based implicit techniques have removed previous barriers by enabling reconstruction in arbitrary resolutions. Yet, such approaches often rely on distinguishing between the inside and outside of a surface in order to extract a zero level set when reconstructing the target. In the case of open surfaces, this distinction often leads to artifacts such as the artificial closing of surface gaps. However, real-world data may contain intricate details defined by salient surface gaps. Implicit functions that regress an unsigned distance field have shown promise in reconstructing such open surfaces. Nonetheless, current unsigned implicit methods rely on a discretized representation of the raw data. This not only bounds the learning process to the representation's resolution, but it also introduces outliers in the reconstruction. To enable accurate reconstruction of open surfaces without introducing outliers, we propose a learning-based implicit point-voxel model (IPVNet). IPVNet predicts the unsigned distance between a surface and a query point in 3D space by leveraging both raw point cloud data and its discretized voxel counterpart. Experiments on synthetic and real-world public datasets demonstrates that IPVNet outperforms the state of the art while producing far fewer outliers in the resulting reconstruction.
</details>
<details>
<summary>摘要</summary>
<<SYS>>计算机视觉中三维开放表面重建（例如非透水的网格）是一个未得到充分的研究领域。近年来的学习基于隐式技术已经消除了之前的障碍，使得重建在任意分辨率中成为可能。然而，这些方法 часто需要在重建目标时分辨内部和外部的区别，以提取零值水平面。在开放表面上，这种分辨可能会导致表面 gap 的人工闭合。然而，实际数据可能包含细腻的表面特征，定义了明确的表面 gap。隐式函数，它们回归了一个无符号距离场，已经显示了在开放表面上的重建的搅乱。然而，当前的隐式方法仅仅基于原始数据的粗粒度表示，这不仅限制了学习过程的分辨率，而且也导入了重建中的异常值。为了准确地重建开放表面而不导入异常值，我们提议一种学习基于隐式点VOXEL模型（IPVNet）。IPVNet 预测了一个表面和查询点在三维空间中的无符号距离，通过利用原始点云数据和其粗粒度的VOXEL对应体。实验表明，IPVNet 在 sintetic 和实际公共数据上超过了当前状态的表现，同时生成的重建中异常值远 fewer。
</details></li>
</ul>
<hr>
<h2 id="3D-Aware-Talking-Head-Video-Motion-Transfer"><a href="#3D-Aware-Talking-Head-Video-Motion-Transfer" class="headerlink" title="3D-Aware Talking-Head Video Motion Transfer"></a>3D-Aware Talking-Head Video Motion Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02549">http://arxiv.org/abs/2311.02549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomiao Ni, Jiachen Liu, Yuan Xue, Sharon X. Huang</li>
<li>for: 本研究旨在提出一种基于3D canonical head的人头视频动作传输网络，以全面利用主体视频中的多视图外观特征。</li>
<li>methods: 该方法包括一种自我监督3D头准确学习模块，用于从2D主体视频帧中预测头姿和深度图，以及一种注意力基于的融合网络，用于将背景和其他细节与3D主体头相结合。</li>
<li>results: 对两个公共的人头视频数据集进行了广泛的实验，证明了 Head3D 在实际cross-identity设定下比2D和3D先前艺术高效，并且可以轻松地适应到pose控制新视频生成任务。<details>
<summary>Abstract</summary>
Motion transfer of talking-head videos involves generating a new video with the appearance of a subject video and the motion pattern of a driving video. Current methodologies primarily depend on a limited number of subject images and 2D representations, thereby neglecting to fully utilize the multi-view appearance features inherent in the subject video. In this paper, we propose a novel 3D-aware talking-head video motion transfer network, Head3D, which fully exploits the subject appearance information by generating a visually-interpretable 3D canonical head from the 2D subject frames with a recurrent network. A key component of our approach is a self-supervised 3D head geometry learning module, designed to predict head poses and depth maps from 2D subject video frames. This module facilitates the estimation of a 3D head in canonical space, which can then be transformed to align with driving video frames. Additionally, we employ an attention-based fusion network to combine the background and other details from subject frames with the 3D subject head to produce the synthetic target video. Our extensive experiments on two public talking-head video datasets demonstrate that Head3D outperforms both 2D and 3D prior arts in the practical cross-identity setting, with evidence showing it can be readily adapted to the pose-controllable novel view synthesis task.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>文本：Motion transfer of talking-head videos involves generating a new video with the appearance of a subject video and the motion pattern of a driving video. Current methodologies primarily depend on a limited number of subject images and 2D representations, thereby neglecting to fully utilize the multi-view appearance features inherent in the subject video. In this paper, we propose a novel 3D-aware talking-head video motion transfer network, Head3D, which fully exploits the subject appearance information by generating a visually-interpretable 3D canonical head from the 2D subject frames with a recurrent network. A key component of our approach is a self-supervised 3D head geometry learning module, designed to predict head poses and depth maps from 2D subject video frames. This module facilitates the estimation of a 3D head in canonical space, which can then be transformed to align with driving video frames. Additionally, we employ an attention-based fusion network to combine the background and other details from subject frames with the 3D subject head to produce the synthetic target video. Our extensive experiments on two public talking-head video datasets demonstrate that Head3D outperforms both 2D and 3D prior arts in the practical cross-identity setting, with evidence showing it can be readily adapted to the pose-controllable novel view synthesis task.中文翻译：现象传输的 talking-head 视频中的动作涉及生成一个新的视频，其外观类似于源视频，而动作模式则类似于驱动视频。当前的方法ologies 主要基于有限多个主体图像和2D表示，因此不能充分利用主体视频中的多视点外观特征。在本文中，我们提出了一种新的3D-aware talking-head 视频动作传输网络，即 Head3D，它可以充分利用主体视频中的外观信息，通过生成可视化的3D canonical 头来捕捉主体视频中的多视点外观特征。我们的方法包括一种无监督的3D 头几何学学习模块，可以从2D主体视频帧中预测头姿和深度地图。这个模块可以为3D 主体头在 canonical 空间中估计，然后将其与驱动视频帧进行对齐。此外，我们还使用了注意力基于的融合网络，将主体视频中的背景和其他细节与3D主体头进行融合，以生成合成目标视频。我们对两个公共的 talking-head 视频数据集进行了广泛的实验，结果表明，Head3D 在实际的跨Identify 设定下表现得更好，并且证明可以轻松地适应pose控制的新视野合成任务。
</details></li>
</ul>
<hr>
<h2 id="VR-NeRF-High-Fidelity-Virtualized-Walkable-Spaces"><a href="#VR-NeRF-High-Fidelity-Virtualized-Walkable-Spaces" class="headerlink" title="VR-NeRF: High-Fidelity Virtualized Walkable Spaces"></a>VR-NeRF: High-Fidelity Virtualized Walkable Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02542">http://arxiv.org/abs/2311.02542</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/EyefulTower">https://github.com/facebookresearch/EyefulTower</a></li>
<li>paper_authors: Linning Xu, Vasu Agrawal, William Laney, Tony Garcia, Aayush Bansal, Changil Kim, Samuel Rota Bulò, Lorenzo Porzi, Peter Kontschieder, Aljaž Božič, Dahua Lin, Michael Zollhöfer, Christian Richardt</li>
<li>for: 高精度虚拟现实中的游走空间捕捉、模型重建和实时渲染</li>
<li>methods: 使用神经辐射场来捕捉、重建和实时渲染高精度游走空间，并使用自定义多摄像头策略和高动态范围图像捕捉</li>
<li>results: 实现高精度游走空间的高效渲染，并在多个数据集上达到高水平的图像质量和速度比Here’s a breakdown of each point:</li>
<li>for: The paper is written for the purpose of capturing, modeling, and rendering walkable spaces in virtual reality with high fidelity.</li>
<li>methods: The paper uses neural radiance fields to capture and reconstruct walkable spaces, and employs a custom multi-camera rig and mip-mapping mechanism to achieve high-quality and efficient rendering.</li>
<li>results: The paper achieves high-quality and high-speed rendering of walkable spaces in virtual reality, and demonstrates the effectiveness of its approach on several challenging datasets.<details>
<summary>Abstract</summary>
We present an end-to-end system for the high-fidelity capture, model reconstruction, and real-time rendering of walkable spaces in virtual reality using neural radiance fields. To this end, we designed and built a custom multi-camera rig to densely capture walkable spaces in high fidelity and with multi-view high dynamic range images in unprecedented quality and density. We extend instant neural graphics primitives with a novel perceptual color space for learning accurate HDR appearance, and an efficient mip-mapping mechanism for level-of-detail rendering with anti-aliasing, while carefully optimizing the trade-off between quality and speed. Our multi-GPU renderer enables high-fidelity volume rendering of our neural radiance field model at the full VR resolution of dual 2K$\times$2K at 36 Hz on our custom demo machine. We demonstrate the quality of our results on our challenging high-fidelity datasets, and compare our method and datasets to existing baselines. We release our dataset on our project website.
</details>
<details>
<summary>摘要</summary>
我们提出了一个端到端系统，用于在虚拟现实中高精度捕捉、模型重建和实时渲染行走空间，使用神经辐射场。为此，我们设计制造了一套特制多摄像头架，以高度捕捉行走空间，并在多视图高动态范围图像中实现无 precedent 的质量和密度。我们extend了快速神经图形元素，使用一种新的感知色彩空间来学习准确的HDR外观，并使用高效的mip映射机制来实现级别Of detail 渲染，同时细致地调整质量和速度之间的交互。我们的多GPU渲染器可以在我们自定义的 demo 机器上实现高精度量子渲染我们的神经辐射场模型，并达到 dual 2K x 2K 的全VR分辨率和36Hz 的刷新率。我们在我们的挑战性高精度数据集上展示了我们的结果质量，并与现有的基准进行比较。我们在我们项目网站上发布了我们的数据集。
</details></li>
</ul>
<hr>
<h2 id="Augment-the-Pairs-Semantics-Preserving-Image-Caption-Pair-Augmentation-for-Grounding-Based-Vision-and-Language-Models"><a href="#Augment-the-Pairs-Semantics-Preserving-Image-Caption-Pair-Augmentation-for-Grounding-Based-Vision-and-Language-Models" class="headerlink" title="Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models"></a>Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02536">http://arxiv.org/abs/2311.02536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingru Yi, Burak Uzkent, Oana Ignat, Zili Li, Amanmeet Garg, Xiang Yu, Linda Liu</li>
<li>for: 这个研究旨在提高grounding-based computer vision和自然语言处理中的精确物体识别能力，并且运用数据增强技术来提高模型的表现。</li>
<li>methods: 本研究使用了文本条件和无文本条件的数据增强技术，包括文本调整颜色噪音和水平排列，以保持图像和文本之间的semantic consistency。此外，我们还从masked signal reconstruction中获得了一种新的数据增强方法：像素级干扰。</li>
<li>results: 经过广泛的实验，我们发现使用了这些数据增强方法可以提高grounding-based computer vision和自然语言处理中的表现，并且在三个常用的数据集（Flickr30k、referring expressions和GQA）上表现出色。<details>
<summary>Abstract</summary>
Grounding-based vision and language models have been successfully applied to low-level vision tasks, aiming to precisely locate objects referred in captions. The effectiveness of grounding representation learning heavily relies on the scale of the training dataset. Despite being a useful data enrichment strategy, data augmentation has received minimal attention in existing vision and language tasks as augmentation for image-caption pairs is non-trivial. In this study, we propose a robust phrase grounding model trained with text-conditioned and text-unconditioned data augmentations. Specifically, we apply text-conditioned color jittering and horizontal flipping to ensure semantic consistency between images and captions. To guarantee image-caption correspondence in the training samples, we modify the captions according to pre-defined keywords when applying horizontal flipping. Additionally, inspired by recent masked signal reconstruction, we propose to use pixel-level masking as a novel form of data augmentation. While we demonstrate our data augmentation method with MDETR framework, the proposed approach is applicable to common grounding-based vision and language tasks with other frameworks. Finally, we show that image encoder pretrained on large-scale image and language datasets (such as CLIP) can further improve the results. Through extensive experiments on three commonly applied datasets: Flickr30k, referring expressions and GQA, our method demonstrates advanced performance over the state-of-the-arts with various metrics. Code can be found in https://github.com/amzn/augment-the-pairs-wacv2024.
</details>
<details>
<summary>摘要</summary>
基于地面的视觉语言模型已经成功应用于低级视觉任务，以准确地标注 referred 的对象。 representational learning 的效iveness 强度取决于训练集的 scale。 despite 是一种有用的数据增强策略，数据增强在现有的视觉语言任务中 receiving  minimal attention。在这种研究中，我们提出了一种鲁棒的短语基准模型，通过 text-conditioned 和 text-unconditioned 数据增强来训练。specifically，我们对 image-caption 对应的文本进行文本条件颜色扰动和水平翻转，以保持图像和文本之间的semantic consistency。为确保图像和文本对应，我们在应用水平翻转时对文本进行预定的关键词修改。此外，我们受到最近的干扰信号重建技术的启发，我们提出了像素级别的干扰作为一种新的数据增强方法。我们通过 MDETR 框架进行了实验，但我们的方法可以应用于其他常用的基准-based 视觉语言任务。最后，我们表明了使用 CLIP 大规模图像和语言数据集（如 Flickr30k、referring expressions 和 GQA）进行图像Encoder 预训练可以提高结果。通过对三个常用的数据集进行了广泛的实验，我们的方法达到了与state-of-the-arts 的高级性表现。代码可以在 <https://github.com/amzn/augment-the-pairs-wacv2024> 找到。
</details></li>
</ul>
<hr>
<h2 id="TokenMotion-Motion-Guided-Vision-Transformer-for-Video-Camouflaged-Object-Detection-Via-Learnable-Token-Selection"><a href="#TokenMotion-Motion-Guided-Vision-Transformer-for-Video-Camouflaged-Object-Detection-Via-Learnable-Token-Selection" class="headerlink" title="TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged Object Detection Via Learnable Token Selection"></a>TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged Object Detection Via Learnable Token Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02535">http://arxiv.org/abs/2311.02535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zifan Yu, Erfan Bank Tavakoli, Meida Chen, Suya You, Raghuveer Rao, Sanjeev Agarwal, Fengbo Ren</li>
<li>for: 提高视频掩护物体检测（VCOD）的性能，解决Texture similarities和Camera movement等特殊问题。</li>
<li>methods: 使用transformer-based模型，抽象出动态特征via learnable token selection，提高VCOD性能。</li>
<li>results: 在MoCA-Mask数据集上评估， compared to现有状态的艺术方法，提高12.8%的Weighted F-measure，提高8.4%的S-measure，提高10.7%的Mean IoU。<details>
<summary>Abstract</summary>
The area of Video Camouflaged Object Detection (VCOD) presents unique challenges in the field of computer vision due to texture similarities between target objects and their surroundings, as well as irregular motion patterns caused by both objects and camera movement. In this paper, we introduce TokenMotion (TMNet), which employs a transformer-based model to enhance VCOD by extracting motion-guided features using a learnable token selection. Evaluated on the challenging MoCA-Mask dataset, TMNet achieves state-of-the-art performance in VCOD. It outperforms the existing state-of-the-art method by a 12.8% improvement in weighted F-measure, an 8.4% enhancement in S-measure, and a 10.7% boost in mean IoU. The results demonstrate the benefits of utilizing motion-guided features via learnable token selection within a transformer-based framework to tackle the intricate task of VCOD.
</details>
<details>
<summary>摘要</summary>
领域内部视频掩体物体检测（VCOD）具有独特的挑战，主要是因为目标对象和周围环境的文本相似性，以及对象和摄像头运动所引起的不规则运动模式。在这篇论文中，我们介绍了TokenMotion（TMNet），它利用转换器基本模型来提高VCOD，通过学习批处理选择Token来提取运动导向特征。在挑战性的MoCA-Mask数据集上进行评估，TMNet达到了VCOD领域的状态对标性性能，与现有状态对标方法相比，提高12.8%的权重F值，提高8.4%的S值，提高10.7%的平均 IoU。结果表明通过在转换器基本框架中使用学习批处理选择Token来捕捉运动导向特征，可以有效地解决VCOD中的复杂问题。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.CV_2023_11_05/" data-id="cloojsmga00kyre88eb487y5s" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.AI_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T12:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.AI_2023_11_05/">cs.AI - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Modelling-Cellular-Perturbations-with-the-Sparse-Additive-Mechanism-Shift-Variational-Autoencoder"><a href="#Modelling-Cellular-Perturbations-with-the-Sparse-Additive-Mechanism-Shift-Variational-Autoencoder" class="headerlink" title="Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder"></a>Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02794">http://arxiv.org/abs/2311.02794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/insitro/sams-vae">https://github.com/insitro/sams-vae</a></li>
<li>paper_authors: Michael Bereket, Theofanis Karaletsos</li>
<li>for: 用于机器学习驱动的生物科学发现</li>
<li>methods: 使用Sparse Additive Mechanism Shift Variational Autoencoder（SAMS-VAE）模型，其 combining compositionality, disentanglement, and interpretability for perturbation models</li>
<li>results: SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, and yields interpretable latent structures which correlate strongly to known biological mechanisms.<details>
<summary>Abstract</summary>
Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In order to measure perturbation-specific model-properties, we also introduce a framework for evaluation of perturbation models based on average treatment effects with links to posterior predictive checks. SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, including a combinatorial reasoning task under resource paucity, and yields interpretable latent structures which correlate strongly to known biological mechanisms. Our results suggest SAMS-VAE is an interesting addition to the modeling toolkit for machine learning-driven scientific discovery.
</details>
<details>
<summary>摘要</summary>
生物学中的观测生成模型在最近几年内得到了广泛的关注，例如药物发现中需要模型多种干扰以 caracterize 未知生物机制。我们提议使用含有可 композиitional、解耦和可解释的 SAMS-VAE 模型，以模型受到干扰的样本的离散状态。SAMS-VAE 将受到干扰的样本的离散状态表示为地方离散变量和干扰效应的稀疏全局变量的和。这些全局变量在各个干扰下进行简化，以确定分解的、干扰特有的离散子空间。我们通过对多个任务进行评估，包括基于单元细胞排序数据集的 combinatorial 逻辑任务和资源缺乏时的性能测试，发现 SAMS-VAE 在泛化性和解释性方面比较出色，并且可以获得可解释的离散结构，与生物机制强相关。这些结果表明 SAMS-VAE 是机器学习驱动的科学发现工具箱中的一个有趣添加。
</details></li>
</ul>
<hr>
<h2 id="CausalCite-A-Causal-Formulation-of-Paper-Citations"><a href="#CausalCite-A-Causal-Formulation-of-Paper-Citations" class="headerlink" title="CausalCite: A Causal Formulation of Paper Citations"></a>CausalCite: A Causal Formulation of Paper Citations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02790">http://arxiv.org/abs/2311.02790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishan Kumar, Zhijing Jin, Ehsan Mokhtarian, Siyuan Guo, Yuen Chen, Negar Kiyavash, Mrinmaya Sachan, Bernhard Schoelkopf</li>
<li>for: 本研究旨在提供一种用于评估科学论文影响力的新方法，以填补 tradicional citation count 的缺陷。</li>
<li>methods: 本研究使用了文本嵌入模型（LLMs）来编码每篇论文，然后使用cosine similarity计算出类似样本，最后通过对类似样本的权重平均来Synthesize一个对应的Counterfactual sample。</li>
<li>results: 研究发现，这种新的metric（CausalCite）具有高度与论文影响力相关的相似性，并且在不同的AI子领域中具有稳定性。此外，研究还提供了一些建议，可以帮助未来的研究者更好地使用这种metric来理解论文质量。<details>
<summary>Abstract</summary>
Evaluating the significance of a paper is pivotal yet challenging for the scientific community. While the citation count is the most commonly used proxy for this purpose, they are widely criticized for failing to accurately reflect a paper's true impact. In this work, we propose a causal inference method, TextMatch, which adapts the traditional matching framework to high-dimensional text embeddings. Specifically, we encode each paper using the text embeddings by large language models (LLMs), extract similar samples by cosine similarity, and synthesize a counterfactual sample by the weighted average of similar papers according to their similarity values. We apply the resulting metric, called CausalCite, as a causal formulation of paper citations. We show its effectiveness on various criteria, such as high correlation with paper impact as reported by scientific experts on a previous dataset of 1K papers, (test-of-time) awards for past papers, and its stability across various sub-fields of AI. We also provide a set of findings that can serve as suggested ways for future researchers to use our metric for a better understanding of a paper's quality. Our code and data are at https://github.com/causalNLP/causal-cite.
</details>
<details>
<summary>摘要</summary>
评估科学论文的重要性是科学社区中的核心问题，但是它具有许多挑战。虽然引用数是最常用的代理，但它们被广泛批判为不能准确反映论文的真实影响。在这种工作中，我们提出了一种 causal inference 方法，即 TextMatch，它将传统的匹配框架应用于高维文本嵌入。specifically，我们使用大语言模型（LLM）生成的文本嵌入来编码每篇论文，然后使用cosine similarity提取类似样本，并将类似样本的权重平均值用作Counterfactual sample。我们将这种度量称为 CausalCite，它可以作为论文引用的 causal 表示。我们在不同的标准数据上进行了评估，包括1K篇论文的影响力，以及过去的论文奖励。我们还提供了一些发现，可以帮助未来的研究人员更好地理解论文的质量。我们的代码和数据可以在 https://github.com/causalNLP/causal-cite 上找到。
</details></li>
</ul>
<hr>
<h2 id="Make-a-Donut-Language-Guided-Hierarchical-EMD-Space-Planning-for-Zero-shot-Deformable-Object-Manipulation"><a href="#Make-a-Donut-Language-Guided-Hierarchical-EMD-Space-Planning-for-Zero-shot-Deformable-Object-Manipulation" class="headerlink" title="Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation"></a>Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02787">http://arxiv.org/abs/2311.02787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang You, Bokui Shen, Congyue Deng, Haoran Geng, He Wang, Leonidas Guibas<br>for:这个论文的目的是解决 робо控制中的弹性物体操作问题，提供一种不需要示范的层次规划方法，可以处理复杂的长期任务。methods:这种方法使用大型自然语言模型（LLM）来描述任务的高级、阶段性计划，并提供了工具和子目标的 Python 代码。在每个阶段中，使用杆形描述符（DiffPhysics-P2P）损失函数和地球运动距离（EMD）空间进行预测控制。results:实验结果表明，这种技术在糖体操作中超越了多个标准准则，包括短期和长期任务。更重要的是，这种模型能够具备对新和未经遇的复杂任务的强大泛化能力，无需任何示范。此外，该方法在真实的 робо控制平台上进行了实验验证。<details>
<summary>Abstract</summary>
Deformable object manipulation stands as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the tool and subgoal for a particular stage at our disposal, we present a granular closed-loop model predictive control strategy. This leverages Differentiable Physics with Point-to-Point correspondence (DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied iteratively. Experimental findings affirm that our technique surpasses multiple benchmarks in dough manipulation, spanning both short and long horizons. Remarkably, our model demonstrates robust generalization capabilities to novel and previously unencountered complex tasks without any preliminary demonstrations. We further substantiate our approach with experimental trials on real-world robotic platforms.
</details>
<details>
<summary>摘要</summary>
不需示范的物体操作方法在机器人学中是一个非常吸引人又具有挑战性的问题。之前的技术主要依靠通过示范学习秘密动力学，通常表示为粒子或图像，但是存在一定的限制：获得适合的示范，特别是 для长期任务，可能是难以捕捉的。此外，基于示范的学习可能会限制模型的泛化能力，不能在示范之外的任务上 generalized。在这种工作中，我们介绍了一种不需示范的层次规划方法，可以解决复杂的长期任务。我们使用大型自然语言模型（LLM）来表达高级、阶段性的计划，对应于指定的任务。对于每个阶段，LLM提供了工具的名称以及Python代码来生成中间目标点云。在获得工具和中间目标的情况下，我们提出了精细的闭环预测控制策略。这种策略利用了差分物理学（DiffPhysics）损失在地球迁移距离（EMD）空间中应用iteratively。实验发现，我们的技术超越多个 referential 在馈料处理中，覆盖了短和长期任务。特别是，我们的模型在未经示范的情况下显示了强大的泛化能力，可以处理 novel 和 previously unencountered 复杂任务。我们进一步证明了我们的方法通过实验测试在真实的机器人平台上。
</details></li>
</ul>
<hr>
<h2 id="Towards-Generic-Anomaly-Detection-and-Understanding-Large-scale-Visual-linguistic-Model-GPT-4V-Takes-the-Lead"><a href="#Towards-Generic-Anomaly-Detection-and-Understanding-Large-scale-Visual-linguistic-Model-GPT-4V-Takes-the-Lead" class="headerlink" title="Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead"></a>Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02782">http://arxiv.org/abs/2311.02782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunkang Cao, Xiaohao Xu, Chen Sun, Xiaonan Huang, Weiming Shen</li>
<li>for: 这个研究旨在探讨GPT-4V（一个强大的视觉语言模型）在多元领域、多种资料类型的异常探测 задача中的应用。</li>
<li>methods: 本研究使用GPT-4V模型来解决多元领域、多种资料类型的异常探测 задача，并将不同的类别信息、人工专家知识和参考图像作为提示进行增强。</li>
<li>results: GPT-4V在多元领域、多种资料类型的异常探测任务中表现出色，能够探测和解释全局和细节 semantic pattern，实现精准地区别正常和异常实例。<details>
<summary>Abstract</summary>
Anomaly detection is a crucial task across different domains and data types. However, existing anomaly detection models are often designed for specific domains and modalities. This study explores the use of GPT-4V(ision), a powerful visual-linguistic model, to address anomaly detection tasks in a generic manner. We investigate the application of GPT-4V in multi-modality, multi-domain anomaly detection tasks, including image, video, point cloud, and time series data, across multiple application areas, such as industrial, medical, logical, video, 3D anomaly detection, and localization tasks. To enhance GPT-4V's performance, we incorporate different kinds of additional cues such as class information, human expertise, and reference images as prompts.Based on our experiments, GPT-4V proves to be highly effective in detecting and explaining global and fine-grained semantic patterns in zero/one-shot anomaly detection. This enables accurate differentiation between normal and abnormal instances. Although we conducted extensive evaluations in this study, there is still room for future evaluation to further exploit GPT-4V's generic anomaly detection capacity from different aspects. These include exploring quantitative metrics, expanding evaluation benchmarks, incorporating multi-round interactions, and incorporating human feedback loops. Nevertheless, GPT-4V exhibits promising performance in generic anomaly detection and understanding, thus opening up a new avenue for anomaly detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译成简化中文。<<SYS>> anomaly detection 是不同领域和数据类型的关键任务。然而，现有的异常检测模型frequently 是为特定领域和modalities 设计。这种研究探讨使用 GPT-4V（视力语言模型）来Address anomaly detection 任务的通用方法。我们Investigate GPT-4V 在多modal, multi-domain anomaly detection 任务中的应用，包括图像、视频、点云和时间序列数据，在多个应用领域，如工业、医疗、逻辑、视频、3D异常检测和位置任务。为了提高 GPT-4V 的表现，我们 incorporate 不同类型的附加cue，如类别信息、人类专家和参考图像作为提示。根据我们的实验， GPT-4V 表现出了高效的异常检测和解释 global 和细化 semantic 模式，从而准确地 differentiate 正常和异常实例。虽然我们进行了广泛的评估，但还有更多的可能性 для未来的评估，以更好地利用 GPT-4V 的通用异常检测能力。这些包括探索量化指标、扩展评估标准、 incorporating 多回交互和 incorporating 人类反馈环回。不过， GPT-4V 在通用异常检测和理解方面表现出了扎实的表现，因此开启了一个新的异常检测avenue。
</details></li>
</ul>
<hr>
<h2 id="ChaTA-Towards-an-Intelligent-Question-Answer-Teaching-Assistant-using-Open-Source-LLMs"><a href="#ChaTA-Towards-an-Intelligent-Question-Answer-Teaching-Assistant-using-Open-Source-LLMs" class="headerlink" title="ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs"></a>ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02775">http://arxiv.org/abs/2311.02775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yann Hicke, Anmol Agarwal, Qianou Ma, Paul Denny</li>
<li>for: 这篇论文目的是提出一种可扩展智能问答（QA）解决方案，以保护数据隐私。</li>
<li>methods: 这篇论文使用开源的大语言模型（LLM），并应用了多种技巧，包括回归增强生成（RAG）、监督微调（SFT）和人工反馈学习（RLHF）等。</li>
<li>results: 经过人工评估和自动LLM评估，这些技巧共同提高了答案质量，增加了33%。此外，RAG也被证明是一个有力的添加。这些结果铺垫了开发一个个性化的QA助手的基础，用于在线问答平台。<details>
<summary>Abstract</summary>
To address the challenges of scalable and intelligent question-answering (QA), we introduce an innovative solution that leverages open-source Large Language Models (LLMs) to ensure data privacy. We use models from the LLaMA-2 family and augmentations including retrieval augmented generation (RAG), supervised fine-tuning (SFT), and an alternative to reinforcement learning with human feedback (RLHF). We perform our experiments on a Piazza dataset from an introductory CS course with 10k QA pairs and 1.5k pairs of preferences data and conduct both human evaluations and automatic LLM evaluations on a small subset. We find preliminary evidence that modeling techniques collectively enhance the quality of answers by 33%, and RAG is an impactful addition. This work paves the way for the development of ChaTA, an intelligent QA assistant customizable for courses with an online QA platform.
</details>
<details>
<summary>摘要</summary>
为了解决扩展和智能问答（QA）的挑战，我们提出了一种创新的解决方案，利用开源的大语言模型（LLM）来保障数据隐私。我们使用LLaMA-2家族中的模型，并使用包括检索增强生成（RAG）、监督精度调整（SFT）和人工反馈学习的替代方法（RLHF）等多种技巧。我们在一个 Piazza 数据集上进行了10000个问答对和1500个偏好数据对的实验，并进行了人工评估和自动 LLM 评估。我们发现，这些技巧的集成可以提高答案质量达33%，而RAG 是一个很有影响的添加。这项工作为开发一个智能 QA 助手，用于自动化课程的问答平台创造了道路。
</details></li>
</ul>
<hr>
<h2 id="Rule-Learning-as-Machine-Translation-using-the-Atomic-Knowledge-Bank"><a href="#Rule-Learning-as-Machine-Translation-using-the-Atomic-Knowledge-Bank" class="headerlink" title="Rule Learning as Machine Translation using the Atomic Knowledge Bank"></a>Rule Learning as Machine Translation using the Atomic Knowledge Bank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02765">http://arxiv.org/abs/2311.02765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kristoffer Æsøy, Ana Ozaki</li>
<li>for: 本研究旨在探讨使用 transformers 将自然语言中的规则表达转换为逻辑规则，以便进行可靠和控制的逻辑推理。</li>
<li>methods: 本研究使用 transformers 模型将自然语言中的规则表达转换为逻辑规则，并对 DKET 数据集进行实验。</li>
<li>results: 研究发现，使用 transformers 可以快速和准确地将自然语言中的规则表达转换为逻辑规则，并且可以通过逻辑推理来验证转换结果的正确性。<details>
<summary>Abstract</summary>
Machine learning models, and in particular language models, are being applied to various tasks that require reasoning. While such models are good at capturing patterns their ability to reason in a trustable and controlled manner is frequently questioned. On the other hand, logic-based rule systems allow for controlled inspection and already established verification methods. However it is well-known that creating such systems manually is time-consuming and prone to errors. We explore the capability of transformers to translate sentences expressing rules in natural language into logical rules. We see reasoners as the most reliable tools for performing logical reasoning and focus on translating language into the format expected by such tools. We perform experiments using the DKET dataset from the literature and create a dataset for language to logic translation based on the Atomic knowledge bank.
</details>
<details>
<summary>摘要</summary>
机器学习模型，特别是语言模型，在进行推理任务上表现出色。然而，这些模型在可靠和控制的方式下进行推理能力受到质疑。相比之下，逻辑基于规则的系统具有已有的验证方法和可控的检查方式。然而，手动创建这些系统是时间consuming和容易出错的。我们 investigate transformers 是否可以将自然语言中的规则表达转换为逻辑规则。我们认为逻辑推理工具是最可靠的推理工具，因此我们将着眼于将语言转换为这些工具所期望的格式。我们使用文献中的 DKET 数据集进行实验，并创建基于 Atomic knowledge bank 的语言到逻辑转换数据集。
</details></li>
</ul>
<hr>
<h2 id="Causal-Question-Answering-with-Reinforcement-Learning"><a href="#Causal-Question-Answering-with-Reinforcement-Learning" class="headerlink" title="Causal Question Answering with Reinforcement Learning"></a>Causal Question Answering with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02760">http://arxiv.org/abs/2311.02760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Lukas Blübaum, Stefan Heindorf</li>
<li>for: 本研究旨在回答 causal 问题，使用 CauseNet 大规模 causal 关系数据集。</li>
<li>methods: 我们采用 reinforcement learning 方法， inspirited by recent successful applications of reinforcement learning to knowledge graph tasks。我们引入了 actor-critic 算法，可以在 CauseNet 上搜索答案。</li>
<li>results: 我们的算法可以成功地缩小搜索空间，回答 binary causal 问题，访问 fewer than 30 nodes per question，比 naive breadth-first search 更高效。我们的ablation study表明，我们的supervised learning strategy提供了强的基础，我们的 reinforcement learning agent 可以进一步提高。我们的 paths 可以解释 cause 如何产生 effect，并且每个 edge 的原始来源可以通过 web 找到，方便验证。<details>
<summary>Abstract</summary>
Causal questions inquire about causal relationships between different events or phenomena. Specifically, they often aim to determine whether there is a relationship between two phenomena, or to identify all causes/effects of a phenomenon. Causal questions are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with CauseNet, a large-scale dataset of causal relations and their provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on CauseNet for causal question answering. We introduce an Actor-Critic based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sparse rewards. Our evaluation shows that the agent successfully prunes the search space to answer binary causal questions by visiting less than 30 nodes per question compared to over 3,000 nodes by a naive breadth-first search. Our ablation study indicates that our supervised learning strategy provides a strong foundation upon which our reinforcement learning agent improves. The paths returned by our agent explain the mechanisms by which a cause produces an effect. Moreover, for each edge on a path, CauseNet stores its original source on the web allowing for easy verification of paths.
</details>
<details>
<summary>摘要</summary>
causal 问题探讨了不同事件或现象之间的 causal 关系。特别是，它们通常想要确定两个现象之间是否存在关系，或者Identify 所有的 cause 和 effect 的现象。 causal 问题是许多用例中重要的，包括虚拟助手和搜索引擎。然而，许多当前的approach to causal question answering 无法提供解释或证据。因此，在这篇论文中，我们使用 CauseNet，一个大规模的 causal 关系和其证据数据集，回答 causal 问题。我们通过 reinforcement learning 在 CauseNet 上应用，并 introduce 一个 Actor-Critic 基于的搜索 Agent，可以在图像上搜索 causal 问题的答案。我们使用一种supervised learning 过程来处理大型动作空间和稀缺奖励。我们的评估表明，我们的 Agent 可以成功地缩减搜索空间，回答 binary causal 问题，只需访问 fewer than 30 个节点，而不是 naive breadth-first search 的over 3,000 个节点。我们的 ablation study 表明，我们的 supervised learning 策略提供了一个强大的基础，于我们的 reinforcement learning Agent 进行改进。Agent 返回的路径解释了 cause 如何产生 effect。此外，每个边在路径上，CauseNet 都存储了其原始来源在网上，使得 paths 的验证变得容易。
</details></li>
</ul>
<hr>
<h2 id="Learning-Independently-from-Causality-in-Multi-Agent-Environments"><a href="#Learning-Independently-from-Causality-in-Multi-Agent-Environments" class="headerlink" title="Learning Independently from Causality in Multi-Agent Environments"></a>Learning Independently from Causality in Multi-Agent Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02741">http://arxiv.org/abs/2311.02741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Pina, Varuna De Silva, Corentin Artaud</li>
<li>for: 这 paper 的目的是investigating the lazy agent pathology in MARL from a causality-based perspective.</li>
<li>methods: 这 paper 使用了一种完全分布式 MARL 设置，并使用 causality 来连接 MARL 和 causality 两个领域。</li>
<li>results: 实验结果表明，在这种设置下，每个agent 的个人观察和团队奖励之间存在 causal 关系，可以用于提高 MARL 团队的表现和个体智能行为。<details>
<summary>Abstract</summary>
Multi-Agent Reinforcement Learning (MARL) comprises an area of growing interest in the field of machine learning. Despite notable advances, there are still problems that require investigation. The lazy agent pathology is a famous problem in MARL that denotes the event when some of the agents in a MARL team do not contribute to the common goal, letting the teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to create the bridge between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralised MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried show how this relation can be used to improve independent agents in MARL, resulting not only on better performances as a team but also on the rise of more intelligent behaviours on individual agents.
</details>
<details>
<summary>摘要</summary>
多智能探索学习（MARL）是机器学习领域的一个快速发展领域。 despite notable advances, there are still many problems that need to be explored. The lazy agent pathology is a famous problem in MARL that refers to the situation where some agents in a MARL team do not contribute to the common goal, letting their teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to establish a connection between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralized MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried out show how this relation can be used to improve independent agents in MARL, resulting not only in better team performances but also in the rise of more intelligent behaviors on individual agents.Here's the translation in Traditional Chinese:多智能探索学习（MARL）是机器学习领域的一个快速发展领域。 despite notable advances, there are still many problems that need to be explored. The lazy agent pathology is a famous problem in MARL that refers to the situation where some agents in a MARL team do not contribute to the common goal, letting their teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to establish a connection between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralized MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried out show how this relation can be used to improve independent agents in MARL, resulting not only in better team performances but also in the rise of more intelligent behaviors on individual agents.
</details></li>
</ul>
<hr>
<h2 id="AV-Lip-Sync-Leveraging-AV-HuBERT-to-Exploit-Multimodal-Inconsistency-for-Video-Deepfake-Detection"><a href="#AV-Lip-Sync-Leveraging-AV-HuBERT-to-Exploit-Multimodal-Inconsistency-for-Video-Deepfake-Detection" class="headerlink" title="AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection"></a>AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02733">http://arxiv.org/abs/2311.02733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahibzada Adil Shahzad, Ammarah Hashmi, Yan-Tsung Peng, Yu Tsao, Hsin-Min Wang</li>
<li>for: 防止伪造 multimedia 内容的传播，提高伪造检测的效率。</li>
<li>methods: 使用多模式自我监督学习（SSL）特征提取器，利用视觉和音频两个模式之间的不一致来检测多模式影片伪造。</li>
<li>results: 在 FakeAVCeleb 和 DeepfakeTIMIT 数据集上取得新的顶尖性能，较前一代模型好。<details>
<summary>Abstract</summary>
Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multi-modal models that can exploit both pieces of information simultaneously. Previous methods mainly adopt uni-modal video forensics and use supervised pre-training for forgery detection. This study proposes a new method based on a multi-modal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multi-modal video forgery detection. We use the transformer-based SSL pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multi-scale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.
</details>
<details>
<summary>摘要</summary>
多Modal manipulations (也称为 audio-visual deepfakes) 使得单模态 deepfake 检测器困难于检测多媒体内容中的伪造。为避免伪造信息和 fake news 的流传，实时检测是关键。过去的方法主要采用单模态视频科学和有supervised预训练进行伪造检测。本研究提出了基于多模态自适应学（SSL）特征提取器的新方法，通过视觉和听音模式之间的不一致来检测多模态视频伪造。我们使用 transformer 基于 SSL 预训练 Audio-Visual HuBERT（AV-HuBERT）模型作为视觉和听音特征提取器，并使用多尺度时间卷积神经网络来捕捉听音和视觉模式之间的时间相关性。由于 AV-HuBERT 只提取视觉特征自舌部，我们还采用另一个 transformer 基于视频模型，以便利用人脸特征并捕捉在深度伪造生成过程中的空间和时间异常。实验结果显示，我们的模型在 FakeAVCeleb 和 DeepfakeTIMIT 数据集上的性能突破所有现有模型，实现了新的状态纪录。
</details></li>
</ul>
<hr>
<h2 id="Extraction-of-Atypical-Aspects-from-Customer-Reviews-Datasets-and-Experiments-with-Language-Models"><a href="#Extraction-of-Atypical-Aspects-from-Customer-Reviews-Datasets-and-Experiments-with-Language-Models" class="headerlink" title="Extraction of Atypical Aspects from Customer Reviews: Datasets and Experiments with Language Models"></a>Extraction of Atypical Aspects from Customer Reviews: Datasets and Experiments with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02702">http://arxiv.org/abs/2311.02702</a></li>
<li>repo_url: None</li>
<li>paper_authors: Smita Nannaware, Erfan Al-Hossami, Razvan Bunescu</li>
<li>for: 这篇论文旨在检测顾客评论中的不寻常元素，以便通过提取这些元素来提高用户满意度。</li>
<li>methods: 该论文使用了人工标注的 benchmark 数据集，并对多种语言模型进行了评估，包括 Flan-T5 的 fine-tuning 和 GPT-3.5 的零aser 和几个shot 提示。</li>
<li>results: 研究发现，通过检测顾客评论中的不寻常元素，可以提高用户满意度，并且可以使用不同的语言模型来提取这些元素。<details>
<summary>Abstract</summary>
A restaurant dinner may become a memorable experience due to an unexpected aspect enjoyed by the customer, such as an origami-making station in the waiting area. If aspects that are atypical for a restaurant experience were known in advance, they could be leveraged to make recommendations that have the potential to engender serendipitous experiences, further increasing user satisfaction. Although relatively rare, whenever encountered, atypical aspects often end up being mentioned in reviews due to their memorable quality. Correspondingly, in this paper we introduce the task of detecting atypical aspects in customer reviews. To facilitate the development of extraction models, we manually annotate benchmark datasets of reviews in three domains - restaurants, hotels, and hair salons, which we use to evaluate a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and few-shot prompting of GPT-3.5.
</details>
<details>
<summary>摘要</summary>
餐厅的晚餐可能会变成一个记忆深刻的经历，因为客户感到了一些不寻常的方面，例如餐厅的等待区域内的 Origami 制作站。如果在先知道这些不寻常的方面，那么可以利用这些方面来制定建议，以提高用户满意度。虽然这些不寻常的方面相对较罕见，但当遇到时，它们通常会在评论中被提及，因为它们具有记忆的质量。在这篇论文中，我们提出了检测客户评论中的不寻常方面的任务。为了促进模型开发，我们手动标注了多个领域的客户评论数据集，包括餐厅、酒店和美容院。我们使用这些数据集来评估多种语言模型，包括修改基于 Flan-T5 的文本到文本转换器，以及 zero-shot 和 few-shot 的 GPT-3.5 的提示。
</details></li>
</ul>
<hr>
<h2 id="Architecture-Matters-Uncovering-Implicit-Mechanisms-in-Graph-Contrastive-Learning"><a href="#Architecture-Matters-Uncovering-Implicit-Mechanisms-in-Graph-Contrastive-Learning" class="headerlink" title="Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning"></a>Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02687">http://arxiv.org/abs/2311.02687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojun Guo, Yifei Wang, Zeming Wei, Yisen Wang</li>
<li>for: This paper focuses on the application of contrastive learning to the graph domain, and investigates the unique properties of graph contrastive learning (GCL) methods.</li>
<li>methods: The paper systematically studies various GCL methods and observes that they differ from traditional VCL methods in several ways, including the lack of positive samples and the lesser influence of data augmentations.</li>
<li>results: The paper provides theoretical insights into the properties of GCL and advocates for more attention to the unique architecture of graph learning when designing GCL methods. The authors also provide code for their experiments at <a target="_blank" rel="noopener" href="https://github.com/PKU-ML/ArchitectureMattersGCL">https://github.com/PKU-ML/ArchitectureMattersGCL</a>.<details>
<summary>Abstract</summary>
With the prosperity of contrastive learning for visual representation learning (VCL), it is also adapted to the graph domain and yields promising performance. However, through a systematic study of various graph contrastive learning (GCL) methods, we observe that some common phenomena among existing GCL methods that are quite different from the original VCL methods, including 1) positive samples are not a must for GCL; 2) negative samples are not necessary for graph classification, neither for node classification when adopting specific normalization modules; 3) data augmentations have much less influence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian noise) can also attain fairly good performance. By uncovering how the implicit inductive bias of GNNs works in contrastive learning, we theoretically provide insights into the above intriguing properties of GCL. Rather than directly porting existing VCL methods to GCL, we advocate for more attention toward the unique architecture of graph learning and consider its implicit influence when designing GCL methods. Code is available at https: //github.com/PKU-ML/ArchitectureMattersGCL.
</details>
<details>
<summary>摘要</summary>
随着视觉对偶学习（VCL）的繁荣，它也被应用于图像领域并显示出了出色的性能。然而，我们通过系统性的研究多种图像对偶学习（GCL）方法时，发现了一些与原始VCL方法不同的现象，包括：1）对GCL来说，正样本并不是必须的；2）对于图像分类和节点分类，不需要负样本；3）对GCL来说，数据增强的影响相对较小，简单的静态域无关增强（例如，高斯噪声）也可以获得良好的性能。我们通过探究图NN的隐式概念偏见在对偶学习中如何工作，从理论角度提供了对上述怪异性质的解释。而不是直接将现有VCL方法port到GCL，我们建议更多关注于图学习的独特架构和其隐式的影响，并在设计GCL方法时给予这些因素更多的注意。代码可以在https: //github.com/PKU-ML/ArchitectureMattersGCL中找到。
</details></li>
</ul>
<hr>
<h2 id="Compute-at-Scale-–-A-Broad-Investigation-into-the-Data-Center-Industry"><a href="#Compute-at-Scale-–-A-Broad-Investigation-into-the-Data-Center-Industry" class="headerlink" title="Compute at Scale – A Broad Investigation into the Data Center Industry"></a>Compute at Scale – A Broad Investigation into the Data Center Industry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02651">http://arxiv.org/abs/2311.02651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/contentone3/guruhr">https://github.com/contentone3/guruhr</a></li>
<li>paper_authors: Konstantin Pilz, Lennart Heim</li>
<li>for: 这篇论文主要描述了数据中心业务和人工智能发展中的重要性。</li>
<li>methods: 该论文使用了各种数据center的特点和行业趋势来描述数据中心的重要性。</li>
<li>results: 论文预计到2025年，全球数据中心市场将达到约2500亿美元，而大规模的数据中心将占据约500个。<details>
<summary>Abstract</summary>
This report characterizes the data center industry and its importance for AI development. Data centers are industrial facilities that efficiently provide compute at scale and thus constitute the engine rooms of today's digital economy. As large-scale AI training and inference become increasingly computationally expensive, they are dominantly executed from this designated infrastructure. Key features of data centers include large-scale compute clusters that require extensive cooling and consume large amounts of power, the need for fast connectivity both within the data center and to the internet, and an emphasis on security and reliability. The global industry is valued at approximately $250B and is expected to double over the next seven years. There are likely about 500 large (above 10 MW) data centers globally, with the US, Europe, and China constituting the most important markets. The report further covers important actors, business models, main inputs, and typical locations of data centers.
</details>
<details>
<summary>摘要</summary>
这份报告描述了数据中心业和其对人工智能发展的重要性。数据中心是一种大规模计算提供的工业设施，它们是当今数字经济的引擎舱。随着大规模人工智能训练和推理变得越来越计算昂贵，它们主要在这些指定的基础设施上进行执行。数据中心的主要特点包括大规模计算集群，需要广泛的冷却和大量的电力，快速内部和互联网连接，以及安全性和可靠性的强调。全球业务额约2500亿美元，预计在下一个七年内将double。全球可能有约500个大于10MW的数据中心，美国、欧洲和中国是最重要的市场。报告还覆盖了数据中心的主要投资者、商业模式、主要输入和常见位置。
</details></li>
</ul>
<hr>
<h2 id="New-Approach-for-an-Affective-Computing-Driven-Quality-of-Experience-QoE-Prediction"><a href="#New-Approach-for-an-Affective-Computing-Driven-Quality-of-Experience-QoE-Prediction" class="headerlink" title="New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction"></a>New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02647">http://arxiv.org/abs/2311.02647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Bègue, Mohamed Aymen Labiod, Abdelhamid Melloulk</li>
<li>for: 这篇论文的主要目的是提出一种基于情感计算的Quality of Experience（QoE）预测模型，以便在多媒体QoE评估上进行自动识别。</li>
<li>methods: 该论文使用了多通道电enzephalogram（EEG）信息进行自动情感识别，并使用了三秒观察窗口计算差异 entropy和功率spectral density。这两个特征被用来训练多个深度学习模型，以便 investigate 是否可以通过五个因素来预测QoE。</li>
<li>results: 该论文使用了一个公共可用的 dataset，并使用了多个深度学习模型进行比较。最好的模型是 LSTM 模型，其中 F1 分数从 68% 到 78%。分析模型和其特征表明，Delta 频率带是最不必要的，两个电极有更高的重要性，两个电极有很低的影响。<details>
<summary>Abstract</summary>
In human interactions, emotion recognition is crucial. For this reason, the topic of computer-vision approaches for automatic emotion recognition is currently being extensively researched. Processing multi-channel electroencephalogram (EEG) information is one of the most researched methods for automatic emotion recognition. This paper presents a new model for an affective computing-driven Quality of Experience (QoE) prediction. In order to validate the proposed model, a publicly available dataset is used. The dataset contains EEG, ECG, and respiratory data and is focused on a multimedia QoE assessment context. The EEG data are retained on which the differential entropy and the power spectral density are calculated with an observation window of three seconds. These two features were extracted to train several deep-learning models to investigate the possibility of predicting QoE with five different factors. The performance of these models is compared, and the best model is optimized to improve the results. The best results were obtained with an LSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the model and its features shows that the Delta frequency band is the least necessary, that two electrodes have a higher importance, and that two other electrodes have a very low impact on the model's performances.
</details>
<details>
<summary>摘要</summary>
人类互动中，情感认知是非常重要。因此，计算机视觉方法自动情感认知的研究在当前得到了广泛的关注。在本文中，我们提出了一种基于情感计算的Quality of Experience（QoE）预测模型。为验证该模型，我们使用了一个公共可用的数据集。该数据集包括EEG、ECG和呼吸数据，并且是在多媒体QoE评估上下文中收集的。EEG数据上计算了差异熵和功率spectral density，使用观察窗口为三秒。这两个特征用于训练多个深度学习模型，以 investigate可能性Predict QoE with five different factors。对这些模型的性能进行比较，并优化最佳模型以提高结果。最佳结果是使用LSTM模型，其F1分数在68%到78%之间。分析模型和其特征显示，Delta频率带是最不必要的，两个电极具有更高的重要性，而两个电极具有很低的影响力。
</details></li>
</ul>
<hr>
<h2 id="PotholeGuard-A-Pothole-Detection-Approach-by-Point-Cloud-Semantic-Segmentation"><a href="#PotholeGuard-A-Pothole-Detection-Approach-by-Point-Cloud-Semantic-Segmentation" class="headerlink" title="PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation"></a>PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02641">http://arxiv.org/abs/2311.02641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Nawale, Dhruv Khut, Daksh Dave, Gauransh Sawhney, Pushkar Aggrawal, Dr. Kailas Devadakar</li>
<li>For: 这个研究旨在提供一个高精度的3D穿孔标注方法，以提高道路维护和安全性。* Methods: 本研究使用了一个创新的点云组合架构，能够高效地捕捉点云中的隐藏特征，并使用反馈机制来强化本地特征表现。此外，本研究还引入了一个地方关系学习模组，以更好地理解点云中的结构关系。* Results: 实验结果显示， compared to existing state-of-the-art methods, PotholeGuard 能够提供更高的精度和准确性 для 3D穿孔标注。<details>
<summary>Abstract</summary>
Pothole detection is crucial for road safety and maintenance, traditionally relying on 2D image segmentation. However, existing 3D Semantic Pothole Segmentation research often overlooks point cloud sparsity, leading to suboptimal local feature capture and segmentation accuracy. Our research presents an innovative point cloud-based pothole segmentation architecture. Our model efficiently identifies hidden features and uses a feedback mechanism to enhance local characteristics, improving feature presentation. We introduce a local relationship learning module to understand local shape relationships, enhancing structural insights. Additionally, we propose a lightweight adaptive structure for refining local point features using the K nearest neighbor algorithm, addressing point cloud density differences and domain selection. Shared MLP Pooling is integrated to learn deep aggregation features, facilitating semantic data exploration and segmentation guidance. Extensive experiments on three public datasets confirm PotholeGuard's superior performance over state-of-the-art methods. Our approach offers a promising solution for robust and accurate 3D pothole segmentation, with applications in road maintenance and safety.
</details>
<details>
<summary>摘要</summary>
沟纹检测对道路安全和维护非常重要，传统上靠二维图像分割。然而，现有的3D semantic pothole segmentation研究经常忽略点云稀疏性，导致本地特征捕捉和分割精度下降。我们的研究提出了一种创新的点云基于的沟纹分割架构。我们的模型高效地找到隐藏的特征，并使用反馈机制提高本地特征表现。我们引入了本地关系学习模块，理解本地形态关系，提高结构性视角。此外，我们提议了一种轻量级适应结构，通过K nearest neighbor算法来修正本地点 cloud特征，解决点云密度差异和领域选择问题。我们共享的多层感知搜索（MLP Pooling）被集成到学习深度聚合特征，促进 semantic数据探索和分割指导。广泛的实验证明了PotholeGuard的超过状态艺术方法的性能。我们的方法提供了一种强大和准确的3D沟纹分割方案，应用于道路维护和安全。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-Promise-and-Pitfalls-of-ChatGPT-for-Automated-Code-Generation"><a href="#Assessing-the-Promise-and-Pitfalls-of-ChatGPT-for-Automated-Code-Generation" class="headerlink" title="Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation"></a>Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02640">http://arxiv.org/abs/2311.02640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mfawadakbar/ChatGPT-promises-and-pitfalls">https://github.com/mfawadakbar/ChatGPT-promises-and-pitfalls</a></li>
<li>paper_authors: Muhammad Fawad Akbar Khan, Max Ramsdell, Erik Falor, Hamid Karimi</li>
<li>For: This paper evaluates the code generation capabilities of ChatGPT, a large language model, and compares them to human programmers.* Methods: The paper uses a novel dataset of code-generation prompts and manual assessment methodology to evaluate correctness, comprehensibility, and security of code generated by ChatGPT and human programmers.* Results: The paper finds that ChatGPT excels in crafting concise and efficient code, particularly in data analysis tasks, but struggles with visual-graphical challenges. It also shows that machine learning models can distinguish ChatGPT code from human code with up to 88% accuracy. The study provides valuable insights into the strengths and limitations of ChatGPT’s code generation capabilities and offers a robust foundation for future research.Here is the same information in Simplified Chinese text:* For: 这篇论文评估了 ChatGPT 大型自然语言模型的代码生成能力，并与人工程师进行比较。* Methods: 论文使用了一个新的代码生成提问集和手动评估方法来评估代码的正确性、可读性和安全性，并对 ChatGPT 和人工程师生成的代码进行比较。* Results: 论文发现 ChatGPT 在数据分析任务上表现出色，能够生成高效和简洁的代码，但在视觉图形挑战中存在限制。它还发现机器学习模型可以准确地 distinguishing ChatGPT 代码和人工程师代码之间的 coding style 差异。该研究为 AI 基于编程助手的发展提供了有价值的贡献，并提供了一个可靠的基础 для未来的研究。所有数据和代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls%E3%80%82">https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls。</a><details>
<summary>Abstract</summary>
This paper presents a comprehensive evaluation of the code generation capabilities of ChatGPT, a prominent large language model, compared to human programmers. A novel dataset of 131 code-generation prompts across 5 categories was curated to enable robust analysis. Code solutions were generated by both ChatGPT and humans for all prompts, resulting in 262 code samples. A meticulous manual assessment methodology prioritized evaluating correctness, comprehensibility, and security using 14 established code quality metrics. The key findings reveal ChatGPT's strengths in crafting concise, efficient code with advanced constructs, showcasing strengths in data analysis tasks (93.1% accuracy) but limitations in visual-graphical challenges. Comparative analysis with human code highlights ChatGPT's inclination towards modular design and superior error handling. Additionally, machine learning models effectively distinguished ChatGPT from human code with up to 88% accuracy, suggesting detectable coding style disparities. By providing profound insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis, this study makes valuable contributions toward advancing AI-based programming assistants. The curated dataset and methodology offer a robust foundation for future research in this nascent domain. All data and codes are available on https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls.
</details>
<details>
<summary>摘要</summary>
The key findings show that ChatGPT excels in crafting concise and efficient code with advanced constructs, particularly in data analysis tasks (93.1% accuracy). However, it struggles with visual-graphical challenges. Comparing ChatGPT's code to human code reveals that ChatGPT tends towards modular design and superior error handling. Additionally, machine learning models can accurately distinguish ChatGPT's code from human code (up to 88% accuracy), indicating detectable differences in coding style.This study provides valuable insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis. The curated dataset and methodology offer a solid foundation for future research in this emerging field. All data and codes are available on GitHub: <https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls>.
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Perceptual-Pre-trained-Model-for-Complex-Trajectory-Recovery"><a href="#A-Critical-Perceptual-Pre-trained-Model-for-Complex-Trajectory-Recovery" class="headerlink" title="A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery"></a>A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02631">http://arxiv.org/abs/2311.02631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dedong Li, Ziyue Li, Zhishuai Li, Lei Bai, Qingyuan Gong, Lijun Sun, Wolfgang Ketter, Rui Zhao<br>for: 这个论文的目的是提供一个更加Robust的路径回传方法，以便应对复杂的路径。methods: 本文使用了Sequential Language Models来进行路径回传，并且将道路段表示vector learning到下游任务。results: 试验结果显示，我们的方法可以更好地学习路径回传，具有5.22%更高的F1分数和8.16%更高的F1分数 для复杂的路径。<details>
<summary>Abstract</summary>
The trajectory on the road traffic is commonly collected at a low sampling rate, and trajectory recovery aims to recover a complete and continuous trajectory from the sparse and discrete inputs. Recently, sequential language models have been innovatively adopted for trajectory recovery in a pre-trained manner: it learns road segment representation vectors, which will be used in the downstream tasks. However, existing methods are incapable of handling complex trajectories: when the trajectory crosses remote road segments or makes several turns, which we call critical nodes, the quality of learned representations deteriorates, and the recovered trajectories skip the critical nodes. This work is dedicated to offering a more robust trajectory recovery for complex trajectories. Firstly, we define the trajectory complexity based on the detour score and entropy score and construct the complexity-aware semantic graphs correspondingly. Then, we propose a Multi-view Graph and Complexity Aware Transformer (MGCAT) model to encode these semantics in trajectory pre-training from two aspects: 1) adaptively aggregate the multi-view graph features considering trajectory pattern, and 2) higher attention to critical nodes in a complex trajectory. Such that, our MGCAT is perceptual when handling the critical scenario of complex trajectories. Extensive experiments are conducted on large-scale datasets. The results prove that our method learns better representations for trajectory recovery, with 5.22% higher F1-score overall and 8.16% higher F1-score for complex trajectories particularly. The code is available at https://github.com/bonaldli/ComplexTraj.
</details>
<details>
<summary>摘要</summary>
《路径轨迹数据通常采集在低频率下，路径恢复目标是恢复完整、连续的路径从稀疏和分据输入中。近年来，顺序语言模型在预训练方式下被创新地应用于路径恢复中，它学习了道路段表示向量，这些向量将在下游任务中使用。然而，现有方法无法处理复杂的路径：当路径过 remote 道路段或者多次转弯时，学习的表示质量会降低，恢复的路径会跳过关键节点。这个工作是为了提供更加Robust的路径恢复方法，我们定义了路径复杂度基于折返分数和 entropy 分数，然后构建了相应的复杂度意识图。然后，我们提出了一种多视图图和复杂度意识 transformer（MGCAT）模型，用于在路径预训练中编码这些 semantics。我们的 MGCAT 能够在复杂路径中更加准确地捕捉关键节点，从而提高恢复路径的质量。我们在大规模数据集上进行了广泛的实验，结果表明我们的方法可以更好地学习路径恢复的表示，全局 F1 分数提高 5.22%，特别是在复杂路径上提高 8.16%。代码可以在 <https://github.com/bonaldli/ComplexTraj> 上获取。
</details></li>
</ul>
<hr>
<h2 id="The-New-Frontier-of-Cybersecurity-Emerging-Threats-and-Innovations"><a href="#The-New-Frontier-of-Cybersecurity-Emerging-Threats-and-Innovations" class="headerlink" title="The New Frontier of Cybersecurity: Emerging Threats and Innovations"></a>The New Frontier of Cybersecurity: Emerging Threats and Innovations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02630">http://arxiv.org/abs/2311.02630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Gauransh Sawhney, Pushkar Aggarwal, Nitish Silswal, Dhruv Khut<br>for:这个研究旨在检查当今数字化连接的世界中cybersecurity威胁的多方面性和影响。methods:这个研究采用了质量研究方法，涵盖了多种cybersecurity威胁类型，包括malware攻击、社会工程攻击、网络漏洞和数据泄露攻击。results:研究发现了许多新型的cybersecurity威胁，包括高级 persistent攻击、劫持攻击、IoT漏洞和社会工程攻击。这些威胁对组织和个人都 pose 重大风险，需要采取多层防范措施。<details>
<summary>Abstract</summary>
In today's digitally interconnected world, cybersecurity threats have reached unprecedented levels, presenting a pressing concern for individuals, organizations, and governments. This study employs a qualitative research approach to comprehensively examine the diverse threats of cybersecurity and their impacts across various sectors. Four primary categories of threats are identified and analyzed, encompassing malware attacks, social engineering attacks, network vulnerabilities, and data breaches. The research delves into the consequences of these threats on individuals, organizations, and society at large. The findings reveal a range of key emerging threats in cybersecurity, including advanced persistent threats, ransomware attacks, Internet of Things (IoT) vulnerabilities, and social engineering exploits. Consequently, it is evident that emerging cybersecurity threats pose substantial risks to both organizations and individuals. The sophistication and diversity of these emerging threats necessitate a multi-layered approach to cybersecurity. This approach should include robust security measures, comprehensive employee training, and regular security audits. The implications of these emerging threats are extensive, with potential consequences such as financial loss, reputational damage, and compromised personal information. This study emphasizes the importance of implementing effective measures to mitigate these threats. It highlights the significance of using strong passwords, encryption methods, and regularly updating software to bolster cyber defenses.
</details>
<details>
<summary>摘要</summary>
今天的数字化连接世界中，计算机安全威胁已经到了历史上没有seen的水平，对个人、组织和政府都提出了严重的挑战。本研究采用资深研究方法，全面探讨了不同领域的计算机安全威胁和其影响。研究涵盖了恶意软件攻击、社会工程攻击、网络漏洞和数据泄露等四大类威胁。研究发现，这些威胁对于个人、组织和社会都具有广泛的影响。研究还揭示了一系列新兴计算机安全威胁，包括高级 persistent攻击、勒索软件攻击、物联网（IoT）漏洞和社会工程攻击等。因此，明显地emerging计算机安全威胁对组织和个人都具有极大的风险。这些新兴威胁的复杂性和多样性需要一种多层次的计算机安全方法。这种方法应包括坚固的安全措施、全面的员工培训和 Regular安全审核。这些新兴威胁的后果很广泛，可能包括财务损失、声誉损害和个人信息泄露等。本研究强调实施有效的防御措施，包括使用强密的密码、加密方法和 Regular更新软件等，以加强计算机防御。
</details></li>
</ul>
<hr>
<h2 id="AIOps-Driven-Enhancement-of-Log-Anomaly-Detection-in-Unsupervised-Scenarios"><a href="#AIOps-Driven-Enhancement-of-Log-Anomaly-Detection-in-Unsupervised-Scenarios" class="headerlink" title="AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios"></a>AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02621">http://arxiv.org/abs/2311.02621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Gauransh Sawhney, Dhruv Khut, Sahil Nawale, Pushkar Aggrawal, Prasenjit Bhavathankar</li>
<li>for: 这个研究旨在提高AIOps平台中的记录异常检测，以应对现代和复杂的系统中的记录分析需求。</li>
<li>methods: 本研究提出了一个新的混合方法，具有一个创新的数学方法，整合了原型对应分析（PCA）和人工神经网络（ANNs），并使用自订损失函数以进一步提高记录异常检测的效能。</li>
<li>results: 实验结果表明，提出的方法可以实现重要的降低 Pseudo-Positive 的效果，并且可以处理记录在原始、未处理的形式下进行分析，这具有很大的优点。<details>
<summary>Abstract</summary>
Artificial intelligence operations (AIOps) play a pivotal role in identifying, mitigating, and analyzing anomalous system behaviors and alerts. However, the research landscape in this field remains limited, leaving significant gaps unexplored. This study introduces a novel hybrid framework through an innovative algorithm that incorporates an unsupervised strategy. This strategy integrates Principal Component Analysis (PCA) and Artificial Neural Networks (ANNs) and uses a custom loss function to substantially enhance the effectiveness of log anomaly detection. The proposed approach encompasses the utilization of both simulated and real-world datasets, including logs from SockShop and Hadoop Distributed File System (HDFS). The experimental results are highly promising, demonstrating significant reductions in pseudo-positives. Moreover, this strategy offers notable advantages, such as the ability to process logs in their raw, unprocessed form, and the potential for further enhancements. The successful implementation of this approach showcases a remarkable reduction in anomalous logs, thus unequivocally establishing the efficacy of the proposed methodology. Ultimately, this study makes a substantial contribution to the advancement of log anomaly detection within AIOps platforms, addressing the critical need for effective and efficient log analysis in modern and complex systems.
</details>
<details>
<summary>摘要</summary>
人工智能操作（AIOps）在识别、消除和分析异常系统行为和警报方面扮演着重要的角色。然而，这一研究领域的研究还很有限，留下了许多未探索的空白。本研究提出了一种新的混合方法，通过一种创新的算法，将原始的PCA和人工神经网络（ANNs）精心融合，使用自定义损失函数，以显著提高日志异常检测的效果。该方法利用了实际和模拟的数据集，包括SockShop和Hadoop分布式文件系统（HDFS）的日志。实验结果很吸引人，显示了显著减少 pseudo-positives。此外，该策略还具有许多优点，如能直接处理原始的日志数据，无需进行额外处理。成功实施该方法，表明了该方法的可行性和效果，为AIOps平台中的日志异常检测做出了重要贡献。最终，本研究为现代和复杂的系统中的日志分析做出了重要贡献，为日志异常检测领域的进一步发展提供了新的思路和方法。
</details></li>
</ul>
<hr>
<h2 id="Get-the-Ball-Rolling-Alerting-Autonomous-Robots-When-to-Help-to-Close-the-Healthcare-Loop"><a href="#Get-the-Ball-Rolling-Alerting-Autonomous-Robots-When-to-Help-to-Close-the-Healthcare-Loop" class="headerlink" title="Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop"></a>Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02602">http://arxiv.org/abs/2311.02602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Shen, Yanyao Liu, Ziming Wang, Ziyuan Jiao, Yufeng Chen, Wenjuan Han</li>
<li>for: 为了促进医疗机器人无需人工指令或干预的研究进步，我们介绍了自主帮助挑战，同时收集了大规模的人才来源数据集。目标是创造能够自动确定帮助需要、生成有用子任务、通过物理机器人执行计划、并根据环境反馈生成新任务的医疗机器人。</li>
<li>methods: 本研究使用了自主帮助挑战和大规模人才来源数据集，并提出了Helpy方法来封闭医疗循环的学习无需设置。</li>
<li>results: 研究通过自主帮助挑战和人才来源数据集，对医疗机器人的自动帮助能力进行了评估，并提出了Helpy方法来封闭医疗循环的学习无需设置。<details>
<summary>Abstract</summary>
To facilitate the advancement of research in healthcare robots without human intervention or commands, we introduce the Autonomous Helping Challenge, along with a crowd-sourcing large-scale dataset. The goal is to create healthcare robots that possess the ability to determine when assistance is necessary, generate useful sub-tasks to aid in planning, carry out these plans through a physical robot, and receive feedback from the environment in order to generate new tasks and continue the process. Besides the general challenge in open-ended scenarios, Autonomous Helping focuses on three specific challenges: autonomous task generation, the gap between the current scene and static commonsense, and the gap between language instruction and the real world. Additionally, we propose Helpy, a potential approach to close the healthcare loop in the learning-free setting.
</details>
<details>
<summary>摘要</summary>
为了促进医疗机器人研究的自主发展，我们提出了无需人工指令或干预的自主帮助挑战，同时发布了大规模的人员参与型数据集。目标是创造能够自动确定帮助需要、生成有用的子任务以帮助规划、通过物理机器人执行计划，并从环境接受反馈以生成新任务的医疗机器人。除了通用场景中的总体挑战外，Autonomous Helping还特点在三个方面：自动任务生成、现场和Static Common Sense之间的差距，以及语言指令和实际世界之间的差距。此外，我们提出了一种可能的方法，即Helpy，以关闭医疗循环的学习自由设定。
</details></li>
</ul>
<hr>
<h2 id="Automated-Camera-Calibration-via-Homography-Estimation-with-GNNs"><a href="#Automated-Camera-Calibration-via-Homography-Estimation-with-GNNs" class="headerlink" title="Automated Camera Calibration via Homography Estimation with GNNs"></a>Automated Camera Calibration via Homography Estimation with GNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02598">http://arxiv.org/abs/2311.02598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giacomo D’Amicantonio, Egor Bondarev, Peter H. N. De With</li>
<li>for: 增强路面安全和优化交通条件</li>
<li>methods: 利用图形神经网络学习拓扑结构，自动核实摄像头姿态</li>
<li>results: 提高了实际摄像头姿态估计和抽象摄像头姿态估计的精度，创造了新的状态纪录<details>
<summary>Abstract</summary>
Over the past few decades, a significant rise of camera-based applications for traffic monitoring has occurred. Governments and local administrations are increasingly relying on the data collected from these cameras to enhance road safety and optimize traffic conditions. However, for effective data utilization, it is imperative to ensure accurate and automated calibration of the involved cameras. This paper proposes a novel approach to address this challenge by leveraging the topological structure of intersections. We propose a framework involving the generation of a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighbourhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters. As a result, the proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.
</details>
<details>
<summary>摘要</summary>
The proposed framework involves generating a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighborhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters.The proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.
</details></li>
</ul>
<hr>
<h2 id="FloodBrain-Flood-Disaster-Reporting-by-Web-based-Retrieval-Augmented-Generation-with-an-LLM"><a href="#FloodBrain-Flood-Disaster-Reporting-by-Web-based-Retrieval-Augmented-Generation-with-an-LLM" class="headerlink" title="FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM"></a>FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02597">http://arxiv.org/abs/2311.02597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grace Colverd, Paul Darm, Leonard Silverberg, Noah Kasmanoff</li>
<li>for: 急需快速灾害影响报告，以便规划人道援助。</li>
<li>methods: 利用大型自然语言模型（LLMs）写出整齐的文本，并完成影响报告中的问题回答和文本摘要等任务。</li>
<li>results: 将网络搜寻结果融合，生成详细和准确的洪水灾害影响报告。与人工撰写的报告相比，使用GPT-4作为后门模型时，与人评分得相似的分数。此外，透过对单一管道元件的删除和修改进行了实验，以评估它们的重要性。<details>
<summary>Abstract</summary>
Fast disaster impact reporting is crucial in planning humanitarian assistance. Large Language Models (LLMs) are well known for their ability to write coherent text and fulfill a variety of tasks relevant to impact reporting, such as question answering or text summarization. However, LLMs are constrained by the knowledge within their training data and are prone to generating inaccurate, or "hallucinated", information. To address this, we introduce a sophisticated pipeline embodied in our tool FloodBrain (floodbrain.com), specialized in generating flood disaster impact reports by extracting and curating information from the web. Our pipeline assimilates information from web search results to produce detailed and accurate reports on flood events. We test different LLMs as backbones in our tool and compare their generated reports to human-written reports on different metrics. Similar to other studies, we find a notable correlation between the scores assigned by GPT-4 and the scores given by human evaluators when comparing our generated reports to human-authored ones. Additionally, we conduct an ablation study to test our single pipeline components and their relevancy for the final reports. With our tool, we aim to advance the use of LLMs for disaster impact reporting and reduce the time for coordination of humanitarian efforts in the wake of flood disasters.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:快速灾害影响报告是紧急应急救援计划的重要一环。大型自然语言模型（LLMs）已经被证明能写出整齐的文本和完成许多相关的任务，例如问题回答或文本摘要。但是LLMs受训数据中的知识所限，容易产生错误或"幻想"的信息。为解决这个问题，我们介绍了一个高级的数据pipeline，实现在我们的工具FloodBrain（floodbrain.com）中，专门生成洪水灾害影响报告，从网页搜寻结果中提取和范例信息。我们在不同的LLMs作为后端，与人工撰写的报告进行比较，以不同的 метри来评分。与其他研究一样，我们发现GPT-4的分数和人工评分者的分数之间存在显著的相关性。此外，我们还进行了一个ablation study，测试我们的单一数据ipeline组件的相关性。我们希望通过使用LLMs进行灾害影响报告，减少人道主义救援行动的协调时间，对洪水灾害的回应。
</details></li>
</ul>
<hr>
<h2 id="scBeacon-single-cell-biomarker-extraction-via-identifying-paired-cell-clusters-across-biological-conditions-with-contrastive-siamese-networks"><a href="#scBeacon-single-cell-biomarker-extraction-via-identifying-paired-cell-clusters-across-biological-conditions-with-contrastive-siamese-networks" class="headerlink" title="scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks"></a>scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02594">http://arxiv.org/abs/2311.02594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Liu, Kweon Yong Jin, Jun Ding</li>
<li>for: 这篇论文旨在探讨单元细胞水平的差异基因分析，并提出了一个名为 scBeacon 的新方法来进行这种分析。</li>
<li>methods: scBeacon 使用了一个深度对称双重构造，并且运用了 VQ-VAE 框架、对称双重网络和迅速迭代策略来识别单元细胞中的差异基因。</li>
<li>results: 根据评估结果，scBeacon 比较适合用于单元细胞差异基因分析，并且可以更好地预测单元细胞中的差异基因。<details>
<summary>Abstract</summary>
Despite the breakthroughs in biomarker discovery facilitated by differential gene analysis, challenges remain, particularly at the single-cell level. Traditional methodologies heavily rely on user-supplied cell annotations, focusing on individually expressed data, often neglecting the critical interactions between biological conditions, such as healthy versus diseased states. In response, here we introduce scBeacon, an innovative framework built upon a deep contrastive siamese network. scBeacon pioneers an unsupervised approach, adeptly identifying matched cell populations across varied conditions, enabling a refined differential gene analysis. By utilizing a VQ-VAE framework, a contrastive siamese network, and a greedy iterative strategy, scBeacon effectively pinpoints differential genes that hold potential as key biomarkers. Comprehensive evaluations on a diverse array of datasets validate scBeacon's superiority over existing single-cell differential gene analysis tools. Its precision and adaptability underscore its significant role in enhancing diagnostic accuracy in biomarker discovery. With the emphasis on the importance of biomarkers in diagnosis, scBeacon is positioned to be a pivotal asset in the evolution of personalized medicine and targeted treatments.
</details>
<details>
<summary>摘要</summary>
尽管生物标记发现方面受到了分子生物学分析的突破，但是在单元级别还存在一些挑战，特别是在健康和疾病状态之间的关键互动方面。传统方法强调用户提供的单元级别的细胞标注，宁静地集中在单个数据点上，frequently neglecting the critical interactions between biological conditions。因此，我们介绍了scBeacon，一种创新的框架，基于深度对比性同声纳网络。scBeacon采用了无监督的方法，能够准确地匹配不同状态下的单元级别细胞人口，从而提高了差异基因分析的精度。通过VQ-VAE框架、对比性同声纳网络和迪iks迭代策略，scBeacon能够有效地找到具有潜在生物标记作用的差异基因。对于多种数据集的全面评估表明，scBeacon在单元级别差异基因分析中超过了现有的工具。它的精度和适应性，强调了它在个性化医疗和Targeted treatments中的重要作用。
</details></li>
</ul>
<hr>
<h2 id="KITS-Inductive-Spatio-Temporal-Kriging-with-Increment-Training-Strategy"><a href="#KITS-Inductive-Spatio-Temporal-Kriging-with-Increment-Training-Strategy" class="headerlink" title="KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy"></a>KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02565">http://arxiv.org/abs/2311.02565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianxiong Xu, Cheng Long, Ziyue Li, Sijie Ruan, Rui Zhao, Zhishuai Li</li>
<li>for: This paper is written for the task of spatio-temporal kriging, specifically addressing the issue of graph gap in training and its negative impact on the generalization of learned patterns.</li>
<li>methods: The paper proposes a novel Increment Training Strategy that adds virtual nodes to the training graph, pairs each virtual node with its most similar observed node, and fuses their features together to enhance the supervision signal. The proposed method also constructs reliable pseudo labels for virtual nodes to improve the learning of the model.</li>
<li>results: The paper demonstrates that the proposed Kriging model with Increment Training Strategy (KITS) consistently outperforms existing kriging methods by large margins, with an improvement over Mean Absolute Error (MAE) score as high as 18.33%.<details>
<summary>Abstract</summary>
Sensors are commonly deployed to perceive the environment. However, due to the high cost, sensors are usually sparsely deployed. Kriging is the tailored task to infer the unobserved nodes (without sensors) using the observed source nodes (with sensors). The essence of kriging task is transferability. Recently, several inductive spatio-temporal kriging methods have been proposed based on graph neural networks, being trained based on a graph built on top of observed nodes via pretext tasks such as masking nodes out and reconstructing them. However, the graph in training is inevitably much sparser than the graph in inference that includes all the observed and unobserved nodes. The learned pattern cannot be well generalized for inference, denoted as graph gap. To address this issue, we first present a novel Increment training strategy: instead of masking nodes (and reconstructing them), we add virtual nodes into the training graph so as to mitigate the graph gap issue naturally. Nevertheless, the empty-shell virtual nodes without labels could have bad-learned features and lack supervision signals. To solve these issues, we pair each virtual node with its most similar observed node and fuse their features together; to enhance the supervision signal, we construct reliable pseudo labels for virtual nodes. As a result, the learned pattern of virtual nodes could be safely transferred to real unobserved nodes for reliable kriging. We name our new Kriging model with Increment Training Strategy as KITS. Extensive experiments demonstrate that KITS consistently outperforms existing kriging methods by large margins, e.g., the improvement over MAE score could be as high as 18.33%.
</details>
<details>
<summary>摘要</summary>
感知器通常用于感知环境。然而，由于高价格，感知器通常 sparse 部署。 Kriging 是专门用于推断没有感知器的节点（无感知器节点）的任务。 Kriging 任务的核心思想是传播性。最近，一些基于图神经网络的 inductive spatio-temporal Kriging 方法已经被提出，通过在观察节点基础上建立图来训练。然而，训练图与推断图（包括所有观察和无感知节点）之间存在差异，这导致学习的模式很难在推断中 generalized。为了解决这个问题，我们首先提出了一种新的增量训练策略：而不是将节点屏蔽（并重建它们），我们将虚拟节点添加到训练图中，以减少推断图与训练图之间的差异。然而，虚拟节点的空壳节点没有标签，可能会导致坏学习特征和缺乏监督信号。为解决这些问题，我们对每个虚拟节点 pair 其最相似的观察节点，并将其特征相互融合。此外，为增强监督信号，我们为虚拟节点构建可靠的 pseudo 标签。因此，虚拟节点learned的模式可以安全地传输到实际的无感知节点，以实现可靠的 Kriging。我们称之为 KITS（增量训练策略）。我们的新 Kriging 模型在 extensivel 实验中， consistently 超越现有的 Kriging 方法，例如，对 MAE 分数的改进可以高达 18.33%。
</details></li>
</ul>
<hr>
<h2 id="Time-Series-Synthesis-Using-the-Matrix-Profile-for-Anonymization"><a href="#Time-Series-Synthesis-Using-the-Matrix-Profile-for-Anonymization" class="headerlink" title="Time Series Synthesis Using the Matrix Profile for Anonymization"></a>Time Series Synthesis Using the Matrix Profile for Anonymization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02563">http://arxiv.org/abs/2311.02563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Audrey Der, Chin-Chia Michael Yeh, Yan Zheng, Junpeng Wang, Huiyuan Chen, Zhongfang Zhuang, Liang Wang, Wei Zhang, Eamonn Keogh</li>
<li>for: 本研究旨在解决数据挖掘中隐私规定或商业机密不得公开的问题，提出时序序列合成方法（TSSUMP），可以在原始数据发布的同时保持时序序列相似性信息。</li>
<li>methods: 本研究使用时序序列合成方法（TSSUMP），通过保持矩阵profile相似性信息来减少原始时序序列与合成时序序列之间的相关性。</li>
<li>results: 研究结果表明，使用TSSUMP方法可以在保持时序序列相似性信息的情况下，对原始时序序列进行合成，而无需披露实际数据。在ECG和性别遮盾预测实验中，结果表明，合成时序序列可以保持原始时序序列中的信息，使得未修改的数据挖掘工具可以在合成时序序列上达到近似于原始时序序列的性能。<details>
<summary>Abstract</summary>
Publishing and sharing data is crucial for the data mining community, allowing collaboration and driving open innovation. However, many researchers cannot release their data due to privacy regulations or fear of leaking confidential business information. To alleviate such issues, we propose the Time Series Synthesis Using the Matrix Profile (TSSUMP) method, where synthesized time series can be released in lieu of the original data. The TSSUMP method synthesizes time series by preserving similarity join information (i.e., Matrix Profile) while reducing the correlation between the synthesized and the original time series. As a result, neither the values for the individual time steps nor the local patterns (or shapes) from the original data can be recovered, yet the resulting data can be used for downstream tasks that data analysts are interested in. We concentrate on similarity joins because they are one of the most widely applied time series data mining routines across different data mining tasks. We test our method on a case study of ECG and gender masking prediction. In this case study, the gender information is not only removed from the synthesized time series, but the synthesized time series also preserves enough information from the original time series. As a result, unmodified data mining tools can obtain near-identical performance on the synthesized time series as on the original time series.
</details>
<details>
<summary>摘要</summary>
发布和分享数据对数据挖掘社区至关重要，它帮助研究者们合作并推动开放创新。然而，许多研究者因隐私法规或担心泄露商业机密而无法发布自己的数据。为解决这些问题，我们提出了时间序列合成使用矩阵profile（TSSUMP）方法，其可以将合成的时间序列发布 вместо原始数据。TSSUMP方法将时间序列合成，保持矩阵profile相似性信息，同时减少合成时间序列和原始时间序列之间的相关性。因此，对于个别时间步骤的值和原始时间序列的本地模式（或形状）都无法恢复，但下游任务中的数据分析者可以使用合成的数据进行分析。我们主要关注矩阵相似性 joins，因为它们在不同的数据挖掘任务中广泛应用。我们在 ECG 和性别遮盾预测案例中测试了我们的方法。在这个案例中，合成时间序列中的性别信息不仅被从合成时间序列中除去，还保留了原始时间序列中的 suficient 信息。因此，未修改的数据分析工具可以在合成时间序列上获得 near-identical 性能和原始时间序列上。
</details></li>
</ul>
<hr>
<h2 id="Ego-Network-Transformer-for-Subsequence-Classification-in-Time-Series-Data"><a href="#Ego-Network-Transformer-for-Subsequence-Classification-in-Time-Series-Data" class="headerlink" title="Ego-Network Transformer for Subsequence Classification in Time Series Data"></a>Ego-Network Transformer for Subsequence Classification in Time Series Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02561">http://arxiv.org/abs/2311.02561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chin-Chia Michael Yeh, Huiyuan Chen, Yujie Fan, Xin Dai, Yan Zheng, Vivian Lai, Junpeng Wang, Zhongfang Zhuang, Liang Wang, Wei Zhang, Eamonn Keogh</li>
<li>for: 时间序列标识问题是资料探索领域中广泛研究的问题，以往的研究主要集中在可以提供单一标签的前景下的子序列上。但是，实际世界的时间序列资料经常包含混合在背景下的前景子序列。成功地类别这些有用的子序列需要不仅分辨不同的类别，而且将前景子序列精确地识别出来。</li>
<li>methods: 我们提出了一种新的子序列类别方法，将每个子序列转换为一个自我网络，提供了重要的最近邻信息给模型。所有的子序列的自我网络共同构成一个时间序列子序列图，我们提出了一个有效地建构这个图的算法。</li>
<li>results: 我们对128个单Variate和30个多Variate时间序列资料集进行了实验，结果显示了我们的方法与其他方法相比的优秀性能。具体来说，我们的方法在104个中比基准方法更好。<details>
<summary>Abstract</summary>
Time series classification is a widely studied problem in the field of time series data mining. Previous research has predominantly focused on scenarios where relevant or foreground subsequences have already been extracted, with each subsequence corresponding to a single label. However, real-world time series data often contain foreground subsequences that are intertwined with background subsequences. Successfully classifying these relevant subsequences requires not only distinguishing between different classes but also accurately identifying the foreground subsequences amidst the background. To address this challenge, we propose a novel subsequence classification method that represents each subsequence as an ego-network, providing crucial nearest neighbor information to the model. The ego-networks of all subsequences collectively form a time series subsequence graph, and we introduce an algorithm to efficiently construct this graph. Furthermore, we have demonstrated the significance of enforcing temporal consistency in the prediction of adjacent subsequences for the subsequence classification problem. To evaluate the effectiveness of our approach, we conducted experiments using 128 univariate and 30 multivariate time series datasets. The experimental results demonstrate the superior performance of our method compared to alternative approaches. Specifically, our method outperforms the baseline on 104 out of 158 datasets.
</details>
<details>
<summary>摘要</summary>
时间序列分类是时间序列数据挖掘领域中广泛研究的问题。先前的研究主要集中在已经提取了相关或前景序列的场景下，每个序列均对应一个标签。然而，实际世界中的时间序列数据经常包含相关序列和背景序列杂mix。成功地分类这些相关序列需要不仅分类不同的类别，还需要准确地识别前景序列中的相关序列。为解决这个挑战，我们提出了一种新的序列分类方法，该方法将每个序列表示为一个个人网络，提供关键的最近邻居信息给模型。所有序列的ego-网络集合形成了时间序列 subsequences 图，我们提出了一种高效地构建该图的算法。此外，我们还证明了在预测相邻序列时对 subsequences 分类问题的时间一致性的要求。为评估我们的方法效果，我们使用了128个单变量时间序列数据集和30个多变量时间序列数据集进行实验。实验结果表明，我们的方法与基线方法相比，在104个数据集上表现出色， Specifically, our method outperforms the baseline on 104 out of 158 datasets.
</details></li>
</ul>
<hr>
<h2 id="Nonlinear-Multi-objective-Reinforcement-Learning-with-Provable-Guarantees"><a href="#Nonlinear-Multi-objective-Reinforcement-Learning-with-Provable-Guarantees" class="headerlink" title="Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees"></a>Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02544">http://arxiv.org/abs/2311.02544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nianli Peng, Brandon Fain</li>
<li>For:  solves a single or multi-objective Markov Decision Process (MDP) with nonlinear functions and fairness-aware welfare optimization.* Methods:  uses a reward-aware version of value iteration and an extended form of Bellman optimality for nonlinear optimization.* Results:  learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.Here is the summary in Traditional Chinese:* For: 解决单或多目标Markov Decision Process（MDP）中的非线性函数和公平意识化营运优化问题。* Methods: 使用奖励感知的值追数和扩展的贝尔曼最佳化算法 для非线性优化。* Results:  learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.<details>
<summary>Abstract</summary>
We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm with provable guarantees for solving a single or multi-objective Markov Decision Process (MDP) where we want to maximize the expected value of a nonlinear function over accumulated rewards. This allows us to model fairness-aware welfare optimization for multi-objective reinforcement learning as well as risk-aware reinforcement learning with nonlinear Von Neumann-Morgenstern utility functions in the single objective setting. RA-E3 extends the classic E3 algorithm that solves MDPs with scalar rewards and linear preferences. We first state a distinct reward-aware version of value iteration that calculates a non-stationary policy that is approximately optimal for a given model of the environment. This sub-procedure is based on an extended form of Bellman optimality for nonlinear optimization that explicitly considers time and current accumulated reward. We then describe how to use this optimization procedure in a larger algorithm that must simultaneously learn a model of the environment. The algorithm learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.
</details>
<details>
<summary>摘要</summary>
我们描述了RA-E3（优先奖励明确探索或利用）算法，它具有解释可能性的保证来解决单或多目标Markov决策过程（MDP）中 maximize 预期值函数的问题。这使得我们可以模型公平性感知的发展优化和风险感知的复杂函数学习。RA-E3 是 класи的E3算法的扩展，它可以解决具有数値奖励和线性偏好的 MDP。我们首先说明了一个特有的优先奖励版本的值迭代，它可以获得一个给定环境模型的非站点政策，这个迭代基于延长的贝尔曼优化的非线性优化，它显式地考虑了时间和累绩奖励。然后，我们描述了如何使用这个优化程序在一个更大的算法中，这个算法可以同时学习环境模型。这个算法可以在 MDP 大小、需要的准确度和非线性函数的平滑程度上取得 polynomial 时间的近似最佳策略，并且在数个目标上取得 exponentially 快的时间。
</details></li>
</ul>
<hr>
<h2 id="Dense-Video-Captioning-A-Survey-of-Techniques-Datasets-and-Evaluation-Protocols"><a href="#Dense-Video-Captioning-A-Survey-of-Techniques-Datasets-and-Evaluation-Protocols" class="headerlink" title="Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols"></a>Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02538">http://arxiv.org/abs/2311.02538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iqra Qasim, Alexander Horsch, Dilip K. Prasad</li>
<li>for: 本研究旨在描述视频中的各种事件和交互，以提高自然语言描述视频的能力。</li>
<li>methods: 本研究使用 dense video captioning (DVC) 技术，包括视频特征EXTRACTION (VFE)、时间事件定位 (TEL) 和稠密标题生成 (DCG) 三个子任务。</li>
<li>results: 研究中提出了许多关于 DVC 和其子任务的方法和技术，以及用于评估这些方法的数据集。<details>
<summary>Abstract</summary>
Untrimmed videos have interrelated events, dependencies, context, overlapping events, object-object interactions, domain specificity, and other semantics that are worth highlighting while describing a video in natural language. Owing to such a vast diversity, a single sentence can only correctly describe a portion of the video. Dense Video Captioning (DVC) aims at detecting and describing different events in a given video. The term DVC originated in the 2017 ActivityNet challenge, after which considerable effort has been made to address the challenge. Dense Video Captioning is divided into three sub-tasks: (1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and (3) Dense Caption Generation (DCG). This review aims to discuss all the studies that claim to perform DVC along with its sub-tasks and summarize their results. We also discuss all the datasets that have been used for DVC. Lastly, we highlight some emerging challenges and future trends in the field.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用简化中文表述文本<</SYS>>未处理的视频具有相互关联的事件、依赖关系、上下文、重叠事件、对象之间交互、域特定性和其他 semantics，这些元素值得在描述视频时被注意。由于这种极大的多样性，单个句子只能正确描述视频的一部分。紧凑视频描述（DVC）目标在检测和描述视频中的不同事件。DVC的起源可以追溯到2017年的ActivityNet挑战，自此以后，对挑战的努力已经很大。DVC分为三个子任务：（1）视频特征提取（VFE），（2）时间事件定位（TEL），和（3）紧凑描述生成（DCG）。本文将评论所有声称能够完成DVC和其子任务的研究，并总结其结果。此外，我们还介绍了所有用于DVC的数据集。最后，我们强调了在这个领域出现的一些新挑战和未来趋势。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.AI_2023_11_05/" data-id="cloojsmbs006rre887eahgxvb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/87/">87</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">67</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
