
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.SD_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T15:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.SD_2023_09_21/">cs.SD - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Variational-Quantum-Harmonizer-Generating-Chord-Progressions-and-Other-Sonification-Methods-with-the-VQE-Algorithm"><a href="#Variational-Quantum-Harmonizer-Generating-Chord-Progressions-and-Other-Sonification-Methods-with-the-VQE-Algorithm" class="headerlink" title="Variational Quantum Harmonizer: Generating Chord Progressions and Other Sonification Methods with the VQE Algorithm"></a>Variational Quantum Harmonizer: Generating Chord Progressions and Other Sonification Methods with the VQE Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12254">http://arxiv.org/abs/2309.12254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paulo Vitor Itaboraí, Tim Schwägerl, María Aguado Yáñez, Arianna Crippa, Karl Jansen, Eduardo Reck Miranda, Peter Thomas</li>
<li>for: This paper explores the use of physical-based sonification to visualize and understand the optimization process of Quadratic Unconstrained Binary Optimization (QUBO) problems, which are solved using the Variational Quantum Eigensolver (VQE) algorithm.</li>
<li>methods: The paper uses a musical interface prototype called Variational Quantum Harmonizer (VQH) to sonify the optimization process, which involves using intermediary statevectors to create musical elements such as chords, chord progressions, and arpeggios.</li>
<li>results: The paper demonstrates the potential of using sonification to enhance data visualization and create artistic pieces, and shows how flexible mapping strategies can supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions. Additionally, the paper highlights the relevance of the methodology for artists to gain intuition towards achieving a desired musical sound by carefully designing QUBO cost functions.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文探讨了使用物理基于的听韵来可见化和理解量子计算机解决的Quadratic Unconstrained Binary Optimization (QUBO) 问题的优化过程。</li>
<li>methods: 这篇论文使用了一个名为Variational Quantum Harmonizer (VQH)的乐interface进行听韵，通过使用中间状态向量来创造音乐元素，如和弦、旋律和arpeggios。</li>
<li>results: 这篇论文显示了使用听韵可以增强数据可视化和创作艺术作品，并表明了可变映射策略可以为QUBO和量子听韵作品提供广泛的音色。此外，论文还 highlights了这种方法的创作意义，可以帮助艺术家更好地理解和实现想要的音乐声色。<details>
<summary>Abstract</summary>
This work investigates a case study of using physical-based sonification of Quadratic Unconstrained Binary Optimization (QUBO) problems, optimized by the Variational Quantum Eigensolver (VQE) algorithm. The VQE approximates the solution of the problem by using an iterative loop between the quantum computer and a classical optimization routine. This work explores the intermediary statevectors found in each VQE iteration as the means of sonifying the optimization process itself. The implementation was realised in the form of a musical interface prototype named Variational Quantum Harmonizer (VQH), providing potential design strategies for musical applications, focusing on chords, chord progressions, and arpeggios. The VQH can be used both to enhance data visualization or to create artistic pieces. The methodology is also relevant in terms of how an artist would gain intuition towards achieving a desired musical sound by carefully designing QUBO cost functions. Flexible mapping strategies could supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions, as demonstrated in a case study composition, "Dependent Origination" by Peter Thomas and Paulo Itaborai.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:这项研究探讨了使用物理基于的SONIFICATION方法来解决Quadratic Unconstrained Binary Optimization (QUBO)问题，使用Variational Quantum Eigensolver (VQE)算法进行优化。VQE算法使用了一个迭代循环来实现解决方案，并使用每个VQE迭代的中间状态向量来SONIFICATIONOptimization过程本身。这种实现形式为音乐界面原型Variational Quantum Harmonizer (VQH)，提供了可能的设计策略 для音乐应用，主要关注于和arpeggios。VQH可以用来增强数据视觉或创作艺术作品。此方法也有用于艺术家如何通过设计QUBO成本函数来获得感知到所需的音乐声色的概念。可以采用灵活的映射策略来供应QUBO和量子启发的各种音色，如在case study作品"Dependent Origination" by Peter Thomas和 Paulo Itaborai中所示。
</details></li>
</ul>
<hr>
<h2 id="A-Multiscale-Autoencoder-MSAE-Framework-for-End-to-End-Neural-Network-Speech-Enhancement"><a href="#A-Multiscale-Autoencoder-MSAE-Framework-for-End-to-End-Neural-Network-Speech-Enhancement" class="headerlink" title="A Multiscale Autoencoder (MSAE) Framework for End-to-End Neural Network Speech Enhancement"></a>A Multiscale Autoencoder (MSAE) Framework for End-to-End Neural Network Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12121">http://arxiv.org/abs/2309.12121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bengt J. Borgstrom, Michael S. Brandstein</li>
<li>for: 提高单通道语音增强的性能</li>
<li>methods: 使用mask-basedArchitecture和多尺度自编码器</li>
<li>results: 相比传统方法，提高了对话质量指标和自动语音识别精度<details>
<summary>Abstract</summary>
Neural network approaches to single-channel speech enhancement have received much recent attention. In particular, mask-based architectures have achieved significant performance improvements over conventional methods. This paper proposes a multiscale autoencoder (MSAE) for mask-based end-to-end neural network speech enhancement. The MSAE performs spectral decomposition of an input waveform within separate band-limited branches, each operating with a different rate and scale, to extract a sequence of multiscale embeddings. The proposed framework features intuitive parameterization of the autoencoder, including a flexible spectral band design based on the Constant-Q transform. Additionally, the MSAE is constructed entirely of differentiable operators, allowing it to be implemented within an end-to-end neural network, and be discriminatively trained. The MSAE draws motivation both from recent multiscale network topologies and from traditional multiresolution transforms in speech processing. Experimental results show the MSAE to provide clear performance benefits relative to conventional single-branch autoencoders. Additionally, the proposed framework is shown to outperform a variety of state-of-the-art enhancement systems, both in terms of objective speech quality metrics and automatic speech recognition accuracy.
</details>
<details>
<summary>摘要</summary>
神经网络方法对单通道语音增强 Received much recent attention. In particular, 面积基 architecture has achieved significant performance improvements over conventional methods. This paper proposes a multiscale autoencoder (MSAE) for mask-based end-to-end neural network speech enhancement. The MSAE performs spectral decomposition of an input waveform within separate band-limited branches, each operating with a different rate and scale, to extract a sequence of multiscale embeddings. The proposed framework features intuitive parameterization of the autoencoder, including a flexible spectral band design based on the Constant-Q transform. Additionally, the MSAE is constructed entirely of differentiable operators, allowing it to be implemented within an end-to-end neural network, and be discriminatively trained. The MSAE draws motivation both from recent multiscale network topologies and from traditional multiresolution transforms in speech processing. Experimental results show the MSAE to provide clear performance benefits relative to conventional single-branch autoencoders. Additionally, the proposed framework is shown to outperform a variety of state-of-the-art enhancement systems, both in terms of objective speech quality metrics and automatic speech recognition accuracy.
</details></li>
</ul>
<hr>
<h2 id="Is-the-Ideal-Ratio-Mask-Really-the-Best-–-Exploring-the-Best-Extraction-Performance-and-Optimal-Mask-of-Mask-based-Beamformers"><a href="#Is-the-Ideal-Ratio-Mask-Really-the-Best-–-Exploring-the-Best-Extraction-Performance-and-Optimal-Mask-of-Mask-based-Beamformers" class="headerlink" title="Is the Ideal Ratio Mask Really the Best? – Exploring the Best Extraction Performance and Optimal Mask of Mask-based Beamformers"></a>Is the Ideal Ratio Mask Really the Best? – Exploring the Best Extraction Performance and Optimal Mask of Mask-based Beamformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12065">http://arxiv.org/abs/2309.12065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsuo Hiroe, Katsutoshi Itoyama, Kazuhiro Nakadai</li>
<li>for: 这个研究旨在investigate mask-based beamformers (BFs), which estimate filters to extract target speech using time-frequency masks.</li>
<li>methods: 研究使用四种mask-based BFs：最大信号响应率BF、两种其变体，以及多通道wiener filter（MWF）BF。为每个utterance获取最佳mask，使得BF输出与目标语音之间的平均方差最小。</li>
<li>results: 经过实验 validate that the four BFs have the same peak performance as the ideal MWF BF, but the optimal mask depends on the adopted BF and differs from the IRM. 这些结论与传统的想法不同，即最佳mask是共同的forall BFs，并且每个BF的 peak performance不同。<details>
<summary>Abstract</summary>
This study investigates mask-based beamformers (BFs), which estimate filters to extract target speech using time-frequency masks. Although several BF methods have been proposed, the following aspects are yet to be comprehensively investigated. 1) Which BF can provide the best extraction performance in terms of the closeness of the BF output to the target speech? 2) Is the optimal mask for the best performance common for all BFs? 3) Is the ideal ratio mask (IRM) identical to the optimal mask? Accordingly, we investigate these issues considering four mask-based BFs: the maximum signal-to-noise ratio BF, two variants of this, and the multichannel Wiener filter (MWF) BF. To obtain the optimal mask corresponding to the peak performance for each BF, we employ an approach that minimizes the mean square error between the BF output and target speech for each utterance. Via the experiments with the CHiME-3 dataset, we verify that the four BFs have the same peak performance as the upper bound provided by the ideal MWF BF, whereas the optimal mask depends on the adopted BF and differs from the IRM. These observations differ from the conventional idea that the optimal mask is common for all BFs and that peak performance differs for each BF. Hence, this study contributes to the design of mask-based BFs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Which BF can provide the best extraction performance in terms of the closeness of the BF output to the target speech?2. Is the optimal mask for the best performance common for all BFs?3. Is the ideal ratio mask (IRM) identical to the optimal mask?To answer these questions, we consider four mask-based BFs: the maximum signal-to-noise ratio BF, two variants of this, and the multichannel Wiener filter (MWF) BF. We use an approach to obtain the optimal mask corresponding to the peak performance for each BF by minimizing the mean square error between the BF output and target speech for each utterance.Our experiments with the CHiME-3 dataset show that the four BFs have the same peak performance as the upper bound provided by the ideal MWF BF, but the optimal mask depends on the adopted BF and differs from the IRM. These observations differ from the conventional idea that the optimal mask is common for all BFs and that peak performance differs for each BF. Therefore, this study contributes to the design of mask-based BFs.</details></li>
</ol>
<hr>
<h2 id="Improving-Language-Model-Based-Zero-Shot-Text-to-Speech-Synthesis-with-Multi-Scale-Acoustic-Prompts"><a href="#Improving-Language-Model-Based-Zero-Shot-Text-to-Speech-Synthesis-with-Multi-Scale-Acoustic-Prompts" class="headerlink" title="Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts"></a>Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11977">http://arxiv.org/abs/2309.11977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shun Lei, Yixuan Zhou, Liyang Chen, Dan Luo, Zhiyong Wu, Xixin Wu, Shiyin Kang, Tao Jiang, Yahui Zhou, Yuxing Han, Helen Meng</li>
<li>for: 这个论文旨在提出一个可以复制无见的话者声音的零数据文本读取与Synthesis系统（TTS）。</li>
<li>methods: 这个方法使用了语言模型来模型语音波形的数据几何，并且使用了一个新的话者感知文本编码器来学习个人话语风格。</li>
<li>results: 实验结果显示，该方法可以与基准相比，提高自然性和话者相似性，并且可以通过规模化style prompt来提高表演。<details>
<summary>Abstract</summary>
Zero-shot text-to-speech (TTS) synthesis aims to clone any unseen speaker's voice without adaptation parameters. By quantizing speech waveform into discrete acoustic tokens and modeling these tokens with the language model, recent language model-based TTS models show zero-shot speaker adaptation capabilities with only a 3-second acoustic prompt of an unseen speaker. However, they are limited by the length of the acoustic prompt, which makes it difficult to clone personal speaking style. In this paper, we propose a novel zero-shot TTS model with the multi-scale acoustic prompts based on a neural codec language model VALL-E. A speaker-aware text encoder is proposed to learn the personal speaking style at the phoneme-level from the style prompt consisting of multiple sentences. Following that, a VALL-E based acoustic decoder is utilized to model the timbre from the timbre prompt at the frame-level and generate speech. The experimental results show that our proposed method outperforms baselines in terms of naturalness and speaker similarity, and can achieve better performance by scaling out to a longer style prompt.
</details>
<details>
<summary>摘要</summary>
<<SYS>>zero-shot文本至语音（TTS）合成targets any unseen speaker's voice without adaptation parameters. Byquantizing speech waveform into discrete acoustic tokens and modeling these tokens with the language model, recent language model-based TTS models show zero-shot speaker adaptation capabilities with only a 3-second acoustic prompt of an unseen speaker. However, they are limited by the length of the acoustic prompt, which makes it difficult to clone personal speaking style. In this paper, we propose a novel zero-shot TTS model with the multi-scale acoustic prompts based on a neural codec language model VALL-E. A speaker-aware text encoder is proposed to learn the personal speaking style at the phoneme-level from the style prompt consisting of multiple sentences. Following that, a VALL-E based acoustic decoder is utilized to model the timbre from the timbre prompt at the frame-level and generate speech. The experimental results show that our proposed method outperforms baselines in terms of naturalness and speaker similarity, and can achieve better performance by scaling out to a longer style prompt.<</SYS>>Here's the translation in Traditional Chinese:<<SYS>>zero-shot文本至语音（TTS）合成targets any unseen speaker's voice without adaptation parameters. Byquantizing speech waveform into discrete acoustic tokens and modeling these tokens with the language model, recent language model-based TTS models show zero-shot speaker adaptation capabilities with only a 3-second acoustic prompt of an unseen speaker. However, they are limited by the length of the acoustic prompt, which makes it difficult to clone personal speaking style. In this paper, we propose a novel zero-shot TTS model with the multi-scale acoustic prompts based on a neural codec language model VALL-E. A speaker-aware text encoder is proposed to learn the personal speaking style at the phoneme-level from the style prompt consisting of multiple sentences. Following that, a VALL-E based acoustic decoder is utilized to model the timbre from the timbre prompt at the frame-level and generate speech. The experimental results show that our proposed method outperforms baselines in terms of naturalness and speaker similarity, and can achieve better performance by scaling out to a longer style prompt.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Multi-Channel-MOSRA-Mean-Opinion-Score-and-Room-Acoustics-Estimation-Using-Simulated-Data-and-a-Teacher-Model"><a href="#Multi-Channel-MOSRA-Mean-Opinion-Score-and-Room-Acoustics-Estimation-Using-Simulated-Data-and-a-Teacher-Model" class="headerlink" title="Multi-Channel MOSRA: Mean Opinion Score and Room Acoustics Estimation Using Simulated Data and a Teacher Model"></a>Multi-Channel MOSRA: Mean Opinion Score and Room Acoustics Estimation Using Simulated Data and a Teacher Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11976">http://arxiv.org/abs/2309.11976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jozef Coldenhoff, Andrew Harper, Paul Kendrick, Tijana Stojkovic, Milos Cernak</li>
<li>for: 预测房间听音参数和语音质量指标</li>
<li>methods: 使用多通道模型进行同时预测多个录音设备的房间听音参数和语音质量指标</li>
<li>results: 比单通道模型提高直接听音比率、清晰度和语音传输指标的预测，并且需要约5倍 menos计算资源，但是其他指标的性能减少不大<details>
<summary>Abstract</summary>
Previous methods for predicting room acoustic parameters and speech quality metrics have focused on the single-channel case, where room acoustics and Mean Opinion Score (MOS) are predicted for a single recording device. However, quality-based device selection for rooms with multiple recording devices may benefit from a multi-channel approach where the descriptive metrics are predicted for multiple devices in parallel. Following our hypothesis that a model may benefit from multi-channel training, we develop a multi-channel model for joint MOS and room acoustics prediction (MOSRA) for five channels in parallel. The lack of multi-channel audio data with ground truth labels necessitated the creation of simulated data using an acoustic simulator with room acoustic labels extracted from the generated impulse responses and labels for MOS generated in a student-teacher setup using a wav2vec2-based MOS prediction model. Our experiments show that the multi-channel model improves the prediction of the direct-to-reverberation ratio, clarity, and speech transmission index over the single-channel model with roughly 5$\times$ less computation while suffering minimal losses in the performance of the other metrics.
</details>
<details>
<summary>摘要</summary>
先前的方法只是针对单通道情况进行预测， Room acoustics 和 Mean Opinion Score (MOS) 的预测都是基于单个录音设备。然而，基于质量的设备选择可能会受益于多通道方法，因为模型可能会从多个设备的描述性度量中受益。根据我们的假设，一个模型可能会从多个通道的训练中受益，因此我们开发了一个同时预测 MOS 和 Room acoustics 的多通道模型（MOSRA），对五个通道进行并行预测。由于没有多个渠道的音频数据有ground truth标签，我们使用一个声学模拟器生成了带有房间响应标签的 simulated data，并使用 wav2vec2-based MOS 预测模型生成了 MOS 标签。我们的实验表明，多通道模型在直接响应比、清晰度和语音传输指数方面的预测比单通道模型提高了大约5倍，而且计算量相对减少了大约5倍，而且减少了其他指标的性能。
</details></li>
</ul>
<hr>
<h2 id="Cluster-based-pruning-techniques-for-audio-data"><a href="#Cluster-based-pruning-techniques-for-audio-data" class="headerlink" title="Cluster-based pruning techniques for audio data"></a>Cluster-based pruning techniques for audio data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11922">http://arxiv.org/abs/2309.11922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boris Bergsma, Marta Brzezinska, Oleg V. Yazyev, Milos Cernak</li>
<li>for: 针对 audio 频段数据进行减少计算开销，提高深度学习模型的计算效率。</li>
<li>methods: 使用 k-means 聚合算法对数据进行 clustering 分析，以实现数据减少。</li>
<li>results: 对关键词检测（KWS）数据集进行 clustering 分析，发现可以使用 k-means 聚合算法减少 audio 数据集大小，保持分类性能。同时，通过缩放分析对大量样本进行优化采样，提高计算效率。<details>
<summary>Abstract</summary>
Deep learning models have become widely adopted in various domains, but their performance heavily relies on a vast amount of data. Datasets often contain a large number of irrelevant or redundant samples, which can lead to computational inefficiencies during the training. In this work, we introduce, for the first time in the context of the audio domain, the k-means clustering as a method for efficient data pruning. K-means clustering provides a way to group similar samples together, allowing the reduction of the size of the dataset while preserving its representative characteristics. As an example, we perform clustering analysis on the keyword spotting (KWS) dataset. We discuss how k-means clustering can significantly reduce the size of audio datasets while maintaining the classification performance across neural networks (NNs) with different architectures. We further comment on the role of scaling analysis in identifying the optimal pruning strategies for a large number of samples. Our studies serve as a proof-of-principle, demonstrating the potential of data selection with distance-based clustering algorithms for the audio domain and highlighting promising research avenues.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Impact-of-Silence-on-Speech-Anti-Spoofing"><a href="#The-Impact-of-Silence-on-Speech-Anti-Spoofing" class="headerlink" title="The Impact of Silence on Speech Anti-Spoofing"></a>The Impact of Silence on Speech Anti-Spoofing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11827">http://arxiv.org/abs/2309.11827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Zhang, Zhuo Li, Jingze Lu, Hua Hua, Wenchao Wang, Pengyuan Zhang</li>
<li>for: 这篇论文主要研究了防御诈骗攻击的影响，具体来说是研究了 silence 的影响。</li>
<li>methods: 本论文使用了 Voice Activity Detection (VAD) 技术和 Class Activation Mapping (CAM) Visualization 来分析诈骗攻击的影响。</li>
<li>results: 研究发现，去掉 silence 会使防御诈骗攻击表现下降，并且不同的 waveform generator 生成的 silence 内容和 bonafide speech 内容之间存在差异。此外，通过对 CM 进行重新训练，可以减少诈骗攻击对 CM 的影响。<details>
<summary>Abstract</summary>
The current speech anti-spoofing countermeasures (CMs) show excellent performance on specific datasets. However, removing the silence of test speech through Voice Activity Detection (VAD) can severely degrade performance. In this paper, the impact of silence on speech anti-spoofing is analyzed. First, the reasons for the impact are explored, including the proportion of silence duration and the content of silence. The proportion of silence duration in spoof speech generated by text-to-speech (TTS) algorithms is lower than that in bonafide speech. And the content of silence generated by different waveform generators varies compared to bonafide speech. Then the impact of silence on model prediction is explored. Even after retraining, the spoof speech generated by neural network based end-to-end TTS algorithms suffers a significant rise in error rates when the silence is removed. To demonstrate the reasons for the impact of silence on CMs, the attention distribution of a CM is visualized through class activation mapping (CAM). Furthermore, the implementation and analysis of the experiments masking silence or non-silence demonstrates the significance of the proportion of silence duration for detecting TTS and the importance of silence content for detecting voice conversion (VC). Based on the experimental results, improving the robustness of CMs against unknown spoofing attacks by masking silence is also proposed. Finally, the attacks on anti-spoofing CMs through concatenating silence, and the mitigation of VAD and silence attack through low-pass filtering are introduced.
</details>
<details>
<summary>摘要</summary>
当前的语音反 spoofing 防范措施（CMs）在特定的数据集上表现出非常出色。然而，通过语音活动检测（VAD）移除测试语音中的沉默可能会严重降低性能。在这篇论文中，我们分析了语音反 spoofing 中 silence 的影响。首先，我们研究了 silence 的原因对性能的影响，包括沉默时间的比例和沉默内容。TTS 算法生成的 spoof speech 中的沉默时间比bonafide speech 长，而生成的沉默内容与 bonafide speech 不同。然后，我们研究了 silence 对模型预测的影响。即使重新训练，使用 neural network 基于 end-to-end TTS 算法生成的 spoof speech 在移除沉默后错误率显著增加。为了说明 silence 对 CMs 的影响的原因，我们通过类 activation mapping（CAM）Visualize CM 的注意力分布。此外，我们还实现了在 silence 或非沉默处理下进行实验，以示 silence 的重要性和 non-silence 的重要性。基于实验结果，我们也提出了改进 CMs 对未知 spoofing 攻击的Robustness的方法。最后，我们介绍了 concatenating silence 的攻击和 VAD 和沉默攻击的mitigation 策略。
</details></li>
</ul>
<hr>
<h2 id="Frame-Pairwise-Distance-Loss-for-Weakly-supervised-Sound-Event-Detection"><a href="#Frame-Pairwise-Distance-Loss-for-Weakly-supervised-Sound-Event-Detection" class="headerlink" title="Frame Pairwise Distance Loss for Weakly-supervised Sound Event Detection"></a>Frame Pairwise Distance Loss for Weakly-supervised Sound Event Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11783">http://arxiv.org/abs/2309.11783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Tao, Yuxing Huang, Xiangdong Wang, Long Yan, Lufeng Zhai, Kazushige Ouchi, Taihao Li</li>
<li>for:  bridging the gap between fully supervised methods and unsupervised techniques in various domains</li>
<li>methods:  introducing a Frame Pairwise Distance (FPD) loss branch and synthesized data to enhance the recognition rate of weakly-supervised sound event detection</li>
<li>results:  validated on the standard DCASE dataset, the proposed approach shows efficacy in improving the recognition rate of weakly-supervised sound event detection.Here’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope that helps!<details>
<summary>Abstract</summary>
Weakly-supervised learning has emerged as a promising approach to leverage limited labeled data in various domains by bridging the gap between fully supervised methods and unsupervised techniques. Acquisition of strong annotations for detecting sound events is prohibitively expensive, making weakly supervised learning a more cost-effective and broadly applicable alternative. In order to enhance the recognition rate of the learning of detection of weakly-supervised sound events, we introduce a Frame Pairwise Distance (FPD) loss branch, complemented with a minimal amount of synthesized data. The corresponding sampling and label processing strategies are also proposed. Two distinct distance metrics are employed to evaluate the proposed approach. Finally, the method is validated on the standard DCASE dataset. The obtained experimental results corroborated the efficacy of this approach.
</details>
<details>
<summary>摘要</summary>
微监督学习已经成为各个领域中利用有限的标注数据的可靠方法之一，它在完全监督方法和无监督技术之间填补了空隙。然而，获取听音事件的强制标注是非常昂贵的，使得微监督学习成为更加经济可行的和广泛适用的替代方案。为提高微监督学习检测听音事件的识别率，我们在本文中引入帧对比距离（FPD）损失分支，并采用一小量的合成数据来补充。同时，我们也提出了采样和标签处理策略。两种不同的距离度量被使用来评估该方法。最后，我们在标准的DCASE dataset上验证了该方法的效果。实验结果证明了该方法的可行性。
</details></li>
</ul>
<hr>
<h2 id="CoMFLP-Correlation-Measure-based-Fast-Search-on-ASR-Layer-Pruning"><a href="#CoMFLP-Correlation-Measure-based-Fast-Search-on-ASR-Layer-Pruning" class="headerlink" title="CoMFLP: Correlation Measure based Fast Search on ASR Layer Pruning"></a>CoMFLP: Correlation Measure based Fast Search on ASR Layer Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11768">http://arxiv.org/abs/2309.11768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Liu, Zhiyuan Peng, Tan Lee</li>
<li>for: 提高资源受限设备上Transformer型声音识别（ASR）模型的性能。</li>
<li>methods: 基于相关度度量的快速搜索层剥离（LP）算法，从多层模型中剥离 redundancy。</li>
<li>results: 比前一代LP方法更高效，仅需常量时间复杂度，并且可以提高ASR模型的性能。<details>
<summary>Abstract</summary>
Transformer-based speech recognition (ASR) model with deep layers exhibited significant performance improvement. However, the model is inefficient for deployment on resource-constrained devices. Layer pruning (LP) is a commonly used compression method to remove redundant layers. Previous studies on LP usually identify the redundant layers according to a task-specific evaluation metric. They are time-consuming for models with a large number of layers, even in a greedy search manner. To address this problem, we propose CoMFLP, a fast search LP algorithm based on correlation measure. The correlation between layers is computed to generate a correlation matrix, which identifies the redundancy among layers. The search process is carried out in two steps: (1) coarse search: to determine top $K$ candidates by pruning the most redundant layers based on the correlation matrix; (2) fine search: to select the best pruning proposal among $K$ candidates using a task-specific evaluation metric. Experiments on an ASR task show that the pruning proposal determined by CoMFLP outperforms existing LP methods while only requiring constant time complexity. The code is publicly available at https://github.com/louislau1129/CoMFLP.
</details>
<details>
<summary>摘要</summary>
“ transformer-based  speech recognition（ASR）模型 WITH deep layers  exhibited significant performance improvement. However, the model is inefficient for deployment on resource-constrained devices. layer pruning（LP）is a commonly used compression method to remove redundant layers. Previous studies on LP usually identify the redundant layers according to a task-specific evaluation metric. They are time-consuming for models with a large number of layers, even in a greedy search manner. To address this problem, we propose CoMFLP, a fast search LP algorithm based on correlation measure. The correlation between layers is computed to generate a correlation matrix, which identifies the redundancy among layers. The search process is carried out in two steps: (1) coarse search: to determine top $K$ candidates by pruning the most redundant layers based on the correlation matrix; (2) fine search: to select the best pruning proposal among $K$ candidates using a task-specific evaluation metric. Experiments on an ASR task show that the pruning proposal determined by CoMFLP outperforms existing LP methods while only requiring constant time complexity. The code is publicly available at https://github.com/louislau1129/CoMFLP.”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Sparsely-Shared-LoRA-on-Whisper-for-Child-Speech-Recognition"><a href="#Sparsely-Shared-LoRA-on-Whisper-for-Child-Speech-Recognition" class="headerlink" title="Sparsely Shared LoRA on Whisper for Child Speech Recognition"></a>Sparsely Shared LoRA on Whisper for Child Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11756">http://arxiv.org/abs/2309.11756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Liu, Ying Qin, Zhiyuan Peng, Tan Lee</li>
<li>for: 这个论文想要提高 whisper 自动语音识别（ASR）模型在low-resource语音上的零shot性能。</li>
<li>methods: 这个论文使用了 parameter-efficient fine-tuning（PEFT）方法，包括 LoRA 和 AdaLoRA，以及一种新的 Sparsely Shared LoRA（S2-LoRA）方法。</li>
<li>results:  experiments 表明，S2-LoRA 可以在low-resource中国儿童语音上达到与 AdaLoRA 相当的适应性，并且在out-of-domain数据上表现更好，并且自动学习的rank分布与 AdaLoRA 的分布类似。<details>
<summary>Abstract</summary>
Whisper is a powerful automatic speech recognition (ASR) model. Nevertheless, its zero-shot performance on low-resource speech requires further improvement. Child speech, as a representative type of low-resource speech, is leveraged for adaptation. Recently, parameter-efficient fine-tuning (PEFT) in NLP was shown to be comparable and even better than full fine-tuning, while only needing to tune a small set of trainable parameters. However, current PEFT methods have not been well examined for their effectiveness on Whisper. In this paper, only parameter composition types of PEFT approaches such as LoRA and Bitfit are investigated as they do not bring extra inference costs. Different popular PEFT methods are examined. Particularly, we compare LoRA and AdaLoRA and figure out the learnable rank coefficient is a good design. Inspired by the sparse rank distribution allocated by AdaLoRA, a novel PEFT approach Sparsely Shared LoRA (S2-LoRA) is proposed. The two low-rank decomposed matrices are globally shared. Each weight matrix only has to maintain its specific rank coefficients that are constrained to be sparse. Experiments on low-resource Chinese child speech show that with much fewer trainable parameters, S2-LoRA can achieve comparable in-domain adaptation performance to AdaLoRA and exhibit better generalization ability on out-of-domain data. In addition, the rank distribution automatically learned by S2-LoRA is found to have similar patterns to AdaLoRA's allocation.
</details>
<details>
<summary>摘要</summary>
噪音是一个强大的自动语音识别（ASR）模型。然而，它的零实例性表现在低资源语音上仍需进一步改进。儿童语音作为低资源语音的代表类型，被利用于适应。最近， Parametric Efficient Fine-Tuning（PEFT）在自然语言处理（NLP）中显示了相当于或更好的性能，而只需要调整一小部分可变参数。然而，当前PEFT方法尚未对噪音进行了广泛的检验。本文只 investigate parameter composition type PEFTapproaches such as LoRA和Bitfit，因为它们不会增加额外的推理成本。不同的流行PEFT方法被比较。特别是，我们比较LoRA和AdaLoRA，并发现了可学习排名系数是一个好的设计。受AdaLoRA的稀疏排名分布启发，我们提出了一种新的PEFT方法——Sparsely Shared LoRA（S2-LoRA）。两个低级别分解的矩阵在全球共享。每个weight矩阵只需保持它的特定排名系数，这些系数是约束为稀疏的。实验表明，与少量可变参数，S2-LoRA可以达到与AdaLoRA相当的适应性，并且在对外域数据进行推理时表现更好。此外，S2-LoRA自动学习的排名分布与AdaLoRA的分布有相似的模式。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-In-the-Wild-Data-for-Effective-Self-Supervised-Pretraining-in-Speaker-Recognition"><a href="#Leveraging-In-the-Wild-Data-for-Effective-Self-Supervised-Pretraining-in-Speaker-Recognition" class="headerlink" title="Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in Speaker Recognition"></a>Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in Speaker Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11730">http://arxiv.org/abs/2309.11730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Wang, Qibing Bai, Qi Liu, Jianwei Yu, Zhengyang Chen, Bing Han, Yanmin Qian, Haizhou Li</li>
<li>for: 提高 speaker recognition 系统性能</li>
<li>methods: 使用 DINO 自助学习方法和 confidence-based data filtering 算法</li>
<li>results: 在大规模的 WenetSpeech 数据集和 CNCeleb 数据集上提高 speaker recognition 系统性能，并且需要 fewer 训练数据<details>
<summary>Abstract</summary>
Current speaker recognition systems primarily rely on supervised approaches, constrained by the scale of labeled datasets. To boost the system performance, researchers leverage large pretrained models such as WavLM to transfer learned high-level features to the downstream speaker recognition task. However, this approach introduces extra parameters as the pretrained model remains in the inference stage. Another group of researchers directly apply self-supervised methods such as DINO to speaker embedding learning, yet they have not explored its potential on large-scale in-the-wild datasets. In this paper, we present the effectiveness of DINO training on the large-scale WenetSpeech dataset and its transferability in enhancing the supervised system performance on the CNCeleb dataset. Additionally, we introduce a confidence-based data filtering algorithm to remove unreliable data from the pretraining dataset, leading to better performance with less training data. The associated pretrained models, confidence files, pretraining and finetuning scripts will be made available in the Wespeaker toolkit.
</details>
<details>
<summary>摘要</summary>
In this paper, we show the effectiveness of DINO training on the large-scale WenetSpeech dataset and its transferability in enhancing supervised system performance on the CNCeleb dataset. We also introduce a confidence-based data filtering algorithm to remove unreliable data from the pretraining dataset, leading to better performance with less training data. The associated pretrained models, confidence files, pretraining and finetuning scripts will be available in the Wespeaker toolkit.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.SD_2023_09_21/" data-id="clmvt7tbv00mb26rddjjh7ryq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.CV_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T13:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.CV_2023_09_21/">cs.CV - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Active-Stereo-Without-Pattern-Projector"><a href="#Active-Stereo-Without-Pattern-Projector" class="headerlink" title="Active Stereo Without Pattern Projector"></a>Active Stereo Without Pattern Projector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12315">http://arxiv.org/abs/2309.12315</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bartn8/vppstereo">https://github.com/bartn8/vppstereo</a></li>
<li>paper_authors: Luca Bartolomei, Matteo Poggi, Fabio Tosi, Andrea Conti, Stefano Mattoccia</li>
<li>for: 提出了一种基于活动镜头原理的标准静止相机系统中的新框架，无需物理模式投影器。</li>
<li>methods: 通过在左右图像中虚拟投射模式，根据深度感知器获取的稀疏测量。任何设备都可以轻松地插入我们的框架中，在任何环境中实现虚拟活动镜头设置，超越物理模式投影器的限制，如工作范围或环境条件。</li>
<li>results: 对室内&#x2F;室外 dataset进行了实验，包括长距离和近距离场景，实验结果表明我们的方法可以准确地提高镜头算法和深度网络的准确率。<details>
<summary>Abstract</summary>
This paper proposes a novel framework integrating the principles of active stereo in standard passive camera systems without a physical pattern projector. We virtually project a pattern over the left and right images according to the sparse measurements obtained from a depth sensor. Any such devices can be seamlessly plugged into our framework, allowing for the deployment of a virtual active stereo setup in any possible environment, overcoming the limitation of pattern projectors, such as limited working range or environmental conditions. Experiments on indoor/outdoor datasets, featuring both long and close-range, support the seamless effectiveness of our approach, boosting the accuracy of both stereo algorithms and deep networks.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的框架，将活动镜头原理 integrate into标准的普通摄像头系统中，不需要物理Pattern projector。我们在左右图像上虚拟展示了模式，根据深度传感器获得的稀疏测量。任何这种设备都可以轻松插入我们的框架中， allowing for the deployment of a virtual active stereo setup in any possible environment，超越了模式项目器的限制，如工作范围或环境条件。对室内/室外数据集进行了实验，包括长距离和近距离，支持我们的方法的无缝效果，提高了镜头算法和深度网络的准确性。
</details></li>
</ul>
<hr>
<h2 id="TinyCLIP-CLIP-Distillation-via-Affinity-Mimicking-and-Weight-Inheritance"><a href="#TinyCLIP-CLIP-Distillation-via-Affinity-Mimicking-and-Weight-Inheritance" class="headerlink" title="TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance"></a>TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12314">http://arxiv.org/abs/2309.12314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kan Wu, Houwen Peng, Zhenghong Zhou, Bin Xiao, Mengchen Liu, Lu Yuan, Hong Xuan, Michael Valenzuela, Xi, Chen, Xinggang Wang, Hongyang Chao, Han Hu</li>
<li>for: 这个论文提出了一种新的跨模型蒸发法，叫做TinyCLIP，用于大规模的语言-图像预训模型。</li>
<li>methods: 这个方法 introduces two core techniques: affinity mimicking和weight inheritance。affinity mimicking探索了modalities之间的互动，使学生模型能够模仿老师的跨modalities的学习行为，实现视征语Modal Affinity Space中的对应关系。weight inheritance将老师模型的预训过的类 weights传递给学生模型，以提高蒸发效率。</li>
<li>results: 实验结果显示，TinyCLIP可以将预训CLIP ViT-B&#x2F;32的大小增加50%，并维持相同的零配置性性能。而且，将蒸发进行多阶段进度的实现了对应关系的增强。此外，我们的TinyCLIP ViT-8M&#x2F;16，在YFCC-15M上训练，在ImageNet上取得了41.1%的零配置性top-1准确率，比原CLIP ViT-B&#x2F;16高3.5%，并且只使用8.9%的参数。最后，我们显示了TinyCLIP在多个下游任务中的优良传播性。代码和模型将在<a target="_blank" rel="noopener" href="https://aka.ms/tinyclip%E4%B8%8A%E5%BC%80%E6%BA%90%E3%80%82">https://aka.ms/tinyclip上开源。</a><details>
<summary>Abstract</summary>
In this paper, we propose a novel cross-modal distillation method, called TinyCLIP, for large-scale language-image pre-trained models. The method introduces two core techniques: affinity mimicking and weight inheritance. Affinity mimicking explores the interaction between modalities during distillation, enabling student models to mimic teachers' behavior of learning cross-modal feature alignment in a visual-linguistic affinity space. Weight inheritance transmits the pre-trained weights from the teacher models to their student counterparts to improve distillation efficiency. Moreover, we extend the method into a multi-stage progressive distillation to mitigate the loss of informative weights during extreme compression. Comprehensive experiments demonstrate the efficacy of TinyCLIP, showing that it can reduce the size of the pre-trained CLIP ViT-B/32 by 50%, while maintaining comparable zero-shot performance. While aiming for comparable performance, distillation with weight inheritance can speed up the training by 1.4 - 7.8 $\times$ compared to training from scratch. Moreover, our TinyCLIP ViT-8M/16, trained on YFCC-15M, achieves an impressive zero-shot top-1 accuracy of 41.1% on ImageNet, surpassing the original CLIP ViT-B/16 by 3.5% while utilizing only 8.9% parameters. Finally, we demonstrate the good transferability of TinyCLIP in various downstream tasks. Code and models will be open-sourced at https://aka.ms/tinyclip.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的跨Modal Distillation方法，称为TinyCLIP，用于大规模语言图像预训练模型。该方法 introduce two core techniques：对模式的亲和力模仿和重量继承。对模式的亲和力模仿探索了多Modalities在Distillation过程中的交互，使学生模型能够模仿教师模型在视觉语言对应空间中学习跨Modal featureAlignment的行为。重量继承将预训练的重量从教师模型传递给其学生版本，以提高Distillation的效率。此外，我们扩展了该方法到多Stage Progressive Distillation，以mitigate the loss of informative weights during extreme compression。我们的实验表明，TinyCLIP可以将预训练CLIP ViT-B/32的大小减少50%，保持相同的零shot性能。而在尝试保持相同性能的情况下，与教师模型的Distillation可以加速训练1.4-7.8倍。此外，我们的TinyCLIP ViT-8M/16，在YFCC-15M上训练，在ImageNet上 achieve Zero-shot top-1准确率41.1%，比原CLIP ViT-B/16提高3.5%，使用只有8.9%的参数。最后，我们示出了TinyCLIP在多种下游任务中的好传输性。代码和模型将在https://aka.ms/tinyclip上开源。
</details></li>
</ul>
<hr>
<h2 id="TalkNCE-Improving-Active-Speaker-Detection-with-Talk-Aware-Contrastive-Learning"><a href="#TalkNCE-Improving-Active-Speaker-Detection-with-Talk-Aware-Contrastive-Learning" class="headerlink" title="TalkNCE: Improving Active Speaker Detection with Talk-Aware Contrastive Learning"></a>TalkNCE: Improving Active Speaker Detection with Talk-Aware Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12306">http://arxiv.org/abs/2309.12306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaeyoung Jung, Suyeon Lee, Kihyun Nam, Kyeongha Rho, You Jin Kim, Youngjoon Jang, Joon Son Chung</li>
<li>for: 本文旨在提出一种新的对话监视损失函数，以便在视频帧序中确定人员是否正在说话。</li>
<li>methods: 本文提出了一种名为TalkNCE的对话感知损失函数，该损失函数仅在屏幕上显示的人员实际说话的部分应用。这种损失函数鼓励模型通过自然的语音和面部运动的对应学习有效的表示。</li>
<li>results: 实验表明，我们的损失函数可以轻松地与现有的ASD模型一起进行joint优化，提高其性能。我们的方法在AVA-ActiveSpeaker和ASW datasets上达到了状态艺术水平。<details>
<summary>Abstract</summary>
The goal of this work is Active Speaker Detection (ASD), a task to determine whether a person is speaking or not in a series of video frames. Previous works have dealt with the task by exploring network architectures while learning effective representations has been less explored. In this work, we propose TalkNCE, a novel talk-aware contrastive loss. The loss is only applied to part of the full segments where a person on the screen is actually speaking. This encourages the model to learn effective representations through the natural correspondence of speech and facial movements. Our loss can be jointly optimized with the existing objectives for training ASD models without the need for additional supervision or training data. The experiments demonstrate that our loss can be easily integrated into the existing ASD frameworks, improving their performance. Our method achieves state-of-the-art performances on AVA-ActiveSpeaker and ASW datasets.
</details>
<details>
<summary>摘要</summary>
本工作的目标是活动说话人检测（ASD），即在视频帧序中确定人是否说话。先前的工作主要关注网络架构，而学习有效表示的研究相对较少。在这项工作中，我们提议了一种新的对话抑制损失函数，即TalkNCE。这种损失函数只应用于屏幕上的人是否实际说话的部分段落。这会让模型学习有效的表示，通过自然的语音和面部运动之间的相对应。我们的损失函数可以与现有的ASD模型训练目标一起优化，无需额外的监督或训练数据。实验表明，我们的损失函数可以轻松地与现有的ASD框架集成，提高其性能。我们的方法在AVA-ActiveSpeaker和ASW数据集上达到了状态盘点的表现。
</details></li>
</ul>
<hr>
<h2 id="SlowFast-Network-for-Continuous-Sign-Language-Recognition"><a href="#SlowFast-Network-for-Continuous-Sign-Language-Recognition" class="headerlink" title="SlowFast Network for Continuous Sign Language Recognition"></a>SlowFast Network for Continuous Sign Language Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12304">http://arxiv.org/abs/2309.12304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junseok Ahn, Youngjoon Jang, Joon Son Chung</li>
<li>for: 本研究旨在实现有效的Continuous Sign Language Recognition（CSLR）特征提取。</li>
<li>methods: 我们使用了两条不同的时间分辨率的SlowFast网络，每一条路径独立地捕捉手势（手势）和表情（表情）的空间信息，以及动作（运动）信息。此外，我们还提出了两种特有的特征融合方法：（1）双向特征融合（BFF），使得动态 semantics transfer into spatial semantics和vice versa；和（2）路径特征增强（PFE），通过辅助子网络增强动态和空间表示，而不需Extra的推理时间。</li>
<li>results: 我们的模型在流行的CSLR数据集上（包括PHOENIX14、PHOENIX14-T和CSL-Daily）达到了当前领先的性能。<details>
<summary>Abstract</summary>
The objective of this work is the effective extraction of spatial and dynamic features for Continuous Sign Language Recognition (CSLR). To accomplish this, we utilise a two-pathway SlowFast network, where each pathway operates at distinct temporal resolutions to separately capture spatial (hand shapes, facial expressions) and dynamic (movements) information. In addition, we introduce two distinct feature fusion methods, carefully designed for the characteristics of CSLR: (1) Bi-directional Feature Fusion (BFF), which facilitates the transfer of dynamic semantics into spatial semantics and vice versa; and (2) Pathway Feature Enhancement (PFE), which enriches dynamic and spatial representations through auxiliary subnetworks, while avoiding the need for extra inference time. As a result, our model further strengthens spatial and dynamic representations in parallel. We demonstrate that the proposed framework outperforms the current state-of-the-art performance on popular CSLR datasets, including PHOENIX14, PHOENIX14-T, and CSL-Daily.
</details>
<details>
<summary>摘要</summary>
目标是提取CSLR中的空间和动态特征，我们利用了两个不同的时间分辨率的SlowFast网络，每个路径独立捕捉空间（手势、 facial expressions）和动态（运动）信息。此外，我们还提出了两种特有的特征融合方法：（1）双向特征融合（BFF），使动态 semantics transfer into spatial semantics和vice versa；（2）路径特征增强（PFE），通过辅助子网络增强动态和空间表示，而不需要额外的推理时间。这种方法使得我们的模型在平行的情况下进一步强化了空间和动态表示。我们的模型在各种CSLR数据集上达到了当前领先的性能，包括PHOENIX14、PHOENIX14-T和CSL-Daily等。
</details></li>
</ul>
<hr>
<h2 id="PanoVOS-Bridging-Non-panoramic-and-Panoramic-Views-with-Transformer-for-Video-Segmentation"><a href="#PanoVOS-Bridging-Non-panoramic-and-Panoramic-Views-with-Transformer-for-Video-Segmentation" class="headerlink" title="PanoVOS:Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation"></a>PanoVOS:Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12303">http://arxiv.org/abs/2309.12303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shilin Yan, Xiaohao Xu, Lingyi Hong, Wenchao Chen, Wenqiang Zhang, Wei Zhang</li>
<li>for: 这篇论文旨在提供一个大型投影视频分割 dataset，以满足投影视频中的视频分割问题。</li>
<li>methods: 该论文使用了15种市场上的视频对象分割模型进行评估，并通过错误分析发现这些模型无法处理投影视频中的像素级别内容缺失。因此，该论文提出了一种基于 semantic boundary information的 Panoramic Space Consistency Transformer（PSCFormer），可以有效地利用上一帧的semantic boundary信息来进行像素级别匹配。</li>
<li>results: 对比之前的最佳模型，我们的 PSCFormer 网络在投影视频下表现出了优于其他模型的 segmentation 结果。<details>
<summary>Abstract</summary>
Panoramic videos contain richer spatial information and have attracted tremendous amounts of attention due to their exceptional experience in some fields such as autonomous driving and virtual reality. However, existing datasets for video segmentation only focus on conventional planar images. To address the challenge, in this paper, we present a panoramic video dataset, PanoVOS. The dataset provides 150 videos with high video resolutions and diverse motions. To quantify the domain gap between 2D planar videos and panoramic videos, we evaluate 15 off-the-shelf video object segmentation (VOS) models on PanoVOS. Through error analysis, we found that all of them fail to tackle pixel-level content discontinues of panoramic videos. Thus, we present a Panoramic Space Consistency Transformer (PSCFormer), which can effectively utilize the semantic boundary information of the previous frame for pixel-level matching with the current frame. Extensive experiments demonstrate that compared with the previous SOTA models, our PSCFormer network exhibits a great advantage in terms of segmentation results under the panoramic setting. Our dataset poses new challenges in panoramic VOS and we hope that our PanoVOS can advance the development of panoramic segmentation/tracking.
</details>
<details>
<summary>摘要</summary>
拼接视频含有更多的空间信息，吸引了很多关注，特别是在自动驾驶和虚拟现实等领域。然而，现有的视频分割数据集只关注传统的平面图像。为了解决这个挑战，在这篇论文中，我们提供了拼接视频数据集（PanoVOS）。该数据集包含150个高分辨率视频和多样化的运动。为了衡量2D平面视频和拼接视频之间的域间差，我们评估了15种市场上的视频对象分割（VOS）模型在PanoVOS上。经过错误分析，我们发现所有模型都无法处理拼接视频中像素级别的内容缺失。因此，我们提出了拼接空间一致变换器（PSCFormer），可以有效利用上一帧的semantic边界信息 для像素级匹配当前帧。广泛的实验表明，与前一代最佳模型相比，我们的PSCFormer网络在拼接设置下展现出了优于其他模型的分割结果。我们的数据集将带来新的拼接VOS挑战，我们希望通过PanoVOS来推动拼接分割/跟踪的发展。
</details></li>
</ul>
<hr>
<h2 id="Text-Guided-Vector-Graphics-Customization"><a href="#Text-Guided-Vector-Graphics-Customization" class="headerlink" title="Text-Guided Vector Graphics Customization"></a>Text-Guided Vector Graphics Customization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12302">http://arxiv.org/abs/2309.12302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiying Zhang, Nanxuan Zhao, Jing Liao</li>
<li>for: 生成高质量自定义 вектор图形，以满足设计师的创造需求。</li>
<li>methods: 提posed a novel pipeline that leverages large pre-trained text-to-image models and semantic-based path alignment method to generate customized raster images guided by textual prompts, while preserving the properties and layer-wise information of a given exemplar SVG.</li>
<li>results: 经过广泛评估，得到了多 metric 的优秀Result，证明了该管道的效果iveness in generating diverse customizations of vector graphics with exceptional quality.<details>
<summary>Abstract</summary>
Vector graphics are widely used in digital art and valued by designers for their scalability and layer-wise topological properties. However, the creation and editing of vector graphics necessitate creativity and design expertise, leading to a time-consuming process. In this paper, we propose a novel pipeline that generates high-quality customized vector graphics based on textual prompts while preserving the properties and layer-wise information of a given exemplar SVG. Our method harnesses the capabilities of large pre-trained text-to-image models. By fine-tuning the cross-attention layers of the model, we generate customized raster images guided by textual prompts. To initialize the SVG, we introduce a semantic-based path alignment method that preserves and transforms crucial paths from the exemplar SVG. Additionally, we optimize path parameters using both image-level and vector-level losses, ensuring smooth shape deformation while aligning with the customized raster image. We extensively evaluate our method using multiple metrics from vector-level, image-level, and text-level perspectives. The evaluation results demonstrate the effectiveness of our pipeline in generating diverse customizations of vector graphics with exceptional quality. The project page is https://intchous.github.io/SVGCustomization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese<</SYS>>Vector graphics 广泛用于数字艺术中，设计师们喜欢它们因为它们可扩展和层次结构的特性。然而，创建和修改vector graphics需要创作和设计技能，这会使得过程变得时间consuming。在这篇论文中，我们提出了一个新的管道，可以根据文本提示生成高质量自定义vector graphics，同时保持原始SVG的特性和层次信息。我们利用大型预训练的文本到图像模型的能力，通过微调模型的交叉注意力层，生成基于文本提示的自定义静止图像。为初始化SVG，我们引入了基于 semantics的路径对齐方法，保持和修改原始SVG中重要的路径。此外，我们使用图像水平和向量水平的损失函数进行路径参数优化，确保图像和向量图像的平滑形变。我们进行了广泛的评估，结果表明我们的管道可以生成多样化的自定义vector graphics，质量极高。项目页面是https://intchous.github.io/SVGCustomization。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Input-image-Normalization-for-Solving-Mode-Collapse-Problem-in-GAN-based-X-ray-Images"><a href="#Adaptive-Input-image-Normalization-for-Solving-Mode-Collapse-Problem-in-GAN-based-X-ray-Images" class="headerlink" title="Adaptive Input-image Normalization for Solving Mode Collapse Problem in GAN-based X-ray Images"></a>Adaptive Input-image Normalization for Solving Mode Collapse Problem in GAN-based X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12245">http://arxiv.org/abs/2309.12245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Muneeb Saad, Mubashir Husain Rehmani, Ruairi O’Reilly</li>
<li>for: 增强医学影像数据集的多样性，提高机器学习分类器的性能。</li>
<li>methods: 使用生成对抗网络（GAN）技术生成 sintetic X-ray 图像，并在 GAN 中加入 adaptive input-image normalization 来解决模式塌collapse问题。</li>
<li>results: DCGAN 和 ACGAN  WITH adaptive input-image normalization 能够提高 classification 性能和多样性 scores，相比于 DCGAN 和 ACGAN  WITH un-normalized X-ray images。<details>
<summary>Abstract</summary>
Biomedical image datasets can be imbalanced due to the rarity of targeted diseases. Generative Adversarial Networks play a key role in addressing this imbalance by enabling the generation of synthetic images to augment datasets. It is important to generate synthetic images that incorporate a diverse range of features to accurately represent the distribution of features present in the training imagery. Furthermore, the absence of diverse features in synthetic images can degrade the performance of machine learning classifiers. The mode collapse problem impacts Generative Adversarial Networks' capacity to generate diversified images. Mode collapse comes in two varieties: intra-class and inter-class. In this paper, both varieties of the mode collapse problem are investigated, and their subsequent impact on the diversity of synthetic X-ray images is evaluated. This work contributes an empirical demonstration of the benefits of integrating the adaptive input-image normalization with the Deep Convolutional GAN and Auxiliary Classifier GAN to alleviate the mode collapse problems. Synthetically generated images are utilized for data augmentation and training a Vision Transformer model. The classification performance of the model is evaluated using accuracy, recall, and precision scores. Results demonstrate that the DCGAN and the ACGAN with adaptive input-image normalization outperform the DCGAN and ACGAN with un-normalized X-ray images as evidenced by the superior diversity scores and classification scores.
</details>
<details>
<summary>摘要</summary>
生成对抗网络可能会遇到两种不同的模式塌溃问题：内类模式塌溃和间类模式塌溃。这两种问题都会导致生成的 sintetic 图像失去多样化。本文研究了这两种模式塌溃问题，并评估它们对生成的 sintetic X-ray 图像的多样化的影响。这个研究还提供了一种实验室的证明，表明将适应输入图像Normalization与深度卷积GAN和辅助分类器GAN相结合可以解决模式塌溃问题。生成的 sintetic 图像被用于数据增强和训练一个 Vision Transformer 模型。模型的分类性能被评估使用准确率、回归率和精度分数。结果表明，DCGAN 和 ACGAN  WITH 适应输入图像Normalization 比 DCGAN 和 ACGAN  WITH 未normalized X-ray 图像表现更好，根据多样化分数和分类分数。
</details></li>
</ul>
<hr>
<h2 id="Can-We-Reliably-Improve-the-Robustness-to-Image-Acquisition-of-Remote-Sensing-of-PV-Systems"><a href="#Can-We-Reliably-Improve-the-Robustness-to-Image-Acquisition-of-Remote-Sensing-of-PV-Systems" class="headerlink" title="Can We Reliably Improve the Robustness to Image Acquisition of Remote Sensing of PV Systems?"></a>Can We Reliably Improve the Robustness to Image Acquisition of Remote Sensing of PV Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12214">http://arxiv.org/abs/2309.12214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel Kasmi, Laurent Dubus, Yves-Marie Saint-Drenan, Philippe Blanc</li>
<li>for: 监控区域级单位的拍照电力系统</li>
<li>methods: 利用波浪对数法（WCAM）分解模型预测的空间�atura领域</li>
<li>results: 提高了内部积分模型的可靠性和敏感度，并获得了对于采购条件的变化的深入理解，以增加清洁能源的安全组合。<details>
<summary>Abstract</summary>
Photovoltaic (PV) energy is crucial for the decarbonization of energy systems. Due to the lack of centralized data, remote sensing of rooftop PV installations is the best option to monitor the evolution of the rooftop PV installed fleet at a regional scale. However, current techniques lack reliability and are notably sensitive to shifts in the acquisition conditions. To overcome this, we leverage the wavelet scale attribution method (WCAM), which decomposes a model's prediction in the space-scale domain. The WCAM enables us to assess on which scales the representation of a PV model rests and provides insights to derive methods that improve the robustness to acquisition conditions, thus increasing trust in deep learning systems to encourage their use for the safe integration of clean energy in electric systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Brain-Tumor-Detection-Using-Deep-Learning-Approaches"><a href="#Brain-Tumor-Detection-Using-Deep-Learning-Approaches" class="headerlink" title="Brain Tumor Detection Using Deep Learning Approaches"></a>Brain Tumor Detection Using Deep Learning Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12193">http://arxiv.org/abs/2309.12193</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Arminsbss/tumor-classification">https://github.com/Arminsbss/tumor-classification</a></li>
<li>paper_authors: Razia Sultana Misu</li>
<li>for: 本研究旨在使用深度学习技术自动检测脑肿瘤，以提高脑肿瘤检测和分类精度。</li>
<li>methods: 本研究使用了五种转移学习模型，包括VGG16、VGG19、DenseNet121、ResNet50和YOLO V4，其中ResNet50达到了最高准确率99.54%。</li>
<li>results: 研究表明，使用深度学习技术可以提高脑肿瘤检测和分类精度，并且ResNet50模型达到了最高准确率。<details>
<summary>Abstract</summary>
Brain tumors are collections of abnormal cells that can develop into masses or clusters. Because they have the potential to infiltrate other tissues, they pose a risk to the patient. The main imaging technique used, MRI, may be able to identify a brain tumor with accuracy. The fast development of Deep Learning methods for use in computer vision applications has been facilitated by a vast amount of training data and improvements in model construction that offer better approximations in a supervised setting. The need for these approaches has been the main driver of this expansion. Deep learning methods have shown promise in improving the precision of brain tumor detection and classification using magnetic resonance imaging (MRI). The study on the use of deep learning techniques, especially ResNet50, for brain tumor identification is presented in this abstract. As a result, this study investigates the possibility of automating the detection procedure using deep learning techniques. In this study, I utilized five transfer learning models which are VGG16, VGG19, DenseNet121, ResNet50 and YOLO V4 where ResNet50 provide the best or highest accuracy 99.54%. The goal of the study is to guide researchers and medical professionals toward powerful brain tumor detecting systems by employing deep learning approaches by way of this evaluation and analysis.
</details>
<details>
<summary>摘要</summary>
脑肿是一种集群畸形细胞的发育，可能形成肿体或集群。由于它们可能会渗透到其他组织，因此对患者存在风险。主要用于识别脑肿的成像技术是MRI，可能准确地识别脑肿。深度学习方法在计算机视觉应用中的快速发展，得益于庞大的训练数据和改进的模型构造，以及更好的超级vised设定。这些方法的需求是扩展的推动者。深度学习方法在MRI中识别和分类脑肿方面表现出了承诺，特别是使用ResNet50模型，其最高准确率为99.54%。本研究旨在通过深度学习方法自动识别脑肿的可能性，并提供一种可靠的脑肿检测系统。本研究使用了五种转移学习模型，包括VGG16、VGG19、DenseNet121、ResNet50和YOLO V4，其中ResNet50提供了最高准确率。本研究的目标是导引研究人员和医疗专业人员通过深度学习方法来实现高效的脑肿检测系统，以便更好地满足医疗需求。
</details></li>
</ul>
<hr>
<h2 id="SG-Bot-Object-Rearrangement-via-Coarse-to-Fine-Robotic-Imagination-on-Scene-Graphs"><a href="#SG-Bot-Object-Rearrangement-via-Coarse-to-Fine-Robotic-Imagination-on-Scene-Graphs" class="headerlink" title="SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on Scene Graphs"></a>SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on Scene Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12188">http://arxiv.org/abs/2309.12188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyao Zhai, Xiaoni Cai, Dianye Huang, Yan Di, Fabian Manhardt, Federico Tombari, Nassir Navab, Benjamin Busam</li>
<li>for: This paper focuses on developing a novel rearrangement framework for robotic-environment interactions, with the goal of achieving lightweight, real-time, and user-controllable characteristics.</li>
<li>methods: The proposed framework, called SG-Bot, utilizes a coarse-to-fine scheme with a scene graph as the scene representation, and employs a three-fold procedure consisting of observation, imagination, and execution to address the task.</li>
<li>results: Experimental results show that SG-Bot outperforms competitors by a large margin, demonstrating its effectiveness in embodied AI tasks.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文关注开发一种新的重新排序框架，用于机器人环境互动，目的是实现轻量级、实时、用户可控的特点。</li>
<li>methods: 提议的框架被称为SG-Bot，它采用一种粗粒度到细粒度的方案，使用场景图作为场景表示，并采用观察、想象和执行的三重过程来解决问题。</li>
<li>results: 实验结果显示，SG-Bot比竞争对手大幅提高了性能，证明了它在机器人AI任务中的有效性。<details>
<summary>Abstract</summary>
Object rearrangement is pivotal in robotic-environment interactions, representing a significant capability in embodied AI. In this paper, we present SG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme with a scene graph as the scene representation. Unlike previous methods that rely on either known goal priors or zero-shot large models, SG-Bot exemplifies lightweight, real-time, and user-controllable characteristics, seamlessly blending the consideration of commonsense knowledge with automatic generation capabilities. SG-Bot employs a three-fold procedure--observation, imagination, and execution--to adeptly address the task. Initially, objects are discerned and extracted from a cluttered scene during the observation. These objects are first coarsely organized and depicted within a scene graph, guided by either commonsense or user-defined criteria. Then, this scene graph subsequently informs a generative model, which forms a fine-grained goal scene considering the shape information from the initial scene and object semantics. Finally, for execution, the initial and envisioned goal scenes are matched to formulate robotic action policies. Experimental results demonstrate that SG-Bot outperforms competitors by a large margin.
</details>
<details>
<summary>摘要</summary>
对象重新排序是人工智能中的一项关键能力，代表了机器人和环境之间的互动。在这篇论文中，我们提出了SG-Bot，一种新的重新排序框架，利用粗略到细化的方案，使用场景图作为场景表示。与前一代方法不同，SG-Bot不依赖于已知目标假设或大型零基础模型，而是具有轻量级、实时和用户可控的特点，可以协调考虑常识知识和自动生成能力。SG-Bot采用三个步骤—观察、想象和执行—以适应任务。首先，从杂乱的场景中提取和识别 объек，并将其粗略地组织和描述于场景图中，以 Commonsense 或用户定义的标准指导。然后，这个场景图将导引一个生成模型，该模型形成基于初始场景和物体 semantics 的细化目标场景。最后，为执行，初始和想象的目标场景相匹配，以形成机器人行为策略。实验结果表明，SG-Bot在竞争者之上大幅提高表现。
</details></li>
</ul>
<hr>
<h2 id="ORTexME-Occlusion-Robust-Human-Shape-and-Pose-via-Temporal-Average-Texture-and-Mesh-Encoding"><a href="#ORTexME-Occlusion-Robust-Human-Shape-and-Pose-via-Temporal-Average-Texture-and-Mesh-Encoding" class="headerlink" title="ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding"></a>ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12183">http://arxiv.org/abs/2309.12183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Cheng, Bo Wang, Robby T. Tan</li>
<li>for:  improve the accuracy of 3D human shape and pose estimation in the presence of occlusion</li>
<li>methods: utilizes temporal information from the input video to better regularize the occluded body parts, and uses a novel average texture learning approach to learn the average appearance of a person and infer a mask based on the average texture</li>
<li>results: achieves significant improvement on the challenging multi-person 3DPW dataset, with 1.8 P-MPJPE error reduction compared to the state-of-the-art rendering-based methods, which enlarge the error up to 5.6 on the same dataset.<details>
<summary>Abstract</summary>
In 3D human shape and pose estimation from a monocular video, models trained with limited labeled data cannot generalize well to videos with occlusion, which is common in the wild videos. The recent human neural rendering approaches focusing on novel view synthesis initialized by the off-the-shelf human shape and pose methods have the potential to correct the initial human shape. However, the existing methods have some drawbacks such as, erroneous in handling occlusion, sensitive to inaccurate human segmentation, and ineffective loss computation due to the non-regularized opacity field. To address these problems, we introduce ORTexME, an occlusion-robust temporal method that utilizes temporal information from the input video to better regularize the occluded body parts. While our ORTexME is based on NeRF, to determine the reliable regions for the NeRF ray sampling, we utilize our novel average texture learning approach to learn the average appearance of a person, and to infer a mask based on the average texture. In addition, to guide the opacity-field updates in NeRF to suppress blur and noise, we propose the use of human body mesh. The quantitative evaluation demonstrates that our method achieves significant improvement on the challenging multi-person 3DPW dataset, where our method achieves 1.8 P-MPJPE error reduction. The SOTA rendering-based methods fail and enlarge the error up to 5.6 on the same dataset.
</details>
<details>
<summary>摘要</summary>
在单一影像视频中的3D人体和姿势估算中，使用有限标签数据训练的模型无法对受遮蔽的影像进行普遍化，这是野外影像中的普遍现象。现有的人类神经渲染方法强调新视角合成，由存在于市场上的人体形状和姿势方法进行初始化，有potential以更正初始人体形状。然而，现有的方法存在一些缺陷，例如错误地处理遮蔽、敏感于不准确的人类分割、以及无法有效地computing条件值场。为了解决这些问题，我们介绍ORTexME，一种防遮蔽时间方法，利用输入影像中的时间信息更好地调节遮蔽的体部部分。我们的ORTexME基于NeRF，以determine可靠的NeRF射线抽样区域，我们运用我们的新的平均文件学习方法学习人类的平均外观，并将其转换为对应的面瘫。此外，为了将NeRF中的透明度场更新更加稳定，我们提议使用人体骨架。我们的量值评估显示，我们的方法在多人3DPW数据集上取得了1.8P-MPJPE误差reduction，而SOTA的渲染基于方法则失败并将误差增加到5.6。
</details></li>
</ul>
<hr>
<h2 id="Autoregressive-Sign-Language-Production-A-Gloss-Free-Approach-with-Discrete-Representations"><a href="#Autoregressive-Sign-Language-Production-A-Gloss-Free-Approach-with-Discrete-Representations" class="headerlink" title="Autoregressive Sign Language Production: A Gloss-Free Approach with Discrete Representations"></a>Autoregressive Sign Language Production: A Gloss-Free Approach with Discrete Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12179">http://arxiv.org/abs/2309.12179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eui Jun Hwang, Huije Lee, Jong C. Park</li>
<li>for: 本研究旨在提供一种直接将口语句子翻译成手语表达，无需中间件gloss。</li>
<li>methods: 本方法基于手势pose序列的vector量化，并支持高级解码方法和latent-levelAlignment。</li>
<li>results: 我们的方法在比较之前的手语生成方法的测试中表现出色，并且通过Back-Translation和Fréchet Gesture Distance的评价指标来证明其可靠性。<details>
<summary>Abstract</summary>
Gloss-free Sign Language Production (SLP) offers a direct translation of spoken language sentences into sign language, bypassing the need for gloss intermediaries. This paper presents the Sign language Vector Quantization Network, a novel approach to SLP that leverages Vector Quantization to derive discrete representations from sign pose sequences. Our method, rooted in both manual and non-manual elements of signing, supports advanced decoding methods and integrates latent-level alignment for enhanced linguistic coherence. Through comprehensive evaluations, we demonstrate superior performance of our method over prior SLP methods and highlight the reliability of Back-Translation and Fr\'echet Gesture Distance as evaluation metrics.
</details>
<details>
<summary>摘要</summary>
simplified Chinese:《无折衣手语生产（SLP）》提供了直接将口语句子翻译成手语，无需中间件。这篇论文介绍了《手语 вектор量化网络》，一种新的SLP方法，利用量化向量来Derive discrete representation from sign pose sequences。我们的方法受到手语的手势和非手势元素的支持，支持高级解码方法并实现了层次匹配。通过全面的评估，我们证明了我们的方法的性能超过了先前的SLP方法，并指出了回传和Fréchet手势距离作为评估指标的可靠性。
</details></li>
</ul>
<hr>
<h2 id="SANPO-A-Scene-Understanding-Accessibility-Navigation-Pathfinding-Obstacle-Avoidance-Dataset"><a href="#SANPO-A-Scene-Understanding-Accessibility-Navigation-Pathfinding-Obstacle-Avoidance-Dataset" class="headerlink" title="SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset"></a>SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12172">http://arxiv.org/abs/2309.12172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sagar M. Waghmare, Kimberly Wilber, Dave Hawkey, Xuan Yang, Matthew Wilson, Stephanie Debats, Cattalyya Nuengsigkapian, Astuti Sharma, Lars Pandikow, Huisheng Wang, Hartwig Adam, Mikhail Sirotenko</li>
<li>for: 这个论文是为了提供一个大规模的人центric视频集，用于 dense prediction 在户外环境中。</li>
<li>methods: 这个论文使用了两种视频SESSION：实际视频SESSION和Synthetic视频SESSION，其中Synthetic视频SESSION是由Parallel Domain提供的。所有SESSION都有密集的深度和ODometer标签，而一部分实际SESSION还有时间相关的密集精度分割标签。</li>
<li>results: 这个论文提供了零基eline和SANPObenchmark，以便未来的研究人员可以使用这些数据进行研究。作者希望通过SANPO dataset的挑战性，推动视频分割、深度估计、多任务视模型和synthetic-to-real领域的进步，并为人工导航系统提供更好的支持。<details>
<summary>Abstract</summary>
We introduce SANPO, a large-scale egocentric video dataset focused on dense prediction in outdoor environments. It contains stereo video sessions collected across diverse outdoor environments, as well as rendered synthetic video sessions. (Synthetic data was provided by Parallel Domain.) All sessions have (dense) depth and odometry labels. All synthetic sessions and a subset of real sessions have temporally consistent dense panoptic segmentation labels. To our knowledge, this is the first human egocentric video dataset with both large scale dense panoptic segmentation and depth annotations. In addition to the dataset we also provide zero-shot baselines and SANPO benchmarks for future research. We hope that the challenging nature of SANPO will help advance the state-of-the-art in video segmentation, depth estimation, multi-task visual modeling, and synthetic-to-real domain adaptation, while enabling human navigation systems.   SANPO is available here: https://google-research-datasets.github.io/sanpo_dataset/
</details>
<details>
<summary>摘要</summary>
我们介绍SANPO dataset，一个大规模的自我视角视频集，专注于户外环境中的密集预测。该集包括多个户外环境中的双视频会议，以及由Parallel Domain提供的Synthetic视频会议。所有会议都有密集的深度和运动标签。 Synthetic会议和一部分实际会议都有时间相关的密集精细分割标签。据我们所知，这是人类自我视角视频集中第一个具有大规模密集精细分割和深度标注的 dataset。此外，我们还提供了零基线和SANPO benchmark，以便未来的研究。我们希望SANPO的挑战性能够推动视频分割、深度估计、多任务视觉模型和Synthetic-to-Real领域的进步，同时帮助人类导航系统。SANPO dataset可以在以下链接下下载：https://google-research-datasets.github.io/sanpo_dataset/
</details></li>
</ul>
<hr>
<h2 id="Information-Forensics-and-Security-A-quarter-century-long-journey"><a href="#Information-Forensics-and-Security-A-quarter-century-long-journey" class="headerlink" title="Information Forensics and Security: A quarter-century-long journey"></a>Information Forensics and Security: A quarter-century-long journey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12159">http://arxiv.org/abs/2309.12159</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mauro Barni, Patrizio Campisi, Edward J. Delp, Gwenael Doërr, Jessica Fridrich, Nasir Memon, Fernando Pérez-González, Anderson Rocha, Luisa Verdoliva, Min Wu</li>
<li>for: 本研究领域的目的是确保人们在数位信息时代中使用设备、数据和知识Properties for authorized purposes, 并且将犯罪分子负责任。</li>
<li>methods: 本文发表了过去25年来研究社区对这个领域的重要技术进步，包括选择性领域的主要技术进步。</li>
<li>results: 本文呈现了过去25年来研究社区对这个领域的未来趋势。<details>
<summary>Abstract</summary>
Information Forensics and Security (IFS) is an active R&D area whose goal is to ensure that people use devices, data, and intellectual properties for authorized purposes and to facilitate the gathering of solid evidence to hold perpetrators accountable. For over a quarter century since the 1990s, the IFS research area has grown tremendously to address the societal needs of the digital information era. The IEEE Signal Processing Society (SPS) has emerged as an important hub and leader in this area, and the article below celebrates some landmark technical contributions. In particular, we highlight the major technological advances on some selected focus areas in the field developed in the last 25 years from the research community and present future trends.
</details>
<details>
<summary>摘要</summary>
信息审查安全（IFS）是一个活跃的研发领域，旨在确保人们在授权的目的下使用设备、数据和知识产权。自1990年代以来，IFS研发领域已经不断增长，以应对数字信息时代的社会需求。IEEE信号处理学会（SPS）在这个领域中已经成为重要的中心和领导者，这篇文章将展望过去25年内从研究 сообщества中出现的一些重要技术进步，并预测未来趋势。
</details></li>
</ul>
<hr>
<h2 id="Vulnerability-of-3D-Face-Recognition-Systems-to-Morphing-Attacks"><a href="#Vulnerability-of-3D-Face-Recognition-Systems-to-Morphing-Attacks" class="headerlink" title="Vulnerability of 3D Face Recognition Systems to Morphing Attacks"></a>Vulnerability of 3D Face Recognition Systems to Morphing Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12118">http://arxiv.org/abs/2309.12118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanjeet Vardam, Luuk Spreeuwers</li>
<li>for: 本研究旨在探讨3DFR系统对3D面部变换攻击的Robustness。</li>
<li>methods: 本文提出了一些方法可以生成高质量的3D面部变换，并对这些变换进行识别。</li>
<li>results: 研究发现，当3DFR系统面临look-a-like变换攻击时，其最高MMPMR约为40%，RMMR约为41.76%。<details>
<summary>Abstract</summary>
In recent years face recognition systems have been brought to the mainstream due to development in hardware and software. Consistent efforts are being made to make them better and more secure. This has also brought developments in 3D face recognition systems at a rapid pace. These 3DFR systems are expected to overcome certain vulnerabilities of 2DFR systems. One such problem that the domain of 2DFR systems face is face image morphing. A substantial amount of research is being done for generation of high quality face morphs along with detection of attacks from these morphs. Comparatively the understanding of vulnerability of 3DFR systems against 3D face morphs is less. But at the same time an expectation is set from 3DFR systems to be more robust against such attacks. This paper attempts to research and gain more information on this matter. The paper describes a couple of methods that can be used to generate 3D face morphs. The face morphs that are generated using this method are then compared to the contributing faces to obtain similarity scores. The highest MMPMR is obtained around 40% with RMMR of 41.76% when 3DFRS are attacked with look-a-like morphs.
</details>
<details>
<summary>摘要</summary>
近年来，人脸识别系统得到了主流的推广，归功于硬件和软件的发展。一直在努力使其更加完善和安全。这也导致了3D人脸识别系统（3DFR）的快速发展，被期望能够超越2D人脸识别系统（2DFR）的一些 limitation。其中一个2DFR系统面临的问题是人脸图像杂化（morphing），目前在这个领域进行了大量的研究，以生成高质量的人脸杂化和攻击检测。然而，对于3DFR系统对3D人脸杂化的抵抗能力的理解仍然较少。但是，预期3DFR系统能够更加强健地对抗这些攻击。本文尝试了对这个问题进行研究，并描述了一些可以用于生成3D人脸杂化的方法。生成的人脸杂化与贡献人脸进行比较，以获得相似度分数。在3DFRS遭受look-a-like杂化攻击时，最高的MMPMR为40%，RMMR为41.76%。
</details></li>
</ul>
<hr>
<h2 id="AutoPET-Challenge-2023-Sliding-Window-based-Optimization-of-U-Net"><a href="#AutoPET-Challenge-2023-Sliding-Window-based-Optimization-of-U-Net" class="headerlink" title="AutoPET Challenge 2023: Sliding Window-based Optimization of U-Net"></a>AutoPET Challenge 2023: Sliding Window-based Optimization of U-Net</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12114">http://arxiv.org/abs/2309.12114</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matt3o/autopet2-submission">https://github.com/matt3o/autopet2-submission</a></li>
<li>paper_authors: Matthias Hadlich, Zdravko Marinov, Rainer Stiefelhagen</li>
<li>for: The paper is written for researchers and developers working on tumor segmentation in medical imaging, particularly those using FDG-PET&#x2F;CT scans.</li>
<li>methods: The paper uses a dataset of 1014 FDG-PET&#x2F;CT studies to challenge researchers to develop accurate tumor segmentation methods that can distinguish between tumor-specific uptake and physiological uptake in normal tissues.</li>
<li>results: The paper provides a dataset of FDG-PET&#x2F;CT scans for researchers to use in developing and testing their tumor segmentation methods, with the goal of improving the accuracy of tumor segmentation in clinical practice.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为医学成像中的肿瘤分 segmentation研究人员和开发者写的，特别是使用FDG-PET&#x2F;CT扫描的。</li>
<li>methods: 这篇论文使用1014个FDG-PET&#x2F;CT成像数据集来挑战研究人员开发准确的肿瘤分 segmentation方法，能够将肿瘤吸收与正常组织的吸收区分开。</li>
<li>results: 这篇论文提供了1014个FDG-PET&#x2F;CT成像数据集，用于研究人员开发和测试他们的肿瘤分 segmentation方法，以提高临床中肿瘤分 segmentation的准确性。<details>
<summary>Abstract</summary>
Tumor segmentation in medical imaging is crucial and relies on precise delineation. Fluorodeoxyglucose Positron-Emission Tomography (FDG-PET) is widely used in clinical practice to detect metabolically active tumors. However, FDG-PET scans may misinterpret irregular glucose consumption in healthy or benign tissues as cancer. Combining PET with Computed Tomography (CT) can enhance tumor segmentation by integrating metabolic and anatomic information. FDG-PET/CT scans are pivotal for cancer staging and reassessment, utilizing radiolabeled fluorodeoxyglucose to highlight metabolically active regions. Accurately distinguishing tumor-specific uptake from physiological uptake in normal tissues is a challenging aspect of precise tumor segmentation. The AutoPET challenge addresses this by providing a dataset of 1014 FDG-PET/CT studies, encouraging advancements in accurate tumor segmentation and analysis within the FDG-PET/CT domain. Code: https://github.com/matt3o/AutoPET2-Submission/
</details>
<details>
<summary>摘要</summary>
肿体分割在医学成像中非常重要，需要精准地界定。 fluorodeoxyglucosePositron-Emission Tomography（FDG-PET）在临床实践中广泛应用，用于检测具有异常代谢活性的肿体。然而，FDG-PET扫描可能会误分辨健康或正常组织中的不规则糖分消耗为癌症。将PET与计算机成像（CT）结合可以提高肿体分割，将元素学和解剖信息结合起来。FDG-PET/CT扫描是癌症评估和重新评估中非常重要的，通过使用标记的 fluorodeoxyglucose来高亮具有代谢活性的区域。正确地从正常组织中的代谢吸收中分化出肿体特有的吸收是精准肿体分割的挑战之一。AutoPET挑战提供了1014个FDG-PET/CT研究数据集，鼓励技术创新，以提高FDG-PET/CT频谱中的准确肿体分割和分析。代码：https://github.com/matt3o/AutoPET2-Submission/
</details></li>
</ul>
<hr>
<h2 id="Exploiting-CLIP-based-Multi-modal-Approach-for-Artwork-Classification-and-Retrieval"><a href="#Exploiting-CLIP-based-Multi-modal-Approach-for-Artwork-Classification-and-Retrieval" class="headerlink" title="Exploiting CLIP-based Multi-modal Approach for Artwork Classification and Retrieval"></a>Exploiting CLIP-based Multi-modal Approach for Artwork Classification and Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12110">http://arxiv.org/abs/2309.12110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Baldrati, Marco Bertini, Tiberio Uricchio, Alberto Del Bimbo</li>
<li>for:  investigate the application of recent CLIP model in artwork domain tasks</li>
<li>methods:  use semantically dense textual supervision to train visual models</li>
<li>results:  impressive zero-shot classification results and promising results in artwork-to-artwork and description-to-artwork domain<details>
<summary>Abstract</summary>
Given the recent advances in multimodal image pretraining where visual models trained with semantically dense textual supervision tend to have better generalization capabilities than those trained using categorical attributes or through unsupervised techniques, in this work we investigate how recent CLIP model can be applied in several tasks in artwork domain. We perform exhaustive experiments on the NoisyArt dataset which is a dataset of artwork images crawled from public resources on the web. On such dataset CLIP achieves impressive results on (zero-shot) classification and promising results in both artwork-to-artwork and description-to-artwork domain.
</details>
<details>
<summary>摘要</summary>
With the recent advances in multimodal image pretraining, visual models trained with semantically dense textual supervision have shown better generalization capabilities compared to those trained using categorical attributes or unsupervised techniques. In this work, we explore the application of the recent CLIP model in various tasks within the artwork domain.We conduct exhaustive experiments on the NoisyArt dataset, a collection of artwork images crawled from public resources on the web. On this dataset, CLIP achieves impressive results in zero-shot classification and promising results in both artwork-to-artwork and description-to-artwork domains.Here's the translation in Simplified Chinese:近期多modal图像预训练的进步，使用语义密集的文本监督训练的视觉模型在泛化能力方面表现出色，比使用分类属性或无监督技术训练的模型更好。在这个工作中，我们探索了最近的CLIP模型在艺术领域中的应用，并在NoisyArt数据集上进行了极限性的实验。在NoisyArt数据集上，CLIP在零shot分类和描述到图像领域中表现出了惊人的成绩，并在描述到图像和艺术作品之间的领域中表现出了可期的成绩。
</details></li>
</ul>
<hr>
<h2 id="FourierLoss-Shape-Aware-Loss-Function-with-Fourier-Descriptors"><a href="#FourierLoss-Shape-Aware-Loss-Function-with-Fourier-Descriptors" class="headerlink" title="FourierLoss: Shape-Aware Loss Function with Fourier Descriptors"></a>FourierLoss: Shape-Aware Loss Function with Fourier Descriptors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12106">http://arxiv.org/abs/2309.12106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehmet Bahadir Erden, Selahattin Cansiz, Onur Caki, Haya Khattak, Durmus Etiz, Melek Cosar Yakar, Kerem Duruer, Berke Barut, Cigdem Gunduz-Demir</li>
<li>for: 这个研究是为了提高医疗影像分类 задачі中的网络模型，以提高精确性。</li>
<li>methods: 这个研究使用了Encoder-decoder网络，并导入了一个新的形状意识损失函数（FourierLoss），以强制网络在训练过程中将物体的形状独特性考虑在内。</li>
<li>results: 实验结果显示，这个灵活的形状意识损失函数可以将医疗影像分类精确性提高，比其他方法更好。<details>
<summary>Abstract</summary>
Encoder-decoder networks become a popular choice for various medical image segmentation tasks. When they are trained with a standard loss function, these networks are not explicitly enforced to preserve the shape integrity of an object in an image. However, this ability of the network is important to obtain more accurate results, especially when there is a low-contrast difference between the object and its surroundings. In response to this issue, this work introduces a new shape-aware loss function, which we name FourierLoss. This loss function relies on quantifying the shape dissimilarity between the ground truth and the predicted segmentation maps through the Fourier descriptors calculated on their objects, and penalizing this dissimilarity in network training. Different than the previous studies, FourierLoss offers an adaptive loss function with trainable hyperparameters that control the importance of the level of the shape details that the network is enforced to learn in the training process. This control is achieved by the proposed adaptive loss update mechanism, which end-to-end learns the hyperparameters simultaneously with the network weights by backpropagation. As a result of using this mechanism, the network can dynamically change its attention from learning the general outline of an object to learning the details of its contour points, or vice versa, in different training epochs. Working on 2879 computed tomography images of 93 subjects, our experiments revealed that the proposed adaptive shape-aware loss function led to statistically significantly better results for liver segmentation, compared to its counterparts.
</details>
<details>
<summary>摘要</summary>
现代编码器-解码器网络在医疗图像分割任务中变得越来越受欢迎。当这些网络被标准损失函数训练时，它们不会显式地保持图像中对象的形状完整性。然而，这种网络的能力是获得更加准确的结果的关键，特别是在对象和周围环境之间存在低对比度的情况下。为解决这个问题，本研究提出了一种新的形状意识损失函数，我们称之为FourierLoss。这个损失函数基于计算对象的真实值和预测分割图像中对象的形状差异的福氏描述子，并对这种差异进行惩罚。与前一些研究不同，FourierLoss提供了一个可调参数的损失函数，通过反向传播来动态地更新参数。这种机制使得网络可以在训练过程中动态地变换注意力，从学习对象的大致轮廓到学习对象的细节点，或者vice versa。我们在2879个计算Tomography图像上进行了93个subject的实验，结果显示，提出的适应形状意识损失函数在肝 segmentation  task中比其他方法更为 statistically significantly better。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-sparsification-for-deep-neural-networks-with-Bayesian-model-reduction"><a href="#Bayesian-sparsification-for-deep-neural-networks-with-Bayesian-model-reduction" class="headerlink" title="Bayesian sparsification for deep neural networks with Bayesian model reduction"></a>Bayesian sparsification for deep neural networks with Bayesian model reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12095">http://arxiv.org/abs/2309.12095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitrije Marković, Karl J. Friston, Stefan J. Kiebel</li>
<li>for: 本研究的目的是提出一种更高效的权重缩减方法，以优化深度学习模型的计算效率和性能。</li>
<li>methods: 本研究使用了权重缩减技术，包括权重缩减和模型减少。具体来说，研究人员使用了权重缩减的bayesian模型，并采用了黑盒Stochastic Variational Inference（SVI）算法来实现权重缩减。</li>
<li>results: 研究人员通过比较bayesian模型和SVI算法的计算效率和缩减率，发现bayesian模型的计算效率明显高于SVI算法，而且bayesian模型可以更好地缩减模型参数。此外，研究人员还通过应用 bayesian模型和SVI算法于不同的深度学习架构，包括LeNet、Vision Transformers和MLP-Mixers等，发现bayesian模型可以在这些架构上实现更高效的缩减。<details>
<summary>Abstract</summary>
Deep learning's immense capabilities are often constrained by the complexity of its models, leading to an increasing demand for effective sparsification techniques. Bayesian sparsification for deep learning emerges as a crucial approach, facilitating the design of models that are both computationally efficient and competitive in terms of performance across various deep learning applications. The state-of-the-art -- in Bayesian sparsification of deep neural networks -- combines structural shrinkage priors on model weights with an approximate inference scheme based on black-box stochastic variational inference. However, model inversion of the full generative model is exceptionally computationally demanding, especially when compared to standard deep learning of point estimates. In this context, we advocate for the use of Bayesian model reduction (BMR) as a more efficient alternative for pruning of model weights. As a generalization of the Savage-Dickey ratio, BMR allows a post-hoc elimination of redundant model weights based on the posterior estimates under a straightforward (non-hierarchical) generative model. Our comparative study highlights the computational efficiency and the pruning rate of the BMR method relative to the established stochastic variational inference (SVI) scheme, when applied to the full hierarchical generative model. We illustrate the potential of BMR to prune model parameters across various deep learning architectures, from classical networks like LeNet to modern frameworks such as Vision Transformers and MLP-Mixers.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-Task-Cooperative-Learning-via-Searching-for-Flat-Minima"><a href="#Multi-Task-Cooperative-Learning-via-Searching-for-Flat-Minima" class="headerlink" title="Multi-Task Cooperative Learning via Searching for Flat Minima"></a>Multi-Task Cooperative Learning via Searching for Flat Minima</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12090">http://arxiv.org/abs/2309.12090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuping Wu, Le Zhang, Yang Sun, Yuanhan Mo, Thomas Nichols, Bartlomiej W. Papiez</li>
<li>for: 提高医疗图像分析的通用性和个别任务性能</li>
<li>methods: 提出了一种多任务学习的多级优化问题解决方案，使得特征从不同任务中学习共同逻辑</li>
<li>results: 在三个公开 dataset 上验证了方法的效果，比靶前方法更加有优势，表现出合作学习的优势<details>
<summary>Abstract</summary>
Multi-task learning (MTL) has shown great potential in medical image analysis, improving the generalizability of the learned features and the performance in individual tasks. However, most of the work on MTL focuses on either architecture design or gradient manipulation, while in both scenarios, features are learned in a competitive manner. In this work, we propose to formulate MTL as a multi/bi-level optimization problem, and therefore force features to learn from each task in a cooperative approach. Specifically, we update the sub-model for each task alternatively taking advantage of the learned sub-models of the other tasks. To alleviate the negative transfer problem during the optimization, we search for flat minima for the current objective function with regard to features from other tasks. To demonstrate the effectiveness of the proposed approach, we validate our method on three publicly available datasets. The proposed method shows the advantage of cooperative learning, and yields promising results when compared with the state-of-the-art MTL approaches. The code will be available online.
</details>
<details>
<summary>摘要</summary>
多任务学习（MTL）在医疗图像分析中表现出了很大的潜力，提高了学习到的特征的通用性和个别任务的性能。然而，大多数MTL工作都集中在架构设计或梯度修正方面，在这两种情况下，特征是在竞争性下学习的。在这个工作中，我们提议将MTL形式为多/双级优化问题，因此让特征从每个任务中学习到的方式是协力的。specifically，我们在每个任务中更新子模型，利用其他任务的学习到的子模型。为了避免优化过程中的负转移问题，我们通过搜索当前目标函数中特征的平坦顶点来缓解负转移问题。为了证明提议的效果，我们在三个公共可用的数据集上验证了我们的方法。提议的方法表现出了协力学习的优势，并与状态的MTL方法进行比较而显示了承诺的结果。代码将在线上公开。
</details></li>
</ul>
<hr>
<h2 id="Self-Calibrating-Fully-Differentiable-NLOS-Inverse-Rendering"><a href="#Self-Calibrating-Fully-Differentiable-NLOS-Inverse-Rendering" class="headerlink" title="Self-Calibrating, Fully Differentiable NLOS Inverse Rendering"></a>Self-Calibrating, Fully Differentiable NLOS Inverse Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12047">http://arxiv.org/abs/2309.12047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiseok Choi, Inchul Kim, Dongyoung Choi, Julio Marco, Diego Gutierrez, Min H. Kim</li>
<li>For: The paper aims to improve the reconstruction of hidden scenes in non-line-of-sight (NLOS) imaging by introducing a fully-differentiable end-to-end pipeline that self-calibrates imaging parameters during the reconstruction process.* Methods: The paper uses a combination of diffraction-based volumetric NLOS reconstruction, path-space light transport, and a simple ray marching technique to extract detailed, dense sets of surface points and normals of hidden scenes. The pipeline is fully differentiable, allowing for gradient descent optimization of imaging parameters.* Results: The paper demonstrates the robustness of the method to consistently reconstruct geometry and albedo, even under significant noise levels. The end-to-end pipeline is able to self-calibrate imaging parameters and produce high-quality reconstructions without the need for manual selection of filtering functions or parameters.<details>
<summary>Abstract</summary>
Existing time-resolved non-line-of-sight (NLOS) imaging methods reconstruct hidden scenes by inverting the optical paths of indirect illumination measured at visible relay surfaces. These methods are prone to reconstruction artifacts due to inversion ambiguities and capture noise, which are typically mitigated through the manual selection of filtering functions and parameters. We introduce a fully-differentiable end-to-end NLOS inverse rendering pipeline that self-calibrates the imaging parameters during the reconstruction of hidden scenes, using as input only the measured illumination while working both in the time and frequency domains. Our pipeline extracts a geometric representation of the hidden scene from NLOS volumetric intensities and estimates the time-resolved illumination at the relay wall produced by such geometric information using differentiable transient rendering. We then use gradient descent to optimize imaging parameters by minimizing the error between our simulated time-resolved illumination and the measured illumination. Our end-to-end differentiable pipeline couples diffraction-based volumetric NLOS reconstruction with path-space light transport and a simple ray marching technique to extract detailed, dense sets of surface points and normals of hidden scenes. We demonstrate the robustness of our method to consistently reconstruct geometry and albedo, even under significant noise levels.
</details>
<details>
<summary>摘要</summary>
现有的非直视（NLOS）成像方法通过推算光路的媒体映射来重建隐藏的场景。这些方法容易受到重建残像的影响，这些残像通常通过手动选择筛选函数和参数来减轻。我们介绍了一个完全可导的终端到终点NLOS反向渲染管道，该管道在重建隐藏场景时自动调整成像参数，使用直接推算光路来估算隐藏场景中的光学信息，并使用梯度下降来优化成像参数。我们的管道使用干扰基于Diffraction的NLOS成像，并结合路径空间光传输和简单的RAY marching技术来提取隐藏场景的详细、稠密的表面点和法向量。我们示示了我们方法在噪音水平较高时仍能顺利重建场景的稳定性。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Image-Borders-Learning-Feature-Extrapolation-for-Unbounded-Image-Composition"><a href="#Beyond-Image-Borders-Learning-Feature-Extrapolation-for-Unbounded-Image-Composition" class="headerlink" title="Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition"></a>Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12042">http://arxiv.org/abs/2309.12042</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuxiaoyu1104/unic">https://github.com/liuxiaoyu1104/unic</a></li>
<li>paper_authors: Xiaoyu Liu, Ming Liu, Junyi Li, Shuai Liu, Xiaotao Wang, Lei Lei, Wangmeng Zuo</li>
<li>for: 提高图像组合和美观品质，避免图像剪辑方法的局限性。</li>
<li>methods: 提出一种联合框架，包括图像预览帧为输入，并提供不受图像边界限制的视图调整建议，以及通过特征拟合扩展视场来提高视图调整预测精度。</li>
<li>results: 通过对 existed image cropping datasets 进行实验，证明了 UNIC 在无限制的视图调整和图像组合中的效果。源代码、数据集和预训练模型可以在 <a target="_blank" rel="noopener" href="https://github.com/liuxiaoyu1104/UNIC">https://github.com/liuxiaoyu1104/UNIC</a> 上获取。<details>
<summary>Abstract</summary>
For improving image composition and aesthetic quality, most existing methods modulate the captured images by striking out redundant content near the image borders. However, such image cropping methods are limited in the range of image views. Some methods have been suggested to extrapolate the images and predict cropping boxes from the extrapolated image. Nonetheless, the synthesized extrapolated regions may be included in the cropped image, making the image composition result not real and potentially with degraded image quality. In this paper, we circumvent this issue by presenting a joint framework for both unbounded recommendation of camera view and image composition (i.e., UNIC). In this way, the cropped image is a sub-image of the image acquired by the predicted camera view, and thus can be guaranteed to be real and consistent in image quality. Specifically, our framework takes the current camera preview frame as input and provides a recommendation for view adjustment, which contains operations unlimited by the image borders, such as zooming in or out and camera movement. To improve the prediction accuracy of view adjustment prediction, we further extend the field of view by feature extrapolation. After one or several times of view adjustments, our method converges and results in both a camera view and a bounding box showing the image composition recommendation. Extensive experiments are conducted on the datasets constructed upon existing image cropping datasets, showing the effectiveness of our UNIC in unbounded recommendation of camera view and image composition. The source code, dataset, and pretrained models is available at https://github.com/liuxiaoyu1104/UNIC.
</details>
<details>
<summary>摘要</summary>
For improving image composition and aesthetic quality, most existing methods delete unnecessary content near the image borders. However, such image cropping methods are limited in the range of image views. Some methods have been suggested to predict cropping boxes from the extrapolated image. However, the synthesized extrapolated regions may be included in the cropped image, making the image composition result not real and potentially with degraded image quality. In this paper, we overcome this issue by presenting a joint framework for both unbounded recommendation of camera view and image composition (i.e., UNIC). In this way, the cropped image is a sub-image of the image acquired by the predicted camera view, and thus can be guaranteed to be real and consistent in image quality. Specifically, our framework takes the current camera preview frame as input and provides a recommendation for view adjustment, which contains operations unlimited by the image borders, such as zooming in or out and camera movement. To improve the prediction accuracy of view adjustment prediction, we further extend the field of view by feature extrapolation. After one or several times of view adjustments, our method converges and results in both a camera view and a bounding box showing the image composition recommendation. Extensive experiments are conducted on the datasets constructed upon existing image cropping datasets, showing the effectiveness of our UNIC in unbounded recommendation of camera view and image composition. The source code, dataset, and pretrained models are available at https://github.com/liuxiaoyu1104/UNIC.
</details></li>
</ul>
<hr>
<h2 id="BASE-Probably-a-Better-Approach-to-Multi-Object-Tracking"><a href="#BASE-Probably-a-Better-Approach-to-Multi-Object-Tracking" class="headerlink" title="BASE: Probably a Better Approach to Multi-Object Tracking"></a>BASE: Probably a Better Approach to Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12035">http://arxiv.org/abs/2309.12035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Vonheim Larsen, Sigmund Rolfsjord, Daniel Gusland, Jörgen Ahlberg, Kim Mathiassen</li>
<li>for: The paper is written for the field of visual object tracking, specifically to address the lack of probabilistic methods in the leaderboards and to propose a set of pragmatic models to improve the performance of probabilistic trackers.</li>
<li>methods: The paper proposes a new probabilistic tracking algorithm called BASE (Bayesian Approximation Single-hypothesis Estimator), which addresses the challenges of distance in target kinematics, detector confidence, and non-uniform clutter characteristics.</li>
<li>results: The paper achieves state-of-the-art (SOTA) performance on MOT17 and MOT20 without using Re-Id, demonstrating the effectiveness of the proposed approach.Here is the information in Simplified Chinese text:</li>
<li>for: 本文为视觉对象跟踪领域的研究，旨在解决现有的概率方法在领导人员中的缺失，并提出一些实用的模型来提高概率跟踪器的性能。</li>
<li>methods: 本文提出了一种新的概率跟踪算法 called BASE ( bayesian Approximation Single-hypothesis Estimator)，该算法 Addresses 目标动态距离、检测器信任度和非uniform的干扰特征等挑战。</li>
<li>results: 本文在 MOT17 和 MOT20 上达到了 state-of-the-art 性能，不使用 Re-Id，demonstrating 提出的方法的有效性。<details>
<summary>Abstract</summary>
The field of visual object tracking is dominated by methods that combine simple tracking algorithms and ad hoc schemes. Probabilistic tracking algorithms, which are leading in other fields, are surprisingly absent from the leaderboards. We found that accounting for distance in target kinematics, exploiting detector confidence and modelling non-uniform clutter characteristics is critical for a probabilistic tracker to work in visual tracking. Previous probabilistic methods fail to address most or all these aspects, which we believe is why they fall so far behind current state-of-the-art (SOTA) methods (there are no probabilistic trackers in the MOT17 top 100). To rekindle progress among probabilistic approaches, we propose a set of pragmatic models addressing these challenges, and demonstrate how they can be incorporated into a probabilistic framework. We present BASE (Bayesian Approximation Single-hypothesis Estimator), a simple, performant and easily extendible visual tracker, achieving state-of-the-art (SOTA) on MOT17 and MOT20, without using Re-Id. Code will be made available at https://github.com/ffi-no
</details>
<details>
<summary>摘要</summary>
“Visual object tracking 领域由简单追踪算法和对应措施组合所控制。 probabilistic 追踪算法，在其他领域中是领先的，在 visual tracking 中却缺乏表现。我们发现，在目标运动中考虑距离、利用探测器信任度和非均匀杂质特征是critical的。 previous probabilistic methods 无法解决这些问题，我们认为这就是为什么它们落后现有的state-of-the-art（SOTA）方法（MOT17 top 100 中没有 probabilistic 追踪器）。为了推动 probabilistic 方法的进步，我们提出了一些实用的模型，并说明如何将它们集成到 probabilistic 框架中。我们提出了 BASE（Bayesian Approximation Single-hypothesis Estimator），一个简单、高效和易扩展的visual 追踪器，在 MOT17 和 MOT20 中获得了state-of-the-art 成绩，无需使用 Re-Id。我们将在 GitHub 上公开代码。”
</details></li>
</ul>
<hr>
<h2 id="Face-Identity-Aware-Disentanglement-in-StyleGAN"><a href="#Face-Identity-Aware-Disentanglement-in-StyleGAN" class="headerlink" title="Face Identity-Aware Disentanglement in StyleGAN"></a>Face Identity-Aware Disentanglement in StyleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12033">http://arxiv.org/abs/2309.12033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Suwała, Bartosz Wójcik, Magdalena Proszewska, Jacek Tabor, Przemysław Spurek, Marek Śmieja</li>
<li>for: 本文主要用于解决现有 Conditional GANs 模型中的一个问题，即同时修改图像中的一些特征，而不是只修改请求的特征。</li>
<li>methods: 本文提出了一种名为 PluGeN4Faces 的插件，用于修改 face 图像中的特征，同时保持图像的人脸特征不变。该方法通过在 Movie Frames 中提取图像，并使用一种类型的对比损失函数，来让模型将同一个人的图像分组在 latent 空间中相似的地方。</li>
<li>results: 实验表明，PluGeN4Faces 比现有状态的 искус智模型更能减少修改 face 特征所带来的影响。<details>
<summary>Abstract</summary>
Conditional GANs are frequently used for manipulating the attributes of face images, such as expression, hairstyle, pose, or age. Even though the state-of-the-art models successfully modify the requested attributes, they simultaneously modify other important characteristics of the image, such as a person's identity. In this paper, we focus on solving this problem by introducing PluGeN4Faces, a plugin to StyleGAN, which explicitly disentangles face attributes from a person's identity. Our key idea is to perform training on images retrieved from movie frames, where a given person appears in various poses and with different attributes. By applying a type of contrastive loss, we encourage the model to group images of the same person in similar regions of latent space. Our experiments demonstrate that the modifications of face attributes performed by PluGeN4Faces are significantly less invasive on the remaining characteristics of the image than in the existing state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>> conditional GANs frequently used manipulating face image attributes, such as expression, hairstyle, pose, or age. although state-of-the-art models successfully modify requested attributes, simultaneously modify important image characteristics, such as person's identity. in this paper, focus on solving problem by introducing PluGeN4Faces, StyleGAN plugin, explicitly disentangles face attributes from person's identity. our key idea perform training images retrieved movie frames, given person appears various poses different attributes. applying type contrastive loss, encourage model group images same person similar regions latent space. our experiments demonstrate modifications face attributes performed PluGeN4Faces significantly less invasive remaining image characteristics than existing state-of-the-art models.
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Hidden-Realm-Self-supervised-Skeleton-based-Action-Recognition-in-Occluded-Environments"><a href="#Unveiling-the-Hidden-Realm-Self-supervised-Skeleton-based-Action-Recognition-in-Occluded-Environments" class="headerlink" title="Unveiling the Hidden Realm: Self-supervised Skeleton-based Action Recognition in Occluded Environments"></a>Unveiling the Hidden Realm: Self-supervised Skeleton-based Action Recognition in Occluded Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12029">http://arxiv.org/abs/2309.12029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cyfml/opstl">https://github.com/cyfml/opstl</a></li>
<li>paper_authors: Yifei Chen, Kunyu Peng, Alina Roitberg, David Schneider, Jiaming Zhang, Junwei Zheng, Ruiping Liu, Yufan Chen, Kailun Yang, Rainer Stiefelhagen</li>
<li>for: 提高自主 robotic 系统中的动作识别率，考虑到目标 occlusion 的情况。</li>
<li>methods: 提议使用 occluded skeleton 序列 pré-train，然后使用 k-means 聚类（KMeans）对序列嵌入进行分组，并使用 K-nearest-neighbor（KNN）填充 missing skeleton 数据。</li>
<li>results: 对 NTURGB+D 60 和 NTURGB+D 120 的 occluded 版本进行验证，证明了我们的填充方法的效iveness。<details>
<summary>Abstract</summary>
To integrate action recognition methods into autonomous robotic systems, it is crucial to consider adverse situations involving target occlusions. Such a scenario, despite its practical relevance, is rarely addressed in existing self-supervised skeleton-based action recognition methods. To empower robots with the capacity to address occlusion, we propose a simple and effective method. We first pre-train using occluded skeleton sequences, then use k-means clustering (KMeans) on sequence embeddings to group semantically similar samples. Next, we employ K-nearest-neighbor (KNN) to fill in missing skeleton data based on the closest sample neighbors. Imputing incomplete skeleton sequences to create relatively complete sequences as input provides significant benefits to existing skeleton-based self-supervised models. Meanwhile, building on the state-of-the-art Partial Spatio-Temporal Learning (PSTL), we introduce an Occluded Partial Spatio-Temporal Learning (OPSTL) framework. This enhancement utilizes Adaptive Spatial Masking (ASM) for better use of high-quality, intact skeletons. The effectiveness of our imputation methods is verified on the challenging occluded versions of the NTURGB+D 60 and NTURGB+D 120. The source code will be made publicly available at https://github.com/cyfml/OPSTL.
</details>
<details>
<summary>摘要</summary>
要将动作识别方法 integrate 到自主 роботи系统中，需要考虑目标 occlusion 的情况。这种情况尚未在现有的自助学习骨架基于动作识别方法中得到充分考虑。为了赋给机器人更多的能力，我们提出了一种简单有效的方法。我们首先使用 occluded 骨架序列进行预训练，然后使用 K-means 聚类（KMeans）对序列嵌入进行分组。接着，我们使用 K-nearest-neighbor（KNN）来填充 missing 骨架数据，基于最近的样本 neighors。填充不完整的骨架序列，以创建相对完整的输入，对现有骨架基于自助学习模型具有重要的优化。此外，我们在 Partial Spatio-Temporal Learning（PSTL）的基础之上，引入 Occluded Partial Spatio-Temporal Learning（OPSTL）框架。这种改进使用 Adaptive Spatial Masking（ASM）来更好地利用高质量、完整的骨架。我们的填充方法的效果被证明在NTURGB+D 60 和 NTURGB+D 120 的 occluded 版本上。源代码将在 GitHub 上公开，可以通过 https://github.com/cyfml/OPSTL 获取。
</details></li>
</ul>
<hr>
<h2 id="Precision-in-Building-Extraction-Comparing-Shallow-and-Deep-Models-using-LiDAR-Data"><a href="#Precision-in-Building-Extraction-Comparing-Shallow-and-Deep-Models-using-LiDAR-Data" class="headerlink" title="Precision in Building Extraction: Comparing Shallow and Deep Models using LiDAR Data"></a>Precision in Building Extraction: Comparing Shallow and Deep Models using LiDAR Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12027">http://arxiv.org/abs/2309.12027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Sulaiman, Mina Farmanbar, Ahmed Nabil Belbachir, Chunming Rong</li>
<li>For: 本文使用 LiDAR 数据进行检测建筑物的深度学习模型，以提高建筑物的分割精度。* Methods: 本文使用了 shallow models，并使用了边界面掩模来提高 BIoU 分数。* Results:  shallow models 在 IoU 分数上出perform deep learning models 8%，但是 deep learning models 在 BIoU 分数上表现更好。边界面掩模可以提高 BIoU 分数4%。 LightGBM 表现比 RF 和 XGBoost 更好。<details>
<summary>Abstract</summary>
Building segmentation is essential in infrastructure development, population management, and geological observations. This article targets shallow models due to their interpretable nature to assess the presence of LiDAR data for supervised segmentation. The benchmark data used in this article are published in NORA MapAI competition for deep learning model. Shallow models are compared with deep learning models based on Intersection over Union (IoU) and Boundary Intersection over Union (BIoU). In the proposed work, boundary masks from the original mask are generated to improve the BIoU score, which relates to building shapes' borderline. The influence of LiDAR data is tested by training the model with only aerial images in task 1 and a combination of aerial and LiDAR data in task 2 and then compared. shallow models outperform deep learning models in IoU by 8% using aerial images (task 1) only and 2% in combined aerial images and LiDAR data (task 2). In contrast, deep learning models show better performance on BIoU scores. Boundary masks improve BIoU scores by 4% in both tasks. Light Gradient-Boosting Machine (LightGBM) performs better than RF and Extreme Gradient Boosting (XGBoost).
</details>
<details>
<summary>摘要</summary>
In the proposed work, boundary masks are generated from the original mask to improve the BIoU score, which relates to building shapes' borderlines. The influence of LiDAR data is tested by training the model with only aerial images in Task 1 and a combination of aerial and LiDAR data in Task 2, and then comparing the results.Shallow models outperform deep learning models in IoU by 8% using aerial images (Task 1) only and 2% in combined aerial images and LiDAR data (Task 2). In contrast, deep learning models show better performance on BIoU scores. Boundary masks improve BIoU scores by 4% in both tasks. Light Gradient-Boosting Machine (LightGBM) performs better than RF and Extreme Gradient Boosting (XGBoost).
</details></li>
</ul>
<hr>
<h2 id="Convolution-and-Attention-Mixer-for-Synthetic-Aperture-Radar-Image-Change-Detection"><a href="#Convolution-and-Attention-Mixer-for-Synthetic-Aperture-Radar-Image-Change-Detection" class="headerlink" title="Convolution and Attention Mixer for Synthetic Aperture Radar Image Change Detection"></a>Convolution and Attention Mixer for Synthetic Aperture Radar Image Change Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12010">http://arxiv.org/abs/2309.12010</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/summitgao/camixer">https://github.com/summitgao/camixer</a></li>
<li>paper_authors: Haopeng Zhang, Zijing Lin, Feng Gao, Junyu Dong, Qian Du, Heng-Chao Li</li>
<li>for:  This paper focuses on improving the performance of synthetic aperture radar (SAR) change detection by incorporating global attention mechanism into Transformer-like architecture.</li>
<li>methods:  The proposed method, called Convolution and Attention Mixer (CAMixer), combines self-attention with shift convolution in a parallel way, and adopts a gating mechanism in the feed-forward network to enhance the non-linear feature transformation.</li>
<li>results:  The proposed CAMixer achieves superior performance in SAR change detection compared to existing CNN-based methods, as demonstrated by extensive experiments conducted on three SAR datasets.<details>
<summary>Abstract</summary>
Synthetic aperture radar (SAR) image change detection is a critical task and has received increasing attentions in the remote sensing community. However, existing SAR change detection methods are mainly based on convolutional neural networks (CNNs), with limited consideration of global attention mechanism. In this letter, we explore Transformer-like architecture for SAR change detection to incorporate global attention. To this end, we propose a convolution and attention mixer (CAMixer). First, to compensate the inductive bias for Transformer, we combine self-attention with shift convolution in a parallel way. The parallel design effectively captures the global semantic information via the self-attention and performs local feature extraction through shift convolution simultaneously. Second, we adopt a gating mechanism in the feed-forward network to enhance the non-linear feature transformation. The gating mechanism is formulated as the element-wise multiplication of two parallel linear layers. Important features can be highlighted, leading to high-quality representations against speckle noise. Extensive experiments conducted on three SAR datasets verify the superior performance of the proposed CAMixer. The source codes will be publicly available at https://github.com/summitgao/CAMixer .
</details>
<details>
<summary>摘要</summary>
“干扰天线射频图像变化检测（SAR）是远感社区中的一个重要任务，但现有的SAR变化检测方法主要基于卷积神经网络（CNN），对于全球注意机制的考虑有限。在本封信中，我们探索了Transformer-like架构来进行SAR变化检测，以内置全球注意机制。为此，我们提出了一个混合卷积和注意混合器（CAMixer）。首先，为了补偿对Transformer的传播偏见，我们在平行的方式结合了自我注意和偏移核函数。这样的平行设计可以同时捕捉全球semantic信息和本地特征特性，从而实现高质量的特征抽象。其次，我们在对待网络中引入了阈值机制，以增强非线性特征转换。这个阈值机制是通过两个平行的线性层进行元素ごとの多项式乘法。重要的特征可以得到高质量的表现，抵制杂音。实验结果显示，我们的CAMixer具有较高的检测性和稳定性，并且可以实现高质量的特征抽象。我们将代码公开于https://github.com/summitgao/CAMixer。”
</details></li>
</ul>
<hr>
<h2 id="Elevating-Skeleton-Based-Action-Recognition-with-Efficient-Multi-Modality-Self-Supervision"><a href="#Elevating-Skeleton-Based-Action-Recognition-with-Efficient-Multi-Modality-Self-Supervision" class="headerlink" title="Elevating Skeleton-Based Action Recognition with Efficient Multi-Modality Self-Supervision"></a>Elevating Skeleton-Based Action Recognition with Efficient Multi-Modality Self-Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12009">http://arxiv.org/abs/2309.12009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiping Wei, Kunyu Peng, Alina Roitberg, Jiaming Zhang, Junwei Zheng, Ruiping Liu, Yufan Chen, Kailun Yang, Rainer Stiefelhagen</li>
<li>for: 本研究旨在提高人体动作识别的自助学习表示。</li>
<li>methods: 我们首先提出了一种偏知交换模块（IKEM），以避免低性能Modalities之间的偏知传递。然后，我们提出了三种新的Modalities，以增强多modalities之间的补充信息。最后，我们提出了一种新的教师生框架，以在引入新Modalities时保持效率，并将第二 modalities中的知识透传到必要modalities中，基于约束anchors, positives和negatives的关系。</li>
<li>results: 实验结果表明，我们的方法有效地提高了skeleton基于多modalities数据的人体动作识别性能。<details>
<summary>Abstract</summary>
Self-supervised representation learning for human action recognition has developed rapidly in recent years. Most of the existing works are based on skeleton data while using a multi-modality setup. These works overlooked the differences in performance among modalities, which led to the propagation of erroneous knowledge between modalities while only three fundamental modalities, i.e., joints, bones, and motions are used, hence no additional modalities are explored.   In this work, we first propose an Implicit Knowledge Exchange Module (IKEM) which alleviates the propagation of erroneous knowledge between low-performance modalities. Then, we further propose three new modalities to enrich the complementary information between modalities. Finally, to maintain efficiency when introducing new modalities, we propose a novel teacher-student framework to distill the knowledge from the secondary modalities into the mandatory modalities considering the relationship constrained by anchors, positives, and negatives, named relational cross-modality knowledge distillation. The experimental results demonstrate the effectiveness of our approach, unlocking the efficient use of skeleton-based multi-modality data. Source code will be made publicly available at https://github.com/desehuileng0o0/IKEM.
</details>
<details>
<summary>摘要</summary>
自我监睹表示学习人体动作识别在最近几年内得到了迅速发展。大多数现有工作基于骨骼数据，使用多模态设置。这些工作忽视了不同模态之间的性能差异，导致错误知识的传播 между模态，只有三种基本模态，即关节、骨骼和运动，因此没有探索其他模态。  在这项工作中，我们首先提出了隐式知识交换模块（IKEM），以消除低性能模态之间的错误知识传播。然后，我们进一步提出了三种新的模态，以增加多模态之间的补充信息。最后，为保持效率而不是引入新模态，我们提出了一种新的教师-学生框架，通过约束anchors、正例和负例之间的关系，将次要模态中的知识透传到必要模态中，称为关系跨模态知识采样。实验结果表明我们的方法的效果，使得骨骼基于多模态数据的高效使用成为可能。源代码将在https://github.com/desehuileng0o0/IKEM公开。
</details></li>
</ul>
<hr>
<h2 id="Identification-of-pneumonia-on-chest-x-ray-images-through-machine-learning"><a href="#Identification-of-pneumonia-on-chest-x-ray-images-through-machine-learning" class="headerlink" title="Identification of pneumonia on chest x-ray images through machine learning"></a>Identification of pneumonia on chest x-ray images through machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11995">http://arxiv.org/abs/2309.11995</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Nabeel-105/Covid-19-and-Pneumonia-Detection-Using-Chest-Xray-Images-Full-Desktop-Application-">https://github.com/Nabeel-105/Covid-19-and-Pneumonia-Detection-Using-Chest-Xray-Images-Full-Desktop-Application-</a></li>
<li>paper_authors: Eduardo Augusto Roeder</li>
<li>for: 这个研究的目的是开发一种用于识别胸部X光图像中的肺炎病例的软件。</li>
<li>methods: 这个研究使用了机器学习技术，特别是传输学习技术，并使用了一个计算模型来训练。</li>
<li>results: 经过训练后，模型可以准确地识别胸部X光图像中的肺炎病例，达到了98%的敏感性和97.3%的特异性。<details>
<summary>Abstract</summary>
Pneumonia is the leading infectious cause of infant death in the world. When identified early, it is possible to alter the prognosis of the patient, one could use imaging exams to help in the diagnostic confirmation. Performing and interpreting the exams as soon as possible is vital for a good treatment, with the most common exam for this pathology being chest X-ray. The objective of this study was to develop a software that identify the presence or absence of pneumonia in chest radiographs. The software was developed as a computational model based on machine learning using transfer learning technique. For the training process, images were collected from a database available online with children's chest X-rays images taken at a hospital in China. After training, the model was then exposed to new images, achieving relevant results on identifying such pathology, reaching 98% sensitivity and 97.3% specificity for the sample used for testing. It can be concluded that it is possible to develop a software that identifies pneumonia in chest X-ray images.
</details>
<details>
<summary>摘要</summary>
全球最主要的感染性新生儿死亡原因是肺炎，早期诊断可以改善病人的结局。使用影像检查可以帮助诊断，其中最常用的检查是胸部X射线。本研究的目标是开发一种可以在胸部X射线图像中识别肺炎的软件。该软件是基于机器学习技术的计算模型，使用了传输学习技术进行训练。训练过程中，图像来自中国医院的儿童胸部X射线图像库。经训练后，模型被推出到新图像上，实现了识别肺炎的相关结果，具有98%的敏感度和97.3%的特异性。可以确定，可以开发一种识别肺炎在胸部X射线图像中的软件。
</details></li>
</ul>
<hr>
<h2 id="Neural-Stochastic-Screened-Poisson-Reconstruction"><a href="#Neural-Stochastic-Screened-Poisson-Reconstruction" class="headerlink" title="Neural Stochastic Screened Poisson Reconstruction"></a>Neural Stochastic Screened Poisson Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11993">http://arxiv.org/abs/2309.11993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silvia Sellán, Alec Jacobson</li>
<li>for:  reconstruction of a surface from a point cloud</li>
<li>methods:  neural network with Poisson smoothness prior</li>
<li>results:  addresses limitations of existing work and can be fully integrated into the 3D scanning pipeline<details>
<summary>Abstract</summary>
Reconstructing a surface from a point cloud is an underdetermined problem. We use a neural network to study and quantify this reconstruction uncertainty under a Poisson smoothness prior. Our algorithm addresses the main limitations of existing work and can be fully integrated into the 3D scanning pipeline, from obtaining an initial reconstruction to deciding on the next best sensor position and updating the reconstruction upon capturing more data.
</details>
<details>
<summary>摘要</summary>
重建表面从点云是一个不充分定义的问题。我们使用神经网络来研究和评估这种重建不确定性，采用波尼尔平滑性先验来做估计。我们的算法解决了现有工作的主要局限性，可以全面地整合到3D扫描管道中，从获取初始重建到决定下一个感知器位置并更新重建。
</details></li>
</ul>
<hr>
<h2 id="Crop-Row-Switching-for-Vision-Based-Navigation-A-Comprehensive-Approach-for-Efficient-Crop-Field-Navigation"><a href="#Crop-Row-Switching-for-Vision-Based-Navigation-A-Comprehensive-Approach-for-Efficient-Crop-Field-Navigation" class="headerlink" title="Crop Row Switching for Vision-Based Navigation: A Comprehensive Approach for Efficient Crop Field Navigation"></a>Crop Row Switching for Vision-Based Navigation: A Comprehensive Approach for Efficient Crop Field Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11989">http://arxiv.org/abs/2309.11989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajitha de Silva, Grzegorz Cielniak, Junfeng Gao</li>
<li>for: 这个论文旨在提出一种基于视觉的移动机器人 navigate 方法，可以在耕地中横跨多个行。</li>
<li>methods: 该方法使用单个前置摄像头和深度数据进行RGB图像分割，以探测行末和下一行的重新入口点。</li>
<li>results: 在实际的甘蔗ibe字段中，该方法能够成功地使移动机器人从一行到下一行 navigate， WITH median errors 为19.25 cm和6.77°。<details>
<summary>Abstract</summary>
Vision-based mobile robot navigation systems in arable fields are mostly limited to in-row navigation. The process of switching from one crop row to the next in such systems is often aided by GNSS sensors or multiple camera setups. This paper presents a novel vision-based crop row-switching algorithm that enables a mobile robot to navigate an entire field of arable crops using a single front-mounted camera. The proposed row-switching manoeuvre uses deep learning-based RGB image segmentation and depth data to detect the end of the crop row, and re-entry point to the next crop row which would be used in a multi-state row switching pipeline. Each state of this pipeline use visual feedback or wheel odometry of the robot to successfully navigate towards the next crop row. The proposed crop row navigation pipeline was tested in a real sugar beet field containing crop rows with discontinuities, varying light levels, shadows and irregular headland surfaces. The robot could successfully exit from one crop row and re-enter the next crop row using the proposed pipeline with absolute median errors averaging at 19.25 cm and 6.77{\deg} for linear and rotational steps of the proposed manoeuvre.
</details>
<details>
<summary>摘要</summary>
视觉基于移动机器人Navigation系统通常仅限于行间导航。在这些系统中，从一行农作物到下一行的过程经常受GNSS传感器或多个摄像头的帮助。本文介绍了一种新的视觉基于的农作物行转换算法，使得移动机器人可以使用单个前置摄像头探测整个农作物场。提议的行转换举动使用深度学习基于RGB图像分割和深度数据探测农作物行的结束和下一行的重新入口点，并在多个状态的管道中使用视觉反馈或机器人轮胎的运动来成功导航到下一行农作物。这个管道在实际的甘蔗ibeet场中进行测试，包括具有不连续的农作物行、不同的照明水平、阴影和不规则的机器人进场面。机器人使用提议的管道成功地离开了一行农作物并重新进入下一行农作物， median误差平均值为19.25cm和6.77度 для直线和旋转步骤。
</details></li>
</ul>
<hr>
<h2 id="ZS6D-Zero-shot-6D-Object-Pose-Estimation-using-Vision-Transformers"><a href="#ZS6D-Zero-shot-6D-Object-Pose-Estimation-using-Vision-Transformers" class="headerlink" title="ZS6D: Zero-shot 6D Object Pose Estimation using Vision Transformers"></a>ZS6D: Zero-shot 6D Object Pose Estimation using Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11986">http://arxiv.org/abs/2309.11986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Ausserlechner, David Haberger, Stefan Thalhammer, Jean-Baptiste Weibel, Markus Vincze</li>
<li>for: recognize diverse objects in complex and unconstrained real-world scenarios</li>
<li>methods: use pre-trained Vision Transformers (ViT) to extract visual descriptors, and RANSAC-based PnP to estimate object’s 6D pose</li>
<li>results: improve the Average Recall on three datasets (LMO, YCBV, and TLESS) compared to two state-of-the-art novel object 6D pose estimation methods, without the need for task-specific fine-tuning.<details>
<summary>Abstract</summary>
As robotic systems increasingly encounter complex and unconstrained real-world scenarios, there is a demand to recognize diverse objects. The state-of-the-art 6D object pose estimation methods rely on object-specific training and therefore do not generalize to unseen objects. Recent novel object pose estimation methods are solving this issue using task-specific fine-tuned CNNs for deep template matching. This adaptation for pose estimation still requires expensive data rendering and training procedures. MegaPose for example is trained on a dataset consisting of two million images showing 20,000 different objects to reach such generalization capabilities. To overcome this shortcoming we introduce ZS6D, for zero-shot novel object 6D pose estimation. Visual descriptors, extracted using pre-trained Vision Transformers (ViT), are used for matching rendered templates against query images of objects and for establishing local correspondences. These local correspondences enable deriving geometric correspondences and are used for estimating the object's 6D pose with RANSAC-based PnP. This approach showcases that the image descriptors extracted by pre-trained ViTs are well-suited to achieve a notable improvement over two state-of-the-art novel object 6D pose estimation methods, without the need for task-specific fine-tuning. Experiments are performed on LMO, YCBV, and TLESS. In comparison to one of the two methods we improve the Average Recall on all three datasets and compared to the second method we improve on two datasets.
</details>
<details>
<summary>摘要</summary>
As robotic systems increasingly encounter complex and unconstrained real-world scenarios, there is a growing need to recognize diverse objects. However, current state-of-the-art 6D object pose estimation methods rely on object-specific training and do not generalize well to unseen objects. To address this issue, recent novel object pose estimation methods have used task-specific fine-tuned convolutional neural networks (CNNs) for deep template matching. However, this approach still requires expensive data rendering and training procedures.To overcome this limitation, we propose a novel zero-shot method for 6D object pose estimation, called ZS6D. Our approach uses visual descriptors extracted using pre-trained Vision Transformers (ViT) to match rendered templates against query images of objects, and establish local correspondences. These local correspondences are then used to estimate the object's 6D pose using RANSAC-based Perspective-n-Point (PnP).Experiments on three datasets (LMO, YCBV, and TLESS) show that our approach achieves a notable improvement over two state-of-the-art novel object 6D pose estimation methods, without the need for task-specific fine-tuning. Specifically, we improve the Average Recall on all three datasets compared to one of the two methods, and improve on two datasets compared to the second method.Here is the translation in Simplified Chinese:随着机器人系统遇到越来越复杂的实际场景，需要认izers多种物体。现状下的6D物体pose估计方法都是基于物体特定的训练，不能泛化到未看过的物体。为了解决这个问题，最新的novel object pose estimation方法都是使用任务特定的深度学习模型进行深度模板匹配。但是，这种方法仍需要费时的数据渲染和训练过程。为了突破这个局限性，我们提出了一种 zeroshot的6D物体pose估计方法，即ZS6D。我们的方法使用预训练的Vision Transformer（ViT）提取的视觉描述符来匹配渲染的模板和查询图像，并建立地方匹配。这些地方匹配然后用RANSAC基于Perspective-n-Point（PnP）来估计物体的6Dpose。在LMO、YCBV和TLESS三个dataset上进行了实验，我们发现我们的方法可以不需要任务特定的微调，就可以在这三个dataset上达到较好的性能。具体来说，我们在这三个dataset上的平均回归率都高于一个方法，并在两个dataset上高于另一个方法。
</details></li>
</ul>
<hr>
<h2 id="NeuralLabeling-A-versatile-toolset-for-labeling-vision-datasets-using-Neural-Radiance-Fields"><a href="#NeuralLabeling-A-versatile-toolset-for-labeling-vision-datasets-using-Neural-Radiance-Fields" class="headerlink" title="NeuralLabeling: A versatile toolset for labeling vision datasets using Neural Radiance Fields"></a>NeuralLabeling: A versatile toolset for labeling vision datasets using Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11966">http://arxiv.org/abs/2309.11966</a></li>
<li>repo_url: None</li>
<li>paper_authors: Floris Erich, Naoya Chiba, Yusuke Yoshiyasu, Noriaki Ando, Ryo Hanai, Yukiyasu Domae</li>
<li>for: 本研究旨在提出一种基于Neural Radiance Fields（NeRF）的图像标注方法和工具集，用于生成分割图、可用性图、2D bounding box、3D bounding box、6DOF对象位置、深度图和物体mesh等。</li>
<li>methods: 本研究使用NeRF作为渲染器，通过使用多视点图像输入和3D空间工具进行标注，并利用图像内容和几何特征（如 occlusion）来提高标注精度。</li>
<li>results: 在对30000帧透明物体RGB和噪音深度图数据集进行训练后，使用 annotated depth maps 进行监督训练的深度神经网络实现了更高的重建性能，比之前使用弱监督法则更高。<details>
<summary>Abstract</summary>
We present NeuralLabeling, a labeling approach and toolset for annotating a scene using either bounding boxes or meshes and generating segmentation masks, affordance maps, 2D bounding boxes, 3D bounding boxes, 6DOF object poses, depth maps and object meshes. NeuralLabeling uses Neural Radiance Fields (NeRF) as renderer, allowing labeling to be performed using 3D spatial tools while incorporating geometric clues such as occlusions, relying only on images captured from multiple viewpoints as input. To demonstrate the applicability of NeuralLabeling to a practical problem in robotics, we added ground truth depth maps to 30000 frames of transparent object RGB and noisy depth maps of glasses placed in a dishwasher captured using an RGBD sensor, yielding the Dishwasher30k dataset. We show that training a simple deep neural network with supervision using the annotated depth maps yields a higher reconstruction performance than training with the previously applied weakly supervised approach.
</details>
<details>
<summary>摘要</summary>
我们提出了NeuralLabeling，一种Scene Labeling的方法和工具集，可以使用矩形框或网格来标识场景，并生成分类图、可用性图、2D矩形框、3D矩形框、6DOF物体位置、深度图和物体网格。NeuralLabeling使用Neural Radiance Fields（NeRF）作为渲染器，允许使用3D空间工具进行标识，同时考虑到隐藏和 occlusion 的几何假设，仅基于多个视角的图像作为输入。为了评估NeuralLabeling在 robotics 中的实用性，我们将添加了透明物体RGB和杂音深度图档案，创建了Dishwasher30k数据集。我们显示了，对于训练一个简单的深度神经网络，使用这些标识的深度图作为超级训练可以获得更高的重建性能，比过去的弱种超级训练方法。
</details></li>
</ul>
<hr>
<h2 id="Ego3DPose-Capturing-3D-Cues-from-Binocular-Egocentric-Views"><a href="#Ego3DPose-Capturing-3D-Cues-from-Binocular-Egocentric-Views" class="headerlink" title="Ego3DPose: Capturing 3D Cues from Binocular Egocentric Views"></a>Ego3DPose: Capturing 3D Cues from Binocular Egocentric Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11962">http://arxiv.org/abs/2309.11962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taeho Kang, Kyungjin Lee, Jinrui Zhang, Youngki Lee</li>
<li>for:  Egocentric 3D pose reconstruction system</li>
<li>methods:  Two novel approaches: 1) two-path network architecture with independent pose estimation for each limb, and 2) perspective-aware representation using trigonometry to estimate 3D orientation of limbs.</li>
<li>results:  Outperforms state-of-the-art models by 23.1% in MPJPE reduction in the UnrealEgo dataset, with superior performance across a range of scenarios and challenges.<details>
<summary>Abstract</summary>
We present Ego3DPose, a highly accurate binocular egocentric 3D pose reconstruction system. The binocular egocentric setup offers practicality and usefulness in various applications, however, it remains largely under-explored. It has been suffering from low pose estimation accuracy due to viewing distortion, severe self-occlusion, and limited field-of-view of the joints in egocentric 2D images. Here, we notice that two important 3D cues, stereo correspondences, and perspective, contained in the egocentric binocular input are neglected. Current methods heavily rely on 2D image features, implicitly learning 3D information, which introduces biases towards commonly observed motions and leads to low overall accuracy. We observe that they not only fail in challenging occlusion cases but also in estimating visible joint positions. To address these challenges, we propose two novel approaches. First, we design a two-path network architecture with a path that estimates pose per limb independently with its binocular heatmaps. Without full-body information provided, it alleviates bias toward trained full-body distribution. Second, we leverage the egocentric view of body limbs, which exhibits strong perspective variance (e.g., a significantly large-size hand when it is close to the camera). We propose a new perspective-aware representation using trigonometry, enabling the network to estimate the 3D orientation of limbs. Finally, we develop an end-to-end pose reconstruction network that synergizes both techniques. Our comprehensive evaluations demonstrate that Ego3DPose outperforms state-of-the-art models by a pose estimation error (i.e., MPJPE) reduction of 23.1% in the UnrealEgo dataset. Our qualitative results highlight the superiority of our approach across a range of scenarios and challenges.
</details>
<details>
<summary>摘要</summary>
我们介绍Ego3DPose，一种高度准确的双目 egocentric 3D姿态重建系统。双目 egocentric 设置提供了实用性和有用性，但它尚未得到充分探索。它因视图扭曲、严重的自遮掩和 Egocentric 2D 图像中关节的视场有限而受到低姿态估计精度的影响。我们注意到，在 egocentric 双目输入中含有两种重要的3D准确度信息：立体匹配和投影。现有方法强调2D图像特征，潜在地学习3D信息，导致对常见动作的偏好和全局精度低下。我们发现它们不仅在困难的遮掩情况下失败，而且在可见关节位置的估计也失败。为解决这些挑战，我们提出了两个新的方法。首先，我们设计了一种两路网络架构，其中一路用于独立地估计每个肢体的姿态，使用双目热图。无需全身信息提供，这种方法减少了对训练全身份布的偏好。其次，我们利用 egocentric 视角中的身体部分，其中具有强大的投影变化（例如，相对较大的手在相机较近时）。我们提出了一种新的投影意识表示，使得网络能够估计肢体的3D方向。最后，我们开发了一个综合的端到端姿态重建网络，将两种技术相结合。我们对 UnrealEgo 数据集进行了广泛的评估，并证明Ego3DPose 相比 estado-of-the-art 模型，MPJPE 估计误差降低23.1%。我们的质量结果表明我们的方法在各种情况和挑战中具有优势。
</details></li>
</ul>
<hr>
<h2 id="A-Study-of-Forward-Forward-Algorithm-for-Self-Supervised-Learning"><a href="#A-Study-of-Forward-Forward-Algorithm-for-Self-Supervised-Learning" class="headerlink" title="A Study of Forward-Forward Algorithm for Self-Supervised Learning"></a>A Study of Forward-Forward Algorithm for Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11955">http://arxiv.org/abs/2309.11955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Brenig, Radu Timofte</li>
<li>for: 本研究是 investigate the performance of forward-forward algorithm for self-supervised representation learning, and provide insights into the learned representation spaces.</li>
<li>methods: 本研究使用了 four standard datasets (MNIST, F-MNIST, SVHN, CIFAR-10) and three commonly used self-supervised representation learning techniques (rotation, flip, jigsaw) to compare the performance of forward-forward algorithm and backpropagation.</li>
<li>results: 研究发现，forward-forward algorithm在(self-)supervised training中与backpropagation相当，但在所有 studied settings中的转移性能却明显落后。这可能由多种因素引起，包括每层有独立损失函数和forward-forward paradigm中的自tek抽象学习方法。相比backpropagation，forward-forward algorithm更注重边界和抛弃一些无用于做出决策的信息，这会妨碍自然语言处理的表征学习目标。<details>
<summary>Abstract</summary>
Self-supervised representation learning has seen remarkable progress in the last few years, with some of the recent methods being able to learn useful image representations without labels. These methods are trained using backpropagation, the de facto standard. Recently, Geoffrey Hinton proposed the forward-forward algorithm as an alternative training method. It utilizes two forward passes and a separate loss function for each layer to train the network without backpropagation.   In this study, for the first time, we study the performance of forward-forward vs. backpropagation for self-supervised representation learning and provide insights into the learned representation spaces. Our benchmark employs four standard datasets, namely MNIST, F-MNIST, SVHN and CIFAR-10, and three commonly used self-supervised representation learning techniques, namely rotation, flip and jigsaw.   Our main finding is that while the forward-forward algorithm performs comparably to backpropagation during (self-)supervised training, the transfer performance is significantly lagging behind in all the studied settings. This may be caused by a combination of factors, including having a loss function for each layer and the way the supervised training is realized in the forward-forward paradigm. In comparison to backpropagation, the forward-forward algorithm focuses more on the boundaries and drops part of the information unnecessary for making decisions which harms the representation learning goal. Further investigation and research are necessary to stabilize the forward-forward strategy for self-supervised learning, to work beyond the datasets and configurations demonstrated by Geoffrey Hinton.
</details>
<details>
<summary>摘要</summary>
自我监督学习在最近几年内取得了非常出色的进步，一些最新的方法可以在无标签情况下学习有用的图像表示。这些方法通过反向传播来进行训练，反向传播是现今标准的训练方法。在这一研究中，我们首次比较了前向前法和反向传播两种训练方法的性能，并对学习的表示空间提供了深入的探讨。我们的标准测试集包括MNIST、F-MNIST、SVHN和CIFAR-10等四个数据集，以及rotation、flip和jigsaw等三种常用的自我监督表示学习技术。我们的主要发现是，虽然前向前法和反向传播在自我监督训练中表现相似，但在所有研究情况下，转移性能明显落后。这可能是由多种因素共同影响的，包括每层有自己的损失函数以及在前向前法中实现自我监督训练的方式。相比反向传播，前向前法更注重边缘和抛弃一些无用于做出决定的信息，这对图像表示学习的目标产生了负面影响。进一步的研究和调查是必要的，以稳定前向前法在自我监督学习中的应用，并在不同的数据集和配置下进行更广泛的探索。
</details></li>
</ul>
<hr>
<h2 id="Fully-Transformer-Equipped-Architecture-for-End-to-End-Referring-Video-Object-Segmentation"><a href="#Fully-Transformer-Equipped-Architecture-for-End-to-End-Referring-Video-Object-Segmentation" class="headerlink" title="Fully Transformer-Equipped Architecture for End-to-End Referring Video Object Segmentation"></a>Fully Transformer-Equipped Architecture for End-to-End Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11933">http://arxiv.org/abs/2309.11933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Li, Yu Zhang, Li Yuan, Xianghua Xu</li>
<li>for: 这篇论文是为了解决视频对话引用（RVOS）问题，即根据自然语言查询语义地 segment 视频中的对象。</li>
<li>methods: 该论文提出了一种基于 transformer 完全架构（FTEA）的解决方案，即将 RVOS 任务看作是一个 mask 序列学习问题，对所有视频中的对象进行候选对象的搜索和学习。</li>
<li>results: 实验结果表明，该方法在三个 benchmark 上表现出色，例如，在 A2D Sentences 和 J-HMDB Sentences 上达到了 45.1% 和 38.7% 的 mAP 分数，在 Ref-YouTube-VOS 上达到了 56.6% 的 $\mathcal{J&amp;F}$ 分数。特别是，与最佳候选方法相比，该方法在 P$@$0.5 上具有了 2.1% 和 3.2% 的提升，在 $\mathcal{J}$ 上具有了 2.9% 的提升。<details>
<summary>Abstract</summary>
Referring Video Object Segmentation (RVOS) requires segmenting the object in video referred by a natural language query. Existing methods mainly rely on sophisticated pipelines to tackle such cross-modal task, and do not explicitly model the object-level spatial context which plays an important role in locating the referred object. Therefore, we propose an end-to-end RVOS framework completely built upon transformers, termed \textit{Fully Transformer-Equipped Architecture} (FTEA), which treats the RVOS task as a mask sequence learning problem and regards all the objects in video as candidate objects. Given a video clip with a text query, the visual-textual features are yielded by encoder, while the corresponding pixel-level and word-level features are aligned in terms of semantic similarity. To capture the object-level spatial context, we have developed the Stacked Transformer, which individually characterizes the visual appearance of each candidate object, whose feature map is decoded to the binary mask sequence in order directly. Finally, the model finds the best matching between mask sequence and text query. In addition, to diversify the generated masks for candidate objects, we impose a diversity loss on the model for capturing more accurate mask of the referred object. Empirical studies have shown the superiority of the proposed method on three benchmarks, e.g., FETA achieves 45.1% and 38.7% in terms of mAP on A2D Sentences (3782 videos) and J-HMDB Sentences (928 videos), respectively; it achieves 56.6% in terms of $\mathcal{J\&F}$ on Ref-YouTube-VOS (3975 videos and 7451 objects). Particularly, compared to the best candidate method, it has a gain of 2.1% and 3.2% in terms of P$@$0.5 on the former two, respectively, while it has a gain of 2.9% in terms of $\mathcal{J}$ on the latter one.
</details>
<details>
<summary>摘要</summary>
参考视频对象 segmentation（RVOS）需要将视频中的对象与自然语言查询相关联。现有方法主要依靠复杂的管道来解决这种跨模态任务，并未直接模型对象水平的空间上下文，这上下文在定位引用对象中扮演重要角色。因此，我们提出了一个 completel y built upon transformers 的框架，称为 Fully Transformer-Equipped Architecture（FTEA），它将 RVOS 任务视为面征序列学习问题，并将所有视频中的对象视为候选对象。给定一个视频剪辑和自然语言查询，视觉语言特征是通过Encoder生成的，而对应的像素级和单词级特征则是在semantic similarity的基础上对准。为了捕捉对象水平的空间上下文，我们开发了堆叠transformer，它可以个别地描述每个候选对象的视觉特征，并将其特征图直接解码到二进制mask sequence中。最后，模型会找到与文本查询最佳匹配的mask sequence。此外，为了捕捉更加准确的mask，我们对模型进行多样性损失，以便在候选对象中捕捉更多的详细信息。实验表明，我们的方法在三个标准准的benchmark上表现出色，例如，FETA在A2D Sentences（3782个视频）和J-HMDB Sentences（928个视频）上的mAP分别达到45.1%和38.7%，在Ref-YouTube-VOS（3975个视频和7451个对象）上的$\mathcal{J\&F}$分别达到56.6%。特别是，相比最佳候选方法，FETA在前两个benchmark上的P$@$0.5分别提高了2.1%和3.2%，而在Ref-YouTube-VOS上的$\mathcal{J}$分别提高了2.9%。
</details></li>
</ul>
<hr>
<h2 id="Bridging-the-Gap-Learning-Pace-Synchronization-for-Open-World-Semi-Supervised-Learning"><a href="#Bridging-the-Gap-Learning-Pace-Synchronization-for-Open-World-Semi-Supervised-Learning" class="headerlink" title="Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning"></a>Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11930">http://arxiv.org/abs/2309.11930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Ye, Kai Gan, Tong Wei, Min-Ling Zhang</li>
<li>for: 这个研究目的是解决开放世界半监督学习中的新类别发现问题，即使用不监督的数据来探索新的类别，同时维持已知类别的性能。</li>
<li>methods: 我们提出了两个方法来解决这个问题：1）适应的margin损失基于估计的类别分布，以将学习速度均衡化，2）pseudo-label对称分组，将可能属于同一类别的样本集中，以增强新类别发现。</li>
<li>results: 我们的广泛评估表明，现有模型仍然对新类别学习产生问题，而我们的方法则能够平衡已知类别和新类别，在ImageNet dataset上达到了3%的平均精度提升，相比先前的州ike-of-the-art。此外，我们发现了精益调整自我监督预训练模型可以很大程度上提高性能。<details>
<summary>Abstract</summary>
In open-world semi-supervised learning, a machine learning model is tasked with uncovering novel categories from unlabeled data while maintaining performance on seen categories from labeled data. The central challenge is the substantial learning gap between seen and novel categories, as the model learns the former faster due to accurate supervisory information. To address this, we introduce 1) an adaptive margin loss based on estimated class distribution, which encourages a large negative margin for samples in seen classes, to synchronize learning paces, and 2) pseudo-label contrastive clustering, which pulls together samples which are likely from the same class in the output space, to enhance novel class discovery. Our extensive evaluations on multiple datasets demonstrate that existing models still hinder novel class learning, whereas our approach strikingly balances both seen and novel classes, achieving a remarkable 3% average accuracy increase on the ImageNet dataset compared to the prior state-of-the-art. Additionally, we find that fine-tuning the self-supervised pre-trained backbone significantly boosts performance over the default in prior literature. After our paper is accepted, we will release the code.
</details>
<details>
<summary>摘要</summary>
在开放世界半监督学习中，一个机器学习模型被要求探索未经标注的数据中的新分类，同时保持已经标注的分类的性能。中心挑战是seen和novel分类之间的学习差距，因为模型在高精度的指导信息下快速学习seen分类。为此，我们提出了以下两点方法：1. 适应margin损失基于估计类分布，该损失函数鼓励在seen分类中的样本具有大负margin，以同步学习速度。2.  Pseudo-label对比分 clustering，该方法在输出空间中吸引同类样本相互吸引，以促进novel分类的发现。我们对多个数据集进行了广泛的评估，发现现有模型仍然受到novel分类学习的限制，而我们的方法能够很好地均衡seen和novel分类，在ImageNet数据集上实现了3%的平均准确率提升 compared to Prior State-of-the-art。此外，我们发现在先前的文献中 defaults 的自然语言预训练模型进行了显著提升性能的观察。在我们的论文被接受后，我们将释放代码。
</details></li>
</ul>
<hr>
<h2 id="Video-Scene-Location-Recognition-with-Neural-Networks"><a href="#Video-Scene-Location-Recognition-with-Neural-Networks" class="headerlink" title="Video Scene Location Recognition with Neural Networks"></a>Video Scene Location Recognition with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11928">http://arxiv.org/abs/2309.11928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukáš Korel, Petr Pulc, Jiří Tumpach, Martin Holeňa</li>
<li>for: 这篇论文探讨了从视频序列中提取场景的可能性，使用人工神经网络。</li>
<li>methods: 该方法选择每个场景中的一些帧，通过预训练的单个图像预处理卷积网络进行转换，然后使用后续层的神经网络来确定场景位置。</li>
<li>results: 研究人员对从《大带费》电视剧获取的数据集进行测试和比较，发现只有某些方法适合当务。<details>
<summary>Abstract</summary>
This paper provides an insight into the possibility of scene recognition from a video sequence with a small set of repeated shooting locations (such as in television series) using artificial neural networks. The basic idea of the presented approach is to select a set of frames from each scene, transform them by a pre-trained singleimage pre-processing convolutional network, and classify the scene location with subsequent layers of the neural network. The considered networks have been tested and compared on a dataset obtained from The Big Bang Theory television series. We have investigated different neural network layers to combine individual frames, particularly AveragePooling, MaxPooling, Product, Flatten, LSTM, and Bidirectional LSTM layers. We have observed that only some of the approaches are suitable for the task at hand.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文探讨了通过视频序列中重复拍摄的小集合来实现场景认识的可能性，使用人工神经网络。提出的方法选择每个场景中的一些帧，通过预训练的单张图像预处理卷积神经网络进行转换，然后使用神经网络的后续层来确定场景位置。我们在《大咖大爆》电视剧集中获取的数据集上测试和比较了不同的神经网络层，包括AveragePooling、MaxPooling、Product、Flatten、LSTM和Bidirectional LSTM层。我们发现只有某些方法适合这种任务。
</details></li>
</ul>
<hr>
<h2 id="TextCLIP-Text-Guided-Face-Image-Generation-And-Manipulation-Without-Adversarial-Training"><a href="#TextCLIP-Text-Guided-Face-Image-Generation-And-Manipulation-Without-Adversarial-Training" class="headerlink" title="TextCLIP: Text-Guided Face Image Generation And Manipulation Without Adversarial Training"></a>TextCLIP: Text-Guided Face Image Generation And Manipulation Without Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11923">http://arxiv.org/abs/2309.11923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaozhou You, Jian Zhang</li>
<li>for: 文章目标是提出一种基于文本指导的图像生成和修改方法，而不需要对敌对模型进行训练。</li>
<li>methods: 方法基于StyleGAN和CLIP的协同适应力，通过特制的映射网络将文本转化为图像。</li>
<li>results: 对多Modal CelebA-HQ数据集进行了广泛的实验，并证明了该方法在文本指导生成和修改任务上具有优于现有方法的性能。<details>
<summary>Abstract</summary>
Text-guided image generation aimed to generate desired images conditioned on given texts, while text-guided image manipulation refers to semantically edit parts of a given image based on specified texts. For these two similar tasks, the key point is to ensure image fidelity as well as semantic consistency. Many previous approaches require complex multi-stage generation and adversarial training, while struggling to provide a unified framework for both tasks. In this work, we propose TextCLIP, a unified framework for text-guided image generation and manipulation without adversarial training. The proposed method accepts input from images or random noise corresponding to these two different tasks, and under the condition of the specific texts, a carefully designed mapping network that exploits the powerful generative capabilities of StyleGAN and the text image representation capabilities of Contrastive Language-Image Pre-training (CLIP) generates images of up to $1024\times1024$ resolution that can currently be generated. Extensive experiments on the Multi-modal CelebA-HQ dataset have demonstrated that our proposed method outperforms existing state-of-the-art methods, both on text-guided generation tasks and manipulation tasks.
</details>
<details>
<summary>摘要</summary>
文本干预图像生成和文本干预图像修改都是类似的任务，关键点是保持图像准确性和 semantics 一致性。许多先前的方法需要复杂的多stage生成和对抗训练，而且很难提供一个简单的框架 для这两个任务。在这项工作中，我们提出了 TextCLIP，一个简单的框架 для文本干预图像生成和修改，不需要对抗训练。该方法接受图像或随机噪声作为输入，根据特定的文本来生成图像，可以生成高分辨率图像（最大 $1024\times1024$）。经验表明，我们提出的方法在多模态 CelebA-HQ 数据集上表现出了比例性，在文本干预图像生成和修改任务中都超过了现有的状态泰技术。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Transformer-based-Video-Compression-Framework"><a href="#Spatial-Temporal-Transformer-based-Video-Compression-Framework" class="headerlink" title="Spatial-Temporal Transformer based Video Compression Framework"></a>Spatial-Temporal Transformer based Video Compression Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11913">http://arxiv.org/abs/2309.11913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanbo Gao, Wenjia Huang, Shuai Li, Hui Yuan, Mao Ye, Siwei Ma</li>
<li>For: 这个研究旨在提出一种基于 transformer 框架的learned video compression（LVC）方法，以提高视频编码的效率和质量。* Methods: 该方法使用了一种叫做 Relaxed Deformable Transformer（RDT）的新型自适应变换器，以稳定地估算视频帧之间的运动信息。同时，该方法还使用了一种多级划分预测（MGP）模块，以更好地利用多个参照帧的信息，以及一种空间特征分布预测（SFD-T）模块，以减少视频的空间-时间重复性。* Results: 实验结果表明，该方法可以与 VTM 比较，并且 achieved the best result with 13.5% BD-Rate saving。<details>
<summary>Abstract</summary>
Learned video compression (LVC) has witnessed remarkable advancements in recent years. Similar as the traditional video coding, LVC inherits motion estimation/compensation, residual coding and other modules, all of which are implemented with neural networks (NNs). However, within the framework of NNs and its training mechanism using gradient backpropagation, most existing works often struggle to consistently generate stable motion information, which is in the form of geometric features, from the input color features. Moreover, the modules such as the inter-prediction and residual coding are independent from each other, making it inefficient to fully reduce the spatial-temporal redundancy. To address the above problems, in this paper, we propose a novel Spatial-Temporal Transformer based Video Compression (STT-VC) framework. It contains a Relaxed Deformable Transformer (RDT) with Uformer based offsets estimation for motion estimation and compensation, a Multi-Granularity Prediction (MGP) module based on multi-reference frames for prediction refinement, and a Spatial Feature Distribution prior based Transformer (SFD-T) for efficient temporal-spatial joint residual compression. Specifically, RDT is developed to stably estimate the motion information between frames by thoroughly investigating the relationship between the similarity based geometric motion feature extraction and self-attention. MGP is designed to fuse the multi-reference frame information by effectively exploring the coarse-grained prediction feature generated with the coded motion information. SFD-T is to compress the residual information by jointly exploring the spatial feature distributions in both residual and temporal prediction to further reduce the spatial-temporal redundancy. Experimental results demonstrate that our method achieves the best result with 13.5% BD-Rate saving over VTM.
</details>
<details>
<summary>摘要</summary>
历年来，学习视频压缩（LVC）技术已经经历了很大的发展。LVC技术继承了传统视频编码中的运动估计/补做、剩余编码等模块，并且通过神经网络（NN）的实现。然而，大多数现有的工作在NN和其训练机制中使用梯度倒逆时，很难一致地生成稳定的运动信息，这种运动信息通常是输入颜色特征的几何特征。此外，模块如 междуPrediction和剩余编码是独立的，这使得它们之间的重叠不充分。为解决这些问题，在这篇论文中，我们提出了一种新的空间-时间变换基本的视频压缩（STT-VC）框架。它包括一个宽度缓和变换（RDT）、基于Uformer的偏移估计，以及一个多级别预测（MGP）模块和一个空间特征分布先验基于变换（SFD-T）。具体来说，RDT是通过彻底调查相似性基于几何运动特征提取和自注意力来稳定地估计运动信息 между帧。MGP是通过有效地探索压缩动作信息中的粗糙预测特征来融合多个参照帧信息。SFD-T是通过同时探索剩余信息中的空间特征分布来进一步减少空间-时间重复。实验结果表明，我们的方法可以在VTM比较下实现13.5%的BD-Rate节省。
</details></li>
</ul>
<hr>
<h2 id="Heart-Rate-Detection-Using-an-Event-Camera"><a href="#Heart-Rate-Detection-Using-an-Event-Camera" class="headerlink" title="Heart Rate Detection Using an Event Camera"></a>Heart Rate Detection Using an Event Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11891">http://arxiv.org/abs/2309.11891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aniket Jagtap, RamaKrishna Venkatesh Saripalli, Joe Lemley, Waseem Shariff, Alan F. Smeaton</li>
<li>for: 这个研究旨在使用事件摄像机来不侵入式地监测心率（HR）。</li>
<li>methods: 研究使用事件摄像机捕捉手臂部分的皮肤微妙变化，并通过自动检测事件来测量心率。</li>
<li>results: 实验结果显示，使用事件摄像机可以精确地检测心率，并且比其他非接触式心率测量方法更高精度。 However, the method is limited by light-induced flickering and subconscious tremors of the individual during data capture.<details>
<summary>Abstract</summary>
Event cameras, also known as neuromorphic cameras, are an emerging technology that offer advantages over traditional shutter and frame-based cameras, including high temporal resolution, low power consumption, and selective data acquisition. In this study, we propose to harnesses the capabilities of event-based cameras to capture subtle changes in the surface of the skin caused by the pulsatile flow of blood in the wrist region. We investigate whether an event camera could be used for continuous noninvasive monitoring of heart rate (HR). Event camera video data from 25 participants, comprising varying age groups and skin colours, was collected and analysed. Ground-truth HR measurements obtained using conventional methods were used to evaluate of the accuracy of automatic detection of HR from event camera data. Our experimental results and comparison to the performance of other non-contact HR measurement methods demonstrate the feasibility of using event cameras for pulse detection. We also acknowledge the challenges and limitations of our method, such as light-induced flickering and the sub-conscious but naturally-occurring tremors of an individual during data capture.
</details>
<details>
<summary>摘要</summary>
事件摄像机也称为神经模型摄像机，是一种emerging技术，它们在传统的闭合式摄像机和帧摄像机方面具有优势，包括高时间分辨率、低功耗和选择性数据收集。在这项研究中，我们利用事件摄像机来捕捉血液径向流动在臂部区域 superficies 上的微小变化。我们调查了事件摄像机是否可以用于无侵入式、连续监测心率（HR）。我们收集了25名参与者的事件摄像机视频数据，其中年龄层width 和肤色各不相同。我们使用传统方法获取的真实心率值来评估自动从事件摄像机数据中检测HR的准确性。我们的实验结果和与其他非接触式心率测量方法的比较表明了使用事件摄像机进行脉吸检测的可行性。然而，我们也承认使用这种方法时存在挑战和限制，如光学辐射引起的闪烁和个体在数据采集过程中自然发生的微小颤动。
</details></li>
</ul>
<hr>
<h2 id="On-the-Fly-SfM-What-you-capture-is-What-you-get"><a href="#On-the-Fly-SfM-What-you-capture-is-What-you-get" class="headerlink" title="On-the-Fly SfM: What you capture is What you get"></a>On-the-Fly SfM: What you capture is What you get</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11883">http://arxiv.org/abs/2309.11883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zongqian Zhan, Rui Xia, Yifei Yu, Yibo Xu, Xin Wang</li>
<li>for: 这 paper 的目的是提出一种在线 Structure from Motion（SfM）方法，可以在图像捕捉过程中实时进行pose和稀疏点云的计算。</li>
<li>methods: 该方法使用了一个学习基于全局特征的词汇树来快速查找新抵达的图像，然后使用了一种robust的特征匹配机制（LSM）来提高图像Alignment性能。最后，通过研究新抵达图像的相邻图像的影响，提出了一种高效的层次权重本地加重（BA）优化方法。</li>
<li>results: 实验结果表明，在线 SfM 可以坚定地将图像注册，而不需要先将图像 fed into SfM 管道。<details>
<summary>Abstract</summary>
Over the last decades, ample achievements have been made on Structure from motion (SfM). However, the vast majority of them basically work in an offline manner, i.e., images are firstly captured and then fed together into a SfM pipeline for obtaining poses and sparse point cloud. In this work, on the contrary, we present an on-the-fly SfM: running online SfM while image capturing, the newly taken On-the-Fly image is online estimated with the corresponding pose and points, i.e., what you capture is what you get. Specifically, our approach firstly employs a vocabulary tree that is unsupervised trained using learning-based global features for fast image retrieval of newly fly-in image. Then, a robust feature matching mechanism with least squares (LSM) is presented to improve image registration performance. Finally, via investigating the influence of newly fly-in image's connected neighboring images, an efficient hierarchical weighted local bundle adjustment (BA) is used for optimization. Extensive experimental results demonstrate that on-the-fly SfM can meet the goal of robustly registering the images while capturing in an online way.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Using-Saliency-and-Cropping-to-Improve-Video-Memorability"><a href="#Using-Saliency-and-Cropping-to-Improve-Video-Memorability" class="headerlink" title="Using Saliency and Cropping to Improve Video Memorability"></a>Using Saliency and Cropping to Improve Video Memorability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11881">http://arxiv.org/abs/2309.11881</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Vaibhav Mudgal, Qingyang Wang, Lorin Sweeney, Alan F. Smeaton</li>
<li>for: 这项研究旨在提高视频的记忆性，以便提高视频的分享、播放和讨论。</li>
<li>methods: 研究人员通过选择ively cropping帧图像来提高视频的记忆性。他们使用了基本的固定剪辑以及动态剪辑，其中剪辑的大小和位置在视频播放时随着图像精力的变化。</li>
<li>results: 研究人员发现，特别是对低初始记忆性的视频，通过这些方法可以提高视频的记忆性。<details>
<summary>Abstract</summary>
Video memorability is a measure of how likely a particular video is to be remembered by a viewer when that viewer has no emotional connection with the video content. It is an important characteristic as videos that are more memorable are more likely to be shared, viewed, and discussed. This paper presents results of a series of experiments where we improved the memorability of a video by selectively cropping frames based on image saliency. We present results of a basic fixed cropping as well as the results from dynamic cropping where both the size of the crop and the position of the crop within the frame, move as the video is played and saliency is tracked. Our results indicate that especially for videos of low initial memorability, the memorability score can be improved.
</details>
<details>
<summary>摘要</summary>
视频记忆性是观看者没有情感连接的视频内容记忆的度量。它是一个重要的特性，因为更有记忆性的视频更有可能被分享、播放和讨论。本文报告了一系列实验，我们通过选择性剪辑帧来提高视频的记忆性。我们发现，特别是初始记忆性较低的视频，记忆性分数可以得到提高。
</details></li>
</ul>
<hr>
<h2 id="TCOVIS-Temporally-Consistent-Online-Video-Instance-Segmentation"><a href="#TCOVIS-Temporally-Consistent-Online-Video-Instance-Segmentation" class="headerlink" title="TCOVIS: Temporally Consistent Online Video Instance Segmentation"></a>TCOVIS: Temporally Consistent Online Video Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11857">http://arxiv.org/abs/2309.11857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jun-long-li/tcovis">https://github.com/jun-long-li/tcovis</a></li>
<li>paper_authors: Junlong Li, Bingyao Yu, Yongming Rao, Jie Zhou, Jiwen Lu</li>
<li>for: 这 paper 是为了提出一种新的在线视频实例分割方法，以实现高效精度的视频实例分割。</li>
<li>methods: 这 paper 使用了一种全新的 global instance assignment strategy 和 spatio-temporal enhancement module，以提高模型的时间一致性。</li>
<li>results: 这 paper 在四个广泛采用的视频实例分割benchmark上 achieved state-of-the-art performance，包括 YouTube-VIS 2019&#x2F;2021&#x2F;2022 和 OVIS。例如，在 YouTube-VIS 2021 上，TCOVIS 实现了 49.5 AP 和 61.3 AP 的最佳性能，使用 ResNet-50 和 Swin-L 的背景。<details>
<summary>Abstract</summary>
In recent years, significant progress has been made in video instance segmentation (VIS), with many offline and online methods achieving state-of-the-art performance. While offline methods have the advantage of producing temporally consistent predictions, they are not suitable for real-time scenarios. Conversely, online methods are more practical, but maintaining temporal consistency remains a challenging task. In this paper, we propose a novel online method for video instance segmentation, called TCOVIS, which fully exploits the temporal information in a video clip. The core of our method consists of a global instance assignment strategy and a spatio-temporal enhancement module, which improve the temporal consistency of the features from two aspects. Specifically, we perform global optimal matching between the predictions and ground truth across the whole video clip, and supervise the model with the global optimal objective. We also capture the spatial feature and aggregate it with the semantic feature between frames, thus realizing the spatio-temporal enhancement. We evaluate our method on four widely adopted VIS benchmarks, namely YouTube-VIS 2019/2021/2022 and OVIS, and achieve state-of-the-art performance on all benchmarks without bells-and-whistles. For instance, on YouTube-VIS 2021, TCOVIS achieves 49.5 AP and 61.3 AP with ResNet-50 and Swin-L backbones, respectively. Code is available at https://github.com/jun-long-li/TCOVIS.
</details>
<details>
<summary>摘要</summary>
近年来，视频实例分割（VIS）领域内有很大的进步，许多离线和在线方法已经达到了状态艺术水平。然而，离线方法在实时场景下不够实用，而在线方法尽管更加实用，但维护时间一致性仍然是一个挑战。在这篇论文中，我们提出了一种新的在线视频实例分割方法，称为TCOVIS，它可以充分利用视频帧序中的时间信息。TCOVIS的核心包括全局实例分配策略和空间时间增强模块，这两个部分都有助于提高视频帧序中特征的时间一致性。具体来说，我们在整个视频帧序中进行全局最佳匹配，并通过全局最佳目标进行监督。同时，我们还捕捉了空间特征，将其与semantic特征相加，实现了空间时间增强。我们在四个广泛采用的 VIS 评测benchmark上进行评测，分别是 YouTube-VIS 2019/2021/2022 和 OVIS，并在所有benchmark上取得了状态艺术性的表现。例如，在 YouTube-VIS 2021 上，TCOVIS 取得了 49.5 AP 和 61.3 AP，使用 ResNet-50 和 Swin-L 的背景中。代码可以在 GitHub 上找到：https://github.com/jun-long-li/TCOVIS。
</details></li>
</ul>
<hr>
<h2 id="DEYOv3-DETR-with-YOLO-for-Real-time-Object-Detection"><a href="#DEYOv3-DETR-with-YOLO-for-Real-time-Object-Detection" class="headerlink" title="DEYOv3: DETR with YOLO for Real-time Object Detection"></a>DEYOv3: DETR with YOLO for Real-time Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11851">http://arxiv.org/abs/2309.11851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haodong Ouyang</li>
<li>For: This paper proposes a new training method called step-by-step training to improve the practical application and design flexibility of end-to-end object detectors, particularly for DETR-like models.* Methods: The proposed method first initializes the end-to-end detector with a pre-trained YOLO detector and then trains the backbone and encoder of the DETR-like model from scratch. The step-by-step training method eliminates the need for additional training data and reduces the training cost of the detector.* Results: The proposed DEYOv3 model achieves higher accuracy than traditional DETR-like models while maintaining real-time speed (270 FPS on T4 GPU). DEYOv3-N reaches 41.1% AP on COCO val2017 and 270 FPS, while DEYOv3-L achieves 51.3% AP and 102 FPS. All of these results are achieved without using additional training data, making DEYOv3 the best real-time object detection model in terms of both speed and accuracy.<details>
<summary>Abstract</summary>
Recently, end-to-end object detectors have gained significant attention from the research community due to their outstanding performance. However, DETR typically relies on supervised pretraining of the backbone on ImageNet, which limits the practical application of DETR and the design of the backbone, affecting the model's potential generalization ability. In this paper, we propose a new training method called step-by-step training. Specifically, in the first stage, the one-to-many pre-trained YOLO detector is used to initialize the end-to-end detector. In the second stage, the backbone and encoder are consistent with the DETR-like model, but only the detector needs to be trained from scratch. Due to this training method, the object detector does not need the additional dataset (ImageNet) to train the backbone, which makes the design of the backbone more flexible and dramatically reduces the training cost of the detector, which is helpful for the practical application of the object detector. At the same time, compared with the DETR-like model, the step-by-step training method can achieve higher accuracy than the traditional training method of the DETR-like model. With the aid of this novel training method, we propose a brand-new end-to-end real-time object detection model called DEYOv3. DEYOv3-N achieves 41.1% on COCO val2017 and 270 FPS on T4 GPU, while DEYOv3-L achieves 51.3% AP and 102 FPS. Without the use of additional training data, DEYOv3 surpasses all existing real-time object detectors in terms of both speed and accuracy. It is worth noting that for models of N, S, and M scales, the training on the COCO dataset can be completed using a single 24GB RTX3090 GPU.
</details>
<details>
<summary>摘要</summary>
近期，端到端对象检测器在研究社区中受到了广泛关注，因为它们的表现非常出色。然而，DETR通常需要在ImageNet上进行supervised预训练，这限制了DETR的实际应用和设计，影响了模型的总体适应能力。在这篇论文中，我们提出了一种新的训练方法called step-by-step training。具体来说，在第一个阶段，使用pre-trained YOLO检测器来初始化端到端检测器。在第二个阶段，背部和编码器与DETR-like模型相同，但是只需要从scratch训练检测器。由于这种训练方法，对象检测器不需要额外的数据集（ImageNet）来训练背部，这使得背部的设计变得更加灵活，对检测器的训练成本减少了极大，这有助于实际应用。同时，相比DETR-like模型，step-by-step training方法可以在同样的精度下达到更高的精度。通过这种新的训练方法，我们提出了一个全新的端到端实时对象检测模型called DEYOv3。DEYOv3-N在COCO val2017上达到了41.1%的分数，而DEYOv3-L在T4 GPU上达到了51.3%的AP和270 FPS。没有使用额外的训练数据，DEYOv3超过了所有现有的实时对象检测器，包括速度和精度两个方面。值得注意的是，对N、S、M缩放的模型，在COCO数据集上进行训练可以使用单个24GB RTX3090 GPU。
</details></li>
</ul>
<hr>
<h2 id="MEFLUT-Unsupervised-1D-Lookup-Tables-for-Multi-exposure-Image-Fusion"><a href="#MEFLUT-Unsupervised-1D-Lookup-Tables-for-Multi-exposure-Image-Fusion" class="headerlink" title="MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion"></a>MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11847">http://arxiv.org/abs/2309.11847</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hedlen/meflut">https://github.com/hedlen/meflut</a></li>
<li>paper_authors: Ting Jiang, Chuan Wang, Xinpeng Li, Ru Li, Haoqiang Fan, Shuaicheng Liu</li>
<li>for: 高品质多曝光图像融合 (高品质MEF)</li>
<li>methods: 利用一维Lookup表 (1D LUT) 将曝光权重编码为 pixel 强度值输入，并通过注意力机制在不同维度（帧、通道和空间）进行学习，以提高高品质和效率的融合。</li>
<li>results: 与现有最佳方法比较，新方法实现高品质和效率的融合，并且实现了4K影像在PC GPU上的几乎即时运行（低于4ms）。code available at：<a target="_blank" rel="noopener" href="https://github.com/Hedlen/MEFLUT%E3%80%82">https://github.com/Hedlen/MEFLUT。</a><details>
<summary>Abstract</summary>
In this paper, we introduce a new approach for high-quality multi-exposure image fusion (MEF). We show that the fusion weights of an exposure can be encoded into a 1D lookup table (LUT), which takes pixel intensity value as input and produces fusion weight as output. We learn one 1D LUT for each exposure, then all the pixels from different exposures can query 1D LUT of that exposure independently for high-quality and efficient fusion. Specifically, to learn these 1D LUTs, we involve attention mechanism in various dimensions including frame, channel and spatial ones into the MEF task so as to bring us significant quality improvement over the state-of-the-art (SOTA). In addition, we collect a new MEF dataset consisting of 960 samples, 155 of which are manually tuned by professionals as ground-truth for evaluation. Our network is trained by this dataset in an unsupervised manner. Extensive experiments are conducted to demonstrate the effectiveness of all the newly proposed components, and results show that our approach outperforms the SOTA in our and another representative dataset SICE, both qualitatively and quantitatively. Moreover, our 1D LUT approach takes less than 4ms to run a 4K image on a PC GPU. Given its high quality, efficiency and robustness, our method has been shipped into millions of Android mobiles across multiple brands world-wide. Code is available at: https://github.com/Hedlen/MEFLUT.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的高质量多曝光图像融合（MEF）方法。我们表明，曝光权重可以被编码成1D Lookup Table（LUT），该LUT接受像素强度值作输入，并生成权重作出输出。我们在每个曝光中学习了1D LUT，然后所有的像素从不同的曝光状态可以独立地查询该曝光的1D LUT，以实现高质量和高效的融合。特别是，为了学习这些1D LUT，我们在MEF任务中包含了注意力机制在帧、通道和空间方向中，从而使我们在SOTA中得到了显著的质量改善。此外，我们收集了一个新的MEF数据集，包含960个样本，其中155个是由专业人员 manually tuned 的参考标准 для评估。我们的网络是通过这个数据集在无监督的情况下进行训练。我们进行了广泛的实验，以证明所有新提出的组件的效iveness，结果表明，我们的方法在我们的数据集和另一个代表性数据集SICE中， Both qualitatively and quantitativelysuperior to the SOTA。此外，我们的1D LUT方法在4K图像上只需0.4毫秒，在PC GPU上运行。由于其高质量、高效和稳定性，我们的方法已经被运送到了世界各地的几百万Android手机中。代码可以在https://github.com/Hedlen/MEFLUT中找到。
</details></li>
</ul>
<hr>
<h2 id="MoPA-Multi-Modal-Prior-Aided-Domain-Adaptation-for-3D-Semantic-Segmentation"><a href="#MoPA-Multi-Modal-Prior-Aided-Domain-Adaptation-for-3D-Semantic-Segmentation" class="headerlink" title="MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation"></a>MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11839">http://arxiv.org/abs/2309.11839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haozhi Cao, Yuecong Xu, Jianfei Yang, Pengyu Yin, Shenghai Yuan, Lihua Xie</li>
<li>for: 提高3D semantic segmentation中罕见对象的性能，使用多Modal无监督领域适应（MM-UDA）方法。</li>
<li>methods: 提出了多Modal Prior Aided（MoPA）领域适应方法，包括 Valid Ground-based Insertion（VGI）和 SAM consistency loss。</li>
<li>results: 实验显示，我们的方法在多Modal无监督领域适应 benchmark 上达到了状态机器人表现。代码将在 GitHub 上公开。<details>
<summary>Abstract</summary>
Multi-modal unsupervised domain adaptation (MM-UDA) for 3D semantic segmentation is a practical solution to embed semantic understanding in autonomous systems without expensive point-wise annotations. While previous MM-UDA methods can achieve overall improvement, they suffer from significant class-imbalanced performance, restricting their adoption in real applications. This imbalanced performance is mainly caused by: 1) self-training with imbalanced data and 2) the lack of pixel-wise 2D supervision signals. In this work, we propose Multi-modal Prior Aided (MoPA) domain adaptation to improve the performance of rare objects. Specifically, we develop Valid Ground-based Insertion (VGI) to rectify the imbalance supervision signals by inserting prior rare objects collected from the wild while avoiding introducing artificial artifacts that lead to trivial solutions. Meanwhile, our SAM consistency loss leverages the 2D prior semantic masks from SAM as pixel-wise supervision signals to encourage consistent predictions for each object in the semantic mask. The knowledge learned from modal-specific prior is then shared across modalities to achieve better rare object segmentation. Extensive experiments show that our method achieves state-of-the-art performance on the challenging MM-UDA benchmark. Code will be available at https://github.com/AronCao49/MoPA.
</details>
<details>
<summary>摘要</summary>
多Modal无监督领域适应（MM-UDA）用于3Dsemantic segmentation是一种实用的解决方案，以实现无需昂贵点级标注的semantic理解。previous MM-UDA方法可以获得总体改进，但它们受到分类偏好的问题，这限制了它们在实际应用中的采用。这种偏好性问题主要来自于：1）自我帮助学习偏好数据，2）缺乏像素级2D监视信号。在这项工作中，我们提出了多Modal Prior帮助（MoPA）领域适应，以提高罕见对象的性能。具体来说，我们开发了有效的基准图Insertion（VGI）技术，以修正不均匀的监视信号，而不是引入人工artefacts，以避免导致轻微解决方案。此外，我们的SAM一致损失函数利用了2D Prior semantic masks从SAM中的像素级监视信号，以强制每个对象在semantic mask中具有一致的预测。知识从modalSpecific Prior中学习的知识然后被共享到不同模式之间，以达到更好的罕见对象分割。广泛的实验表明，我们的方法在MM-UDA benchmark上达到了最佳性能。代码将在https://github.com/AronCao49/MoPA中提供。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Endoscopic-Ultrasound-Station-Recognition-with-Limited-Data"><a href="#Automatic-Endoscopic-Ultrasound-Station-Recognition-with-Limited-Data" class="headerlink" title="Automatic Endoscopic Ultrasound Station Recognition with Limited Data"></a>Automatic Endoscopic Ultrasound Station Recognition with Limited Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11820">http://arxiv.org/abs/2309.11820</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amrita-medical-ai/eusml-labeller">https://github.com/amrita-medical-ai/eusml-labeller</a></li>
<li>paper_authors: Abhijit Ramesh, Anantha Nandanan, Anantha Nandanan, Priya Nair MD, Gilad Gressel</li>
<li>for: 这个论文的目的是提高检测胆囊癌的精度，以提高患者的诊断和存活率。</li>
<li>methods: 这个论文使用了人工智能技术，以帮助医生更准确地检测胆囊癌。特别是，它使用了深度学习算法来识别胆囊癌的不同区域，以提高检测的精度。</li>
<li>results: 研究表明，使用这个人工智能检测工具可以提高检测胆囊癌的精度，并且只需要43个检测过程，无需进行价值革新的训练。此外，这个工具还可以提供可读性和可解释的视觉化技术，帮助医生更好地理解检测结果。<details>
<summary>Abstract</summary>
Pancreatic cancer is a lethal form of cancer that significantly contributes to cancer-related deaths worldwide. Early detection is essential to improve patient prognosis and survival rates. Despite advances in medical imaging techniques, pancreatic cancer remains a challenging disease to detect. Endoscopic ultrasound (EUS) is the most effective diagnostic tool for detecting pancreatic cancer. However, it requires expert interpretation of complex ultrasound images to complete a reliable patient scan. To obtain complete imaging of the pancreas, practitioners must learn to guide the endoscope into multiple "EUS stations" (anatomical locations), which provide different views of the pancreas. This is a difficult skill to learn, involving over 225 proctored procedures with the support of an experienced doctor. We build an AI-assisted tool that utilizes deep learning techniques to identify these stations of the stomach in real time during EUS procedures. This computer-assisted diagnostic (CAD) will help train doctors more efficiently. Historically, the challenge faced in developing such a tool has been the amount of retrospective labeling required by trained clinicians. To solve this, we developed an open-source user-friendly labeling web app that streamlines the process of annotating stations during the EUS procedure with minimal effort from the clinicians. Our research shows that employing only 43 procedures with no hyperparameter fine-tuning obtained a balanced accuracy of 90%, comparable to the current state of the art. In addition, we employ Grad-CAM, a visualization technology that provides clinicians with interpretable and explainable visualizations.
</details>
<details>
<summary>摘要</summary>
胰腺癌是一种致命的癌症，对全球癌症相关死亡率具有重要贡献。早期发现是提高病人 прогноosis 和存生率的关键。 despite advances in medical imaging techniques, pancreatic cancer remains a challenging disease to detect. Endoscopic ultrasound (EUS) is the most effective diagnostic tool for detecting pancreatic cancer, but it requires expert interpretation of complex ultrasound images to complete a reliable patient scan. To obtain complete imaging of the pancreas, practitioners must learn to guide the endoscope into multiple "EUS stations" (anatomical locations), which provide different views of the pancreas. This is a difficult skill to learn, involving over 225 proctored procedures with the support of an experienced doctor. We have developed an AI-assisted tool that utilizes deep learning techniques to identify these stations of the stomach in real time during EUS procedures. This computer-assisted diagnostic (CAD) will help train doctors more efficiently. Historically, the challenge faced in developing such a tool has been the amount of retrospective labeling required by trained clinicians. To solve this, we have developed an open-source, user-friendly labeling web app that streamlines the process of annotating stations during the EUS procedure with minimal effort from the clinicians. Our research shows that employing only 43 procedures with no hyperparameter fine-tuning obtained a balanced accuracy of 90%, comparable to the current state of the art. In addition, we employ Grad-CAM, a visualization technology that provides clinicians with interpretable and explainable visualizations.
</details></li>
</ul>
<hr>
<h2 id="FGFusion-Fine-Grained-Lidar-Camera-Fusion-for-3D-Object-Detection"><a href="#FGFusion-Fine-Grained-Lidar-Camera-Fusion-for-3D-Object-Detection" class="headerlink" title="FGFusion: Fine-Grained Lidar-Camera Fusion for 3D Object Detection"></a>FGFusion: Fine-Grained Lidar-Camera Fusion for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11804">http://arxiv.org/abs/2309.11804</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xaviergrool/fgfusion">https://github.com/xaviergrool/fgfusion</a></li>
<li>paper_authors: Zixuan Yin, Han Sun, Ningzhong Liu, Huiyu Zhou, Jiaquan Shen</li>
<li>for: 本文旨在提出一种细化的 lidar-camera 结合方法，以便在自动驾驶中提高 3D 检测的精度。</li>
<li>methods: 本方法使用了 dual pathway hierarchy 结构，以提取图像中的高级 semantics 和低级细节信息，并在 auxiliary network 的帮助下，点云特征更好地学习细致的空间信息。 最后，我们提出了多级 fusión（MSF）方法，将图像和点云的最后 N 个特征图 fusion。</li>
<li>results: 我们在 KITTI 和 Waymo 两个流行的自动驾驶 benchmark 上进行了广泛的实验，并证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Lidars and cameras are critical sensors that provide complementary information for 3D detection in autonomous driving. While most prevalent methods progressively downscale the 3D point clouds and camera images and then fuse the high-level features, the downscaled features inevitably lose low-level detailed information. In this paper, we propose Fine-Grained Lidar-Camera Fusion (FGFusion) that make full use of multi-scale features of image and point cloud and fuse them in a fine-grained way. First, we design a dual pathway hierarchy structure to extract both high-level semantic and low-level detailed features of the image. Second, an auxiliary network is introduced to guide point cloud features to better learn the fine-grained spatial information. Finally, we propose multi-scale fusion (MSF) to fuse the last N feature maps of image and point cloud. Extensive experiments on two popular autonomous driving benchmarks, i.e. KITTI and Waymo, demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
<SYS>请将给定文本翻译成简化中文。</SYS>感谢！以下是文本的翻译： lidar和摄像头是自动驾驶中不可或缺的感知器，大多数现有方法是逐渐减小3D点云和摄像头图像，然后将高级特征进行融合。然而，下降的特征无法保留低级细节信息。在这篇论文中，我们提出了细腻的激光干涉摄像头融合（FGFusion），使用多尺度特征来融合图像和点云的细节信息。首先，我们设计了两个层次结构，一个用于提取图像的高级semantic特征，另一个用于提取低级细节特征。其次，我们引入了一个协助网络，以便点云特征更好地学习细腻的空间信息。最后，我们提出了多尺度融合（MSF），用于融合图像和点云的最后N个特征图。我们在KITTI和Waymo两个流行的自动驾驶测试平台上进行了广泛的实验，结果表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="A-Real-Time-Multi-Task-Learning-System-for-Joint-Detection-of-Face-Facial-Landmark-and-Head-Pose"><a href="#A-Real-Time-Multi-Task-Learning-System-for-Joint-Detection-of-Face-Facial-Landmark-and-Head-Pose" class="headerlink" title="A Real-Time Multi-Task Learning System for Joint Detection of Face, Facial Landmark and Head Pose"></a>A Real-Time Multi-Task Learning System for Joint Detection of Face, Facial Landmark and Head Pose</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11773">http://arxiv.org/abs/2309.11773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingtian Wu, Liming Zhang</li>
<li>for: 这篇论文主要针对面部分析任务中的极大角度头 pose 问题，提出了一种实时多任务检测系统，可同时检测面部、 facial landmark 和头 pose。</li>
<li>methods: 该系统基于广泛采用的 YOLOv8 检测框架，添加了更多的landmark regression head，以便高效地确定面部关键点。此外，我们对 YOLOv8 框架中的多个模块进行了优化和提升。</li>
<li>results: 我们在 300W-LP 和 AFLW2000-3D 数据集上进行了广泛的实验，结果表明我们的模型可以有效地处理大角度头 pose 问题，同时具有实时性。<details>
<summary>Abstract</summary>
Extreme head postures pose a common challenge across a spectrum of facial analysis tasks, including face detection, facial landmark detection (FLD), and head pose estimation (HPE). These tasks are interdependent, where accurate FLD relies on robust face detection, and HPE is intricately associated with these key points. This paper focuses on the integration of these tasks, particularly when addressing the complexities posed by large-angle face poses. The primary contribution of this study is the proposal of a real-time multi-task detection system capable of simultaneously performing joint detection of faces, facial landmarks, and head poses. This system builds upon the widely adopted YOLOv8 detection framework. It extends the original object detection head by incorporating additional landmark regression head, enabling efficient localization of crucial facial landmarks. Furthermore, we conduct optimizations and enhancements on various modules within the original YOLOv8 framework. To validate the effectiveness and real-time performance of our proposed model, we conduct extensive experiments on 300W-LP and AFLW2000-3D datasets. The results obtained verify the capability of our model to tackle large-angle face pose challenges while delivering real-time performance across these interconnected tasks.
</details>
<details>
<summary>摘要</summary>
极端头 pose  pose 是一种常见的挑战，涉及到脸部检测、脸部关键点检测 (FLD) 和头 pose 估算 (HPE) 等多个面部分析任务。这些任务之间存在互相关系，精准的 FLD 需要正确的脸部检测，而 HPE 则取决于关键点的确定。本文关注这些任务的集成，特别是在处理大角度头 pose 时的复杂性。我们提出了一个实时多任务检测系统，可同时检测脸部、脸部关键点和头 pose。这个系统基于广泛采用的 YOLOv8 检测框架。我们在原始的对象检测头上添加了附加的关键点 regression 头，以便高效地确定脸部关键点。此外，我们对 YOLOv8 框架中的各个模块进行了优化和改进。为了证明我们提出的模型的有效性和实时性，我们在 300W-LP 和 AFLW2000-3D 数据集上进行了广泛的实验。实验结果表明，我们的模型能够 effectively 处理大角度头 pose 挑战，并在这些相关任务中提供实时性。
</details></li>
</ul>
<hr>
<h2 id="Fast-Satellite-Tensorial-Radiance-Field-for-Multi-date-Satellite-Imagery-of-Large-Size"><a href="#Fast-Satellite-Tensorial-Radiance-Field-for-Multi-date-Satellite-Imagery-of-Large-Size" class="headerlink" title="Fast Satellite Tensorial Radiance Field for Multi-date Satellite Imagery of Large Size"></a>Fast Satellite Tensorial Radiance Field for Multi-date Satellite Imagery of Large Size</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11767">http://arxiv.org/abs/2309.11767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tongtong Zhang, Yuanxiang Li</li>
<li>for: 提高卫星图像NeRF模型的速度和可扩展性，并解决了大尺寸卫星图像处理的限制。</li>
<li>methods: 使用多尺度矩阵分解方法来表示颜色、体积密度和辅助变量，并使用总变量损失来修正多日图像的不一致性。</li>
<li>results: 与state-of-the-art Sat-NeRF系列相比，SatensoRF在新视图合成性能方面表现出色，并且需要 fewer parameters для训练和推断，具有更快的训练和推断速度和更低的计算需求。<details>
<summary>Abstract</summary>
Existing NeRF models for satellite images suffer from slow speeds, mandatory solar information as input, and limitations in handling large satellite images. In response, we present SatensoRF, which significantly accelerates the entire process while employing fewer parameters for satellite imagery of large size. Besides, we observed that the prevalent assumption of Lambertian surfaces in neural radiance fields falls short for vegetative and aquatic elements. In contrast to the traditional hierarchical MLP-based scene representation, we have chosen a multiscale tensor decomposition approach for color, volume density, and auxiliary variables to model the lightfield with specular color. Additionally, to rectify inconsistencies in multi-date imagery, we incorporate total variation loss to restore the density tensor field and treat the problem as a denosing task.To validate our approach, we conducted assessments of SatensoRF using subsets from the spacenet multi-view dataset, which includes both multi-date and single-date multi-view RGB images. Our results clearly demonstrate that SatensoRF surpasses the state-of-the-art Sat-NeRF series in terms of novel view synthesis performance. Significantly, SatensoRF requires fewer parameters for training, resulting in faster training and inference speeds and reduced computational demands.
</details>
<details>
<summary>摘要</summary>
现有的卫星图像NeRF模型受到慢速、必需日升信息作为输入以及处理大型卫星图像的限制。作为回应，我们提出了SatensoRF，它可以快速加速整个过程，并使用 fewer parameters 来处理大型卫星图像。此外，我们发现了传统的LAMBERTIAN表面假设在神经采集场景中失足，特别是 для植物和水生元素。相比传统的层次MLP基本Scene表示，我们选择了多尺度矩阵分解方法来表示颜色、体积密度和辅助变量，以模型光场。此外，为了纠正多日图像之间的不一致，我们添加了总变量损失来修复密度矩阵场景，并将问题视为锈除task。为验证我们的方法，我们对SpaceNet多视点数据集中的subset进行了评估，该数据集包括了多日和单日多视点RGB图像。我们的结果表明，SatensoRF超越了state-of-the-art Sat-NeRF系列在新视图合成性能方面。特别是，SatensoRF需要 fewer parameters 进行训练，导致更快的训练和推理速度，以及减少的计算占用。
</details></li>
</ul>
<hr>
<h2 id="Dictionary-Attack-on-IMU-based-Gait-Authentication"><a href="#Dictionary-Attack-on-IMU-based-Gait-Authentication" class="headerlink" title="Dictionary Attack on IMU-based Gait Authentication"></a>Dictionary Attack on IMU-based Gait Authentication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11766">http://arxiv.org/abs/2309.11766</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rajeshjnu2006/dictionaryattackonimugait">https://github.com/rajeshjnu2006/dictionaryattackonimugait</a></li>
<li>paper_authors: Rajesh Kumar, Can Isik, Chilukuri K. Mohan</li>
<li>for: 本研究旨在攻击使用IMU嵌入式加速度计记录的步征 Authentication系统。</li>
<li>methods: 本研究使用了一种基于字典的攻击方法，即使用一个IMUGait模式字典来攻击 Authentication系统。</li>
<li>results: 研究发现，可以通过使用IMUGait模式字典来攻击多种用户认证模型，并且对认证系统的安全性提出了挑战。<details>
<summary>Abstract</summary>
We present a novel adversarial model for authentication systems that use gait patterns recorded by the inertial measurement unit (IMU) built into smartphones. The attack idea is inspired by and named after the concept of a dictionary attack on knowledge (PIN or password) based authentication systems. In particular, this work investigates whether it is possible to build a dictionary of IMUGait patterns and use it to launch an attack or find an imitator who can actively reproduce IMUGait patterns that match the target's IMUGait pattern. Nine physically and demographically diverse individuals walked at various levels of four predefined controllable and adaptable gait factors (speed, step length, step width, and thigh-lift), producing 178 unique IMUGait patterns. Each pattern attacked a wide variety of user authentication models. The deeper analysis of error rates (before and after the attack) challenges the belief that authentication systems based on IMUGait patterns are the most difficult to spoof; further research is needed on adversarial models and associated countermeasures.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的反攻击模型，用于authentication系统，利用智能手机内置的抗重力测量单元（IMU）记录的步态特征。这种攻击的想法来自于和知识（PIN或密码）基于的字典攻击。本研究是否可以构建一个IMUGait特征的词典，并使用其发动攻击或找到一个能够活泼地复制目标用户的IMUGait特征。我们采集了9名物理和人口多样化的个体，在四种可控和可适应的步态因素（速度、步长、步宽和膝盖）的不同水平上步行，共生成178个唯一的IMUGait特征。每个特征攻击了多种用户身份验证模型。我们进行了更深层次的错误率分析（之前和之后攻击），挑战了基于IMUGait特征的身份验证系统是最难模仿的假设。需要进一步的研究反攻击模型和相关的防范措施。
</details></li>
</ul>
<hr>
<h2 id="SAM-OCTA-A-Fine-Tuning-Strategy-for-Applying-Foundation-Model-to-OCTA-Image-Segmentation-Tasks"><a href="#SAM-OCTA-A-Fine-Tuning-Strategy-for-Applying-Foundation-Model-to-OCTA-Image-Segmentation-Tasks" class="headerlink" title="SAM-OCTA: A Fine-Tuning Strategy for Applying Foundation Model to OCTA Image Segmentation Tasks"></a>SAM-OCTA: A Fine-Tuning Strategy for Applying Foundation Model to OCTA Image Segmentation Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11758">http://arxiv.org/abs/2309.11758</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shellredia/sam-octa">https://github.com/shellredia/sam-octa</a></li>
<li>paper_authors: Chengliang Wang, Xinrun Chen, Haojian Ning, Shiying Li</li>
<li>for: 这个论文的目的是提出一种基于低级别适应技术的方法，用于处理多种分类任务在optical coherence tomography angiography（OCTA）图像上。</li>
<li>methods: 该方法使用了基于低级别适应技术的基础模型细化和相关提示点生成策略，以处理OCTA图像上的多种分类任务。</li>
<li>results: 该方法在公共可用的OCTA-500数据集上进行实验，并实现了当前最佳性能指标，同时可以高效地进行本地血管分 segmentation以及有效的血管-血管分 segmentation，这些任务在前一些工作中尚未得到很好的解决。<details>
<summary>Abstract</summary>
In the analysis of optical coherence tomography angiography (OCTA) images, the operation of segmenting specific targets is necessary. Existing methods typically train on supervised datasets with limited samples (approximately a few hundred), which can lead to overfitting. To address this, the low-rank adaptation technique is adopted for foundation model fine-tuning and proposed corresponding prompt point generation strategies to process various segmentation tasks on OCTA datasets. This method is named SAM-OCTA and has been experimented on the publicly available OCTA-500 dataset. While achieving state-of-the-art performance metrics, this method accomplishes local vessel segmentation as well as effective artery-vein segmentation, which was not well-solved in previous works. The code is available at: https://github.com/ShellRedia/SAM-OCTA.
</details>
<details>
<summary>摘要</summary>
在Optical coherence tomography angiography（OCTA）图像分析中，需要进行特定目标分割。现有方法通常在有限样本（约几百个）上进行supervised学习，这可能导致过拟合。为解决这个问题，我们采用了low-rank adaptation技术来修改基本模型，并提出了相应的提示点生成策略来处理不同的分割任务。这种方法被称为SAM-OCTA，并在公共可用的OCTA-500 dataset上进行实验。它不仅实现了state-of-the-art性能指标，还能够成功地进行本地血管分割以及有效的动脉-静脉分割，这在前一些工作中尚未得到解决。代码可以在：https://github.com/ShellRedia/SAM-OCTA中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Vision-Centric-Approach-for-Static-Map-Element-Annotation"><a href="#A-Vision-Centric-Approach-for-Static-Map-Element-Annotation" class="headerlink" title="A Vision-Centric Approach for Static Map Element Annotation"></a>A Vision-Centric Approach for Static Map Element Annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11754">http://arxiv.org/abs/2309.11754</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manymuch/cama">https://github.com/manymuch/cama</a></li>
<li>paper_authors: Jiaxin Zhang, Shiyuan Chen, Haoran Yin, Ruohong Mei, Xuan Liu, Cong Yang, Qian Zhang, Wei Sui<br>for:CAMA is designed to provide high-quality, consistent, and accurate annotations for training machine learning models in the field of computer vision and autonomous driving.methods:CAMA uses a vision-centric approach that leverages cameras to generate 3D annotations of static map elements without relying on LiDAR inputs. The framework achieves high reprojection accuracy across multiple cameras and is spatial-temporally consistent across the entire sequence.results:The proposed CAMA framework is evaluated on the popular nuScenes dataset and shows improved performance compared to the original nuScenes static map elements, with lower reprojection errors (e.g., 4.73 vs. 8.03 pixels).<details>
<summary>Abstract</summary>
The recent development of online static map element (a.k.a. HD Map) construction algorithms has raised a vast demand for data with ground truth annotations. However, available public datasets currently cannot provide high-quality training data regarding consistency and accuracy. To this end, we present CAMA: a vision-centric approach for Consistent and Accurate Map Annotation. Without LiDAR inputs, our proposed framework can still generate high-quality 3D annotations of static map elements. Specifically, the annotation can achieve high reprojection accuracy across all surrounding cameras and is spatial-temporal consistent across the whole sequence. We apply our proposed framework to the popular nuScenes dataset to provide efficient and highly accurate annotations. Compared with the original nuScenes static map element, models trained with annotations from CAMA achieve lower reprojection errors (e.g., 4.73 vs. 8.03 pixels).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PIE-Simulating-Disease-Progression-via-Progressive-Image-Editing"><a href="#PIE-Simulating-Disease-Progression-via-Progressive-Image-Editing" class="headerlink" title="PIE: Simulating Disease Progression via Progressive Image Editing"></a>PIE: Simulating Disease Progression via Progressive Image Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11745">http://arxiv.org/abs/2309.11745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaizhao Liang, Xu Cao, Kuei-Da Liao, Tianren Gao, Zhengyu Chen, Tejas Nama</li>
<li>for: 预测疾病进展，促进临床诊断、预后评估和治疗方案设计。</li>
<li>methods: 基于文本生成图像模型，实现疾病进展精准模拟和个性化。iterative refining过程中的梯度下降算法进行了 teoretic 分析。</li>
<li>results: 比对 CLIP 分数（现实度）和疾病分类信息确定率，PIE 超过 Stable Diffusion Walk 和 Style-Based Manifold Extrapolation 等方法。用户测试中，76.2% 的反馈表明生成的进程准确性高。PIE 是首个实现真实标准的疾病进展图像生成方法，有望在医疗机构中应用，改善病人结果。<details>
<summary>Abstract</summary>
Disease progression simulation is a crucial area of research that has significant implications for clinical diagnosis, prognosis, and treatment. One major challenge in this field is the lack of continuous medical imaging monitoring of individual patients over time. To address this issue, we develop a novel framework termed Progressive Image Editing (PIE) that enables controlled manipulation of disease-related image features, facilitating precise and realistic disease progression simulation. Specifically, we leverage recent advancements in text-to-image generative models to simulate disease progression accurately and personalize it for each patient. We theoretically analyze the iterative refining process in our framework as a gradient descent with an exponentially decayed learning rate. To validate our framework, we conduct experiments in three medical imaging domains. Our results demonstrate the superiority of PIE over existing methods such as Stable Diffusion Walk and Style-Based Manifold Extrapolation based on CLIP score (Realism) and Disease Classification Confidence (Alignment). Our user study collected feedback from 35 veteran physicians to assess the generated progressions. Remarkably, 76.2% of the feedback agrees with the fidelity of the generated progressions. To our best knowledge, PIE is the first of its kind to generate disease progression images meeting real-world standards. It is a promising tool for medical research and clinical practice, potentially allowing healthcare providers to model disease trajectories over time, predict future treatment responses, and improve patient outcomes.
</details>
<details>
<summary>摘要</summary>
疾病发展模拟是医学研究中的一个重要领域，具有诊断、预后和治疗中的重要意义。然而，现有的医学影像监测技术存在缺乏连续监测的问题，这限制了疾病发展模拟的准确性和可靠性。为解决这个问题，我们提出了一种新的框架，称为进程图像编辑（PIE），它可以控制疾病相关的图像特征，实现精准和现实的疾病发展模拟。具体来说，我们利用了最新的文本生成图像技术，模拟疾病发展的过程，并为每个患者个性化模拟。我们对PIE框架的迭代纠正过程进行了理论分析，认为它可以视为一种梯度下降算法，其学习率逐渐减少。为验证PIE框架，我们在医学影像领域进行了三项实验。我们的结果显示，PIE框架比现有的方法，如稳定扩散步和基于CLIP的Style-Based Manifold Extrapolation，在CLIP分数（现实）和疾病分类信心度（对齐）方面具有更高的超越性。我们的用户研究收集了35名 veteran physician 的反馈，评估生成的进程是否准确。结果显示，76.2%的反馈同意生成的进程准确性。到我们知道的 extend，PIE是首个满足现代医学标准的疾病发展图像生成框架。它是一种有前途的工具，可以帮助医疗专业人员模拟疾病轨迹，预测未来治疗响应，并提高患者的结果。
</details></li>
</ul>
<hr>
<h2 id="CPR-Coach-Recognizing-Composite-Error-Actions-based-on-Single-class-Training"><a href="#CPR-Coach-Recognizing-Composite-Error-Actions-based-on-Single-class-Training" class="headerlink" title="CPR-Coach: Recognizing Composite Error Actions based on Single-class Training"></a>CPR-Coach: Recognizing Composite Error Actions based on Single-class Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11718">http://arxiv.org/abs/2309.11718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunli Wang, Qing Yu, Shuaibing Wang, Dingkang Yang, Liuzhen Su, Xiao Zhao, Haopeng Kuang, Peixuan Zhang, Peng Zhai, Lihua Zhang</li>
<li>for: 这篇论文的目的是为了提高细部医疗动作分析和技能评估，特别是在紧急救援中Cardiopulmonary Resuscitation（CPR）技能的评估。</li>
<li>methods: 本文使用了视觉基于的系统来完成CPR动作识别和技能评估，并开发了名为CPR-Coach的视频数据集。另外，本文还提出了一个人类认知驿站（ImagineNet）框架，以解决单一类别训练和多类别测试的问题。</li>
<li>results: 实验结果显示，ImagineNet框架能够提高模型的多错识别性，并且在受限监督下进行训练。<details>
<summary>Abstract</summary>
The fine-grained medical action analysis task has received considerable attention from pattern recognition communities recently, but it faces the problems of data and algorithm shortage. Cardiopulmonary Resuscitation (CPR) is an essential skill in emergency treatment. Currently, the assessment of CPR skills mainly depends on dummies and trainers, leading to high training costs and low efficiency. For the first time, this paper constructs a vision-based system to complete error action recognition and skill assessment in CPR. Specifically, we define 13 types of single-error actions and 74 types of composite error actions during external cardiac compression and then develop a video dataset named CPR-Coach. By taking the CPR-Coach as a benchmark, this paper thoroughly investigates and compares the performance of existing action recognition models based on different data modalities. To solve the unavoidable Single-class Training & Multi-class Testing problem, we propose a humancognition-inspired framework named ImagineNet to improve the model's multierror recognition performance under restricted supervision. Extensive experiments verify the effectiveness of the framework. We hope this work could advance research toward fine-grained medical action analysis and skill assessment. The CPR-Coach dataset and the code of ImagineNet are publicly available on Github.
</details>
<details>
<summary>摘要</summary>
《细腔医学动作分析任务在图像识别领域内已经吸引了广泛的关注，但是它面临着数据和算法不足的问题。心肺复苏（CPR）是紧急情况下的重要技能之一，现在CPR技能评估主要靠假人和教练进行，导致训练成本高、效率低。本文首次构建了一个视觉基于的系统，用于完成CPR动作识别和技能评估。特别是，我们定义了13种单个错误动作和74种复合错误动作 durante la compressión cardíaca externa，并开发了名为CPR-Coach的视频数据集。通过使用CPR-Coach作为标准，本文对现有动作识别模型基于不同数据模式进行了广泛的 investigate 和比较。为解决不可避免的单类训练和多类测试问题，我们提出了一个人类认知 inspirited 框架名为ImagineNet，以提高模型的多错误识别性能。广泛的实验证明了效果性。我们希望这项工作能够推动细腔医学动作分析和技能评估的研究进步。CPR-Coach数据集和ImagineNet框架的代码都公开可用于GitHub。
</details></li>
</ul>
<hr>
<h2 id="Deshadow-Anything-When-Segment-Anything-Model-Meets-Zero-shot-shadow-removal"><a href="#Deshadow-Anything-When-Segment-Anything-Model-Meets-Zero-shot-shadow-removal" class="headerlink" title="Deshadow-Anything: When Segment Anything Model Meets Zero-shot shadow removal"></a>Deshadow-Anything: When Segment Anything Model Meets Zero-shot shadow removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11715">http://arxiv.org/abs/2309.11715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Feng Zhang, Tian Yi Song, Jia Wei Yao</li>
<li>for: Image shadow removal and image restoration.</li>
<li>methods: Deshadow-Anything model, Fine-tuning on large-scale datasets, diffusion model, Multi-Self-Attention Guidance (MSAG), and adaptive input perturbation (DDPM-AIP).</li>
<li>results: Effective improvement in image restoration performance.Here’s the simplified Chinese text:</li>
<li>for: 图像阴影除去和图像修复。</li>
<li>methods: Deshadow-Anything模型、大规模数据集微调、扩散模型、多自注意导航（MSAG）和适应输入扰动（DDPM-AIP）。</li>
<li>results: 图像修复性能得到明显改进。<details>
<summary>Abstract</summary>
Segment Anything (SAM), an advanced universal image segmentation model trained on an expansive visual dataset, has set a new benchmark in image segmentation and computer vision. However, it faced challenges when it came to distinguishing between shadows and their backgrounds. To address this, we developed Deshadow-Anything, considering the generalization of large-scale datasets, and we performed Fine-tuning on large-scale datasets to achieve image shadow removal. The diffusion model can diffuse along the edges and textures of an image, helping to remove shadows while preserving the details of the image. Furthermore, we design Multi-Self-Attention Guidance (MSAG) and adaptive input perturbation (DDPM-AIP) to accelerate the iterative training speed of diffusion. Experiments on shadow removal tasks demonstrate that these methods can effectively improve image restoration performance.
</details>
<details>
<summary>摘要</summary>
segments anything (SAM), an advanced universal image segmentation model trained on an expansive visual dataset, has set a new benchmark in image segmentation and computer vision. However, it faced challenges when it came to distinguishing between shadows and their backgrounds. To address this, we developed Deshadow-Anything, considering the generalization of large-scale datasets, and we performed Fine-tuning on large-scale datasets to achieve image shadow removal. The diffusion model can diffuse along the edges and textures of an image, helping to remove shadows while preserving the details of the image. Furthermore, we design Multi-Self-Attention Guidance (MSAG) and adaptive input perturbation (DDPM-AIP) to accelerate the iterative training speed of diffusion. Experiments on shadow removal tasks demonstrate that these methods can effectively improve image restoration performance.Here's the breakdown of the text in Simplified Chinese:segments anything (SAM)：这是一个先进的通用图像分割模型，通过一个庞大的视觉数据集进行训练，为图像分割和计算机视觉设置了新的标准。However, it faced challenges when it came to distinguishing between shadows and their backgrounds：这个模型在分割阴影和背景之间困难。To address this, we developed Deshadow-Anything：为解决这个问题，我们开发了Deshadow-Anything。considering the generalization of large-scale datasets：我们考虑了大规模数据集的通用性。and we performed Fine-tuning on large-scale datasets to achieve image shadow removal：我们在大规模数据集上进行细化调整，以实现图像阴影除去。The diffusion model can diffuse along the edges and textures of an image, helping to remove shadows while preserving the details of the image：涉游模型可以在图像的边缘和Texture上扩散，帮助去除阴影，保留图像的细节。Furthermore, we design Multi-Self-Attention Guidance (MSAG) and adaptive input perturbation (DDPM-AIP) to accelerate the iterative training speed of diffusion：我们还设计了多重自我注意力指导（MSAG）和适应输入扰动（DDPM-AIP），以加速涉游训练的迭代速度。Experiments on shadow removal tasks demonstrate that these methods can effectively improve image restoration performance：实验表明，这些方法可以有效提高图像恢复性能。
</details></li>
</ul>
<hr>
<h2 id="MoDA-Leveraging-Motion-Priors-from-Videos-for-Advancing-Unsupervised-Domain-Adaptation-in-Semantic-Segmentation"><a href="#MoDA-Leveraging-Motion-Priors-from-Videos-for-Advancing-Unsupervised-Domain-Adaptation-in-Semantic-Segmentation" class="headerlink" title="MoDA: Leveraging Motion Priors from Videos for Advancing Unsupervised Domain Adaptation in Semantic Segmentation"></a>MoDA: Leveraging Motion Priors from Videos for Advancing Unsupervised Domain Adaptation in Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11711">http://arxiv.org/abs/2309.11711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Pan, Xu Yin, Seokju Lee, Sungeui Yoon, In So Kweon</li>
<li>for: 这篇论文的目的是提出一个更实用的领域对应（UDA）方法，用于处理 semantic segmentation 任务中缺乏目标领域标签的问题。</li>
<li>methods: 这篇论文使用了自我指导学习，将 object motion 自然地从无标签的影像中学习出高效的表示。</li>
<li>results: 实验结果显示，MoDA 比已有方法更有效地处理领域对应题，并且可以与现有的 state-of-the-art 方法相结合以进一步提高性能。<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) is an effective approach to handle the lack of annotations in the target domain for the semantic segmentation task. In this work, we consider a more practical UDA setting where the target domain contains sequential frames of the unlabeled videos which are easy to collect in practice. A recent study suggests self-supervised learning of the object motion from unlabeled videos with geometric constraints. We design a motion-guided domain adaptive semantic segmentation framework (MoDA), that utilizes self-supervised object motion to learn effective representations in the target domain. MoDA differs from previous methods that use temporal consistency regularization for the target domain frames. Instead, MoDA deals separately with the domain alignment on the foreground and background categories using different strategies. Specifically, MoDA contains foreground object discovery and foreground semantic mining to align the foreground domain gaps by taking the instance-level guidance from the object motion. Additionally, MoDA includes background adversarial training which contains a background category-specific discriminator to handle the background domain gaps. Experimental results on multiple benchmarks highlight the effectiveness of MoDA against existing approaches in the domain adaptive image segmentation and domain adaptive video segmentation. Moreover, MoDA is versatile and can be used in conjunction with existing state-of-the-art approaches to further improve performance.
</details>
<details>
<summary>摘要</summary>
无监督领域适应（USDA）是一种有效的方法，用于处理目标领域中缺乏标注的问题。在这项工作中，我们考虑了更实用的USDA设定，其中目标领域包含序列帧的无标注视频，这些视频易于在实践中收集。一项latest study suggests self-supervised learning of object motion from unlabeled videos with geometric constraints。我们设计了一个基于自我指导的领域适应Semantic segmentation框架（MoDA），该框架利用无标注视频中的自我指导对象运动来学习有效的表示。MoDA与之前的方法不同，它不使用目标领域帧的时间一致约束。相反，MoDA在前景和背景类别上分别进行领域对接，使用不同的策略。具体来说，MoDA包括前景 объек discovery和前景semantic mining，用于对接前景领域的差距。此外，MoDA还包括背景对抗培训，其中包括一个特定于背景类别的挑战器，用于处理背景领域的差距。实验结果表明，MoDA在多个benchmark上比既有approaches更有效，并且MoDA可以与现有的state-of-the-art方法相结合，以进一步提高性能。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Long-Short-Temporal-Attention-Network-for-Unsupervised-Video-Object-Segmentation"><a href="#Efficient-Long-Short-Temporal-Attention-Network-for-Unsupervised-Video-Object-Segmentation" class="headerlink" title="Efficient Long-Short Temporal Attention Network for Unsupervised Video Object Segmentation"></a>Efficient Long-Short Temporal Attention Network for Unsupervised Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11707">http://arxiv.org/abs/2309.11707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Li, Yu Zhang, Li Yuan, Huaxin Xiao, Binbin Lin, Xianghua Xu</li>
<li>For: Unsupervised video object segmentation (VOS) in real-time, without prior knowledge.* Methods: Proposed Long-Short Temporal Attention (LSTA) network, consisting of Long Temporal Memory and Short Temporal Attention modules, with efficient projection and locality-based sliding window techniques for speedup.* Results: Promising performances on several benchmarks with high efficiency.<details>
<summary>Abstract</summary>
Unsupervised Video Object Segmentation (VOS) aims at identifying the contours of primary foreground objects in videos without any prior knowledge. However, previous methods do not fully use spatial-temporal context and fail to tackle this challenging task in real-time. This motivates us to develop an efficient Long-Short Temporal Attention network (termed LSTA) for unsupervised VOS task from a holistic view. Specifically, LSTA consists of two dominant modules, i.e., Long Temporal Memory and Short Temporal Attention. The former captures the long-term global pixel relations of the past frames and the current frame, which models constantly present objects by encoding appearance pattern. Meanwhile, the latter reveals the short-term local pixel relations of one nearby frame and the current frame, which models moving objects by encoding motion pattern. To speedup the inference, the efficient projection and the locality-based sliding window are adopted to achieve nearly linear time complexity for the two light modules, respectively. Extensive empirical studies on several benchmarks have demonstrated promising performances of the proposed method with high efficiency.
</details>
<details>
<summary>摘要</summary>
Unsupervised Video Object Segmentation (VOS) targets identifying primary foreground object contours in videos without prior knowledge. However, previous methods do not fully utilize spatial-temporal context and fail to tackle this challenging task in real-time. This motivates us to develop an efficient Long-Short Temporal Attention network (LSTA) for unsupervised VOS from a holistic view. Specifically, LSTA consists of two dominant modules: Long Temporal Memory and Short Temporal Attention. The former captures long-term global pixel relations of past frames and the current frame, modeling constantly present objects by encoding appearance pattern. Meanwhile, the latter reveals short-term local pixel relations of one nearby frame and the current frame, modeling moving objects by encoding motion pattern. To speed up inference, efficient projection and locality-based sliding window are adopted to achieve nearly linear time complexity for the two light modules, respectively. Extensive empirical studies on several benchmarks have demonstrated promising performances of the proposed method with high efficiency.
</details></li>
</ul>
<hr>
<h2 id="Meta-OOD-Learning-for-Continuously-Adaptive-OOD-Detection"><a href="#Meta-OOD-Learning-for-Continuously-Adaptive-OOD-Detection" class="headerlink" title="Meta OOD Learning for Continuously Adaptive OOD Detection"></a>Meta OOD Learning for Continuously Adaptive OOD Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11705">http://arxiv.org/abs/2309.11705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinheng Wu, Jie Lu, Zhen Fang, Guangquan Zhang</li>
<li>for: 这篇论文目的是为了提出一种基于流动分布的假值检测方法，以适应现实世界中的动态和不断变化的分布。</li>
<li>methods: 本文使用了元学习的方法，包括设计了一个学习到适应图表，以便在训练过程中初始化一个好的假值检测模型，并在测试过程中快速适应新的分布。</li>
<li>results: 实验结果显示，本文的方法可以保持ID类别准确率和假值检测性能，在流动分布下进行测试。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is crucial to modern deep learning applications by identifying and alerting about the OOD samples that should not be tested or used for making predictions. Current OOD detection methods have made significant progress when in-distribution (ID) and OOD samples are drawn from static distributions. However, this can be unrealistic when applied to real-world systems which often undergo continuous variations and shifts in ID and OOD distributions over time. Therefore, for an effective application in real-world systems, the development of OOD detection methods that can adapt to these dynamic and evolving distributions is essential. In this paper, we propose a novel and more realistic setting called continuously adaptive out-of-distribution (CAOOD) detection which targets on developing an OOD detection model that enables dynamic and quick adaptation to a new arriving distribution, with insufficient ID samples during deployment time. To address CAOOD, we develop meta OOD learning (MOL) by designing a learning-to-adapt diagram such that a good initialized OOD detection model is learned during the training process. In the testing process, MOL ensures OOD detection performance over shifting distributions by quickly adapting to new distributions with a few adaptations. Extensive experiments on several OOD benchmarks endorse the effectiveness of our method in preserving both ID classification accuracy and OOD detection performance on continuously shifting distributions.
</details>
<details>
<summary>摘要</summary>
现代深度学习应用中，外部分布（OOD）检测是关键性能的一部分，可以识别并警示不应该进行测试或预测的外部样本。现有的OOD检测方法在固定分布下已经做出了重要的进步。然而，这可能是不切实际的，因为实际系统经常发生连续变化和分布的更新。因此，为了有效应用于实际系统，需要开发一种能够适应动态和演变分布的OOD检测方法。在这篇论文中，我们提出了一种新的设定，即连续适应外部分布（CAOOD）检测，旨在开发一种能够在部署时间内动态适应新到达的分布，并且只需要很少的标注样本。为了解决CAOOD，我们开发了元外部分布学习（MOL），它通过设计学习适应图来使得一个初始化好的OOD检测模型在训练过程中快速适应新的分布。在测试过程中，MOL确保OOD检测性能在分布Shift过程中保持高效，只需要很少的适应。我们在多个OOD benchmark上进行了广泛的实验，并证明了我们的方法可以保持ID分类精度和OOD检测性能在连续变化的分布下。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.CV_2023_09_21/" data-id="clmvt7t9s00de26rd2ghrbp2n" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.AI_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T12:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.AI_2023_09_21/">cs.AI - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ForceSight-Text-Guided-Mobile-Manipulation-with-Visual-Force-Goals"><a href="#ForceSight-Text-Guided-Mobile-Manipulation-with-Visual-Force-Goals" class="headerlink" title="ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals"></a>ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12312">http://arxiv.org/abs/2309.12312</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AlenoWar/For-friends1231231230-23092">https://github.com/AlenoWar/For-friends1231231230-23092</a></li>
<li>paper_authors: Jeremy A. Collins, Cody Houff, You Liang Tan, Charles C. Kemp</li>
<li>for: 本文描述了一种基于深度学习的文本导引移动抓取系统，可以预测视觉力目标和相应的力目标。</li>
<li>methods: 该系统使用深度神经网络，根据单个RGBD图像和文本提示，确定目标减动器姿态和相应的力目标。</li>
<li>results: 在一个实验中，该系统在不同物体实例和未看过的环境中完成了精准抓取、抽屉打开和物体传递等任务，成功率为81%。在另一个实验中，仅通过视觉服务器而忽略力目标时，成功率降低至45%，这表明力目标可以显著提高性能。<details>
<summary>Abstract</summary>
We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network. Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal). Together, these two components form a visual-force goal. Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots. Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems. When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data. In a separate experiment, relying exclusively on visual servoing and ignoring force goals dropped the success rate from 90% to 45%, demonstrating that force goals can significantly enhance performance. The appendix, videos, code, and trained models are available at https://force-sight.github.io/.
</details>
<details>
<summary>摘要</summary>
我们现在提出了 ForceSight，一种基于文本导引的移动操作系统，该系统使用深度神经网络预测视觉力目标。给定一个RGBD图像和文本提示，ForceSight可以确定摄像头帧中的目标器位（动力目标）以及相关的力（力目标）。这两个组成部分共同形成了视觉力目标。在先前的研究中，使用深度模型输出人类可解释的动力目标可以实现灵活的操作。然而，在这些系统中，力通常被视为低级别执行。当部署在搭载了眼在手RGBD相机的移动操作器时，ForceSight在不同环境中完成了精度抓取、抽屉打开和物品传递等任务，成功率达81%。在另一个实验中，完全依赖于视觉服务并忽略力目标，成功率从90%下降到45%，这表明力目标可以明显提高性能。详细信息、视频、代码和训练模型可以在<https://force-sight.github.io/>上获取。
</details></li>
</ul>
<hr>
<h2 id="LLM-Grounder-Open-Vocabulary-3D-Visual-Grounding-with-Large-Language-Model-as-an-Agent"><a href="#LLM-Grounder-Open-Vocabulary-3D-Visual-Grounding-with-Large-Language-Model-as-an-Agent" class="headerlink" title="LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent"></a>LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12311">http://arxiv.org/abs/2309.12311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianing Yang, Xuweiyi Chen, Shengyi Qian, Nikhil Madaan, Madhavan Iyengar, David F. Fouhey, Joyce Chai</li>
<li>for: 提高家用机器人的3D视觉固定率，使其能够基于环境进行导航、对象搜索和回答问题。</li>
<li>methods: 提出了一种基于大语言模型（LLM）的开放词汇、零shot的3D视觉固定率管道，使用LLM将自然语言查询分解成 semantic constituents，并使用视觉固定工具（如OpenScene或LERF）来确定3D场景中的对象。</li>
<li>results: 在ScanRefer benchmark上进行评估，显示了与状态艺术的零shot固定率表现，尤其是对于复杂的自然语言查询。<details>
<summary>Abstract</summary>
3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment. While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene. The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision. Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy. Our findings indicate that LLMs significantly improve the grounding capability, especially for complex language queries, making LLM-Grounder an effective approach for 3D vision-language tasks in robotics. Videos and interactive demos can be found on the project website https://chat-with-nerf.github.io/ .
</details>
<details>
<summary>摘要</summary>
三维视觉固定是家庭机器人的关键技能，它允许机器人在环境中导航、操作物品以及回答问题。现有的方法通常需要大量标注数据或者具有处理复杂语言查询的限制，而我们提出了LLM-Grounder，一种新的零批量、开 vocabulary 的大语言模型（LLM）基于的三维视觉固定管道。LLM-Grounder 使用 LLM 将复杂的自然语言查询分解成 semantic constituents，然后使用三维场景识别工具，如 OpenScene 或 LERF，确定场景中的物体。LLM 然后评估场景中提议的物体之间的空间和通用感知关系，以确定最终的固定决策。我们的方法不需要任何标注训练数据，可以泛化到新的三维场景和任意文本查询。我们在 ScanRefer benchmark 上进行了评估，并示出了零批量固定精度。我们的发现表明，LLM 可以大幅提高固定能力，特别是对复杂语言查询，使LLM-Grounder 成为三维视觉语言任务中的有效方法。视频和互动示例可以在项目网站 https://chat-with-nerf.github.io/ 找到。
</details></li>
</ul>
<hr>
<h2 id="Rehearsal-Simulating-Conflict-to-Teach-Conflict-Resolution"><a href="#Rehearsal-Simulating-Conflict-to-Teach-Conflict-Resolution" class="headerlink" title="Rehearsal: Simulating Conflict to Teach Conflict Resolution"></a>Rehearsal: Simulating Conflict to Teach Conflict Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12309">http://arxiv.org/abs/2309.12309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Shaikh, Valentino Chai, Michele J. Gelfand, Diyi Yang, Michael S. Bernstein</li>
<li>for: 提高冲突管理技能</li>
<li>methods: 使用 simulate 人工智能对话者进行冲突练习，探索不同的对话路径，并通过Feedback学习冲突解决策略。</li>
<li>results: 在比对组与控制组之间进行实验后，参与者们通过使用 Rehearsal 增强了冲突管理技能，减少了竞争策略的使用率，同时 doubling 合作策略的使用率。<details>
<summary>Abstract</summary>
Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.
</details>
<details>
<summary>摘要</summary>
人际冲突是生活中不可避免的一个不舒适的事实。成功 navigating 冲突是一种技能 -- 可以通过意识的练习学习 -- 但是很少人有效的训练和反馈。为了扩大这种训练的access，我们介绍了 Rehearsal，一个系统，允许用户通过与生动的 simulate 对话者进行模拟冲突，探索不同的对话路径，并通过反馈学习冲突策略。用户可以使用 Rehearsal 练习各种预先定义的冲突场景，从办公室争议到关系问题，或者他们可以创建自己的。为了实现 Rehearsal，我们开发了 IRP 提示，一种基于冲突解决理论中的有力 Interest-Rights-Power（IRP）的方法，用于生成与冲突解决相关的语言模型输出。Rehearsal 使用 IRP 生成对话，引导用户采用不同的对话策略，以帮助他们在困难的对话中减少竞争策略的使用，同时增加合作策略的使用。在一个 between-subjects 评估中，40名参与者在与假对手进行实际冲突后接受了 simulated 训练。与控制组（ receives 同 IRP 理论的讲解材料）相比，参与者通过 Rehearsal 的模拟训练显著改善了他们在无助的冲突中的表现，减少了竞争策略的使用量by 67%，同时 doubling 合作策略的使用。总之，Rehearsal highlights 语言模型的潜在效果iveness 作为人际技能学习和练习的工具。
</details></li>
</ul>
<hr>
<h2 id="LongLoRA-Efficient-Fine-tuning-of-Long-Context-Large-Language-Models"><a href="#LongLoRA-Efficient-Fine-tuning-of-Long-Context-Large-Language-Models" class="headerlink" title="LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"></a>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12307">http://arxiv.org/abs/2309.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dvlab-research/longlora">https://github.com/dvlab-research/longlora</a></li>
<li>paper_authors: Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song Han, Jiaya Jia</li>
<li>for: 这 paper 是为了提高大型语言模型（LLM）的上下文大小，并且减少计算成本。</li>
<li>methods: 这 paper 使用了两种方法来减少计算成本：1) 使用稀疏的局部注意力进行微调，而不是 dense 的全球注意力；2) 修改 LoRA 的参数fficient fine-tuning 策略，以便在训练时使用更小的上下文大小。</li>
<li>results: 这 paper 在多个任务上都显示了优秀的 empirical  результаhat,包括使用 LLaMA2 模型从 7B&#x2F;13B 到 70B，并在单个 8x A100 机器上完成了Context 的扩展。<details>
<summary>Abstract</summary>
We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA demonstrates strong empirical results on various tasks on LLaMA2 models from 7B/13B to 70B. LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like FlashAttention-2. In addition, to make LongLoRA practical, we collect a dataset, LongQA, for supervised fine-tuning. It contains more than 3k long context question-answer pairs.
</details>
<details>
<summary>摘要</summary>
我们介绍了LongLoRA，一种高效的微调方法，可以将预训练的大型自然语言模型（LLM）的上下文大小扩展，而不需要很多计算成本。通常，在训练LLMs时，使用长context大小需要大量的计算时间和GPU资源。例如，在context长度为8192时，自我注意层的计算成本将增加16倍。在这篇论文中，我们提高了LLM的上下文扩展的计算效率，从两个方面进行了优化。一方面，虽然在推理时需要 dense global attention，但是在微调过程中可以使用笔 sparse local attention，从而提高计算效率。我们提出了shift short attention技术，可以快速扩展上下文，同时保持与原始模型的性能相似。另一方面，我们再次检视了参数效率微调环境，发现LoRA在trainable embedding和normalization的前提下，可以很好地扩展上下文。LongLoRA在多个任务上获得了强的实际结果，使用LLaMA2模型从7B/13B到70B。LongLoRA可以在单个8x A100机器上从4k context扩展到100k，或者从70B扩展到32k。LongLoRA可以保持原始模型的结构，与大多数现有技术兼容，如FlashAttention-2。此外，为使LongLoRA实用，我们收集了一个超过3k长context问答对的数据集，名为LongQA。
</details></li>
</ul>
<hr>
<h2 id="Environment-biased-Feature-Ranking-for-Novelty-Detection-Robustness"><a href="#Environment-biased-Feature-Ranking-for-Novelty-Detection-Robustness" class="headerlink" title="Environment-biased Feature Ranking for Novelty Detection Robustness"></a>Environment-biased Feature Ranking for Novelty Detection Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12301">http://arxiv.org/abs/2309.12301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Smeu, Elena Burceanu, Emanuela Haller, Andrei Liviu Nicolicioiu</li>
<li>for: 本研究的目的是robust novelty detection，即检测 semantic content 中的新鲜事物，并在不同环境下保持检测的稳定性。</li>
<li>methods: 本研究使用了一种基于预训练 embedding 和多环境设置的方法，可以 rank 特征按照其环境吸引力。首先，我们计算了每个特征的分布方差变化强度，然后选择高分的特征进行去除，以消除干扰关系并提高总性能。</li>
<li>results: 我们的方法可以在 covariance 和 sub-population shift 两种情况下提高检测性能，在两个实际和 sintetic benchmark 中实现了6%的提高。<details>
<summary>Abstract</summary>
We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task.
</details>
<details>
<summary>摘要</summary>
我们面临着一个robust新鲜度检测问题，我们想检测新鲜度从 semantics 角度来，而不受其他无关因素的变化影响。特别是，我们在多个环境中运行，并确定了与环境相关的特征，而不是与任务相关的内容。因此，我们提出了一种方法，它从预训练 embedding 和多环境设置开始，然后对特征进行排名，以便根据环境注重。首先，我们计算每个特征的分布方差变化分数，以确定它们在不同环境中的分布情况。接着，我们证明了，通过抛弃高分的特征，可以消除干扰关系，并提高总表现，达到6%的提升，包括covariance和sub-population shift两种情况。这种提升可以在真实和 sintetic  benchmark 中实现。
</details></li>
</ul>
<hr>
<h2 id="See-to-Touch-Learning-Tactile-Dexterity-through-Visual-Incentives"><a href="#See-to-Touch-Learning-Tactile-Dexterity-through-Visual-Incentives" class="headerlink" title="See to Touch: Learning Tactile Dexterity through Visual Incentives"></a>See to Touch: Learning Tactile Dexterity through Visual Incentives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12300">http://arxiv.org/abs/2309.12300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Irmak Guzey, Yinlong Dai, Ben Evans, Soumith Chintala, Lerrel Pinto</li>
<li>for: 提高多指 robot 的灵活搔挠能力，使其能够具备人类的灵活搔挠能力。</li>
<li>methods: 使用视觉奖励来优化气肺动作策略，并通过对人类示范的对比来学习视觉表示。</li>
<li>results: 在六个复杂任务中，TAVI 实现了 73% 的成功率，比使用气肺动作和视觉奖励的策略高出 108%，比没有气肺 observational 输入的策略高出 135%。<details>
<summary>Abstract</summary>
Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: https://see-to-touch.github.io/.
</details>
<details>
<summary>摘要</summary>
Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: <https://see-to-touch.github.io/>.Here's the translation in Traditional Chinese:Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: <https://see-to-touch.github.io/>.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Drive-Anywhere"><a href="#Learning-to-Drive-Anywhere" class="headerlink" title="Learning to Drive Anywhere"></a>Learning to Drive Anywhere</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12295">http://arxiv.org/abs/2309.12295</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Ruizhao Zhu, Peng Huang, Eshed Ohn-Bar, Venkatesh Saligrama</li>
<li>for: 本研究旨在提出一种能够快速适应不同地区和交通规则的自动驾驶模型，以满足现代自动驾驶系统的需求。</li>
<li>methods: 该模型使用了条件学习和地理位置信息来适应不同地区的驾驶行为，并通过对照学习对象来快速学习和适应不同的驾驶情况。</li>
<li>results: 研究表明，该模型可以在多个数据集、城市和部署方式下表现出色，比如中央化、半supervised和分布式 Agent 训练方式，并且在 CARLA 上测试中比基eline 高出14%。<details>
<summary>Abstract</summary>
Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic. In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability. In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics. Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner. By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and location-dependent events. We demonstrate the benefits of our AnyD agent across multiple datasets, cities, and scalable deployment paradigms, i.e., centralized, semi-supervised, and distributed agent training. Specifically, AnyD outperforms CIL baselines by over 14% in open-loop evaluation and 30% in closed-loop testing on CARLA.
</details>
<details>
<summary>摘要</summary>
人类驾驶员可以无缝地适应不同地区的条件和道路规则，如左右手交通。然而，现有的自动驾驶模型只能在限定的运行Domain中进行部署，无法考虑不同地区的驾驶行为或模型扩展性。在这种工作中，我们提出AnyD，一种能够快速学习从多元化和全球分布的数据中的 conditional imitation learning（CIL）模型。我们的关键发现是引入高容量的地理位置基于的通道注意力机制，可以有效地适应当地特性，同时也可以数据驱动地模型同地区之间的相似性。通过优化一个对比式学习目标函数，我们的提出的方法可以高效地扩展到自然具有偏斜分布的数据集和地点事件。我们在多个数据集、城市和扩展模型训练方法（中央、半supervised、分布式代理训练）上展示了AnyD代理的优势， Specifically, AnyD比CIL基eline高出14%在开loop评估中和30%在closed-loop测试中。
</details></li>
</ul>
<hr>
<h2 id="The-Reversal-Curse-LLMs-trained-on-“A-is-B”-fail-to-learn-“B-is-A”"><a href="#The-Reversal-Curse-LLMs-trained-on-“A-is-B”-fail-to-learn-“B-is-A”" class="headerlink" title="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"></a>The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12288">http://arxiv.org/abs/2309.12288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lukasberglund/reversal_curse">https://github.com/lukasberglund/reversal_curse</a></li>
<li>paper_authors: Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans</li>
<li>for: 这个论文旨在描述一种语言模型具有的惊人的总结不良现象，即模型在句子的逆向方向上不能自动总结。</li>
<li>methods: 这个论文使用了自动推导大语言模型（LLM）的训练和细化来探讨这种现象。</li>
<li>results: 研究发现，即使模型在句子中具有”A是B”的Pattern，它们也不能自动总结”B是A”的句子。这表明模型存在一种基本的逻辑推理失败，并且不能总结句子中的普遍规律。<details>
<summary>Abstract</summary>
We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as "Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]" and the reverse "Who is Mary Lee Pfeiffer's son?". GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse. Code is available at https://github.com/lukasberglund/reversal_curse.
</details>
<details>
<summary>摘要</summary>
我们揭示了普遍性不足的抽象问题在自动进行语言模型（LLM）中。如果一个模型在“A是B”的句子上训练，那么它不会自动推导到“B是A”的方向。这被称为“推倒祸咒”。例如，如果一个模型在“奥拉夫·舒兹是德国第九任总理”上训练，那么它不会自动回答“谁是德国第九任总理？”的问题。此外，对于正确答案（奥拉夫·舒兹）的概率不高于随机名称。因此，模型表现出基本的逻辑推理失败，不能推导出训练集中 prevailing pattern（即“A是B”发生时，“B是A”更 probable）。我们通过在虚假句子上精细调整GPT-3和Llama-1模型，并证明它们在“Uriah Hawthorne是《abyssal Melodies》的作曲家”这类句子上失败，不能正确回答“abyssal Melodies”的作曲家是谁。推倒祸咒是模型大小和家族的robust，不受数据增强的影响。我们还测试了ChatGPT（GPT-3.5和GPT-4）在关于真实名人的问题上，如“谁是汤米·克鲁塞的妈妈？”和其反向“谁是mary Lee Pfeiffer的儿子？”。GPT-4在前者79%的时间内正确回答问题，比后者33%的时间更高。这显示了逻辑推理的失败，我们假设是由推倒祸咒引起的。代码可以在https://github.com/lukasberglund/reversal_curse上找到。
</details></li>
</ul>
<hr>
<h2 id="MetaMath-Bootstrap-Your-Own-Mathematical-Questions-for-Large-Language-Models"><a href="#MetaMath-Bootstrap-Your-Own-Mathematical-Questions-for-Large-Language-Models" class="headerlink" title="MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"></a>MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12284">http://arxiv.org/abs/2309.12284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu<br>for:这篇论文的目的是提高大型自然语言模型（LLM）在数学领域的理解能力，以解决问题时需要进行复杂的推理过程。methods:论文使用了自然语言生成技术，将数学问题重新写成多种角度，从而创建了一个新的数学问题集合（MetaMathQA），并对LLaMA-2模型进行微调。results:实验结果显示，MetaMath模型在两个流行的数学理解测试 benchmark（GSM8K和MATH）上表现出色，较前一代模型高出11.5%和8.7%。特别是，MetaMath-7B模型在GSM8K上得分66.4%，MATH上得分19.4%。<details>
<summary>Abstract</summary>
Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by $11.5\%$ and $8.7\%$. Particularly, {MetaMath-70B} achieves an accuracy of $82.3\%$ on {GSM8K}, slightly better than {GPT-3.5-Turbo}. We release the {MetaMathQA} dataset, the {MetaMath} models with different model sizes and the training code for public use.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）已经推动了自然语言理解的限制，并表现出了优秀的问题解决能力。 despite the great success, most existing open-source LLMs (eg, LLaMA-2) are still far from satisfactory for solving mathematical problems due to complex reasoning procedures. To bridge this gap, we propose 《MetaMath》, a fine-tuned language model specializing in mathematical reasoning. Specifically, we start by rewriting mathematical questions from multiple perspectives without extra knowledge, resulting in a new dataset called {MetaMathQA}. Then, we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (ie, GSM8K and MATH) for mathematical reasoning show that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves 66.4% on GSM8K and 19.4% on MATH, exceeding the state-of-the-art models of the same size by 11.5% and 8.7%. Particularly, our MetaMath-70B model achieves an accuracy of 82.3% on GSM8K, slightly better than GPT-3.5-Turbo. We release the MetaMathQA dataset, the MetaMath models with different model sizes, and the training code for public use.
</details></li>
</ul>
<hr>
<h2 id="LLMR-Real-time-Prompting-of-Interactive-Worlds-using-Large-Language-Models"><a href="#LLMR-Real-time-Prompting-of-Interactive-Worlds-using-Large-Language-Models" class="headerlink" title="LLMR: Real-time Prompting of Interactive Worlds using Large Language Models"></a>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12276">http://arxiv.org/abs/2309.12276</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asem010/legend-pice">https://github.com/asem010/legend-pice</a></li>
<li>paper_authors: Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier</li>
<li>for: 这个论文是为了描述一种基于大自然语言模型（LLM）的混合现实创作和修改框架，用于实时创建和修改互动型混合现实经验。</li>
<li>methods: 该框架使用了一些新的策略来解决缺乏理想训练数据或需要 sintheziser internal dynamics、intuitive analysis 和高级互动性的情况。它使用文本交互和 Unity 游戏引擎，并包括Scene Understanding、Task Planning、Self-Debugging 和 Memory Management 等技术。</li>
<li>results: 与标准 GPT-4 相比，LLMR 的平均错误率下降至 4 倍。作者们在多个示例世界中证明了 LLMR 的跨平台兼容性，并通过许多创建和修改任务来表明它可以生成和编辑多样化的对象、工具和场景。最后，作者们进行了一项用户研究（N&#x3D;11），发现参与者们对系统有积极的经验，并表示会再次使用它。<details>
<summary>Abstract</summary>
We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
</details>
<details>
<summary>摘要</summary>
我团队推出了混合现实语言大型模型框架（LLMR），用于在实时创建和修改混合现实体验的实时创作和修改。 LLMR 采用了新的策略来解决缺乏理想训练数据或设计目标需要内在动力、直观分析或高级互动的情况。 我们的框架基于文本交互和 Unity 游戏引擎，并包括场景理解、任务规划、自我调试和内存管理等技术。 相比标准 GPT-4，LLMR 的平均错误率下降了4倍。 我们示例了 LLMR 的跨平台兼容性，并对多种创建和修改任务进行了评估，以示其能够生成和修改多样化的对象、工具和场景。 最后，我们进行了一项用户研究（N=11），发现参与者们有积极的体验，并表示他们会再次使用这系统。
</details></li>
</ul>
<hr>
<h2 id="Enabling-Quartile-based-Estimated-Mean-Gradient-Aggregation-As-Baseline-for-Federated-Image-Classifications"><a href="#Enabling-Quartile-based-Estimated-Mean-Gradient-Aggregation-As-Baseline-for-Federated-Image-Classifications" class="headerlink" title="Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications"></a>Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12267">http://arxiv.org/abs/2309.12267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusen Wu, Jamie Deng, Hao Chen, Phuong Nguyen, Yelena Yesha</li>
<li>for: 本研究旨在提出一种名为Estimated Mean Aggregation（EMA）的创新解决方案，用于解决 Federated Learning（FL）系统中数据多样性和安全性问题。</li>
<li>methods: EMA使用trimmed means来有效地处理恶意外异值，同时揭示数据不同性，以确保训练的模型在各客户端数据上具备适应性。</li>
<li>results: EMA在一系列实验中表现出高准确率和地下曲线Area Under the Curve（AUC），相比其他方法，EMA成为FL集成方法评估效果和安全性的基本参考点。EMA的贡献因此为FL系统的效率、安全性和多样性带来了重要的进步。<details>
<summary>Abstract</summary>
Federated Learning (FL) has revolutionized how we train deep neural networks by enabling decentralized collaboration while safeguarding sensitive data and improving model performance. However, FL faces two crucial challenges: the diverse nature of data held by individual clients and the vulnerability of the FL system to security breaches. This paper introduces an innovative solution named Estimated Mean Aggregation (EMA) that not only addresses these challenges but also provides a fundamental reference point as a $\mathsf{baseline}$ for advanced aggregation techniques in FL systems. EMA's significance lies in its dual role: enhancing model security by effectively handling malicious outliers through trimmed means and uncovering data heterogeneity to ensure that trained models are adaptable across various client datasets. Through a wealth of experiments, EMA consistently demonstrates high accuracy and area under the curve (AUC) compared to alternative methods, establishing itself as a robust baseline for evaluating the effectiveness and security of FL aggregation methods. EMA's contributions thus offer a crucial step forward in advancing the efficiency, security, and versatility of decentralized deep learning in the context of FL.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）已经革命化了深度神经网络的训练方式，使得各个客户端的数据可以共同合作，同时保护敏感数据和提高模型性能。然而，FL还面临两个重要挑战：客户端数据的多样性和FL系统的安全性。这篇文章提出了一个创新的解决方案，即估算平均联合（EMA），这个方法不仅能够有效地处理邪恶的偏出现，同时也能够探索数据的多样性，以确保训练出来的模型能够适应不同的客户端数据。通过丰富的实验，EMA证明了它在精确率和投影面积（AUC）方面的优秀性，并成为FL联合方法的基本底线，这让EMA在评估FL联合方法的效iveness和安全性方面提供了一个重要的引用点。EMA的贡献因此为FL技术的效率、安全性和多样性带来了一个重要的进步。
</details></li>
</ul>
<hr>
<h2 id="SALSA-CLRS-A-Sparse-and-Scalable-Benchmark-for-Algorithmic-Reasoning"><a href="#SALSA-CLRS-A-Sparse-and-Scalable-Benchmark-for-Algorithmic-Reasoning" class="headerlink" title="SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning"></a>SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12253">http://arxiv.org/abs/2309.12253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jkminder/salsa-clrs">https://github.com/jkminder/salsa-clrs</a></li>
<li>paper_authors: Julian Minder, Florian Grötschla, Joël Mathys, Roger Wattenhofer</li>
<li>for: 本文提出了一个扩展版的CLRS算法学习benchmark，强调可扩展性和使用稀疏表示。</li>
<li>methods: 本文使用了适应算法从原CLRSbenchmark中，以及新增的分布式和随机算法。</li>
<li>results: 本文进行了广泛的实验评估。<details>
<summary>Abstract</summary>
We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations. Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem. Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale). However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks. Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind. Our approach includes adapted algorithms from the original CLRS benchmark and introduces new problems from distributed and randomized algorithms. Moreover, we perform a thorough empirical evaluation of our benchmark. Code is publicly available at https://github.com/jkminder/SALSA-CLRS.
</details>
<details>
<summary>摘要</summary>
我们介绍一个对CLRS算法学习标准的扩展，强调可扩展性和使用稀疏表示。许多CLRS中的算法需要全球内存或资讯交换，这反映在它的执行模型中，它会建立全连接（不稀疏）图基于下面问题。尽管CLRS的目的是评估学习算法如何对更大的实例进行扩展，但现有的执行模型对于内存需求和时间成本（Difficult to scale）具有显著的限制。然而，许多重要的算法不需要全连接图，这些算法通常是分布式的，与Graph Neural Networks中的讯息传递模式相似。因此，我们提出了SALSA-CLRS，一个CLRS标准的扩展，专注于可扩展性和稀疏性。我们的方法包括原CLRS标准中的修改算法和新问题，并对我们的标准进行了详细的实验评估。代码可以在https://github.com/jkminder/SALSA-CLRS上下载。
</details></li>
</ul>
<hr>
<h2 id="Bad-Actor-Good-Advisor-Exploring-the-Role-of-Large-Language-Models-in-Fake-News-Detection"><a href="#Bad-Actor-Good-Advisor-Exploring-the-Role-of-Large-Language-Models-in-Fake-News-Detection" class="headerlink" title="Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection"></a>Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12247">http://arxiv.org/abs/2309.12247</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ictmcg/arg">https://github.com/ictmcg/arg</a></li>
<li>paper_authors: Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, Peng Qi<br>for: 这篇论文主要研究了大语言模型（LLMs）在假新闻检测方面的潜力。methods: 作者采用了一种名为 adaptive rationale guidance network（ARG）的网络，该网络使用了精心调整的小语言模型（SLMs）和大语言模型（LLMs）来检测假新闻。results: 实验结果显示，作者的方法可以在两个实际数据集上超过三种基eline方法，包括SLM-based、LLM-based和这两种模型的组合。<details>
<summary>Abstract</summary>
Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models.
</details>
<details>
<summary>摘要</summary>
检测假新闻需要一种细腻的多种迹象推理和深刻的现实背景理解，这些检测器基于小语言模型（SLM）的知识和能力限制使得它们的表现还有限。然而，大语言模型（LLM）的最近进步在多种任务中表现出色，但是LLM是否可以帮助检测假新闻仍然未得到充分探索。本文 investigate LLM在假新闻检测中的潜力。我们首先进行实验研究，发现一个成熟的LLM如GPT 3.5可以暴露假新闻并提供愉悦多元理由，但是仍然落后于精通BERT的基本SLM。我们 subsequnt分析发现这种差距是因为LLM无法正确地选择和 инте格 rationales来结论。根据这些发现，我们提出了LLM不能完全取代精通SLM，但可以作为SLM的好助手，提供多元指导性的理由。为实现这一提议，我们设计了一个适应性 rationales 指导网络（ARG），其中SLM可以选择性地从LLM的理由中获得分析新闻的 instruciton。此外，我们还 derivation 一个不需要 rationales 的ARG-D版本，通过浸泡来实现cost-sensitive场景中的服务。我们在两个实际数据集上进行实验，发现ARG和ARG-D都高于三种基eline方法，包括SLM、LLM和小语言模型和大语言模型的组合。
</details></li>
</ul>
<hr>
<h2 id="ChaCha-Leveraging-Large-Language-Models-to-Prompt-Children-to-Share-Their-Emotions-about-Personal-Events"><a href="#ChaCha-Leveraging-Large-Language-Models-to-Prompt-Children-to-Share-Their-Emotions-about-Personal-Events" class="headerlink" title="ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events"></a>ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12244">http://arxiv.org/abs/2309.12244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Woosuk Seo, Chanmo Yang, Young-Ho Kim</li>
<li>for: 本研究旨在开发一个名为ChaCha的谈话机器人，以便儿童通过分享自己的故事和感受来学习表达情感。</li>
<li>methods: 这个研究使用了状态机和大语言模型（LLMs），以保持对话在轨道，同时允许儿童自由发展对话。</li>
<li>results: 经过对20名儿童（年龄在8-12岁）的exploratory研究发现，儿童认为ChaCha是一个亲密的朋友，并将个人故事和感受分享给ChaCha。研究发现，使用LLMs可以设计出适合儿童的谈话机器人，以支持儿童在表达情感方面。<details>
<summary>Abstract</summary>
Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to support children in sharing their emotions.
</details>
<details>
<summary>摘要</summary>
孩子通常通过与他们的家人分享故事和感受来学习识别和表达情感。然而，由于孩子的通信技能还在发展，因此与孩子进行情感交流可以是很困难的。我们提出了 ChaCha，一个聊天机器人，它鼓励和指导孩子分享个人事件和相关的情感。ChaCha结合状态机和大型自然语言模型（LLMs），以保持对话在轨而进行自由化对话。经过20名8-12岁的孩子参与的exploratory研究，我们发现ChaCha可以让孩子 perceive为一个亲密的朋友，并让他们分享各种话题，如家庭旅行和个人成就。根据量化和质化的结果，我们讨论了如何通过LLMs设计为孩子友好的聊天机器人，以支持孩子在表达情感方面。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Artificial-Intelligence-for-Drug-Discovery-and-Development-–-A-Comprehensive-Survey"><a href="#Explainable-Artificial-Intelligence-for-Drug-Discovery-and-Development-–-A-Comprehensive-Survey" class="headerlink" title="Explainable Artificial Intelligence for Drug Discovery and Development – A Comprehensive Survey"></a>Explainable Artificial Intelligence for Drug Discovery and Development – A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12177">http://arxiv.org/abs/2309.12177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roohallah Alizadehsani, Sadiq Hussain, Rene Ripardo Calixto, Victor Hugo C. de Albuquerque, Mohamad Roshanzamir, Mohamed Rahouti, Senthil Kumar Jagatheesaperumal<br>for:* 这篇评论文章旨在提供对XAI技术在药物发现领域的全面了解，以及XAI技术在药物发现中的应用和挑战。methods:* 这篇评论文章总结了目前XAI技术在药物发现领域的状态，包括各种XAI方法的应用和挑战，以及XAI技术在药物发现中的应用。results:* 这篇评论文章结合了XAI技术在药物发现中的应用，包括目标预测、化学物质设计和毒性预测等方面。同时，文章还提出了未来XAI技术在药物发现领域的可能性和挑战。<details>
<summary>Abstract</summary>
The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furthermore, the article suggests potential future research directions for the application of XAI in drug discovery. The aim of this review article is to provide a comprehensive understanding of the current state of XAI in drug discovery and its potential to transform the field.
</details>
<details>
<summary>摘要</summary>
随着人工智能（AI）和机器学习（ML）技术的出现，药物发现领域经历了极具挑战性的变革。然而，随着AI和ML模型的复杂化，需要对这些模型的透明度和可解释性的需求也在增加。解释人工智能（XAI）是一种新的方法，它能够提供更加可解释的机器学习模型预测结果的理解。在过去几年中，对药物发现领域应用XAI技术的兴趣不断增加。本文提供了药物发现领域XAI技术的现状报告，包括不同的XAI方法、其在药物发现中的应用、以及XAI技术在药物发现中的挑战和限制。此外，文章还概述了XAI在药物发现中的应用，包括目标识别、化合物设计和毒性预测。最后，文章还提出了未来对XAI在药物发现领域的研究发展的可能性。本文的目的是为读者提供药物发现领域XAI技术的全面了解，以及其在未来可能带来的变革。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Domain-Adaptation-for-Self-Driving-from-Past-Traversal-Features"><a href="#Unsupervised-Domain-Adaptation-for-Self-Driving-from-Past-Traversal-Features" class="headerlink" title="Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features"></a>Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12140">http://arxiv.org/abs/2309.12140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Travis Zhang, Katie Luo, Cheng Perng Phoo, Yurong You, Wei-Lun Chao, Bharath Hariharan, Mark Campbell, Kilian Q. Weinberger</li>
<li>for: 提高自动驾驶车辆中3D对象检测系统的准确性。</li>
<li>methods: 利用无标签重复游走多个位置来适应新的驾驶环境，并通过计算重复LiDAR扫描数据的统计来导航适应过程。</li>
<li>results: 提高了基于LiDAR的检测模型，使其更适应不同的驾驶环境，并在实际数据集上实现了up to 20点的性能提升，尤其是检测人行和远距离对象。Here’s the translation in English:</li>
<li>for: To improve the accuracy of 3D object detection systems for self-driving cars.</li>
<li>methods: Utilize unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments, and leverage statistics computed from repeated LiDAR scans to guide the adaptation process.</li>
<li>results: Enhance LiDAR-based detection models, making them more adaptable to different driving environments, and achieve up to 20-point performance gain, especially in detecting pedestrians and distant objects, on real-world datasets.<details>
<summary>Abstract</summary>
The rapid development of 3D object detection systems for self-driving cars has significantly improved accuracy. However, these systems struggle to generalize across diverse driving environments, which can lead to safety-critical failures in detecting traffic participants. To address this, we propose a method that utilizes unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments. By incorporating statistics computed from repeated LiDAR scans, we guide the adaptation process effectively. Our approach enhances LiDAR-based detection models using spatial quantized historical features and introduces a lightweight regression head to leverage the statistics for feature regularization. Additionally, we leverage the statistics for a novel self-training process to stabilize the training. The framework is detector model-agnostic and experiments on real-world datasets demonstrate significant improvements, achieving up to a 20-point performance gain, especially in detecting pedestrians and distant objects. Code is available at https://github.com/zhangtravis/Hist-DA.
</details>
<details>
<summary>摘要</summary>
“自驾车3D对象检测系统的快速发展已经显著提高了准确性。然而，这些系统在不同的驾驶环境下难以泛化，这可能会导致检测交通参与者的失败。为解决这个问题，我们提出了一种方法，它利用多个位置的重复旋转进行不标注的多次旋转，以适应新的驾驶环境。我们通过计算重复扫描 LiDAR 的统计数据，有效地导向适应过程。我们的方法可以增强基于 LiDAR 的检测模型，并引入空间量化历史特征来减少特征训练。此外，我们还利用统计数据进行一种新的自动训练过程，以稳定训练。这个框架是检测模型无关的，实验表明，在真实世界 datasets 上，我们的方法可以获得大约 20 个表现指标的提高，特别是检测人行和远距离对象。代码可以在 https://github.com/zhangtravis/Hist-DA 上获取。”Note: The translation is in Simplified Chinese, which is the standard Chinese writing system used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="On-the-relationship-between-Benchmarking-Standards-and-Certification-in-Robotics-and-AI"><a href="#On-the-relationship-between-Benchmarking-Standards-and-Certification-in-Robotics-and-AI" class="headerlink" title="On the relationship between Benchmarking, Standards and Certification in Robotics and AI"></a>On the relationship between Benchmarking, Standards and Certification in Robotics and AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12139">http://arxiv.org/abs/2309.12139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alan F. T. Winfield, Matthew Studley</li>
<li>for: 本文旨在探讨标准、认证和测试 benchmarking 的关系，并 argue 这三个过程是负责任创新的重要组成部分。</li>
<li>methods: 本文使用例子从标准、认证和测试 benchmarking 等领域，探讨这些过程如何相互关联，并为负责任创新提供指导。</li>
<li>results: 本文 argue 通过标准、认证和测试 benchmarking 等过程，可以帮助确保机器人和人工智能系统的负责任创新。<details>
<summary>Abstract</summary>
Benchmarking, standards and certification are closely related processes. Standards can provide normative requirements that robotics and AI systems may or may not conform to. Certification generally relies upon conformance with one or more standards as the key determinant of granting a certificate to operate. And benchmarks are sets of standardised tests against which robots and AI systems can be measured. Benchmarks therefore can be thought of as informal standards. In this paper we will develop these themes with examples from benchmarking, standards and certification, and argue that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation.
</details>
<details>
<summary>摘要</summary>
标准、认证和测试是密切相关的过程。标准可以提供规范要求，机器人和人工智能系统可能或可能不遵循。认证通常基于一个或多个标准来决定授予操作证书。而测试是使用标准化的测试方法来评估机器人和人工智能系统的性能。因此，测试可以被视为非正式的标准。在这篇论文中，我们将通过实例来发展这些主题，并 argue that这三个连接过程不仅是有用的，而且是责任创新的必要条件。
</details></li>
</ul>
<hr>
<h2 id="OSN-MDAD-Machine-Translation-Dataset-for-Arabic-Multi-Dialectal-Conversations-on-Online-Social-Media"><a href="#OSN-MDAD-Machine-Translation-Dataset-for-Arabic-Multi-Dialectal-Conversations-on-Online-Social-Media" class="headerlink" title="OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media"></a>OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12137">http://arxiv.org/abs/2309.12137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatimah Alzamzami, Abdulmotaleb El Saddik</li>
<li>for: 这个论文主要是为了解决阿拉伯语言的社交媒体翻译问题。</li>
<li>methods: 这篇论文使用的方法是基于上述提出的内容翻译指南，通过对英语推文进行上下文翻译，生成四种阿拉伯语方言的转化。</li>
<li>results: 根据作者的实验结果，使用这些方法可以实现高效的阿拉伯语方言翻译。<details>
<summary>Abstract</summary>
While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. While few attempts have been made to build translation datasets for dialectal Arabic, they are domain dependent and are not OSN cultural-language friendly. In this work, we attempt to alleviate these limitations by proposing an online social network-based multidialect Arabic dataset that is crafted by contextually translating English tweets into four Arabic dialects: Gulf, Yemeni, Iraqi, and Levantine. To perform the translation, we followed our proposed guideline framework for content translation, which could be universally applicable for translation between foreign languages and local dialects. We validated the authenticity of our proposed dataset by developing neural MT models for four Arabic dialects. Our results have shown a superior performance of our NMT models trained using our dataset. We believe that our dataset can reliably serve as an Arabic multidialectal translation dataset for informal MT tasks.
</details>
<details>
<summary>摘要</summary>
在英语社交媒体上，资源相对充足，但在阿拉伯语社交媒体上，资源仍然落后。主要原因是阿拉伯语有多种方言，使得社交媒体上的用户通常使用方言而不是标准版本（MSA）。阿拉伯人不使用MSA在日常交流中，而是使用方言版本。这种现象也影响了社交媒体平台上的使用，从而提高了为建立适用于语言依赖应用的AI模型的需求。现有的机器翻译（MT）系统设计 дляMSA无法正确地处理阿拉伯语方言。为此，需要适应社交媒体上的不正式交流方式，并开发MT系统可以有效地处理不同的阿拉伯语方言。与MSA的MT系统进步相比，对阿拉伯语方言的努力很少。尝试了为阿拉伯语方言建立翻译数据集，但这些数据集是域名相关的，并不适合社交媒体文化语言。在这种情况下，我们尝试缓解这些限制，并提出了一个在线社交媒体基础上创建的多方言阿拉伯语数据集。我们采用了我们提出的内部翻译指南，将英语推文翻译成四种阿拉伯语方言：古富、 йемен语、伊拉克语和levantine语。我们验证了我们提出的数据集的 Authenticity，并开发了四种阿拉伯语方言的神经翻译模型。我们的结果表明，我们的NMT模型在使用我们的数据集进行训练时表现出色。我们认为，我们的数据集可靠地作为阿拉伯语多方言翻译数据集来使用。
</details></li>
</ul>
<hr>
<h2 id="A-knowledge-representation-approach-for-construction-contract-knowledge-modeling"><a href="#A-knowledge-representation-approach-for-construction-contract-knowledge-modeling" class="headerlink" title="A knowledge representation approach for construction contract knowledge modeling"></a>A knowledge representation approach for construction contract knowledge modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12132">http://arxiv.org/abs/2309.12132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunmo Zheng, Saika Wong, Xing Su, Yinqiu Tang</li>
<li>for:  automatize construction contract management, reducing human errors and saving time and costs</li>
<li>methods:  uses a nested knowledge representation framework and LLM-assisted contract review pipeline</li>
<li>results:  achieves promising performance in contract risk reviewing, demonstrating the potential of combining LLM and KG for more reliable and interpretable contract management<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的出现提供了前所未有的自动化建筑合同管理机会，可以减少人类错误和成本。然而，LLM可能生成吸引人的 yet inaccurate和 misleading 内容，因为缺乏领域专业知识。为解决这个问题，我们可以将专家驱动的合同知识表示在结构化的方式下，以限制自动合同管理过程。本文介绍了嵌入式合同知识图（NCKG），一种知识表示方法，它使用嵌入结构来捕捉合同知识的复杂性。它包括嵌入结构框架、基于框架的 NCKG  Ontology 和实现方法。此外，我们还介绍了利用外部知识的 LLM 协助合同审核管道。我们的管道实现了合同风险审核中的优秀表现，推照在 LLM 和 KG 的结合下，可以实现更可靠和可解释的合同管理。
</details></li>
</ul>
<hr>
<h2 id="Incentivizing-Massive-Unknown-Workers-for-Budget-Limited-Crowdsensing-From-Off-Line-and-On-Line-Perspectives"><a href="#Incentivizing-Massive-Unknown-Workers-for-Budget-Limited-Crowdsensing-From-Off-Line-and-On-Line-Perspectives" class="headerlink" title="Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives"></a>Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12113">http://arxiv.org/abs/2309.12113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Li, Yuqi Chai, Huan Yang, Pengfei Hu, Lingjie Duan</li>
<li>For: 这个论文是为了解决在具有限制的预算下，面临大量未知工作者的 combinatorial multi-armed bandit (CMAB) 问题。* Methods: 该论文提出了一种基于奖励机制的 Context-Aware CMAB (CACI) 机制，通过在分区的上下文空间中进行exploration-exploitation 质量来办理奖励，以具有效地鼓励大量未知工作者。同时，该机制还在在线设置中进行了扩展，以适应工作者Join或离开系统的动态变化。* Results: 该论文通过理论分析和实验 validate 了其机制的正确性和个人合理性，并且在synthetic和实际数据集上进行了广泛的实验验证。<details>
<summary>Abstract</summary>
Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited. Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves. To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget. We also extend the above basic idea to the on-line setting where unknown workers may join in or depart from the systems dynamically, and propose an on-line version of the CACI mechanism. Specifically, by the exploitation-exploration trade-off in the context space, we learn to estimate the sensing ability of any unknown worker (even it never appeared in the system before) according to its context information. We perform rigorous theoretical analysis to reveal the upper bounds on the regrets of our CACI mechanisms and to prove their truthfulness and individual rationality, respectively. Extensive experiments on both synthetic and real datasets are also conducted to verify the efficacy of our mechanisms.
</details>
<details>
<summary>摘要</summary>
尽管工人的不确定性可以通过标准的Combinatorial Multi-Armed Bandit（CMAB）框架在现有的提议中Address，但我们可能没有足够的预算来实现这种贸易在各个工人之间，特别是当工人的数量很大而预算受限时。此外，标准的CMAB通常假设工人总是在系统中，而工人可能在系统中加入或离开，这意味着我们对个体工人所学的知识不能在它离开系统后应用。为解决这些挑战，在本文中，我们首先提出了OFF-LINE的Context-Aware CMAB-based Incentive（CACI）机制。我们创新地利用了在分割后的上下文空间中的exploration-exploitation贸易，以有效地鼓励大量的未知工人，并且具有很限制的预算。我们还将上述基本想法扩展到在线设置，在系统中动态加入或离开的未知工人上。 Specifically，通过在上下文空间中的利用-exploration贸易，我们可以根据 Context information来估算任何未知工人（即使它从未在系统中出现过）的感知能力。我们进行了严格的理论分析，以揭示我们CACI机制的误差的Upper bound，并证明它们的真实性和个人合理性，分别。我们还进行了大量的实验，以验证我们的机制的有效性。
</details></li>
</ul>
<hr>
<h2 id="PEFTT-Parameter-Efficient-Fine-Tuning-for-low-resource-Tibetan-pre-trained-language-models"><a href="#PEFTT-Parameter-Efficient-Fine-Tuning-for-low-resource-Tibetan-pre-trained-language-models" class="headerlink" title="PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models"></a>PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12109">http://arxiv.org/abs/2309.12109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhou Mingjun, Daiqing Zhuoma, Qun Nuo, Nyima Tashi</li>
<li>for: 这个研究的目的是为了提高 Tibetan NLP 领域中的模型训练效率，以便更好地应用于语言应用程序。</li>
<li>methods: 这个研究使用了三种有效的 fine-tuning 策略，即 “prompt-tuning”、”Adapter lightweight fine-tuning” 和 “prompt-tuning + Adapter fine-tuning”，以提高 Tibetan 语言模型的性能。</li>
<li>results: 实验结果表明，使用这三种 fine-tuning 策略可以在 TNCC-title 数据集上实现显著的改进，为 Tibetan 语言应用程序提供有价值的意义。<details>
<summary>Abstract</summary>
In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions. The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity. However, there has been very little exploration for various low-resource languages, such as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive. Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary. Our research can serve as a reference to fill this crucial gap. Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration. We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: "prompt-tuning," "Adapter lightweight fine-tuning," and "prompt-tuning + Adapter fine-tuning." The experimental results demonstrate significant improvements using these methods, providing valuable insights for advancing Tibetan language applications in the context of pre-trained models.
</details>
<details>
<summary>摘要</summary>
在这个大语言模型（LLM）时代，传统的模型训练已经变得越来越难以想象 для普通用户和机构。研究高资源语言模型的高效微调是一种逐渐受欢迎的趋势，但对低资源语言，如藏语，的研究几乎没有任何探索。因此，研究低资源语言模型的高效微调是非常必要的。在目前没有任何藏语大语言模型的情况下，我们的研究可以填补这一关键的空白。关于藏语自然语言处理（NLP）的研究是罕见和有限的。我们在公共可用的 TNCC-title 数据集上进行了三种高效微调实验："提示微调，" "Adapter 轻量级微调，" 和 "提示微调 + Adapter 微调。"实验结果显示了这些方法的显著改善，为 Tibetan 语言应用在预训练模型的上提供了价值的指导。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Thematic-Investment-with-Prompt-Tuned-Pretrained-Language-Models"><a href="#Accelerating-Thematic-Investment-with-Prompt-Tuned-Pretrained-Language-Models" class="headerlink" title="Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models"></a>Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12075">http://arxiv.org/abs/2309.12075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valentin Leonhard Buchner, Lele Cao, Jan-Christoph Kalo</li>
<li>for: 本研究使用Prompt Tuning方法进行实验，以解决多标签文本分类 задачі中的一些限制。</li>
<li>methods: 本研究使用Prompt Tuning和基eline方法进行比较，以测试它们在多标签文本分类 задачі中的性能和computational efficiency。</li>
<li>results: 研究结果显示，Prompt Tuning方法可以优化PLMs的性能和computational efficiency，并且可以解决多标签文本分类 задачі中的一些限制。<details>
<summary>Abstract</summary>
Prompt Tuning is emerging as a scalable and cost-effective method to fine-tune Pretrained Language Models (PLMs). This study benchmarks the performance and computational efficiency of Prompt Tuning and baseline methods on a multi-label text classification task. This is applied to the use case of classifying companies into an investment firm's proprietary industry taxonomy, supporting their thematic investment strategy. Text-to-text classification with PLMs is frequently reported to outperform classification with a classification head, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens: (a) Generated labels may not match any label in the industry taxonomy; (b) During fine-tuning, multiple labels must be provided in an arbitrary order; (c) The model provides a binary decision for each label, rather than an appropriate confidence score. Limitation (a) is addressed by applying constrained decoding using Trie Search, which slightly improves classification performance. All limitations (a), (b), and (c) are addressed by replacing the PLM's language head with a classification head. This improves performance significantly, while also reducing computational costs during inference. The results indicate the continuing need to adapt state-of-the-art methods to domain-specific tasks, even in the era of PLMs with strong generalization abilities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Benchmarking-quantized-LLaMa-based-models-on-the-Brazilian-Secondary-School-Exam"><a href="#Benchmarking-quantized-LLaMa-based-models-on-the-Brazilian-Secondary-School-Exam" class="headerlink" title="Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam"></a>Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12071">http://arxiv.org/abs/2309.12071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matheus L. O. Santos, Cláudio E. C. Campelo</li>
<li>for: 本研究旨在评估基于7和13亿LLaMA模型的大语言模型（LLMs）在家用硬件上的性能。</li>
<li>methods: 我们使用了一个包含1,006个问题的数据库，来评估这些模型的有效性。我们还测试了这些模型的计算效率，并记录了在一台配备AMD Ryzen 5 3600x处理器的机器上处理查询所需的时间。</li>
<li>results: 我们发现，最佳performing模型在原始葡萄牙语问题上的准确率约为46%，而在其英文翻译中的准确率约为49%。此外，我们发现7和13亿LLMs在这些查询中的计算效率相对较高，它们在一台机器上平均需要20和50秒时间来处理查询。<details>
<summary>Abstract</summary>
Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approximately 20 and 50 seconds, respectively, to process the queries on a machine equipped with an AMD Ryzen 5 3600x processor
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:尽管大型语言模型（LLMs）代表了计算机与人类之间交互的革命，允许建构复杂的问题并对语句进行推理，但它们的使用受到硬件限制。在这项研究中，我们评估了基于7和13亿LLaMA模型的LMMs，经过量化处理并在家用硬件上运行。我们考虑的模型包括Alpaca、Koala和Vicuna。为了评估这些模型的效果，我们创建了包含1,006个问题的ENEM（巴西国家高中考试）数据库。我们的分析表明，最佳表现的模型在原始葡萄牙语问题上达到了约46%的准确率，而在英语翻译中达到了约49%的准确率。此外，我们还评估了这些模型的计算效率，并测量了在一台配备AMD Ryzen 5 3600x处理器的机器上执行查询所需的时间。平均而言，7和13亿LLMs在20和50秒之间执行查询。
</details></li>
</ul>
<hr>
<h2 id="Survey-of-Action-Recognition-Spotting-and-Spatio-Temporal-Localization-in-Soccer-–-Current-Trends-and-Research-Perspectives"><a href="#Survey-of-Action-Recognition-Spotting-and-Spatio-Temporal-Localization-in-Soccer-–-Current-Trends-and-Research-Perspectives" class="headerlink" title="Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer – Current Trends and Research Perspectives"></a>Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer – Current Trends and Research Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12067">http://arxiv.org/abs/2309.12067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karolina Seweryn, Anna Wróblewska, Szymon Łukasik</li>
<li>for: 本文提供了足球动作识别领域的全面回顾，包括动作识别、位置识别和时空动作地址Localization，特别是modalities使用和多modal方法。</li>
<li>methods: 文章详细介绍了公共可用数据源和评价模型性能的度量，同时还探讨了最新的state-of-the-art方法，包括深度学习技术和传统方法。文章特别强调了多modal方法，这些方法将多个源信息 integrate into one model，如视频和音频数据。</li>
<li>results: 文章评论了不同方法的优势和局限性，以及它们在准确性和Robustness方面的潜在提升。最后，文章提出了一些未解决的问题和未来方向，包括多modal方法在足球动作识别领域的潜在推动作用。<details>
<summary>Abstract</summary>
Action scene understanding in soccer is a challenging task due to the complex and dynamic nature of the game, as well as the interactions between players. This article provides a comprehensive overview of this task divided into action recognition, spotting, and spatio-temporal action localization, with a particular emphasis on the modalities used and multimodal methods. We explore the publicly available data sources and metrics used to evaluate models' performance. The article reviews recent state-of-the-art methods that leverage deep learning techniques and traditional methods. We focus on multimodal methods, which integrate information from multiple sources, such as video and audio data, and also those that represent one source in various ways. The advantages and limitations of methods are discussed, along with their potential for improving the accuracy and robustness of models. Finally, the article highlights some of the open research questions and future directions in the field of soccer action recognition, including the potential for multimodal methods to advance this field. Overall, this survey provides a valuable resource for researchers interested in the field of action scene understanding in soccer.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chineseoccer场景理解是一项复杂和动态的任务，由于游戏中玩家之间的互动和多方面的关系。这篇文章提供了全面的概述，分为行为识别、识别和空间时间行为定位，强调modalities使用和多模态方法。我们探讨了公共可用数据源和评估模型性能的度量，并评论了最新的状态艺术方法，包括深度学习技术和传统方法。我们专注于多模态方法，这些方法将多个来源的信息集成，如视频和音频数据，以及表示一种来源的不同方式。我们讨论了方法的优势和局限性，以及它们在准确性和可靠性方面的潜在提高。最后，文章强调了在足球行为识别领域的一些未解决问题和未来方向，包括多模态方法的潜在推动该领域的前景。总之，这篇文章为研究者们关注足球场景理解领域提供了有价值的资源。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Consolidation-of-Word-Embedding-and-Deep-Learning-Techniques-for-Classifying-Anticancer-Peptides-FastText-BiLSTM"><a href="#An-Efficient-Consolidation-of-Word-Embedding-and-Deep-Learning-Techniques-for-Classifying-Anticancer-Peptides-FastText-BiLSTM" class="headerlink" title="An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM"></a>An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12058">http://arxiv.org/abs/2309.12058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onur Karakaya, Zeynep Hilal Kilimci</li>
<li>for: 预防和治疗癌症的抗癌肽（ACPs）</li>
<li>methods: 使用word embedding和深度学习模型进行抗癌肽分类</li>
<li>results: 提出了一种高精度的抗癌肽分类模型，在常用的数据集上达到了新的州OF-THE-ART水平，即ACPs250数据集的准确率为92.50%，独立数据集的准确率为96.15%。<details>
<summary>Abstract</summary>
Anticancer peptides (ACPs) are a group of peptides that exhibite antineoplastic properties. The utilization of ACPs in cancer prevention can present a viable substitute for conventional cancer therapeutics, as they possess a higher degree of selectivity and safety. Recent scientific advancements generate an interest in peptide-based therapies which offer the advantage of efficiently treating intended cells without negatively impacting normal cells. However, as the number of peptide sequences continues to increase rapidly, developing a reliable and precise prediction model becomes a challenging task. In this work, our motivation is to advance an efficient model for categorizing anticancer peptides employing the consolidation of word embedding and deep learning models. First, Word2Vec and FastText are evaluated as word embedding techniques for the purpose of extracting peptide sequences. Then, the output of word embedding models are fed into deep learning approaches CNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework, extensive experiments are carried on widely-used datasets in the literature, ACPs250 and Independent. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for ACPs250 dataset, and 96.15% of accuracy for Independent dataset, thence determining new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
安定肽（ACPs）是一组肽蛋白，具有抗肿瘤性能。使用ACPs在抗癌治疗中可能成为一种可靠的替代方案，因为它们具有更高的选择性和安全性。随着肽序列的数量在快速增长，开发一个可靠和精准的预测模型成为一项挑战。在这种情况下，我们的动机是提出一种高效的分类模型，使用词嵌入和深度学习模型。首先，我们评估了Word2Vec和FastText作为词嵌入技术，以提取肽序列。然后，Word2Vec和FastText模型的输出被 fed into深度学习模型CNN、LSTM、BiLSTM。为证明提案的贡献，我们在文献中常用的数据集上进行了广泛的实验。实验结果表明，我们的模型可以提高分类精度，比领先研究更高。具体来说，使用我们的模型，ACPS250数据集的准确率达92.50%，独立数据集的准确率达96.15%，从而确定新的顶峰。
</details></li>
</ul>
<hr>
<h2 id="BELT-Bootstrapping-Electroencephalography-to-Language-Decoding-and-Zero-Shot-Sentiment-Classification-by-Natural-Language-Supervision"><a href="#BELT-Bootstrapping-Electroencephalography-to-Language-Decoding-and-Zero-Shot-Sentiment-Classification-by-Natural-Language-Supervision" class="headerlink" title="BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision"></a>BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12056">http://arxiv.org/abs/2309.12056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinzhao Zhou, Yiqun Duan, Yu-Cheng Chang, Yu-Kai Wang, Chin-Teng Lin</li>
<li>for: 本研究旨在提出一种基于大规模预训练语言模型的脑语言翻译模型和学习框架（BELT），以解决脑信号解码或脑语言翻译中的限制性问题。</li>
<li>methods: 该模型由深度套件编码器和量化编码器组成，通过对比学习步骤提供自然语言监督，以实现semantic EEG表示。</li>
<li>results: 在两个特征性脑解码任务上，包括脑语言翻译和零扫ENT sentiment classification，OUR模型比基eline模型提高5.45%和over 10%，并在翻译任务上实现42.31% BLEU-1分数和67.32%精度。<details>
<summary>Abstract</summary>
This paper presents BELT, a novel model and learning framework for the pivotal topic of brain-to-language translation research. The translation from noninvasive brain signals into readable natural language has the potential to promote the application scenario as well as the development of brain-computer interfaces (BCI) as a whole. The critical problem in brain signal decoding or brain-to-language translation is the acquisition of semantically appropriate and discriminative EEG representation from a dataset of limited scale and quality. The proposed BELT method is a generic and efficient framework that bootstraps EEG representation learning using off-the-shelf large-scale pretrained language models (LMs). With a large LM's capacity for understanding semantic information and zero-shot generalization, BELT utilizes large LMs trained on Internet-scale datasets to bring significant improvements to the understanding of EEG signals.   In particular, the BELT model is composed of a deep conformer encoder and a vector quantization encoder. Semantical EEG representation is achieved by a contrastive learning step that provides natural language supervision. We achieve state-of-the-art results on two featuring brain decoding tasks including the brain-to-language translation and zero-shot sentiment classification. Specifically, our model surpasses the baseline model on both tasks by 5.45% and over 10% and archives a 42.31% BLEU-1 score and 67.32% precision on the main evaluation metrics for translation and zero-shot sentiment classification respectively.
</details>
<details>
<summary>摘要</summary>
To address this problem, the BELT method leverages off-the-shelf large-scale pretrained language models (LMs) to bootstrap EEG representation learning. With the large capacity of LMs for understanding semantic information and their ability to generalize to new situations, BELT can significantly improve the understanding of EEG signals.The BELT model consists of a deep conformer encoder and a vector quantization encoder. To achieve semantically meaningful EEG representations, a contrastive learning step is used to provide natural language supervision. The model is evaluated on two brain decoding tasks, brain-to-language translation and zero-shot sentiment classification, and achieves state-of-the-art results. Specifically, the model outperforms the baseline model by 5.45% and over 10% on both tasks, with a BLEU-1 score of 42.31% and precision of 67.32% for translation and zero-shot sentiment classification, respectively.
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-driven-Exploration-Strategies-for-Online-Grasp-Learning"><a href="#Uncertainty-driven-Exploration-Strategies-for-Online-Grasp-Learning" class="headerlink" title="Uncertainty-driven Exploration Strategies for Online Grasp Learning"></a>Uncertainty-driven Exploration Strategies for Online Grasp Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12038">http://arxiv.org/abs/2309.12038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitian Shi, Philipp Schillinger, Miroslav Gabriel, Alexander Kuss, Zohar Feldman, Hanna Ziesche, Ngo Anh Vien</li>
<li>for: 本研究旨在提出一种在线学习 grasp 预测方法，以适应 robotic bin picking 中新的抓取enario。</li>
<li>methods: 本方法基于 Reinforcement Learning 的online学习策略，并采用有效的探索策略来改善适应性。</li>
<li>results: 实验结果表明，提出的方法可以在实际的 bin picking 场景中具有显著的改善，并且比传统的在线学习方法具有更高的适应性。<details>
<summary>Abstract</summary>
Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Specifically, the online learning algorithm with an effective exploration strategy can significantly improve its adaptation performance to unseen environment settings. To this end, we first propose to formulate online grasp learning as a RL problem that will allow to adapt both grasp reward prediction and grasp poses. We propose various uncertainty estimation schemes based on Bayesian Uncertainty Quantification and Distributional Ensembles. We carry out evaluations on real-world bin picking scenes of varying difficulty. The objects in the bin have various challenging physical and perceptual characteristics that can be characterized by semi- or total transparency, and irregular or curved surfaces. The results of our experiments demonstrate a notable improvement in the suggested approach compared to conventional online learning methods which incorporate only naive exploration strategies.
</details>
<details>
<summary>摘要</summary>
现有的握取预测方法大多基于离线学习，而忽略了在线适应新抓取场景时的探索式握取学习。在这篇论文中，我们提出了一种新的在线学习握取预测方法，以解决这个问题。特别是，我们提出了一种有效的探索策略，可以显著提高在未经见的环境设置下的适应性。为此，我们首先将在线握取学习转化为一种RL问题，以适应握取奖励预测和握取姿态。我们还提出了多种不确定度估计方法，基于 bayesian不确定度量化和分布 ensemble。我们在实际的 bin picking 场景中进行了评估，结果显示，我们的方法在不同的难度水平下表现出了显著的改善。Here's a word-for-word translation of the text using Traditional Chinese characters:现有的握取预测方法大多基于离线学习，而忽略了在线适应新捕取场景时的探索式握取学习。在这篇论文中，我们提出了一种新的在线学习握取预测方法，以解决这个问题。特别是，我们提出了一种有效的探索策略，可以明显提高在未经见的环境设置下的适应性。为此，我们首先将在线握取学习转换为一个RL问题，以适应握取奖励预测和握取姿势。我们还提出了多种不确定度估计方法，基于 bayesian不确定度量化和分布ensemble。我们在实际的 bin picking 场景中进行了评估，结果显示，我们的方法在不同的难度水平下表现出了明显的改善。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Hypergraph-Structure-Learning-for-Traffic-Flow-Forecasting"><a href="#Dynamic-Hypergraph-Structure-Learning-for-Traffic-Flow-Forecasting" class="headerlink" title="Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting"></a>Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12028">http://arxiv.org/abs/2309.12028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusheng Zhao, Xiao Luo, Wei Ju, Chong Chen, Xian-Sheng Hua, Ming Zhang</li>
<li>for: 预测未来交通情况，基于路网和过去交通情况来预测未来交通状况。</li>
<li>methods: 使用强化图学习方法，抽取高维图 струкural信息，模型交通网络中的动态关系，并通过互动图卷积块来模型不同时间的交通关系。</li>
<li>results: 与竞争对手比较，实验结果表明，提出的 DyHSL 方法在四个流行的交通数据集上具有更高的预测精度和稳定性。<details>
<summary>Abstract</summary>
This paper studies the problem of traffic flow forecasting, which aims to predict future traffic conditions on the basis of road networks and traffic conditions in the past. The problem is typically solved by modeling complex spatio-temporal correlations in traffic data using spatio-temporal graph neural networks (GNNs). However, the performance of these methods is still far from satisfactory since GNNs usually have limited representation capacity when it comes to complex traffic networks. Graphs, by nature, fall short in capturing non-pairwise relations. Even worse, existing methods follow the paradigm of message passing that aggregates neighborhood information linearly, which fails to capture complicated spatio-temporal high-order interactions. To tackle these issues, in this paper, we propose a novel model named Dynamic Hypergraph Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise relationships, our DyHSL extracts hypergraph structural information to model dynamics in the traffic networks, and updates each node representation by aggregating messages from its associated hyperedges. Additionally, to capture high-order spatio-temporal relations in the road network, we introduce an interactive graph convolution block, which further models the neighborhood interaction for each node. Finally, we integrate these two views into a holistic multi-scale correlation extraction module, which conducts temporal pooling with different scales to model different temporal patterns. Extensive experiments on four popular traffic benchmark datasets demonstrate the effectiveness of our proposed DyHSL compared with a broad range of competing baselines.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这篇论文研究了交通流量预测问题，目的是根据过去的道路网络和交通情况预测未来交通情况。传统的方法使用空间时间图内存神经网络（GNN），但其表现仍然不够满意，因为GNN通常在复杂的交通网络上具有有限的表示能力。为解决这个问题，我们在这篇论文中提出了一种名为动态质量结构学习（DyHSL）的新模型，用于预测交通流量。DyHSL使用质量结构信息来模型交通网络中的动态，并为每个节点更新表示信息，通过聚合与其相关的质量结构上的消息。此外，我们还引入了一种互动图卷积块，用于模型每个节点的邻居交互。最后，我们将这两个视角集成到一个整体多级相关提取模块中，并进行不同的时间膨胀来模型不同的时间模式。我们对四个流行的交通测试集进行了广泛的实验，并证明了我们提出的DyHSL在与一系列基线模型进行比较时的效果。
</details></li>
</ul>
<hr>
<h2 id="Demystifying-Visual-Features-of-Movie-Posters-for-Multi-Label-Genre-Identification"><a href="#Demystifying-Visual-Features-of-Movie-Posters-for-Multi-Label-Genre-Identification" class="headerlink" title="Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification"></a>Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12022">http://arxiv.org/abs/2309.12022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Utsav Kumar Nareti, Chandranath Adak, Soumi Chattopadhyay</li>
<li>for: 这 paper 是用于自动多标签电影类型识别，只使用电影海报图像，无需其他文本&#x2F;元数据信息。</li>
<li>methods: 这 paper 使用了深度变换器网络，并添加了概率模块来识别电影类型。</li>
<li>results: 在实验分析中，模型在13882张电影海报图像上表现出了鼓舞人心的result，甚至超过了一些当前主流架构。<details>
<summary>Abstract</summary>
In the film industry, movie posters have been an essential part of advertising and marketing for many decades, and continue to play a vital role even today in the form of digital posters through online, social media and OTT platforms. Typically, movie posters can effectively promote and communicate the essence of a film, such as its genre, visual style/ tone, vibe and storyline cue/ theme, which are essential to attract potential viewers. Identifying the genres of a movie often has significant practical applications in recommending the film to target audiences. Previous studies on movie genre identification are limited to subtitles, plot synopses, and movie scenes that are mostly accessible after the movie release. Posters usually contain pre-release implicit information to generate mass interest. In this paper, we work for automated multi-label genre identification only from movie poster images, without any aid of additional textual/meta-data information about movies, which is one of the earliest attempts of its kind. Here, we present a deep transformer network with a probabilistic module to identify the movie genres exclusively from the poster. For experimental analysis, we procured 13882 number of posters of 13 genres from the Internet Movie Database (IMDb), where our model performances were encouraging and even outperformed some major contemporary architectures.
</details>
<details>
<summary>摘要</summary>
在电影业内，电影海报已经是广告和市场营销的重要组成部分，并且在今天的形式中仍然扮演着重要的角色，包括数字海报通过在线、社交媒体和OTT平台。通常，电影海报可以有效地推广和传达电影的核心元素，如其类型、视觉风格/调子、氛围和故事线索/主题，这些元素都是吸引 posible viewers 的关键。识别电影的类型有很多实际应用，例如推荐电影给target audience。过去的研究主要集中在电影场景、剧本简介和电影片段等，这些信息都是电影发布后才可以获取。海报通常包含在电影发布之前的隐式信息，以便引起大量的兴趣。在这篇论文中，我们采用了自动化多个标签类别识别方法，只使用电影海报图像，不需要任何其他电影相关的文本/元数据信息，这是目前已知的其中之一。我们在实验分析中使用了13882张海报图像，来自互联网电影数据库（IMDb），我们的模型表现很 Encouraging，甚至超过了一些当前的主流架构。
</details></li>
</ul>
<hr>
<h2 id="Safe-Hierarchical-Reinforcement-Learning-for-CubeSat-Task-Scheduling-Based-on-Energy-Consumption"><a href="#Safe-Hierarchical-Reinforcement-Learning-for-CubeSat-Task-Scheduling-Based-on-Energy-Consumption" class="headerlink" title="Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption"></a>Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12004">http://arxiv.org/abs/2309.12004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahya Ramezani, M. Amin Alandihallaj, Jose Luis Sanchez-Lopez, Andreas Hein</li>
<li>for: 优化CubeSat任务调度在低地球轨道（LEO）中</li>
<li>methods: 基于层次强化学习的方法，包括全球任务分布高级政策和实时适应低级政策作为安全机制，同时包括相似注意力基于编码器（SABE） для任务优先级调整和多层扩散器（MLP）估计器 для能量消耗预测</li>
<li>results: 对多个CubeSat配置进行了仿真测试，结果表明层次强化学习方法在任务 converges 和成功率方面具有超越MADDPG模型和随机调度的优势。<details>
<summary>Abstract</summary>
This paper presents a Hierarchical Reinforcement Learning methodology tailored for optimizing CubeSat task scheduling in Low Earth Orbits (LEO). Incorporating a high-level policy for global task distribution and a low-level policy for real-time adaptations as a safety mechanism, our approach integrates the Similarity Attention-based Encoder (SABE) for task prioritization and an MLP estimator for energy consumption forecasting. Integrating this mechanism creates a safe and fault-tolerant system for CubeSat task scheduling. Simulation results validate the Hierarchical Reinforcement Learning superior convergence and task success rate, outperforming both the MADDPG model and traditional random scheduling across multiple CubeSat configurations.
</details>
<details>
<summary>摘要</summary>
本文提出了一种层次优化方法，用于优化 LEO 牛顿级卫星任务调度。该方法包括一个高级策略用于全球任务分配和一个低级策略用于实时调整作为安全机制，并 integrates 类似注意力基于编码器（SABE）用于任务优先级调度和一个 MLP 预测器用于能源消耗预测。通过这种机制，我们构建了一个安全和可靠的 CubeSat 任务调度系统。实验结果表明，层次优化学习超越了 MADDPG 模型和随机调度，在多种 CubeSat 配置下实现了更高的任务成功率。
</details></li>
</ul>
<hr>
<h2 id="LMSYS-Chat-1M-A-Large-Scale-Real-World-LLM-Conversation-Dataset"><a href="#LMSYS-Chat-1M-A-Large-Scale-Real-World-LLM-Conversation-Dataset" class="headerlink" title="LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"></a>LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11998">http://arxiv.org/abs/2309.11998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric. P Xing, Joseph E. Gonzalez, Ion Stoica, Hao Zhang</li>
<li>For: 这个论文的目的是为了研究人们在真实场景中与大型自然语言模型（LLM）进行交互的方式。* Methods: 这篇论文使用了25种当前最先进的LMM进行实际场景中的交互，并从210K个唯一的IP地址中收集了100万个对话。* Results: 论文提供了这个数据集的概述，包括其批处程序、基本统计和话题分布，并通过四个用例展示了这个数据集的多样性和大小，包括开发内容审核模型、建立安全标准、训练遵循 instrux 模型和创建挑战性的问题集。<details>
<summary>Abstract</summary>
Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at \url{https://huggingface.co/datasets/lmsys/lmsys-chat-1m}.
</details>
<details>
<summary>摘要</summary>
我们将介绍一个名为LMSYS-Chat-1M的大规模数据集，它包含25个现代大语言模型在实际场景中的一百万个对话。这个数据集是从我们的Vicuna demo和Chatbot Arena网站上获取的210K个唯一的IP地址。我们将介绍这个数据集的内容，包括它的数据收集过程、基本统计和主题分布，并强调其多样性、原始性和规模。我们还会显示这个数据集的多方位性，包括发展内容审核模型，建立安全参考基准，训练遵循命令的模型，和创建挑战性的问题。我们认为这个数据集将成为大语言模型能力的理解和进步的重要资源。这个数据集现在在\url{https://huggingface.co/datasets/lmsys/lmsys-chat-1m}上公开提供。
</details></li>
</ul>
<hr>
<h2 id="Predictability-and-Comprehensibility-in-Post-Hoc-XAI-Methods-A-User-Centered-Analysis"><a href="#Predictability-and-Comprehensibility-in-Post-Hoc-XAI-Methods-A-User-Centered-Analysis" class="headerlink" title="Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis"></a>Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11987">http://arxiv.org/abs/2309.11987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anahid Jalali, Bernhard Haslhofer, Simone Kriglstein, Andreas Rauber</li>
<li>for: 本研究旨在评估黑盒机器学习模型预测结果的后续解释方法的可解性和预测能力。</li>
<li>methods: 研究使用了两种广泛使用的工具：LIME和SHAP。研究还 investigate了对于用户理解和预测模型行为的影响。</li>
<li>results: 研究发现，SHAP的可解性在模型决策边界附近受到显著降低。此外，对比例解释和错误类型的影响也发现了增加用户理解模型行为的能力。基于研究结果，还提出了未来 posterior explainability 方法的设计建议。<details>
<summary>Abstract</summary>
Post-hoc explainability methods aim to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increased comprehensibility and predictability.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Post-hoc explainability methods aim to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increased comprehensibility and predictability." into Simplified Chinese.翻译文本为简化字的中文：Post-hoc解释方法旨在解释黑盒机器学习模型的预测结果。然而，目前还不清楚用户对提供的解释是否能够准确理解和预测模型的行为。我们通过进行用户研究，评估了两种广泛使用的工具：LIME和SHAP的可 comprendibility和预测能力。此外，我们还研究了对用户的counterfactual解释和错误分类对用户理解和预测模型行为的影响。我们发现，SHAP的可 comprendibility在解释靠近决策边界时显著降低。此外，我们发现，counterfactual解释和错误分类可以帮助用户更好地理解机器学习模型如何做出决策。基于我们的发现，我们还提出了未来post-hoc解释方法的设计建议，以提高可 comprendibility和预测能力。
</details></li>
</ul>
<hr>
<h2 id="Representation-Abstractions-as-Incentives-for-Reinforcement-Learning-Agents-A-Robotic-Grasping-Case-Study"><a href="#Representation-Abstractions-as-Incentives-for-Reinforcement-Learning-Agents-A-Robotic-Grasping-Case-Study" class="headerlink" title="Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study"></a>Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11984">http://arxiv.org/abs/2309.11984</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panagiotis Petropoulakis, Ludwig Gräf, Josip Josifovski, Mohammadhossein Malmir, Alois Knoll</li>
<li>for: 这项研究的目的是探讨RL机器人在不同状态表示方法下解决反极和平面物捕获任务的能力。</li>
<li>methods: 该研究使用了模型基于的方法、数字化的方法和图像基于的方法来表示环境，并对这些方法的影响进行了调查。</li>
<li>results: 研究发现RL机器人使用数字化状态可以与非学习基eline相当，而使用图像基于的状态从预训练环境向量得到的表示 perfoms更好，并且假设任务特定的知识是控制机器人成功的关键因素。<details>
<summary>Abstract</summary>
Choosing an appropriate representation of the environment for the underlying decision-making process of the \gls{RL} agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and compact enough to increase sample efficiency for policy training. Given this outlook, this work examines the effect of various state representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representation abstractions is defined, starting from a model-based approach with complete system knowledge, through hand-crafted numerical, to image-based representations with decreasing level of induced task-specific knowledge. We examine the effects of each representation in the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot. The results show that RL agents using numerical states can perform on par with non-learning baselines. Furthermore, we find that agents using image-based representations from pre-trained environment embedding vectors perform better than end-to-end trained agents, and hypothesize that task-specific knowledge is necessary for achieving convergence and high success rates in robot control. Supplementary material can be found at the project webpage: https://github.com/PetropoulakisPanagiotis/igae.
</details>
<details>
<summary>摘要</summary>
选择合适的环境表示方式 дляRL代理的基础决策过程并不总是 straightforward。状态表示应该包含足够的信息，使代理能够有优决策，同时也应该尽量紧凑，以提高策略训练的示例效率。在这个视角下，本工作研究了不同的状态表示方式对RL代理解决特有的 робо控制任务：把物 grasping。我们定义了一种维度的状态表示抽象continuum，从模型基于的方法（完全系统知识），通过手工制定的数值，到图像基于的表示（减少任务特定知识）。我们研究了每种表示方式对代理解决任务的能力，以及这些策略在真实机器人上的可转移性。结果表明RL代理使用数值状态可以与非学习基线一样高效，而使用图像基于的表示从预训练环境嵌入向量而来的代理，则比末端培训的代理更高效。我们认为任务特定的知识是控制机器人高效和具有高成功率的关键。补充材料可以在项目网页上找到：https://github.com/PetropoulakisPanagiotis/igae。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-the-Evaluating-Framework-for-Natural-Language-Understanding-in-AI-Systems-Language-Acquisition-as-a-Core-for-Future-Metrics"><a href="#Rethinking-the-Evaluating-Framework-for-Natural-Language-Understanding-in-AI-Systems-Language-Acquisition-as-a-Core-for-Future-Metrics" class="headerlink" title="Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics"></a>Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11981">http://arxiv.org/abs/2309.11981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patricio Vera, Pedro Moya, Lisa Barraza</li>
<li>for: 本研究旨在探讨人工智能（AI）领域内大语言模型（LLMs）的进步对传统机器智能评价指标的影响，并提出一种基于语言学习和理解的新评价框架。</li>
<li>methods: 本研究采用了多种学科的优秀成果，包括语言学习和理解、自然语言处理（NLP）等，以探讨传统机器智能评价指标的缺陷和不足，并提出一种更加全面和可持续的评价方法。</li>
<li>results: 本研究提出了一种基于语言学习和理解的新评价框架，可以更好地评价机器智能的能力和表现，并且可以帮助解决传统机器智能评价指标的缺陷和不足。<details>
<summary>Abstract</summary>
In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
</details>
<details>
<summary>摘要</summary>
在人工智能（AI）领域的不断发展中，大型自然语言处理（NLP）模型的前无古人成就，对传统机器智能评估 metric 的形式和内容都提供了机遇。随着机器认知领域已经达到仿制的水平，接下来的核心任务是语言学习和理解。我们的论文提议一种借鉴现代 LLM 的概念shift，强调语言学习，而不是已有的图灵测试。我们的贡献受到了不同领域的出色工作的推动，要保持交往桥梁打开，并提出了更加坚强和可持续的方法。
</details></li>
</ul>
<hr>
<h2 id="Inferring-Capabilities-from-Task-Performance-with-Bayesian-Triangulation"><a href="#Inferring-Capabilities-from-Task-Performance-with-Bayesian-Triangulation" class="headerlink" title="Inferring Capabilities from Task Performance with Bayesian Triangulation"></a>Inferring Capabilities from Task Performance with Bayesian Triangulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11975">http://arxiv.org/abs/2309.11975</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Burden, Konstantinos Voudouris, Ryan Burnell, Danaja Rutar, Lucy Cheke, José Hernández-Orallo</li>
<li>for: 这篇论文旨在Characterizing machine learning models in richer, more meaningful ways, and describing a method to infer the cognitive profile of a system from diverse experimental data.</li>
<li>methods: 该方法使用了 measurement layouts to model how task-instance features interact with system capabilities, and used Bayesian probabilistic programming library PyMC to infer different cognitive profiles for agents in two scenarios.</li>
<li>results: 研究人员通过使用这种方法，能够从非常复杂的数据中推断出系统的能力profile，并在两个场景中显示了 capability-oriented evaluation 的潜力。<details>
<summary>Abstract</summary>
As machine learning models become more general, we need to characterise them in richer, more meaningful ways. We describe a method to infer the cognitive profile of a system from diverse experimental data. To do so, we introduce measurement layouts that model how task-instance features interact with system capabilities to affect performance. These features must be triangulated in complex ways to be able to infer capabilities from non-populational data -- a challenge for traditional psychometric and inferential tools. Using the Bayesian probabilistic programming library PyMC, we infer different cognitive profiles for agents in two scenarios: 68 actual contestants in the AnimalAI Olympics and 30 synthetic agents for O-PIAAGETS, an object permanence battery. We showcase the potential for capability-oriented evaluation.
</details>
<details>
<summary>摘要</summary>
（machine learning models become more general, we need to characterize them in richer, more meaningful ways） machine learning模型变得更加通用，我们需要对其进行更加丰富、有意义的描述。我们介绍了一种方法，用于从多种实验数据中推断系统的认知profile。为此，我们引入了任务实例特征与系统能力之间的测量布局，以影响性能。这些特征需要在复杂的方式进行拟合，以便从非流行数据中推断能力——传统心理测量和推断工具所面临的挑战。使用PyMC的 bayesian概率编程库，我们对 AnimalAI奥运会中的68名实际参赛者和O-PIAAGETS对象永恒测试中的30名 sintetic agents进行了不同的认知 profiling。我们展示了可能性-oriented评估的潜力。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Review-on-Financial-Explainable-AI"><a href="#A-Comprehensive-Review-on-Financial-Explainable-AI" class="headerlink" title="A Comprehensive Review on Financial Explainable AI"></a>A Comprehensive Review on Financial Explainable AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11960">http://arxiv.org/abs/2309.11960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Jie Yeo, Wihan van der Heever, Rui Mao, Erik Cambria, Ranjan Satapathy, Gianmarco Mengaldo</li>
<li>for: 该论文主要旨在提供一种对深度学习模型可读性的比较survey，以便在金融领域内采用可读性AI方法。</li>
<li>methods: 该论文分析了一些提高深度学习模型可读性的方法，并将其分为不同的特征类型。</li>
<li>results: 该论文评估了采用可读性AI方法的问题和挑战，以及未来采用这些方法的未来方向。<details>
<summary>Abstract</summary>
The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）和深度学习模型的成功导致它们在不同领域得到广泛的应用，这主要是因为它们可以处理庞大数据量和学习复杂的模式。然而，由于它们的不可解性，在重要领域如金融和医疗等，决策透明度的问题具有重要性。在这篇论文中，我们提供了深入比较了在金融领域中改进深度学习模型的可解性的方法。我们根据它们的特点分类ify这些可解AI方法，并评估采用可解AI方法的问题和挑战，以及未来适当和重要的方向。
</details></li>
</ul>
<hr>
<h2 id="On-the-Definition-of-Appropriate-Trust-and-the-Tools-that-Come-with-it"><a href="#On-the-Definition-of-Appropriate-Trust-and-the-Tools-that-Come-with-it" class="headerlink" title="On the Definition of Appropriate Trust and the Tools that Come with it"></a>On the Definition of Appropriate Trust and the Tools that Come with it</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11937">http://arxiv.org/abs/2309.11937</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Helena Löfström</li>
<li>for: 本研究旨在评估人工智能交互的效率，包括主观和客观质量方面。</li>
<li>methods: 本研究使用定义适当信任的方法进行评估，并与模型性能评估进行比较，发现两者之间存在强相似性。</li>
<li>results: 本研究提出了一种新的适当信任评估方法，并对用户性能进行了多个方面的评估，包括建议一种测量不确定性和适当信任的方法。<details>
<summary>Abstract</summary>
Evaluating the efficiency of human-AI interactions is challenging, including subjective and objective quality aspects. With the focus on the human experience of the explanations, evaluations of explanation methods have become mostly subjective, making comparative evaluations almost impossible and highly linked to the individual user. However, it is commonly agreed that one aspect of explanation quality is how effectively the user can detect if the predictions are trustworthy and correct, i.e., if the explanations can increase the user's appropriate trust in the model. This paper starts with the definitions of appropriate trust from the literature. It compares the definitions with model performance evaluation, showing the strong similarities between appropriate trust and model performance evaluation. The paper's main contribution is a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper offers several straightforward evaluation methods for different aspects of user performance, including suggesting a method for measuring uncertainty and appropriate trust in regression.
</details>
<details>
<summary>摘要</summary>
评估人类-AI交互的效率具有挑战性，包括主观和客观质量方面。针对解释方法的评估通常受到用户经验的限制，导致对比评估变得困难，同时与个人用户的偏好息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息字。本文从文献中定义了适当信任的定义，并与模型性能评估进行比较，发现这两者之间存在强烈的相似性。本文的主要贡献是一种新的适当信任评估方法，利用定义之间的相似性。文章还提供了不同方面的用户性能评估方法，包括一种用于减迷和适当信任的回归方法。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Recover-for-Safe-Reinforcement-Learning"><a href="#Learning-to-Recover-for-Safe-Reinforcement-Learning" class="headerlink" title="Learning to Recover for Safe Reinforcement Learning"></a>Learning to Recover for Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11907">http://arxiv.org/abs/2309.11907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Wang, Xin Yuan, Qinqing Ren</li>
<li>for: 本文旨在研究如何通过学习算法构建安全控制器，以实现安全的返点学习。</li>
<li>methods: 本文提出了一种三 stage 架构，即 TU-Recovery 架构，包括安全评估器和恢复策略。这些 componenets 共同形成了一个安全控制器，确保任务训练中的安全性。</li>
<li>results: 在一个 robot 导航环境中进行了一系列实验，结果表明，TU-Recovery 在 reward 获取和约束违反方面在任务训练中表现出色，并且 auxiliary reward 可以进一步提高 TU-Recovery 的 reward-to-cost 比例，同时减少约束违反。<details>
<summary>Abstract</summary>
Safety controllers is widely used to achieve safe reinforcement learning. Most methods that apply a safety controller are using handcrafted safety constraints to construct the safety controller. However, when the environment dynamics are sophisticated, handcrafted safety constraints become unavailable. Therefore, it worth to research on constructing safety controllers by learning algorithms. We propose a three-stage architecture for safe reinforcement learning, namely TU-Recovery Architecture. A safety critic and a recovery policy is learned before task training. They form a safety controller to ensure safety in task training. Then a phenomenon induced by disagreement between task policy and recovery policy, called adversarial phenomenon, which reduces learning efficiency and model performance, is described. Auxiliary reward is proposed to mitigate adversarial phenomenon, while help the task policy to learn to recover from high-risk states. A series of experiments are conducted in a robot navigation environment. Experiments demonstrate that TU-Recovery outperforms unconstrained counterpart in both reward gaining and constraint violations during task training, and auxiliary reward further improve TU-Recovery in reward-to-cost ratio by significantly reduce constraint violations.
</details>
<details>
<summary>摘要</summary>
安全控制器广泛应用于安全强化学习。大多数应用安全控制器的方法使用手工安全约束来构建安全控制器。然而，当环境动力学复杂时，手工安全约束成为不可用。因此，研究构建安全控制器的学习算法是有价值的。我们提出了三个阶段的安全强化学习架构，称为TU-Recovery架构。一个安全评价员和一个恢复策略在任务训练之前被学习出来。它们组成一个安全控制器，以确保任务训练中的安全。然后，一种由任务策略和恢复策略之间的不一致现象引起的，称为对抗现象，这会降低学习效率和模型性能。我们提出了auxiliary reward来 mitigate对抗现象，同时帮助任务策略学习从高风险状态恢复。在一个 робот导航环境中进行了一系列实验，实验结果表明，TU-Recovery在增加奖励和约束违反时在任务训练中表现出了比对ounterpart更好的性能，并且auxiliary reward可以进一步提高TU-Recovery的奖励比率。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Heart-Using-Adaptive-Locked-Agnostic-Networks"><a href="#Unlocking-the-Heart-Using-Adaptive-Locked-Agnostic-Networks" class="headerlink" title="Unlocking the Heart Using Adaptive Locked Agnostic Networks"></a>Unlocking the Heart Using Adaptive Locked Agnostic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11899">http://arxiv.org/abs/2309.11899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AstraZeneca/UnlockingHeart">https://github.com/AstraZeneca/UnlockingHeart</a></li>
<li>paper_authors: Sylwia Majchrowska, Anders Hildeman, Philip Teare, Tom Diethe<br>for:* The paper is written for medical imaging applications, specifically for echocardiography datasets.methods:* The paper introduces the Adaptive Locked Agnostic Network (ALAN) method, which uses self-supervised visual feature extraction and a large backbone model to produce anatomically robust semantic self-segmentation.results:* The paper demonstrates that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view. Additionally, the paper designs two downstream models for segmenting a target anatomical region and echocardiogram view classification.Here is the information in Simplified Chinese text:for:* 这篇论文是为医疗影像应用而写的，特别是对于echocardiography dataset。methods:* 这篇论文介绍了Adaptive Locked Agnostic Network（ALAN）方法，该方法使用自动鉴定的视觉特征提取和大型后置网络来生成医学robust的semantic自 segmentation。results:* 这篇论文表明，自动鉴定后置网络可以坚定地标识心脏四室视图中的生物学特征。此外，论文还设计了两个下游模型，一个用于标识目标生物学区域，另一个用于echocardiogram视图分类。<details>
<summary>Abstract</summary>
Supervised training of deep learning models for medical imaging applications requires a significant amount of labeled data. This is posing a challenge as the images are required to be annotated by medical professionals. To address this limitation, we introduce the Adaptive Locked Agnostic Network (ALAN), a concept involving self-supervised visual feature extraction using a large backbone model to produce anatomically robust semantic self-segmentation. In the ALAN methodology, this self-supervised training occurs only once on a large and diverse dataset. Due to the intuitive interpretability of the segmentation, downstream models tailored for specific tasks can be easily designed using white-box models with few parameters. This, in turn, opens up the possibility of communicating the inner workings of a model with domain experts and introducing prior knowledge into it. It also means that the downstream models become less data-hungry compared to fully supervised approaches. These characteristics make ALAN particularly well-suited for resource-scarce scenarios, such as costly clinical trials and rare diseases. In this paper, we apply the ALAN approach to three publicly available echocardiography datasets: EchoNet-Dynamic, CAMUS, and TMED-2. Our findings demonstrate that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view. Building upon this, we design two downstream models, one for segmenting a target anatomical region, and a second for echocardiogram view classification.
</details>
<details>
<summary>摘要</summary>
审核训练深度学习模型 для医疗影像应用需要大量标注数据。然而，由于影像需要由医疗专业人员进行标注，这成为一个挑战。为解决这个限制，我们介绍了自适应锁定agnostic网络（ALAN），它利用大型后骨骼模型进行自我超视觉特征提取，以生成具有体系 robust的 semantic自segmentation。在ALAN方法中，这种自我超视觉训练只在一个大型和多样的数据集上进行一次。由于分割结果的直观解释，下游模型可以轻松地使用白盒模型和少量参数进行定制。这种特点使得ALAN在资源匮乏的情况下特别有优势，例如成本高的临床试验和罕见疾病。在这篇论文中，我们应用ALAN方法于三个公共可用的echo医学数据集：EchoNet-Dynamic、CAMUS和TMED-2。我们的发现表明，自适应锁定agnostic网络可以强健地 identificates心脏四室视图中的 анатомичеSUBREGION。基于这个结果，我们设计了两个下游模型，一个用于分割目标生物学区域，另一个用于echo医学视图类型分类。
</details></li>
</ul>
<hr>
<h2 id="Audio-Contrastive-based-Fine-tuning"><a href="#Audio-Contrastive-based-Fine-tuning" class="headerlink" title="Audio Contrastive based Fine-tuning"></a>Audio Contrastive based Fine-tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11895">http://arxiv.org/abs/2309.11895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Wang, Qibin Liang, Chenghao Xiao, Yizhi Li, Noura Al Moubayed, Chenghua Lin</li>
<li>for: Audio classification tasks, such as speech and sound processing, with a wide range of applications.</li>
<li>methods: 用对照学习的转移性能来提高模型的测试准确性和适应能力。</li>
<li>results: 在不同的audio classification任务中，AudioConFit方法可以实现高度的效果和稳定性，并且在不同的测试数据集上获得了最佳的结果。<details>
<summary>Abstract</summary>
Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
</details>
<details>
<summary>摘要</summary>
音频分类在语音和声音处理任务中扮演着关键角色，具有广泛的应用场景。然而，模型适应训练数据的问题仍然是一大挑战，以避免过拟合。我们基于对比学习的传送性，提出了音频对比细化（AudioConFit），一种高效的方法，具有强大的通用性。实验证明，我们的方法在不同的音频分类任务中具有优秀的效果和稳定性，达到了不同设置下的状态态表现。
</details></li>
</ul>
<hr>
<h2 id="Multi-level-Asymmetric-Contrastive-Learning-for-Medical-Image-Segmentation-Pre-training"><a href="#Multi-level-Asymmetric-Contrastive-Learning-for-Medical-Image-Segmentation-Pre-training" class="headerlink" title="Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training"></a>Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11876">http://arxiv.org/abs/2309.11876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Zeng, Lei Zhu, Xinliang Zhang, Zifeng Tian, Qian Chen, Lujia Jin, Jiayi Wang, Yanye Lu</li>
<li>for: 本文针对医疗影像分类任务提出了一个新的不对称对称学习框架（JCL），以自动扮演验证预训。</li>
<li>methods: 本文提出了一个新的不对称对称学习策略，同时预训encoder和decoder，以提供更好的预设值 для医疗影像分类模型。 multi-level对称损失函数被设计来考虑对于特征水平、影像水平和像素水平的对应关系，以确保encoder和decoder在预训过程中可以学习多个水平的表示。</li>
<li>results: 在多个医疗影像数据集上实验显示，我们的JCL框架比现有的SOTA对称学习策略更高效。<details>
<summary>Abstract</summary>
Contrastive learning, which is a powerful technique for learning image-level representations from unlabeled data, leads a promising direction to dealing with the dilemma between large-scale pre-training and limited labeled data. However, most existing contrastive learning strategies are designed mainly for downstream tasks of natural images, therefore they are sub-optimal and even worse than learning from scratch when directly applied to medical images whose downstream tasks are usually segmentation. In this work, we propose a novel asymmetric contrastive learning framework named JCL for medical image segmentation with self-supervised pre-training. Specifically, (1) A novel asymmetric contrastive learning strategy is proposed to pre-train both encoder and decoder simultaneously in one-stage to provide better initialization for segmentation models. (2) A multi-level contrastive loss is designed to take the correspondence among feature-level, image-level and pixel-level projections, respectively into account to make sure multi-level representations can be learned by the encoder and decoder during pre-training. (3) Experiments on multiple medical image datasets indicate our JCL framework outperforms existing SOTA contrastive learning strategies.
</details>
<details>
<summary>摘要</summary>
对于医疗影像的分类问题，对于大规模预训数据和有限的标签数据的冲突是一个挑战。然而，现有的对比学习策略主要是设计来应用于自然像素，因此它们在医疗影像的下游任务中表现不佳，甚至比起从零学习还差。在这个工作中，我们提出了一个名为JCL的 novel asymmetric对比学习框架，用于医疗影像分类。具体来说，我们提出了以下三个方法：1. 一个新的对比学习策略，同时在一阶段中预训encoder和decoder，以提供更好的初始化 для分类模型。2. 一个多层对比损失函数，用于考虑对于特征层、影像层和像素层的对应关系，以确保encoder和decoder在预训过程中学习到多层表示。3. 在多个医疗影像数据集上进行了实验，结果显示了我们的JCL框架比现有的SOTA对比学习策略更高效。
</details></li>
</ul>
<hr>
<h2 id="Stochastic-stiffness-identification-and-response-estimation-of-Timoshenko-beams-via-physics-informed-Gaussian-processes"><a href="#Stochastic-stiffness-identification-and-response-estimation-of-Timoshenko-beams-via-physics-informed-Gaussian-processes" class="headerlink" title="Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes"></a>Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11875">http://arxiv.org/abs/2309.11875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gledsonrt/pigptimoshenkobeam">https://github.com/gledsonrt/pigptimoshenkobeam</a></li>
<li>paper_authors: Gledson Rodrigo Tondo, Sebastian Rau, Igor Kavrakov, Guido Morgenthal</li>
<li>for: 这篇论文旨在用机器学习模型进行系统识别，特别是Timoshenko梁元件的结构健康监测数据。</li>
<li>methods: 该论文提出了一种基于 Gaussian Process（GP）模型的物理 informed 方法，用于结构参数的 indentification。该模型是一种多输出GP模型，其covariance和cross-covariance函数 Analytical derivation based on the differential equations of deflections, rotations, strains, bending moments, shear forces and applied loads。</li>
<li>results: 对于结构参数的 indentification，使用 Bayesian 格式的最大化 posterior model，通过 Markov chain Monte Carlo 方法进行优化，得到了一个随机模型。此外，该方法还可以用于probabilistic predictions of unobserved responses。实验结果表明，提出的方法可以有效地 indentify结构参数，并且可以融合不同类型和多价信息感知器的数据。结果的质量和不确定性也得到了验证。该方法有广泛的应用前提在结构健康监测（SHM）领域。<details>
<summary>Abstract</summary>
Machine learning models trained with structural health monitoring data have become a powerful tool for system identification. This paper presents a physics-informed Gaussian process (GP) model for Timoshenko beam elements. The model is constructed as a multi-output GP with covariance and cross-covariance kernels analytically derived based on the differential equations for deflections, rotations, strains, bending moments, shear forces and applied loads. Stiffness identification is performed in a Bayesian format by maximising a posterior model through a Markov chain Monte Carlo method, yielding a stochastic model for the structural parameters. The optimised GP model is further employed for probabilistic predictions of unobserved responses. Additionally, an entropy-based method for physics-informed sensor placement optimisation is presented, exploiting heterogeneous sensor position information and structural boundary conditions built into the GP model. Results demonstrate that the proposed approach is effective at identifying structural parameters and is capable of fusing data from heterogeneous and multi-fidelity sensors. Probabilistic predictions of structural responses and internal forces are in closer agreement with measured data. We validate our model with an experimental setup and discuss the quality and uncertainty of the obtained results. The proposed approach has potential applications in the field of structural health monitoring (SHM) for both mechanical and structural systems.
</details>
<details>
<summary>摘要</summary>
机器学习模型使用结构健康监测数据成为了系统识别的强大工具。这篇论文提出了基于Timoshenko梁元素的物理知识泛化过程（GP）模型。该模型是一种多输出GP模型，其covariance和交叉covariancekernel analytically derive了基于摆动、旋转、强度、剪力、应用负荷的偏微分方程。在 bayesian 格式下，通过Markov chain Monte Carlo 方法进行了权重最大化，从而获得了一个随机模型 для结构参数。该优化后的 GP 模型进一步用于 probabilistic 预测未观测Response。此外，本文还提出了基于物理知识的感知器位置优化方法，利用不同类型感知器位置信息和结构边界条件，并将其建入 GP 模型中。结果表明，提出的方法能够有效地识别结构参数，并能够融合不同类型和多优化感知器的数据。probabilistic 预测结构响应和内部力的结果与实验数据更加吻合。我们验证了我们的模型，并讨论了获得的结果的质量和不确定性。该方法在结构健康监测（SHM）领域有广泛的应用前景。
</details></li>
</ul>
<hr>
<h2 id="OSNet-MNetO-Two-Types-of-General-Reconstruction-Architectures-for-Linear-Computed-Tomography-in-Multi-Scenarios"><a href="#OSNet-MNetO-Two-Types-of-General-Reconstruction-Architectures-for-Linear-Computed-Tomography-in-Multi-Scenarios" class="headerlink" title="OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios"></a>OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11858">http://arxiv.org/abs/2309.11858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhisheng Wang, Zihan Deng, Fenglin Liu, Yixing Huang, Haijun Yu, Junning Cui<br>for:* Linear computed tomography (LCT) systems Linear computed tomography (LCT) systems are the focus of this paper, and the authors aim to improve image reconstruction for these systems.methods:*  Backprojection filtration (BPF) algorithm The BPF algorithm is used to weaken projection truncation and image the region of interest (ROI) for LCT.*  Two types of reconstruction architectures are proposed: Overlay-Single Network (OSNet) and Multiple Networks Overlaying (MNetO) These architectures use multiple DBP images to obtain a complete DBP image and train different directional Hilbert filtering models for DBP images of multiple linear scannings, respectively.results:*  OSNet outperforms BPF in various scenarios The OSNet architecture outperforms the traditional BPF algorithm in different scenarios, including interior ROI, complete object, and exterior region beyond field-of-view (FOV).*  ST-pix2pixGAN is superior to pix2pixGAN and CycleGAN The authors introduce a Swin Transformer (ST) block to the generator of pix2pixGAN to extract both local and global features from DBP images at the same time, and ST-pix2pixGAN is found to be superior to pix2pixGAN and CycleGAN.*  MNetO exhibits a few artifacts due to the differences among the multiple models MNetO uses multiple networks to train different directional Hilbert filtering models for DBP images of multiple linear scannings, but it exhibits a few artifacts due to the differences among the multiple models.<details>
<summary>Abstract</summary>
Recently, linear computed tomography (LCT) systems have actively attracted attention. To weaken projection truncation and image the region of interest (ROI) for LCT, the backprojection filtration (BPF) algorithm is an effective solution. However, in BPF for LCT, it is difficult to achieve stable interior reconstruction, and for differentiated backprojection (DBP) images of LCT, multiple rotation-finite inversion of Hilbert transform (Hilbert filtering)-inverse rotation operations will blur the image. To satisfy multiple reconstruction scenarios for LCT, including interior ROI, complete object, and exterior region beyond field-of-view (FOV), and avoid the rotation operations of Hilbert filtering, we propose two types of reconstruction architectures. The first overlays multiple DBP images to obtain a complete DBP image, then uses a network to learn the overlying Hilbert filtering function, referred to as the Overlay-Single Network (OSNet). The second uses multiple networks to train different directional Hilbert filtering models for DBP images of multiple linear scannings, respectively, and then overlays the reconstructed results, i.e., Multiple Networks Overlaying (MNetO). In two architectures, we introduce a Swin Transformer (ST) block to the generator of pix2pixGAN to extract both local and global features from DBP images at the same time. We investigate two architectures from different networks, FOV sizes, pixel sizes, number of projections, geometric magnification, and processing time. Experimental results show that two architectures can both recover images. OSNet outperforms BPF in various scenarios. For the different networks, ST-pix2pixGAN is superior to pix2pixGAN and CycleGAN. MNetO exhibits a few artifacts due to the differences among the multiple models, but any one of its models is suitable for imaging the exterior edge in a certain direction.
</details>
<details>
<summary>摘要</summary>
最近，线性计算 Tomatoes系统（LCT）已经吸引了一些注意。为了弱化投影截断和图像区域内部（ROI）的投影，使用backprojection filtration（BPF）算法是一个有效的解决方案。然而，在LCT中的BPF中，很难实现稳定的内部重建，而且对于DBP图像的LCT，多个旋转finite inversion of Hilbert transform（Hilbert filtering）操作会模糊图像。为了满足LCT的多种重建场景，包括内部ROI、完整的对象和外部区域超出FOV（场景），并且避免旋转Hilbert filtering的操作，我们提出了两种重建建筑。第一种方法是将多个DBP图像 overlay 成一个完整的DBP图像，然后使用一个网络来学习投影过程中的Hilbert filtering函数，被称为Overlay-Single Network（OSNet）。第二种方法是使用多个网络来训练不同的方向的Hilbert filtering模型，并将其重建结果 overlay 在一起，即Multiple Networks Overlaying（MNetO）。在两种建筑中，我们引入了Swin Transformer（ST）块到 pix2pixGAN 生成器中，以同时提取 DBP 图像的本地和全局特征。我们从不同的网络、FOV 大小、像素大小、投影数量、几何增大和处理时间等方面进行了调查。实验结果表明，两种建筑都可以重建图像，OSNet 在多种场景中表现出色，超过 BPF。而ST-pix2pixGAN 比 pix2pixGAN 和 CycleGAN 更高效。MNetO 显示了一些缺陷，但任何一个模型都适用于某些方向的图像重建。
</details></li>
</ul>
<hr>
<h2 id="BitCoin-Bidirectional-Tagging-and-Supervised-Contrastive-Learning-based-Joint-Relational-Triple-Extraction-Framework"><a href="#BitCoin-Bidirectional-Tagging-and-Supervised-Contrastive-Learning-based-Joint-Relational-Triple-Extraction-Framework" class="headerlink" title="BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework"></a>BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11853">http://arxiv.org/abs/2309.11853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luyao He, Zhongbao Zhang, Sen Su, Yuxin Chen</li>
<li>for: 提高关系 triple EXTRACTION（RTE）任务的精度和效率，解决现有方法的一般化和特定性问题。</li>
<li>methods: 提出了一种创新的双向标注和监督对比学习基于的关系 triple EXTRACTION框架（BitCoin），包括多个可能的正例而不仅仅是一个正例，并引入对象和主题之间的偏差项来避免对象和主题之间的过度相似性。</li>
<li>results: 实验结果显示，BitCoin在标准数据集上达到了当前最佳Result，在不同的任务上（包括Normal、SEO、EPO和多关系EXTRACTION）显著提高了F1分数。<details>
<summary>Abstract</summary>
Relation triple extraction (RTE) is an essential task in information extraction and knowledge graph construction. Despite recent advancements, existing methods still exhibit certain limitations. They just employ generalized pre-trained models and do not consider the specificity of RTE tasks. Moreover, existing tagging-based approaches typically decompose the RTE task into two subtasks, initially identifying subjects and subsequently identifying objects and relations. They solely focus on extracting relational triples from subject to object, neglecting that once the extraction of a subject fails, it fails in extracting all triples associated with that subject. To address these issues, we propose BitCoin, an innovative Bidirectional tagging and supervised Contrastive learning based joint relational triple extraction framework. Specifically, we design a supervised contrastive learning method that considers multiple positives per anchor rather than restricting it to just one positive. Furthermore, a penalty term is introduced to prevent excessive similarity between the subject and object. Our framework implements taggers in two directions, enabling triples extraction from subject to object and object to subject. Experimental results show that BitCoin achieves state-of-the-art results on the benchmark datasets and significantly improves the F1 score on Normal, SEO, EPO, and multiple relation extraction tasks.
</details>
<details>
<summary>摘要</summary>
“关系 triple 提取（RTE）是信息提取和知识图建构中的关键任务。尽管最近有所进步，现有方法仍然存在一定的限制。它们只是使用通用预训练模型，未考虑RTE任务的特点。另外，现有的标签化方法通常将RTE任务分解成两个子任务，先确定主题，然后确定 объек 和关系。它们仅专注于从主题到 объек 中提取关系 triple，忽略了如果提取主题失败，那么所有与该主题相关的 triple 都将难以提取。为解决这些问题，我们提出了 BitCoin，一种创新的双向标签和监督对比学习基于的关系 triple 提取框架。具体来说，我们设计了一种监督对比学习方法，考虑多个可能的正例而不是仅仅 restricting 到一个正例。此外，我们引入了一个罚项，以避免主题和 объек 之间的过度相似性。我们的框架实现了两个方向的标签，即从主题到 объек 和从 objet 到主题。实验结果表明，BitCoin 在标准数据集上达到了当前最佳的结果，并在多个关系提取任务上显著提高了 F1 分数。”
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Large-Language-Models-for-Document-grounded-Response-Generation-in-Information-Seeking-Dialogues"><a href="#Evaluating-Large-Language-Models-for-Document-grounded-Response-Generation-in-Information-Seeking-Dialogues" class="headerlink" title="Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues"></a>Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11838">http://arxiv.org/abs/2309.11838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Norbert Braunschweiler, Rama Doddipatla, Simon Keizer, Svetlana Stoyanchev</li>
<li>for: 这个研究是为了研究使用大语言模型（LLMs）like ChatGPT来生成基于文档的响应，特别是在信息寻求对话中。</li>
<li>methods: 这个研究使用了两种方法：ChatCompletion和LlamaIndex。ChatCompletion使用了ChatGPT模型的预training知识，而LlamaIndex则从文档中提取了相关信息。</li>
<li>results: 研究发现，使用LLMs来生成基于文档的响应是不可靠的，因为它们可能包含未在文档中出现的信息，可能是幻想。同时，两种ChatGPT变体的输出被评估为更高，比之前的分享任务赢家系统和人类响应。<details>
<summary>Abstract</summary>
In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses. While both ChatGPT variants are more likely to include information not present in the relevant segments, possibly including a presence of hallucinations, they are rated higher than both the shared task winning system and human responses.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了大型自然语言模型（LLM）如ChatGPT在信息寻求对话中的回答生成。为评估，我们使用MultiDoc2Dial词汇对话 corpus，这是四个社会服务领域的任务型对话，已经在DialDoc 2022 Shared Task中使用。信息寻求对话转归基于多份文档提供相关信息。我们生成对话完成回答，使用两种方法：Chat-Completion和LlamaIndex。ChatCompletion利用ChatGPT模型的先前预测知识，而LlamaIndex也从文档中提取相关信息。由于文档基础回答生成via LLMs无法准确评估，我们进行了人工评估。评估结果显示，两个ChatGPT变体的输出高于分享任务获胜系统和人类回答。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Transformers-for-Wireless-Communications-A-Case-Study-in-Beam-Prediction"><a href="#Multimodal-Transformers-for-Wireless-Communications-A-Case-Study-in-Beam-Prediction" class="headerlink" title="Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction"></a>Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11811">http://arxiv.org/abs/2309.11811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itu-ai-ml-in-5g-challenge/deepsense6g_tii">https://github.com/itu-ai-ml-in-5g-challenge/deepsense6g_tii</a></li>
<li>paper_authors: Yu Tian, Qiyang Zhao, Zine el abidine Kherroubi, Fouzi Boukhalfa, Kebin Wu, Faouzi Bader</li>
<li>for: 本研究旨在提高无线通信高频带的大antenna数组面临的扫描管理问题，通过多模态感知信息（包括摄像头、LiDAR、雷达和GPS）的多模态感知训练deep learning框架。</li>
<li>methods: 本研究使用多模态转换器深度学习框架，将多modal的感知信息经过核心网络提取特征，然后使用transformer编码器学习不同modalities和时间点之间的隐藏关系，生成下一层特征提取的编码器。</li>
<li>results: 实验结果显示，使用图像和GPS数据进行训练的解决方案可以达到78.44%的距离基于准确性，并且在不seen日景和夜景中实现了73%和84%的泛化性。这些结果超过了使用其他modalities和arbitrary数据处理技术，从而证明了转换器在图像和GPS数据上的准确性和泛化性。<details>
<summary>Abstract</summary>
Wireless communications at high-frequency bands with large antenna arrays face challenges in beam management, which can potentially be improved by multimodality sensing information from cameras, LiDAR, radar, and GPS. In this paper, we present a multimodal transformer deep learning framework for sensing-assisted beam prediction. We employ a convolutional neural network to extract the features from a sequence of images, point clouds, and radar raw data sampled over time. At each convolutional layer, we use transformer encoders to learn the hidden relations between feature tokens from different modalities and time instances over abstraction space and produce encoded vectors for the next-level feature extraction. We train the model on a combination of different modalities with supervised learning. We try to enhance the model over imbalanced data by utilizing focal loss and exponential moving average. We also evaluate data processing and augmentation techniques such as image enhancement, segmentation, background filtering, multimodal data flipping, radar signal transformation, and GPS angle calibration. Experimental results show that our solution trained on image and GPS data produces the best distance-based accuracy of predicted beams at 78.44%, with effective generalization to unseen day scenarios near 73% and night scenarios over 84%. This outperforms using other modalities and arbitrary data processing techniques, which demonstrates the effectiveness of transformers with feature fusion in performing radio beam prediction from images and GPS. Furthermore, our solution could be pretrained from large sequences of multimodality wireless data, on fine-tuning for multiple downstream radio network tasks.
</details>
<details>
<summary>摘要</summary>
无线通信在高频段 WITH 大antenna array 面临 beam 管理问题，可能可以通过多模态感知信息 FROM camera, LiDAR, radar, GPS 进行改进。在这篇论文中，我们提出了一种多模态 transformer 深度学习框架 FOR 感知协助的 beam 预测。我们使用卷积神经网络提取图像、点云和雷达原始数据序列中的特征，并在每层卷积层使用 transformer 编码器学习不同模态和时间实例之间的隐藏关系，生成下一层特征提取的编码 вектор。我们使用多模态supervised学习训练模型，并尝试通过使用焦点损失和指数移动平均来增强模型对不均衡数据的适应。我们还评估了数据处理和扩展技术，如图像提升、分割、背景筛选、多模态数据翻转、雷达信号转换和GPS角度准确。实验结果表明，我们基于图像和 GPS 数据训练的解决方案可以在78.44%的距离基于准确率上预测 beam，并且在未看到的日场景中 Near 73% AND 夜场景中超过 84%。这超过了使用其他模式和自由数据处理技术，这表明 transformers 在图像和 GPS 数据上进行 radio beam 预测具有效果，并且可以通过多模态数据进行预训练，并在多个无线网络下执行多种下游任务进行 fine-tuning。
</details></li>
</ul>
<hr>
<h2 id="JobRecoGPT-–-Explainable-job-recommendations-using-LLMs"><a href="#JobRecoGPT-–-Explainable-job-recommendations-using-LLMs" class="headerlink" title="JobRecoGPT – Explainable job recommendations using LLMs"></a>JobRecoGPT – Explainable job recommendations using LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11805">http://arxiv.org/abs/2309.11805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Preetam Ghosh, Vaishali Sadaphal</li>
<li>for: 这个论文是为了推荐适合候选人的工作而写的。</li>
<li>methods: 这篇论文使用了人工智能技术，特别是大语言模型（LLMs）来捕捉原文中的信息，以便更好地推荐适合候选人的工作。</li>
<li>results: 这篇论文 comparing了四种不同的方法，即内容基于的决定方法、LLM指导的方法、LLM无指导的方法以及混合方法，并评估了每种方法的时间需求和性能。<details>
<summary>Abstract</summary>
In today's rapidly evolving job market, finding the right opportunity can be a daunting challenge. With advancements in the field of AI, computers can now recommend suitable jobs to candidates. However, the task of recommending jobs is not same as recommending movies to viewers. Apart from must-have criteria, like skills and experience, there are many subtle aspects to a job which can decide if it is a good fit or not for a given candidate. Traditional approaches can capture the quantifiable aspects of jobs and candidates, but a substantial portion of the data that is present in unstructured form in the job descriptions and resumes is lost in the process of conversion to structured format. As of late, Large Language Models (LLMs) have taken over the AI field by storm with extraordinary performance in fields where text-based data is available. Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form. To this end, we compare performance of four different approaches for job recommendations namely, (i) Content based deterministic, (ii) LLM guided, (iii) LLM unguided, and (iv) Hybrid. In this study, we present advantages and limitations of each method and evaluate their performance in terms of time requirements.
</details>
<details>
<summary>摘要</summary>
Recently, Large Language Models (LLMs) have revolutionized the AI field with extraordinary performance in text-based data. Inspired by their capabilities, we leverage their ability to understand natural language to capture the information that was previously lost during the conversion of unstructured data to a structured form. To achieve this, we compare the performance of four different approaches for job recommendations:1. Content-based deterministic approach2. LLM-guided approach3. LLM unguided approach4. Hybrid approachIn this study, we present the advantages and limitations of each method and evaluate their performance in terms of time requirements.
</details></li>
</ul>
<hr>
<h2 id="DimCL-Dimensional-Contrastive-Learning-For-Improving-Self-Supervised-Learning"><a href="#DimCL-Dimensional-Contrastive-Learning-For-Improving-Self-Supervised-Learning" class="headerlink" title="DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning"></a>DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11782">http://arxiv.org/abs/2309.11782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanh Nguyen, Trung Pham, Chaoning Zhang, Tung Luu, Thang Vu, Chang D. Yoo</li>
<li>for: 提高自动学习（SSL）的表现，增强特征多样性</li>
<li>methods: 维度对冲学习（DimCL），一种在维度方向进行对冲学习而不是批处理方向的新方法</li>
<li>results: 在多个数据集和背景架构上实现了表现的提高，并且发现了困难度感知的特性对其成功起到了关键作用<details>
<summary>Abstract</summary>
Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance improvement by a non-trivial margin on various datasets and backbone architectures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="2DDATA-2D-Detection-Annotations-Transmittable-Aggregation-for-Semantic-Segmentation-on-Point-Cloud"><a href="#2DDATA-2D-Detection-Annotations-Transmittable-Aggregation-for-Semantic-Segmentation-on-Point-Cloud" class="headerlink" title="2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud"></a>2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11755">http://arxiv.org/abs/2309.11755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guan-Cheng Lee</li>
<li>for: 这篇论文目的是提出一种解决多感器模型中精度准确性问题的方法，使得这些模型能够在实际应用中使用。</li>
<li>methods: 这篇论文使用了2D检测注释传输汇聚(\textbf{2DDATA})方法，并设计了一个本地对象分支(\textbf{Local Object Branch})来处理点云数据。</li>
<li>results: 研究人员通过实验证明了他们的简单设计可以传输矩形盒注释信息到3D编码器模型，证明了大型多感器模型与模态特定数据的混合是可能的。<details>
<summary>Abstract</summary>
Recently, multi-modality models have been introduced because of the complementary information from different sensors such as LiDAR and cameras. It requires paired data along with precise calibrations for all modalities, the complicated calibration among modalities hugely increases the cost of collecting such high-quality datasets, and hinder it from being applied to practical scenarios. Inherit from the previous works, we not only fuse the information from multi-modality without above issues, and also exhaust the information in the RGB modality. We introduced the 2D Detection Annotations Transmittable Aggregation(\textbf{2DDATA}), designing a data-specific branch, called \textbf{Local Object Branch}, which aims to deal with points in a certain bounding box, because of its easiness of acquiring 2D bounding box annotations. We demonstrate that our simple design can transmit bounding box prior information to the 3D encoder model, proving the feasibility of large multi-modality models fused with modality-specific data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improve-the-efficiency-of-deep-reinforcement-learning-through-semantic-exploration-guided-by-natural-language"><a href="#Improve-the-efficiency-of-deep-reinforcement-learning-through-semantic-exploration-guided-by-natural-language" class="headerlink" title="Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language"></a>Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11753">http://arxiv.org/abs/2309.11753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhourui Guo, Meng Yao, Yang Yu, Qiyue Yin</li>
<li>for: 本文提出了一种新的方法，用于在RL中选择性地使用oracle，以提高RL的效率。</li>
<li>methods: 本文使用了一种模板问题和答案的方法，通过对 previous interactions 的整合，使用神经网络对当前状态和oracle的编码，并从corpus中检索最相关的问题。</li>
<li>results: 本文在一个物体把握任务上进行了评估，显示了 compared to基线方法，使用oracle可以显著提高RL的效率，减少RL需要进行的交互数量。<details>
<summary>Abstract</summary>
Reinforcement learning is a powerful technique for learning from trial and error, but it often requires a large number of interactions to achieve good performance. In some domains, such as sparse-reward tasks, an oracle that can provide useful feedback or guidance to the agent during the learning process is really of great importance. However, querying the oracle too frequently may be costly or impractical, and the oracle may not always have a clear answer for every situation. Therefore, we propose a novel method for interacting with the oracle in a selective and efficient way, using a retrieval-based approach. We assume that the interaction can be modeled as a sequence of templated questions and answers, and that there is a large corpus of previous interactions available. We use a neural network to encode the current state of the agent and the oracle, and retrieve the most relevant question from the corpus to ask the oracle. We then use the oracle's answer to update the agent's policy and value function. We evaluate our method on an object manipulation task. We show that our method can significantly improve the efficiency of RL by reducing the number of interactions needed to reach a certain level of performance, compared to baselines that do not use the oracle or use it in a naive way.
</details>
<details>
<summary>摘要</summary>
�� Reinforcement learning 是一种强大的学习技术，但它经常需要大量的交互来达到良好的性能。在某些领域，如稀谱奖励任务，一个 oracle 可以提供有用的反馈或指导 для Agent  durante el proceso de aprendizaje。然而，请求 oracle 的频率可能是成本高或实际不切实际的，而且 oracle 并不总是有清晰的答案对每个情况。因此，我们提出了一种新的方法来与 oracle 交互，使用一种检索基本的方法。我们假设交互可以被模型为一个序列化的问题和答案，并且有一大量的前期交互数据库。我们使用神经网络来编码 Agent 和 oracle 的当前状态，并从数据库中检索最相关的问题来问 oracle。然后，我们使用 oracle 的答案来更新 Agent 的政策和价值函数。我们在一个物体抓取任务上评估了我们的方法，并显示了我们的方法可以减少 RL 中交互的次数，以达到一定的性能水平，相比于不使用 oracle 或使用它的做法。
</details></li>
</ul>
<hr>
<h2 id="How-Robust-is-Google’s-Bard-to-Adversarial-Image-Attacks"><a href="#How-Robust-is-Google’s-Bard-to-Adversarial-Image-Attacks" class="headerlink" title="How Robust is Google’s Bard to Adversarial Image Attacks?"></a>How Robust is Google’s Bard to Adversarial Image Attacks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11751">http://arxiv.org/abs/2309.11751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-ml/attack-bard">https://github.com/thu-ml/attack-bard</a></li>
<li>paper_authors: Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu</li>
<li>for: 这研究旨在研究Google的Bard chatbot的抗击型识别器 robustness，以便更好地理解商业多模态大语言模型（MLLMs）中的漏洞。</li>
<li>methods: 我们使用了白盒子代理视觉编码器或 MLLMs 进行攻击，生成了对 Bard 的 adversarial examples，并证明了这些攻击可以让 Bard 输出错误的图像描述。</li>
<li>results: 我们发现，对 Bard 的 adversarial examples 可以达到 22% 的成功率，并且可以攻击其他 MLLMs，如 Bing Chat 和 ERNIE bot。此外，我们还发现了 Bard 的两种防御机制，包括图像检测和图像攻击检测。我们设计了对这些防御机制的攻击，证明了现有的防御机制也是易于绕过的。<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection and toxicity detection of images. We design corresponding attacks to evade these defenses, demonstrating that the current defenses of Bard are also vulnerable. We hope this work can deepen our understanding on the robustness of MLLMs and facilitate future research on defenses. Our code is available at https://github.com/thu-ml/Attack-Bard.
</details>
<details>
<summary>摘要</summary>
多模态大语言模型（MLLMs），尤其是与视觉相结合，在多种多 modal 任务中表现出色。然而，由于视觉模型的不可预测性问题，MLLMs 可能带来更严重的安全和安全风险。在这项工作中，我们研究了Google的Bard，一个与 ChatGPT 竞争的聊天机器人，以更好地理解商业MLLMs 的漏洞。我们发现，通过攻击白盒子代理视觉encoder或 MLLMs，可以生成 adversarial 例子，导致 Bard 输出错误的图像描述，成功率达22%。此外，我们发现这些 adversarial 例子还可以攻击其他 MLLMs，例如 Bing Chat 和 ERNIE 机器人。此外，我们还发现 Bard 具有两种防御机制：脸部检测和图像攻击检测。我们设计了相应的攻击，证明现有防御机制也是易攻击的。我们希望这项工作可以深入我们对 MLLMs 的稳定性和防御机制的理解，并促进未来研究。我们的代码可以在 <https://github.com/thu-ml/Attack-Bard> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Choice-75-A-Dataset-on-Decision-Branching-in-Script-Learning"><a href="#Choice-75-A-Dataset-on-Decision-Branching-in-Script-Learning" class="headerlink" title="Choice-75: A Dataset on Decision Branching in Script Learning"></a>Choice-75: A Dataset on Decision Branching in Script Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11737">http://arxiv.org/abs/2309.11737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyi Joey Hou, Li Zhang, Chris Callison-Burch</li>
<li>for: 本研究旨在探讨日常事件的发展过程。</li>
<li>methods: 本研究使用 Choice-75  benchmark，该 benchmark 包含 75 个场景和超过 600 个enario，以测试智能系统在面对描述性场景时的决策能力。</li>
<li>results: 大型语言模型在总体上表现不错，但在许多困难场景下仍有很大的进攻空间。<details>
<summary>Abstract</summary>
Script learning studies how daily events unfold. Previous works tend to consider a script as a linear sequence of events while ignoring the potential branches that arise due to people's circumstantial choices. We hence propose Choice-75, the first benchmark that challenges intelligent systems to predict decisions given descriptive scenarios, containing 75 scripts and more than 600 scenarios. While large language models demonstrate overall decent performances, there is still notable room for improvement in many hard scenarios.
</details>
<details>
<summary>摘要</summary>
学习脚本研究每日事件的发展。先前的工作通常将脚本视为一个直线性的事件序列，忽略人们因 circumstance 的选择所导致的可能的分支。我们因此提出了 Choice-75，首个挑战智能系统预测基于描述场景的决策，包含75个脚本和超过600个场景。虽然大语言模型在总体上表现不错，但在许多困难场景中仍有很大的改进空间。
</details></li>
</ul>
<hr>
<h2 id="FluentEditor-Text-based-Speech-Editing-by-Considering-Acoustic-and-Prosody-Consistency"><a href="#FluentEditor-Text-based-Speech-Editing-by-Considering-Acoustic-and-Prosody-Consistency" class="headerlink" title="FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency"></a>FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11725">http://arxiv.org/abs/2309.11725</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-s2-lab/fluenteditor">https://github.com/ai-s2-lab/fluenteditor</a></li>
<li>paper_authors: Rui Liu, Jiatian Xi, Ziyue Jiang, Haizhou Li</li>
<li>for: 提高语音编辑技术的自然性和流畅性</li>
<li>methods: 使用fluency-aware训练 критерий，包括音频一致性约束和语调一致性约束</li>
<li>results: 对VCTK数据集进行subjective和objective эксперименты，表明我们的FluentEditor模型在自然性和流畅性方面具有显著优势，Audioamples和代码可以在github上获取<details>
<summary>Abstract</summary>
Text-based speech editing (TSE) techniques are designed to enable users to edit the output audio by modifying the input text transcript instead of the audio itself. Despite much progress in neural network-based TSE techniques, the current techniques have focused on reducing the difference between the generated speech segment and the reference target in the editing region, ignoring its local and global fluency in the context and original utterance. To maintain the speech fluency, we propose a fluency speech editing model, termed \textit{FluentEditor}, by considering fluency-aware training criterion in the TSE training. Specifically, the \textit{acoustic consistency constraint} aims to smooth the transition between the edited region and its neighboring acoustic segments consistent with the ground truth, while the \textit{prosody consistency constraint} seeks to ensure that the prosody attributes within the edited regions remain consistent with the overall style of the original utterance. The subjective and objective experimental results on VCTK demonstrate that our \textit{FluentEditor} outperforms all advanced baselines in terms of naturalness and fluency. The audio samples and code are available at \url{https://github.com/Ai-S2-Lab/FluentEditor}.
</details>
<details>
<summary>摘要</summary>
文本基于的语音修编（TSE）技术是为了让用户通过修改输入文本脚本而不是直接修改音频来编辑语音。虽然现有的神经网络基于TSE技术已经做出了很大的进步，但是现有的技术都是关注在编辑区域中减少生成的语音段与参照标题之间的差异，而忽略了当地和全局的流畅性。为保持语音流畅，我们提议一种流畅语音修编模型，称为“流畅编辑器”，通过考虑流畅意识训练 criterion 在 TSE 训练中来实现。具体来说，“语音一致性约束”是为了使编辑区域和其邻近的语音段之间的过渡变得更加平滑，与真实的语音一致；而“表情一致性约束”则是为了确保在编辑区域中的表情特征与原始语音的整体风格保持一致。对于 VCTK 的实验结果表明，我们的“流畅编辑器”在自然性和流畅性两个方面都超过了所有高级基elines。听音样本和代码可以在 GitHub 上找到：https://github.com/Ai-S2-Lab/FluentEditor。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Aware-Prosodic-Phrasing-for-Expressive-Text-to-Speech"><a href="#Emotion-Aware-Prosodic-Phrasing-for-Expressive-Text-to-Speech" class="headerlink" title="Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech"></a>Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11724">http://arxiv.org/abs/2309.11724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-s2-lab/emopp">https://github.com/ai-s2-lab/emopp</a></li>
<li>paper_authors: Rui Liu, Bin Liu, Haizhou Li</li>
<li>for: 这篇论文的目的是提出一种能够准确地捕捉语音中情感信息的情感意识排序模型（EmoPP），以便更好地表达情感。</li>
<li>methods: 这篇论文使用了对ESD数据集的 объектив观察，以验证情感和排序之间的强相关性。然后，对比了基eline和EmoPP模型，并进行了对比性和主观评价。</li>
<li>results: 研究结果表明，EmoPP模型在情感表达方面表现出色，与基eline模型相比，具有更高的表达效果和准确性。code和音频样本可以在github上下载。<details>
<summary>Abstract</summary>
Prosodic phrasing is crucial to the naturalness and intelligibility of end-to-end Text-to-Speech (TTS). There exist both linguistic and emotional prosody in natural speech. As the study of prosodic phrasing has been linguistically motivated, prosodic phrasing for expressive emotion rendering has not been well studied. In this paper, we propose an emotion-aware prosodic phrasing model, termed \textit{EmoPP}, to mine the emotional cues of utterance accurately and predict appropriate phrase breaks. We first conduct objective observations on the ESD dataset to validate the strong correlation between emotion and prosodic phrasing. Then the objective and subjective evaluations show that the EmoPP outperforms all baselines and achieves remarkable performance in terms of emotion expressiveness. The audio samples and the code are available at \url{https://github.com/AI-S2-Lab/EmoPP}.
</details>
<details>
<summary>摘要</summary>
“句子间的调音是 тек字至话（TTS）的自然和可理解性的关键。自然语言中存在语言和情感的调音。由于研究调音 phrasing 的动机主要是语言学的，因此对于表达情感的调音 phrasing 尚未受到充分研究。在这篇文章中，我们提出了一个情感认知的调音 phrasing 模型，称为 EmoPP，以精确地捕捉说话中的情感讯号和适当的分割点。我们首先通过对 ESD dataset 的 объектив观察， Validate 调音 phrasing 和情感之间的强相关。然后，对比性和主观评价显示，EmoPP 在情感表达方面具有很高的表现。另外，我们还提供了 Audio 示例和代码，可以在 GitHub 上找到。”Note that Simplified Chinese uses a different set of characters and grammar compared to Traditional Chinese, so the translation may differ slightly from the original text.
</details></li>
</ul>
<hr>
<h2 id="A-Dynamic-Domain-Adaptation-Deep-Learning-Network-for-EEG-based-Motor-Imagery-Classification"><a href="#A-Dynamic-Domain-Adaptation-Deep-Learning-Network-for-EEG-based-Motor-Imagery-Classification" class="headerlink" title="A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification"></a>A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11714">http://arxiv.org/abs/2309.11714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Jiao, Meiyan Xu, Qingqing Chen, Hefan Zhou, Wangliang Zhou</li>
<li>for: 提高 EEG 基于脑机器人接口的精度和效率，以及适应不同个体和Session 间的差异。</li>
<li>methods: 提议使用动态领域适应深度学习网络 (DADL-Net)，通过3D 卷积模块学习 EEG 数据的三维几何特征，然后使用空间通道注意力机制加强特征，并使用最大平均差分损失函数适应不同个体和Session 间的差异。</li>
<li>results: 在 BCI 竞赛 IV 2a 和 OpenBMI 数据集上验证了提议的方法，实现了70.42% 和73.91% 的准确率。<details>
<summary>Abstract</summary>
There is a correlation between adjacent channels of electroencephalogram (EEG), and how to represent this correlation is an issue that is currently being explored. In addition, due to inter-individual differences in EEG signals, this discrepancy results in new subjects need spend a amount of calibration time for EEG-based motor imagery brain-computer interface. In order to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net). First, the EEG data is mapped to the three-dimensional geometric space and its temporal-spatial features are learned through the 3D convolution module, and then the spatial-channel attention mechanism is used to strengthen the features, and the final convolution module can further learn the spatial-temporal information of the features. Finally, to account for inter-subject and cross-sessions differences, we employ a dynamic domain-adaptive strategy, the distance between features is reduced by introducing a Maximum Mean Discrepancy loss function, and the classification layer is fine-tuned by using part of the target domain data. We verify the performance of the proposed method on BCI competition IV 2a and OpenBMI datasets. Under the intra-subject experiment, the accuracy rates of 70.42% and 73.91% were achieved on the OpenBMI and BCIC IV 2a datasets.
</details>
<details>
<summary>摘要</summary>
“electroencephalogram（EEG）附近通道之间存在相关性，但如何表示这种相关性是目前正在探索的问题。此外，由于EEG信号间的差异，需要新的训练时间以便EEG基于脑神经接口。为解决上述问题，我们提出了动态领域适应基于深度学习网络（DADL-Net）。首先，EEG数据会被对三维几何空间中的映射，并通过3D梯度层学习三维空间中的特征，然后使用空间频道注意力机制来强化特征，最后通过最后一个梯度层学习特征的空间-时间信息。为了考虑对象和跨会议差异，我们使用动态领域适应策略，将特征之间的距离降低，并使用Maximum Mean Discrepancy损失函数微调分类层。我们证明提案的方法在BCI竞赛IV 2a和OpenBMI数据集上表现出色。在内部实验中，OpenBMI和BCIC IV 2a数据集的准确率分别为70.42%和73.91%。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.AI_2023_09_21/" data-id="clmvt7t7s004926rdg90i0rfa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.CL_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T11:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.CL_2023_09_21/">cs.CL - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Reranking-for-Natural-Language-Generation-from-Logical-Forms-A-Study-based-on-Large-Language-Models"><a href="#Reranking-for-Natural-Language-Generation-from-Logical-Forms-A-Study-based-on-Large-Language-Models" class="headerlink" title="Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models"></a>Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12294">http://arxiv.org/abs/2309.12294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Levon Haroutunian, Zhuang Li, Lucian Galescu, Philip Cohen, Raj Tumuluri, Gholamreza Haffari</li>
<li>for: 本研究旨在提高大语言模型（LLM）生成的自然语言质量，特别是在自然语言生成从逻辑形式（LF）时的输出质量。</li>
<li>methods: 我们提出了一种生成并重新排序的方法，其包括首先通过提问LLM生成一组候选输出，然后使用任务特定的重新排序模型对其进行重新排序。此外，我们还收集了一个手动抽象的数据集，用于评估不同排名指标和人类判断的对应关系。</li>
<li>results: 我们在三个不同的数据集上进行了广泛的实验，并证明了我们的方法可以提高LLM生成的输出质量，特别是在 semantic consistency 和 fluency 两个维度上。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs). This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations. In this work, we tackle this issue by proposing a novel generate-and-rerank approach. Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model. In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements. The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model. By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics. Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Inspire-the-Large-Language-Model-by-External-Knowledge-on-BioMedical-Named-Entity-Recognition"><a href="#Inspire-the-Large-Language-Model-by-External-Knowledge-on-BioMedical-Named-Entity-Recognition" class="headerlink" title="Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition"></a>Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12278">http://arxiv.org/abs/2309.12278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Bian, Jiaxuan Zheng, Yuyi Zhang, Shanfeng Zhu</li>
<li>for: 这篇论文是为了解决生物医学命名实体识别（BioNER）任务而写的。</li>
<li>methods: 该论文使用链式思维的方法，将NER任务拆分成了实体识别和实体类型决定两个步骤。此外，为了解决LLM缺乏域知识的问题，我们在实体类型决定中注入了实体知识。</li>
<li>results: 实验结果表明，我们的两步 BioNER 方法与之前的几个shot LLMBasis 比较显著提高了表现。此外，含外部知识的 incorporation 也显著提高了实体类型决定性表现。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks. However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER). In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination. Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category. Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline. Additionally, the incorporation of external knowledge significantly enhances entity category determination performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-VTE-Identification-through-Adaptive-NLP-Model-Selection-and-Clinical-Expert-Rule-based-Classifier-from-Radiology-Reports"><a href="#Improving-VTE-Identification-through-Adaptive-NLP-Model-Selection-and-Clinical-Expert-Rule-based-Classifier-from-Radiology-Reports" class="headerlink" title="Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports"></a>Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12273">http://arxiv.org/abs/2309.12273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jamie Deng, Yusen Wu, Hilary Hayssen, Brain Englum, Aman Kankaria, Minerva Mayorga-Carlin, Shalini Sahoo, John Sorkin, Brajesh Lal, Yelena Yesha, Phuong Nguyen</li>
<li>for: 这研究旨在提高无结构（自由文本）医疗报告中的深部静脉血栓（DVT）和肺动脉血栓（PE）识别率，以便更好地治疗 cardiovascular disease。</li>
<li>methods: 这研究使用自然语言处理（NLP）方法，包括深度学习（DL）和NLP模型，以自动识别医疗报告中的VTE事件。</li>
<li>results: 实验结果显示，这模型可以实现97%的准确率和97%的F1分数在预测DVT，以及98.3%的准确率和98.4%的F1分数在预测PE。这些结果证明了这模型的稳定性和其在VTE研究中的潜在贡献。<details>
<summary>Abstract</summary>
Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment. Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports. However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance. This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports. Our experimental results demonstrate the model's efficacy, achieving an impressive 97\% accuracy and 97\% F1 score in predicting DVT, and an outstanding 98.3\% accuracy and 98.4\% F1 score in predicting PE. These findings emphasize the model's robustness and its potential to significantly contribute to VTE research.
</details>
<details>
<summary>摘要</summary>
快速和准确地识别深静脉 tromboembolismo (VTE)，包括深静脉 trombosis (DVT) 和肺动脉 trombosis (PE)，是诊断Cardiovascular disease 的关键。通过自然语言处理（NLP）技术，自动方法在从Retrospective data cohorts 中提取VTE事件已经显示出了可观的进步。然而，因为医疗数据的有限性， radiology report的复杂性和多样性，以及数据不均衡，训练深度学习（DL）和NLP模型是一项挑战。这项研究提出了一种 combining DL 方法，并与数据扩展、适应预训练 NLP 模型选择和临床专家 NLP 规则生成器，以提高无结构（free-text） radiology report中VTE识别的准确性。我们的实验结果表明，该模型在 DVT 预测中达到了97%的准确率和97%的 F1 分数，而在 PE 预测中达到了98.3%的准确率和98.4%的 F1 分数。这些结果证明了模型的稳定性，并且其潜在地对 VTE 研究做出了重要贡献。
</details></li>
</ul>
<hr>
<h2 id="The-Cambridge-Law-Corpus-A-Corpus-for-Legal-AI-Research"><a href="#The-Cambridge-Law-Corpus-A-Corpus-for-Legal-AI-Research" class="headerlink" title="The Cambridge Law Corpus: A Corpus for Legal AI Research"></a>The Cambridge Law Corpus: A Corpus for Legal AI Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12269">http://arxiv.org/abs/2309.12269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Östling, Holli Sargeant, Huiyuan Xie, Ludwig Bull, Alexander Terenin, Leif Jonsson, Måns Magnusson, Felix Steffek</li>
<li>for: 这个论文是为了推广法律人工智能研究而创建的剑桥法律词库（CLC）。</li>
<li>methods: 该词库包含了250,000余个法律案例，主要来自21世纪，但也包括16世纪以前的案例。论文还提供了638个案例的注释，由法律专家进行标注。</li>
<li>results: 通过使用GPT-3、GPT-4和RoBERTa模型进行训练和评估， authors提供了情况出来案例结果抽取的基准。<details>
<summary>Abstract</summary>
We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
</details>
<details>
<summary>摘要</summary>
我们介绍了剑桥法律词库（CLC），一个用于法律人工智能研究的词库。它包含了超过250,000个法律案例，大多数是21世纪的案例，但词库还包括了16世纪的案例。本文发布了词库的首个版本，包括原始文本和元数据。同时，我们提供了638个案例的法律专家标注，用于训练和评估案例结果提取模型。我们还进行了广泛的法律和伦理讨论，以Address the potentially sensitive nature of this material。因此，词库将仅为研究用途发布，受到一定的限制。
</details></li>
</ul>
<hr>
<h2 id="On-the-Relationship-between-Skill-Neurons-and-Robustness-in-Prompt-Tuning"><a href="#On-the-Relationship-between-Skill-Neurons-and-Robustness-in-Prompt-Tuning" class="headerlink" title="On the Relationship between Skill Neurons and Robustness in Prompt Tuning"></a>On the Relationship between Skill Neurons and Robustness in Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12263">http://arxiv.org/abs/2309.12263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Ackermann, Xenia Ohmer</li>
<li>for: 这个论文的目的是研究Prompt Tuning在PLMs中的稳定性，以及这种方法如何在不同任务上进行转移学习。</li>
<li>methods: 作者使用了RoBERTa和T5进行实验，并通过分析Prompt Tuning activates specific neurons in transformer的feed-forward networks，以及这些神经元在不同任务上的表现，来研究Prompt Tuning的稳定性。</li>
<li>results: 研究发现，Prompt Tuning在不同任务上的表现不够稳定，尤其是在对抗数据上。而T5比RoBERTa更高的对抗 robustness可能与模型在对抗数据上活动的相关神经元有关。同时，研究还发现了RoBERTa和T5中的技能神经元，并证明了这些神经元在不同任务上的表现。<details>
<summary>Abstract</summary>
Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these "skill neurons", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data.
</details>
<details>
<summary>摘要</summary>
Prompt Tuning 是一种广泛使用的减少参数的 finetuning 方法 для预训练大语言模型（PLM）。最近，通过 RoBERTa 的实验，提出了 Prompt Tuning 可以活化特定的 neuron 在 transformer 的Feedforward 网络中，这些 neuron 对给定任务是非常预测和选择性的。在这篇文章中，我们研究了 Prompt Tuning 的稳定性，与这些“技能 neuron”相关。我们使用 RoBERTa 和 T5 进行实验，并发现：Prompt Tuning 为特定任务适应性较高，但对 adversarial 数据不够稳定。同时，我们复现了 RoBERTa 中的技能 neuron，并发现 T5 中的技能 neuron 也存在。有趣的是，T5 中的技能 neuron 在非 adversarial 数据上确定的也是最预测性的 neuron 在 adversarial 数据上，而 RoBERTa 中的技能 neuron 不是。我们 conclude  что高度 adversarial 稳定性可能与模型的能力启动相关的技能 neuron 在 adversarial 数据上有关。
</details></li>
</ul>
<hr>
<h2 id="SQUARE-Automatic-Question-Answering-Evaluation-using-Multiple-Positive-and-Negative-References"><a href="#SQUARE-Automatic-Question-Answering-Evaluation-using-Multiple-Positive-and-Negative-References" class="headerlink" title="SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References"></a>SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12250">http://arxiv.org/abs/2309.12250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Gabburo, Siddhant Garg, Rik Koncel Kedziorski, Alessandro Moschitti</li>
<li>for: 评估问答系统的可靠性和效果是非常困难和昂贵的，现有的最可靠的方法是人工标注问答的正确性。</li>
<li>methods: 我们提出了一个新的评估指标：SQuArE（句子级问答回答评估），使用多个参考答案（组合多个正确和错误的参考答案）来评估句子级问答系统。</li>
<li>results: 我们在多个学术和工业数据集上评估了SQuArE，并发现它比前一些基线表现更好，并与人工标注之间有最高的相关性。<details>
<summary>Abstract</summary>
Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations.
</details>
<details>
<summary>摘要</summary>
评估问答系统非常具有挑战性和成本高，人工注解正确答案为问题的最可靠方法。最近的研究（AVA、BEM）表明，基于转换器LM推理器的相似度指标可以有效地评估问答系统，但它们受到单个正确参考答案的限制。我们提议一种新的评估指标：SQuArE（句子级问题答案评估），使用多个参考答案（包括多个正确和错误参考）进行句子级问题评估。我们对多个学术和工业数据集进行了评估，并发现SQuArE超过了之前的基线和人工注解之间的相关性。
</details></li>
</ul>
<hr>
<h2 id="Bridging-the-Gaps-of-Both-Modality-and-Language-Synchronous-Bilingual-CTC-for-Speech-Translation-and-Speech-Recognition"><a href="#Bridging-the-Gaps-of-Both-Modality-and-Language-Synchronous-Bilingual-CTC-for-Speech-Translation-and-Speech-Recognition" class="headerlink" title="Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition"></a>Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12234">http://arxiv.org/abs/2309.12234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Xu, Xiaoqian Liu, Erfeng He, Yuhao Zhang, Qianqian Dong, Tong Xiao, Jingbo Zhu, Dapeng Man, Wu Yang</li>
<li>for: 这项研究旨在提出同步双语Connectionist Temporal Classification（CTC）框架，用于bridging模式和语言之间的差异在语音翻译（ST）任务中。</li>
<li>methods: 我们使用了训练录音和翻译为同时目标的CTC，将audio和文本之间的差异桥接，以及源语言和目标语言之间的差异。我们基于 latest CTC应用的进步，开发了加强版BiL-CTC+，在资源受限的情况下在MuST-C STbenchmark上达到新的州OF-THE-ART表现。</li>
<li>results: 我们的方法不仅在ST任务中实现了新的州OF-THE-ART表现，还显著提高了语音识别性能， demonstarting cross-lingual learning的广泛应用和语音识别的相互关系。<details>
<summary>Abstract</summary>
In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提出了同步双语Connectionist Temporal Classification（CTC）框架，这是一种创新的框架，可以跨越语言和modalities在语音翻译（ST）任务中bridges the gaps。我们利用讲解和翻译作为同时目标，我们的模型可以将音频和文本相互关联，以及源语言和目标语言之间的关联。 builds upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. source code is available at https://github.com/xuchennlp/S2T.
</details></li>
</ul>
<hr>
<h2 id="Towards-Answering-Health-related-Questions-from-Medical-Videos-Datasets-and-Approaches"><a href="#Towards-Answering-Health-related-Questions-from-Medical-Videos-Datasets-and-Approaches" class="headerlink" title="Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches"></a>Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12224">http://arxiv.org/abs/2309.12224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Gupta, Kush Attal, Dina Demner-Fushman</li>
<li>for:  Answering health-related questions asked by the public through visual answers from medical videos.</li>
<li>methods:  Created two large-scale datasets (HealthVidQA-CRF and HealthVidQA-Prompt) and proposed monomodal and multimodal approaches to provide visual answers from medical videos to natural language questions.</li>
<li>results:  Datasets have the potential to enhance the performance of medical visual answer localization tasks, and pre-trained language-vision models may further improve performance.Here’s the Chinese translation:</li>
<li>for:  Answering 公众健康问题通过医疗视频的视觉答案。</li>
<li>methods:  开发了两个大规模数据集（HealthVidQA-CRF 和 HealthVidQA-Prompt），并提出了单模态和多模态方法，以寻找医疗视频中的自然语言问题的视觉答案。</li>
<li>results: 数据集可能提高医疗视answer定位任务的性能，并且可能通过预训练语言视觉模型进一步提高性能。<details>
<summary>Abstract</summary>
The increase in the availability of online videos has transformed the way we access information and knowledge. A growing number of individuals now prefer instructional videos as they offer a series of step-by-step procedures to accomplish particular tasks. The instructional videos from the medical domain may provide the best possible visual answers to first aid, medical emergency, and medical education questions. Toward this, this paper is focused on answering health-related questions asked by the public by providing visual answers from medical videos. The scarcity of large-scale datasets in the medical domain is a key challenge that hinders the development of applications that can help the public with their health-related questions. To address this issue, we first proposed a pipelined approach to create two large-scale datasets: HealthVidQA-CRF and HealthVidQA-Prompt. Later, we proposed monomodal and multimodal approaches that can effectively provide visual answers from medical videos to natural language questions. We conducted a comprehensive analysis of the results, focusing on the impact of the created datasets on model training and the significance of visual features in enhancing the performance of the monomodal and multi-modal approaches. Our findings suggest that these datasets have the potential to enhance the performance of medical visual answer localization tasks and provide a promising future direction to further enhance the performance by using pre-trained language-vision models.
</details>
<details>
<summary>摘要</summary>
随着在线视频的普及，我们获取信息和知识的方式发生了深刻的变革。更多的人现在偏好使用说明视频，因为它们提供了一系列步骤的操作来完成特定任务。医疗领域的 instruccional videos 可以提供最佳的视觉答案，用于医疗问题的第一 aid、紧急情况和医学教育。为此，本文将关注公众提出的健康问题，通过医疗视频提供视觉答案。医疗领域的数据匮乏是主要挑战，这阻碍了应用程序的发展，用于帮助公众解决其健康问题。为解决这个问题，我们首先提出了一种管道方法，用于创建两个大规模数据集：HealthVidQA-CRF 和 HealthVidQA-Prompt。后来，我们提出了单模态和多模态方法，可以有效地从医疗视频中提取视觉答案，并与自然语言问题进行对应。我们对结果进行了全面的分析，注重数据集的创建对模型训练的影响，以及视觉特征在单模态和多模态方法中的重要性。我们的发现表明，这些数据集有potentiality 提高医疗视 Answer Localization 任务的性能，并提供了未来可能性，通过使用预训练语言视觉模型，进一步提高性能。
</details></li>
</ul>
<hr>
<h2 id="Code-Soliloquies-for-Accurate-Calculations-in-Large-Language-Models"><a href="#Code-Soliloquies-for-Accurate-Calculations-in-Large-Language-Models" class="headerlink" title="Code Soliloquies for Accurate Calculations in Large Language Models"></a>Code Soliloquies for Accurate Calculations in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12161">http://arxiv.org/abs/2309.12161</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luffycodes/tutorbot-spock-phys">https://github.com/luffycodes/tutorbot-spock-phys</a></li>
<li>paper_authors: Shashank Sonkar, MyCo Le, Xinghe Chen, Naiming Liu, Debshila Basu Mallick, Richard G. Baraniuk</li>
<li>for: 这paper是为了提高大型语言模型（LLM）后端的开发而写的，具体来说是为了提高学生和ITS之间的互动质量。</li>
<li>methods: 这paper使用了先进的GPT-4模型来生成合成学生教师对话，以便用于精度地准确地训练LLM后端。</li>
<li>results: 这paper的结果表明，使用我们的新的状态full prompt设计可以增强合成对话集的质量，特别是在需要计算的科学概念上。我们的Higgs模型（一个LLaMAfinetune的模型）能够有效地使用Python进行计算，并且通过使用我们生成的代码演讲来提高它的答案的准确性和计算可靠性。<details>
<summary>Abstract</summary>
High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations. If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations. Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses.
</details>
<details>
<summary>摘要</summary>
高品质的对话Dataset是智能教学系统（ITS）的成功开发所需的一个重要组成部分。这些Dataset，当用于调整LLM后端，将会对学生和ITS之间的互动提高质量。一种常见的发展策略是使用进步的GPT-4模型生成 sintetic的学生-教师对话。但是，当这些对话需要复杂的计算时，GPT-4的表现会变差，这是一个重要的限制，它对于这些主题的 utility 有限。为了解决这些挑战，这篇文章提出了一个创新的状态执行Prompt设计。我们的方法生成了一个模拟学生和教师的对话，这两个角色都是由GPT-4 simulate。每个学生回应都会触发GPT-tutorbot的内言（soliloquy），判断其回应是否需要计算。如果是，它会进行Python脚本的scripting，然后使用结果来建立对学生的回应。我们的方法对于计算数量充满的主题特别有助，我们的发现显示，我们的Higgs模型（LLaMA finetuned with我们的新状态执行Prompt设计）能够有效地使用Python进行计算。因此，在我们的Dataset中添加了code soliloquies后，调整Higgs的精度和计算可靠性都会提高。
</details></li>
</ul>
<hr>
<h2 id="How-to-Guides-for-Specific-Audiences-A-Corpus-and-Initial-Findings"><a href="#How-to-Guides-for-Specific-Audiences-A-Corpus-and-Initial-Findings" class="headerlink" title="How-to Guides for Specific Audiences: A Corpus and Initial Findings"></a>How-to Guides for Specific Audiences: A Corpus and Initial Findings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12117">http://arxiv.org/abs/2309.12117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicola Fanton, Agnieszka Falenska, Michael Roth</li>
<li>for: 这篇论文探讨了wikiHow上的指南文章是如何针对不同目标群体而变化的。</li>
<li>methods: 研究者采用了资深分析和计算方法来检测wikiHow上的指南文章是否受到社会偏见和潜伏偏见的影响。</li>
<li>results: 研究结果表明，wikiHow上的指南文章受到了潜伏偏见，且这些偏见随着目标群体的不同而发生变化。<details>
<summary>Abstract</summary>
Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals. However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes. In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience. We conduct two case studies in which we examine qualitative features of texts written for specific audiences. In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods. The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases. We aim to raise awareness of these inequalities as a first step to addressing them in future work.
</details>
<details>
<summary>摘要</summary>
instrucitonal 文本应该考虑目标群体的先前知识和需求，以有效地引导他们达到他们的目标。然而，targeting 特定群体也可能表达不同的社会规范和潜在偏见。在这篇论文中，我们调查了wikiHow的how-to 指南是否因target audience而有所不同。我们进行了两项案例研究，以及一项通用研究，以系统地表明这些差异。我们的研究结果表明，wikiHow的指南，如其他文本类型，受到潜在偏见的影响。我们希望通过这篇论文来启发人们对这些不平等的意识，以便在未来的工作中解决它们。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Computational-Analysis-of-Vagueness-in-Revisions-of-Instructional-Texts"><a href="#A-Computational-Analysis-of-Vagueness-in-Revisions-of-Instructional-Texts" class="headerlink" title="A Computational Analysis of Vagueness in Revisions of Instructional Texts"></a>A Computational Analysis of Vagueness in Revisions of Instructional Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12107">http://arxiv.org/abs/2309.12107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alok Debnath, Michael Roth</li>
<li>for: 本研究旨在分析 revision history 中带有uncertainty的 instruction 的修改。</li>
<li>methods: 研究采用 neural network 模型，对两个版本的 instruction 进行对比，并采用 previous work 中的 pairwise ranking 任务来评价模型的能力。</li>
<li>results: 研究显示，使用 neural network 模型可以准确地分辨两个版本的 instruction，并且与existig baselines 相比，显示出提高的性能。<details>
<summary>Abstract</summary>
WikiHow is an open-domain repository of instructional articles for a variety of tasks, which can be revised by users. In this paper, we extract pairwise versions of an instruction before and after a revision was made. Starting from a noisy dataset of revision histories, we specifically extract and analyze edits that involve cases of vagueness in instructions. We further investigate the ability of a neural model to distinguish between two versions of an instruction in our data by adopting a pairwise ranking task from previous work and showing improvements over existing baselines.
</details>
<details>
<summary>摘要</summary>
WikiHow 是一个开放领域的指南文章存储库，可以由用户修改。在这篇论文中，我们从含有噪声的修订历史数据中提取了对 instrucion 进行了修改的对。我们specifically 提取和分析修订中包含抽象指令的修订。进一步，我们采用了一种对两个 instrucion 版本进行对比的 neural 模型，并证明我们的模型可以在我们的数据集中提高对比性。Note: " instrucion" is a typo in the original text, and I have corrected it to "instruction" in the translation.
</details></li>
</ul>
<hr>
<h2 id="SemEval-2022-Task-7-Identifying-Plausible-Clarifications-of-Implicit-and-Underspecified-Phrases-in-Instructional-Texts"><a href="#SemEval-2022-Task-7-Identifying-Plausible-Clarifications-of-Implicit-and-Underspecified-Phrases-in-Instructional-Texts" class="headerlink" title="SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts"></a>SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12102">http://arxiv.org/abs/2309.12102</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/acidann/claire">https://github.com/acidann/claire</a></li>
<li>paper_authors: Michael Roth, Talita Anthonio, Anna Sauer</li>
<li>for: 这项研究的目的是评估帮助文章的解释是否有效。</li>
<li>methods: 这项研究使用了人工生成的解释和人类的可能性评估来训练参与系统。</li>
<li>results: 参与系统的最佳系统达到了68.9%的准确率，而8个团队的系统描述也被报告。此外，我们还发现了使用最佳参与系统的预测可以在多个可能的解释上达到75.2%的准确率。<details>
<summary>Abstract</summary>
We describe SemEval-2022 Task 7, a shared task on rating the plausibility of clarifications in instructional texts. The dataset for this task consists of manually clarified how-to guides for which we generated alternative clarifications and collected human plausibility judgements. The task of participating systems was to automatically determine the plausibility of a clarification in the respective context. In total, 21 participants took part in this task, with the best system achieving an accuracy of 68.9%. This report summarizes the results and findings from 8 teams and their system descriptions. Finally, we show in an additional evaluation that predictions by the top participating team make it possible to identify contexts with multiple plausible clarifications with an accuracy of 75.2%.
</details>
<details>
<summary>摘要</summary>
我们描述SemEval-2022任务7，这是一个评估 instrucitonal 文本中的解释可能性的共同任务。该任务的数据集包括 manually clarified 的使用指南，我们生成了备用的解释，并收集了人类的可能性评估。参与系统的任务是自动确定解释的可能性在特定上下文中。总共有21个参与者，最佳系统的准确率达到68.9%。这份报告Summarizes 8个团队和他们的系统描述，并在附加评估中表明了最佳参与者的预测可以在多个可能的解释上准确地识别 context 的准确率达到75.2%。
</details></li>
</ul>
<hr>
<h2 id="AceGPT-Localizing-Large-Language-Models-in-Arabic"><a href="#AceGPT-Localizing-Large-Language-Models-in-Arabic" class="headerlink" title="AceGPT, Localizing Large Language Models in Arabic"></a>AceGPT, Localizing Large Language Models in Arabic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12053">http://arxiv.org/abs/2309.12053</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/freedomintelligence/acegpt">https://github.com/freedomintelligence/acegpt</a></li>
<li>paper_authors: Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Ziche Liu, Zhiyi Zhang, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu</li>
<li>for: 本研究旨在开发一个适应阿拉伯语言特点的本地大型自然语言处理模型（LLM），以满足阿拉伯语言speaking community的多样化应用需求。</li>
<li>methods: 该研究提出了一个包装解决方案，包括额外预训练阿拉伯文本，监督精度调整（SFT）使用本地阿拉伯语言指令和GPT-4响应，以及强化学习使用人工智能反馈（RLAIF）的奖励模型，以训练具有当地文化和价值观念的阿拉伯语言LLM。</li>
<li>results: 对于多种测试 benchmark，包括阿拉伯语言 Vicuna-80 和 AlpacaEval 的 instrucion-following benchmark、阿拉伯语言 MMLU 和 EXAMs 的知识 benchmark，以及新提出的阿拉伯文化和价值Alignment benchmark，AceGPT 得到了最高的 SOTA 开放阿拉伯语言 LLM 成绩。尤其是在使用 GPT-4 时，AceGPT 在 Vicuna-80  benchmark 中高于 ChatGPT，尽管这个benchmark的规模相对较小。<details>
<summary>Abstract</summary>
This paper explores the imperative need and methodology for developing a localized Large Language Model (LLM) tailored for Arabic, a language with unique cultural characteristics that are not adequately addressed by current mainstream models like ChatGPT. Key concerns additionally arise when considering cultural sensitivity and local values. To this end, the paper outlines a packaged solution, including further pre-training with Arabic texts, supervised fine-tuning (SFT) using native Arabic instructions and GPT-4 responses in Arabic, and reinforcement learning with AI feedback (RLAIF) using a reward model that is sensitive to local culture and values. The objective is to train culturally aware and value-aligned Arabic LLMs that can serve the diverse application-specific needs of Arabic-speaking communities.   Extensive evaluations demonstrated that the resulting LLM called `\textbf{AceGPT}' is the SOTA open Arabic LLM in various benchmarks, including instruction-following benchmark (i.e., Arabic Vicuna-80 and Arabic AlpacaEval), knowledge benchmark (i.e., Arabic MMLU and EXAMs), as well as the newly-proposed Arabic cultural \& value alignment benchmark. Notably, AceGPT outperforms ChatGPT in the popular Vicuna-80 benchmark when evaluated with GPT-4, despite the benchmark's limited scale. % Natural Language Understanding (NLU) benchmark (i.e., ALUE)   Codes, data, and models are in https://github.com/FreedomIntelligence/AceGPT.
</details>
<details>
<summary>摘要</summary>
这篇论文探讨了需要开发本地化的大语言模型（LLM），以满足阿拉伯语言的独特文化特征，现有主流模型如ChatGPT无法充分考虑。文章还提出了一个套件解决方案，包括额外预训练阿拉伯文本，监督细化（SFT）使用本地阿拉伯指令和GPT-4回答，以及强化学习使用人工智能反馈（RLAIF）的奖励模型，以训练具有本地文化和价值观的阿拉伯语言模型。这些模型可以满足阿拉伯语言社区的多样化应用需求。经过评估， authors 提出了名为 `\textbf{AceGPT}` 的模型，它在不同的测试上达到了最高的表现，包括 instruc-following 测试（i.e., Arabic Vicuna-80和Arabic AlpacaEval）、知识测试（i.e., Arabic MMLU和EXAMs）以及 newly-proposed 阿拉伯文化和价值观念测试。特别是，AceGPT 在 Vicuna-80 测试中，使用 GPT-4 时与 ChatGPT 进行比较，即使测试的规模较小。codes、数据和模型可以在 GitHub 上找到：<https://github.com/FreedomIntelligence/AceGPT>。
</details></li>
</ul>
<hr>
<h2 id="CAMERA-A-Multimodal-Dataset-and-Benchmark-for-Ad-Text-Generation"><a href="#CAMERA-A-Multimodal-Dataset-and-Benchmark-for-Ad-Text-Generation" class="headerlink" title="CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation"></a>CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12030">http://arxiv.org/abs/2309.12030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Mita, Soichiro Murakami, Akihiko Kato, Peinan Zhang</li>
<li>for: 本研究旨在提高自动广告文本生成（ATG）领域的研究，并为其引入了一个重新定义的任务和一个标准评价 bencmark。</li>
<li>methods: 本研究使用了多种方法，包括使用不同类型的预训练语言模型和利用多Modal信息。</li>
<li>results: 研究者通过多个基线模型的评价实验，发现CA Multimodal Evaluation for Ad Text GeneRAtion（CAMERA）数据集能够充分利用多Modal信息，并且可以进行产业综合评价。<details>
<summary>Abstract</summary>
In response to the limitations of manual online ad production, significant research has been conducted in the field of automatic ad text generation (ATG). However, comparing different methods has been challenging because of the lack of benchmarks encompassing the entire field and the absence of well-defined problem sets with clear model inputs and outputs. To address these challenges, this paper aims to advance the field of ATG by introducing a redesigned task and constructing a benchmark. Specifically, we defined ATG as a cross-application task encompassing various aspects of the Internet advertising. As part of our contribution, we propose a first benchmark dataset, CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA), carefully designed for ATG to be able to leverage multi-modal information and conduct an industry-wise evaluation. Furthermore, we demonstrate the usefulness of our proposed benchmark through evaluation experiments using multiple baseline models, which vary in terms of the type of pre-trained language model used and the incorporation of multi-modal information. We also discuss the current state of the task and the future challenges.
</details>
<details>
<summary>摘要</summary>
Traditional online advertising production has limitations, so researchers have been studying automatic ad text generation (ATG) to address these limitations. However, comparing different ATG methods has been difficult due to a lack of benchmarks that cover the entire field and well-defined problem sets with clear inputs and outputs. To solve these problems, this paper aims to advance the field of ATG by introducing a new task and creating a benchmark. Specifically, we define ATG as a cross-application task that includes various aspects of internet advertising. As part of our contribution, we propose a benchmark dataset called CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA), which is carefully designed for ATG and can leverage multi-modal information to conduct an industry-wide evaluation. We also demonstrate the usefulness of our proposed benchmark through evaluation experiments using multiple baseline models, which differ in the type of pre-trained language model used and the incorporation of multi-modal information. Finally, we discuss the current state of the task and future challenges.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Stock-Market-Sentiment-Classification-and-Backtesting-via-Fine-tuned-BERT"><a href="#Stock-Market-Sentiment-Classification-and-Backtesting-via-Fine-tuned-BERT" class="headerlink" title="Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT"></a>Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11979">http://arxiv.org/abs/2309.11979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiashu Lou</li>
<li>for: 本研究的目的是将情感因素纳入量化交易中，以提高交易效率和回换率。</li>
<li>methods: 本研究使用BERT自然语言处理模型进行训练，并将用户评论标题数据网络爬虫，进行数据清洁和处理。</li>
<li>results: 实验结果显示，将情感因素纳入量化交易中，可以提高交易效率和回换率，比基准模型和原始Alpha191模型有73.8%和32.41%的提升。<details>
<summary>Abstract</summary>
With the rapid development of big data and computing devices, low-latency automatic trading platforms based on real-time information acquisition have become the main components of the stock trading market, so the topic of quantitative trading has received widespread attention. And for non-strongly efficient trading markets, human emotions and expectations always dominate market trends and trading decisions. Therefore, this paper starts from the theory of emotion, taking East Money as an example, crawling user comment titles data from its corresponding stock bar and performing data cleaning. Subsequently, a natural language processing model BERT was constructed, and the BERT model was fine-tuned using existing annotated data sets. The experimental results show that the fine-tuned model has different degrees of performance improvement compared to the original model and the baseline model. Subsequently, based on the above model, the user comment data crawled is labeled with emotional polarity, and the obtained label information is combined with the Alpha191 model to participate in regression, and significant regression results are obtained. Subsequently, the regression model is used to predict the average price change for the next five days, and use it as a signal to guide automatic trading. The experimental results show that the incorporation of emotional factors increased the return rate by 73.8\% compared to the baseline during the trading period, and by 32.41\% compared to the original alpha191 model. Finally, we discuss the advantages and disadvantages of incorporating emotional factors into quantitative trading, and give possible directions for further research in the future.
</details>
<details>
<summary>摘要</summary>
随着大数据和计算设备的快速发展，低延迟自动交易平台基于实时信息获取已成为股票交易市场的主要组成部分，因此量化交易的话题受到了广泛关注。而在不强效交易市场中，人类情感和期望总是控制市场趋势和交易决策。因此，本文从情感理论出发，以东方财富为例，从其相应股票板幕中提取用户评论标题数据，并进行数据清洁。然后，构建了自然语言处理模型BERT，并将BERT模型细化使用现有注解数据集。实验结果显示，细化模型在原始模型和基准模型的比较中具有不同程度的性能改进。接着，基于上述模型，提取的用户评论数据被标注为情感方向，并将获得的标签信息与Alpha191模型结合进行回归，并获得了显著的回归结果。然后，使用回归模型预测下一五天的均价变化，并使其作为自动交易的信号导航。实验结果显示，包含情感因素的integration提高了基准期望的回报率73.8%，相比基准期望模型。最后，我们讨论了在量化交易中包含情感因素的优势和缺点，并提出了未来可能的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Scaling-up-COMETKIWI-Unbabel-IST-2023-Submission-for-the-Quality-Estimation-Shared-Task"><a href="#Scaling-up-COMETKIWI-Unbabel-IST-2023-Submission-for-the-Quality-Estimation-Shared-Task" class="headerlink" title="Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task"></a>Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11925">http://arxiv.org/abs/2309.11925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Rei, Nuno M. Guerreiro, José Pombal, Daan van Stigt, Marcos Treviso, Luisa Coheur, José G. C. de Souza, André F. T. Martins</li>
<li>for: 这个论文是为了参加WMT 2023共同任务中的质量估计（QE）任务而写的。</li>
<li>methods: 这个论文使用了COMETKIWI-22模型（Rei et al., 2022b），并在所有任务上进行了多语言方法的探索。</li>
<li>results: 这个论文的 multilingual 方法在所有任务上达到了状态的性能，并与人类评估相关度（Spearman 相关度）之间显示了大幅提升（最多10个Spearman点），同时也超过了第二名的多语言提交。<details>
<summary>Abstract</summary>
We present the joint contribution of Unbabel and Instituto Superior T\'ecnico to the WMT 2023 Shared Task on Quality Estimation (QE). Our team participated on all tasks: sentence- and word-level quality prediction (task 1) and fine-grained error span detection (task 2). For all tasks, we build on the COMETKIWI-22 model (Rei et al., 2022b). Our multilingual approaches are ranked first for all tasks, reaching state-of-the-art performance for quality estimation at word-, span- and sentence-level granularity. Compared to the previous state-of-the-art COMETKIWI-22, we show large improvements in correlation with human judgements (up to 10 Spearman points). Moreover, we surpass the second-best multilingual submission to the shared-task with up to 3.8 absolute points.
</details>
<details>
<summary>摘要</summary>
我们现在报告我们和 Instituto Superior Técnico 在 WMT 2023 共同任务中的合作贡献，我们参加了所有任务：句子和单词水平质量预测（任务 1）以及细致错误探测（任务 2）。对于所有任务，我们基于 COMETKIWI-22 模型（Rei et al., 2022b）。我们的多语言方法在所有任务上排名第一，达到了质量预测的州际先进性，包括单词、句子和span级别的准确性。相比之前的州际先进 COMETKIWI-22，我们显示出了大幅提升与人类评估的相关度（最高达 10 点）。此外，我们超过了共同任务中的第二名多语言提交，差异达到 3.8 个绝对点。
</details></li>
</ul>
<hr>
<h2 id="InstructERC-Reforming-Emotion-Recognition-in-Conversation-with-a-Retrieval-Multi-task-LLMs-Framework"><a href="#InstructERC-Reforming-Emotion-Recognition-in-Conversation-with-a-Retrieval-Multi-task-LLMs-Framework" class="headerlink" title="InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework"></a>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11911">http://arxiv.org/abs/2309.11911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LIN-SHANG/InstructERC">https://github.com/LIN-SHANG/InstructERC</a></li>
<li>paper_authors: Shanglin Lei, Guanting Dong, Xiaoping Wang, Keheng Wang, Sirui Wang</li>
<li>for: 提高对话中情感识别（ERC）的发展，解决了过度适应特定数据集和对话模式的问题。</li>
<li>methods: 提出了一种新的approach，即InstructERC，将ERC任务从推断性框架转换到生成性框架，基于大语言模型（LLM）。</li>
<li>results: InstructERC在三个常用的ERC数据集上 achieve 独特的SOTA，并通过 parameter-efficient 和 data-scaling 实验提供了实践场景中的参考指南。<details>
<summary>Abstract</summary>
The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely   InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based plug-and-play plugin framework significantly outperforms all previous models and achieves comprehensive SOTA on three commonly used ERC datasets. Extensive analysis of parameter-efficient and data-scaling experiments provide empirical guidance for applying InstructERC in practical scenarios. Our code will be released after blind review.
</details>
<details>
<summary>摘要</summary>
developoment of emotion recognition in dialogue (ERC) 被复杂的管道设计所阻碍，导致 ERC 模型经常过拟合特定的数据集和对话模式。在本研究中，我们提出了一种新的方法，即 InstructERC，它将 ERC 任务从描述性框架转换为生成框架，基于大型语言模型（LLM）。InstructERC 具有两个重要贡献：首先，InstructERC 引入了一种简单 yet 有效的检索模板模块，该模块通过 concatenate 历史对话内容、标签声明和情感领域示例来显式地整合多级别对话监督信息。其次，我们引入了两个附加的情感对应任务，即说话人标识和情感预测任务，以impllicitly 模型对话角色关系和未来情感趋势在对话中。我们的 LLM 基于插件框架在三个常用的 ERC 数据集上达到了广泛的 SOTA 水平。我们进行了参数高效和数据扩展的实验，以提供实践场景中应用 InstructERC 的实际指南。我们的代码将在审稿后发布。
</details></li>
</ul>
<hr>
<h2 id="Focal-Inferential-Infusion-Coupled-with-Tractable-Density-Discrimination-for-Implicit-Hate-Speech-Detection"><a href="#Focal-Inferential-Infusion-Coupled-with-Tractable-Density-Discrimination-for-Implicit-Hate-Speech-Detection" class="headerlink" title="Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection"></a>Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11896">http://arxiv.org/abs/2309.11896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lcs2-iiitd/fiadd">https://github.com/lcs2-iiitd/fiadd</a></li>
<li>paper_authors: Sarah Masud, Ashutosh Bajpai, Tanmoy Chakraborty</li>
<li>for: 本研究旨在提高预训练大语言模型（PLM）对含有潜在仇恨语言表达的文本识别的能力，特别是对于含有潜在仇恨语言表达的含义不明确的文本。</li>
<li>methods: 本研究提出了一种新的Focus Inferential Adaptive Density Discrimination（FiADD）框架，将PLMfinetuning管道中的表达更加接近含义的形式，同时提高不同类别之间的间距。</li>
<li>results: 对于三个隐式仇恨语料集，FiADD可以在二元和三元 hate classification任务中获得显著改进，并在掌握含义不明确的三个其他任务中也获得了类似的改进。<details>
<summary>Abstract</summary>
Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in which surface and implied forms differ, and observe similar performance improvement. We analyze the generated latent space to understand its evolution under FiADD, which corroborates the advantage of employing FiADD for implicit hate speech detection.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管预训练的大型自然语言模型（PLM）已经达到了许多NLP任务的状态流行，但它们缺乏对媚扰性表达的理解。这种细微和潜在的媚扰通常会被误分类为非媚扰。各种尝试都在扩展外部上下文或者通过距离基于的度量来增强恶意内容的检测。我们将这两种方法结合并引入FiADD，一种新的集中推理适应性权威度分区框架。FiADD通过将表面形式的潜在媚扰语言更近于其暗示形式，同时提高不同类别间的间距，以提高PLM的训练pipeline。我们在三个潜在媚扰数据集上测试FiADD，并观察到了两个和三个 hate类别分类任务中的显著改进。我们进一步在三个其他任务上进行了测试，即检测嘲笑、讽刺和立场，这些任务中表面和暗示形式不同，并观察到了类似的改进。我们分析生成的潜在空间，以理解FiADD在媚扰语言检测中的优势。
</details></li>
</ul>
<hr>
<h2 id="Is-It-Really-Useful-to-Jointly-Parse-Constituency-and-Dependency-Trees-A-Revisit"><a href="#Is-It-Really-Useful-to-Jointly-Parse-Constituency-and-Dependency-Trees-A-Revisit" class="headerlink" title="Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit"></a>Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11888">http://arxiv.org/abs/2309.11888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanggang Gu, Yang Hou, Zhefeng Wang, Xinyu Duan, Zhenghua Li</li>
<li>for: 这paper是为了同时解析成分树和依赖树而写的，以便更好地表示句子的语法结构。</li>
<li>methods: 这paper使用了一种更高效的解码算法，以及在训练阶段进行共同模型化，以及提出了高阶分数组件来捕捉成分-依赖关系。</li>
<li>results:  compared to previous works, this paper makes progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, (3) proposing high-order scoring components for constituent-dependency interaction, and (4) gaining more insights via in-depth experiments and analysis.<details>
<summary>Abstract</summary>
This work visits the topic of jointly parsing constituency and dependency trees, i.e., to produce compatible constituency and dependency trees simultaneously for input sentences, which is attractive considering that the two types of trees are complementary in representing syntax. Compared with previous works, we make progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, instead of only at the inference phase, (3) proposing high-order scoring components for constituent-dependency interaction, (4) gaining more insights via in-depth experiments and analysis.
</details>
<details>
<summary>摘要</summary>
这个工作探讨了同时解析成分树和依赖树的问题，即为输入句子生成兼容的成分树和依赖树，这是很吸引人的，因为这两种树是 syntax 表示的补充。与前一些工作相比，我们在四个方面做出了进步：1. 采用了非常高效的解码算法，2. 在训练阶段进行同时模型化，而不是只在推断阶段，3. 提出了高阶分数组件来描述成分-依赖关系，4. 通过深入实验和分析获得了更多的发现。
</details></li>
</ul>
<hr>
<h2 id="Syntactic-Variation-Across-the-Grammar-Modelling-a-Complex-Adaptive-System"><a href="#Syntactic-Variation-Across-the-Grammar-Modelling-a-Complex-Adaptive-System" class="headerlink" title="Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System"></a>Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11869">http://arxiv.org/abs/2309.11869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Dunn</li>
<li>for: 这个论文的目的是研究语言是一个复杂的自适应系统，并评估现有的语言研究方法是否能够准确地捕捉语言的复杂性。</li>
<li>methods: 这篇论文使用了系统地模型了英语口语的地方方言变化，并使用了整个语法和各个语法节点的隔离来描述这些变化。</li>
<li>results: 研究结果表明，语法中的各个节点之间存在许多交互，这些交互对于语言变化的理解具有重要意义。此外，研究还发现，在不同的语法节点被考察时，不同的地方方言之间的相似性会有所不同。<details>
<summary>Abstract</summary>
While language is a complex adaptive system, most work on syntactic variation observes a few individual constructions in isolation from the rest of the grammar. This means that the grammar, a network which connects thousands of structures at different levels of abstraction, is reduced to a few disconnected variables. This paper quantifies the impact of such reductions by systematically modelling dialectal variation across 49 local populations of English speakers in 16 countries. We perform dialect classification with both an entire grammar as well as with isolated nodes within the grammar in order to characterize the syntactic differences between these dialects. The results show, first, that many individual nodes within the grammar are subject to variation but, in isolation, none perform as well as the grammar as a whole. This indicates that an important part of syntactic variation consists of interactions between different parts of the grammar. Second, the results show that the similarity between dialects depends heavily on the sub-set of the grammar being observed: for example, New Zealand English could be more similar to Australian English in phrasal verbs but at the same time more similar to UK English in dative phrases.
</details>
<details>
<summary>摘要</summary>
语言是一个复杂的适应系统，大多数语法变化研究通常只关注几个个体构造，即使这些构造在语法 grammar 中处于不同层次的抽象水平之间。这意味着语法，一个连接千个结构的网络，被减少为几个分离的变量。这篇论文使用系统地模型了英语Speakers的地方方言变化，以Characterize这些方言之间的语法差异。我们使用整个语法和语法中各个节点进行地域分类，以Quantify这些变化的影响。结果显示，首先，语法中的多个节点都受到了变化，但是孤立地没有任何节点能够与整个语法一起表现得更好。这表明，语法变化中的一部分是不同部分之间的交互。其次，结果显示，不同地区的方言之间的相似性取决于观察到的语法子集：例如，新西兰英语可能与澳大利亚英语在短语动词方面更相似，而与英国英语在指示语raspects更相似。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Sanitization-of-Large-Language-Models"><a href="#Knowledge-Sanitization-of-Large-Language-Models" class="headerlink" title="Knowledge Sanitization of Large Language Models"></a>Knowledge Sanitization of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11852">http://arxiv.org/abs/2309.11852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yoichi Ishibashi, Hidetoshi Shimodaira</li>
<li>for: 防止语言模型泄露敏感信息</li>
<li>methods: 细化模型，让其生成无害回答</li>
<li>results: successfully mitigated knowledge leakage and preserved overall performance of LLM<details>
<summary>Abstract</summary>
We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique fine-tunes these models, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLM. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations.
</details>
<details>
<summary>摘要</summary>
我们研究了一种知识净化方法，以减轻大语言模型（LLM）中存在的隐私问题。这些模型通过大量网络数据训练，可能会记忆和泄露敏感或 конфиденциаль信息，这会引起严重的安全问题。我们的技术是通过精细地调整这些模型，使其在特定信息 queries 时返回无害的回答，如“我不知道”。我们的实验结果表明，我们的简单方法不仅可以减少特定知识泄露，还可以保持 LL 的总性能。这两点优点共同强化了对抽取攻击的防御，并减少了负面内容的泄露，如幻想。
</details></li>
</ul>
<hr>
<h2 id="A-Discourse-level-Multi-scale-Prosodic-Model-for-Fine-grained-Emotion-Analysis"><a href="#A-Discourse-level-Multi-scale-Prosodic-Model-for-Fine-grained-Emotion-Analysis" class="headerlink" title="A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis"></a>A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11849">http://arxiv.org/abs/2309.11849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xianhao Wei, Jia Jia, Xiang Li, Zhiyong Wu, Ziyi Wang</li>
<li>for: 这个研究旨在预测基于文本层次的细致情感特征，以提高语音合成模型的表达性。</li>
<li>methods: 我们使用一种style transfer模型提取phoneme-level Local Prosody Embedding序列和全局风格嵌入，并提出一种多层次文本Prosodic模型（D-MPM）来利用这些特征。</li>
<li>results: 我们的模型可以更好地预测情感特征，并且在用户评价指标上表现更好 than style transfer模型。<details>
<summary>Abstract</summary>
This paper explores predicting suitable prosodic features for fine-grained emotion analysis from the discourse-level text. To obtain fine-grained emotional prosodic features as predictive values for our model, we extract a phoneme-level Local Prosody Embedding sequence (LPEs) and a Global Style Embedding as prosodic speech features from the speech with the help of a style transfer model. We propose a Discourse-level Multi-scale text Prosodic Model (D-MPM) that exploits multi-scale text to predict these two prosodic features. The proposed model can be used to analyze better emotional prosodic features and thus guide the speech synthesis model to synthesize more expressive speech. To quantitatively evaluate the proposed model, we contribute a new and large-scale Discourse-level Chinese Audiobook (DCA) dataset with more than 13,000 utterances annotated sequences to evaluate the proposed model. Experimental results on the DCA dataset show that the multi-scale text information effectively helps to predict prosodic features, and the discourse-level text improves both the overall coherence and the user experience. More interestingly, although we aim at the synthesis effect of the style transfer model, the synthesized speech by the proposed text prosodic analysis model is even better than the style transfer from the original speech in some user evaluation indicators.
</details>
<details>
<summary>摘要</summary>
To evaluate the proposed model, the authors contribute a new large-scale Discourse-level Chinese Audiobook (DCA) dataset with over 13,000 annotated utterances. Experimental results show that the multi-scale text information effectively predicts prosodic features, and the discourse-level text improves coherence and user experience. Surprisingly, the synthesized speech by the proposed text prosodic analysis model is even better than the style transfer from the original speech in some user evaluation indicators.
</details></li>
</ul>
<hr>
<h2 id="A-Chinese-Prompt-Attack-Dataset-for-LLMs-with-Evil-Content"><a href="#A-Chinese-Prompt-Attack-Dataset-for-LLMs-with-Evil-Content" class="headerlink" title="A Chinese Prompt Attack Dataset for LLMs with Evil Content"></a>A Chinese Prompt Attack Dataset for LLMs with Evil Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11830">http://arxiv.org/abs/2309.11830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengyuan Liu, Fubang Zhao, Lizhi Qing, Yangyang Kang, Changlong Sun, Kun Kuang, Fei Wu</li>
<li>for: 这篇论文主要针对大语言模型（LLMs）的危险攻击和防御问题。</li>
<li>methods: 论文使用了多种黑盒攻击方法，如提示攻击，以测试LLMs的安全性。</li>
<li>results: 试验结果显示，论文引入的中文提示集（CPAD）对 LLMs 有70%的攻击成功率，表明这些提示有效地攻击了 LLMs。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and analysed. We run several well-known Chinese LLMs on our dataset, and the results show that our prompts are significantly harmful to LLMs, with around 70% attack success rate. We will release CPAD to encourage further studies on prompt attack and defense.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在文本理解和生成方面具有重要优势。然而，LLM受到生成危险内容的风险，特别是在应用程序中使用时。现有许多黑盒子攻击方法，如提示攻击，可以改变LLM的行为，让LLM生成意外的答案，包含危险内容。研究人员对提示攻击和LLM防御具有浓厚的兴趣，但是没有公共可用的数据集来评估防御能力。在这篇论文中，我们介绍了一个中文提示攻击数据集（CPAD），用于测试LLM的防御能力。我们的提示包括了三个维度：内容、攻击方法和目标，因此可以轻松地评估和分析回快。我们运行了一些知名的中文LLM在我们的数据集上，结果显示，我们的提示对LLM具有70%攻击成功率。我们将CPAD发布，以便更多的研究人员可以进行提示攻击和防御的研究。
</details></li>
</ul>
<hr>
<h2 id="Word-Embedding-with-Neural-Probabilistic-Prior"><a href="#Word-Embedding-with-Neural-Probabilistic-Prior" class="headerlink" title="Word Embedding with Neural Probabilistic Prior"></a>Word Embedding with Neural Probabilistic Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11824">http://arxiv.org/abs/2309.11824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaogang Ren, Dingcheng Li, Ping Li</li>
<li>for: 提高单词表示学习的词 embedding 模型</li>
<li>methods: 提出了一种可以与单词 embedding 模型集成的 probabilistic prior，使得词 embedding 可以作为概率生成模型来进行规范化。</li>
<li>results: 对多种任务进行了广泛的实验，并显示了提高单词表示的效果。<details>
<summary>Abstract</summary>
To improve word representation learning, we propose a probabilistic prior which can be seamlessly integrated with word embedding models. Different from previous methods, word embedding is taken as a probabilistic generative model, and it enables us to impose a prior regularizing word representation learning. The proposed prior not only enhances the representation of embedding vectors but also improves the model's robustness and stability. The structure of the proposed prior is simple and effective, and it can be easily implemented and flexibly plugged in most existing word embedding models. Extensive experiments show the proposed method improves word representation on various tasks.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "word representation" is translated as "字符表示" (zhì chào biǎo yì)* "probabilistic prior" is translated as "概率先验" (guè shí jiān yì)* "word embedding" is translated as "字符嵌入" (zhì chào fù rù)* "extensive experiments" is translated as "广泛实验" (guǎn fāng shí yan)
</details></li>
</ul>
<hr>
<h2 id="SLHCat-Mapping-Wikipedia-Categories-and-Lists-to-DBpedia-by-Leveraging-Semantic-Lexical-and-Hierarchical-Features"><a href="#SLHCat-Mapping-Wikipedia-Categories-and-Lists-to-DBpedia-by-Leveraging-Semantic-Lexical-and-Hierarchical-Features" class="headerlink" title="SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features"></a>SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11791">http://arxiv.org/abs/2309.11791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyi Wang, Zhenyang Zhang, Jiaxin Qin, Mizuho Iwaihara</li>
<li>for: 解决 CaLiGraph 生成的不完整和粗糙的映射问题，实现一个大规模的知识图库。</li>
<li>methods: 使用ontologyAlignment的方法，利用知识图的结构信息和ontology类名的语言和SemanticSimilarities来发现可信的映射。</li>
<li>results: 比基eline模型准确率高25%，提供一种实际的大规模ontology映射解决方案。<details>
<summary>Abstract</summary>
Wikipedia articles are hierarchically organized through categories and lists, providing one of the most comprehensive and universal taxonomy, but its open creation is causing redundancies and inconsistencies. Assigning DBPedia classes to Wikipedia categories and lists can alleviate the problem, realizing a large knowledge graph which is essential for categorizing digital contents through entity linking and typing. However, the existing approach of CaLiGraph is producing incomplete and non-fine grained mappings. In this paper, we tackle the problem as ontology alignment, where structural information of knowledge graphs and lexical and semantic features of ontology class names are utilized to discover confident mappings, which are in turn utilized for finetuing pretrained language models in a distant supervision fashion. Our method SLHCat consists of two main parts: 1) Automatically generating training data by leveraging knowledge graph structure, semantic similarities, and named entity typing. 2) Finetuning and prompt-tuning of the pre-trained language model BERT are carried out over the training data, to capture semantic and syntactic properties of class names. Our model SLHCat is evaluated over a benchmark dataset constructed by annotating 3000 fine-grained CaLiGraph-DBpedia mapping pairs. SLHCat is outperforming the baseline model by a large margin of 25% in accuracy, offering a practical solution for large-scale ontology mapping.
</details>
<details>
<summary>摘要</summary>
Wikipedia文章通过分类和列表归类，提供了一个最完整和通用的分类体系，但是开放创建导致重复和不一致。将DBPedia类划分到Wikipedia分类和列表中可以解决这个问题，实现大量知识图的构建，这是对数字内容进行分类和类型的关键。然而，现有的CaLiGraph方法产生了不完整和粗糙的映射。在这篇论文中，我们视为ontology对齐，利用知识图结构、语义和命名实体类型的信息，以确定可靠的映射，然后利用远程监督的方式来训练预训练的语言模型。我们的方法SLHCat包括两个主要部分：1. 利用知识图结构、语义相似度和命名实体类型自动生成训练数据。2. 使用训练数据进行远程监督方式来训练和提前训练预训练的语言模型BERT，以捕捉类名的语义和 sintaxis性质。我们的模型SLHCat在一个建立的基准数据集上进行评估，与基eline模型相比，SLHCat的准确率高出25%，提供了一个实用的大规模 Ontology mapping 解决方案。
</details></li>
</ul>
<hr>
<h2 id="ContextRef-Evaluating-Referenceless-Metrics-For-Image-Description-Generation"><a href="#ContextRef-Evaluating-Referenceless-Metrics-For-Image-Description-Generation" class="headerlink" title="ContextRef: Evaluating Referenceless Metrics For Image Description Generation"></a>ContextRef: Evaluating Referenceless Metrics For Image Description Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11710">http://arxiv.org/abs/2309.11710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elisakreiss/contextref">https://github.com/elisakreiss/contextref</a></li>
<li>paper_authors: Elisa Kreiss, Eric Zelikman, Christopher Potts, Nick Haber</li>
<li>for: 本研究用于评估无参考度量测试方法，以便更快地进行进步。</li>
<li>methods: 本研究使用预训练的视觉语言模型来评估图文描述，并提出了 ContextRef  benchmark，用于评估这些方法的对人类喜好性的Alignment。</li>
<li>results: 研究发现，无论使用哪种预训练模型或者 scoring functions，都无法通过 ContextRef 测试。但是，通过精心微调，可以获得显著改进。 ContextRef  remain 一个挑战性的 bencmark，主要归因于图文描述的上下文依赖。<details>
<summary>Abstract</summary>
Referenceless metrics (e.g., CLIPScore) use pretrained vision--language models to assess image descriptions directly without costly ground-truth reference texts. Such methods can facilitate rapid progress, but only if they truly align with human preference judgments. In this paper, we introduce ContextRef, a benchmark for assessing referenceless metrics for such alignment. ContextRef has two components: human ratings along a variety of established quality dimensions, and ten diverse robustness checks designed to uncover fundamental weaknesses. A crucial aspect of ContextRef is that images and descriptions are presented in context, reflecting prior work showing that context is important for description quality. Using ContextRef, we assess a variety of pretrained models, scoring functions, and techniques for incorporating context. None of the methods is successful with ContextRef, but we show that careful fine-tuning yields substantial improvements. ContextRef remains a challenging benchmark though, in large part due to the challenge of context dependence.
</details>
<details>
<summary>摘要</summary>
无参准度量器（例如CLIPScore）使用预训练视语模型直接评估图文描述，而不需要昂贵的参照文本。这些方法可以促进快速进步，但只有如果它们与人类偏好判断相一致。在这篇论文中，我们介绍ContextRef，一个用于评估无参准度量器的benchmark。ContextRef有两个组成部分：人类评分多种已知质量维度，以及十种多样化的Robustness Check，旨在揭示基本弱点。ContextRef中图文的展示是在Context中进行的，这与先前的研究表明，Context对描述质量具有重要作用。使用ContextRef，我们评估了多种预训练模型、分数函数和Context的integiration方法。结果显示，None of the methods是ContextRef中成功的，但我们展示了精细微调可以实现显著改进。ContextRef仍然是一个挑战性的benchmark，主要是因为Context的依赖性。
</details></li>
</ul>
<hr>
<h2 id="Memory-Augmented-LLM-Personalization-with-Short-and-Long-Term-Memory-Coordination"><a href="#Memory-Augmented-LLM-Personalization-with-Short-and-Long-Term-Memory-Coordination" class="headerlink" title="Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination"></a>Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11696">http://arxiv.org/abs/2309.11696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Zhang, Fubang Zhao, Yangyang Kang, Xiaozhong Liu</li>
<li>for: 提高用户特定的自然语言生成结果（User-oriented natural language generation）</li>
<li>methods: 提出了一种新的计算机力学记忆机制，并采用参数效率的精度调整方案进行个性化（Parameter-efficient fine-tuning schema）</li>
<li>results: 实验结果表明提案的方法有效并且超越传统方法（Extensive experimental results demonstrate the effectiveness and superiority of the proposed approach）<details>
<summary>Abstract</summary>
Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable proficiency in comprehending and generating natural language. However, their unpersonalized generation paradigm may result in suboptimal user-specific outcomes. Typically, users converse differently based on their knowledge and preferences. This necessitates the task of enhancing user-oriented LLM which remains unexplored. While one can fully train an LLM for this objective, the resource consumption is unaffordable. Prior research has explored memory-based methods to store and retrieve knowledge to enhance generation without retraining for new queries. However, we contend that a mere memory module is inadequate to comprehend a user's preference, and fully training an LLM can be excessively costly. In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach. To encourage further research into this area, we are releasing a new conversation dataset generated entirely by LLM based on an open-source medical corpus, as well as our implementation code.
</details>
<details>
<summary>摘要</summary>
In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach. To encourage further research in this area, we are releasing a new conversation dataset generated entirely by LLM based on an open-source medical corpus, as well as our implementation code.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.CL_2023_09_21/" data-id="clmvt7t8q008r26rdeysi0spj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.LG_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T10:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.LG_2023_09_21/">cs.LG - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Performance-Conditioning-for-Diffusion-Based-Multi-Instrument-Music-Synthesis"><a href="#Performance-Conditioning-for-Diffusion-Based-Multi-Instrument-Music-Synthesis" class="headerlink" title="Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis"></a>Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12283">http://arxiv.org/abs/2309.12283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Maman, Johannes Zeitler, Meinard Müller, Amit H. Bermano</li>
<li>for: 本研究的目的是提高多楽器合成的控制精度，使其更能够符合音乐的特性和演奏环境。</li>
<li>methods: 本研究基于当前顶尖的扩散模型，引入表演环境调整，以提高音乐生成的时期和乐器风格控制。</li>
<li>results: 这项研究的评估结果显示，使用表演环境调整可以实现更高的乐器特性和演奏风格控制，并且在不同乐器和演奏环境下实现了类比于人类聆听者的音乐生成。<details>
<summary>Abstract</summary>
Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is available at benadar293.github.io/midipm
</details>
<details>
<summary>摘要</summary>
<<SYS>>将 symbolic music representation 转化为多种乐器音乐是音乐信息检索（MIR）领域中的重要任务。这个问题的中心问题是在生成过程中提供音乐和听众意见。作为本工作的主要贡献，我们提议通过指定特定的表演和录音环境来增强多乐器合成的控制。基于当前的扩散型音乐生成模型，我们引入表演条件 - 一种简单的工具，用于指定生成模型Synthesize music with specific instruments and timbre from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. More information, including samples and demonstrations, can be found at benadar293.github.io/midipm.Note: "FAD" stands for "Flexible Audio Database", which is a standard evaluation metric for music generation systems. A high FAD realism score indicates that the generated music sounds realistic and similar to the original recording.
</details></li>
</ul>
<hr>
<h2 id="The-Broad-Impact-of-Feature-Imitation-Neural-Enhancements-Across-Financial-Speech-and-Physiological-Domains"><a href="#The-Broad-Impact-of-Feature-Imitation-Neural-Enhancements-Across-Financial-Speech-and-Physiological-Domains" class="headerlink" title="The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains"></a>The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12279">http://arxiv.org/abs/2309.12279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Khanmohammadi, Tuka Alhanai, Mohammad M. Ghassemi</li>
<li>for: 这篇论文旨在测试对不同时间序列数据进行初始化神经网络的性能影响。</li>
<li>methods: 本研究使用Feature Imitating Networks（FIN）技术，将神经网络的初始化参数设置为模仿特定的关闭形式统计特征，以提高深度学习架构的性能。</li>
<li>results: 在Bitcoin价格预测任务中，将FIN给神经网络模型中的表现下降了约1000，对比基准模型。在语音情感识别任务中，将FIN与神经网络模型相结合后，提高了分类精度约3%。在chronic neck pain检测任务中，将FIN给神经网络模型中的表现提高了约7%，对比现有的分类器。这些发现证明了FIN在多种应用中的广泛应用和优化性。<details>
<summary>Abstract</summary>
Initialization of neural network weights plays a pivotal role in determining their performance. Feature Imitating Networks (FINs) offer a novel strategy by initializing weights to approximate specific closed-form statistical features, setting a promising foundation for deep learning architectures. While the applicability of FINs has been chiefly tested in biomedical domains, this study extends its exploration into other time series datasets. Three different experiments are conducted in this study to test the applicability of imitating Tsallis entropy for performance enhancement: Bitcoin price prediction, speech emotion recognition, and chronic neck pain detection. For the Bitcoin price prediction, models embedded with FINs reduced the root mean square error by around 1000 compared to the baseline. In the speech emotion recognition task, the FIN-augmented model increased classification accuracy by over 3 percent. Lastly, in the CNP detection experiment, an improvement of about 7 percent was observed compared to established classifiers. These findings validate the broad utility and potency of FINs in diverse applications.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:初始化神经网络权重的初始化方法对其性能产生决定性的影响。特征模仿网络（FIN）提供了一种新的策略，通过初始化权重来 aproximate 特定的关闭形式统计特征，为深度学习架构提供了一个良好的基础。虽然FIN的可用性主要在生物医学领域进行了证明，但这项研究尝试将其应用到其他时间序列数据集上。这个研究进行了三个不同的实验来测试FIN的可行性和表现：比特币价格预测、语音情感识别和慢性颈部疼痛检测。在比特币价格预测任务中，包含FIN的模型降低了根圆误差约1000比例。在语音情感识别任务中，FIN-加强模型提高了分类精度高达3%。最后，在慢性颈部疼痛检测任务中，FIN-加强模型与现有分类器相比，提高了约7%的性能。这些发现证明了FIN在多样化应用中的广泛适用性和强大性。
</details></li>
</ul>
<hr>
<h2 id="Soft-Merging-A-Flexible-and-Robust-Soft-Model-Merging-Approach-for-Enhanced-Neural-Network-Performance"><a href="#Soft-Merging-A-Flexible-and-Robust-Soft-Model-Merging-Approach-for-Enhanced-Neural-Network-Performance" class="headerlink" title="Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance"></a>Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12259">http://arxiv.org/abs/2309.12259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Yusen Wu, Phuong Nguyen, Chao Liu, Yelena Yesha</li>
<li>for: 提高深度学习模型的性能和稳定性</li>
<li>methods: 使用soft merging方法，通过学习门户参数来融合多个本地最优模型，并使用硬核分布来避免恶性模型的影响</li>
<li>results: 实验表明，使用融合模型可以提高深度学习模型的性能和稳定性，并且可以降低计算成本<details>
<summary>Abstract</summary>
Stochastic Gradient Descent (SGD), a widely used optimization algorithm in deep learning, is often limited to converging to local optima due to the non-convex nature of the problem. Leveraging these local optima to improve model performance remains a challenging task. Given the inherent complexity of neural networks, the simple arithmetic averaging of the obtained local optima models in undesirable results. This paper proposes a {\em soft merging} method that facilitates rapid merging of multiple models, simplifies the merging of specific parts of neural networks, and enhances robustness against malicious models with extreme values. This is achieved by learning gate parameters through a surrogate of the $l_0$ norm using hard concrete distribution without modifying the model weights of the given local optima models. This merging process not only enhances the model performance by converging to a better local optimum, but also minimizes computational costs, offering an efficient and explicit learning process integrated with stochastic gradient descent. Thorough experiments underscore the effectiveness and superior performance of the merged neural networks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Parallelizing-non-linear-sequential-models-over-the-sequence-length"><a href="#Parallelizing-non-linear-sequential-models-over-the-sequence-length" class="headerlink" title="Parallelizing non-linear sequential models over the sequence length"></a>Parallelizing non-linear sequential models over the sequence length</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12252">http://arxiv.org/abs/2309.12252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Heng Lim, Qi Zhu, Joshua Selfridge, Muhammad Firmansyah Kasim</li>
<li>for:  acceleration of GPU evaluation of sequential models</li>
<li>methods:  parallel algorithm without special structure in the architecture</li>
<li>results:  training 10 times faster with no compromise on accuracy<details>
<summary>Abstract</summary>
Sequential models, such as Recurrent Neural Networks and Neural Ordinary Differential Equations, have long suffered from slow training due to their inherent sequential nature. For many years this bottleneck has persisted, as many thought sequential models could not be parallelized. We challenge this long-held belief with our parallel algorithm that accelerates GPU evaluation of sequential models by up to 3 orders of magnitude faster without compromising output accuracy. The algorithm does not need any special structure in the sequential models' architecture, making it applicable to a wide range of architectures. Using our method, training sequential models can be more than 10 times faster than the common sequential method without any meaningful difference in the training results. Leveraging this accelerated training, we discovered the efficacy of the Gated Recurrent Unit in a long time series classification problem with 17k time samples. By overcoming the training bottleneck, our work serves as the first step to unlock the potential of non-linear sequential models for long sequence problems.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本，对于具体的翻译请参考下面的详细翻译）Sequential models, such as Recurrent Neural Networks and Neural Ordinary Differential Equations, have long been limited by their sequential nature, leading to slow training times. Many believed that these models could not be parallelized, but we challenge this belief with our parallel algorithm that accelerates GPU evaluation of sequential models by up to 3 orders of magnitude faster without compromising output accuracy. Our method is applicable to a wide range of architectures and can train sequential models up to 10 times faster than traditional methods without any significant difference in training results. By overcoming the training bottleneck, our work paves the way for the potential of non-linear sequential models in long sequence problems.
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-Automated-Audio-Captioning-via-text-only-training"><a href="#Weakly-supervised-Automated-Audio-Captioning-via-text-only-training" class="headerlink" title="Weakly-supervised Automated Audio Captioning via text only training"></a>Weakly-supervised Automated Audio Captioning via text only training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12242">http://arxiv.org/abs/2309.12242</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zelaki/wsac">https://github.com/zelaki/wsac</a></li>
<li>paper_authors: Theodoros Kouzelis, Vassilis Katsouros</li>
<li>for: automatically generating descriptions for audio clips (AAC)</li>
<li>methods: weakly-supervised approach using text data and pre-trained CLAP model, with strategies to bridge the modality gap</li>
<li>results: relative performance of up to ~$83%$ compared to fully supervised approaches trained with paired target data on Clotho and AudioCaps datasets<details>
<summary>Abstract</summary>
In recent years, datasets of paired audio and captions have enabled remarkable success in automatically generating descriptions for audio clips, namely Automated Audio Captioning (AAC). However, it is labor-intensive and time-consuming to collect a sufficient number of paired audio and captions. Motivated by the recent advances in Contrastive Language-Audio Pretraining (CLAP), we propose a weakly-supervised approach to train an AAC model assuming only text data and a pre-trained CLAP model, alleviating the need for paired target data. Our approach leverages the similarity between audio and text embeddings in CLAP. During training, we learn to reconstruct the text from the CLAP text embedding, and during inference, we decode using the audio embeddings. To mitigate the modality gap between the audio and text embeddings we employ strategies to bridge the gap during training and inference stages. We evaluate our proposed method on Clotho and AudioCaps datasets demonstrating its ability to achieve a relative performance of up to ~$83\%$ compared to fully supervised approaches trained with paired target data.
</details>
<details>
<summary>摘要</summary>
近年来，带有音频和caption的数据集已经实现了自动生成音频描述的remarkable成功，即自动语音描述（AAC）。然而，收集到充足数量的带有音频和caption的数据集是时间和劳动密集的。鼓 motivated by recent advances in Contrastive Language-Audio Pretraining（CLAP），我们提出了一种弱监督的方法，通过假设只有文本数据和预训练的CLAP模型，解决了需要对Target数据进行监督的问题。我们的方法利用CLAP模型中的文本和音频嵌入的相似性。在训练过程中，我们学习将文本重建为CLAP文本嵌入，并在推理阶段使用音频嵌入进行解码。为了在模式之间减少差距，我们在训练和推理阶段使用了bridging策略。我们在Clotho和AudioCaps数据集上评估了我们的提议方法，并证明其能够实现相对于完全监督方法训练于带有Target数据的性能的$83\%$。
</details></li>
</ul>
<hr>
<h2 id="t-EER-Parameter-Free-Tandem-Evaluation-of-Countermeasures-and-Biometric-Comparators"><a href="#t-EER-Parameter-Free-Tandem-Evaluation-of-Countermeasures-and-Biometric-Comparators" class="headerlink" title="t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators"></a>t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12237">http://arxiv.org/abs/2309.12237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/takhemlata/t-eer">https://github.com/takhemlata/t-eer</a></li>
<li>paper_authors: Tomi Kinnunen, Kong Aik Lee, Hemlata Tak, Nicholas Evans, Andreas Nautsch</li>
<li>for: The paper is written to propose a new metric for the joint evaluation of presentation attack detection (PAD) solutions operating in tandem with biometric verification.</li>
<li>methods: The paper introduces a new metric called tandem equal error rate (t-EER) for evaluating the performance of PAD solutions in combination with biometric verification systems. The t-EER is a parameter-free metric that measures the equal error rate of both false alarms and misses at a set of operating points.</li>
<li>results: The paper demonstrates the application of the t-EER metric to a wide range of biometric system evaluations under attack, using both simulated and real scores for a voice biometrics application. The proposed approach is shown to be a strong candidate metric for the tandem evaluation of PAD systems and biometric comparators.Here is the simplified Chinese text for the three key information points:</li>
<li>for: 本文是为了提出一个新的 metric 用于 tandem 识别攻击检测 (PAD) 和生物特征验证系统的共同评估。</li>
<li>methods: 本文提出了一个名为 tandem 平等错误率 (t-EER) 的新metric，用于评估 PAD 解决方案和生物特征验证系统之间的共同性能。t-EER 是一个无参数的 metric，可以在多个操作点上测试 false alarm 和 miss 的平等错误率。</li>
<li>results: 本文使用了 simulated 和实际数据，对一个语音生物特征验证应用进行了广泛的评估。结果表明，tandem EER 是一个强andidate metric 用于 tandem 识别攻击检测和生物特征验证系统之间的评估。<details>
<summary>Abstract</summary>
Presentation attack (spoofing) detection (PAD) typically operates alongside biometric verification to improve reliablity in the face of spoofing attacks. Even though the two sub-systems operate in tandem to solve the single task of reliable biometric verification, they address different detection tasks and are hence typically evaluated separately. Evidence shows that this approach is suboptimal. We introduce a new metric for the joint evaluation of PAD solutions operating in situ with biometric verification. In contrast to the tandem detection cost function proposed recently, the new tandem equal error rate (t-EER) is parameter free. The combination of two classifiers nonetheless leads to a \emph{set} of operating points at which false alarm and miss rates are equal and also dependent upon the prevalence of attacks. We therefore introduce the \emph{concurrent} t-EER, a unique operating point which is invariable to the prevalence of attacks. Using both modality (and even application) agnostic simulated scores, as well as real scores for a voice biometrics application, we demonstrate application of the t-EER to a wide range of biometric system evaluations under attack. The proposed approach is a strong candidate metric for the tandem evaluation of PAD systems and biometric comparators.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Smooth-ECE-Principled-Reliability-Diagrams-via-Kernel-Smoothing"><a href="#Smooth-ECE-Principled-Reliability-Diagrams-via-Kernel-Smoothing" class="headerlink" title="Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing"></a>Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12236">http://arxiv.org/abs/2309.12236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apple/ml-calibration">https://github.com/apple/ml-calibration</a></li>
<li>paper_authors: Jarosław Błasiok, Preetum Nakkiran</li>
<li>for: 这篇论文主要研究了如何使用抽象函数来测量和解释抽象预测器的准确性。</li>
<li>methods: 这篇论文使用了Radius Band Function(RBF)核函数来平滑观测值，然后计算Expected Calibration Error(ECE)。</li>
<li>results: 这篇论文提出了一种新的准确性测量方法，即SmoothECE，可以减轻抽象预测器的准确性问题。此外，这篇论文还提供了一个Python包，可以简单地测量和可读地展示抽象预测器的准确性。<details>
<summary>Abstract</summary>
Calibration measures and reliability diagrams are two fundamental tools for measuring and interpreting the calibration of probabilistic predictors. Calibration measures quantify the degree of miscalibration, and reliability diagrams visualize the structure of this miscalibration. However, the most common constructions of reliability diagrams and calibration measures -- binning and ECE -- both suffer from well-known flaws (e.g. discontinuity). We show that a simple modification fixes both constructions: first smooth the observations using an RBF kernel, then compute the Expected Calibration Error (ECE) of this smoothed function. We prove that with a careful choice of bandwidth, this method yields a calibration measure that is well-behaved in the sense of (B{\l}asiok, Gopalan, Hu, and Nakkiran 2023a) -- a consistent calibration measure. We call this measure the SmoothECE. Moreover, the reliability diagram obtained from this smoothed function visually encodes the SmoothECE, just as binned reliability diagrams encode the BinnedECE.   We also provide a Python package with simple, hyperparameter-free methods for measuring and plotting calibration: `pip install relplot\`.
</details>
<details>
<summary>摘要</summary>
“测量和可靠图是概率预测器的二个基本工具。测量措施量化预测器的误差，并可以视觉化这种误差的结构。然而，通常的构建方法，例如桶化和ECE，都受到了知名的缺陷（例如缺陷）。我们显示，使用RBF核函数平滑观测值后，计算预测ERROR的Expected Calibration Error（ECE），可以得到一个良好的测量方法。对于适当的标Width选择，这种方法具有一定的稳定性（Błasiok等2023a），我们称之为SmoothECE。此外，从这个平滑函数中得到的可靠图可以视觉化SmoothECE，与桶化的可靠图相似。我们还提供了一个Python套件，包含了简单、无参数的方法来量化和Plot calibration：`pip install relplot\`.”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Smooth-Nash-Equilibria-Algorithms-and-Complexity"><a href="#Smooth-Nash-Equilibria-Algorithms-and-Complexity" class="headerlink" title="Smooth Nash Equilibria: Algorithms and Complexity"></a>Smooth Nash Equilibria: Algorithms and Complexity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12226">http://arxiv.org/abs/2309.12226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Constantinos Daskalakis, Noah Golowich, Nika Haghtalab, Abhishek Shetty</li>
<li>for: 这篇论文旨在解决 Nash 平衡的计算复杂性问题，提出了一种名为 $\sigma$-粗化 Nash 平衡的变种，并研究了其计算性质。</li>
<li>methods: 该论文使用了简化分析的想法，引入了一种名为 $\sigma$-粗化 Nash 平衡的概念，并提出了两种不同的 $\sigma$-粗化 Nash 平衡变种：强型 $\sigma$-粗化 Nash 平衡和弱型 $\sigma$-粗化 Nash 平衡。</li>
<li>results: 论文表明，在常量 $\sigma$ 和 $\epsilon$ 以及玩家数量都是常数时，可以在常量时间内随机找到一个 $\epsilon$-相近 $\sigma$-粗化 Nash 平衡，而且在同样的参数 régime 下，可以在多项时间内寻找一个强型 $\epsilon$-相近 $\sigma$-粗化 Nash 平衡。这些结果与 Nash 平衡的优化算法不可避免的复杂性不同。<details>
<summary>Abstract</summary>
A fundamental shortcoming of the concept of Nash equilibrium is its computational intractability: approximating Nash equilibria in normal-form games is PPAD-hard. In this paper, inspired by the ideas of smoothed analysis, we introduce a relaxed variant of Nash equilibrium called $\sigma$-smooth Nash equilibrium, for a smoothness parameter $\sigma$. In a $\sigma$-smooth Nash equilibrium, players only need to achieve utility at least as high as their best deviation to a $\sigma$-smooth strategy, which is a distribution that does not put too much mass (as parametrized by $\sigma$) on any fixed action. We distinguish two variants of $\sigma$-smooth Nash equilibria: strong $\sigma$-smooth Nash equilibria, in which players are required to play $\sigma$-smooth strategies under equilibrium play, and weak $\sigma$-smooth Nash equilibria, where there is no such requirement.   We show that both weak and strong $\sigma$-smooth Nash equilibria have superior computational properties to Nash equilibria: when $\sigma$ as well as an approximation parameter $\epsilon$ and the number of players are all constants, there is a constant-time randomized algorithm to find a weak $\epsilon$-approximate $\sigma$-smooth Nash equilibrium in normal-form games. In the same parameter regime, there is a polynomial-time deterministic algorithm to find a strong $\epsilon$-approximate $\sigma$-smooth Nash equilibrium in a normal-form game. These results stand in contrast to the optimal algorithm for computing $\epsilon$-approximate Nash equilibria, which cannot run in faster than quasipolynomial-time. We complement our upper bounds by showing that when either $\sigma$ or $\epsilon$ is an inverse polynomial, finding a weak $\epsilon$-approximate $\sigma$-smooth Nash equilibria becomes computationally intractable.
</details>
<details>
<summary>摘要</summary>
《纳什平衡概念的基本缺陷》：纳什平衡的计算复杂性问题，在正常形游戏中，是PPAD困难的。在这篇论文中，我们根据精细分析的想法，引入一种Namedashed variant of Nash equilibrium，即$\sigma$-粗糙纳什平衡，其中$\sigma$是一个精度参数。在一个$\sigma$-粗糙纳什平衡中，玩家只需要实现 Utility 高于或等于它的最佳偏转策，这个策略是一个不太多的质量（如 parametrized by $\sigma$）的分布。我们将这种纳什平衡分为两种变种：强制 $\sigma$-粗糙纳什平衡，在平衡状态下，玩家需要采取 $\sigma$-粗糙策略，以及弱 $\sigma$-粗糙纳什平衡，没有这种要求。我们显示，在常数 $\sigma$ 和 Approximation parameter $\epsilon$ 以及玩家数量都是常数时，可以采取常数时间的随机算法来找到弱 $\epsilon$-近似 $\sigma$-粗糙纳什平衡，并且在同样的参数域内，可以采取多项时间的排序算法来找到强制 $\epsilon$-近似 $\sigma$-粗糙纳什平衡。这些结果与纳什平衡的优化算法不同，后者无法在超过半定时的情况下运行。我们补充了我们的上界，表明当 $\sigma$ 或 $\epsilon$ 是反射函数时，找到弱 $\epsilon$-近似 $\sigma$-粗糙纳什平衡就变得计算困难。
</details></li>
</ul>
<hr>
<h2 id="Regionally-Additive-Models-Explainable-by-design-models-minimizing-feature-interactions"><a href="#Regionally-Additive-Models-Explainable-by-design-models-minimizing-feature-interactions" class="headerlink" title="Regionally Additive Models: Explainable-by-design models minimizing feature interactions"></a>Regionally Additive Models: Explainable-by-design models minimizing feature interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12215">http://arxiv.org/abs/2309.12215</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/givasile/RAM">https://github.com/givasile/RAM</a></li>
<li>paper_authors: Vasilis Gkolemis, Anargiros Tzerefos, Theodore Dalamagas, Eirini Ntoutsi, Christos Diou</li>
<li>for: 本研究旨在提出一种新的可解释模型，即区域添加模型（RAMs），用于解决基于多特征的机器学习问题中，加比模型（GAMs）的缺陷。</li>
<li>methods: 本研究提出了一种三步法则，首先使用黑盒模型进行训练，然后使用区域效果图来确定特征空间中的子区域，最后在每个子区域中采用加比模型来表示输出。</li>
<li>results: 实验结果表明，RAMs 比 GAMs 更高的表达能力，同时保持可解释性。<details>
<summary>Abstract</summary>
Generalized Additive Models (GAMs) are widely used explainable-by-design models in various applications. GAMs assume that the output can be represented as a sum of univariate functions, referred to as components. However, this assumption fails in ML problems where the output depends on multiple features simultaneously. In these cases, GAMs fail to capture the interaction terms of the underlying function, leading to subpar accuracy. To (partially) address this issue, we propose Regionally Additive Models (RAMs), a novel class of explainable-by-design models. RAMs identify subregions within the feature space where interactions are minimized. Within these regions, it is more accurate to express the output as a sum of univariate functions (components). Consequently, RAMs fit one component per subregion of each feature instead of one component per feature. This approach yields a more expressive model compared to GAMs while retaining interpretability. The RAM framework consists of three steps. Firstly, we train a black-box model. Secondly, using Regional Effect Plots, we identify subregions where the black-box model exhibits near-local additivity. Lastly, we fit a GAM component for each identified subregion. We validate the effectiveness of RAMs through experiments on both synthetic and real-world datasets. The results confirm that RAMs offer improved expressiveness compared to GAMs while maintaining interpretability.
</details>
<details>
<summary>摘要</summary>
通用加тив模型（GAMs）广泛应用于不同领域的解释性模型中。GAMs假设输出可以表示为一些单变量函数的总和，称为组件。然而，在机器学习问题中，输出受多个特征的同时影响，这个假设失败。在这些情况下，GAMs无法捕捉输出函数的交叉项，导致准确率下降。为解决这个问题，我们提出了区域加тив模型（RAMs），一种新的解释性模型类型。RAMs确定特征空间中的子区域，在这些子区域中，交叉项的影响最小。因此，RAMs采用一个组件来描述每个特征的子区域中的输出。相比GAMs，RAMs采用更加表达力的模型，同时保持可解释性。RAMs的框架包括三个步骤：首先，我们训练黑盒模型；其次，使用地方效果图来确定特征空间中的子区域，这些子区域中黑盒模型的地方效果较低；最后，我们采用GAM组件来描述每个确定的子区域。我们通过对synthetic和实际数据进行实验，证明RAMs可以提高表达力，同时保持可解释性。结果表明，RAMs比GAMs更好地适应机器学习问题。
</details></li>
</ul>
<hr>
<h2 id="SupeRBNN-Randomized-Binary-Neural-Network-Using-Adiabatic-Superconductor-Josephson-Devices"><a href="#SupeRBNN-Randomized-Binary-Neural-Network-Using-Adiabatic-Superconductor-Josephson-Devices" class="headerlink" title="SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices"></a>SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12212">http://arxiv.org/abs/2309.12212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengang Li, Geng Yuan, Tomoharu Yamauchi, Zabihi Masoud, Yanyue Xie, Peiyan Dong, Xulong Tang, Nobuyuki Yoshikawa, Devesh Tiwari, Yanzhi Wang, Olivia Chen</li>
<li>For: 这 paper 是为了提出一种基于 Adiabatic Quantum-Flux-Parametron (AQFP) 的 randomized Binary Neural Network (BNN) 加速器框架 SupeRBNN，以解决 AQFP 设备在 BNN 计算中的一些关键挑战。* Methods: 这 paper 使用了 AQFP 设备的特殊极性来 denote логические值，并提出了一种基于随机行为的 BNN 加速器框架 SupeRBNN，包括一种随机计算模块和一种时钟调整 Based 电路优化策略。* Results:  compared 于不同技术的实现，包括 CMOS、ReRAM 和超导器 RSFQ&#x2F;ERSFQ，这 paper 的设计在多个数据集和网络架构上进行了验证，并达到了约 7.8 x 10^4 倍于 ReRAM-based BNN 框架的能量效率，同时保持了相似的模型准确率。此外，与超导器基本设备相比，这 paper 的设计在最少两个数量级上高于能量效率。<details>
<summary>Abstract</summary>
Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency. By employing the distinct polarity of current to denote logic `0' and `1', AQFP devices serve as excellent carriers for binary neural network (BNN) computations. Although recent research has made initial strides toward developing an AQFP-based BNN accelerator, several critical challenges remain, preventing the design from being a comprehensive solution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN acceleration framework that leverages software-hardware co-optimization to eventually make the AQFP devices a feasible solution for BNN acceleration. Specifically, we investigate the randomized behavior of the AQFP devices and analyze the impact of crossbar size on current attenuation, subsequently formulating the current amplitude into the values suitable for use in BNN computation. To tackle the accumulation problem and improve overall hardware performance, we propose a stochastic computing-based accumulation module and a clocking scheme adjustment-based circuit optimization method. We validate our SupeRBNN framework across various datasets and network architectures, comparing it with implementations based on different technologies, including CMOS, ReRAM, and superconducting RSFQ/ERSFQ. Experimental results demonstrate that our design achieves an energy efficiency of approximately 7.8x10^4 times higher than that of the ReRAM-based BNN framework while maintaining a similar level of model accuracy. Furthermore, when compared with superconductor-based counterparts, our framework demonstrates at least two orders of magnitude higher energy efficiency.
</details>
<details>
<summary>摘要</summary>
adiabatic量子流 Parametron (AQFP) 是一种超导逻辑，具有极高的能效性。通过使用流动中的极性来表示逻辑“0”和“1”，AQFP设备成为优秀的二进制神经网络（BNN）计算器。虽然最近的研究已经做出了初步的进展，但是还有许多关键的挑战，使得设计无法成为全面的解决方案。在这篇论文中，我们提出了SupeRBNN框架，它是基于AQFP的随机BNN加速器。我们研究了AQFP设备的随机行为，并分析了跨栅大小对流动强度的影响，从而将流动强度转换为适合BNN计算的值。为了解决积累问题并提高硬件性能，我们提出了随机计算模块和时钟调整缓存器优化方法。我们在不同的 datasets 和网络架构上验证了我们的SupeRBNN框架，并与不同技术的实现进行比较，包括CMOS、ReRAM 和超导器RSFQ/ERSFQ。实验结果表明，我们的设计可以达到约7.8×10^4倍高于ReRAM基于BNN框架的能效性，同时保持相同的模型准确性水平。此外，与超导器基于counterparts 相比，我们的框架可以达到至少两个数量级的高效性。
</details></li>
</ul>
<hr>
<h2 id="Physics-informed-State-space-Neural-Networks-for-Transport-Phenomena"><a href="#Physics-informed-State-space-Neural-Networks-for-Transport-Phenomena" class="headerlink" title="Physics-informed State-space Neural Networks for Transport Phenomena"></a>Physics-informed State-space Neural Networks for Transport Phenomena</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12211">http://arxiv.org/abs/2309.12211</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshay J Dave, Richard B. Vilim</li>
<li>for: 本研究开展了一种名为物理数据驱动模型（PSM），用于实时优化、灵活性和故障忍受性在自主系统中，特别是在化学、生物医学和电力等领域的交通主导系统。传统的数据驱动方法缺乏物理限制，PSMs 则通过训练深度神经网络和物理约束使用组件的偏微分方程（PDE），实现物理约束的、端到端可微分前向动力模型。</li>
<li>methods: PSMs 使用感知器数据和物理约束组件的 PDE 训练深度神经网络，以实现物理约束的、端到端可微分前向动力模型。</li>
<li>results: 通过两个在 Silico 实验（一个热通道和一个冷却系统循环），我们证明 PSMs 比传统的数据驱动模型更加准确。此外，PSMs 还有许多优势，例如可以处理常数和时间依赖的约束，并且可以用于系统诊断和故障检测。<details>
<summary>Abstract</summary>
This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants. Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model. Through two in silico experiments - a heated channel and a cooling system loop - we demonstrate that PSMs offer a more accurate approach than purely data-driven models.   Beyond accuracy, there are several compelling use cases for PSMs. In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs. The former demonstrates the ability of PSMs to handle both constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection. We further posit that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Creation of a nonlinear supervisory controller through a sequentially updated state-space representation, demonstrating the ability of PSMs to handle both constant and time-dependent constraints.2. Proposal of a diagnostic algorithm using residuals from each of the PDEs, illustrating the value of PSMs in system diagnostics and fault detection.We also suggest that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems.</details></li>
</ol>
<hr>
<h2 id="Boolformer-Symbolic-Regression-of-Logic-Functions-with-Transformers"><a href="#Boolformer-Symbolic-Regression-of-Logic-Functions-with-Transformers" class="headerlink" title="Boolformer: Symbolic Regression of Logic Functions with Transformers"></a>Boolformer: Symbolic Regression of Logic Functions with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12207">http://arxiv.org/abs/2309.12207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sdascoli/boolformer">https://github.com/sdascoli/boolformer</a></li>
<li>paper_authors: Stéphane d’Ascoli, Samy Bengio, Josh Susskind, Emmanuel Abbé</li>
<li>for: 这个论文旨在介绍一种名为Boolformer的 transformer 架构，用于进行端到端 симвоlic regression 的整数函数预测。</li>
<li>methods: 这种架构使用 clean truth table 预测复杂函数，并在 incomplete 和噪声观察下找到approximate表达。</li>
<li>results: 在各种实际 binary classification 问题上进行了评估，并在模型动态遗传网络中得到了竞争力。 code 和模型都公开 available。<details>
<summary>Abstract</summary>
In this work, we introduce Boolformer, the first Transformer architecture trained to perform end-to-end symbolic regression of Boolean functions. First, we show that it can predict compact formulas for complex functions which were not seen during training, when provided a clean truth table. Then, we demonstrate its ability to find approximate expressions when provided incomplete and noisy observations. We evaluate the Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods. Finally, we apply it to the widespread task of modelling the dynamics of gene regulatory networks. Using a recent benchmark, we show that Boolformer is competitive with state-of-the art genetic algorithms with a speedup of several orders of magnitude. Our code and models are available publicly.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了 Boolformer，首个基于Transformer架构的端到端符号 regression 的布尔函数搜索算法。我们首先表明，它可以预测复杂函数的简洁公式，当提供了干净的真实表格时。然后，我们证明了它在提供不完整和噪音观测时可以找到approximate表达。我们对一组实际的二分类 datasets 进行了评估，表明它可以作为可读性的代替方法。最后，我们将其应用到了模拟生物学网络的动态方面，使用最新的benchmark，我们发现它与当前的遗传算法竞赛得分，但速度快得多个数量级。我们的代码和模型公共可用。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Conditional-Inference-in-Adaptive-Experiments"><a href="#Optimal-Conditional-Inference-in-Adaptive-Experiments" class="headerlink" title="Optimal Conditional Inference in Adaptive Experiments"></a>Optimal Conditional Inference in Adaptive Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12162">http://arxiv.org/abs/2309.12162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiafeng Chen, Isaiah Andrews</li>
<li>for: 研究批处理强化实验，即在实验中采样批处理时，可能会采用不同的批处理策略和目标参数，并且可能会在实验过程中动态地更新这些参数。</li>
<li>methods: 使用了批处理强化实验中的实验设计和数据分析技术，包括使用最后一批数据进行推断和估计。</li>
<li>results: 研究结果表明，在不假设批处理策略和目标参数的情况下，使用最后一批数据进行推断和估计是最佳的。此外，当批处理策略和目标参数是位置不变的（即不受数据的影响）时，可以通过一个额外的线性函数来捕捉更多的信息。<details>
<summary>Abstract</summary>
We study batched bandit experiments and consider the problem of inference conditional on the realized stopping time, assignment probabilities, and target parameter, where all of these may be chosen adaptively using information up to the last batch of the experiment. Absent further restrictions on the experiment, we show that inference using only the results of the last batch is optimal. When the adaptive aspects of the experiment are known to be location-invariant, in the sense that they are unchanged when we shift all batch-arm means by a constant, we show that there is additional information in the data, captured by one additional linear function of the batch-arm means. In the more restrictive case where the stopping time, assignment probabilities, and target parameter are known to depend on the data only through a collection of polyhedral events, we derive computationally tractable and optimal conditional inference procedures.
</details>
<details>
<summary>摘要</summary>
我们研究批处bandit实验，考虑实验中的批处时间、分配概率和目标参数都可能被选择适应信息，直到最后一批。不受其他限制，我们显示在只使用最后一批结果时进行推断是优化的。当批处方面的可靠性是位置不变的，即批处arm的均值在所有批处时间下都是不变的，我们显示存在一个额外的线性函数，捕捉了批处arm的均值。在更紧张的情况下，停止时间、分配概率和目标参数都知道通过数据来，我们 derivates可运行的和优化的条件推断过程。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-and-Truly-Large-Scale-Audio-Sheet-Music-Retrieval"><a href="#Towards-Robust-and-Truly-Large-Scale-Audio-Sheet-Music-Retrieval" class="headerlink" title="Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval"></a>Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12158">http://arxiv.org/abs/2309.12158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis Carvalho, Gerhard Widmer</li>
<li>for: 本研究的目的是探讨cross-modal music information retrieval的最新方法和技术，特别是将音频和乐谱图像连接到相同的音乐内容上。</li>
<li>methods: 本研究使用深度学习架构来学习joint embedding空间，将音频和乐谱图像modalities相连接。</li>
<li>results: 本研究提出了许多挑战，包括robustness和大规模应用等问题，并 documenated step-by-step improvement along several dimensions。<details>
<summary>Abstract</summary>
A range of applications of multi-modal music information retrieval is centred around the problem of connecting large collections of sheet music (images) to corresponding audio recordings, that is, identifying pairs of audio and score excerpts that refer to the same musical content. One of the typical and most recent approaches to this task employs cross-modal deep learning architectures to learn joint embedding spaces that link the two distinct modalities - audio and sheet music images. While there has been steady improvement on this front over the past years, a number of open problems still prevent large-scale employment of this methodology. In this article we attempt to provide an insightful examination of the current developments on audio-sheet music retrieval via deep learning methods. We first identify a set of main challenges on the road towards robust and large-scale cross-modal music retrieval in real scenarios. We then highlight the steps we have taken so far to address some of these challenges, documenting step-by-step improvement along several dimensions. We conclude by analysing the remaining challenges and present ideas for solving these, in order to pave the way to a unified and robust methodology for cross-modal music retrieval.
</details>
<details>
<summary>摘要</summary>
多种多Modal music信息检索的应用集中在将大量的乐谱图像（图像）与对应的音频录音相连接，即 identificador pairs of audio和乐谱摘要段 refer to the same musical content。一种常见的最近的方法是使用交叉模态深度学习建筑来学习联结这两种不同的模态——音频和乐谱图像。随着过去几年的不断改进，但还有一些打开的问题阻碍了大规模应用这种方法。在这篇文章中，我们尝试提供深入的检查当前的深度学习方法在Audio-Sheet music检索方面的发展。我们首先确定了在实际应用中Robust和大规模交叉模态音乐检索的主要挑战。然后，我们高亮了我们已经做出的努力，并记录了一些维度上的改进。 finally，我们分析了剩下的挑战，并提出了解决这些挑战的想法，以便开拓出一种统一和Robust的交叉模态音乐检索方法。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Contrastive-Learning-for-Robust-Audio-Sheet-Music-Retrieval-Systems"><a href="#Self-Supervised-Contrastive-Learning-for-Robust-Audio-Sheet-Music-Retrieval-Systems" class="headerlink" title="Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems"></a>Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12134">http://arxiv.org/abs/2309.12134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Luis Carvalho, Tobias Washüttl, Gerhard Widmer</li>
<li>for: 提高跨模态音乐检索系统的效果</li>
<li>methods: 使用自我超vision学习法，通过对各种模式的杂音训练网络，从实际音乐内容中提取有用的特征</li>
<li>results: 在多种实验中，预训练模型能够更好地回归 audio 和 sheet 图像中的片断，并在跨模态作品识别任务中提高检索质量<details>
<summary>Abstract</summary>
Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems. One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music. However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios. In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images. Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations. Encouraged by these results, we employ the snippet embeddings in the higher-level task of cross-modal piece identification and conduct more experiments on several retrieval configurations. In this task, we observe that the retrieval quality improves from 30% up to 100% when real music data is present. We then conclude by arguing for the potential of self-supervised contrastive learning for alleviating the annotated data scarcity in multi-modal music retrieval models.
</details>
<details>
<summary>摘要</summary>
链接Sheet music图像到音频录音的问题是多媒体音乐检索系统的关键问题。一种基本的方法是通过深度神经网络学习一个跨Modal空间，将 audio和Sheet music之间的连接短暂的音频和Sheet music片段。然而，实际音乐内容的罕见标注数据限制了这些方法的泛化能力。在这项工作中，我们研究了是否可以通过自动学习对比学习来缓解这种限制，通过对 audio和Sheet music之间的随机扩展后的视图进行对比。通过一系列的实验，我们发现在所有场景和预训练配置下，预训练模型都能够更好地检索片段。鼓动了这些结果，我们使用片段嵌入在高级任务中的跨Modal段落识别中，进行更多的实验。在这个任务中，我们发现，当有实际音乐数据时，检索质量从30%提高到100%。最后，我们结论，自动学习对比学习可以减轻多媒体音乐检索模型中的标注数据稀缺。
</details></li>
</ul>
<hr>
<h2 id="Convergence-and-Recovery-Guarantees-of-Unsupervised-Neural-Networks-for-Inverse-Problems"><a href="#Convergence-and-Recovery-Guarantees-of-Unsupervised-Neural-Networks-for-Inverse-Problems" class="headerlink" title="Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems"></a>Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12128">http://arxiv.org/abs/2309.12128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathan Buskulic, Jalal Fadili, Yvain Quéau</li>
<li>for: 解决 inverse problems</li>
<li>methods: 使用 unsupervised feedforward multilayer neural networks 和 deterministic convergence and recovery guarantees</li>
<li>results: 提供了对这类网络的 deterministic convergence and recovery guarantees，并 derive overparametrization boundsHere’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 本文目的是解决 inverse problems</li>
<li>methods: 使用 unsupervised feedforward multilayer neural networks 和 deterministic convergence and recovery guarantees</li>
<li>results: 本文提供了对这类网络的 deterministic convergence and recovery guarantees，并 derive overparametrization bounds<details>
<summary>Abstract</summary>
Neural networks have become a prominent approach to solve inverse problems in recent years. While a plethora of such methods was developed to solve inverse problems empirically, we are still lacking clear theoretical guarantees for these methods. On the other hand, many works proved convergence to optimal solutions of neural networks in a more general setting using overparametrization as a way to control the Neural Tangent Kernel. In this work we investigate how to bridge these two worlds and we provide deterministic convergence and recovery guarantees for the class of unsupervised feedforward multilayer neural networks trained to solve inverse problems. We also derive overparametrization bounds under which a two-layers Deep Inverse Prior network with smooth activation function will benefit from our guarantees.
</details>
<details>
<summary>摘要</summary>
“神经网络在最近几年内已成为解决反问题的主要方法之一。虽然大量的方法被开发来解决反问题，但我们仍然缺乏明确的理论保证。然而，许多研究证明了神经网络在更一般的设置下 converges to optimal solutions，使用过参数化来控制神经 Tangent Kernel。在这个工作中，我们尝试将这两个世界联系起来，并提供反问题的推理和恢复保证 для无监督Feedforward多层神经网络。我们还计算了过参数化的下限，表明在使用滑动函数 activation 时，两层 Deep Inverse Prior 网络会受益于我们的保证。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Passage-Summarization-with-Recurrent-Models-for-Audio-Sheet-Music-Retrieval"><a href="#Passage-Summarization-with-Recurrent-Models-for-Audio-Sheet-Music-Retrieval" class="headerlink" title="Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval"></a>Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12111">http://arxiv.org/abs/2309.12111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis Carvalho, Gerhard Widmer</li>
<li>for: 这篇论文关注的是如何将Sheet Music和音频录音连接起来，以便进行跨modal音乐检索。</li>
<li>methods: 该论文提出了一种使用深度神经网络学习Sheet Music和音频录音之间的共同 embedding空间，并通过适当的相似性结构来连接它们。</li>
<li>results: 该论文通过设计一种循环网络，解决了训练神经网络所需的强相关数据和音乐和音频之间的抽象差异问题，并在实验中表明了该方法可以更高度准确地进行跨modal音乐检索。<details>
<summary>Abstract</summary>
Many applications of cross-modal music retrieval are related to connecting sheet music images to audio recordings. A typical and recent approach to this is to learn, via deep neural networks, a joint embedding space that correlates short fixed-size snippets of audio and sheet music by means of an appropriate similarity structure. However, two challenges that arise out of this strategy are the requirement of strongly aligned data to train the networks, and the inherent discrepancies of musical content between audio and sheet music snippets caused by local and global tempo differences. In this paper, we address these two shortcomings by designing a cross-modal recurrent network that learns joint embeddings that can summarize longer passages of corresponding audio and sheet music. The benefits of our method are that it only requires weakly aligned audio-sheet music pairs, as well as that the recurrent network handles the non-linearities caused by tempo variations between audio and sheet music. We conduct a number of experiments on synthetic and real piano data and scores, showing that our proposed recurrent method leads to more accurate retrieval in all possible configurations.
</details>
<details>
<summary>摘要</summary>
很多跨Modal音乐检索应用都与将乐谱图像与音频记录连接起来。一种常见的方法是通过深度神经网络学习一个共同嵌入空间，使得短时间内的音频和乐谱图像之间存在相似性结构。然而，这种方法存在两个挑战：首先，需要强相关的数据来训练网络，其次，音频和乐谱图像中的音乐内容之间的本地和全局滥讲差异会导致各种非线性。在这篇论文中，我们解决这两个缺陷，通过设计一种跨Modal循环网络，学习联合嵌入空间，可以摘要长passage的相应音频和乐谱图像。我们的方法的优点是：只需弱相关的音频-乐谱图像对，以及循环网络可以处理非线性，带来更高的检索精度。我们在合成和实际钢琴数据和谱面上进行了一系列实验，表明我们的提议的循环方法可以在所有可能的配置下实现更高的检索精度。
</details></li>
</ul>
<hr>
<h2 id="Clustering-based-Domain-Incremental-Learning"><a href="#Clustering-based-Domain-Incremental-Learning" class="headerlink" title="Clustering-based Domain-Incremental Learning"></a>Clustering-based Domain-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12078">http://arxiv.org/abs/2309.12078</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SOYJUN/Implement-ODR-protocol">https://github.com/SOYJUN/Implement-ODR-protocol</a></li>
<li>paper_authors: Christiaan Lamers, Rene Vidal, Nabil Belbachir, Niki van Stein, Thomas Baeck, Paris Giampouras</li>
<li>for:  solves the catastrophic forgetting problem in domain-incremental learning, a setting that was previously unsolved.</li>
<li>methods:  uses an online clustering-based approach on a dynamically updated finite pool of samples or gradients to alleviate the need for task information.</li>
<li>results:  experiments on real datasets demonstrate the effectiveness of the proposed strategy and its promising performance compared to state-of-the-art methods.<details>
<summary>Abstract</summary>
We consider the problem of learning multiple tasks in a continual learning setting in which data from different tasks is presented to the learner in a streaming fashion. A key challenge in this setting is the so-called "catastrophic forgetting problem", in which the performance of the learner in an "old task" decreases when subsequently trained on a "new task". Existing continual learning methods, such as Averaged Gradient Episodic Memory (A-GEM) and Orthogonal Gradient Descent (OGD), address catastrophic forgetting by minimizing the loss for the current task without increasing the loss for previous tasks. However, these methods assume the learner knows when the task changes, which is unrealistic in practice. In this paper, we alleviate the need to provide the algorithm with information about task changes by using an online clustering-based approach on a dynamically updated finite pool of samples or gradients. We thereby successfully counteract catastrophic forgetting in one of the hardest settings, namely: domain-incremental learning, a setting for which the problem was previously unsolved. We showcase the benefits of our approach by applying these ideas to projection-based methods, such as A-GEM and OGD, which lead to task-agnostic versions of them. Experiments on real datasets demonstrate the effectiveness of the proposed strategy and its promising performance compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
我们考虑了多个任务在连续学习设定下学习问题，在数据流式方式下提供不同任务的数据给学习者。一个关键问题在这个设定下是所谓的“追忆问题”（catastrophic forgetting），即学习者在学习新任务时，对于之前学习的任务的性能下降。现有的连续学习方法，如Averaged Gradient Episodic Memory（A-GEM）和Orthogonal Gradient Descent（OGD），解决了追忆问题 by 将当前任务的损失降到最低，而不会提高之前任务的损失。但这些方法假设学习者知道任务的变化，这在实践中是不现实的。在这篇论文中，我们使用在线 clustering-based 方法，对于动态更新的有限池的样本或梯度进行处理，从而成功地避免了追忆问题。我们在域逐学习设定下应用这些想法，并将其应用到投影基本方法，如A-GEM 和 OGD，从而实现了任务无关的版本。实验结果表明，提议的策略有效地解决了追忆问题，并在实际数据上达到了比state-of-the-art方法更高的性能。
</details></li>
</ul>
<hr>
<h2 id="S-GBDT-Frugal-Differentially-Private-Gradient-Boosting-Decision-Trees"><a href="#S-GBDT-Frugal-Differentially-Private-Gradient-Boosting-Decision-Trees" class="headerlink" title="S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees"></a>S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12041">http://arxiv.org/abs/2309.12041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moritz Kirsche, Thorsten Peinemann, Joshua Stock, Carlos Cotrini, Esfandiar Mohammadi</li>
<li>For: The paper aims to develop a privacy-preserving learning method for gradient boosting decision trees (GBDT) that provides strong utility-privacy tradeoffs for tabular data.* Methods: The proposed method uses four techniques to improve the utility-privacy tradeoff: (1) an improved noise scaling approach with tighter accounting of privacy leakage, (2) integration of individual R&#39;enyi filters, (3) incorporation of random decision tree splits, and (4) subsampling for privacy amplification.* Results: The proposed method achieves high accuracy on two datasets (Abalone and Adult) with varying levels of privacy parameters (ε). Specifically, on the Abalone dataset, the proposed method achieves a $R^2$-score of 0.39 for ε&#x3D;0.15, which is the closest prior work only achieved for ε&#x3D;10.0. On the Adult dataset, the proposed method achieves a test error of 18.7% for ε&#x3D;0.07, which is the closest prior work only achieved for ε&#x3D;1.0. The proposed method also achieves high accuracy on the Abalone dataset for higher privacy parameters (ε&#x3D;0.54) and is very close to the accuracy of the non-private version of GBDT on the Adult dataset (ε&#x3D;0.54).<details>
<summary>Abstract</summary>
Privacy-preserving learning of gradient boosting decision trees (GBDT) has the potential for strong utility-privacy tradeoffs for tabular data, such as census data or medical meta data: classical GBDT learners can extract non-linear patterns from small sized datasets. The state-of-the-art notion for provable privacy-properties is differential privacy, which requires that the impact of single data points is limited and deniable. We introduce a novel differentially private GBDT learner and utilize four main techniques to improve the utility-privacy tradeoff. (1) We use an improved noise scaling approach with tighter accounting of privacy leakage of a decision tree leaf compared to prior work, resulting in noise that in expectation scales with $O(1/n)$, for $n$ data points. (2) We integrate individual R\'enyi filters to our method to learn from data points that have been underutilized during an iterative training process, which -- potentially of independent interest -- results in a natural yet effective insight to learning streams of non-i.i.d. data. (3) We incorporate the concept of random decision tree splits to concentrate privacy budget on learning leaves. (4) We deploy subsampling for privacy amplification. Our evaluation shows for the Abalone dataset ($<4k$ training data points) a $R^2$-score of $0.39$ for $\varepsilon=0.15$, which the closest prior work only achieved for $\varepsilon=10.0$. On the Adult dataset ($50k$ training data points) we achieve test error of $18.7\,\%$ for $\varepsilon=0.07$ which the closest prior work only achieved for $\varepsilon=1.0$. For the Abalone dataset for $\varepsilon=0.54$ we achieve $R^2$-score of $0.47$ which is very close to the $R^2$-score of $0.54$ for the nonprivate version of GBDT. For the Adult dataset for $\varepsilon=0.54$ we achieve test error $17.1\,\%$ which is very close to the test error $13.7\,\%$ of the nonprivate version of GBDT.
</details>
<details>
<summary>摘要</summary>
privacy-preserving 学习树 boosting 算法（GBDT）在 tabular 数据上有强大的用户-隐私交易，例如人口普查数据或医疗特征数据：经典 GBDT 学习器可以从小型数据集中提取非线性模式。我们引入了一种新的具有证明性隐私性质的 GBDT 学习器，并使用四种主要技术来改善用户-隐私交易。1. 我们使用改进的噪声扩大方法，对决策树叶节点的隐私泄露进行更精细的评估，从而使噪声在预期中呈线性关系，与数据点数 $n$ 成正比。2. 我们将个体 R\'enyi 筛选器 integrate 到我们的方法中，以学习尚未被利用的数据点，这可能是独立有趣的发现，并且自然地带来一种有效的学习流程。3. 我们启用随机决策树分裂的概念，以集中隐私预算在学习叶节点上。4. 我们使用采样来增强隐私压缩。我们的评估显示，在 Abalone 数据集（训练数据点数 fewer than 4k）中，我们在 $\varepsilon=0.15$ 下达到 $R^2$ 分数为 0.39，而最近的相关工作只能在 $\varepsilon=10.0$ 下达到这个分数。在 Adult 数据集（训练数据点数 50k）中，我们在 $\varepsilon=0.07$ 下达到测试错误率为 18.7%，而最近的相关工作只能在 $\varepsilon=1.0$ 下达到这个错误率。在 Abalone 数据集中，在 $\varepsilon=0.54$ 下，我们达到 $R^2$ 分数为 0.47，几乎与非隐私版 GBDT 的 $R^2$ 分数相同。在 Adult 数据集中，在 $\varepsilon=0.54$ 下，我们达到测试错误率为 17.1%，几乎与非隐私版 GBDT 的测试错误率相同。
</details></li>
</ul>
<hr>
<h2 id="Uplift-vs-predictive-modeling-a-theoretical-analysis"><a href="#Uplift-vs-predictive-modeling-a-theoretical-analysis" class="headerlink" title="Uplift vs. predictive modeling: a theoretical analysis"></a>Uplift vs. predictive modeling: a theoretical analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12036">http://arxiv.org/abs/2309.12036</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/theoverhelst/uplift-predictive-paper">https://github.com/theoverhelst/uplift-predictive-paper</a></li>
<li>paper_authors: Théo Verhelst, Robin Petit, Wouter Verbeke, Gianluca Bontempi</li>
<li>for: 本研究旨在探讨机器学习技术在决策中的可加价效应，并对相关的论证和实践提供了一个全面的探讨。</li>
<li>methods: 本研究使用了一种既包含了机器学习技术又具有 causal orientation 的方法，并对这种方法的性能进行了 theoretically 的分析和实践验证。</li>
<li>results: 研究结果显示，在某些情况下，可加价模型会在predictive 模型之上带来更高的效果，但是这些情况下的参数会影响这种效果。研究还发现，mutual information 和 estimator variance 等参数具有重要作用。<details>
<summary>Abstract</summary>
Despite the growing popularity of machine-learning techniques in decision-making, the added value of causal-oriented strategies with respect to pure machine-learning approaches has rarely been quantified in the literature. These strategies are crucial for practitioners in various domains, such as marketing, telecommunications, health care and finance. This paper presents a comprehensive treatment of the subject, starting from firm theoretical foundations and highlighting the parameters that influence the performance of the uplift and predictive approaches. The focus of the paper is on a binary outcome case and a binary action, and the paper presents a theoretical analysis of uplift modeling, comparing it with the classical predictive approach. The main research contributions of the paper include a new formulation of the measure of profit, a formal proof of the convergence of the uplift curve to the measure of profit ,and an illustration, through simulations, of the conditions under which predictive approaches still outperform uplift modeling. We show that the mutual information between the features and the outcome plays a significant role, along with the variance of the estimators, the distribution of the potential outcomes and the underlying costs and benefits of the treatment and the outcome.
</details>
<details>
<summary>摘要</summary>
The main research contributions of the paper include:1. A new formulation of the measure of profit.2. A formal proof of the convergence of the uplift curve to the measure of profit.3. An illustration, through simulations, of the conditions under which predictive approaches still outperform uplift modeling.We show that the mutual information between the features and the outcome plays a significant role, along with the variance of the estimators, the distribution of the potential outcomes, and the underlying costs and benefits of the treatment and the outcome.
</details></li>
</ul>
<hr>
<h2 id="Human-in-the-Loop-Causal-Discovery-under-Latent-Confounding-using-Ancestral-GFlowNets"><a href="#Human-in-the-Loop-Causal-Discovery-under-Latent-Confounding-using-Ancestral-GFlowNets" class="headerlink" title="Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets"></a>Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12032">http://arxiv.org/abs/2309.12032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiago da Silva, Eliezer Silva, Adèle Ribeiro, António Góis, Dominik Heider, Samuel Kaski, Diego Mesquita</li>
<li>for: 提高 causal inference 的精度，尤其是在数据稀缺时，避免因为 latent confounders 的影响而导致的不准确的 causal relation 推断。</li>
<li>methods: 提出一种基于 generative flow networks 的方法，通过在 candidate graphs 中采样 proportionally to a belief distribution 以及通过对 experts 的反馈来 iteratively 缩小 uncertainty 。</li>
<li>results: 通过实验表明，该方法可以准确地采样 ancestral graphs  distribution，并且可以通过人类反馈来改进推断质量。<details>
<summary>Abstract</summary>
Structure learning is the crux of causal inference. Notably, causal discovery (CD) algorithms are brittle when data is scarce, possibly inferring imprecise causal relations that contradict expert knowledge -- especially when considering latent confounders. To aggravate the issue, most CD methods do not provide uncertainty estimates, making it hard for users to interpret results and improve the inference process. Surprisingly, while CD is a human-centered affair, no works have focused on building methods that both 1) output uncertainty estimates that can be verified by experts and 2) interact with those experts to iteratively refine CD. To solve these issues, we start by proposing to sample (causal) ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC), using generative flow networks. Then, we leverage the diversity in candidate graphs and introduce an optimal experimental design to iteratively probe the expert about the relations among variables, effectively reducing the uncertainty of our belief over ancestral graphs. Finally, we update our samples to incorporate human feedback via importance sampling. Importantly, our method does not require causal sufficiency (i.e., unobserved confounders may exist). Experiments with synthetic observational data show that our method can accurately sample from distributions over ancestral graphs and that we can greatly improve inference quality with human aid.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Structure learning is the crux of causal inference. Notably, causal discovery (CD) algorithms are brittle when data is scarce, possibly inferring imprecise causal relations that contradict expert knowledge -- especially when considering latent confounders. To aggravate the issue, most CD methods do not provide uncertainty estimates, making it hard for users to interpret results and improve the inference process. Surprisingly, while CD is a human-centered affair, no works have focused on building methods that both 1) output uncertainty estimates that can be verified by experts and 2) interact with those experts to iteratively refine CD. To solve these issues, we start by proposing to sample (causal) ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC), using generative flow networks. Then, we leverage the diversity in candidate graphs and introduce an optimal experimental design to iteratively probe the expert about the relations among variables, effectively reducing the uncertainty of our belief over ancestral graphs. Finally, we update our samples to incorporate human feedback via importance sampling. Importantly, our method does not require causal sufficiency (i.e., unobserved confounders may exist). Experiments with synthetic observational data show that our method can accurately sample from distributions over ancestral graphs and that we can greatly improve inference quality with human aid."中文翻译：<<SYS>> translate "结构学习是 causal inference 的核心。特别是在数据稀缺时， causal discovery（CD）算法容易导致不准确的 causal 关系推断，而且这些关系可能与专家知识相悖。此外，大多数 CD 方法不提供不确定性估计，使得用户不能正确地 интерпретирова结果并改进推断过程。很奇怪的是，CD 是人类中心的事物，但没有任何研究旨在构建可以 outputs 不确定性估计并且与专家交互改进 CD 的方法。为解决这些问题，我们开始由 proposing 使用 generative flow 网络来样本 (causal) 祖先图 proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC)。然后，我们利用候选图的多样性并引入最佳实验设计，以便逐次询问专家关于变量之间的关系，从而减少我们对祖先图的不确定性。最后，我们更新样本以包括人类反馈 via importance sampling。重要的是，我们的方法不需要 causal sufficiency (i.e., unobserved confounders may exist)。我们在 sintetic observational data 上进行了实验，结果表明我们的方法可以准确样本 distribution over ancestral graphs，并且可以通过人类帮助提高推断质量。
</details></li>
</ul>
<hr>
<h2 id="Robust-Approximation-Algorithms-for-Non-monotone-k-Submodular-Maximization-under-a-Knapsack-Constraint"><a href="#Robust-Approximation-Algorithms-for-Non-monotone-k-Submodular-Maximization-under-a-Knapsack-Constraint" class="headerlink" title="Robust Approximation Algorithms for Non-monotone $k$-Submodular Maximization under a Knapsack Constraint"></a>Robust Approximation Algorithms for Non-monotone $k$-Submodular Maximization under a Knapsack Constraint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12025">http://arxiv.org/abs/2309.12025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tantdhvan/KSE2023">https://github.com/tantdhvan/KSE2023</a></li>
<li>paper_authors: Dung T. K. Ha, Canh V. Pham, Tan D. Tran, Huan X. Hoang</li>
<li>for: 提出了一个非MONOTONE $k$-submodular最大化问题，用于数据概要、信息传递等应用。</li>
<li>methods: 提出了两种杜林约化算法，可以在$O(nk)$查询复杂度下提供竞争性提高的解。</li>
<li>results: 算法可以在$O(nk)$查询复杂度下提供常数约化比率，比现有算法快速返回解。实验结果也证明了算法的理论分析和实际效果。<details>
<summary>Abstract</summary>
The problem of non-monotone $k$-submodular maximization under a knapsack constraint ($\kSMK$) over the ground set size $n$ has been raised in many applications in machine learning, such as data summarization, information propagation, etc. However, existing algorithms for the problem are facing questioning of how to overcome the non-monotone case and how to fast return a good solution in case of the big size of data. This paper introduces two deterministic approximation algorithms for the problem that competitively improve the query complexity of existing algorithms.   Our first algorithm, $\LAA$, returns an approximation ratio of $1/19$ within $O(nk)$ query complexity. The second one, $\RLA$, improves the approximation ratio to $1/5-\epsilon$ in $O(nk)$ queries, where $\epsilon$ is an input parameter.   Our algorithms are the first ones that provide constant approximation ratios within only $O(nk)$ query complexity for the non-monotone objective. They, therefore, need fewer the number of queries than state-of-the-the-art ones by a factor of $\Omega(\log n)$.   Besides the theoretical analysis, we have evaluated our proposed ones with several experiments in some instances: Influence Maximization and Sensor Placement for the problem. The results confirm that our algorithms ensure theoretical quality as the cutting-edge techniques and significantly reduce the number of queries.
</details>
<details>
<summary>摘要</summary>
“非单调 $k$-submodular最大化问题（$\kSMK$) 在机器学习应用中得到了很多关注，例如摘要、信息传递等。然而，现有的算法对这个问题存在两个问题：一是如何解决非单调情况，二是如何快速返回良好的解决方案。本文提出了两个决定性近似算法，它们可以对 $\kSMK$ 问题提供竞争性提高查询量的解决方案。我们的第一个算法（$\LAA$）可以在 $O(nk)$ 查询量下提供一个近似比率为 $1/19$。第二个算法（$\RLA$）可以在 $O(nk)$ 查询量下提供一个近似比率为 $1/5-\epsilon$，其中 $\epsilon$ 是输入参数。我们的算法是第一个可以在非单调情况下提供常数近似比率，并且需要 fewer 查询量 than state-of-the-art 的一个因数为 $\Omega(\log n)$。”Note that the translation is in Simplified Chinese, which is one of the two standardized Chinese writing systems. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-SAEAs-with-Unevaluated-Solutions-A-Case-Study-of-Relation-Model-for-Expensive-Optimization"><a href="#Enhancing-SAEAs-with-Unevaluated-Solutions-A-Case-Study-of-Relation-Model-for-Expensive-Optimization" class="headerlink" title="Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization"></a>Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11994">http://arxiv.org/abs/2309.11994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Hao, Xiaoqun Zhang, Aimin Zhou</li>
<li>for: 提高优化问题的解决效率（EOPs）中的质量解决方案。</li>
<li>methods: 使用模型帮助选择技术来提高SAEAs的效率。</li>
<li>results: 在两个测试集上，使用关系模型选择未评估解决方案可以更好地提高算法的效率，并且这些未评估解决方案具有高潜力。<details>
<summary>Abstract</summary>
Surrogate-assisted evolutionary algorithms (SAEAs) hold significant importance in resolving expensive optimization problems~(EOPs). Extensive efforts have been devoted to improving the efficacy of SAEAs through the development of proficient model-assisted selection methods. However, generating high-quality solutions is a prerequisite for selection. The fundamental paradigm of evaluating a limited number of solutions in each generation within SAEAs reduces the variance of adjacent populations, thus impacting the quality of offspring solutions. This is a frequently encountered issue, yet it has not gained widespread attention. This paper presents a framework using unevaluated solutions to enhance the efficiency of SAEAs. The surrogate model is employed to identify high-quality solutions for direct generation of new solutions without evaluation. To ensure dependable selection, we have introduced two tailored relation models for the selection of the optimal solution and the unevaluated population. A comprehensive experimental analysis is performed on two test suites, which showcases the superiority of the relation model over regression and classification models in the selection phase. Furthermore, the surrogate-selected unevaluated solutions with high potential have been shown to significantly enhance the efficiency of the algorithm.
</details>
<details>
<summary>摘要</summary>
受助者质量进化算法（SAEA）在解决成本高优化问题（EOP）方面具有重要意义。针对提高 SAEA 的效果，广泛的努力已经投入到了开发高效的模型协助选择方法上。然而，生成高质量解决方案是选择高质量解决方案的先置条件。SAEA 中评估每代限制的解决方案的基本思想会减少邻居 populations 的方差，从而影响下一代解决方案的质量。这是一个 часто遇到的问题，但它尚未受到广泛的关注。本文提出了一种使用未评估解决方案来提高 SAEA 的效率的框架。使用 surrogate 模型来标识高质量解决方案，然后直接生成新的解决方案。为保证可靠的选择，我们引入了两种特制的关系模型，一种用于选择优质解决方案，另一种用于选择未评估 популяции。通过对两个测试集进行了全面的实验分析，我们展示了模型在选择阶段的优越性，以及 surrogate 选择的未评估解决方案具有显著提高 SAEA 效率的作用。
</details></li>
</ul>
<hr>
<h2 id="Variational-Connectionist-Temporal-Classification-for-Order-Preserving-Sequence-Modeling"><a href="#Variational-Connectionist-Temporal-Classification-for-Order-Preserving-Sequence-Modeling" class="headerlink" title="Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling"></a>Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11983">http://arxiv.org/abs/2309.11983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Nan, Ting Dang, Vidhyasaharan Sethu, Beena Ahmed</li>
<li>for: This paper is written for researchers and practitioners working on sequence modeling tasks, particularly in the area of speech recognition, who are interested in using CTC with variational models to improve the generalization of their models and handle data variability.</li>
<li>methods: The paper proposes integrating CTC with a variational model, and derives two versions of a novel variational CTC loss function based on reasonable assumptions about the latent variables. The loss functions allow direct optimization of the variational lower bound for the model log-likelihood, and are computationally tractable.</li>
<li>results: The paper presents the results of training sequence models using the proposed variational CTC loss functions, and shows that they lead to more generalizable models that preserve order in the input and target sequences. The results demonstrate the effectiveness of the proposed approach in handling data variability and improving the performance of sequence models.<details>
<summary>Abstract</summary>
Connectionist temporal classification (CTC) is commonly adopted for sequence modeling tasks like speech recognition, where it is necessary to preserve order between the input and target sequences. However, CTC is only applied to deterministic sequence models, where the latent space is discontinuous and sparse, which in turn makes them less capable of handling data variability when compared to variational models. In this paper, we integrate CTC with a variational model and derive loss functions that can be used to train more generalizable sequence models that preserve order. Specifically, we derive two versions of the novel variational CTC based on two reasonable assumptions, the first being that the variational latent variables at each time step are conditionally independent; and the second being that these latent variables are Markovian. We show that both loss functions allow direct optimization of the variational lower bound for the model log-likelihood, and present computationally tractable forms for implementing them.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用 Connectionist Temporal Classification (CTC) 是一种常用的序列模型化任务，如语音识别，因为它需要保持输入和目标序列之间的顺序关系。然而，CTC 只适用于决定性序列模型，其潜在空间是离散的和稀疏的，这使得它们在面对数据变化时比较不能处理。在这篇论文中，我们将 CT 与变量模型结合，并 derive loss functions 可以用来训练更一般化的序列模型，保持顺序。 Specifically，我们 deriv 两个版本的新的变量 CT 基于两个合理的假设：第一个假设是变量 latent 在每个时间步是独立的；第二个假设是这些 latent 变量是 Markovian。我们显示了这两个损失函数可以直接优化变量下界，并提供了实现的计算 tractable 形式。Note: "Simplified Chinese" is a romanization of the Chinese language that uses a simplified set of characters and pronunciation, which is commonly used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Generating-Hierarchical-Structures-for-Improved-Time-Series-Classification-Using-Stochastic-Splitting-Functions"><a href="#Generating-Hierarchical-Structures-for-Improved-Time-Series-Classification-Using-Stochastic-Splitting-Functions" class="headerlink" title="Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions"></a>Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11963">http://arxiv.org/abs/2309.11963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alagoz/hc4tsc_hdc_ssf">https://github.com/alagoz/hc4tsc_hdc_ssf</a></li>
<li>paper_authors: Celal Alagoz</li>
<li>For: The paper is written for enhancing classification performance in multi-class datasets through hierarchical classification.* Methods: The paper introduces a novel hierarchical divisive clustering approach with stochastic splitting functions (SSFs) to generate hierarchy without requiring explicit information.* Results: The approach significantly improves classification performance in approximately half and a third of the datasets when using rocket and svm as the classifier, respectively. The study also explores the relationship between dataset features and HC performance.Here is the simplified Chinese text for the three key points:* For: 这篇论文是为了提高多类数据集中的分类性能而写的。* Methods: 论文提出了一种基于杂素分割函数（SSF）的层次分类方法，可以不需要明确的层次信息来生成层次结构。* Results: 实验结果表明，该方法在使用rocket和svm分类器时，在约半数和一third的数据集中能够显著提高分类性能。<details>
<summary>Abstract</summary>
This study introduces a novel hierarchical divisive clustering approach with stochastic splitting functions (SSFs) to enhance classification performance in multi-class datasets through hierarchical classification (HC). The method has the unique capability of generating hierarchy without requiring explicit information, making it suitable for datasets lacking prior knowledge of hierarchy. By systematically dividing classes into two subsets based on their discriminability according to the classifier, the proposed approach constructs a binary tree representation of hierarchical classes. The approach is evaluated on 46 multi-class time series datasets using popular classifiers (svm and rocket) and SSFs (potr, srtr, and lsoo). The results reveal that the approach significantly improves classification performance in approximately half and a third of the datasets when using rocket and svm as the classifier, respectively. The study also explores the relationship between dataset features and HC performance. While the number of classes and flat classification (FC) score show consistent significance, variations are observed with different splitting functions. Overall, the proposed approach presents a promising strategy for enhancing classification by generating hierarchical structure in multi-class time series datasets. Future research directions involve exploring different splitting functions, classifiers, and hierarchy structures, as well as applying the approach to diverse domains beyond time series data. The source code is made openly available to facilitate reproducibility and further exploration of the method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Probability-of-Immunity"><a href="#On-the-Probability-of-Immunity" class="headerlink" title="On the Probability of Immunity"></a>On the Probability of Immunity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11942">http://arxiv.org/abs/2309.11942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZahirSen/scaling-octo-guide">https://github.com/ZahirSen/scaling-octo-guide</a></li>
<li>paper_authors: Jose M. Peña</li>
<li>for: 本研究探讨了免疫机会的概率，即是否曝露对结果的影响。</li>
<li>methods: 我们 derive了免疫必要和 suficient conditions，以及 $\epsilon$-bounded免疫，即免疫概率为零和 $\epsilon$-bounded的情况。</li>
<li>results: 我们可以从随机控制试验中估计受益的概率（即曝露导致效果），并且可以生成更紧的受益概率 bounds。此外，我们还引入了间接免疫（通过介质）的概念，并重复了我们之前的分析。最后，我们提出了对免疫概率下无量化影响的敏感分析方法。<details>
<summary>Abstract</summary>
This work is devoted to the study of the probability of immunity, i.e. the effect occurs whether exposed or not. We derive necessary and sufficient conditions for non-immunity and $\epsilon$-bounded immunity, i.e. the probability of immunity is zero and $\epsilon$-bounded, respectively. The former allows us to estimate the probability of benefit (i.e., the effect occurs if and only if exposed) from a randomized controlled trial, and the latter allows us to produce bounds of the probability of benefit that are tighter than the existing ones. We also introduce the concept of indirect immunity (i.e., through a mediator) and repeat our previous analysis for it. Finally, we propose a method for sensitivity analysis of the probability of immunity under unmeasured confounding.
</details>
<details>
<summary>摘要</summary>
这项研究探讨了免疫概率的可能性，即效果发生或不发生。我们 deriv出了免疫必要和 suficient conditions，即免疫概率为零和ε-bounded免疫概率，分别表示效果发生和ε-bounded的免疫概率。前者允许我们从Randomized controlled trial中估算效果发生的概率，而后者允许我们生成更紧的效果发生的概率上限。我们还介绍了间接免疫（通过介质）的概念，并重复了我们的前一次分析。最后，我们提出了对免疫概率下隐藏偏见的敏感分析方法。Note: "ε-bounded" in the text refers to the probability of immunity being bounded above by a small positive value ε.
</details></li>
</ul>
<hr>
<h2 id="A-Machine-Learning-oriented-Survey-on-Tiny-Machine-Learning"><a href="#A-Machine-Learning-oriented-Survey-on-Tiny-Machine-Learning" class="headerlink" title="A Machine Learning-oriented Survey on Tiny Machine Learning"></a>A Machine Learning-oriented Survey on Tiny Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11932">http://arxiv.org/abs/2309.11932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luigi Capogrosso, Federico Cunico, Dong Seon Cheng, Franco Fummi, Marco cristani</li>
<li>for: 这篇论文旨在为tiny machine learning（TinyML）领域的研究提供一个权威的综述，尤其是关于TinyML中的学习算法。</li>
<li>methods: 本文采用了PRISMA方法流程进行系统性的文献综述，分为三个工作流程：ML-oriented、HW-oriented和合理设计。</li>
<li>results: 本文提出了TinyML学习领域的分类体系，涵盖了不同家族的模型优化和设计，以及当前领域的最佳实践。<details>
<summary>Abstract</summary>
The emergence of Tiny Machine Learning (TinyML) has positively revolutionized the field of Artificial Intelligence by promoting the joint design of resource-constrained IoT hardware devices and their learning-based software architectures. TinyML carries an essential role within the fourth and fifth industrial revolutions in helping societies, economies, and individuals employ effective AI-infused computing technologies (e.g., smart cities, automotive, and medical robotics). Given its multidisciplinary nature, the field of TinyML has been approached from many different angles: this comprehensive survey wishes to provide an up-to-date overview focused on all the learning algorithms within TinyML-based solutions. The survey is based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow, allowing for a systematic and complete literature survey. In particular, firstly we will examine the three different workflows for implementing a TinyML-based system, i.e., ML-oriented, HW-oriented, and co-design. Secondly, we propose a taxonomy that covers the learning panorama under the TinyML lens, examining in detail the different families of model optimization and design, as well as the state-of-the-art learning techniques. Thirdly, this survey will present the distinct features of hardware devices and software tools that represent the current state-of-the-art for TinyML intelligent edge applications. Finally, we discuss the challenges and future directions.
</details>
<details>
<summary>摘要</summary>
《tiny machine learning（tinyml）的出现》已经对人工智能（ai）领域产生了积极的革命，推动了资源受限的iot设备和其学习基础架构的共同设计。 tinyml在第四和第五个工业革命中发挥着重要的角色，帮助社会、经济和个人使用有效的ai混合计算技术（例如智能城市、汽车和医疗机器人）。由于tinyml的多学科性，该领域被不同的方向攻击：本综述旨在提供tinyml基础设施中所有学习算法的全面检视。本综述采用《Preferred Reporting Items for Systematic Reviews and Meta-Analyses》（prisma）方法流程，以系统和完整的方式检查文献。特别是，我们首先检查tinyml基础设施实施的三种不同工作流程，即ml oriented、hw oriented和codesign。其次，我们提出了tinyml学习领域的分类，审查ml下的不同家族模型优化和设计，以及当前领域的state-of-the-art学习技术。最后，本综述将展示当前tinyml智能边缘应用中的硬件设备和软件工具的最新状态。 Finally, we discuss the challenges and future directions.
</details></li>
</ul>
<hr>
<h2 id="Activation-Compression-of-Graph-Neural-Networks-using-Block-wise-Quantization-with-Improved-Variance-Minimization"><a href="#Activation-Compression-of-Graph-Neural-Networks-using-Block-wise-Quantization-with-Improved-Variance-Minimization" class="headerlink" title="Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization"></a>Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11856">http://arxiv.org/abs/2309.11856</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/saintslab/i-exact">https://github.com/saintslab/i-exact</a></li>
<li>paper_authors: Sebastian Eliassen, Raghavendra Selvan</li>
<li>for: 提高大规模图 neural network 的训练效率，尤其是减少内存消耗。</li>
<li>methods: 使用极端活动压缩（EXACT）策略，对中间激活图进行量化，从 INT2 精度下进行压缩，以实现大幅减少 GPU 内存消耗，而无需做出重要性的牺牲。</li>
<li>results: 在 EXACT 策略的基础上，使用块级别的量化策略，可以进一步减少内存消耗（&gt;15%），并且在每个 epoch 中提高运行速度（约 5%），即使在执行极端的量化时也可以保持相似的性能交易。此外，对 EXACT 中间激活图分布的假设（假设为均匀分布）进行了更正，并提供了改进的量化和解量化步骤的方差估计。<details>
<summary>Abstract</summary>
Efficient training of large-scale graph neural networks (GNNs) has been studied with a specific focus on reducing their memory consumption. Work by Liu et al. (2022) proposed extreme activation compression (EXACT) which demonstrated drastic reduction in memory consumption by performing quantization of the intermediate activation maps down to using INT2 precision. They showed little to no reduction in performance while achieving large reductions in GPU memory consumption. In this work, we present an improvement to the EXACT strategy by using block-wise quantization of the intermediate activation maps. We experimentally analyze different block sizes and show further reduction in memory consumption (>15%), and runtime speedup per epoch (about 5%) even when performing extreme extents of quantization with similar performance trade-offs as with the original EXACT. Further, we present a correction to the assumptions on the distribution of intermediate activation maps in EXACT (assumed to be uniform) and show improved variance estimations of the quantization and dequantization steps.
</details>
<details>
<summary>摘要</summary>
大规模图 neural network (GNN) 的高效训练已经被研究，特别是减少它们的内存消耗。工作 by Liu et al. (2022) 提出了极化活动压缩 (EXACT)，通过对中间活动图进行量化，以 INT2 精度进行压缩。他们发现了很少到无关于性能的下降，同时实现了大量的 GPU 内存消耗减少。在这个工作中，我们提出了对 EXACT 策略的改进，通过分割 activation map 的块式压缩。我们通过不同的块大小进行实验分析，并证明了更大的减少内存消耗（> 15%）和每个轮次的运行速度增加（约 5%），即使在执行极端的量化时，与原始 EXACT 的性能折衔保持相同。此外，我们对 EXACT 中对中间活动图的分布假设（假设为均匀分布）进行了修正，并提供了改进的量化和解量化步骤的方差估计。
</details></li>
</ul>
<hr>
<h2 id="TMac-Temporal-Multi-Modal-Graph-Learning-for-Acoustic-Event-Classification"><a href="#TMac-Temporal-Multi-Modal-Graph-Learning-for-Acoustic-Event-Classification" class="headerlink" title="TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification"></a>TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11845">http://arxiv.org/abs/2309.11845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mgithubl/tmac">https://github.com/mgithubl/tmac</a></li>
<li>paper_authors: Meng Liu, Ke Liang, Dayu Hu, Hao Yu, Yue Liu, Lingyuan Meng, Wenxuan Tu, Sihang Zhou, Xinwang Liu<br>for:This paper proposes a method for acoustic event classification using temporal multi-modal graph learning, which can better handle the information of multi-modal data with temporal attributes.methods:The proposed method, called TMac, constructs a temporal graph for each acoustic event, dividing its audio and video data into multiple segments and modeling the temporal relationships between them using graph learning techniques.results:Experiments show that TMac outperforms other state-of-the-art models in performance, demonstrating its effectiveness in capturing the dynamic information in intra-modal and inter-modal data. The code is available at <a target="_blank" rel="noopener" href="https://github.com/MGitHubL/TMac.Here">https://github.com/MGitHubL/TMac.Here</a> is the simplified Chinese text:for:这篇论文提出了一种基于时间多模式图学习的声音事件分类方法，可以更好地处理具有时间属性的多模式数据。methods:该方法，称为TMac，对声音事件进行分解，将其声音数据和视频数据分割成多个segment，然后使用图学习技术来模型这些segment之间的时间关系。results:实验表明，TMac比其他状态对应模型更高效，能够更好地捕捉多模式数据中的内部和间部关系。代码可以在<a target="_blank" rel="noopener" href="https://github.com/MGitHubL/TMac%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/MGitHubL/TMac上下载。</a><details>
<summary>Abstract</summary>
Audiovisual data is everywhere in this digital age, which raises higher requirements for the deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual modal. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning techniques. In particular, we construct a temporal graph for each acoustic event, dividing its audio data and video data into multiple segments. Each segment can be considered as a node, and the temporal relationships between nodes can be considered as timestamps on their edges. In this case, we can smoothly capture the dynamic information in intra-modal and inter-modal. Several experiments are conducted to demonstrate TMac outperforms other SOTA models in performance. Our code is available at https://github.com/MGitHubL/TMac.
</details>
<details>
<summary>摘要</summary>
现在的数字时代，audiovisual数据在 everywhere，这 heightened the requirements for the deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual experience. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning techniques. In particular, we construct a temporal graph for each acoustic event, dividing its audio data and video data into multiple segments. Each segment can be considered as a node, and the temporal relationships between nodes can be considered as timestamps on their edges. In this case, we can smoothly capture the dynamic information in intra-modal and inter-modal. Several experiments are conducted to demonstrate TMac outperforms other SOTA models in performance. Our code is available at https://github.com/MGitHubL/TMac.Note: "Simplified Chinese" is a romanization of the Chinese language that uses a simplified set of characters and grammar rules to represent the language in a more phonetic and easier-to-learn format. The translation above is written in Simplified Chinese, but the original text is in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Review-of-Community-Detection-in-Graphs"><a href="#A-Comprehensive-Review-of-Community-Detection-in-Graphs" class="headerlink" title="A Comprehensive Review of Community Detection in Graphs"></a>A Comprehensive Review of Community Detection in Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11798">http://arxiv.org/abs/2309.11798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songlai Ning, Jiakang Li, Yonggang Lu</li>
<li>for: 本文探讨了图像中的社区结构，强调了图像中的社区结构的探讨，以及社区结构的探讨在不同领域的应用。</li>
<li>methods: 本文介绍了多种社区检测方法，包括一种新的方法，并对这些方法进行了详细的介绍。</li>
<li>results: 本文总结了社区检测方法的发展历程，并对社区检测的应用在不同领域进行了探讨。<details>
<summary>Abstract</summary>
The study of complex networks has significantly advanced our understanding of community structures which serves as a crucial feature of real-world graphs. Detecting communities in graphs is a challenging problem with applications in sociology, biology, and computer science. Despite the efforts of an interdisciplinary community of scientists, a satisfactory solution to this problem has not yet been achieved. This review article delves into the topic of community detection in graphs, which serves as a crucial role in understanding the organization and functioning of complex systems. We begin by introducing the concept of community structure, which refers to the arrangement of vertices into clusters, with strong internal connections and weaker connections between clusters. Then, we provide a thorough exposition of various community detection methods, including a new method designed by us. Additionally, we explore real-world applications of community detection in diverse networks. In conclusion, this comprehensive review provides a deep understanding of community detection in graphs. It serves as a valuable resource for researchers and practitioners in multiple disciplines, offering insights into the challenges, methodologies, and applications of community detection in complex networks.
</details>
<details>
<summary>摘要</summary>
学术研究复杂网络已经有了大量的进展，我们对复杂网络中社区结构的理解得到了重要进步。检测复杂网络中的社区是一个具有挑战性的问题，在社会学、生物学和计算机科学等领域都有着广泛的应用。尽管一群来自不同领域的科学家努力奔走，但是满意的解决方案还没有得到。这篇评论文章将探讨复杂网络中的社区检测问题，这是理解复杂系统的组织和运作的关键部分。我们首先介绍社区结构的概念，即顶点的分布到群集中，群集之间的连接较弱。然后，我们对各种社区检测方法进行了详细的介绍，包括我们新提出的方法。此外，我们还探讨了不同网络中社区检测的实际应用。 conclude，这篇评论文章为研究者和实践者在多种领域提供了深入的理解社区检测在复杂网络中的挑战、方法和应用。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Preserving-In-Context-Learning-with-Differentially-Private-Few-Shot-Generation"><a href="#Privacy-Preserving-In-Context-Learning-with-Differentially-Private-Few-Shot-Generation" class="headerlink" title="Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"></a>Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11765">http://arxiv.org/abs/2309.11765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/dp-few-shot-generation">https://github.com/microsoft/dp-few-shot-generation</a></li>
<li>paper_authors: Xinyu Tang, Richard Shin, Huseyin A. Inan, Andre Manoel, Fatemehsadat Mireshghallah, Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Robert Sim</li>
<li>for: 实现隐私对称学习（ICL）大语言模型（LLM）上private dataset。</li>
<li>methods: 提出了一个新的算法，将私人集成的几个示例通过正式数据隐私（DP）保证生成为几个实验示例，并证明了它可以实现有效的ICL。</li>
<li>results: 实验结果显示，我们的算法可以与高度隐私水平相当的实现优异的性能，并且与非私人ICL和零例解决方案相比，具有更好的缩减性和更高的可重用性。<details>
<summary>Abstract</summary>
We study the problem of in-context learning (ICL) with large language models (LLMs) on private datasets. This scenario poses privacy risks, as LLMs may leak or regurgitate the private examples demonstrated in the prompt. We propose a novel algorithm that generates synthetic few-shot demonstrations from the private dataset with formal differential privacy (DP) guarantees, and show empirically that it can achieve effective ICL. We conduct extensive experiments on standard benchmarks and compare our algorithm with non-private ICL and zero-shot solutions. Our results demonstrate that our algorithm can achieve competitive performance with strong privacy levels. These results open up new possibilities for ICL with privacy protection for a broad range of applications.
</details>
<details>
<summary>摘要</summary>
我们研究在私有数据集上使用大语言模型（LLM）进行上下文学习（ICL）问题，这种情况可能会导致隐私泄露或模型重复示例。我们提出了一种新的算法，通过从私有数据集生成几拍示例，并提供正式的差分隐私（DP）保证，以实现有效的ICL。我们进行了广泛的实验，并与非私有ICL和零shot解决方案进行比较。我们的结果表明，我们的算法可以实现竞争性的性能，同时保证高度的隐私水平。这些结果开 up了新的可能性，使得ICL中的隐私保护可以推广到许多应用程序。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Optimal-SDG-Pathways-An-Innovative-Approach-Leveraging-Graph-Pruning-and-Intent-Graph-for-Effective-Recommendations"><a href="#Unveiling-Optimal-SDG-Pathways-An-Innovative-Approach-Leveraging-Graph-Pruning-and-Intent-Graph-for-Effective-Recommendations" class="headerlink" title="Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph Pruning and Intent Graph for Effective Recommendations"></a>Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph Pruning and Intent Graph for Effective Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11741">http://arxiv.org/abs/2309.11741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihang Yu, Shu Wang, Yunqiang Zhu, Wen Yuan, Xiaoliang Dai, Zhiqiang Zou</li>
<li>for: 提出了一种基于用户图 после剪裁和意图图（UGPIG）方法，用于解决现有计算机科学领域推荐算法不能充分考虑地区环境特点和历史互动数据稀缺性的问题，以提高可持续发展模式的推荐效果。</li>
<li>methods: 该方法首先利用了剪裁后用户图的高密度链接能力，解决了推荐算法忽略地区空间不同性的问题。其次，通过建立意图图，capture了目标地区Attributes的偏好，有效地解决了历史互动数据稀缺性问题。</li>
<li>results: 经过广泛的实验，UGPIG方法在可持续发展模式推荐方面比现有的推荐算法（KGCN、KGAT、KGIN）高效，最大提升9.61%。<details>
<summary>Abstract</summary>
The recommendation of appropriate development pathways, also known as ecological civilization patterns for achieving Sustainable Development Goals (namely, sustainable development patterns), are of utmost importance for promoting ecological, economic, social, and resource sustainability in a specific region. To achieve this, the recommendation process must carefully consider the region's natural, environmental, resource, and economic characteristics. However, current recommendation algorithms in the field of computer science fall short in adequately addressing the spatial heterogeneity related to environment and sparsity of regional historical interaction data, which limits their effectiveness in recommending sustainable development patterns. To overcome these challenges, this paper proposes a method called User Graph after Pruning and Intent Graph (UGPIG). Firstly, we utilize the high-density linking capability of the pruned User Graph to address the issue of spatial heterogeneity neglect in recommendation algorithms. Secondly, we construct an Intent Graph by incorporating the intent network, which captures the preferences for attributes including environmental elements of target regions. This approach effectively alleviates the problem of sparse historical interaction data in the region. Through extensive experiments, we demonstrate that UGPIG outperforms state-of-the-art recommendation algorithms like KGCN, KGAT, and KGIN in sustainable development pattern recommendations, with a maximum improvement of 9.61% in Top-3 recommendation performance.
</details>
<details>
<summary>摘要</summary>
“ ecovillage civilization ”模式的建议，即可持续发展目标的实现，对于某地区的生态、经济、社会和资源可持续发展具有极其重要的作用。为了实现这一目标，建议过程应当考虑该地区的自然、环境、资源和经济特点。然而，当前的计算机科学领域的推荐算法尚未能充分考虑地域间的空间不同性和历史互动数据的稀缺性，这限制了它们在可持续发展模式的推荐上的效果。为了解决这些挑战，本文提出了一种方法called User Graph after Pruning and Intent Graph (UGPIG)。首先，我们利用了剪除后的用户图高密度链接能力，解决了推荐算法忽视地域间空间不同性的问题。其次，我们构建了意图图， capture 目标区域的环境元素的偏好。这种方法有效地解决了历史互动数据稀缺性问题。经过广泛的实验，我们证明UGPIG可以比state-of-the-art推荐算法like KGCN、KGAT和KGIN在可持续发展模式的推荐上表现出较高的Top-3推荐性能，最大提升率为9.61%。
</details></li>
</ul>
<hr>
<h2 id="Turaco-Complexity-Guided-Data-Sampling-for-Training-Neural-Surrogates-of-Programs"><a href="#Turaco-Complexity-Guided-Data-Sampling-for-Training-Neural-Surrogates-of-Programs" class="headerlink" title="Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates of Programs"></a>Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates of Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11726">http://arxiv.org/abs/2309.11726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Renda, Yi Ding, Michael Carbin</li>
<li>for: 本研究旨在提供一种方法ология，用于在训练神经网络模型时，从程序的输入空间中采样数据，以优化模型的准确性。</li>
<li>methods: 本研究使用了一种基于程序执行路径的复杂性分析方法，以确定采样数据的比例，并使用神经网络模型来训练代理模型。</li>
<li>results: 实验结果表明，基于复杂性分析的采样方法可以提高模型的准确性，并且在各种真实世界程序中进行了成功应用。<details>
<summary>Abstract</summary>
Programmers and researchers are increasingly developing surrogates of programs, models of a subset of the observable behavior of a given program, to solve a variety of software development challenges. Programmers train surrogates from measurements of the behavior of a program on a dataset of input examples. A key challenge of surrogate construction is determining what training data to use to train a surrogate of a given program.   We present a methodology for sampling datasets to train neural-network-based surrogates of programs. We first characterize the proportion of data to sample from each region of a program's input space (corresponding to different execution paths of the program) based on the complexity of learning a surrogate of the corresponding execution path. We next provide a program analysis to determine the complexity of different paths in a program. We evaluate these results on a range of real-world programs, demonstrating that complexity-guided sampling results in empirical improvements in accuracy.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法来采样培训数据，以训练基于神经网络的代程模型。我们首先量化程序输入空间中每个执行路径的学习复杂性，然后根据复杂性来决定从哪些地方采样数据。接着，我们通过程序分析来确定不同路径的复杂性。我们对多个实际Program进行评估，并证明了复杂性导向采样的实际改进精度。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Core-selecting-Incentive-Mechanism-for-Data-Sharing-in-Federated-Learning"><a href="#Efficient-Core-selecting-Incentive-Mechanism-for-Data-Sharing-in-Federated-Learning" class="headerlink" title="Efficient Core-selecting Incentive Mechanism for Data Sharing in Federated Learning"></a>Efficient Core-selecting Incentive Mechanism for Data Sharing in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11722">http://arxiv.org/abs/2309.11722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengda Ji, Genjiu Xu, Jianjun Ge, Mingqiang Li</li>
<li>for: 这个论文的目的是设计一种激励机制，使参与者输入真实数据，并稳定合作。</li>
<li>methods: 这个论文使用游戏理论的核心概念来设计核心选择机制，并使用放弃方法和采样approximation来降低计算开销。</li>
<li>results: 实验表明，这种高效的核心选择机制可以激励参与者输入高质量数据，并且可以降低计算开销相比之前的核心选择机制。<details>
<summary>Abstract</summary>
Federated learning is a distributed machine learning system that uses participants' data to train an improved global model. In federated learning, participants cooperatively train a global model, and they will receive the global model and payments. Rational participants try to maximize their individual utility, and they will not input their high-quality data truthfully unless they are provided with satisfactory payments based on their data quality. Furthermore, federated learning benefits from the cooperative contributions of participants. Accordingly, how to establish an incentive mechanism that both incentivizes inputting data truthfully and promotes stable cooperation has become an important issue to consider. In this paper, we introduce a data sharing game model for federated learning and employ game-theoretic approaches to design a core-selecting incentive mechanism by utilizing a popular concept in cooperative games, the core. In federated learning, the core can be empty, resulting in the core-selecting mechanism becoming infeasible. To address this, our core-selecting mechanism employs a relaxation method and simultaneously minimizes the benefits of inputting false data for all participants. However, this mechanism is computationally expensive because it requires aggregating exponential models for all possible coalitions, which is infeasible in federated learning. To address this, we propose an efficient core-selecting mechanism based on sampling approximation that only aggregates models on sampled coalitions to approximate the exact result. Extensive experiments verify that the efficient core-selecting mechanism can incentivize inputting high-quality data and stable cooperation, while it reduces computational overhead compared to the core-selecting mechanism.
</details>
<details>
<summary>摘要</summary>
federated learning 是一种分布式机器学习系统，用 particiants' 数据来训练一个改进的全球模型。在 federated learning 中，particiants 合作训练全球模型，并将收到全球模型和支付。理解 particiants 会尽可能地提高自己的个人利益，并不会真实输入高质量数据，除非他们得到满意的支付基于数据质量。此外，federated learning 受到参与者的合作贡献帮助。因此，如何建立一个奖励机制，使 particiants 尽可能地输入真实数据，同时促进稳定合作成为了一个重要的问题。在这篇论文中，我们介绍了一种数据共享游戏模型，并使用游戏理论方法设计核心选择奖励机制。在 federated learning 中，核心可能是空的，这会使核心选择机制成为不可能的。为解决这个问题，我们的核心选择机制使用了松弛方法，同时减少所有参与者输入假数据的收益。然而，这种机制是计算昂贵的，因为它需要对所有可能的联盟进行汇总，这是 federated learning 中不可能完成的。为解决这个问题，我们提出了一种高效的核心选择机制，基于采样approximation，只需对选择的联盟进行汇总，来近似 exact 结果。广泛的实验证明，高效的核心选择机制可以奖励输入高质量数据和稳定合作，同时减少计算负担，相比核心选择机制。
</details></li>
</ul>
<hr>
<h2 id="Quasi-Monte-Carlo-for-3D-Sliced-Wasserstein"><a href="#Quasi-Monte-Carlo-for-3D-Sliced-Wasserstein" class="headerlink" title="Quasi-Monte Carlo for 3D Sliced Wasserstein"></a>Quasi-Monte Carlo for 3D Sliced Wasserstein</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11713">http://arxiv.org/abs/2309.11713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khai Nguyen, Nicola Bariletto, Nhat Ho</li>
<li>for: 这个论文主要是为了提供一种更好的empirical Sliced Wasserstein（SW）Distance的方法，即Quasi-Sliced Wasserstein（QSW）方法，以及一种基于Randomized Quasi-Sliced Wasserstein（RQSW）的随机化版本，用于3D任务。</li>
<li>methods: 这个论文使用了Quasi-Monte Carlo（QMC）方法，包括Gaussian-based mapping、equal area mapping、generalized spiral points和优化犯 COUNT energies等方法来构建QMC点 clouds。此外，为了减少估计误差， authors还提出了一种基于随机化低犯 COUNT sequence的RQSW方法。</li>
<li>results: 该论文通过实验表明，QSW和RQSW方法在3D任务中表现出色，比如点云比较、点云插值、图像风格传输和深度点云自动编码器的训练等。此外， authors还证明了QSW和RQSW方法的 asymptotic convergence和无偏性。<details>
<summary>Abstract</summary>
Monte Carlo (MC) approximation has been used as the standard computation approach for the Sliced Wasserstein (SW) distance, which has an intractable expectation in its analytical form. However, the MC method is not optimal in terms of minimizing the absolute approximation error. To provide a better class of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of QMC for SW, we focus on the 3D setting, specifically computing the SW between probability measures in three dimensions. In greater detail, we empirically verify various ways of constructing QMC points sets on the 3D unit-hypersphere, including Gaussian-based mapping, equal area mapping, generalized spiral points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased estimation for stochastic optimization, we extend QSW into Randomized Quasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed low-discrepancy sequences. For theoretical properties, we prove the asymptotic convergence of QSW and the unbiasedness of RQSW. Finally, we conduct experiments on various 3D tasks, such as point-cloud comparison, point-cloud interpolation, image style transfer, and training deep point-cloud autoencoders, to demonstrate the favorable performance of the proposed QSW and RQSW variants.
</details>
<details>
<summary>摘要</summary>
蒙特卡洛（MC）方法已经被广泛使用作为水星剖分（SW）距离的标准计算方法，但MC方法不是最优的精度下采样方法。为提供更好的empirical SW，我们提议使用 quasi-水星剖分（QSW）方法，该方法基于 quasi-蒙特卡洛（QMC）方法。在更加详细的3D设置下，我们进行了对QMC方法的广泛研究，包括在3D单位球上构建QMC点集的多种方法，如 Gaussian-based mapping、equal area mapping、generalized spiral points和优化误差能量。此外，为了获得不偏向的优化，我们将QSW扩展为Randomized Quasi-Sliced Wasserstein（RQSW），通过引入随机性来讲谱低误差序列。我们证明了QSW的极限收敛性和RQSW的无偏性。最后，我们在多个3D任务上进行了实验，包括点云比较、点云拟合、图像风格传输和深度点云自动编码器的训练，以示提案的QSW和RQSW变体的报道性能。
</details></li>
</ul>
<hr>
<h2 id="Incentivized-Communication-for-Federated-Bandits"><a href="#Incentivized-Communication-for-Federated-Bandits" class="headerlink" title="Incentivized Communication for Federated Bandits"></a>Incentivized Communication for Federated Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11702">http://arxiv.org/abs/2309.11702</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhepei Wei, Chuanhao Li, Haifeng Xu, Hongning Wang</li>
<li>for: 鼓励客户端分享数据，以提高联合学习效率和实际可行性。</li>
<li>methods: 提出了一种奖励客户端分享数据的通信问题，并提出了首个奖励通信协议——Inc-FedUCB，可以在Contextual Linear Setting下实现近似优化的停损 regret。</li>
<li>results: 通过Synthetic和实际数据的广泛实验，证明了提案方法在不同环境下的效果。<details>
<summary>Abstract</summary>
Most existing works on federated bandits take it for granted that all clients are altruistic about sharing their data with the server for the collective good whenever needed. Despite their compelling theoretical guarantee on performance and communication efficiency, this assumption is overly idealistic and oftentimes violated in practice, especially when the algorithm is operated over self-interested clients, who are reluctant to share data without explicit benefits. Negligence of such self-interested behaviors can significantly affect the learning efficiency and even the practical operability of federated bandit learning. In light of this, we aim to spark new insights into this under-explored research area by formally introducing an incentivized communication problem for federated bandits, where the server shall motivate clients to share data by providing incentives. Without loss of generality, we instantiate this bandit problem with the contextual linear setting and propose the first incentivized communication protocol, namely, Inc-FedUCB, that achieves near-optimal regret with provable communication and incentive cost guarantees. Extensive empirical experiments on both synthetic and real-world datasets further validate the effectiveness of the proposed method across various environments.
</details>
<details>
<summary>摘要</summary>
现有大多数聚合强投资的研究假设所有客户端都是积极的分享其数据，以便服务器可以实现共同利益。尽管这种假设具有抽象理论保证的性和通信效率，但在实践中，这种假设经常被违背，特别是当算法在自私的客户端上运行时。不正确地忽略这些自私行为可能会对联合强投资学习的学习效率和实际操作性产生很大的影响。为了解决这个下 lista under-explored 的研究领域，我们希望通过正式地引入一种奖励通信问题，使服务器可以鼓励客户端分享数据，以获得奖励。无论总体来说，我们在Contextual linear setting中实例化这个强投资问题，并提出首个奖励通信协议，即Inc-FedUCB，可以实现近似最佳的 regret  guarantee，同时保证通信和奖励成本的 garantate。经验性实验表明，我们的方法在多种环境下都具有很高的实际效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.LG_2023_09_21/" data-id="clmvt7tas00hz26rd9zcm28jg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/eess.IV_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T09:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/eess.IV_2023_09_21/">eess.IV - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Bloch-Equation-Enables-Physics-informed-Neural-Network-in-Parametric-Magnetic-Resonance-Imaging"><a href="#Bloch-Equation-Enables-Physics-informed-Neural-Network-in-Parametric-Magnetic-Resonance-Imaging" class="headerlink" title="Bloch Equation Enables Physics-informed Neural Network in Parametric Magnetic Resonance Imaging"></a>Bloch Equation Enables Physics-informed Neural Network in Parametric Magnetic Resonance Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11763">http://arxiv.org/abs/2309.11763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingrui Cai, Liuhong Zhu, Jianjun Zhou, Chen Qian, Di Guo, Xiaobo Qu</li>
<li>for: 这个论文的目的是提出一种 Parametric Imaging 方法，可以在临床诊断中提供更多有用的信息。</li>
<li>methods: 这种方法使用 Physically Informed Neural Network (PINN)，其中嵌入了 Bloch 方程，以便学习 T2 参数和生成物理合理的数据。</li>
<li>results: 实验结果表明，这种方法可以在靶体和卡中心 imaging 中提供高度准确的数据，并且不需要大量的训练数据。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) is an important non-invasive imaging method in clinical diagnosis. Beyond the common image structures, parametric imaging can provide the intrinsic tissue property thus could be used in quantitative evaluation. The emerging deep learning approach provides fast and accurate parameter estimation but still encounters the lack of network interpretation and enough training data. Even with a large amount of training data, the mismatch between the training and target data may introduce errors. Here, we propose one way that solely relies on the target scanned data and does not need a pre-defined training database. We provide a proof-of-concept that embeds the physical rule of MRI, the Bloch equation, into the loss of physics-informed neural network (PINN). PINN enables learning the Bloch equation, estimating the T2 parameter, and generating a series of physically synthetic data. Experimental results are conducted on phantom and cardiac imaging to demonstrate its potential in quantitative MRI.
</details>
<details>
<summary>摘要</summary>
магнитно резонантно изображение (MRI) е важно неинвазивно изображување метод при клиничкој дијагнози. Осим обичних слика структура, параметрично изображување може датирати урођене својства ткива и може бити коришћено за квалитативну оцену. Емерџинг деп леARNING приступ може датирати параметре брзо и тачно, али још увек се сусреће са недостатком интерпретације мреже и достатком тренинг података. Иако са великим количином тренинг података, нескланост између тренинг и мета података може увести грешке. Отуд предлажемо један начин који се искључиво заснива на мети сканираних података и не захтева претходно дефинисану базу података за тренинг. Омогућавамо доказивање да ембедирамо физички закон MRI, Блокова једначина, у губитку физички информиране неуронне мреже (PINN). PINN омогућава учење Блокове једначине, процену параметра T2 и генерисање серије физички симулационих података. Експериментални резултати су извршени на фантазији и кардиоваскуларном изображујуњу да би се демострирало његово потенцијал у квалитативном MRI.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/eess.IV_2023_09_21/" data-id="clmvt7tdi00sq26rd9x1x5sed" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/eess.SP_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T08:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/eess.SP_2023_09_21/">eess.SP - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="RadYOLOLet-Radar-Detection-and-Parameter-Estimation-Using-YOLO-and-WaveLet"><a href="#RadYOLOLet-Radar-Detection-and-Parameter-Estimation-Using-YOLO-and-WaveLet" class="headerlink" title="RadYOLOLet: Radar Detection and Parameter Estimation Using YOLO and WaveLet"></a>RadYOLOLet: Radar Detection and Parameter Estimation Using YOLO and WaveLet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12094">http://arxiv.org/abs/2309.12094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Sarkar, Dongning Guo, Danijela Cabric</li>
<li>for: 这篇论文是为了探讨无助助的激光信号探测，并且可以在未来的共享频率无线网络中实现这一目标。</li>
<li>methods: 这篇论文提出了一个半upervised深度学习基本的频率探测方法，名为RadYOLOLet，可以检测低功率激光信号，并且可以在干扰下进行检测。RadYOLOLet使用了两个不同的卷积神经网（CNN）：RadYOLO和Wavelet-CNN，这两个神经网在独立地训练。</li>
<li>results: 根据论文的评估，RadYOLOLet可以在不同的干扰信号下实现100%的激光信号检测精度，并且可以在干扰信号水准为16 dB SINR下正确地运作。<details>
<summary>Abstract</summary>
Detection of radar signals without assistance from the radar transmitter is a crucial requirement for emerging and future shared-spectrum wireless networks like Citizens Broadband Radio Service (CBRS). In this paper, we propose a supervised deep learning-based spectrum sensing approach called RadYOLOLet that can detect low-power radar signals in the presence of interference and estimate the radar signal parameters. The core of RadYOLOLet is two different convolutional neural networks (CNN), RadYOLO and Wavelet-CNN, that are trained independently. RadYOLO operates on spectrograms and provides most of the capabilities of RadYOLOLet. However, it suffers from low radar detection accuracy in the low signal-to-noise ratio (SNR) regime. We develop Wavelet-CNN specifically to deal with this limitation of RadYOLO. Wavelet-CNN operates on continuous Wavelet transform of the captured signals, and we use it only when RadYOLO fails to detect any radar signal. We thoroughly evaluate RadYOLOLet using different experiments corresponding to different types of interference signals. Based on our evaluations, we find that RadYOLOLet can achieve 100% radar detection accuracy for our considered radar types up to 16 dB SNR, which cannot be guaranteed by other comparable methods. RadYOLOLet can also function accurately under interference up to 16 dB SINR.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这是一篇关于探测无助于激光发射器的激光信号探测方法的论文。我们提出了一个受监督的深度学习基础的探测方法，名为RadYOLOLet，可以在干扰的情况下探测低功率激光信号，并估算激光信号的参数。RadYOLOLet的核心是两个不同的卷积神经网（CNN）：RadYOLO和Wavelet-CNN。它们分别在干扰下和低信号输入下进行训练。RadYOLO在spectrogram上运作，提供了RadYOLOLet的大部分功能。但是，它在低信号输入下的激光探测精度不高。我们为了解决这个问题，开发了Wavelet-CNN，它在缩推 трансформа后的讯号上运作。当RadYOLO无法探测任何激光信号时，我们将Wavelet-CNN使用。我们对RadYOLOLet进行了不同类型的干扰信号的评估，根据我们的评估，RadYOLOLet可以在考虑的激光类型下达到100%的激光探测精度，并且在干扰至16 dB SINR的情况下还能正确运作。
</details></li>
</ul>
<hr>
<h2 id="UAV-Swarm-Deployment-and-Trajectory-for-3D-Area-Coverage-via-Reinforcement-Learning"><a href="#UAV-Swarm-Deployment-and-Trajectory-for-3D-Area-Coverage-via-Reinforcement-Learning" class="headerlink" title="UAV Swarm Deployment and Trajectory for 3D Area Coverage via Reinforcement Learning"></a>UAV Swarm Deployment and Trajectory for 3D Area Coverage via Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11992">http://arxiv.org/abs/2309.11992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia He, Ziye Jia, Chao Dong, Junyu Liu, Qihui Wu, Jingxian Liu</li>
<li>for: 该论文旨在研究无人机群组织和轨迹设计，以实现大规模三维场景中无人机群的无线通信服务。</li>
<li>methods: 该论文提出了层次群组织方案，以高效地服务于大规模用户。然后，问题被转化为最小化无人机群轨迹损失的问题。为解决非凸性问题，我们将其拆分为用户卷积、无人机群悬停点选择和群轨迹决定等子问题。</li>
<li>results: 我们采用Q学习算法加速解决效率。经验表明，我们的方法在其他参照方法中具有更高的效率和可扩展性。<details>
<summary>Abstract</summary>
Unmanned aerial vehicles (UAVs) are recognized as promising technologies for area coverage due to the flexibility and adaptability. However, the ability of a single UAV is limited, and as for the large-scale three-dimensional (3D) scenario, UAV swarms can establish seamless wireless communication services. Hence, in this work, we consider a scenario of UAV swarm deployment and trajectory to satisfy 3D coverage considering the effects of obstacles. In detail, we propose a hierarchical swarm framework to efficiently serve the large-area users. Then, the problem is formulated to minimize the total trajectory loss of the UAV swarm. However, the problem is intractable due to the non-convex property, and we decompose it into smaller issues of users clustering, UAV swarm hovering points selection, and swarm trajectory determination. Moreover, we design a Q-learning based algorithm to accelerate the solution efficiency. Finally, we conduct extensive simulations to verify the proposed mechanisms, and the designed algorithm outperforms other referred methods.
</details>
<details>
<summary>摘要</summary>
无人飞行器（UAV）被认为是有前途的技术，因为它具有灵活性和适应性。然而，单个UAV的能力有限，而在大规模三维（3D）场景中，UAV群可以建立无缝无线通信服务。因此，在这种工作中，我们考虑了UAV群的部署和轨迹，以满足3D覆盖。在详细的描述中，我们提出了层次群组织来有效地服务大面积用户。然后，我们将问题定义为最小化UAV群的总轨迹损失。然而，问题具有非拟合性，我们将其分解为更小的用户团 clustering、UAV群驻留点选择和群轨迹决定。此外，我们设计了Q学习算法来加速解决效率。最后，我们进行了详细的 simulations，并证明了我们的机制和算法的优化性。
</details></li>
</ul>
<hr>
<h2 id="Alteration-of-skeletal-muscle-energy-metabolism-assessed-by-31P-MRS-in-clinical-routine-part-2-Clinical-application"><a href="#Alteration-of-skeletal-muscle-energy-metabolism-assessed-by-31P-MRS-in-clinical-routine-part-2-Clinical-application" class="headerlink" title="Alteration of skeletal muscle energy metabolism assessed by 31P MRS in clinical routine, part 2: Clinical application"></a>Alteration of skeletal muscle energy metabolism assessed by 31P MRS in clinical routine, part 2: Clinical application</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11934">http://arxiv.org/abs/2309.11934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Naëgel, Hélène Ratiney, Jabrane Karkouri, Djahid Kennouche, Nicolas Royer, Jill M Slade, Jérôme Morel, Pierre Croisille, Magalie Viallon</li>
<li>for: 这个研究是为了评估高级质量控制管道在严重急性呼吸综合征和多发性硬化病例中的影响。</li>
<li>methods: 这个研究使用3T临床MRI机器进行31P-MRS测量，并在19名COVID-19患者、38名多发性硬化患者和40名健康控制群体中进行了实验。动态取样使用MR可控ergometer进行了40秒的休息阶段、2分钟的运动阶段和6分钟的恢复阶段。长TR和短TR的获得也在休息阶段进行了T1修正。</li>
<li>results: 应用高级质量控制管道后，研究结果显示了更高的统计力和更改的一些结果值，以及减少了数据变化的SD。COVID-19和多发性硬化患者与健康控制群体之间存在 significante differences，特别是T1PCr和T1Pi的差异。此外，使用固定修正因子导致了系统性地高于使用个体修正因子时的估计PCr和Pi的值。在休息阶段，COVID-19和多发性硬化患者与健康控制群体之间存在 significante differences。在运动阶段，COVID-19患者的动态指标$\tau$PCr、$\tau$Pi、ViPCr和Vmax都比控制群体低。<details>
<summary>Abstract</summary>
Background: In this second part of a two-part paper, we intend to demonstrate the impact of the previously proposed advanced quality control pipeline. To understand its benefit and challenge the proposed methodology in a real scenario, we chose to compare the outcome when applying it to the analysis of two patient populations with a significant but highly different types of fatigue: COVID19 and multiple sclerosis (MS). Experimental: 31P-MRS was performed on a 3T clinical MRI, in 19 COVID19 patients, 38 MS patients, and 40 matched healthy controls. Dynamic acquisitions using an MR-compatible ergometer ran over a rest(40s), exercise(2min), and a recovery phase(6min). Long and short TR acquisitions were also made at rest for T1 correction. The advanced data quality control pipeline presented in part 1 is applied to the selected patient cohorts to investigate its impact on clinical outcomes. We first used power and sample size analysis to estimate objectively the impact of adding QCS. Then, comparisons between patients and healthy control groups using validated QCS were performed using unpaired T-tests or Mann-Whitney tests (p<0.05).Results: The application of the QCS resulted in increased statistical power, changed the values of several outcome measures, and reduced variability (SD). A significant difference was found between the T1PCr and T1Pi of MS patients and healthy controls. Furthermore, the use of a fixed correction factor led to systematically higher estimated concentrations of PCr and Pi than when using individually corrected factors. We observed significant differences between the two patient populations and healthy controls for resting [PCr] -- MS only, [Pi], [ADP], [H2PO4-] and pH -- COVID19 only, and post-exercise [PCr],[Pi] and [H2PO4-] - MS only. The dynamic indicators $\tau$PCr, $\tau$Pi, ViPCr and Vmax were reduced for COVID19 and MS patients compared to controls. Conclusion: Our results show that QCS in dynamic 31P-MRS studies results in smaller data variability and therefore impacts study sample size and power. Although QCS resulted in discarded data and therefore reduced the acceptable data and subject numbers, this rigorous and unbiased approach allowed for proper assessment of muscle metabolites and metabolism in patient populations. The outcomes include an increased metabolite T1, which directly affect the T1 correction factor applied to the amplitudes of the metabolite, and a prolonged $\tau$PCr indicating reduced muscle oxidative capacity for patients with MS and COVID19.
</details>
<details>
<summary>摘要</summary>
Background: 在本文第二部分中，我们想要证明先前提出的高级质量控制管道的影响。为了更好地理解其效果和挑战，我们选择了使用COVID-19和多发性硬化病（MS）两种不同类型的疲劳作为研究对象，并对这两种疲劳的研究结果进行比较。Experimental: 在3T临床MRI机器上，使用31P-MRS技术进行实验，收集了19名COVID-19患者、38名MS患者和40名健康群的数据。在休息（40秒）、运动（2分）和恢复阶段（6分）之间，使用MR可移动ergometer进行动态收集。同时，也进行了长TR和短TR的获取，以便对T1的修正。在第一部分中提出的高级数据质量控制管道被应用于选择的患者群体，以研究它对临床结果的影响。我们首先使用力和样本大小分析来 объекively 评估加入QCS后的影响。然后，通过无对比T检测或曼恩-怀特检测（p<0.05）来比较患者和健康群的数据。Results: QCS的应用导致数据变化的范围变小，因此对研究样本大小和功能有影响。虽然QCS导致了数据抛弃，因此减少了可用数据和参与者数量，但这种坚实和无偏处的方法允许我们在患者群体中正确评估肌肉元素和代谢。结果显示，COVID-19和MS患者的肌肉代谢与健康群有显著差异。特别是，MS患者的T1PCr和T1Pi与健康群有 statistically significant difference。此外，使用固定修正因子导致了系统性地高于使用个体修正因子的估计PCr和Pi的浓度。我们发现COVID-19和MS患者在休息期的 [PCr]、[Pi]、[ADP]、[H2PO4-] 和 pH 中有显著差异。验证了MS患者的恢复期 [PCr]、[Pi] 和 [H2PO4-] 中的差异。同时，COVID-19患者的动态指标 $\tau$PCr、$\tau$Pi、ViPCr 和 Vmax 相比健康群下降。Conclusion: 我们的结果表明，QCS在动态31P-MRS研究中对数据的可靠性和可重复性有积极影响。虽然QCS导致了数据抛弃和样本大小减少，但这种坚实和无偏处的方法允许我们在患者群体中正确评估肌肉元素和代谢。结果包括肌肉T1的增加，直接影响T1修正因子应用于元素的振荡强度，以及COVID-19和MS患者的肌肉代谢减退。
</details></li>
</ul>
<hr>
<h2 id="Index-Modulation-based-Information-Harvesting-for-Far-Field-RF-Power-Transfer"><a href="#Index-Modulation-based-Information-Harvesting-for-Far-Field-RF-Power-Transfer" class="headerlink" title="Index Modulation-based Information Harvesting for Far-Field RF Power Transfer"></a>Index Modulation-based Information Harvesting for Far-Field RF Power Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11929">http://arxiv.org/abs/2309.11929</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Ertug Pihtili, Mehmet C. Ilter, Ertugrul Basar, Risto Wichman, Jyri Hämäläinen</li>
<li>for: 本研究旨在探讨如何使用现有的无线能量传输（WPT）机制来实现无电池通信技术，以满足以 sixth generation 无线通信（6G）时代的互联网物联网（IoT）平台中终端设备的能源储存限制。</li>
<li>methods: 本研究提出了一种新的协议，即信息收集（IH）协议，它利用现有的WPT机制来实现数据通信，并通过在远场传输机制中 incorporate 索引修改（IM）技术来提高数据传输效率。</li>
<li>results: 研究发现，使用IM技术可以在现有的WPT系统中实现数据通信，特别是在下一代IoT无线网络中。results also show that the proposed IH mechanism has the potential to improve the data transmission rate and reduce the power consumption of the system.<details>
<summary>Abstract</summary>
While wireless information transmission (WIT) is evolving into its sixth generation (6G), maintaining terminal operations that rely on limited battery capacities has become one of the most paramount challenges for Internet-of-Things (IoT) platforms. In this respect, there exists a growing interest in energy harvesting technology from ambient resources, and wireless power transfer (WPT) can be the key solution towards enabling battery-less infrastructures referred to as zero-power communication technology. Indeed, eclectic integration approaches between WPT and WIT mechanisms are becoming a vital necessity to limit the need for replacing batteries. Beyond the conventional separation between data and power components of the emitted waveforms, as in simultaneous wireless information and power transfer (SWIPT) mechanisms, a novel protocol referred to as information harvesting (IH) has recently emerged. IH leverages existing WPT mechanisms for data communication by incorporating index modulation (IM) techniques on top of the existing far-field power transfer mechanism. In this paper, a unified framework for the IM-based IH mechanisms has been presented where the feasibility of various IM techniques are evaluated based on different performance metrics. The presented results demonstrate the substantial potential to enable data communication within existing far-field WPT systems, particularly in the context of next-generation IoT wireless networks.
</details>
<details>
<summary>摘要</summary>
sixth generation 无线信息传输 (6G) 中，维护依赖有限电池容量的终端操作已成为互联网物联网 (IoT) 平台上最重要的挑战。在这种情况下，人们对于可在周围环境中汲取能量的技术 Display 增加了兴趣，而无线电力传输 (WPT) 可以成为启用零电池基础设施所需的关键解决方案。此外，在WPT和无线信息传输 (WIT) 机制之间的融合方法也在成为实现零电池通信技术的必要手段。在传统的WIT系统中，数据和电力两个组件通常分别在不同的频率域中进行传输。相比之下，同时进行数据和电力传输的机制被称为同时无线信息和电力传输 (SWIPT) 机制。在这篇论文中，我们提出了一种基于指标修改 (IM) 技术的信息汲取 (IH) 机制的统一框架。我们对不同的 IM 技术进行了评估，并根据不同的性能指标进行评估。结果表明，IH 机制在现有的 far-field WPT 系统中具有潜在的可能性，特别是在下一代 IoT 无线网络中。
</details></li>
</ul>
<hr>
<h2 id="Multi-Passive-Active-IRS-Enhanced-Wireless-Coverage-Deployment-Optimization-and-Cost-Performance-Trade-off"><a href="#Multi-Passive-Active-IRS-Enhanced-Wireless-Coverage-Deployment-Optimization-and-Cost-Performance-Trade-off" class="headerlink" title="Multi-Passive&#x2F;Active-IRS Enhanced Wireless Coverage: Deployment Optimization and Cost-Performance Trade-off"></a>Multi-Passive&#x2F;Active-IRS Enhanced Wireless Coverage: Deployment Optimization and Cost-Performance Trade-off</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11918">http://arxiv.org/abs/2309.11918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Fu, Weidong Mei, Rui Zhang<br>for: 这个论文主要关注在增强无线网络覆盖率的问题上，具体来说是通过在复杂环境中部署多个反射器，创建多个阻挡物减少的直线传输链路，以提高无线网络的覆盖率。methods: 该论文使用了多个反射器（PIRS&#x2F;AIRS）和多个天线的基站（BS）在一定区域内进行研究，并对这种多个反射器帮助的无线网络进行了分析和优化。results: 该论文的研究结果表明，使用多个反射器可以在复杂环境中提高无线网络的覆盖率，并且可以通过优化反射器的数量和位置来最大化覆盖率和降低成本。<details>
<summary>Abstract</summary>
Both passive and active intelligent reflecting surfaces (IRSs) can be deployed in complex environments to enhance wireless network coverage by creating multiple blockage-free cascaded line-of-sight (LoS) links. In this paper, we study a multi-passive/active-IRS (PIRS/AIRS) aided wireless network with a multi-antenna base station (BS) in a given region. First, we divide the region into multiple non-overlapping cells, each of which may contain one candidate location that can be deployed with a single PIRS or AIRS. Then, we show several trade-offs between minimizing the total IRS deployment cost and enhancing the signal-to-noise ratio (SNR) performance over all cells via direct/cascaded LoS transmission with the BS. To reconcile these trade-offs, we formulate a joint multi-PIRS/AIRS deployment problem to select an optimal subset of all candidate locations for deploying IRS and also optimize the number of passive/active reflecting elements deployed at each selected location to satisfy a given SNR target over all cells, such that the total deployment cost is minimized. However, due to the combinatorial optimization involved, the formulated problem is difficult to be solved optimally. To tackle this difficulty, we first optimize the reflecting element numbers with given PIRS/AIRS deployed locations via sequential refinement, followed by a partial enumeration to determine the PIRS/AIRS locations. Simulation results show that our proposed algorithm achieves better cost-performance trade-offs than other baseline deployment strategies.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译为简化字典。 Both passive and active intelligent reflecting surfaces (IRSs) can be deployed in complex environments to enhance wireless network coverage by creating multiple blockage-free cascaded line-of-sight (LoS) links. In this paper, we study a multi-passive/active-IRS (PIRS/AIRS) aided wireless network with a multi-antenna base station (BS) in a given region. First, we divide the region into multiple non-overlapping cells, each of which may contain one candidate location that can be deployed with a single PIRS or AIRS. Then, we show several trade-offs between minimizing the total IRS deployment cost and enhancing the signal-to-noise ratio (SNR) performance over all cells via direct/cascaded LoS transmission with the BS. To reconcile these trade-offs, we formulate a joint multi-PIRS/AIRS deployment problem to select an optimal subset of all candidate locations for deploying IRS and also optimize the number of passive/active reflecting elements deployed at each selected location to satisfy a given SNR target over all cells, such that the total deployment cost is minimized. However, due to the combinatorial optimization involved, the formulated problem is difficult to be solved optimally. To tackle this difficulty, we first optimize the reflecting element numbers with given PIRS/AIRS deployed locations via sequential refinement, followed by a partial enumeration to determine the PIRS/AIRS locations. Simulation results show that our proposed algorithm achieves better cost-performance trade-offs than other baseline deployment strategies.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="REM-U-net-Deep-Learning-Based-Agile-REM-Prediction-with-Energy-Efficient-Cell-Free-Use-Case"><a href="#REM-U-net-Deep-Learning-Based-Agile-REM-Prediction-with-Energy-Efficient-Cell-Free-Use-Case" class="headerlink" title="REM-U-net: Deep Learning Based Agile REM Prediction with Energy-Efficient Cell-Free Use Case"></a>REM-U-net: Deep Learning Based Agile REM Prediction with Energy-Efficient Cell-Free Use Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11898">http://arxiv.org/abs/2309.11898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hazem Sallouha, Shamik Sarkar, Enes Krijestorac, Danijela Cabric</li>
<li>for: 本文提出了一种高效的Radio环境地图（REM）预测方法，用于优化无线网络部署、提高网络性能和有效管理频谱资源。</li>
<li>methods: 本文使用了深度学习的u-net结构，并对大规模3D地图数据进行了训练。此外，文章还 investigate了数据处理步骤，以进一步提高REM预测精度。</li>
<li>results: 评估结果显示，提出的方法在2023年IEEE ICASSP Signal Processing Grand Challenge中的First Pathloss Radio Map Prediction Challenge中获得了平均正常化根圆弦误差（RMSE）0.045，并且平均运行时间为14毫秒（ms）。此外，文章还对CF-mMIMO网络中采用最小干扰APSwitch ON&#x2F;OFF策略时的能gy浪费进行了评估。<details>
<summary>Abstract</summary>
Radio environment maps (REMs) hold a central role in optimizing wireless network deployment, enhancing network performance, and ensuring effective spectrum management. Conventional REM prediction methods are either excessively time-consuming, e.g., ray tracing, or inaccurate, e.g., statistical models, limiting their adoption in modern inherently dynamic wireless networks. Deep-learning-based REM prediction has recently attracted considerable attention as an appealing, accurate, and time-efficient alternative. However, existing works on REM prediction using deep learning are either confined to 2D maps or use a limited dataset. In this paper, we introduce a runtime-efficient REM prediction framework based on u-nets, trained on a large-scale 3D maps dataset. In addition, data preprocessing steps are investigated to further refine the REM prediction accuracy. The proposed u-net framework, along with preprocessing steps, are evaluated in the context of the 2023 IEEE ICASSP Signal Processing Grand Challenge, namely, the First Pathloss Radio Map Prediction Challenge. The evaluation results demonstrate that the proposed method achieves an average normalized root-mean-square error (RMSE) of 0.045 with an average of 14 milliseconds (ms) runtime. Finally, we position our achieved REM prediction accuracy in the context of a relevant cell-free massive multiple-input multiple-output (CF-mMIMO) use case. We demonstrate that one can obviate consuming energy on large-scale fading measurements and rely on predicted REM instead to decide on which sleep access points (APs) to switch on in a CF-mMIMO network that adopts a minimum propagation loss AP switch ON/OFF strategy.
</details>
<details>
<summary>摘要</summary>
Radio环境地图（REM）在无线网络部署、提高网络性能和各频谱管理中扮演中心角色。传统的REM预测方法是太时间消耗或不准确，如折线追踪或统计模型，因此它们在现代自然动扩无线网络中得不到广泛的应用。深度学习基于的REM预测在latest years中吸引了广泛的关注，因为它可以提供准确、高效并且有时效的预测。然而，现有的REM预测使用深度学习的研究都是局限于2D地图或使用有限的数据集。在本文中，我们介绍一个高效运行时的REM预测框架，基于u-nets，在大规模3D地图数据集上训练。此外，我们还 investigate了数据预处理步骤，以进一步提高REM预测精度。我们的u-net框架，以及预处理步骤，在2023年IEEE ICASSP Signal Processing Grand Challenge中进行评估，即First Pathloss Radio Map Prediction Challenge。评估结果显示，我们的方法实现了平均正常化根圆方差误差（RMSE）0.045，平均运行时间14毫秒（ms）。最后，我们将我们实现的REM预测精度与相关的cell-free巨量多输入多输出（CF-mMIMO）应用场景进行比较。我们示出，可以不消耗大量能量进行大规模干扰测量，而是依靠预测REM来决定CF-mMIMO网络中的sleepAccess Points（AP）是否需要关机。
</details></li>
</ul>
<hr>
<h2 id="On-the-Performance-Analysis-of-RIS-Empowered-Communications-Over-Nakagami-m-Fading"><a href="#On-the-Performance-Analysis-of-RIS-Empowered-Communications-Over-Nakagami-m-Fading" class="headerlink" title="On the Performance Analysis of RIS-Empowered Communications Over Nakagami-m Fading"></a>On the Performance Analysis of RIS-Empowered Communications Over Nakagami-m Fading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11893">http://arxiv.org/abs/2309.11893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Selimis, Kostas P. Peppas, George C. Alexandropoulos, Fotis I. Lazarakis</li>
<li>for: 研究无线通信透过可程度智能表面（RIS）在 Nakagami-m 抽掉通道上的性能。</li>
<li>methods: 考虑了两种阶段配置设计 для RIS，一种随机的和另一种基于协调相位调节。</li>
<li>results: 提出了单组合表达式 для 失败率和binary modulation scheme的误bit error rate，并提出了精确的关键带宽对应。另外，还提出了简单的分析表达式，它们在大量RIS反射元件时会变为紧密的。<details>
<summary>Abstract</summary>
In this paper, we study the performance of wireless communications empowered by Reconfigurable Intelligent Surface (RISs) over Nakagami-m fading channels. We consider two phase configuration designs for the RIS, one random and another one based on coherent phase shifting. For both phase configuration cases, we present single-integral expressions for the outage probability and the bit error rate of binary modulation schemes, which can be efficiently evaluated numerically. In addition, we propose accurate closed-form approximations for the ergodic capacity of the considered system. For all considered metrics, we have also derived simple analytical expressions that become tight for large numbers of RIS reflecting elements. Numerically evaluated results compared with Monte Carlo simulations are presented in order to verify the correctness of the proposed analysis and showcase the impact of various system settings.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了基于可重配置智能表面（RIS）的无线通信系统在 Nakagami-m 折射通道上的性能。我们考虑了两种阶段配置设计 для RIS，一个是随机的，另一个是基于各相位的干扰。对于两种阶段配置情况，我们提供了单一积分表达式 для 失败率和二进制模ulation 的误差率，可以高效地数值计算。此外，我们提出了准确的闭式表达式 для 耗时容量的耗时容量。对于所有考虑的指标，我们还 deriv了简单的分析表达式，这些表达式在大量 RIS 反射元件时变得紧张。在进行数值计算后，我们对比了 Monte Carlo 仿真结果，以验证我们的分析正确性和系统参数的影响。
</details></li>
</ul>
<hr>
<h2 id="Near-Field-Beam-Training-Joint-Angle-and-Range-Estimation-with-DFT-Codebook"><a href="#Near-Field-Beam-Training-Joint-Angle-and-Range-Estimation-with-DFT-Codebook" class="headerlink" title="Near-Field Beam Training: Joint Angle and Range Estimation with DFT Codebook"></a>Near-Field Beam Training: Joint Angle and Range Estimation with DFT Codebook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11872">http://arxiv.org/abs/2309.11872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xun Wu, Changsheng You, Jiapeng Li, Yunpu Zhang</li>
<li>for: 提高near-field beam training的效率和准确性</li>
<li>methods: 使用DFT codebook进行off-grid范围估计，并提出了两种简单有效的 schemes来联合估计用户角度和范围</li>
<li>results: 对比各种 Referen schemes，numeric simulations显示，提议的方案可以大幅降低near-field beam training的训练负担和提高范围估计精度<details>
<summary>Abstract</summary>
Prior works on near-field beam training have mostly assumed dedicated polar-domain codebook and on-grid range estimation, which, however, may suffer long training overhead and degraded estimation accuracy. To address these issues, we propose in this paper new and efficient beam training schemes with off-grid range estimation by using conventional discrete Fourier transform (DFT) codebook. Specifically, we first analyze the received beam pattern at the user when far-field beamforming vectors are used for beam scanning, and show an interesting result that this beam pattern contains useful user angle and range information. Then, we propose two efficient schemes to jointly estimate the user angle and range with the DFT codebook. The first scheme estimates the user angle based on a defined angular support and resolves the user range by leveraging an approximated angular support width, while the second scheme estimates the user range by minimizing a power ratio mean square error (MSE) to improve the range estimation accuracy. Finally, numerical simulations show that our proposed schemes greatly reduce the near-field beam training overhead and improve the range estimation accuracy as compared to various benchmark schemes.
</details>
<details>
<summary>摘要</summary>
先前的近场ibeam训练工作都主要假设了专门的方位频域代码库和在格rid上的范围估计，这些方法可能会受到长时间的训练开销和质量下降。为了解决这些问题，我们在本纸提出了新的和高效的ibeam训练方案，使用常见的快速傅立叶变换（DFT）代码库进行范围估计。我们首先分析接收到的ibeam Pattern在用户端的情况下，并显示了一个有趣的结果：ibeam Pattern中包含了有用的用户角度和范围信息。然后，我们提出了两种高效的方案，用于同时估计用户角度和范围。第一种方案基于定义的 Angular support 来估计用户角度，然后利用 Approximated angular support width 来解决用户范围；第二种方案则是通过最小化力量比均方差误差（MSE）来提高范围估计精度。最后，我们通过数学仿真显示了我们的提议方案可以减少近场ibeam训练开销，并提高范围估计精度，相比于不同的参考方案。
</details></li>
</ul>
<hr>
<h2 id="Joint-Beamforming-for-RIS-Aided-Full-Duplex-Integrated-Sensing-and-Uplink-Communication"><a href="#Joint-Beamforming-for-RIS-Aided-Full-Duplex-Integrated-Sensing-and-Uplink-Communication" class="headerlink" title="Joint Beamforming for RIS Aided Full-Duplex Integrated Sensing and Uplink Communication"></a>Joint Beamforming for RIS Aided Full-Duplex Integrated Sensing and Uplink Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11850">http://arxiv.org/abs/2309.11850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Guo, Yang Liu, Qingqing Wu, Xin Zeng, Qingjiang Shi</li>
<li>For: This paper focuses on the development of an integrated sensing and communication (ISAC) technology in a full-duplex (FD) uplink communication system.* Methods: The paper employs a reconfigurable intelligent surface (RIS) to improve self-interference (SI) suppression and signal processing gain, and uses convex optimization techniques such as majorization-minimization (MM) and penalty-dual-decomposition (PDD) to optimize joint beamforming, RIS configuration, and mobile users’ power allocation.* Results: Numerical results demonstrate the effectiveness of the proposed solution and the benefits of employing RIS in the FD ISAC system.<details>
<summary>Abstract</summary>
This paper studies integrated sensing and communication (ISAC) technology in a full-duplex (FD) uplink communication system. As opposed to the half-duplex system, where sensing is conducted in a first-emit-then-listen manner, FD ISAC system emits and listens simultaneously and hence conducts uninterrupted target sensing. Besides, impressed by the recently emerging reconfigurable intelligent surface (RIS) technology, we also employ RIS to improve the self-interference (SI) suppression and signal processing gain. As will be seen, the joint beamforming, RIS configuration and mobile users' power allocation is a difficult optimization problem. To resolve this challenge, via leveraging the cutting-the-edge majorization-minimization (MM) and penalty-dual-decomposition (PDD) methods, we develop an iterative solution that optimizes all variables via using convex optimization techniques. Numerical results demonstrate the effectiveness of our proposed solution and the great benefit of employing RIS in the FD ISAC system.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Semi-Supervised-Variational-Inference-over-Nonlinear-Channels"><a href="#Semi-Supervised-Variational-Inference-over-Nonlinear-Channels" class="headerlink" title="Semi-Supervised Variational Inference over Nonlinear Channels"></a>Semi-Supervised Variational Inference over Nonlinear Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11841">http://arxiv.org/abs/2309.11841</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Burshtein, Eli Bery</li>
<li>for: 这篇论文探讨了用深度学习方法传输未知非线性通道，特别是使用 semi-supervised learning 方法来解码这些通道。</li>
<li>methods: 这篇论文使用了 Monte Carlo expectation maximization 和variational autoencoder 等 semi-supervised learning 方法，这些方法可以对几个实验symbols和资料传输几个实验symbols。</li>
<li>results: 根据 abstract，这篇论文获得了最佳的 semi-supervised learning 结果，并且在充分多个资料传输几个实验symbols时，variational autoencoder 也具有较低的错误率，比 meta learning 使用 pilot data 的现在和前一个传输对。<details>
<summary>Abstract</summary>
Deep learning methods for communications over unknown nonlinear channels have attracted considerable interest recently. In this paper, we consider semi-supervised learning methods, which are based on variational inference, for decoding unknown nonlinear channels. These methods, which include Monte Carlo expectation maximization and a variational autoencoder, make efficient use of few pilot symbols and the payload data. The best semi-supervised learning results are achieved with a variational autoencoder. For sufficiently many payload symbols, the variational autoencoder also has lower error rate compared to meta learning that uses the pilot data of the present as well as previous transmission blocks.
</details>
<details>
<summary>摘要</summary>
现在的某些推荐方法已经吸引了很多关注。在这篇论文中，我们考虑了半监督学习方法，它们基于变量推理。这些方法包括Monte Carlo预期最大化和变量自适应器。它们可以高效地使用少量的准则符号和 payload 数据。最佳的半监督学习结果是通过变量自适应器实现。当 payload 符号够多的时候，变量自适应器也比使用现在和前一个传输块的准则数据来学习的meta学习更低的错误率。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Study-of-PAPR-Reduction-Techniques-for-Deep-Joint-Source-Channel-Coding-in-OFDM-Systems"><a href="#A-Comprehensive-Study-of-PAPR-Reduction-Techniques-for-Deep-Joint-Source-Channel-Coding-in-OFDM-Systems" class="headerlink" title="A Comprehensive Study of PAPR Reduction Techniques for Deep Joint Source Channel Coding in OFDM Systems"></a>A Comprehensive Study of PAPR Reduction Techniques for Deep Joint Source Channel Coding in OFDM Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11803">http://arxiv.org/abs/2309.11803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maolin Liu, Wei Chen, Jialong Xu, Bo Ai</li>
<li>for: 这篇论文主要针对的是深度联合源通道编码（DJSCC）系统中的带宽和信号噪比（SNR）下的性能问题。</li>
<li>methods: 本论文使用了多种 orthogonal frequency division multiplexing（OFDM）带宽膨胀率（PAPR）降低技术，包括传统技术如剪辑、压缩、SLM和PTS，以及深度学习基于的PAPR降低技术如PAPR损失和剪辑重训练。</li>
<li>results: 我们的调查表明，虽然传统的PAPR降低技术可以应用于DJSCC，但它们在DJSCC中的表现与传统的分源通道编码不同。此外，我们发现在信号损害PAPR降低技术中，剪辑重训练最佳地降低PAPR并保持信号重建精度。此外，我们发现在信号非损害PAPR降低技术中，可以成功地降低DJSCC中的PAPR无需牺牲信号重建精度。<details>
<summary>Abstract</summary>
Recently, deep joint source channel coding (DJSCC) techniques have been extensively studied and have shown significant performance with limited bandwidth and low signal to noise ratio. Most DJSCC work considers discrete-time analog transmission, while combining it with orthogonal frequency division multiplexing (OFDM) creates serious high peak-to-average power ratio (PAPR) problem. This paper conducts a comprehensive analysis on the use of various OFDM PAPR reduction techniques in the DJSCC system, including both conventional techniques such as clipping, companding, SLM and PTS, and deep learning-based PAPR reduction techniques such as PAPR loss and clipping with retraining. Our investigation shows that although conventional PAPR reduction techniques can be applied to DJSCC, their performance in DJSCC is different from the conventional split source channel coding. Moreover, we observe that for signal distortion PAPR reduction techniques, clipping with retraining achieves the best performance in terms of both PAPR reduction and recovery accuracy. It is also noticed that signal non-distortion PAPR reduction techniques can successfully reduce the PAPR in DJSCC without compromise to signal reconstruction.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:最近，深度 JOINT SOURCE CHANNEL CODING（DJSCC）技术已经广泛研究，并显示了有限带宽和低信号噪声比下的出色表现。大多数DJSCC工作假设了分时分析传输，而将它与分多频分配多重（OFDM）结合使得PAPR问题变得严重。这篇论文对DJSCC系统中OFDM PAPR减少技术的使用进行了全面的分析，包括传统技术 such as clipping, companding, SLM和PTS，以及基于深度学习的PAPR减少技术 such as PAPR损失和clipping重新训练。我们的调查表明，虽然传统PAPR减少技术可以应用于DJSCC，但它们在DJSCC中的性能不同于传统分Split Source Channel Coding。此外，我们还发现，对信号损害PAPR减少技术，clipping重新训练得到了最好的性能，包括PAPR减少和重建精度。此外，我们还发现，对信号非损害PAPR减少技术，可以成功减少DJSCC中的PAPR，无需牺牲信号重建精度。
</details></li>
</ul>
<hr>
<h2 id="Quantum-Circuits-for-Stabilizer-Error-Correcting-Codes-A-Tutorial"><a href="#Quantum-Circuits-for-Stabilizer-Error-Correcting-Codes-A-Tutorial" class="headerlink" title="Quantum Circuits for Stabilizer Error Correcting Codes: A Tutorial"></a>Quantum Circuits for Stabilizer Error Correcting Codes: A Tutorial</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11793">http://arxiv.org/abs/2309.11793</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Mondal, Keshab K. Parhi</li>
<li>for: 这篇论文的目的是教育读者设计和仿真量子编码和解码电路，以实现稳定的量子计算。</li>
<li>methods: 论文使用的方法包括设计和仿真五量子码和斯特恩码的编码和解码电路，以及使用IBM Qiskit进行验证。</li>
<li>results: 论文通过设计和仿真电路，实现了五量子码和斯特恩码的编码和解码。此外，论文还提供了邻居相关的编码和解码电路。<details>
<summary>Abstract</summary>
Quantum computers have the potential to provide exponential speedups over their classical counterparts. Quantum principles are being applied to fields such as communications, information processing, and artificial intelligence to achieve quantum advantage. However, quantum bits are extremely noisy and prone to decoherence. Thus, keeping the qubits error free is extremely important toward reliable quantum computing. Quantum error correcting codes have been studied for several decades and methods have been proposed to import classical error correcting codes to the quantum domain. However, circuits for such encoders and decoders haven't been explored in depth. This paper serves as a tutorial on designing and simulating quantum encoder and decoder circuits for stabilizer codes. We present encoding and decoding circuits for five-qubit code and Steane code, along with verification of these circuits using IBM Qiskit. We also provide nearest neighbour compliant encoder and decoder circuits for the five-qubit code.
</details>
<details>
<summary>摘要</summary>
量子计算机有可能提供幂数倍速的加速，应用量子原理到通信、信息处理和人工智能等领域以实现量子优势。然而，量子比特非常易受噪声和破坏，因此保持量子比特错误自由是非常重要的。量子错误修复码已经在数十年内研究，提出了将类型错误修复码引入量子领域的方法。然而，这些圈定器和解码器的电路尚未得到了深入研究。本文为读者提供了设计和实现量子编码器和解码器电路的 tutorials，包括五个量子比特的编码和解码电路以及Steane码的编码和解码电路。此外，我们还提供了邻居相似的编码器和解码器电路。我们使用IBM Qiskit进行验证。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Fault-Identification-Reconstruction-in-Multi-Agent-Systems"><a href="#Collaborative-Fault-Identification-Reconstruction-in-Multi-Agent-Systems" class="headerlink" title="Collaborative Fault-Identification &amp; Reconstruction in Multi-Agent Systems"></a>Collaborative Fault-Identification &amp; Reconstruction in Multi-Agent Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11784">http://arxiv.org/abs/2309.11784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiraz Khan, Inseok Hwang</li>
<li>for: 本研究旨在提出一种高效的分布式逻辑检测、识别和重建（FDIR）机制，适用于多智能体应用。</li>
<li>methods: 该研究基于非线性测量数据进行分布式多智能体FDIR算法的设计，并使用了顺序凸 программирова（SCP）和分布式多智能体优化方法（ADMM）。</li>
<li>results: 提出的分布式多智能体FDIR算法可以处理各种间智能体测量数据（包括距离、方向、相对速度和夹角），并可以识别FAULTY智能体和重建其真实状态。<details>
<summary>Abstract</summary>
The conventional solutions for fault-detection, identification, and reconstruction (FDIR) require centralized decision-making mechanisms which are typically combinatorial in their nature, necessitating the design of an efficient distributed FDIR mechanism that is suitable for multi-agent applications. To this end, we develop a general framework for efficiently reconstructing a sparse vector being observed over a sensor network via nonlinear measurements. The proposed framework is used to design a distributed multi-agent FDIR algorithm based on a combination of the sequential convex programming (SCP) and the alternating direction method of multipliers (ADMM) optimization approaches. The proposed distributed FDIR algorithm can process a variety of inter-agent measurements (including distances, bearings, relative velocities, and subtended angles between agents) to identify the faulty agents and recover their true states. The effectiveness of the proposed distributed multi-agent FDIR approach is demonstrated by considering a numerical example in which the inter-agent distances are used to identify the faulty agents in a multi-agent configuration, as well as reconstruct their error vectors.
</details>
<details>
<summary>摘要</summary>
传统的瑕疵检测、识别和重建（FDIR）解决方案具有中央决策机制，通常是 combinatorial 的性质，需要设计一个高效的分布式 FDIR 机制，适用于多机器人应用。为此，我们提出了一个通用的分布式 sparse vector 重建框架，可以通过非线性测量来重建。基于此框架，我们设计了一种基于 sequential convex programming（SCP）和 alternating direction method of multipliers（ADMM）优化方法的分布式多机器人 FDIR 算法。该算法可以处理多机器人之间的各种测量（包括距离、方向、相对速度和夹角）来识别瑕疵机器人并重建其真实状态。我们通过一个数学示例表明了该分布式多机器人 FDIR 方法的效果。在这个示例中，我们使用了机器人之间的距离来识别瑕疵机器人并重建其错误向量。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-the-SEFDM-Performance-in-High-Doppler-Channels"><a href="#Enhancing-the-SEFDM-Performance-in-High-Doppler-Channels" class="headerlink" title="Enhancing the SEFDM Performance in High-Doppler Channels"></a>Enhancing the SEFDM Performance in High-Doppler Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11774">http://arxiv.org/abs/2309.11774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Shamsi, Farokh Marvasti</li>
<li>for: 提高移动通信网络中延迟和Doppler偏移的影响管理</li>
<li>methods: 使用Spectrally Efficient Frequency Division Multiplexing (SEFDM)技术，并采用频域预处理和修改非线性加速技术来提高系统性能和 spectral efficiency</li>
<li>results: 在模拟场景中，使用提议方法可以实现可靠和高质量的通信，并且在Doppler频率下保持SEFDM的优于OFDM的spectral efficiency<details>
<summary>Abstract</summary>
In this paper, we propose the use of Spectrally Efficient Frequency Division Multiplexing (SEFDM) with additional techniques such as Frequency Domain Cyclic Prefix (FDCP) and Modified Non-Linear (MNL) acceleration for efficient handling of the impact of delay and Doppler shift in mobile communication channels. Our approach exhibits superior performance and spectral efficiency in comparison to traditional communication systems, while maintaining low computational cost. We study a model of the SEFDM communication system and investigate the impact of MNL acceleration with soft and hard decision Inverse System on the performance of SEFDM detection in the AWGN channel. We also analyze the effectiveness of FDCP in compensating for the impact of Doppler shift, and report BER detection figures using Regularized Sphere Decoding in various simulation scenarios. Our simulations demonstrate that it is possible to achieve acceptable performance in Doppler channels while maintaining the superiority of SEFDM over OFDM in terms of spectral efficiency. The results suggest that our proposed approach can tackle the effects of delay and Doppler shift in mobile communication networks, guaranteeing dependable and high-quality communication even in extremely challenging environments.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提议使用具有频率分配多路复用（SEFDM）技术，并采用频域循环前缀（FDCP）和修改非线性加速（MNL）技术来有效地处理移动通信频道中的延迟和Doppler偏移的影响。我们的方法可以在比较具有传统通信系统的优势下，实现高效的spectral efficiency，同时保持低的计算成本。我们研究了SEFDM通信系统的模型，并研究MNL加速器在半硬件决策和软件决策下对SEFDM检测在AWGN频道的性能的影响。我们还分析了FDCP在补偿Doppler偏移的效果，并在不同的 simulate scenariodemitt BER detection figure using Regularized Sphere Decoding。我们的 simulations表明，可以在Doppler频道中实现可接受的性能，同时保持SEFDM在OFDM方面的 spectral efficiency。结果表明，我们提议的方法可以在移动通信网络中抵消延迟和Doppler偏移的影响，确保高质量和可靠的通信，即使在EXTREMELY challenging environment中。
</details></li>
</ul>
<hr>
<h2 id="Symbol-Detection-for-Coarsely-Quantized-OTFS"><a href="#Symbol-Detection-for-Coarsely-Quantized-OTFS" class="headerlink" title="Symbol Detection for Coarsely Quantized OTFS"></a>Symbol Detection for Coarsely Quantized OTFS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11759">http://arxiv.org/abs/2309.11759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwei He, Haochuan Zhang, Chao Dong, Huimin Zhu</li>
<li>for: 这篇论文专门设计了一种基于对角时域频率空间（OTFS）的差异和杂变量化通信系统，以提高成本和功耗效率。</li>
<li>methods: 论文使用了一种新的估算消息传递（AMP）算法，以及一种改进的普通期望一致的信号恢复（GEC-SR）算法，以解决差异量化导致的频率域频率偏移问题。</li>
<li>results: 论文通过对OTFS系统进行模拟和分析，发现差异量化可以提高成本和功耗效率，但是需要采用低复杂度的算法来实现。<details>
<summary>Abstract</summary>
This paper explicitly models a coarse and noisy quantization in a communication system empowered by orthogonal time frequency space (OTFS) for cost and power efficiency. We first point out, with coarse quantization, the effective channel is imbalanced and thus no longer able to circularly shift the transmitted symbols along the delay-Doppler domain. Meanwhile, the effective channel is non-isotropic, which imposes a significant loss to symbol detection algorithms like the original approximate message passing (AMP). Although the algorithm of generalized expectation consistent for signal recovery (GEC-SR) can mitigate this loss, the complexity in computation is prohibitively high, mainly due to an dramatic increase in the matrix size of OTFS. In this context, we propose a low-complexity algorithm that incorporates into the GEC-SR a quick inversion of quasi-banded matrices, reducing the complexity from a cubic order to a linear order while keeping the performance at the same level.
</details>
<details>
<summary>摘要</summary>
这篇论文显式地模型了一种粗略和噪声量化在基于对角时域频率空间 (OTFS) 的通信系统中，以提高成本和功率效率。我们首先指出，当使用粗略量化时，有效通道变得不均衡，因此不能在延迟-杂散域中循环推移传输的符号。此外，有效通道不均匀，这会对符号检测算法如原始approximate message passing (AMP) 带来重大损失。虽然generalized expectation consistent for signal recovery (GEC-SR) 算法可以减轻这种损失，但计算复杂性过高，主要是因为OTFS 矩阵的维度增加了 exponential。在这种情况下，我们提议一种低复杂性算法，将 GEC-SR 中的快速归一化 quasi-banded 矩阵合并到一起，从 cubic 阶减少到 linear 阶，保持性能水平不变。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Meets-Swarm-Intelligence-for-UAV-Assisted-IoT-Coverage-in-Massive-MIMO"><a href="#Deep-Learning-Meets-Swarm-Intelligence-for-UAV-Assisted-IoT-Coverage-in-Massive-MIMO" class="headerlink" title="Deep Learning Meets Swarm Intelligence for UAV-Assisted IoT Coverage in Massive MIMO"></a>Deep Learning Meets Swarm Intelligence for UAV-Assisted IoT Coverage in Massive MIMO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11748">http://arxiv.org/abs/2309.11748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mobeen Mahmood, MohammadMahdi Ghadaksaz, Asil Koc, Tho Le-Ngoc</li>
<li>for: 这个研究 investigate了一个由无人机（UAV） assisted的多用户多输入多输出（MU-mMIMO）系统，其中UAV acting as a decode-and-forward（DF） relay，以帮助基站（BS）向多个互联网物（IoT）用户传输数据流。</li>
<li>methods: 该研究提出了一个joint优化问题，包括 гибри德束成形（HBF）、UAV relay位置划分和功率分配（PA），以 Maximize the total achievable rate（AR）。研究采用了一个基于geometry的 millimeter-wave（mmWave）通道模型，并提出了三种遗传智能（SI）基本解决方案来优化：1）UAVlocation with equal PA; 2）PA with fixed UAV location; 3）joint PA with UAV deployment。</li>
<li>results: 研究结果显示，提出的算法解决方案可以 achieve higher capacity and reduce average delay for delay-constrained transmissions in a UAV-assisted MU-mMIMO IoT systems。此外，提出的J-HBF-DLLPA可以 closely approach the optimal capacity while significantly reducing the runtime by 99%, which makes the DL-based solution a promising implementation for real-time online applications in UAV-assisted MU-mMIMO IoT systems.<details>
<summary>Abstract</summary>
This study considers a UAV-assisted multi-user massive multiple-input multiple-output (MU-mMIMO) systems, where a decode-and-forward (DF) relay in the form of an unmanned aerial vehicle (UAV) facilitates the transmission of multiple data streams from a base station (BS) to multiple Internet-of-Things (IoT) users. A joint optimization problem of hybrid beamforming (HBF), UAV relay positioning, and power allocation (PA) to multiple IoT users to maximize the total achievable rate (AR) is investigated. The study adopts a geometry-based millimeter-wave (mmWave) channel model for both links and proposes three different swarm intelligence (SI)-based algorithmic solutions to optimize: 1) UAV location with equal PA; 2) PA with fixed UAV location; and 3) joint PA with UAV deployment. The radio frequency (RF) stages are designed to reduce the number of RF chains based on the slow time-varying angular information, while the baseband (BB) stages are designed using the reduced-dimension effective channel matrices. Then, a novel deep learning (DL)-based low-complexity joint hybrid beamforming, UAV location and power allocation optimization scheme (J-HBF-DLLPA) is proposed via fully-connected deep neural network (DNN), consisting of an offline training phase, and an online prediction of UAV location and optimal power values for maximizing the AR. The illustrative results show that the proposed algorithmic solutions can attain higher capacity and reduce average delay for delay-constrained transmissions in a UAV-assisted MU-mMIMO IoT systems. Additionally, the proposed J-HBF-DLLPA can closely approach the optimal capacity while significantly reducing the runtime by 99%, which makes the DL-based solution a promising implementation for real-time online applications in UAV-assisted MU-mMIMO IoT systems.
</details>
<details>
<summary>摘要</summary>
To solve the optimization problem, the study proposes three different swarm intelligence (SI)-based algorithmic solutions:1. UAV location with equal PA2. PA with fixed UAV location3. Joint PA with UAV deploymentThe radio frequency (RF) stages are designed to reduce the number of RF chains based on slow time-varying angular information, while the baseband (BB) stages are designed using reduced-dimension effective channel matrices.Furthermore, a novel deep learning (DL)-based low-complexity joint hybrid beamforming, UAV location, and power allocation optimization scheme (J-HBF-DLLPA) is proposed. The scheme consists of an offline training phase and an online prediction of UAV location and optimal power values for maximizing the AR.The illustrative results show that the proposed algorithmic solutions can achieve higher capacity and reduce average delay for delay-constrained transmissions in a UAV-assisted MU-mMIMO IoT system. Additionally, the proposed J-HBF-DLLPA can closely approach the optimal capacity while significantly reducing the runtime by 99%, making it a promising implementation for real-time online applications in UAV-assisted MU-mMIMO IoT systems.
</details></li>
</ul>
<hr>
<h2 id="Resource-Allocation-for-Semantic-Aware-Mobile-Edge-Computing-Systems"><a href="#Resource-Allocation-for-Semantic-Aware-Mobile-Edge-Computing-Systems" class="headerlink" title="Resource Allocation for Semantic-Aware Mobile Edge Computing Systems"></a>Resource Allocation for Semantic-Aware Mobile Edge Computing Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11736">http://arxiv.org/abs/2309.11736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihan Cang, Ming Chen, Zhaohui Yang, Yuntao Hu, Yinlu Wang, Zhaoyang Zhang, Kai-Kit Wong</li>
<li>for: 提高Mobile Edge Computing（MEC）系统中终端设备（TD）的计算任务执行效率，通过在TD上执行计算任务，并将小型Semantic Information（SI）发送到MEC服务器 instead of large-size raw data。</li>
<li>methods: 提出了一种semantic-aware的共享计算资源分配框架，使用了几何编程将原始非几何问题转化为几何问题，并使用alternating optimization algorithm解决了该问题。</li>
<li>results: 相比benchmark算法，提出的算法可以减少最大执行延迟达37.10%，并且在大任务大小和差 channel conditions下，小型Semantic Extraction Factor（SEF）被首选。<details>
<summary>Abstract</summary>
In this paper, a semantic-aware joint communication and computation resource allocation framework is proposed for mobile edge computing (MEC) systems. In the considered system, each terminal device (TD) has a computation task, which needs to be executed by offloading to the MEC server. To further decrease the transmission burden, each TD sends the small-size extracted semantic information of tasks to the server instead of the large-size raw data. An optimization problem of joint semantic-aware division factor, communication and computation resource management is formulated. The problem aims to minimize the maximum execution delay of all TDs while satisfying energy consumption constraints. The original non-convex problem is transformed into a convex one based on the geometric programming and the optimal solution is obtained by the alternating optimization algorithm. Moreover, the closed-form optimal solution of the semantic extraction factor is derived. Simulation results show that the proposed algorithm yields up to 37.10% delay reduction compared with the benchmark algorithm without semantic-aware allocation. Furthermore, small semantic extraction factors are preferred in the case of large task sizes and poor channel conditions.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，一种基于 semantics 的共享通信和计算资源分配框架被提出用于移动边缘计算（MEC）系统。在考虑系统中，每个终端设备（TD）都有一个计算任务，需要通过下载到 MEC 服务器进行执行。为了进一步减少传输负担，每个 TD 将向服务器发送小型的提取后的semantics信息而不是大量的原始数据。一个优化问题的共享 semantic-aware 分配因子、通信和计算资源管理问题被形ulated。该问题的目标是最小化所有 TD 的执行延迟，同时满足能耗约束。原始的非几何问题被转化为几何问题，并通过幂等优化算法获得了最优解。此外，关闭型优化解的semantic提取因子也得到了解。模拟结果显示，提出的算法可以减少最多37.10%的延迟，相比无semantic-aware分配的参考算法。此外，在大任务大小和 poor 通道条件下，小semantic提取因子被首选。
</details></li>
</ul>
<hr>
<h2 id="A-class-weighted-supervised-contrastive-learning-long-tailed-bearing-fault-diagnosis-approach-using-quadratic-neural-network"><a href="#A-class-weighted-supervised-contrastive-learning-long-tailed-bearing-fault-diagnosis-approach-using-quadratic-neural-network" class="headerlink" title="A class-weighted supervised contrastive learning long-tailed bearing fault diagnosis approach using quadratic neural network"></a>A class-weighted supervised contrastive learning long-tailed bearing fault diagnosis approach using quadratic neural network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11717">http://arxiv.org/abs/2309.11717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuweien1120/CCQNet">https://github.com/yuweien1120/CCQNet</a></li>
<li>paper_authors: Wei-En Yu, Jinwei Sun, Shiping Zhang, Xiaoge Zhang, Jing-Xiao Liao<br>for:  This paper proposes a supervised contrastive learning approach to enhance the feature extraction capability of neural networks for fault diagnosis in industrial settings, where data is highly imbalanced or long-tailed.methods:  The proposed approach uses a class-aware loss function and a class-weighted contrastive learning quadratic network (CCQNet) consisting of a quadratic convolutional residual network backbone, a contrastive learning branch, and a classifier branch.results:  Experimental results on public and proprietary datasets show that CCQNet outperforms state-of-the-art (SOTA) methods in handling extremely imbalanced data, demonstrating the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Deep learning has achieved remarkable success in bearing fault diagnosis. However, its performance oftentimes deteriorates when dealing with highly imbalanced or long-tailed data, while such cases are prevalent in industrial settings because fault is a rare event that occurs with an extremely low probability. Conventional data augmentation methods face fundamental limitations due to the scarcity of samples pertaining to the minority class. In this paper, we propose a supervised contrastive learning approach with a class-aware loss function to enhance the feature extraction capability of neural networks for fault diagnosis. The developed class-weighted contrastive learning quadratic network (CCQNet) consists of a quadratic convolutional residual network backbone, a contrastive learning branch utilizing a class-weighted contrastive loss, and a classifier branch employing logit-adjusted cross-entropy loss. By utilizing class-weighted contrastive loss and logit-adjusted cross-entropy loss, our approach encourages equidistant representation of class features, thereby inducing equal attention on all the classes. We further analyze the superior feature extraction ability of quadratic network by establishing the connection between quadratic neurons and autocorrelation in signal processing. Experimental results on public and proprietary datasets are used to validate the effectiveness of CCQNet, and computational results reveal that CCQNet outperforms SOTA methods in handling extremely imbalanced data substantially.
</details>
<details>
<summary>摘要</summary>
深度学习在机器fault diagnosis中取得了非常出色的成果。然而，其性能经常下降在面临高度不均衡或长尾数据时，这些情况在工业Setting中很普遍，因为缺陷是一种非常罕见的事件，发生的概率非常低。传统的数据扩充方法面临基本的限制，因为缺陷类型的样本稀缺。在这篇论文中，我们提出了一种supervised contrastive learning方法，使用类 weighted contrastive loss函数，以提高神经网络的特征提取能力。我们提出的CCQNet模型包括quadratic convolutional residual network底层、contrastive learning分支、类别分支和logit-adjusted cross-entropy loss函数。通过使用类 weighted contrastive loss函数和logit-adjusted cross-entropy loss函数，我们的方法促进了类别特征的恰等表示，从而使得所有类别受到相同的注意。我们还分析了quadratic neuron的超越性，并证明了它们与信号处理中的自相关之间的联系。实验结果表明，CCQNet在处理极端不均衡数据时表现出了显著的优异性，与state-of-the-art方法相比，CCQNet在极端不均衡数据上的表现有所提高。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/eess.SP_2023_09_21/" data-id="clmvt7tds00u026rd0csaf46q" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/20/cs.SD_2023_09_20/" class="article-date">
  <time datetime="2023-09-20T15:00:00.000Z" itemprop="datePublished">2023-09-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/20/cs.SD_2023_09_20/">cs.SD - 2023-09-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Joint-Minimum-Processing-Beamforming-and-Near-end-Listening-Enhancement"><a href="#Joint-Minimum-Processing-Beamforming-and-Near-end-Listening-Enhancement" class="headerlink" title="Joint Minimum Processing Beamforming and Near-end Listening Enhancement"></a>Joint Minimum Processing Beamforming and Near-end Listening Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11243">http://arxiv.org/abs/2309.11243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas J. Fuglsig, Jesper Jensen, Zheng-Hua Tan, Lars S. Bertelsen, Jens Christian Lindof, Jan Østergaard</li>
<li>for: 这个研究旨在提高受到噪音环境影响的语音识别度，并限制噪音处理量，以确保语音质量不会过度受损。</li>
<li>methods: 这个研究使用了最小处理框架，以减少噪音或增强听力，并保证语音质量不会过度受损。</li>
<li>results: 研究结果显示， JOINT 最小处理框架可以提高语音识别度，并限制噪音处理量，对于有利的噪音情况下，语音质量不会过度受损。<details>
<summary>Abstract</summary>
We consider speech enhancement for signals picked up in one noisy environment that must be rendered to a listener in another noisy environment. For both far-end noise reduction and near-end listening enhancement, it has been shown that excessive focus on noise suppression or intelligibility maximization may lead to excessive speech distortions and quality degradations in favorable noise conditions, where intelligibility is already at ceiling level. Recently [1,2] propose to remedy this with a minimum processing framework that either reduces noise or enhances listening a minimum amount given that a certain intelligibility criterion is still satisfied. Additionally, it has been shown that joint consideration of both environments improves speech enhancement performance. In this paper, we formulate a joint far- and near-end minimum processing framework, that improves intelligibility while limiting speech distortions in favorable noise conditions. We provide closed-form solutions to specific boundary scenarios and investigate performance for the general case using numerical optimization. We also show that concatenating existing minimum processing far- and near-end enhancement methods preserves the effects of the initial methods. Results show that the joint optimization can further improve performance compared to the concatenated approach.
</details>
<details>
<summary>摘要</summary>
我们考虑 speech 增强器在一个噪音环境中捕捉的讯号，需要在另一个噪音环境中呈现给听者。对于距离端噪音抑制和近端听力增强而言，过度强调噪音抑制或智能化最大化可能会导致对于有利的噪音情况下的话语变化和质量下降。最近，[1,2] 提出了一个最小处理框架，可以在保持智能化水平下最小化噪音或增强听力。此外，jointly 考虑两个环境可以提高话语增强表现。在这篇文章中，我们建立了一个共同距离和近端最小处理框架，可以在有利噪音情况下提高智能化水平，并限制话语变化。我们提供了关闭式解的具体情况，并通过数值优化进行探索。我们还证明了 concatenating 现有的最小处理距离和近端增强方法可以保持初始方法的效果。结果显示，共同优化可以进一步提高表现，比 concatenated 方法更好。
</details></li>
</ul>
<hr>
<h2 id="Deep-Complex-U-Net-with-Conformer-for-Audio-Visual-Speech-Enhancement"><a href="#Deep-Complex-U-Net-with-Conformer-for-Audio-Visual-Speech-Enhancement" class="headerlink" title="Deep Complex U-Net with Conformer for Audio-Visual Speech Enhancement"></a>Deep Complex U-Net with Conformer for Audio-Visual Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11059">http://arxiv.org/abs/2309.11059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shafique Ahmed, Chia-Wei Chen, Wenze Ren, Chin-Jou Li, Ernie Chu, Jun-Cheng Chen, Amir Hussain, Hsin-Min Wang, Yu Tsao, Jen-Cheng Hou</li>
<li>for: 提高语音增强系统的性能，使其能够更好地处理语音和视频数据。</li>
<li>methods: 使用深度复杂U-Net架构，并将音频和视频信号进行复杂编码和解码，以及使用嵌入自我注意机制和卷积操作来捕捉语音和视频数据的相互关系。</li>
<li>results: 在COG-MHEAR AVSE Challenge 2023 的基准模型上表现出优于0.14的提升，并在台湾官话语音视频数据集（TMSV）上与状态级模型相当，并且在所有比较模型中表现出最佳result。<details>
<summary>Abstract</summary>
Recent studies have increasingly acknowledged the advantages of incorporating visual data into speech enhancement (SE) systems. In this paper, we introduce a novel audio-visual SE approach, termed DCUC-Net (deep complex U-Net with conformer network). The proposed DCUC-Net leverages complex domain features and a stack of conformer blocks. The encoder and decoder of DCUC-Net are designed using a complex U-Net-based framework. The audio and visual signals are processed using a complex encoder and a ResNet-18 model, respectively. These processed signals are then fused using the conformer blocks and transformed into enhanced speech waveforms via a complex decoder. The conformer blocks consist of a combination of self-attention mechanisms and convolutional operations, enabling DCUC-Net to effectively capture both global and local audio-visual dependencies. Our experimental results demonstrate the effectiveness of DCUC-Net, as it outperforms the baseline model from the COG-MHEAR AVSE Challenge 2023 by a notable margin of 0.14 in terms of PESQ. Additionally, the proposed DCUC-Net performs comparably to a state-of-the-art model and outperforms all other compared models on the Taiwan Mandarin speech with video (TMSV) dataset.
</details>
<details>
<summary>摘要</summary>
近年研究均认可了将视觉数据 integrate 到语音提升（SE）系统中的优势。在这篇论文中，我们介绍了一种新的嵌入式音视频SE方法，称为DCUC-Net（深度复杂U-Net with 准确网络）。我们的DCUC-Net利用复杂Domain特征和一个堆栈的准确块。编码器和解码器都采用了复杂U-Net的框架。音频和视频信号分别通过复杂编码器和ResNet-18模型处理，然后通过准确块进行拼接，并转化为提升后的语音波形。准确块包括自注意机制和卷积操作，使DCUC-Net能够有效地捕捉全局和局部音视频相互依赖关系。我们的实验结果表明，DCUC-Net比基线模型在COG-MHEAR AVSE Challenge 2023中表现出了明显的提升（0.14），并且与当前的状态艺模型相当，在台湾官话语音视频（TMSV）数据集上表现出了最高的性能。
</details></li>
</ul>
<hr>
<h2 id="Ensembling-Multilingual-Pre-Trained-Models-for-Predicting-Multi-Label-Regression-Emotion-Share-from-Speech"><a href="#Ensembling-Multilingual-Pre-Trained-Models-for-Predicting-Multi-Label-Regression-Emotion-Share-from-Speech" class="headerlink" title="Ensembling Multilingual Pre-Trained Models for Predicting Multi-Label Regression Emotion Share from Speech"></a>Ensembling Multilingual Pre-Trained Models for Predicting Multi-Label Regression Emotion Share from Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11014">http://arxiv.org/abs/2309.11014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bagus Tris Atmaja, Akira Sasou</li>
<li>for: 这个论文主要针对的是speech emotion recognition领域的研究和实践应用。</li>
<li>methods: 这个论文使用了ensemble learning方法，将多种预训练模型的结果进行融合，以提高speech emotion recognition的性能。</li>
<li>results: 测试集的spearman correlation coefficient为0.537，开发集的spearman correlation coefficient为0.524，两者都高于之前基于单语言数据的融合方法的研究结果（test集的spearman correlation coefficient为0.476，开发集的spearman correlation coefficient为0.470）。<details>
<summary>Abstract</summary>
Speech emotion recognition has evolved from research to practical applications. Previous studies of emotion recognition from speech have focused on developing models on certain datasets like IEMOCAP. The lack of data in the domain of emotion modeling emerges as a challenge to evaluate models in the other dataset, as well as to evaluate speech emotion recognition models that work in a multilingual setting. This paper proposes an ensemble learning to fuse results of pre-trained models for emotion share recognition from speech. The models were chosen to accommodate multilingual data from English and Spanish. The results show that ensemble learning can improve the performance of the baseline model with a single model and the previous best model from the late fusion. The performance is measured using the Spearman rank correlation coefficient since the task is a regression problem with ranking values. A Spearman rank correlation coefficient of 0.537 is reported for the test set, while for the development set, the score is 0.524. These scores are higher than the previous study of a fusion method from monolingual data, which achieved scores of 0.476 for the test and 0.470 for the development.
</details>
<details>
<summary>摘要</summary>
研究者们在演讲情感识别方面从研究阶段逐渐演化到实际应用。 previous studies on speech emotion recognition have focused on developing models on specific datasets such as IEMOCAP. However, the lack of data in the domain of emotion modeling poses a challenge to evaluate models on other datasets and to evaluate speech emotion recognition models that work in a multilingual setting. This paper proposes an ensemble learning approach to fuse the results of pre-trained models for speech emotion recognition. The models chosen accommodate multilingual data from English and Spanish. The results show that ensemble learning can improve the performance of the baseline model and the previous best model from late fusion. The performance is measured using the Spearman rank correlation coefficient, as the task is a regression problem with ranking values. The reported Spearman rank correlation coefficient for the test set is 0.537, while for the development set, the score is 0.524. These scores are higher than the previous study of a fusion method from monolingual data, which achieved scores of 0.476 for the test and 0.470 for the development.
</details></li>
</ul>
<hr>
<h2 id="Directional-Source-Separation-for-Robust-Speech-Recognition-on-Smart-Glasses"><a href="#Directional-Source-Separation-for-Robust-Speech-Recognition-on-Smart-Glasses" class="headerlink" title="Directional Source Separation for Robust Speech Recognition on Smart Glasses"></a>Directional Source Separation for Robust Speech Recognition on Smart Glasses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.10993">http://arxiv.org/abs/2309.10993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiantian Feng, Ju Lin, Yiteng Huang, Weipeng He, Kaustubh Kalgaonkar, Niko Moritz, Li Wan, Xin Lei, Ming Sun, Frank Seide</li>
<li>for: 提高日常交流中语音识别率和说话者检测精度</li>
<li>methods: 使用高级音频感知和机器学习技术实现实时转录和字幕服务，并利用多极麦克风灵活提高语音识别精度</li>
<li>results: irectional source separation 可以提高语音识别率和说话者检测精度，但是对对话伙伴无效。 joint training Directional source separation 和 ASR 模型可以 achieve the best overall ASR performance.<details>
<summary>Abstract</summary>
Modern smart glasses leverage advanced audio sensing and machine learning technologies to offer real-time transcribing and captioning services, considerably enriching human experiences in daily communications. However, such systems frequently encounter challenges related to environmental noises, resulting in degradation to speech recognition and speaker change detection. To improve voice quality, this work investigates directional source separation using the multi-microphone array. We first explore multiple beamformers to assist source separation modeling by strengthening the directional properties of speech signals. In addition to relying on predetermined beamformers, we investigate neural beamforming in multi-channel source separation, demonstrating that automatic learning directional characteristics effectively improves separation quality. We further compare the ASR performance leveraging separated outputs to noisy inputs. Our results show that directional source separation benefits ASR for the wearer but not for the conversation partner. Lastly, we perform the joint training of the directional source separation and ASR model, achieving the best overall ASR performance.
</details>
<details>
<summary>摘要</summary>
现代智能眼镜利用先进的音频感知和机器学习技术，在实时转录和字幕服务方面提供了很大的便利，对日常交流中的人类体验带来了很大的改善。然而，这些系统经常遇到环境噪音的挑战，导致语音识别和发言者变换的干扰。为了提高音质，本工作研究了多频道源分离。我们首先探讨了多种扩声器，以增强对话语音的方向性特性。此外，我们还 investigate了基于自动学习的神经扩声器在多个通道源分离中的应用，并证明了自动学习方向特性可以有效提高分离质量。最后，我们比较了利用分离输出进行ASR的性能和直接使用噪音输入进行ASR的性能，结果表明irectional source separation对ASR有利，但对对话伙伴无效。最后，我们实现了irectional source separation和ASR模型的共同训练，达到了最佳的总ASR性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/20/cs.SD_2023_09_20/" data-id="clmvt7tbu00m926rd5bvzanlz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_09_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/20/eess.AS_2023_09_20/" class="article-date">
  <time datetime="2023-09-20T14:00:00.000Z" itemprop="datePublished">2023-09-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/20/eess.AS_2023_09_20/">eess.AS - 2023-09-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Neural-TTS-System-with-Parallel-Prosody-Transfer-from-Unseen-Speakers"><a href="#A-Neural-TTS-System-with-Parallel-Prosody-Transfer-from-Unseen-Speakers" class="headerlink" title="A Neural TTS System with Parallel Prosody Transfer from Unseen Speakers"></a>A Neural TTS System with Parallel Prosody Transfer from Unseen Speakers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11487">http://arxiv.org/abs/2309.11487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Slava Shechtman, Raul Fernandez</li>
<li>for: 这个研究的目的是开发一种可以从 parallel text recording 中提取高级别的语音特征，并将其应用于不同的 TTS  voz 中，以实现更加自然和表情充沛的语音读取。</li>
<li>methods: 该研究使用了一种基于神经网络的 TTS 系统，并将其 equiped  avec prosody-control 功能，以便在推理时间对语音输出进行更direct的Shape。</li>
<li>results: 研究表明，该系统可以准确地从新的说话者的 parallel text recording 中提取语音特征，并将其应用于不同的 TTS voz 中，无质量下降，同时保持目标 TTS voz 的identidad，根据一系列主观听力实验的评估。<details>
<summary>Abstract</summary>
Modern neural TTS systems are capable of generating natural and expressive speech when provided with sufficient amounts of training data. Such systems can be equipped with prosody-control functionality, allowing for more direct shaping of the speech output at inference time. In some TTS applications, it may be desirable to have an option that guides the TTS system with an ad-hoc speech recording exemplar to impose an implicit fine-grained, user-preferred prosodic realization for certain input prompts. In this work we present a first-of-its-kind neural TTS system equipped with such functionality to transfer the prosody from a parallel text recording from an unseen speaker. We demonstrate that the proposed system can precisely transfer the speech prosody from novel speakers to various trained TTS voices with no quality degradation, while preserving the target TTS speakers' identity, as evaluated by a set of subjective listening experiments.
</details>
<details>
<summary>摘要</summary>
现代神经网络Text-to-Speech系统可以从充足的训练数据中生成自然和表达力强的语音。这些系统可以搭载受控拍层功能，以更直接在推理时调节语音输出。在某些TTS应用程序中，可能愿意有一个选项，使TTS系统通过额外的即时示例来强制某些输入提示的细腻、用户首选的语音表现。在这种工作中，我们介绍了一种首次实现的神经网络TTS系统，可以将来自未见的说话人的语音特征精确地传递到不同的训练过的TTSvoice中，而无损质量，同时保持目标TTS speaker的身份，根据一组主观听力试验的评价。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/20/eess.AS_2023_09_20/" data-id="clmvt7tcc00oe26rdcfsgajxu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/20/cs.CV_2023_09_20/" class="article-date">
  <time datetime="2023-09-20T13:00:00.000Z" itemprop="datePublished">2023-09-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/20/cs.CV_2023_09_20/">cs.CV - 2023-09-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Understanding-Pose-and-Appearance-Disentanglement-in-3D-Human-Pose-Estimation"><a href="#Understanding-Pose-and-Appearance-Disentanglement-in-3D-Human-Pose-Estimation" class="headerlink" title="Understanding Pose and Appearance Disentanglement in 3D Human Pose Estimation"></a>Understanding Pose and Appearance Disentanglement in 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11667">http://arxiv.org/abs/2309.11667</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krishna Kanth Nakka, Mathieu Salzmann</li>
<li>for: 本研究目的是分析当前领域内最新的自然语言描述学习方法是否能够真正分离 pose 信息和 appearance 信息。</li>
<li>methods: 本研究使用了三种当前领域内最新的自然语言描述学习方法进行分析，即 DenseCap, DensePose, 和 H3DNet。</li>
<li>results: 研究发现，这三种方法中的 pose 代码含有显著的 appearance 信息，而且这些方法的分离效果并不够完善。<details>
<summary>Abstract</summary>
As 3D human pose estimation can now be achieved with very high accuracy in the supervised learning scenario, tackling the case where 3D pose annotations are not available has received increasing attention. In particular, several methods have proposed to learn image representations in a self-supervised fashion so as to disentangle the appearance information from the pose one. The methods then only need a small amount of supervised data to train a pose regressor using the pose-related latent vector as input, as it should be free of appearance information. In this paper, we carry out in-depth analysis to understand to what degree the state-of-the-art disentangled representation learning methods truly separate the appearance information from the pose one. First, we study disentanglement from the perspective of the self-supervised network, via diverse image synthesis experiments. Second, we investigate disentanglement with respect to the 3D pose regressor following an adversarial attack perspective. Specifically, we design an adversarial strategy focusing on generating natural appearance changes of the subject, and against which we could expect a disentangled network to be robust. Altogether, our analyses show that disentanglement in the three state-of-the-art disentangled representation learning frameworks if far from complete, and that their pose codes contain significant appearance information. We believe that our approach provides a valuable testbed to evaluate the degree of disentanglement of pose from appearance in self-supervised 3D human pose estimation.
</details>
<details>
<summary>摘要</summary>
As 3D human pose estimation 可以在超级vised learning scenario 中实现非常高的准确率，因此处理没有3D pose annotations的情况 receiving increasing attention. 特别是，several methods have proposed to learn image representations in a self-supervised fashion so as to disentangle the appearance information from the pose one. The methods then only need a small amount of supervised data to train a pose regressor using the pose-related latent vector as input, as it should be free of appearance information.In this paper, we carry out in-depth analysis to understand to what degree the state-of-the-art disentangled representation learning methods truly separate the appearance information from the pose one. First, we study disentanglement from the perspective of the self-supervised network, via diverse image synthesis experiments. Second, we investigate disentanglement with respect to the 3D pose regressor following an adversarial attack perspective. Specifically, we design an adversarial strategy focusing on generating natural appearance changes of the subject, and against which we could expect a disentangled network to be robust.Altogether, our analyses show that disentanglement in the three state-of-the-art disentangled representation learning frameworks is far from complete, and that their pose codes contain significant appearance information. We believe that our approach provides a valuable testbed to evaluate the degree of disentanglement of pose from appearance in self-supervised 3D human pose estimation.
</details></li>
</ul>
<hr>
<h2 id="Neural-Image-Compression-Using-Masked-Sparse-Visual-Representation"><a href="#Neural-Image-Compression-Using-Masked-Sparse-Visual-Representation" class="headerlink" title="Neural Image Compression Using Masked Sparse Visual Representation"></a>Neural Image Compression Using Masked Sparse Visual Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11661">http://arxiv.org/abs/2309.11661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Jiang, Wei Wang, Yue Chen</li>
<li>for: 这篇论文主要研究了基于稀疏视觉表示（SVR）的神经图像压缩，目的是提高压缩率和压缩后图像质量。</li>
<li>methods: 这篇论文提出了一种基于SVR的压缩方法，其中图像被嵌入到一个离散的 latent space 中，并使用了学习的视觉codebook来表示图像。在编码器和解码器之间共享 codebook，编码器将图像转换为 integer 代码word indices，并将这些指标传输给解码器进行重建。这种方法提出了一种名为 Masked Adaptive Codebook 的学习方法，可以在bitrate和重建质量之间进行负权补偿。</li>
<li>results: 实验结果表明，M-AdaCode 方法可以在 JPEG-AI 标准数据集上实现更高的压缩率和更高的重建质量，并且可以在不同的传输比特率下进行负权补偿。<details>
<summary>Abstract</summary>
We study neural image compression based on the Sparse Visual Representation (SVR), where images are embedded into a discrete latent space spanned by learned visual codebooks. By sharing codebooks with the decoder, the encoder transfers integer codeword indices that are efficient and cross-platform robust, and the decoder retrieves the embedded latent feature using the indices for reconstruction. Previous SVR-based compression lacks effective mechanism for rate-distortion tradeoffs, where one can only pursue either high reconstruction quality or low transmission bitrate. We propose a Masked Adaptive Codebook learning (M-AdaCode) method that applies masks to the latent feature subspace to balance bitrate and reconstruction quality. A set of semantic-class-dependent basis codebooks are learned, which are weighted combined to generate a rich latent feature for high-quality reconstruction. The combining weights are adaptively derived from each input image, providing fidelity information with additional transmission costs. By masking out unimportant weights in the encoder and recovering them in the decoder, we can trade off reconstruction quality for transmission bits, and the masking rate controls the balance between bitrate and distortion. Experiments over the standard JPEG-AI dataset demonstrate the effectiveness of our M-AdaCode approach.
</details>
<details>
<summary>摘要</summary>
我们研究基于稀疏视觉表示（SVR）的神经网络图像压缩，图像被嵌入到学习的视觉码库中的离散特征空间中。通过在编码器和解码器之间共享码库，编码器将转化为整数编码字符串，这些编码字符串是高效穿梭平台强的和可靠的，而解码器通过这些编码字符串来重建图像。 précédente 的 SVR 基于压缩缺乏有效的Rate-Distortion 质量衡量机制，只能追求高重建质量或低传输比特率。我们提出了一种带有掩码（Mask）的自适应码库学习（M-AdaCode）方法，通过掩码在干扰特征空间中进行权重调整，以实现Rate-Distortion 质量衡量机制。我们学习了基于输入图像的semantic类别的基础码库，并将这些基础码库Weightedly 组合，以生成高质量重建的综合特征。编码器中的掩码将掩蔽不重要的权重，而解码器中的掩码将重新还原这些掩码，以实现Rate-Distortion 质量衡量机制。实验结果表明，我们的 M-AdaCode 方法在标准 JPEG-AI 数据集上表现出色。
</details></li>
</ul>
<hr>
<h2 id="GenLayNeRF-Generalizable-Layered-Representations-with-3D-Model-Alignment-for-Multi-Human-View-Synthesis"><a href="#GenLayNeRF-Generalizable-Layered-Representations-with-3D-Model-Alignment-for-Multi-Human-View-Synthesis" class="headerlink" title="GenLayNeRF: Generalizable Layered Representations with 3D Model Alignment for Multi-Human View Synthesis"></a>GenLayNeRF: Generalizable Layered Representations with 3D Model Alignment for Multi-Human View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11627">http://arxiv.org/abs/2309.11627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youssef Abdelkareem, Shady Shehata, Fakhri Karray</li>
<li>for: 这个研究是为了解决多人Scene中的复杂人物 occlusion 问题，提供一个通用的 layered representation 来捕捉多人Scene 的内容。</li>
<li>methods: 我们提出了一个名为 GenLayNeRF 的方法，它使用一个多层架构来分解Scene，并使用一个新的对策机制来进行适应器调整和多观察特征融合，以确保 pixel-level 的体模型与输入视野的同步。</li>
<li>results: 我们的方法在 NVS 中表现出色，与通用 NeRF 方法相比，它能够在几乎没有预期优化的情况下提供高品质的内容生成。而与层化 per-scene NeRF 方法相比，它能够在几乎没有测试时间优化的情况下提供相似或更好的表现。<details>
<summary>Abstract</summary>
Novel view synthesis (NVS) of multi-human scenes imposes challenges due to the complex inter-human occlusions. Layered representations handle the complexities by dividing the scene into multi-layered radiance fields, however, they are mainly constrained to per-scene optimization making them inefficient. Generalizable human view synthesis methods combine the pre-fitted 3D human meshes with image features to reach generalization, yet they are mainly designed to operate on single-human scenes. Another drawback is the reliance on multi-step optimization techniques for parametric pre-fitting of the 3D body models that suffer from misalignment with the images in sparse view settings causing hallucinations in synthesized views. In this work, we propose, GenLayNeRF, a generalizable layered scene representation for free-viewpoint rendering of multiple human subjects which requires no per-scene optimization and very sparse views as input. We divide the scene into multi-human layers anchored by the 3D body meshes. We then ensure pixel-level alignment of the body models with the input views through a novel end-to-end trainable module that carries out iterative parametric correction coupled with multi-view feature fusion to produce aligned 3D models. For NVS, we extract point-wise image-aligned and human-anchored features which are correlated and fused using self-attention and cross-attention modules. We augment low-level RGB values into the features with an attention-based RGB fusion module. To evaluate our approach, we construct two multi-human view synthesis datasets; DeepMultiSyn and ZJU-MultiHuman. The results indicate that our proposed approach outperforms generalizable and non-human per-scene NeRF methods while performing at par with layered per-scene methods without test time optimization.
</details>
<details>
<summary>摘要</summary>
《 Novel View Synthesis of Multi-Human Scenes with Generalizable Layered Scene Representation》 Multi-human scene novel view synthesis （NVS）面临许多挑战，主要是因为人体 occlusion 复杂。层次表示处理这些复杂性，通过将场景分解为多层Radiance Fields，但是它们主要是基于场景优化，因此效率低。通用人体视图合成方法将预先适应的3D人体模型与图像特征结合起来，但是它们主要是针对单个人体场景设计。另一个缺点是在缺视设定下，使用多步优化技术进行参数预定的3D人体模型会导致投影幻觉。在这种情况下，我们提出了GenLayNeRF，一种通用层次场景表示，用于无需场景优化和非常罕见的视图输入进行自由视角渲染多个人体主题。我们将场景分解成多个人体层，由3D人体模型anchor。然后，我们通过一种新的终端可调模块，通过iterative parametric correction和多视图特征融合来确保像素级匹配3D模型与输入视图。 для NVS，我们提取人体嵌入和图像对齐的点级特征，并使用自注意力和交叉注意力模块进行相关和融合。此外，我们还将低级RGB值加入特征中，使用注意力基于RGB融合模块。为了评估我们的方法，我们建立了两个多个人体视图合成数据集：DeepMultiSyn和ZJU-MultiHuman。结果表明，我们的提出方法在比较通用和非人体场景NeRF方法的同时，能够达到相同的性能水平，而不需要测试时优化。
</details></li>
</ul>
<hr>
<h2 id="Sentence-Attention-Blocks-for-Answer-Grounding"><a href="#Sentence-Attention-Blocks-for-Answer-Grounding" class="headerlink" title="Sentence Attention Blocks for Answer Grounding"></a>Sentence Attention Blocks for Answer Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11593">http://arxiv.org/abs/2309.11593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedalireza Khoshsirat, Chandra Kambhamettu</li>
<li>for: 本文提出了一种新的建筑块，即 Sentence Attention Block，以解决文本描述答案问题中的问题。</li>
<li>methods: 本文使用了一种已知的注意力方法，并通过小改进，提高了结果。</li>
<li>results: 本文在 TextVQA-X、VQS、VQA-X 和 VizWiz-VQA-Grounding 数据集上达到了状态的最佳准确率。<details>
<summary>Abstract</summary>
Answer grounding is the task of locating relevant visual evidence for the Visual Question Answering task. While a wide variety of attention methods have been introduced for this task, they suffer from the following three problems: designs that do not allow the usage of pre-trained networks and do not benefit from large data pre-training, custom designs that are not based on well-grounded previous designs, therefore limiting the learning power of the network, or complicated designs that make it challenging to re-implement or improve them. In this paper, we propose a novel architectural block, which we term Sentence Attention Block, to solve these problems. The proposed block re-calibrates channel-wise image feature-maps by explicitly modeling inter-dependencies between the image feature-maps and sentence embedding. We visually demonstrate how this block filters out irrelevant feature-maps channels based on sentence embedding. We start our design with a well-known attention method, and by making minor modifications, we improve the results to achieve state-of-the-art accuracy. The flexibility of our method makes it easy to use different pre-trained backbone networks, and its simplicity makes it easy to understand and be re-implemented. We demonstrate the effectiveness of our method on the TextVQA-X, VQS, VQA-X, and VizWiz-VQA-Grounding datasets. We perform multiple ablation studies to show the effectiveness of our design choices.
</details>
<details>
<summary>摘要</summary>
Answer grounding 任务是为Visual Question Answering 任务中找到相关的视觉证据。虽然过去的很多注意力方法被提出，但它们受到以下三个问题的限制：不允许使用预训练网络，不能充分利用大规模预训练数据，或者自定义的设计不基于已有的固定设计，因此限制了网络的学习能力。在这篇论文中，我们提出了一种新的建筑块，我们称之为句子注意力块（Sentence Attention Block），以解决这些问题。我们的块通过显式地模型图像特征地图和句子嵌入的间接关系来重新准确化通道 wise 图像特征地图。我们可视示了该块如何基于句子嵌入来过滤不相关的通道 wise 图像特征地图。我们从一个已知的注意力方法开始，通过小量修改，我们提高了结果，达到了状态之Art accuracy。我们的方法的灵活性使得可以使用不同的预训练后台网络，其简洁性使得容易理解和重新实现。我们在TextVQA-X、VQS、VQA-X 和 VizWiz-VQA-Grounding 数据集上进行了多个缺省研究，以证明我们的设计选择的有效性。
</details></li>
</ul>
<hr>
<h2 id="Continuous-Levels-of-Detail-for-Light-Field-Networks"><a href="#Continuous-Levels-of-Detail-for-Light-Field-Networks" class="headerlink" title="Continuous Levels of Detail for Light Field Networks"></a>Continuous Levels of Detail for Light Field Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11591">http://arxiv.org/abs/2309.11591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AugmentariumLab/continuous-lfn">https://github.com/AugmentariumLab/continuous-lfn</a></li>
<li>paper_authors: David Li, Brandon Y. Feng, Amitabh Varshney</li>
<li>for: 提高rendering效果和资源利用率，通过使用连续多级详细度（LODs）生成神经表示。</li>
<li>methods: 使用权重梯度滤波和重要性 sampling 技术，实现精细控制详细度的调整，以适应不同的 rendering 条件。</li>
<li>results: 提出一种基于连续 LODs 的神经网络表示方法，可以实现进度式流式神经网络表示，降低渲染延迟和资源使用率。<details>
<summary>Abstract</summary>
Recently, several approaches have emerged for generating neural representations with multiple levels of detail (LODs). LODs can improve the rendering by using lower resolutions and smaller model sizes when appropriate. However, existing methods generally focus on a few discrete LODs which suffer from aliasing and flicker artifacts as details are changed and limit their granularity for adapting to resource limitations. In this paper, we propose a method to encode light field networks with continuous LODs, allowing for finely tuned adaptations to rendering conditions. Our training procedure uses summed-area table filtering allowing efficient and continuous filtering at various LODs. Furthermore, we use saliency-based importance sampling which enables our light field networks to distribute their capacity, particularly limited at lower LODs, towards representing the details viewers are most likely to focus on. Incorporating continuous LODs into neural representations enables progressive streaming of neural representations, decreasing the latency and resource utilization for rendering.
</details>
<details>
<summary>摘要</summary>
近些年，多级细节（LOD）生成神经表示方法得到了一些突破。LOD可以通过使用较低的分辨率和小型模型来提高渲染。然而，现有方法通常只关注一些精确的LOD，这会导致抖抖和闪烁artifacts，限制其细节适应资源的变化。在这篇论文中，我们提出了一种使用连续LOD编码光场网络方法，允许为渲染条件进行细化适应。我们的训练过程使用总面积表 filtering，以实现高效的连续filtering在不同LODs。此外，我们使用关注度基于的重要性采样，使我们的光场网络能够更好地分配其容量，特别是在较低的LODs。将连续LODintegrated into神经表示允许进行进程式流动神经表示，降低渲染的延迟和资源利用率。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Kernel-Temporal-Segmentation-as-an-Adaptive-Tokenizer-for-Long-form-Video-Understanding"><a href="#Revisiting-Kernel-Temporal-Segmentation-as-an-Adaptive-Tokenizer-for-Long-form-Video-Understanding" class="headerlink" title="Revisiting Kernel Temporal Segmentation as an Adaptive Tokenizer for Long-form Video Understanding"></a>Revisiting Kernel Temporal Segmentation as an Adaptive Tokenizer for Long-form Video Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11569">http://arxiv.org/abs/2309.11569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Afham, Satya Narayan Shukla, Omid Poursaeed, Pengchuan Zhang, Ashish Shah, Sernam Lim</li>
<li>for: 提高长视频理解的效果，适应实际视频中的 semantic consistency。</li>
<li>methods: 基于 Kernel Temporal Segmentation (KTS) 的适应 sampling 和 tokenization 方法，不需要任务特定的supervision或固定长度的clip。</li>
<li>results: 在视频分类和 temporal action localization 任务上实现了consistent improvement，并达到了长视频模型的state-of-the-art表现。<details>
<summary>Abstract</summary>
While most modern video understanding models operate on short-range clips, real-world videos are often several minutes long with semantically consistent segments of variable length. A common approach to process long videos is applying a short-form video model over uniformly sampled clips of fixed temporal length and aggregating the outputs. This approach neglects the underlying nature of long videos since fixed-length clips are often redundant or uninformative. In this paper, we aim to provide a generic and adaptive sampling approach for long-form videos in lieu of the de facto uniform sampling. Viewing videos as semantically consistent segments, we formulate a task-agnostic, unsupervised, and scalable approach based on Kernel Temporal Segmentation (KTS) for sampling and tokenizing long videos. We evaluate our method on long-form video understanding tasks such as video classification and temporal action localization, showing consistent gains over existing approaches and achieving state-of-the-art performance on long-form video modeling.
</details>
<details>
<summary>摘要</summary>
当今大多数视频理解模型都是在短范围clip上运行，但实际世界中的视频往往是数分钟长，并且有semantically consistent的分割段。一种常见的方法处理长视频是，将短视频模型应用于固定 temporal length的clip上，并将输出集成。这种方法忽略了长视频的本质，因为固定长clip经常是 redundancy or uninformative。在这篇论文中，我们目的是提供一种通用和适应性的抽样方法，以代替现有的固定抽样。视频被视为semantically consistent的分割段，我们基于Kernel Temporal Segmentation（KTS）提出了一种任务无关、无监督和可扩展的方法，用于抽取和 tokenize 长视频。我们对长视频理解任务，如视频分类和 temporal action localization，进行了评估，并显示了与现有方法相比的consistent提升，并实现了长视频模型的州际性表现。
</details></li>
</ul>
<hr>
<h2 id="A-Large-scale-Dataset-for-Audio-Language-Representation-Learning"><a href="#A-Large-scale-Dataset-for-Audio-Language-Representation-Learning" class="headerlink" title="A Large-scale Dataset for Audio-Language Representation Learning"></a>A Large-scale Dataset for Audio-Language Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11500">http://arxiv.org/abs/2309.11500</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Luoyi Sun, Xuenan Xu, Mengyue Wu, Weidi Xie</li>
<li>for: 这篇论文是为了提出一个新的自动音频描述生成管道，以及构建一个大规模、高质量的音频语言数据集（Auto-ACD）。</li>
<li>methods: 该论文使用了一系列公共工具或 API，自动生成了大量的音频描述文本。</li>
<li>results: 论文通过在不同下游任务上训练 популяр的模型，展示了对 Audio-Language Retrieval、Audio Captioning 和环境分类等任务的性能改进。此外，论文还提出了一个新的测试集，并为音频语言任务提供了一个 referential 平台。<details>
<summary>Abstract</summary>
The AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets. However, in the audio representation learning community, the present audio-language datasets suffer from limitations such as insufficient volume, simplistic content, and arduous collection procedures. To tackle these challenges, we present an innovative and automatic audio caption generation pipeline based on a series of public tools or APIs, and construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.9M audio-text pairs. To demonstrate the effectiveness of the proposed dataset, we train popular models on our dataset and show performance improvement on various downstream tasks, namely, audio-language retrieval, audio captioning, environment classification. In addition, we establish a novel test set and provide a benchmark for audio-text tasks. The proposed dataset will be released at https://auto-acd.github.io/.
</details>
<details>
<summary>摘要</summary>
《人工智能社区在开发强大基础模型方面已经做出了 significiant 进步，这些基础模型得益于大规模多modal数据驱动。然而，在音频表示学术社区中，现有的音频语言数据集受到一些限制，如数据量不足、内容过于简单、收集过程较为繁琐。为了解决这些挑战，我们提出了一种创新的自动音频caption生成管道，基于一系列公共工具或API，并构建了大规模、高质量的音频语言数据集，名为Auto-ACD，包含超过190万个音频文本对。为了证明我们的数据集的效iveness，我们在我们的数据集上训练了popular模型，并在多个下游任务上显示了性能改进，包括音频语言检索、音频captioning、环境分类。此外，我们设立了一个新的测试集，并提供了音频文本任务的benchmark。我们计划在https://auto-acd.github.io/上发布我们的数据集。》Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="FreeU-Free-Lunch-in-Diffusion-U-Net"><a href="#FreeU-Free-Lunch-in-Diffusion-U-Net" class="headerlink" title="FreeU: Free Lunch in Diffusion U-Net"></a>FreeU: Free Lunch in Diffusion U-Net</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11497">http://arxiv.org/abs/2309.11497</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ChenyangSi/FreeU">https://github.com/ChenyangSi/FreeU</a></li>
<li>paper_authors: Chenyang Si, Ziqi Huang, Yuming Jiang, Ziwei Liu</li>
<li>For: 提高 diffusion U-Net 生成质量，无需额外训练或调整。* Methods: 利用 U-Net 架构的 skip connections 和 backbone feature maps，通过重新权重分配来提高生成质量。* Results: 在图像和视频生成任务中，提出了一种简单 yet effective 的方法 FreeU，可以轻松地与现有的 diffusion 模型结合使用，提高生成质量。<details>
<summary>Abstract</summary>
In this paper, we uncover the untapped potential of diffusion U-Net, which serves as a "free lunch" that substantially improves the generation quality on the fly. We initially investigate the key contributions of the U-Net architecture to the denoising process and identify that its main backbone primarily contributes to denoising, whereas its skip connections mainly introduce high-frequency features into the decoder module, causing the network to overlook the backbone semantics. Capitalizing on this discovery, we propose a simple yet effective method-termed "FreeU" - that enhances generation quality without additional training or finetuning. Our key insight is to strategically re-weight the contributions sourced from the U-Net's skip connections and backbone feature maps, to leverage the strengths of both components of the U-Net architecture. Promising results on image and video generation tasks demonstrate that our FreeU can be readily integrated to existing diffusion models, e.g., Stable Diffusion, DreamBooth, ModelScope, Rerender and ReVersion, to improve the generation quality with only a few lines of code. All you need is to adjust two scaling factors during inference. Project page: https://chenyangsi.top/FreeU/.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们揭示了扩散U-Net的未利用潜力，它作为一种"免费的午餐"，可以在飞行中显著提高生成质量。我们首先调查扩散U-Net的建筑均衡对减噪过程的关键贡献，并发现其主要脊梁主要做减噪，而跳转连接主要将高频特征引入到解码模块，使网络忽略脊梁 semantics。基于这一发现，我们提出了一种简单 yet effective的方法——FreeU，可以无需额外训练或微调，提高生成质量。我们关键的思路是在扩散U-Net的跳转连接和脊梁特征图之间进行权重调整，以利用扩散U-Net的两个组件之间的优势。 promising results on image and video generation tasks show that our FreeU can be easily integrated into existing diffusion models, such as Stable Diffusion, DreamBooth, ModelScope, Rerender and ReVersion, to improve the generation quality with only a few lines of code. All you need is to adjust two scaling factors during inference. Project page: <https://chenyangsi.top/FreeU/>.
</details></li>
</ul>
<hr>
<h2 id="Budget-Aware-Pruning-Handling-Multiple-Domains-with-Less-Parameters"><a href="#Budget-Aware-Pruning-Handling-Multiple-Domains-with-Less-Parameters" class="headerlink" title="Budget-Aware Pruning: Handling Multiple Domains with Less Parameters"></a>Budget-Aware Pruning: Handling Multiple Domains with Less Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11464">http://arxiv.org/abs/2309.11464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Felipe dos Santos, Rodrigo Berriel, Thiago Oliveira-Santos, Nicu Sebe, Jurandy Almeida</li>
<li>for: 这个研究的目的是实现多元领域学习（Multi-Domain Learning），即让模型在多个领域中表现良好，并且降低计算成本和模型大小。</li>
<li>methods: 这个研究使用了削除策略来实现模型缩减，即鼓励所有领域使用相同的子集 filters 来构成模型，并将不使用的 filters 削除。</li>
<li>results: 研究获得了与基准模型相似的分类性能，并且降低了计算成本和模型大小。另外，这个方法在资源有限的设备上也能够更好地运行。<details>
<summary>Abstract</summary>
Deep learning has achieved state-of-the-art performance on several computer vision tasks and domains. Nevertheless, it still has a high computational cost and demands a significant amount of parameters. Such requirements hinder the use in resource-limited environments and demand both software and hardware optimization. Another limitation is that deep models are usually specialized into a single domain or task, requiring them to learn and store new parameters for each new one. Multi-Domain Learning (MDL) attempts to solve this problem by learning a single model that is capable of performing well in multiple domains. Nevertheless, the models are usually larger than the baseline for a single domain. This work tackles both of these problems: our objective is to prune models capable of handling multiple domains according to a user-defined budget, making them more computationally affordable while keeping a similar classification performance. We achieve this by encouraging all domains to use a similar subset of filters from the baseline model, up to the amount defined by the user's budget. Then, filters that are not used by any domain are pruned from the network. The proposed approach innovates by better adapting to resource-limited devices while, to our knowledge, being the only work that handles multiple domains at test time with fewer parameters and lower computational complexity than the baseline model for a single domain.
</details>
<details>
<summary>摘要</summary>
深度学习已经在计算机视觉任务和领域上达到了状态对抗性。然而，它仍然具有高的计算成本和需要较多的参数。这些限制使得在资源有限的环境中使用它们变得困难，需要软件和硬件优化。另外，深度模型通常是专门为单个领域或任务设计的，因此它们需要学习和存储每个新领域或任务的新参数。多个领域学习（MDL）尝试解决这个问题，通过学习一个能够在多个领域中表现好的单一模型。然而，这些模型通常比基eline模型更大。本工作解决了这两个问题：我们的目标是使用用户定义的预算来采样和裁剪模型，使其在计算上更加可持预算而仍保持相似的分类性能。我们实现了这一点通过优化所有领域使用基eline模型的相似subset of filters，并且不用于任何领域的筛子被裁剪出去。我们的方法创新在资源有限的设备上更好地适应，并且，至于我们所知道的，是唯一一个在测试时处理多个领域的方法，使用 fewer parameters 和更低的计算复杂度来比基eline模型在单个领域中表现。
</details></li>
</ul>
<hr>
<h2 id="Weight-Averaging-Improves-Knowledge-Distillation-under-Domain-Shift"><a href="#Weight-Averaging-Improves-Knowledge-Distillation-under-Domain-Shift" class="headerlink" title="Weight Averaging Improves Knowledge Distillation under Domain Shift"></a>Weight Averaging Improves Knowledge Distillation under Domain Shift</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11446">http://arxiv.org/abs/2309.11446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vorobeevich/distillation-in-dg">https://github.com/vorobeevich/distillation-in-dg</a></li>
<li>paper_authors: Valeriy Berezovskiy, Nikita Morozov</li>
<li>for: 本研究探讨了知识塑化（KD）技术在不同领域数据上的性能。</li>
<li>methods: 本研究使用了学习 teacher 网络和学生网络，并对学生网络进行了权重平均技术。</li>
<li>results: 研究发现，权重平均技术可以提高知识塑化在不同领域数据上的性能。此外，提出了一种简单的权重平均策略，不需要在训练过程中评估验证数据，并证明其与SWAD和SMA相当。<details>
<summary>Abstract</summary>
Knowledge distillation (KD) is a powerful model compression technique broadly used in practical deep learning applications. It is focused on training a small student network to mimic a larger teacher network. While it is widely known that KD can offer an improvement to student generalization in i.i.d setting, its performance under domain shift, i.e. the performance of student networks on data from domains unseen during training, has received little attention in the literature. In this paper we make a step towards bridging the research fields of knowledge distillation and domain generalization. We show that weight averaging techniques proposed in domain generalization literature, such as SWAD and SMA, also improve the performance of knowledge distillation under domain shift. In addition, we propose a simplistic weight averaging strategy that does not require evaluation on validation data during training and show that it performs on par with SWAD and SMA when applied to KD. We name our final distillation approach Weight-Averaged Knowledge Distillation (WAKD).
</details>
<details>
<summary>摘要</summary>
知识塑化（KD）是一种广泛应用在深度学习实践中的模型压缩技术。它关注训练一个小学生网络，以模仿一个更大的教师网络。虽然广泛认知KD可以提高学生网络在同一个分布下的泛化性能，但它在领域转移情况下的性能尚未得到了文献的充分关注。在这篇论文中，我们尝试将知识塑化和领域总结两个领域联系起来。我们表明了在领域转移情况下使用Weight averaging技术，如SWAD和SMA，可以提高知识塑化的性能。此外，我们还提出了一种简单的Weight averaging策略，不需要在训练过程中评估验证数据，并证明它与SWAD和SMA在KD中具有相同的性能。我们将这种最终塑化方法称为Weight-Averaged Knowledge Distillation（WAKD）。
</details></li>
</ul>
<hr>
<h2 id="SkeleTR-Towrads-Skeleton-based-Action-Recognition-in-the-Wild"><a href="#SkeleTR-Towrads-Skeleton-based-Action-Recognition-in-the-Wild" class="headerlink" title="SkeleTR: Towrads Skeleton-based Action Recognition in the Wild"></a>SkeleTR: Towrads Skeleton-based Action Recognition in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11445">http://arxiv.org/abs/2309.11445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haodong Duan, Mingze Xu, Bing Shuai, Davide Modolo, Zhuowen Tu, Joseph Tighe, Alessandro Bergamo</li>
<li>for: 本文 targets more general scenarios of action recognition, such as variable number of people and various forms of interaction.</li>
<li>methods: 方法使用 two-stage paradigm，首先使用图 convolutions 模型每个人的内部动作动态，然后使用堆式 transformer encoder 捕捉人之间的交互。</li>
<li>results: 对多种 skeleton-based action recognition 任务进行了全面的解决，包括视频级动作分类、实例级动作检测和群体活动识别。实现了 transfer learning 和共同训练 across different action tasks and datasets，并且在多个 benchmark 上达到了 state-of-the-art 性能。<details>
<summary>Abstract</summary>
We present SkeleTR, a new framework for skeleton-based action recognition. In contrast to prior work, which focuses mainly on controlled environments, we target more general scenarios that typically involve a variable number of people and various forms of interaction between people. SkeleTR works with a two-stage paradigm. It first models the intra-person skeleton dynamics for each skeleton sequence with graph convolutions, and then uses stacked Transformer encoders to capture person interactions that are important for action recognition in general scenarios. To mitigate the negative impact of inaccurate skeleton associations, SkeleTR takes relative short skeleton sequences as input and increases the number of sequences. As a unified solution, SkeleTR can be directly applied to multiple skeleton-based action tasks, including video-level action classification, instance-level action detection, and group-level activity recognition. It also enables transfer learning and joint training across different action tasks and datasets, which result in performance improvement. When evaluated on various skeleton-based action recognition benchmarks, SkeleTR achieves the state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
我们提出了SkeleTR，一个新的骨架基于动作识别框架。与先前的工作不同，SkeleTR针对更加一般的场景，通常包括变量数量的人员和人员之间多种互动。SkeleTR采用两stage架构，首先使用图 convolution 模型每个骨sequences的内部动作动态，然后使用堆式 transformer 编码器捕捉人员之间重要的动作识别。为了减轻不准确的骨 association 的影响，SkeleTR 使用短skeleton sequence 作为输入，并增加输入序列的数量。作为一个通用解决方案，SkeleTR 可以直接应用于多种骨基于动作任务，包括视频级动作分类、实例级动作检测和群体活动识别。它还允许转移学习和共同训练不同的动作任务和数据集，从而提高性能。在多种骨基于动作识别 benchmark 上评估，SkeleTR 实现了状态的极佳表现。
</details></li>
</ul>
<hr>
<h2 id="Signature-Activation-A-Sparse-Signal-View-for-Holistic-Saliency"><a href="#Signature-Activation-A-Sparse-Signal-View-for-Holistic-Saliency" class="headerlink" title="Signature Activation: A Sparse Signal View for Holistic Saliency"></a>Signature Activation: A Sparse Signal View for Holistic Saliency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11443">http://arxiv.org/abs/2309.11443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dtak/signature-activation">https://github.com/dtak/signature-activation</a></li>
<li>paper_authors: Jose Roberto Tello Ayala, Akl C. Fahed, Weiwei Pan, Eugene V. Pomerantsev, Patrick T. Ellinor, Anthony Philippakis, Finale Doshi-Velez</li>
<li>for: 这篇论文的目的是提出一种基于Machine Learning的医疗图像处理方法，以提高医疗图像识别的透明度和解释性。</li>
<li>methods: 本文引入了Signature Activation，一种可靠性方法，它可以对于卷积神经网络（CNN）的输出生成整体和无关对象的解释。本方法基于医疗图像中的前景和背景物件之间的显著差异。</li>
<li>results: 本文透过评估 coronary angiogram 中的病变检测，证明了 Signature Activation 的可靠性和有用性。<details>
<summary>Abstract</summary>
The adoption of machine learning in healthcare calls for model transparency and explainability. In this work, we introduce Signature Activation, a saliency method that generates holistic and class-agnostic explanations for Convolutional Neural Network (CNN) outputs. Our method exploits the fact that certain kinds of medical images, such as angiograms, have clear foreground and background objects. We give theoretical explanation to justify our methods. We show the potential use of our method in clinical settings through evaluating its efficacy for aiding the detection of lesions in coronary angiograms.
</details>
<details>
<summary>摘要</summary>
《机器学习在医疗领域的应用需要模型的透明度和解释性》。在这项工作中，我们介绍了《签名活化》，一种可以生成整体和无类别的解释方法，用于 convolutional neural network（CNN）输出。我们的方法利用了某些医疗图像，如血管agram，具有明确的前景和背景对象。我们给出了理论解释，以便证明我们的方法。我们通过评估其在 coronary angiogram 中的可用性，显示了我们的方法在临床应用中的潜在价值。
</details></li>
</ul>
<hr>
<h2 id="CalibFPA-A-Focal-Plane-Array-Imaging-System-based-on-Online-Deep-Learning-Calibration"><a href="#CalibFPA-A-Focal-Plane-Array-Imaging-System-based-on-Online-Deep-Learning-Calibration" class="headerlink" title="CalibFPA: A Focal Plane Array Imaging System based on Online Deep-Learning Calibration"></a>CalibFPA: A Focal Plane Array Imaging System based on Online Deep-Learning Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11421">http://arxiv.org/abs/2309.11421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alper Güngör, M. Umut Bahceci, Yasin Ergen, Ahmet Sözak, O. Oner Ekiz, Tolga Yelboga, Tolga Çukur</li>
<li>for: 这个论文的目的是提出一种基于深度学习的压缩镜头数组系统（CalibFPA），以实现高分辨率（HR）成像，并且不需要线上准备。</li>
<li>methods: 该系统使用了电子控制的空间光模ulators（SLM）进行多重编码，并使用了一个深度学习网络来在多个LR测量中 correect 系统不良的影响。</li>
<li>results: 在模拟和实验数据上，CalibFPA的性能超过了现有的压缩镜头数组方法，并且进行了系统元素的分析和计算复杂度的评估。<details>
<summary>Abstract</summary>
Compressive focal plane arrays (FPA) enable cost-effective high-resolution (HR) imaging by acquisition of several multiplexed measurements on a low-resolution (LR) sensor. Multiplexed encoding of the visual scene is typically performed via electronically controllable spatial light modulators (SLM). An HR image is then reconstructed from the encoded measurements by solving an inverse problem that involves the forward model of the imaging system. To capture system non-idealities such as optical aberrations, a mainstream approach is to conduct an offline calibration scan to measure the system response for a point source at each spatial location on the imaging grid. However, it is challenging to run calibration scans when using structured SLMs as they cannot encode individual grid locations. In this study, we propose a novel compressive FPA system based on online deep-learning calibration of multiplexed LR measurements (CalibFPA). We introduce a piezo-stage that locomotes a pre-printed fixed coded aperture. A deep neural network is then leveraged to correct for the influences of system non-idealities in multiplexed measurements without the need for offline calibration scans. Finally, a deep plug-and-play algorithm is used to reconstruct images from corrected measurements. On simulated and experimental datasets, we demonstrate that CalibFPA outperforms state-of-the-art compressive FPA methods. We also report analyses to validate the design elements in CalibFPA and assess computational complexity.
</details>
<details>
<summary>摘要</summary>
高度压缩的投影平面阵列（FPA）可以实现低成本高分辨率（HR）成像，通过多个多样化测量在低分辨率（LR）感知器上。多样化编码视场通常通过电子控制可变光学模拟器（SLM）进行。然后，从编码测量中重建HR图像，通过解决一个反射问题，该问题涉及到成像系统的前向模型。但是，使用结构化SLM时难以进行线上准备扫描，以便测量系统响应点源在每个空间位置上。在本研究中，我们提出了一种新的压缩FPA系统，基于在线深度学习准备多样化LR测量（CalibFPA）。我们引入了一个 piezo 阶段，使得预制印刷的固定编码窗口在不同的空间位置上移动。然后，我们利用了深度神经网络来纠正多样化测量中系统非理想的影响，无需进行线上准备扫描。最后，我们使用了深度插件播客算法来重建图像。在模拟和实验数据集上，我们证明了CalibFPA的性能比现有压缩FPA方法更高。我们还进行了分析，以验证设计元素的合理性和计算复杂性。
</details></li>
</ul>
<hr>
<h2 id="CNNs-for-JPEGs-A-Study-in-Computational-Cost"><a href="#CNNs-for-JPEGs-A-Study-in-Computational-Cost" class="headerlink" title="CNNs for JPEGs: A Study in Computational Cost"></a>CNNs for JPEGs: A Study in Computational Cost</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11417">http://arxiv.org/abs/2309.11417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Felipe dos Santos, Nicu Sebe, Jurandy Almeida</li>
<li>for: 本文旨在研究频域预处理后的深度学习模型，以优化计算成本和参数数量。</li>
<li>methods: 本文使用了DCT频域表示法，并对传统 CNN 架构进行了修改，以适应频域数据。</li>
<li>results: 本文提出了一些手动和数据驱动的技术来降低计算成本和参数数量，以实现高效且精准的频域深度学习模型。<details>
<summary>Abstract</summary>
Convolutional neural networks (CNNs) have achieved astonishing advances over the past decade, defining state-of-the-art in several computer vision tasks. CNNs are capable of learning robust representations of the data directly from the RGB pixels. However, most image data are usually available in compressed format, from which the JPEG is the most widely used due to transmission and storage purposes demanding a preliminary decoding process that have a high computational load and memory usage. For this reason, deep learning methods capable of learning directly from the compressed domain have been gaining attention in recent years. Those methods usually extract a frequency domain representation of the image, like DCT, by a partial decoding, and then make adaptation to typical CNNs architectures to work with them. One limitation of these current works is that, in order to accommodate the frequency domain data, the modifications made to the original model increase significantly their amount of parameters and computational complexity. On one hand, the methods have faster preprocessing, since the cost of fully decoding the images is avoided, but on the other hand, the cost of passing the images though the model is increased, mitigating the possible upside of accelerating the method. In this paper, we propose a further study of the computational cost of deep models designed for the frequency domain, evaluating the cost of decoding and passing the images through the network. We also propose handcrafted and data-driven techniques for reducing the computational complexity and the number of parameters for these models in order to keep them similar to their RGB baselines, leading to efficient models with a better trade off between computational cost and accuracy.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在过去的一代时间内取得了非常的进步，在计算机视觉任务中定义了状态的艺术。CNN可以直接从RGB像素上学习坚实的数据表示。然而，大多数图像数据通常是压缩形式，JPEG是最常用的，因为传输和存储目的需要高计算负担和内存使用。为此，可以直接从压缩领域学习深度学习方法在过去几年内得到了关注。这些方法通常提取图像的频率频谱表示，例如DCT，通过部分解码，然后将其与传统的CNN架构进行适应。现有的方法的一个限制是，为了适应频率频谱数据，模型的修改会增加显著。一方面，预处理更快，因为完全解码图像的成本被避免了，但另一方面，通过网络传输图像的成本增加，这可能导致加速方法的可能性减退。在这篇论文中，我们将进一步研究深度模型在频率频谱频谱上的计算成本，以及图像传输和网络传输的成本。我们还将提出手工和数据驱动的技术，以减少模型的计算复杂性和参数数量，以保持与RGB基eline相似的效率，从而实现更好的计算成本和准确性的负担平衡。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-motion-trajectory-segmentation-of-rigid-bodies-using-a-novel-screw-based-trajectory-shape-representation"><a href="#Enhancing-motion-trajectory-segmentation-of-rigid-bodies-using-a-novel-screw-based-trajectory-shape-representation" class="headerlink" title="Enhancing motion trajectory segmentation of rigid bodies using a novel screw-based trajectory-shape representation"></a>Enhancing motion trajectory segmentation of rigid bodies using a novel screw-based trajectory-shape representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11413">http://arxiv.org/abs/2309.11413</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arno Verduyn, Maxim Vochten, Joris De Schutter</li>
<li>for: 这篇论文主要针对3D固体运动的轨迹分割。</li>
<li>methods: 该论文提出了一种新的轨迹表示方法，它包括一个 геометрический进度率和一个第三阶轨迹形态描述器，并且具有一些惯性性和参考点无关性的特点。</li>
<li>results: 该论文使用自我监督分割方法进行验证，在实验和真实的人类斟 Pouring 动作记录中表现出更加稳定和一致的分割结果，与传统表示方法相比。<details>
<summary>Abstract</summary>
Trajectory segmentation refers to dividing a trajectory into meaningful consecutive sub-trajectories. This paper focuses on trajectory segmentation for 3D rigid-body motions. Most segmentation approaches in the literature represent the body's trajectory as a point trajectory, considering only its translation and neglecting its rotation. We propose a novel trajectory representation for rigid-body motions that incorporates both translation and rotation, and additionally exhibits several invariant properties. This representation consists of a geometric progress rate and a third-order trajectory-shape descriptor. Concepts from screw theory were used to make this representation time-invariant and also invariant to the choice of body reference point. This new representation is validated for a self-supervised segmentation approach, both in simulation and using real recordings of human-demonstrated pouring motions. The results show a more robust detection of consecutive submotions with distinct features and a more consistent segmentation compared to conventional representations. We believe that other existing segmentation methods may benefit from using this trajectory representation to improve their invariance.
</details>
<details>
<summary>摘要</summary>
准确地描述行走过程的分段是指将行走过程分解成有意义的连续子过程。这篇论文关注于三维固定体运动的轨迹分段。大多数文献中的分段方法只考虑体的翻译和忽略其旋转。我们提出了一种新的轨迹表示方法，该方法包括一个 геометрический进度率和一个第三阶轨迹形态描述器。我们使用了滚筒理论来使这种表示方法时间不变和参照点无关。这种新的表示方法在自主监督分段方法中得到验证，包括在模拟和真实的人类倒 Pouring 动作记录中。结果显示，使用这种轨迹表示方法可以更好地检测出不同特征的连续子过程，并且比传统表示方法更加一致。我们认为其他现有的分段方法可能会从这种轨迹表示方法中受益，以提高其对称性。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-learning-unveils-change-in-urban-housing-from-street-level-images"><a href="#Self-supervised-learning-unveils-change-in-urban-housing-from-street-level-images" class="headerlink" title="Self-supervised learning unveils change in urban housing from street-level images"></a>Self-supervised learning unveils change in urban housing from street-level images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11354">http://arxiv.org/abs/2309.11354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steven Stalder, Michele Volpi, Nicolas Büttner, Stephen Law, Kenneth Harttgen, Esra Suel</li>
<li>for:  tracks progress in urban housing, specifically in London’s housing supply</li>
<li>methods:  uses deep learning-based computer vision methods and self-supervised techniques to measure change in street-level images</li>
<li>results:  successfully identified point-level change in London’s housing supply and distinguished between major and minor change, providing timely information for urban planning and policy decisions.<details>
<summary>Abstract</summary>
Cities around the world face a critical shortage of affordable and decent housing. Despite its critical importance for policy, our ability to effectively monitor and track progress in urban housing is limited. Deep learning-based computer vision methods applied to street-level images have been successful in the measurement of socioeconomic and environmental inequalities but did not fully utilize temporal images to track urban change as time-varying labels are often unavailable. We used self-supervised methods to measure change in London using 15 million street images taken between 2008 and 2021. Our novel adaptation of Barlow Twins, Street2Vec, embeds urban structure while being invariant to seasonal and daily changes without manual annotations. It outperformed generic embeddings, successfully identified point-level change in London's housing supply from street-level images, and distinguished between major and minor change. This capability can provide timely information for urban planning and policy decisions toward more liveable, equitable, and sustainable cities.
</details>
<details>
<summary>摘要</summary>
全球各地城市面临着供应充足、安全、健康的住房的紧迫需求。尽管城市住房问题的政策重要性不言而喻，但我们对城市变化的追踪和监测能力却受到限制。使用深度学习计算机视觉方法对街道级图像进行分析，可以成功地衡量社会经济和环境不平等，但这些方法通常无法利用时间变化来追踪城市变化。我们使用自动学习方法，使用2008年至2021年之间的1500万个街道级图像，在伦敦市进行了时间变化的追踪。我们对Barlow Twins进行了改进，称之为Street2Vec，它可以嵌入城市结构，同时具有季节和日期变化的抗辐射性，无需手动标注。Street2Vec在伦敦市的住房供应变化追踪中表现出色，可以提供实时的城市规划和政策决策信息，以建立更加人居住、公平、可持续的城市。
</details></li>
</ul>
<hr>
<h2 id="You-can-have-your-ensemble-and-run-it-too-–-Deep-Ensembles-Spread-Over-Time"><a href="#You-can-have-your-ensemble-and-run-it-too-–-Deep-Ensembles-Spread-Over-Time" class="headerlink" title="You can have your ensemble and run it too – Deep Ensembles Spread Over Time"></a>You can have your ensemble and run it too – Deep Ensembles Spread Over Time</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11333">http://arxiv.org/abs/2309.11333</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isak Meding, Alexander Bodin, Adam Tonderski, Joakim Johnander, Christoffer Petersson, Lennart Svensson</li>
<li>for: 这个研究旨在探讨深度 Ensemble 可以在时间序列上扩展以提高预测性和不确定性估计的可能性。</li>
<li>methods: 我们提出了 Deep Ensembles Spread Over Time (DESOT) 方法，将单一的 Ensemble  member 应用到每个数据点上，并融合多个数据点的预测。</li>
<li>results: DESOT 可以获得深度 Ensemble 的优化性和不确定性估计性，而不需要额外的计算成本增加。 DESOT 也简单实现，不需要在训练过程中使用时间序列。 最后，我们发现 DESOT 和深度 Ensemble 都能在非标准数据上进行预测和不确定性估计。<details>
<summary>Abstract</summary>
Ensembles of independently trained deep neural networks yield uncertainty estimates that rival Bayesian networks in performance. They also offer sizable improvements in terms of predictive performance over single models. However, deep ensembles are not commonly used in environments with limited computational budget -- such as autonomous driving -- since the complexity grows linearly with the number of ensemble members. An important observation that can be made for robotics applications, such as autonomous driving, is that data is typically sequential. For instance, when an object is to be recognized, an autonomous vehicle typically observes a sequence of images, rather than a single image. This raises the question, could the deep ensemble be spread over time?   In this work, we propose and analyze Deep Ensembles Spread Over Time (DESOT). The idea is to apply only a single ensemble member to each data point in the sequence, and fuse the predictions over a sequence of data points. We implement and experiment with DESOT for traffic sign classification, where sequences of tracked image patches are to be classified. We find that DESOT obtains the benefits of deep ensembles, in terms of predictive and uncertainty estimation performance, while avoiding the added computational cost. Moreover, DESOT is simple to implement and does not require sequences during training. Finally, we find that DESOT, like deep ensembles, outperform single models for out-of-distribution detection.
</details>
<details>
<summary>摘要</summary>
ensemble of independently trained deep neural networks可以提供与 bayesian networks相当的不确定性估计，同时也可以提高预测性能。但是，深度 ensemble在计算budget有限的环境中并不很常见，因为ensemble的复杂度随着成员增加而增加。在робо特应用，如自动驾驶，发现数据通常是顺序的。例如，当需要识别一个物体时，一辆自动驾驶车通常会观察一串图像，而不是单个图像。这引出了一个问题：可以将深度 ensemble推广到时间吗？在这种情况下，我们提出了深度 ensemble推广到时间（DESOT）的想法。我们只应用一个 ensemble member 到每个数据点的序列中，并将预测结果进行融合。我们实现并对 traffic sign classification 进行实验，Sequence of tracked image patches 需要进行分类。我们发现 DESOT 可以获得深度 ensemble 的优点，即预测性能和不确定性估计的好处，而不需要添加计算成本。此外，DESOT 简单易实现，不需要在训练时序列。最后，我们发现 DESOT 也可以超过单个模型的表现，对于非标准范围检测。
</details></li>
</ul>
<hr>
<h2 id="How-to-turn-your-camera-into-a-perfect-pinhole-model"><a href="#How-to-turn-your-camera-into-a-perfect-pinhole-model" class="headerlink" title="How to turn your camera into a perfect pinhole model"></a>How to turn your camera into a perfect pinhole model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11326">http://arxiv.org/abs/2309.11326</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivan De Boi, Stuti Pathak, Marina Oliveira, Rudi Penne</li>
<li>for: 提高计算机视觉应用中的相机准备环境，提供一种可以处理多种扭曲源的新方法。</li>
<li>methods: 使用 Gaussian processes 来去除图像中的扭曲和相机缺陷，并创建一个虚拟的理想投射相机，只需一张正方形网格检查模式图像。</li>
<li>results: 提高了许多计算机视觉算法和应用的性能，消除了扭曲参数和迭代优化。  Validated by synthetic data and real-world images.<details>
<summary>Abstract</summary>
Camera calibration is a first and fundamental step in various computer vision applications. Despite being an active field of research, Zhang's method remains widely used for camera calibration due to its implementation in popular toolboxes. However, this method initially assumes a pinhole model with oversimplified distortion models. In this work, we propose a novel approach that involves a pre-processing step to remove distortions from images by means of Gaussian processes. Our method does not need to assume any distortion model and can be applied to severely warped images, even in the case of multiple distortion sources, e.g., a fisheye image of a curved mirror reflection. The Gaussian processes capture all distortions and camera imperfections, resulting in virtual images as though taken by an ideal pinhole camera with square pixels. Furthermore, this ideal GP-camera only needs one image of a square grid calibration pattern. This model allows for a serious upgrade of many algorithms and applications that are designed in a pure projective geometry setting but with a performance that is very sensitive to nonlinear lens distortions. We demonstrate the effectiveness of our method by simplifying Zhang's calibration method, reducing the number of parameters and getting rid of the distortion parameters and iterative optimization. We validate by means of synthetic data and real world images. The contributions of this work include the construction of a virtual ideal pinhole camera using Gaussian processes, a simplified calibration method and lens distortion removal.
</details>
<details>
<summary>摘要</summary>
Camera 卡利ibration 是 computer vision 应用中的第一步和基础步骤。尽管是一个活跃的研究领域，张的方法仍然广泛使用于 camera 卡利ibration due to its implementation in popular toolboxes。然而，这种方法初始化假设了缩影模型，忽略了真实的扭曲模型。在这种工作中，我们提出了一种新的方法，该方法通过 Gaussian processes 来从图像中除扭曲。我们的方法不需要任何扭曲模型，可以应用于严重扭曲的图像，甚至在多个扭曲源的情况下，如 fisheye 图像 reflection 的弯曲镜。 Gaussian processes 捕捉了所有的扭曲和相机缺陷，从而生成虚拟的 ideal pinhole camera 图像，如quare pixels。此外，这个 ideal GP-camera 只需一个平方格 calibration pattern 图像。这种模型允许许多算法和应用程序，其中一些是在纯 proyective geometry 设定下设计，但是性能受到非线性镜头扭曲的影响。我们通过简化张的卡利ibration 方法，减少参数的数量，消除扭曲参数和迭代优化来证明方法的有效性。我们验证了这种方法的有效性通过 synthetic 数据和实际图像。本研究的贡献包括：在 Gaussian processes 中构建虚拟的 ideal pinhole camera，简化卡利ibration 方法和镜头扭曲除除。
</details></li>
</ul>
<hr>
<h2 id="Face-Aging-via-Diffusion-based-Editing"><a href="#Face-Aging-via-Diffusion-based-Editing" class="headerlink" title="Face Aging via Diffusion-based Editing"></a>Face Aging via Diffusion-based Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11321">http://arxiv.org/abs/2309.11321</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MunchkinChen/FADING">https://github.com/MunchkinChen/FADING</a></li>
<li>paper_authors: Xiangyi Chen, Stéphane Lathuilière</li>
<li>for: 本研究旨在解决面部年轻化问题，生成面部图像的过去或未来图像，通过增加年龄相关的变化。</li>
<li>methods: 我们提出了一种新的方法，即FADING，利用语言-图像扩散模型的丰富前提，来解决面部年轻化问题。我们首先特化一个预训练的扩散模型，使其更适应面部年轻化任务，然后对输入图像进行倒散、获取优化的Null噪音嵌入，最后通过文本引导的地方年轻编辑。</li>
<li>results: 我们的方法与现有方法相比，在年轻精度、特征保留和年轻质量等方面具有明显的优势。<details>
<summary>Abstract</summary>
In this paper, we address the problem of face aging: generating past or future facial images by incorporating age-related changes to the given face. Previous aging methods rely solely on human facial image datasets and are thus constrained by their inherent scale and bias. This restricts their application to a limited generatable age range and the inability to handle large age gaps. We propose FADING, a novel approach to address Face Aging via DIffusion-based editiNG. We go beyond existing methods by leveraging the rich prior of large-scale language-image diffusion models. First, we specialize a pre-trained diffusion model for the task of face age editing by using an age-aware fine-tuning scheme. Next, we invert the input image to latent noise and obtain optimized null text embeddings. Finally, we perform text-guided local age editing via attention control. The quantitative and qualitative analyses demonstrate that our method outperforms existing approaches with respect to aging accuracy, attribute preservation, and aging quality.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们解决了人脸年龄化问题：通过 incorporating 年龄相关变化来生成过去或未来的脸部图像。先前的年龄方法仅仅基于人类脸部图像集合，因此受到其内置的尺度和偏见的限制，只能生成有限的年龄范围内的图像，并且无法处理大的年龄差。我们提出了 FADING，一种新的方法来解决人脸年龄化问题，通过语言-图像扩散模型的质量丰富的先天知识来超越现有方法。首先，我们特化了预训练的扩散模型，使其更适应人脸年龄编辑任务，并使用年龄意识 fine-tuning 方案进行特化。接着，我们将输入图像反转为干扰噪 embedding，并获得优化的 null text embedding。最后，我们通过文本引导的本地年龄编辑来进行控制。量化和质量分析表明，我们的方法在年龄准确性、特征保持和年龄质量等方面都超越了现有方法。
</details></li>
</ul>
<hr>
<h2 id="Uncovering-the-effects-of-model-initialization-on-deep-model-generalization-A-study-with-adult-and-pediatric-Chest-X-ray-images"><a href="#Uncovering-the-effects-of-model-initialization-on-deep-model-generalization-A-study-with-adult-and-pediatric-Chest-X-ray-images" class="headerlink" title="Uncovering the effects of model initialization on deep model generalization: A study with adult and pediatric Chest X-ray images"></a>Uncovering the effects of model initialization on deep model generalization: A study with adult and pediatric Chest X-ray images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11318">http://arxiv.org/abs/2309.11318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sivaramakrishnan Rajaraman, Ghada Zamzmi, Feng Yang, Zhaohui Liang, Zhiyun Xue, Sameer Antani<br>for: 这个研究旨在提高深度学习模型在医疗计算机视觉应用中的性能和可靠性。而关于医疗图像（特别是胸部X射线图像）的影响则更少了解。本研究探讨了三种深度模型初始化技术：冷启动、暖启动和缩小和扰动start，对成人和儿童两个人口进行了评估。methods: 本研究使用了三种深度模型初始化技术：冷启动、暖启动和缩小和扰动start。这些技术在医疗图像的批处理训练场景下进行了评估，以适应实际世界中数据不断来临和模型更新的需求。results: 研究结果表明，使用ImageNet预训练权重初始化的模型在成人和儿童两个人口中的总体化能力较高，超过随机初始化的模型。此外，ImageNet预训练模型在不同训练场景下的内部和外部测试中都表现了稳定的性能。weight级 ensemble方法也显示了明显的提高（p&lt;0.05），特别是在测试阶段。因此，本研究强调了使用ImageNet预训练权重初始化的好处，尤其是在weight级 ensemble方法下，为创建可靠和总体化的深度学习解决方案。<details>
<summary>Abstract</summary>
Model initialization techniques are vital for improving the performance and reliability of deep learning models in medical computer vision applications. While much literature exists on non-medical images, the impacts on medical images, particularly chest X-rays (CXRs) are less understood. Addressing this gap, our study explores three deep model initialization techniques: Cold-start, Warm-start, and Shrink and Perturb start, focusing on adult and pediatric populations. We specifically focus on scenarios with periodically arriving data for training, thereby embracing the real-world scenarios of ongoing data influx and the need for model updates. We evaluate these models for generalizability against external adult and pediatric CXR datasets. We also propose novel ensemble methods: F-score-weighted Sequential Least-Squares Quadratic Programming (F-SLSQP) and Attention-Guided Ensembles with Learnable Fuzzy Softmax to aggregate weight parameters from multiple models to capitalize on their collective knowledge and complementary representations. We perform statistical significance tests with 95% confidence intervals and p-values to analyze model performance. Our evaluations indicate models initialized with ImageNet-pre-trained weights demonstrate superior generalizability over randomly initialized counterparts, contradicting some findings for non-medical images. Notably, ImageNet-pretrained models exhibit consistent performance during internal and external testing across different training scenarios. Weight-level ensembles of these models show significantly higher recall (p<0.05) during testing compared to individual models. Thus, our study accentuates the benefits of ImageNet-pretrained weight initialization, especially when used with weight-level ensembles, for creating robust and generalizable deep learning solutions.
</details>
<details>
<summary>摘要</summary>
“模型初始化技术对深度学习模型在医疗计算机视觉应用中的性能和可靠性有着重要的影响。虽然关于非医学图像的研究已经充分，但对医学图像，特别是胸部X射影（CXR）的影响还未得到充分了解。为了解决这个差距，我们的研究探讨了三种深度模型初始化技术：冷启动、温启动和缩放和扰动启动，对于成人和儿童两个人口进行了研究。我们强调在进行训练时periodically arriving data的情况下，以满足实际世界中数据不断来临和模型更新的需求。我们使用F-score-weighted Sequential Least-Squares Quadratic Programming（F-SLSQP）和Attention-Guided Ensembles with Learnable Fuzzy Softmax来权衡多个模型的参数，以便充分利用它们的共同知识和补充表示。我们对模型性能进行了统计学 significativity 测试，结果表明，使用ImageNet预训练权重初始化的模型在总体性能方面表现出色，并且在不同的训练场景下保持了一致的表现。此外，对这些模型进行权重级别的合并也表现出了明显的提升（p<0.05）。因此，我们的研究证明了使用ImageNet预训练权重初始化的模型，特别是在权重级别的合并下，可以创建可靠和总体性能优秀的深度学习解决方案。”
</details></li>
</ul>
<hr>
<h2 id="Generalizing-Across-Domains-in-Diabetic-Retinopathy-via-Variational-Autoencoders"><a href="#Generalizing-Across-Domains-in-Diabetic-Retinopathy-via-Variational-Autoencoders" class="headerlink" title="Generalizing Across Domains in Diabetic Retinopathy via Variational Autoencoders"></a>Generalizing Across Domains in Diabetic Retinopathy via Variational Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11301">http://arxiv.org/abs/2309.11301</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sharonchokuwa/VAE-DG">https://github.com/sharonchokuwa/VAE-DG</a></li>
<li>paper_authors: Sharon Chokuwa, Muhammad H. Khan</li>
<li>for: 这篇论文旨在探讨Variational Autoencoder（VA）是否能够实现类型普遍化，以对抗DR预测 задачі中的领域转移。</li>
<li>methods: 这篇论文使用Variational Autoencoder（VA）来分析眼底照片的latent space，以获得一个更加灵活和适应的领域不对称表示，以应对DR数据集中的领域转移。</li>
<li>results: 这篇论文显示，使用VA的简单方法可以超越现有的州际顶对应方法，并在公开可用的数据集上达到更高的准确率。这些结果显示，简单的方法可以在医疗图像领域中实现更好的领域普遍化，而不是仅仅靠赖高度复杂的技术。<details>
<summary>Abstract</summary>
Domain generalization for Diabetic Retinopathy (DR) classification allows a model to adeptly classify retinal images from previously unseen domains with various imaging conditions and patient demographics, thereby enhancing its applicability in a wide range of clinical environments. In this study, we explore the inherent capacity of variational autoencoders to disentangle the latent space of fundus images, with an aim to obtain a more robust and adaptable domain-invariant representation that effectively tackles the domain shift encountered in DR datasets. Despite the simplicity of our approach, we explore the efficacy of this classical method and demonstrate its ability to outperform contemporary state-of-the-art approaches for this task using publicly available datasets. Our findings challenge the prevailing assumption that highly sophisticated methods for DR classification are inherently superior for domain generalization. This highlights the importance of considering simple methods and adapting them to the challenging task of generalizing medical images, rather than solely relying on advanced techniques.
</details>
<details>
<summary>摘要</summary>
域 generale 化 для 诊断糖尿病 Retinopathy (DR) 让模型能够efficacious 分类 retinal 图像从以前未经见到的域与不同的拍摄条件和患者特征下，从而提高其在各种临床环境中的应用性。在这项研究中，我们探讨了变量自动编码器内置的latent space的分解能力，以获得更加稳定和适应的域不对称表示，以更好地解决DR数据集中的域转移问题。虽然我们的方法简单，但我们发现这种经典方法的效果可以超过当今的状态对DR分类任务的方法。我们的发现证明了不要仅仅依赖于高度复杂的方法，而是应该考虑简单的方法并适应它们来普遍化医疗图像。
</details></li>
</ul>
<hr>
<h2 id="Language-driven-Object-Fusion-into-Neural-Radiance-Fields-with-Pose-Conditioned-Dataset-Updates"><a href="#Language-driven-Object-Fusion-into-Neural-Radiance-Fields-with-Pose-Conditioned-Dataset-Updates" class="headerlink" title="Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates"></a>Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11281">http://arxiv.org/abs/2309.11281</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kcshum/pose-conditioned-NeRF-object-fusion">https://github.com/kcshum/pose-conditioned-NeRF-object-fusion</a></li>
<li>paper_authors: Ka Chun Shum, Jaeyeon Kim, Binh-Son Hua, Duc Thanh Nguyen, Sai-Kit Yeung</li>
<li>for: 这 paper 是用于描述一种基于神经辐射场的图像渲染方法，可以生成高质量的多视图一致的图像。</li>
<li>methods: 这 paper 使用了一种基于文本扩展的方法来实现对 neural radiance field 中的对象的操作，包括插入新背景和 removing 已有对象。</li>
<li>results: 实验结果表明，这 paper 的方法可以生成高质量的渲染图像，并且在 3D 重建和神经辐射场融合方面超过了现有的方法。<details>
<summary>Abstract</summary>
Neural radiance field is an emerging rendering method that generates high-quality multi-view consistent images from a neural scene representation and volume rendering. Although neural radiance field-based techniques are robust for scene reconstruction, their ability to add or remove objects remains limited. This paper proposes a new language-driven approach for object manipulation with neural radiance fields through dataset updates. Specifically, to insert a new foreground object represented by a set of multi-view images into a background radiance field, we use a text-to-image diffusion model to learn and generate combined images that fuse the object of interest into the given background across views. These combined images are then used for refining the background radiance field so that we can render view-consistent images containing both the object and the background. To ensure view consistency, we propose a dataset updates strategy that prioritizes radiance field training with camera views close to the already-trained views prior to propagating the training to remaining views. We show that under the same dataset updates strategy, we can easily adapt our method for object insertion using data from text-to-3D models as well as object removal. Experimental results show that our method generates photorealistic images of the edited scenes, and outperforms state-of-the-art methods in 3D reconstruction and neural radiance field blending.
</details>
<details>
<summary>摘要</summary>
神经辐射场是一种出现在渲染方法中的新技术，它可以生成高质量、多视图一致的图像从神经场景表示和体积渲染。 although neural radiance field-based techniques are robust for scene reconstruction, their ability to add or remove objects remains limited. This paper proposes a new language-driven approach for object manipulation with neural radiance fields through dataset updates. Specifically, to insert a new foreground object represented by a set of multi-view images into a background radiance field, we use a text-to-image diffusion model to learn and generate combined images that fuse the object of interest into the given background across views. These combined images are then used for refining the background radiance field so that we can render view-consistent images containing both the object and the background. To ensure view consistency, we propose a dataset updates strategy that prioritizes radiance field training with camera views close to the already-trained views prior to propagating the training to remaining views. We show that under the same dataset updates strategy, we can easily adapt our method for object insertion using data from text-to-3D models as well as object removal. Experimental results show that our method generates photorealistic images of the edited scenes, and outperforms state-of-the-art methods in 3D reconstruction and neural radiance field blending.
</details></li>
</ul>
<hr>
<h2 id="Towards-Real-Time-Neural-Video-Codec-for-Cross-Platform-Application-Using-Calibration-Information"><a href="#Towards-Real-Time-Neural-Video-Codec-for-Cross-Platform-Application-Using-Calibration-Information" class="headerlink" title="Towards Real-Time Neural Video Codec for Cross-Platform Application Using Calibration Information"></a>Towards Real-Time Neural Video Codec for Cross-Platform Application Using Calibration Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11276">http://arxiv.org/abs/2309.11276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuan Tian, Yonghang Guan, Jinxi Xiang, Jun Zhang, Xiao Han, Wei Yang</li>
<li>for: 这个论文是为了提出一种实时跨平台神经视频编码器，以解决现有神经网络编码器在实际应用中的两大挑战。</li>
<li>methods: 作者使用了一种协调传输系统来保证编码和解码过程中的统一化量化参数，并使用了一种尺度约束来修复分布 Entropy 参数的不均匀性。</li>
<li>results: 实验结果显示，作者的模型可以在 NVIDIA RTX 2080 GPU 上实现 25 FPS 的解码速度，并且可以在另一个平台上编码的 720P 视频进行实时解码。此外，实时模型可以提供最高 24.2% BD-rate 改善，相比 anchor H.265。<details>
<summary>Abstract</summary>
The state-of-the-art neural video codecs have outperformed the most sophisticated traditional codecs in terms of RD performance in certain cases. However, utilizing them for practical applications is still challenging for two major reasons. 1) Cross-platform computational errors resulting from floating point operations can lead to inaccurate decoding of the bitstream. 2) The high computational complexity of the encoding and decoding process poses a challenge in achieving real-time performance. In this paper, we propose a real-time cross-platform neural video codec, which is capable of efficiently decoding of 720P video bitstream from other encoding platforms on a consumer-grade GPU. First, to solve the problem of inconsistency of codec caused by the uncertainty of floating point calculations across platforms, we design a calibration transmitting system to guarantee the consistent quantization of entropy parameters between the encoding and decoding stages. The parameters that may have transboundary quantization between encoding and decoding are identified in the encoding stage, and their coordinates will be delivered by auxiliary transmitted bitstream. By doing so, these inconsistent parameters can be processed properly in the decoding stage. Furthermore, to reduce the bitrate of the auxiliary bitstream, we rectify the distribution of entropy parameters using a piecewise Gaussian constraint. Second, to match the computational limitations on the decoding side for real-time video codec, we design a lightweight model. A series of efficiency techniques enable our model to achieve 25 FPS decoding speed on NVIDIA RTX 2080 GPU. Experimental results demonstrate that our model can achieve real-time decoding of 720P videos while encoding on another platform. Furthermore, the real-time model brings up to a maximum of 24.2\% BD-rate improvement from the perspective of PSNR with the anchor H.265.
</details>
<details>
<summary>摘要</summary>
现代神经视频编码器在某些情况下已经超越了最复杂的传统编码器，但在实际应用中仍然存在两大挑战。首先，由浮点运算引起的平台间计算错误可能导致错误解码bitstream。其次，编码和解码过程的计算复杂性使得实时性很难实现。在这篇论文中，我们提出了一种实时可靠的cross-platform神经视频编码器，可以在consumer-grade GPU上高速解码720P视频bitstream。首先，为了解决由不确定的浮点计算所引起的编码器不一致性问题，我们设计了卡利ibration transmitting系统，以 garantuee the consistent quantization of entropy parameters between the encoding and decoding stages。在编码阶段，我们标识出可能存在跨界量译参数的问题，并将其坐标传输给下游编码器。这样，在解码阶段可以正确处理这些不一致的参数。其次，为了降低auxiliary bitstream的比特率，我们使用piecewise Gaussian constraint来修正参数的分布。其次，为了在解码器端实现实时性，我们设计了一种轻量级模型。我们采用了一系列的效率技巧，使得我们的模型在NVIDIA RTX 2080 GPU上可以达到25帧/秒的解码速度。实验结果表明，我们的模型可以实时解码720P视频，而encoded on another platform。此外，实时模型可以提高最多24.2%的BD-rate，相比 anchor H.265。
</details></li>
</ul>
<hr>
<h2 id="StructChart-Perception-Structuring-Reasoning-for-Visual-Chart-Understanding"><a href="#StructChart-Perception-Structuring-Reasoning-for-Visual-Chart-Understanding" class="headerlink" title="StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding"></a>StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11268">http://arxiv.org/abs/2309.11268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renqiu Xia, Bo Zhang, Haoyang Peng, Ning Liao, Peng Ye, Botian Shi, Junchi Yan, Yu Qiao</li>
<li>for: 这篇论文目标是建立一种统一的学习模式，能够同时完成图表感知和理解任务。</li>
<li>methods: 论文使用了一种名为Structured Triplet Representations（STR）的新的表示方式，以及一种名为Structuring Chart-oriented Representation Metric（SCRM）的表现评价方法，来提高图表理解能力。</li>
<li>results: 经过广泛的实验，论文发现这种统一的学习模式能够在不同的图表任务上达到极高的表现，并且能够扩大图表数据集，以提高图表理解能力。<details>
<summary>Abstract</summary>
Charts are common in literature across different scientific fields, conveying rich information easily accessible to readers. Current chart-related tasks focus on either chart perception which refers to extracting information from the visual charts, or performing reasoning given the extracted data, e.g. in a tabular form. In this paper, we aim to establish a unified and label-efficient learning paradigm for joint perception and reasoning tasks, which can be generally applicable to different downstream tasks, beyond the question-answering task as specifically studied in peer works. Specifically, StructChart first reformulates the chart information from the popular tubular form (specifically linearized CSV) to the proposed Structured Triplet Representations (STR), which is more friendly for reducing the task gap between chart perception and reasoning due to the employed structured information extraction for charts. We then propose a Structuring Chart-oriented Representation Metric (SCRM) to quantitatively evaluate the performance for the chart perception task. To enrich the dataset for training, we further explore the possibility of leveraging the Large Language Model (LLM), enhancing the chart diversity in terms of both chart visual style and its statistical information. Extensive experiments are conducted on various chart-related tasks, demonstrating the effectiveness and promising potential for a unified chart perception-reasoning paradigm to push the frontier of chart understanding.
</details>
<details>
<summary>摘要</summary>
图表是科学文献中常见的数据可视化方式，能够快速传递丰富的信息给读者。目前的图表相关任务主要集中在图表识别和基于EXTRACTED数据的逻辑思维两个方面。在这篇论文中，我们希望建立一种统一的和标签有效的学习 парадигм，能够普适应用于不同的下游任务，而不仅仅是特定的问答任务，如在同等作者的论文中所研究。 Specifically, StructChart首先将流行的 tubular 形式（具体是线性化 CSV）中的图表信息重新表述为我们提出的结构化 triplet 表示（STR），这种结构化信息提取技术使得图表识别和逻辑思维之间的任务差距更小。然后，我们提出了一种 Chart-oriented Representation Metric（SCRM）来衡量图表识别任务的表现。为了让训练集更加丰富，我们还探索了使用 Large Language Model（LLM），通过扩展图表的视觉风格和统计信息，提高图表的多样性。我们在不同的图表相关任务上进行了广泛的实验，并证明了这种统一的图表识别和逻辑思维方法的有效性和潜在的前iers。
</details></li>
</ul>
<hr>
<h2 id="From-Classification-to-Segmentation-with-Explainable-AI-A-Study-on-Crack-Detection-and-Growth-Monitoring"><a href="#From-Classification-to-Segmentation-with-Explainable-AI-A-Study-on-Crack-Detection-and-Growth-Monitoring" class="headerlink" title="From Classification to Segmentation with Explainable AI: A Study on Crack Detection and Growth Monitoring"></a>From Classification to Segmentation with Explainable AI: A Study on Crack Detection and Growth Monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11267">http://arxiv.org/abs/2309.11267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florent Forest, Hugo Porta, Devis Tuia, Olga Fink</li>
<li>for: 本研究旨在 automatization 基础设施中的表面裂隙监测，以实现结构健康监测。</li>
<li>methods: 本研究使用机器学习方法，但需要大量标注数据进行超vised 训练。而once a crack is detected， monitoring its severity 通常需要精准的像素级别分割。然而，对于每个图像进行像素级别分割的标注是劳动密集的。为了解决这个问题，本研究提议使用可解释的人工智能（XAI）方法，从类ifier的解释中 derivate 分割，只需要弱型图像级别的监督。</li>
<li>results: 本研究发现，使用XAI方法可以生成有意义的分割面掩模，即使无需大量的标注数据。Results reveal that while the resulting segmentation masks may exhibit lower quality than those produced by supervised methods, they remain meaningful and enable severity monitoring, thus reducing substantial labeling costs.<details>
<summary>Abstract</summary>
Monitoring surface cracks in infrastructure is crucial for structural health monitoring. Automatic visual inspection offers an effective solution, especially in hard-to-reach areas. Machine learning approaches have proven their effectiveness but typically require large annotated datasets for supervised training. Once a crack is detected, monitoring its severity often demands precise segmentation of the damage. However, pixel-level annotation of images for segmentation is labor-intensive. To mitigate this cost, one can leverage explainable artificial intelligence (XAI) to derive segmentations from the explanations of a classifier, requiring only weak image-level supervision. This paper proposes applying this methodology to segment and monitor surface cracks. We evaluate the performance of various XAI methods and examine how this approach facilitates severity quantification and growth monitoring. Results reveal that while the resulting segmentation masks may exhibit lower quality than those produced by supervised methods, they remain meaningful and enable severity monitoring, thus reducing substantial labeling costs.
</details>
<details>
<summary>摘要</summary>
监测基础设施表面裂隙是结构健康监测的关键。自动视见检测提供了一个有效的解决方案，特别是在困难 accessed 的地方。机器学习方法已经证明其效果，但通常需要大量的注释化数据集 дляsupervised 训练。一旦裂隙被检测出来，则需要精确地分类损害。然而，像素级注释图像 для分类是时间consuming。为了解决这个问题，这篇论文提议使用可解释人工智能（XAI） derive 分类器的解释，只需弱型图像级指导。这种方法可以帮助实现裂隙分类和严重性评估，并且可以降低大量的标注成本。我们评估了不同的XAI方法的性能，并研究了这种方法是否可以实现严重性评估和生长监测。结果表明，尽管生成的分类器分割面可能不如supervised 方法生成的分割面质量高，但它们仍然有意义，并且可以实现严重性评估和生长监测，从而减少标注成本。
</details></li>
</ul>
<hr>
<h2 id="TwinTex-Geometry-aware-Texture-Generation-for-Abstracted-3D-Architectural-Models"><a href="#TwinTex-Geometry-aware-Texture-Generation-for-Abstracted-3D-Architectural-Models" class="headerlink" title="TwinTex: Geometry-aware Texture Generation for Abstracted 3D Architectural Models"></a>TwinTex: Geometry-aware Texture Generation for Abstracted 3D Architectural Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11258">http://arxiv.org/abs/2309.11258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Ligo04/TwinTex">https://github.com/Ligo04/TwinTex</a></li>
<li>paper_authors: Weidan Xiong, Hongqian Zhang, Botao Peng, Ziyu Hu, Yongli Wu, Jianwei Guo, Hui Huang</li>
<li>for: 这个论文是为了生成一个精细的城市 Digital Twin 中的建筑物和景观的图像Texture mapping。</li>
<li>methods: 这个方法使用了一种新的自动化文本映射方法，包括选择高质量照片，提取LoL特征，对照片和geometry进行对齐，并使用一个新的扩展数据集和滤波模型来完善缺失区域。</li>
<li>results: 实验结果表明，这种方法可以高效地生成高质量的文本映射，并且可以在不同的建筑物和景观中实现人工专家水平的效果，而不需要太多的工作。<details>
<summary>Abstract</summary>
Coarse architectural models are often generated at scales ranging from individual buildings to scenes for downstream applications such as Digital Twin City, Metaverse, LODs, etc. Such piece-wise planar models can be abstracted as twins from 3D dense reconstructions. However, these models typically lack realistic texture relative to the real building or scene, making them unsuitable for vivid display or direct reference. In this paper, we present TwinTex, the first automatic texture mapping framework to generate a photo-realistic texture for a piece-wise planar proxy. Our method addresses most challenges occurring in such twin texture generation. Specifically, for each primitive plane, we first select a small set of photos with greedy heuristics considering photometric quality, perspective quality and facade texture completeness. Then, different levels of line features (LoLs) are extracted from the set of selected photos to generate guidance for later steps. With LoLs, we employ optimization algorithms to align texture with geometry from local to global. Finally, we fine-tune a diffusion model with a multi-mask initialization component and a new dataset to inpaint the missing region. Experimental results on many buildings, indoor scenes and man-made objects of varying complexity demonstrate the generalization ability of our algorithm. Our approach surpasses state-of-the-art texture mapping methods in terms of high-fidelity quality and reaches a human-expert production level with much less effort. Project page: https://vcc.tech/research/2023/TwinTex.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译成简化中文。</SYS>>建筑模型经常在大规模生成，从个别建筑到场景，用于下游应用程序，如数字城市、Metaverse、LODs等。这些块状平面模型可以被抽象为真实建筑或场景的孪生。然而，这些模型通常缺乏真实建筑或场景的精炼文化，使其不适合精彩显示或直接参考。在这篇论文中，我们介绍了 TwinTex，首个自动Texture mapping框架，用于生成具有高精炼度的Texture для块状平面代理。我们的方法解决了这类孪生Texture生成中的主要挑战。具体来说，对于每个基本平面，我们首先选择一小集数据，使用善意的规则来考虑光学质量、视角质量和建筑面料完整性。然后，我们从这些选择的数据中提取不同级别的线条特征（LoLs），以供后续步骤的引导。使用LoLs，我们运用优化算法将Texture与Geometry进行对齐。最后，我们使用扩展模型，并在新的数据集上进行填充缺失区域。实验结果表明，我们的算法可以在许多不同复杂度的建筑、室内场景和人工制品上实现高精炼度的Texture mapping，并且超过了当前状态艺的Texture mapping方法。我们的方法可以减少很多劳动力，达到人工专家水平。项目页面：https://vcc.tech/research/2023/TwinTex。
</details></li>
</ul>
<hr>
<h2 id="Box2Poly-Memory-Efficient-Polygon-Prediction-of-Arbitrarily-Shaped-and-Rotated-Text"><a href="#Box2Poly-Memory-Efficient-Polygon-Prediction-of-Arbitrarily-Shaped-and-Rotated-Text" class="headerlink" title="Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and Rotated Text"></a>Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and Rotated Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11248">http://arxiv.org/abs/2309.11248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuyang Chen, Dong Wang, Konrad Schindler, Mingwei Sun, Yongliang Wang, Nicolo Savioli, Liqiu Meng</li>
<li>For: 提高文本检测的精度和效率，尤其是对于不规则的文本布局。* Methods: 基于Sparse R-CNN的协调解码管道，通过逐次精度调整多边形预测，使用单个特征向量导引多边形实例准备。* Results: 比较DPText-DETR方法，具有更高的内存效率（&gt;50%）和推理速度（&gt;40%），同时保持了基准测试集上的性能水平。<details>
<summary>Abstract</summary>
Recently, Transformer-based text detection techniques have sought to predict polygons by encoding the coordinates of individual boundary vertices using distinct query features. However, this approach incurs a significant memory overhead and struggles to effectively capture the intricate relationships between vertices belonging to the same instance. Consequently, irregular text layouts often lead to the prediction of outlined vertices, diminishing the quality of results. To address these challenges, we present an innovative approach rooted in Sparse R-CNN: a cascade decoding pipeline for polygon prediction. Our method ensures precision by iteratively refining polygon predictions, considering both the scale and location of preceding results. Leveraging this stabilized regression pipeline, even employing just a single feature vector to guide polygon instance regression yields promising detection results. Simultaneously, the leverage of instance-level feature proposal substantially enhances memory efficiency (>50% less vs. the state-of-the-art method DPText-DETR) and reduces inference speed (>40% less vs. DPText-DETR) with minor performance drop on benchmarks.
</details>
<details>
<summary>摘要</summary>
traducción al chino simplificado:现在，基于Transformer的文本检测技术尝试预测多边形，通过对各个边界顶点的坐标使用特定的查询特征进行编码。然而，这种方法带来了显著的内存开销，并且很难准确地捕捉同一个实例中的逻辑关系。因此，不规则的文本布局经常导致预测的边界顶点变为围栏顶点，这会导致结果的质量下降。为了解决这些挑战，我们提出了一种创新的方法，基于Sparse R-CNN：一个逻辑拓展管道 для多边形预测。我们的方法保证准确性，通过迭代地纠正多边形预测结果，考虑多边形的缩放和位置。通过这个稳定的回归管道，甚至只使用一个特征向量来引导多边形实例回归，也可以获得了有前途的检测结果。同时，通过实例级别的特征提档，可以大幅提高内存效率（>50%比DPText-DETR更高），并且降低推理速度（>40%比DPText-DETR更低），而无需做出重要的性能下降。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Few-shot-Point-Cloud-Semantic-Segmentation"><a href="#Towards-Robust-Few-shot-Point-Cloud-Semantic-Segmentation" class="headerlink" title="Towards Robust Few-shot Point Cloud Semantic Segmentation"></a>Towards Robust Few-shot Point Cloud Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11228">http://arxiv.org/abs/2309.11228</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Pixie8888/R3DFSSeg">https://github.com/Pixie8888/R3DFSSeg</a></li>
<li>paper_authors: Yating Xu, Na Zhao, Gim Hee Lee</li>
<li>for: 提高几何点云Semantic segmentation的鲁棒性，使其在实际世界中快速适应新的未知类型，只需几个支持集样本。</li>
<li>methods: 我们提出了一种Component-level Clean Noise Separation（CCNS）表示学习，以学习细分target类的净样本与噪声样本之间的分化特征表示。然后，我们提出了一种Multi-scale Degree-based Noise Suppression（MDNS）方案，以消除支持集中的噪声样本。</li>
<li>results: 我们在不同噪声设定下进行了广泛的实验，结果显示CCNS和MDNS的组合显著提高了性能。<details>
<summary>Abstract</summary>
Few-shot point cloud semantic segmentation aims to train a model to quickly adapt to new unseen classes with only a handful of support set samples. However, the noise-free assumption in the support set can be easily violated in many practical real-world settings. In this paper, we focus on improving the robustness of few-shot point cloud segmentation under the detrimental influence of noisy support sets during testing time. To this end, we first propose a Component-level Clean Noise Separation (CCNS) representation learning to learn discriminative feature representations that separates the clean samples of the target classes from the noisy samples. Leveraging the well separated clean and noisy support samples from our CCNS, we further propose a Multi-scale Degree-based Noise Suppression (MDNS) scheme to remove the noisy shots from the support set. We conduct extensive experiments on various noise settings on two benchmark datasets. Our results show that the combination of CCNS and MDNS significantly improves the performance. Our code is available at https://github.com/Pixie8888/R3DFSSeg.
</details>
<details>
<summary>摘要</summary>
文本：几个类别点云 semantic segmentation 目标是训练一个模型快速适应新未见类别，仅仅需要一些支持集样本。然而，实际世界中的实际设定中可能会轻松违反无噪设定。在这篇论文中，我们专注于增强几个类别点云 semantic segmentation 的Robustness，在测试时testing时的恶劣影响下。为此，我们首先提出了Component-level Clean Noise Separation (CCNS) 表示学习，以学习分类特征表现，将目标类别的清洁样本与噪音样本分离。然后，我们更进一步提出了Multi-scale Degree-based Noise Suppression (MDNS) 方案，以移除测试时的噪音样本。我们对不同噪音设定进行了广泛的实验，结果显示，CCNS 和 MDNS 的组合可以明显提高性能。我们的代码可以在 <https://github.com/Pixie8888/R3DFSSeg> 中找到。翻译结果：文本：几个类别点云 semantic segmentation 目标是训练一个模型快速适应新未见类别，仅仅需要一些支持集样本。然而，实际世界中的实际设定中可能会轻松违反无噪设定。在这篇论文中，我们专注于增强几个类别点云 semantic segmentation 的Robustness，在测试时testing时的恶劣影响下。为此，我们首先提出了Component-level Clean Noise Separation (CCNS) 表示学习，以学习分类特征表现，将目标类别的清洁样本与噪音样本分离。然后，我们更进一步提出了Multi-scale Degree-based Noise Suppression (MDNS) 方案，以移除测试时的噪音样本。我们对不同噪音设定进行了广泛的实验，结果显示，CCNS 和 MDNS 的组合可以明显提高性能。我们的代码可以在 <https://github.com/Pixie8888/R3DFSSeg> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Few-Shot-Point-Cloud-Segmentation-Via-Geometric-Words"><a href="#Generalized-Few-Shot-Point-Cloud-Segmentation-Via-Geometric-Words" class="headerlink" title="Generalized Few-Shot Point Cloud Segmentation Via Geometric Words"></a>Generalized Few-Shot Point Cloud Segmentation Via Geometric Words</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11222">http://arxiv.org/abs/2309.11222</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Pixie8888/GFS-3DSeg_GWs">https://github.com/Pixie8888/GFS-3DSeg_GWs</a></li>
<li>paper_authors: Yating Xu, Conghui Hu, Na Zhao, Gim Hee Lee</li>
<li>For: 这篇论文的目的是提出一种更实用的普通多少shot点云分割方法，可以在新类出现时通过几个支持点云来泛化到新类，同时保持基础类的分割精度。* Methods: 该方法使用的是 geometric words 来表示基础和新类之间的 geometric 共同部分，并将其 incorporated 到一种新的 geometric-aware semantic representation 中，以便更好地泛化到新类而不忘记基础类。此外，该方法还引入 geometric prototypes 来导引分割，使用 geometric prior knowledge。* Results:  compared with基eline方法，该方法在 S3DIS 和 ScanNet 上的实验表现出色，显示了更高的性能。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Existing fully-supervised point cloud segmentation methods suffer in the dynamic testing environment with emerging new classes. Few-shot point cloud segmentation algorithms address this problem by learning to adapt to new classes at the sacrifice of segmentation accuracy for the base classes, which severely impedes its practicality. This largely motivates us to present the first attempt at a more practical paradigm of generalized few-shot point cloud segmentation, which requires the model to generalize to new categories with only a few support point clouds and simultaneously retain the capability to segment base classes. We propose the geometric words to represent geometric components shared between the base and novel classes, and incorporate them into a novel geometric-aware semantic representation to facilitate better generalization to the new classes without forgetting the old ones. Moreover, we introduce geometric prototypes to guide the segmentation with geometric prior knowledge. Extensive experiments on S3DIS and ScanNet consistently illustrate the superior performance of our method over baseline methods. Our code is available at: https://github.com/Pixie8888/GFS-3DSeg_GWs.
</details>
<details>
<summary>摘要</summary>
现有的完全监督的点云分割方法在新类出现的动态测试环境中表现不佳，这是因为这些方法在学习新类时会卷积到基础类的精度，这大大限制了其实用性。这种情况激励我们提出一种更实用的通用几shot点云分割方法，要求模型能够通过几个支持点云来扩展到新类，同时保持基础类的分割精度。我们使用“geometry words”来表示基础和新类之间的几何共同部分，并将其 integrate into a novel geometric-aware semantic representation，以便更好地适应新类而无需忘记旧类。此外，我们还引入几何规范来导航分割，以利用几何知识来提高分割精度。我们的实验表明，我们的方法在S3DIS和ScanNet上的扩展性和稳定性都显著提高。代码可以在：https://github.com/Pixie8888/GFS-3DSeg_GWs 中找到。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Bat-Call-Classification-using-Transformer-Networks"><a href="#Automatic-Bat-Call-Classification-using-Transformer-Networks" class="headerlink" title="Automatic Bat Call Classification using Transformer Networks"></a>Automatic Bat Call Classification using Transformer Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11218">http://arxiv.org/abs/2309.11218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frank Fundel, Daniel A. Braun, Sebastian Gottwald</li>
<li>for:  automatic bat call identification</li>
<li>methods:  Transformer architecture for multi-label classification</li>
<li>results:  single species accuracy of 88.92% (F1-score of 84.23%), multi species macro F1-score of 74.40%<details>
<summary>Abstract</summary>
Automatically identifying bat species from their echolocation calls is a difficult but important task for monitoring bats and the ecosystem they live in. Major challenges in automatic bat call identification are high call variability, similarities between species, interfering calls and lack of annotated data. Many currently available models suffer from relatively poor performance on real-life data due to being trained on single call datasets and, moreover, are often too slow for real-time classification. Here, we propose a Transformer architecture for multi-label classification with potential applications in real-time classification scenarios. We train our model on synthetically generated multi-species recordings by merging multiple bats calls into a single recording with multiple simultaneous calls. Our approach achieves a single species accuracy of 88.92% (F1-score of 84.23%) and a multi species macro F1-score of 74.40% on our test set. In comparison to three other tools on the independent and publicly available dataset ChiroVox, our model achieves at least 25.82% better accuracy for single species classification and at least 6.9% better macro F1-score for multi species classification.
</details>
<details>
<summary>摘要</summary>
自动识别蝙蝠种类从呼叫声中是一项具有挑战性和重要性的任务，用于监测蝙蝠和它们所处生态系统。主要挑战在自动蝙蝠呼叫识别中是呼叫声的高度变化、种类之间的相似性、干扰声和缺乏标注数据。现有的许多模型在实际数据上表现较差，主要是因为它们在单个呼叫数据集上训练。我们提出一种Transformer架构，用于多类别分类，具有实时分类场景的应用 potential。我们在合成生成的多种 recording中训练我们的模型，其中每个记录包含多个同时发生的呼叫。我们的方法实现了单种呼叫精度88.92%（F1-score为84.23%）和多种macro F1-score74.40%。与三个其他工具在独立公共的数据集ChiroVox上进行比较，我们的模型至少25.82%更高的单种呼叫精度和6.9%更高的多种 macro F1-score。
</details></li>
</ul>
<hr>
<h2 id="EPTQ-Enhanced-Post-Training-Quantization-via-Label-Free-Hessian"><a href="#EPTQ-Enhanced-Post-Training-Quantization-via-Label-Free-Hessian" class="headerlink" title="EPTQ: Enhanced Post-Training Quantization via Label-Free Hessian"></a>EPTQ: Enhanced Post-Training Quantization via Label-Free Hessian</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11531">http://arxiv.org/abs/2309.11531</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssi-research/eptq">https://github.com/ssi-research/eptq</a></li>
<li>paper_authors: Ofir Gordon, Hai Victor Habi, Arnon Netzer</li>
<li>for: 这篇论文旨在提出一种新的增强后期量化方法（EPTQ），以提高深度神经网络（DNN）的嵌入。</li>
<li>methods: 这篇论文使用了知识传播（knowledge distillation）和自适应层重复（adaptive weighting of layers）来实现增强后期量化。另外，论文还引入了一种无标签技术来近似任务损失的希耶数（Label-Free Hessian），以除去需要标签数据集的需求。</li>
<li>results: 这篇论文的实验结果显示，通过使用EPTQ，可以在各种模型、任务和数据集上取得最佳的结果，包括ImageNet分类、COCO物件检测和Pascal-VOC semantic segmentation。此外，论文还证明了EPTQ的可行性和可替代性，可以在不同的架构上进行实现，包括CNNs、Transformers、混合和MLP-only模型。<details>
<summary>Abstract</summary>
Quantization of deep neural networks (DNN) has become a key element in the efforts of embedding such networks on end-user devices. However, current quantization methods usually suffer from costly accuracy degradation. In this paper, we propose a new method for Enhanced Post Training Quantization named EPTQ. The method is based on knowledge distillation with an adaptive weighting of layers. In addition, we introduce a new label-free technique for approximating the Hessian trace of the task loss, named Label-Free Hessian. This technique removes the requirement of a labeled dataset for computing the Hessian. The adaptive knowledge distillation uses the Label-Free Hessian technique to give greater attention to the sensitive parts of the model while performing the optimization. Empirically, by employing EPTQ we achieve state-of-the-art results on a wide variety of models, tasks, and datasets, including ImageNet classification, COCO object detection, and Pascal-VOC for semantic segmentation. We demonstrate the performance and compatibility of EPTQ on an extended set of architectures, including CNNs, Transformers, hybrid, and MLP-only models.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）的量化已成为嵌入这些网络在用户端设备的关键元素。然而，当前的量化方法通常会导致精度下降。在这篇论文中，我们提出了一种新的增强后期量化方法，称为增强后期量化（EPTQ）。该方法基于知识传承，并使用自适应层权重。此外，我们还介绍了一种新的无标签技术，用于估计任务损失的希尔伯特特征，称为无标签希尔伯特特征（Label-Free Hessian）。这种技术消除了需要标注数据集来计算希尔伯特特征的需求。适应知识传承使用无标签希尔伯特特征来增加对模型敏感部分的注意力，进行优化。我们的实验结果表明，通过使用EPTQ，我们在各种模型、任务和数据集上达到了状态对的结果，包括ImageNet分类、COCO物体检测和Pascal-VOC semantics segmentation。我们也证明了EPTQ在扩展的集成体系中的性能和兼容性，包括CNNs、Transformers、混合和MLP-only模型。
</details></li>
</ul>
<hr>
<h2 id="Partition-A-Medical-Image-Extracting-Multiple-Representative-Sub-regions-for-Few-shot-Medical-Image-Segmentation"><a href="#Partition-A-Medical-Image-Extracting-Multiple-Representative-Sub-regions-for-Few-shot-Medical-Image-Segmentation" class="headerlink" title="Partition-A-Medical-Image: Extracting Multiple Representative Sub-regions for Few-shot Medical Image Segmentation"></a>Partition-A-Medical-Image: Extracting Multiple Representative Sub-regions for Few-shot Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11172">http://arxiv.org/abs/2309.11172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YazhouZhu19/PAMI">https://github.com/YazhouZhu19/PAMI</a></li>
<li>paper_authors: Yazhou Zhu, Shidong Wang, Tong Xin, Zheng Zhang, Haofeng Zhang</li>
<li>for: 这则研究targets医疗影像分类任务，旨在提供更有前途的解决方案，因为医疗影像分类任务中高质量的标签是自然罕见。</li>
<li>methods: 本研究使用Regional Prototypical Learning (RPL)模块将支持影像的前景 decomposed into distinct regions，然后使用这些区域来 derivation region-level representations。此外，我们还引入了一个新的Prototypical Representation Debiasing (PRD)模块，用于抑制区域表示的干扰。</li>
<li>results: 经过广泛的实验证明，本研究在三个公开 accessible medical imaging datasets上实现了与主流 FSMIS 方法相比的稳定改进。并且提供了一个可用的源代码（<a target="_blank" rel="noopener" href="https://github.com/YazhouZhu19/PAMI%EF%BC%89%E3%80%82">https://github.com/YazhouZhu19/PAMI）。</a><details>
<summary>Abstract</summary>
Few-shot Medical Image Segmentation (FSMIS) is a more promising solution for medical image segmentation tasks where high-quality annotations are naturally scarce. However, current mainstream methods primarily focus on extracting holistic representations from support images with large intra-class variations in appearance and background, and encounter difficulties in adapting to query images. In this work, we present an approach to extract multiple representative sub-regions from a given support medical image, enabling fine-grained selection over the generated image regions. Specifically, the foreground of the support image is decomposed into distinct regions, which are subsequently used to derive region-level representations via a designed Regional Prototypical Learning (RPL) module. We then introduce a novel Prototypical Representation Debiasing (PRD) module based on a two-way elimination mechanism which suppresses the disturbance of regional representations by a self-support, Multi-direction Self-debiasing (MS) block, and a support-query, Interactive Debiasing (ID) block. Finally, an Assembled Prediction (AP) module is devised to balance and integrate predictions of multiple prototypical representations learned using stacked PRD modules. Results obtained through extensive experiments on three publicly accessible medical imaging datasets demonstrate consistent improvements over the leading FSMIS methods. The source code is available at https://github.com/YazhouZhu19/PAMI.
</details>
<details>
<summary>摘要</summary>
供少医学图像分割（FSMIS）是一种更有前途的解决方案，用于医学图像分割任务中，高质量标注很难获得。然而，当前主流方法主要是提取支持图像中巨量的内部变化的整体表示，并遇到在查询图像上适应的困难。在这种工作中，我们提出了一种方法，可以从支持医学图像中提取多个代表性子区域，以便精细地选择生成的图像区域。具体来说，支持图像的前景被分解成不同的区域，然后通过我们设计的区域层学习（RPL）模块来 derivation region-level表示。我们然后引入了一种新的表示偏导（PRD）模块，基于两种排除机制，即自我支持的多向排除（MS）块和支持-查询的互动排除（ID）块。最后，我们设计了一个集成预测（AP）模块，可以平衡和集成多个表示学习的PRD模块中的预测。经过了广泛的实验，我们在三个公共 accessible的医学图像数据集上获得了一致的改进。源代码可以在https://github.com/YazhouZhu19/PAMI上获取。
</details></li>
</ul>
<hr>
<h2 id="AutoSynth-Learning-to-Generate-3D-Training-Data-for-Object-Point-Cloud-Registration"><a href="#AutoSynth-Learning-to-Generate-3D-Training-Data-for-Object-Point-Cloud-Registration" class="headerlink" title="AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud Registration"></a>AutoSynth: Learning to Generate 3D Training Data for Object Point Cloud Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11170">http://arxiv.org/abs/2309.11170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Dang, Mathieu Salzmann</li>
<li>for: 本研究旨在提供一种自动生成3D训练数据的方法，以提高3D对象注册任务的训练数据质量和数量。</li>
<li>methods: 本研究使用自动生成的3D数据集，通过筛选搜索空间中的优秀数据集，以便在低成本下获得优质的3D训练数据。</li>
<li>results: 研究表明，使用我们的方法可以在TUD-L、LINEMOD和Occluded-LINEMOD等任务上实现更好的性能，比如ModelNet40数据集。此外，我们还证明了我们的方法可以在不同的点云注册网络上实现更好的性能。<details>
<summary>Abstract</summary>
In the current deep learning paradigm, the amount and quality of training data are as critical as the network architecture and its training details. However, collecting, processing, and annotating real data at scale is difficult, expensive, and time-consuming, particularly for tasks such as 3D object registration. While synthetic datasets can be created, they require expertise to design and include a limited number of categories. In this paper, we introduce a new approach called AutoSynth, which automatically generates 3D training data for point cloud registration. Specifically, AutoSynth automatically curates an optimal dataset by exploring a search space encompassing millions of potential datasets with diverse 3D shapes at a low cost.To achieve this, we generate synthetic 3D datasets by assembling shape primitives, and develop a meta-learning strategy to search for the best training data for 3D registration on real point clouds. For this search to remain tractable, we replace the point cloud registration network with a much smaller surrogate network, leading to a $4056.43$ times speedup. We demonstrate the generality of our approach by implementing it with two different point cloud registration networks, BPNet and IDAM. Our results on TUD-L, LINEMOD and Occluded-LINEMOD evidence that a neural network trained on our searched dataset yields consistently better performance than the same one trained on the widely used ModelNet40 dataset.
</details>
<details>
<summary>摘要</summary>
现在的深度学习 paradigma中，训练数据的量和质量是网络架构和训练细节的 equally important factors。然而，收集、处理和标注实际数据在大规模上是困难、昂贵和时间consuming的，特别是 для tasks such as 3D object registration。 although synthetic datasets can be created, they require expertise to design and have a limited number of categories. In this paper, we introduce a new approach called AutoSynth, which automatically generates 3D training data for point cloud registration. Specifically, AutoSynth automatically curates an optimal dataset by exploring a search space encompassing millions of potential datasets with diverse 3D shapes at a low cost.To achieve this, we generate synthetic 3D datasets by assembling shape primitives, and develop a meta-learning strategy to search for the best training data for 3D registration on real point clouds. For this search to remain tractable, we replace the point cloud registration network with a much smaller surrogate network, leading to a $4056.43$ times speedup. We demonstrate the generality of our approach by implementing it with two different point cloud registration networks, BPNet and IDAM. Our results on TUD-L, LINEMOD and Occluded-LINEMOD evidence that a neural network trained on our searched dataset yields consistently better performance than the same one trained on the widely used ModelNet40 dataset.
</details></li>
</ul>
<hr>
<h2 id="Multi-grained-Temporal-Prototype-Learning-for-Few-shot-Video-Object-Segmentation"><a href="#Multi-grained-Temporal-Prototype-Learning-for-Few-shot-Video-Object-Segmentation" class="headerlink" title="Multi-grained Temporal Prototype Learning for Few-shot Video Object Segmentation"></a>Multi-grained Temporal Prototype Learning for Few-shot Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11160">http://arxiv.org/abs/2309.11160</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nankepan/VIPMT">https://github.com/nankepan/VIPMT</a></li>
<li>paper_authors: Nian Liu, Kepan Nan, Wangbo Zhao, Yuanwei Liu, Xiwen Yao, Salman Khan, Hisham Cholakkal, Rao Muhammad Anwer, Junwei Han, Fahad Shahbaz Khan</li>
<li>for: 这个论文旨在用少量标注图像支持进行视频对象分割，以便在视频数据中分割同一类目标对象。</li>
<li>methods: 该方法基于IPMT，一种现有的少量图像分割方法，并将多重层次时间引导信息引入视频数据处理中。具体来说，查询视频信息被分解成clip型prototype和记忆型prototype，以捕捉当地和长期内部时间引导信息。每帧独立使用框型 prototype 处理细致化适应引导，并实现了双向clip-frame prototype 交流。此外，为减少噪音记忆的影响，提出了基于结构相似关系的支持选择可靠记忆帧。此外，还提出了一种新的分割损失，以提高学习 prototype 的类别可识别度。</li>
<li>results: 实验结果表明，我们提出的视频 IPMT 模型在两个标准测试集上显著超过了之前的模型。<details>
<summary>Abstract</summary>
Few-Shot Video Object Segmentation (FSVOS) aims to segment objects in a query video with the same category defined by a few annotated support images. However, this task was seldom explored. In this work, based on IPMT, a state-of-the-art few-shot image segmentation method that combines external support guidance information with adaptive query guidance cues, we propose to leverage multi-grained temporal guidance information for handling the temporal correlation nature of video data. We decompose the query video information into a clip prototype and a memory prototype for capturing local and long-term internal temporal guidance, respectively. Frame prototypes are further used for each frame independently to handle fine-grained adaptive guidance and enable bidirectional clip-frame prototype communication. To reduce the influence of noisy memory, we propose to leverage the structural similarity relation among different predicted regions and the support for selecting reliable memory frames. Furthermore, a new segmentation loss is also proposed to enhance the category discriminability of the learned prototypes. Experimental results demonstrate that our proposed video IPMT model significantly outperforms previous models on two benchmark datasets. Code is available at https://github.com/nankepan/VIPMT.
</details>
<details>
<summary>摘要</summary>
几个视频对象分割（FSVOS）目标是使用一些定义同一类目的支持图像来分割查询视频中的对象。然而，这个任务几乎没有被研究。在这个工作中，我们基于IPMT，一种现有的少量图像分割方法，通过 вне部支持导航信息和适应查询导航征料来拓展我们的方法。我们将查询视频信息分解成一个clip原型和一个记忆原型，以捕捉本地和长期内部 temporal导航信息。每帧prototype被使用，以独立处理细腻的适应导航和两个方向clip-frame prototype通信。为了减少干扰的内存，我们提议使用不同预测区域之间的结构相似关系和支持选择可靠的记忆帧。此外，我们还提出了一种新的分割损失，以提高学习的类别可识别度。实验结果表明，我们的提出的视频IPMT模型在两个标准数据集上显著超越了之前的模型。代码可以在https://github.com/nankepan/VIPMT上获取。
</details></li>
</ul>
<hr>
<h2 id="Learning-Deformable-3D-Graph-Similarity-to-Track-Plant-Cells-in-Unregistered-Time-Lapse-Images"><a href="#Learning-Deformable-3D-Graph-Similarity-to-Track-Plant-Cells-in-Unregistered-Time-Lapse-Images" class="headerlink" title="Learning Deformable 3D Graph Similarity to Track Plant Cells in Unregistered Time Lapse Images"></a>Learning Deformable 3D Graph Similarity to Track Plant Cells in Unregistered Time Lapse Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11157">http://arxiv.org/abs/2309.11157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Shazid Islam, Arindam Dutta, Calvin-Khang Ta, Kevin Rodriguez, Christian Michael, Mark Alber, G. Venugopala Reddy, Amit K. Roy-Chowdhury</li>
<li>for: 该论文旨在提出一种基于学习的方法，用于准确地跟踪植物细胞图像中的细胞。</li>
<li>methods: 该方法利用植物细胞的紧密排列三维结构，创建三维图库，以实现准确的细胞跟踪。另外，该方法还提出了新的细胞分裂检测算法和高效三维对 align 算法。</li>
<li>results: 该论文在一个标准数据集上进行了实验，并证明了该方法的跟踪精度和搜索时间的优势。<details>
<summary>Abstract</summary>
Tracking of plant cells in images obtained by microscope is a challenging problem due to biological phenomena such as large number of cells, non-uniform growth of different layers of the tightly packed plant cells and cell division. Moreover, images in deeper layers of the tissue being noisy and unavoidable systemic errors inherent in the imaging process further complicates the problem. In this paper, we propose a novel learning-based method that exploits the tightly packed three-dimensional cell structure of plant cells to create a three-dimensional graph in order to perform accurate cell tracking. We further propose novel algorithms for cell division detection and effective three-dimensional registration, which improve upon the state-of-the-art algorithms. We demonstrate the efficacy of our algorithm in terms of tracking accuracy and inference-time on a benchmark dataset.
</details>
<details>
<summary>摘要</summary>
track plant cells in microscope images 是一个复杂的问题，因为生物现象如大量细胞、不均生长的不同层次紧密排列的植物细胞，以及细胞分裂。此外，深层组织图像中的噪声和不可避免的图像捕捉过程中的系统性错误更加复杂了问题。在本文中，我们提出了一种基于学习的方法，利用植物细胞紧密三维结构来创建三维图表，以进行准确的细胞跟踪。我们还提出了新的细胞分裂检测算法和有效的三维对接算法，这些算法都超过了当前状态的算法。我们通过对一个标准数据集进行评估，证明了我们的算法的准确性和推理时间。
</details></li>
</ul>
<hr>
<h2 id="CNN-based-local-features-for-navigation-near-an-asteroid"><a href="#CNN-based-local-features-for-navigation-near-an-asteroid" class="headerlink" title="CNN-based local features for navigation near an asteroid"></a>CNN-based local features for navigation near an asteroid</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11156">http://arxiv.org/abs/2309.11156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olli Knuuttila, Antti Kestilä, Esa Kallio</li>
<li>for:  asteroid exploration missions and on-orbit servicing</li>
<li>methods:  lightweight feature extractor specifically tailored for asteroid proximity navigation, designed to be robust to illumination changes and affine transformations</li>
<li>results:  effective navigation and localization, with incremental improvements over existing methods and a trained feature extractor<details>
<summary>Abstract</summary>
This article addresses the challenge of vision-based proximity navigation in asteroid exploration missions and on-orbit servicing. Traditional feature extraction methods struggle with the significant appearance variations of asteroids due to limited scattered light. To overcome this, we propose a lightweight feature extractor specifically tailored for asteroid proximity navigation, designed to be robust to illumination changes and affine transformations. We compare and evaluate state-of-the-art feature extraction networks and three lightweight network architectures in the asteroid context. Our proposed feature extractors and their evaluation leverages both synthetic images and real-world data from missions such as NEAR Shoemaker, Hayabusa, Rosetta, and OSIRIS-REx. Our contributions include a trained feature extractor, incremental improvements over existing methods, and a pipeline for training domain-specific feature extractors. Experimental results demonstrate the effectiveness of our approach in achieving accurate navigation and localization. This work aims to advance the field of asteroid navigation and provides insights for future research in this domain.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)这篇文章关注 asteroid 探测和处理任务中的视觉靠近导航挑战，传统的特征提取方法由于 asteroid 的限制散射光导致表现变化强大。为了解决这个问题，我们提议一种适应 asteroid 靠近导航的轻量级特征提取器，可以抗抗照明变化和抽象变换。我们比较和评估了现有的特征提取网络和三种轻量级网络体系，并在 asteroid 上进行了评估。我们的提案包括一个已经训练好的特征提取器，以及对现有方法进行了改进。我们的实验结果表明，我们的方法可以实现高精度的导航和地址确定。这项工作希望可以推动 asteroid 导航领域的进步，并为未来的研究提供了新的思路和灵感。
</details></li>
</ul>
<hr>
<h2 id="Online-Calibration-of-a-Single-Track-Ground-Vehicle-Dynamics-Model-by-Tight-Fusion-with-Visual-Inertial-Odometry"><a href="#Online-Calibration-of-a-Single-Track-Ground-Vehicle-Dynamics-Model-by-Tight-Fusion-with-Visual-Inertial-Odometry" class="headerlink" title="Online Calibration of a Single-Track Ground Vehicle Dynamics Model by Tight Fusion with Visual-Inertial Odometry"></a>Online Calibration of a Single-Track Ground Vehicle Dynamics Model by Tight Fusion with Visual-Inertial Odometry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11148">http://arxiv.org/abs/2309.11148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haolong Li, Joerg Stueckler</li>
<li>for: 这篇论文是为了提供一种基于视觉遥感和动力学模型的单车跑动估计方法，用于 Navigation Planning。</li>
<li>methods: 该方法使用了单车动力学模型，与视觉遥感（VIO）相结合，在线进行模型Parameters calibration和适应。</li>
<li>results: 实验表明，该方法可以在不同的环境下（室内和外），适应环境变化，并且可以准确地预测未来控制输入的效果。同时，该方法还可以提高跟踪精度。<details>
<summary>Abstract</summary>
Wheeled mobile robots need the ability to estimate their motion and the effect of their control actions for navigation planning. In this paper, we present ST-VIO, a novel approach which tightly fuses a single-track dynamics model for wheeled ground vehicles with visual inertial odometry. Our method calibrates and adapts the dynamics model online and facilitates accurate forward prediction conditioned on future control inputs. The single-track dynamics model approximates wheeled vehicle motion under specific control inputs on flat ground using ordinary differential equations. We use a singularity-free and differentiable variant of the single-track model to enable seamless integration as dynamics factor into VIO and to optimize the model parameters online together with the VIO state variables. We validate our method with real-world data in both indoor and outdoor environments with different terrain types and wheels. In our experiments, we demonstrate that our ST-VIO can not only adapt to the change of the environments and achieve accurate prediction under new control inputs, but even improves the tracking accuracy. Supplementary video: https://youtu.be/BuGY1L1FRa4.
</details>
<details>
<summary>摘要</summary>
自动移动机器人需要估算其运动和控制动作的影响以实现导航规划。本文提出了ST-VIO，一种新的方法，它将单车辆动力学模型紧密融合视觉陀螺仪定位。我们的方法在线投入和调整动力学模型，并使用未来控制输入的前提下进行高精度预测。单车辆动力学模型是在特定的控制输入下，在平地上使用普通微分方程描述车辆的运动。我们使用不含特征点和可微分的单车辆模型，以便轻松地将动力学模型纳入VIО中，并在VIО状态变量上线上调整模型参数。我们通过实验证明，我们的ST-VIO可以不仅适应环境变化，并在新的控制输入下实现高精度跟踪。补充视频：https://youtu.be/BuGY1L1FRa4。
</details></li>
</ul>
<hr>
<h2 id="GraphEcho-Graph-Driven-Unsupervised-Domain-Adaptation-for-Echocardiogram-Video-Segmentation"><a href="#GraphEcho-Graph-Driven-Unsupervised-Domain-Adaptation-for-Echocardiogram-Video-Segmentation" class="headerlink" title="GraphEcho: Graph-Driven Unsupervised Domain Adaptation for Echocardiogram Video Segmentation"></a>GraphEcho: Graph-Driven Unsupervised Domain Adaptation for Echocardiogram Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11145">http://arxiv.org/abs/2309.11145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/GraphEcho">https://github.com/xmed-lab/GraphEcho</a></li>
<li>paper_authors: Jiewen Yang, Xinpeng Ding, Ziyang Zheng, Xiaowei Xu, Xiaomeng Li</li>
<li>For: 这个论文研究了非监督领域适应（Unsupervised Domain Adaptation，UDA）在echocardiogram视频分割方面，目的是将来自源频谱域的模型泛化到其他未标注目标频谱域。* Methods: 我们引入了一个新的CardiacUDA数据集和一种名为GraphEcho的新方法，该方法包括两个创新模块：空间域频谱匹配（SCGM）和心跳周期一致性（TCC）模块。这两个模块可以更好地对global和local特征从源和目标频谱域进行对齐，从而提高UDA分割结果。* Results: 我们的GraphEcho方法在对比 existed状态的推荐UDA分割方法时表现出色，实验结果表明。我们的CardiacUDA数据集和代码将在接受后公开发布，这项工作将为心脏结构分割从echocardiogram视频中奠定新的、坚实的基础。代码和数据集可以通过<a target="_blank" rel="noopener" href="https://github.com/xmed-lab/GraphEcho%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/xmed-lab/GraphEcho访问。</a><details>
<summary>Abstract</summary>
Echocardiogram video segmentation plays an important role in cardiac disease diagnosis. This paper studies the unsupervised domain adaption (UDA) for echocardiogram video segmentation, where the goal is to generalize the model trained on the source domain to other unlabelled target domains. Existing UDA segmentation methods are not suitable for this task because they do not model local information and the cyclical consistency of heartbeat. In this paper, we introduce a newly collected CardiacUDA dataset and a novel GraphEcho method for cardiac structure segmentation. Our GraphEcho comprises two innovative modules, the Spatial-wise Cross-domain Graph Matching (SCGM) and the Temporal Cycle Consistency (TCC) module, which utilize prior knowledge of echocardiogram videos, i.e., consistent cardiac structure across patients and centers and the heartbeat cyclical consistency, respectively. These two modules can better align global and local features from source and target domains, improving UDA segmentation results. Experimental results showed that our GraphEcho outperforms existing state-of-the-art UDA segmentation methods. Our collected dataset and code will be publicly released upon acceptance. This work will lay a new and solid cornerstone for cardiac structure segmentation from echocardiogram videos. Code and dataset are available at: https://github.com/xmed-lab/GraphEcho
</details>
<details>
<summary>摘要</summary>
《echocardiogram视频分割 plays an important role in cardiac disease diagnosis。This paper studies the unsupervised domain adaption（UDA）for echocardiogram视频分割，where the goal is to generalize the model trained on the source domain to other unlabelled target domains。Existing UDA segmentation methods are not suitable for this task because they do not model local information and the cyclical consistency of heartbeat。In this paper, we introduce a newly collected CardiacUDA dataset and a novel GraphEcho method for cardiac structure segmentation。Our GraphEcho comprises two innovative modules，the Spatial-wise Cross-domain Graph Matching（SCGM）and the Temporal Cycle Consistency（TCC）module，which utilize prior knowledge of echocardiogram videos，i.e., consistent cardiac structure across patients and centers and the heartbeat cyclical consistency，respectively。These two modules can better align global and local features from source and target domains，improving UDA segmentation results。Experimental results showed that our GraphEcho outperforms existing state-of-the-art UDA segmentation methods。Our collected dataset and code will be publicly released upon acceptance。This work will lay a new and solid cornerstone for cardiac structure segmentation from echocardiogram videos。Code and dataset are available at：https://github.com/xmed-lab/GraphEcho。》Note that Simplified Chinese is the official writing system used in mainland China, and it may be different from Traditional Chinese, which is used in Taiwan and other regions.
</details></li>
</ul>
<hr>
<h2 id="GL-Fusion-Global-Local-Fusion-Network-for-Multi-view-Echocardiogram-Video-Segmentation"><a href="#GL-Fusion-Global-Local-Fusion-Network-for-Multi-view-Echocardiogram-Video-Segmentation" class="headerlink" title="GL-Fusion: Global-Local Fusion Network for Multi-view Echocardiogram Video Segmentation"></a>GL-Fusion: Global-Local Fusion Network for Multi-view Echocardiogram Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11144">http://arxiv.org/abs/2309.11144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/GL-Fusion">https://github.com/xmed-lab/GL-Fusion</a></li>
<li>paper_authors: Ziyang Zheng, Jiewen Yang, Xinpeng Ding, Xiaowei Xu, Xiaomeng Li</li>
<li>for: 这种研究旨在提高自动分类echocardiogram视频中的心脏结构分割精度和可靠性。</li>
<li>methods: 该研究提出了一种全新的全球-本地融合网络（GL-Fusion），用于同时利用多视图信息的全球和本地特征，以提高echocardiogram分析的准确性。</li>
<li>results: 该研究通过使用MvEVD数据集进行测试，发现GL-Fusion方法可以提高echocardiogram分析的准确性，与基eline方法相比提高了7.83%。此外，GL-Fusion方法还超过了现有的状态 искусственный智能方法。<details>
<summary>Abstract</summary>
Cardiac structure segmentation from echocardiogram videos plays a crucial role in diagnosing heart disease. The combination of multi-view echocardiogram data is essential to enhance the accuracy and robustness of automated methods. However, due to the visual disparity of the data, deriving cross-view context information remains a challenging task, and unsophisticated fusion strategies can even lower performance. In this study, we propose a novel Gobal-Local fusion (GL-Fusion) network to jointly utilize multi-view information globally and locally that improve the accuracy of echocardiogram analysis. Specifically, a Multi-view Global-based Fusion Module (MGFM) is proposed to extract global context information and to explore the cyclic relationship of different heartbeat cycles in an echocardiogram video. Additionally, a Multi-view Local-based Fusion Module (MLFM) is designed to extract correlations of cardiac structures from different views. Furthermore, we collect a multi-view echocardiogram video dataset (MvEVD) to evaluate our method. Our method achieves an 82.29% average dice score, which demonstrates a 7.83% improvement over the baseline method, and outperforms other existing state-of-the-art methods. To our knowledge, this is the first exploration of a multi-view method for echocardiogram video segmentation. Code available at: https://github.com/xmed-lab/GL-Fusion
</details>
<details>
<summary>摘要</summary>
卡第亚结构分割自echocardiogram视频中扮演重要的角色，用于诊断心血管疾病。多视图echocardiogram数据的组合是提高自动方法的准确性和可靠性的关键。然而，由于视觉差异， derivation of cross-view context information remains a challenging task, and unsophisticated fusion strategies can even lower performance. 在这种研究中，我们提出了一种全新的全球-本地混合（GL-Fusion）网络，用于同时利用多视图信息的全球和本地信息，以提高echocardiogram分析的准确性。 Specifically, a Multi-view Global-based Fusion Module (MGFM) is proposed to extract global context information and to explore the cyclic relationship of different heartbeat cycles in an echocardiogram video. Additionally, a Multi-view Local-based Fusion Module (MLFM) is designed to extract correlations of cardiac structures from different views. Furthermore, we collect a multi-view echocardiogram video dataset (MvEVD) to evaluate our method. Our method achieves an 82.29% average dice score, which demonstrates a 7.83% improvement over the baseline method, and outperforms other existing state-of-the-art methods. To our knowledge, this is the first exploration of a multi-view method for echocardiogram video segmentation. 可以在https://github.com/xmed-lab/GL-Fusion找到我们的代码。
</details></li>
</ul>
<hr>
<h2 id="More-complex-encoder-is-not-all-you-need"><a href="#More-complex-encoder-is-not-all-you-need" class="headerlink" title="More complex encoder is not all you need"></a>More complex encoder is not all you need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11139">http://arxiv.org/abs/2309.11139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aitechlabcn/neUNet">https://github.com/aitechlabcn/neUNet</a></li>
<li>paper_authors: Weibin Yang, Longwei Xu, Pengwei Wang, Dehua Geng, Yusong Li, Mingyuan Xu, Zhiqi Dong</li>
<li>for: 这个论文主要用于提高医疗影像分类的精度和效率。</li>
<li>methods: 本文使用的方法包括：U-Net和其变体，并将注意力集中在增强解oder的部分，特别是增强upsampling部分以提高分类结果。</li>
<li>results: 本文的结果显示，使用了新的Sub-pixel Convolution和多条气平面输入模块，可以提高分类结果的精度和效率，并且在Synapse和ACDC datasets上表现出色，超越了其他现有的方法。<details>
<summary>Abstract</summary>
U-Net and its variants have been widely used in medical image segmentation. However, most current U-Net variants confine their improvement strategies to building more complex encoder, while leaving the decoder unchanged or adopting a simple symmetric structure. These approaches overlook the true functionality of the decoder: receiving low-resolution feature maps from the encoder and restoring feature map resolution and lost information through upsampling. As a result, the decoder, especially its upsampling component, plays a crucial role in enhancing segmentation outcomes. However, in 3D medical image segmentation, the commonly used transposed convolution can result in visual artifacts. This issue stems from the absence of direct relationship between adjacent pixels in the output feature map. Furthermore, plain encoder has already possessed sufficient feature extraction capability because downsampling operation leads to the gradual expansion of the receptive field, but the loss of information during downsampling process is unignorable. To address the gap in relevant research, we extend our focus beyond the encoder and introduce neU-Net (i.e., not complex encoder U-Net), which incorporates a novel Sub-pixel Convolution for upsampling to construct a powerful decoder. Additionally, we introduce multi-scale wavelet inputs module on the encoder side to provide additional information. Our model design achieves excellent results, surpassing other state-of-the-art methods on both the Synapse and ACDC datasets.
</details>
<details>
<summary>摘要</summary>
U-Net和其变种在医学影像分割中广泛应用。然而，现有的U-Net变种通常是通过建立更复杂的编码器来提高性能，而忽略了解码器的真正功能：接收低分辨率特征图并将其修复到原始分辨率和丢失信息。这些方法忽略了解码器中的upsampling组件的重要作用，这使得分割结果受到限制。尤其在3D医学影像分割中，通常使用的拼接 convolution 可能会导致视觉artefacts。这种问题的原因在于输出特征图中不存在直接相邻像素的直接关系。此外，简单的编码器已经拥有了充足的特征提取能力，因为下降操作导致捕捉区域的扩展，但是下降操作中丢失的信息是不可忽略的。为了解决这个研究漏洞，我们扩展了我们的关注范围，并引入了一种新的Sub-pixel Convolution для upsampling，以建立一个强大的解码器。此外，我们还引入了多尺度wavelet输入模块在编码器Side来提供额外信息。我们的模型设计实现了出色的结果，超过了其他状态对的方法在Synapse和ACDC数据集上。
</details></li>
</ul>
<hr>
<h2 id="Shape-Anchor-Guided-Holistic-Indoor-Scene-Understanding"><a href="#Shape-Anchor-Guided-Holistic-Indoor-Scene-Understanding" class="headerlink" title="Shape Anchor Guided Holistic Indoor Scene Understanding"></a>Shape Anchor Guided Holistic Indoor Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11133">http://arxiv.org/abs/2309.11133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Geo-Tell/AncRec">https://github.com/Geo-Tell/AncRec</a></li>
<li>paper_authors: Mingyue Dong, Linxi Huan, Hanjiang Xiong, Shuhan Shen, Xianwei Zheng</li>
<li>for: 提出了一种基于形态锚点的学习策略（AncLearn），用于实现室内Scene理解的稳定和准确性。</li>
<li>methods: 利用形态锚点生成anchors，以便在搜索空间中提取实际存在的对象表示，并且通过对噪声和目标相关特征进行分离，提供可靠的提议。在重建阶段，通过减少异常值，提供高质量的对象点抽象。</li>
<li>results: 在ScanNetv2 dataset上进行了实验，并取得了在3D对象检测、布局估计和形态重建方面的状态 искусственный智能性能。<details>
<summary>Abstract</summary>
This paper proposes a shape anchor guided learning strategy (AncLearn) for robust holistic indoor scene understanding. We observe that the search space constructed by current methods for proposal feature grouping and instance point sampling often introduces massive noise to instance detection and mesh reconstruction. Accordingly, we develop AncLearn to generate anchors that dynamically fit instance surfaces to (i) unmix noise and target-related features for offering reliable proposals at the detection stage, and (ii) reduce outliers in object point sampling for directly providing well-structured geometry priors without segmentation during reconstruction. We embed AncLearn into a reconstruction-from-detection learning system (AncRec) to generate high-quality semantic scene models in a purely instance-oriented manner. Experiments conducted on the challenging ScanNetv2 dataset demonstrate that our shape anchor-based method consistently achieves state-of-the-art performance in terms of 3D object detection, layout estimation, and shape reconstruction. The code will be available at https://github.com/Geo-Tell/AncRec.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Locate-and-Verify-A-Two-Stream-Network-for-Improved-Deepfake-Detection"><a href="#Locate-and-Verify-A-Two-Stream-Network-for-Improved-Deepfake-Detection" class="headerlink" title="Locate and Verify: A Two-Stream Network for Improved Deepfake Detection"></a>Locate and Verify: A Two-Stream Network for Improved Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11131">http://arxiv.org/abs/2309.11131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sccsok/Locate-and-Verify">https://github.com/sccsok/Locate-and-Verify</a></li>
<li>paper_authors: Chao Shuai, Jieming Zhong, Shuang Wu, Feng Lin, Zhibo Wang, Zhongjie Ba, Zhenguang Liu, Lorenzo Cavallaro, Kui Ren</li>
<li>for: 本研究旨在提高深伪检测方法的一般化能力和特定 forgery 区域探测能力。</li>
<li>methods: 本文提出了三个方法来解决现有方法的缺陷：一个创新的两条流网络，三个功能模组，以及一个半supervised Patch Similarity Learning策略。</li>
<li>results: 本文的方法在六个benchmark上与现有方法比较，表现出了significantly improved的一般化和特定 forgery 区域探测能力，包括Frame-level AUC在Deepfake Detection Challenge preview dataset上从0.797提高到0.835，以及Video-level AUC在CelebDF$_$v1 dataset上从0.811提高到0.847。<details>
<summary>Abstract</summary>
Deepfake has taken the world by storm, triggering a trust crisis. Current deepfake detection methods are typically inadequate in generalizability, with a tendency to overfit to image contents such as the background, which are frequently occurring but relatively unimportant in the training dataset. Furthermore, current methods heavily rely on a few dominant forgery regions and may ignore other equally important regions, leading to inadequate uncovering of forgery cues. In this paper, we strive to address these shortcomings from three aspects: (1) We propose an innovative two-stream network that effectively enlarges the potential regions from which the model extracts forgery evidence. (2) We devise three functional modules to handle the multi-stream and multi-scale features in a collaborative learning scheme. (3) Confronted with the challenge of obtaining forgery annotations, we propose a Semi-supervised Patch Similarity Learning strategy to estimate patch-level forged location annotations. Empirically, our method demonstrates significantly improved robustness and generalizability, outperforming previous methods on six benchmarks, and improving the frame-level AUC on Deepfake Detection Challenge preview dataset from 0.797 to 0.835 and video-level AUC on CelebDF$\_$v1 dataset from 0.811 to 0.847. Our implementation is available at https://github.com/sccsok/Locate-and-Verify.
</details>
<details>
<summary>摘要</summary>
深刻的假动作（Deepfake）已经在世界上引发了一场信任危机。目前的假动作检测方法通常无法普遍化，往往对背景进行过滤，这些背景虽然常见但相对 speaking 不重要。此外，现有的方法倾向于仅对一些主导的伪造区域进行过滤，可能会忽略其他Equally important regions，从而导致伪造讯号的不充分探测。在这篇文章中，我们尝试解决这些缺陷自三个方面：1. 我们提出了一个创新的两条流网络，实际地扩大了模型从中提取伪造证据的可能区域。2. 我们设计了三个功能模组，以实现多条流和多个标准之间的合作学习。3. 面对伪造标注的挑战，我们提出了一个半supervised Patch Similarity Learning策略，以估计伪造区域标注。实际上，我们的方法在六个benchmark上表现出色，与前一代方法相比，具有更好的 Robustness 和普遍化能力。我们的实现可以在https://github.com/sccsok/Locate-and-Verify上找到。
</details></li>
</ul>
<hr>
<h2 id="PSDiff-Diffusion-Model-for-Person-Search-with-Iterative-and-Collaborative-Refinement"><a href="#PSDiff-Diffusion-Model-for-Person-Search-with-Iterative-and-Collaborative-Refinement" class="headerlink" title="PSDiff: Diffusion Model for Person Search with Iterative and Collaborative Refinement"></a>PSDiff: Diffusion Model for Person Search with Iterative and Collaborative Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11125">http://arxiv.org/abs/2309.11125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengyou Jia, Minnan Luo, Zhuohang Dang, Guang Dai, Xiaojun Chang, Jingdong Wang, Qinghua Zheng</li>
<li>for: 本文旨在提出一种新的人员搜索框架，以解决现有方法中的两个主要挑战：1）探测阶段模块不适合人脸识别任务；2）两个子任务之间的协作被忽略。</li>
<li>methods: 本文使用了Diffusion模型，将人员搜索转化为两个阶段的双杂化过程，从噪声框和人脸嵌入转化为实际情况。与传统的探测到人脸识别的方法不同，我们的杂化方法可以消除探测阶段模块，从而避免人脸识别任务的地方最优点。此外，我们还设计了一种新的协同杂化层，以便在探测和人脸识别两个子任务之间进行融合协同，使两个子任务互相帮助。</li>
<li>results: 实验结果表明，PSDiff在标准测试集上达到了当前最佳性能，具有较少的参数和灵活计算负担。<details>
<summary>Abstract</summary>
Dominant Person Search methods aim to localize and recognize query persons in a unified network, which jointly optimizes two sub-tasks, \ie, detection and Re-IDentification (ReID). Despite significant progress, two major challenges remain: 1) Detection-prior modules in previous methods are suboptimal for the ReID task. 2) The collaboration between two sub-tasks is ignored. To alleviate these issues, we present a novel Person Search framework based on the Diffusion model, PSDiff. PSDiff formulates the person search as a dual denoising process from noisy boxes and ReID embeddings to ground truths. Unlike existing methods that follow the Detection-to-ReID paradigm, our denoising paradigm eliminates detection-prior modules to avoid the local-optimum of the ReID task. Following the new paradigm, we further design a new Collaborative Denoising Layer (CDL) to optimize detection and ReID sub-tasks in an iterative and collaborative way, which makes two sub-tasks mutually beneficial. Extensive experiments on the standard benchmarks show that PSDiff achieves state-of-the-art performance with fewer parameters and elastic computing overhead.
</details>
<details>
<summary>摘要</summary>
主流人体搜索方法目标是在一个统一网络中本地化和识别查询人体，同时优化两个子任务，即探测和ReID（人体识别）。尽管有了很大的进步，但两个主要挑战仍然存在：1）探测优先模块在先前的方法中是不佳的ReID任务。2）两个子任务之间的合作被忽视。为了解决这些问题，我们提出了一种基于Diffusion模型的人体搜索框架，称为PSDiff。PSDiff将人体搜索转化为一个双方减噪过程，从噪声框和ReID嵌入转化到实际值。与先前的方法不同，我们的减噪方法不需要探测优先模块，以避免探测任务的本地最佳点。在新的 paradigma下，我们进一步设计了一个新的合作减噪层（CDL），以便在迭代和协同的方式优化探测和ReID子任务，使两个子任务互相有利。经验表明，PSDiff在标准测试准则上达到了状态的精度性表现，并且具有 fewer 参数和灵活计算负担。
</details></li>
</ul>
<hr>
<h2 id="Hyperspectral-Benchmark-Bridging-the-Gap-between-HSI-Applications-through-Comprehensive-Dataset-and-Pretraining"><a href="#Hyperspectral-Benchmark-Bridging-the-Gap-between-HSI-Applications-through-Comprehensive-Dataset-and-Pretraining" class="headerlink" title="Hyperspectral Benchmark: Bridging the Gap between HSI Applications through Comprehensive Dataset and Pretraining"></a>Hyperspectral Benchmark: Bridging the Gap between HSI Applications through Comprehensive Dataset and Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11122">http://arxiv.org/abs/2309.11122</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cogsys-tuebingen/hsi_benchmark">https://github.com/cogsys-tuebingen/hsi_benchmark</a></li>
<li>paper_authors: Hannah Frank, Leon Amadeus Varga, Andreas Zell</li>
<li>for: 这个研究旨在提供一个全面的专门应用于几何pectral实验（HSI）的benchmark dataset，以便更好地评估几何spectral模型的能力。</li>
<li>methods: 本研究使用了一个新的benchmark dataset，包括三个不同的HSI应用：食品检查、远程感知和回收。此外，研究还提出了一个预训管道，以提高专门的训练过程稳定性。</li>
<li>results: 本研究的结果显示，这个benchmark dataset可以更好地评估专门的HSI模型，并且可以推广现有的方法。此外，预训管道可以提高专门的训练过程稳定性。<details>
<summary>Abstract</summary>
Hyperspectral Imaging (HSI) serves as a non-destructive spatial spectroscopy technique with a multitude of potential applications. However, a recurring challenge lies in the limited size of the target datasets, impeding exhaustive architecture search. Consequently, when venturing into novel applications, reliance on established methodologies becomes commonplace, in the hope that they exhibit favorable generalization characteristics. Regrettably, this optimism is often unfounded due to the fine-tuned nature of models tailored to specific HSI contexts.   To address this predicament, this study introduces an innovative benchmark dataset encompassing three markedly distinct HSI applications: food inspection, remote sensing, and recycling. This comprehensive dataset affords a finer assessment of hyperspectral model capabilities. Moreover, this benchmark facilitates an incisive examination of prevailing state-of-the-art techniques, consequently fostering the evolution of superior methodologies.   Furthermore, the enhanced diversity inherent in the benchmark dataset underpins the establishment of a pretraining pipeline for HSI. This pretraining regimen serves to enhance the stability of training processes for larger models. Additionally, a procedural framework is delineated, offering insights into the handling of applications afflicted by limited target dataset sizes.
</details>
<details>
<summary>摘要</summary>
干elespectral Imaging（HSI）是一种不 destrucción的空间спектроскопи技术，具有各种应用前景。然而，一个常 recurs的挑战是目标数据集的有限大小，导致了较少的模型搜索空间。因此，在探索新应用场景时，通常会依靠已有的方法，希望它们在不同的HSI上能够展现良好的泛化特性。然而，这种optimism通常是不符的，因为这些模型是为特定HSI上精心定制的。为解决这个困境，本研究提出了一个创新的标准数据集，包括三个明确不同的HSI应用：食品检查、远程感知和回收。这个全面的数据集为干elespectral模型的能力进行更加细致的评估。此外，这个标准数据集还支持现有的state-of-the-art技术的准确性的减弱，从而促进了更高水平的方法的进化。此外，增强的数据集多样性为HSI预训练管道提供了基础。这个预训练管道可以增强大型模型的训练过程的稳定性。此外，本研究还提出了一种手动框架，用于处理受有限target数据集大小的应用。
</details></li>
</ul>
<hr>
<h2 id="BroadBEV-Collaborative-LiDAR-camera-Fusion-for-Broad-sighted-Bird’s-Eye-View-Map-Construction"><a href="#BroadBEV-Collaborative-LiDAR-camera-Fusion-for-Broad-sighted-Bird’s-Eye-View-Map-Construction" class="headerlink" title="BroadBEV: Collaborative LiDAR-camera Fusion for Broad-sighted Bird’s Eye View Map Construction"></a>BroadBEV: Collaborative LiDAR-camera Fusion for Broad-sighted Bird’s Eye View Map Construction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11119">http://arxiv.org/abs/2309.11119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsu Kim, Giseop Kim, Kyong Hwan Jin, Sunwook Choi</li>
<li>for: 本研究旨在提高激光摄像机（LiDAR）和摄像机（camera）的 Bird’s Eye View（BEV）空间融合，以实现更广泛的视场和高精度的地面检测。</li>
<li>methods: 我们提出了一种广泛的 BEV融合策略（BroadBEV），包括点散发（Point-scattering）和自注重权重（ColFusion）两个部分。点散发方法使得LiDAR BEV分布散射到摄像机深度分布中，以提高摄像机分支的深度估计和精度。自注重权重方法在LiDAR和摄像机 BEV特征之间应用自注重权重，以实现有效的 BEV融合。</li>
<li>results: 我们的实验表明，BroadBEV可以提供广泛的 BEV视场，并且有较高的性能提升。<details>
<summary>Abstract</summary>
A recent sensor fusion in a Bird's Eye View (BEV) space has shown its utility in various tasks such as 3D detection, map segmentation, etc. However, the approach struggles with inaccurate camera BEV estimation, and a perception of distant areas due to the sparsity of LiDAR points. In this paper, we propose a broad BEV fusion (BroadBEV) that addresses the problems with a spatial synchronization approach of cross-modality. Our strategy aims to enhance camera BEV estimation for a broad-sighted perception while simultaneously improving the completion of LiDAR's sparsity in the entire BEV space. Toward that end, we devise Point-scattering that scatters LiDAR BEV distribution to camera depth distribution. The method boosts the learning of depth estimation of the camera branch and induces accurate location of dense camera features in BEV space. For an effective BEV fusion between the spatially synchronized features, we suggest ColFusion that applies self-attention weights of LiDAR and camera BEV features to each other. Our extensive experiments demonstrate that BroadBEV provides a broad-sighted BEV perception with remarkable performance gains.
</details>
<details>
<summary>摘要</summary>
Recently, a sensor fusion in a bird's eye view (BEV) space has shown its potential in various tasks such as 3D detection and map segmentation. However, the approach is limited by inaccurate camera BEV estimation and a lack of information on distant areas due to the sparsity of LiDAR points. In this paper, we propose a broad BEV fusion (BroadBEV) that addresses these problems using a cross-modality spatial synchronization approach. Our method aims to improve camera BEV estimation for a broad-sighted perception while simultaneously enhancing the completion of LiDAR's sparsity in the entire BEV space. To achieve this, we use Point-scattering to scatter LiDAR BEV distribution to camera depth distribution, which boosts the learning of depth estimation of the camera branch and accurately locates dense camera features in BEV space. Additionally, we propose ColFusion, which applies self-attention weights of LiDAR and camera BEV features to each other for effective BEV fusion. Our extensive experiments show that BroadBEV provides a broad-sighted BEV perception with significant performance gains.
</details></li>
</ul>
<hr>
<h2 id="PRAT-PRofiling-Adversarial-aTtacks"><a href="#PRAT-PRofiling-Adversarial-aTtacks" class="headerlink" title="PRAT: PRofiling Adversarial aTtacks"></a>PRAT: PRofiling Adversarial aTtacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11111">http://arxiv.org/abs/2309.11111</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rahulambati/PRAT">https://github.com/rahulambati/PRAT</a></li>
<li>paper_authors: Rahul Ambati, Naveed Akhtar, Ajmal Mian, Yogesh Singh Rawat</li>
<li>for: 这个研究的目的是为了检测和识别深度学习模型面对攻击时所产生的攻击方法。</li>
<li>methods: 这个研究使用了一个新的架构，叫做GLOF（Global-LOcal Feature）模组，它可以将攻击示例中的特征提取出来，并且用于识别攻击的方法。</li>
<li>results: 这个研究使用了一个大量的攻击识别数据集（AID），包含了180,000个攻击示例，并通过使用GLOF模组进行攻击识别，获得了多个有趣的比较结果。<details>
<summary>Abstract</summary>
Intrinsic susceptibility of deep learning to adversarial examples has led to a plethora of attack techniques with a broad common objective of fooling deep models. However, we find slight compositional differences between the algorithms achieving this objective. These differences leave traces that provide important clues for attacker profiling in real-life scenarios. Inspired by this, we introduce a novel problem of PRofiling Adversarial aTtacks (PRAT). Given an adversarial example, the objective of PRAT is to identify the attack used to generate it. Under this perspective, we can systematically group existing attacks into different families, leading to the sub-problem of attack family identification, which we also study. To enable PRAT analysis, we introduce a large Adversarial Identification Dataset (AID), comprising over 180k adversarial samples generated with 13 popular attacks for image specific/agnostic white/black box setups. We use AID to devise a novel framework for the PRAT objective. Our framework utilizes a Transformer based Global-LOcal Feature (GLOF) module to extract an approximate signature of the adversarial attack, which in turn is used for the identification of the attack. Using AID and our framework, we provide multiple interesting benchmark results for the PRAT problem.
</details>
<details>
<summary>摘要</summary>
深度学习内置的攻击例子感受性问题，导致了许多攻击技术的出现，它们的共同目标都是欺骗深度模型。然而，我们发现这些攻击技术之间存在轻微的组合差异，这些差异留下了重要的攻击者追踪 traces。 inspirited by this，我们提出了一个新的问题：PRofiling Adversarial aTtacks（PRAT）。给定一个攻击例子，PRAT 的目标是确定攻击该例子的攻击方法。基于这种视角，我们可以系统地将现有的攻击分为不同的家族，导致了攻击家族识别问题的研究，我们也进行了这种研究。为了启用 PRAT 分析，我们提出了一个大型的攻击标识数据集（AID），包含了180k多个生成了13种流行的攻击的攻击示例，用于黑色/白色盒子设置。我们使用 AID 和我们的框架，提出了一种新的框架来实现 PRAT 目标。我们的框架使用 Transformer 基于的全局-本地特征（GLOF）模块，将攻击例子中的攻击特征提取出来，并用于攻击的识别。使用 AID 和我们的框架，我们提供了多个有趣的 PRAT 问题的 benchmark 结果。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Domain-agnostic-Domain-Adaptation-for-Satellite-Images"><a href="#Self-supervised-Domain-agnostic-Domain-Adaptation-for-Satellite-Images" class="headerlink" title="Self-supervised Domain-agnostic Domain Adaptation for Satellite Images"></a>Self-supervised Domain-agnostic Domain Adaptation for Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11109">http://arxiv.org/abs/2309.11109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fahong Zhang, Yilei Shi, Xiao Xiang Zhu</li>
<li>for:  Addressing the domain shift issue in machine learning for global scale satellite image processing.</li>
<li>methods:  Proposed an self-supervised domain-agnostic domain adaptation (SS(DA)2) method, which uses a contrastive generative adversarial loss to train a generative network for image-to-image translation, and improves the generalizability of downstream models by augmenting the training data with different testing spectral characteristics.</li>
<li>results:  Experimental results on public benchmarks verified the effectiveness of SS(DA)2.<details>
<summary>Abstract</summary>
Domain shift caused by, e.g., different geographical regions or acquisition conditions is a common issue in machine learning for global scale satellite image processing. A promising method to address this problem is domain adaptation, where the training and the testing datasets are split into two or multiple domains according to their distributions, and an adaptation method is applied to improve the generalizability of the model on the testing dataset. However, defining the domain to which each satellite image belongs is not trivial, especially under large-scale multi-temporal and multi-sensory scenarios, where a single image mosaic could be generated from multiple data sources. In this paper, we propose an self-supervised domain-agnostic domain adaptation (SS(DA)2) method to perform domain adaptation without such a domain definition. To achieve this, we first design a contrastive generative adversarial loss to train a generative network to perform image-to-image translation between any two satellite image patches. Then, we improve the generalizability of the downstream models by augmenting the training data with different testing spectral characteristics. The experimental results on public benchmarks verify the effectiveness of SS(DA)2.
</details>
<details>
<summary>摘要</summary>
域外转移问题，如不同地理区域或获取条件，是机器学习在全球范围卫星图像处理中的常见问题。一种有前途的方法是领域适应，其中训练集和测试集被分成两个或多个领域，并应用适应方法以提高测试集模型的泛化性。然而，定义各卫星图像归属的领域并不是易事，尤其在大规模多时间和多感器场景下，一个卫星图像融合可能来自多个数据源。在这篇论文中，我们提出了一种自主适应领域无关的自动适应（SS(DA)2）方法，无需定义各卫星图像的领域。为此，我们首先设计了一种对比生成隐藏层的挑战推荐损失，以训练生成网络进行卫星图像块之间的自动翻译。然后，我们通过增加不同测试spectral特征来提高下游模型的泛化性。实验结果表明，SS(DA)2有效地解决了域外转移问题。
</details></li>
</ul>
<hr>
<h2 id="Forgery-aware-Adaptive-Vision-Transformer-for-Face-Forgery-Detection"><a href="#Forgery-aware-Adaptive-Vision-Transformer-for-Face-Forgery-Detection" class="headerlink" title="Forgery-aware Adaptive Vision Transformer for Face Forgery Detection"></a>Forgery-aware Adaptive Vision Transformer for Face Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11092">http://arxiv.org/abs/2309.11092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anwei Luo, Rizhao Cai, Chenqi Kong, Xiangui Kang, Jiwu Huang, Alex C. Kot</li>
<li>for: 保护 authentication 完整性，防止 face 伪造攻击。</li>
<li>methods: 提出了一种 Novel Forgery-aware Adaptive Vision Transformer (FA-ViT)，具有冻结 vanilla ViT 的参数，并采用 Local-aware Forgery Injector (LFI) 和 Global-aware Forgery Adaptor (GFA) 两种特殊组件，以适应伪造相关的知识。</li>
<li>results: 实验表明，我们的 FA-ViT 在 cross-dataset 评估和 cross- manipulate 场景中达到了状态机器人的性能，并提高了对未经看到的干扰的Robustness。<details>
<summary>Abstract</summary>
With the advancement in face manipulation technologies, the importance of face forgery detection in protecting authentication integrity becomes increasingly evident. Previous Vision Transformer (ViT)-based detectors have demonstrated subpar performance in cross-database evaluations, primarily because fully fine-tuning with limited Deepfake data often leads to forgetting pre-trained knowledge and over-fitting to data-specific ones. To circumvent these issues, we propose a novel Forgery-aware Adaptive Vision Transformer (FA-ViT). In FA-ViT, the vanilla ViT's parameters are frozen to preserve its pre-trained knowledge, while two specially designed components, the Local-aware Forgery Injector (LFI) and the Global-aware Forgery Adaptor (GFA), are employed to adapt forgery-related knowledge. our proposed FA-ViT effectively combines these two different types of knowledge to form the general forgery features for detecting Deepfakes. Specifically, LFI captures local discriminative information and incorporates these information into ViT via Neighborhood-Preserving Cross Attention (NPCA). Simultaneously, GFA learns adaptive knowledge in the self-attention layer, bridging the gap between the two different domain. Furthermore, we design a novel Single Domain Pairwise Learning (SDPL) to facilitate fine-grained information learning in FA-ViT. The extensive experiments demonstrate that our FA-ViT achieves state-of-the-art performance in cross-dataset evaluation and cross-manipulation scenarios, and improves the robustness against unseen perturbations.
</details>
<details>
<summary>摘要</summary>
随着人脸杜撰技术的发展，保护身份验证的 authenticty integrity 成为越来越重要的。先前的 Vision Transformer (ViT) 基于的检测器在跨数据库评估中表现不佳，主要因为完全精度调整 WITH 有限的 Deepfake 数据通常会导致忘记预训练知识并过拟合数据库specific 的知识。为了解决这些问题，我们提出了一种 novel Forgery-aware Adaptive Vision Transformer (FA-ViT)。在 FA-ViT 中，vanilla ViT 的参数被冻结，以保持其预训练的知识。同时，我们采用了两个特制的组件：Local-aware Forgery Injector (LFI) 和 Global-aware Forgery Adaptor (GFA)。LFI 捕捉了地方特征信息，并将这些信息与 Neighborhood-Preserving Cross Attention (NPCA) 结合，以便在 ViT 中捕捉到地方特征。而 GFA 在自注意层中学习了适应性知识， bridging the gap  между两种不同的领域。此外，我们还设计了一种 novel Single Domain Pairwise Learning (SDPL)，以便在 FA-ViT 中进行细化信息学习。广泛的实验表明，我们的 FA-ViT 在跨数据库评估和跨杜撰场景中表现出了 state-of-the-art 的性能，并且能够对未经见杜撰的攻击进行鲁棒化。
</details></li>
</ul>
<hr>
<h2 id="Learning-Segment-Similarity-and-Alignment-in-Large-Scale-Content-Based-Video-Retrieval"><a href="#Learning-Segment-Similarity-and-Alignment-in-Large-Scale-Content-Based-Video-Retrieval" class="headerlink" title="Learning Segment Similarity and Alignment in Large-Scale Content Based Video Retrieval"></a>Learning Segment Similarity and Alignment in Large-Scale Content Based Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11091">http://arxiv.org/abs/2309.11091</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Jiang, Kaiming Huang, Sifeng He, Xudong Yang, Wei Zhang, Xiaobo Zhang, Yuan Cheng, Lei Yang, Qing Wang, Furong Xu, Tan Pan, Wei Chu</li>
<li>for: 这篇论文主要旨在提高内容基于视频检索（CBVR）的精度和效率，尤其是在长视频场景下。</li>
<li>methods: 该论文提出了一种基于自助学习的 Segment Similarity and Alignment Network (SSAN)，包括两个新提出的模块：(1) 高效的自动生成关键帧EXTraction（SKE）模块，(2) 稳定的 Similarity Pattern Detection（SPD）模块。</li>
<li>results: 对于公共数据集的实验结果表明，SSAN可以获得更高的Alignment精度，同时减少存储和在线查询计算成本，比既有方法更高。<details>
<summary>Abstract</summary>
With the explosive growth of web videos in recent years, large-scale Content-Based Video Retrieval (CBVR) becomes increasingly essential in video filtering, recommendation, and copyright protection. Segment-level CBVR (S-CBVR) locates the start and end time of similar segments in finer granularity, which is beneficial for user browsing efficiency and infringement detection especially in long video scenarios. The challenge of S-CBVR task is how to achieve high temporal alignment accuracy with efficient computation and low storage consumption. In this paper, we propose a Segment Similarity and Alignment Network (SSAN) in dealing with the challenge which is firstly trained end-to-end in S-CBVR. SSAN is based on two newly proposed modules in video retrieval: (1) An efficient Self-supervised Keyframe Extraction (SKE) module to reduce redundant frame features, (2) A robust Similarity Pattern Detection (SPD) module for temporal alignment. In comparison with uniform frame extraction, SKE not only saves feature storage and search time, but also introduces comparable accuracy and limited extra computation time. In terms of temporal alignment, SPD localizes similar segments with higher accuracy and efficiency than existing deep learning methods. Furthermore, we jointly train SSAN with SKE and SPD and achieve an end-to-end improvement. Meanwhile, the two key modules SKE and SPD can also be effectively inserted into other video retrieval pipelines and gain considerable performance improvements. Experimental results on public datasets show that SSAN can obtain higher alignment accuracy while saving storage and online query computational cost compared to existing methods.
</details>
<details>
<summary>摘要</summary>
随着网络视频的快速增长，大规模的内容基于视频检索（CBVR）在视频筛选、推荐和版权保护中变得越来越重要。segment级CBVR（S-CBVR）可以在更细粒度上定位相似的分割时间，这对用户浏览效率和侵权检测尤为重要，特别是在长视频场景下。S-CBVR任务的挑战是如何实现高精度时间对对应和高效计算且快速存储消耗。在这篇论文中，我们提出了一种Segment Similarity and Alignment Network（SSAN）来解决这个挑战。SSAN基于两个新提出的模块：（1）高效的自动学习键帧EXTRACTION（SKE）模块，以减少缓存和搜索时间，同时保持相似性和精度；（2）Robust的同时间模式检测（SPD）模块，用于时间对对应。相比于固定帧EXTRACTION，SKE不仅减少了特征存储和搜索时间，还引入了相似的准确性和有限的额外计算时间。在时间对对应方面，SPD可以更高精度地local化相似分割，而且更高效 than现有的深度学习方法。此外，我们将SSAN、SKE和SPD联合训练，实现了端到端提升。此外，这两个关键模块也可以在其他视频检索管道中插入，并获得显著性能提升。实验结果表明，SSAN可以在公共数据集上获得更高的对应精度，同时减少存储和在线查询计算成本。
</details></li>
</ul>
<hr>
<h2 id="Dense-2D-3D-Indoor-Prediction-with-Sound-via-Aligned-Cross-Modal-Distillation"><a href="#Dense-2D-3D-Indoor-Prediction-with-Sound-via-Aligned-Cross-Modal-Distillation" class="headerlink" title="Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation"></a>Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11081">http://arxiv.org/abs/2309.11081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heeseung Yun, Joonil Na, Gunhee Kim</li>
<li>for: 这篇论文旨在探讨如何使深度网络拥有空间逻辑能力，以便在我们日常生活中更好地利用声音信息。</li>
<li>methods: 该论文提出了一种名为“匹配引导”（SAM）的知识填充框架，用于在视觉知识传输中匹配地址问题。该框架将听音特征与视觉准确的学习空间嵌入结合起来，以解决多层学生模型中的不一致性问题。</li>
<li>results: 该论文通过一个新创建的封闭预测数据集（DAPS），成功地解决了indoor dense prediction问题，包括声音基础 depth estimation、semantic segmentation和3D场景重建等问题。在不同的metric和后处理架构下，该distillation框架一致地实现了状态的最佳性能。<details>
<summary>Abstract</summary>
Sound can convey significant information for spatial reasoning in our daily lives. To endow deep networks with such ability, we address the challenge of dense indoor prediction with sound in both 2D and 3D via cross-modal knowledge distillation. In this work, we propose a Spatial Alignment via Matching (SAM) distillation framework that elicits local correspondence between the two modalities in vision-to-audio knowledge transfer. SAM integrates audio features with visually coherent learnable spatial embeddings to resolve inconsistencies in multiple layers of a student model. Our approach does not rely on a specific input representation, allowing for flexibility in the input shapes or dimensions without performance degradation. With a newly curated benchmark named Dense Auditory Prediction of Surroundings (DAPS), we are the first to tackle dense indoor prediction of omnidirectional surroundings in both 2D and 3D with audio observations. Specifically, for audio-based depth estimation, semantic segmentation, and challenging 3D scene reconstruction, the proposed distillation framework consistently achieves state-of-the-art performance across various metrics and backbone architectures.
</details>
<details>
<summary>摘要</summary>
声音可以传递重要的信息来帮助我们日常准备空间理解。为了让深度网络具备这种能力，我们在视Audio知识传递中处理紧凑的室内预测问题。在这项工作中，我们提出了一种名为匹配（SAM）知识传递框架，该框架在视Audio知识传递中找到本地匹配点，以解决多层学习模型中的不一致。SAM将音频特征与视觉一致的学习可变的空间嵌入结合起来，以解决多层学习模型中的不一致。我们的方法不依赖特定的输入表示，因此可以在输入形状或维度上进行灵活的调整无论影响性。我们新编制了一个名为环境预测（DAPS）的权威数据集，我们是第一个在2D和3D室内环境预测中使用音频观察结果进行密集预测。特别是，我们的框架在音频基于深度估计、语义分割和复杂3D场景重建等方面均实现了状态的最佳性。
</details></li>
</ul>
<hr>
<h2 id="Visual-Question-Answering-in-the-Medical-Domain"><a href="#Visual-Question-Answering-in-the-Medical-Domain" class="headerlink" title="Visual Question Answering in the Medical Domain"></a>Visual Question Answering in the Medical Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11080">http://arxiv.org/abs/2309.11080</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abachaa/VQA-Med-2019">https://github.com/abachaa/VQA-Med-2019</a></li>
<li>paper_authors: Louisa Canepa, Sonit Singh, Arcot Sowmya</li>
<li>for: 这篇研究旨在提出一个适应医疗图像问题的机器学习模型，以解答基于 givent medical images 的自然语言问题。</li>
<li>methods: 本研究使用了专门的领域预训练策略，包括一种新的对称学习预训方法，以减少小规模 dataset 的问题。</li>
<li>results: 我们的提案模型在 VQA-Med 2019 测试集上获得了60%的准确率，与其他州OF-the-art Med-VQA 模型相当。<details>
<summary>Abstract</summary>
Medical visual question answering (Med-VQA) is a machine learning task that aims to create a system that can answer natural language questions based on given medical images. Although there has been rapid progress on the general VQA task, less progress has been made on Med-VQA due to the lack of large-scale annotated datasets. In this paper, we present domain-specific pre-training strategies, including a novel contrastive learning pretraining method, to mitigate the problem of small datasets for the Med-VQA task. We find that the model benefits from components that use fewer parameters. We also evaluate and discuss the model's visual reasoning using evidence verification techniques. Our proposed model obtained an accuracy of 60% on the VQA-Med 2019 test set, giving comparable results to other state-of-the-art Med-VQA models.
</details>
<details>
<summary>摘要</summary>
医学视觉问答（Med-VQA）是一种机器学习任务，旨在创建一个能够根据给定医学图像回答自然语言问题的系统。虽然总体VQA任务上有了快速的进步，但Med-VQA任务上的进步较少，这主要归结于医学图像数据的小规模。在这篇论文中，我们提出了域特定预训练策略，包括一种新的对比学习预训练方法，以解决Med-VQA任务的数据小规模问题。我们发现模型受到参数数量的限制具有好处。我们还评估和讨论模型的视觉逻辑使用证明技术。我们的提议的模型在VQA-Med 2019测试集上取得了60%的准确率，与其他状态之前的Med-VQA模型相当。
</details></li>
</ul>
<hr>
<h2 id="Score-Mismatching-for-Generative-Modeling"><a href="#Score-Mismatching-for-Generative-Modeling" class="headerlink" title="Score Mismatching for Generative Modeling"></a>Score Mismatching for Generative Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11043">http://arxiv.org/abs/2309.11043</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/senmaoy/Score-Mismatching">https://github.com/senmaoy/Score-Mismatching</a></li>
<li>paper_authors: Senmao Ye, Fei Liu</li>
<li>for: 这篇论文的目的是提出一种新的分数基本模型，用于生成图像。</li>
<li>methods: 这篇论文使用了一步采样方法，取代了之前的迭代采样方法。在这个模型中，一个独立的生成器将所有的时间步采样压缩到了梯度反propagation来自分数网络。</li>
<li>results: 这篇论文的模型在CIFAR-10数据集上比Consistency Model和Denoising Score Matching更高效，这表明了这种框架的潜在力量。此外，模型还在MINIST和LSUN数据集上进行了更多的示例。代码可以在GitHub上下载。<details>
<summary>Abstract</summary>
We propose a new score-based model with one-step sampling. Previously, score-based models were burdened with heavy computations due to iterative sampling. For substituting the iterative process, we train a standalone generator to compress all the time steps with the gradient backpropagated from the score network. In order to produce meaningful gradients for the generator, the score network is trained to simultaneously match the real data distribution and mismatch the fake data distribution. This model has the following advantages: 1) For sampling, it generates a fake image with only one step forward. 2) For training, it only needs 10 diffusion steps.3) Compared with consistency model, it is free of the ill-posed problem caused by consistency loss. On the popular CIFAR-10 dataset, our model outperforms Consistency Model and Denoising Score Matching, which demonstrates the potential of the framework. We further provide more examples on the MINIST and LSUN datasets. The code is available on GitHub.
</details>
<details>
<summary>摘要</summary>
我们提出了一个新的分数基于模型，使用单步采样。在过去，分数基于模型受到迭代采样的计算压力。为了替代迭代过程，我们训练了一个独立的生成器，使其在分数网络的梯度归整下压缩所有时间步。为了生成有意义的梯度，分数网络需要同时匹配真实数据分布和假数据分布。这个模型具有以下优点：1）采样时只需一步前进。2）训练时只需10步扩散。3）与一致性模型相比，它免受一致性损失导致的糟糕问题。在流行的 CIFAR-10 数据集上，我们的模型超越了一致性模型和杂噪分匹配模型，这表明了该框架的潜力。我们还提供了更多的例子在 MINIST 和 LSUN 数据集上。代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="CaveSeg-Deep-Semantic-Segmentation-and-Scene-Parsing-for-Autonomous-Underwater-Cave-Exploration"><a href="#CaveSeg-Deep-Semantic-Segmentation-and-Scene-Parsing-for-Autonomous-Underwater-Cave-Exploration" class="headerlink" title="CaveSeg: Deep Semantic Segmentation and Scene Parsing for Autonomous Underwater Cave Exploration"></a>CaveSeg: Deep Semantic Segmentation and Scene Parsing for Autonomous Underwater Cave Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11038">http://arxiv.org/abs/2309.11038</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Abdullah, T. Barua, R. Tibbetts, Z. Chen, M. J. Islam, I. Rekleitis</li>
<li>for: 本研究开发了一个用于潜水洞穴探索和地图创建的自主潜水器视觉学习管线，协助AUV在潜水洞穴环境中快速完成 semantic segmentation 和 scene parsing。</li>
<li>methods: 本研究使用了一个具有全面性的数据集，以便对潜水洞穴场景进行semantic segmentation，并开发了一个基于 transformer 的视觉模型，具有快速执行和低 computational complexity。</li>
<li>results: 本研究通过在美国、墨西哥和西班牙的洞穴系统进行了 comprehensive benchmark 分析，证明了可以透过 CaveSeg 发展出高性能的深度视觉模型，并且在实际应用中实现了快速的 semantic scene parsing。<details>
<summary>Abstract</summary>
In this paper, we present CaveSeg - the first visual learning pipeline for semantic segmentation and scene parsing for AUV navigation inside underwater caves. We address the problem of scarce annotated training data by preparing a comprehensive dataset for semantic segmentation of underwater cave scenes. It contains pixel annotations for important navigation markers (e.g. caveline, arrows), obstacles (e.g. ground plain and overhead layers), scuba divers, and open areas for servoing. Through comprehensive benchmark analyses on cave systems in USA, Mexico, and Spain locations, we demonstrate that robust deep visual models can be developed based on CaveSeg for fast semantic scene parsing of underwater cave environments. In particular, we formulate a novel transformer-based model that is computationally light and offers near real-time execution in addition to achieving state-of-the-art performance. Finally, we explore the design choices and implications of semantic segmentation for visual servoing by AUVs inside underwater caves. The proposed model and benchmark dataset open up promising opportunities for future research in autonomous underwater cave exploration and mapping.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了CaveSeg，首个用于semantic segmentation和场景分解的AUV内水洞环境视觉学习管道。我们解决了罕见的注释培训数据的问题，prepare了包含重要导航标记（例如， cave line、箭头）、障碍物（例如，地面层和天花板层）、潜水员和开放区域的像素注释。通过对美国、墨西哥和西班牙等地水洞系统进行了全面的比较分析，我们证明了可以基于CaveSeg构建Robust的深度视觉模型，用于快速semantic scene parsing水洞环境。尤其是，我们提出了一种新的 transformer-based 模型，具有较少计算量和实时执行能力，同时也达到了状态实验室的性能。最后，我们探讨了semantic segmentation对AUV内水洞环境的视ervoking的设计选择和意义。提出的模型和数据集开 up了未来水洞exploration和 mapping 的可能性。
</details></li>
</ul>
<hr>
<h2 id="Light-Field-Diffusion-for-Single-View-Novel-View-Synthesis"><a href="#Light-Field-Diffusion-for-Single-View-Novel-View-Synthesis" class="headerlink" title="Light Field Diffusion for Single-View Novel View Synthesis"></a>Light Field Diffusion for Single-View Novel View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11525">http://arxiv.org/abs/2309.11525</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifeng Xiong, Haoyu Ma, Shanlin Sun, Kun Han, Xiaohui Xie</li>
<li>for: 单视图新视角合成，生成基于单个参考图像的图像，是计算机视觉领域中一项重要但具有挑战性的任务。</li>
<li>methods: 我们使用Light Field Diffusion（LFD）模型，这是一种基于扩散的增强模型，在扩散过程中将摄像头视角信息转换为光场编码，并与参考图像相结合。这种设计引入了本地像素级别的约束，从而促进了多视图一致性。</li>
<li>results: 我们的LFD可以高效地生成高质量图像，并在复杂的区域中保持更好的3D一致性。我们的方法可以与NeRF-based模型相比，并且我们的模型规模只是NeRF-based模型的一半。<details>
<summary>Abstract</summary>
Single-view novel view synthesis, the task of generating images from new viewpoints based on a single reference image, is an important but challenging task in computer vision. Recently, Denoising Diffusion Probabilistic Model (DDPM) has become popular in this area due to its strong ability to generate high-fidelity images. However, current diffusion-based methods directly rely on camera pose matrices as viewing conditions, globally and implicitly introducing 3D constraints. These methods may suffer from inconsistency among generated images from different perspectives, especially in regions with intricate textures and structures. In this work, we present Light Field Diffusion (LFD), a conditional diffusion-based model for single-view novel view synthesis. Unlike previous methods that employ camera pose matrices, LFD transforms the camera view information into light field encoding and combines it with the reference image. This design introduces local pixel-wise constraints within the diffusion models, thereby encouraging better multi-view consistency. Experiments on several datasets show that our LFD can efficiently generate high-fidelity images and maintain better 3D consistency even in intricate regions. Our method can generate images with higher quality than NeRF-based models, and we obtain sample quality similar to other diffusion-based models but with only one-third of the model size.
</details>
<details>
<summary>摘要</summary>
单视图novel视觉合成问题，即基于单个参考图像生成新视点图像，是计算机视觉中重要但困难的任务。最近，Denosing Diffusion Probabilistic Model (DDPM) 在这个领域中得到了广泛应用，因为它可以生成高品质图像。然而，当前的扩散基本方法直接使用摄像机pose矩阵作为视图条件，全局和强制性地引入3D约束。这些方法可能在不同视点图像中生成的图像之间存在不一致，特别是在具有复杂 текстура和结构的区域中。在这种情况下，我们提出了Light Field Diffusion (LFD)，一种基于条件扩散的单视图novel视觉合成模型。与之前的方法不同，LFD将摄像机视角信息转换为光场编码，并将其与参考图像相结合。这种设计引入了本地像素级别的扩散模型中的约束，从而鼓励更好的多视图一致性。我们的LFD可以高效地生成高品质图像，并在复杂区域中保持更好的3D一致性。我们的方法可以生成图像质量高于NeRF-based模型，并且在模型大小方面与其他扩散基本方法相当，但只需一半的模型大小。
</details></li>
</ul>
<hr>
<h2 id="Conformalized-Multimodal-Uncertainty-Regression-and-Reasoning"><a href="#Conformalized-Multimodal-Uncertainty-Regression-and-Reasoning" class="headerlink" title="Conformalized Multimodal Uncertainty Regression and Reasoning"></a>Conformalized Multimodal Uncertainty Regression and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11018">http://arxiv.org/abs/2309.11018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Domenico Parente, Nastaran Darabi, Alex C. Stutts, Theja Tulabandhula, Amit Ranjan Trivedi</li>
<li>for: 这篇论文旨在探讨一种轻量级的不确定度估计器，可以预测多modal（分离）的不确定度 bound，通过将конформаル预测与深度学习回推器结合起来。</li>
<li>methods: 这篇论文使用了将конформаル预测与深度学习回推器结合起来，以预测多modal（分离）的不确定度 bound。</li>
<li>results:  simulations 结果显示，在我们的框架中，不确定度估计器适应了具有严重噪音、有限训练数据和有限预测模型大小的问题。此外，我们开发了一个理解框架，利用这些可靠的不确定度估计器，并与光流基于的理解来提高预测精度。因此，通过适当地考虑数据驱动学习中的预测不确定性，并透过规律基于的理解来关闭预测模型的估计loop，我们的方法在所有这些问题上显著超越了传统的深度学习方法，实际上降低预测错误的比例为2-3倍。<details>
<summary>Abstract</summary>
This paper introduces a lightweight uncertainty estimator capable of predicting multimodal (disjoint) uncertainty bounds by integrating conformal prediction with a deep-learning regressor. We specifically discuss its application for visual odometry (VO), where environmental features such as flying domain symmetries and sensor measurements under ambiguities and occlusion can result in multimodal uncertainties. Our simulation results show that uncertainty estimates in our framework adapt sample-wise against challenging operating conditions such as pronounced noise, limited training data, and limited parametric size of the prediction model. We also develop a reasoning framework that leverages these robust uncertainty estimates and incorporates optical flow-based reasoning to improve prediction prediction accuracy. Thus, by appropriately accounting for predictive uncertainties of data-driven learning and closing their estimation loop via rule-based reasoning, our methodology consistently surpasses conventional deep learning approaches on all these challenging scenarios--pronounced noise, limited training data, and limited model size-reducing the prediction error by 2-3x.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文介绍了一种轻量级的不确定性估计器，可以通过将 конформальный预测与深度学习回归器结合来预测多Modal不确定性 bound。我们特别探讨了它在视觉运动（VO）中的应用， где environmental features和感知测量在异常和遮挡下可能导致多Modal不确定性。我们的 simulations 表明，在我们的框架中的不确定性估计适应样本所对抗复杂的运行条件，如强度的噪音、有限的训练数据和有限的预测模型大小。我们还开发了一种使用这些稳健的不确定性估计和基于推Flow的reasoning Framework来提高预测准确性。因此，通过合理地考虑数据驱动学习的预测不确定性和关闭其估计循环 via 规则基于的reasoning，我们的方法在所有这些复杂的 scenarios中一直赶在深度学习方法之前，减少预测错误 by 2-3倍。
</details></li>
</ul>
<hr>
<h2 id="Controllable-Dynamic-Appearance-for-Neural-3D-Portraits"><a href="#Controllable-Dynamic-Appearance-for-Neural-3D-Portraits" class="headerlink" title="Controllable Dynamic Appearance for Neural 3D Portraits"></a>Controllable Dynamic Appearance for Neural 3D Portraits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11009">http://arxiv.org/abs/2309.11009</a></li>
<li>repo_url: None</li>
<li>paper_authors: ShahRukh Athar, Zhixin Shu, Zexiang Xu, Fujun Luan, Sai Bi, Kalyan Sunkavalli, Dimitris Samaras</li>
<li>for: 创建完全可控的3D人物头像，在真实捕捉环境中。</li>
<li>methods: 使用NeRF技术，通过动态出现模型来 aproximate照明依赖的效果，并通过面法导向来准确预测表면法向量。</li>
<li>results: 使用短视频 captured with smartphone，在不同的头部姿势和表情控制下实现了高质量的自由视 sintesis效果，并且能够模拟真实的照明效果。<details>
<summary>Abstract</summary>
Recent advances in Neural Radiance Fields (NeRFs) have made it possible to reconstruct and reanimate dynamic portrait scenes with control over head-pose, facial expressions and viewing direction. However, training such models assumes photometric consistency over the deformed region e.g. the face must be evenly lit as it deforms with changing head-pose and facial expression. Such photometric consistency across frames of a video is hard to maintain, even in studio environments, thus making the created reanimatable neural portraits prone to artifacts during reanimation. In this work, we propose CoDyNeRF, a system that enables the creation of fully controllable 3D portraits in real-world capture conditions. CoDyNeRF learns to approximate illumination dependent effects via a dynamic appearance model in the canonical space that is conditioned on predicted surface normals and the facial expressions and head-pose deformations. The surface normals prediction is guided using 3DMM normals that act as a coarse prior for the normals of the human head, where direct prediction of normals is hard due to rigid and non-rigid deformations induced by head-pose and facial expression changes. Using only a smartphone-captured short video of a subject for training, we demonstrate the effectiveness of our method on free view synthesis of a portrait scene with explicit head pose and expression controls, and realistic lighting effects. The project page can be found here: http://shahrukhathar.github.io/2023/08/22/CoDyNeRF.html
</details>
<details>
<summary>摘要</summary>
最近的神经辐射场（NeRF）技术突破，使得可以重建和复活动态肖像场景，包括头部姿态和表情的控制。然而，训练这些模型时需要光ometric consistency over the deformed region，例如脸部必须在不同的头部姿态和表情变化中保持光度的均匀性。这种光度一致性在视频帧中很难保持，即使在studio environment中，因此创建的可控3D肖像容易出现artifacts during reanimation。在这项工作中，我们提出了CoDyNeRF系统，可以在真实的捕捉条件下创建完全可控的3D肖像。CoDyNeRF通过learns to approximate illumination dependent effects via a dynamic appearance model in the canonical space that is conditioned on predicted surface normals and the facial expressions and head-pose deformations来解决这个问题。 surface normals prediction是通过3DMM normals作为一个粗略的估计器来引导的，因为direct prediction of normals是由于头部姿态和表情变化induced的固定和非固定扭曲而困难。通过只使用短视频 capture的智能手机训练，我们示示了我们的方法在free view synthesis of a portrait scene with explicit head pose and expression controls, and realistic lighting effects。相关项目页面可以在以下链接中找到：http://shahrukhathar.github.io/2023/08/22/CoDyNeRF.html
</details></li>
</ul>
<hr>
<h2 id="STARNet-Sensor-Trustworthiness-and-Anomaly-Recognition-via-Approximated-Likelihood-Regret-for-Robust-Edge-Autonomy"><a href="#STARNet-Sensor-Trustworthiness-and-Anomaly-Recognition-via-Approximated-Likelihood-Regret-for-Robust-Edge-Autonomy" class="headerlink" title="STARNet: Sensor Trustworthiness and Anomaly Recognition via Approximated Likelihood Regret for Robust Edge Autonomy"></a>STARNet: Sensor Trustworthiness and Anomaly Recognition via Approximated Likelihood Regret for Robust Edge Autonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11006">http://arxiv.org/abs/2309.11006</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sinatayebati/STARNet">https://github.com/sinatayebati/STARNet</a></li>
<li>paper_authors: Nastaran Darabi, Sina Tayebati, Sureshkumar S., Sathya Ravi, Theja Tulabandhula, Amit R. Trivedi</li>
<li>for: This paper is written to address the reliability concerns of complex sensors such as LiDAR and camera sensors in autonomous robotics, and to improve the prediction accuracy of deep learning models by detecting untrustworthy sensor streams.</li>
<li>methods: STARNet, a Sensor Trustworthiness and Anomaly Recognition Network, is used to detect untrustworthy sensor streams. STARNet employs the concept of approximated likelihood regret, a gradient-free framework tailored for low-complexity hardware.</li>
<li>results: STARNet enhances prediction accuracy by approximately 10% by filtering out untrustworthy sensor streams in unimodal and multimodal settings, especially in addressing internal sensor failures such as cross-sensor interference and crosstalk.<details>
<summary>Abstract</summary>
Complex sensors such as LiDAR, RADAR, and event cameras have proliferated in autonomous robotics to enhance perception and understanding of the environment. Meanwhile, these sensors are also vulnerable to diverse failure mechanisms that can intricately interact with their operation environment. In parallel, the limited availability of training data on complex sensors also affects the reliability of their deep learning-based prediction flow, where their prediction models can fail to generalize to environments not adequately captured in the training set. To address these reliability concerns, this paper introduces STARNet, a Sensor Trustworthiness and Anomaly Recognition Network designed to detect untrustworthy sensor streams that may arise from sensor malfunctions and/or challenging environments. We specifically benchmark STARNet on LiDAR and camera data. STARNet employs the concept of approximated likelihood regret, a gradient-free framework tailored for low-complexity hardware, especially those with only fixed-point precision capabilities. Through extensive simulations, we demonstrate the efficacy of STARNet in detecting untrustworthy sensor streams in unimodal and multimodal settings. In particular, the network shows superior performance in addressing internal sensor failures, such as cross-sensor interference and crosstalk. In diverse test scenarios involving adverse weather and sensor malfunctions, we show that STARNet enhances prediction accuracy by approximately 10% by filtering out untrustworthy sensor streams. STARNet is publicly available at \url{https://github.com/sinatayebati/STARNet}.
</details>
<details>
<summary>摘要</summary>
复杂的感知器如LiDAR、RADAR和事件摄像头在自主 робо扮中广泛应用，以提高环境的感知和理解。然而，这些感知器也面临着多种失效机制，这些失效机制可能与其运行环境互相复杂交互。同时，对于复杂的感知器，有限的训练数据也会影响其深度学习基于预测流的可靠性，其预测模型可能无法泛化到不充分 captured 的环境中。为解决这些可靠性问题，本文介绍了 STARNet，一种感知器可靠性和异常检测网络，可以检测不可靠的感知流，这些感知流可能由感知器故障和/或挑战环境引起。我们 especifically 对 LiDAR 和摄像头数据进行了 benchmark。STARNet 采用了approximated likelihood regret，一种适用于低复杂度硬件的梯度自由框架。通过广泛的 simulations，我们展示了 STARNet 在单模态和多模态设置下的效果。尤其是，网络在内部感知器故障方面表现出色，如交叉感知和电磁干扰。在多种测试enario中，包括不良天气和感知器故障，我们表明 STARNet 可以提高预测精度约 10%，通过筛选不可靠的感知流。STARNet 公共可用于 \url{https://github.com/sinatayebati/STARNet}.
</details></li>
</ul>
<hr>
<h2 id="PPD-A-New-Valet-Parking-Pedestrian-Fisheye-Dataset-for-Autonomous-Driving"><a href="#PPD-A-New-Valet-Parking-Pedestrian-Fisheye-Dataset-for-Autonomous-Driving" class="headerlink" title="PPD: A New Valet Parking Pedestrian Fisheye Dataset for Autonomous Driving"></a>PPD: A New Valet Parking Pedestrian Fisheye Dataset for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11002">http://arxiv.org/abs/2309.11002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zizhang Wu, Xinyuan Chen, Fan Song, Yuanzhu Gan, Tianhao Xu, Jian Pu, Rui Tang</li>
<li>for: 本研究旨在提供一个大规模的 fisheye 数据集，以支持对实际世界中的步行人进行研究，特别是在干扰和多种姿势下。</li>
<li>methods: 本研究使用 fisheye 摄像头捕捉了多种类型的步行人，并提出了两种数据增强技术来提高基eline。</li>
<li>results: 实验证明了我们的新的数据增强方法的效果，并证明了数据集的非常普遍化。<details>
<summary>Abstract</summary>
Pedestrian detection under valet parking scenarios is fundamental for autonomous driving. However, the presence of pedestrians can be manifested in a variety of ways and postures under imperfect ambient conditions, which can adversely affect detection performance. Furthermore, models trained on publicdatasets that include pedestrians generally provide suboptimal outcomes for these valet parking scenarios. In this paper, wepresent the Parking Pedestrian Dataset (PPD), a large-scale fisheye dataset to support research dealing with real-world pedestrians, especially with occlusions and diverse postures. PPD consists of several distinctive types of pedestrians captured with fisheye cameras. Additionally, we present a pedestrian detection baseline on PPD dataset, and introduce two data augmentation techniques to improve the baseline by enhancing the diversity ofthe original dataset. Extensive experiments validate the effectiveness of our novel data augmentation approaches over baselinesand the dataset's exceptional generalizability.
</details>
<details>
<summary>摘要</summary>
自动驾驶中的人行检测在停车场景下是基本的。然而，人行可以在不同的环境条件下表现出多种形式和姿势，这会 adversely affect 检测性能。尤其是模型通常在公共数据集上训练，这些数据集中的人行通常不适合停车场景。在这篇论文中，我们提出了停车场景人行数据集（PPD），一个大规模的鱼眼数据集，以支持实际世界中的人行检测，特别是干扰和多种姿势。PPD 包括多种特征的人行，通过鱼眼摄像头捕捉。此外，我们还提出了人行检测基线在 PPD 数据集上，并介绍了两种数据增强技术来提高基线，以提高数据集的多样性。广泛的实验证明了我们的新的数据增强方法的有效性，以及数据集的出色的普适性。
</details></li>
</ul>
<hr>
<h2 id="COSE-A-Consistency-Sensitivity-Metric-for-Saliency-on-Image-Classification"><a href="#COSE-A-Consistency-Sensitivity-Metric-for-Saliency-on-Image-Classification" class="headerlink" title="COSE: A Consistency-Sensitivity Metric for Saliency on Image Classification"></a>COSE: A Consistency-Sensitivity Metric for Saliency on Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.10989">http://arxiv.org/abs/2309.10989</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cvl-umass/COSE">https://github.com/cvl-umass/COSE</a></li>
<li>paper_authors: Rangel Daroya, Aaron Sun, Subhransu Maji</li>
<li>for: 本研究旨在提供一套基于视觉优先的表现评估方法，用于评估图像分类任务中模型的表现。</li>
<li>methods: 本研究使用了多种视觉焦点映射方法，包括GradCAM、Guided Backpropagation（GBP）和DeepLIFT（DLIFT）等。</li>
<li>results: 研究发现，虽然多种焦点映射方法都能够解释模型决策，但是transformer模型比 convolutional模型更难被这些方法解释。此外，GradCAM表现最佳，但是它在细节化数据集上缺乏多样性。通过对准则和敏感度进行平衡，可以获得一个准确地表示模型行为的焦点映射。<details>
<summary>Abstract</summary>
We present a set of metrics that utilize vision priors to effectively assess the performance of saliency methods on image classification tasks. To understand behavior in deep learning models, many methods provide visual saliency maps emphasizing image regions that most contribute to a model prediction. However, there is limited work on analyzing the reliability of saliency methods in explaining model decisions. We propose the metric COnsistency-SEnsitivity (COSE) that quantifies the equivariant and invariant properties of visual model explanations using simple data augmentations. Through our metrics, we show that although saliency methods are thought to be architecture-independent, most methods could better explain transformer-based models over convolutional-based models. In addition, GradCAM was found to outperform other methods in terms of COSE but was shown to have limitations such as lack of variability for fine-grained datasets. The duality between consistency and sensitivity allow the analysis of saliency methods from different angles. Ultimately, we find that it is important to balance these two metrics for a saliency map to faithfully show model behavior.
</details>
<details>
<summary>摘要</summary>
我们提出了一组维度度量，使用视觉优先来评估针对图像分类任务的精度方法的表现。在深度学习模型中，许多方法提供视觉精度地图，强调图像区域对模型预测的贡献。然而，对于分析深度学习模型决策的可靠性的工作几乎缺乏。我们提出了COnsistency-SEnsitivity（COSE）度量，用于衡量视觉模型解释的等变和不变性。通过我们的度量，我们发现，虽然许多方法被认为是无关于模型结构的，但大多数方法在基于转换器模型时表现较好。此外，GradCAM在COSE方面表现出色，但它在细腻数据上缺乏变化。这种对照性Allow我们从不同角度分析精度方法。最终，我们发现，为了让精度地图准确反映模型行为，需要平衡这两个度量。
</details></li>
</ul>
<hr>
<h2 id="RMT-Retentive-Networks-Meet-Vision-Transformers"><a href="#RMT-Retentive-Networks-Meet-Vision-Transformers" class="headerlink" title="RMT: Retentive Networks Meet Vision Transformers"></a>RMT: Retentive Networks Meet Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11523">http://arxiv.org/abs/2309.11523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qihang Fan, Huaibo Huang, Mingrui Chen, Hongmin Liu, Ran He</li>
<li>for: 本研究的目的是探讨将Retrieval Network（RetNet）的思想应用于计算机视觉领域，以提高计算机视觉任务的性能。</li>
<li>methods: 本研究提出了一种组合RetNet和Transformer的模型，称为RMT。该模型引入了明确的衰减元素，以帮助计算机视觉模型更好地控制各个Token的范围。此外，为了降低全模型的计算成本，我们将模型分解成两个坐标轴上的分割。</li>
<li>results: 我们的RMT在多种计算机视觉任务中表现出色，例如在ImageNet-1k上达到84.1%的Top1-acc，使用了仅4.5G FLOPs。此外，RMT在下游任务中，如物体检测、实例分割和semantic segmentation中也表现出优异。<details>
<summary>Abstract</summary>
Transformer first appears in the field of natural language processing and is later migrated to the computer vision domain, where it demonstrates excellent performance in vision tasks. However, recently, Retentive Network (RetNet) has emerged as an architecture with the potential to replace Transformer, attracting widespread attention in the NLP community. Therefore, we raise the question of whether transferring RetNet's idea to vision can also bring outstanding performance to vision tasks. To address this, we combine RetNet and Transformer to propose RMT. Inspired by RetNet, RMT introduces explicit decay into the vision backbone, bringing prior knowledge related to spatial distances to the vision model. This distance-related spatial prior allows for explicit control of the range of tokens that each token can attend to. Additionally, to reduce the computational cost of global modeling, we decompose this modeling process along the two coordinate axes of the image. Abundant experiments have demonstrated that our RMT exhibits exceptional performance across various computer vision tasks. For example, RMT achieves 84.1% Top1-acc on ImageNet-1k using merely 4.5G FLOPs. To the best of our knowledge, among all models, RMT achieves the highest Top1-acc when models are of similar size and trained with the same strategy. Moreover, RMT significantly outperforms existing vision backbones in downstream tasks such as object detection, instance segmentation, and semantic segmentation. Our work is still in progress.
</details>
<details>
<summary>摘要</summary>
transformer 最初出现在自然语言处理领域，后来迁移到计算机视觉领域，在视觉任务中表现出色。然而，最近，Retentive Network（RetNet） Architecture 出现，吸引了自然语言社区的广泛关注。因此，我们提出了将 RetNet 的想法应用于视觉领域，以提高视觉任务的表现。为此，我们将 RetNet 和 transformer 结合，提出了 RMT。 RetNet 中引入了显式衰减，使视觉模型受到相对距离的知识。这种距离相关的空间先验使每个token可以显式控制所能attend的token范围。此外，为降低全局模型的计算成本，我们将模型化过程分解成两个坐标轴的图像。我们的 RMT 在多个计算机视觉任务中表现出色，例如在 ImageNet-1k 中 achiev 84.1% Top1-acc 使用仅 4.5G FLOPs。我们知道，在同样大小的模型和同样策略下，RMT 在所有模型中具有最高的 Top1-acc。此外，RMT 在下游任务中，如物体检测、实例分割和 semantics 分割，也表现出了显著的优异。我们的工作仍在进行中。
</details></li>
</ul>
<hr>
<h2 id="SEMPART-Self-supervised-Multi-resolution-Partitioning-of-Image-Semantics"><a href="#SEMPART-Self-supervised-Multi-resolution-Partitioning-of-Image-Semantics" class="headerlink" title="SEMPART: Self-supervised Multi-resolution Partitioning of Image Semantics"></a>SEMPART: Self-supervised Multi-resolution Partitioning of Image Semantics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.10972">http://arxiv.org/abs/2309.10972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sriram Ravindran, Debraj Basu</li>
<li>for: 本文为了解决基于图像数据的稀缺时，准确地定义图像中重要的区域而作出了贡献。</li>
<li>methods: 本文使用了基于DINO的自动编写方法，并利用图像 semantic graph中的含义来找到前景物体。</li>
<li>results: 本文提出了一种名为SEMPART的方法，可以同时确定图像的粗细分割和细分割，并且可以快速生成高质量的mask。<details>
<summary>Abstract</summary>
Accurately determining salient regions of an image is challenging when labeled data is scarce. DINO-based self-supervised approaches have recently leveraged meaningful image semantics captured by patch-wise features for locating foreground objects. Recent methods have also incorporated intuitive priors and demonstrated value in unsupervised methods for object partitioning. In this paper, we propose SEMPART, which jointly infers coarse and fine bi-partitions over an image's DINO-based semantic graph. Furthermore, SEMPART preserves fine boundary details using graph-driven regularization and successfully distills the coarse mask semantics into the fine mask. Our salient object detection and single object localization findings suggest that SEMPART produces high-quality masks rapidly without additional post-processing and benefits from co-optimizing the coarse and fine branches.
</details>
<details>
<summary>摘要</summary>
精确地定义图像中重要区域是一项具有挑战性的任务，尤其当标注数据稀缺时。基于DINO的自动学习方法最近在捕捉图像中具有意义的Semantic Feature中找到了前景对象。现有方法还将直觉约束 incorporated 到了无监督方法中，并在对象分割方面表现出了价值。在这篇论文中，我们提议了 SEMPART，它同时分解图像的DINO基于semantic graph的粗细分割结果。此外，SEMPART还使用图像驱动的正则化来保持细节，并成功地储存粗细分割结果。我们的精确对象检测和单个对象Localization结果表明，SEMPART可以快速生成高质量的Mask，无需额外处理，并且受益于粗细分支的共同优化。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/20/cs.CV_2023_09_20/" data-id="clmvt7t9s00dc26rd4ylh18be" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/54/">54</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">77</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">77</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">21</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">150</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
