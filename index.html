
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/cs.SD_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T15:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/cs.SD_2023_11_21/">cs.SD - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Adapting-pretrained-speech-model-for-Mandarin-lyrics-transcription-and-alignment"><a href="#Adapting-pretrained-speech-model-for-Mandarin-lyrics-transcription-and-alignment" class="headerlink" title="Adapting pretrained speech model for Mandarin lyrics transcription and alignment"></a>Adapting pretrained speech model for Mandarin lyrics transcription and alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12488">http://arxiv.org/abs/2311.12488</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/navi0105/LyricAlignment">https://github.com/navi0105/LyricAlignment</a></li>
<li>paper_authors: Jun-You Wang, Chon-In Leong, Yu-Chen Lin, Li Su, Jyh-Shing Roger Jang</li>
<li>for: 本研究主要针对polyphonic Mandarin pop music的歌词识别和歌词对齐，即使在低资源环境下进行。</li>
<li>methods: 我们采用了预训练的Whisper模型，并在一个单声道普通话 Dataset上进行了微调。通过数据扩展和源分离模型，我们实现了歌词识别和歌词对齐的目标。</li>
<li>results: 结果表明，我们的方法在一个polyphonic Mandarin Dataset上实现了歌词识别的Character Error Rate（CER）低于18%，并且歌词对齐的Mean Absolute Error（MAE）为0.071秒。这些结果表明了预训练的语音模型在低资源情况下的应用潜力。<details>
<summary>Abstract</summary>
The tasks of automatic lyrics transcription and lyrics alignment have witnessed significant performance improvements in the past few years. However, most of the previous works only focus on English in which large-scale datasets are available. In this paper, we address lyrics transcription and alignment of polyphonic Mandarin pop music in a low-resource setting. To deal with the data scarcity issue, we adapt pretrained Whisper model and fine-tune it on a monophonic Mandarin singing dataset. With the use of data augmentation and source separation model, results show that the proposed method achieves a character error rate of less than 18% on a Mandarin polyphonic dataset for lyrics transcription, and a mean absolute error of 0.071 seconds for lyrics alignment. Our results demonstrate the potential of adapting a pretrained speech model for lyrics transcription and alignment in low-resource scenarios.
</details>
<details>
<summary>摘要</summary>
在过去几年中，自动歌词识别和歌词对齐的任务有所进步。然而，大多数前一些工作只是关注英语，因为英语有庞大的数据库。在这篇论文中，我们讨论了使用低资源设置中进行政府歌词识别和对齐。为了解决数据稀缺问题，我们采用预训练的Whisper模型，并将其精度地 fine-tune 到了一个单声道普通话歌曲数据集。通过数据扩展和来源分离模型，我们的方法可以在一个普通话Polyphonic Mandarin pop音乐数据集上实现 caracter error rate 低于18%，以及 Mean absolute error 低于0.071秒的歌词对齐结果。我们的结果表明，可以在低资源情况下适应预训练的语音模型进行歌词识别和对齐。
</details></li>
</ul>
<hr>
<h2 id="HPCNeuroNet-Advancing-Neuromorphic-Audio-Signal-Processing-with-Transformer-Enhanced-Spiking-Neural-Networks"><a href="#HPCNeuroNet-Advancing-Neuromorphic-Audio-Signal-Processing-with-Transformer-Enhanced-Spiking-Neural-Networks" class="headerlink" title="HPCNeuroNet: Advancing Neuromorphic Audio Signal Processing with Transformer-Enhanced Spiking Neural Networks"></a>HPCNeuroNet: Advancing Neuromorphic Audio Signal Processing with Transformer-Enhanced Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12449">http://arxiv.org/abs/2311.12449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Murat Isik, Hiruna Vishwamith, Kayode Inadagbo, I. Can Dikmen</li>
<li>for: 这篇研究旨在探讨一种基于神经网络的语音处理方法，整合了神经网络、转换器和高性能计算（HPC）技术，以实现高性能且能效的语音处理系统。</li>
<li>methods: 本研究使用了Intel N-DNS数据集，利用短时间傅立叶变换（STFT）来实现时间频率表示，使用转换器嵌入来生成紧密的 вектор，并使用神经网络的encoding&#x2F;decoding机制来将神经网络讯号转换为发射频率讯号。</li>
<li>results: 研究发现，融合神经网络和转换器的HPCNeuroNet架构可以实现高性能且能效的语音处理，并且可以适应多种语言和背景噪音。另外，通过设计空间探索，研究发现可以透过优化核心能力来提高语音处理效能。<details>
<summary>Abstract</summary>
This paper presents a novel approach to neuromorphic audio processing by integrating the strengths of Spiking Neural Networks (SNNs), Transformers, and high-performance computing (HPC) into the HPCNeuroNet architecture. Utilizing the Intel N-DNS dataset, we demonstrate the system's capability to process diverse human vocal recordings across multiple languages and noise backgrounds. The core of our approach lies in the fusion of the temporal dynamics of SNNs with the attention mechanisms of Transformers, enabling the model to capture intricate audio patterns and relationships. Our architecture, HPCNeuroNet, employs the Short-Time Fourier Transform (STFT) for time-frequency representation, Transformer embeddings for dense vector generation, and SNN encoding/decoding mechanisms for spike train conversions. The system's performance is further enhanced by leveraging the computational capabilities of NVIDIA's GeForce RTX 3060 GPU and Intel's Core i9 12900H CPU. Additionally, we introduce a hardware implementation on the Xilinx VU37P HBM FPGA platform, optimizing for energy efficiency and real-time processing. The proposed accelerator achieves a throughput of 71.11 Giga-Operations Per Second (GOP/s) with a 3.55 W on-chip power consumption at 100 MHz. The comparison results with off-the-shelf devices and recent state-of-the-art implementations illustrate that the proposed accelerator has obvious advantages in terms of energy efficiency and design flexibility. Through design-space exploration, we provide insights into optimizing core capacities for audio tasks. Our findings underscore the transformative potential of integrating SNNs, Transformers, and HPC for neuromorphic audio processing, setting a new benchmark for future research and applications.
</details>
<details>
<summary>摘要</summary>
The HPCNeuroNet architecture employs the Short-Time Fourier Transform (STFT) for time-frequency representation, Transformer embeddings for dense vector generation, and SNN encoding/decoding mechanisms for spike train conversions. The system's performance is further enhanced by leveraging the computational capabilities of NVIDIA's GeForce RTX 3060 GPU and Intel's Core i9 12900H CPU. Additionally, we present a hardware implementation on the Xilinx VU37P HBM FPGA platform, optimized for energy efficiency and real-time processing. The proposed accelerator achieves a throughput of 71.11 Giga-Operations Per Second (GOP/s) with a 3.55 W on-chip power consumption at 100 MHz.Compared to off-the-shelf devices and recent state-of-the-art implementations, the proposed accelerator has obvious advantages in terms of energy efficiency and design flexibility. Through design-space exploration, we provide insights into optimizing core capacities for audio tasks. Our findings demonstrate the transformative potential of integrating SNNs, Transformers, and HPC for neuromorphic audio processing, setting a new benchmark for future research and applications.
</details></li>
</ul>
<hr>
<h2 id="Equipping-Pretrained-Unconditional-Music-Transformers-with-Instrument-and-Genre-Controls"><a href="#Equipping-Pretrained-Unconditional-Music-Transformers-with-Instrument-and-Genre-Controls" class="headerlink" title="Equipping Pretrained Unconditional Music Transformers with Instrument and Genre Controls"></a>Equipping Pretrained Unconditional Music Transformers with Instrument and Genre Controls</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12257">http://arxiv.org/abs/2311.12257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weihan Xu, Julian McAuley, Shlomo Dubnov, Hao-Wen Dong</li>
<li>for: 这个研究旨在探讨“预训练和最终训练”模式在 симвоlic music generation 中的效果，通过利用最大的象征音乐数据集（来自 MuseScore 论坛）进行预训练。</li>
<li>methods: 我们首先预训一个大型无条件 transformer 模型使用 1.5 百万首歌曲，然后提出一个简单的技术来将这个预训模型与乐器和流派控制token一起运行。</li>
<li>results: 我们的提案模型可以成功实现用户指定的乐器和流派的音乐生成，并在主观听觉测试中比预训基eline模型高于各项coherence、和谐、排序和整体质量。<details>
<summary>Abstract</summary>
The ''pretraining-and-finetuning'' paradigm has become a norm for training domain-specific models in natural language processing and computer vision. In this work, we aim to examine this paradigm for symbolic music generation through leveraging the largest ever symbolic music dataset sourced from the MuseScore forum. We first pretrain a large unconditional transformer model using 1.5 million songs. We then propose a simple technique to equip this pretrained unconditional music transformer model with instrument and genre controls by finetuning the model with additional control tokens. Our proposed representation offers improved high-level controllability and expressiveness against two existing representations. The experimental results show that the proposed model can successfully generate music with user-specified instruments and genre. In a subjective listening test, the proposed model outperforms the pretrained baseline model in terms of coherence, harmony, arrangement and overall quality.
</details>
<details>
<summary>摘要</summary>
《预训练和最终调整》模式在自然语言处理和计算机视觉领域中成为了标准训练域特化模型的方法。在这项工作中，我们想要检查这种模式是否适用于符号音乐生成。我们首先使用150万首歌曲进行预训练一个大型无条件变换器模型。然后，我们提议一种简单的技术来使用这个预训练的无条件音乐变换器模型中添加 instrumente和类型控制 tokens。我们提出的表示方式具有提高高级控制性和表达能力，比对两种现有表示方式。实验结果显示，我们的模型可以成功地根据用户指定的 instrumente和类型生成符号音乐。在主观听测中，我们的模型在听测中胜过预训练基线模型，在coherence、和谐、排序和总质量方面表现更好。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/cs.SD_2023_11_21/" data-id="clpxp6c7z012oee88a4k666eg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/eess.AS_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T14:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/eess.AS_2023_11_21/">eess.AS - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Learning-based-Array-Configuration-Independent-Binaural-Audio-Telepresence-with-Scalable-Signal-Enhancement-and-Ambience-Preservation"><a href="#Learning-based-Array-Configuration-Independent-Binaural-Audio-Telepresence-with-Scalable-Signal-Enhancement-and-Ambience-Preservation" class="headerlink" title="Learning-based Array Configuration-Independent Binaural Audio Telepresence with Scalable Signal Enhancement and Ambience Preservation"></a>Learning-based Array Configuration-Independent Binaural Audio Telepresence with Scalable Signal Enhancement and Ambience Preservation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12706">http://arxiv.org/abs/2311.12706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yicheng Hsu, Mingsian R. Bai</li>
<li>For: The paper aims to create an immersive audio experience for users at the near end of an audio telepresence (AT) system, with a focus on signal enhancement and ambience preservation.* Methods: The proposed Binaural AT (BAT) system uses an array-based approach with the DeepFilterNet as the backbone, and includes a tunable weighting between signal enhancement and ambience preservation. The system also uses an array configuration-independent Spatial COherence REpresentation (SCORE) feature for training.* Results: The proposed BAT system achieves superior telepresence performance with a desired balance between signal enhancement and ambience preservation, even when the array configurations are unseen in the training phase. The system is evaluated using magnitude-weighted Interaural Phase Difference error (mw-IPDe), magnitude-weighted Interaural Level Difference error (mw-ILDe), and modified Scale-Invariant Signal-to-Distortion Ratio (mSI-SDR) metrics, as well as subjective listening tests.<details>
<summary>Abstract</summary>
Audio Telepresence (AT) aims to create an immersive experience of the audio scene at the far end for the user(s) at the near end. The application of AT could encompass scenarios with varying degrees of emphasis on signal enhancement and ambience preservation. It is desirable for an AT system to be scalable between these two extremes. To this end, we propose an array-based Binaural AT (BAT) system using the DeepFilterNet as the backbone to convert the array microphone signals into the Head-Related Transfer Function (HRTF)-filtered signals, with a tunable weighting between signal enhancement and ambience preservation. An array configuration-independent Spatial COherence REpresentation (SCORE) feature is proposed for the model training so that the network remains robust to different array geometries and sensor counts. magnitude-weighted Interaural Phase Difference error (mw-IPDe), magnitude-weighted Interaural Level Difference error (mw-ILDe), and modified Scale-Invariant Signal-to-Distortion Ratio (mSI-SDR) are defined as performance metrics for objective evaluation. Subjective listening tests were also performed to validate the proposed BAT system. The results have shown that the proposed BAT system can achieve superior telepresence performance with the desired balance between signal enhancement and ambience preservation, even when the array configurations are unseen in the training phase.
</details>
<details>
<summary>摘要</summary>
Audio Telepresence (AT) 目标是创造远端听音场的充满体验 для用户。应用场景可以具有不同的强调级别，从增强信号到保留环境。欢迎使用 AT 系统可扩展到这两个极端。为此，我们提议使用 DeepFilterNet 作为后准基础，将阵列麦克风信号转化为基于 Head-Related Transfer Function (HRTF) 的 filtered signals，并使用可调整的 Signal 增强和环境保留的权重。我们还提出了不受阵列几何和感知器数量影响的 Spatial COherence REpresentation (SCORE) 特征，以便在不同的阵列配置和感知器数量下，网络仍然具有 robustness。用于对象评估的性能指标包括 magnitude-weighted Interaural Phase Difference error (mw-IPDe), magnitude-weighted Interaural Level Difference error (mw-ILDe), 和 modified Scale-Invariant Signal-to-Distortion Ratio (mSI-SDR)。Subjective listening tests 也进行了进行验证。结果表明，我们的 BAT 系统可以在不同的阵列配置下实现Superior telepresence性能，并且可以在训练阶段未看到阵列配置时保持 Desired 的信号增强和环境保留平衡。
</details></li>
</ul>
<hr>
<h2 id="A-Distributed-Algorithm-for-Personal-Sound-Zones-Systems"><a href="#A-Distributed-Algorithm-for-Personal-Sound-Zones-Systems" class="headerlink" title="A Distributed Algorithm for Personal Sound Zones Systems"></a>A Distributed Algorithm for Personal Sound Zones Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12427">http://arxiv.org/abs/2311.12427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sipei Zhao, Guoqiang Zhang, Eva Cheng, Ian S. Burnett</li>
<li>for: 该论文旨在提出一种高效的分布式个人声音区系统，以便在共享空间中无需穿戴Headset听音乐&#x2F;语音内容。</li>
<li>methods: 该论文提出了一种分布式算法，以便在多个节点之间分担计算负担，从而降低了总计算复杂性，但是会导致一定的性能下降。</li>
<li>results: 通过在真实的房间响应测试中进行 simulations，证明了提出的分布式个人声音区系统的可行性。<details>
<summary>Abstract</summary>
A Personal Sound Zones (PSZ) system aims to generate two or more independent listening zones that allow multiple users to listen to different music/audio content in a shared space without the need for wearing headphones. Most existing studies assume that the acoustic paths between loudspeakers and microphones are measured beforehand in a stationary environment. Recently, adaptive PSZ systems have been explored to adapt the system in a time-varying acoustic environment. However, because a PSZ system usually requires multiple loudspeakers, the multichannel adaptive algorithms impose a high computational load on the processor. To overcome that problem, this paper proposes an efficient distributed algorithm for PSZ systems, which not only spreads the computational burden over multiple nodes but also reduces the overall computational complexity, at the expense of a slight decrease in performance. Simulation results with true room impulse responses measured in a Hemi-Anechoic chamber are performed to verify the proposed distributed PSZ system.
</details>
<details>
<summary>摘要</summary>
personal sound zones (PSZ) 系统的目的是生成两个或更多独立的听众区，以便在共享空间中让多个用户listen to different music/audio content而无需穿戴headphones。现有的大多数研究假设了在静止环境中测量喇叭和 Microphone的Acoustic path。在最近，适应PSZ系统在时间变化的听频环境中进行了探索。然而，由于PSZ系统通常需要多个喇叭， multichannel adaptive algorithms 会对处理器带来高计算负担。为了解决这个问题，本文提出了PSZ系统的高效分布式算法，不仅将计算负担分散到多个节点，还可以降低总计算复杂性，但是会导致一定的性能下降。为验证提议的分布式PSZ系统，在真实的半静音室回声响应中进行了Simulation结果。
</details></li>
</ul>
<hr>
<h2 id="AudioLog-LLMs-Powered-Long-Audio-Logging-with-Acoustic-Scenes-and-Events-Joint-Estimation"><a href="#AudioLog-LLMs-Powered-Long-Audio-Logging-with-Acoustic-Scenes-and-Events-Joint-Estimation" class="headerlink" title="AudioLog: LLMs-Powered Long Audio Logging with Acoustic Scenes and Events Joint Estimation"></a>AudioLog: LLMs-Powered Long Audio Logging with Acoustic Scenes and Events Joint Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12371">http://arxiv.org/abs/2311.12371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jisheng Bai, Han Yin, Mou Wang, Dongyuan Shi, Woon-Seng Gan, Jianfeng Chen</li>
<li>for: 这篇论文是为了提出一种基于大语言模型（LLM）的自动化音频描述系统，以便更好地捕捉长 audio sequence 中的各种听觉场景和事件的完整时间细节。</li>
<li>methods: 该论文提出了一种joint training网络，通过练习一个基于预先训练的层次token-semantic audio Transformer 的大 audio 模型，并通过语言模型（LLM）来编写音频日志，概括音频环境的文字描述。</li>
<li>results: 实验表明，提出的系统在听觉场景分类和声音事件检测方面具有出色的表现，超越了现有的方法。此外，further analyses 还表明，AudioLog 能够有效地概括长 audio sequence。<details>
<summary>Abstract</summary>
Previous studies in automated audio captioning have faced difficulties in accurately capturing the complete temporal details of acoustic scenes and events within long audio sequences. This paper presents AudioLog, a large language models (LLMs)-powered audio logging system with multi-task learning of acoustic tasks. Specifically, we propose a joint training network, achieved by fine-tuning a large audio model based on the pre-trained hierarchical token-semantic audio Transformer. We then leverage LLMs to craft audio logs that summarize textual descriptions of the acoustic environment. Experiments show that the proposed system attains exceptional performance in acoustic scene classification and sound event detection, surpassing existing methods in the field. Further analyses demonstrate AudioLog's power in effectively summarizing long audio sequences.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Rethinking-the-Output-Architecture-for-Sound-Source-Localization"><a href="#Rethinking-the-Output-Architecture-for-Sound-Source-Localization" class="headerlink" title="Rethinking the Output Architecture for Sound Source Localization"></a>Rethinking the Output Architecture for Sound Source Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12305">http://arxiv.org/abs/2311.12305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linfeng Feng, Xiao-Lei Zhang, Xuelong Li</li>
<li>for: 本研究旨在提高音源Localization（SSL）中的Direction of Arrival（DOA）估计精度。</li>
<li>methods: 本文提出了一种基于分类的DOA估计方法，使用了Soft Label Distribution（ULD）、Negative Log Absolute Error（NLAE）loss函数和Mean Squared Error loss函数 ohne Activation（MSE(wo)）。</li>
<li>results: 实验结果表明，提出的方法可以达到领域内最佳性能，并且Weighted Adjacent Decoding（WAD）解码方法可以超越现有解码方法的量化误差限制。<details>
<summary>Abstract</summary>
Sound source localization (SSL) involves estimating the direction of arrival (DOA) of a sound signal. The output space of the DOA estimation is continuous, suggesting that regression may be the most appropriate formulation for DOA. However, in practice, converting the DOA estimation into a classification problem often results in better performance than the regression formulation, since that classification problems are generally easier to model, and are more robust in handling noise and uncertainty than regression problems. In the classification formulation of DOA, the output space is discretized into several intervals, each of which is treated as a class. These classes exhibit strong inter-class correlation, with their mutual-similarity increasing when they approach each other and being ordered. However, this property is not sufficiently explored. To exploit these property, we propose a soft label distribution, named Unbiased Label Distribution (ULD), for eliminating the quantization error of the training target and further taking the inter-class similarity into strong consideration. We further introduce two loss functions, named the Negative Log Absolute Error (NLAE) loss function and {Mean Squared Error loss function without activation (MSE(wo))}, for the soft label family. Finally, we design a new decoding method to map the predicted distribution to sound source locations, called Weighted Adjacent Decoding (WAD). It uses the weighted sum of the probabilities of the peak classes and their adjacent classes in the predicted distribution for decoding. Experimental results show that the proposed method achieves the state-of-the-art performance, and the WAD decoding method is able to even breakthrough the quantization error limits of existing decoding methods.
</details>
<details>
<summary>摘要</summary>
声源localization（SSL）涉及估计声信号的方向来源（DOA）的方向。由于DOA估计的输出空间是连续的，因此可以使用回归来模型声源。然而，在实践中，将DOA估计转换成分类问题通常会产生更好的性能，因为分类问题比回归问题更容易模型，并且对噪声和不确定性更加抗应。在分类形式下，DOA的输出空间被精确化为一些时间间隔，每个时间间隔都被视为一个类。这些类之间存在强相关性，它们之间的相似性随着它们的距离增加，并且按照一定的顺序排序。然而，这个特性并没有得到充分利用。为了利用这个特性，我们提出了一种不偏 Label Distribution（ULD），用于消除培育目标的量化误差，同时更加强调类之间的相似性。我们还引入了两种损失函数：Negative Log Absolute Error（NLAE）损失函数和Mean Squared Error损失函数 без活动（MSE(wo)），用于soft label家族。最后，我们设计了一种新的解码方法，名为Weighted Adjacent Decoding（WAD），用于将预测分布映射到声源位置。它使用预测分布中峰值类和其相邻类的权重加权和，进行解码。实验结果表明，我们的方法可以达到状态公共的性能，而WAD解码方法甚至可以超越现有解码方法的量化误差限制。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/eess.AS_2023_11_21/" data-id="clpxp6c9l016jee88d5lfcmv7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/cs.CV_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T13:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/cs.CV_2023_11_21/">cs.CV - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Physics-guided-Shape-from-Template-Monocular-Video-Perception-through-Neural-Surrogate-Models"><a href="#Physics-guided-Shape-from-Template-Monocular-Video-Perception-through-Neural-Surrogate-Models" class="headerlink" title="Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models"></a>Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12796">http://arxiv.org/abs/2311.12796</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Stotko, Nils Wandel, Reinhard Klein</li>
<li>For: 重建三维动态场景* Methods: 使用预训练神经网络代理模型，快速评估，稳定，生成平滑的重建结果，同时通过对模拟的网格进行可微分渲染，实现像素级比较，从而对Physics simulation进行权重补做，以提取形状信息和物理参数。* Results: 比较 $\phi$-SfT方法，runtime reduction为400-500倍，实现了精确、稳定、平滑的重建结果。<details>
<summary>Abstract</summary>
3D reconstruction of dynamic scenes is a long-standing problem in computer graphics and increasingly difficult the less information is available. Shape-from-Template (SfT) methods aim to reconstruct a template-based geometry from RGB images or video sequences, often leveraging just a single monocular camera without depth information, such as regular smartphone recordings. Unfortunately, existing reconstruction methods are either unphysical and noisy or slow in optimization. To solve this problem, we propose a novel SfT reconstruction algorithm for cloth using a pre-trained neural surrogate model that is fast to evaluate, stable, and produces smooth reconstructions due to a regularizing physics simulation. Differentiable rendering of the simulated mesh enables pixel-wise comparisons between the reconstruction and a target video sequence that can be used for a gradient-based optimization procedure to extract not only shape information but also physical parameters such as stretching, shearing, or bending stiffness of the cloth. This allows to retain a precise, stable, and smooth reconstructed geometry while reducing the runtime by a factor of 400-500 compared to $\phi$-SfT, a state-of-the-art physics-based SfT approach.
</details>
<details>
<summary>摘要</summary>
三维重建动态场景是计算机图形领域的长期问题，随着信息的更少，变得越来越困难。形状从模板（SfT）方法 aspire to reconstruct a template-based geometry from RGB images or video sequences, often leveraging just a single monocular camera without depth information, such as regular smartphone recordings. Unfortunately, existing reconstruction methods are either unphysical and noisy or slow in optimization. To solve this problem, we propose a novel SfT reconstruction algorithm for cloth using a pre-trained neural surrogate model that is fast to evaluate, stable, and produces smooth reconstructions due to a regularizing physics simulation. Differentiable rendering of the simulated mesh enables pixel-wise comparisons between the reconstruction and a target video sequence that can be used for a gradient-based optimization procedure to extract not only shape information but also physical parameters such as stretching, shearing, or bending stiffness of the cloth. This allows to retain a precise, stable, and smooth reconstructed geometry while reducing the runtime by a factor of 400-500 compared to $\phi$-SfT, a state-of-the-art physics-based SfT approach.Here's the text with some additional information about the translation:I used the Google Translate API to translate the text into Simplified Chinese. The translation is in the form of Traditional Chinese, which is the standard writing system used in Taiwan and other parts of the world. The translation is in Simplified Chinese, which is used in mainland China.The translation is written in a formal and professional style, using technical terms and phrases that are commonly used in the field of computer graphics. I tried to preserve the original meaning and context of the text as much as possible, while also making sure that the translation is accurate and natural-sounding.Please note that the translation may not be perfect, and there may be some nuances or cultural references that are lost in translation. If you have any specific questions or concerns, please feel free to ask.
</details></li>
</ul>
<hr>
<h2 id="ShareGPT4V-Improving-Large-Multi-Modal-Models-with-Better-Captions"><a href="#ShareGPT4V-Improving-Large-Multi-Modal-Models-with-Better-Captions" class="headerlink" title="ShareGPT4V: Improving Large Multi-Modal Models with Better Captions"></a>ShareGPT4V: Improving Large Multi-Modal Models with Better Captions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12793">http://arxiv.org/abs/2311.12793</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ShareGPT4V/ShareGPT4V.github.io">https://github.com/ShareGPT4V/ShareGPT4V.github.io</a></li>
<li>paper_authors: Lin Chen, Jisong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, Dahua Lin<br>for:* The paper is written to address the scarcity of high-quality image-text data for training large multi-modal models (LMMs).methods:* The authors introduce the ShareGPT4V dataset, a large-scale resource featuring 1.2 million highly descriptive captions that cover world knowledge, object properties, spatial relationships, and aesthetic evaluations.* The dataset is expanded from a curated 100K high-quality captions collected from advanced GPT4-Vision, and is further enhanced with a superb caption model trained on this subset.results:* The ShareGPT4V dataset significantly enhances the performance of LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME and MMBench benchmarks, with respective gains of 222.8&#x2F;22.0&#x2F;22.3 and 2.7&#x2F;1.3&#x2F;1.5.* The authors also incorporate ShareGPT4V data into both the pre-training and SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple architecture that has remarkable performance across a majority of the multi-modal benchmarks.<details>
<summary>Abstract</summary>
In the realm of large multi-modal models (LMMs), efficient modality alignment is crucial yet often constrained by the scarcity of high-quality image-text data. To address this bottleneck, we introduce the ShareGPT4V dataset, a pioneering large-scale resource featuring 1.2 million highly descriptive captions, which surpasses existing datasets in diversity and information content, covering world knowledge, object properties, spatial relationships, and aesthetic evaluations. Specifically, ShareGPT4V originates from a curated 100K high-quality captions collected from advanced GPT4-Vision and has been expanded to 1.2M with a superb caption model trained on this subset. ShareGPT4V first demonstrates its effectiveness for the Supervised Fine-Tuning (SFT) phase, by substituting an equivalent quantity of detailed captions in existing SFT datasets with a subset of our high-quality captions, significantly enhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME and MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and 2.7/1.3/1.5. We further incorporate ShareGPT4V data into both the pre-training and SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple architecture that has remarkable performance across a majority of the multi-modal benchmarks. This project is available at https://ShareGPT4V.github.io to serve as a pivotal resource for advancing the LMMs community.
</details>
<details>
<summary>摘要</summary>
在大型多modal模型（LMMs）领域，有效的modal匹配是关键，然而经常受到高质量图文数据的缺乏所限制。为解决这个瓶颈，我们介绍了ShareGPT4V dataset，这是一个创新的大规模资源，包含120万高度描述性的标签，超过现有数据集的多样性和信息内容，覆盖世界知识、物品属性、空间关系和艺术评价等领域。具体来说，ShareGPT4V来自于我们自动选择的100K高质量标签，并通过这些标签进行扩展至120万。ShareGPT4V首先在Supervised Fine-Tuning（SFT）阶段表现出色，通过将现有SFT数据集中的相应量的详细标签替换为我们高质量标签，使LMMs like LLaVA-7B、LLaVA-1.5-13B和Qwen-VL-Chat-7B在MME和MMBench bencmarks上显著提高，增幅分别为222.8/22.0/22.3和2.7/1.3/1.5。我们进一步将ShareGPT4V数据集 integrate到预训练和SFT阶段，得到了ShareGPT4V-7B，一个基于简单结构的优秀LMM，在多种多Modalbenchmarks上表现出色。这个项目可以在https://ShareGPT4V.github.io中下载，以便为LMMs社区提供积极的资源。
</details></li>
</ul>
<hr>
<h2 id="SuGaR-Surface-Aligned-Gaussian-Splatting-for-Efficient-3D-Mesh-Reconstruction-and-High-Quality-Mesh-Rendering"><a href="#SuGaR-Surface-Aligned-Gaussian-Splatting-for-Efficient-3D-Mesh-Reconstruction-and-High-Quality-Mesh-Rendering" class="headerlink" title="SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering"></a>SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12775">http://arxiv.org/abs/2311.12775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Guédon, Vincent Lepetit</li>
<li>for: This paper proposes a method for extracting a mesh from 3D Gaussian Splatting, which is a recently popular method for realistic rendering that is faster to train than NeRFs.</li>
<li>methods: The method introduced in the paper includes a regularization term that encourages the gaussians to align with the surface of the scene, and a Poisson reconstruction method to extract a mesh from the gaussians.</li>
<li>results: The paper reports that the proposed method can extract a mesh from 3D Gaussian Splatting within minutes, which is faster than the state-of-the-art methods on neural SDFs, and provides a better rendering quality. Additionally, the method allows for easy editing, sculpting, rigging, animating, compositing, and relighting of the gaussians using traditional software by manipulating the mesh.<details>
<summary>Abstract</summary>
We propose a method to allow precise and extremely fast mesh extraction from 3D Gaussian Splatting. Gaussian Splatting has recently become very popular as it yields realistic rendering while being significantly faster to train than NeRFs. It is however challenging to extract a mesh from the millions of tiny 3D gaussians as these gaussians tend to be unorganized after optimization and no method has been proposed so far. Our first key contribution is a regularization term that encourages the gaussians to align well with the surface of the scene. We then introduce a method that exploits this alignment to extract a mesh from the Gaussians using Poisson reconstruction, which is fast, scalable, and preserves details, in contrast to the Marching Cubes algorithm usually applied to extract meshes from Neural SDFs. Finally, we introduce an optional refinement strategy that binds gaussians to the surface of the mesh, and jointly optimizes these Gaussians and the mesh through Gaussian splatting rendering. This enables easy editing, sculpting, rigging, animating, compositing and relighting of the Gaussians using traditional softwares by manipulating the mesh instead of the gaussians themselves. Retrieving such an editable mesh for realistic rendering is done within minutes with our method, compared to hours with the state-of-the-art methods on neural SDFs, while providing a better rendering quality.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，允许精确并非常快地从3D Gaussian Splatting中提取网格。 Gaussian Splatting在最近很受欢迎，因为它可以提供真实的渲染，而且在训练时间上比NeRF更快。然而，从millions of tiny 3D Gaussian中提取网格是一个挑战，因为这些Gaussian在优化后通常不具有有序结构。我们的首要贡献是一个正则化项，使Gaussian与场景表面align。我们然后介绍了一种利用这种alignment提取网格的方法，使用Poisson重建，这是快速、可扩展、细节保持的。此外，我们还介绍了一种可选的精度增强策略，将Gaussian绑定到网格上，并通过Gaussian splatting rendering进行共同优化。这使得可以使用传统软件进行编辑、雕塑、rigging、动画、复制和重新照明Gaussian，而不需要直接操作Gaussian本身。通过我们的方法，可以在几分钟内获得高质量的编辑网格，而不是以前的多个小时。
</details></li>
</ul>
<hr>
<h2 id="Iris-Presentation-Attack-Assessing-the-Impact-of-Combining-Vanadium-Dioxide-Films-with-Artificial-Eyes"><a href="#Iris-Presentation-Attack-Assessing-the-Impact-of-Combining-Vanadium-Dioxide-Films-with-Artificial-Eyes" class="headerlink" title="Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films with Artificial Eyes"></a>Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films with Artificial Eyes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12773">http://arxiv.org/abs/2311.12773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Darshika Jauhari, Renu Sharma, Cunjian Chen, Nelson Sepulveda, Arun Ross</li>
<li>for: 这个论文旨在检测人工眼睛上的呈现攻击（presentation attack），以及这些攻击的影响于距离辐射识别系统（iris recognition system）的可靠性。</li>
<li>methods: 这篇论文使用了覆盖人工眼睛表面的 Vanadium Dioxide (VO2) Film，以调整距离辐射捕捉到的对象的光学特性。</li>
<li>results: 研究发现，在使用两种现状顶尖眼识别方法时，加上 VO2 Film 的人工眼睛可能会导致这些方法错分为真实的眼睛。这表示需要系统性的分析和有效地解决这种攻击。<details>
<summary>Abstract</summary>
Iris recognition systems, operating in the near infrared spectrum (NIR), have demonstrated vulnerability to presentation attacks, where an adversary uses artifacts such as cosmetic contact lenses, artificial eyes or printed iris images in order to circumvent the system. At the same time, a number of effective presentation attack detection (PAD) methods have been developed. These methods have demonstrated success in detecting artificial eyes (e.g., fake Van Dyke eyes) as presentation attacks. In this work, we seek to alter the optical characteristics of artificial eyes by affixing Vanadium Dioxide (VO2) films on their surface in various spatial configurations. VO2 films can be used to selectively transmit NIR light and can, therefore, be used to regulate the amount of NIR light from the object that is captured by the iris sensor. We study the impact of such images produced by the sensor on two state-of-the-art iris PA detection methods. We observe that the addition of VO2 films on the surface of artificial eyes can cause the PA detection methods to misclassify them as bonafide eyes in some cases. This represents a vulnerability that must be systematically analyzed and effectively addressed.
</details>
<details>
<summary>摘要</summary>
芳麻识别系统，在近红外谱（NIR）spectrum中运行，已经显示出对于投入攻击（presentation attacks）的感itivity。攻击者可以使用cosmetic contact lenses、人工眼或印刷眼膜来绕过系统。同时，一些有效的投入攻击检测（PAD）方法也已经开发出来。这些方法能够检测到人工眼（如假 Van Dyke 眼）作为投入攻击。在这项工作中，我们想要改变人工眼的光学特性，通过在其表面尝试VO2 films的不同空间配置。VO2 films可以选择性地传输NIR光，因此可以用来控制眼镜传感器接收的NIR光量。我们研究了这些由感器产生的图像对两种现代芳麻PA检测方法的影响。我们发现，在人工眼表面添加VO2 films可以导致PA检测方法在某些情况下错分为真实的眼睛。这表示了一个需要系统分析和解决的漏洞。
</details></li>
</ul>
<hr>
<h2 id="Swift-Parameter-free-Attention-Network-for-Efficient-Super-Resolution"><a href="#Swift-Parameter-free-Attention-Network-for-Efficient-Super-Resolution" class="headerlink" title="Swift Parameter-free Attention Network for Efficient Super-Resolution"></a>Swift Parameter-free Attention Network for Efficient Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12770">http://arxiv.org/abs/2311.12770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hongyuanyu/span">https://github.com/hongyuanyu/span</a></li>
<li>paper_authors: Cheng Wan, Hongyuan Yu, Zhiqi Li, Yihang Chen, Yajun Zou, Yuqing Liu, Xuanwu Yin, Kunlong Zuo</li>
<li>for: 提高单张超解像图像（SISR）任务中的计算效率，使用Parameter-free Attention Network（SPAN）来平衡参数数量、执行速度和图像质量。</li>
<li>methods: 使用新的参数自由注意机制，通过对称的活动函数和循环连接来增强高贡献信息并压抑 redundant信息。</li>
<li>results: 在多个benchmark上评估SPAN，显示其在图像质量和执行速度之间做出了显著的质速交换，并在NTIRE 2023高效超解像挑战中获得了最高PSNR值27.09 dB，同时降低了测试时间7.08ms。<details>
<summary>Abstract</summary>
Single Image Super-Resolution (SISR) is a crucial task in low-level computer vision, aiming to reconstruct high-resolution images from low-resolution counterparts. Conventional attention mechanisms have significantly improved SISR performance but often result in complex network structures and large number of parameters, leading to slow inference speed and large model size. To address this issue, we propose the Swift Parameter-free Attention Network (SPAN), a highly efficient SISR model that balances parameter count, inference speed, and image quality. SPAN employs a novel parameter-free attention mechanism, which leverages symmetric activation functions and residual connections to enhance high-contribution information and suppress redundant information. Our theoretical analysis demonstrates the effectiveness of this design in achieving the attention mechanism's purpose. We evaluate SPAN on multiple benchmarks, showing that it outperforms existing efficient super-resolution models in terms of both image quality and inference speed, achieving a significant quality-speed trade-off. This makes SPAN highly suitable for real-world applications, particularly in resource-constrained scenarios. Notably, our model attains the best PSNR of 27.09 dB, and the test runtime of our team is reduced by 7.08ms in the NTIRE 2023 efficient super-resolution challenge. Our code and models are made publicly available at \url{https://github.com/hongyuanyu/SPAN}.
</details>
<details>
<summary>摘要</summary>
Single Image Super-Resolution (SISR) 是计算机视觉领域中的一项重要任务，目的是从低分辨率图像中重construct高分辨率图像。传统的注意力机制有效提高了 SISR 性能，但常常导致复杂的网络结构和大量参数，从而导致慢速 inference 速度和大型模型。为解决这个问题，我们提出了 Swift Parameter-free Attention Network (SPAN)，一种高效的 SISR 模型，能够平衡参数数量、插入速度和图像质量。SPAN 使用了一种新的参数自由注意机制，通过对称的活动函数和径向连接来增强高贡献信息和抑制 redundancy 信息。我们的理论分析表明这种设计可以实现注意机制的目的。我们在多个标准测试上评估了 SPAN，并证明它在图像质量和插入速度之间实现了显著的质量-速度交换。这使得 SPAN 在实际应用中非常适合，特别是在有限资源的场景下。值得一提的是，我们的模型在 NTIRE 2023 年度高效超分辨计划中达到了最高 PSNR 值为 27.09 dB，并在测试时间上减少了 7.08ms。我们的代码和模型在 <https://github.com/hongyuanyu/SPAN> 上公开提供。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Weight-Perturbed-Deep-Neural-Networks-With-Application-in-Iris-Presentation-Attack-Detection"><a href="#Investigating-Weight-Perturbed-Deep-Neural-Networks-With-Application-in-Iris-Presentation-Attack-Detection" class="headerlink" title="Investigating Weight-Perturbed Deep Neural Networks With Application in Iris Presentation Attack Detection"></a>Investigating Weight-Perturbed Deep Neural Networks With Application in Iris Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12764">http://arxiv.org/abs/2311.12764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/redwankarimsony/weightperturbation-msu">https://github.com/redwankarimsony/weightperturbation-msu</a></li>
<li>paper_authors: Renu Sharma, Redwan Sony, Arun Ross</li>
<li>for: 这篇论文的目的是分析深度神经网络（DNNs）对参数变化的敏感性，以便在实际应用中使用之前进行分析。</li>
<li>methods: 这篇论文使用了三种DNN架构（VGG、ResNet和DenseNet），以及三种参数变化方法（高斯噪声、重量归零和重量缩放）。它们在芳香检测任务中进行了实验，并使用了两个设定（整个网络和层级）。</li>
<li>results: 根据敏感性分析， authors提出了改进的模型，只需在网络参数中进行小 perturbation，而无需进行再训练。此外，他们还将这些perturbed模型 ensemble在分数级和参数级进行了提升，从而实现了模型的性能提升。 LivDet-Iris-2017 数据集上的平均提升率为43.58%，而 LivDet-Iris-2020 数据集上的提升率为9.25%。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) exhibit superior performance in various machine learning tasks, e.g., image classification, speech recognition, biometric recognition, object detection, etc. However, it is essential to analyze their sensitivity to parameter perturbations before deploying them in real-world applications. In this work, we assess the sensitivity of DNNs against perturbations to their weight and bias parameters. The sensitivity analysis involves three DNN architectures (VGG, ResNet, and DenseNet), three types of parameter perturbations (Gaussian noise, weight zeroing, and weight scaling), and two settings (entire network and layer-wise). We perform experiments in the context of iris presentation attack detection and evaluate on two publicly available datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the sensitivity analysis, we propose improved models simply by perturbing parameters of the network without undergoing training. We further combine these perturbed models at the score-level and at the parameter-level to improve the performance over the original model. The ensemble at the parameter-level shows an average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on the LivDet-Iris-2020 dataset. The source code is available at \href{https://github.com/redwankarimsony/WeightPerturbation-MSU}{https://github.com/redwankarimsony/WeightPerturbation-MSU}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="High-resolution-Image-based-Malware-Classification-using-Multiple-Instance-Learning"><a href="#High-resolution-Image-based-Malware-Classification-using-Multiple-Instance-Learning" class="headerlink" title="High-resolution Image-based Malware Classification using Multiple Instance Learning"></a>High-resolution Image-based Malware Classification using Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12760">http://arxiv.org/abs/2311.12760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/timppeters/mil-malware-images">https://github.com/timppeters/mil-malware-images</a></li>
<li>paper_authors: Tim Peters, Hikmat Farhat</li>
<li>for: 防御 binary 扩大的恶意软件分类</li>
<li>methods: 使用高精度灰度图像和多实例学习来缺陷 binary 扩大</li>
<li>results: 实验表明，提议方法可以在对抗恶意软件分类中提高准确率，最高达 $96.6%$，比基准 $22.8%$ 高。<details>
<summary>Abstract</summary>
This paper proposes a novel method of classifying malware into families using high-resolution greyscale images and multiple instance learning to overcome adversarial binary enlargement. Current methods of visualisation-based malware classification largely rely on lossy transformations of inputs such as resizing to handle the large, variable-sized images. Through empirical analysis and experimentation, it is shown that these approaches cause crucial information loss that can be exploited. The proposed solution divides the images into patches and uses embedding-based multiple instance learning with a convolutional neural network and an attention aggregation function for classification. The implementation is evaluated on the Microsoft Malware Classification dataset and achieves accuracies of up to $96.6\%$ on adversarially enlarged samples compared to the baseline of $22.8\%$. The Python code is available online at https://github.com/timppeters/MIL-Malware-Images .
</details>
<details>
<summary>摘要</summary>
这个论文提出了一种新的恶意软件分类方法，使用高分辨率灰度图像和多实例学习来超越对恶意 binary 扩大的攻击。现有的视觉化基于识别方法主要通过lossy变换输入来处理大小可变的图像。经验表明，这些方法会导致重要信息的丢失，可以被利用。该提案将图像分成块，使用嵌入式多实例学习的 convolutional neural network 和注意聚合函数进行分类。实现在 Microsoft Malware Classification 数据集上进行评估，可以达到 $96.6\%$ 的准确率，比基准 $22.8\%$ 高出许多。Python 代码可以在 https://github.com/timppeters/MIL-Malware-Images 上下载。
</details></li>
</ul>
<hr>
<h2 id="Towards-Natural-Language-Guided-Drones-GeoText-1652-Benchmark-with-Spatially-Relation-Matching"><a href="#Towards-Natural-Language-Guided-Drones-GeoText-1652-Benchmark-with-Spatially-Relation-Matching" class="headerlink" title="Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with Spatially Relation Matching"></a>Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with Spatially Relation Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12751">http://arxiv.org/abs/2311.12751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Chu, Zhedong Zheng, Wei Ji, Tat-Seng Chua</li>
<li>for: 提高飞行器控制和导航的自然语言指令集成</li>
<li>methods: 利用大型自然语言模型生成数据集，并与预训练视觉模型结合使用，以实现精细的图像文本框架对应。</li>
<li>results: 提出了一个新的优化目标，即缓冲空间匹配，以便在区域级别上进行精细的空间关系匹配。实验结果表明，该方法在不同的描述复杂度下保持了Exceptional recall rate。<details>
<summary>Abstract</summary>
Drone navigation through natural language commands remains a significant challenge due to the lack of publicly available multi-modal datasets and the intricate demands of fine-grained visual-text alignment. In response to this pressing need, we present a new human-computer interaction annotation benchmark called GeoText-1652, meticulously curated through a robust Large Language Model (LLM)-based data generation framework and the expertise of pre-trained vision models. This new dataset seamlessly extends the existing image dataset, \ie, University-1652, with spatial-aware text annotations, encompassing intricate image-text-bounding box associations. Besides, we introduce a new optimization objective to leverage fine-grained spatial associations, called blending spatial matching, for region-level spatial relation matching. Extensive experiments reveal that our approach maintains an exceptional recall rate under varying description complexities. This underscores the promising potential of our approach in elevating drone control and navigation through the seamless integration of natural language commands in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
<<SYS>>游戏机器人导航透过自然语言命令仍然是一个重要的挑战，主要因为缺乏公开的多modal资料集和细部的视觉文本对铺设。为解决这个紧迫需求，我们提出了一个新的人机交互标准参考集called GeoText-1652，通过一个可靠的大型自然语言模型（LLM）基础的数据生成框架和预训的视觉模型来实现。这个新标准集扩展了现有的图像集，即University-1652， adds spatial-aware text annotations，包括细部的图像-文本 bounding box 协调。此外，我们引入了一个新的优化目标，叫做混合空间匹配，以利用细部的空间关联。实验结果表明，我们的方法可以在不同的描述复杂性下保持高的精度率。这说明了我们的方法在实际应用中对游戏机器人导航和控制的潜在应用非常高。
</details></li>
</ul>
<hr>
<h2 id="Attacking-Motion-Planners-Using-Adversarial-Perception-Errors"><a href="#Attacking-Motion-Planners-Using-Adversarial-Perception-Errors" class="headerlink" title="Attacking Motion Planners Using Adversarial Perception Errors"></a>Attacking Motion Planners Using Adversarial Perception Errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12722">http://arxiv.org/abs/2311.12722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Sadeghi, Nicholas A. Lord, John Redford, Romain Mueller</li>
<li>for: 本文旨在探讨自动驾驶（AD）系统的模块化设计和测试方法，以及测试结果的解释。</li>
<li>methods: 本文使用了一种简单的边界攻击算法，可以系统地构造出识别质量高但导致 плани策略失败的输入。</li>
<li>results: 研究人员使用了这种算法在CARLA simulateur上测试了两个黑盒计划器，并在城市和高速公路驾驶场景中发现了许多攻击。这些攻击是隔离在计划器输入空间中的，并且对自动驾驶系统部署和测试有重要的含义。<details>
<summary>Abstract</summary>
Autonomous driving (AD) systems are often built and tested in a modular fashion, where the performance of different modules is measured using task-specific metrics. These metrics should be chosen so as to capture the downstream impact of each module and the performance of the system as a whole. For example, high perception quality should enable prediction and planning to be performed safely. Even though this is true in general, we show here that it is possible to construct planner inputs that score very highly on various perception quality metrics but still lead to planning failures. In an analogy to adversarial attacks on image classifiers, we call such inputs \textbf{adversarial perception errors} and show they can be systematically constructed using a simple boundary-attack algorithm. We demonstrate the effectiveness of this algorithm by finding attacks for two different black-box planners in several urban and highway driving scenarios using the CARLA simulator. Finally, we analyse the properties of these attacks and show that they are isolated in the input space of the planner, and discuss their implications for AD system deployment and testing.
</details>
<details>
<summary>摘要</summary>
自主驾驶（AD）系统通常以模块化的方式设计和测试，其中不同模块的性能通过任务特定的 метри来进行评估。这些 метри应选择以捕捉下游影响和整个系统性能。例如，高识别质量可以确保安全地进行预测和规划。虽然这是通常的情况，但我们在这里示出了可以通过简单的边界攻击算法构造出具有高识别质量метри但导致规划失败的输入。我们称这些输入为“对抗识别错误”，并证明它们可以通过一种简单的边界攻击算法系统地构造。我们使用 CARLA  simulateur 在城市和高速公路上驾驶场景中对两种黑盒规划器进行了多个攻击检测。最后，我们分析了这些攻击的性质并证明它们在输入空间中孤立，并讨论它们对自动驾驶系统部署和测试的影响。
</details></li>
</ul>
<hr>
<h2 id="Cascade-Learning-Localises-Discriminant-Features-in-Visual-Scene-Classification"><a href="#Cascade-Learning-Localises-Discriminant-Features-in-Visual-Scene-Classification" class="headerlink" title="Cascade Learning Localises Discriminant Features in Visual Scene Classification"></a>Cascade Learning Localises Discriminant Features in Visual Scene Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12704">http://arxiv.org/abs/2311.12704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwen Wang, Katayoun Farrahi</li>
<li>for: 本研究旨在解决深度卷积神经网络（DCNN）在医学领域的解释性不足问题，特别是临床医生希望得到可信worthy的自动化决策。</li>
<li>methods: 本研究使用两种不同的学习方法，分别是传统的端到端（E2E）学习和层次学习（CL），以解析DCNN中特征表示的本地化性。</li>
<li>results: 我们的分析表明，E2E学习策略在多层网络层中具有有限的本地化特征表示能力，而CL学习策略则能够更好地本地化特征表示。我们的结果还表明，在YOLO对象检测框架上，CL学习策略比E2E策略高$2%$的准确率。<details>
<summary>Abstract</summary>
Lack of interpretability of deep convolutional neural networks (DCNN) is a well-known problem particularly in the medical domain as clinicians want trustworthy automated decisions. One way to improve trust is to demonstrate the localisation of feature representations with respect to expert labeled regions of interest. In this work, we investigate the localisation of features learned via two varied learning paradigms and demonstrate the superiority of one learning approach with respect to localisation. Our analysis on medical and natural datasets show that the traditional end-to-end (E2E) learning strategy has a limited ability to localise discriminative features across multiple network layers. We show that a layer-wise learning strategy, namely cascade learning (CL), results in more localised features. Considering localisation accuracy, we not only show that CL outperforms E2E but that it is a promising method of predicting regions. On the YOLO object detection framework, our best result shows that CL outperforms the E2E scheme by $2\%$ in mAP.
</details>
<details>
<summary>摘要</summary>
深度卷积神经网络（DCNN）的解释性不足是医疗领域中一个公认的问题，因为临床医生希望得到可靠的自动化决策。为了提高信任度，我们可以证明特征表示的地方化。在这项工作中，我们研究了DCNN学习两种不同的学习模式下特征的地方化，并证明一种学习方法在地方化方面具有优势。我们对医疗和自然数据集进行分析，发现传统的端到端（E2E）学习策略在多层网络中具有局部特征的局限性。我们显示，层wise学习策略（cascade learning，CL）可以更好地地方化特征。基于地方化精度，我们不仅表明CL exceeds E2E，而且可以有效预测区域。在YOLO对象检测框架上，我们最佳结果表明CL比E2E方案高$2\%$的射频精度。
</details></li>
</ul>
<hr>
<h2 id="Transferring-to-Real-World-Layouts-A-Depth-aware-Framework-for-Scene-Adaptation"><a href="#Transferring-to-Real-World-Layouts-A-Depth-aware-Framework-for-Scene-Adaptation" class="headerlink" title="Transferring to Real-World Layouts: A Depth-aware Framework for Scene Adaptation"></a>Transferring to Real-World Layouts: A Depth-aware Framework for Scene Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12682">http://arxiv.org/abs/2311.12682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mu Chen, Zhedong Zheng, Yi Yang<br>for: 本文主要目标是提出一种深度感知的频率预处理方法，以便在无监督领域适应（UDA）中转移知识，从源频率数据中学习到目标频率数据中，以避免手动标注 pixels。methods: 本文提出了一种depth-aware框架，包括一个深度引导的上下文滤波（DCF）和一个交叉任务编码器。DCF通过模拟真实的世界布局来扩大数据集，而交叉任务编码器则进一步适应了两个补做任务之间的相互作用。此外， authors还使用了公共数据集中没有深度标注，因此他们使用了市场上的深度估计网络来生成假深度。results: 对两个广泛使用的标准 bench-mark 进行了广泛的实验，结果表明， authors 的提出的方法，即使使用假深度，仍能在 GTA 到 Cityscapes 和 Synthia 到 Cityscapes 上达到竞争性表现，具体来说是 77.7 mIoU 和 69.3 mIoU。<details>
<summary>Abstract</summary>
Scene segmentation via unsupervised domain adaptation (UDA) enables the transfer of knowledge acquired from source synthetic data to real-world target data, which largely reduces the need for manual pixel-level annotations in the target domain. To facilitate domain-invariant feature learning, existing methods typically mix data from both the source domain and target domain by simply copying and pasting the pixels. Such vanilla methods are usually sub-optimal since they do not take into account how well the mixed layouts correspond to real-world scenarios. Real-world scenarios are with an inherent layout. We observe that semantic categories, such as sidewalks, buildings, and sky, display relatively consistent depth distributions, and could be clearly distinguished in a depth map. Based on such observation, we propose a depth-aware framework to explicitly leverage depth estimation to mix the categories and facilitate the two complementary tasks, i.e., segmentation and depth learning in an end-to-end manner. In particular, the framework contains a Depth-guided Contextual Filter (DCF) forndata augmentation and a cross-task encoder for contextual learning. DCF simulates the real-world layouts, while the cross-task encoder further adaptively fuses the complementing features between two tasks. Besides, it is worth noting that several public datasets do not provide depth annotation. Therefore, we leverage the off-the-shelf depth estimation network to generate the pseudo depth. Extensive experiments show that our proposed methods, even with pseudo depth, achieve competitive performance on two widely-used bench-marks, i.e. 77.7 mIoU on GTA to Cityscapes and 69.3 mIoU on Synthia to Cityscapes.
</details>
<details>
<summary>摘要</summary>
We observe that semantic categories such as sidewalks, buildings, and sky have consistent depth distributions and can be distinguished in a depth map. Based on this observation, we propose a depth-aware framework that leverages depth estimation to mix categories and perform segmentation and depth learning in an end-to-end manner. The framework includes a Depth-guided Contextual Filter (DCF) for data augmentation and a cross-task encoder for contextual learning. DCF simulates real-world layouts, while the cross-task encoder adaptively fuses complementary features between the two tasks.As some public datasets do not provide depth annotations, we use an off-the-shelf depth estimation network to generate pseudo depth. Our proposed method, even with pseudo depth, achieves competitive performance on two widely-used benchmarks, with a mIoU of 77.7 on GTA to Cityscapes and 69.3 on Synthia to Cityscapes.
</details></li>
</ul>
<hr>
<h2 id="BundleMoCap-Efficient-Robust-and-Smooth-Motion-Capture-from-Sparse-Multiview-Videos"><a href="#BundleMoCap-Efficient-Robust-and-Smooth-Motion-Capture-from-Sparse-Multiview-Videos" class="headerlink" title="BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse Multiview Videos"></a>BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse Multiview Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12679">http://arxiv.org/abs/2311.12679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Albanis, Nikolaos Zioulis, Kostas Kolomvatsos</li>
<li>for: 这篇论文的目的是提出一种高效且简单的 markerless 动作捕捉方法，以解决现有的方法具有较高计算成本和多个阶段的问题。</li>
<li>methods: 该方法基于 manifold interpolation between latent keyframes，不需要时间约束和多个阶段的数据驱动回归和优化，可以高效地解决动作捕捉问题。</li>
<li>results: 对比于现有的状态对技术，BundleMoCap 能够达到高质量的动作捕捉结果，而无需增加复杂度。更多细节可以参考 <a target="_blank" rel="noopener" href="https://moverseai.github.io/bundle/%E3%80%82">https://moverseai.github.io/bundle/。</a><details>
<summary>Abstract</summary>
Capturing smooth motions from videos using markerless techniques typically involves complex processes such as temporal constraints, multiple stages with data-driven regression and optimization, and bundle solving over temporal windows. These processes can be inefficient and require tuning multiple objectives across stages. In contrast, BundleMoCap introduces a novel and efficient approach to this problem. It solves the motion capture task in a single stage, eliminating the need for temporal smoothness objectives while still delivering smooth motions. BundleMoCap outperforms the state-of-the-art without increasing complexity. The key concept behind BundleMoCap is manifold interpolation between latent keyframes. By relying on a local manifold smoothness assumption, we can efficiently solve a bundle of frames using a single code. Additionally, the method can be implemented as a sliding window optimization and requires only the first frame to be properly initialized, reducing the overall computational burden. BundleMoCap's strength lies in its ability to achieve high-quality motion capture results with simplicity and efficiency. More details can be found at https://moverseai.github.io/bundle/.
</details>
<details>
<summary>摘要</summary>
capturing smooth motions from videos using markerless techniques 通常需要复杂的过程，例如时间约束、多个阶段的数据驱动回归和优化、和时间窗口内的集合解决。这些过程可能是不效率的并需要在不同阶段调整多个目标。相比之下，BundleMoCap 引入了一种新的和高效的解决方案。它在单个阶段内解决动作捕捉任务，消除了时间稳定性目标，同时仍能提供平滑的动作。BundleMoCap 超越了当前状态的性能，而不需增加复杂性。BundleMoCap 的关键思想是在 latent keyframes 之间进行抽象 interpolating。通过假设本地满足性，我们可以高效地解决一个包含多帧的缓存。此外，该方法可以作为滑块窗口优化进行实现，只需要初始化第一帧，从而减少总计算负担。BundleMoCap 的优势在于它可以通过简单和高效的方式实现高质量的动作捕捉结果。更多细节可以在 <https://moverseai.github.io/bundle/> 找到。
</details></li>
</ul>
<hr>
<h2 id="Similar-Document-Template-Matching-Algorithm"><a href="#Similar-Document-Template-Matching-Algorithm" class="headerlink" title="Similar Document Template Matching Algorithm"></a>Similar Document Template Matching Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12663">http://arxiv.org/abs/2311.12663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshitha Yenigalla, Bommareddy Revanth Srinivasa Reddy, Batta Venkata Rahul, Nannapuraju Hemanth Raju</li>
<li>for: 这个研究旨在提供一种涵盖模板EXTRACTION、比较和诈骗检测的全面方法，以验证医疗文档。</li>
<li>methods: 该方法包括使用高级技术进行模板EXTRACTION，包括区域特征分析和边缘识别，以确保模板的清晰度。然后是模板比较算法，使用高级特征匹配和描述符，以增强比较的可靠性。诈骗检测包括计算SSIM量和OCR技术，以EXTRACT文本信息。</li>
<li>results: 该方法可以提供可靠的医疗文档验证，Addressing Complexities in template EXTRACTION、比较和诈骗检测，并且可以适应不同的文档结构。<details>
<summary>Abstract</summary>
This study outlines a comprehensive methodology for verifying medical documents, integrating advanced techniques in template extraction, comparison, and fraud detection. It begins with template extraction using sophisticated region-of-interest (ROI) methods, incorporating contour analysis and edge identification. Pre-processing steps ensure template clarity through morphological operations and adaptive thresholding. The template comparison algorithm utilizes advanced feature matching with key points and descriptors, enhancing robustness through histogram-based analysis for accounting variations. Fraud detection involves the SSIM computation and OCR for textual information extraction. The SSIM quantifies structural similarity, aiding in potential match identification. OCR focuses on critical areas like patient details, provider information, and billing amounts. Extracted information is compared with a reference dataset, and confidence thresholding ensures reliable fraud detection. Adaptive parameters enhance system flexibility for dynamic adjustments to varying document layouts. This methodology provides a robust approach to medical document verification, addressing complexities in template extraction, comparison, fraud detection, and adaptability to diverse document structures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Template extraction using sophisticated ROI methods, including contour analysis and edge identification, to ensure template clarity.2. Pre-processing steps such as morphological operations and adaptive thresholding to enhance template quality.3. Template comparison using advanced feature matching with key points and descriptors, followed by histogram-based analysis to account for variations.4. Fraud detection involving the computation of SSIM (Structural Similarity Index Measure) and OCR (Optical Character Recognition) for textual information extraction.5. Comparison of extracted information with a reference dataset, and confidence thresholding to ensure reliable fraud detection.6. Adaptive parameters to enhance system flexibility and allow for dynamic adjustments to varying document layouts.This methodology provides a robust approach to medical document verification, addressing the complexities in template extraction, comparison, fraud detection, and adaptability to diverse document structures.</details></li>
</ol>
<hr>
<h2 id="Visually-Guided-Object-Grasping"><a href="#Visually-Guided-Object-Grasping" class="headerlink" title="Visually Guided Object Grasping"></a>Visually Guided Object Grasping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12660">http://arxiv.org/abs/2311.12660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Radu Horaud, Fadi Dornaika, Bernard Espiau</li>
<li>for: 本研究旨在提出一种视觉控制方法，用于对物体抓取和精确对接两个实体的问题。</li>
<li>methods: 本方法基于Espiau等人提出的方法，并在摄像头不安装在控制机器人上的情况下进行扩展。我们强调实时计算图形Jacobian的重要性。</li>
<li>results: 我们表示了一种用于描述三维对象的抓取或对接的3D对应空间表示方法，使用不准备 camera参数的单镜照相机。这种3D对应空间表示方法是视觉无关的，可以轻松地将图像集成为准确的设定。此外，我们还进行了视觉控制算法的性能分析和抓取精度的预测。<details>
<summary>Abstract</summary>
In this paper we present a visual servoing approach to the problem of object grasping and more generally, to the problem of aligning an end-effector with an object. First we extend the method proposed by Espiau et al. [1] to the case of a camera which is not mounted onto the robot being controlled and we stress the importance of the real-time estimation of the image Jacobian. Second, we show how to represent a grasp or more generally, an alignment between two solids in 3-D projective space using an uncalibrated stereo rig. Such a 3-D projective representation is view-invariant in the sense that it can be easily mapped into an image set-point without any knowledge about the camera parameters. Third, we perform an analysis of the performances of the visual servoing algorithm and of the grasping precision that can be expected from this type of approach.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种视Servoing方法来解决物体抓取和更广泛的对着器与物体的对齐问题。首先，我们对Espiau等人的方法进行了扩展，并在Camera不 mounted onto the robot being controlled的情况下进行了详细的讨论。其次，我们示出了如何使用无加工stereo rig来表示一个抓或更广泛的对两个物体的对齐在3D项目空间中。这种3D项目空间表示是视点不变的，可以无需了解相机参数直接映射到图像集点。最后，我们进行了视Servoing算法的性能分析和抓取精度的预期分析。
</details></li>
</ul>
<hr>
<h2 id="Hand-Eye-Calibration"><a href="#Hand-Eye-Calibration" class="headerlink" title="Hand-Eye Calibration"></a>Hand-Eye Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12655">http://arxiv.org/abs/2311.12655</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IFL-CAMP/easy_handeye">https://github.com/IFL-CAMP/easy_handeye</a></li>
<li>paper_authors: Radu Horaud, Fadi Dornaika</li>
<li>for: 这篇论文是关于机器人手上的感器尺度准确性问题的研究。</li>
<li>methods: 该论文提出了两种解决手机器人尺度准确性问题的方法：一种是将摄像头视角矩阵与机器人手的尺度矩阵相multiply，另一种是使用非线性优化方法同时解决摄像头视角和机器人手尺度的问题。</li>
<li>results: 该论文通过稳定性分析，发现非线性优化方法比线性方法更加稳定，可以更好地抵制噪声和测量误差。<details>
<summary>Abstract</summary>
Whenever a sensor is mounted on a robot hand it is important to know the relationship between the sensor and the hand. The problem of determining this relationship is referred to as hand-eye calibration, which is important in at least two types of tasks: (i) map sensor centered measurements into the robot workspace and (ii) allow the robot to precisely move the sensor. In the past some solutions were proposed in the particular case of a camera. With almost no exception, all existing solutions attempt to solve the homogeneous matrix equation AX=XB. First we show that there are two possible formulations of the hand-eye calibration problem. One formulation is the classical one that we just mentioned. A second formulation takes the form of the following homogeneous matrix equation: MY=M'YB. The advantage of the latter is that the extrinsic and intrinsic camera parameters need not be made explicit. Indeed, this formulation directly uses the 3 by 4 perspective matrices (M and M') associated with two positions of the camera. Moreover, this formulation together with the classical one cover a wider range of camera-based sensors to be calibrated with respect to the robot hand. Second, we develop a common mathematical framework to solve for the hand-eye calibration problem using either of the two formulations. We present two methods, (i) a rotation then translation and (ii) a non-linear solver for rotation and translation. Third, we perform a stability analysis both for our two methods and for the classical linear method developed. In the light of this comparison, the non-linear optimization method, that solves for rotation and translation simultaneously, seems to be the most robust one with respect to noise and to measurement errors.
</details>
<details>
<summary>摘要</summary>
当感测器安装在机器人手上时，必须了解感测器和手的关系。这个问题被称为手眼准备，它在至少两种任务中很重要：（i）将感测器中的测量转换到机器人工作空间中，（ii）让机器人准确地移动感测器。在过去，一些解决方案在特定情况下使用摄像头。大多数现有的解决方案都尝试解决homogeneous matrix equation AX=XB。我们首先表明了手眼准备问题的两种可能的形式化。一种形式是我们已经提到的经典形式。另一种形式为以下homogeneous matrix equation：MY=M'YB。这种形式的优点在于感测器和机器人手之间的外部和内部参数不需要显式地指定。实际上，这种形式直接使用机器人手上的3x4 perspective matrices（M和M'），它们与摄像头的两个位置相关。此外，这种形式与经典形式共同覆盖了更多的摄像头基于的感测器需要与机器人手进行准备。二、我们开发了一个共同的数学框架来解决手眼准备问题，使用任一种形式化。我们提出了两种方法：（i）先转换 rotation then translation，（ii）非线性优化方法。三、我们进行了稳定性分析，包括我们两种方法和经典线性方法。在这种比较下，非线性优化方法，同时解决 rotation和 translation，显示对噪声和测量错误更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Polyhedral-Object-Recognition-by-Indexing"><a href="#Polyhedral-Object-Recognition-by-Indexing" class="headerlink" title="Polyhedral Object Recognition by Indexing"></a>Polyhedral Object Recognition by Indexing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12641">http://arxiv.org/abs/2311.12641</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/crowdbotics-dev/abd-231102-s1-dev-126419">https://github.com/crowdbotics-dev/abd-231102-s1-dev-126419</a></li>
<li>paper_authors: Radu Horaud, Humberto Sossa</li>
<li>for: 本文解决了计算机视觉中的图像索引问题，即从2D图像中识别3D多面体对象。</li>
<li>methods: 本文提出了一种基于多项式特征化和哈希函数的图像索引方法，用于识别多面体对象。</li>
<li>results: 实验结果表明，该方法可以快速和准确地识别多面体对象从2D图像中。<details>
<summary>Abstract</summary>
In computer vision, the indexing problem is the problem of recognizing a few objects in a large database of objects while avoiding the help of the classical image-feature-to-object-feature matching paradigm. In this paper we address the problem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both the objects to be recognized and the images are represented by weighted graphs. The indexing problem is therefore the problem of determining whether a graph extracted from the image is present or absent in a database of model graphs. We introduce a novel method for performing this graph indexing process which is based both on polynomial characterization of binary and weighted graphs and on hashing. We describe in detail this polynomial characterization and then we show how it can be used in the context of polyhedral object recognition. Next we describe a practical recognition-by-indexing system that includes the organization of the database, the representation of polyhedral objects in terms of 2-D characteristic views, the representation of this views in terms of weighted graphs, and the associated image processing. Finally, some experimental results allow the evaluation of the system performance.
</details>
<details>
<summary>摘要</summary>
To solve this problem, we propose a novel method that combines polynomial characterization of binary and weighted graphs with hashing. We provide a detailed description of this polynomial characterization and demonstrate how it can be applied in the context of polyhedral object recognition.Our practical recognition-by-indexing system includes the organization of the database, the representation of polyhedral objects in terms of 2D characteristic views, the representation of these views as weighted graphs, and the associated image processing. We also present experimental results to evaluate the performance of our system.
</details></li>
</ul>
<hr>
<h2 id="GPT4Motion-Scripting-Physical-Motions-in-Text-to-Video-Generation-via-Blender-Oriented-GPT-Planning"><a href="#GPT4Motion-Scripting-Physical-Motions-in-Text-to-Video-Generation-via-Blender-Oriented-GPT-Planning" class="headerlink" title="GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning"></a>GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12631">http://arxiv.org/abs/2311.12631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Lv, Yi Huang, Mingfu Yan, Jiancheng Huang, Jianzhuang Liu, Yifan Liu, Yafei Wen, Xiaoxin Chen, Shifeng Chen</li>
<li>for: 提高文本至视频生成质量，增强视频的物理运动准确性和实体一致性。</li>
<li>methods: 利用大语言模型GPT-4生成Blender脚本，基于文本提示 commanded Blender的物理引擎生成基本场景元素，然后通过稳定扩散来生成视频。</li>
<li>results: 在三种基本物理运动场景中（块体落下与碰撞、布料摆倒与摆动、液体流动），GPT4Motion可以高效生成高质量视频，保持运动准确性和实体一致性。<details>
<summary>Abstract</summary>
Recent advances in text-to-video generation have harnessed the power of diffusion models to create visually compelling content conditioned on text prompts. However, they usually encounter high computational costs and often struggle to produce videos with coherent physical motions. To tackle these issues, we propose GPT4Motion, a training-free framework that leverages the planning capability of large language models such as GPT, the physical simulation strength of Blender, and the excellent image generation ability of text-to-image diffusion models to enhance the quality of video synthesis. Specifically, GPT4Motion employs GPT-4 to generate a Blender script based on a user textual prompt, which commands Blender's built-in physics engine to craft fundamental scene components that encapsulate coherent physical motions across frames. Then these components are inputted into Stable Diffusion to generate a video aligned with the textual prompt. Experimental results on three basic physical motion scenarios, including rigid object drop and collision, cloth draping and swinging, and liquid flow, demonstrate that GPT4Motion can generate high-quality videos efficiently in maintaining motion coherency and entity consistency. GPT4Motion offers new insights in text-to-video research, enhancing its quality and broadening its horizon for future explorations.
</details>
<details>
<summary>摘要</summary>
最近的文本到视频生成技术发展，利用了扩散模型来创造基于文本提示的视觉吸引人的内容。然而，它们通常会遇到高计算成本，并且往往难以生成具有连贯的物理动作的视频。为了解决这些问题，我们提出了GPT4Motion，一个无需训练的框架，利用大型自然语言模型 such as GPT的规划能力，Blender的物理渲染力和文本到图像扩散模型的优秀图像生成能力，以提高视频合成的质量。具体来说，GPT4Motion使用GPT-4生成基于用户文本提示的Blender脚本，这个脚本命令Blender的内置物理引擎来生成基于文本提示的场景元素，这些元素包括连续的物理动作。然后，这些元素被输入到稳定扩散模型中，以生成与文本提示相对应的视频。实验结果表明，GPT4Motion可以高效地生成高质量的视频，同时保持动作准确性和实体一致性。GPT4Motion为文本到视频研究提供了新的突破，提高了其质量和扩展了未来的探索领域。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Generalization-Gaps-in-High-Content-Imaging-Through-Online-Self-Supervised-Domain-Adaptation"><a href="#Bridging-Generalization-Gaps-in-High-Content-Imaging-Through-Online-Self-Supervised-Domain-Adaptation" class="headerlink" title="Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation"></a>Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12623">http://arxiv.org/abs/2311.12623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johan Fredin Haslum, Christos Matsoukas, Karl-Johan Leuchowius, Kevin Smith</li>
<li>for: This paper aims to address the challenges of applying machine learning models to high content imaging (HCI) datasets in drug discovery and development pipelines, specifically the problem of domain shift due to differences in imaging equipment.</li>
<li>methods: The proposed method, CODA, is an online self-supervised domain adaptation approach that separates the classifier into a generic feature extractor and a task-specific model. CODA adapts the feature extractor’s weights to the new domain using cross-batch self-supervision, while keeping the task-specific model unchanged.</li>
<li>results: The results show that CODA significantly reduces the generalization gap, achieving up to a 300% improvement when applied to data from different labs utilizing different microscopes. CODA can be applied to new, unlabeled out-of-domain data sources of different sizes, from a single plate to multiple experimental batches.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是解决应用机器学习模型到高内容成像（HCI）数据集中的问题，具体是因为不同的探针设备而导致的领域shift。</li>
<li>methods: 提议的方法是CODA，它是一种在线自动适应领域方法，将分类器分为通用特征提取器和任务特定模型。CODA将通用特征提取器的参数适应新领域使用交叉批自监督，保持任务特定模型不变。</li>
<li>results: 结果表明，CODA可以显著减少总体差距，在不同实验室使用不同探针的数据上达到300%的提升。CODA可以应用到新、无标签的外域数据源，不同的大小，从单个板到多个实验批。<details>
<summary>Abstract</summary>
High Content Imaging (HCI) plays a vital role in modern drug discovery and development pipelines, facilitating various stages from hit identification to candidate drug characterization. Applying machine learning models to these datasets can prove challenging as they typically consist of multiple batches, affected by experimental variation, especially if different imaging equipment have been used. Moreover, as new data arrive, it is preferable that they are analyzed in an online fashion. To overcome this, we propose CODA, an online self-supervised domain adaptation approach. CODA divides the classifier's role into a generic feature extractor and a task-specific model. We adapt the feature extractor's weights to the new domain using cross-batch self-supervision while keeping the task-specific model unchanged. Our results demonstrate that this strategy significantly reduces the generalization gap, achieving up to a 300% improvement when applied to data from different labs utilizing different microscopes. CODA can be applied to new, unlabeled out-of-domain data sources of different sizes, from a single plate to multiple experimental batches.
</details>
<details>
<summary>摘要</summary>
高内容成像（HCI）在现代药物发现和开发流水线中扮演着重要的角色，涵盖各个阶段，从发现到候选药物特性化。在应用机器学习模型时，这些数据集通常包含多个批次，受到实验室内外部变量的影响，特别是使用不同的成像设备时。此外，随着新数据的到达，感知是在线模式下进行分析的。为解决这个问题，我们提出了CODA，一种在线无监督领域适应方法。CODA将分类器的角色分为通用特征提取器和任务特定模型。我们使用交叉批次自监督来适应特征提取器的加载，保持任务特定模型不变。我们的结果显示，这种策略可以减少泛化差距，达到300%的提高，当应用于不同实验室使用不同显微镜的数据时。CODA可以应用于新、无监督的外域数据源，不同的大小，从单个板到多个实验批次。
</details></li>
</ul>
<hr>
<h2 id="Crowd-management-crime-detection-work-monitoring-using-aiml"><a href="#Crowd-management-crime-detection-work-monitoring-using-aiml" class="headerlink" title="Crowd management, crime detection, work monitoring using aiml"></a>Crowd management, crime detection, work monitoring using aiml</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12621">http://arxiv.org/abs/2311.12621</a></li>
<li>repo_url: None</li>
<li>paper_authors: P. R. Adithya, Dheepak. S, B. Akash, Harshini. V, Sai Lakshana</li>
<li>for: 这项研究旨在利用现有的关闭电视（CCTV）网络，实现严格的人群管理、犯罪预防和工作场所监测，通过人工智能（AI）和机器学习（ML）技术的集成。</li>
<li>methods: 本研究使用了AI&#x2F;ML技术进行实时视频分析，以识别和评估人群动态、早期发现可能的犯罪活动，并持续监测工作环境。</li>
<li>results: 本研究通过实时视频分析，提高了公共安全措施和组织Productivity，并且可以在现有基础设施上进行改进，无需重大改进系统。<details>
<summary>Abstract</summary>
This research endeavors to harness the potential of existing Closed-Circuit Television (CCTV) networks for a comprehensive approach to crowd management, crime prevention, and workplace monitoring through the integration of Artificial Intelligence (AI) and Machine Learning (ML) technologies. The primary objective is to develop and implement advanced algorithms capable of real-time analysis of video feeds, enabling the identification and assessment of crowd dynamics, early detection of potential criminal activities, and continuous monitoring of workplace environments. By leveraging AI/ML, the project aims to optimize surveillance capabilities, thereby enhancing public safety measures and improving organizational productivity. This initiative underscores the transformative impact that intelligent video analytics can have on existing infrastructure, mitigating the need for extensive system overhauls while significantly advancing security and operational efficiency.
</details>
<details>
<summary>摘要</summary>
这项研究目标是利用现有的关闭回路电视（CCTV）网络来实现全面的人群管理、犯罪预防和工作场所监测，通过人工智能（AI）和机器学习（ML）技术的集成。项目的 PRIMARY 目标是开发并实施实时视频分析算法，以识别和评估人群动态、早期发现可能的犯罪活动和不断监测工作环境。通过利用 AI/ML，项目旨在提高Surveillance  capabilities，以提高公共安全措施和组织效率。该 initative  highlights  the transformative impact that intelligent video analytics can have on existing infrastructure， mitigating the need for extensive system overhauls while significantly advancing security and operational efficiency.
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Unlabeled-Data-for-3D-Medical-Image-Segmentation-through-Self-Supervised-Contrastive-Learning"><a href="#Leveraging-Unlabeled-Data-for-3D-Medical-Image-Segmentation-through-Self-Supervised-Contrastive-Learning" class="headerlink" title="Leveraging Unlabeled Data for 3D Medical Image Segmentation through Self-Supervised Contrastive Learning"></a>Leveraging Unlabeled Data for 3D Medical Image Segmentation through Self-Supervised Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12617">http://arxiv.org/abs/2311.12617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanaz Karimijafarbigloo, Reza Azad, Yury Velichko, Ulas Bagci, Dorit Merhof<br>for: 这篇研究目的是提出一种基于semi-supervised learning的3D图像分割方法，以解决现有方法忽略Contextual information和生成可靠pseudo-labels的问题。methods: 方法包括两个独立的子网络，用于探索和利用预测结果的不一致。具体来说，我们在预测结果不一致的地方进行了定向验证训练 процесс，以 corrected erroneous prediction results。此外，我们还使用了一种自动调整的contrastive learning方法，以提高网络的表达能力和预测uncertainty的降低。results: 我们通过对脑血管 segmentation task进行实验，使用了临床MRI和CT扫描数据，并证明了我们的方法的效果，比起现有方法更高。codebase可以在 \href{<a target="_blank" rel="noopener" href="https://github.com/xmindflow/SSL-contrastive%7D%7BGitHub%7D%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/xmindflow/SSL-contrastive}{GitHub}上找到。</a><details>
<summary>Abstract</summary>
Current 3D semi-supervised segmentation methods face significant challenges such as limited consideration of contextual information and the inability to generate reliable pseudo-labels for effective unsupervised data use. To address these challenges, we introduce two distinct subnetworks designed to explore and exploit the discrepancies between them, ultimately correcting the erroneous prediction results. More specifically, we identify regions of inconsistent predictions and initiate a targeted verification training process. This procedure strategically fine-tunes and harmonizes the predictions of the subnetworks, leading to enhanced utilization of contextual information. Furthermore, to adaptively fine-tune the network's representational capacity and reduce prediction uncertainty, we employ a self-supervised contrastive learning paradigm. For this, we use the network's confidence to distinguish between reliable and unreliable predictions. The model is then trained to effectively minimize unreliable predictions. Our experimental results for organ segmentation, obtained from clinical MRI and CT scans, demonstrate the effectiveness of our approach when compared to state-of-the-art methods. The codebase is accessible on \href{https://github.com/xmindflow/SSL-contrastive}{GitHub}.
</details>
<details>
<summary>摘要</summary>
当前的3D半监督分割方法面临着有限的上下文信息考虑和不可靠的 Pseudo-标签生成，从而影响其效果性的使用。为解决这些挑战，我们提出了两个不同的子网络，用于探索和利用它们之间的差异，最终 corrections 预测结果。更加具体地说，我们将预测结果中的不一致区域标识出来，并进行Targeted Verification Training进程。这个过程可以减少预测结果中的不确定性，并使用上下文信息进行协调。此外，为了适应性地自我调整网络的表达能力，我们使用了一种自动超参的自我超vised contrastive learning模型。在这个模型中，我们使用网络的信任度来 distinguishes 可靠和不可靠的预测结果，然后训练网络以最小化不可靠的预测结果。我们的实验结果，基于临床MRI和CT扫描数据，表明我们的方法在比较之前的方法的效果性。代码库可以在 \href{https://github.com/xmindflow/SSL-contrastive}{GitHub} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Dense-Pseudo-Label-Selection-for-Semi-supervised-Oriented-Object-Detection"><a href="#Adaptive-Dense-Pseudo-Label-Selection-for-Semi-supervised-Oriented-Object-Detection" class="headerlink" title="Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented Object Detection"></a>Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12608">http://arxiv.org/abs/2311.12608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Zhao, Qiang Fang, Shuohao Shi, Xin Xu</li>
<li>for: 这篇论文主要针对 semi-supervised object detection (SSOD) 问题，特别是在航空照片中常见的多向和紧密的物体上。</li>
<li>methods: 我们提出了 Adaptive Dense Pseudo Label Selection (ADPLS) 方法，包括专门设计的弹性机制，帮助选择精密的pseudo labels。我们还提出了对应的 Mean Feature-Richness Score (mFRS)，来估计潜在物体的密度。</li>
<li>results: 在 DOTA-v1.5 标准 benchmark 上，我们的方法比前一代方法更高，尤其是当 annotated data 仅有 5% 时。例如，我们在 5% annotated data 下 achieve 49.78 mAP，比以前的 state-of-the-art method 在 10% annotated data 下的result surpasses by 1.15 mAP。<details>
<summary>Abstract</summary>
Recently, dense pseudo-label, which directly selects pseudo labels from the original output of the teacher model without any complicated post-processing steps, has received considerable attention in semi-supervised object detection (SSOD). However, for the multi-oriented and dense objects that are common in aerial scenes, existing dense pseudo-label selection methods are inefficient and impede the performance in semi-supervised oriented object detection. Therefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for semi-supervised oriented object detection. In ADPLS, we design a simple but effective adaptive mechanism to guide the selection of dense pseudo labels. Specifically, we propose the mean Feature-Richness Score (mFRS) to estimate the density of potential objects and use this score to adjust the number of dense pseudo labels. On the DOTA-v1.5 benchmark, the proposed method outperforms previous methods especially when labeled data are scarce. For example, it achieves 49.78 mAP given only 5% of annotated data, which surpasses previous state-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will be available soon.
</details>
<details>
<summary>摘要</summary>
ADPLS features an adaptive mechanism that guides the selection of dense pseudo labels. Specifically, we introduce the mean Feature-Richness Score (mFRS) to estimate the density of potential objects and adjust the number of dense pseudo labels based on this score. Our approach outperforms previous methods, especially when labeled data are scarce. For example, on the DOTA-v1.5 benchmark, ADPLS achieves 49.78 mAP with only 5% of annotated data, surpassing the previous state-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will be available soon.
</details></li>
</ul>
<hr>
<h2 id="Surgical-Temporal-Action-aware-Network-with-Sequence-Regularization-for-Phase-Recognition"><a href="#Surgical-Temporal-Action-aware-Network-with-Sequence-Regularization-for-Phase-Recognition" class="headerlink" title="Surgical Temporal Action-aware Network with Sequence Regularization for Phase Recognition"></a>Surgical Temporal Action-aware Network with Sequence Regularization for Phase Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12603">http://arxiv.org/abs/2311.12603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Chen, Yuhao Zhai, Jun Zhang, Jinqiao Wang</li>
<li>For: 适用于助手在运作室中的干预computer-assisted surgical system，需要对医疗过程的详细理解。* Methods: 提出了一个名为STAR-Net的新网络模型，包括一个高效的多尺度医疗动作（MS-STA）模块和一个双检测器序列调整（DSR），可以对医疗动作进行更加精确的识别。* Results: 实验结果显示，STAR-Net在一个大规模的胃切除手术 dataset 和公共 Cholectc80 标准上实现了与之前的state-of-the-art的比较。<details>
<summary>Abstract</summary>
To assist surgeons in the operating theatre, surgical phase recognition is critical for developing computer-assisted surgical systems, which requires comprehensive understanding of surgical videos. Although existing studies made great progress, there are still two significant limitations worthy of improvement. First, due to the compromise of resource consumption, frame-wise visual features are extracted by 2D networks and disregard spatial and temporal knowledge of surgical actions, which hinders subsequent inter-frame modeling for phase prediction. Second, these works simply utilize ordinary classification loss with one-hot phase labels to optimize the phase predictions, and cannot fully explore surgical videos under inadequate supervision. To overcome these two limitations, we propose a Surgical Temporal Action-aware Network with sequence Regularization, named STAR-Net, to recognize surgical phases more accurately from input videos. Specifically, we propose an efficient multi-scale surgical temporal action (MS-STA) module, which integrates visual features with spatial and temporal knowledge of surgical actions at the cost of 2D networks. Moreover, we devise the dual-classifier sequence regularization (DSR) to facilitate the training of STAR-Net by the sequence guidance of an auxiliary classifier with a smaller capacity. Our STAR-Net with MS-STA and DSR can exploit visual features of surgical actions with effective regularization, thereby leading to the superior performance of surgical phase recognition. Extensive experiments on a large-scale gastrectomy surgery dataset and the public Cholec80 benchmark prove that our STAR-Net significantly outperforms state-of-the-arts of surgical phase recognition.
</details>
<details>
<summary>摘要</summary>
为帮助手术医生在操作室中工作，计算机助手手术系统的开发需要全面的了解手术视频。虽然现有的研究已经做出了很大的进步，但还有两个重要的限制值得进一步改进。首先，由于资源消耗的限制，使用2D网络提取帧级视觉特征，而忽略手术动作的空间和时间知识，这会阻碍后续的帧间模型化 для预测阶段。其次，这些工作都是使用一个简单的分类损失函数和一个热一颗分类器来优化阶段预测，无法充分利用手术视频的不足监督。为了解决这两个限制，我们提议一种名为STAR-Net的手术时间动作相关网络，可以更准确地从输入视频中识别手术阶段。具体来说，我们提出了一种高效的多级手术时间动作（MS-STA）模块，可以同时 интеграVisual特征和手术动作的空间和时间知识，而不是2D网络。此外，我们还提出了双类ifier序列化（DSR），以便通过auxiliary classifier的小容量导航，使STAR-Net在训练中更加有效地进行序列化。我们的STAR-Net with MS-STA and DSR可以有效地利用手术动作的视觉特征，并且通过有效的序列化，从而实现更高的手术阶段识别性。我们在一个大规模的胃手术手术数据集和公共的Cholec80数据集上进行了广泛的实验，证明了我们的STAR-Net在手术阶段识别方面具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="TouchSDF-A-DeepSDF-Approach-for-3D-Shape-Reconstruction-using-Vision-Based-Tactile-Sensing"><a href="#TouchSDF-A-DeepSDF-Approach-for-3D-Shape-Reconstruction-using-Vision-Based-Tactile-Sensing" class="headerlink" title="TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using Vision-Based Tactile Sensing"></a>TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using Vision-Based Tactile Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12602">http://arxiv.org/abs/2311.12602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mauro Comi, Yijiong Lin, Alex Church, Alessio Tonioni, Laurence Aitchison, Nathan F. Lepora</li>
<li>for: 本研究旨在提出一种数据驱动的战略，用于通过视觉感知器来探索和操纵物体，并使用深度学习来重建3D形状。</li>
<li>methods: 本研究使用了一种组合的方法，包括一个卷积神经网络和深度学习函数，以将战略图像转换为本地网格表示 superficies 的形状。</li>
<li>results: 本研究在实验和实际场景中能够成功地重建3D形状，并且可以在不同的材料和环境下进行robust 3D-aware表示和多模态感知。<details>
<summary>Abstract</summary>
Humans rely on their visual and tactile senses to develop a comprehensive 3D understanding of their physical environment. Recently, there has been a growing interest in exploring and manipulating objects using data-driven approaches that utilise high-resolution vision-based tactile sensors. However, 3D shape reconstruction using tactile sensing has lagged behind visual shape reconstruction because of limitations in existing techniques, including the inability to generalise over unseen shapes, the absence of real-world testing, and limited expressive capacity imposed by discrete representations. To address these challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D shape reconstruction that leverages the rich information provided by a vision-based tactile sensor and the expressivity of the implicit neural representation DeepSDF. Our technique consists of two components: (1) a Convolutional Neural Network that maps tactile images into local meshes representing the surface at the touch location, and (2) an implicit neural function that predicts a signed distance function to extract the desired 3D shape. This combination allows TouchSDF to reconstruct smooth and continuous 3D shapes from tactile inputs in simulation and real-world settings, opening up research avenues for robust 3D-aware representations and improved multimodal perception in robotics. Code and supplementary material are available at: https://touchsdf.github.io/
</details>
<details>
<summary>摘要</summary>
人类依靠视觉和感觉来发展一个完整的3D环境认知。现在，利用数据驱动的方法来探索和操作物体已经吸引了越来越多的关注。然而，使用感觉获取3D形状重建仍然落后于视觉形状重建，因为现有技术存在一些限制，如无法泛化到未经见过的形状、缺乏实际测试和精度表示的受限。为解决这些挑战，我们提出了TouchSDF，一种基于深度学习的感觉3D形状重建方法。我们的技术包括两部分：（1）一个 convolutional neural network 将感觉图像映射到触摸位置的表面的本地网格，和（2）一个隐藏层函数预测 signed distance function，以提取所需的3D形状。这种组合使得TouchSDF可以从感觉输入中提取平滑和连续的3D形状，在实际和模拟环境中进行重建，开启了robust 3D-aware表示和多模态感知的研究途径。代码和补充材料可以在以下链接中找到：https://touchsdf.github.io/
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-based-detection-of-morphological-features-associated-with-hypoxia-in-H-E-breast-cancer-whole-slide-images"><a href="#Deep-learning-based-detection-of-morphological-features-associated-with-hypoxia-in-H-E-breast-cancer-whole-slide-images" class="headerlink" title="Deep learning-based detection of morphological features associated with hypoxia in H&amp;E breast cancer whole slide images"></a>Deep learning-based detection of morphological features associated with hypoxia in H&amp;E breast cancer whole slide images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12601">http://arxiv.org/abs/2311.12601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Petru Manescu, Joseph Geradts, Delmiro Fernandez-Reyes</li>
<li>for: 这个研究用于评估乳癌组织中的衰竭水平，以及这种衰竭水平对肿瘤的生物学进程和临床进程的影响。</li>
<li>methods: 这个研究使用深度学习技术来评估乳癌组织中的衰竭水平。特别是，研究使用了弱监督深度学习（WSDL）模型来检测乳癌组织中的衰竭相关特征。</li>
<li>results: 研究结果表明，使用WSDL模型可以准确地检测乳癌组织中的衰竭相关特征。研究在240个乳癌主要站点的干片上训练和评估了深度多例学习模型，并在遗弃测试集上得到了0.87的AUC平均值。此外，研究还发现了衰竭和正常组织区域之间的显著差异。这种DL衰竭H&amp;E WSI检测模型可能可以扩展到其他肿瘤类型，并且可以轻松地在病理工作流程中integrated，无需额外的成本。<details>
<summary>Abstract</summary>
Hypoxia occurs when tumour cells outgrow their blood supply, leading to regions of low oxygen levels within the tumour. Calculating hypoxia levels can be an important step in understanding the biology of tumours, their clinical progression and response to treatment. This study demonstrates a novel application of deep learning to evaluate hypoxia in the context of breast cancer histomorphology. More precisely, we show that Weakly Supervised Deep Learning (WSDL) models can accurately detect hypoxia associated features in routine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and evaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue from breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on a left-out test set. We also showed significant differences between features of hypoxic and normoxic tissue regions as distinguished by the WSDL models. Such DL hypoxia H&E WSI detection models could potentially be extended to other tumour types and easily integrated into the pathology workflow without requiring additional costly assays.
</details>
<details>
<summary>摘要</summary>
肿瘤缺氧（hypoxia）发生在肿瘤细胞超出血液供应，导致肿瘤中的氧气水平降低。计算肿瘤缺氧水平是理解肿瘤生物学、临床进程和治疗效果的重要步骤。这项研究展示了深度学习在肿瘤 Histomorphology 中评估缺氧的新应用。具体来说，我们表明了弱监督深度学习（WSDL）模型可以准确地检测肿瘤缺氧相关特征在普通的 Hematoxylin and Eosin（H&E）整个扫描片像（WSI）中。我们使用了240个Breast cancer主病site的H&E扫描片图像进行训练和评估，得到了平均0.87的AUC在留下测试集中。我们还发现了肿瘤缺氧和正常细胞区域之间的差异，这些差异被WSDL模型所 отличи出。这些深度学习肿瘤H&E WSI检测模型可能可以扩展到其他肿瘤类型，并且可以轻松地integrated into Pathology workflow，不需要额外的昂贵的检测。
</details></li>
</ul>
<hr>
<h2 id="HiPose-Hierarchical-Binary-Surface-Encoding-and-Correspondence-Pruning-for-RGB-D-6DoF-Object-Pose-Estimation"><a href="#HiPose-Hierarchical-Binary-Surface-Encoding-and-Correspondence-Pruning-for-RGB-D-6DoF-Object-Pose-Estimation" class="headerlink" title="HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning for RGB-D 6DoF Object Pose Estimation"></a>HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning for RGB-D 6DoF Object Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12588">http://arxiv.org/abs/2311.12588</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongliang Lin, Yongzhi Su, Praveen Nathan, Sandeep Inuganti, Yan Di, Martin Sundermeyer, Fabian Manhardt, Didier Stricke, Jason Rambach, Yu Zhang</li>
<li>for: 6DoF object pose estimation from a single RGB-D image</li>
<li>methods: 使用 hierarchical binary surface encoding 和 point-to-surface matching 进行 dense-correspondence</li>
<li>results: 在多个公共benchmark上（LM-O、YCB-V、T-Less）表现出色，超过所有不需要重finement的方法，并且与高效的refinement-based方法匹配。 Code和模型将被释出。<details>
<summary>Abstract</summary>
In this work, we present a novel dense-correspondence method for 6DoF object pose estimation from a single RGB-D image. While many existing data-driven methods achieve impressive performance, they tend to be time-consuming due to their reliance on rendering-based refinement approaches. To circumvent this limitation, we present HiPose, which establishes 3D-3D correspondences in a coarse-to-fine manner with a hierarchical binary surface encoding. Unlike previous dense-correspondence methods, we estimate the correspondence surface by employing point-to-surface matching and iteratively constricting the surface until it becomes a correspondence point while gradually removing outliers. Extensive experiments on public benchmarks LM-O, YCB-V, and T-Less demonstrate that our method surpasses all refinement-free methods and is even on par with expensive refinement-based approaches. Crucially, our approach is computationally efficient and enables real-time critical applications with high accuracy requirements. Code and models will be released.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的粗粒匹配方法，用于基于单个RGB-D图像的6DoF物体pose估计。虽然许多现有的数据驱动方法已经实现了吸引人的性能，但它们往往因为依赖于渲染基于的精度提升方法而变得慢。为了缺乏这些限制，我们提出了HiPose，它在层次 binary 表示中进行粗粒匹配，并通过点到表面匹配和步进抑制表面直到它变成匹配点而逐渐移除异常点。与前一些粗粒匹配方法不同，我们不需要进行渲染基于的精度提升。我们的方法在公共benchmark LM-O、YCB-V 和 T-Less上进行了广泛的实验，并证明了我们的方法超过了所有不包括Refine的方法，并与较昂贵的Refine-based方法相当。这些方法的计算效率高，可以满足实时的应用需求。我们将释放代码和模型。
</details></li>
</ul>
<hr>
<h2 id="A-Region-of-Interest-Focused-Triple-UNet-Architecture-for-Skin-Lesion-Segmentation"><a href="#A-Region-of-Interest-Focused-Triple-UNet-Architecture-for-Skin-Lesion-Segmentation" class="headerlink" title="A Region of Interest Focused Triple UNet Architecture for Skin Lesion Segmentation"></a>A Region of Interest Focused Triple UNet Architecture for Skin Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12581">http://arxiv.org/abs/2311.12581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoqing Liu, Yu Guo, Caiying Wu, Guoqing Chen, Barintag Saheya, Qiyu Jin</li>
<li>for: 这篇论文的目的是提出一个自动标识皮肤病变的方法，以便进行皮肤病变分析和后续的治疗。</li>
<li>methods: 本论文提出了一个名为Triple-UNet的方法，它是三个UNet架构的有机结合。这三个UNet架构分别是第一个UNet、第二个UNet和第三个UNet。为了更好地融合第一个和第二个UNet的output，我们设计了一个区域增强模块（ROIE）。ROIE使用预测得分图来增强目标物体区域的影像，以帮助第二个UNet获得更好的得分图。最后，结果被第三个UNet进行精确化。</li>
<li>results: 我们对一个公开available的皮肤病变标识 dataset进行了实验，结果显示Triple-UNet比前一些方法在皮肤病变标识方面更高效。<details>
<summary>Abstract</summary>
Skin lesion segmentation is of great significance for skin lesion analysis and subsequent treatment. It is still a challenging task due to the irregular and fuzzy lesion borders, and diversity of skin lesions. In this paper, we propose Triple-UNet to automatically segment skin lesions. It is an organic combination of three UNet architectures with suitable modules. In order to concatenate the first and second sub-networks more effectively, we design a region of interest enhancement module (ROIE). The ROIE enhances the target object region of the image by using the predicted score map of the first UNet. The features learned by the first UNet and the enhanced image help the second UNet obtain a better score map. Finally, the results are fine-tuned by the third UNet. We evaluate our algorithm on a publicly available dataset of skin lesion segmentation. Experiments show that Triple-UNet outperforms the state-of-the-art on skin lesion segmentation.
</details>
<details>
<summary>摘要</summary>
皮肤损伤分割是皮肤损伤分析和后续治疗中的关键任务。然而，由于损伤边界的不规则和杂乱，以及皮肤损伤的多样性，这还是一项具有挑战性的任务。在这篇论文中，我们提议了Triple-UNet算法，用于自动分割皮肤损伤。这是三个UNet架构的有机组合，其中每个架构都具有适当的模块。为了更有效地连接第一和第二子网络，我们设计了一个区域增强模块（ROIE）。ROIE使用预测得分图来增强目标对象区域的图像，并使得第二子网络得到更好的分数图。最后，结果被第三子网络进行细化。我们在一个公共可用的皮肤损伤分割数据集上进行了实验，结果显示，Triple-UNet在皮肤损伤分割任务中超过了状态之前的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Multi-Resolution-Planar-Region-Extraction-for-Uneven-Terrains"><a href="#Multi-Resolution-Planar-Region-Extraction-for-Uneven-Terrains" class="headerlink" title="Multi-Resolution Planar Region Extraction for Uneven Terrains"></a>Multi-Resolution Planar Region Extraction for Uneven Terrains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12562">http://arxiv.org/abs/2311.12562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinghan Sun, Linfang Zheng, Hua Chen, Wei Zhang</li>
<li>for: 本研究旨在从不规则点云测量中提取平面区域，以解决机器人应用中的感知行进问题。</li>
<li>methods: 我们提出了一种多resolution平面区域提取策略，通过平衡精度和计算效率来解决过去方法的问题。我们的方法包括点 wise分类预处理模块和多resolution分 segmentation模块。</li>
<li>results: 我们通过实验表明，提出的方法可以在不同的不平坦地形上实现高效、稳定的平面区域提取，实现每帧超过35帧的帧率。<details>
<summary>Abstract</summary>
This paper studies the problem of extracting planar regions in uneven terrains from unordered point cloud measurements. Such a problem is critical in various robotic applications such as robotic perceptive locomotion. While existing approaches have shown promising results in effectively extracting planar regions from the environment, they often suffer from issues such as low computational efficiency or loss of resolution. To address these issues, we propose a multi-resolution planar region extraction strategy in this paper that balances the accuracy in boundaries and computational efficiency. Our method begins with a pointwise classification preprocessing module, which categorizes all sampled points according to their local geometric properties to facilitate multi-resolution segmentation. Subsequently, we arrange the categorized points using an octree, followed by an in-depth analysis of nodes to finish multi-resolution plane segmentation. The efficiency and robustness of the proposed approach are verified via synthetic and real-world experiments, demonstrating our method's ability to generalize effectively across various uneven terrains while maintaining real-time performance, achieving frame rates exceeding 35 FPS.
</details>
<details>
<summary>摘要</summary>
Our method begins with a pointwise classification preprocessing module, which categorizes all sampled points based on their local geometric properties to facilitate multi-resolution segmentation. We then arrange the categorized points using an octree, followed by an in-depth analysis of nodes to finish multi-resolution plane segmentation.We verify the efficiency and robustness of our approach through synthetic and real-world experiments, demonstrating its ability to generalize effectively across various uneven terrains while maintaining real-time performance, with frame rates exceeding 35 FPS.
</details></li>
</ul>
<hr>
<h2 id="Convolutional-Neural-Networks-for-Neuroimaging-in-Parkinson’s-Disease-Is-Preprocessing-Needed"><a href="#Convolutional-Neural-Networks-for-Neuroimaging-in-Parkinson’s-Disease-Is-Preprocessing-Needed" class="headerlink" title="Convolutional Neural Networks for Neuroimaging in Parkinson’s Disease: Is Preprocessing Needed?"></a>Convolutional Neural Networks for Neuroimaging in Parkinson’s Disease: Is Preprocessing Needed?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12561">http://arxiv.org/abs/2311.12561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francisco J. Martinez-Murcia, Juan M. Górriz, Javier Ramírez, Andrés Ortiz</li>
<li>for: 本研究旨在检验 convolutional neural networks (CNNs) 是否可以考虑空间和INTENSITY差异，并不需要进行常见的空间和INTENSITYNormalization处理。</li>
<li>methods: 本研究使用了四种不同的 CNN 模型，基于已知的架构，并或不使用不同的空间和INTENSITYNormalization处理。</li>
<li>results: 结果显示，一个足够复杂的模型，如我们的三维版本的 ALEXNET，可以有效地考虑空间差异，达到诊断精度为 94.1%，ROC曲线下的面积为 0.984。仔细分析结果，可以看出模型正确地找到与文献中的模式匹配，无需应用复杂的空间Normalization处理。然而，INTENSITYNormalization的选择和处理方法对结果和准确率产生了重要的影响。<details>
<summary>Abstract</summary>
Spatial and intensity normalization are nowadays a prerequisite for neuroimaging analysis. Influenced by voxel-wise and other univariate comparisons, where these corrections are key, they are commonly applied to any type of analysis and imaging modalities. Nuclear imaging modalities such as PET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease diagnosis, are especially dependent on intensity normalization. However, these steps are computationally expensive and furthermore, they may introduce deformations in the images, altering the information contained in them. Convolutional Neural Networks (CNNs), for their part, introduce position invariance to pattern recognition, and have been proven to classify objects regardless of their orientation, size, angle, etc. Therefore, a question arises: how well can CNNs account for spatial and intensity differences when analysing nuclear brain imaging? Are spatial and intensity normalization still needed? To answer this question, we have trained four different CNN models based on well-established architectures, using or not different spatial and intensity normalization preprocessing. The results show that a sufficiently complex model such as our three-dimensional version of the ALEXNET can effectively account for spatial differences, achieving a diagnosis accuracy of 94.1% with an area under the ROC curve of 0.984. The visualization of the differences via saliency maps shows that these models are correctly finding patterns that match those found in the literature, without the need of applying any complex spatial normalization procedure. However, the intensity normalization -- and its type -- is revealed as very influential in the results and accuracy of the trained model, and therefore must be well accounted.
</details>
<details>
<summary>摘要</summary>
现代神经成像分析中，空间和强度 норmalization 已成为必备的前提。这些 corrected 通常适用于所有类型的分析和成像模式。核lear imaging模式，如 PET-FDG 或 FP-CIT SPECT，特别dependent on intensity normalization，是 Parkinson's disease 诊断中常用的一种常见模式。然而，这些步骤可能会 computationally expensive 并且可能会将图像中的信息扭曲。 Convolutional Neural Networks (CNNs) 引入了位置不变性，以便 Pattern recognition 中减少了图像的影响。因此，一个问题出现：CNNs 能够考虑到空间和强度差异吗？是否还需要进行空间和强度 normalization ？为了回答这个问题，我们训练了四个不同的 CNN 模型，使用或不使用不同的空间和强度 normalization 预处理。结果表明，一个足够复杂的模型，如我们的三维版本的 ALEXNET，可以有效地考虑空间差异，达到诊断精度为 94.1%，ROC 曲线下的面积为 0.984。在 Visualization 中，这些模型可以正确地找到与文献中所描述的模式匹配的pattern，无需应用任何复杂的空间normalization 过程。然而，强度normalization 的类型和影响结果的准确性。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-bias-Expanding-clinical-AI-model-card-to-incorporate-bias-reporting-of-social-and-non-social-factors"><a href="#Benchmarking-bias-Expanding-clinical-AI-model-card-to-incorporate-bias-reporting-of-social-and-non-social-factors" class="headerlink" title="Benchmarking bias: Expanding clinical AI model card to incorporate bias reporting of social and non-social factors"></a>Benchmarking bias: Expanding clinical AI model card to incorporate bias reporting of social and non-social factors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12560">http://arxiv.org/abs/2311.12560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carolina A. M. Heming, Mohamed Abdalla, Monish Ahluwalia, Linglin Zhang, Hari Trivedi, MinJae Woo, Benjamin Fine, Judy Wawira Gichoya, Leo Anthony Celi, Laleh Seyyed-Kalantari</li>
<li>for: 这篇论文主要是关于扩展临床AI模型报告卡，以包括广泛的偏见报告，包括社交和非社交因素。</li>
<li>methods: 论文使用了AI模型，并使用了不同的方法来检测和报告偏见。</li>
<li>results: 论文发现，扩展报告卡可以帮助检测和解决AI模型中的偏见，并且可以提高AI模型的安全性和可靠性。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Clinical AI model reporting cards should be expanded to incorporate a broad bias reporting of both social and non-social factors. Non-social factors consider the role of other factors, such as disease dependent, anatomic, or instrument factors on AI model bias, which are essential to ensure safe deployment.
</details>
<details>
<summary>摘要</summary>
临床AI模型报告卡应该扩展到包括广泛的偏见报告，包括社会和非社会因素。非社会因素包括疾病依赖、解剖学因素和实验室因素等，这些因素对AI模型偏见的影响非常重要，以确保安全的部署。
</details></li>
</ul>
<hr>
<h2 id="“HoVer-UNet”-Accelerating-HoVerNet-with-UNet-based-multi-class-nuclei-segmentation-via-knowledge-distillation"><a href="#“HoVer-UNet”-Accelerating-HoVerNet-with-UNet-based-multi-class-nuclei-segmentation-via-knowledge-distillation" class="headerlink" title="“HoVer-UNet”: Accelerating HoVerNet with UNet-based multi-class nuclei segmentation via knowledge distillation"></a>“HoVer-UNet”: Accelerating HoVerNet with UNet-based multi-class nuclei segmentation via knowledge distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12553">http://arxiv.org/abs/2311.12553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/diagnijmegen/hover-unet">https://github.com/diagnijmegen/hover-unet</a></li>
<li>paper_authors: Cristian Tommasino, Cristiano Russo, Antonio Maria Rinaldi, Francesco Ciompi</li>
<li>for: 这个论文是为了提取多支分支 HoVerNet 框架中关于细胞实例分类和识别的知识，以提高 histopathology 领域中 nuclei 实例分类和识别的效率和准确率。</li>
<li>methods: 该论文提出了一种压缩式单个 UNet 网络，并在其中使用了 Mix Vision Transformer 核心，以优化编码 HoVerNet 中的知识。此外，该论文还提出了一种自定义损失函数，以优化模型的训练。</li>
<li>results: 该论文表明，使用 HoVer-UNet 模型可以在 PanNuke 和 Consep 公共数据集上实现与 HoVerNet 相当的性能，但是具有三倍减少的计算时间。code 可以在 <a target="_blank" rel="noopener" href="https://github.com/DIAGNijmegen/HoVer-UNet">https://github.com/DIAGNijmegen/HoVer-UNet</a> 上获取。<details>
<summary>Abstract</summary>
We present "HoVer-UNet", an approach to distill the knowledge of the multi-branch HoVerNet framework for nuclei instance segmentation and classification in histopathology. We propose a compact, streamlined single UNet network with a Mix Vision Transformer backbone, and equip it with a custom loss function to optimally encode the distilled knowledge of HoVerNet, reducing computational requirements without compromising performances. We show that our model achieved results comparable to HoVerNet on the public PanNuke and Consep datasets with a three-fold reduction in inference time. We make the code of our model publicly available at https://github.com/DIAGNijmegen/HoVer-UNet.
</details>
<details>
<summary>摘要</summary>
我们介绍了“HoVer-UNet”方法，用于在 Histopathology 中分类和实例化核体。我们提出了一个嵌入式、流lined的单个 UNet 网络，并将其与 Mix Vision Transformer 背bone结合使用。我们还提出了一个定制的损失函数，以优化压缩了 HoVerNet 的知识，降低计算成本而不妨碍性能。我们的模型在公共 PanNuke 和 Consep 数据集上达到了与 HoVerNet 相同的Result，但具有三倍减少的推理时间。我们将我们的代码公开于 GitHub 上，具体信息请参考 <https://github.com/DIAGNijmegen/HoVer-UNet>。
</details></li>
</ul>
<hr>
<h2 id="GMISeg-General-Medical-Image-Segmentation-without-Re-Training"><a href="#GMISeg-General-Medical-Image-Segmentation-without-Re-Training" class="headerlink" title="GMISeg: General Medical Image Segmentation without Re-Training"></a>GMISeg: General Medical Image Segmentation without Re-Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12539">http://arxiv.org/abs/2311.12539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Xu</li>
<li>for: 解决医疗图像分割领域中 unknown 任务，即新的组织结构、图像形态或标签等。</li>
<li>methods: 提出了一种基于 SAM（Segment Anything Model）图像编码器的 novel low-rank 精度调整策略，与提示编码器和面减解编码器结合使用，以 Fine-tune 已经标注的数据集而无需进一步训练。</li>
<li>results: GMISeg 在 unknown 任务中表现出优于最新方法，并进行了对方法的全面分析和总结。<details>
<summary>Abstract</summary>
Although deep learning models have become the main method for medical image segmentation, they often cannot be extended to unknown segmentation tasks involving new anatomical structures, image shapes, or labels. For new segmentation tasks, researchers often have to retrain or fine-tune the model, which is time-consuming and poses a significant obstacle to clinical researchers, who often lack the resources and professional knowledge to train neural networks. Therefore, we proposed a general method that can solve unknown medical image segmentation tasks without requiring additional training. Given an example set of images and prompts for defining new segmentation tasks, GMISeg applies a novel low-rank fine-tuning strategy based on the proposed approach to the SAM (Segment Anything Model) image encoder, and works with the prompt encoder and mask decoder to fine-tune the labeled dataset without the need for additional training. To achieve generalization of new tasks, we used medical image datasets with different imaging modes for different parts. We trained and generalized GMISeg on a different set of anatomical and imaging modes using cardiac images on other site datasets. We have demonstrated that GMISeg outperforms the latest methods on unknown tasks and have conducted a comprehensive analysis and summary of the important performance of the proposed method.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)尽管深度学习模型已成为医学图像分割的主要方法，但它们经常无法适应未知的分割任务，包括新的解剖结构、图像形态和标签。为新的分割任务，研究人员经常需要重新训练或微调模型，这是时间consuming的并且对临床研究人员来说是一个重大障碍，他们通常缺乏训练神经网络的资源和专业知识。因此，我们提出了一种可以解决未知医学图像分割任务的通用方法。给出了示例集合和用于定义新分割任务的提示，GMISeg应用了一种新的低级别微调策略，基于我们提出的方法，与提示编码器和掩码解码器一起微调已标注数据集，而不需要额外的训练。为实现新任务的总体化，我们使用了不同的医学图像数据集，包括不同的解剖和扫描模式。我们在不同的部位和扫描模式上训练和总结GMISeg，并示出了GMISeg在未知任务上的性能比latest方法更高，并进行了完整的分析和总结。
</details></li>
</ul>
<hr>
<h2 id="Hyb-NeRF-A-Multiresolution-Hybrid-Encoding-for-Neural-Radiance-Fields"><a href="#Hyb-NeRF-A-Multiresolution-Hybrid-Encoding-for-Neural-Radiance-Fields" class="headerlink" title="Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields"></a>Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12490">http://arxiv.org/abs/2311.12490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Wang, Yi Gong, Yuan Zeng</li>
<li>for: 高精度场景重建和新视图合成</li>
<li>methods: 使用多分辨率混合编码，并使用快速优化和本地细节快速学习 Positional 特征，以及使用 cone tracing 特征来消除编码混乱和减少抖音artefacts</li>
<li>results: 在 synthetic 和实际数据集上实现更快的渲染速度，同时维护高质量渲染效果和更低的内存占用率，与之前的状态态method 相比<details>
<summary>Abstract</summary>
Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity scene reconstruction for novel view synthesis. However, NeRF requires hundreds of network evaluations per pixel to approximate a volume rendering integral, making it slow to train. Caching NeRFs into explicit data structures can effectively enhance rendering speed but at the cost of higher memory usage. To address these issues, we present Hyb-NeRF, a novel neural radiance field with a multi-resolution hybrid encoding that achieves efficient neural modeling and fast rendering, which also allows for high-quality novel view synthesis. The key idea of Hyb-NeRF is to represent the scene using different encoding strategies from coarse-to-fine resolution levels. Hyb-NeRF exploits memory-efficiency learnable positional features at coarse resolutions and the fast optimization speed and local details of hash-based feature grids at fine resolutions. In addition, to further boost performance, we embed cone tracing-based features in our learnable positional encoding that eliminates encoding ambiguity and reduces aliasing artifacts. Extensive experiments on both synthetic and real-world datasets show that Hyb-NeRF achieves faster rendering speed with better rending quality and even a lower memory footprint in comparison to previous state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Hyb-NeRF represents the scene using different encoding strategies from coarse-to-fine resolution levels. It exploits memory-efficiency learnable positional features at coarse resolutions and the fast optimization speed and local details of hash-based feature grids at fine resolutions. Additionally, to further boost performance, we embed cone tracing-based features in our learnable positional encoding, which eliminates encoding ambiguity and reduces aliasing artifacts.Extensive experiments on both synthetic and real-world datasets show that Hyb-NeRF achieves faster rendering speed with better rendering quality and even a lower memory footprint compared to previous state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="HCA-Net-Hierarchical-Context-Attention-Network-for-Intervertebral-Disc-Semantic-Labeling"><a href="#HCA-Net-Hierarchical-Context-Attention-Network-for-Intervertebral-Disc-Semantic-Labeling" class="headerlink" title="HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc Semantic Labeling"></a>HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc Semantic Labeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12486">http://arxiv.org/abs/2311.12486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Afshin Bozorgpour, Bobby Azad, Reza Azad, Yury Velichko, Ulas Bagci, Dorit Merhof</li>
<li>for: 这篇论文的目的是提出一个新的内容关注网络架构（HCA-Net），用于医疗影像中的脊椎突出物（IVD）的semantic标签。</li>
<li>methods: HCA-Net使用了对各个IVD的估计，将IVD标签视为一个位置估计问题，并使用了骨骼损失函数来强制模型对骨架的几何依赖。</li>
<li>results: 在多中心脊椎数据集上进行了广泛的实验评估，HCA-Net的方法与之前的州OF-the-art方法相比，在MRI T1w和T2wmodalities上均有优秀的表现。<details>
<summary>Abstract</summary>
Accurate and automated segmentation of intervertebral discs (IVDs) in medical images is crucial for assessing spine-related disorders, such as osteoporosis, vertebral fractures, or IVD herniation. We present HCA-Net, a novel contextual attention network architecture for semantic labeling of IVDs, with a special focus on exploiting prior geometric information. Our approach excels at processing features across different scales and effectively consolidating them to capture the intricate spatial relationships within the spinal cord. To achieve this, HCA-Net models IVD labeling as a pose estimation problem, aiming to minimize the discrepancy between each predicted IVD location and its corresponding actual joint location. In addition, we introduce a skeletal loss term to reinforce the model's geometric dependence on the spine. This loss function is designed to constrain the model's predictions to a range that matches the general structure of the human vertebral skeleton. As a result, the network learns to reduce the occurrence of false predictions and adaptively improves the accuracy of IVD location estimation. Through extensive experimental evaluation on multi-center spine datasets, our approach consistently outperforms previous state-of-the-art methods on both MRI T1w and T2w modalities. The codebase is accessible to the public on \href{https://github.com/xmindflow/HCA-Net}{GitHub}.
</details>
<details>
<summary>摘要</summary>
医学影像中间 vertebral discs（IVD）的准确和自动化分割是评估脊梗疾病的关键，如骨质疏松、vertebral fractures或IVD herniation。我们提出了HCA-Net，一种新的含义 Labeling 网络架构，强调利用先前的几何信息。我们的方法可以处理不同的比例和缩放因子，并将其集成起来，以捕捉脊梗中的复杂的空间关系。为此，HCA-Net 将 IVD 标注作为一个pose estimation问题，以最小化每个预测的 IVD 位置与其对应的实际联合位置之间的差异。此外，我们引入了一个骨架损失函数，以加强模型的几何依赖于脊梗。这个损失函数是设计来限制模型的预测在一个匹配人类脊梗骨架的范围内。因此，网络将学习减少false预测的发生，并适应IVD位置估计的准确性。经过对多中心脊梗数据集的广泛实验评估，我们的方法在 T1w 和 T2w 模态上都能够稳定地超越前一代的状态态势。代码库可以在 \href{https://github.com/xmindflow/HCA-Net}{GitHub} 上获取。
</details></li>
</ul>
<hr>
<h2 id="MaskFlow-Object-Aware-Motion-Estimation"><a href="#MaskFlow-Object-Aware-Motion-Estimation" class="headerlink" title="MaskFlow: Object-Aware Motion Estimation"></a>MaskFlow: Object-Aware Motion Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12476">http://arxiv.org/abs/2311.12476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aria Ahmadi, David R. Walton, Tim Atherton, Cagatay Dikici</li>
<li>for: 估计高精度动态场景中的物体运动场景，尤其是小物体、大移动和快速变化的情况下的准确运动场景估计。</li>
<li>methods: MaskFlow方法使用了对象级别特征和分割，并将其用于估计物体的翻译运动场景。该方法还提出了一种新的把部分翻译运动场景引入后续运动估计网络进行精度调整的方法。</li>
<li>results: MaskFlow方法在我们新的挑战性 synthetic 数据集上测试，与状态 Künstler 的方法相比，在准确性和稳定性方面均有较好的表现，而且在流行的 FlyingThings3D 数据集上也能够达到相似的结果。<details>
<summary>Abstract</summary>
We introduce a novel motion estimation method, MaskFlow, that is capable of estimating accurate motion fields, even in very challenging cases with small objects, large displacements and drastic appearance changes. In addition to lower-level features, that are used in other Deep Neural Network (DNN)-based motion estimation methods, MaskFlow draws from object-level features and segmentations. These features and segmentations are used to approximate the objects' translation motion field. We propose a novel and effective way of incorporating the incomplete translation motion field into a subsequent motion estimation network for refinement and completion. We also produced a new challenging synthetic dataset with motion field ground truth, and also provide extra ground truth for the object-instance matchings and corresponding segmentation masks. We demonstrate that MaskFlow outperforms state of the art methods when evaluated on our new challenging dataset, whilst still producing comparable results on the popular FlyingThings3D benchmark dataset.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的动作估计方法，MaskFlow，可以准确地估计动作场景，即使是非常困难的情况下，包括小物体、大偏移和悬峰变化。除了低级特征，其他深度神经网络（DNN）基于动作估计方法使用的特征之外，MaskFlow还利用了物体级别特征和分割。这些特征和分割用于估计物体的翻译动作场景。我们提出了一种新的和有效的方法，将部分动作场景纳入后续动作估计网络进行修正和完善。我们还生成了一个新的挑战性的 sintetic 数据集，并提供了对象匹配和相应的分割Masks的附加真实的地面实据。我们示示了MaskFlow在我们新的挑战性数据集上的表现优于当前状态的方法，而仍然在Popular FlyingThings3D 数据集上Produce相似的结果。
</details></li>
</ul>
<hr>
<h2 id="GLAD-Global-Local-View-Alignment-and-Background-Debiasing-for-Unsupervised-Video-Domain-Adaptation-with-Large-Domain-Gap"><a href="#GLAD-Global-Local-View-Alignment-and-Background-Debiasing-for-Unsupervised-Video-Domain-Adaptation-with-Large-Domain-Gap" class="headerlink" title="GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation with Large Domain Gap"></a>GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation with Large Domain Gap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12467">http://arxiv.org/abs/2311.12467</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khuvll/glad">https://github.com/khuvll/glad</a></li>
<li>paper_authors: Hyogun Lee, Kyungho Bae, Seongjong Ha, Yumin Ko, Gyeongmoon Park, Jinwoo Choi</li>
<li>for: 这个研究是针对无监督类别影片领域对应（UVDA）进行探索，专注于具有较大领域差距的情况，而非现有的工作主要是处理小领域差距。</li>
<li>methods: 我们提出了一种全新的UVDA情况，称为Kinetics-&gt;BABEL，具有更大的领域差距，包括时间动态和背景的类别变化。我们解决时间差距的问题，我们提出了全球-本地视野对齐方法，并通过时间顺序学习和背景增强来减少背景差距。</li>
<li>results: 我们验证了我们的提案在Kinetics-&gt;BABEL数据集上表现出色，与现有方法相比，具有较大的改善。<details>
<summary>Abstract</summary>
In this work, we tackle the challenging problem of unsupervised video domain adaptation (UVDA) for action recognition. We specifically focus on scenarios with a substantial domain gap, in contrast to existing works primarily deal with small domain gaps between labeled source domains and unlabeled target domains. To establish a more realistic setting, we introduce a novel UVDA scenario, denoted as Kinetics->BABEL, with a more considerable domain gap in terms of both temporal dynamics and background shifts. To tackle the temporal shift, i.e., action duration difference between the source and target domains, we propose a global-local view alignment approach. To mitigate the background shift, we propose to learn temporal order sensitive representations by temporal order learning and background invariant representations by background augmentation. We empirically validate that the proposed method shows significant improvement over the existing methods on the Kinetics->BABEL dataset with a large domain gap. The code is available at https://github.com/KHUVLL/GLAD.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们面临着无监督视频领域适应（UVDA）问题的挑战。我们专门关注具有较大领域差异的场景，而不是现有工作主要面临小领域差异 между标注源领域和无标注目标领域。为建立更真实的设定，我们介绍了一个新的 UVDA 场景，称为 Kinetics->BABEL，它具有更大的领域差异以及时间动态和背景偏移。为解决时间偏移问题，即源频率和目标频率之间的动作持续时间差异，我们提议一种全局本地视图匹配方法。为减少背景偏移，我们提议通过时间顺序学习和背景扩展来学习时间顺序敏感的表示和背景不变的表示。我们经验 validate 表示我们提出的方法在 Kinetics->BABEL 数据集上显示出了明显的改进。代码可以在 <https://github.com/KHUVLL/GLAD> 上获取。
</details></li>
</ul>
<hr>
<h2 id="HiFi-Syn-Hierarchical-Granularity-Discrimination-for-High-Fidelity-Synthesis-of-MR-Images-with-Structure-Preservation"><a href="#HiFi-Syn-Hierarchical-Granularity-Discrimination-for-High-Fidelity-Synthesis-of-MR-Images-with-Structure-Preservation" class="headerlink" title="HiFi-Syn: Hierarchical Granularity Discrimination for High-Fidelity Synthesis of MR Images with Structure Preservation"></a>HiFi-Syn: Hierarchical Granularity Discrimination for High-Fidelity Synthesis of MR Images with Structure Preservation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12461">http://arxiv.org/abs/2311.12461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Yu, Botao Zhao, Shengjie Zhang, Xiang Chen, Jianfeng Feng, Tingying Peng, Xiao-Yong Zhang</li>
<li>for: 本研究旨在提高医疗图像的同构翻译，以保持医疗图像中的结构信息。</li>
<li>methods: 我们介绍了层次划分精度，利用不同层次的semantic信息，以及一种重要权重策略来保持医疗图像的结构准确性。</li>
<li>results: 我们的方法在三个独立的数据集（UK Biobank、IXI和BraTS 2018）上进行了测试，并表现出优于当前最佳方法。特别是，我们的模型不仅能够同构正常结构，还能够处理异常（疾病）结构，如脑肿瘤，并且在不同的医疗成像Modalities上具有较高的医学价值。<details>
<summary>Abstract</summary>
Synthesizing medical images while preserving their structural information is crucial in medical research. In such scenarios, the preservation of anatomical content becomes especially important. Although recent advances have been made by incorporating instance-level information to guide translation, these methods overlook the spatial coherence of structural-level representation and the anatomical invariance of content during translation. To address these issues, we introduce hierarchical granularity discrimination, which exploits various levels of semantic information present in medical images. Our strategy utilizes three levels of discrimination granularity: pixel-level discrimination using a Brain Memory Bank, structure-level discrimination on each brain structure with a re-weighting strategy to focus on hard samples, and global-level discrimination to ensure anatomical consistency during translation. The image translation performance of our strategy has been evaluated on three independent datasets (UK Biobank, IXI, and BraTS 2018), and it has outperformed state-of-the-art algorithms. Particularly, our model excels not only in synthesizing normal structures but also in handling abnormal (pathological) structures, such as brain tumors, despite the variations in contrast observed across different imaging modalities due to their pathological characteristics. The diagnostic value of synthesized MR images containing brain tumors has been evaluated by radiologists. This indicates that our model may offer an alternative solution in scenarios where specific MR modalities of patients are unavailable. Extensive experiments further demonstrate the versatility of our method, providing unique insights into medical image translation.
</details>
<details>
<summary>摘要</summary>
医学图像合成是医学研究中非常重要的一环，特别是保持图像结构信息的重要性。虽然最新的进展已经通过使用实例级信息来引导翻译，但这些方法忽视了图像结构水平的准确性和医学特征的不变性。为解决这些问题，我们介绍了层次粒度识别法，利用医学图像中不同级别的Semantic信息。我们的策略使用三级层次识别粒度：像素级识别使用Brain Memory Bank，结构级识别使用重量调整策略，以及全局级识别确保图像结构一致。我们的策略在三个独立的数据集（UK Biobank、IXI和BraTS 2018）上进行了图像翻译性能评估，并在比较当前的算法时表现出色。特别是，我们的模型不仅能够合成正常结构，还能够处理异常（病理）结构，如脑肿瘤，尽管各种成像模式的病理特征导致图像的对比度变化。医生评估的合成MR图像中的脑肿瘤的诊断价值得到了证明，这表明我们的模型可能在某些特定的MR模式不可用时提供一个备用解决方案。广泛的实验还证明了我们的方法的多样性，为医学图像翻译提供了新的视角。
</details></li>
</ul>
<hr>
<h2 id="Learning-Site-specific-Styles-for-Multi-institutional-Unsupervised-Cross-modality-Domain-Adaptation"><a href="#Learning-Site-specific-Styles-for-Multi-institutional-Unsupervised-Cross-modality-Domain-Adaptation" class="headerlink" title="Learning Site-specific Styles for Multi-institutional Unsupervised Cross-modality Domain Adaptation"></a>Learning Site-specific Styles for Multi-institutional Unsupervised Cross-modality Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12437">http://arxiv.org/abs/2311.12437</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Liu, Yubo Fan, Zhoubing Xu, Benoit M. Dawant, Ipek Oguz</li>
<li>for: 这个研究是为了解决医疗影像分析中的无监督跨频道领域适应问题，特别是当源频道和目标频道资料来自多个机构时。</li>
<li>methods: 我们使用无对照图像转换来转换源频道图像到目标频道，并设计了动态网络来生成自适应目标频道图像，并且进行自我训练来降低领域差。</li>
<li>results: 我们的解决方案在验证和测试阶段都获得了第一名。<details>
<summary>Abstract</summary>
Unsupervised cross-modality domain adaptation is a challenging task in medical image analysis, and it becomes more challenging when source and target domain data are collected from multiple institutions. In this paper, we present our solution to tackle the multi-institutional unsupervised domain adaptation for the crossMoDA 2023 challenge. First, we perform unpaired image translation to translate the source domain images to the target domain, where we design a dynamic network to generate synthetic target domain images with controllable, site-specific styles. Afterwards, we train a segmentation model using the synthetic images and further reduce the domain gap by self-training. Our solution achieved the 1st place during both the validation and testing phases of the challenge.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。</SYS>>医疗图像分析中无监督交叉模式领域适应是一项挑战，而当源频率和目标频率数据来自多家机构时，这项任务变得更加挑战。在这篇论文中，我们提出了解决多家机构Unsupervised Cross-Modality Domain Adaptation（crossMoDA 2023）挑战的解决方案。首先，我们通过无对应图像翻译将源频率图像翻译到目标频率，并设计了一个动态网络生成可控、站点特定的样本风格的synthetic目标频率图像。然后，我们使用这些synthetic图像进行分类器训练，并通过自我训练来减少频率差距。我们的解决方案在验证和测试阶段的挑战中均获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="AR-Visualization-System-for-Ship-Detection-and-Recognition-Based-on-AI"><a href="#AR-Visualization-System-for-Ship-Detection-and-Recognition-Based-on-AI" class="headerlink" title="AR Visualization System for Ship Detection and Recognition Based on AI"></a>AR Visualization System for Ship Detection and Recognition Based on AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12430">http://arxiv.org/abs/2311.12430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Ye, Limin Huang, Yongji Wu, Min Hu</li>
<li>for: 这个项目是一个基于人工智能和扩展现实技术的船 detection和识别系统，主要包括人工智能模块、Unity开发模块和Hololens2AR模块。</li>
<li>methods: 该项目使用了R3Det算法来完成远程感知图像中船的探测和识别，并在RTX 2080Ti上训练了模型，其检测精度可达96%。然后，通过船类划分和信息获得3D船模型，并在虚拟场景中生成。最后，添加了语音模块和UI交互模块，并通过MRTK部署到Hololens2上。</li>
<li>results: 该系统实现了计算机视觉和扩展现实技术的融合，将物体检测结果映射到AR场景中，是未来技术趋势和智能应用的勇敢一步。<details>
<summary>Abstract</summary>
Augmented reality technology has been widely used in industrial design interaction, exhibition guide, information retrieval and other fields. The combination of artificial intelligence and augmented reality technology has also become a future development trend. This project is an AR visualization system for ship detection and recognition based on AI, which mainly includes three parts: artificial intelligence module, Unity development module and Hololens2AR module. This project is based on R3Det algorithm to complete the detection and recognition of ships in remote sensing images. The recognition rate of model detection trained on RTX 2080Ti can reach 96%. Then, the 3D model of the ship is obtained by ship categories and information and generated in the virtual scene. At the same time, voice module and UI interaction module are added. Finally, we completed the deployment of the project on Hololens2 through MRTK. The system realizes the fusion of computer vision and augmented reality technology, which maps the results of object detection to the AR field, and makes a brave step toward the future technological trend and intelligent application.
</details>
<details>
<summary>摘要</summary>
“增强现实技术在工业设计互动、展览指南、信息检索等领域得广泛应用。融合人工智能和增强现实技术的趋势也在未来发展。这个项目是一个基于AI的船检测和识别的AR视觉系统，主要包括三部分：人工智能模块、Unity开发模块和Hololens2AR模块。这个项目基于R3Det算法来完成远程感知图像中船的检测和识别。训练使用RTX 2080Ti的模型可达96%的识别率。然后，通过船类划分和信息获取，生成船的3D模型在虚拟场景中。同时，添加了语音模块和UI互动模块。最后，通过MRTK进行了Hololens2的部署。系统实现了计算机视觉和增强现实技术的融合，将对象检测结果映射到AR场景中，向未来技术趋势和智能应用踏出了一步。”
</details></li>
</ul>
<hr>
<h2 id="Two-Views-Are-Better-than-One-Monocular-3D-Pose-Estimation-with-Multiview-Consistency"><a href="#Two-Views-Are-Better-than-One-Monocular-3D-Pose-Estimation-with-Multiview-Consistency" class="headerlink" title="Two Views Are Better than One: Monocular 3D Pose Estimation with Multiview Consistency"></a>Two Views Are Better than One: Monocular 3D Pose Estimation with Multiview Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12421">http://arxiv.org/abs/2311.12421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Keilstrup Ingwersen, Anders Bjorholm Dahl, Janus Nørtoft Jensen, Morten Rieger Hannemose</li>
<li>for: 提高单视人体 pose 估算模型性能，使其可以在不需要价格的情况下进行定制化。</li>
<li>methods: 提出了一种新的损失函数——多视图一致性损失，使得在没有3D数据时可以通过多视图数据进行精度的定制。</li>
<li>results: 实验表明，只需要使用两个不同视角的数据，可以获得良好的性能，并且随着更多视角的添加，性能只有小幅提高。这些结果开启了新的可行性 для领域适应性的3D人体 pose 估算。<details>
<summary>Abstract</summary>
Deducing a 3D human pose from a single 2D image or 2D keypoints is inherently challenging, given the fundamental ambiguity wherein multiple 3D poses can correspond to the same 2D representation. The acquisition of 3D data, while invaluable for resolving pose ambiguity, is expensive and requires an intricate setup, often restricting its applicability to controlled lab environments. We improve performance of monocular human pose estimation models using multiview data for fine-tuning. We propose a novel loss function, multiview consistency, to enable adding additional training data with only 2D supervision. This loss enforces that the inferred 3D pose from one view aligns with the inferred 3D pose from another view under similarity transformations. Our consistency loss substantially improves performance for fine-tuning with no available 3D data. Our experiments demonstrate that two views offset by 90 degrees are enough to obtain good performance, with only marginal improvements by adding more views. Thus, we enable the acquisition of domain-specific data by capturing activities with off-the-shelf cameras, eliminating the need for elaborate calibration procedures. This research introduces new possibilities for domain adaptation in 3D pose estimation, providing a practical and cost-effective solution to customize models for specific applications. The used dataset, featuring additional views, will be made publicly available.
</details>
<details>
<summary>摘要</summary>
基于单个2D图像或2D关键点的3D人姿推断是内在困难的，因为多个3D姿势可以对应同一个2D表示。获取3D数据可以解决姿势歧义问题，但是costly和需要复杂的设置，通常只能在控制的室内环境中进行应用。我们提高了单视图人姿推断模型的性能，使用多视图数据进行练习。我们提出了一个新的损失函数，多视图一致性，以便在没有3D数据时进行训练。这个损失函数要求一个视图中推断出的3D姿势与另一个视图中推断出的3D姿势相似。我们的一致性损失substantially提高了没有3D数据的情况下的性能。我们的实验表明，两个视图夹角90度的差够以获得良好的性能，只有在加入更多视图时才有些许改善。因此，我们可以通过捕捉活动中的几个视图，无需进行复杂的 calibration 过程，获得域specific的数据。这项研究开创了3D姿势推断领域的新可能性，提供了可靠且cost-effective的解决方案，可以适应特定应用场景。我们使用的数据集，包含多个视图，将在未来公开。
</details></li>
</ul>
<hr>
<h2 id="Board-to-Board-Evaluating-Moonboard-Grade-Prediction-Generalization"><a href="#Board-to-Board-Evaluating-Moonboard-Grade-Prediction-Generalization" class="headerlink" title="Board-to-Board: Evaluating Moonboard Grade Prediction Generalization"></a>Board-to-Board: Evaluating Moonboard Grade Prediction Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12419">http://arxiv.org/abs/2311.12419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a1773620/moonboard-grade-prediction">https://github.com/a1773620/moonboard-grade-prediction</a></li>
<li>paper_authors: Daniel Petashvili, Matthew Rodda</li>
<li>for:  This paper aims to develop a grade prediction model for bouldering routes, using classical and deep-learning techniques to improve the accuracy and reduce bias in grading.</li>
<li>methods:  The paper uses the 2016, 2017, and 2019 Moonboard datasets and features a novel vision-based method of grade prediction. The model does not require decomposing routes into individual moves, which is a common method in literature and introduces bias.</li>
<li>results:  The paper achieves state-of-the-art grade prediction performance with 0.87 MAE and 1.12 RMSE on the Moonboard datasets. The generalization performance of these techniques is below human level performance currently, but the authors propose these methods as a basis for future work.<details>
<summary>Abstract</summary>
Bouldering is a sport where athletes aim to climb up an obstacle using a set of defined holds called a route. Typically routes are assigned a grade to inform climbers of its difficulty and allow them to more easily track their progression. However, the variation in individual climbers technical and physical attributes and many nuances of an individual route make grading a difficult and often biased task. In this work, we apply classical and deep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard datasets, achieving state of the art grade prediction performance with 0.87 MAE and 1.12 RMSE. We achieve this performance on a feature-set that does not require decomposing routes into individual moves, which is a method common in literature and introduces bias. We also demonstrate the generalization capability of this model between editions and introduce a novel vision-based method of grade prediction. While the generalization performance of these techniques is below human level performance currently, we propose these methods as a basis for future work. Such a tool could be implemented in pre-existing mobile applications and would allow climbers to better track their progress and assess new routes with reduced bias.
</details>
<details>
<summary>摘要</summary>
布尔дер运动是一种 Athletes 通过一系列定义的持有（route）进行攀登的运动。通常，路由会被分配一个等级，以便 climbers 了解其困难程度并更容易跟踪其进步。然而，个体 climbers 的技术和物理属性的变化以及路由的多种细节使得评分变得困难且偏向。在这项工作中，我们使用古典和深度学习模型技术来对2016、2017和2019年的月坛数据集进行评分，实现了状态的评分性能，MAE 0.87 和 RMSE 1.12。我们实现了这一性能在一个不需要分解路由为个move的特征集上，这是文献中常见的方法，并且引入偏见。我们还示出了这些模型在不同版本之间的泛化性能，并提出了一种新的视觉评分方法。虽然这些技术的总体性能目前还不及人类水平，但我们提出这些方法作为未来工作的基础。这种工具可以在现有的移动应用程序中实现，并允许 climbers 更好地跟踪其进步和评估新路由，减少偏见。
</details></li>
</ul>
<hr>
<h2 id="Learning-Part-Motion-of-Articulated-Objects-Using-Spatially-Continuous-Neural-Implicit-Representations"><a href="#Learning-Part-Motion-of-Articulated-Objects-Using-Spatially-Continuous-Neural-Implicit-Representations" class="headerlink" title="Learning Part Motion of Articulated Objects Using Spatially Continuous Neural Implicit Representations"></a>Learning Part Motion of Articulated Objects Using Spatially Continuous Neural Implicit Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12407">http://arxiv.org/abs/2311.12407</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Yushi-Du/PartMotion">https://github.com/Yushi-Du/PartMotion</a></li>
<li>paper_authors: Yushi Du, Ruihai Wu, Yan Shen, Hao Dong</li>
<li>for:  This paper aims to improve the understanding and manipulation of articulated objects, such as doors and drawers, by introducing a novel framework for modeling their part motions using neural implicit representations.</li>
<li>methods:  The proposed framework explicitly disentangles the part motion of articulated objects by predicting the transformation matrix of points on the part surface, allowing for smooth modeling of part motion in the space. The method is generic to different kinds of joint motions, meaning it can model diverse types of joint motions in the space.</li>
<li>results:  Quantitative and qualitative results of experiments over diverse categories of articulated objects demonstrate the effectiveness of the proposed framework, showing that it can accurately model part motions and handle diverse types of joint motions.<details>
<summary>Abstract</summary>
Articulated objects (e.g., doors and drawers) exist everywhere in our life. Different from rigid objects, articulated objects have higher degrees of freedom and are rich in geometries, semantics, and part functions. Modeling different kinds of parts and articulations with nerual networks plays an essential role in articulated object understanding and manipulation, and will further benefit 3D vision and robotics communities. To model articulated objects, most previous works directly encode articulated objects into feature representations, without specific designs for parts, articulations and part motions. In this paper, we introduce a novel framework that explicitly disentangles the part motion of articulated objects by predicting the transformation matrix of points on the part surface, using spatially continuous neural implicit representations to model the part motion smoothly in the space. More importantly, while many methods could only model a certain kind of joint motion (such as the revolution in the clockwise order), our proposed framework is generic to different kinds of joint motions in that transformation matrix can model diverse kinds of joint motions in the space. Quantitative and qualitative results of experiments over diverse categories of articulated objects demonstrate the effectiveness of our proposed framework.
</details>
<details>
<summary>摘要</summary>
everywhere in our lives 有各种各样的叉体对象（例如门和柜）。与固定对象不同，叉体对象具有更高的自由度和更丰富的几何、 semantics 和部件功能。使用神经网络模型不同种类的部件和叉动可以在叉体对象理解和操作方面发挥重要作用，并对3D视觉和机器人领域产生积极影响。在模型叉体对象方面，大多数前一些工作直接编码叉体对象到特征表示中，没有特定的部件、叉动和部件运动设计。在这篇论文中，我们提出了一种新的框架，其中明确分离叉体对象的部件运动，通过采用空间连续神经凝重表示来平滑地在空间中模型部件运动。此外，我们的提posed框架可以涵盖不同类型的 JOINT 运动，而不是只能模型某种特定的 JOINT 运动（如顺时静转）。经过对不同类型叉体对象的实验，我们获得了证明我们的提posed框架的有效性的数量和质量结果。
</details></li>
</ul>
<hr>
<h2 id="CASR-Refining-Action-Segmentation-via-Magrinalizing-Frame-levle-Causal-Relationships"><a href="#CASR-Refining-Action-Segmentation-via-Magrinalizing-Frame-levle-Causal-Relationships" class="headerlink" title="CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal Relationships"></a>CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal Relationships</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12401">http://arxiv.org/abs/2311.12401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keqing Du, Xinyu Yang, Hang Chen</li>
<li>for: 提高 Temporal Action Segmentation (TAS) 任务的解释性，通过深度学习和 causal discovery  integrate。</li>
<li>methods: 提出了 Causal Abstraction Segmentation Refiner (CASR)，可以通过增强视频 causality 来提高 TAS 结果，并且定义了等效帧级 causal model 和段级 causal model，以便在 marginalized 帧级 causal 关系中表示段级 causal 关系。</li>
<li>results: 对主流数据集进行了广泛的实验，结果显示，CASR 可以significantly 超越现有的多种方法在动作分 segmentation 性能、 causal 解释性和泛化性等方面。<details>
<summary>Abstract</summary>
Integrating deep learning and causal discovery has increased the interpretability of Temporal Action Segmentation (TAS) tasks. However, frame-level causal relationships exist many complicated noises outside the segment-level, making it infeasible to directly express macro action semantics. Thus, we propose \textit{\textbf{Causal Abstraction Segmentation Refiner (CASR)}, which can refine TAS results from various models by enhancing video causality in marginalizing frame-level casual relationships. Specifically, we define the equivalent frame-level casual model and segment-level causal model, so that the causal adjacency matrix constructed from marginalized frame-level causal relationships has the ability to represent the segmnet-level causal relationships. CASR works out by reducing the difference in the causal adjacency matrix between we constructed and pre-segmentation results of backbone models. In addition, we propose a novel evaluation metric Causal Edit Distance (CED) to evaluate the causal interpretability. Extensive experimental results on mainstream datasets indicate that CASR significantly surpasses existing various methods in action segmentation performance, as well as in causal explainability and generalization. Our code will be available soon.
</details>
<details>
<summary>摘要</summary>
integrate deep learning and causal discovery 增加了 Temporal Action Segmentation (TAS) 任务的解释性。然而，框架级别的 causal 关系存在多种复杂的噪声，使得直接表达 macro action semantics 变得不可能。因此，我们提议 \textit{\textbf{Causal Abstraction Segmentation Refiner (CASR)}, 可以修复来自不同模型的 TAS 结果，通过增强视频 causality 来增强 marginalized 框架级别 causal 关系。 Specifically, we define the equivalent frame-level casual model and segment-level causal model, so that the causal adjacency matrix constructed from marginalized frame-level causal relationships has the ability to represent the segment-level causal relationships。CASR works by reducing the difference in the causal adjacency matrix between the constructed and pre-segmentation results of backbone models。 In addition, we propose a novel evaluation metric Causal Edit Distance (CED) to evaluate the causal interpretability。Extensive experimental results on mainstream datasets indicate that CASR significantly surpasses existing various methods in action segmentation performance, as well as in causal explainability and generalization。 Our code will be available soon。Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="RFTrans-Leveraging-Refractive-Flow-of-Transparent-Objects-for-Surface-Normal-Estimation-and-Manipulation"><a href="#RFTrans-Leveraging-Refractive-Flow-of-Transparent-Objects-for-Surface-Normal-Estimation-and-Manipulation" class="headerlink" title="RFTrans: Leveraging Refractive Flow of Transparent Objects for Surface Normal Estimation and Manipulation"></a>RFTrans: Leveraging Refractive Flow of Transparent Objects for Surface Normal Estimation and Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12398">http://arxiv.org/abs/2311.12398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tutian Tang, Jiyu Liu, Jieyi Zhang, Haoyuan Fu, Wenqiang Xu, Cewu Lu</li>
<li>for: 本研究的目的是教 robots 如何与透明物体互动，因为直接从 RGB 图像中提取 geometry 信息可能会受到反射和折射的影响，导致 RGB-D 摄像头的准确性受到影响。</li>
<li>methods: 本研究提出了 RFTrans，一种基于 RGB-D 的方法，用于透明物体表面法向估计和操作。该方法利用了射流作为中间表示，从而缺乏直接从 RGB 图像中提取 geometry 信息的缺陷，并帮助bridge sim-to-real  gap。RFTrans 组合了 RFNet 和 F2Net，其中 RFNet 预测射流、物体mask 和边界，然后 F2Net 利用射流来估计表面法。为了实现操作，global optimization module 将预测结果与原始深度进行精细调整，并将点云与法向相结合。接下来，使用 ISF 分析抓取算法来生成抓取姿势。</li>
<li>results: 在 synthetic 数据集上训练 RFTrans 后，它可以在 synthetic 和实际世界 benchmark 中 consistently 超越基线 ClearGrasp 的表现，差异较大。此外，在实际世界中，使用 RFTrans 实现了83%的成功率，证明了射流可以帮助实现直接 sim-to-real 转移。<details>
<summary>Abstract</summary>
Transparent objects are widely used in our daily lives, making it important to teach robots to interact with them. However, it's not easy because the reflective and refractive effects can make RGB-D cameras fail to give accurate geometry measurements. To solve this problem, this paper introduces RFTrans, an RGB-D-based method for surface normal estimation and manipulation of transparent objects. By leveraging refractive flow as an intermediate representation, RFTrans circumvents the drawbacks of directly predicting the geometry (e.g. surface normal) from RGB images and helps bridge the sim-to-real gap. RFTrans integrates the RFNet, which predicts refractive flow, object mask, and boundaries, followed by the F2Net, which estimates surface normal from the refractive flow. To make manipulation possible, a global optimization module will take in the predictions, refine the raw depth, and construct the point cloud with normal. An analytical grasp planning algorithm, ISF, is followed to generate the grasp poses. We build a synthetic dataset with physically plausible ray-tracing rendering techniques to train the networks. Results show that the RFTrans trained on the synthetic dataset can consistently outperform the baseline ClearGrasp in both synthetic and real-world benchmarks by a large margin. Finally, a real-world robot grasping task witnesses an 83% success rate, proving that refractive flow can help enable direct sim-to-real transfer. The code, data, and supplementary materials are available at https://rftrans.robotflow.ai.
</details>
<details>
<summary>摘要</summary>
透明物体在我们日常生活中广泛使用，因此教 robot 如何与它们交互变得非常重要。然而，由于镜面和折射效果，RGB-D 摄像头可能无法提供准确的几何测量。为解决这个问题，这篇论文引入了 RFTrans，一种基于 RGB-D 的表面法向量估计和透明物体把握方法。通过利用折射流作为中间表示，RFTrans 可以缺失直接从 RGB 图像中提取几何信息的缺陷，帮助bridges 实验室到实际的差距。RFTrans 结合了 RFNet，这个网络预测了折射流、物体mask 和边界，然后结合 F2Net，它根据折射流来估计表面法向量。为了实现把握，一个全球优化模块会接受预测结果，进行原始深度的精炼，并将点云与表面法向量结合起来。一种基于分析的抓取算法，ISF，用于生成抓取姿势。我们使用physically plausible的投射渲染技术来训练网络。结果显示，使用 synthetic 数据集训练的 RFTrans 可以在 synthetic 和实际 benchmark 中一直高于基准 ClearGrasp 的表现，差异很大。最后，一个实际 robot 抓取任务中观察到 83% 的成功率，证明了折射流可以帮助实际到 simulate 的直接传输。代码、数据和补充材料可以在 <https://rftrans.robotflow.ai> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Rich-and-Poor-Texture-Contrast-A-Simple-yet-Effective-Approach-for-AI-generated-Image-Detection"><a href="#Rich-and-Poor-Texture-Contrast-A-Simple-yet-Effective-Approach-for-AI-generated-Image-Detection" class="headerlink" title="Rich and Poor Texture Contrast: A Simple yet Effective Approach for AI-generated Image Detection"></a>Rich and Poor Texture Contrast: A Simple yet Effective Approach for AI-generated Image Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12397">http://arxiv.org/abs/2311.12397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Zhong, Yiran Xu, Zhenxing Qian, Xinpeng Zhang</li>
<li>for: 本研究旨在开发一种能够识别由各种生成模型生成的假图像的检测器。</li>
<li>methods: 本研究提出了一种基于图像内部纹理区域的对比特征的方法，通过分解图像为多个小块，然后重建这些块，从而提取各个纹理区域之间的对比特征，以用于识别假图像。</li>
<li>results: 对于16种常见的生成模型，本研究的方法能够准确地识别假图像，并且与现有基elines相比，表现出了显著的提高。<details>
<summary>Abstract</summary>
Recent generative models show impressive performance in generating photographic images. Humans can hardly distinguish such incredibly realistic-looking AI-generated images from real ones. AI-generated images may lead to ubiquitous disinformation dissemination. Therefore, it is of utmost urgency to develop a detector to identify AI-generated images. Most existing detectors suffer from sharp performance drops over unseen generative models. In this paper, we propose a novel AI-generated image detector capable of identifying fake images created by a wide range of generative models. Our approach leverages the inter-pixel correlation contrast between rich and poor texture regions within an image. Pixels in rich texture regions exhibit more significant fluctuations than those in poor texture regions. This discrepancy reflects that the entropy of rich texture regions is larger than that of poor ones. Consequently, synthesizing realistic rich texture regions proves to be more challenging for existing generative models. Based on this principle, we divide an image into multiple patches and reconstruct them into two images, comprising rich-texture and poor-texture patches respectively. Subsequently, we extract the inter-pixel correlation discrepancy feature between rich and poor texture regions. This feature serves as a universal fingerprint used for AI-generated image forensics across different generative models. In addition, we build a comprehensive AI-generated image detection benchmark, which includes 16 kinds of prevalent generative models, to evaluate the effectiveness of existing baselines and our approach. Our benchmark provides a leaderboard for follow-up studies. Extensive experimental results show that our approach outperforms state-of-the-art baselines by a significant margin. Our project: https://fdmas.github.io/AIGCDetect/
</details>
<details>
<summary>摘要</summary>
近期的生成模型显示出了惊人的表现，可以生成出非常真实的图像。人们几乎无法分辨这些由AI生成的图像和真实的图像之间的差异。然而，这些AI生成的图像可能会导致广泛的假信息散布。因此，发展一个可以识别AI生成图像的检测器非常有优先性。现有的检测器往往会在未看过的生成模型上表现维度下降。在这篇论文中，我们提出了一种新的AI生成图像检测器，可以识别由各种生成模型生成的假图像。我们的方法利用图像内部像素之间的干扰对比，rich texture region中像素的波动较大，而poor texture region中像素的波动较小。这种差异反映了生成模型Synthesizing realistic rich texture regions是更加困难的。基于这个原理，我们将图像分解成多个patch，然后将它们重construct成两个图像，包括rich texture和poor texture patches。接着，我们提取rich texture和poor texture patches之间的干扰对比特征。这个特征作为一种通用的人工智能生成图像掌略，可以在不同的生成模型上进行检测。此外，我们建立了一个全面的AI生成图像检测 benchmark，包括16种常见的生成模型。我们的 benchmark 提供了一个领导者榜，用于后续的研究。我们的实验结果表明，我们的方法在现有基elines之上表现出了显著的优势。我们的项目：https://fdmas.github.io/AIGCDetect/
</details></li>
</ul>
<hr>
<h2 id="From-Wrong-To-Right-A-Recursive-Approach-Towards-Vision-Language-Explanation"><a href="#From-Wrong-To-Right-A-Recursive-Approach-Towards-Vision-Language-Explanation" class="headerlink" title="From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation"></a>From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12391">http://arxiv.org/abs/2311.12391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Ge, Sanjay Subramanian, Trevor Darrell, Boyi Li</li>
<li>for: 提高视觉理解任务中的解释质量，尤其是在有限的标注数据下。</li>
<li>methods: 提出了一种循环计算视觉特征（基于文本输入）、答案和解释，以逐步改进解释质量。</li>
<li>results: 与先前的方法相比，我们的方法可以更好地 corrrect its own answers，并且在10个纪录中取得了5%的人工标注数据，并且在VCR和VQA-X数据集上取得了4.2和1.3的BLEU-1分数提高。<details>
<summary>Abstract</summary>
Addressing the challenge of adapting pre-trained vision-language models for generating insightful explanations for visual reasoning tasks with limited annotations, we present ReVisE: a $\textbf{Re}$cursive $\textbf{Vis}$ual $\textbf{E}$xplanation algorithm. Our method iteratively computes visual features (conditioned on the text input), an answer, and an explanation, to improve the explanation quality step by step until the answer converges. We find that this multi-step approach guides the model to correct its own answers and outperforms single-step explanation generation. Furthermore, explanations generated by ReVisE also serve as valuable annotations for few-shot self-training. Our approach outperforms previous methods while utilizing merely 5% of the human-annotated explanations across 10 metrics, demonstrating up to a 4.2 and 1.3 increase in BLEU-1 score on the VCR and VQA-X datasets, underscoring the efficacy and data-efficiency of our method.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:面对预训练视语模型适应视理解任务的限制注释挑战，我们提出了ReVisE：一种循环的视释解释算法。我们的方法在每一步计算视特征（基于文本输入）、答案和解释，以改进解释质量，直到答案 converges。我们发现这种多步 Approach 使模型自 corrections 其答案，并且超过单步解释生成。此外，ReVisE 生成的解释还可以作为有限少量自我训练的有价值注释。我们的方法在10个指标中胜过前一代方法，只用5%的人工注释，在 VCR 和 VQA-X 数据集上表现出4.2和1.3的BLEU-1 分数提高，这表明我们的方法的有效性和数据效果。
</details></li>
</ul>
<hr>
<h2 id="Point-Segment-and-Count-A-Generalized-Framework-for-Object-Counting"><a href="#Point-Segment-and-Count-A-Generalized-Framework-for-Object-Counting" class="headerlink" title="Point, Segment and Count: A Generalized Framework for Object Counting"></a>Point, Segment and Count: A Generalized Framework for Object Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12386">http://arxiv.org/abs/2311.12386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huang Zhizhong, Dai Mingliang, Zhang Yi, Zhang Junping, Shan Hongming<br>for:The paper is written for object counting and detection in images, specifically for few-shot and zero-shot scenarios.methods:The paper proposes a generalized framework for object counting and detection based on detection, which combines the advantages of two foundation models (SAM and CLIP) without compromising their zero-shot capability. The framework includes three steps: point, segment, and count.results:The proposed method, PseCo, achieves state-of-the-art performance in both few-shot&#x2F;zero-shot object counting&#x2F;detection on the FSC-147 dataset, with additional results on large-scale COCO and LVIS datasets. The source code is available at GitHub.<details>
<summary>Abstract</summary>
Class-agnostic object counting aims to count all objects in an image with respect to example boxes or class names, \emph{a.k.a} few-shot and zero-shot counting. Current state-of-the-art methods highly rely on density maps to predict object counts, which lacks model interpretability. In this paper, we propose a generalized framework for both few-shot and zero-shot object counting based on detection. Our framework combines the superior advantages of two foundation models without compromising their zero-shot capability: (\textbf{i}) SAM to segment all possible objects as mask proposals, and (\textbf{ii}) CLIP to classify proposals to obtain accurate object counts. However, this strategy meets the obstacles of efficiency overhead and the small crowded objects that cannot be localized and distinguished. To address these issues, our framework, termed PseCo, follows three steps: point, segment, and count. Specifically, we first propose a class-agnostic object localization to provide accurate but least point prompts for SAM, which consequently not only reduces computation costs but also avoids missing small objects. Furthermore, we propose a generalized object classification that leverages CLIP image/text embeddings as the classifier, following a hierarchical knowledge distillation to obtain discriminative classifications among hierarchical mask proposals. Extensive experimental results on FSC-147 dataset demonstrate that PseCo achieves state-of-the-art performance in both few-shot/zero-shot object counting/detection, with additional results on large-scale COCO and LVIS datasets. The source code is available at \url{https://github.com/Hzzone/PseCo}.
</details>
<details>
<summary>摘要</summary>
现代状态的方法都高度依赖密度地图来预测对象数量，这lacks model interpretability。在这篇论文中，我们提出一种通用的基本框架，用于几拟零shot和零shot对象数量计算。我们的框架结合了两种基础模型的优点，不会削弱它们的零shot能力：（i）SAM用于分 segment所有可能的对象，（ii）CLIP用于分类提案以获取准确的对象数量。然而，这种策略遇到了效率 overhead和小型拥挤的对象无法被本地化和分辨的问题。为解决这些问题，我们提出了一种名为PseCo的框架，包括以下三步：（1）提出一种类型不受限制的对象本地化，以提供准确但是最少的点提示 дляSAM，从而降低计算成本并避免小对象被漏掉。（2）提出一种通用对象分类方法，使用CLIP图像/文本嵌入来分类提案，并通过层次知识储存来获得特征分类。（3）对于拥挤的对象，我们提出了一种Point-Segment-Count的方法，通过对点提示进行分割，以提高对象的本地化和分辨。我们的PseCo框架在FSC-147数据集上实现了当前最佳的几拟零shot/零shot对象数量计算/检测性能，并在COCO和LVIS数据集上获得了优秀的结果。代码可以在GitHub上找到：<https://github.com/Hzzone/PseCo>。
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Medical-Image-Segmentation-via-Query-Distribution-Consistency"><a href="#Semi-supervised-Medical-Image-Segmentation-via-Query-Distribution-Consistency" class="headerlink" title="Semi-supervised Medical Image Segmentation via Query Distribution Consistency"></a>Semi-supervised Medical Image Segmentation via Query Distribution Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12364">http://arxiv.org/abs/2311.12364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rong Wu, Dehua Li, Cong Zhang</li>
<li>for: 这个论文是为了提出一个基于两个模组的DUAL KMAX UX-Net框架，用于实现半指导式医疗影像分类。</li>
<li>methods: 这个方法使用了3D UX-Net作为我们的背景元架，并且使用KMax解oder来强化分类性能。我们还采用了一种相互学习策略，将两个模组相互连接，以优化分类性能。</li>
<li>results: 实验结果显示，我们的方法可以将未abeled Data与labeled Data融合，以提高分类性能。同时，我们的框架在10%和20%具有labeled数据的设定下，与现有的半指导式学习方法相比，表现更好。<details>
<summary>Abstract</summary>
Semi-supervised learning is increasingly popular in medical image segmentation due to its ability to leverage large amounts of unlabeled data to extract additional information. However, most existing semi-supervised segmentation methods focus only on extracting information from unlabeled data. In this paper, we propose a novel Dual KMax UX-Net framework that leverages labeled data to guide the extraction of information from unlabeled data. Our approach is based on a mutual learning strategy that incorporates two modules: 3D UX-Net as our backbone meta-architecture and KMax decoder to enhance the segmentation performance. Extensive experiments on the Atrial Segmentation Challenge dataset have shown that our method can significantly improve performance by merging unlabeled data. Meanwhile, our framework outperforms state-of-the-art semi-supervised learning methods on 10\% and 20\% labeled settings. Code located at: https://github.com/Rows21/DK-UXNet.
</details>
<details>
<summary>摘要</summary>
semi-supervised learning在医疗图像分割中日益受欢迎，因为它可以利用大量无标签数据来提取更多的信息。然而，大多数现有的半指导学习分割方法仅仅是利用无标签数据提取信息。在这篇论文中，我们提出了一种新的 dual KMax UX-Net框架，该框架利用标注数据来引导无标签数据中的信息提取。我们的方法基于一种互助学习策略，该策略包括3D UX-Net作为我们的基础元体系和KMax解码器来增强分割性能。我们的实验在Atrial Segmentation Challenge数据集上展现了，我们的方法可以显著提高性能，并且在10%和20%标注设置下超过了当前最佳的半指导学习方法。代码位于：https://github.com/Rows21/DK-UXNet。
</details></li>
</ul>
<hr>
<h2 id="Modality-Mixer-Exploiting-Complementary-Information-for-Multi-modal-Action-Recognition"><a href="#Modality-Mixer-Exploiting-Complementary-Information-for-Multi-modal-Action-Recognition" class="headerlink" title="Modality Mixer Exploiting Complementary Information for Multi-modal Action Recognition"></a>Modality Mixer Exploiting Complementary Information for Multi-modal Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12344">http://arxiv.org/abs/2311.12344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumin Lee, Sangmin Woo, Muhammad Adi Nugroho, Changick Kim</li>
<li>for: 本研究旨在提高多modal action recognition的精度，通过efficacious incorporation of complementary information across modalities and temporal context of actions。</li>
<li>methods: 我们提出了一种新网络 architecture，名为Modality Mixer（M-Mixer）网络，它可以有效地利用不同modalities之间的协同信息，同时考虑action的时间上下文。MCU是我们的关键组件，它可以在一个模式（例如RGB）中编码动作内容特征，并且在其他模式（例如深度和红外模式）中提取动作内容特征。此外，我们还提出了一个新的模块，名为Complementary Feature Extraction Module（CFEM），它可以提取不同模式之间的相互补充信息。</li>
<li>results: 我们的提出方法在NTU RGB+D 60、NTU RGB+D 120和NW-UCLA数据集上达到了现有方法的最高水平。此外，我们还进行了详细的ablation study，以验证我们的提出方法的有效性。<details>
<summary>Abstract</summary>
Due to the distinctive characteristics of sensors, each modality exhibits unique physical properties. For this reason, in the context of multi-modal action recognition, it is important to consider not only the overall action content but also the complementary nature of different modalities. In this paper, we propose a novel network, named Modality Mixer (M-Mixer) network, which effectively leverages and incorporates the complementary information across modalities with the temporal context of actions for action recognition. A key component of our proposed M-Mixer is the Multi-modal Contextualization Unit (MCU), a simple yet effective recurrent unit. Our MCU is responsible for temporally encoding a sequence of one modality (e.g., RGB) with action content features of other modalities (e.g., depth and infrared modalities). This process encourages M-Mixer network to exploit global action content and also to supplement complementary information of other modalities. Furthermore, to extract appropriate complementary information regarding to the given modality settings, we introduce a new module, named Complementary Feature Extraction Module (CFEM). CFEM incorporates sepearte learnable query embeddings for each modality, which guide CFEM to extract complementary information and global action content from the other modalities. As a result, our proposed method outperforms state-of-the-art methods on NTU RGB+D 60, NTU RGB+D 120, and NW-UCLA datasets. Moreover, through comprehensive ablation studies, we further validate the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
due to the distinctive characteristics of sensors, each modality exhibits unique physical properties. For this reason, in the context of multi-modal action recognition, it is important to consider not only the overall action content but also the complementary nature of different modalities. In this paper, we propose a novel network, named Modality Mixer (M-Mixer) network, which effectively leverages and incorporates the complementary information across modalities with the temporal context of actions for action recognition. A key component of our proposed M-Mixer is the Multi-modal Contextualization Unit (MCU), a simple yet effective recurrent unit. Our MCU is responsible for temporally encoding a sequence of one modality (e.g., RGB) with action content features of other modalities (e.g., depth and infrared modalities). This process encourages M-Mixer network to exploit global action content and also to supplement complementary information of other modalities. Furthermore, to extract appropriate complementary information regarding to the given modality settings, we introduce a new module, named Complementary Feature Extraction Module (CFEM). CFEM incorporates separate learnable query embeddings for each modality, which guide CFEM to extract complementary information and global action content from the other modalities. As a result, our proposed method outperforms state-of-the-art methods on NTU RGB+D 60, NTU RGB+D 120, and NW-UCLA datasets. Moreover, through comprehensive ablation studies, we further validate the effectiveness of our proposed method.Here's the breakdown of the translation:* due to the distinctive characteristics of sensors: 由于各种感测器的特殊特点* each modality exhibits unique physical properties: 每种模式都表现出独特的物理特性* For this reason, in the context of multi-modal action recognition: 因此，在多modal动作识别中，需要考虑不同模式之间的相互补做* it is important to consider not only the overall action content: 需要考虑不同模式之间的相互补做，以及动作内容的总体特征* but also the complementary nature of different modalities: 并且需要考虑不同模式之间的补做关系* In this paper, we propose a novel network, named Modality Mixer (M-Mixer) network: 在本文中，我们提出了一种新的网络 architecture，名为Modal Mixer（M-Mixer）网络* which effectively leverages and incorporates the complementary information across modalities: 可以有效地利用和集成不同模式之间的补做信息* with the temporal context of actions for action recognition: 以动作识别的时间上下文为基础* A key component of our proposed M-Mixer is the Multi-modal Contextualization Unit (MCU): 我们的提议的M-Mixer中的关键组件是多modal上下文化单元（MCU）* a simple yet effective recurrent unit: 一种简单 yet 有效的循环单元* Our MCU is responsible for temporally encoding a sequence of one modality (e.g., RGB) with action content features of other modalities (e.g., depth and infrared modalities): 我们的MCU负责在不同模式之间进行时间编码，以便从其他模式中提取动作内容特征* This process encourages M-Mixer network to exploit global action content and also to supplement complementary information of other modalities: 这个过程鼓励M-Mixer网络利用全局动作内容，并且补做其他模式的补做信息* Furthermore, to extract appropriate complementary information regarding to the given modality settings, we introduce a new module, named Complementary Feature Extraction Module (CFEM): 此外，为了在给定的模式设置下提取适当的补做信息，我们提出了一个新的模块，名为补做特征提取模块（CFEM）* CFEM incorporates separate learnable query embeddings for each modality, which guide CFEM to extract complementary information and global action content from the other modalities: CFEM使用每个模式的分离学习的查询嵌入，以便从其他模式中提取补做信息和全局动作内容* As a result, our proposed method outperforms state-of-the-art methods on NTU RGB+D 60, NTU RGB+D 120, and NW-UCLA datasets: 因此，我们的提议方法在NTU RGB+D 60、NTU RGB+D 120和NW-UCLA数据集上表现出了更高的性能* Moreover, through comprehensive ablation studies, we further validate the effectiveness of our proposed method: 此外，我们还通过了全面的抽象研究，以验证我们的提议方法的有效性
</details></li>
</ul>
<hr>
<h2 id="LoCo-Locally-Constrained-Training-Free-Layout-to-Image-Synthesis"><a href="#LoCo-Locally-Constrained-Training-Free-Layout-to-Image-Synthesis" class="headerlink" title="LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis"></a>LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12342">http://arxiv.org/abs/2311.12342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiang Zhao, Han Li, Ruiyang Jin, S. Kevin Zhou</li>
<li>for: Layout-to-image synthesis with high-quality images aligned with textual prompts and spatial layouts.</li>
<li>methods: Localized Attention Constraint and Padding Token Constraint to refine cross-attention and leverage semantic information from padding tokens.</li>
<li>results: Superior performance compared to existing training-free layout-to-image methods, with qualitative and quantitative improvements across multiple benchmarks.Here’s the summary in Traditional Chinese:</li>
<li>for: 实现文本描述和空间配置 aligned 的高品质图像生成。</li>
<li>methods: 地域化注意力限制和padding token限制，从padding tokens中获取semantic information，避免实体融合问题。</li>
<li>results: 与现有training-free layout-to-image方法相比，具有较高的表现和多个benchmark上的量化改进。<details>
<summary>Abstract</summary>
Recent text-to-image diffusion models have reached an unprecedented level in generating high-quality images. However, their exclusive reliance on textual prompts often falls short in accurately conveying fine-grained spatial compositions. In this paper, we propose LoCo, a training-free approach for layout-to-image synthesis that excels in producing high-quality images aligned with both textual prompts and spatial layouts. Our method introduces a Localized Attention Constraint to refine cross-attention for individual objects, ensuring their precise placement in designated regions. We further propose a Padding Token Constraint to leverage the semantic information embedded in previously neglected padding tokens, thereby preventing the undesired fusion of synthesized objects. LoCo seamlessly integrates into existing text-to-image and layout-to-image models, significantly amplifying their performance and effectively addressing semantic failures observed in prior methods. Through extensive experiments, we showcase the superiority of our approach, surpassing existing state-of-the-art training-free layout-to-image methods both qualitatively and quantitatively across multiple benchmarks.
</details>
<details>
<summary>摘要</summary>
最近的文本到图像扩散模型已达到历史上无 precedent 的水平，但它们偏重文本提示语 часто不够精确地传达细腻的空间组合。在这篇论文中，我们提议LoCo，一种不需要训练的方法 для文本到图像合成，可以生成高质量的图像，同时兼顾文本提示语和空间布局。我们的方法引入了局部注意力约束，以提高对个体物体的横跨注意力，使其准确地放置在指定的区域中。此外，我们还提出了补充符约束，以利用padding token中嵌入的semantic信息，避免synthesized对象的不良融合。LoCo可以顺利地与现有的文本到图像和布局到图像模型结合使用，明显提高其性能，并有效地解决先前方法中的语义失败。通过广泛的实验，我们展示了我们的方法的超越性，在多个 benchmark 上胜过现有的状态态的training-free布局到图像方法， both qualitatively and quantitatively。
</details></li>
</ul>
<hr>
<h2 id="ViLaM-A-Vision-Language-Model-with-Enhanced-Visual-Grounding-and-Generalization-Capability"><a href="#ViLaM-A-Vision-Language-Model-with-Enhanced-Visual-Grounding-and-Generalization-Capability" class="headerlink" title="ViLaM: A Vision-Language Model with Enhanced Visual Grounding and Generalization Capability"></a>ViLaM: A Vision-Language Model with Enhanced Visual Grounding and Generalization Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12327">http://arxiv.org/abs/2311.12327</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymgiant/vilam">https://github.com/anonymgiant/vilam</a></li>
<li>paper_authors: Xiaoyu Yang, Lijian Xu, Hongsheng Li, Shaoting Zhang</li>
<li>for: 这个研究旨在提出一个统一的视力语言模型（ViLaM），以便将大型预训语言模型的知识和推理能力最佳化 для跨modal任务。</li>
<li>methods: 这个模型使用预先冻结的预训encoder来对图像和文本特征进行编码和对alignment，以便处理多种基于文本指令的视觉任务。此外，我们还提出了循环训练的方法来处理参考表达的问题。</li>
<li>results: 我们在公共通用dataset上评估了ViLaM的表现，并确认了它在医学dataset上的一般化性。此外，我们还观察到了模型的优异零shot学习能力，这表明了未来可能将ViLaM应用在医学领域。<details>
<summary>Abstract</summary>
Vision-language models have revolutionized human-computer interaction and shown significant progress in multi-modal tasks. However, applying these models to complex visual tasks like medical image analysis remains challenging. In this study, we propose ViLaM, a unified Vision-Language transformer model that integrates instruction tuning predicated on a large language model. This approach enables us to optimally utilize the knowledge and reasoning capacities of large pre-trained language models for an array of tasks encompassing both language and vision. We employ frozen pre-trained encoders to encode and align both image and text features, enabling ViLaM to handle a variety of visual tasks following textual instructions. Besides, we've designed cycle training for referring expressions to address the need for high-quality, paired referring expression datasets for training large models in terms of both quantity and quality. We evaluated ViLaM's exceptional performance on public general datasets and further confirmed its generalizability on medical datasets. Importantly, we've observed the model's impressive zero-shot learning ability, indicating the potential future application of ViLaM in the medical field.
</details>
<details>
<summary>摘要</summary>
视力语言模型已经革命化人机交互和多模态任务，但对复杂视觉任务如医疗图像分析仍然是挑战。在这项研究中，我们提出了ViLaM，一种 integrate 视力语言变换模型，它通过基于大型预训练语言模型的 instruction 预测来优化视觉任务的执行。我们使用冻结预训练encoder来编码和对应图像和文本特征，使ViLaM可以处理多种视觉任务， seguido de textual  instrucciones。此外，我们还设计了 cycle 训练来改进 Referring 表达，以满足大型模型的训练所需的高质量、量化 paired  Referring 表达数据集。我们在公共普遍数据集上评估了ViLaM的突出表现，并证明其普遍性在医疗数据集上。进一步，我们发现了模型的强大零shot 学习能力，表明 ViLaM 在未来可能在医疗领域应用。
</details></li>
</ul>
<hr>
<h2 id="ABFL-Angular-Boundary-Discontinuity-Free-Loss-for-Arbitrary-Oriented-Object-Detection-in-Aerial-Images"><a href="#ABFL-Angular-Boundary-Discontinuity-Free-Loss-for-Arbitrary-Oriented-Object-Detection-in-Aerial-Images" class="headerlink" title="ABFL: Angular Boundary Discontinuity Free Loss for Arbitrary Oriented Object Detection in Aerial Images"></a>ABFL: Angular Boundary Discontinuity Free Loss for Arbitrary Oriented Object Detection in Aerial Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12311">http://arxiv.org/abs/2311.12311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zifei Zhao, Shengyang Li</li>
<li>for: 这篇论文主要关注的是空中图像中的自由方向物体检测（AOOD） task，并且提出了一个基于 von Mises 分布的 Angular Boundary Free Loss（ABFL）来解决了这个问题。</li>
<li>methods: 本文使用了一个简单且有效的方法，即将角度视为圆形数据，从而引入角度周期性来减少ABD问题，并且不需要额外的编码-解码结构。</li>
<li>results: 实验结果显示，提出的ABFL损失函数可以比一些州前方法更好地解决ABD问题，并且在DOTA和HRSC2016数据集上表现出色。<details>
<summary>Abstract</summary>
Arbitrary oriented object detection (AOOD) in aerial images is a widely concerned and highly challenging task, and plays an important role in many scenarios. The core of AOOD involves the representation, encoding, and feature augmentation of oriented bounding-boxes (Bboxes). Existing methods lack intuitive modeling of angle difference measurement in oriented Bbox representations. Oriented Bboxes under different representations exhibit rotational symmetry with varying periods due to angle periodicity. The angular boundary discontinuity (ABD) problem at periodic boundary positions is caused by rotational symmetry in measuring angular differences. In addition, existing methods also use additional encoding-decoding structures for oriented Bboxes. In this paper, we design an angular boundary free loss (ABFL) based on the von Mises distribution. The ABFL aims to solve the ABD problem when detecting oriented objects. Specifically, ABFL proposes to treat angles as circular data rather than linear data when measuring angle differences, aiming to introduce angle periodicity to alleviate the ABD problem and improve the accuracy of angle difference measurement. In addition, ABFL provides a simple and effective solution for various periodic boundary discontinuities caused by rotational symmetry in AOOD tasks, as it does not require additional encoding-decoding structures for oriented Bboxes. Extensive experiments on the DOTA and HRSC2016 datasets show that the proposed ABFL loss outperforms some state-of-the-art methods focused on addressing the ABD problem.
</details>
<details>
<summary>摘要</summary>
aerial 图像中的随机方向对象检测（AOOD）是一项广泛关注且高度挑战的任务，对多种场景都具有重要作用。 AOOD 的核心在于对 oriented bounding-boxes（Bboxes）的表示、编码和特征增强。现有方法缺乏对夹角差的直观表示。oriented Bboxes 在不同的表示下展现出固定期的旋转对称，导致测量夹角差的问题。此外，现有方法还使用了额外的编码-解码结构 для oriented Bboxes。在这篇论文中，我们设计了一种角度边界缺失损失（ABFL）基于麦斯维度分布。ABFL 目的是解决在检测oriented对象时出现的夹角边界缺失问题。特别是，ABFL 将 treat angles 为圆形数据而不是直线数据，以便在测量夹角差时引入圆形对称，以解决夹角边界缺失问题并提高对角度差的准确度。此外，ABFL 不需要额外的编码-解码结构，可以简单地和有效地解决由旋转对称引起的 periodic boundary discontinuities 在 AOOD 任务中。广泛的实验表明，我们提出的 ABFL 损失可以超越一些专注于解决 ABD 问题的state-of-the-art方法。
</details></li>
</ul>
<hr>
<h2 id="Challenges-in-Video-Based-Infant-Action-Recognition-A-Critical-Examination-of-the-State-of-the-Art"><a href="#Challenges-in-Video-Based-Infant-Action-Recognition-A-Critical-Examination-of-the-State-of-the-Art" class="headerlink" title="Challenges in Video-Based Infant Action Recognition: A Critical Examination of the State of the Art"></a>Challenges in Video-Based Infant Action Recognition: A Critical Examination of the State of the Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12300">http://arxiv.org/abs/2311.12300</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ostadabbas/video-based-infant-action-recognition">https://github.com/ostadabbas/video-based-infant-action-recognition</a></li>
<li>paper_authors: Elaheh Hatamimajoumerd, Pooria Daneshvar Kakhaki, Xiaofei Huang, Lingfei Luan, Somaieh Amraee, Sarah Ostadabbas</li>
<li>for: 这个论文的目的是研究婴儿动作识别，这是计算机视觉领域的一个快速发展领域，有很多应用，例如监控、安全、人computer交互、医疗诊断等。</li>
<li>methods: 这篇论文使用了一个新的数据集“InfActPrimitive”，这个数据集包含5种重要的婴儿发展阶段动作类别，并使用了专门的预处理技术来处理婴儿数据。</li>
<li>results: 研究发现，使用 poseC3D 模型可以达到约71%的准确率，但其他模型很难正确地捕捉婴儿动作的动态特征。这显示出婴儿动作识别领域和成年人动作识别领域之间的知识差距非常大，需要开发数据效率的管道模型。<details>
<summary>Abstract</summary>
Automated human action recognition, a burgeoning field within computer vision, boasts diverse applications spanning surveillance, security, human-computer interaction, tele-health, and sports analysis. Precise action recognition in infants serves a multitude of pivotal purposes, encompassing safety monitoring, developmental milestone tracking, early intervention for developmental delays, fostering parent-infant bonds, advancing computer-aided diagnostics, and contributing to the scientific comprehension of child development. This paper delves into the intricacies of infant action recognition, a domain that has remained relatively uncharted despite the accomplishments in adult action recognition. In this study, we introduce a groundbreaking dataset called ``InfActPrimitive'', encompassing five significant infant milestone action categories, and we incorporate specialized preprocessing for infant data. We conducted an extensive comparative analysis employing cutting-edge skeleton-based action recognition models using this dataset. Our findings reveal that, although the PoseC3D model achieves the highest accuracy at approximately 71%, the remaining models struggle to accurately capture the dynamics of infant actions. This highlights a substantial knowledge gap between infant and adult action recognition domains and the urgent need for data-efficient pipeline models.
</details>
<details>
<summary>摘要</summary>
自动化人类动作识别，计算机视觉领域的一个快速发展领域，具有广泛的应用领域，包括监控、安全、人机交互、 теле医疗和体育分析。精准的 infant 动作识别服务多种重要目的，包括安全监控、发展阶段跟踪、早期发现发展延迟、促进父母婴儿缔造、计算机助け的诊断和加强科学child development的认知。本文对 infant 动作识别领域进行了深入的分析，这个领域尚未得到了成人动作识别领域的同等关注，尽管在成人动作识别方面已经取得了 significante accomplishments。在这项研究中，我们提出了一个名为“InfActPrimitive”的新的数据集，包括5个重要的 infant 针对动作类别，并对婴儿数据进行了特殊的预处理。我们通过使用 cutting-edge skeleton-based action recognition models 对这个数据集进行了广泛的比较分析。我们的发现表明，虽然 PoseC3D 模型的准确率达到了大约 71%，但其他模型很难准确地捕捉婴儿动作的动态特征。这种情况 highlights 成人动作识别领域和 infant 动作识别领域之间的知识差距，以及需要数据效率的ipeline models。
</details></li>
</ul>
<hr>
<h2 id="Instance-aware-3D-Semantic-Segmentation-powered-by-Shape-Generators-and-Classifiers"><a href="#Instance-aware-3D-Semantic-Segmentation-powered-by-Shape-Generators-and-Classifiers" class="headerlink" title="Instance-aware 3D Semantic Segmentation powered by Shape Generators and Classifiers"></a>Instance-aware 3D Semantic Segmentation powered by Shape Generators and Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12291">http://arxiv.org/abs/2311.12291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Sun, Qixing Huang, Xiangru Huang</li>
<li>for: 本研究旨在提出一种新的3Dsemantic segmentation方法，能够在实例 уров层提取形状信息。</li>
<li>methods: 该方法结合了多个geometry处理任务，以实例水平进行监督，以提高学习的特征表示。具体来说，该方法使用形状生成器和形状分类器来进行形状重建和分类任务，以便在不同实例之间共享相似的形状特征。</li>
<li>results: 在多个公共benchmark上，该方法与现有方法进行比较，得到了显著的性能提升。<details>
<summary>Abstract</summary>
Existing 3D semantic segmentation methods rely on point-wise or voxel-wise feature descriptors to output segmentation predictions. However, these descriptors are often supervised at point or voxel level, leading to segmentation models that can behave poorly at instance-level. In this paper, we proposed a novel instance-aware approach for 3D semantic segmentation. Our method combines several geometry processing tasks supervised at instance-level to promote the consistency of the learned feature representation. Specifically, our methods use shape generators and shape classifiers to perform shape reconstruction and classification tasks for each shape instance. This enforces the feature representation to faithfully encode both structural and local shape information, with an awareness of shape instances. In the experiments, our method significantly outperform existing approaches in 3D semantic segmentation on several public benchmarks, such as Waymo Open Dataset, SemanticKITTI and ScanNetV2.
</details>
<details>
<summary>摘要</summary>
现有的3Dsemantic segmentation方法通常采用点级或封顶级特征描述器来输出 segmentation 预测。然而，这些描述器经常是以点或封顶为基础，导致 segmentation 模型在实例级别上表现不佳。在这篇论文中，我们提出了一种新的实例意识的方法 для 3Dsemantic segmentation。我们的方法结合了多个geometry处理任务，以实例级supervise 来提高学习的特征表示的一致性。Specifically，我们使用形态生成器和形态分类器来实现形态重建和分类任务，以确保特征表示能够准确地编码 strucutral 和局部形态信息，同时具备实例意识。在实验中，我们的方法在多个公共benchmark上显著超过了现有方法，如 Waymo Open Dataset、SemanticKITTI 和 ScanNetV2。
</details></li>
</ul>
<hr>
<h2 id="Procedural-Generation-of-Grain-Orientations-using-the-Wave-Function-Collapse-Algorithm"><a href="#Procedural-Generation-of-Grain-Orientations-using-the-Wave-Function-Collapse-Algorithm" class="headerlink" title="Procedural Generation of Grain Orientations using the Wave Function Collapse Algorithm"></a>Procedural Generation of Grain Orientations using the Wave Function Collapse Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12272">http://arxiv.org/abs/2311.12272</a></li>
<li>repo_url: None</li>
<li>paper_authors: G. Magny-Fokam, D. Madisetti, J. El-Awady</li>
<li>for: 研究生成代表性的颗粒微结构，以便进一步分析附加的塑性和失效行为。</li>
<li>methods: 使用Wave Function Collapse（WFC）算法和Markov Junior（MJ）软件进行生成代表性颗粒微结构。</li>
<li>results: Markov Junior算法能够生成具有相似orientation和体积分数的 Voronoi划分，可以用于生成EBSD图像，并且与参考图像的orientation和体积分数相似。<details>
<summary>Abstract</summary>
Statistics of grain sizes and orientations in metals correlate to the material's mechanical properties. Reproducing representative volume elements for further analysis of deformation and failure in metals, like 316L stainless steel, is particularly important due to their wide use in manufacturing goods today. Two approaches, initially created for video games, were considered for the procedural generation of representative grain microstructures. The first is the Wave Function Collapse (WFC) algorithm, and the second is constraint propagation and probabilistic inference through Markov Junior, a free and open-source software. This study aimed to investigate these two algorithms' effectiveness in using reference electron backscatter diffraction (EBSD) maps and recreating a statistically similar one that could be used in further research. It utilized two stainless steel EBSD maps as references to test both algorithms. First, the WFC algorithm was too constricting and, thus, incapable of producing images that resembled EBSDs. The second, MarkovJunior, was much more effective in creating a Voronoi tessellation that could be used to create an EBSD map in Python. When comparing the results between the reference and the generated EBSD, we discovered that the orientation and volume fractions were extremely similar. With the study, it was concluded that MarkovJunior is an effective machine learning tool that can reproduce representative grain microstructures.
</details>
<details>
<summary>摘要</summary>
统计性粉体大小和方向在金属中与材料的机械性能相关。为了进一步分析金属的变形和失败，如316L不锈钢，复制代表性粉体微结构非常重要。这种问题的两种方法， initially created for video games， were considered for the procedural generation of representative grain microstructures。一个是波函数崩溃（WFC）算法，另一个是Markov Junior，一个免费和开源的软件。本研究的目的是调查这两种算法在使用参考电子后退干涉diffraction（EBSD）地图来生成一个统计相似的粉体微结构，并在Python中使用Voronoi划分来生成EBSD地图。使用了两个钢铁EBSD地图作为参考，我们发现WFC算法无法生成与EBSD地图相似的图像。然而，Markov Junior算法非常有效，可以生成一个Voronoi划分，并在Python中使用这个划分来生成一个EBSD地图。对比refs和生成的EBSD地图，我们发现它们的方向和体积分布非常相似。结论是Markov Junior是一个有效的机器学习工具，可以复制代表性粉体微结构。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Audio-visual-Zero-shot-Learning-with-Large-Language-Models"><a href="#Boosting-Audio-visual-Zero-shot-Learning-with-Large-Language-Models" class="headerlink" title="Boosting Audio-visual Zero-shot Learning with Large Language Models"></a>Boosting Audio-visual Zero-shot Learning with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12268">http://arxiv.org/abs/2311.12268</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenhaoxing/KDA">https://github.com/chenhaoxing/KDA</a></li>
<li>paper_authors: Haoxing Chen, Yaohui Li, Yan Hong, Zizheng Huang, Zhuoer Xu, Zhangxuan Gu, Jun Lan, Huijia Zhu, Weiqiang Wang</li>
<li>for: Recognize unseen categories based on paired audio-visual sequences.</li>
<li>methods: Propose a simple yet effective framework named Knowledge-aware Distribution Adaptation (KDA) to better grasp novel action contents with an external knowledge base.</li>
<li>results: Outperform state-of-the-art methods on three popular audio-visual zero-shot learning datasets.<details>
<summary>Abstract</summary>
Audio-visual zero-shot learning aims to recognize unseen categories based on paired audio-visual sequences. Recent methods mainly focus on learning aligned and discriminative multi-modal features to boost generalization towards unseen categories. However, these approaches ignore the obscure action concepts in category names and may inevitably introduce complex network structures with difficult training objectives. In this paper, we propose a simple yet effective framework named Knowledge-aware Distribution Adaptation (KDA) to help the model better grasp the novel action contents with an external knowledge base. Specifically, we first propose using large language models to generate rich descriptions from category names, which leads to a better understanding of unseen categories. Additionally, we propose a distribution alignment loss as well as a knowledge-aware adaptive margin loss to further improve the generalization ability towards unseen categories. Extensive experimental results demonstrate that our proposed KDA can outperform state-of-the-art methods on three popular audio-visual zero-shot learning datasets. Our code will be avaliable at \url{https://github.com/chenhaoxing/KDA}.
</details>
<details>
<summary>摘要</summary>
audio-visual零shot学习目标是通过对应的音频视频序列认识未经见过的类别。现有方法主要关注学习对应的多Modal特征，以提高对未经见过的类别的泛化能力。然而，这些方法可能忽略类别名称中的抽象动作概念，并且可能会采用复杂的网络结构和困难的训练目标。在这篇论文中，我们提出了一个简单 yet effective的框架，即知识aware Distribution Adaptation（KDA），以帮助模型更好地理解未经见过的动作内容。 Specifically,我们首先提出使用大型自然语言模型生成类别名称中的丰富描述，以便更好地理解未经见过的类别。其次，我们提出了分布对齐损失以及知识aware adaptive Margin损失，以进一步提高对未经见过的类别的泛化能力。我们的实验结果表明，我们的提出的KDA可以在三个 популяр的 audio-visual零shot学习数据集上表现出色，超过当前state-of-the-art方法。我们的代码将在 \url{https://github.com/chenhaoxing/KDA} 上提供。
</details></li>
</ul>
<hr>
<h2 id="Virtual-Home-Staging-Inverse-Rendering-and-Editing-an-Indoor-Panorama-under-Natural-Illumination"><a href="#Virtual-Home-Staging-Inverse-Rendering-and-Editing-an-Indoor-Panorama-under-Natural-Illumination" class="headerlink" title="Virtual Home Staging: Inverse Rendering and Editing an Indoor Panorama under Natural Illumination"></a>Virtual Home Staging: Inverse Rendering and Editing an Indoor Panorama under Natural Illumination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12265">http://arxiv.org/abs/2311.12265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gzhji/cali-hdr-dataset">https://github.com/gzhji/cali-hdr-dataset</a></li>
<li>paper_authors: Guanzhou Ji, Azadeh O. Sawyer, Srinivasa G. Narasimhan</li>
<li>for: 这篇论文是为了解决现有indoor panoramic图像下新家具布局的问题，使用自然照明。</li>
<li>methods: 该方法包括三个关键组成部分：（1）扫描房间内的家具检测和移除，（2）自动生成房间地板设计，（3）基于场景几何、新家具对象和实时户外照片的全景渲染。</li>
<li>results: 该方法可以在不同的户外照明条件下实现indoor场景的重新渲染，并且提供了一个新的标准化HDR数据集（Cali-HDR），包括137个标准化indoor panoramic图像和其关联的户外照片。<details>
<summary>Abstract</summary>
We propose a novel inverse rendering method that enables the transformation of existing indoor panoramas with new indoor furniture layouts under natural illumination. To achieve this, we captured indoor HDR panoramas along with real-time outdoor hemispherical HDR photographs. Indoor and outdoor HDR images were linearly calibrated with measured absolute luminance values for accurate scene relighting. Our method consists of three key components: (1) panoramic furniture detection and removal, (2) automatic floor layout design, and (3) global rendering with scene geometry, new furniture objects, and a real-time outdoor photograph. We demonstrate the effectiveness of our workflow in rendering indoor scenes under different outdoor illumination conditions. Additionally, we contribute a new calibrated HDR (Cali-HDR) dataset that consists of 137 calibrated indoor panoramas and their associated outdoor photographs. The source code and dataset are available: https://github.com/Gzhji/Cali-HDR-Dataset.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的反向渲染方法，可以将现有的室内投影改变为新的室内家具布局，同时在自然照明下进行变换。为实现这一点，我们捕捉了室内高Dynamic Range（HDR）投影，以及实时的外部半球形HDR照片。室内和外部HDR图像在灯光照明下进行线性投影，并与测量的绝对亮度值进行准确的场景重新照明。我们的方法包括三个关键组成部分：（1）投影式家具检测和移除，（2）自动化地板设计，（3）基于场景几何、新的家具对象和实时外部照片的全球渲染。我们 demonstarte了我们的工作流程可以在不同的外部照明条件下进行渲染室内场景。此外，我们还提供了一个新的标准化HDR（Cali-HDR）数据集，该数据集包括137个标准化的室内投影和其相关的外部照片。源代码和数据集可以在以下链接中下载：https://github.com/Gzhji/Cali-HDR-Dataset。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/cs.CV_2023_11_21/" data-id="clpxp6c2p00noee8889axhkes" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/cs.AI_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T12:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/cs.AI_2023_11_21/">cs.AI - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Intrinsic-Image-Decomposition-via-Ordinal-Shading"><a href="#Intrinsic-Image-Decomposition-via-Ordinal-Shading" class="headerlink" title="Intrinsic Image Decomposition via Ordinal Shading"></a>Intrinsic Image Decomposition via Ordinal Shading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12792">http://arxiv.org/abs/2311.12792</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/compphoto/Intrinsic">https://github.com/compphoto/Intrinsic</a></li>
<li>paper_authors: Chris Careaga, Yağız Aksoy</li>
<li>for: 高级视觉问题：解剖照明照片和计算摄影涂抹</li>
<li>methods: 使用分解问题为两个部分：首先使用稳定的损失函数来估算精度的排序颜色信息，然后将低分辨率和高分辨率的估算结果集成在一起，通过第二个网络来生成具有全局协调和地方细节的颜色估算。</li>
<li>results: 对比州前方法，我们的方法可以更高精度地估算照明照片的内在分解结果，并且可以进行难以实现的编辑任务，如重新彩色和重新照明。<details>
<summary>Abstract</summary>
Intrinsic decomposition is a fundamental mid-level vision problem that plays a crucial role in various inverse rendering and computational photography pipelines. Generating highly accurate intrinsic decompositions is an inherently under-constrained task that requires precisely estimating continuous-valued shading and albedo. In this work, we achieve high-resolution intrinsic decomposition by breaking the problem into two parts. First, we present a dense ordinal shading formulation using a shift- and scale-invariant loss in order to estimate ordinal shading cues without restricting the predictions to obey the intrinsic model. We then combine low- and high-resolution ordinal estimations using a second network to generate a shading estimate with both global coherency and local details. We encourage the model to learn an accurate decomposition by computing losses on the estimated shading as well as the albedo implied by the intrinsic model. We develop a straightforward method for generating dense pseudo ground truth using our model's predictions and multi-illumination data, enabling generalization to in-the-wild imagery. We present an exhaustive qualitative and quantitative analysis of our predicted intrinsic components against state-of-the-art methods. Finally, we demonstrate the real-world applicability of our estimations by performing otherwise difficult editing tasks such as recoloring and relighting.
</details>
<details>
<summary>摘要</summary>
内在分解是视觉领域的基本中等问题，对各种 inverse rendering 和计算摄影管道起着关键作用。生成高度准确的内在分解是一个具有内在约束的不充分定的任务，需要精准地估计连续值的颜色和反射率。在这种工作中，我们通过分解问题为两个部分来实现高分辨率内在分解。首先，我们提出了一种密集的ORDINAL颜色表示方法，使用偏移量和缩放不变的损失函数来估计ORDINAL颜色提示，而不是限制预测符合内在模型。然后，我们将低分辨率和高分辨率的ORDINAL估计结合使用第二个网络来生成具有全局准确性和本地细节的颜色估计。我们将模型学习准确地分解，通过计算预测的颜色和内在模型预测的反射率之间的损失函数。我们开发了一种简单的方法来生成密集的pseudo实际数据，使得模型可以通过多光源数据进行普适化。我们进行了详细的qualitative和量化分析，证明我们的预测结果与现状方法相比具有明显的优势。最后，我们示出了使用我们的估计结果进行其他难以完成的编辑任务，如重新颜色和重新照明。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Impairment-and-Disease-Severity-Using-AI-Models-Trained-on-Healthy-Subjects"><a href="#Quantifying-Impairment-and-Disease-Severity-Using-AI-Models-Trained-on-Healthy-Subjects" class="headerlink" title="Quantifying Impairment and Disease Severity Using AI Models Trained on Healthy Subjects"></a>Quantifying Impairment and Disease Severity Using AI Models Trained on Healthy Subjects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12781">http://arxiv.org/abs/2311.12781</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fishneck/cobra">https://github.com/fishneck/cobra</a></li>
<li>paper_authors: Boyang Yu, Aakash Kaku, Kangning Liu, Avinash Parnandi, Emily Fokas, Anita Venkatesan, Natasha Pandit, Rajesh Ranganath, Heidi Schambra, Carlos Fernandez-Granda</li>
<li>for: 这 paper aims to address the challenge of automatic assessment of impairment and disease severity in data-driven medicine.</li>
<li>methods: The proposed framework leverages AI models trained exclusively on healthy individuals to quantify the deviation of impaired or diseased patients from the healthy population.</li>
<li>results: The COBRA score, computed automatically in under one minute, is strongly correlated with the gold-standard Fugl-Meyer Assessment on two different data modalities (wearable sensors and video) and demonstrates generalizability to other conditions such as knee osteoarthritis.<details>
<summary>Abstract</summary>
Automatic assessment of impairment and disease severity is a key challenge in data-driven medicine. We propose a novel framework to address this challenge, which leverages AI models trained exclusively on healthy individuals. The COnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the decrease in confidence of these models when presented with impaired or diseased patients to quantify their deviation from the healthy population. We applied the COBRA score to address a key limitation of current clinical evaluation of upper-body impairment in stroke patients. The gold-standard Fugl-Meyer Assessment (FMA) requires in-person administration by a trained assessor for 30-45 minutes, which restricts monitoring frequency and precludes physicians from adapting rehabilitation protocols to the progress of each patient. The COBRA score, computed automatically in under one minute, is shown to be strongly correlated with the FMA on an independent test cohort for two different data modalities: wearable sensors ($\rho = 0.845$, 95% CI [0.743,0.908]) and video ($\rho = 0.746$, 95% C.I [0.594, 0.847]). To demonstrate the generalizability of the approach to other conditions, the COBRA score was also applied to quantify severity of knee osteoarthritis from magnetic-resonance imaging scans, again achieving significant correlation with an independent clinical assessment ($\rho = 0.644$, 95% C.I [0.585,0.696]).
</details>
<details>
<summary>摘要</summary>
自动评估残疾和疾病严重度是数据驱动医学中的关键挑战。我们提出了一种新的框架，利用专门用于健康人群训练的AI模型来解决这一挑战。我们称之为COBRA分数（Confidence-Based chaRacterization of Anomalies），它利用这些模型对受损或疾病患者的诊断时的信任度下降来衡量其与健康人群的偏差。我们应用了COBRA分数来解决现有的评估障碍肢上的问题，由于评估需要专业评估员在面对面进行30-45分钟的评估，这限制了监测频率和防止医生根据患者的进步而适应复制办法。COBRA分数可以在一分钟内自动计算，与FMA（Fugl-Meyer评估）的黄金标准相比，在独立测试集上显示强相关性（$\rho = 0.845$, 95% CI [0.743,0.908]）和视频数据（$\rho = 0.746$, 95% C.I [0.594, 0.847]）两种数据模式上。为了证明该方法的普适性，我们还应用了COBRA分数来评估关节风扁病的严重程度，并在独立评估中获得了 statistically significant相关性（$\rho = 0.644$, 95% C.I [0.585,0.696]）。
</details></li>
</ul>
<hr>
<h2 id="Digital-Twin-Framework-for-Optimal-and-Autonomous-Decision-Making-in-Cyber-Physical-Systems-Enhancing-Reliability-and-Adaptability-in-the-Oil-and-Gas-Industry"><a href="#Digital-Twin-Framework-for-Optimal-and-Autonomous-Decision-Making-in-Cyber-Physical-Systems-Enhancing-Reliability-and-Adaptability-in-the-Oil-and-Gas-Industry" class="headerlink" title="Digital Twin Framework for Optimal and Autonomous Decision-Making in Cyber-Physical Systems: Enhancing Reliability and Adaptability in the Oil and Gas Industry"></a>Digital Twin Framework for Optimal and Autonomous Decision-Making in Cyber-Physical Systems: Enhancing Reliability and Adaptability in the Oil and Gas Industry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12755">http://arxiv.org/abs/2311.12755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carine Menezes Rebello, Johannes Jäschkea, Idelfonso B. R. Nogueira</li>
<li>for: 这个研究的目的是为了提出一个能够在生产过程中实现自主决策的数位双（DT）框架，以增强生产过程中的可靠性和适应力。</li>
<li>methods: 这个研究使用了数位双框架，融合了潜在推理、蒙地卡罗 simulate、传播学习、在线学习和新的战略，包括模型高维度减少和认知攻击。</li>
<li>results: 这个研究获得了一个能够高效、可靠、信任worthy的数位双识别框架，并且可以在变化的环境下适应和 incorporating prediction uncertainty，进一步增强了生产过程中的决策过程。<details>
<summary>Abstract</summary>
The concept of creating a virtual copy of a complete Cyber-Physical System opens up numerous possibilities, including real-time assessments of the physical environment and continuous learning from the system to provide reliable and precise information. This process, known as the twinning process or the development of a digital twin (DT), has been widely adopted across various industries. However, challenges arise when considering the computational demands of implementing AI models, such as those employed in digital twins, in real-time information exchange scenarios. This work proposes a digital twin framework for optimal and autonomous decision-making applied to a gas-lift process in the oil and gas industry, focusing on enhancing the robustness and adaptability of the DT. The framework combines Bayesian inference, Monte Carlo simulations, transfer learning, online learning, and novel strategies to confer cognition to the DT, including model hyperdimensional reduction and cognitive tack. Consequently, creating a framework for efficient, reliable, and trustworthy DT identification was possible. The proposed approach addresses the current gap in the literature regarding integrating various learning techniques and uncertainty management in digital twin strategies. This digital twin framework aims to provide a reliable and efficient system capable of adapting to changing environments and incorporating prediction uncertainty, thus enhancing the overall decision-making process in complex, real-world scenarios. Additionally, this work lays the foundation for further developments in digital twins for process systems engineering, potentially fostering new advancements and applications across various industrial sectors.
</details>
<details>
<summary>摘要</summary>
“创建虚拟复制物的概念打开了许多可能性，如实时评估物理环境和持续学习系统以提供可靠和精准的信息。这个过程，称为虚拟孪生（DT）的开发过程，在不同的业务中广泛应用。但是，在实时信息交换场景中考虑AI模型的计算需求时，会遇到挑战。这种工作提出了一个用于油气业中气动压过程的数字孪生框架，以提高DT的可靠性和自适应性。该框架结合 bayesian 推理、蒙地卡罗 simulate、传输学习、在线学习和创新的策略，包括模型高维度减少和认知护卫。因此，创建高效、可靠、信任worthy的DT标识框架成为可能。该提出的方法填补了现有文献中 интеGRating 多种学习技术和不确定性管理在数字孪生策略中的空白。这个数字孪生框架目标是提供可靠和高效的系统，能够适应变化的环境，并将预测不确定性纳入决策过程中，从而提高复杂实际场景中的决策过程。此外，这种工作为数字孪生技术的进一步发展和应用奠定了基础，可能激发新的进步和应用于不同的产业领域。”
</details></li>
</ul>
<hr>
<h2 id="SelfOcc-Self-Supervised-Vision-Based-3D-Occupancy-Prediction"><a href="#SelfOcc-Self-Supervised-Vision-Based-3D-Occupancy-Prediction" class="headerlink" title="SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction"></a>SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12754">http://arxiv.org/abs/2311.12754</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huang-yh/selfocc">https://github.com/huang-yh/selfocc</a></li>
<li>paper_authors: Yuanhui Huang, Wenzhao Zheng, Borui Zhang, Jie Zhou, Jiwen Lu</li>
<li>for: 提高视觉自动驾驶的稳定性，预测周围3D空间中每个点的占用状态。</li>
<li>methods: 使用自我超级vised学习方法，只使用视频序列来学习3D占用状态。将图像转换到3D空间（例如，鸟瞰视角），然后对3D表示进行约束，并使用多个深度提案来直接优化SDF引用的 weights。</li>
<li>results: 与前一个最佳方法SceneRF相比，SelfOcc在SemanticKITTI上提高了58.7%的性能，并在Occ3D上生成了可靠的3D占用状态。在SemanticKITTI、KITTI-2015和nuScenes等 datasets上，SelfOcc实现了高质量的深度和达到了状态监测的最新水平。代码：<a target="_blank" rel="noopener" href="https://github.com/huang-yh/SelfOcc%E3%80%82">https://github.com/huang-yh/SelfOcc。</a><details>
<summary>Abstract</summary>
3D occupancy prediction is an important task for the robustness of vision-centric autonomous driving, which aims to predict whether each point is occupied in the surrounding 3D space. Existing methods usually require 3D occupancy labels to produce meaningful results. However, it is very laborious to annotate the occupancy status of each voxel. In this paper, we propose SelfOcc to explore a self-supervised way to learn 3D occupancy using only video sequences. We first transform the images into the 3D space (e.g., bird's eye view) to obtain 3D representation of the scene. We directly impose constraints on the 3D representations by treating them as signed distance fields. We can then render 2D images of previous and future frames as self-supervision signals to learn the 3D representations. We propose an MVS-embedded strategy to directly optimize the SDF-induced weights with multiple depth proposals. Our SelfOcc outperforms the previous best method SceneRF by 58.7% using a single frame as input on SemanticKITTI and is the first self-supervised work that produces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc produces high-quality depth and achieves state-of-the-art results on novel depth synthesis, monocular depth estimation, and surround-view depth estimation on the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code: https://github.com/huang-yh/SelfOcc.
</details>
<details>
<summary>摘要</summary>
“3D占用预测是自主驾驶视觉系统中的一项重要任务，它目的是预测环境中每个点是否占用。现有方法通常需要3D占用标签以生成有意义的结果。然而， annotating each voxel's occupancy status is very laborious。在这篇论文中，我们提出了一种自动学习的方法，名为SelfOcc，以使用仅仅是视频序列来学习3D占用。我们首先将图像转换到3D空间（例如，鸟瞰视）以获得场景的3D表示。我们直接对3D表示进行约束，并将其视为签名距离场景。我们可以将先前和后续帧的2D图像渲染成自我超级视觉信号，以便学习3D表示。我们提出了一种嵌入MVS的策略，以直接优化SDF引起的权重。我们的SelfOcc在使用单帧输入时与前一个最佳方法SceneRF的比较达到58.7%的提升。SelfOcc是第一个使用自动学习方法生成有理性3D占用的周边摄像头的自主驾驶方法。SelfOcc在SemanticKITTI、KITTI-2015和nuScenes等三个数据集上取得了最高质量的深度和状态图像，并在新的深度Synthesis、单目深度估计和周边视图深度估计方面取得了最高的成绩。代码：https://github.com/huang-yh/SelfOcc。”
</details></li>
</ul>
<hr>
<h2 id="Image-Transformation-for-IoT-Time-Series-Data-A-Review"><a href="#Image-Transformation-for-IoT-Time-Series-Data-A-Review" class="headerlink" title="Image Transformation for IoT Time-Series Data: A Review"></a>Image Transformation for IoT Time-Series Data: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12742">http://arxiv.org/abs/2311.12742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duygu Altunkaya, Feyza Yildirim Okay, Suat Ozdemir</li>
<li>for: 本研究评论使用图像变换&#x2F;编码技术在IoT领域中进行时间序列数据分类。</li>
<li>methods: 本研究使用图像变换&#x2F;编码技术来转换IoT时间序列数据，并对这些图像进行学习模型训练。</li>
<li>results: 本研究发现，使用图像变换&#x2F;编码技术可以提高IoT时间序列数据分类的性能，并且可以捕捉到时间序列数据中隐藏的动态模式和趋势。<details>
<summary>Abstract</summary>
In the era of the Internet of Things (IoT), where smartphones, built-in systems, wireless sensors, and nearly every smart device connect through local networks or the internet, billions of smart things communicate with each other and generate vast amounts of time-series data. As IoT time-series data is high-dimensional and high-frequency, time-series classification or regression has been a challenging issue in IoT. Recently, deep learning algorithms have demonstrated superior performance results in time-series data classification in many smart and intelligent IoT applications. However, it is hard to explore the hidden dynamic patterns and trends in time-series. Recent studies show that transforming IoT data into images improves the performance of the learning model. In this paper, we present a review of these studies which use image transformation/encoding techniques in IoT domain. We examine the studies according to their encoding techniques, data types, and application areas. Lastly, we emphasize the challenges and future dimensions of image transformation.
</details>
<details>
<summary>摘要</summary>
在互联网物联网（IoT）时代，智能手机、内置系统、无线传感器和几乎所有智能设备通过本地网络或互联网相连，数以亿计的智能东西通过无线方式进行通信，生成大量时间序列数据。由于IoT时间序列数据具有高维度和高频率，时间序列分类或回归成为IoT中的挑战。然而，深度学习算法在IoT应用中表现出色，尤其是在时间序列数据分类方面。然而，挖掘时间序列中隐藏的动态模式和趋势却是一大挑战。近年来，一些研究使用图像转换/编码技术来解决这个问题。在本文中，我们对这些研究进行了一个回顾，分析了他们的编码技术、数据类型和应用领域。最后，我们还强调了图像转换的挑战和未来维度。
</details></li>
</ul>
<hr>
<h2 id="Content-Augmented-Graph-Neural-Networks"><a href="#Content-Augmented-Graph-Neural-Networks" class="headerlink" title="Content Augmented Graph Neural Networks"></a>Content Augmented Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12741">http://arxiv.org/abs/2311.12741</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fatemehgholamzadeh/augss-gnn">https://github.com/fatemehgholamzadeh/augss-gnn</a></li>
<li>paper_authors: Fatemeh Gholamzadeh Nasrabadi, AmirHossein Kashani, Pegah Zahedi, Mostafa Haghir Chehreghani</li>
<li>for: 本文提出了一种基于图 neural network (GNN) 的方法，以解决图上问题。这些模型通常利用图的链接结构，并在每层更新节点的嵌入。但是，在这些层次上应用的筛子或卷积会导致初始嵌入的影响减弱，无法在最终嵌入中产生重要效果。</li>
<li>methods: 本文提出了一种解决这个问题的方法，即在 GNN 层次上计算节点的结构嵌入和内容嵌入，并将这两个嵌入组合成节点的嵌入。此外，文章还提出了一些实现方法，如使用自动编码器或建立内容图。</li>
<li>results: 通过在多个真实世界数据集上进行实验，文章证明了该方法的高精度和性能。<details>
<summary>Abstract</summary>
In recent years, graph neural networks (GNNs) have become a popular tool for solving various problems over graphs. In these models, the link structure of the graph is typically exploited and nodes' embeddings are iteratively updated based on adjacent nodes. Nodes' contents are used solely in the form of feature vectors, served as nodes' first-layer embeddings. However, the filters or convolutions, applied during iterations/layers to these initial embeddings lead to their impact diminish and contribute insignificantly to the final embeddings. In order to address this issue, in this paper we propose augmenting nodes' embeddings by embeddings generating from their content, at higher GNN layers. More precisely, we propose models wherein a structural embedding using a GNN and a content embedding are computed for each node. These two are combined using a combination layer to form the embedding of a node at a given layer. We suggest methods such as using an auto-encoder or building a content graph, to generate content embeddings. In the end, by conducting experiments over several real-world datasets, we demonstrate the high accuracy and performance of our models.
</details>
<details>
<summary>摘要</summary>
近年来，图 нейрон网络（GNNs）已成为解决各种图问题的流行工具。在这些模型中，图的链接结构通常被利用，并且节点的嵌入是基于邻居节点的更新。节点的内容仅用作节点的第一层嵌入，而在迭代层次中应用的筛选器或卷积操作会导致它们的影响减弱，对最终嵌入的贡献微不足。为了解决这问题，在本文中我们提出了在高层次GNN层次添加节点嵌入的方法。具体来说，我们提出了一种结构嵌入使用GNN和内容嵌入，并将这两个嵌入组合在一起，以形成每个节点的嵌入。我们还提出了使用自动编码器或构建内容图来生成内容嵌入的方法。在实验中，我们通过使用多个真实世界数据集，证明了我们的模型的高精度和性能。
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Legal-Document-AI-Chatbot"><a href="#Development-of-a-Legal-Document-AI-Chatbot" class="headerlink" title="Development of a Legal Document AI-Chatbot"></a>Development of a Legal Document AI-Chatbot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12719">http://arxiv.org/abs/2311.12719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranav Nataraj Devaraj, Rakesh Teja P V, Aaryav Gangrade, Manoj Kumar R</li>
<li>for: 该论文目的是开发一个智能的法律文档谈判机器人，以帮助处理大量的数字法律文档。</li>
<li>methods: 该论文使用了许多相关的技术，包括机器学习、自然语言处理和人机交互。具体来说，该论文使用了一个Android应用程序和Langchain查询处理代码，并通过Flask后端和REST API方式进行集成。</li>
<li>results: 该论文通过实现了一个功能强大的法律文档谈判机器人，可以帮助减少法律文档的处理时间和劳动力成本。<details>
<summary>Abstract</summary>
With the exponential growth of digital data and the increasing complexity of legal documentation, there is a pressing need for efficient and intelligent tools to streamline the handling of legal documents.With the recent developments in the AI field, especially in chatbots, it cannot be ignored as a very compelling solution to this problem.An insight into the process of creating a Legal Documentation AI Chatbot with as many relevant features as possible within the given time frame is presented.The development of each component of the chatbot is presented in detail.Each component's workings and functionality has been discussed.Starting from the build of the Android app and the Langchain query processing code till the integration of both through a Flask backend and REST API methods.
</details>
<details>
<summary>摘要</summary>
中文简体版随着数字数据的急速增长和法律文书的日益复杂化，有一项急需快速有效的工具来简化法律文书的处理。尤其是在人工智能领域的最新发展，尝试不可以忽略聊天机器人的潜在解决方案。本文将对创建法律文书AI聊天机器人的过程进行详细介绍，包括最 relevante 的功能。从安卓应用程序的构建到语言链查询处理代码的集成，以及通过Flask后端和REST API方法的集成。Each component of the chatbot and its workings have been discussed in detail, including the build of the Android app and the Langchain query processing code, as well as the integration of both through a Flask backend and REST API methods.
</details></li>
</ul>
<hr>
<h2 id="minimax-Efficient-Baselines-for-Autocurricula-in-JAX"><a href="#minimax-Efficient-Baselines-for-Autocurricula-in-JAX" class="headerlink" title="minimax: Efficient Baselines for Autocurricula in JAX"></a>minimax: Efficient Baselines for Autocurricula in JAX</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12716">http://arxiv.org/abs/2311.12716</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/minimax">https://github.com/facebookresearch/minimax</a></li>
<li>paper_authors: Minqi Jiang, Michael Dennis, Edward Grefenstette, Tim Rocktäschel</li>
<li>for: 本研究旨在提高自动课程学习（Unsupervised Environment Design，UED）的训练效率，以便培养具有零基eline转移能力的决策maker。</li>
<li>methods: 本研究使用JAX实现了全张量环境和自动课程算法，并使用加速硬件进行编译。</li>
<li>results: 与前一代实现相比，本研究在同等批处理大小的情况下实现了更 чем 120倍的速度提升。<details>
<summary>Abstract</summary>
Unsupervised environment design (UED) is a form of automatic curriculum learning for training robust decision-making agents to zero-shot transfer into unseen environments. Such autocurricula have received much interest from the RL community. However, UED experiments, based on CPU rollouts and GPU model updates, have often required several weeks of training. This compute requirement is a major obstacle to rapid innovation for the field. This work introduces the minimax library for UED training on accelerated hardware. Using JAX to implement fully-tensorized environments and autocurriculum algorithms, minimax allows the entire training loop to be compiled for hardware acceleration. To provide a petri dish for rapid experimentation, minimax includes a tensorized grid-world based on MiniGrid, in addition to reusable abstractions for conducting autocurricula in procedurally-generated environments. With these components, minimax provides strong UED baselines, including new parallelized variants, which achieve over 120$\times$ speedups in wall time compared to previous implementations when training with equal batch sizes. The minimax library is available under the Apache 2.0 license at https://github.com/facebookresearch/minimax.
</details>
<details>
<summary>摘要</summary>
自动课程学习环境设计（UED）是一种自动课程学习方法，用于培养具有零shot传输能力的决策agt。这种自动课程学习方法在RL社区中受到了广泛的关注。然而，UED实验通常需要数周的训练时间，这使得快速创新在该领域受到了阻碍。本工作介绍了用于UED训练的加速硬件库minimax。使用JAX实现完全张量化环境和自动课程算法，minimax可以将整个训练循环编译到硬件加速器上。为提供快速实验的环境，minimax包含了张量化网格世界，以及可重用的自动课程抽象，用于在生成的环境中进行自动课程。通过这些组件，minimax提供了强大的UED基线，包括新的并行化变体，其在与批处理大小相同的情况下实现了120倍的增速。minimax库可以在Apache 2.0 许可下从https://github.com/facebookresearch/minimax获取。
</details></li>
</ul>
<hr>
<h2 id="Alpha-Zero-for-Physics-Application-of-Symbolic-Regression-with-Alpha-Zero-to-find-the-analytical-methods-in-physics"><a href="#Alpha-Zero-for-Physics-Application-of-Symbolic-Regression-with-Alpha-Zero-to-find-the-analytical-methods-in-physics" class="headerlink" title="Alpha Zero for Physics: Application of Symbolic Regression with Alpha Zero to find the analytical methods in physics"></a>Alpha Zero for Physics: Application of Symbolic Regression with Alpha Zero to find the analytical methods in physics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12713">http://arxiv.org/abs/2311.12713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yoshihiro Michishita</li>
<li>for:  Physicists can use machine learning to find analytical methods.</li>
<li>methods:  The paper proposes using the Alpha Zero algorithm (AZfP) to develop analytical methods in physics.</li>
<li>results:  The paper demonstrates that AZfP can derive the high-frequency expansion in Floquet systems.Here’s the full text in Simplified Chinese:</li>
<li>for: Physics中使用机器学习找到分析方法。</li>
<li>methods: 本文提出使用Alpha Zero算法（AZfP）发展物理分析方法。</li>
<li>results: 本文示例展示AZfP可以 derivate Floquet系统的高频扩展。I hope that helps!<details>
<summary>Abstract</summary>
Machine learning with neural networks is now becoming a more and more powerful tool for various tasks, such as natural language processing, image recognition, winning the game, and even for the issues of physics. Although there are many studies on the application of machine learning to numerical calculation and the assistance of experimental detection, the methods of applying machine learning to find the analytical method are poorly studied. In this paper, we propose the frameworks of developing analytical methods in physics by using the symbolic regression with the Alpha Zero algorithm, that is Alpha Zero for physics (AZfP). As a demonstration, we show that AZfP can derive the high-frequency expansion in the Floquet systems. AZfP may have the possibility of developing a new theoretical framework in physics.
</details>
<details>
<summary>摘要</summary>
机器学习与神经网络现在成为了许多任务的更加有力的工具，如自然语言处理、图像识别、游戏赢得和物理问题。虽然有许多关于机器学习的应用于数值计算和实验探测的研究，但使用机器学习找到分析方法的方法尚未得到充分研究。在这篇论文中，我们提出了在物理中使用符号回归和Alpha Zero算法来开发分析方法的框架，即Alpha Zero for Physics（AZfP）。为了展示，我们显示了AZfP可以 derivate Floquet系统中的高频扩展。AZfP可能有可能开发出新的物理理论框架。Note: "Floquet系统" in the original text is translated as "Floquet系统" in Simplified Chinese, which is the pinyin Romanization of the Chinese term. The correct Chinese term for "Floquet system" is "托托列系统" (tàotào lèixìtsū) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Keeping-Users-Engaged-During-Repeated-Administration-of-the-Same-Questionnaire-Using-Large-Language-Models-to-Reliably-Diversify-Questions"><a href="#Keeping-Users-Engaged-During-Repeated-Administration-of-the-Same-Questionnaire-Using-Large-Language-Models-to-Reliably-Diversify-Questions" class="headerlink" title="Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions"></a>Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12707">http://arxiv.org/abs/2311.12707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hye Sun Yun, Mehdi Arjmand, Phillip Raymond Sherlock, Michael Paasche-Orlow, James W. Griffith, Timothy Bickmore</li>
<li>for: 这篇论文旨在提供一种使用大语言模型生成多种问卷版本，同时保持对 psychometric properties 的控制方法，以解决问卷疲劳问题。</li>
<li>methods: 本研究使用了大语言模型 (LLM) 生成问卷版本，并与专业评估问卷进行比较，以评估其灵活性和有效性。</li>
<li>results: 研究结果显示，LLM-生成问卷版本能够保持与外部标准相似的可靠性和有效性，而且 participants 评价这些问卷版本为比较有趣和有吸引力的。<details>
<summary>Abstract</summary>
Standardized, validated questionnaires are vital tools in HCI research and healthcare, offering dependable self-report data. However, their repeated use in longitudinal or pre-post studies can induce respondent fatigue, impacting data quality via response biases and decreased response rates. We propose utilizing large language models (LLMs) to generate diverse questionnaire versions while retaining good psychometric properties. In a longitudinal study, participants engaged with our agent system and responded daily for two weeks to either a standardized depression questionnaire or one of two LLM-generated questionnaire variants, alongside a validated depression questionnaire. Psychometric testing revealed consistent covariation between the external criterion and the focal measure administered across the three conditions, demonstrating the reliability and validity of the LLM-generated variants. Participants found the repeated administration of the standardized questionnaire significantly more repetitive compared to the variants. Our findings highlight the potential of LLM-generated variants to invigorate questionnaires, fostering engagement and interest without compromising validity.
</details>
<details>
<summary>摘要</summary>
标准化、验证的问卷是人机交互研究和医疗领域的重要工具，提供可靠的自报数据。然而，在长期或预后研究中，重复使用标准问卷可能会导致参与者疲劳，影响数据质量via 响应偏见和回答率下降。我们建议使用大语言模型（LLM）生成多个问卷版本，保持好的心理测量属性。在一个长期研究中，参与者与我们的代理系统交互，每天对于两周都回答了标准化的抑郁问卷或LLM生成的两个问卷变体，并且与验证的抑郁问卷一起进行心理测量。心理测量表明，在三个条件下，外部标准和关键测量之间存在一致的 covariation，证明LLM生成的变体具有可靠性和有效性。参与者认为，通过 repeatedly 使用标准问卷 significantly 更加厌恶，与变体相比。我们的发现指出，LLM生成的变体可以激励问卷，提高参与者的参与度和兴趣，不会COMPROMISE 有效性。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Understand-Content-and-Propagation-for-Misinformation-Detection-An-Empirical-Study"><a href="#Can-Large-Language-Models-Understand-Content-and-Propagation-for-Misinformation-Detection-An-Empirical-Study" class="headerlink" title="Can Large Language Models Understand Content and Propagation for Misinformation Detection: An Empirical Study"></a>Can Large Language Models Understand Content and Propagation for Misinformation Detection: An Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12699">http://arxiv.org/abs/2311.12699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengyang Chen, Lingwei Wei, Han Cao, Wei Zhou, Songlin Hu</li>
<li>for: 本研究探讨了大型自然语言模型（LLMs）在识别假信息任务中的表现。</li>
<li>methods: 本研究使用多种提示来评估多种LLMs的理解能力，并设计了四种 instrucion-tuned 策略来提高 LLMS 的识别性能。</li>
<li>results: 研究发现，使用多种提示的 LLMs 在文本基于的假信息检测任务中具有相似的表现，但在媒体传播结构基于的假信息检测任务中表现较差。同时，提出的四种 instrucion-tuned 策略可以提高 LLMS 的识别性能。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have garnered significant attention for their powerful ability in natural language understanding and reasoning. In this paper, we present a comprehensive empirical study to explore the performance of LLMs on misinformation detection tasks. This study stands as the pioneering investigation into the understanding capabilities of multiple LLMs regarding both content and propagation across social media platforms. Our empirical studies on five misinformation detection datasets show that LLMs with diverse prompts achieve comparable performance in text-based misinformation detection but exhibit notably constrained capabilities in comprehending propagation structure compared to existing models in propagation-based misinformation detection. Besides, we further design four instruction-tuned strategies to enhance LLMs for both content and propagation-based misinformation detection. These strategies boost LLMs to actively learn effective features from multiple instances or hard instances, and eliminate irrelevant propagation structures, thereby achieving better detection performance. Extensive experiments further demonstrate LLMs would play a better capacity in content and propagation structure under these proposed strategies and achieve promising detection performance. These findings highlight the potential ability of LLMs to detect misinformation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="From-Concept-to-Manufacturing-Evaluating-Vision-Language-Models-for-Engineering-Design"><a href="#From-Concept-to-Manufacturing-Evaluating-Vision-Language-Models-for-Engineering-Design" class="headerlink" title="From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design"></a>From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12668">http://arxiv.org/abs/2311.12668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyril Picard, Kristen M. Edwards, Anna C. Doris, Brandon Man, Giorgio Giannone, Md Ferdous Alam, Faez Ahmed<br>for:This paper aims to evaluate the capabilities of a multimodal vision language model, GPT-4V, in a wide range of engineering design tasks, including conceptual design, system-level and detailed design, manufacturing and inspection, and engineering education tasks.methods:The paper uses a comprehensive evaluation of GPT-4V across a variety of engineering design tasks, including sketch similarity analysis, concept selection using Pugh Charts, material selection, engineering drawing analysis, CAD generation, topology optimization, design for additive and subtractive manufacturing, spatial reasoning challenges, and textbook problems.results:The study shows that GPT-4V demonstrates impressive capabilities in handling complex design and manufacturing challenges, but also identifies its limitations in complex engineering design applications. The paper provides a foundation for future assessments of vision language models and contributes a set of benchmark testing datasets for ongoing advancements in this field.<details>
<summary>Abstract</summary>
Engineering Design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning. Large language models have demonstrated impressive capabilities in enabling this shift. Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to. This gap is addressed with the release of multimodal vision language models, such as GPT-4V, enabling AI to impact many more types of tasks. In light of these advancements, this paper presents a comprehensive evaluation of GPT-4V, a vision language model, across a wide spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks. Our study assesses GPT-4V's capabilities in design tasks such as sketch similarity analysis, concept selection using Pugh Charts, material selection, engineering drawing analysis, CAD generation, topology optimization, design for additive and subtractive manufacturing, spatial reasoning challenges, and textbook problems. Through this structured evaluation, we not only explore GPT-4V's proficiency in handling complex design and manufacturing challenges but also identify its limitations in complex engineering design applications. Our research establishes a foundation for future assessments of vision language models, emphasizing their immense potential for innovating and enhancing the engineering design and manufacturing landscape. It also contributes a set of benchmark testing datasets, with more than 1000 queries, for ongoing advancements and applications in this field.
</details>
<details>
<summary>摘要</summary>
工程设计正在通过人工智能的普及，开启一个新的时代，推动产品、系统和服务规划的方式。大型自然语言模型已经表现出了很好的能力，但它们只能通过文本作为输入模式，无法利用工程师 centuries 使用的大量视觉文件。这个问题被解决通过多Modal 视觉语言模型的推出，如 GPT-4V，使得人工智能能够影响更多类型的任务。鉴于这些进步，本文对 GPT-4V 进行了全面的评估，在工程设计任务中分为四个主要领域：概念设计、系统级别和细节设计、制造和检查、工程教育任务。我们的研究评估 GPT-4V 在设计任务中的能力，包括绘制相似性分析、选择 Pugh 图表、材料选择、工程图分析、 CAD 生成、顺序优化、设计增加和减少制造、空间逻辑挑战和文本教材问题。通过这种结构化的评估，我们不仅探索 GPT-4V 在复杂设计和制造挑战中的能力，还提出了它在复杂工程设计应用中的局限性。我们的研究建立了未来评估视觉语言模型的基础，强调它们在工程设计和制造领域的潜在潜力，并提供了一个包含超过 1000 个查询的测试数据集，为未来的进步和应用提供了基础。
</details></li>
</ul>
<hr>
<h2 id="The-DURel-Annotation-Tool-Human-and-Computational-Measurement-of-Semantic-Proximity-Sense-Clusters-and-Semantic-Change"><a href="#The-DURel-Annotation-Tool-Human-and-Computational-Measurement-of-Semantic-Proximity-Sense-Clusters-and-Semantic-Change" class="headerlink" title="The DURel Annotation Tool: Human and Computational Measurement of Semantic Proximity, Sense Clusters and Semantic Change"></a>The DURel Annotation Tool: Human and Computational Measurement of Semantic Proximity, Sense Clusters and Semantic Change</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12664">http://arxiv.org/abs/2311.12664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Schlechtweg, Shafqat Mumtaz Virk, Pauline Sander, Emma Sköldberg, Lukas Theuer Linke, Tuo Zhang, Nina Tahmasebi, Jonas Kuhn, Sabine Schulte im Walde</li>
<li>for: 这篇论文是为了介绍一种新的word-in-context模型，用于实现语义距离的注释。</li>
<li>methods: 这篇论文使用了标准化的人工注释和计算注释，并使用Word-in-Context模型来建立语义距离的注释。</li>
<li>results: 该工具可以快速和简单地实现语义距离的注释，并提供了对注释审核者之间的一致性和时间变化的整体分析。<details>
<summary>Abstract</summary>
We present the DURel tool that implements the annotation of semantic proximity between uses of words into an online, open source interface. The tool supports standardized human annotation as well as computational annotation, building on recent advances with Word-in-Context models. Annotator judgments are clustered with automatic graph clustering techniques and visualized for analysis. This allows to measure word senses with simple and intuitive micro-task judgments between use pairs, requiring minimal preparation efforts. The tool offers additional functionalities to compare the agreement between annotators to guarantee the inter-subjectivity of the obtained judgments and to calculate summary statistics giving insights into sense frequency distributions, semantic variation or changes of senses over time.
</details>
<details>
<summary>摘要</summary>
我团队现在发布了一个名为DURel的工具，它实现了将单词之间语义靠近性的注释转化为在线、开源界面上的工具。该工具支持标准化的人类注释以及计算机注释，基于最近的Word-in-Context模型。注释审核结果使用图像聚合技术集成并可视化分析，以测量单词的感知词语分布。这使得可以通过简单和直观的微任务判断对用语对之间的语义关系，需要最小的准备努力。工具还提供了比较注释者之间的一致性，以及计算概念频率分布、语义变化或时间变化的摘要统计信息。
</details></li>
</ul>
<hr>
<h2 id="PARK-Parkinson’s-Analysis-with-Remote-Kinetic-tasks"><a href="#PARK-Parkinson’s-Analysis-with-Remote-Kinetic-tasks" class="headerlink" title="PARK: Parkinson’s Analysis with Remote Kinetic-tasks"></a>PARK: Parkinson’s Analysis with Remote Kinetic-tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12654">http://arxiv.org/abs/2311.12654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Saiful Islam, Sangwu Lee, Abdelrahman Abdelkader, Sooyong Park, Ehsan Hoque</li>
<li>for: 这个研究是为了开发一个基于网络的诊断渠道，帮助患有parkinson病的人进行家庭中的诊断。</li>
<li>methods: 这个研究使用了三种任务，包括语音、表情和手部运动，并通过分析这些任务的视频来诊断患有parkinson病的人。</li>
<li>results: 这个研究得到了一种简单易于理解的结果，同时还提供了个性化的资源，以便患有parkinson病的人可以更好地访问治疗和护理。<details>
<summary>Abstract</summary>
We present a web-based framework to screen for Parkinson's disease (PD) by allowing users to perform neurological tests in their homes. Our web framework guides the users to complete three tasks involving speech, facial expression, and finger movements. The task videos are analyzed to classify whether the users show signs of PD. We present the results in an easy-to-understand manner, along with personalized resources to further access to treatment and care. Our framework is accessible by any major web browser, improving global access to neurological care.
</details>
<details>
<summary>摘要</summary>
我们提供一套基于网络的框架，以帮助用户在家中进行parkinson病（PD）的检测。我们的网络框架会引导用户完成三项任务，包括语音、面部表达和手指运动。这些任务的视频会被分析，以确定用户是否显示出PD的 symptoms。我们将结果显示在易于理解的方式下，并提供个性化的资源，以便更好地访问治疗和护理。我们的框架可以通过任何主要浏览器访问，从而提高全球神经科学的访问度。
</details></li>
</ul>
<hr>
<h2 id="Mobile-Seed-Joint-Semantic-Segmentation-and-Boundary-Detection-for-Mobile-Robots"><a href="#Mobile-Seed-Joint-Semantic-Segmentation-and-Boundary-Detection-for-Mobile-Robots" class="headerlink" title="Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots"></a>Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12651">http://arxiv.org/abs/2311.12651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/WHU-USI3DV/Mobile-Seed">https://github.com/WHU-USI3DV/Mobile-Seed</a></li>
<li>paper_authors: Youqi Liao, Shuhao Kang, Jianping Li, Yang Liu, Yun Liu, Zhen Dong, Bisheng Yang, Xieyuanli Chen</li>
<li>for: 本研究旨在提供一个轻量级的双任务框架，以同时提高 semantic segmentation 和 bounding detection 的性能。</li>
<li>methods: 该框架包括两条流量对应的 encoder，以及一个 active fusion decoder (AFD) 和双任务调整方法。encoder 分为两条路径：一条捕捉类别意识的 semantic information，另一条从多个比例特征中提取 bounding information。AFD 模组在内部学习通道之间的关系，以允许精确地将每个通道的重要性分配。</li>
<li>results: 比较 existing methods，提案的 Mobile-Seed 提供了轻量级的框架，以提高 semantic segmentation 性能和精确地定义物体 bounding。Cityscapes 数据集的实验结果显示，Mobile-Seed 与 SOTA 基eline 相比，提高了 2.2 分点 (pp) 的 mIoU 和 4.2 pp 的 mF-score，并维持在线执行速度为 23.9 帧&#x2F;秒 (FPS) 的 1024x2048 分辨率输入上的 RTX 2080 Ti GPU 上。<details>
<summary>Abstract</summary>
Precise and rapid delineation of sharp boundaries and robust semantics is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units. Although boundary detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection. In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection. Our framework features a two-stream encoder, an active fusion decoder (AFD) and a dual-task regularization approach. The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features. The AFD module dynamically adapts the fusion of semantic and boundary information by learning channel-wise relationships, allowing for precise weight assignment of each channel. Furthermore, we introduce a regularization loss to mitigate the conflicts in dual-task learning and deep diversity supervision. Compared to existing methods, the proposed Mobile-Seed offers a lightweight framework to simultaneously improve semantic segmentation performance and accurately locate object boundaries. Experiments on the Cityscapes dataset have shown that Mobile-Seed achieves notable improvement over the state-of-the-art (SOTA) baseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while maintaining an online inference speed of 23.9 frames-per-second (FPS) with 1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on CamVid and PASCAL Context datasets confirm our method's generalizability. Code and additional results are publicly available at \url{https://martin-liao.github.io/Mobile-Seed/}.
</details>
<details>
<summary>摘要</summary>
必须准确快速地定义锐利边界和 Robust  semantics，以便 robotic 任务中的许多任务，如机器人抓取和处理、实时 semantic mapping 和在 Edge computing 单元上进行的 online sensor calibration。虽然边界探测和semantic segmentation 是 complementary 任务，但大多数研究强调轻量级模型 для semantic segmentation，忽略了边界探测的重要性。在这种情况下，我们引入 Mobile-Seed，一个轻量级、双任务框架，适用于同时进行 semantic segmentation 和边界探测。我们的框架包括两条通道：一个捕捉类别意识的信息，另一个是从多尺度特征中提取边界信息。我们的 AFD 模块可以动态地适应 semantic 和边界信息的融合，通过学习通道之间的关系，以便精确地分配每个通道的Weight。此外，我们还引入了一种调节 dual-task 学习和深度多样性supervision的损失函数。相比现有方法，我们的 Mobile-Seed 提供了一个轻量级的框架，可以同时提高 semantic segmentation 性能和精确地定义 объек 的边界。我们在 Cityscapes 数据集上进行了实验，并证明了我们的方法可以与状态理论（SOTA）基eline 相比，在 mIoU 和 mF-score 中提高了2.2个百分点和4.2个百分点，同时保持在线推理速度为23.9帧/秒，分辨率为1024x2048，使用 RTX 2080 Ti GPU。其他 CamVid 和 PASCAL Context 数据集的实验证明了我们的方法的普适性。代码和更多的结果可以在 \url{https://martin-liao.github.io/Mobile-Seed/} 上找到。
</details></li>
</ul>
<hr>
<h2 id="KNVQA-A-Benchmark-for-evaluation-knowledge-based-VQA"><a href="#KNVQA-A-Benchmark-for-evaluation-knowledge-based-VQA" class="headerlink" title="KNVQA: A Benchmark for evaluation knowledge-based VQA"></a>KNVQA: A Benchmark for evaluation knowledge-based VQA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12639">http://arxiv.org/abs/2311.12639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sirui Cheng, Siyu Zhang, Jiayi Wu, Muchen Lan</li>
<li>for: 这项研究的目的是提出一种新的知识基于VQA任务评估方法，以评估multimodal LVLMs的实际性。</li>
<li>methods: 该研究使用了一种新的KNVQA数据集，通过综合评估LVLMs的语言和视觉系统的感知和理解能力，以及相关的知识信息。</li>
<li>results: 研究发现，现有的LVLMs在知识基于VQA任务中存在诸如 объек hallucination 和 factual accuracy 等问题，而且先前的评估方法更关注语言内容的理解和推理能力，缺乏对多modal交互的全面评估。<details>
<summary>Abstract</summary>
Within the multimodal field, large vision-language models (LVLMs) have made significant progress due to their strong perception and reasoning capabilities in the visual and language systems. However, LVLMs are still plagued by the two critical issues of object hallucination and factual accuracy, which limit the practicality of LVLMs in different scenarios. Furthermore, previous evaluation methods focus more on the comprehension and reasoning of language content but lack a comprehensive evaluation of multimodal interactions, thereby resulting in potential limitations. To this end, we propose a novel KNVQA-Eval, which is devoted to knowledge-based VQA task evaluation to reflect the factuality of multimodal LVLMs. To ensure the robustness and scalability of the evaluation, we develop a new KNVQA dataset by incorporating human judgment and perception, aiming to evaluate the accuracy of standard answers relative to AI-generated answers in knowledge-based VQA. This work not only comprehensively evaluates the contextual information of LVLMs using reliable human annotations, but also further analyzes the fine-grained capabilities of current methods to reveal potential avenues for subsequent optimization of LVLMs-based estimators. Our proposed VQA-Eval and corresponding dataset KNVQA will facilitate the development of automatic evaluation tools with the advantages of low cost, privacy protection, and reproducibility. Our code will be released upon publication.
</details>
<details>
<summary>摘要</summary>
在多模态领域，大视语模型（LVLM）已经做出了重要的进步，因为它们在视觉和语言系统中具有强大的感知和理解能力。然而，LVLM仍然面临着两个重要的问题：物体推断和事实准确性，这些问题限制了LVLM在不同场景中的实际应用。此外，前一代评估方法更关注语言内容的理解和推理，而忽略了多模态互动的全面评估，从而可能导致了限制。为此，我们提出了一种新的KNVQA评估方法，专门用于知识基础VQA任务的评估，以反映LVLM的事实准确性。为确保评估的稳定性和可扩展性，我们开发了一个新的KNVQA数据集，通过人类判断和感知来补充标准答案和AI生成的答案之间的差异。这项工作不仅全面评估了LVLM在多模态互动中的上下文信息，还进一步分析了当前方法的细化能力，以揭示可能的优化方向。我们的提出的VQA评估和相应的KNVQA数据集将促进基于LVLM的自动评估工具的开发，具有低成本、隐私保护和可重现性的优点。我们将在发表时释出代码。
</details></li>
</ul>
<hr>
<h2 id="ChessVision-–-A-Dataset-for-Logically-Coherent-Multi-label-Classification"><a href="#ChessVision-–-A-Dataset-for-Logically-Coherent-Multi-label-Classification" class="headerlink" title="ChessVision – A Dataset for Logically Coherent Multi-label Classification"></a>ChessVision – A Dataset for Logically Coherent Multi-label Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12610">http://arxiv.org/abs/2311.12610</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/espressovi/chessvisionchallenge">https://github.com/espressovi/chessvisionchallenge</a></li>
<li>paper_authors: Soumadeep Saha, Utpal Garain</li>
<li>for: 这种研究旨在检验深度学习技术是否能够捕捉围棋游戏中的语义上下文和逻辑约束。</li>
<li>methods: 这个研究使用了一个新的围棋游戏图像集（ChessVision Dataset），并设计了一组约束来限制预测的游戏状态。</li>
<li>results: 研究发现，虽然现有的视觉模型在标准指标上表现出色，但它们在面对这个 dataset 时却产生了大量的不一致结果，表明这个 dataset 对未来研究呈现了 significiant 挑战。<details>
<summary>Abstract</summary>
Starting with early successes in computer vision tasks, deep learning based techniques have since overtaken state of the art approaches in a multitude of domains. However, it has been demonstrated time and again that these techniques fail to capture semantic context and logical constraints, instead often relying on spurious correlations to arrive at the answer. Since application of deep learning techniques to critical scenarios are dependent on adherence to domain specific constraints, several attempts have been made to address this issue. One limitation holding back a thorough exploration of this area, is a lack of suitable datasets which feature a rich set of rules. In order to address this, we present the ChessVision Dataset, consisting of 200,000+ images of annotated chess games in progress, requiring recreation of the game state from its corresponding image. This is accompanied by a curated set of rules which constrains the set of predictions to "reasonable" game states, and are designed to probe key semantic abilities like localization and enumeration. Alongside standard metrics, additional metrics to measure performance with regards to logical consistency is presented. We analyze several popular and state of the art vision models on this task, and show that, although their performance on standard metrics are laudable, they produce a plethora of incoherent results, indicating that this dataset presents a significant challenge for future works.
</details>
<details>
<summary>摘要</summary>
开始于计算机视觉任务的早期成功，深度学习基于技术已经在多个领域超越了国际一级的方法。然而，它们时常不能捕捉 semantic context 和逻辑约束，而是通过偶合关系来得到答案。由于应用深度学习技术到重要的应用场景需要遵循域pecific的约束，因此有几个尝试来解决这个问题。一个 limiting factor 是缺乏适用的数据集，该集feature了丰富的规则。为了解决这个问题，我们提出了ChessVision Dataset，包含200,000+个 annotated chess game的图像，需要从图像中重建棋盘状态。此外，我们还提供了一组约束，以限制预测的set of game states，并且是为了考验关键的 semantic ability，如localization和枚举。在此任务上，我们分析了一些流行的视觉模型，并发现它们的性能在标准 metric 上是卓越的，但它们在这个 dataset 上产生了大量的不一致结果，这表明这个 dataset 对 future works 呈现了一个 significiant challenge。
</details></li>
</ul>
<hr>
<h2 id="Trustworthy-AI-Deciding-What-to-Decide"><a href="#Trustworthy-AI-Deciding-What-to-Decide" class="headerlink" title="Trustworthy AI: Deciding What to Decide"></a>Trustworthy AI: Deciding What to Decide</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12604">http://arxiv.org/abs/2311.12604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Caesar Wu, Yuan-Fang Li, Jian Li, Jingjing Xu, Bouvry Pascal</li>
<li>for: 本研究旨在 Addressing the challenge of determining which information can be trusted when using Artificial Intelligence (AI) systems for decision-making, known as Trustworthy AI (TAI).</li>
<li>methods: 本研究提出了一种新的 TAI 框架，包括 representation space、loss function 和 optimizer 三个关键组件，每个组件具有四个 TAI 属性。</li>
<li>results: 通过 quantitive 和 qualitative 研究方法，本研究实现了 twelve TAI 属性，并提出了一个可以用于应用策略投资决策的优化预测模型。<details>
<summary>Abstract</summary>
When engaging in strategic decision-making, we are frequently confronted with overwhelming information and data. The situation can be further complicated when certain pieces of evidence contradict each other or become paradoxical. The primary challenge is how to determine which information can be trusted when we adopt Artificial Intelligence (AI) systems for decision-making. This issue is known as deciding what to decide or Trustworthy AI. However, the AI system itself is often considered an opaque black box. We propose a new approach to address this issue by introducing a novel framework of Trustworthy AI (TAI) encompassing three crucial components of AI: representation space, loss function, and optimizer. Each component is loosely coupled with four TAI properties. Altogether, the framework consists of twelve TAI properties. We aim to use this framework to conduct the TAI experiments by quantitive and qualitative research methods to satisfy TAI properties for the decision-making context. The framework allows us to formulate an optimal prediction model trained by the given dataset for applying the strategic investment decision of credit default swaps (CDS) in the technology sector. Finally, we provide our view of the future direction of TAI research
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a new approach that includes a novel framework for Trustworthy AI (TAI) that encompasses three crucial components of AI: the representation space, the loss function, and the optimizer. Each component is loosely coupled with four TAI properties. In total, the framework consists of twelve TAI properties. We plan to use this framework to conduct experiments using quantitative and qualitative research methods to satisfy TAI properties for the decision-making context.Using this framework, we can formulate an optimal prediction model trained by the given dataset for applying strategic investment decisions in the technology sector. Finally, we provide our view of the future direction of TAI research.
</details></li>
</ul>
<hr>
<h2 id="Visual-tracking-brain-computer-interface"><a href="#Visual-tracking-brain-computer-interface" class="headerlink" title="Visual tracking brain computer interface"></a>Visual tracking brain computer interface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12592">http://arxiv.org/abs/2311.12592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changxing Huang, Nanlin Shi, Yining Miao, Xiaogang Chen, Yijun Wang, Xiaorong Gao<br>for: 这项研究的目的是提出一种基于视觉神经 Interface (BCI) 的自然 kontinuierliche 控制方法，以超越传统的精确点击响应。methods: 该研究使用了非侵入性的 electroencephalography (EEG) 技术，并实现了一种新的空间编码刺激方法，以及相应的投影方法，以实现连续控制。results: 实验结果显示，该 BCIs 的 Fitt’s ITR 为 0.55 bps 和 0.37 bps，表明该方法可以实现高效的连续控制。此外，该 BCIs 还被应用于绘画和游戏等两个应用程序中。<details>
<summary>Abstract</summary>
Brain-computer interfaces (BCIs) offer a way to interact with computers without relying on physical movements. Non-invasive electroencephalography (EEG)-based visual BCIs, known for efficient speed and calibration ease, face limitations in continuous tasks due to discrete stimulus design and decoding methods. To achieve continuous control, we implemented a novel spatial encoding stimulus paradigm and devised a corresponding projection method to enable continuous modulation of decoded velocity. Subsequently, we conducted experiments involving 17 participants and achieved Fitt's ITR of 0.55 bps for the fixed tracking task and 0.37 bps for the random tracking task. The proposed BCI with a high Fitt's ITR was then integrated into two applications, including painting and gaming. In conclusion, this study proposed a visual BCI-based control method to go beyond discrete commands, allowing natural continuous control based on neural activity.
</details>
<details>
<summary>摘要</summary>
��ubble-computer interfaces (BCIs) offer a way to interact with computers without relying on physical movements. Non-invasive electroencephalography (EEG)-based visual BCIs, known for efficient speed and calibration ease, face limitations in continuous tasks due to discrete stimulus design and decoding methods. To achieve continuous control, we implemented a novel spatial encoding stimulus paradigm and devised a corresponding projection method to enable continuous modulation of decoded velocity. Subsequently, we conducted experiments involving 17 participants and achieved Fitt's ITR of 0.55 bps for the fixed tracking task and 0.37 bps for the random tracking task. The proposed BCI with a high Fitt's ITR was then integrated into two applications, including painting and gaming. In conclusion, this study proposed a visual BCI-based control method to go beyond discrete commands, allowing natural continuous control based on neural activity.Here's the translation in Traditional Chinese as well:��ubble-computer interfaces (BCIs) offer a way to interact with computers without relying on physical movements. Non-invasive electroencephalography (EEG)-based visual BCIs, known for efficient speed and calibration ease, face limitations in continuous tasks due to discrete stimulus design and decoding methods. To achieve continuous control, we implemented a novel spatial encoding stimulus paradigm and devised a corresponding projection method to enable continuous modulation of decoded velocity. Subsequently, we conducted experiments involving 17 participants and achieved Fitt's ITR of 0.55 bps for the fixed tracking task and 0.37 bps for the random tracking task. The proposed BCI with a high Fitt's ITR was then integrated into two applications, including painting and gaming. In conclusion, this study proposed a visual BCI-based control method to go beyond discrete commands, allowing natural continuous control based on neural activity.
</details></li>
</ul>
<hr>
<h2 id="Improving-Source-Free-Target-Adaptation-with-Vision-Transformers-Leveraging-Domain-Representation-Images"><a href="#Improving-Source-Free-Target-Adaptation-with-Vision-Transformers-Leveraging-Domain-Representation-Images" class="headerlink" title="Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images"></a>Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12589">http://arxiv.org/abs/2311.12589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gauransh Sawhney, Daksh Dave, Adeel Ahmed, Jiechao Gao, Khalid Saleem</li>
<li>for: 提高基于ViT的频率预测性能在无源频率预测任务中</li>
<li>methods: 使用DRIs作为域特异标记，并将域特异标记与键元素结合，以提高ViT在源自由目标适应任务中的性能</li>
<li>results: 对于Cross Instance DRI SO控制任务，含DRIs的方法可以提高平均准确率，表明DRIs在UDA任务中对ViT的性能有较大提高作用<details>
<summary>Abstract</summary>
Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer from a labeled source domain to an unlabeled target domain, navigating the obstacle of domain shift. While Convolutional Neural Networks (CNNs) are a staple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for domain generalization. This paper presents an innovative method to bolster ViT performance in source-free target adaptation, beginning with an evaluation of how key, query, and value elements affect ViT outcomes. Experiments indicate that altering the key component has negligible effects on Transformer performance. Leveraging this discovery, we introduce Domain Representation Images (DRIs), feeding embeddings through the key element. DRIs act as domain-specific markers, effortlessly merging with the training regimen. To assess our method, we perform target adaptation tests on the Cross Instance DRI source-only (SO) control. We measure the efficacy of target adaptation with and without DRIs, against existing benchmarks like SHOT-B* and adaptations via CDTrans. Findings demonstrate that excluding DRIs offers limited gains over SHOT-B*, while their inclusion in the key segment boosts average precision promoting superior domain generalization. This research underscores the vital role of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent for further domain adaptation explorations.
</details>
<details>
<summary>摘要</summary>
Unsupervised领域适应（UDA）技术可以将来自已知源频谱的知识传递到无标签目标频谱，缓解频谱差异的障碍。而卷积神经网络（CNNs）是UDA的核心，但是受欢迎的视图转换器（ViTs）也为频谱泛化提供了新的可能性。这篇论文提出了一种创新的方法，用于提高ViT在源频谱自由目标适应中的性能，开始于对键、查询和值元素对ViT的影响进行评估。实验表明，对键元素进行修改对转换器性能的影响是微不足道。基于这一发现，我们引入频谱表示图像（DRIs），将表示图像通过键元素进行 feeding。DRIs acts as domain-specific markers， effortlessly merging with the training regimen。为评估我们的方法，我们在 Cross Instance DRI source-only（SO）控制下进行目标适应测试。我们测量了不包括DRIs的target适应和包括DRIs的target适应，与现有的标准如SHOT-B*和CDTrans的适应进行比较。发现，不包括DRIs的target适应具有有限的提升，而包括DRIs的target适应则提高了平均精度，从而提高了频谱泛化性能。这些研究证明了DRIs在UDA场景中对ViT效率的重要作用，设立了频谱泛化探索的先例。
</details></li>
</ul>
<hr>
<h2 id="Echocardiogram-Foundation-Model-–-Application-1-Estimating-Ejection-Fraction"><a href="#Echocardiogram-Foundation-Model-–-Application-1-Estimating-Ejection-Fraction" class="headerlink" title="Echocardiogram Foundation Model – Application 1: Estimating Ejection Fraction"></a>Echocardiogram Foundation Model – Application 1: Estimating Ejection Fraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12582">http://arxiv.org/abs/2311.12582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adil Dahlan, Cyril Zakka, Abhinav Kumar, Laura Tang, Rohan Shad, Robyn Fong, William Hiesinger</li>
<li>for: 这个论文的目的是提出一种基于自动学习的echocardiogram基础模型，以提高cardiac function的评估精度和效率。</li>
<li>methods: 该模型使用了自动学习（SSL）技术，在150万个echocardiogram中进行自动训练，以提高cardiac function的评估精度和效率。</li>
<li>results: 通过对echocardiogram进行 fine-tuning，模型可以达到专家医生的准确率（9.40%），表明模型的性能与专家医生的评估相当。<details>
<summary>Abstract</summary>
Cardiovascular diseases stand as the primary global cause of mortality. Among the various imaging techniques available for visualising the heart and evaluating its function, echocardiograms emerge as the preferred choice due to their safety and low cost. Quantifying cardiac function based on echocardiograms is very laborious, time-consuming and subject to high interoperator variability. In this work, we introduce EchoAI, an echocardiogram foundation model, that is trained using self-supervised learning (SSL) on 1.5 million echocardiograms. We evaluate our approach by fine-tuning EchoAI to estimate the ejection fraction achieving a mean absolute percentage error of 9.40%. This level of accuracy aligns with the performance of expert sonographers.
</details>
<details>
<summary>摘要</summary>
心血管疾病是全球最主要的死亡原因。 Among various imaging技术用于心脏视图和评估其功能，电子心征成为首选，因为它的安全和成本低。 量化心脏功能基于电子心征是很努力，时间consuming和operator变化很大。 In this work, we introduce EchoAI, an echocardiogram foundation model, which is trained using self-supervised learning (SSL) on 1.5 million echocardiograms. We evaluate our approach by fine-tuning EchoAI to estimate the ejection fraction, achieving a mean absolute percentage error of 9.40%. This level of accuracy aligns with the performance of expert sonographers.Note: "心血管疾病" is a combination of "心血管" (cardiovascular) and "疾病" (disease), and "sonographers" is translated as "专业对心脏的评估专家" (expert sonographers) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="IMGTB-A-Framework-for-Machine-Generated-Text-Detection-Benchmarking"><a href="#IMGTB-A-Framework-for-Machine-Generated-Text-Detection-Benchmarking" class="headerlink" title="IMGTB: A Framework for Machine-Generated Text Detection Benchmarking"></a>IMGTB: A Framework for Machine-Generated Text Detection Benchmarking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12574">http://arxiv.org/abs/2311.12574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michal Spiegel, Dominik Macko<br>for: 本研究旨在提供一个简单易用的测试框架，以便实现机器生成文本检测方法的测试和比较。methods: 本研究使用的方法包括IMGTB框架，可以让研究人员轻松地整合自己的新方法和评估数据，并且提供了一些默认的分析、 метри和可视化工具，以便与现有的国际标准进行比较。results: 本研究的结果显示，IMGTB框架可以轻松地整合新的检测方法和评估数据，并且可以实现简单易用的测试和比较。default set of analyses、metrics和可视化工具，以便与现有的国际标准进行比较。<details>
<summary>Abstract</summary>
In the era of large language models generating high quality texts, it is a necessity to develop methods for detection of machine-generated text to avoid harmful use or simply due to annotation purposes. It is, however, also important to properly evaluate and compare such developed methods. Recently, a few benchmarks have been proposed for this purpose; however, integration of newest detection methods is rather challenging, since new methods appear each month and provide slightly different evaluation pipelines. In this paper, we present the IMGTB framework, which simplifies the benchmarking of machine-generated text detection methods by easy integration of custom (new) methods and evaluation datasets. Its configurability and flexibility makes research and development of new detection methods easier, especially their comparison to the existing state-of-the-art detectors. The default set of analyses, metrics and visualizations offered by the tool follows the established practices of machine-generated text detection benchmarking found in state-of-the-art literature.
</details>
<details>
<summary>摘要</summary>
在大型语言模型生成高质量文本的时代，检测机器生成文本的方法的开发已成为一项必要的任务，以避免恶势力使用或只是因为标注目的。然而，也重要地是正确评估和比较已经开发出来的方法。最近，一些比较标准的测试准则已经被提出来用于这个目的；然而，新方法每月出现一次，它们的评估管道略有不同。本文介绍了IMGTB框架，它使得机器生成文本检测方法的benchmarking更加简单，可以轻松地 интегра部署自定义（新）方法和评估数据集。它的可 configurability和灵活性使得研发新检测方法的研究和开发变得更加容易，特别是与现有的状态对照检测器进行比较。默认的分析、指标和视觉化工具由工具提供，与现有的机器生成文本检测 benchmarking Literature 中的已Established practices相符。
</details></li>
</ul>
<hr>
<h2 id="Moderating-Model-Marketplaces-Platform-Governance-Puzzles-for-AI-Intermediaries"><a href="#Moderating-Model-Marketplaces-Platform-Governance-Puzzles-for-AI-Intermediaries" class="headerlink" title="Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries"></a>Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12573">http://arxiv.org/abs/2311.12573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert Gorwa, Michael Veale</li>
<li>for: 本文探讨了AI系统在多个平台上的Platform Governance问题，即如何管理用户上传的模型和数据。</li>
<li>methods: 本文使用了三个例子来分析平台如何对模型进行模eration：Hugging Face、GitHub和Civitai。</li>
<li>results: 本文结论了现有的industry实践，包括licensing、访问和使用限制、自动内容审核和开放政策开发，以应对模eration问题。<details>
<summary>Abstract</summary>
The AI development community is increasingly making use of hosting intermediaries such as Hugging Face provide easy access to user-uploaded models and training data. These model marketplaces lower technical deployment barriers for hundreds of thousands of users, yet can be used in numerous potentially harmful and illegal ways. In this article, we explain ways in which AI systems, which can both `contain' content and be open-ended tools, present one of the trickiest platform governance challenges seen to date. We provide case studies of several incidents across three illustrative platforms -- Hugging Face, GitHub and Civitai -- to examine how model marketplaces moderate models. Building on this analysis, we outline important (and yet nevertheless limited) practices that industry has been developing to respond to moderation demands: licensing, access and use restrictions, automated content moderation, and open policy development. While the policy challenge at hand is a considerable one, we conclude with some ideas as to how platforms could better mobilize resources to act as a careful, fair, and proportionate regulatory access point.
</details>
<details>
<summary>摘要</summary>
美元发展社区正在越来越多地利用托管中间人如Hugging Face提供用户上传模型和训练数据的容易访问。这些模型市场降低了数量达到百万的用户的技术部署障碍，但可以用于多种可能有害和不法的方式。在这篇文章中，我们介绍了AI系统如何成为Platform Governance挑战之一，该系统可以包含内容并且是开放的工具。我们通过对Hugging Face、GitHub和Civitai等三个示例平台的情况进行分析，探讨了模型市场如何管理模型。以此为基础，我们介绍了行业在应对审核需求方面的重要（却又有限的）实践：许可证、访问和使用限制、自动内容审核、开放政策开发。虽然政策挑战很大，但我们在结尾透过一些想法，以便平台可以更好地借鉴资源，成为一个仔细、公平、评估的法规访问点。
</details></li>
</ul>
<hr>
<h2 id="Scheduling-Distributed-Flexible-Assembly-Lines-using-Safe-Reinforcement-Learning-with-Soft-Shielding"><a href="#Scheduling-Distributed-Flexible-Assembly-Lines-using-Safe-Reinforcement-Learning-with-Soft-Shielding" class="headerlink" title="Scheduling Distributed Flexible Assembly Lines using Safe Reinforcement Learning with Soft Shielding"></a>Scheduling Distributed Flexible Assembly Lines using Safe Reinforcement Learning with Soft Shielding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12572">http://arxiv.org/abs/2311.12572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lele Li, Liyong Lin</li>
<li>for: 这篇论文是为了解决分布式灵活生产线上的作业调度问题，以提高生产效率、减少延迟、提高安全性和可靠性。</li>
<li>methods: 该论文提出了一种基于优先级执行器和批处理学习算法的协调调度方法，以实现分布式灵活生产线上的实时调度。此外，它还提出了一种缩写环境表示方法，以优化行为空间，并使用Monte-Carlo搜索算法来帮助解决长序靠前不安全行为和监测延迟调度的风险。</li>
<li>results: 该论文的实验和评估结果表明，提出的调度方法和软防护Component可以有效地解决分布式灵活生产线上的作业调度问题，提高生产效率和安全性。<details>
<summary>Abstract</summary>
Highly automated assembly lines enable significant productivity gains in the manufacturing industry, particularly in mass production condition. Nonetheless, challenges persist in job scheduling for make-to-job and mass customization, necessitating further investigation to improve efficiency, reduce tardiness, promote safety and reliability. In this contribution, an advantage actor-critic based reinforcement learning method is proposed to address scheduling problems of distributed flexible assembly lines in a real-time manner. To enhance the performance, a more condensed environment representation approach is proposed, which is designed to work with the masks made by priority dispatching rules to generate fixed and advantageous action space. Moreover, a Monte-Carlo tree search based soft shielding component is developed to help address long-sequence dependent unsafe behaviors and monitor the risk of overdue scheduling. Finally, the proposed algorithm and its soft shielding component are validated in performance evaluation.
</details>
<details>
<summary>摘要</summary>
高度自动化的生产线可以实现大量生产的产量增加，但是在make-to-job和个性化生产中，仍然存在困难。为了解决这些问题，本贡献提出了基于优点批评学习的推荐方法，可以在实时下解决分布式 flexible assembly line 的调度问题。为了提高性能，我们还提出了一种更加压缩的环境表示方法，可以通过优先调度规则生成固定和有利的动作空间。此外，我们还开发了基于 Monte-Carlo 搜索的软遮盾组件，可以帮助解决长序 dependent 不安全行为和监测晚点调度的风险。最后，我们验证了提议的算法和软遮盾组件的性能评估。
</details></li>
</ul>
<hr>
<h2 id="Multi-Session-Budget-Optimization-for-Forward-Auction-based-Federated-Learning"><a href="#Multi-Session-Budget-Optimization-for-Forward-Auction-based-Federated-Learning" class="headerlink" title="Multi-Session Budget Optimization for Forward Auction-based Federated Learning"></a>Multi-Session Budget Optimization for Forward Auction-based Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12548">http://arxiv.org/abs/2311.12548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoli Tang, Han Yu</li>
<li>for: 这个研究旨在解决在多次训练Session中，联合学习（Federated Learning，FL）模型用户（Multi-User，MU）需要所有数据所有者（Data Owner，DO）集合在一起才能开始训练的问题。</li>
<li>methods: 本研究提出了一个基于层次强化学习的多Session预算优化策略（Multi-Session Budget Optimization Strategy，MultiBOS-AFL），它将在多Session中协同优化进行拍卖的预算和内部拍卖，以最大化总用户（Utility）。</li>
<li>results: 在六个 benchmark 数据集上进行了广泛的实验，该方法与七种现有的方法进行比较，结果显示，MultiBOS-AFL 可以将总用户提高12.28%，透过拍卖获取更多的数据（14.52%），并且提高模型的测试准确度（1.23%）。<details>
<summary>Abstract</summary>
Auction-based Federated Learning (AFL) has emerged as an important research field in recent years. The prevailing strategies for FL model users (MUs) assume that the entire team of the required data owners (DOs) for an FL task must be assembled before training can commence. In practice, an MU can trigger the FL training process multiple times. DOs can thus be gradually recruited over multiple FL model training sessions. Existing bidding strategies for AFL MUs are not designed to handle such scenarios. Therefore, the problem of multi-session AFL remains open. To address this problem, we propose the Multi-session Budget Optimization Strategy for forward Auction-based Federated Learning (MultiBOS-AFL). Based on hierarchical reinforcement learning, MultiBOS-AFL jointly optimizes inter-session budget pacing and intra-session bidding for AFL MUs, with the objective of maximizing the total utility. Extensive experiments on six benchmark datasets show that it significantly outperforms seven state-of-the-art approaches. On average, MultiBOS-AFL achieves 12.28% higher utility, 14.52% more data acquired through auctions for a given budget, and 1.23% higher test accuracy achieved by the resulting FL model compared to the best baseline. To the best of our knowledge, it is the first budget optimization decision support method with budget pacing capability designed for MUs in multi-session forward auction-based federated learning
</details>
<details>
<summary>摘要</summary>
优胜式联合学习（AFL）在最近几年内成为重要的研究领域。现有的策略假设所有联合数据拥有者（DO）必须在联合学习任务开始之前汇集。然而，实际情况是一个联合学习用户（MU）可以触发多次联合学习训练过程。DO可以逐渐加入多个联合学习训练会议。现有的拍卖策略不能处理这些场景。因此，多会议AFL问题仍然存在。为解决这个问题，我们提出了多会议预算优化策略（MultiBOS-AFL）。基于层次强化学习，MultiBOS-AFL同时优化了间会议预算步骤和会议中拍卖策略，以最大化总用得。经验表明，它在6个标准数据集上表现出色，与7种现有方法相比，平均提高了12.28%的用得，14.52%更多的预算通过拍卖获得，1.23%更高的测试精度。到目前为止，这是首个为MU在多会议前向拍卖基于联合学习的预算优化决策支持方法。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Learning-Functions-with-Varying-Number-of-Minima"><a href="#In-Context-Learning-Functions-with-Varying-Number-of-Minima" class="headerlink" title="In-Context Learning Functions with Varying Number of Minima"></a>In-Context Learning Functions with Varying Number of Minima</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12538">http://arxiv.org/abs/2311.12538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pittnail/icl-minima">https://github.com/pittnail/icl-minima</a></li>
<li>paper_authors: David Oniani, Yanshan Wang</li>
<li>for: 本研究探讨了语言模型在具体上学习（In-Context Learning，ICL）中的表现，以及ICL如何与函数approximation的特性相互作用。</li>
<li>methods: 本研究使用了正式框架来研究ICL，并提出了一种新的函数approximation任务，即将输入作为最小点生成函数。</li>
<li>results: 研究发现，增加最小点数会下降ICL性能，但ICL在所有设置下都能够超越2层神经网络（2NN）模型，并且ICL在所有设置下都能够更快地学习。这些结论得到了一系列几个极少例示的实验 validate。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have proven effective at In-Context Learning (ICL), an ability that allows them to create predictors from labeled examples. Few studies have explored the interplay between ICL and specific properties of functions it attempts to approximate. In our study, we use a formal framework to explore ICL and propose a new task of approximating functions with varying number of minima. We implement a method that allows for producing functions with given inputs as minima. We find that increasing the number of minima degrades ICL performance. At the same time, our evaluation shows that ICL outperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster than 2NN in all settings. We validate the findings through a set of few-shot experiments across various hyperparameter configurations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Oasis-Data-Curation-and-Assessment-System-for-Pretraining-of-Large-Language-Models"><a href="#Oasis-Data-Curation-and-Assessment-System-for-Pretraining-of-Large-Language-Models" class="headerlink" title="Oasis: Data Curation and Assessment System for Pretraining of Large Language Models"></a>Oasis: Data Curation and Assessment System for Pretraining of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12537">http://arxiv.org/abs/2311.12537</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tongzhou21/oasis">https://github.com/tongzhou21/oasis</a></li>
<li>paper_authors: Tong Zhou, Yubo Chen, Pengfei Cao, Kang Liu, Jun Zhao, Shengping Liu</li>
<li>for: 这篇论文的目的是提出一种针对大语言模型数据预处理 corpora 的自动化筛选和评估平台，以提高数据质量和量化。</li>
<li>methods: 该论文使用了一种交互式模块化规则筛选器，可以根据显式反馈来定制规则，以及一种倾斜分类模型来除掉偏见。还有一个可以执行大规模重复的文档去重模块。</li>
<li>results: 该论文通过使用 Oasis 平台对各种数据进行自动化筛选和评估，可以提高数据质量和量化。此外，该论文还公开发布了一个800GB的双语 corpora，以便进一步研究和应用。<details>
<summary>Abstract</summary>
Data is one of the most critical elements in building a large language model. However, existing systems either fail to customize a corpus curation pipeline or neglect to leverage comprehensive corpus assessment for iterative optimization of the curation. To this end, we present a pretraining corpus curation and assessment platform called Oasis -- a one-stop system for data quality improvement and quantification with user-friendly interactive interfaces. Specifically, the interactive modular rule filter module can devise customized rules according to explicit feedback. The debiased neural filter module builds the quality classification dataset in a negative-centric manner to remove the undesired bias. The adaptive document deduplication module could execute large-scale deduplication with limited memory resources. These three parts constitute the customized data curation module. And in the holistic data assessment module, a corpus can be assessed in local and global views, with three evaluation means including human, GPT-4, and heuristic metrics. We exhibit a complete process to use Oasis for the curation and assessment of pretraining data. In addition, an 800GB bilingual corpus curated by Oasis is publicly released.
</details>
<details>
<summary>摘要</summary>
<SYS>  将文本翻译到简化中文。</SYS>大量语言模型的建立需要一些关键元素，其中数据是其中之一。然而，现有系统可能会忽略或者不会自定义 corpus 筛选管道，从而导致不充分利用了全面的 corpus 评估，以便在 Iterative 优化中进行更好的数据优化。为此，我们提出了一个预训练 corpus 筛选和评估平台，称为 Oasis。 Oasis 是一个一站式系统，可以帮助用户提高数据质量，并且具有易用的交互式界面。 Specifically，Oasis 中的交互式模块可以根据用户的Explicit 反馈来制定自定义规则。 debiased  нейрон过滤模块可以在负面中建立质量分类数据集，以移除不良偏见。 Adaptive 文档重复模块可以在有限内存资源下执行大规模重复。这三部分组成了自定义数据筛选模块。而整体数据评估模块可以在本地和全球视图下评估 corpus，并使用人工、GPT-4 和 Heuristic 度量。我们展示了使用 Oasis 进行预训练数据的筛选和评估的完整过程。此外，我们也公共发布了 Oasis 预训练 800GB 双语词库。
</details></li>
</ul>
<hr>
<h2 id="Neural-Network-Pruning-by-Gradient-Descent"><a href="#Neural-Network-Pruning-by-Gradient-Descent" class="headerlink" title="Neural Network Pruning by Gradient Descent"></a>Neural Network Pruning by Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12526">http://arxiv.org/abs/2311.12526</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/3riccc/neural_pruning">https://github.com/3riccc/neural_pruning</a></li>
<li>paper_authors: Zhang Zhang, Ruyi Tao, Jiang Zhang</li>
<li>for: 这篇论文旨在提出一个新的神经网络删除框架，以实现神经网络矩阵和结构同时优化，并且使用泊松-软max技术。</li>
<li>methods: 这个框架使用测量 Gradient Descent 进行统一的优化，可以同时删除神经网络的矩阵和结构，并且可以从删除的网络中提取重要的特征。</li>
<li>results: 实验结果显示，这个框架可以实现高精度的删除，只使用0.15%的原始网络parameters，并且可以增加神经网络的解释性，例如通过直接从删除的网络中提取特征的重要性，以及通过删除的网络中的特征相互关联和结构。<details>
<summary>Abstract</summary>
The rapid increase in the parameters of deep learning models has led to significant costs, challenging computational efficiency and model interpretability. In this paper, we introduce a novel and straightforward neural network pruning framework that incorporates the Gumbel-Softmax technique. This framework enables the simultaneous optimization of a network's weights and topology in an end-to-end process using stochastic gradient descent. Empirical results demonstrate its exceptional compression capability, maintaining high accuracy on the MNIST dataset with only 0.15\% of the original network parameters. Moreover, our framework enhances neural network interpretability, not only by allowing easy extraction of feature importance directly from the pruned network but also by enabling visualization of feature symmetry and the pathways of information propagation from features to outcomes. Although the pruning strategy is learned through deep learning, it is surprisingly intuitive and understandable, focusing on selecting key representative features and exploiting data patterns to achieve extreme sparse pruning. We believe our method opens a promising new avenue for deep learning pruning and the creation of interpretable machine learning systems.
</details>
<details>
<summary>摘要</summary>
“深度学习模型参数的快速增长导致了 significiant 成本、计算效率和模型解释性的挑战。在这篇论文中，我们介绍了一种新的和简单的神经网络剪枝框架，该框架通过使用Gumbel-Softmax技术来同时优化神经网络的权重和结构。我们通过使用渐进式梯度下降来实现这一目标。实验结果表明，我们的框架可以压缩神经网络参数，保持高度准确性，在MNIST数据集上只需0.15%的原始网络参数。此外，我们的框架还提高了神经网络解释性，不仅可以直接从剪枝后的神经网络中提取特征重要性，还可以Visualize特征的对称性和特征征向信息传递的路径。尽管剪枝策略是通过深度学习学习的，但它却感人INTUITIVE和理解，集中于选择关键代表特征并利用数据模式来实现极度稀疏剪枝。我们认为，我们的方法将开启深度学习剪枝的新的可能性，并创造可解释的机器学习系统。”
</details></li>
</ul>
<hr>
<h2 id="ALPHA-AnomaLous-Physiological-Health-Assessment-Using-Large-Language-Models"><a href="#ALPHA-AnomaLous-Physiological-Health-Assessment-Using-Large-Language-Models" class="headerlink" title="ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models"></a>ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12524">http://arxiv.org/abs/2311.12524</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mcjacktang/llm-healthassistant">https://github.com/mcjacktang/llm-healthassistant</a></li>
<li>paper_authors: Jiankai Tang, Kegang Wang, Hongming Hu, Xiyuxing Zhang, Peiyu Wang, Xin Liu, Yuntao Wang</li>
<li>for: 这项研究旨在评估大自然语言模型（LLMs）在医疗领域的有效性，特别是在个人异常健康监测中的应用。我们的研究主要是通过使用获取了FDA批准设备的生物 физиологи数据进行分析和解释来评估LLMs的能力。</li>
<li>methods: 我们使用了一种模拟海拔低压环境中获取的异常生理数据进行了广泛的分析，以评估LLMs在诊断和评估用户健康状况方面的精度和可靠性。</li>
<li>results: 我们发现LLMs在诊断医学指标方面表现出色，包括心率的 Mean Absolute Error（MAE）低于1 beat&#x2F;分钟，和氧气含量（SpO2）的 Mean Absolute Percentage Error（MAPE）低于1%，总的医疗评估准确率超过85%。在图像分析任务中，我们特制的GPT模型在解读光谱波格raph（PPG）数据方面表现出色，MAE低于1 bpm，心率估计 error低于7.28%。这项研究证明LLMs可以作为健康数据分析工具和高级人工智能医疗助手的重要组成部分，提供个性化的健康洞察和建议。<details>
<summary>Abstract</summary>
This study concentrates on evaluating the efficacy of Large Language Models (LLMs) in healthcare, with a specific focus on their application in personal anomalous health monitoring. Our research primarily investigates the capabilities of LLMs in interpreting and analyzing physiological data obtained from FDA-approved devices. We conducted an extensive analysis using anomalous physiological data gathered in a simulated low-air-pressure plateau environment. This allowed us to assess the precision and reliability of LLMs in understanding and evaluating users' health status with notable specificity. Our findings reveal that LLMs exhibit exceptional performance in determining medical indicators, including a Mean Absolute Error (MAE) of less than 1 beat per minute for heart rate and less than 1% for oxygen saturation (SpO2). Furthermore, the Mean Absolute Percentage Error (MAPE) for these evaluations remained below 1%, with the overall accuracy of health assessments surpassing 85%. In image analysis tasks, such as interpreting photoplethysmography (PPG) data, our specially adapted GPT models demonstrated remarkable proficiency, achieving less than 1 bpm error in cycle count and 7.28 MAE for heart rate estimation. This study highlights LLMs' dual role as health data analysis tools and pivotal elements in advanced AI health assistants, offering personalized health insights and recommendations within the future health assistant framework.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Classification-of-Tabular-Data-by-Text-Processing"><a href="#Classification-of-Tabular-Data-by-Text-Processing" class="headerlink" title="Classification of Tabular Data by Text Processing"></a>Classification of Tabular Data by Text Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12521">http://arxiv.org/abs/2311.12521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keshav Ramani, Daniel Borrajo</li>
<li>for: 本研究提出了一个新的文本基于分类框架(Text Based Classification, TBC)，用于应用文本处理技术来解决条件分类任务。</li>
<li>methods: 本研究使用了现代文本处理技术，包括文本特征提取和分类模型。</li>
<li>results: 实验结果显示，TBC框架可以与多种现代分类模型相比，在精度、特征选择和预测类别的精度方面具有相似的性能。<details>
<summary>Abstract</summary>
Natural Language Processing technology has advanced vastly in the past decade. Text processing has been successfully applied to a wide variety of domains. In this paper, we propose a novel framework, Text Based Classification(TBC), that uses state of the art text processing techniques to solve classification tasks on tabular data. We provide a set of controlled experiments where we present the benefits of using this approach against other classification methods. Experimental results on several data sets also show that this framework achieves comparable performance to that of several state of the art models in accuracy, precision and recall of predicted classes.
</details>
<details>
<summary>摘要</summary>
自过去一代，自然语言处理技术有了很大的进步。文本处理技术已经成功应用于各种领域。在这篇论文中，我们提出了一个新的框架，文本基于类别（TBC），它使用现代文本处理技术来解决标量数据上的分类任务。我们提供了一组控制的实验，其中我们展示了使用这种方法的好处，与其他分类方法进行比较。实验结果也显示，这个框架在几个数据集上达到了与当今state of the art模型的准确率、精度和准确率的比较。
</details></li>
</ul>
<hr>
<h2 id="Fin-QD-A-Computational-Design-Framework-for-Soft-Grippers-Integrating-MAP-Elites-and-High-fidelity-FEM"><a href="#Fin-QD-A-Computational-Design-Framework-for-Soft-Grippers-Integrating-MAP-Elites-and-High-fidelity-FEM" class="headerlink" title="Fin-QD: A Computational Design Framework for Soft Grippers: Integrating MAP-Elites and High-fidelity FEM"></a>Fin-QD: A Computational Design Framework for Soft Grippers: Integrating MAP-Elites and High-fidelity FEM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12477">http://arxiv.org/abs/2311.12477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Xie, Xing Wang, Fumiya Iida, David Howard</li>
<li>for: 这个论文旨在开发一种自动化计算设计优化框架，以实现手动设计多种吸盘器，以便在不同物理环境下成功地抓取多种几何体积物体。</li>
<li>methods: 该论文使用了一种基于质量多样性的计算设计优化策略，以探索吸盘器框架设计空间中的巨大可能性空间。同时，使用了SOFA中的 contacts-based Finite Element Modeling（FEM）来生成高精度抓取数据，并对吸盘器的特征进行评估和测量。</li>
<li>results: 该论文通过自动化计算设计优化框架，成功地生成了多种吸盘器设计，以便在不同物理环境下抓取多种几何体积物体。这些设计具有较高的吸盘器体积和工作空间，同时能够在简单的控制方案下实现高效的抓取行为。<details>
<summary>Abstract</summary>
Computational design can excite the full potential of soft robotics that has the drawbacks of being highly nonlinear from material, structure, and contact. Up to date, enthusiastic research interests have been demonstrated for individual soft fingers, but the frame design space (how each soft finger is assembled) remains largely unexplored. Computationally design remains challenging for the finger-based soft gripper to grip across multiple geometrical-distinct object types successfully. Including the design space for the gripper frame can bring huge difficulties for conventional optimisation algorithms and fitness calculation methods due to the exponential growth of high-dimensional design space. This work proposes an automated computational design optimisation framework that generates gripper diversity to individually grasp geometrically distinct object types based on a quality-diversity approach. This work first discusses a significantly large design space (28 design parameters) for a finger-based soft gripper, including the rarely-explored design space of finger arrangement that is converted to various configurations to arrange individual soft fingers. Then, a contact-based Finite Element Modelling (FEM) is proposed in SOFA to output high-fidelity grasping data for fitness evaluation and feature measurements. Finally, diverse gripper designs are obtained from the framework while considering features such as the volume and workspace of grippers. This work bridges the gap of computationally exploring the vast design space of finger-based soft grippers while grasping large geometrically distinct object types with a simple control scheme.
</details>
<details>
<summary>摘要</summary>
computational design可以激发软 robotics的全部潜力，软 robotics具有材料、结构和接触的高度非线性。目前，对具有各种软指的研究兴趣很高，但是把各个软指组装在一起的框架设计空间（软指把手的设计）仍然未得到充分探索。计算机设计对软指抓取器抓取多种几何体型成功仍然是挑战。由于抓取器框架的设计空间是高维的，使用传统优化算法和评价方法会遇到巨大的困难。本工作提出了一个自动化计算设计优化框架，该框架可以生成软指抓取器的多样性，以便在多种几何体型上成功抓取。本工作首先介绍了软指抓取器的庞大设计空间（28个参数），包括软指的布局设计空间，该空间通过不同的配置转换为多种配置。然后，提出了基于SOFA的contact-based Finite Element Modelling（FEM），以生成高精度的抓取数据，用于评价和特征测量。最后，该框架可以从多种 consid=ering特征，如抓取器的体积和工作空间，获得多种软指抓取器的设计。本工作将计算机设计探索软指抓取器的庞大设计空间和多种几何体型之间的关系，提供了一个简单的控制方案。
</details></li>
</ul>
<hr>
<h2 id="PhayaThaiBERT-Enhancing-a-Pretrained-Thai-Language-Model-with-Unassimilated-Loanwords"><a href="#PhayaThaiBERT-Enhancing-a-Pretrained-Thai-Language-Model-with-Unassimilated-Loanwords" class="headerlink" title="PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with Unassimilated Loanwords"></a>PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with Unassimilated Loanwords</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12475">http://arxiv.org/abs/2311.12475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panyut Sriwirote, Jalinee Thapiang, Vasan Timtong, Attapol T. Rutherford</li>
<li>for: 这篇论文是为了提高泰语语言模型的性能，特别是对外语词汇的理解。</li>
<li>methods: 该论文使用了词汇传递法来扩展 WangchanBERTa 的词汇库，并从 XLM-R 的预训练 tokenizer 中获取外语词汇。然后，该论文使用了这个扩展后的 tokenizer 和 WangchanBERTa 的起点Checkpoint来预训练一个新的模型，并在一个更大的数据集上进行训练。</li>
<li>results: 该论文的新预训练模型（即 PhayaThaiBERT）在多个下游任务和数据集上表现出色，比 WangchanBERTa 更高。<details>
<summary>Abstract</summary>
While WangchanBERTa has become the de facto standard in transformer-based Thai language modeling, it still has shortcomings in regard to the understanding of foreign words, most notably English words, which are often borrowed without orthographic assimilation into Thai in many contexts. We identify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the main source of these shortcomings. We then expand WangchanBERTa's vocabulary via vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new model using the expanded tokenizer, starting from WangchanBERTa's checkpoint, on a new dataset that is larger than the one used to train WangchanBERTa. Our results show that our new pretrained model, PhayaThaiBERT, outperforms WangchanBERTa in many downstream tasks and datasets.
</details>
<details>
<summary>摘要</summary>
While WangchanBERTa has become the de facto standard in transformer-based Thai language modeling, it still has shortcomings in regard to the understanding of foreign words, most notably English words, which are often borrowed without orthographic assimilation into Thai in many contexts. We identify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the main source of these shortcomings. We then expand WangchanBERTa's vocabulary via vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new model using the expanded tokenizer, starting from WangchanBERTa's checkpoint, on a new dataset that is larger than the one used to train WangchanBERTa. Our results show that our new pretrained model, PhayaThaiBERT, outperforms WangchanBERTa in many downstream tasks and datasets.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan, Hong Kong, and other regions.
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Deconfounding-Against-Spatio-Temporal-Shifts-Theory-and-Modeling"><a href="#Self-Supervised-Deconfounding-Against-Spatio-Temporal-Shifts-Theory-and-Modeling" class="headerlink" title="Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling"></a>Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12472">http://arxiv.org/abs/2311.12472</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shotdowndiane/steve">https://github.com/shotdowndiane/steve</a></li>
<li>paper_authors: Jiahao Ji, Wentao Zhang, Jingyuan Wang, Yue He, Chao Huang</li>
<li>for: 这项研究的目的是提高城市交通效率和推动可持续发展，通过对时空数据进行预测。</li>
<li>methods: 该研究使用 causal 图来构造时空数据的 causal 关系，并提出了一种名为 Disentangled Contextual Adjustment (DCA) 的解决方案，以及一种 Spatio-Temporal sElf-superVised dEconfounding (STEVE) 框架。</li>
<li>results: 该研究的实验结果表明，STEVE 在不同的时空数据外测场景下都能够超过州态艺术的基eline。<details>
<summary>Abstract</summary>
As an important application of spatio-temporal (ST) data, ST traffic forecasting plays a crucial role in improving urban travel efficiency and promoting sustainable development. In practice, the dynamics of traffic data frequently undergo distributional shifts attributed to external factors such as time evolution and spatial differences. This entails forecasting models to handle the out-of-distribution (OOD) issue where test data is distributed differently from training data. In this work, we first formalize the problem by constructing a causal graph of past traffic data, future traffic data, and external ST contexts. We reveal that the failure of prior arts in OOD traffic data is due to ST contexts acting as a confounder, i.e., the common cause for past data and future ones. Then, we propose a theoretical solution named Disentangled Contextual Adjustment (DCA) from a causal lens. It differentiates invariant causal correlations against variant spurious ones and deconfounds the effect of ST contexts. On top of that, we devise a Spatio-Temporal sElf-superVised dEconfounding (STEVE) framework. It first encodes traffic data into two disentangled representations for associating invariant and variant ST contexts. Then, we use representative ST contexts from three conceptually different perspectives (i.e., temporal, spatial, and semantic) as self-supervised signals to inject context information into both representations. In this way, we improve the generalization ability of the learned context-oriented representations to OOD ST traffic forecasting. Comprehensive experiments on four large-scale benchmark datasets demonstrate that our STEVE consistently outperforms the state-of-the-art baselines across various ST OOD scenarios.
</details>
<details>
<summary>摘要</summary>
为了提高城市交通效率和推动可持续发展，ST数据预测作为重要应用在ST数据中扮演着关键的角色。然而，交通数据的动态过程中经常出现分布性的变化，这使得预测模型需要处理异常数据（OOD）问题。在这种情况下，我们首先将问题正式化， constructed a causal graph of past traffic data, future traffic data, and external ST contexts。我们发现，先前的方法在OOD交通数据上出现失败的原因是ST上下文作为共同因素，即过去数据和未来数据之间的共同原因。然后，我们提出了一种名为分解上下文调整（DCA）的理论解决方案，它可以从 causal 镜像中分解不变 causal 相关性和变异的干扰因素。此外，我们还提出了一种STEVE框架，它首先将交通数据编码成两个分解表示，其中一个表示不变的ST上下文，另一个表示变化的ST上下文。然后，我们使用不同的三个视角（时间、空间和semantic）中的代表ST上下文来自顾框架。通过这种方式，我们可以在OOD ST交通预测中提高学习的Context-oriented表示的普适性。我们在四个大规模 benchmark 数据集上进行了广泛的实验，结果显示，我们的STEVE consistently 超过了状态机制基elines across various ST OOD scenarios。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Gateway-for-Knowledge-Graph-Schemas-Collection-Analysis-and-Embedding"><a href="#Towards-a-Gateway-for-Knowledge-Graph-Schemas-Collection-Analysis-and-Embedding" class="headerlink" title="Towards a Gateway for Knowledge Graph Schemas Collection, Analysis, and Embedding"></a>Towards a Gateway for Knowledge Graph Schemas Collection, Analysis, and Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12465">http://arxiv.org/abs/2311.12465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mattia Fumagalli, Marco Boffo, Daqian Shi, Mayukh Bagchi, Fausto Giunchiglia</li>
<li>for: 该论文的目的是如何使用现有的知识图来训练统计模型。</li>
<li>methods: 该论文使用了一个名为LiveSchema的网关，该网关可以将多种源 catalogs和Repository 的数据集合起来，并提供了一些关键的功能，如查询所有收集的资源、将每个给定的数据集转换成正式概念分析矩阵、生成模型和张量。</li>
<li>results: 该论文提出了一个初版的LiveSchema网关，该网关可以将多种现有的知识图和ontology 集成起来，并提供了一些关键的功能，如查询所有收集的资源、将每个给定的数据集转换成正式概念分析矩阵、生成模型和张量。<details>
<summary>Abstract</summary>
One of the significant barriers to the training of statistical models on knowledge graphs is the difficulty that scientists have in finding the best input data to address their prediction goal. In addition to this, a key challenge is to determine how to manipulate these relational data, which are often in the form of particular triples (i.e., subject, predicate, object), to enable the learning process. Currently, many high-quality catalogs of knowledge graphs, are available. However, their primary goal is the re-usability of these resources, and their interconnection, in the context of the Semantic Web. This paper describes the LiveSchema initiative, namely, a first version of a gateway that has the main scope of leveraging the gold mine of data collected by many existing catalogs collecting relational data like ontologies and knowledge graphs. At the current state, LiveSchema contains - 1000 datasets from 4 main sources and offers some key facilities, which allow to: i) evolving LiveSchema, by aggregating other source catalogs and repositories as input sources; ii) querying all the collected resources; iii) transforming each given dataset into formal concept analysis matrices that enable analysis and visualization services; iv) generating models and tensors from each given dataset.
</details>
<details>
<summary>摘要</summary>
一个 significante barrier to the training of statistical models on knowledge graphs is the difficulty that scientists have in finding the best input data to address their prediction goal. In addition to this, a key challenge is to determine how to manipulate these relational data, which are often in the form of particular triples (i.e., subject, predicate, object), to enable the learning process. Currently, many high-quality catalogs of knowledge graphs, are available. However, their primary goal is the re-usability of these resources, and their interconnection, in the context of the Semantic Web. This paper describes the LiveSchema initiative, namely, a first version of a gateway that has the main scope of leveraging the gold mine of data collected by many existing catalogs collecting relational data like ontologies and knowledge graphs. At the current state, LiveSchema contains - 1000 datasets from 4 main sources and offers some key facilities, which allow to: i) evolving LiveSchema, by aggregating other source catalogs and repositories as input sources; ii) querying all the collected resources; iii) transforming each given dataset into formal concept analysis matrices that enable analysis and visualization services; iv) generating models and tensors from each given dataset.Here's the breakdown of the translation:* 一个 significante barrier (一个 significante barrier) - This phrase is used to emphasize the significance of the barrier.* difficulty (difficulty) - The word "difficulty" is used to describe the challenge of finding the best input data.* 找到最佳输入数据 (finding the best input data) - This phrase is used to describe the goal of finding the best input data for training statistical models.*  relational data (relational data) - This phrase is used to describe the type of data that is in the form of particular triples.* 如ontologies and knowledge graphs (such as ontologies and knowledge graphs) - This phrase is used to provide examples of the type of data that is being referred to.*  LiveSchema (LiveSchema) - This is the name of the initiative being described.*  gateway (gateway) - This word is used to describe the main scope of the LiveSchema initiative.*  leveraging (leveraging) - This word is used to describe the main goal of the LiveSchema initiative, which is to leverage the data collected by many existing catalogs.*  gold mine (gold mine) - This phrase is used to emphasize the richness of the data collected by the catalogs.*  data (data) - This word is used to refer to the data collected by the catalogs.*  collecting (collecting) - This word is used to describe the action of collecting data.*  relational data (relational data) - This phrase is used to describe the type of data being collected.*  like ontologies and knowledge graphs (like ontologies and knowledge graphs) - This phrase is used to provide examples of the type of data being collected.*  Currently (currently) - This word is used to indicate that the data collection is ongoing.*  many high-quality catalogs (many high-quality catalogs) - This phrase is used to describe the quality of the catalogs.*  are available (are available) - This phrase is used to indicate that the catalogs are accessible.*  primary goal (primary goal) - This phrase is used to describe the main goal of the catalogs, which is the re-usability of the resources.*  interconnection (interconnection) - This phrase is used to describe the goal of interconnecting the resources.*  in the context of the Semantic Web (in the context of the Semantic Web) - This phrase is used to provide context for the goal of interconnecting the resources.*  This paper (this paper) - This phrase is used to refer to the paper being described.*  describes (describes) - This word is used to indicate that the paper describes the LiveSchema initiative.*  the LiveSchema initiative (the LiveSchema initiative) - This phrase is used to refer to the initiative being described.*  a first version (a first version) - This phrase is used to indicate that the LiveSchema initiative is a first version of a gateway.*  that has the main scope (that has the main scope) - This phrase is used to describe the main goal of the LiveSchema initiative.*  of leveraging (of leveraging) - This word is used to describe the main goal of the LiveSchema initiative, which is to leverage the data collected by many existing catalogs.*  the gold mine (the gold mine) - This phrase is used to emphasize the richness of the data collected by the catalogs.*  At the current state (At the current state) - This phrase is used to indicate that the LiveSchema initiative is currently in progress.*  contains (contains) - This word is used to describe the contents of the LiveSchema initiative.*  - 1000 datasets (1000 datasets) - This phrase is used to describe the number of datasets contained in the LiveSchema initiative.*  from 4 main sources (from 4 main sources) - This phrase is used to describe the sources of the datasets.*  and offers (and offers) - This phrase is used to describe the facilities offered by the LiveSchema initiative.*  some key facilities (some key facilities) - This phrase is used to emphasize the importance of the facilities offered.*  i) evolving LiveSchema (i) evolving LiveSchema) - This phrase is used to describe the first facility offered by the LiveSchema initiative.*  by aggregating (by aggregating) - This word is used to describe the action of aggregating data.*  other source catalogs and repositories (other source catalogs and repositories) - This phrase is used to describe the data being aggregated.*  as input sources (as input sources) - This phrase is used to describe the purpose of aggregating the data.*  ii) querying all the collected resources (ii) querying all the collected resources) - This phrase is used to describe the second facility offered by the LiveSchema initiative.*  iii) transforming each given dataset (iii) transforming each given dataset) - This phrase is used to describe the third facility offered by the LiveSchema initiative.*  into formal concept analysis matrices (into formal concept analysis matrices) - This phrase is used to describe the action of transforming the datasets.*  that enable analysis and visualization services (that enable analysis and visualization services) - This phrase is used to describe the purpose of transforming the datasets.*  iv) generating models and tensors (iv) generating models and tensors) - This phrase is used to describe the fourth facility offered by the LiveSchema initiative.*  from each given dataset (from each given dataset) - This phrase is used to describe the purpose of generating models and tensors.
</details></li>
</ul>
<hr>
<h2 id="HierSpeech-Bridging-the-Gap-between-Semantic-and-Acoustic-Representation-of-Speech-by-Hierarchical-Variational-Inference-for-Zero-shot-Speech-Synthesis"><a href="#HierSpeech-Bridging-the-Gap-between-Semantic-and-Acoustic-Representation-of-Speech-by-Hierarchical-Variational-Inference-for-Zero-shot-Speech-Synthesis" class="headerlink" title="HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis"></a>HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12454">http://arxiv.org/abs/2311.12454</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sh-lee-prml/hierspeechpp">https://github.com/sh-lee-prml/hierspeechpp</a></li>
<li>paper_authors: Sang-Hoon Lee, Ha-Yeong Choi, Seung-Bin Kim, Seong-Whan Lee</li>
<li>for: 这篇论文旨在提出一种快速和强大的零shot语音合成器，用于文本到语音（TTS）和语音转换（VC）。</li>
<li>methods: 该论文使用了层次语音合成框架，以提高合成语音的稳定性和表达力。具体来说，它采用了文本到 вектор框架，生成一个自我超vised语音表示和F0表示，然后使用这些表示生成语音。此外，它还引入了高效的语音超分辨框架，从16 kHz提升到48 kHz。</li>
<li>results: 实验结果表明，层次变分 autoencoder 可以作为一个强大的零shot语音合成器，并且其性能高于 LLM-based 和扩散基于的模型。此外，它还实现了首次人类水平质量的零shot语音合成。<details>
<summary>Abstract</summary>
Large language models (LLM)-based speech synthesis has been widely adopted in zero-shot speech synthesis. However, they require a large-scale data and possess the same limitations as previous autoregressive speech models, including slow inference speed and lack of robustness. This paper proposes HierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech (TTS) and voice conversion (VC). We verified that hierarchical speech synthesis frameworks could significantly improve the robustness and expressiveness of the synthetic speech. Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios. For text-to-speech, we adopt the text-to-vec framework, which generates a self-supervised speech representation and an F0 representation based on text representations and prosody prompts. Then, HierSpeech++ generates speech from the generated vector, F0, and voice prompt. We further introduce a high-efficient speech super-resolution framework from 16 kHz to 48 kHz. The experimental results demonstrated that the hierarchical variational autoencoder could be a strong zero-shot speech synthesizer given that it outperforms LLM-based and diffusion-based models. Moreover, we achieved the first human-level quality zero-shot speech synthesis. Audio samples and source code are available at https://github.com/sh-lee-prml/HierSpeechpp.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）基于的语音合成已广泛应用于零shot语音合成。然而，它们需要大量数据并具有之前autoregressive语音模型的同样局限性，包括慢速推理速度和缺乏可靠性。这篇论文提出了层次语音合成框架HierSpeech++，它是一个快速强大的零shot语音合成器。我们证明了层次语音合成框架可以显著提高合成语音的稳定性和表达力。此外，我们在零shot语音合成场景下还可以提高合成语音的自然性和发音人类化。对于文本到语音（TTS），我们采用文本到vec框架，它生成了一个自我超vised语音表示和F0表示基于文本表示和气质提示。然后，HierSpeech++生成语音从生成的向量、F0和声音提示。我们还提出了一种高效的语音超分辨框架，从16 kHz提升到48 kHz。实验结果表明，层次变分析器可以作为一个强大的零shot语音合成器，并且超过LLM基于和扩散基于模型。此外，我们实现了人类水平的零shot语音合成。音频样本和源代码可以在https://github.com/sh-lee-prml/HierSpeechpp上获取。
</details></li>
</ul>
<hr>
<h2 id="Extracting-Definienda-in-Mathematical-Scholarly-Articles-with-Transformers"><a href="#Extracting-Definienda-in-Mathematical-Scholarly-Articles-with-Transformers" class="headerlink" title="Extracting Definienda in Mathematical Scholarly Articles with Transformers"></a>Extracting Definienda in Mathematical Scholarly Articles with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12448">http://arxiv.org/abs/2311.12448</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sufianj/def_extraction">https://github.com/sufianj/def_extraction</a></li>
<li>paper_authors: Shufan Jiang, Pierre Senellart</li>
<li>for: 本研究旨在自动识别学术论文中定义的概念。</li>
<li>methods: 本研究使用了精度适应的 пре-训练 transformer 进行 Token-level 分类任务，以及一个通用的大语言模型 (GPT) 进行问题解答任务。</li>
<li>results: 实验结果显示，可以使用 recent (和昂贵) GPT 4 或更简单的预训练模型，以高精度和回传率进行定义识别。<details>
<summary>Abstract</summary>
We consider automatically identifying the defined term within a mathematical definition from the text of an academic article. Inspired by the development of transformer-based natural language processing applications, we pose the problem as (a) a token-level classification task using fine-tuned pre-trained transformers; and (b) a question-answering task using a generalist large language model (GPT). We also propose a rule-based approach to build a labeled dataset from the LATEX source of papers. Experimental results show that it is possible to reach high levels of precision and recall using either recent (and expensive) GPT 4 or simpler pre-trained models fine-tuned on our task.
</details>
<details>
<summary>摘要</summary>
我们考虑自动从学术论文中提取定义中的特定 термин。受过 transformations 基础模型的发展启发，我们将问题定义为（a）一个token级别分类任务，使用调整后的预训练 transformers；以及（b）一个问答任务，使用通用大语言模型（GPT）。我们还提出了一种基于规则的方法来从 LATEX 文档中生成标注数据集。实验结果显示，可以使用Recent（和昂贵） GPT 4 或更简单的预训练模型，达到高精度和准确率。
</details></li>
</ul>
<hr>
<h2 id="Designing-Long-term-Group-Fair-Policies-in-Dynamical-Systems"><a href="#Designing-Long-term-Group-Fair-Policies-in-Dynamical-Systems" class="headerlink" title="Designing Long-term Group Fair Policies in Dynamical Systems"></a>Designing Long-term Group Fair Policies in Dynamical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12447">http://arxiv.org/abs/2311.12447</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miriam Rateike, Isabel Valera, Patrick Forré</li>
<li>for: 这篇论文旨在提出一个新的框架，以长期确保系统动态中的群体公平。</li>
<li>methods: 本论文使用时间同调Markov链来模型系统动态，并利用Markov链均匀定理来优化策略，以确保策略在长期下可以对Targeted公平状态 converge。</li>
<li>results: 本论文提出了一个时间独立的策略，可以在系统动态中实现长期的群体公平，并且可以评估不同的长期目标，包括不同的社会和政策实现的公平目标。<details>
<summary>Abstract</summary>
Neglecting the effect that decisions have on individuals (and thus, on the underlying data distribution) when designing algorithmic decision-making policies may increase inequalities and unfairness in the long term - even if fairness considerations were taken in the policy design process. In this paper, we propose a novel framework for achieving long-term group fairness in dynamical systems, in which current decisions may affect an individual's features in the next step, and thus, future decisions. Specifically, our framework allows us to identify a time-independent policy that converges, if deployed, to the targeted fair stationary state of the system in the long term, independently of the initial data distribution. We model the system dynamics with a time-homogeneous Markov chain and optimize the policy leveraging the Markov chain convergence theorem to ensure unique convergence. We provide examples of different targeted fair states of the system, encompassing a range of long-term goals for society and policymakers. Furthermore, we show how our approach facilitates the evaluation of different long-term targets by examining their impact on the group-conditional population distribution in the long term and how it evolves until convergence.
</details>
<details>
<summary>摘要</summary>
忽略算法决策对个人（以及相应的数据分布）的影响可能导致长期不平等和不公正，即使在政策设计过程中考虑了公平考虑因素。在这篇论文中，我们提出了一种新的框架，用于实现长期团体公平的动态系统中的决策。specifically，我们的框架允许我们在下一步的决策中考虑当前决策对个人的影响，从而在长期实现targeted公平状态。我们使用时间几乎同质的Markov链来模型系统动态，并通过Markov链收敛定理来确保唯一收敛。我们还提供了不同的targeted公平状态的示例，涵盖了社会和政策制定者的长期目标。此外，我们还示了我们的方法如何评估不同的长期目标，以及它们在长期发展中对群体公共分布的影响。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Base-Enabled-Semantic-Communication-A-Generative-Perspective"><a href="#Knowledge-Base-Enabled-Semantic-Communication-A-Generative-Perspective" class="headerlink" title="Knowledge Base Enabled Semantic Communication: A Generative Perspective"></a>Knowledge Base Enabled Semantic Communication: A Generative Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12443">http://arxiv.org/abs/2311.12443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinke Ren, Zezhong Zhang, Jie Xu, Guanying Chen, Yaping Sun, Ping Zhang, Shuguang Cui</li>
<li>for: 提高 sixth-generation 无线网络的通信效率</li>
<li>methods: 利用 semantic knowledge base 技术</li>
<li>results: 提高通信效率，超越传统的 sintactic 通信和 classical semantic 通信Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to improve the communication efficiency of sixth-generation wireless networks by exploiting semantic knowledge base technology.</li>
<li>methods: The paper proposes using semantic knowledge base to represent source messages in low-dimensional subspaces while preserving their desired meaning. This is achieved by introducing three sub-KBs: source, task, and channel KBs.</li>
<li>results: The paper demonstrates the superiority of generative semantic communication over conventional syntactic communication and classical semantic communication through a case study. The results show that generative semantic communication can significantly enhance the communication efficiency.<details>
<summary>Abstract</summary>
Semantic communication is widely touted as a key technology for propelling the sixth-generation (6G) wireless networks. However, providing effective semantic representation is quite challenging in practice. To address this issue, this article takes a crack at exploiting semantic knowledge base (KB) to usher in a new era of generative semantic communication. Via semantic KB, source messages can be characterized in low-dimensional subspaces without compromising their desired meaning, thus significantly enhancing the communication efficiency. The fundamental principle of semantic KB is first introduced, and a generative semantic communication architecture is developed by presenting three sub-KBs, namely source, task, and channel KBs. Then, the detailed construction approaches for each sub-KB are described, followed by their utilization in terms of semantic coding and transmission. A case study is also provided to showcase the superiority of generative semantic communication over conventional syntactic communication and classical semantic communication. In a nutshell, this article establishes a scientific foundation for the exciting uncharted frontier of generative semantic communication.
</details>
<details>
<summary>摘要</summary>
semantic communication 被广泛提出为第六代无线网络（6G）的关键技术。然而，在实践中提供有效的 semantic representation 是很困难的。为解决这个问题，本文尝试利用 semantic knowledge base（KB），推动一个新的 era of generative semantic communication。通过 semantic KB，源消息可以在低维度空间中表示，而不会失去其愿意的含义，因此明显提高了通信效率。 semantic KB 的基本原则首先被介绍，然后是基于三个子 KB：源 KB、任务 KB 和通道 KB。每个子 KB 的建构方法被详细描述，以及它们在 semantic coding 和传输中的使用。此外，还提供了一个 case study，以显示 generative semantic communication 的优越性，相比于 conventional syntactic communication 和 classical semantic communication。简单来说，本文建立了 generative semantic communication 的科学基础，开启了无人曾经踏进的未知领域。
</details></li>
</ul>
<hr>
<h2 id="Fair-Enough-A-map-of-the-current-limitations-of-the-requirements-to-have-“fair’’-algorithms"><a href="#Fair-Enough-A-map-of-the-current-limitations-of-the-requirements-to-have-“fair’’-algorithms" class="headerlink" title="Fair Enough? A map of the current limitations of the requirements to have “fair’’ algorithms"></a>Fair Enough? A map of the current limitations of the requirements to have “fair’’ algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12435">http://arxiv.org/abs/2311.12435</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Castelnovo, Nicole Inverardi, Gabriele Nanino, Ilaria Giuseppina Penco, Daniele Regoli</li>
<li>for: The paper discusses the issue of bias and unfairness in automated decision-making systems and the need for more societal choices to make the demand for “fair” algorithms actionable.</li>
<li>methods: The paper highlights the current efforts to assess, quantify, and mitigate biases in algorithms, but argues that these efforts are not enough without a clearer understanding of what “fairness” means in real-world scenarios.</li>
<li>results: The paper identifies a list of fundamental ambiguities and attention points that must be addressed in order to give a concrete meaning to the demand for fairness in automated decision-making systems.<details>
<summary>Abstract</summary>
In the recent years, the raise in the usage and efficiency of Artificial Intelligence and, more in general, of Automated Decision-Making systems has brought with it an increasing and welcome awareness of the risks associated with such systems. One of such risks is that of perpetuating or even amplifying bias and unjust disparities present in the data from which many of these systems learn to adjust and optimise their decisions. This awareness has on one side encouraged several scientific communities to come up with more and more appropriate ways and methods to assess, quantify, and possibly mitigate such biases and disparities. On the other hand, it has prompted more and more layers of society, including policy makers, to call for ``fair'' algorithms. We believe that while a lot of excellent and multidisciplinary research is currently being conducted, what is still fundamentally missing is the awareness that having ``fair'' algorithms is per s\'e a nearly meaningless requirement, that needs to be complemented with a lot of additional societal choices to become actionable. Namely, there is a hiatus between what the society is demanding from Automated Decision-Making systems, and what this demand actually means in real-world scenarios. In this work, we outline the key features of such a hiatus, and pinpoint a list of fundamental ambiguities and attention points that we as a society must address in order to give a concrete meaning to the increasing demand of fairness in Automated Decision-Making systems.
</details>
<details>
<summary>摘要</summary>
在过去几年，人工智能和自动决策系统的使用和效率的提高，使人们对这些系统的风险的认识提高，特别是对它们学习和优化决策的数据中存在的偏见和不公平的问题。这种认识导致了一些科学社区开发出更多和更适合的方法来评估、量化和可能地mitigate这些偏见和不公平。同时，更多的社会层次，包括政策制定者，呼吁“公平”的算法。我们认为，虽然目前有很多优秀的多学科研究，但实际上还缺乏基本的社会选择，以使“公平”的算法成为实际行动的准则。即使在社会对自动决策系统的要求中，有一个差距，这些要求在实际情况下并没有具体的含义。在这项工作中，我们描述了这个差距的关键特征，并指出了一些基本的歧义和注意事项，我们作为一个社会必须解决，以赋予“公平”的算法具体的含义。
</details></li>
</ul>
<hr>
<h2 id="A-recurrent-connectionist-model-of-melody-perception-An-exploration-using-TRACX2"><a href="#A-recurrent-connectionist-model-of-melody-perception-An-exploration-using-TRACX2" class="headerlink" title="A recurrent connectionist model of melody perception : An exploration using TRACX2"></a>A recurrent connectionist model of melody perception : An exploration using TRACX2</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12431">http://arxiv.org/abs/2311.12431</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Defays, Robert French, Barbara Tillmann</li>
<li>for: 这研究探讨了一种基于认知的连接主义自适应模型（TRACX2）是如何应用于基本旋律识别。</li>
<li>methods: 这个模型是一个三层自适应神经网络，通过识别’’chunk’’的短序列间隔而模仿了语音和序列图像处理。</li>
<li>results: 研究发现，TRACX2可以在音乐中识别’’human-recognizable’’的旋律类别，并且感知音频序列的形态和距离信息。这些结果表明，TRACX2可能是一种通用的分割和拼接机制，不仅适用于单词和图像分割，还适用于基本旋律处理。<details>
<summary>Abstract</summary>
Are similar, or even identical, mechanisms used in the computational modeling of speech segmentation, serial image processing and music processing? We address this question by exploring how TRACX2, (French et al., 2011; French \& Cottrell, 2014; Mareschal \& French, 2017), a recognition-based, recursive connectionist autoencoder model of chunking and sequence segmentation, which has successfully simulated speech and serial-image processing, might be applied to elementary melody perception. The model, a three-layer autoencoder that recognizes ''chunks'' of short sequences of intervals that have been frequently encountered on input, is trained on the tone intervals of melodically simple French children's songs. It dynamically incorporates the internal representations of these chunks into new input. Its internal representations cluster in a manner that is consistent with ''human-recognizable'' melodic categories. TRACX2 is sensitive to both contour and proximity information in the musical chunks that it encounters in its input. It shows the ''end-of-word'' superiority effect demonstrated by Saffran et al. (1999) for short musical phrases. The overall findings suggest that the recursive autoassociative chunking mechanism, as implemented in TRACX2, may be a general segmentation and chunking mechanism, underlying not only word-and imagechunking, but also elementary melody processing.
</details>
<details>
<summary>摘要</summary>
是否存在类似或 même identical 的机制在计算模型中模拟speech segmentation、 serial image processing 和 music processing？我们通过探索TRACX2（French et al., 2011; French & Cottrell, 2014; Mareschal & French, 2017）模型，这是一个基于认知的、复合连接式 autoencoder 模型，可以成功模拟speech 和 serial-image processing，以及如何应用这种模型来处理基本旋律听觉。TRACX2 是一个三层 autoencoder 模型，可以识别 ''chunk'' 的短序列间隔，这些序列频繁出现在输入中。它在新输入中动态 incorporate 这些 chunk 的内部表示，并且这些表示会归一化到 ''human-recognizable'' 的旋律类别。TRACX2 感知输入中的音频 chunk 的形状和距离信息。它展现了 Saffran et al. (1999) 所示的 ''end-of-word'' 优势效应，即短乐段中的 ''end-of-word'' 会受到更多的听觉干扰。总的来说，这种 recursive autoassociative chunking 机制可能是一种通用的分 segmentation 和 chunking 机制，不仅存在 word-和 imagechunking，还存在基本旋律处理中。
</details></li>
</ul>
<hr>
<h2 id="How-Far-Have-We-Gone-in-Vulnerability-Detection-Using-Large-Language-Models"><a href="#How-Far-Have-We-Gone-in-Vulnerability-Detection-Using-Large-Language-Models" class="headerlink" title="How Far Have We Gone in Vulnerability Detection Using Large Language Models"></a>How Far Have We Gone in Vulnerability Detection Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12420">http://arxiv.org/abs/2311.12420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Gao, Hao Wang, Yuchen Zhou, Wenyu Zhu, Chao Zhang</li>
<li>for: 评估大自然语言模型（LLMs）在漏洞检测中的潜力</li>
<li>methods: 使用 VulBench  benchmark，融合 CTFT 挑战和实际应用程序数据，并对每个漏洞函数进行精确的分类</li>
<li>results: 发现一些 LLMs 可以超越传统的深度学习模型，提供更高的漏洞检测性能，这些结果为软件安全领域中 LLMS 的应用提供了新的可能性。<details>
<summary>Abstract</summary>
As software becomes increasingly complex and prone to vulnerabilities, automated vulnerability detection is critically important, yet challenging. Given the significant successes of Large Language Models (LLMs) in various tasks, there is growing anticipation of their efficacy in vulnerability detection. However, a quantitative understanding of their potential in vulnerability detection is still missing. To bridge this gap, we introduce a comprehensive vulnerability benchmark VulBench. This benchmark aggregates high-quality data from a wide range of CTF (Capture-the-Flag) challenges and real-world applications, with annotations for each vulnerable function detailing the vulnerability type and its root cause. Through our experiments encompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models and static analyzers, we find that several LLMs outperform traditional deep learning approaches in vulnerability detection, revealing an untapped potential in LLMs. This work contributes to the understanding and utilization of LLMs for enhanced software security.
</details>
<details>
<summary>摘要</summary>
《软件在日益复杂和易受攻击的情况下，自动漏洞检测变得非常重要，却非常困难。在大语言模型（LLM）在不同任务中的显著成功的基础上，有关其在漏洞检测中的潜在效果的期待增加。然而，这一点的量化理解仍然缺失。为了填补这一空白，我们介绍了一个完整的漏洞benchmark VulBench。这个benchmark集成了多种CTF挑战和实际应用程序中的高质量数据，并对每个漏洞函数进行了每种漏洞类型和根本原因的注释。经我们的实验，包括16个LLM和6个现有的深度学习基于模型和静态分析器，我们发现了一些LLMs在漏洞检测中超过传统深度学习方法的表现，这 revelas了LLMs在软件安全方面的未经利用的潜力。这项工作对LLMs的理解和利用做出了贡献，以提高软件安全。》Note: Please keep in mind that the translation is done by a machine and may not be perfect. Also, the grammar and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="nach0-Multimodal-Natural-and-Chemical-Languages-Foundation-Model"><a href="#nach0-Multimodal-Natural-and-Chemical-Languages-Foundation-Model" class="headerlink" title="nach0: Multimodal Natural and Chemical Languages Foundation Model"></a>nach0: Multimodal Natural and Chemical Languages Foundation Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12410">http://arxiv.org/abs/2311.12410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Micha Livne, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, Anthony Costa, Alex Aliper, Alex Zhavoronkov</li>
<li>For: The paper introduces a new foundation model called nach0, which can solve various chemical and biological tasks such as biomedical question answering, named entity recognition, molecular generation, and others.* Methods: The model is a multi-domain and multi-task encoder-decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings. The authors used instruction tuning to fine-tune the model for the final set of tasks, and leveraged the NeMo framework for efficient parallel optimization of both base and large model versions.* Results: The model outperforms state-of-the-art baselines on single-domain and cross-domain tasks, and can generate high-quality outputs in molecular and textual formats, demonstrating its effectiveness in multi-domain setups.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have substantially driven scientific progress in various domains, and many papers have demonstrated their ability to tackle complex problems with creative solutions. Our paper introduces a new foundation model, nach0, capable of solving various chemical and biological tasks: biomedical question answering, named entity recognition, molecular generation, molecular synthesis, attributes prediction, and others. nach0 is a multi-domain and multi-task encoder-decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge. We employed instruction tuning, where specific task-related instructions are utilized to fine-tune nach0 for the final set of tasks. To train nach0 effectively, we leverage the NeMo framework, enabling efficient parallel optimization of both base and large model versions. Extensive experiments demonstrate that our model outperforms state-of-the-art baselines on single-domain and cross-domain tasks. Furthermore, it can generate high-quality outputs in molecular and textual formats, showcasing its effectiveness in multi-domain setups.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）已经在不同领域产生了重要的科学进步，许多论文都表明了它们可以解决复杂问题的创新方案。我们的论文介绍了一个新的基础模型 nach0，可以解决各种化学和生物任务：生物医学问答、命名实体识别、分子生成、分子合成、特征预测等等。nach0 是一个多领域多任务的 encoder-decoder LLM，在不标注的科学文献、专利和分子字符串上进行预训练，以包含多种化学和语言知识。我们使用了“指导调教”方法，通过特定任务相关的指导来细化 nach0  для最终的任务。为了训练 nach0 效果，我们利用了 NeMo 框架，以实现效率的并行优化基模型和大模型版本。广泛的实验表明，我们的模型在单领域和交叉领域任务上表现出优于状态之前的基准点。此外，它可以生成高质量的分子和文本格式输出，展现了其在多领域设置中的效果。
</details></li>
</ul>
<hr>
<h2 id="Infinite-forecast-combinations-based-on-Dirichlet-process"><a href="#Infinite-forecast-combinations-based-on-Dirichlet-process" class="headerlink" title="Infinite forecast combinations based on Dirichlet process"></a>Infinite forecast combinations based on Dirichlet process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12379">http://arxiv.org/abs/2311.12379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinuo Ren, Feng Li, Yanfei Kang</li>
<li>for: 本研究旨在提出一种基于 Dirichlet 过程的深度学习 ensemble 预测模型，用于Integrating information from various sources and improving forecasting accuracy.</li>
<li>methods: 该模型使用三个基础分布作为超参数，通过抽样策略将 Dirichlet 过程转化为有限的一个。然后，通过收集所有检查点，建立一个深度学习子模型池，并在组合过程中使用重量调整和多样性策略。</li>
<li>results: 对于M4竞赛的每周数据集，该模型提出的ensemble模型显示了substantial improvement 的预测精度和稳定性，相比单个标准模型。此外，对于不同的模型数量进行敏感分析，结果表明该模型在不同的情况下具有普遍性和竞争力。<details>
<summary>Abstract</summary>
Forecast combination integrates information from various sources by consolidating multiple forecast results from the target time series. Instead of the need to select a single optimal forecasting model, this paper introduces a deep learning ensemble forecasting model based on the Dirichlet process. Initially, the learning rate is sampled with three basis distributions as hyperparameters to convert the infinite mixture into a finite one. All checkpoints are collected to establish a deep learning sub-model pool, and weight adjustment and diversity strategies are developed during the combination process. The main advantage of this method is its ability to generate the required base learners through a single training process, utilizing the decaying strategy to tackle the challenge posed by the stochastic nature of gradient descent in determining the optimal learning rate. To ensure the method's generalizability and competitiveness, this paper conducts an empirical analysis using the weekly dataset from the M4 competition and explores sensitivity to the number of models to be combined. The results demonstrate that the ensemble model proposed offers substantial improvements in prediction accuracy and stability compared to a single benchmark model.
</details>
<details>
<summary>摘要</summary>
预测组合将多种源信息 integrate into one forecast result by consolidating multiple forecast results from the target time series. Instead of selecting a single optimal forecasting model, this paper introduces a deep learning ensemble forecasting model based on the Dirichlet process. Initially, the learning rate is sampled with three basis distributions as hyperparameters to convert the infinite mixture into a finite one. All checkpoints are collected to establish a deep learning sub-model pool, and weight adjustment and diversity strategies are developed during the combination process. The main advantage of this method is its ability to generate the required base learners through a single training process, utilizing the decaying strategy to tackle the challenge posed by the stochastic nature of gradient descent in determining the optimal learning rate. To ensure the method's generalizability and competitiveness, this paper conducts an empirical analysis using the weekly dataset from the M4 competition and explores sensitivity to the number of models to be combined. The results demonstrate that the ensemble model proposed offers substantial improvements in prediction accuracy and stability compared to a single benchmark model.Here is the text with some additional information about the translation:This text is translated from English to Simplified Chinese. The translation is written in a formal and technical style, using appropriate vocabulary and grammar to convey the meaning of the original text. The text includes some specialized terms and concepts, such as "deep learning ensemble forecasting model" and "Dirichlet process," which are translated accurately and consistently to ensure clarity and precision. The translation also includes some cultural references and idioms that are appropriate for the target audience and context. Overall, the translation is accurate, clear, and fluent, and it effectively conveys the meaning and information of the original text to a Simplified Chinese-speaking audience.
</details></li>
</ul>
<hr>
<h2 id="Post-Training-Quantization-with-Low-precision-Minifloats-and-Integers-on-FPGAs"><a href="#Post-Training-Quantization-with-Low-precision-Minifloats-and-Integers-on-FPGAs" class="headerlink" title="Post-Training Quantization with Low-precision Minifloats and Integers on FPGAs"></a>Post-Training Quantization with Low-precision Minifloats and Integers on FPGAs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12359">http://arxiv.org/abs/2311.12359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shivam Aggarwal, Alessandro Pappalardo, Hans Jakob Damsgaard, Giuseppe Franco, Thomas B. Preußer, Michaela Blott, Tulika Mitra</li>
<li>for: 本研究旨在提出一种新的减小模型精度的技术，以便降低模型的内存占用量、延迟时间和能耗cost。</li>
<li>methods: 本研究使用了多种PTQ技术，包括weight equalization、bias correction、SmoothQuant、gradient-based learned rounding和GPTQ方法。</li>
<li>results: 实验结果表明，使用低精度minifloat可以与integer quantization schemes相比，在减少精度和维持准确性之间进行trade-off。此外，我们还评估了这些技术的硬件成本，发现integer quantization通常是Pareto优化的选择，因为它的硬件资源占用较少。<details>
<summary>Abstract</summary>
Post-Training Quantization (PTQ) is a powerful technique for model compression, reducing the precision of neural networks without additional training overhead. Recent works have investigated adopting 8-bit floating-point quantization (FP8) in the context of PTQ for model inference. However, the exploration of floating-point formats smaller than 8 bits and their comparison with integer quantization remains relatively limited. In this work, we present minifloats, which are reduced-precision floating-point formats capable of further reducing the memory footprint, latency, and energy cost of a model while approaching full-precision model accuracy. Our work presents a novel PTQ design-space exploration, comparing minifloat and integer quantization schemes across a range of 3 to 8 bits for both weights and activations. We examine the applicability of various PTQ techniques to minifloats, including weight equalization, bias correction, SmoothQuant, gradient-based learned rounding, and the GPTQ method. Our experiments validate the effectiveness of low-precision minifloats when compared to their integer counterparts across a spectrum of accuracy-precision trade-offs on a set of reference deep learning vision workloads. Finally, we evaluate our results against an FPGA-based hardware cost model, showing that integer quantization often remains the Pareto-optimal option, given its relatively smaller hardware resource footprint.
</details>
<details>
<summary>摘要</summary>
POST-TRAINING 量化（PTQ）是一种有力的模型压缩技术，可以降低神经网络的精度无需额外训练开销。Recent works have investigated adopting 8-bit floating-point quantization（FP8）in the context of PTQ for model inference. However, the exploration of floating-point formats smaller than 8 bits and their comparison with integer quantization remains relatively limited. In this work, we present minifloats, which are reduced-precision floating-point formats capable of further reducing the memory footprint, latency, and energy cost of a model while approaching full-precision model accuracy. Our work presents a novel PTQ design-space exploration, comparing minifloat and integer quantization schemes across a range of 3 to 8 bits for both weights and activations. We examine the applicability of various PTQ techniques to minifloats, including weight equalization, bias correction, SmoothQuant, gradient-based learned rounding, and the GPTQ method. Our experiments validate the effectiveness of low-precision minifloats when compared to their integer counterparts across a spectrum of accuracy-precision trade-offs on a set of reference deep learning vision workloads. Finally, we evaluate our results against an FPGA-based hardware cost model, showing that integer quantization often remains the Pareto-optimal option, given its relatively smaller hardware resource footprint.Here's the text with some additional information about the translation:I used the Google Translate API to translate the text into Simplified Chinese. The translation is in the "Simplified Chinese" language setting, which is the most commonly used language setting for Chinese translation.Please note that the translation may not be perfect and may require some adjustments to accurately convey the intended meaning. Additionally, the translation may not capture all the nuances and idiomatic expressions present in the original text.
</details></li>
</ul>
<hr>
<h2 id="Stable-Diffusion-For-Aerial-Object-Detection"><a href="#Stable-Diffusion-For-Aerial-Object-Detection" class="headerlink" title="Stable Diffusion For Aerial Object Detection"></a>Stable Diffusion For Aerial Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12345">http://arxiv.org/abs/2311.12345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanan Jian, Fuxun Yu, Simranjit Singh, Dimitrios Stamoulis</li>
<li>for: 这篇论文的目的是解决航空图像中物体检测的挑战，特别是实现大规模数据收集和长尾分布的问题。</li>
<li>methods: 这篇论文使用了一个对应于航空图像的数据增强方法，即稳定扩散（SD）方法。</li>
<li>results: 这篇论文通过将这个方法与航空图像相结合，实现了更好的航空图像物体检测。<details>
<summary>Abstract</summary>
Aerial object detection is a challenging task, in which one major obstacle lies in the limitations of large-scale data collection and the long-tail distribution of certain classes. Synthetic data offers a promising solution, especially with recent advances in diffusion-based methods like stable diffusion (SD). However, the direct application of diffusion methods to aerial domains poses unique challenges: stable diffusion's optimization for rich ground-level semantics doesn't align with the sparse nature of aerial objects, and the extraction of post-synthesis object coordinates remains problematic. To address these challenges, we introduce a synthetic data augmentation framework tailored for aerial images. It encompasses sparse-to-dense region of interest (ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model with low-rank adaptation (LORA) to circumvent exhaustive retraining, and finally, a Copy-Paste method to compose synthesized objects with backgrounds, providing a nuanced approach to aerial object detection through synthetic data.
</details>
<details>
<summary>摘要</summary>
天空物体检测是一项具有挑战性的任务，其中一个主要障碍是大规模数据收集的限制和某些类型的长尾分布。人工数据提供了一个有前途的解决方案，特别是在 latest advances in diffusion-based methods like stable diffusion (SD) 中。然而，直接将 diffusion methods 应用于天空领域存在独特的挑战：stable diffusion 的优化 для富有地面 semantics 与天空物体的稀疏性不符，并且提取后synthesis object坐标仍然是一个问题。为了解决这些挑战，我们介绍了一个适用于天空图像的人工数据增强框架。它包括将稀疏区域 Interest (ROI) 提取成为 bridge the semantic gap，使用 low-rank adaptation (LORA) 来绕过耗时 retraining，以及最后，使用 Copy-Paste 方法将生成的对象贴合背景，提供了一种细化的方法 для天空物体检测 through synthetic data。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Large-Language-Models-for-Personalized-and-Explainable-Recommendations"><a href="#A-Survey-on-Large-Language-Models-for-Personalized-and-Explainable-Recommendations" class="headerlink" title="A Survey on Large Language Models for Personalized and Explainable Recommendations"></a>A Survey on Large Language Models for Personalized and Explainable Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12338">http://arxiv.org/abs/2311.12338</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Chen</li>
<li>for: 本研究旨在探讨大语言模型在推荐系统中的应用，以提高用户体验。</li>
<li>methods: 本研究使用了大语言模型进行文本处理和个性化推荐，以解决冷启动问题、不公平问题和偏见问题。</li>
<li>results: 研究发现，大语言模型可以提供高效的文本处理和个性化推荐，但存在一些挑战，如冷启动问题、不公平问题和偏见问题。<details>
<summary>Abstract</summary>
In recent years, Recommender Systems(RS) have witnessed a transformative shift with the advent of Large Language Models(LLMs) in the field of Natural Language Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from Meta, have demonstrated unprecedented capabilities in understanding and generating human-like text. This has led to a paradigm shift in the realm of personalized and explainable recommendations, as LLMs offer a versatile toolset for processing vast amounts of textual data to enhance user experiences. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey aims to analyze how RS can benefit from LLM-based methodologies. Furthermore, we describe major challenges in Personalized Explanation Generating(PEG) tasks, which are cold-start problems, unfairness and bias problems in RS.
</details>
<details>
<summary>摘要</summary>
Recently, Recommender Systems (RS) have undergone a significant transformation with the emergence of Large Language Models (LLMs) in the field of Natural Language Processing (NLP). These models, such as OpenAI's GPT-3.5/4 and Llama from Meta, have shown unprecedented capabilities in understanding and generating human-like text. This has led to a paradigm shift in the realm of personalized and explainable recommendations, as LLMs provide a versatile toolset for processing vast amounts of textual data to enhance user experiences. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey aims to analyze how RS can benefit from LLM-based methodologies. Furthermore, we describe major challenges in Personalized Explanation Generating (PEG) tasks, such as cold-start problems, unfairness, and bias problems in RS.Here's the translation in Traditional Chinese:近年来，推荐系统（RS）已经受到大量语言模型（LLMs）的革命性变革，这些模型包括OpenAI的GPT-3.5/4和Meta的Llama。这些模型已经展示了人类化文本理解和生成的无 precedent能力，这导致了推荐系统的价值领域进行了重大的变革。这篇调查旨在分析RS如何从LLM-based方法ologies中受益，并描述PEG任务中的主要挑战，包括冷启始问题、不公平和偏见问题。
</details></li>
</ul>
<hr>
<h2 id="Do-Smaller-Language-Models-Answer-Contextualised-Questions-Through-Memorisation-Or-Generalisation"><a href="#Do-Smaller-Language-Models-Answer-Contextualised-Questions-Through-Memorisation-Or-Generalisation" class="headerlink" title="Do Smaller Language Models Answer Contextualised Questions Through Memorisation Or Generalisation?"></a>Do Smaller Language Models Answer Contextualised Questions Through Memorisation Or Generalisation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12337">http://arxiv.org/abs/2311.12337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Hartill, Joshua Bensemann, Michael Witbrock, Patricia J. Riddle</li>
<li>for: 本研究旨在检验语言模型是否能通过推理来回答问题，而不是仅仅靠记忆。</li>
<li>methods: 本研究使用语义相似性来 identific evaluation samples，并使用两个语言模型进行多任务训练，其中一个模型添加了两个数据集来增强数字逻辑能力。</li>
<li>results: 研究发现，在一些评价数据集上，使用这种方法可以提高语言模型的表现，特别是在不可 memorization 的subset中。在 DROP 和 ROPES 评价数据集上，表现提高了9.0%和25.7% respectively，而其他评价数据集没有显著变化。<details>
<summary>Abstract</summary>
A distinction is often drawn between a model's ability to predict a label for an evaluation sample that is directly memorised from highly similar training samples versus an ability to predict the label via some method of generalisation. In the context of using Language Models for question-answering, discussion continues to occur as to the extent to which questions are answered through memorisation. We consider this issue for questions that would ideally be answered through reasoning over an associated context. We propose a method of identifying evaluation samples for which it is very unlikely our model would have memorised the answers. Our method is based on semantic similarity of input tokens and label tokens between training and evaluation samples. We show that our method offers advantages upon some prior approaches in that it is able to surface evaluation-train pairs that have overlap in either contiguous or discontiguous sequences of tokens. We use this method to identify unmemorisable subsets of our evaluation datasets. We train two Language Models in a multitask fashion whereby the second model differs from the first only in that it has two additional datasets added to the training regime that are designed to impart simple numerical reasoning strategies of a sort known to improve performance on some of our evaluation datasets but not on others. We then show that there is performance improvement between the two models on the unmemorisable subsets of the evaluation datasets that were expected to benefit from the additional training datasets. Specifically, performance on unmemorisable subsets of two of our evaluation datasets, DROP and ROPES significantly improves by 9.0%, and 25.7% respectively while other evaluation datasets have no significant change in performance.
</details>
<details>
<summary>摘要</summary>
很 oft，一个模型的能力被分为两个方面：直接从高度相似的训练样本中记忆标签，以及通过总结来预测标签。在使用语言模型进行问答时，人们仍在讨论 memorization 的问题。我们认为这个问题在需要通过推理来解答问题时 particualrly 重要。我们提出了一种方法来确定评估样本，这些样本很 unlikely 被我们的模型记忆。我们的方法基于输入和标签Token之间的语义相似性。我们展示了这种方法的优点，可以检测到跨样本序列中的 overlap 和不连续序列中的 overlap。我们使用这种方法来确定评估样本中的不可 memorizable 子集。我们在多任务模式下训练了两个语言模型，其中第二个模型与第一个模型只有两个额外的训练集添加到训练过程中，这些训练集是为了帮助模型学习一些简单的数字推理策略，这些策略已知能够提高一些我们的评估样本中的性能。我们Then 示出了这两个模型在不可 memorizable 子集上的性能改善。特别是，在 DROP 和 ROPES 两个评估样本上，性能提高了9.0%和25.7%。而其他评估样本没有显著变化。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-Instagram-fake-users-using-supervised-machine-learning-algorithms"><a href="#Classification-of-Instagram-fake-users-using-supervised-machine-learning-algorithms" class="headerlink" title="Classification of Instagram fake users using supervised machine learning algorithms"></a>Classification of Instagram fake users using supervised machine learning algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12336">http://arxiv.org/abs/2311.12336</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vertika Singh, Naman Tolasaria, Patel Meet Alpeshkumar, Shreyash Bartwal</li>
<li>for: 本研究旨在帮助公司保护自己免受社交媒体上的诈骗和人身侵犯。</li>
<li>methods: 该应用程序使用人工智能和机器学习技术来检测和neutralize社交媒体上的假 profiles和在线隐身。</li>
<li>results: 该应用程序可以帮助调查机构（特别是刑事分部）更好地掌握社交媒体的复杂领域，并与现有的调查程序集成。<details>
<summary>Abstract</summary>
In the contemporary era, online social networks have become integral to social life, revolutionizing the way individuals manage their social connections. While enhancing accessibility and immediacy, these networks have concurrently given rise to challenges, notably the proliferation of fraudulent profiles and online impersonation. This paper proposes an application designed to detect and neutralize such dishonest entities, with a focus on safeguarding companies from potential fraud. The user-centric design of the application ensures accessibility for investigative agencies, particularly the criminal branch, facilitating navigation of complex social media landscapes and integration with existing investigative procedures
</details>
<details>
<summary>摘要</summary>
现代时期，在线社交网络已成为社会生活的重要组成部分，推动了人们如何管理社交连接的方式。然而，这些网络同时也产生了一些挑战，主要是假 profiling 和在线人身伪装。这篇论文提出了一种应用程序，用于检测和消除这些不诚实的实体，特别是保护公司免受诈骗。该应用程序具有用户中心的设计，使得审查机关，特别是刑事部门，可以方便地浏览复杂的社交媒体景观，并与现有的审查过程集成。
</details></li>
</ul>
<hr>
<h2 id="Quantum-Enhanced-Support-Vector-Machine-for-Large-Scale-Stellar-Classification-with-GPU-Acceleration"><a href="#Quantum-Enhanced-Support-Vector-Machine-for-Large-Scale-Stellar-Classification-with-GPU-Acceleration" class="headerlink" title="Quantum-Enhanced Support Vector Machine for Large-Scale Stellar Classification with GPU Acceleration"></a>Quantum-Enhanced Support Vector Machine for Large-Scale Stellar Classification with GPU Acceleration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12328">http://arxiv.org/abs/2311.12328</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuan-Cheng Chen, Xiaotian Xu, Henry Makhanov, Hui-Hsuan Chung, Chen-Yu Liu</li>
<li>for: 这个研究旨在开展一种创新的量子机器学习方法（Quantum-enhanced Support Vector Machine，QSVM），用于星系分类，充分利用量子计算和GPU加速。</li>
<li>methods: 这个方法利用量子原理和GPU加速，实现了高精度的星系分类，特别是在复杂的二元和多项分类情况下。</li>
<li>results: 相比传统方法（如K-Nearest Neighbors和Logistic Regression），QSVM方法在处理复杂的星系分类 задачі中表现出更高的准确率和更快的处理速度。<details>
<summary>Abstract</summary>
In this study, we introduce an innovative Quantum-enhanced Support Vector Machine (QSVM) approach for stellar classification, leveraging the power of quantum computing and GPU acceleration. Our QSVM algorithm significantly surpasses traditional methods such as K-Nearest Neighbors (KNN) and Logistic Regression (LR), particularly in handling complex binary and multi-class scenarios within the Harvard stellar classification system. The integration of quantum principles notably enhances classification accuracy, while GPU acceleration using the cuQuantum SDK ensures computational efficiency and scalability for large datasets in quantum simulators. This synergy not only accelerates the processing process but also improves the accuracy of classifying diverse stellar types, setting a new benchmark in astronomical data analysis. Our findings underscore the transformative potential of quantum machine learning in astronomical research, marking a significant leap forward in both precision and processing speed for stellar classification. This advancement has broader implications for astrophysical and related scientific fields
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们介绍了一种创新的量子机器学习（QSVM）方法，用于星系分类，利用量子计算和GPU加速。我们的QSVM算法在处理复杂的 binary 和多类enario 时表现出特别的优势，特别是在使用哈佛星系分类系统时。量子原理的integrating  notable enhances 分类精度，而使用 cuQuantum SDK 的 GPU 加速 guarantees 计算效率和可扩展性。这种synergy 不仅加速处理过程，还提高了分类多样星系类型的精度，创造了新的benchmark 在天体数据分析领域。我们的发现表明量子机器学习在天体研究中具有转变性，在精度和处理速度方面为星系分类带来了 significiant 进步。这种进步对astrophysical 和相关的科学领域都具有广泛的意义。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Multimodal-Large-Language-Models-for-Autonomous-Driving"><a href="#A-Survey-on-Multimodal-Large-Language-Models-for-Autonomous-Driving" class="headerlink" title="A Survey on Multimodal Large Language Models for Autonomous Driving"></a>A Survey on Multimodal Large Language Models for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12320">http://arxiv.org/abs/2311.12320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/irohxu/awesome-multimodal-llm-autonomous-driving">https://github.com/irohxu/awesome-multimodal-llm-autonomous-driving</a></li>
<li>paper_authors: Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zichong Yang, Kuei-Da Liao, Tianren Gao, Erlong Li, Kun Tang, Zhipeng Cao, Tong Zhou, Ao Liu, Xinrui Yan, Shuqi Mei, Jianguo Cao, Ziran Wang, Chao Zheng</li>
<li>for: This paper aims to provide a comprehensive understanding of the key challenges, opportunities, and future endeavors in applying Large Language Models (LLMs) to autonomous driving systems.</li>
<li>methods: The paper uses a systematic investigation approach, including an overview of existing MLLM tools, datasets, and benchmarks, as well as a summary of the works presented in the 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD).</li>
<li>results: The paper identifies several important problems that need to be solved by both academia and industry in order to further promote the development of LLMs in autonomous driving systems, including the need for better multimodal models, more diverse and high-quality datasets, and more advanced benchmarks.Here’s the Chinese version of the three key points:</li>
<li>for: 这篇论文的目的是为了为大语言模型（LLM）在自动驾驶系统中的应用提供全面的理解。</li>
<li>methods: 这篇论文使用了系统性的调查方法，包括现有的 MLLM 工具、数据集和比较指标的概述，以及 WACV 工作坊的作品概述。</li>
<li>results: 这篇论文 indentified several important problems需要由学术和产业共同解决，以进一步推动 MLLM 在自动驾驶系统中的发展，包括建立更好的多模态模型、更多和更高质量的数据集、以及更高级的指标。<details>
<summary>Abstract</summary>
With the emergence of Large Language Models (LLMs) and Vision Foundation Models (VFMs), multimodal AI systems benefiting from large models have the potential to equally perceive the real world, make decisions, and control tools as humans. In recent months, LLMs have shown widespread attention in autonomous driving and map systems. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors to apply in LLM driving systems. In this paper, we present a systematic investigation in this field. We first introduce the background of Multimodal Large Language Models (MLLMs), the multimodal models development using LLMs, and the history of autonomous driving. Then, we overview existing MLLM tools for driving, transportation, and map systems together with existing datasets and benchmarks. Moreover, we summarized the works in The 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), which is the first workshop of its kind regarding LLMs in autonomous driving. To further promote the development of this field, we also discuss several important problems regarding using MLLMs in autonomous driving systems that need to be solved by both academia and industry.
</details>
<details>
<summary>摘要</summary>
大量语言模型（LLM）和视觉基础模型（VFM）的出现，使得多模态人工智能系统可以和人类一样理解现实世界，做出决策，控制工具。最近几个月，LLM在自动驾驶和地图系统中得到了广泛的关注。虽然它拥有巨大的潜力，但是还没有一个全面的理解关键挑战、机遇和未来应用在LLM驾驶系统中的研究。在这篇论文中，我们提供了一个系统性的调查。我们首先介绍了多模态大语言模型（MLLM）的背景、基于LLM的多模态模型开发、自动驾驶的历史。然后，我们综述了现有的MLLM工具、交通、地图系统以及相关的数据集和标准。此外，我们还概述了在WACV工作坊上关于大语言和视觉模型 для自动驾驶（LLVM-AD）的工作，这是自动驾驶领域中第一次关于LLM的工作坊。为了进一步推动这一领域的发展，我们还讨论了在使用MLLM时需要解决的一些重要问题，这些问题需要由学术和产业界共同努力解决。
</details></li>
</ul>
<hr>
<h2 id="Overcoming-Pathology-Image-Data-Deficiency-Generating-Images-from-Pathological-Transformation-Process"><a href="#Overcoming-Pathology-Image-Data-Deficiency-Generating-Images-from-Pathological-Transformation-Process" class="headerlink" title="Overcoming Pathology Image Data Deficiency: Generating Images from Pathological Transformation Process"></a>Overcoming Pathology Image Data Deficiency: Generating Images from Pathological Transformation Process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12316">http://arxiv.org/abs/2311.12316</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rowerliu/adbd">https://github.com/rowerliu/adbd</a></li>
<li>paper_authors: Zeyu Liu, Yufang He, Yu Zhao, Yunlu Feng, Guanglei Zhang</li>
<li>for:  overcome the limitations of histopathology and provide timely clinical analysis</li>
<li>methods:  adaptive depth-controlled bidirectional diffusion (ADBD) network for image data generation, hybrid attention strategy, and adaptive depth-controlled strategy</li>
<li>results:  unlimited cross-domain intermediate images with corresponding soft labels, effective for overcoming pathological image data deficiency and supportable for further pathology-related research.Here’s the full text in Simplified Chinese:</li>
<li>for:  Histopathology 的限制，提供快速的临床分析</li>
<li>methods:  adaptive depth-controlled bidirectional diffusion (ADBD) 网络，混合注意策略和 adaptive depth-controlled 策略</li>
<li>results:  cross-domain 中间图像的无限数量，与相应的软标签相对应，有效地解决了病理图像数据的不足问题，支持进一步的病理相关研究。<details>
<summary>Abstract</summary>
Histopathology serves as the gold standard for medical diagnosis but faces application limitations due to the shortage of medical resources. Leveraging deep learning, computer-aided diagnosis has the potential to alleviate the pathologist scarcity and provide timely clinical analysis. However, developing a reliable model generally necessitates substantial data for training, which is challenging in pathological field. In response, we propose an adaptive depth-controlled bidirectional diffusion (ADBD) network for image data generation. The domain migration approach can work with small trainset and overcome the diffusion overfitting by source information guidance. Specifically, we developed a hybrid attention strategy to blend global and local attention priorities, which guides the bidirectional diffusion and ensures the migration success. In addition, we developed the adaptive depth-controlled strategy to simulate physiological transformations, capable of yielding unlimited cross-domain intermediate images with corresponding soft labels. ADBD is effective for overcoming pathological image data deficiency and supportable for further pathology-related research.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The translation is written in the traditional Chinese characters, rather than the simplified ones used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="IEKM-A-Model-Incorporating-External-Keyword-Matrices"><a href="#IEKM-A-Model-Incorporating-External-Keyword-Matrices" class="headerlink" title="IEKM: A Model Incorporating External Keyword Matrices"></a>IEKM: A Model Incorporating External Keyword Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12310">http://arxiv.org/abs/2311.12310</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Luo, Qin Li, Zhao Yan, Mengliang Rao, Yunbo Cao</li>
<li>for: 这个论文是为了解决客户服务平台系统中的核心文本含义相似性任务中的两个紧迫挑战的：一是不同领域的客户 adaptive（DDA），二是模型很难分辨 literal close yet semantically different 的句子对（hard negative samples）。</li>
<li>methods: 我们提出了一种 incorporating external keywords matrices 模型（IEKM）来解决这些挑战。该模型使用外部工具或词典构建外部矩阵，然后通过门控单元融合到 transformer 结构中的自注意层，以实现灵活的 corrections。</li>
<li>results: 我们在多个 datasets 上评估了该方法，结果显示我们的方法在所有 datasets 上都有提高表现。为了证明我们的方法可以有效解决所有挑战，我们进行了 flexible correction 实验，其结果是从 56.61 提高到 73.53 的 F1 值。<details>
<summary>Abstract</summary>
A customer service platform system with a core text semantic similarity (STS) task faces two urgent challenges: Firstly, one platform system needs to adapt to different domains of customers, i.e., different domains adaptation (DDA). Secondly, it is difficult for the model of the platform system to distinguish sentence pairs that are literally close but semantically different, i.e., hard negative samples. In this paper, we propose an incorporation external keywords matrices model (IEKM) to address these challenges. The model uses external tools or dictionaries to construct external matrices and fuses them to the self-attention layers of the Transformer structure through gating units, thus enabling flexible corrections to the model results. We evaluate the method on multiple datasets and the results show that our method has improved performance on all datasets. To demonstrate that our method can effectively solve all the above challenges, we conduct a flexible correction experiment, which results in an increase in the F1 value from 56.61 to 73.53. Our code will be publicly available.
</details>
<details>
<summary>摘要</summary>
一个客户服务平台系统面临两个紧迫的挑战：首先，平台系统需要适应不同的客户领域（DDA）。其次，模型很难区分具有相似文本但具有不同含义的句子对，即困难的负样本（hard negative samples）。在这篇论文中，我们提出一种外部关键词矩阵模型（IEKM）来解决这些挑战。该模型通过使用外部工具或词典构建外部矩阵，然后将其与Transformer结构中的自我注意力层进行融合，以实现灵活的修正。我们对多个数据集进行评估，结果显示我们的方法在所有数据集上有改善的表现。为了证明我们的方法可以有效解决所有挑战，我们进行了灵活修正实验，其结果显示F1值从56.61提高到73.53。我们的代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Causality-is-all-you-need"><a href="#Causality-is-all-you-need" class="headerlink" title="Causality is all you need"></a>Causality is all you need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12307">http://arxiv.org/abs/2311.12307</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Xu, Yifei Gao, Hongshuo Tian, Yongdong Zhang, An-An Liu</li>
<li>for: 提出一个整合 causal 框架，以便在数据中探索隐藏的 causal 关系</li>
<li>methods: 基于 intervenion 机制，建立一个 stacked 网络框架，包括多个平行的 deconfounding 块，并通过 sufficient cause 概念选择适合的 deconfounding 方法</li>
<li>results: 在 CV 和 NLP 两个 классических任务上，CGR 可以超越当前状态的方法，并且在 Visual Question Answer 和 Long Document Classification 任务上达到了优秀的结果，具有潜在的应用空间在建立 “causal” pre-training 大规模模型<details>
<summary>Abstract</summary>
In the fundamental statistics course, students are taught to remember the well-known saying: "Correlation is not Causation". Till now, statistics (i.e., correlation) have developed various successful frameworks, such as Transformer and Pre-training large-scale models, which have stacked multiple parallel self-attention blocks to imitate a wide range of tasks. However, in the causation community, how to build an integrated causal framework still remains an untouched domain despite its excellent intervention capabilities. In this paper, we propose the Causal Graph Routing (CGR) framework, an integrated causal scheme relying entirely on the intervention mechanisms to reveal the cause-effect forces hidden in data. Specifically, CGR is composed of a stack of causal layers. Each layer includes a set of parallel deconfounding blocks from different causal graphs. We combine these blocks via the concept of the proposed sufficient cause, which allows the model to dynamically select the suitable deconfounding methods in each layer. CGR is implemented as the stacked networks, integrating no confounder, back-door adjustment, front-door adjustment, and probability of sufficient cause. We evaluate this framework on two classical tasks of CV and NLP. Experiments show CGR can surpass the current state-of-the-art methods on both Visual Question Answer and Long Document Classification tasks. In particular, CGR has great potential in building the "causal" pre-training large-scale model that effectively generalizes to diverse tasks. It will improve the machines' comprehension of causal relationships within a broader semantic space.
</details>
<details>
<summary>摘要</summary>
在基础统计课程中，学生们被教育要记住一句著名的话：“相关性不等于 causation”。到目前为止，统计（即相关性）已经发展出了多种成功的框架，如 transformer 和预训练大规模模型，这些模型堆叠了多个并行的自注意力块，以模拟多种任务。然而，在 causation 社区中，如何建立一个完整的 causal 框架仍然是一个未解决的问题，尽管它的 intervención 能力非常出色。在这篇论文中，我们提出了 causal graph routing（CGR）框架，一种完整的 causal 方案，仅仅通过 intervención 机制来揭示数据中隐藏的 causal 力量。具体来说，CGR 由一 stack 的 causal layers 组成，每层包括一组并行的干扰整理方法。我们通过 proposed sufficient cause 概念，将这些层结合在一起，让模型在不同的 causal graphs 中动态选择适当的干扰方法。CGR 实现为堆叠网络，包括无干扰、后门补做、前门补做和潜在 suficient cause 概念。我们在 CV 和 NLP 两个 класси型任务上进行了实验，结果表明，CGR 可以超越当前状态的艺术方法。特别是，CGR 在建立 "causal" 预训练大规模模型方面有很大的潜力，这将有助于机器更好地理解 causal 关系，并在更广泛的 semantic space 中进行泛化。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Effective-Policies-for-Land-Use-Planning"><a href="#Discovering-Effective-Policies-for-Land-Use-Planning" class="headerlink" title="Discovering Effective Policies for Land-Use Planning"></a>Discovering Effective Policies for Land-Use Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12304">http://arxiv.org/abs/2311.12304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Risto Miikkulainen, Olivier Francon, Daniel Young, Elliot Meyerson, Babak Hodjat</li>
<li>for: 这项研究的目的是为了提供一种可以快速和效率地评估不同地区决策者可能选择的土地利用政策选择工具。</li>
<li>methods: 该研究使用了可用历史数据变化的土地使用和模拟吸收二氧化碳的过程来学习一个代理模型，以便有效地评估不同选项。然后，使用进化搜索过程来找到适合特定地点的有效土地利用策略。</li>
<li>results: 该系统可以生成自适应性的Pareto前面，其中评估碳气影响和变化量在不同地点之间进行了交换，从而为土地规划提供了一个有用的工具。<details>
<summary>Abstract</summary>
How areas of land are allocated for different uses, such as forests, urban, and agriculture, has a large effect on carbon balance, and therefore climate change. Based on available historical data on changes in land use and a simulation of carbon emissions/absorption, a surrogate model can be learned that makes it possible to evaluate the different options available to decision-makers efficiently. An evolutionary search process can then be used to discover effective land-use policies for specific locations. Such a system was built on the Project Resilience platform and evaluated with the Land-Use Harmonization dataset and the BLUE simulator. It generates Pareto fronts that trade off carbon impact and amount of change customized to different locations, thus providing a potentially useful tool for land-use planning.
</details>
<details>
<summary>摘要</summary>
预设语言：中文（简体）</SYS>不同用途的土地分配对碳平衡有着很大的影响，从而影响气候变化。通过历史数据变化和碳排放/吸收的模拟，可以学习一个代表模型，以便有效地评估不同选择。然后，一种EVOLUTIONARY搜索过程可以用来找到适合特定地点的有效土地使用政策。这种系统在Project Resilience平台上实现，并使用Land-Use Harmonization数据集和BLUE simulator进行评估。它生成了碳影响和变化量的平衡 Front，以便为土地使用规划提供有用工具。
</details></li>
</ul>
<hr>
<h2 id="Detecting-subtle-macroscopic-changes-in-a-finite-temperature-classical-scalar-field-with-machine-learning"><a href="#Detecting-subtle-macroscopic-changes-in-a-finite-temperature-classical-scalar-field-with-machine-learning" class="headerlink" title="Detecting subtle macroscopic changes in a finite temperature classical scalar field with machine learning"></a>Detecting subtle macroscopic changes in a finite temperature classical scalar field with machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12303">http://arxiv.org/abs/2311.12303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiming Yang, Yutong Zheng, Jiahong Zhou, Huiyu Li, Jun Yin</li>
<li>for: 本研究的目的是探索用于检测多体系统中巨观变化的方法，以寻找可以超过物理方法和统计方法的敏感度。</li>
<li>methods: 本研究使用了Scalar field samples在不同温度下进行对比，并评估了物理方法、统计方法和AI方法的 differentiations 的效果。</li>
<li>results: 研究发现，使用AI方法可以具有更高的敏感度，并且能够检测到物理方法和统计方法所忽略的巨观变化。这得到的结果提供了一种可能性，即AI可以在多体系统中检测到物理方法所难以捕捉的巨观变化。<details>
<summary>Abstract</summary>
The ability to detect macroscopic changes is important for probing the behaviors of experimental many-body systems from the classical to the quantum realm. Although abrupt changes near phase boundaries can easily be detected, subtle macroscopic changes are much more difficult to detect as the changes can be obscured by noise. In this study, as a toy model for detecting subtle macroscopic changes in many-body systems, we try to differentiate scalar field samples at varying temperatures. We compare different methods for making such differentiations, from physics method, statistics method, to AI method. Our finding suggests that the AI method outperforms both the statistical method and the physics method in its sensitivity. Our result provides a proof-of-concept that AI can potentially detect macroscopic changes in many-body systems that elude physical measures.
</details>
<details>
<summary>摘要</summary>
importance of detecting macroscopic changes在实验几体系中从古典到量子领域的行为探测中，检测大规模变化的能力是关键。虽然近界面的快速变化容易被检测，但极其微妙的变化可能会受到噪声所隐藏。在这种研究中，我们作为几体系中细微变化探测的玩偶模型，尝试将扩散场样本在不同温度下进行差异化。我们比较了不同的方法进行这种差异化，包括物理方法、统计方法以及人工智能方法。我们的发现表明，人工智能方法在敏感性方面胜过物理方法和统计方法。我们的结果提供了一个证明，AI可能在物理测量所逃脱的几体系中探测到大规模变化。
</details></li>
</ul>
<hr>
<h2 id="Noise-in-Relation-Classification-Dataset-TACRED-Characterization-and-Reduction"><a href="#Noise-in-Relation-Classification-Dataset-TACRED-Characterization-and-Reduction" class="headerlink" title="Noise in Relation Classification Dataset TACRED: Characterization and Reduction"></a>Noise in Relation Classification Dataset TACRED: Characterization and Reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12298">http://arxiv.org/abs/2311.12298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshay Parekh, Ashish Anand, Amit Awekar</li>
<li>for: 本研究的目标是两fold，一是探索基于模型的方法来 caracterize TACRED 数据集中的噪音的主要原因，二是自动标识可能噪音的实例。</li>
<li>methods: 我们分析了当前顶峰模型的预测和性能，以便在 TACRED 数据集中 indentify 噪音的根本原因。我们发现大多数噪音来自于被标记为无关的实例。为了实现第二个目标，我们探索了两种基于 nearest-neighbor 策略的方法来自动标识可能噪音的实例。</li>
<li>results: 我们的实验结果表明，使用 Intrinsic Strategy (IS) 可以提高 SOTA 模型在 TACRED-E 上的平均 F1 分数 by 4%，而使用 Extrinsic Strategy (ES) 可以提高 SOTA 模型在 TACRED-E 和 TACRED-RN 上的平均 F1 分数 by 3.8% 和 4.4%  соответpectively。此外，我们还扩展了 ES 以清理正例，这 führt 到了平均性能提高 5.8% 和 5.6% 在 TACRED-ENP 和 TACRED-RNP 上。<details>
<summary>Abstract</summary>
The overarching objective of this paper is two-fold. First, to explore model-based approaches to characterize the primary cause of the noise. in the RE dataset TACRED Second, to identify the potentially noisy instances. Towards the first objective, we analyze predictions and performance of state-of-the-art (SOTA) models to identify the root cause of noise in the dataset. Our analysis of TACRED shows that the majority of the noise in the dataset originates from the instances labeled as no-relation which are negative examples. For the second objective, we explore two nearest-neighbor-based strategies to automatically identify potentially noisy examples for elimination and reannotation. Our first strategy, referred to as Intrinsic Strategy (IS), is based on the assumption that positive examples are clean. Thus, we have used false-negative predictions to identify noisy negative examples. Whereas, our second approach, referred to as Extrinsic Strategy, is based on using a clean subset of the dataset to identify potentially noisy negative examples. Finally, we retrained the SOTA models on the eliminated and reannotated dataset. Our empirical results based on two SOTA models trained on TACRED-E following the IS show an average 4% F1-score improvement, whereas reannotation (TACRED-R) does not improve the original results. However, following ES, SOTA models show the average F1-score improvement of 3.8% and 4.4% when trained on respective eliminated (TACRED-EN) and reannotated (TACRED-RN) datasets respectively. We further extended the ES for cleaning positive examples as well, which resulted in an average performance improvement of 5.8% and 5.6% for the eliminated (TACRED-ENP) and reannotated (TACRED-RNP) datasets respectively.
</details>
<details>
<summary>摘要</summary>
本文的主要目标是两重。第一，通过模型方法来探讨TACRED数据集中噪音的主要原因。第二，并将潜在的噪音实例标记出来。对于第一个目标，我们分析了领先的模型（SOTA）的预测和性能，以确定TACRED数据集中噪音的根本原因。我们的分析表明，TACRED数据集中的噪音主要来自于标记为“无关”的实例，即负例。为了实现第二个目标，我们探讨了两种基于最近邻居的策略来自动标记潜在的噪音实例。我们的第一种策略（IS）假设正例是干净的，因此我们使用了false-negative预测来标识噪音的负例。而我们的第二种策略（ES）则是基于使用干净的子集来标识潜在的噪音负例。最后，我们在TACRED-E中重新训练了SOTA模型，并基于IS进行了预测。我们的实验结果表明，TACRED-E中使用IS后，SOTA模型的平均F1分数提高了4%。然而，TACRED-R不改善原来的结果。但是，基于ES进行了潜在噪音实例的标记和重新标注，SOTA模型在TACRED-EN和TACRED-RN中分别提高了3.8%和4.4%的平均F1分数。此外，我们还将ES扩展到清理正例上，并在TACRED-ENP和TACRED-RNP中分别提高了5.8%和5.6%的平均F1分数。
</details></li>
</ul>
<hr>
<h2 id="ATLANTIC-Structure-Aware-Retrieval-Augmented-Language-Model-for-Interdisciplinary-Science"><a href="#ATLANTIC-Structure-Aware-Retrieval-Augmented-Language-Model-for-Interdisciplinary-Science" class="headerlink" title="ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for Interdisciplinary Science"></a>ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for Interdisciplinary Science</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12289">http://arxiv.org/abs/2311.12289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Munikoti, Anurag Acharya, Sridevi Wagle, Sameera Horawalavithana</li>
<li>for: 提高语言模型在科学任务中的表现，特别是 faithfulness 和 relevance 的问题。</li>
<li>methods: 提出了一种基于文档结构的搜索增强技术，通过文档关系图建模文档之间的结构关系，并在语言模型预训练过程中使用这些结构关系。</li>
<li>results: 实验结果表明，基于结构的搜索增强可以提取更加相关、准确和 faithful 的段落，同时与总准确率相对保持接近。<details>
<summary>Abstract</summary>
Large language models record impressive performance on many natural language processing tasks. However, their knowledge capacity is limited to the pretraining corpus. Retrieval augmentation offers an effective solution by retrieving context from external knowledge sources to complement the language model. However, existing retrieval augmentation techniques ignore the structural relationships between these documents. Furthermore, retrieval models are not explored much in scientific tasks, especially in regard to the faithfulness of retrieved documents. In this paper, we propose a novel structure-aware retrieval augmented language model that accommodates document structure during retrieval augmentation. We create a heterogeneous document graph capturing multiple types of relationships (e.g., citation, co-authorship, etc.) that connect documents from more than 15 scientific disciplines (e.g., Physics, Medicine, Chemistry, etc.). We train a graph neural network on the curated document graph to act as a structural encoder for the corresponding passages retrieved during the model pretraining. Particularly, along with text embeddings of the retrieved passages, we obtain structural embeddings of the documents (passages) and fuse them together before feeding them to the language model. We evaluate our model extensively on various scientific benchmarks that include science question-answering and scientific document classification tasks. Experimental results demonstrate that structure-aware retrieval improves retrieving more coherent, faithful and contextually relevant passages, while showing a comparable performance in the overall accuracy.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理模型在许多任务上表现出色，但它们的知识容量受到预训练文本集的限制。检索增强技术可以补充语言模型，但现有技术忽略了文档之间的结构关系。此外，在科学任务中，检索模型尚未得到充分的研究，特别是文档的准确性。在这篇论文中，我们提出了一种新的结构意识检索增强语言模型，可以在检索过程中考虑文档的结构。我们创建了一个多类关系（如引用、共作者等）连接来自多个科学领域（如物理、医学、化学等）的文档 graphs。我们在这些文档 graphs 上训练了一个图 neural network，作为文档（段落）的结构编码器。特别是在 retrieve 过程中获取的文档（段落）的文本嵌入，我们还获取了它们的结构嵌入，并将它们合并在一起，然后将其传递给语言模型。我们在科学问答和科学文档分类任务中进行了广泛的实验评估。实验结果表明，结构意识检索可以更好地检索具有准确性、完整性和文本关联性的段落，同时保持相对的精度。
</details></li>
</ul>
<hr>
<h2 id="Adapting-LLMs-for-Efficient-Personalized-Information-Retrieval-Methods-and-Implications"><a href="#Adapting-LLMs-for-Efficient-Personalized-Information-Retrieval-Methods-and-Implications" class="headerlink" title="Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications"></a>Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12287">http://arxiv.org/abs/2311.12287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samira Ghodratnama, Mehrdad Zakershahrak</li>
<li>for: This paper focuses on the application of Large Language Models (LLMs) in information retrieval (IR) systems, with the goal of enriching the IR experience and improving result accuracy.</li>
<li>methods: The paper explores various methodologies to optimize the retrieval process, select optimal models, and effectively scale and orchestrate LLMs, while addressing challenges such as model hallucination and ensuring cost-efficiency.</li>
<li>results: The paper unveils innovative strategies for integrating LLMs with IR systems, and highlights the need for a balanced approach aligned with user-centric principles, taking into account considerations such as user privacy, data optimization, and system clarity and interpretability.<details>
<summary>Abstract</summary>
The advent of Large Language Models (LLMs) heralds a pivotal shift in online user interactions with information. Traditional Information Retrieval (IR) systems primarily relied on query-document matching, whereas LLMs excel in comprehending and generating human-like text, thereby enriching the IR experience significantly. While LLMs are often associated with chatbot functionalities, this paper extends the discussion to their explicit application in information retrieval. We explore methodologies to optimize the retrieval process, select optimal models, and effectively scale and orchestrate LLMs, aiming for cost-efficiency and enhanced result accuracy. A notable challenge, model hallucination-where the model yields inaccurate or misinterpreted data-is addressed alongside other model-specific hurdles. Our discourse extends to crucial considerations including user privacy, data optimization, and the necessity for system clarity and interpretability. Through a comprehensive examination, we unveil not only innovative strategies for integrating Language Models (LLMs) with Information Retrieval (IR) systems, but also the consequential considerations that underline the need for a balanced approach aligned with user-centric principles.
</details>
<details>
<summary>摘要</summary>
随着大型自然语言模型（LLMs）的出现，在线用户与信息交互方式发生了重要的转变。传统的信息检索（IR）系统主要依赖于查询文档匹配，而 LLMs 则在理解和生成人类语言方面表现出色，从而对 IR 体验进行了显著改善。虽然 LLMs frequently 被关联到 chatbot 功能，但这篇论文推广了它们在 IR 领域的直接应用。我们探讨了优化检索过程、选择优质模型、并有效地执行和协调 LLMs，以实现成本效益和提高结果准确性。一个显著的挑战是模型幻觉-模型生成的数据不准确或被误 интерпретирова为。我们的讨论还涵盖了关键考虑因素，包括用户隐私、数据优化和系统清晰性和可解释性。通过全面的检视，我们不仅描述了将 Language Models（LLMs）与 Information Retrieval（IR）系统集成的创新策略，还探讨了这些策略的下游考虑。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Forecast-Reconciliation-with-Kullback-Leibler-Divergence-Regularization"><a href="#Probabilistic-Forecast-Reconciliation-with-Kullback-Leibler-Divergence-Regularization" class="headerlink" title="Probabilistic Forecast Reconciliation with Kullback-Leibler Divergence Regularization"></a>Probabilistic Forecast Reconciliation with Kullback-Leibler Divergence Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12279">http://arxiv.org/abs/2311.12279</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanyu0316/Probabilistic-Forecast-Reconciliation-with-DL">https://github.com/guanyu0316/Probabilistic-Forecast-Reconciliation-with-DL</a></li>
<li>paper_authors: Guanyu Zhang, Feng Li, Yanfei Kang</li>
<li>for: 这个研究旨在提出一种新的机器学习方法来实现可能性预测重复调和。</li>
<li>methods: 这个方法使用了深度学习框架，并将重复调和步骤与预测步骤融合在一起，使得重复调和步骤更加软和 гиб可。</li>
<li>results: 这个方法在三个层次时间系列数据上进行评估，与其他可能性预测重复调和方法相比，展现了更好的性能。<details>
<summary>Abstract</summary>
As the popularity of hierarchical point forecast reconciliation methods increases, there is a growing interest in probabilistic forecast reconciliation. Many studies have utilized machine learning or deep learning techniques to implement probabilistic forecasting reconciliation and have made notable progress. However, these methods treat the reconciliation step as a fixed and hard post-processing step, leading to a trade-off between accuracy and coherency. In this paper, we propose a new approach for probabilistic forecast reconciliation. Unlike existing approaches, our proposed approach fuses the prediction step and reconciliation step into a deep learning framework, making the reconciliation step more flexible and soft by introducing the Kullback-Leibler divergence regularization term into the loss function. The approach is evaluated using three hierarchical time series datasets, which shows the advantages of our approach over other probabilistic forecast reconciliation methods.
</details>
<details>
<summary>摘要</summary>
As the popularity of hierarchical point forecast reconciliation methods increases, there is a growing interest in probabilistic forecast reconciliation. Many studies have utilized machine learning or deep learning techniques to implement probabilistic forecasting reconciliation and have made notable progress. However, these methods treat the reconciliation step as a fixed and hard post-processing step, leading to a trade-off between accuracy and coherency. In this paper, we propose a new approach for probabilistic forecast reconciliation. Unlike existing approaches, our proposed approach fuses the prediction step and reconciliation step into a deep learning framework, making the reconciliation step more flexible and soft by introducing the Kullback-Leibler divergence regularization term into the loss function. The approach is evaluated using three hierarchical time series datasets, which shows the advantages of our approach over other probabilistic forecast reconciliation methods.Here's the translation breakdown:* "As the popularity of hierarchical point forecast reconciliation methods increases" becomes "随着层次点预测重叠方法的流行度提高"* "there is a growing interest in probabilistic forecast reconciliation" becomes "对 probabilistic forecasting 重叠方法产生了越来越大的兴趣"* "Many studies have utilized machine learning or deep learning techniques to implement probabilistic forecasting reconciliation" becomes "许多研究使用机器学习或深度学习技术实现 probabilistic forecasting 重叠方法"* "and have made notable progress" becomes "并取得了显著的进步"* "However, these methods treat the reconciliation step as a fixed and hard post-processing step" becomes "然而，这些方法将重叠步骤视为一个固定和硬的后处理步骤"* "leading to a trade-off between accuracy and coherency" becomes "导致精度和一致性之间的负担"* "In this paper, we propose a new approach for probabilistic forecast reconciliation" becomes "在这篇论文中，我们提出了一种新的 probabilistic forecasting 重叠方法"* "Unlike existing approaches, our proposed approach fuses the prediction step and reconciliation step into a deep learning framework" becomes "与现有方法不同，我们的提议方法将预测步骤和重叠步骤集成到深度学习框架中"* "making the reconciliation step more flexible and soft" becomes "使重叠步骤更加灵活和软"* "by introducing the Kullback-Leibler divergence regularization term into the loss function" becomes "通过在损失函数中引入库拉-莱布勒分子违异项来实现"* "The approach is evaluated using three hierarchical time series datasets" becomes "该方法在三个层次时间序列数据集上进行评估"* "which shows the advantages of our approach over other probabilistic forecast reconciliation methods" becomes "显示了我们的方法与其他 probabilistic forecasting 重叠方法相比有优势"
</details></li>
</ul>
<hr>
<h2 id="Learning-Causal-Representations-from-General-Environments-Identifiability-and-Intrinsic-Ambiguity"><a href="#Learning-Causal-Representations-from-General-Environments-Identifiability-and-Intrinsic-Ambiguity" class="headerlink" title="Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity"></a>Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12267">http://arxiv.org/abs/2311.12267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jikai Jin, Vasilis Syrgkanis</li>
<li>for: 本文研究了 causal representation learning，即从低级数据中恢复高级 latent variables 和其 causal 关系。</li>
<li>methods: 本文使用 linear causal models 和 general non-parametric causal models，并提供了一种名为 LiNGCReL 的算法，可以在不假设硬 intervenction 的情况下提供 identifiability 保证。</li>
<li>results: 本文提供了一种新的 identifiability 推论，可以在 general environments 下对 causal graph 进行全面回归，但 latent variables 只能被确定到 effect-domination ambiguity（EDA）。同时， LiNGCReL 算法可以在 numerical experiments 中证明其效果。<details>
<summary>Abstract</summary>
This paper studies causal representation learning, the task of recovering high-level latent variables and their causal relationships from low-level data that we observe, assuming access to observations generated from multiple environments. While existing works are able to prove full identifiability of the underlying data generating process, they typically assume access to single-node, hard interventions which is rather unrealistic in practice. The main contribution of this paper is characterize a notion of identifiability which is provably the best one can achieve when hard interventions are not available. First, for linear causal models, we provide identifiability guarantee for data observed from general environments without assuming any similarities between them. While the causal graph is shown to be fully recovered, the latent variables are only identified up to an effect-domination ambiguity (EDA). We then propose an algorithm, LiNGCReL which is guaranteed to recover the ground-truth model up to EDA, and we demonstrate its effectiveness via numerical experiments. Moving on to general non-parametric causal models, we prove the same idenfifiability guarantee assuming access to groups of soft interventions. Finally, we provide counterparts of our identifiability results, indicating that EDA is basically inevitable in our setting.
</details>
<details>
<summary>摘要</summary>
For linear causal models, we provide identifiability guarantees for data observed from general environments without assuming any similarities between them. Although the causal graph is fully recovered, the latent variables are only identified up to an effect-domination ambiguity (EDA). We then propose an algorithm, LiNGCReL, which is guaranteed to recover the ground-truth model up to EDA, and we demonstrate its effectiveness through numerical experiments.For general non-parametric causal models, we prove the same identifiability guarantee assuming access to groups of soft interventions. Finally, we provide counterparts of our identifiability results, indicating that EDA is inevitable in our setting.Translated into Simplified Chinese:这篇论文研究了 causal representation learning，即从低级数据中恢复高级潜在变量和其 causal 关系。现有的工作可以证明潜在数据生成过程的全部可 identificability，但它们假设有访问单个硬 intervención，这是在实际中不太实际。本文的主要贡献是 characterize一种可 identificability 的定义，这是在硬 intervención不可用时最好的。对于线性 causal 模型，我们提供了数据从通用环境中观察的可 identificability  garantuee，无需假设任何相似性。虽然 causal 图完全回归，但潜在变量只能被识别到 effect-domination ambiguity（EDA）。我们Then propose了一个算法，LiNGCReL，它可以 garantuee 回归真实模型，并在数值实验中证明其效果。对于普通非参数 causal 模型，我们证明了同样的可 identificability  garantuee，假设有访问一组软 intervención。最后，我们提供了对我们可 identificability 结果的对应，表明 EDA 是我们设定中不可避免的。
</details></li>
</ul>
<hr>
<h2 id="Resilient-Control-of-Networked-Microgrids-using-Vertical-Federated-Reinforcement-Learning-Designs-and-Real-Time-Test-Bed-Validations"><a href="#Resilient-Control-of-Networked-Microgrids-using-Vertical-Federated-Reinforcement-Learning-Designs-and-Real-Time-Test-Bed-Validations" class="headerlink" title="Resilient Control of Networked Microgrids using Vertical Federated Reinforcement Learning: Designs and Real-Time Test-Bed Validations"></a>Resilient Control of Networked Microgrids using Vertical Federated Reinforcement Learning: Designs and Real-Time Test-Bed Validations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12264">http://arxiv.org/abs/2311.12264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayak Mukherjee, Ramij R. Hossain, Sheik M. Mohiuddin, Yuan Liu, Wei Du, Veronica Adetola, Rohit A. Jinsiwale, Qiuhua Huang, Tianzhixi Yin, Ankit Singhal</li>
<li>for: 这篇论文的目的是提高网络化微型发电团队的系统级别坚韧性，面对增加的增verter-based资源（IBR）人口。</li>
<li>methods: 该论文提出了一种受到敌意cyber事件的攻击的控制设计，并提出了一种新的联邦强化学习（Fed-RL）方法来解决模型复杂性和不确定的IBR设备动态行为问题，以及数据分享在多方所有的网络化发电团队中的隐私问题。</li>
<li>results: 该论文通过将在 simulations 中学习的控制策略转移到硬件实验室中，成功bridging the sim-to-real gap，并且实验结果表明，由RL控制器 Mitigate the injected attacks。<details>
<summary>Abstract</summary>
Improving system-level resiliency of networked microgrids is an important aspect with increased population of inverter-based resources (IBRs). This paper (1) presents resilient control design in presence of adversarial cyber-events, and proposes a novel federated reinforcement learning (Fed-RL) approach to tackle (a) model complexities, unknown dynamical behaviors of IBR devices, (b) privacy issues regarding data sharing in multi-party-owned networked grids, and (2) transfers learned controls from simulation to hardware-in-the-loop test-bed, thereby bridging the gap between simulation and real world. With these multi-prong objectives, first, we formulate a reinforcement learning (RL) training setup generating episodic trajectories with adversaries (attack signal) injected at the primary controllers of the grid forming (GFM) inverters where RL agents (or controllers) are being trained to mitigate the injected attacks. For networked microgrids, the horizontal Fed-RL method involving distinct independent environments is not appropriate, leading us to develop vertical variant Federated Soft Actor-Critic (FedSAC) algorithm to grasp the interconnected dynamics of networked microgrid. Next, utilizing OpenAI Gym interface, we built a custom simulation set-up in GridLAB-D/HELICS co-simulation platform, named Resilient RL Co-simulation (ResRLCoSIM), to train the RL agents with IEEE 123-bus benchmark test systems comprising 3 interconnected microgrids. Finally, the learned policies in simulation world are transferred to the real-time hardware-in-the-loop test-bed set-up developed using high-fidelity Hypersim platform. Experiments show that the simulator-trained RL controllers produce convincing results with the real-time test-bed set-up, validating the minimization of sim-to-real gap.
</details>
<details>
<summary>摘要</summary>
提高网络化微型发电团队的系统级别鲁棒性是一项非常重要的任务，随着升高的人口倾向于投入器件基础资源（IBR）。本文（1）提出了在敌意网络事件存在下的鲁棒控制设计，并提出了一种新的联邦强化学习（Fed-RL）方法来解决模型复杂性、不知道IBR设备的动态行为和多方所有网络发电团队数据共享隐私问题。此外，文章还考虑了将学习控制从模拟世界转移到硬件实验室中的问题。为了实现这些多重目标，我们首先设计了一种基于学习控制的训练布局，生成了随机攻击信号插入Grid Forming Matrix（GFM）逻辑控制器的循环训练过程，以让RL代理（或控制器）在抗击攻击方面进行抵抗。由于网络微型发电团队的横向联邦方法不适用，我们开发了垂直变种的联邦软 actor-critic（FedSAC）算法，以捕捉网络微型发电团队的水平联接动态。然后，我们使用OpenAI Gym接口，在GridLAB-D/HELICS协同 simulate平台上建立了一个自定义的模拟设置，名为Resilient RL Co-simulation（ResRLCoSIM），以在IEEE 123-bus标准测试系统上训练RL代理。最后，在实时硬件实验室中使用高精度的Hypersim平台，将模拟世界中学习到的策略转移到实时硬件实验室中。实验结果表明，模拟世界中训练的RL控制器在实时硬件实验室中的表现非常有力，验证了模拟和实际世界之间的减少。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/cs.AI_2023_11_21/" data-id="clpxp6bxn007pee88a5075y8f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/cs.CL_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T11:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/cs.CL_2023_11_21/">cs.CL - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="LowResource-at-BLP-2023-Task-2-Leveraging-BanglaBert-for-Low-Resource-Sentiment-Analysis-of-Bangla-Language"><a href="#LowResource-at-BLP-2023-Task-2-Leveraging-BanglaBert-for-Low-Resource-Sentiment-Analysis-of-Bangla-Language" class="headerlink" title="LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource Sentiment Analysis of Bangla Language"></a>LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource Sentiment Analysis of Bangla Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12735">http://arxiv.org/abs/2311.12735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aunabil4602/bnlp-workshop-task2-2023">https://github.com/aunabil4602/bnlp-workshop-task2-2023</a></li>
<li>paper_authors: Aunabil Chakma, Masum Hasan</li>
<li>for: 本研究的目的是为BLP-2023任务2中进行情感分析，使用不同社交媒体平台上的公开帖子和评论。</li>
<li>methods: 本研究使用了BanglaBert模型，包括微调、随机tokenDrop和多个外部数据集，以及task-adaptive具体和重新措词。</li>
<li>results: 本研究的最终模型是三个最好的BanglaBert变种的弹性结合。在30支队中的测试集上，我们的系统获得了3rd的成绩，分别为0.718。此外，我们还讨论了不太好的系统，包括使用BanglaT5进行任务适应的具体和重新措词。<details>
<summary>Abstract</summary>
This paper describes the system of the LowResource Team for Task 2 of BLP-2023, which involves conducting sentiment analysis on a dataset composed of public posts and comments from diverse social media platforms. Our primary aim is to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus, using various strategies including fine-tuning, dropping random tokens, and using several external datasets. Our final model is an ensemble of the three best BanglaBert variations. Our system has achieved overall 3rd in the Test Set among 30 participating teams with a score of 0.718. Additionally, we discuss the promising systems that didn't perform well namely task-adaptive pertaining and paraphrasing using BanglaT5. Training codes and external datasets which are used for our system are publicly available at https://github.com/Aunabil4602/bnlp-workshop-task2-2023
</details>
<details>
<summary>摘要</summary>
这篇论文描述了我们在BLP-2023任务2中的系统，即对不同社交媒体平台上的公共帖子和评论进行情感分析。我们的主要目标是使用BanglaBert模型，包括微调、随机删除token和使用外部数据集，以实现不同的推理策略。我们的最终模型是 ensemble of 三个最佳 BanglaBert 变体。我们的系统在30个参与队伍中的测试集中得到了总第三名，得分为0.718。此外，我们还讨论了不太好的系统，namely task-adaptive pertaining和paraphrasing使用BanglaT5。我们使用的训练代码和外部数据集在https://github.com/Aunabil4602/bnlp-workshop-task2-2023上公开可用。
</details></li>
</ul>
<hr>
<h2 id="Soft-Random-Sampling-A-Theoretical-and-Empirical-Analysis"><a href="#Soft-Random-Sampling-A-Theoretical-and-Empirical-Analysis" class="headerlink" title="Soft Random Sampling: A Theoretical and Empirical Analysis"></a>Soft Random Sampling: A Theoretical and Empirical Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12727">http://arxiv.org/abs/2311.12727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaodong Cui, Ashish Mittal, Songtao Lu, Wei Zhang, George Saon, Brian Kingsbury</li>
<li>for: 大规模深度神经网络的高效训练</li>
<li>methods: 随机抽样法（SRS），包括每个纪元内随机选择数据集的子集</li>
<li>results:	+  theoretically analyzed sampling dynamics, including data coverage and occupancy	+  demonstrated convergence with non-convex objective functions and given convergence rate	+  shown to have better accuracy-efficiency trade-off compared to existing coreset-based data selection methods	+  significantly reduced training time with competitive performance on real-world industrial scale data sets, with almost no additional computing cost.<details>
<summary>Abstract</summary>
Soft random sampling (SRS) is a simple yet effective approach for efficient training of large-scale deep neural networks when dealing with massive data. SRS selects a subset uniformly at random with replacement from the full data set in each epoch. In this paper, we conduct a theoretical and empirical analysis of SRS. First, we analyze its sampling dynamics including data coverage and occupancy. Next, we investigate its convergence with non-convex objective functions and give the convergence rate. Finally, we provide its generalization performance. We empirically evaluate SRS for image recognition on CIFAR10 and automatic speech recognition on Librispeech and an in-house payload dataset to demonstrate its effectiveness. Compared to existing coreset-based data selection methods, SRS offers a better accuracy-efficiency trade-off. Especially on real-world industrial scale data sets, it is shown to be a powerful training strategy with significant speedup and competitive performance with almost no additional computing cost.
</details>
<details>
<summary>摘要</summary>
Random sampling (SRS) is a simple yet effective approach for efficient training of large-scale deep neural networks when dealing with massive data. SRS selects a subset uniformly at random with replacement from the full data set in each epoch. In this paper, we conduct a theoretical and empirical analysis of SRS. First, we analyze its sampling dynamics including data coverage and occupancy. Next, we investigate its convergence with non-convex objective functions and give the convergence rate. Finally, we provide its generalization performance. We empirically evaluate SRS for image recognition on CIFAR10 and automatic speech recognition on Librispeech and an in-house payload dataset to demonstrate its effectiveness. Compared to existing coreset-based data selection methods, SRS offers a better accuracy-efficiency trade-off. Especially on real-world industrial scale data sets, it is shown to be a powerful training strategy with significant speedup and competitive performance with almost no additional computing cost.Here's the translation in Traditional Chinese:Random sampling (SRS) is a simple yet effective approach for efficient training of large-scale deep neural networks when dealing with massive data. SRS selects a subset uniformly at random with replacement from the full data set in each epoch. In this paper, we conduct a theoretical and empirical analysis of SRS. First, we analyze its sampling dynamics including data coverage and occupancy. Next, we investigate its convergence with non-convex objective functions and give the convergence rate. Finally, we provide its generalization performance. We empirically evaluate SRS for image recognition on CIFAR10 and automatic speech recognition on Librispeech and an in-house payload dataset to demonstrate its effectiveness. Compared to existing coreset-based data selection methods, SRS offers a better accuracy-efficiency trade-off. Especially on real-world industrial scale data sets, it is shown to be a powerful training strategy with significant speedup and competitive performance with almost no additional computing cost.
</details></li>
</ul>
<hr>
<h2 id="Fair-Text-Classification-with-Wasserstein-Independence"><a href="#Fair-Text-Classification-with-Wasserstein-Independence" class="headerlink" title="Fair Text Classification with Wasserstein Independence"></a>Fair Text Classification with Wasserstein Independence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12689">http://arxiv.org/abs/2311.12689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/letenothibaud/wasserstein_fair_classification">https://github.com/letenothibaud/wasserstein_fair_classification</a></li>
<li>paper_authors: Thibaud Leteno, Antoine Gourru, Charlotte Laclau, Rémi Emonet, Christophe Gravier</li>
<li>for: This paper is written for mitigating biases in neural text classification and achieving fair treatment between sensitive groups.</li>
<li>methods: The paper uses adversarial training to induce Wasserstein independence between representations learned to predict the target label and the ones learned to predict sensitive attributes.</li>
<li>results: The approach provides two significant advantages: it does not require annotations of sensitive attributes in both testing and training data, and it exhibits a comparable or better fairness-accuracy trade-off compared to existing methods.<details>
<summary>Abstract</summary>
Group fairness is a central research topic in text classification, where reaching fair treatment between sensitive groups (e.g. women vs. men) remains an open challenge. This paper presents a novel method for mitigating biases in neural text classification, agnostic to the model architecture. Considering the difficulty to distinguish fair from unfair information in a text encoder, we take inspiration from adversarial training to induce Wasserstein independence between representations learned to predict our target label and the ones learned to predict some sensitive attribute. Our approach provides two significant advantages. Firstly, it does not require annotations of sensitive attributes in both testing and training data. This is more suitable for real-life scenarios compared to existing methods that require annotations of sensitive attributes at train time. Second, our approach exhibits a comparable or better fairness-accuracy trade-off compared to existing methods.
</details>
<details>
<summary>摘要</summary>
group fairness是文本分类中的一个中心研究话题，即在敏感群体（例如男女）中实现公正待遇仍然是一个开放的挑战。本文提出了一种新的方法来减少文本分类中的偏见，不受模型体系限制。由于难以在文本编码器中分辨公正与不公正的信息，我们从对抗训练中习惯到抗 Wasserstein 独立性 между预测目标标签和敏感特征的表示。我们的方法具有两个重要优势：首先，它不需要在测试和训练数据中都提供敏感特征标注。这与现有方法相比更适合实际应用中的情况，其中需要在训练数据中提供敏感特征标注。其次，我们的方法在公正精度之间与现有方法进行比较或更好的质量协调。
</details></li>
</ul>
<hr>
<h2 id="MathGloss-Building-mathematical-glossaries-from-text"><a href="#MathGloss-Building-mathematical-glossaries-from-text" class="headerlink" title="MathGloss: Building mathematical glossaries from text"></a>MathGloss: Building mathematical glossaries from text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12649">http://arxiv.org/abs/2311.12649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucy Horowitz, Valeria de Paiva</li>
<li>for: 该论文旨在创建一个自动生成的数学知识图（KG），用于大学 mathematics 教学，使用现有的自然语言处理（NLP）工具和资源。</li>
<li>methods: 该论文使用了 Wikidata、大学 mathematics 课程涵盖的术语、法国高等教育部 mathematics 课程班本、MuLiMa 数学词典和 nLab Category Theory wiki 等五个资源，通过自动化链接和整合，创建了一个有机的数学知识图。</li>
<li>results: 该论文通过组合不同资源，实现了自动生成数学知识图，帮助学生和数学家按照自己的偏好来学习数学，并且可以帮助数学家和形式化工具专家更好地理解和交流。<details>
<summary>Abstract</summary>
MathGloss is a project to create a knowledge graph (KG) for undergraduate mathematics from text, automatically, using modern natural language processing (NLP) tools and resources already available on the web. MathGloss is a linked database of undergraduate concepts in mathematics. So far, it combines five resources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph hosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses at the University of Chicago, (iii) the syllabus of the French undergraduate mathematics curriculum which includes hyperlinks to the automated theorem prover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by mathematicians, and (v) the nLab, a wiki for category theory also curated by mathematicians. MathGloss's goal is to bring together resources for learning mathematics and to allow every mathematician to tailor their learning to their own preferences. Moreover, by organizing different resources for learning undergraduate mathematics alongside those for learning formal mathematics, we hope to make it easier for mathematicians and formal tools (theorem provers, computer algebra systems, etc) experts to "understand" each other and break down some of the barriers to formal math.
</details>
<details>
<summary>摘要</summary>
mathgloss 是一个项目，旨在使用现代自然语言处理（NLP）工具和已有网络资源自动创建高等数学知识图（KG），以便为大学生数学学习提供一个链接数据库。 mathgloss 是一个跨语言的数学概念链接数据库，目前包括五种资源：（一）Wikidata，由wikimedia基金会共同编辑的多语言知识图；（二）大学 Of Chicago 的数学课程覆盖的概念列表；（三）法国大学数学课程班目录，包括自动证明工具 Lean 4 的链接；（四） MuLiMa，由数学家编辑的多语言数学词典；以及（五） nLab，由数学家编辑的类型论wiki。 mathgloss 的目标是将数学学习资源集成起来，让每个数学家可以根据自己的喜好自定义学习。此外，通过将不同的数学学习资源与正式数学（证明工具、计算代数系统等）相结合，我们希望能够让数学家和正式工具专家更好地理解对方，缓解一些正式数学的障碍。
</details></li>
</ul>
<hr>
<h2 id="Evaluation-Metrics-of-Language-Generation-Models-for-Synthetic-Traffic-Generation-Tasks"><a href="#Evaluation-Metrics-of-Language-Generation-Models-for-Synthetic-Traffic-Generation-Tasks" class="headerlink" title="Evaluation Metrics of Language Generation Models for Synthetic Traffic Generation Tasks"></a>Evaluation Metrics of Language Generation Models for Synthetic Traffic Generation Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12534">http://arxiv.org/abs/2311.12534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simone Filice, Jason Ingyu Choi, Giuseppe Castellucci, Eugene Agichtein, Oleg Rokhlenko</li>
<li>for: 本研究旨在探讨自然语言生成（NLG）任务中，如何评估生成的多个文本是否具备真实用户语言的多样性。</li>
<li>methods: 本研究使用了常见的NLG评价指标，如BLEU，以评估生成的交通数据。同时，我们还提出了一些适用于评估生成交通数据的新指标，并对其进行自动化和人工验证。</li>
<li>results: 实验结果显示，我们提出的新指标能够更好地评估生成交通数据的多样性，与人工判断相吻合度提高至20%。这些发现可能会推动更好的代理人生成文本数据的评估方法的发展。<details>
<summary>Abstract</summary>
Many Natural Language Generation (NLG) tasks aim to generate a single output text given an input prompt. Other settings require the generation of multiple texts, e.g., for Synthetic Traffic Generation (STG). This generation task is crucial for training and evaluating QA systems as well as conversational agents, where the goal is to generate multiple questions or utterances resembling the linguistic variability of real users. In this paper, we show that common NLG metrics, like BLEU, are not suitable for evaluating STG. We propose and evaluate several metrics designed to compare the generated traffic to the distribution of real user texts. We validate our metrics with an automatic procedure to verify whether they capture different types of quality issues of generated data; we also run human annotations to verify the correlation with human judgements. Experiments on three tasks, i.e., Shopping Utterance Generation, Product Question Generation and Query Auto Completion, demonstrate that our metrics are effective for evaluating STG tasks, and improve the agreement with human judgement up to 20% with respect to common NLG metrics. We believe these findings can pave the way towards better solutions for estimating the representativeness of synthetic text data.
</details>
<details>
<summary>摘要</summary>
很多自然语言生成（NLG）任务的目标是生成一个输入提示的输出文本。然而，有些设置需要生成多个文本，如Synthetic Traffic Generation（STG）。这种生成任务对于训练和评估问答系统以及对话代理系统非常重要，其目标是生成多个问题或句子，模拟真实用户的语言多样性。在这篇论文中，我们表明，常见的NLG指标，如BLEU，对STG任务不适用。我们提议和评估了一些适合比较生成的交通数据与真实用户文本的分布的指标。我们使用自动程序来验证我们的指标是否捕捉不同类型的质量问题，并进行了人工标注来验证与人类判断的相关性。我们在购物问题生成、产品问题生成和查询自动完成三个任务上进行了实验，并证明了我们的指标对STG任务有效，可以提高与常见NLG指标的协调性达到20%。我们认为这些发现可以为估计生成文本数据的表现性提供新的方向。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Word-Embeddings-for-Low-Resource-Languages-using-Anchors-and-a-Chain-of-Related-Languages"><a href="#Multilingual-Word-Embeddings-for-Low-Resource-Languages-using-Anchors-and-a-Chain-of-Related-Languages" class="headerlink" title="Multilingual Word Embeddings for Low-Resource Languages using Anchors and a Chain of Related Languages"></a>Multilingual Word Embeddings for Low-Resource Languages using Anchors and a Chain of Related Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12489">http://arxiv.org/abs/2311.12489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Viktor Hangya, Silvia Severini, Radoslav Ralev, Alexander Fraser, Hinrich Schütze</li>
<li>for: 本研究旨在提高低资源语言（&lt;5M tokens）和中等资源语言（&lt;50M）的多语言NLP表示法性能。</li>
<li>methods: 我们提出了一种语言链基本方法，通过逐渐添加每种语言到链中，从资源充足的源语言开始，以建立多语言词嵌入（MWEs）。我们还扩展了半联合双语方法，以消除前一代工作中的主要弱点，即独立训练的单语言嵌入。</li>
<li>results: 我们在4种语言家族中进行了双语词induction测试，包括4种低资源语言（&lt;5M tokens）和4种中等资源语言（&lt;50M）的目标语言，并显示了对两种类型的目标语言的改进表现。此外，我们的分析表明，中间语言的质量很重要，以及在多语言空间中使用所有语言的固定点也很重要。<details>
<summary>Abstract</summary>
Very low-resource languages, having only a few million tokens worth of data, are not well-supported by multilingual NLP approaches due to poor quality cross-lingual word representations. Recent work showed that good cross-lingual performance can be achieved if a source language is related to the low-resource target language. However, not all language pairs are related. In this paper, we propose to build multilingual word embeddings (MWEs) via a novel language chain-based approach, that incorporates intermediate related languages to bridge the gap between the distant source and target. We build MWEs one language at a time by starting from the resource rich source and sequentially adding each language in the chain till we reach the target. We extend a semi-joint bilingual approach to multiple languages in order to eliminate the main weakness of previous works, i.e., independently trained monolingual embeddings, by anchoring the target language around the multilingual space. We evaluate our method on bilingual lexicon induction for 4 language families, involving 4 very low-resource (<5M tokens) and 4 moderately low-resource (<50M) target languages, showing improved performance in both categories. Additionally, our analysis reveals the importance of good quality embeddings for intermediate languages as well as the importance of leveraging anchor points from all languages in the multilingual space.
</details>
<details>
<summary>摘要</summary>
非常低资源语言，具有只有几百万个Token的数据，由于跨语言Word表示质量不佳，不受现代多语言NLP方法支持。然而，一些语言对不对。在这篇论文中，我们提议使用语言链approach构建多语言词嵌入(MWEs)，通过包含中间相关语言来桥接源语言和目标语言之间的距离。我们从 richex源语言开始，逐一添加每种语言，直到达到目标语言。我们对多种语言进行扩展，以消除先前工作的主要弱点，即独立地训练的单语言嵌入。我们通过将目标语言固定在多语言空间中进行anchor来消除独立嵌入的主要弱点。我们对4种语言家族进行双语词典推导，包括4种非常低资源（<5M tokens）和4种moderately low-resource（<50M）目标语言，并表示提高了两类表现。此外，我们的分析表明中间语言的高质量嵌入的重要性以及在多语言空间中所有语言的泊点的重要性。
</details></li>
</ul>
<hr>
<h2 id="Speaker-Adapted-End-to-End-Visual-Speech-Recognition-for-Continuous-Spanish"><a href="#Speaker-Adapted-End-to-End-Visual-Speech-Recognition-for-Continuous-Spanish" class="headerlink" title="Speaker-Adapted End-to-End Visual Speech Recognition for Continuous Spanish"></a>Speaker-Adapted End-to-End Visual Speech Recognition for Continuous Spanish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12480">http://arxiv.org/abs/2311.12480</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos</li>
<li>for: 这 paper 的目的是研究如何通过特定人员的特征来提高视觉语音识别系统的质量。</li>
<li>methods: 这 paper 使用了基于精度调整技术的不同适应策略，以及一个预训练的 CTC&#x2F;Attention 架构作为基准。</li>
<li>results: 研究发现，在首先将 VSR 系统适应任务领域后，进行了两步精度调整处理，可以获得显著改善，而且只需使用有限的数据量就可以达到与当前状态艺术相当的结果。<details>
<summary>Abstract</summary>
Different studies have shown the importance of visual cues throughout the speech perception process. In fact, the development of audiovisual approaches has led to advances in the field of speech technologies. However, although noticeable results have recently been achieved, visual speech recognition remains an open research problem. It is a task in which, by dispensing with the auditory sense, challenges such as visual ambiguities and the complexity of modeling silence must be faced. Nonetheless, some of these challenges can be alleviated when the problem is approached from a speaker-dependent perspective. Thus, this paper studies, using the Spanish LIP-RTVE database, how the estimation of specialized end-to-end systems for a specific person could affect the quality of speech recognition. First, different adaptation strategies based on the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention architecture was used as a baseline throughout our experiments. Our findings showed that a two-step fine-tuning process, where the VSR system is first adapted to the task domain, provided significant improvements when the speaker adaptation was addressed. Furthermore, results comparable to the current state of the art were reached even when only a limited amount of data was available.
</details>
<details>
<summary>摘要</summary>
不同的研究表明视觉cue在语音识别过程中具有重要性。实际上，audiovisual Approach的发展在语音技术领域取得了进步。然而，虽然最近得到了显著的成果，视觉语音识别仍然是一个开放的研究问题。这是一个不使用听觉感的任务，需要面临视觉歧义和模拟 silence 的挑战。然而，通过将问题看作 speaker-dependent 的角度，一些这些挑战可以得到解决。因此，本文使用西班牙LIP-RTVE数据库，研究了特定人士特定系统的特化end-to-end系统如何影响语音识别质量。首先，不同的适应策略基于细致调整技术被提出。然后，我们使用了预训练的 CTC/Attention 架构作为基线。我们的发现表明，在任务领域中首先适应 VSR 系统，然后进行第二步的细致调整，可以提供显著改善。此外，即使只有有限的数据可用，我们还可以达到与当前状态艺术的比较好的成果。
</details></li>
</ul>
<hr>
<h2 id="CSMeD-Bridging-the-Dataset-Gap-in-Automated-Citation-Screening-for-Systematic-Literature-Reviews"><a href="#CSMeD-Bridging-the-Dataset-Gap-in-Automated-Citation-Screening-for-Systematic-Literature-Reviews" class="headerlink" title="CSMeD: Bridging the Dataset Gap in Automated Citation Screening for Systematic Literature Reviews"></a>CSMeD: Bridging the Dataset Gap in Automated Citation Screening for Systematic Literature Reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12474">http://arxiv.org/abs/2311.12474</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wojciechkusa/systematic-review-datasets">https://github.com/wojciechkusa/systematic-review-datasets</a></li>
<li>paper_authors: Wojciech Kusa, Oscar E. Mendoza, Matthias Samwald, Petr Knoth, Allan Hanbury</li>
<li>For: The paper aims to address the challenges of evaluating the performance of automated literature screening systems for systematic literature reviews (SLRs) by introducing a meta-dataset called CSMeD, which consolidates nine publicly released collections of SLRs.* Methods: The paper uses a combination of manual and automated methods to create the CSMeD meta-dataset, which provides unified access to 325 SLRs from the fields of medicine and computer science. The authors also introduce a new dataset called CSMeD-FT, designed specifically for evaluating the full text publication screening task.* Results: The authors conduct experiments and establish baselines on new datasets using CSMeD and CSMeD-FT, demonstrating the utility of the meta-dataset for training and evaluating automated citation screening models.<details>
<summary>Abstract</summary>
Systematic literature reviews (SLRs) play an essential role in summarising, synthesising and validating scientific evidence. In recent years, there has been a growing interest in using machine learning techniques to automate the identification of relevant studies for SLRs. However, the lack of standardised evaluation datasets makes comparing the performance of such automated literature screening systems difficult. In this paper, we analyse the citation screening evaluation datasets, revealing that many of the available datasets are either too small, suffer from data leakage or have limited applicability to systems treating automated literature screening as a classification task, as opposed to, for example, a retrieval or question-answering task. To address these challenges, we introduce CSMeD, a meta-dataset consolidating nine publicly released collections, providing unified access to 325 SLRs from the fields of medicine and computer science. CSMeD serves as a comprehensive resource for training and evaluating the performance of automated citation screening models. Additionally, we introduce CSMeD-FT, a new dataset designed explicitly for evaluating the full text publication screening task. To demonstrate the utility of CSMeD, we conduct experiments and establish baselines on new datasets.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)系统性文献评估 (SLR) 在科学证据的总结、Synthesizing 和验证中发挥了关键作用。在最近几年，使用机器学习技术自动化文献creening 的兴趣在提高。然而，由于缺乏标准化评估数据集，对自动化文献creening 系统的性能评估具有困难。在这篇论文中，我们分析了文献creening 评估数据集，发现许多可用数据集都很小，或者受到数据泄露或者应用范围受限。为了解决这些挑战，我们介绍了 CSMeD，一个meta-dataset，集成了9个公共发布的集合，提供了325篇SLR的资源，来训练和评估自动化文献creening 模型。此外，我们还介绍了 CSMeD-FT，一个专门为评估全文公布creening 任务而设计的新数据集。通过使用 CSMeD，我们实验了新的基准值。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Visual-Features-for-Continuous-Lipreading-in-Spanish"><a href="#Analysis-of-Visual-Features-for-Continuous-Lipreading-in-Spanish" class="headerlink" title="Analysis of Visual Features for Continuous Lipreading in Spanish"></a>Analysis of Visual Features for Continuous Lipreading in Spanish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12468">http://arxiv.org/abs/2311.12468</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos</li>
<li>for: 这个论文的目的是提出一种自动视觉语音识别系统，以便在没有声音时可以更好地理解语音。</li>
<li>methods: 该论文使用了基于隐藏马尔可夫模型的 Gaussian Mixture Models 来进行视觉语音识别，并使用了 eigenlips 作为视觉特征。</li>
<li>results: 研究结果表明，在限制的条件下，使用 eigenlips 和深度特征可以得到视觉语音识别的良好结果，但该任务 remain 具有挑战性。<details>
<summary>Abstract</summary>
During a conversation, our brain is responsible for combining information obtained from multiple senses in order to improve our ability to understand the message we are perceiving. Different studies have shown the importance of presenting visual information in these situations. Nevertheless, lipreading is a complex task whose objective is to interpret speech when audio is not available. By dispensing with a sense as crucial as hearing, it will be necessary to be aware of the challenge that this lack presents. In this paper, we propose an analysis of different speech visual features with the intention of identifying which of them is the best approach to capture the nature of lip movements for natural Spanish and, in this way, dealing with the automatic visual speech recognition task. In order to estimate our system, we present an audiovisual corpus compiled from a subset of the RTVE database, which has been used in the Albayz\'in evaluations. We employ a traditional system based on Hidden Markov Models with Gaussian Mixture Models. Results show that, although the task is difficult, in restricted conditions we obtain recognition results which determine that using eigenlips in combination with deep features is the best visual approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="LIP-RTVE-An-Audiovisual-Database-for-Continuous-Spanish-in-the-Wild"><a href="#LIP-RTVE-An-Audiovisual-Database-for-Continuous-Spanish-in-the-Wild" class="headerlink" title="LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild"></a>LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12457">http://arxiv.org/abs/2311.12457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/david-gimeno/lip-rtve">https://github.com/david-gimeno/lip-rtve</a></li>
<li>paper_authors: David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos</li>
<li>for: 这篇论文主要是为了提高自动语音识别系统的稳定性和准确性，通过结合音频和视觉信息。</li>
<li>methods: 这篇论文使用了Hidden Markov Models（隐马尔可夫模型），一种传统的Speech Technologies中广泛使用的方法。</li>
<li>results: 这篇论文在无法定的自然 español语言中提供了13小时的数据，并报告了基线结果，包括Speaker-dependent和Speaker-independent两种场景。<details>
<summary>Abstract</summary>
Speech is considered as a multi-modal process where hearing and vision are two fundamentals pillars. In fact, several studies have demonstrated that the robustness of Automatic Speech Recognition systems can be improved when audio and visual cues are combined to represent the nature of speech. In addition, Visual Speech Recognition, an open research problem whose purpose is to interpret speech by reading the lips of the speaker, has been a focus of interest in the last decades. Nevertheless, in order to estimate these systems in the currently Deep Learning era, large-scale databases are required. On the other hand, while most of these databases are dedicated to English, other languages lack sufficient resources. Thus, this paper presents a semi-automatically annotated audiovisual database to deal with unconstrained natural Spanish, providing 13 hours of data extracted from Spanish television. Furthermore, baseline results for both speaker-dependent and speaker-independent scenarios are reported using Hidden Markov Models, a traditional paradigm that has been widely used in the field of Speech Technologies.
</details>
<details>
<summary>摘要</summary>
文本被视为多模态过程中的一个核心，听见和视觉是两个基础柱子。实际上，许多研究表明，将音频和视觉提示结合起来可以提高自动语音识别系统的可靠性。此外，视觉语音识别，一个已经吸引了多年研究的问题，目标是通过读取说话人的唇语来理解说话。然而，在当前的深度学习时代，大规模数据库是必需的。然而，大多数这些数据库专注于英语，其他语言缺乏充足的资源。因此，本文介绍了一个半自动地标注的 audiovisual 数据库，用于处理无结构的自然西班牙语，提供了 13 小时的数据，从西班牙电视中提取。此外，基线结果在两个场景下报告了：一个是受束的场景，另一个是无束的场景，使用传统的隐马kov 模型。
</details></li>
</ul>
<hr>
<h2 id="Visual-Analytics-for-Generative-Transformer-Models"><a href="#Visual-Analytics-for-Generative-Transformer-Models" class="headerlink" title="Visual Analytics for Generative Transformer Models"></a>Visual Analytics for Generative Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12418">http://arxiv.org/abs/2311.12418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raymond Li, Ruixin Yang, Wen Xiao, Ahmed AbuRaed, Gabriel Murray, Giuseppe Carenini</li>
<li>for: 本研究旨在支持分析转换器基于模型的可读性。</li>
<li>methods: 我们提出了一种新的可见分析框架，用于支持转换器基于模型的分析。与之前的研究主要关注encoder模型的分析而言，我们的框架是对转换器基于encoder-decoder模型和decoder模型的分析进行了一种首先的分析。因此，我们提供了一个直观的概述，让用户可以通过交互式视觉化来探索不同方面的模型。</li>
<li>results: 我们通过三个实际的NL表示问题进行了详细的案例研究，以证明我们的框架的可行性和实用性。<details>
<summary>Abstract</summary>
While transformer-based models have achieved state-of-the-art results in a variety of classification and generation tasks, their black-box nature makes them challenging for interpretability. In this work, we present a novel visual analytical framework to support the analysis of transformer-based generative networks. In contrast to previous work, which has mainly focused on encoder-based models, our framework is one of the first dedicated to supporting the analysis of transformer-based encoder-decoder models and decoder-only models for generative and classification tasks. Hence, we offer an intuitive overview that allows the user to explore different facets of the model through interactive visualization. To demonstrate the feasibility and usefulness of our framework, we present three detailed case studies based on real-world NLP research problems.
</details>
<details>
<summary>摘要</summary>
While transformer-based models have achieved state-of-the-art results in a variety of classification and generation tasks, their black-box nature makes them challenging for interpretability. In this work, we present a novel visual analytical framework to support the analysis of transformer-based generative networks. In contrast to previous work, which has mainly focused on encoder-based models, our framework is one of the first dedicated to supporting the analysis of transformer-based encoder-decoder models and decoder-only models for generative and classification tasks. Hence, we offer an intuitive overview that allows the user to explore different facets of the model through interactive visualization. To demonstrate the feasibility and usefulness of our framework, we present three detailed case studies based on real-world NLP research problems.Here's the translation in Traditional Chinese:而 tranformer 型模型在多种标签和生成任务中则 achieved state-of-the-art 结果，但它们的黑盒性质使得它们难以 interpretability。在这个工作中，我们提出了一个新的可视分析框架，用于支持 transformer 型生成网络的分析。与前一些工作不同，我们的框架主要针对 encoder-based 模型，并且是第一个专门针对 transformer 型 encoder-decoder 模型和 decoder-only 模型的生成和标签任务。因此，我们提供了一个直观的概述，让用户可以通过互动式可视化来探索不同的模型方面。为了证明我们的框架的可行性和有用性，我们在三个实际的 NLP 研究问题上进行了详细的案例研究。
</details></li>
</ul>
<hr>
<h2 id="IndoRobusta-Towards-Robustness-Against-Diverse-Code-Mixed-Indonesian-Local-Languages"><a href="#IndoRobusta-Towards-Robustness-Against-Diverse-Code-Mixed-Indonesian-Local-Languages" class="headerlink" title="IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian Local Languages"></a>IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian Local Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12405">http://arxiv.org/abs/2311.12405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Genta Indra Winata, Pascale Fung, Ayu Purwarianti</li>
<li>for: 本研究旨在探讨印尼语言混合现象，尤其是英语、SUNDA、JAVA和马来语与印尼语混合的现象。</li>
<li>methods: 本研究使用四种嵌入语言（英语、SUNDA、JAVA和马来语）与印尼语混合，并引入indoRobusta框架来评估和改进代码混合 robustness。</li>
<li>results: 分析结果显示，预训练词汇偏见对印尼英语混合处理能力产生影响，即使其他本地语言的语言多样性较高。<details>
<summary>Abstract</summary>
Significant progress has been made on Indonesian NLP. Nevertheless, exploration of the code-mixing phenomenon in Indonesian is limited, despite many languages being frequently mixed with Indonesian in daily conversation. In this work, we explore code-mixing in Indonesian with four embedded languages, i.e., English, Sundanese, Javanese, and Malay; and introduce IndoRobusta, a framework to evaluate and improve the code-mixing robustness. Our analysis shows that the pre-training corpus bias affects the model's ability to better handle Indonesian-English code-mixing when compared to other local languages, despite having higher language diversity.
</details>
<details>
<summary>摘要</summary>
“印度尼西亚NLP的进步非常 significativ。然而，对印度尼西亚语言杂mix的研究 ainda是有限的，尤其是在日常对话中frequently杂mix多种语言。在这种工作中，我们对印度尼西亚语言杂mix进行了四种嵌入语言（英语、 Sundanese、 Javanese 和 Malay）的研究，并引入了IndoRobusta框架来评估和提高代码杂mix的可靠性。我们的分析表明，预训练 corpus 偏见影响了模型对印度尼西亚英语杂mix的处理能力，尽管有更高的语言多样性。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="InterPrompt-Interpretable-Prompting-for-Interrelated-Interpersonal-Risk-Factors-in-Reddit-Posts"><a href="#InterPrompt-Interpretable-Prompting-for-Interrelated-Interpersonal-Risk-Factors-in-Reddit-Posts" class="headerlink" title="InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk Factors in Reddit Posts"></a>InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk Factors in Reddit Posts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12404">http://arxiv.org/abs/2311.12404</a></li>
<li>repo_url: None</li>
<li>paper_authors: MSVPJ Sathvik, Surjodeep Sarkar, Chandni Saxena, Sunghwan Sohn, Muskan Garg</li>
<li>for: 这paper的目的是旨在预测心理健康问题的早期发现，通过人工智能模型进行自动识别和推荐。</li>
<li>methods: 这paper使用的方法是使用GPT-3模型进行N-shot学习，并通过微调GPT-3模型来增强语言修改和提高模型的解释能力。</li>
<li>results: 研究结果表明，当使用InterPrompt方法微调GPT-3模型时，可以获得更好的分类和解释生成结果，而且模型的解释能力得到显著提高。<details>
<summary>Abstract</summary>
Mental health professionals and clinicians have observed the upsurge of mental disorders due to Interpersonal Risk Factors (IRFs). To simulate the human-in-the-loop triaging scenario for early detection of mental health disorders, we recognized textual indications to ascertain these IRFs : Thwarted Belongingness (TBe) and Perceived Burdensomeness (PBu) within personal narratives. In light of this, we use N-shot learning with GPT-3 model on the IRF dataset, and underscored the importance of fine-tuning GPT-3 model to incorporate the context-specific sensitivity and the interconnectedness of textual cues that represent both IRFs.   In this paper, we introduce an Interpretable Prompting (InterPrompt)} method to boost the attention mechanism by fine-tuning the GPT-3 model. This allows a more sophisticated level of language modification by adjusting the pre-trained weights. Our model learns to detect usual patterns and underlying connections across both the IRFs, which leads to better system-level explainability and trustworthiness. The results of our research demonstrate that all four variants of GPT-3 model, when fine-tuned with InterPrompt, perform considerably better as compared to the baseline methods, both in terms of classification and explanation generation.
</details>
<details>
<summary>摘要</summary>
精神医生和临床专业人员已经观察到因人际风险因素（IRF）而导致的精神疾病的增加。为了模拟人类在循环中排查精神疾病的情况，我们在个人故事中找到了文本指示，以确定IRFs：被排挤的belongingness（TBe）和感受到的压力（PBu）。在这种情况下，我们使用N-shot学习的GPT-3模型，并强调了GPT-3模型的Context-specific敏感性和文本提示之间的相互关联性。在这篇论文中，我们介绍了一种可解释的提示方法（InterPrompt），用于提高GPT-3模型的注意力机制。这种方法通过修改预训练的权重来实现更加复杂的语言修改，从而使模型能够更好地检测文本中的常见模式和下面的连接。我们的研究结果表明，对GPT-3模型进行InterPrompt的 fine-tuning，可以使其在分类和解释生成方面表现更好，并且提高系统级别的解释可读性和可信度。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Graph-Meets-Large-Language-Model-Progress-and-Future-Directions"><a href="#A-Survey-of-Graph-Meets-Large-Language-Model-Progress-and-Future-Directions" class="headerlink" title="A Survey of Graph Meets Large Language Model: Progress and Future Directions"></a>A Survey of Graph Meets Large Language Model: Progress and Future Directions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12399">http://arxiv.org/abs/2311.12399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, Jeffrey Xu Yu</li>
<li>for: This paper is written for researchers and practitioners working in the field of graph-related tasks, particularly those interested in leveraging Large Language Models (LLMs) for improving the performance of graph-based methods.</li>
<li>methods: The paper surveys and analyzes existing methods that integrate LLMs with graphs, and proposes a new taxonomy to categorize these methods based on the role played by LLMs. The paper also provides a systematic review of representative methods along the three categories of the taxonomy.</li>
<li>results: The paper discusses the remaining limitations of existing studies and highlights promising avenues for future research in the field of LLMs in graph-related tasks. The paper also provides a comprehensive overview of the state-of-the-art performance of LLMs in various graph-related tasks.Here are the three key information points in Simplified Chinese text:</li>
<li>for: 这篇论文是为研究者和实践者工作在图相关任务领域，特别是感兴趣利用大语言模型（LLMs）来改进图基的方法的人所写的。</li>
<li>methods: 这篇论文对现有的图与LLMs的方法进行了抽象和分析，并提出了一个新的分类方法，将现有的方法分为三个类别，根据LLMs在图相关任务中的角色。</li>
<li>results: 这篇论文讨论了现有研究的限制，并指出了未来研究的可能性，提供了图相关任务中LMMs的状态艺术表现。<details>
<summary>Abstract</summary>
Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.
</details>
<details>
<summary>摘要</summary>
GRAPH 在实际应用中表示和分析复杂关系的重要角色，如引用网络、社交网络和生物数据。最近，大型自然语言模型（LLMs），在不同领域取得了很大成功，也在图关联任务中被利用，以超越传统的图神经网络（GNNs）基于方法并达到状态之最好性。在这项调查中，我们首先提供了一个完整的评论和分析现有的方法，这些方法是根据 LLMS 在图关联任务中扮演的角色（即增强器、预测器和对齐组件）进行分类。然后，我们系统地报道了代表性方法的评论，并将其分类到三个类别中。最后，我们讨论了现有研究的剩下的限制，并 highlighted 未来研究的可能性。相关论文将在：https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks 中进行系统性的汇总和更新。
</details></li>
</ul>
<hr>
<h2 id="Problems-of-Non-equivalent-Words-in-Technical-Translation"><a href="#Problems-of-Non-equivalent-Words-in-Technical-Translation" class="headerlink" title="Problems of Non-equivalent Words in Technical Translation"></a>Problems of Non-equivalent Words in Technical Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12395">http://arxiv.org/abs/2311.12395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Ibrahim Qani</li>
<li>for: 这个研究论文的主要目的是解决英语和俄语之间的非等效词语问题，以便更好地理解这两种语言之间的连接。</li>
<li>methods: 这篇论文使用了不同的方法和规则来将源语言中的非等效词语翻译到目标语言中，以解决这些词语在不同语言中的差异。</li>
<li>results: 这篇论文的结果表明，通过使用不同的方法和规则，可以减少英语和俄语之间的非等效词语问题，并提高这两种语言之间的连接和理解。<details>
<summary>Abstract</summary>
Translating words which do not have equivalent in target language is not easy and finding proper equivalent of those words are very important to render correctly and understandably, the article defines some thoughts and ideas of scientists on the common problems of non-equivalent words from English to Russian language and includes English and Russian examples and ideas of certain scientist. The English language is worldwide spoken and there are 1.35 billion English speakers and over 258 million Russian speakers according to the 2021s statistics. Inevitably, these billions of speakers around the world have connection and they may have deal in different criteria. In order to understand one another they need to have a pure and fully-understood language. These pure languages understanding directly relates to translation knowledge where linguists and translators need to work and research to eradicate misunderstanding. Misunderstandings mostly appear in non-equivalent words because there are different local and internal words like food, garment, cultural and traditional words and others in every notion. Truly, most of these words do not have equivalent in the target language and these words need to be worked and find their equivalent in the target language to fully understand the both languages. However, some of these non-equivalent words are already professionally rendered to the target language but still there many other words to be rendered. Hence, this research paper includes different ways and rules of rendering non-equivalent words from source language to the target language.
</details>
<details>
<summary>摘要</summary>
英语是全球最广泛使用的语言之一，有135亿英语母语者和258万俄语母语者，根据2021年统计。这些亿万speaker在世界各地有联系，可能有不同的标准和规范。为了理解彼此，他们需要有一种纯正的语言理解。这种纯正语言理解直接与翻译知识相关， linguisits和翻译员需要努力工作和研究，以消除不同解释。非等效词是翻译中最大的障碍，因为每种语言都有不同的本地和内部词汇，如食物、服装、文化和传统词汇等。大多数这些词没有等效的目标语言词汇，需要 linguisits和翻译员一直在工作，以找到目标语言中的等效词汇。然而，一些非等效词已经在目标语言中得到了职业的翻译，但还有很多其他的词汇需要翻译。因此，这篇研究论文探讨了不同的翻译方法和规则，以帮助 linguisits和翻译员更好地翻译非等效词。
</details></li>
</ul>
<hr>
<h2 id="The-Obscure-Limitation-of-Modular-Multilingual-Language-Models"><a href="#The-Obscure-Limitation-of-Modular-Multilingual-Language-Models" class="headerlink" title="The Obscure Limitation of Modular Multilingual Language Models"></a>The Obscure Limitation of Modular Multilingual Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12375">http://arxiv.org/abs/2311.12375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Ayu Purwarianti</li>
<li>for: 这篇论文探讨了模块化多语言模型（MLM）在多语言推理场景中的局限性，特别是在未知语言情况下。</li>
<li>methods: 该论文使用了语言标识（LID）模块，以评估模块化MLM在真实多语言场景中的性能。</li>
<li>results: 研究发现，在加入LID模块后，模块化MLM在多语言推理场景中的性能受到了改善。<details>
<summary>Abstract</summary>
We expose the limitation of modular multilingual language models (MLMs) in multilingual inference scenarios with unknown languages. Existing evaluations of modular MLMs exclude the involvement of language identification (LID) modules, which obscures the performance of real-case multilingual scenarios of modular MLMs. In this work, we showcase the effect of adding LID on the multilingual evaluation of modular MLMs and provide discussions for closing the performance gap of caused by the pipelined approach of LID and modular MLMs.
</details>
<details>
<summary>摘要</summary>
我团队揭示了模块化多语言模型（MLM）在多语言推理场景中的局限性。现有的评估方法中排除了语言标识（LID）模块的参与，这使得真实的多语言场景中模块化MLM的性能被遮盖。在这项工作中，我们表明了将LID纳入多语言评估中对模块化MLM的影响，并提供了关闭性能差距的讨论。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Turing-A-Comparative-Analysis-of-Approaches-for-Detecting-Machine-Generated-Text"><a href="#Beyond-Turing-A-Comparative-Analysis-of-Approaches-for-Detecting-Machine-Generated-Text" class="headerlink" title="Beyond Turing: A Comparative Analysis of Approaches for Detecting Machine-Generated Text"></a>Beyond Turing: A Comparative Analysis of Approaches for Detecting Machine-Generated Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12373">http://arxiv.org/abs/2311.12373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Farid Adilazuarda, Nikolaos Nektarios Arkoulis, Oleksii Chumakov</li>
<li>for: 本研究旨在评估三种方法用于人工智能文本与人类文本之间的区分，以提高自然语言处理领域中的机器人混淆检测能力。</li>
<li>methods: 本研究使用传统的浅学习、语言模型精度调整和多语言模型调整三种方法来处理机器生成的文本。</li>
<li>results: 研究发现这三种方法在各种机器生成文本上的表现有显著差异，表明这一领域仍需进一步发展。<details>
<summary>Abstract</summary>
Significant progress has been made on text generation by pre-trained language models (PLMs), yet distinguishing between human and machine-generated text poses an escalating challenge. This paper offers an in-depth evaluation of three distinct methods used to address this task: traditional shallow learning, Language Model (LM) fine-tuning, and Multilingual Model fine-tuning. These approaches are rigorously tested on a wide range of machine-generated texts, providing a benchmark of their competence in distinguishing between human-authored and machine-authored linguistic constructs. The results reveal considerable differences in performance across methods, thus emphasizing the continued need for advancement in this crucial area of NLP. This study offers valuable insights and paves the way for future research aimed at creating robust and highly discriminative models.
</details>
<details>
<summary>摘要</summary>
“文本生成领域内，已经取得了重要进展，但是分辨人工和机器生成的文本却成为了一个增长的挑战。这篇论文对三种不同的方法进行了深入的评估：传统的浅学习、语言模型（LM）练习和多语言模型练习。这些方法在各种机器生成文本上进行了严格的测试，为分辨人工和机器生成语言结构的能力提供了标准。结果表明这些方法之间存在显著的差异，因此高亮了需要进一步改进的这一重要领域。这篇研究提供了有价值的洞察和指导，为未来的研究提供了路径。”
</details></li>
</ul>
<hr>
<h2 id="Utilizing-Language-Models-for-Tour-Itinerary-Recommendation"><a href="#Utilizing-Language-Models-for-Tour-Itinerary-Recommendation" class="headerlink" title="Utilizing Language Models for Tour Itinerary Recommendation"></a>Utilizing Language Models for Tour Itinerary Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12355">http://arxiv.org/abs/2311.12355</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ngai Lam Ho, Kwan Hui Lim</li>
<li>for: 这篇论文旨在提出一种基于语言模型的旅游计划和建议方法，用于推荐个性化的旅游点 Interest (POI) 和根据各种约束制定一个合理的旅游计划。</li>
<li>methods: 本文使用了词嵌入技术 Word2Vec 和 GloVe 来学习 POI 嵌入，以及基于 transformer 技术的 BERT 来生成旅游计划。</li>
<li>results: 本文的实验结果表明，使用语言模型可以提高旅游计划的个性化程度和约束满足度，并且可以减少计划时间。<details>
<summary>Abstract</summary>
Tour itinerary recommendation involves planning a sequence of relevant Point-of-Interest (POIs), which combines challenges from the fields of both Operations Research (OR) and Recommendation Systems (RS). As an OR problem, there is the need to maximize a certain utility (e.g., popularity of POIs in the tour) while adhering to some constraints (e.g., maximum time for the tour). As a RS problem, it is heavily related to problem or filtering or ranking a subset of POIs that are relevant to a user and recommending it as part of an itinerary. In this paper, we explore the use of language models for the task of tour itinerary recommendation and planning. This task has the unique requirement of recommending personalized POIs relevant to users and planning these POIs as an itinerary that satisfies various constraints. We discuss some approaches in this area, such as using word embedding techniques like Word2Vec and GloVe for learning POI embeddings and transformer-based techniques like BERT for generating   itineraries.
</details>
<details>
<summary>摘要</summary>
旅行计划建议涉及到规划一系列相关的点索引（POI），这种问题同时具有操作研究（OR）和推荐系统（RS）两个领域的挑战。作为OR问题，需要最大化一定的用户喜好（例如旅游点的受欢迎程度），同时遵循一些约束（例如旅行时间的上限）。作为RS问题，它与过滤或排序POI相关的用户有着密切的关系，并且需要为用户推荐个性化的旅行计划。在这篇论文中，我们探讨使用语言模型来解决旅行计划建议和规划的问题。这种问题具有个性化推荐用户相关的POI，并将其组织成满足多种约束的旅行计划。我们介绍了一些在这个领域的方法，包括使用word embedding技术如Word2Vec和GloVe来学习POI嵌入，以及使用 transformer-based技术如BERT来生成旅行计划。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Transformer-Architecture-in-Long-Context-Large-Language-Models-A-Comprehensive-Survey"><a href="#Advancing-Transformer-Architecture-in-Long-Context-Large-Language-Models-A-Comprehensive-Survey" class="headerlink" title="Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey"></a>Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12351">http://arxiv.org/abs/2311.12351</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/strivin0311/long-llms-learning">https://github.com/strivin0311/long-llms-learning</a></li>
<li>paper_authors: Yunpeng Huang, Jingwei Xu, Zixu Jiang, Junyu Lai, Zenan Li, Yuan Yao, Taolue Chen, Lijuan Yang, Zhou Xin, Xiaoxing Ma</li>
<li>for: 本研究主要是为了提高Transformer基于模型在长文本上的能力，以便在实际场景中更有效地应用。</li>
<li>methods: 本文提出了一种全面的分类方法，以便浏览Transformer模型在不同阶段的改进，包括预训练和推理阶段。</li>
<li>results: 本文提供了一些评估需求，包括数据集、评价指标和基准模型，以及一些优化工具包，以提高LLMs的效率和可靠性在不同阶段。<details>
<summary>Abstract</summary>
With the bomb ignited by ChatGPT, Transformer-based Large Language Models (LLMs) have paved a revolutionary path toward Artificial General Intelligence (AGI) and have been applied in diverse areas as knowledge bases, human interfaces, and dynamic agents. However, a prevailing limitation exists: many current LLMs, constrained by resources, are primarily pre-trained on shorter texts, rendering them less effective for longer-context prompts, commonly encountered in real-world settings. In this paper, we present a comprehensive survey focusing on the advancement of model architecture in Transformer-based LLMs to optimize long-context capabilities across all stages from pre-training to inference. We firstly delineate and analyze the problems of handling long-context input and output with the current Transformer-based models. Then, we mainly offer a holistic taxonomy to navigate the landscape of Transformer upgrades on architecture to solve these problems. Afterward, we provide the investigation on wildly used evaluation necessities tailored for long-context LLMs, including datasets, metrics, and baseline models, as well as some amazing optimization toolkits like libraries, systems, and compilers to augment LLMs' efficiency and efficacy across different stages. Finally, we further discuss the predominant challenges and potential avenues for future research in this domain. Additionally, we have established a repository where we curate relevant literature with real-time updates at https://github.com/Strivin0311/long-llms-learning.
</details>
<details>
<summary>摘要</summary>
With the bomb ignited by ChatGPT, Transformer-based Large Language Models (LLMs) have paved a revolutionary path toward Artificial General Intelligence (AGI) and have been applied in diverse areas as knowledge bases, human interfaces, and dynamic agents. However, a prevailing limitation exists: many current LLMs, constrained by resources, are primarily pre-trained on shorter texts, rendering them less effective for longer-context prompts, commonly encountered in real-world settings. In this paper, we present a comprehensive survey focusing on the advancement of model architecture in Transformer-based LLMs to optimize long-context capabilities across all stages from pre-training to inference.Firstly, we delineate and analyze the problems of handling long-context input and output with the current Transformer-based models. Then, we mainly offer a holistic taxonomy to navigate the landscape of Transformer upgrades on architecture to solve these problems. Afterward, we provide the investigation on wildly used evaluation necessities tailored for long-context LLMs, including datasets, metrics, and baseline models, as well as some amazing optimization toolkits like libraries, systems, and compilers to augment LLMs' efficiency and efficacy across different stages. Finally, we further discuss the predominant challenges and potential avenues for future research in this domain. Additionally, we have established a repository where we curate relevant literature with real-time updates at <https://github.com/Strivin0311/long-llms-learning>.
</details></li>
</ul>
<hr>
<h2 id="Modeling-Political-Orientation-of-Social-Media-Posts-An-Extended-Analysis"><a href="#Modeling-Political-Orientation-of-Social-Media-Posts-An-Extended-Analysis" class="headerlink" title="Modeling Political Orientation of Social Media Posts: An Extended Analysis"></a>Modeling Political Orientation of Social Media Posts: An Extended Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12323">http://arxiv.org/abs/2311.12323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadia Kamal, Brenner Little, Jade Gullic, Trevor Harms, Kristin Olofsson, Arunkumar Bagavathi</li>
<li>for: 本研究旨在Characterizing political polarization on online social media, specifically in the social media posts themselves.</li>
<li>methods: 本研究使用two heuristic methods to label social media posts, leveraging on news media bias and post content.  comparison with a randomly sampled human-annotated dataset.</li>
<li>results: 研究表明，current machine learning models can exhibit improved performance in predicting political orientation of social media posts, employing both traditional supervised learning and few-shot learning setups.<details>
<summary>Abstract</summary>
Developing machine learning models to characterize political polarization on online social media presents significant challenges. These challenges mainly stem from various factors such as the lack of annotated data, presence of noise in social media datasets, and the sheer volume of data. The common research practice typically examines the biased structure of online user communities for a given topic or qualitatively measuring the impacts of polarized topics on social media. However, there is limited work focusing on analyzing polarization at the ground-level, specifically in the social media posts themselves. Such existing analysis heavily relies on annotated data, which often requires laborious human labeling, offers labels only to specific problems, and lacks the ability to determine the near-future bias state of a social media conversations. Understanding the degree of political orientation conveyed in social media posts is crucial for quantifying the bias of online user communities and investigating the spread of polarized content. In this work, we first introduce two heuristic methods that leverage on news media bias and post content to label social media posts. Next, we compare the efficacy and quality of heuristically labeled dataset with a randomly sampled human-annotated dataset. Additionally, we demonstrate that current machine learning models can exhibit improved performance in predicting political orientation of social media posts, employing both traditional supervised learning and few-shot learning setups. We conduct experiments using the proposed heuristic methods and machine learning approaches to predict the political orientation of posts collected from two social media forums with diverse political ideologies: Gab and Twitter.
</details>
<details>
<summary>摘要</summary>
开发机器学习模型来 caracterize 在社交媒体上的政治偏见存在 significativ challenges。这些挑战主要来自于各种因素，如社交媒体数据集中的噪音、缺乏标注数据以及数据量的庞大。现有的研究通常是通过分析在线用户社区的偏见结构来研究特定主题的偏见，或者通过衡量偏见话题在社交媒体上的影响来衡量偏见的程度。然而，有限的研究将注意力集中在社交媒体帖子本身的偏见分析上，特别是在帖子中的政治偏见。现有的分析方法通常需要人工标注，且只能对特定问题提供标签，而且无法在社交媒体对话中确定未来偏见状态。了解社交媒体帖子中政治方向的程度是Quantifying the bias of online user communities和推广偏见内容的调查中非常重要的一步。在这种情况下，我们首先介绍了两种可靠的方法，即通过新闻媒体偏见和帖子内容来标注社交媒体帖子。然后，我们比较了这些方法与随机抽样的人工标注数据的效果和质量。此外，我们还示出了现有的机器学习模型可以通过使用传统的超vision学习和几 shot learning的方式提高预测社交媒体帖子的政治方向性表现。我们在两个社交媒体平台上（Gab和Twitter）进行了实验，以验证我们的方法和模型。
</details></li>
</ul>
<hr>
<h2 id="AcademicGPT-Empowering-Academic-Research"><a href="#AcademicGPT-Empowering-Academic-Research" class="headerlink" title="AcademicGPT: Empowering Academic Research"></a>AcademicGPT: Empowering Academic Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12315">http://arxiv.org/abs/2311.12315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shufa Wei, Xiaolong Xu, Xianbiao Qi, Xi Yin, Jun Xia, Jingyi Ren, Peijun Tang, Yuxiang Zhong, Yihao Chen, Xiaoqin Ren, Yuxin Liang, Liankai Huang, Kai Xie, Weikang Gui, Wei Tan, Shuanglong Sun, Yongquan Hu, Qinxian Liu, Nanjin Li, Chihao Dai, Lihua Wang, Xiaohui Liu, Lei Zhang, Yutao Xie</li>
<li>for: 该论文旨在探讨大语言模型（LLMs）在学术研究领域的应用，并提出了一种针对学术研究领域的培训模型——AcademicGPT。</li>
<li>methods: 该论文使用了一种基于LLaMA2-70B的 continual training 模型，并在学术研究领域中进行了培训，主要使用了学术论文、论文集、学术域内容等数据。</li>
<li>results: 该论文通过在多个公共评价指标（MMLU、CEval）和专业学术指标（PubMedQA、SCIEval、ComputerScienceQA）上进行了评估，证明了AcademicGPT在普通知识、中文能力和学术能力等方面具有出色的能力。此外，该论文还推出了一些针对学术领域的应用，如通用学术问答、AI助力论文阅读、论文评审和AI助力标题和摘要生成等。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated exceptional capabilities across various natural language processing tasks. Yet, many of these advanced LLMs are tailored for broad, general-purpose applications. In this technical report, we introduce AcademicGPT, designed specifically to empower academic research. AcademicGPT is a continual training model derived from LLaMA2-70B. Our training corpus mainly consists of academic papers, thesis, content from some academic domain, high-quality Chinese data and others. While it may not be extensive in data scale, AcademicGPT marks our initial venture into a domain-specific GPT tailored for research area. We evaluate AcademicGPT on several established public benchmarks such as MMLU and CEval, as well as on some specialized academic benchmarks like PubMedQA, SCIEval, and our newly-created ComputerScienceQA, to demonstrate its ability from general knowledge ability, to Chinese ability, and to academic ability. Building upon AcademicGPT's foundation model, we also developed several applications catered to the academic area, including General Academic Question Answering, AI-assisted Paper Reading, Paper Review, and AI-assisted Title and Abstract Generation.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经表现出色在不同的自然语言处理任务中。然而，许多这些高级LLM都是为广泛的通用应用设计的。在这份技术报告中，我们介绍AcademicGPT，这是为学术研究而设计的域 especific GPT。AcademicGPT是基于LLaMA2-70B的连续训练模型。我们的训练集主要由学术论文、硬件、学术领域内容、高质量的中文数据和其他组成。虽然数据规模不够广泛，但AcademicGPT标志着我们在域特定GPT领域的首次尝试。我们使用了多个公共的benchmark测试AcademicGPT的能力，包括MMLU和CEval，以及一些专门的学术benchmark，如PubMedQA、SCIEval和我们新创的ComputerScienceQA，以示其在通用知识、中文能力和学术能力方面的能力。基于AcademicGPT的基础模型，我们还开发了一些针对学术领域的应用程序，包括通用学术问答、AI助手读硬件、论文评审和AI助手标题和摘要生成。
</details></li>
</ul>
<hr>
<h2 id="Enabling-On-Device-Large-Language-Model-Personalization-with-Self-Supervised-Data-Selection-and-Synthesis"><a href="#Enabling-On-Device-Large-Language-Model-Personalization-with-Self-Supervised-Data-Selection-and-Synthesis" class="headerlink" title="Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis"></a>Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12275">http://arxiv.org/abs/2311.12275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiyang Qin, Jun Xia, Zhenge Jia, Meng Jiang, Ahmed Abbasi, Peipei Zhou, Jingtong Hu, Yiyu Shi</li>
<li>for: 这个论文的目的是提出一种基于Edge设备的自然语言处理（NLP）模型个性化方法，以便在用户生成的对话数据上进行实时回答生成。</li>
<li>methods: 该方法使用了自然语言生成（NLG）技术，通过在线选择和存储最有代表性的数据，以及使用多个semantically相似的问题文本和预期答案对进行自我监督学习。</li>
<li>results:  experiments show that the proposed framework achieves the best user-specific content-generating capability (accuracy) and fine-tuning speed (performance) compared with vanilla baselines.<details>
<summary>Abstract</summary>
After a large language model (LLM) is deployed on edge devices, it is desirable for these devices to learn from user-generated conversation data to generate user-specific and personalized responses in real-time. However, user-generated data usually contains sensitive and private information, and uploading such data to the cloud for annotation is not preferred if not prohibited. While it is possible to obtain annotation locally by directly asking users to provide preferred responses, such annotations have to be sparse to not affect user experience. In addition, the storage of edge devices is usually too limited to enable large-scale fine-tuning with full user-generated data. It remains an open question how to enable on-device LLM personalization, considering sparse annotation and limited on-device storage. In this paper, we propose a novel framework to select and store the most representative data online in a self-supervised way. Such data has a small memory footprint and allows infrequent requests of user annotations for further fine-tuning. To enhance fine-tuning quality, multiple semantically similar pairs of question texts and expected responses are generated using the LLM. Our experiments show that the proposed framework achieves the best user-specific content-generating capability (accuracy) and fine-tuning speed (performance) compared with vanilla baselines. To the best of our knowledge, this is the very first on-device LLM personalization framework.
</details>
<details>
<summary>摘要</summary>
After a large language model (LLM) is deployed on edge devices, it is desirable for these devices to learn from user-generated conversation data to generate user-specific and personalized responses in real-time. However, user-generated data usually contains sensitive and private information, and uploading such data to the cloud for annotation is not preferred if not prohibited. While it is possible to obtain annotation locally by directly asking users to provide preferred responses, such annotations have to be sparse to not affect user experience. In addition, the storage of edge devices is usually too limited to enable large-scale fine-tuning with full user-generated data. It remains an open question how to enable on-device LLM personalization, considering sparse annotation and limited on-device storage. In this paper, we propose a novel framework to select and store the most representative data online in a self-supervised way. Such data has a small memory footprint and allows infrequent requests of user annotations for further fine-tuning. To enhance fine-tuning quality, multiple semantically similar pairs of question texts and expected responses are generated using the LLM. Our experiments show that the proposed framework achieves the best user-specific content-generating capability (准确率) and fine-tuning speed (性能) compared with vanilla baselines. To the best of our knowledge, this is the very first on-device LLM personalization framework.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/cs.CL_2023_11_21/" data-id="clpxp6c0300fnee88am8y1q3t" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/cs.LG_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T10:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/cs.LG_2023_11_21/">cs.LG - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Mechanistically-analyzing-the-effects-of-fine-tuning-on-procedurally-defined-tasks"><a href="#Mechanistically-analyzing-the-effects-of-fine-tuning-on-procedurally-defined-tasks" class="headerlink" title="Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"></a>Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12786">http://arxiv.org/abs/2311.12786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samyak Jain, Robert Kirk, Ekdeep Singh Lubana, Robert P. Dick, Hidenori Tanaka, Edward Grefenstette, Tim Rocktäschel, David Scott Krueger</li>
<li>for: 本研究旨在解释 fine-tuning 如何影响模型内置的能力。</li>
<li>methods: 研究者使用 synthetic 和控制的设置，并使用机制可读性工具（例如网络剔除和探针）来理解模型内置的能力是如何变化的。</li>
<li>results: 研究结果表明：(i) fine-tuning 通常不会改变模型内置的能力；(ii) 模型通常会学习一个封装（即 ‘wrapper’），这使得模型看起来已经改变了能力；(iii) 继续 fine-tuning 模型在具有相关隐藏能力的任务上，可以快速地“复活”这些能力，即模型会在只需几个梯度步骤后开始再使用这些能力。这表明，实际上，许多 fine-tuning 实践可能会意外地移除模型的安全封装。<details>
<summary>Abstract</summary>
Fine-tuning large pre-trained models has become the de facto strategy for developing both task-specific and general-purpose machine learning systems, including developing models that are safe to deploy. Despite its clear importance, there has been minimal work that explains how fine-tuning alters the underlying capabilities learned by a model during pretraining: does fine-tuning yield entirely novel capabilities or does it just modulate existing ones? We address this question empirically in synthetic, controlled settings where we can use mechanistic interpretability tools (e.g., network pruning and probing) to understand how the model's underlying capabilities are changing. We perform an extensive analysis of the effects of fine-tuning in these settings, and show that: (i) fine-tuning rarely alters the underlying model capabilities; (ii) a minimal transformation, which we call a 'wrapper', is typically learned on top of the underlying model capabilities, creating the illusion that they have been modified; and (iii) further fine-tuning on a task where such hidden capabilities are relevant leads to sample-efficient 'revival' of the capability, i.e., the model begins reusing these capability after only a few gradient steps. This indicates that practitioners can unintentionally remove a model's safety wrapper merely by fine-tuning it on a, e.g., superficially unrelated, downstream task. We additionally perform analysis on language models trained on the TinyStories dataset to support our claims in a more realistic setup.
</details>
<details>
<summary>摘要</summary>
现在，训练大型预训模型的细化已成为开发任务特定和通用机器学习系统的默认策略。尽管其重要性很明显，但是有很少的研究解释了如何细化改变模型在预训时学习的基本能力：细化是否产生全新的能力，还是只是调整现有的能力呢？我们在制定的、控制的 synthetic 环境中使用机制可读性工具（例如网络剔除和探测）来解释模型的基本能力是如何变化。我们对细化的影响进行了广泛的分析，发现：(i) 细化往往不改变模型的基本能力；(ii) 模型通常learns一个 ' wrapper'，这个 wrapper 是基于模型的基本能力，创造了 modify 模型的illusion；(iii) 在需要这些隐藏能力的任务上进一步细化，则模型可以迅速地 reuse 这些能力，即使只有几个梯度步。这表明，实际上，训练模型的过程可能会意外地删除模型的安全覆盖物。我们还对基于 TinyStories 数据集训练的语言模型进行了更加实际的分析，以支持我们的声明。
</details></li>
</ul>
<hr>
<h2 id="Optimality-in-Mean-Estimation-Beyond-Worst-Case-Beyond-Sub-Gaussian-and-Beyond-1-α-Moments"><a href="#Optimality-in-Mean-Estimation-Beyond-Worst-Case-Beyond-Sub-Gaussian-and-Beyond-1-α-Moments" class="headerlink" title="Optimality in Mean Estimation: Beyond Worst-Case, Beyond Sub-Gaussian, and Beyond $1+α$ Moments"></a>Optimality in Mean Estimation: Beyond Worst-Case, Beyond Sub-Gaussian, and Beyond $1+α$ Moments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12784">http://arxiv.org/abs/2311.12784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Trung Dang, Jasper C. H. Lee, Maoyuan Song, Paul Valiant</li>
<li>for: 这个论文的目的是研究如何使用算法提高基本统计问题中的均值估计，包括均值估计在 $\mathbb{R}$ 中的最优性。</li>
<li>methods: 这篇论文使用了 median-of-means 算法和 sub-Gaussian constant 来研究均值估计问题。</li>
<li>results: 研究发现，对于任何分布 $p$ ，存在一个分布 $q$，使得 $q$ 的均值很 distant 于 $p$ 的均值，但是 $p$ 和 $q$ 在高概率下是不可分辨的，并且 $q$ 保持了 $p$ 的 moment 在常量倍数上。这导致了无论是任何分布都不可以通过任何可理解的方式实现更好的均值估计。<details>
<summary>Abstract</summary>
There is growing interest in improving our algorithmic understanding of fundamental statistical problems such as mean estimation, driven by the goal of understanding the limits of what we can extract from valuable data. The state of the art results for mean estimation in $\mathbb{R}$ are 1) the optimal sub-Gaussian mean estimator by [LV22], with the tight sub-Gaussian constant for all distributions with finite but unknown variance, and 2) the analysis of the median-of-means algorithm by [BCL13] and a lower bound by [DLLO16], characterizing the big-O optimal errors for distributions for which only a $1+\alpha$ moment exists for $\alpha \in (0,1)$. Both results, however, are optimal only in the worst case. We initiate the fine-grained study of the mean estimation problem: Can algorithms leverage useful features of the input distribution to beat the sub-Gaussian rate, without explicit knowledge of such features?   We resolve this question with an unexpectedly nuanced answer: "Yes in limited regimes, but in general no". For any distribution $p$ with a finite mean, we construct a distribution $q$ whose mean is well-separated from $p$'s, yet $p$ and $q$ are not distinguishable with high probability, and $q$ further preserves $p$'s moments up to constants. The main consequence is that no reasonable estimator can asymptotically achieve better than the sub-Gaussian error rate for any distribution, matching the worst-case result of [LV22]. More generally, we introduce a new definitional framework to analyze the fine-grained optimality of algorithms, which we call "neighborhood optimality", interpolating between the unattainably strong "instance optimality" and the trivially weak "admissibility" definitions. Applying the new framework, we show that median-of-means is neighborhood optimal, up to constant factors. It is open to find a neighborhood-optimal estimator without constant factor slackness.
</details>
<details>
<summary>摘要</summary>
“对于基本统计问题的算法理解正在不断提高，特别是对于均值估计的研究。这是由于了解有价值的数据中可以提取的最大限制所导致的。现有最佳的结果是LV22提出的最佳半子泊比均值估计器，它在所有有限但未知方差的分布上具有紧密的半子泊比常数。此外，BCL13和DLLO16也提出了分布下的下界和中位均值算法的分析，它们对于具有$1+\alpha$维度的分布进行了big-O最佳的错误分析。但这些结果仅在最坏情况下是最佳的。我们开始了均值估计问题的细部研究：可以算法利用均值估计问题中的有用特征来超过半子泊比率，不需要明确地知道这些特征吗？我们答案是“是，但仅对有限均值的分布”。我们可以建构一个分布$q$，其均值与$p$的均值相差很大，但$p$和$q$在高概率下不可识别，且$q$保留了$p$的维度到常数。这主要结果是：不可能在任何分布下使用合理的估计器，在均值估计问题中超过半子泊比率，匹配LV22的最坏情况结果。更一般地，我们引入了一个新的定义框架，即“邻域最佳”（neighborhood optimality），以分析算法的细部最佳性。我们显示了中位均值算法是邻域最佳，仅对于常数因素有松动。是否可以找到一个不含常数因素的邻域最佳估计器是开问题。”
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Optimise-Wind-Farms-with-Graph-Transformers"><a href="#Learning-to-Optimise-Wind-Farms-with-Graph-Transformers" class="headerlink" title="Learning to Optimise Wind Farms with Graph Transformers"></a>Learning to Optimise Wind Farms with Graph Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12750">http://arxiv.org/abs/2311.12750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyi Li, Arnaud Robert, A. Aldo Faisal, Matthew D. Piggott</li>
<li>for: 提供一种数据驱动的模型，能够对风力发电园的所有风机产生准确的预测，无论风轮的布局、仰角配置或风Condition。</li>
<li>methods: 使用图Transformer模型，将风力发电园编码成完全连接图，并将图表示进行图Transformer处理。</li>
<li>results: 示示了这种模型可以对风力发电园的仰角配置进行优化，使用生物学算法，与工业标准风力发电园仰角配置工具相当准确，只需要一小部分的计算时间。<details>
<summary>Abstract</summary>
This work proposes a novel data-driven model capable of providing accurate predictions for the power generation of all wind turbines in wind farms of arbitrary layout, yaw angle configurations and wind conditions. The proposed model functions by encoding a wind farm into a fully-connected graph and processing the graph representation through a graph transformer. The graph transformer surrogate is shown to generalise well and is able to uncover latent structural patterns within the graph representation of wind farms. It is demonstrated how the resulting surrogate model can be used to optimise yaw angle configurations using genetic algorithms, achieving similar levels of accuracy to industrially-standard wind farm simulation tools while only taking a fraction of the computational cost.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-Graph-Classification-Techniques-Under-Low-Data-Constraints-A-Comprehensive-Study"><a href="#Exploring-Graph-Classification-Techniques-Under-Low-Data-Constraints-A-Comprehensive-Study" class="headerlink" title="Exploring Graph Classification Techniques Under Low Data Constraints: A Comprehensive Study"></a>Exploring Graph Classification Techniques Under Low Data Constraints: A Comprehensive Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12737">http://arxiv.org/abs/2311.12737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kush Kothari, Bhavya Mehta, Reshmika Nambiar, Seema Shrawne</li>
<li>for: 这篇论文主要探讨了最新的图数据增强和几个步骤学习方法。</li>
<li>methods: 论文涵盖了多种图数据增强技术，包括节点和边扰动、图缩放和图生成等方法，以及最新的几个步骤学习技术，如元学习和模型独立元学习。</li>
<li>results: 论文对这些领域进行了深入探讨，并将它们分为rule based approaches和learning based approaches两类。在图增强方面，论文还研究了几个度量学习技术和优化技术来解决图处理问题。<details>
<summary>Abstract</summary>
This survey paper presents a brief overview of recent research on graph data augmentation and few-shot learning. It covers various techniques for graph data augmentation, including node and edge perturbation, graph coarsening, and graph generation, as well as the latest developments in few-shot learning, such as meta-learning and model-agnostic meta-learning. The paper explores these areas in depth and delves into further sub classifications. Rule based approaches and learning based approaches are surveyed under graph augmentation techniques. Few-Shot Learning on graphs is also studied in terms of metric learning techniques and optimization-based techniques. In all, this paper provides an extensive array of techniques that can be employed in solving graph processing problems faced in low-data scenarios.
</details>
<details>
<summary>摘要</summary>
这篇论文提供了图数据增强和少量学习的最新研究的简要概述。它涵盖了图数据增强的多种技术，包括节点和边扰动、图缩放、图生成等，以及最新的少量学习技术，如元学习和模型无关元学习。文章深入探讨这些领域，并进一步划分为规则基于的方法和学习基于的方法。图像学习技术和优化基于的技术也被研究在少量学习中。总的来说，这篇论文提供了丰富的解决图处理问题在低数据情况下的技术。
</details></li>
</ul>
<hr>
<h2 id="Attacks-of-fairness-in-Federated-Learning"><a href="#Attacks-of-fairness-in-Federated-Learning" class="headerlink" title="Attacks of fairness in Federated Learning"></a>Attacks of fairness in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12715">http://arxiv.org/abs/2311.12715</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/slkdfjslkjfd/fl_fairness_attacks">https://github.com/slkdfjslkjfd/fl_fairness_attacks</a></li>
<li>paper_authors: Joseph Rance, Filip Svoboda</li>
<li>for: 这个论文旨在探讨 Federated Learning 中的一种新型攻击，即在控制一些客户端上引入不公正性。</li>
<li>methods: 该论文使用了一种类似于后门攻击的威胁模型，通过控制单个客户端来影响模型的性能分布。</li>
<li>results: 研究发现，这种攻击可以让模型在某些特定的属性上表现不公正，并且只需控制一个客户端即可。这种攻击可以让模型在训练过程中受到不公正的影响，从而导致模型的性能不均匀。<details>
<summary>Abstract</summary>
Federated Learning is an important emerging distributed training paradigm that keeps data private on clients. It is now well understood that by controlling only a small subset of FL clients, it is possible to introduce a backdoor to a federated learning model, in the presence of certain attributes. In this paper, we present a new type of attack that compromises the fairness of the trained model. Fairness is understood to be the attribute-level performance distribution of a trained model. It is particularly salient in domains where, for example, skewed accuracy discrimination between subpopulations could have disastrous consequences. We find that by employing a threat model similar to that of a backdoor attack, an attacker is able to influence the aggregated model to have an unfair performance distribution between any given set of attributes. Furthermore, we find that this attack is possible by controlling only a single client. While combating naturally induced unfairness in FL has previously been discussed in depth, its artificially induced kind has been neglected. We show that defending against attacks on fairness should be a critical consideration in any situation where unfairness in a trained model could benefit a user who participated in its training.
</details>
<details>
<summary>摘要</summary>
federated learning 是一种重要的新趋势的分布式训练方法，它可以保持客户端上的数据私有。现在已经证明，只需控制一小部分的 FL 客户端，就可以引入一个后门到联邦学习模型中，具有某些特征。在这篇论文中，我们介绍了一种新的攻击方法，它会对联邦学习模型的偏见性造成影响。偏见性被理解为模型在不同特征上的性能分布。在一些领域，如果模型对某些子群体的准确率存在偏见性，可能会导致严重的后果。我们发现，通过控制一个客户端，攻击者可以影响集成模型的偏见性，使其在任意特征上的性能分布不均匀。此外，我们发现这种攻击可以通过控制单个客户端进行。虽然已经有很多关于联邦学习中自然引起的不公正性的研究，但是人为引起的不公正性却受到了忽视。我们表明，在任何情况下，如果模型中的不公正性可以为用户的训练参与者带来利益， THEN defending against attacks on fairness should be a critical consideration。
</details></li>
</ul>
<hr>
<h2 id="Regression-Based-Analysis-of-Multimodal-Single-Cell-Data-Integration-Strategies"><a href="#Regression-Based-Analysis-of-Multimodal-Single-Cell-Data-Integration-Strategies" class="headerlink" title="Regression-Based Analysis of Multimodal Single-Cell Data Integration Strategies"></a>Regression-Based Analysis of Multimodal Single-Cell Data Integration Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12711">http://arxiv.org/abs/2311.12711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bhavya Mehta, Nirmit Deliwala, Madhav Chandane</li>
<li>for: 这项研究旨在提高单元细胞数据的集成分析，以推断疾病生物标志物和药物发现。</li>
<li>methods: 该研究采用了多种机器学习技术，包括零均值网络、支持向量机器学习和隐藏状态隐藏层网络，以模型单元细胞中的DNA、RNA和蛋白质之间的相关性。</li>
<li>results: 研究发现，使用Echo State Networks方法可以达到极高的相关性分数（0.94和0.895），在多样Omics和CiteSeq数据集上。这些结果表明，这种方法可以有效地捕捉单元细胞中的多种数据类型之间的关系，并且可以在疾病诊断和药物发现中提供有价值的支持。<details>
<summary>Abstract</summary>
Multimodal single-cell technologies enable the simultaneous collection of diverse data types from individual cells, enhancing our understanding of cellular states. However, the integration of these datatypes and modeling the interrelationships between modalities presents substantial computational and analytical challenges in disease biomarker detection and drug discovery. Established practices rely on isolated methodologies to investigate individual molecular aspects separately, often resulting in inaccurate analyses. To address these obstacles, distinct Machine Learning Techniques are leveraged, each of its own kind to model the co-variation of DNA to RNA, and finally to surface proteins in single cells during hematopoietic stem cell development, which simplifies understanding of underlying cellular mechanisms and immune responses. Experiments conducted on a curated subset of a 300,000-cell time course dataset, highlights the exceptional performance of Echo State Networks, boasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on Multi-omic and CiteSeq datasets. Beyond the confines of this study, these findings hold promise for advancing comprehension of cellular differentiation and function, leveraging the potential of Machine Learning.
</details>
<details>
<summary>摘要</summary>
多模态单细胞技术可以同时收集单个细胞的多种数据类型，从而提高我们对细胞状态的理解。然而，将这些数据类型集成并模型细胞间关系存在巨大的计算和分析挑战，在疾病生物标志物发现和药物探索中。现有的做法通常是采用隔离的方法来研究单个分子方面，这经常导致不准确的分析。为了解决这些障碍，不同的机器学习技术被投入使用，每种都用自己的方式来模型细胞中DNA和RNA之间的相关性，最终是surface proteins的模型。在单细胞发育过程中，这种方法简化了细胞内部机制和免疫应答的理解。在一个精心选择的300,000个细胞时序数据集上进行实验，显示了Echo State Networks的极高水平的状态识别能力，其 correlate score为0.94和0.895，在多Omics和CiteSeq数据集上。这些发现不仅限于本研究，也持有推动细胞分化和功能理解的潜在潜力。>>>
</details></li>
</ul>
<hr>
<h2 id="On-the-Out-of-Distribution-Coverage-of-Combining-Split-Conformal-Prediction-and-Bayesian-Deep-Learning"><a href="#On-the-Out-of-Distribution-Coverage-of-Combining-Split-Conformal-Prediction-and-Bayesian-Deep-Learning" class="headerlink" title="On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning"></a>On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12688">http://arxiv.org/abs/2311.12688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Scemama, Ariel Kapusta</li>
<li>for: 这个论文探讨了将 bayesian deep learning 和分割免疑预测结合使用以提高机器学习系统的不确定性传递和安全性。</li>
<li>methods: 该论文使用了 bayesian deep learning 和 split conformal prediction 的组合，以研究这两种方法对多类图像分类中的 OUT-OF-DISTRIBUTION 覆盖性的影响。</li>
<li>results: 研究结果表明，如果模型在审核集上通常是不足自信的，那么结果的 conformal sets 可能会比简单的预测可信区sets 更差地覆盖 OUT-OF-DISTRIBUTION 样本。相反，如果模型在审核集上过于自信，那么使用 conformal prediction 可能会提高 OUT-OF-DISTRIBUTION 覆盖性。<details>
<summary>Abstract</summary>
Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining Bayesian deep learning models with split conformal prediction can, in some cases, cause unintended consequences such as reducing out-of-distribution coverage.
</details>
<details>
<summary>摘要</summary>
bayesian深度学习和充分预测是两种方法，可以用于传递不确定性并提高机器学习系统的安全性。我们专注于将bayesian深度学习与分割充分预测结合使用，并对这种组合对 OUT-OF-DISTRIBUTION覆盖产生的影响进行分析，尤其是在多类图像分类 task 中。我们发现，如果模型在校对集上一般下预测不准确，那么结果的充分预测集可能会比简单预测可靠集更差地覆盖 OUT-OF-DISTRIBUTION 区域。相反，如果模型在校对集上过于自信，那么使用充分预测可能会提高 OUT-OF-DISTRIBUTION 覆盖。我们通过将拆分充分预测方法与神经网络（i）随机梯度下降（ii）深度ensemble（iii）mean-field variational inference 相结合来评估预测集。我们的结果表明，将bayesian深度学习模型与分割充分预测结合使用可能会导致一些不良后果，例如减少 OUT-OF-DISTRIBUTION 覆盖。
</details></li>
</ul>
<hr>
<h2 id="Managing-ML-Based-Application-Non-Functional-Behavior-A-Multi-Model-Approach"><a href="#Managing-ML-Based-Application-Non-Functional-Behavior-A-Multi-Model-Approach" class="headerlink" title="Managing ML-Based Application Non-Functional Behavior: A Multi-Model Approach"></a>Managing ML-Based Application Non-Functional Behavior: A Multi-Model Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12686">http://arxiv.org/abs/2311.12686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Anisetti, Claudio A. Ardagna, Nicola Bena, Ernesto Damiani, Paolo G. Panero</li>
<li>for: This paper aims to provide a solution for ensuring the stable non-functional behavior of Machine Learning (ML) models in modern applications, particularly in the edge-cloud continuum.</li>
<li>methods: The proposed solution uses a multi-model approach built on dynamic classifier selection, where multiple ML models showing similar non-functional properties are made available to the application and one model is selected over time according to contextual changes.</li>
<li>results: The proposed solution is experimentally evaluated in a real-world scenario focusing on non-functional property fairness, and is shown to provide a stable and continuous support of non-functional properties.<details>
<summary>Abstract</summary>
Modern applications are increasingly driven by Machine Learning (ML) models whose non-deterministic behavior is affecting the entire application life cycle from design to operation. The pervasive adoption of ML is urgently calling for approaches that guarantee a stable non-functional behavior of ML-based applications over time and across model changes. To this aim, non-functional properties of ML models, such as privacy, confidentiality, fairness, and explainability, must be monitored, verified, and maintained. This need is even more pressing when modern applications operate in the edge-cloud continuum, increasing their complexity and dynamicity. Existing approaches mostly focus on i) implementing classifier selection solutions according to the functional behavior of ML models, ii) finding new algorithmic solutions to this need, such as continuous re-training. In this paper, we propose a multi-model approach built on dynamic classifier selection, where multiple ML models showing similar non-functional properties are made available to the application and one model is selected over time according to (dynamic and unpredictable) contextual changes. Our solution goes beyond the state of the art by providing an architectural and methodological approach that continuously guarantees a stable non-functional behavior of ML-based applications, is applicable to different ML models, and is driven by non-functional properties assessed on the models themselves. It consists of a two-step process working during application operation, where model assessment verifies non-functional properties of ML models trained and selected at development time, and model substitution guarantees a continuous and stable support of non-functional properties. We experimentally evaluate our solution in a real-world scenario focusing on non-functional property fairness.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Adversarial-Reweighting-Guided-by-Wasserstein-Distance-for-Bias-Mitigation"><a href="#Adversarial-Reweighting-Guided-by-Wasserstein-Distance-for-Bias-Mitigation" class="headerlink" title="Adversarial Reweighting Guided by Wasserstein Distance for Bias Mitigation"></a>Adversarial Reweighting Guided by Wasserstein Distance for Bias Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12684">http://arxiv.org/abs/2311.12684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Zhao, Simone Fabbrizzi, Paula Reyero Lobo, Siamak Ghodsi, Klaus Broelemann, Steffen Staab, Gjergji Kasneci</li>
<li>for: Addressing discrimination in machine learning models due to unequal representation of different groups in the sample population.</li>
<li>methods: Proposes a novel adversarial reweighting method to address representation bias by deemphasizing samples from the majority group and preferring samples that are close to the minority group based on the Wasserstein distance.</li>
<li>results: Mitigates bias without sacrificing classification accuracy, outperforming related state-of-the-art methods on image and tabular benchmark datasets.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在Addressing discrimination in machine learning models due to unequal representation of different groups in the sample population.</li>
<li>methods: 提出了一种 novel adversarial reweighting method, 通过减少主要群体中的样本来减轻代表偏见, 并 prefer samples that are close to the minority group based on the Wasserstein distance.</li>
<li>results: 实验表明, 该方法可以不减少预测精度，同时减少偏见, 在图像和表格 benchmark datasets 上表现出色。<details>
<summary>Abstract</summary>
The unequal representation of different groups in a sample population can lead to discrimination of minority groups when machine learning models make automated decisions. To address these issues, fairness-aware machine learning jointly optimizes two (or more) metrics aiming at predictive effectiveness and low unfairness. However, the inherent under-representation of minorities in the data makes the disparate treatment of subpopulations less noticeable and difficult to deal with during learning. In this paper, we propose a novel adversarial reweighting method to address such \emph{representation bias}. To balance the data distribution between the majority and the minority groups, our approach deemphasizes samples from the majority group. To minimize empirical risk, our method prefers samples from the majority group that are close to the minority group as evaluated by the Wasserstein distance. Our theoretical analysis shows the effectiveness of our adversarial reweighting approach. Experiments demonstrate that our approach mitigates bias without sacrificing classification accuracy, outperforming related state-of-the-art methods on image and tabular benchmark datasets.
</details>
<details>
<summary>摘要</summary>
不平等的人群表示在样本人口中可能导致机器学习模型自动做出不公正的决策。为解决这些问题，公平意识机器学习同时优化了两个或更多的指标，即预测效果和低不公正。然而，数据中少数群体的自然下降使得对各个子人口的不公正待遇更难发现和处理。在这篇论文中，我们提出了一种新的对抗重量方法来解决这种表示偏见。为了平衡数据分布 между主流群体和少数群体，我们的方法减少了主流群体的样本。为了降低实际风险，我们的方法偏好主流群体的样本与少数群体的距离 Wasserstein 距离较近。我们的理论分析表明我们的对抗重量方法的效果。实验表明，我们的方法可以减轻偏见而不 sacrificing 预测精度，比相关的当前状态艺术方法在图像和表格 benchmark 数据集上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Interpretation-of-the-Transformer-and-Improvement-of-the-Extractor"><a href="#Interpretation-of-the-Transformer-and-Improvement-of-the-Extractor" class="headerlink" title="Interpretation of the Transformer and Improvement of the Extractor"></a>Interpretation of the Transformer and Improvement of the Extractor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12678">http://arxiv.org/abs/2311.12678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhe Chen</li>
<li>for: 本文对Transformer架构进行了深入的解释和解读，以便更好地理解和改进Transformer架构。</li>
<li>methods: 本文使用了自己的理解和经验来对Transformer架构进行了广泛的解释，并对这些解释进行了证明和验证。</li>
<li>results: 本文提出了一种基于Extractor的改进方法，该方法可以在不添加额外可训练参数的情况下，超越自注意。实验结果表明，改进后的Extractor表现更出色，这表明了可以改进Transformer架构。<details>
<summary>Abstract</summary>
It has been over six years since the Transformer architecture was put forward. Surprisingly, the vanilla Transformer architecture is still widely used today. One reason is that the lack of deep understanding and comprehensive interpretation of the Transformer architecture makes it more challenging to improve the Transformer architecture. In this paper, we first interpret the Transformer architecture comprehensively in plain words based on our understanding and experiences. The interpretations are further proved and verified. These interpretations also cover the Extractor, a family of drop-in replacements for the multi-head self-attention in the Transformer architecture. Then, we propose an improvement on a type of the Extractor that outperforms the self-attention, without introducing additional trainable parameters. Experimental results demonstrate that the improved Extractor performs even better, showing a way to improve the Transformer architecture.
</details>
<details>
<summary>摘要</summary>
六年以上了， transformer 架构仍然广泛使用。一个原因是，因为对 transformer 架构的深入理解和全面解释而做出的进一步改进很困难。在这篇论文中，我们首先通过我们的理解和经验对 transformer 架构进行了全面的解释，这些解释得到了证明和验证。这些解释还涵盖了一家drop-in replacement的多头自注意 Mechanism，称为 Extractor。然后，我们提出了一种改进 drop-in replacement 的方法，不需要添加额外的可训练参数。实验结果表明，改进后的 Extractor 性能更佳，显示了如何改进 transformer 架构。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Left-Right-Wearable-Sensors-IMUs-Consistency-Matching-for-HAR"><a href="#Contrastive-Left-Right-Wearable-Sensors-IMUs-Consistency-Matching-for-HAR" class="headerlink" title="Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for HAR"></a>Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for HAR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12674">http://arxiv.org/abs/2311.12674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominique Nshimyimana, Vitor Fortes Rey, Paul Lukowic</li>
<li>for: 这个论文目的是提出一种使用实际数据进行自然语言处理无需任何变换的方法，以便减少人工标注的瓶颈。</li>
<li>methods: 该方法利用传感器数据的对称性，对两个不同的传感器（左右手或腿上的IMUs）进行对比匹配，使同时发生的传感器数据的表示更加相似，不同的传感器数据的表示更加不同。</li>
<li>results: 在MM-Fit和Opportunity datasets上测试了该方法，在MM-Fit上显著超过基线的超级vised和自动标注方法SimCLR，在Opportunity上则超过基线的超级vised方法和slightly exceed SimCLR。此外，该方法还可以在只使用小量数据进行训练时提高超级vised基eline。未来的工作应该研究这种方法在人动作识别系统和相关应用场景中的优点和缺点。<details>
<summary>Abstract</summary>
Machine learning algorithms are improving rapidly, but annotating training data remains a bottleneck for many applications. In this paper, we show how real data can be used for self-supervised learning without any transformations by taking advantage of the symmetry present in the activities. Our approach involves contrastive matching of two different sensors (left and right wrist or leg-worn IMUs) to make representations of co-occurring sensor data more similar and those of non-co-occurring sensor data more different. We test our approach on the Opportunity and MM-Fit datasets. In MM-Fit we show significant improvement over the baseline supervised and self-supervised method SimCLR, while for Opportunity there is significant improvement over the supervised baseline and slight improvement when compared to SimCLR. Moreover, our method improves supervised baselines even when using only a small amount of the data for training. Future work should explore under which conditions our method is beneficial for human activity recognition systems and other related applications.
</details>
<details>
<summary>摘要</summary>
（Machine learning algoritms are improving rapidly, but annotating training data remains a bottleneck for many applications. In this paper, we show how real data can be used for self-supervised learning without any transformations by taking advantage of the symmetry present in the activities. Our approach involves contrastive matching of two different sensors, such as the left and right wrist or leg-worn IMUs, to make representations of co-occurring sensor data more similar and those of non-co-occurring sensor data more different. We test our approach on the Opportunity and MM-Fit datasets. In MM-Fit, we show significant improvement over the baseline supervised and self-supervised method SimCLR, while for Opportunity, there is significant improvement over the supervised baseline and slight improvement when compared to SimCLR. Moreover, our method improves supervised baselines even when using only a small amount of the data for training. Future work should explore under which conditions our method is beneficial for human activity recognition systems and other related applications.）
</details></li>
</ul>
<hr>
<h2 id="Towards-a-more-inductive-world-for-drug-repurposing-approaches"><a href="#Towards-a-more-inductive-world-for-drug-repurposing-approaches" class="headerlink" title="Towards a more inductive world for drug repurposing approaches"></a>Towards a more inductive world for drug repurposing approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12670">http://arxiv.org/abs/2311.12670</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ubioinformat/graphemb">https://github.com/ubioinformat/graphemb</a></li>
<li>paper_authors: Jesus de la Fuente, Guillermo Serrano, Uxía Veleiro, Mikel Casals, Laura Vera, Marija Pizurica, Antonio Pineda-Lucena, Idoia Ochoa, Silve Vicent, Olivier Gevaert, Mikel Hernaez</li>
<li>for: 这个论文主要针对的是药用Target交互预测（DTI）的挑战，以及如何使用图模型来降低药品复用的成本和时间投入。</li>
<li>methods: 作者首先对当前的DTI预测方法进行了深入的评估，并发现现有的模型在不同的结构上存在差异，这使得对模型的比较不公。此外，作者还提出了一种基于负边采样的新方法，通过尝试 validate的方式，证明了该方法可以发现真实存在的交互。</li>
<li>results: 作者通过对当前DTI预测数据集和模型进行了深入的评估，发现现有的预测方法在某些情况下存在泛化问题，并且当以前的方法来评估时，其性能会被膨胀。同时，作者还提出了一种基于生物学驱动的负边采样策略，并通过尝试 validate的方式证明了该策略可以发现真实存在的交互。<details>
<summary>Abstract</summary>
Drug-target interaction (DTI) prediction is a challenging, albeit essential task in drug repurposing. Learning on graph models have drawn special attention as they can significantly reduce drug repurposing costs and time commitment. However, many current approaches require high-demanding additional information besides DTIs that complicates their evaluation process and usability. Additionally, structural differences in the learning architecture of current models hinder their fair benchmarking. In this work, we first perform an in-depth evaluation of current DTI datasets and prediction models through a robust benchmarking process, and show that DTI prediction methods based on transductive models lack generalization and lead to inflated performance when evaluated as previously done in the literature, hence not being suited for drug repurposing approaches. We then propose a novel biologically-driven strategy for negative edge subsampling and show through in vitro validation that newly discovered interactions are indeed true. We envision this work as the underpinning for future fair benchmarking and robust model design. All generated resources and tools are publicly available as a python package.
</details>
<details>
<summary>摘要</summary>
药Target交互（DTI）预测是药物重用中的一项挑战，但它也是非常重要的。学习图模型在药物重用中吸引了特别的关注，因为它们可以大幅降低药物重用的成本和时间投入。然而，现有的方法frequently需要更多的信息，这会让评估过程变得复杂和不可靠。此外，现有的学习建筑设计带来了模型之间的结构差异，使得它们之间的公平比较困难。在这项工作中，我们首先进行了DTI数据集和预测模型的深入评估，并发现DTI预测方法基于推uctive模型存在泛化问题，导致过去文献中的性能评估结果被膨胀。我们然后提出了一种基于生物学驱动的负边样本采样策略，并通过室内验证表明新发现的交互 действительно是真实的。我们期望这项工作可以成为未来评估和模型设计的基础。所有生成的资源和工具都公开可用，可以通过python包获取。
</details></li>
</ul>
<hr>
<h2 id="SSVEP-DAN-A-Data-Alignment-Network-for-SSVEP-based-Brain-Computer-Interfaces"><a href="#SSVEP-DAN-A-Data-Alignment-Network-for-SSVEP-based-Brain-Computer-Interfaces" class="headerlink" title="SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer Interfaces"></a>SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer Interfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12666">http://arxiv.org/abs/2311.12666</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cecnl/ssvep-dan">https://github.com/cecnl/ssvep-dan</a></li>
<li>paper_authors: Sung-Yu Chen, Chi-Min Chang, Kuan-Jung Chiang, Chun-Shu Wei</li>
<li>for: 提高 SSVEP 基于 BCIs 的效率，使其能够在有限的准备数据下进行快速响应。</li>
<li>methods: 提出了 SSVEP-DAN 模型，用于对 SSVEP 数据进行匹配，从而使得 SSVEP 基于 BCIs 可以在不同的场景下使用。</li>
<li>results: 在多个跨领域场景中实验证明 SSVEP-DAN 模型能够将存在不同域的 SSVEP 数据转换成补充的准备数据，从而提高 SSVEP 基于 BCIs 的解码精度。<details>
<summary>Abstract</summary>
Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces (BCIs) offer a non-invasive means of communication through high-speed speller systems. However, their efficiency heavily relies on individual training data obtained during time-consuming calibration sessions. To address the challenge of data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first dedicated neural network model designed for aligning SSVEP data across different domains, which can encompass various sessions, subjects, or devices. Our experimental results across multiple cross-domain scenarios demonstrate SSVEP-DAN's capability to transform existing source SSVEP data into supplementary calibration data, significantly enhancing SSVEP decoding accuracy in scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst for practical SSVEP-based BCI applications with minimal calibration. The source codes in this work are available at: https://github.com/CECNL/SSVEP-DAN.
</details>
<details>
<summary>摘要</summary>
steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces (BCIs) 提供了一种非侵入式的通信方式，通过高速的字母系统。然而，其效率受到各自的训练数据的影响，具体来说是在耗时的准备session中获取的数据。为了解决 SSVEP 基于 BCIs 的数据不足的挑战，我们提出了 SSVEP-DAN，首个特有的神经网络模型，可以将 SSVEP 数据平移到不同的领域中，包括不同的会话、主体或设备。我们在多个跨领域场景中进行了实验， demonstarted SSVEP-DAN 的能力可以将存在的源 SSVEP 数据转化成补充calibration 数据，明显提高 SSVEP 解码精度在有限的 calibration 数据情况下。我们期望 SSVEP-DAN 能够推动 SSVEP 基于 BCI 的实际应用，只需 minimal calibration。source code 在这里可以获取：https://github.com/CECNL/SSVEP-DAN。
</details></li>
</ul>
<hr>
<h2 id="Carbohydrate-NMR-chemical-shift-predictions-using-E-3-equivariant-graph-neural-networks"><a href="#Carbohydrate-NMR-chemical-shift-predictions-using-E-3-equivariant-graph-neural-networks" class="headerlink" title="Carbohydrate NMR chemical shift predictions using E(3) equivariant graph neural networks"></a>Carbohydrate NMR chemical shift predictions using E(3) equivariant graph neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12657">http://arxiv.org/abs/2311.12657</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mariabankestad/geqshift">https://github.com/mariabankestad/geqshift</a></li>
<li>paper_authors: Maria Bånkestad, Keven M. Dorst, Göran Widmalm, Jerk Rönnols<br>for: 这项研究的目的是提出一种基于E(3)对称图解决方法，用于预测碳水化合物核磁共振（NMR）谱图。methods: 该方法利用E(3)对称图神经网络来预测碳水化合物NMR谱图，并且可以减少mean absolute error，比传统方法更准确。results: 该模型在有限数据情况下表现出色，表明它具有良好的稳定性和泛化能力。这些结果有助于加速药物应用、生物化学和结构生物学等领域的研究，并可能影响其他than NMR spectroscopy的分子结构分析技术。<details>
<summary>Abstract</summary>
Carbohydrates, vital components of biological systems, are well-known for their structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays a crucial role in understanding their intricate molecular arrangements and is essential in assessing and verifying the molecular structure of organic molecules. An important part of this process is to predict the NMR chemical shift from the molecular structure. This work introduces a novel approach that leverages E(3) equivariant graph neural networks to predict carbohydrate NMR spectra. Notably, our model achieves a substantial reduction in mean absolute error, up to threefold, compared to traditional models that rely solely on two-dimensional molecular structure. Even with limited data, the model excels, highlighting its robustness and generalization capabilities. The implications are far-reaching and go beyond an advanced understanding of carbohydrate structures and spectral interpretation. For example, it could accelerate research in pharmaceutical applications, biochemistry, and structural biology, offering a faster and more reliable analysis of molecular structures. Furthermore, our approach is a key step towards a new data-driven era in spectroscopy, potentially influencing spectroscopic techniques beyond NMR.
</details>
<details>
<summary>摘要</summary>
碳水化合物是生物系统中重要的组成部分，其分子结构多样性很强。核磁共振（NMR） спектроскопия在理解这些分子结构中扮演着关键角色，是评估和验证有机分子结构的关键工具。 Predicting NMR chemical shift from molecular structure is an important part of this process. 本文提出了一种新的方法，利用E(3)对称的图像神经网络来预测碳水化合物NMR спектrum。与传统模型相比，我们的模型可以 achieve a substantial reduction in mean absolute error, up to threefold, even with limited data. This highlights the robustness and generalization capabilities of our approach. The implications of this work are far-reaching and extend beyond an advanced understanding of carbohydrate structures and spectral interpretation. For example, it could accelerate research in pharmaceutical applications, biochemistry, and structural biology, offering a faster and more reliable analysis of molecular structures. Furthermore, our approach is a key step towards a new data-driven era in spectroscopy, potentially influencing spectroscopic techniques beyond NMR.Note: The translation is in Simplified Chinese, which is the standardized form of Chinese used in mainland China and other countries. The traditional Chinese form of the text is slightly different, but the meaning remains the same.
</details></li>
</ul>
<hr>
<h2 id="FedDRO-Federated-Compositional-Optimization-for-Distributionally-Robust-Learning"><a href="#FedDRO-Federated-Compositional-Optimization-for-Distributionally-Robust-Learning" class="headerlink" title="FedDRO: Federated Compositional Optimization for Distributionally Robust Learning"></a>FedDRO: Federated Compositional Optimization for Distributionally Robust Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12652">http://arxiv.org/abs/2311.12652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prashant Khanduri, Chengyin Li, Rafi Ibn Sultan, Yao Qiang, Joerg Kliewer, Dongxiao Zhu</li>
<li>For: The paper is written for solving non-convex compositional optimization (CO) problems in the context of distributed machine learning, specifically in federated learning (FL) settings.* Methods: The paper proposes a novel federated learning framework called FedDRO, which utilizes the structure of the distributed optimization problem to design a communication strategy that controls the bias in the estimation of the compositional gradient. The proposed method does not rely on large batch gradients and achieves $\mathcal{O}(\epsilon^{-2})$ sample and $\mathcal{O}(\epsilon^{-3&#x2F;2})$ communication complexity.* Results: The paper achieves linear speedup with the number of clients in the FL setting and corroborates the theoretical findings with empirical studies on large-scale distributed optimization problems. The proposed method is able to solve non-convex CO problems without relying on large batch gradients, which is a key contribution of the paper.Here’s the simplified Chinese text for the three information points:* For: 本文解决了分布式机器学习中的非对称 композиitional optimization（CO）问题。* Methods: 本文提出了一种基于分布式优化问题的 federated learning（FL）框架，称为FedDRO，该框架利用分布式优化问题的结构来设计通信策略，以控制每个客户端的相对误差。* Results: 本文实现了与客户端数量成线性相关的加速，并通过大规模实验证明了理论发现。该方法不需要大批量导数（以及函数评估），可以解决非对称CO问题。<details>
<summary>Abstract</summary>
Recently, compositional optimization (CO) has gained popularity because of its applications in distributionally robust optimization (DRO) and many other machine learning problems. Large-scale and distributed availability of data demands the development of efficient federated learning (FL) algorithms for solving CO problems. Developing FL algorithms for CO is particularly challenging because of the compositional nature of the objective. Moreover, current state-of-the-art methods to solve such problems rely on large batch gradients (depending on the solution accuracy) not feasible for most practical settings. To address these challenges, in this work, we propose efficient FedAvg-type algorithms for solving non-convex CO in the FL setting. We first establish that vanilla FedAvg is not suitable to solve distributed CO problems because of the data heterogeneity in the compositional objective at each client which leads to the amplification of bias in the local compositional gradient estimates. To this end, we propose a novel FL framework FedDRO that utilizes the DRO problem structure to design a communication strategy that allows FedAvg to control the bias in the estimation of the compositional gradient. A key novelty of our work is to develop solution accuracy-independent algorithms that do not require large batch gradients (and function evaluations) for solving federated CO problems. We establish $\mathcal{O}(\epsilon^{-2})$ sample and $\mathcal{O}(\epsilon^{-3/2})$ communication complexity in the FL setting while achieving linear speedup with the number of clients. We corroborate our theoretical findings with empirical studies on large-scale DRO problems.
</details>
<details>
<summary>摘要</summary>
近期， compositional optimization（CO）已经受到应用于分布式Robust optimization（DRO）和其他机器学习问题的欢迎。随着数据的大规模和分布式化，需要开发高效的联合学习（FL）算法来解决 CO 问题。解决 CO 问题在 FL 设置中特别困难，因为 CO 目标函数的compositional性。现有的状态先进方法是使用大批量梯度（取决于解决精度），但这些方法在实际场景中不可行。为了解决这些挑战，在这种工作中，我们提出了高效的 FedAvg-type算法来解决非对称 CO 问题。我们首先证明了vanilla FedAvg 无法解决分布式 CO 问题，因为每个客户端上的数据不同性会导致 CO 目标函数的地址偏置。为此，我们提出了一种新的联合学习框架 FedDRO，利用 DRO 问题的结构设计了一种通信策略，使 FedAvg 可以控制地址偏置的局部 композиitional 梯度估计。我们的工作的一个重要创新是开发不依赖于大批量梯度（以及函数评估）的解决方案，可以在 FL 设置中解决联合 CO 问题。我们证明了 $\mathcal{O}(\epsilon^{-2})$ 样本和 $\mathcal{O}(\epsilon^{-3/2})$ 通信复杂度，而且在客户端数量增加时实现了直线性加速。我们的理论发现得到了大规模 DRO 问题的实际研究证明。
</details></li>
</ul>
<hr>
<h2 id="Careful-Selection-and-Thoughtful-Discarding-Graph-Explicit-Pooling-Utilizing-Discarded-Nodes"><a href="#Careful-Selection-and-Thoughtful-Discarding-Graph-Explicit-Pooling-Utilizing-Discarded-Nodes" class="headerlink" title="Careful Selection and Thoughtful Discarding: Graph Explicit Pooling Utilizing Discarded Nodes"></a>Careful Selection and Thoughtful Discarding: Graph Explicit Pooling Utilizing Discarded Nodes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12644">http://arxiv.org/abs/2311.12644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuang Liu, Wenhang Yu, Kuang Gao, Xueqi Ma, Yibing Zhan, Jia Wu, Bo Du, Wenbin Hu</li>
<li>for: 提高Graph Neural Networks（GNNs）中的层次图像学习， Graph pooling 方法可以帮助减少图像的维度，从而提高模型的泛化能力。</li>
<li>methods: 我们提出了一种新的 Graph Explicit Pooling（GrePool）方法，通过显式利用节点之间的关系和最终表示向量来选择节点。 此外，我们还提出了一种扩展版本的 GrePool（即 GrePool+），通过对产生的节点进行均匀损失来增强训练过程和提高分类精度。</li>
<li>results: 我们在12个常用的数据集上进行了广泛的实验，并证明了 GrePool 可以在大多数数据集上超过 14 个基准方法的性能。此外，在应用 GrePool+ 时，可以进一步提高 GrePool 的性能，而无需增加计算成本。<details>
<summary>Abstract</summary>
Graph pooling has been increasingly recognized as crucial for Graph Neural Networks (GNNs) to facilitate hierarchical graph representation learning. Existing graph pooling methods commonly consist of two stages: selecting top-ranked nodes and discarding the remaining to construct coarsened graph representations. However, this paper highlights two key issues with these methods: 1) The process of selecting nodes to discard frequently employs additional Graph Convolutional Networks or Multilayer Perceptrons, lacking a thorough evaluation of each node's impact on the final graph representation and subsequent prediction tasks. 2) Current graph pooling methods tend to directly discard the noise segment (dropped) of the graph without accounting for the latent information contained within these elements. To address the first issue, we introduce a novel Graph Explicit Pooling (GrePool) method, which selects nodes by explicitly leveraging the relationships between the nodes and final representation vectors crucial for classification. The second issue is addressed using an extended version of GrePool (i.e., GrePool+), which applies a uniform loss on the discarded nodes. This addition is designed to augment the training process and improve classification accuracy. Furthermore, we conduct comprehensive experiments across 12 widely used datasets to validate our proposed method's effectiveness, including the Open Graph Benchmark datasets. Our experimental results uniformly demonstrate that GrePool outperforms 14 baseline methods for most datasets. Likewise, implementing GrePool+ enhances GrePool's performance without incurring additional computational costs.
</details>
<details>
<summary>摘要</summary>
graph pooling已经被认为是graph neural networks（GNNs）中重要的一环，以便实现 hierarchical graph representation learning。现有的graph pooling方法通常包括两个阶段：选择top-ranked nodes并抛弃剩下的节点来构建缩进的graph representation。然而，这篇论文指出了两个关键问题：1）选择节点抛弃的过程经常使用额外的graph convolutional networks或多层感知器，缺乏对每个节点对最终graph representation和预测任务的全面评估。2）当前的graph pooling方法通常直接抛弃图像的噪音部分（dropped）而不考虑这些元素中含的 latent information。为了解决第一个问题，我们引入了一种novel的Graph Explicit Pooling（GrePool）方法，该方法选择节点通过显式利用节点之间的关系和最终表示向量的关系，这些关系对于分类非常重要。为了解决第二个问题，我们提出了一种扩展版的GrePool（i.e., GrePool+），该方法在抛弃节点时应用一个均匀损失。这种添加是为了增强训练过程并提高分类精度。此外，我们在12个常用的dataset上进行了广泛的实验，以验证我们提出的方法的有效性。我们的实验结果表明，GrePool在大多数dataset上都高于14个基eline方法。同时，在实现GrePool+后，GrePool的性能得到了进一步提高，而无需额外的计算成本。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Joint-Graph-Learning-and-Multivariate-Time-Series-Forecasting"><a href="#Hierarchical-Joint-Graph-Learning-and-Multivariate-Time-Series-Forecasting" class="headerlink" title="Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting"></a>Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12630">http://arxiv.org/abs/2311.12630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juhyeon Kim, Hyungeun Lee, Seungwon Yu, Ung Hwang, Wooyul Jung, Miseon Park, Kijung Yoon</li>
<li>for: 本研究旨在解决多变量时间序列数据的复杂关系和长远依赖问题，提出一种基于图 neural network 和注意机制的方法来有效地学习时间序列数据的下一步预测。</li>
<li>methods: 本研究使用图 neural network 和注意机制来表示多变量时间序列数据，并运用层次信号分解来捕捉多个空间依赖关系。</li>
<li>results: 对多个实际数据集进行了比较，结果显示本研究的方法可以减少平均平方误差（MSE）23%，与现有方法相比显著提高了预测性能。<details>
<summary>Abstract</summary>
Multivariate time series is prevalent in many scientific and industrial domains. Modeling multivariate signals is challenging due to their long-range temporal dependencies and intricate interactions--both direct and indirect. To confront these complexities, we introduce a method of representing multivariate signals as nodes in a graph with edges indicating interdependency between them. Specifically, we leverage graph neural networks (GNN) and attention mechanisms to efficiently learn the underlying relationships within the time series data. Moreover, we suggest employing hierarchical signal decompositions running over the graphs to capture multiple spatial dependencies. The effectiveness of our proposed model is evaluated across various real-world benchmark datasets designed for long-term forecasting tasks. The results consistently showcase the superiority of our model, achieving an average 23\% reduction in mean squared error (MSE) compared to existing models.
</details>
<details>
<summary>摘要</summary>
多变量时间序列在许多科学和工业领域很普遍。模型多变量信号具有长范围时间相关性和复杂的相互作用——直接和间接相互作用。为了面对这些复杂性，我们提出了将多变量信号表示为图形式，其中边指示多变量信号之间的相互依赖关系。具体来说，我们利用图神经网络（GNN）和注意机制来高效地学习多变量信号之间的下面关系。此外，我们建议使用层次信号分解运行于图上，以捕捉多个空间相依关系。我们的提议模型在多种实际benchmark数据集上进行了长期预测任务的效果评估，结果一致显示我们的模型在已有模型的23%的平均方差误差（MSE）下降。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Algorithmic-Information-Theory-and-Machine-Learning-A-New-Approach-to-Kernel-Learning"><a href="#Bridging-Algorithmic-Information-Theory-and-Machine-Learning-A-New-Approach-to-Kernel-Learning" class="headerlink" title="Bridging Algorithmic Information Theory and Machine Learning: A New Approach to Kernel Learning"></a>Bridging Algorithmic Information Theory and Machine Learning: A New Approach to Kernel Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12624">http://arxiv.org/abs/2311.12624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boumediene Hamzi, Marcus Hutter, Houman Owhadi</li>
<li>for: 本研究探讨了机器学习（ML）和算法信息理论（AIT）如何从不同的角度来看待复杂性。</li>
<li>methods: 本研究采用了AIT的视角来研究学习kernel的问题，具体来说是通过 sparse kernel flows 方法来学习数据中的kernel。</li>
<li>results: 本研究证明了 sparse kernel flows 方法是学习kernel的自然选择，而且不需要通过统计路径来 derivate它。 Code-lengths 和复杂度是 AIT 中出现的概念，可以直接应用于机器学习中。<details>
<summary>Abstract</summary>
Machine Learning (ML) and Algorithmic Information Theory (AIT) look at Complexity from different points of view. We explore the interface between AIT and Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on the problem of learning kernels from data, in kernel ridge regression, through the method of Sparse Kernel Flows. In particular, by looking at the differences and commonalities between Minimal Description Length (MDL) and Regularization in Machine Learning (RML), we prove that the method of Sparse Kernel Flows is the natural approach to adopt to learn kernels from data. This paper shows that it is not necessary to use the statistical route to derive Sparse Kernel Flows and that one can directly work with code-lengths and complexities that are concepts that show up in AIT.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）和算法信息理论（AIT）都从不同的角度来看复杂性。我们通过采用AIT的角度来研究kernel方法在数据上学习问题，特别是在核方程 regression 中使用稀疏核流程。在这种情况下，我们通过比较描述长度（MDL）和机器学习中的REGULARIZATION（RML）的不同和共同点来证明稀疏核流程是学习核的自然方法。这篇论文还证明了不需要通过统计路径来 derivate稀疏核流程，可以直接使用代码长度和复杂度，这些概念在AIT中出现。
</details></li>
</ul>
<hr>
<h2 id="Koopman-Learning-with-Episodic-Memory"><a href="#Koopman-Learning-with-Episodic-Memory" class="headerlink" title="Koopman Learning with Episodic Memory"></a>Koopman Learning with Episodic Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12615">http://arxiv.org/abs/2311.12615</a></li>
<li>repo_url: None</li>
<li>paper_authors: William T. Redman, Dean Huang, Maria Fonoberova, Igor Mezić</li>
<li>for: 学习非站点时序数据的模型，提高预测和控制性能</li>
<li>methods: 使用 Koopman 算法，具有更高的解释性和更低的计算成本</li>
<li>results: 基本实现 Koopman 学习 +  episodic memory 可以在 synthetic 和实际数据上提高预测性能<details>
<summary>Abstract</summary>
Koopman operator theory, a data-driven dynamical systems framework, has found significant success in learning models from complex, real-world data sets, enabling state-of-the-art prediction and control. The greater interpretability and lower computational costs of these models, compared to traditional machine learning methodologies, make Koopman learning an especially appealing approach. Despite this, little work has been performed on endowing Koopman learning with the ability to learn from its own mistakes. To address this, we equip Koopman methods - developed for predicting non-stationary time-series - with an episodic memory mechanism, enabling global recall of (or attention to) periods in time where similar dynamics previously occurred. We find that a basic implementation of Koopman learning with episodic memory leads to significant improvements in prediction on synthetic and real-world data. Our framework has considerable potential for expansion, allowing for future advances, and opens exciting new directions for Koopman learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Decentralised-Q-Learning-for-Multi-Agent-Markov-Decision-Processes-with-a-Satisfiability-Criterion"><a href="#Decentralised-Q-Learning-for-Multi-Agent-Markov-Decision-Processes-with-a-Satisfiability-Criterion" class="headerlink" title="Decentralised Q-Learning for Multi-Agent Markov Decision Processes with a Satisfiability Criterion"></a>Decentralised Q-Learning for Multi-Agent Markov Decision Processes with a Satisfiability Criterion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12613">http://arxiv.org/abs/2311.12613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keshav P. Keval, Vivek S. Borkar</li>
<li>For: 这篇论文的目的是提出一个强化学习算法，用于解决多代理Markov决策过程（MMDP）。* Methods: 这篇论文使用了Q学习算法，并与 Metropolis-Hastings 或多项分数Weight  formalism 组合，实现了每个代理的成本权重的加权组合。它还使用了多个时间尺度，并证明了在某些条件下，这个算法可以精确地达成每个代理的目标。* Results: 这篇论文的结果显示，这个算法可以在MMDP中实现时间平均成本下降，并且在更一般的MMDP中，可以实现独立的代理成本下降。<details>
<summary>Abstract</summary>
In this paper, we propose a reinforcement learning algorithm to solve a multi-agent Markov decision process (MMDP). The goal, inspired by Blackwell's Approachability Theorem, is to lower the time average cost of each agent to below a pre-specified agent-specific bound. For the MMDP, we assume the state dynamics to be controlled by the joint actions of agents, but the per-stage costs to only depend on the individual agent's actions. We combine the Q-learning algorithm for a weighted combination of the costs of each agent, obtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative Weights formalisms to modulate the averaging matrix of the gossip. We use multiple timescales in our algorithm and prove that under mild conditions, it approximately achieves the desired bounds for each of the agents. We also demonstrate the empirical performance of this algorithm in the more general setting of MMDPs having jointly controlled per-stage costs.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种强化学习算法，用于解决多个代理人Markov决策过程（MMDP）。我们的目标，受黑威尔的接近性定理启发，是将每个代理人的时均成本降低到下预先指定的代理人特定的上限以下。对于MMDP，我们假设状态动力采用了多个代理人的共同行动，但每个阶段的成本只受到每个代理人的行动的影响。我们将Q学习算法与 Metropolis-Hastings 或 multiplicative weights 的形式来权衡每个代理人的成本，并使用多个时间尺度。我们证明，在某些条件下，该算法可以相对准确地实现每个代理人的目标。此外，我们还在更一般的MMDP中进行了实验，并证明了其效果。
</details></li>
</ul>
<hr>
<h2 id="A-New-Type-Of-Upper-And-Lower-Bounds-On-Right-Tail-Probabilities-Of-Continuous-Random-Variables"><a href="#A-New-Type-Of-Upper-And-Lower-Bounds-On-Right-Tail-Probabilities-Of-Continuous-Random-Variables" class="headerlink" title="A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of Continuous Random Variables"></a>A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of Continuous Random Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12612">http://arxiv.org/abs/2311.12612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikola Zlatanov</li>
<li>for: 这篇论文描述了一种新的continueRandomVariable的上下 bounds，即右尾 probabilities的上下 bounds，其取决于PDF、其第一个导数和两个参数，这些参数用于紧缩 bounds。</li>
<li>methods: 该论文使用了PDF、其第一个导数和两个参数来构建上下 bounds，并且需要这些参数满足 certain conditions。</li>
<li>results: numerical examples表明，这种新的tail bounds是right-tail probabilities的一种紧缩的 estimator。<details>
<summary>Abstract</summary>
In this paper, I present a completely new type of upper and lower bounds on the right-tail probabilities of continuous random variables with unbounded support and with semi-bounded support from the left. The presented upper and lower right-tail bounds depend only on the probability density function (PDF), its first derivative, and two parameters that are used for tightening the bounds. These tail bounds hold under certain conditions that depend on the PDF, its first and second derivatives, and the two parameters. The new tail bounds are shown to be tight for a wide range of continuous random variables via numerical examples.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我提出了一种完全新的右尾上下限 bounds，这种 bounds 适用于具有无限支持的连续随机变量和半有界支持的随机变量。我们的上下限 bounds 仅仅取决于概率密度函数（PDF）、其导数和两个参数，这两个参数用于紧张 bounds。这些尾 bounds 在满足某些基于 PDF、其导数和参数的条件下成立。我们通过实验示例展示，这些尾 bounds 在许多连续随机变量上具有高度的紧张性。
</details></li>
</ul>
<hr>
<h2 id="ChronoPscychosis-Temporal-Segmentation-and-Its-Impact-on-Schizophrenia-Classification-Using-Motor-Activity-Data"><a href="#ChronoPscychosis-Temporal-Segmentation-and-Its-Impact-on-Schizophrenia-Classification-Using-Motor-Activity-Data" class="headerlink" title="ChronoPscychosis: Temporal Segmentation and Its Impact on Schizophrenia Classification Using Motor Activity Data"></a>ChronoPscychosis: Temporal Segmentation and Its Impact on Schizophrenia Classification Using Motor Activity Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12590">http://arxiv.org/abs/2311.12590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pradnya Rajendra Jadhav, Raviprasad Aduri<br>for:本研究旨在提高分类精度，通过分析患有Schizophrenia的患者和控制组的动作数据中的时间特征。methods:我们使用16个统计特征，从12个、8个、6个、4个、3个和2个不同的时间段中提取特征，然后使用七种机器学习模型进行训练。results:我们发现，时间分 segmentation 可以显著提高分类性能，AUC-ROC &#x3D; 0.93，F1 score &#x3D; 0.84（LightGBM模型，无分 segmentation）和AUC-ROC &#x3D; 0.98，F1 score &#x3D; 0.93（LightGBM模型，与分 segmentation）。此外，我们发现，分 segmentation 可以增强对比患者和控制组的差异，但是进一步分解时间段不会提高分类性能。<details>
<summary>Abstract</summary>
Schizophrenia is a complicated mental illness characterized by a broad spectrum of symptoms affecting cognition, behavior, and emotion. The task of identifying reliable biomarkers to classify Schizophrenia accurately continues to be a challenge in the field of psychiatry. We investigate the temporal patterns within the motor activity data as a potential key to enhancing the categorization of individuals with Schizophrenia, using the dataset having motor activity recordings of 22 Schizophrenia patients and 32 control subjects. The dataset contains per-minute motor activity measurements collected for an average of 12.7 days in a row for each participant. We dissect each day into segments (Twelve, Eight, six, four, three, and two parts) and evaluate their impact on classification. We employ sixteen statistical features within these temporal segments and train them on Seven machine learning models to get deeper insights. LightGBM model outperforms the other six models. Our results indicate that the temporal segmentation significantly improves the classification, with AUC-ROC = 0.93, F1 score = 0.84( LightGBM- without any segmentation) and AUC-ROC = 0.98, F1 score = 0.93( LightGBM- with segmentation). Distinguishing between diurnal and nocturnal segments amplifies the differences between Schizophrenia patients and controls. However, further subdivisions into smaller time segments do not affect the AUC- ROC significantly. Morning, afternoon, evening, and night partitioning gives similar classification performance to day-night partitioning. These findings are valuable as they indicate that extensive temporal classification beyond distinguishing between day and night does not yield substantial results, offering an efficient approach for further classification, early diagnosis, and monitoring of Schizophrenia.
</details>
<details>
<summary>摘要</summary>
Schizophrenia 是一种复杂的心理疾病，具有各种表现 symptoms 影响认知、行为和情感。鉴定可靠的生物标志物仍然是 психиатрия 领域的挑战。我们在 motor activity 数据中寻找时间序列的潜在键，以提高将患有 Schizophrenia 分类的精度，使用包含 motor activity 记录的 22 名患者和 32 名控制人群的数据集。数据集包含每分钟的 motor activity 测量，每名参与者的平均记录天数为 12.7 天。我们将每天分成多个部分（12、8、6、4、3、2），并评估它们对分类的影响。我们使用 16 个统计特征，并在每个时间段中训练 7 种机器学习模型，以获得更深入的理解。LightGBM 模型在所有模型中表现出色，我们的结果表明，时间分 segmentation 可以显著改善分类，AUC-ROC = 0.93，F1 分数 = 0.84（LightGBM 无分 segmentation）和 AUC-ROC = 0.98，F1 分数 = 0.93（LightGBM  WITH segmentation）。distinguishing between diurnal 和 nocturnal  segment amplifies 患者和控制人群之间的差异。然而，进一步分为更小的时间段并不会对 AUC-ROC 产生显著影响。 morning、afternoon、evening 和 night 分割给出相同的分类性能。这些发现有价值，因为它们表明，extensive 时间分类 beyond  distinguishing  between day 和 night 不会产生显著的结果，提供一种有效的方法，用于进一步分类、早期诊断和监测 Schizophrenia。
</details></li>
</ul>
<hr>
<h2 id="Machine-Guided-Discovery-of-a-Real-World-Rogue-Wave-Model"><a href="#Machine-Guided-Discovery-of-a-Real-World-Rogue-Wave-Model" class="headerlink" title="Machine-Guided Discovery of a Real-World Rogue Wave Model"></a>Machine-Guided Discovery of a Real-World Rogue Wave Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12579">http://arxiv.org/abs/2311.12579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dionhaefner/rogue-wave-discovery">https://github.com/dionhaefner/rogue-wave-discovery</a></li>
<li>paper_authors: Dion Häfner, Johannes Gemmrich, Markus Jochum</li>
<li>for: This paper aims to demonstrate how machine learning can be used for scientific discovery, specifically in the field of oceanic rogue waves.</li>
<li>methods: The authors use a combination of causal analysis, deep learning, parsimony-guided model selection, and symbolic regression to discover a new symbolic model for oceanic rogue waves from data.</li>
<li>results: The resulting model reproduces known behavior, generates well-calibrated probabilities, and achieves better predictive scores on unseen data than current theory, showcasing how machine learning can facilitate inductive scientific discovery and pave the way for more accurate rogue wave forecasting.<details>
<summary>Abstract</summary>
Big data and large-scale machine learning have had a profound impact on science and engineering, particularly in fields focused on forecasting and prediction. Yet, it is still not clear how we can use the superior pattern matching abilities of machine learning models for scientific discovery. This is because the goals of machine learning and science are generally not aligned. In addition to being accurate, scientific theories must also be causally consistent with the underlying physical process and allow for human analysis, reasoning, and manipulation to advance the field. In this paper, we present a case study on discovering a new symbolic model for oceanic rogue waves from data using causal analysis, deep learning, parsimony-guided model selection, and symbolic regression. We train an artificial neural network on causal features from an extensive dataset of observations from wave buoys, while selecting for predictive performance and causal invariance. We apply symbolic regression to distill this black-box model into a mathematical equation that retains the neural network's predictive capabilities, while allowing for interpretation in the context of existing wave theory. The resulting model reproduces known behavior, generates well-calibrated probabilities, and achieves better predictive scores on unseen data than current theory. This showcases how machine learning can facilitate inductive scientific discovery, and paves the way for more accurate rogue wave forecasting.
</details>
<details>
<summary>摘要</summary>
大数据和大规模机器学习对科学和工程领域的预测和预测具有深远的影响，特别是在预测领域。然而，如何使用机器学习模型的高级模式匹配能力进行科学发现仍然不清楚。这是因为机器学习和科学的目标通常不吻合。除了准确性外，科学理论还必须满足物理过程的 causal 一致性和人类分析、逻辑和操作，以提高领域的进步。在这篇论文中，我们提出了一个案例研究，用于从数据中发现新的 симвоlic 模型，并使用 causal 分析、深度学习、parsimony-guided 模型选择和符号回归。我们将一个人工神经网络在 causal 特征上训练，并选择 predictive 性和 causal 一致性。我们通过符号回归将这个黑盒模型转化为一个可解释的数学方程，保留模型的预测能力，同时允许在现有波动理论中进行解释。结果表明，这个模型可以重现已知行为，生成准确抽象，并在未经见过的数据上达到现有理论的预测能力。这种示例演示了如何使用机器学习进行 inductive 科学发现，并为更准确的黑潮预测提供了道路。
</details></li>
</ul>
<hr>
<h2 id="BEND-Benchmarking-DNA-Language-Models-on-biologically-meaningful-tasks"><a href="#BEND-Benchmarking-DNA-Language-Models-on-biologically-meaningful-tasks" class="headerlink" title="BEND: Benchmarking DNA Language Models on biologically meaningful tasks"></a>BEND: Benchmarking DNA Language Models on biologically meaningful tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12570">http://arxiv.org/abs/2311.12570</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/frederikkemarin/bend">https://github.com/frederikkemarin/bend</a></li>
<li>paper_authors: Frederikke Isa Marin, Felix Teufel, Marc Horrender, Dennis Madsen, Dennis Pultz, Ole Winther, Wouter Boomsma</li>
<li>for: 这个论文的目的是为了评估 DNA 语言模型，以便更好地理解 genomic DNA 中的功能、非编码和规则元素。</li>
<li>methods: 该论文使用了一个名为 BEND 的 Benchmark，用于评估 DNA 语言模型。BEND 包含了一系列的真实和生物学上有意义的下游任务，这些任务是基于人类基因组。</li>
<li>results: 研究发现，当前的 DNA LM 可以在某些任务上 approached 专家方法的性能，但只能捕捉长距离特征的有限信息。<details>
<summary>Abstract</summary>
The genome sequence contains the blueprint for governing cellular processes. While the availability of genomes has vastly increased over the last decades, experimental annotation of the various functional, non-coding and regulatory elements encoded in the DNA sequence remains both expensive and challenging. This has sparked interest in unsupervised language modeling of genomic DNA, a paradigm that has seen great success for protein sequence data. Although various DNA language models have been proposed, evaluation tasks often differ between individual works, and might not fully recapitulate the fundamental challenges of genome annotation, including the length, scale and sparsity of the data. In this study, we introduce BEND, a Benchmark for DNA language models, featuring a collection of realistic and biologically meaningful downstream tasks defined on the human genome. We find that embeddings from current DNA LMs can approach performance of expert methods on some tasks, but only capture limited information about long-range features. BEND is available at https://github.com/frederikkemarin/BEND.
</details>
<details>
<summary>摘要</summary>
genomic DNA 序列中包含细胞生物学过程的蓝图。自过去几十年来， genomic DNA 的可用性有了很大的提高，但实验室标注 genomic DNA 中不同类型的功能、非编码和调控元件的 эксперименталь描述仍然是非常昂贵和困难的。这引发了人们对 genomic DNA 的无监督语言模型的兴趣，这种模型在蛋白质序列数据上已经取得了很大的成功。虽然有很多 DNA 语言模型被提出，但不同的评估任务经常存在差异，这些任务可能不能充分反映 genomic DNA 的注释挑战，包括序列长度、 масштаб和稀缺性。在本研究中，我们引入 BEND，一个基准测试集（Benchmark），其中包含人类基因组中的真实和生物学意义的下游任务。我们发现，当前的 DNA 语言模型可以在某些任务上 approached 专家方法的性能，但只能捕捉长距离特征的有限信息。 BEND 可以在 <https://github.com/frederikkemarin/BEND> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Sampling-of-Categorical-Distributions-Using-the-CatLog-Derivative-Trick"><a href="#Differentiable-Sampling-of-Categorical-Distributions-Using-the-CatLog-Derivative-Trick" class="headerlink" title="Differentiable Sampling of Categorical Distributions Using the CatLog-Derivative Trick"></a>Differentiable Sampling of Categorical Distributions Using the CatLog-Derivative Trick</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12569">http://arxiv.org/abs/2311.12569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lennert De Smet, Emanuele Sansone, Pedro Zuidberg Dos Martires</li>
<li>for: 该论文旨在提出一种基于分类随机变量的离散幂学习模型，以及一种基于这种模型的不同抽象估计器，以优化随机搜索和机器学习算法。</li>
<li>methods: 该论文使用了Log-Derivative trick来估计分类随机变量的梯度，并提出了一种基于这种技巧的新估计器 called CatLog-Derivative trick。</li>
<li>results: 该论文通过实验表明，使用CatLog-Derivative trick和IndeCateR估计器可以获得更低偏差和方差的梯度估计，并且可以快速和有效地实现。<details>
<summary>Abstract</summary>
Categorical random variables can faithfully represent the discrete and uncertain aspects of data as part of a discrete latent variable model. Learning in such models necessitates taking gradients with respect to the parameters of the categorical probability distributions, which is often intractable due to their combinatorial nature. A popular technique to estimate these otherwise intractable gradients is the Log-Derivative trick. This trick forms the basis of the well-known REINFORCE gradient estimator and its many extensions. While the Log-Derivative trick allows us to differentiate through samples drawn from categorical distributions, it does not take into account the discrete nature of the distribution itself. Our first contribution addresses this shortcoming by introducing the CatLog-Derivative trick - a variation of the Log-Derivative trick tailored towards categorical distributions. Secondly, we use the CatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient estimator for the important case of products of independent categorical distributions with provably lower variance than REINFORCE. Thirdly, we empirically show that IndeCateR can be efficiently implemented and that its gradient estimates have significantly lower bias and variance for the same number of samples compared to the state of the art.
</details>
<details>
<summary>摘要</summary>
categorical random variables 可以准确表示数据中的离散和不确定性方面，作为一种离散潜在变量模型的一部分。学习这些模型时，需要对模型中的 categorical 概率分布的参数进行梯度下降，但这通常是因为这些概率分布的 combinatorial 性而成为不可解析的。一种广泛使用的技术来估算这些不可解析的梯度是 Log-Derivative 技巧。这种技巧可以将概率分布中的样本拟合到梯度下降中，但它不考虑概率分布本身的离散性。我们的第一个贡献是提出了 CatLog-Derivative 技巧，这是 Log-Derivative 技巧的一种变种，专门针对 categorical 概率分布。其次，我们使用 CatLog-Derivative 技巧来引入 IndeCateR，一种新的、不偏的梯度估计器，用于估计独立的 categorical 概率分布中的梯度。最后，我们employned实验表明，IndeCateR 可以有效地实现，并且其梯度估计的偏差和方差比 REINFORCE 更低。
</details></li>
</ul>
<hr>
<h2 id="Variational-Elliptical-Processes"><a href="#Variational-Elliptical-Processes" class="headerlink" title="Variational Elliptical Processes"></a>Variational Elliptical Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12566">http://arxiv.org/abs/2311.12566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Bånkestad, Jens Sjölund, Jalil Taghia, Thomas B. Schöon</li>
<li>for: 这篇论文是为了描述一种新的非参数型 probabilistic 模型，它包括 Gaussian 过程和 Student’s t 过程的总结，并且包含了一些新的重 tailed 行为。</li>
<li>methods: 这篇论文使用了一种基于椭圆分布的 continuous mixture of Gaussian distributions 的表示方法，并使用了 variational inference 来参数化这种混合分布。</li>
<li>results: 论文通过 regression 和 classification  эксперименты展示了 elliptical processes 的优势，包括在非 Gaussian 的 likelihood 下和在需要精准尾部模型时的应用。<details>
<summary>Abstract</summary>
We present elliptical processes, a family of non-parametric probabilistic models that subsume Gaussian processes and Student's t processes. This generalization includes a range of new heavy-tailed behaviors while retaining computational tractability. Elliptical processes are based on a representation of elliptical distributions as a continuous mixture of Gaussian distributions. We parameterize this mixture distribution as a spline normalizing flow, which we train using variational inference. The proposed form of the variational posterior enables a sparse variational elliptical process applicable to large-scale problems. We highlight advantages compared to Gaussian processes through regression and classification experiments. Elliptical processes can supersede Gaussian processes in several settings, including cases where the likelihood is non-Gaussian or when accurate tail modeling is essential.
</details>
<details>
<summary>摘要</summary>
我们提出了椭圆过程，一种非 Parametric概率模型，包含 Gaussian 过程和 Student's t 过程的推广。这个推广包括一些新的重 tailed 行为，并保留 computationally tractable。椭圆过程基于圆形分布的连续混合，我们将这个混合分布parameterized 为 spline 正规化流，并通过 Variational inference 训练。提议的形式的 Variational posterior 使得可以实现 sparse variational elliptical process，适用于大规模问题。我们透过 regression 和 classification 实验，强调 elliptical 过程比 Gaussian 过程在一些设定中更有优势，例如非 Gaussian 的 likelihood 或精确的尾部模型是必要的情况下。
</details></li>
</ul>
<hr>
<h2 id="Summary-of-the-DISPLACE-Challenge-2023-–-DIarization-of-SPeaker-and-LAnguage-in-Conversational-Environments"><a href="#Summary-of-the-DISPLACE-Challenge-2023-–-DIarization-of-SPeaker-and-LAnguage-in-Conversational-Environments" class="headerlink" title="Summary of the DISPLACE Challenge 2023 – DIarization of SPeaker and LAnguage in Conversational Environments"></a>Summary of the DISPLACE Challenge 2023 – DIarization of SPeaker and LAnguage in Conversational Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12564">http://arxiv.org/abs/2311.12564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikha Baghel, Shreyas Ramoji, Somil Jain, Pratik Roy Chowdhuri, Prachi Singh, Deepu Vijayasenan, Sriram Ganapathy</li>
<li>for: 这个论文主要是为了描述一个多语言对话场景下的语音技术挑战（DISPLACE），以及这个挑战的评测和比较。</li>
<li>methods: 这个挑战使用了两个 tracks，一个是 speaker diarization（SD），另一个是 language diarization（LD）。 SD 和 LD 都使用了同一个原始音频数据，并提供了一个基eline系统作为参考。</li>
<li>results: 挑战共收到 $42$ 个世界各地的注册，并接受了 $19$ 个combined submissions。 paper 还提供了参与者的系统简要概述，特别是 top performing 系统。 最后，paper 还提供了 SD 和 LD 任务的未来展望，以及系统需要在这些对话中进行进一步改进的关键挑战。<details>
<summary>Abstract</summary>
In multi-lingual societies, where multiple languages are spoken in a small geographic vicinity, informal conversations often involve mix of languages. Existing speech technologies may be inefficient in extracting information from such conversations, where the speech data is rich in diversity with multiple languages and speakers. The DISPLACE (DIarization of SPeaker and LAnguage in Conversational Environments) challenge constitutes an open-call for evaluating and bench-marking the speaker and language diarization technologies on this challenging condition. The challenge entailed two tracks: Track-1 focused on speaker diarization (SD) in multilingual situations while, Track-2 addressed the language diarization (LD) in a multi-speaker scenario. Both the tracks were evaluated using the same underlying audio data. To facilitate this evaluation, a real-world dataset featuring multilingual, multi-speaker conversational far-field speech was recorded and distributed. Furthermore, a baseline system was made available for both SD and LD task which mimicked the state-of-art in these tasks. The challenge garnered a total of $42$ world-wide registrations and received a total of $19$ combined submissions for Track-1 and Track-2. This paper describes the challenge, details of the datasets, tasks, and the baseline system. Additionally, the paper provides a concise overview of the submitted systems in both tracks, with an emphasis given to the top performing systems. The paper also presents insights and future perspectives for SD and LD tasks, focusing on the key challenges that the systems need to overcome before wide-spread commercial deployment on such conversations.
</details>
<details>
<summary>摘要</summary>
在多语言社会中， где多种语言在小地理范围内被使用，日常对话经常涉及多种语言的混合。现有的语音技术可能无法有效地提取这些对话中的信息，因为语音数据具有多种语言和说话人的多样性。为解决这个挑战，DISPLACE（分类对话中的说话人和语言）挑战被发起，它是一个开源的评测和比较语音分类技术在多语言多说话人的情况下的能力的挑战。这个挑战包括了两个追踪：Track-1关注说话人分类（SD），Track-2关注语言分类（LD）。两个追踪都使用同一个基础数据集进行评测。为了促进这种评测，一个真实的多语言多说话人对话型far-field语音数据集被录制并分发。此外，一个基eline系统也被提供给SD和LD两个任务，这个系统模仿了当前状态的最佳实践。挑战共收到全球42个注册，并接收了SD和LD两个任务的总共19个合并提交。本文将介绍挑战，数据集、任务和基eline系统的细节。此外，本文还将提供对SD和LD任务的投票系统的简洁概述，强调最高排名的系统。此外，文章还提供了SD和LD任务的未来前景，强调系统需要在这些对话中解决的关键挑战，以便在商业化应用中广泛使用。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Anomaly-Detection-using-Masked-Latent-Generative-Modeling"><a href="#Explainable-Anomaly-Detection-using-Masked-Latent-Generative-Modeling" class="headerlink" title="Explainable Anomaly Detection using Masked Latent Generative Modeling"></a>Explainable Anomaly Detection using Masked Latent Generative Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12550">http://arxiv.org/abs/2311.12550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daesoo Lee, Sara Malacarne, Erlend Aune</li>
<li>for: 本研究旨在提出一种新的时间序列异常检测方法，可以提供高度的检测精度以及更高的解释性。</li>
<li>methods: 该方法基于TimeVQVAE模型，利用遮层生成模型在时间频域中进行掩码学习，保留时间频域的维度 semantics，从而在不同的频率带上计算异常分数，提供更好的异常检测 Insight。</li>
<li>results: 我们在UCR时间序列异常架构上进行实验，发现TimeVQVAE-AD方法在检测精度和解释性两个方面均与现有方法有显著的优势。<details>
<summary>Abstract</summary>
We present a novel time series anomaly detection method that achieves excellent detection accuracy while offering a superior level of explainability. Our proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted from the cutting-edge time series generation method known as TimeVQVAE. The prior model is trained on the discrete latent space of a time-frequency domain. Notably, the dimensional semantics of the time-frequency domain are preserved in the latent space, enabling us to compute anomaly scores across different frequency bands, which provides a better insight into the detected anomalies. Additionally, the generative nature of the prior model allows for sampling likely normal states for detected anomalies, enhancing the explainability of the detected anomalies through counterfactuals. Our experimental evaluation on the UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD significantly surpasses the existing methods in terms of detection accuracy and explainability.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的时间序列异常检测方法，可以具有优秀的检测精度和更高的解释性。我们的提议方法，TimeVQVAE-AD，利用了masked生成模型，这种技术来自于时间序列生成领域的前沿方法TimeVQVAE。先前模型在时间频率域的离散内存空间进行训练，其中保留了时间频率域的维度 semantics，因此可以在不同的频率带上计算异常分数，提供更好的异常检测结果的解释。此外，生成性的先前模型允许对检测到的异常进行采样，从而提高了异常检测结果的解释性。我们对UCRC时间序列异常架构的实验表明，TimeVQVAE-AD在检测精度和解释性两个方面与现有方法有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="An-efficient-likelihood-free-Bayesian-inference-method-based-on-sequential-neural-posterior-estimation"><a href="#An-efficient-likelihood-free-Bayesian-inference-method-based-on-sequential-neural-posterior-estimation" class="headerlink" title="An efficient likelihood-free Bayesian inference method based on sequential neural posterior estimation"></a>An efficient likelihood-free Bayesian inference method based on sequential neural posterior estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12530">http://arxiv.org/abs/2311.12530</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Yifei-Xiong/Efficient-SNPE">https://github.com/Yifei-Xiong/Efficient-SNPE</a></li>
<li>paper_authors: Yifei Xiong, Xiliang Yang, Sanguo Zhang, Zhijian He</li>
<li>for: 这paper是为了解决基于 simulations的模型难以求解的 posterior estimation问题而提出的新技术。</li>
<li>methods: 这paper使用Sequential Neural Posterior Estimation（SNPE）技术，其中使用神经网络来Estimate the conditional density of the posterior distribution。</li>
<li>results: 这paper提出了一种改进SNPE-B方法，通过使用适应抑制kernel来提高数据效率，并提供了关于相关 Monte Carlo estimators的理论分析。numerical experiments表明，这种方法在某些任务上比原始方法和其他现有竞争者更高效。<details>
<summary>Abstract</summary>
Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. Unlike approximate Bayesian computation, SNPE techniques learn the posterior from sequential simulation using neural network-based conditional density estimators. This paper reclaims SNPE-B proposed by Lueckmann et al. (2017), which suffers from inefficiency and slow inference due to inefficient utilization of simulated data and high variance of parameter updates. To address these issues, we firstly introduce a concentrated loss function based on an adaptive calibration kernel that reweights the simulated data appropriately to improve the data efficiency. Moreover, we provide a theoretical analysis of the variance of associated Monte Carlo estimators. Based on this analysis, we then propose several variance reduction techniques to further accelerate the process of learning. Numerical experiments demonstrate that our method outperforms the original method together with other existing competitors on certain tasks.
</details>
<details>
<summary>摘要</summary>
带有序列隐藏 posterior 估计（SNPE）技术最近被提出用于处理基于模拟的模型，其具有不可解析的 posterior 隐藏。不同于approximate Bayesian computation，SNPE 技术从序列模拟中学习 posterior，使用神经网络基于的假设概率分布Estimator。本文重新提出了Lueckmann等人（2017）提出的SNPE-B方法，该方法受到效率低下和参数更新的高方差影响。为解决这些问题，我们首先引入一种集中损失函数，基于适应calibration kernel来重新权重适用的模拟数据，从而提高数据效率。此外，我们还提供了关于相关 Monte Carlo 估计的理论分析。基于这个分析，我们然后提出了一些减少幂度的技巧，以进一步加速学习过程。 numerically experiments表明，我们的方法在某些任务上高于原始方法和其他现有竞争者。
</details></li>
</ul>
<hr>
<h2 id="Inverse-Problems-with-Learned-Forward-Operators"><a href="#Inverse-Problems-with-Learned-Forward-Operators" class="headerlink" title="Inverse Problems with Learned Forward Operators"></a>Inverse Problems with Learned Forward Operators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12528">http://arxiv.org/abs/2311.12528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Arridge, Andreas Hauptmann, Yury Korolev</li>
<li>for:  inverse problems reconstruction with learned forward operators</li>
<li>methods: completely agnostic to the forward operator, learns its restriction to the subspace spanned by the training data, and regularisation by projection; uses a simplified model of the physics of the measurement process and only relies on the training data to learn a model correction.</li>
<li>results: both methods require, or at least benefit from, training data not only for the forward operator, but also for its adjoint.Here’s the format you requested:</li>
<li>for:  inverse problems reconstruction with learned forward operators</li>
<li>methods: 完全不知道前进Operator的方法，包括学习其 restriction 到训练数据中的子空间，以及使用 regularisation by projection; 使用简化的测量过程物理模型，只凭借训练数据来学习模型更正。</li>
<li>results: 两种方法都需要、或至少受益于，训练数据不仅 для前进Operator，还 для其 adj。<details>
<summary>Abstract</summary>
Solving inverse problems requires knowledge of the forward operator, but accurate models can be computationally expensive and hence cheaper variants are desired that do not compromise reconstruction quality. This chapter reviews reconstruction methods in inverse problems with learned forward operators that follow two different paradigms. The first one is completely agnostic to the forward operator and learns its restriction to the subspace spanned by the training data. The framework of regularisation by projection is then used to find a reconstruction. The second one uses a simplified model of the physics of the measurement process and only relies on the training data to learn a model correction. We present the theory of these two approaches and compare them numerically. A common theme emerges: both methods require, or at least benefit from, training data not only for the forward operator, but also for its adjoint.
</details>
<details>
<summary>摘要</summary>
解决反向问题需要对前进Operator有知识，但高精度的模型可能是计算成本高昂的。这章简要介绍了使用学习前进Operator的恢复方法。这两种方法都遵循两种不同的思想。第一种是完全不知前进Operator，通过限制到训练数据所 span 的子空间来学习其 restriction。然后使用常规化by projection来找到恢复。第二种使用测量过程的物理模型的简化版本，只靠训练数据来学习一个模型修正。我们提出了这两种方法的理论基础，并对其进行了数值比较。一个共同之处发现：两种方法都需要或至少受益于训练数据不仅 для前进Operator，还 für其 adj 。
</details></li>
</ul>
<hr>
<h2 id="Fair-Polylog-Approximate-Low-Cost-Hierarchical-Clustering"><a href="#Fair-Polylog-Approximate-Low-Cost-Hierarchical-Clustering" class="headerlink" title="Fair Polylog-Approximate Low-Cost Hierarchical Clustering"></a>Fair Polylog-Approximate Low-Cost Hierarchical Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12501">http://arxiv.org/abs/2311.12501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marina Knittel, Max Springer, John Dickerson, MohammadTaghi Hajiaghayi</li>
<li>for: 研究公平机器学习和特别是归一化，在过去几年内得到了更多的关注，因为现代智能系统在伦理上引起了许多争议。</li>
<li>methods:  Ahmedian等人（2020）在归一化 clustering 中研究了公平性，这是Well-known flat counterpart的更强大、更结构化的变体，但他们提出的算法仍然很理论性。</li>
<li>results: Knittel等人（2023）then proposed the first practical fair approximation for cost, but they were unable to break the polynomial-approximate barrier they posed as a hurdle of interest. 我们破坏了这个障碍，提出了首个真正的多逻论拟合低成本公平归一化 clustering，从而在最佳公平和普通归一化 clustering approximations之间大幅度减少了差距。<details>
<summary>Abstract</summary>
Research in fair machine learning, and particularly clustering, has been crucial in recent years given the many ethical controversies that modern intelligent systems have posed. Ahmadian et al. [2020] established the study of fairness in \textit{hierarchical} clustering, a stronger, more structured variant of its well-known flat counterpart, though their proposed algorithm that optimizes for Dasgupta's [2016] famous cost function was highly theoretical. Knittel et al. [2023] then proposed the first practical fair approximation for cost, however they were unable to break the polynomial-approximate barrier they posed as a hurdle of interest. We break this barrier, proposing the first truly polylogarithmic-approximate low-cost fair hierarchical clustering, thus greatly bridging the gap between the best fair and vanilla hierarchical clustering approximations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-Objective-Reinforcement-Learning-based-on-Decomposition-A-taxonomy-and-framework"><a href="#Multi-Objective-Reinforcement-Learning-based-on-Decomposition-A-taxonomy-and-framework" class="headerlink" title="Multi-Objective Reinforcement Learning based on Decomposition: A taxonomy and framework"></a>Multi-Objective Reinforcement Learning based on Decomposition: A taxonomy and framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12495">http://arxiv.org/abs/2311.12495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lucasalegre/morl-baselines">https://github.com/lucasalegre/morl-baselines</a></li>
<li>paper_authors: Florian Felten, El-Ghazali Talbi, Grégoire Danoy</li>
<li>for: 本文旨在探讨多目标强化学习（MORL）的研究，它扩展了传统的强化学习（RL），通过在不同目标之间做出不同的妥协来寻找策略。</li>
<li>methods: 本文使用了多对多对象优化（MOO&#x2F;D）的方法，提供了一种基于分解的多对象强化学习方法（MORL&#x2F;D），并提出了一个完整的分类方法，以便对现有和潜在的MORL研究进行分类。</li>
<li>results: 本文通过使用不同的实例和工具来证明MORL&#x2F;D的灵活性和可靠性，并证明了MORL&#x2F;D实例可以与当前状态对策案相比赢得比较出色的性能。<details>
<summary>Abstract</summary>
Multi-objective reinforcement learning (MORL) extends traditional RL by seeking policies making different compromises among conflicting objectives. The recent surge of interest in MORL has led to diverse studies and solving methods, often drawing from existing knowledge in multi-objective optimization based on decomposition (MOO/D). Yet, a clear categorization based on both RL and MOO/D is lacking in the existing literature. Consequently, MORL researchers face difficulties when trying to classify contributions within a broader context due to the absence of a standardized taxonomy. To tackle such an issue, this paper introduces Multi-Objective Reinforcement Learning based on Decomposition (MORL/D), a novel methodology bridging RL and MOO literature. A comprehensive taxonomy for MORL/D is presented, providing a structured foundation for categorizing existing and potential MORL works. The introduced taxonomy is then used to scrutinize MORL research, enhancing clarity and conciseness through well-defined categorization. Moreover, a flexible framework derived from the taxonomy is introduced. This framework accommodates diverse instantiations using tools from both RL and MOO/D. Implementation across various configurations demonstrates its versatility, assessed against benchmark problems. Results indicate MORL/D instantiations achieve comparable performance with significantly greater versatility than current state-of-the-art approaches. By presenting the taxonomy and framework, this paper offers a comprehensive perspective and a unified vocabulary for MORL. This not only facilitates the identification of algorithmic contributions but also lays the groundwork for novel research avenues in MORL, contributing to the continued advancement of this field.
</details>
<details>
<summary>摘要</summary>
多目标强化学习（MORL）扩展了传统的强化学习，寻找既能够满足多个矛盾的目标的策略。在最近几年，关于MORL的研究得到了广泛的关注，并且有多种研究方法和解决方案， часто借鉴了现有的多目标优化基于分解（MOO/D）的知识。然而，现有文献中对MORL的分类是缺乏标准化的，这使得MORL研究人员在归类研究时遇到困难，因为缺乏一个普遍的分类体系。为解决这个问题，这篇论文提出了基于分解的多目标强化学习（MORL/D），一种新的方法olojy，将RL和MOO/D两个领域的知识相结合。本论文还提出了一个完整的分类体系，用于ategorizing现有和 potential的MORL工作。这个分类体系的引入，使得MORL研究更加明了清晰，并且通过定义了分类，提高了研究的 conciseness。此外，本论文还提出了一个灵活的框架，该框架可以适应不同的实现方式，并且可以通过RL和MOO/D两个领域中的工具来实现。在多种配置下进行实现，这个框架的灵活性得到了证明，并且与当前状态的艺术方法相比，其实现的性能相对较高。通过提出分类体系和框架，本论文不仅为MORL提供了一个全面的视角，还为这一领域的进一步发展奠定了基础。
</details></li>
</ul>
<hr>
<h2 id="Heuristics-for-Detecting-CoinJoin-Transactions-on-the-Bitcoin-Blockchain"><a href="#Heuristics-for-Detecting-CoinJoin-Transactions-on-the-Bitcoin-Blockchain" class="headerlink" title="Heuristics for Detecting CoinJoin Transactions on the Bitcoin Blockchain"></a>Heuristics for Detecting CoinJoin Transactions on the Bitcoin Blockchain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12491">http://arxiv.org/abs/2311.12491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hugo Schnoering, Michalis Vazirgiannis</li>
<li>for: 本研究探讨比特币的隐私保护问题，尤其是用户采用CoinJoin技术来增强交易隐私。</li>
<li>methods: 本研究使用了开源实现的JoinMarket、Wasabi和Whirlpool协议来分析CoinJoin交易的特点和难点。</li>
<li>results: 研究对比特币区块chain进行了深入分析，并开发了更加精准的钱包分析技术，以便更好地识别CoinJoin交易。<details>
<summary>Abstract</summary>
This research delves into the intricacies of Bitcoin, a decentralized peer-to-peer network, and its associated blockchain, which records all transactions since its inception. While this ensures integrity and transparency, the transparent nature of Bitcoin potentially compromises users' privacy rights. To address this concern, users have adopted CoinJoin, a method that amalgamates multiple transaction intents into a single, larger transaction to bolster transactional privacy. This process complicates individual transaction tracing and disrupts many established blockchain analysis heuristics. Despite its significance, limited research has been conducted on identifying CoinJoin transactions. Particularly noteworthy are varied CoinJoin implementations such as JoinMarket, Wasabi, and Whirlpool, each presenting distinct challenges due to their unique transaction structures. This study delves deeply into the open-source implementations of these protocols, aiming to develop refined heuristics for identifying their transactions on the blockchain. Our exhaustive analysis covers transactions up to block 760,000, offering a comprehensive insight into CoinJoin transactions and their implications for Bitcoin blockchain analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Harnessing-FPGA-Technology-for-Enhanced-Biomedical-Computation"><a href="#Harnessing-FPGA-Technology-for-Enhanced-Biomedical-Computation" class="headerlink" title="Harnessing FPGA Technology for Enhanced Biomedical Computation"></a>Harnessing FPGA Technology for Enhanced Biomedical Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12439">http://arxiv.org/abs/2311.12439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nisanur Alici, Kayode Inadagbo, Murat Isik</li>
<li>for: 这个研究探讨了使用Field Programmable Gate Arrays (FPGAs)来提高心电图信号分析的复杂神经网络框架，包括卷积神经网络 (CNN)、循环神经网络 (RNN)、Long Short-Term Memory Networks (LSTMs) 和 Deep Belief Networks (DBNs)。</li>
<li>methods: 这个研究使用了MIT-BIH 心电图数据库作为训练和评估模型的基础，并添加了 Gaussian 噪声以提高算法的抗耗性。研究者们设计了具有特定处理和分类功能的层，并使用了 EarlyStopping 回调函数和 Dropout 层来避免过拟合。此外，这篇论文还详细介绍了如何使用 Tensor Compute Unit (TCU) 加速器来实现PYNQ Z1 平台上的FPGA-based 机器学习。</li>
<li>results: 研究者们通过评估性能指标如响应时间和通过率来证明 FPGAs 在生物医学计算中的高效性。这篇论文最终成为了FPGA-based 机器学习的全面指南，涵盖了模型配置、Tensil 工具链的 Docker 配置、PS-PL 配置和模型编译和部署等方面。<details>
<summary>Abstract</summary>
This research delves into sophisticated neural network frameworks like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for improved analysis of ECG signals via Field Programmable Gate Arrays (FPGAs). The MIT-BIH Arrhythmia Database serves as the foundation for training and evaluating our models, with added Gaussian noise to heighten the algorithms' resilience. The developed architectures incorporate various layers for specific processing and categorization functions, employing strategies such as the EarlyStopping callback and Dropout layer to prevent overfitting. Additionally, this paper details the creation of a tailored Tensor Compute Unit (TCU) accelerator for the PYNQ Z1 platform. It provides a thorough methodology for implementing FPGA-based machine learning, encompassing the configuration of the Tensil toolchain in Docker, selection of architectures, PS-PL configuration, and the compilation and deployment of models. By evaluating performance indicators like latency and throughput, we showcase the efficacy of FPGAs in advanced biomedical computing. This study ultimately serves as a comprehensive guide to optimizing neural network operations on FPGAs across various fields.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Classifier-Calibration-with-ROC-Regularized-Isotonic-Regression"><a href="#Classifier-Calibration-with-ROC-Regularized-Isotonic-Regression" class="headerlink" title="Classifier Calibration with ROC-Regularized Isotonic Regression"></a>Classifier Calibration with ROC-Regularized Isotonic Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12436">http://arxiv.org/abs/2311.12436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eugene Berta, Francis Bach, Michael Jordan</li>
<li>for: 本研究旨在提高机器学习分类器的可靠性和可解释性，使模型信任度和实际概率之间bridge gap。</li>
<li>methods: 本文提出了一种常见技术——iso逻辑回归（IR），用于calibrating binary classifiers，通过MONOTONE TRANSFORMATIONS来减少cross entropy损失。</li>
<li>results: 本文首次证明了IR preserved the convex hull of the ROC curve，保证了分类器的calibration while controlling for overfitting of the calibration set。此外，本文还提出了一种扩展IR来Accommodate K类分类器，并通过加入多维度的adaptive binning scheme来实现多类calibration error equal to zero。<details>
<summary>Abstract</summary>
Calibration of machine learning classifiers is necessary to obtain reliable and interpretable predictions, bridging the gap between model confidence and actual probabilities. One prominent technique, isotonic regression (IR), aims at calibrating binary classifiers by minimizing the cross entropy on a calibration set via monotone transformations. IR acts as an adaptive binning procedure, which allows achieving a calibration error of zero, but leaves open the issue of the effect on performance. In this paper, we first prove that IR preserves the convex hull of the ROC curve -- an essential performance metric for binary classifiers. This ensures that a classifier is calibrated while controlling for overfitting of the calibration set. We then present a novel generalization of isotonic regression to accommodate classifiers with K classes. Our method constructs a multidimensional adaptive binning scheme on the probability simplex, again achieving a multi-class calibration error equal to zero. We regularize this algorithm by imposing a form of monotony that preserves the K-dimensional ROC surface of the classifier. We show empirically that this general monotony criterion is effective in striking a balance between reducing cross entropy loss and avoiding overfitting of the calibration set.
</details>
<details>
<summary>摘要</summary>
���ط�calibration of machine learning classifiers is necessary to obtain reliable and interpretable predictions, bridging the gap between model confidence and actual probabilities. One prominent technique, isotonic regression (IR), aims at calibrating binary classifiers by minimizing the cross entropy on a calibration set via monotone transformations. IR acts as an adaptive binning procedure, which allows achieving a calibration error of zero, but leaves open the issue of the effect on performance. In this paper, we first prove that IR preserves the convex hull of the ROC curve -- an essential performance metric for binary classifiers. This ensures that a classifier is calibrated while controlling for overfitting of the calibration set. We then present a novel generalization of isotonic regression to accommodate classifiers with K classes. Our method constructs a multidimensional adaptive binning scheme on the probability simplex, again achieving a multi-class calibration error equal to zero. We regularize this algorithm by imposing a form of monotony that preserves the K-dimensional ROC surface of the classifier. We show empirically that this general monotony criterion is effective in striking a balance between reducing cross entropy loss and avoiding overfitting of the calibration set.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Looped-Transformers-are-Better-at-Learning-Learning-Algorithms"><a href="#Looped-Transformers-are-Better-at-Learning-Learning-Algorithms" class="headerlink" title="Looped Transformers are Better at Learning Learning Algorithms"></a>Looped Transformers are Better at Learning Learning Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12424">http://arxiv.org/abs/2311.12424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liu Yang, Kangwook Lee, Robert Nowak, Dimitris Papailiopoulos</li>
<li>for: 解决各种数据适应问题</li>
<li>methods: 使用循环转换器架构和相关训练方法，具有迭代特性</li>
<li>results: 实验结果表明，使用循环转换器可以与标准转换器相比，在解决不同数据适应问题时达到相似的性能水平，而且参数计数少于10%。<details>
<summary>Abstract</summary>
Transformers have demonstrated effectiveness in \emph{in-context solving} data-fitting problems from various (latent) models, as reported by Garg et al. However, the absence of an inherent iterative structure in the transformer architecture presents a challenge in emulating the iterative algorithms, which are commonly employed in traditional machine learning methods. To address this, we propose the utilization of \emph{looped} transformer architecture and its associated training methodology, with the aim of incorporating iterative characteristics into the transformer architectures. Experimental results suggest that the looped transformer achieves performance comparable to the standard transformer in solving various data-fitting problems, while utilizing less than 10\% of the parameter count.
</details>
<details>
<summary>摘要</summary>
Transformers 已经证明在各种模型的 \emph{域内解决} 问题上表现出色，据gart等人的报道。然而，transformer 架构缺乏自身迭代结构，这使得模仿传统机器学习方法中常用的迭代算法变得困难。为解决这个问题，我们提议利用 \emph{循环} transformer 架构和其相关的训练方法，以实现将迭代特性引入 transformer 架构中。实验结果表明，循环 transformer 可以与标准 transformer 相比，在解决多种数据适应问题上达到相似的表现，同时使用参数计数少于 10%。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-via-Consensus-Mechanism-on-Heterogeneous-Data-A-New-Perspective-on-Convergence"><a href="#Federated-Learning-via-Consensus-Mechanism-on-Heterogeneous-Data-A-New-Perspective-on-Convergence" class="headerlink" title="Federated Learning via Consensus Mechanism on Heterogeneous Data: A New Perspective on Convergence"></a>Federated Learning via Consensus Mechanism on Heterogeneous Data: A New Perspective on Convergence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12358">http://arxiv.org/abs/2311.12358</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fedcome/fedcome">https://github.com/fedcome/fedcome</a></li>
<li>paper_authors: Shu Zheng, Tiandi Ye, Xiang Li, Ming Gao</li>
<li>for: This paper focuses on addressing the risk decrease for each client in federated learning (FL) on heterogeneous data (non-IID data).</li>
<li>methods: The proposed method, FedCOME, introduces a consensus mechanism to enforce decreased risk for each client after each training round. The consensus mechanism allows for a slight adjustment to a client’s gradient on the server side, which generates an acute angle between the corrected gradient and the original ones of other clients.</li>
<li>results: The authors theoretically show that the consensus mechanism can guarantee the convergence of the global objective. They also devise a novel client sampling strategy to select the most representative clients for the global data distribution, which leads to risk decrease for clients that are not selected. The experiments on four benchmark datasets demonstrate the superiority of FedCOME against other state-of-the-art methods in terms of effectiveness, efficiency, and fairness.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文关注在 federated learning（FL）中处理异步数据（非同一样本）中每个客户端的风险减少。</li>
<li>methods: 提议的方法是 FedCOME，它引入了一种协议来确保每个客户端的风险减少。该协议允许服务器端对客户端的Gradient进行微小调整，以生成客户端Gradient与其他客户端Gradient的锐角。</li>
<li>results: 作者们 theoretically 表明，该协议可以保证全局目标的整合。它们还提出了一种选择最 Representative 的客户端来实现全局数据分布的抽样，这可以使得不被选择的客户端也能够得到风险减少。实验表明，FedCOME 在四个 benchmark 数据集上表现出了与其他状态理想方法相比的优势，包括有效性、效率和公平性。为了促进重复性，作者们将源代码公开发布在 GitHub 上：\url{<a target="_blank" rel="noopener" href="https://github.com/fedcome/fedcome%7D">https://github.com/fedcome/fedcome}</a>.<details>
<summary>Abstract</summary>
Federated learning (FL) on heterogeneous data (non-IID data) has recently received great attention. Most existing methods focus on studying the convergence guarantees for the global objective. While these methods can guarantee the decrease of the global objective in each communication round, they fail to ensure risk decrease for each client. In this paper, to address the problem,we propose FedCOME, which introduces a consensus mechanism to enforce decreased risk for each client after each training round. In particular, we allow a slight adjustment to a client's gradient on the server side, which generates an acute angle between the corrected gradient and the original ones of other clients. We theoretically show that the consensus mechanism can guarantee the convergence of the global objective. To generalize the consensus mechanism to the partial participation FL scenario, we devise a novel client sampling strategy to select the most representative clients for the global data distribution. Training on these selected clients with the consensus mechanism could empirically lead to risk decrease for clients that are not selected. Finally, we conduct extensive experiments on four benchmark datasets to show the superiority of FedCOME against other state-of-the-art methods in terms of effectiveness, efficiency and fairness. For reproducibility, we make our source code publicly available at: \url{https://github.com/fedcome/fedcome}.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) on 异步数据 (异步数据) 在最近几年内得到了广泛关注。大多数现有方法都是研究 global 目标的收敛保证。而这些方法可以保证每个通信轮次中 global 目标的减少，但它们无法确保每个客户端上的风险减少。在本文中，我们提出了 FedCOME，它引入了一种协调机制，以确保每个客户端上的风险减少。具体来说，我们在服务器端对客户端的梯度进行了微小调整，这会在客户端的原始梯度和其他客户端的梯度之间生成一个锐角。我们理论上表明，协调机制可以确保 global 目标的收敛。为普遍化协调机制，我们提出了一种新的客户端采样策略，可以选择符合全局数据分布的最佳客户端。通过在这些选择的客户端上使用协调机制，我们可以实际地观察到非选择客户端上的风险减少。最后，我们在四个 benchmark 数据集上进行了广泛的实验，并证明 FedCOME 在效iveness、效率和公平性等方面比其他当前状态的方法更为优秀。为确保可重复性，我们在 GitHub 上公开了我们的源代码，具体地址为：\url{https://github.com/fedcome/fedcome}.
</details></li>
</ul>
<hr>
<h2 id="Random-Linear-Projections-Loss-for-Hyperplane-Based-Optimization-in-Regression-Neural-Networks"><a href="#Random-Linear-Projections-Loss-for-Hyperplane-Based-Optimization-in-Regression-Neural-Networks" class="headerlink" title="Random Linear Projections Loss for Hyperplane-Based Optimization in Regression Neural Networks"></a>Random Linear Projections Loss for Hyperplane-Based Optimization in Regression Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12356">http://arxiv.org/abs/2311.12356</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahmedaloui1997/randomlinearprojections">https://github.com/ahmedaloui1997/randomlinearprojections</a></li>
<li>paper_authors: Shyam Venkatasubramanian, Ahmed Aloui, Vahid Tarokh</li>
<li>for: 降低适束神经网络的过拟合</li>
<li>methods: 使用乱散直线对应（Random Linear Projections，RLP）损失函数</li>
<li>results: 比起均方误（MSE）损失函数，使用RLP损失函数可以提高神经网络的表现，需要 fewer data samples，具有更好的响应性和更好的类别误差特征。<details>
<summary>Abstract</summary>
Despite their popularity across a wide range of domains, regression neural networks are prone to overfitting complex datasets. In this work, we propose a loss function termed Random Linear Projections (RLP) loss, which is empirically shown to mitigate overfitting. With RLP loss, the distance between sets of hyperplanes connecting fixed-size subsets of the neural network's feature-prediction pairs and feature-label pairs is minimized. The intuition behind this loss derives from the notion that if two functions share the same hyperplanes connecting all subsets of feature-label pairs, then these functions must necessarily be equivalent. Our empirical studies, conducted across benchmark datasets and representative synthetic examples, demonstrate the improvements of the proposed RLP loss over mean squared error (MSE). Specifically, neural networks trained with the RLP loss achieve better performance while requiring fewer data samples and are more robust to additive noise. We provide theoretical analysis supporting our empirical findings.
</details>
<details>
<summary>摘要</summary>
尽管归 regression 神经网络广泛应用于多个领域，但它们仍然容易过拟合复杂的数据集。在这项工作中，我们提出了一种名为随机直线 проекции（RLP）损失函数，可以 empirically 验证其能够 mitigate 过拟合。RLP 损失函数的INTUITION 是，如果两个函数共享所有subsets of 神经网络的 feature-label pairs 的 hyperplanes，则这两个函数必然相同。我们的实验研究，在标准数据集和代表性的 sintetic 示例中，表明提出的 RLP 损失函数可以提高 neural network 的性能，需要 fewer data samples，并且更敏感于添加itive noise。我们还提供了理论分析，支持我们的实验结果。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Ordinary-Differential-Equations-based-method-for-Collaborative-Filtering"><a href="#Graph-Neural-Ordinary-Differential-Equations-based-method-for-Collaborative-Filtering" class="headerlink" title="Graph Neural Ordinary Differential Equations-based method for Collaborative Filtering"></a>Graph Neural Ordinary Differential Equations-based method for Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12329">http://arxiv.org/abs/2311.12329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Xu, Yuanjie Zhu, Weizhi Zhang, Philip S. Yu</li>
<li>for: 提高 collaborative filtering 的效果和效率，适用于实际世界中的应用。</li>
<li>methods: 基于 Graph Neural Ordinary Differential Equation (GODE) 模型，可以跳过多层 Graph Convolutional Networks (GCN) 层，从而避免创建多个层。</li>
<li>results: 在多个 datasets 上进行了实验，比较了 GODE-CF 模型与其他竞争对手模型，结果显示 GODE-CF 模型能够超越竞争对手模型，并且具有简单、高效的特点。<details>
<summary>Abstract</summary>
Graph Convolution Networks (GCNs) are widely considered state-of-the-art for collaborative filtering. Although several GCN-based methods have been proposed and achieved state-of-the-art performance in various tasks, they can be computationally expensive and time-consuming to train if too many layers are created. However, since the linear GCN model can be interpreted as a differential equation, it is possible to transfer it to an ODE problem. This inspired us to address the computational limitations of GCN-based models by designing a simple and efficient NODE-based model that can skip some GCN layers to reach the final state, thus avoiding the need to create many layers. In this work, we propose a Graph Neural Ordinary Differential Equation-based method for Collaborative Filtering (GODE-CF). This method estimates the final embedding by utilizing the information captured by one or two GCN layers. To validate our approach, we conducted experiments on multiple datasets. The results demonstrate that our model outperforms competitive baselines, including GCN-based models and other state-of-the-art CF methods. Notably, our proposed GODE-CF model has several advantages over traditional GCN-based models. It is simple, efficient, and has a fast training time, making it a practical choice for real-world situations.
</details>
<details>
<summary>摘要</summary>
graph convolutional networks (GCNs) 广泛被认为是现状顶尖的 collaborative filtering (CF) 方法。 although several GCN-based methods have been proposed and achieved state-of-the-art performance in various tasks, they can be computationally expensive and time-consuming to train if too many layers are created. however, since the linear GCN model can be interpreted as a differential equation, it is possible to transfer it to an ODE problem. this inspired us to address the computational limitations of GCN-based models by designing a simple and efficient NODE-based model that can skip some GCN layers to reach the final state, thus avoiding the need to create many layers. in this work, we propose a graph neural ordinary differential equation-based method for collaborative filtering (goode-cf). this method estimates the final embedding by utilizing the information captured by one or two GCN layers. to validate our approach, we conducted experiments on multiple datasets. the results demonstrate that our model outperforms competitive baselines, including GCN-based models and other state-of-the-art CF methods. notably, our proposed GODE-CF model has several advantages over traditional GCN-based models. it is simple, efficient, and has a fast training time, making it a practical choice for real-world situations.
</details></li>
</ul>
<hr>
<h2 id="Power-grid-operational-risk-assessment-using-graph-neural-network-surrogates"><a href="#Power-grid-operational-risk-assessment-using-graph-neural-network-surrogates" class="headerlink" title="Power grid operational risk assessment using graph neural network surrogates"></a>Power grid operational risk assessment using graph neural network surrogates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12309">http://arxiv.org/abs/2311.12309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yadong Zhang, Pranav M Karve, Sankaran Mahadevan</li>
<li>For:  This paper investigates the use of graph neural networks (GNNs) as proxies for power grid operational decision-making algorithms (optimal power flow (OPF) and security-constrained unit commitment (SCUC)) to enable risk quantification.* Methods: The paper uses Monte Carlo (MC) samples drawn from spatio-temporally correlated stochastic grid variables to train GNN models, and evaluates their performance in predicting quantities of interest (QoIs) derived from decision variables in OPF and SCUC.* Results: The paper shows that GNNs are capable of providing fast and accurate predictions of QoIs, and have the potential to be applied in real-time and hours-ahead risk quantification. The excellent accuracy of GNN-based reliability and risk assessment suggests that GNN surrogate models can be used for OPF and SCUC.<details>
<summary>Abstract</summary>
We investigate the utility of graph neural networks (GNNs) as proxies of power grid operational decision-making algorithms (optimal power flow (OPF) and security-constrained unit commitment (SCUC)) to enable rigorous quantification of the operational risk. To conduct principled risk analysis, numerous Monte Carlo (MC) samples are drawn from the (foretasted) probability distributions of spatio-temporally correlated stochastic grid variables. The corresponding OPF and SCUC solutions, which are needed to quantify the risk, are generated using traditional OPF and SCUC solvers to generate data for training GNN model(s). The GNN model performance is evaluated in terms of the accuracy of predicting quantities of interests (QoIs) derived from the decision variables in OPF and SCUC. Specifically, we focus on thermal power generation and load shedding at system and individual zone level. We also perform reliability and risk quantification based on GNN predictions and compare with that obtained from OPF/SCUC solutions. Our results demonstrate that GNNs are capable of providing fast and accurate prediction of QoIs and thus can be good surrogate models for OPF and SCUC. The excellent accuracy of GNN-based reliability and risk assessment further suggests that GNN surrogate has the potential to be applied in real-time and hours-ahead risk quantification.
</details>
<details>
<summary>摘要</summary>
我们研究图 neural network (GNN) 作为电力网运行决策算法（最优电力流动（OPF）和安全约束单机制（SCUC））的代理，以便进行科学的风险评估。为了进行原则性的风险分析，我们从 spatio-temporally 相关的随机Grid变量中采样了多个 Monte Carlo（MC）样本。对应的 OPF 和 SCUC 解决方案，需要用传统的 OPF 和 SCUC 解决方案来生成数据用于训练 GNN 模型。GNN 模型性能被评估基于对决变量中的量 Of interests（QoIs）的准确预测。我们主要关注系统和个别区域热电力生产和减充。我们还进行了基于 GNN 预测的可靠性和风险评估，并与 OPF/SCUC 解决方案中的风险评估进行比较。我们的结果表明，GNN 可以提供快速和准确的 QoIs 预测，因此可以作为 OPF 和 SCUC 的代理模型。GNN 模型的可靠性和风险评估准确性还表明了它的应用潜在性在实时和多小时风险评估中。
</details></li>
</ul>
<hr>
<h2 id="Mapping-“Brain-Coral”-Regions-on-Mars-using-Deep-Learning"><a href="#Mapping-“Brain-Coral”-Regions-on-Mars-using-Deep-Learning" class="headerlink" title="Mapping “Brain Coral” Regions on Mars using Deep Learning"></a>Mapping “Brain Coral” Regions on Mars using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12292">http://arxiv.org/abs/2311.12292</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pearsonkyle/mars-brain-coral-network">https://github.com/pearsonkyle/mars-brain-coral-network</a></li>
<li>paper_authors: Kyle A. Pearson, Eldar Noe, Daniel Zhao, Alphan Altinok, Alex Morgan</li>
<li>for:  Mars Exploration Program aims to search for evidence of past or current life on the planet, specifically focusing on regions with liquid or frozen water.</li>
<li>methods: The paper uses convolutional neural networks (CNNs) to detect surface regions containing “Brain Coral” terrain, which may have formed as a consequence of freeze&#x2F;thaw cycles. The authors use large images from the Mars Reconnaissance Orbiter and leverage a classifier network in the Fourier domain to expedite the processing.</li>
<li>results: The authors found detections in over 200 images and maintained an accuracy of ~93% while reducing the processing time by ~95% compared to running the segmentation network at the full resolution on every image. The segmentation masks and source code are available on Github for the community to explore and build upon.<details>
<summary>Abstract</summary>
One of the main objectives of the Mars Exploration Program is to search for evidence of past or current life on the planet. To achieve this, Mars exploration has been focusing on regions that may have liquid or frozen water. A set of critical areas may have seen cycles of ice thawing in the relatively recent past in response to periodic changes in the obliquity of Mars. In this work, we use convolutional neural networks to detect surface regions containing "Brain Coral" terrain, a landform on Mars whose similarity in morphology and scale to sorted stone circles on Earth suggests that it may have formed as a consequence of freeze/thaw cycles. We use large images (~100-1000 megapixels) from the Mars Reconnaissance Orbiter to search for these landforms at resolutions close to a few tens of centimeters per pixel (~25--50 cm). Over 52,000 images (~28 TB) were searched (~5% of the Martian surface) where we found detections in over 200 images. To expedite the processing we leverage a classifier network (prior to segmentation) in the Fourier domain that can take advantage of JPEG compression by leveraging blocks of coefficients from a discrete cosine transform in lieu of decoding the entire image at the full spatial resolution. The hybrid pipeline approach maintains ~93% accuracy while cutting down on ~95% of the total processing time compared to running the segmentation network at the full resolution on every image. The timely processing of big data sets helps inform mission operations, geologic surveys to prioritize candidate landing sites, avoid hazardous areas, or map the spatial extent of certain terrain. The segmentation masks and source code are available on Github for the community to explore and build upon.
</details>
<details>
<summary>摘要</summary>
一个主要目标 OF Mars Exploration Program 是搜索 Mars 上过去或当前生命的证据。 To achieve this, Mars exploration has been focusing on regions that may have liquid or frozen water. A set of critical areas may have seen cycles of ice thawing in the relatively recent past in response to periodic changes in the obliquity of Mars. In this work, we use convolutional neural networks to detect surface regions containing "Brain Coral" terrain, a landform on Mars whose similarity in morphology and scale to sorted stone circles on Earth suggests that it may have formed as a consequence of freeze/thaw cycles. We use large images (~100-1000 megapixels) from the Mars Reconnaissance Orbiter to search for these landforms at resolutions close to a few tens of centimeters per pixel (~25--50 cm). Over 52,000 images (~28 TB) were searched (~5% of the Martian surface) where we found detections in over 200 images. To expedite the processing we leverage a classifier network (prior to segmentation) in the Fourier domain that can take advantage of JPEG compression by leveraging blocks of coefficients from a discrete cosine transform in lieu of decoding the entire image at the full spatial resolution. The hybrid pipeline approach maintains ~93% accuracy while cutting down on ~95% of the total processing time compared to running the segmentation network at the full resolution on every image. The timely processing of big data sets helps inform mission operations, geologic surveys to prioritize candidate landing sites, avoid hazardous areas, or map the spatial extent of certain terrain. The segmentation masks and source code are available on Github for the community to explore and build upon.
</details></li>
</ul>
<hr>
<h2 id="A-Supervised-Contrastive-Learning-Pretrain-Finetune-Approach-for-Time-Series"><a href="#A-Supervised-Contrastive-Learning-Pretrain-Finetune-Approach-for-Time-Series" class="headerlink" title="A Supervised Contrastive Learning Pretrain-Finetune Approach for Time Series"></a>A Supervised Contrastive Learning Pretrain-Finetune Approach for Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12290">http://arxiv.org/abs/2311.12290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Trang H. Tran, Lam M. Nguyen, Kyongmin Yeo, Nam Nguyen, Roman Vaculin</li>
<li>for: This paper is written for researchers and practitioners working in the field of machine learning, particularly those interested in time series models and their applications.</li>
<li>methods: The paper proposes a novel pretraining procedure that leverages supervised contrastive learning to extract representations and transfer knowledge from pretraining datasets to the target finetuning dataset. The proposed method uses a probabilistic similarity metric to assess the likelihood of a univariate sample being closely related to one of the pretraining datasets.</li>
<li>results: The paper reports promising results from experiments that demonstrate the efficacy of the proposed approach in enhancing the accurate prediction of the target data by aligning it more closely with the learned dynamics of the pretraining datasets.<details>
<summary>Abstract</summary>
Foundation models have recently gained attention within the field of machine learning thanks to its efficiency in broad data processing. While researchers had attempted to extend this success to time series models, the main challenge is effectively extracting representations and transferring knowledge from pretraining datasets to the target finetuning dataset. To tackle this issue, we introduce a novel pretraining procedure that leverages supervised contrastive learning to distinguish features within each pretraining dataset. This pretraining phase enables a probabilistic similarity metric, which assesses the likelihood of a univariate sample being closely related to one of the pretraining datasets. Subsequently, using this similarity metric as a guide, we propose a fine-tuning procedure designed to enhance the accurate prediction of the target data by aligning it more closely with the learned dynamics of the pretraining datasets. Our experiments have shown promising results which demonstrate the efficacy of our approach.
</details>
<details>
<summary>摘要</summary>
基于模型在机器学习领域的成功，现在许多研究者尝试将其应用于时间序列模型。然而，主要挑战在于从预训练数据集中提取特征并将知识传递到目标练级数据集。为解决这个问题，我们介绍了一种新的预训练方法，利用指导学习来分别特征在每个预训练数据集中。这种预训练阶段使得一个概率相似度度量，用于评估预训练数据集中的样本是否与目标数据集 closely related。然后，我们提议一种练级过程，使用这种相似度度量作为引导，以更好地对目标数据集进行预测。我们的实验结果表明，我们的方法可以得到惊喜的结果，这表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Orthogonally-weighted-ell-2-1-regularization-for-rank-aware-joint-sparse-recovery-algorithm-and-analysis"><a href="#Orthogonally-weighted-ell-2-1-regularization-for-rank-aware-joint-sparse-recovery-algorithm-and-analysis" class="headerlink" title="Orthogonally weighted $\ell_{2,1}$ regularization for rank-aware joint sparse recovery: algorithm and analysis"></a>Orthogonally weighted $\ell_{2,1}$ regularization for rank-aware joint sparse recovery: algorithm and analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12282">http://arxiv.org/abs/2311.12282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a-petr/owl">https://github.com/a-petr/owl</a></li>
<li>paper_authors: Armenak Petrosyan, Konstantin Pieper, Hoang Tran</li>
<li>for: 解决紧凑稀疏还原问题</li>
<li>methods: 使用新的正则化基于方法，名为正交权重$\ell_{2,1}$（ow$\ell_{2,1}$），该方法特点在于考虑解matrix的级别</li>
<li>results: 提出了一种高效的算法，并提供了解题的证明和实验来 validate the effectiveness of the proposed method on real-world problems.<details>
<summary>Abstract</summary>
We propose and analyze an efficient algorithm for solving the joint sparse recovery problem using a new regularization-based method, named orthogonally weighted $\ell_{2,1}$ ($\mathit{ow}\ell_{2,1}$), which is specifically designed to take into account the rank of the solution matrix. This method has applications in feature extraction, matrix column selection, and dictionary learning, and it is distinct from commonly used $\ell_{2,1}$ regularization and other existing regularization-based approaches because it can exploit the full rank of the row-sparse solution matrix, a key feature in many applications. We provide a proof of the method's rank-awareness, establish the existence of solutions to the proposed optimization problem, and develop an efficient algorithm for solving it, whose convergence is analyzed. We also present numerical experiments to illustrate the theory and demonstrate the effectiveness of our method on real-life problems.
</details>
<details>
<summary>摘要</summary>
我们提出并分析了一种高效的算法，用于解决共聚散恢复问题，使用我们新提出的正则化基于方法，即正交权重 $\ell_{2,1}$（ $\mathit{ow}\ell_{2,1}$），这种方法特别是为了考虑解决矩阵的排名。这种方法在特征提取、矩阵列选择和字典学习中有应用，与通常使用 $\ell_{2,1}$ 正则化和其他现有的正则化基于方法不同，因为它可以利用纤程矩阵的全部纤程，这是许多应用中的关键特点。我们提供了方法的排名意识证明，证明存在解决提出的优化问题的解，并开发了一种高效的解决方案，其 converges 分析。我们还发表了数字实验，用于证明理论和实践中的效果。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Simulated-Drivers-Evaluating-the-Impact-of-Real-World-Car-Following-in-Mixed-Traffic-Control"><a href="#Beyond-Simulated-Drivers-Evaluating-the-Impact-of-Real-World-Car-Following-in-Mixed-Traffic-Control" class="headerlink" title="Beyond Simulated Drivers: Evaluating the Impact of Real-World Car-Following in Mixed Traffic Control"></a>Beyond Simulated Drivers: Evaluating the Impact of Real-World Car-Following in Mixed Traffic Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12261">http://arxiv.org/abs/2311.12261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bibek Poudel, Weizi Li</li>
<li>For: This paper aims to improve the performance of robot vehicles (RVs) in mitigating traffic congestion and increasing safety and efficiency in real-world traffic scenarios, by incorporating real-world human driving behaviors into the simulation and introducing a reinforcement learning-based RV that can adapt to diverse human driving behaviors.* Methods: The paper uses real-world human driving trajectories to extract a wide range of acceleration behaviors during car-following, and incorporates these behaviors into a simulation environment to evaluate the performance of RVs. The proposed RVs use a congestion stage classifier neural network to optimize either “safety+stability” or “efficiency” in the presence of diverse human driving behaviors.* Results: The proposed RVs are evaluated in two different mixed traffic control environments at various densities, configurations, and penetration rates, and compared with existing RVs. The results show that the proposed RVs can improve safety, efficiency, and stability in real-world traffic scenarios, and adapt to diverse human driving behaviors.<details>
<summary>Abstract</summary>
Human-driven vehicles can amplify naturally occurring perturbations in traffic, leading to congestion and consequently increased fuel consumption, higher collision risks, and reduced capacity utilization. While previous research has highlighted that a fraction of Robot Vehicles (RVs) can mitigate these issues, they often rely on simulations with simplistic, model-based Human-driven Vehicles (HVs) during car-following scenarios. Diverging from this trend, in this study, we analyze real-world human driving trajectories, extracting a wide range of acceleration behaviors during car-following. We then incorporate these behaviors in simulation where RVs from prior studies are employed to mitigate congestion, and evaluate their safety, efficiency, and stability. Further, we also introduce a reinforcement learning based RV that utilizes a congestion stage classifier neural network to optimize either "safety+stability" or "efficiency" in the presence of the diverse human driving behaviors. We evaluate the proposed RVs in two different mixed traffic control environments at various densities, configurations, and penetration rates and compare with the existing RVs.
</details>
<details>
<summary>摘要</summary>
人类驾驶车辆可以增强天然发生的交通干扰，导致拥堵和更高的燃油消耗、更高的碰撞风险和更低的容量利用率。而先前的研究常常使用简化的模型基于人类驾驶车辆进行 simulations，以评估Robot Vehicles（RVs）在减轻这些问题方面的作用。不同于这一趋势，本研究使用实际的人类驾驶轨迹数据，提取了车辆跟随行为的各种加速行为。然后，我们在模拟中包含这些行为，并使用先前的RVs来减轻拥堵，并评估其安全、效率和稳定性。此外，我们还引入了基于强化学习的RV，使用拥堵阶段分类神经网络来优化“安全+稳定”或“效率”在人类驾驶行为的存在下。我们在不同的混合交通控制环境中评估了提议的RVs，并与先前的RVs进行比较。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Time-Granularity-on-Temporal-Graphs-for-Dynamic-Link-Prediction-in-Real-world-Networks"><a href="#Exploring-Time-Granularity-on-Temporal-Graphs-for-Dynamic-Link-Prediction-in-Real-world-Networks" class="headerlink" title="Exploring Time Granularity on Temporal Graphs for Dynamic Link Prediction in Real-world Networks"></a>Exploring Time Granularity on Temporal Graphs for Dynamic Link Prediction in Real-world Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12255">http://arxiv.org/abs/2311.12255</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/silencex12138/time-granularity-on-temporal-graphs">https://github.com/silencex12138/time-granularity-on-temporal-graphs</a></li>
<li>paper_authors: Xiangjian Jiang, Yanyi Pu</li>
<li>for: 本研究探讨了在动态图structured data上使用动态图神经网络（DGNNs）进行预测任务时，时间粒度的影响。</li>
<li>methods: 本研究使用了多种领域的动态图，并对三种不同的DGNNs和基准模型进行了extensive的实验 comparisons。</li>
<li>results: 我们的结果显示，在动态图预测任务中，一个复杂的记忆机制和合适的时间粒度是关键的，以确保DGNNs的竞争力和稳定性。  Additionally, we discuss the limitations of the considered models and datasets and propose promising directions for future research on the time granularity of temporal graphs.<details>
<summary>Abstract</summary>
Dynamic Graph Neural Networks (DGNNs) have emerged as the predominant approach for processing dynamic graph-structured data. However, the influence of temporal information on model performance and robustness remains insufficiently explored, particularly regarding how models address prediction tasks with different time granularities. In this paper, we explore the impact of time granularity when training DGNNs on dynamic graphs through extensive experiments. We examine graphs derived from various domains and compare three different DGNNs to the baseline model across four varied time granularities. We mainly consider the interplay between time granularities, model architectures, and negative sampling strategies to obtain general conclusions. Our results reveal that a sophisticated memory mechanism and proper time granularity are crucial for a DGNN to deliver competitive and robust performance in the dynamic link prediction task. We also discuss drawbacks in considered models and datasets and propose promising directions for future research on the time granularity of temporal graphs.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>动态图 neural network (DGNN) 已成为处理动态图数据的主要方法。然而，模型在不同时间粒度下的表现和可靠性的影响仍未得到充分探讨，特别是在不同时间粒度下进行预测任务时。在本文中，我们通过广泛的实验研究 DGNN 在动态图上的训练中，不同时间粒度下的影响。我们分析了来自不同领域的图集，并将三种不同的 DGNN 与基准模型进行比较，在四种不同的时间粒度下进行比较。我们主要考虑了时间粒度、模型架构和负样本策略的相互作用，以获得一般结论。我们的结果表明，在动态链接预测任务中，一种复杂的记忆机制和适当的时间粒度是关键的，以确保 DGNN 能够在竞争和可靠的表现。我们还讨论了考虑模型和数据集中的缺点，并提出了未来研究时间粒度的动态图模型的可能性。
</details></li>
</ul>
<hr>
<h2 id="The-limitation-of-neural-nets-for-approximation-and-optimization"><a href="#The-limitation-of-neural-nets-for-approximation-and-optimization" class="headerlink" title="The limitation of neural nets for approximation and optimization"></a>The limitation of neural nets for approximation and optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12253">http://arxiv.org/abs/2311.12253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sohaboumaima/basesnnapproxforopt">https://github.com/sohaboumaima/basesnnapproxforopt</a></li>
<li>paper_authors: Tommaso Giovannelli, Oumaima Sohab, Luis Nunes Vicente</li>
<li>for: 本研究旨在利用神经网络作为优化问题中的假函数模型，以优化和最小化目标函数。</li>
<li>methods: 本研究使用了SiLU activation function来确定优化问题中目标函数的最佳激活函数，并分析了神经网络和 interpol&#x2F;regression模型对目标函数的值、梯度和Hessian的近似性。</li>
<li>results: 研究发现，使用神经网络可以提供竞争力强的零和首项近似（但需要高训练成本），但在第二项近似方面表现较差。然而，结合神经网络激活函数和自然基准可以减少参数数量，并且提供了一种基于自然基准的derivative-free优化算法。最后，研究表明，使用神经网络或其他假函数模型来 aproximate梯度的性能几乎无法超越state-of-the-art derivative-free优化算法的性能。<details>
<summary>Abstract</summary>
We are interested in assessing the use of neural networks as surrogate models to approximate and minimize objective functions in optimization problems. While neural networks are widely used for machine learning tasks such as classification and regression, their application in solving optimization problems has been limited. Our study begins by determining the best activation function for approximating the objective functions of popular nonlinear optimization test problems, and the evidence provided shows that~SiLU has the best performance. We then analyze the accuracy of function value, gradient, and Hessian approximations for such objective functions obtained through interpolation/regression models and neural networks. When compared to interpolation/regression models, neural networks can deliver competitive zero- and first-order approximations (at a high training cost) but underperform on second-order approximation. However, it is shown that combining a neural net activation function with the natural basis for quadratic interpolation/regression can waive the necessity of including cross terms in the natural basis, leading to models with fewer parameters to determine. Lastly, we provide evidence that the performance of a state-of-the-art derivative-free optimization algorithm can hardly be improved when the gradient of an objective function is approximated using any of the surrogate models considered, including neural networks.
</details>
<details>
<summary>摘要</summary>
我们有兴趣测试神经网络作为估计函数的来源，以估计和最小化估计函数中的问题。 Although neural networks are widely used for machine learning tasks such as classification and regression, their application in solving optimization problems has been limited. Our study begins by determining the best activation function for approximating the objective functions of popular nonlinear optimization test problems, and the evidence provided shows that~SiLU has the best performance. We then analyze the accuracy of function value, gradient, and Hessian approximations for such objective functions obtained through interpolation/regression models and neural networks. When compared to interpolation/regression models, neural networks can deliver competitive zero- and first-order approximations (at a high training cost) but underperform on second-order approximation. However, it is shown that combining a neural net activation function with the natural basis for quadratic interpolation/regression can waive the necessity of including cross terms in the natural basis, leading to models with fewer parameters to determine. Lastly, we provide evidence that the performance of a state-of-the-art derivative-free optimization algorithm can hardly be improved when the gradient of an objective function is approximated using any of the surrogate models considered, including neural networks.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/cs.LG_2023_11_21/" data-id="clpxp6c5o00w8ee8892gbfip9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/eess.SP_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T08:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/21/eess.SP_2023_11_21/">eess.SP - 2023-11-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Learn-to-Augment-Network-Simulators-Towards-Digital-Network-Twins"><a href="#Learn-to-Augment-Network-Simulators-Towards-Digital-Network-Twins" class="headerlink" title="Learn to Augment Network Simulators Towards Digital Network Twins"></a>Learn to Augment Network Simulators Towards Digital Network Twins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12745">http://arxiv.org/abs/2311.12745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuru Zhang, Ming Zhao, Qiang Liu</li>
<li>for: 提出一种新的方法，使用 context-aware 神经网络来增强网络仿真器。</li>
<li>methods: 提出了一种 learn-to-bridge 算法，用于在实际网络和网络仿真器之间减少 sim-to-real 差异。在两个阶段中，首先使用新的 cost-aware Bayesian 优化选择状态来评估实际网络中的性能，然后使用 Bayesian neural networks (BNN) 来学习状态上下文并bridge probabilistic 差异。</li>
<li>results: 评估结果显示，提出的解决方案可以减少 sim-to-real 差异的92.2%以上。<details>
<summary>Abstract</summary>
Digital network twin (DNT) is a promising paradigm to replicate real-world cellular networks toward continual assessment, proactive management, and what-if analysis. Existing discussions have been focusing on using only deep learning techniques to build DNTs, which raises widespread concerns regarding their generalization, explainability, and transparency. In this paper, we explore an alternative approach to augment network simulators with context-aware neural agents. The main challenge lies in the non-trivial simulation-to-reality (sim-to-real) discrepancy between offline simulators and real-world networks. To solve the challenge, we propose a new learn-to-bridge algorithm to cost-efficiently bridge the sim-to-real discrepancy in two alternative stages. In the first stage, we select states to query performances in real-world networks by using newly-designed cost-aware Bayesian optimization. In the second stage, we train the neural agent to learn the state context and bridge the probabilistic discrepancy based on Bayesian neural networks (BNN). In addition, we build a small-scale end-to-end network testbed based on OpenAirInterface RAN and Core with USRP B210 and a smartphone, and replicate the network in NS-3. The evaluation results show that, our proposed solution substantially outperforms existing methods, with more than 92\% reduction in the sim-to-real discrepancy.
</details>
<details>
<summary>摘要</summary>
数字网络双（DNT）是一种有前途的思路，可以对现实世界的无线网络进行不断评估、牵引管理和什么样的分析。现有的讨论都是使用深度学习技术来构建DNT，这会引发广泛的担忧，包括泛化、解释性和透明度。在这篇论文中，我们探索了一种可以补充网络模拟器的上下文智能代理人的方法。主要挑战在于非轻松的模拟器到实际（sim-to-real）差异，我们提出了一种新的学习到桥梁算法，以成本高效地跨越这一差异。在第一个阶段，我们使用新设计的成本意识搜索选择状态来评估实际网络中的性能。在第二个阶段，我们使用泛化神经网络（BNN）训练神经网络学习状态上的上下文，并用 Bridge probability  gap。此外，我们建立了一个小规模的终端到终端网络测试床，基于 OpenAirInterface RAN 和核心，使用 USRP B210 和智能手机，并在 NS-3 中重现网络。评估结果表明，我们的解决方案在与现有方法进行比较时，可以 achieve 92% 以上的减少 sim-to-real 差异。
</details></li>
</ul>
<hr>
<h2 id="Satellite-Swarms-for-Narrow-Beamwidth-Applications"><a href="#Satellite-Swarms-for-Narrow-Beamwidth-Applications" class="headerlink" title="Satellite Swarms for Narrow Beamwidth Applications"></a>Satellite Swarms for Narrow Beamwidth Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12721">http://arxiv.org/abs/2311.12721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan A. Vásquez-Peralvo, Juan Carlos Merlano Duncan, Geoffrey Eappen, Symeon Chatzinotas</li>
<li>for: 这篇论文是为了研究一种基于分布式子阵列配置的卫星群组，以实现高精度的方向性干扰。</li>
<li>methods: 该方案使用多个小卫星作为分布式子阵列，每个子阵列具有20000个波长径的限制，采用中心频率为19GHz的扩展干扰。</li>
<li>results:  simulations shows that the proposed swarm concept can achieve a beamwidth as narrow as 0.0015度，且最大侧lob level为18.8dB和扩散lob level为14.8dB，可用于高速数据应用或紧急通信系统。<details>
<summary>Abstract</summary>
Satellite swarms have recently gained attention in the space industry due to their ability to provide extremely narrow beamwidths at a lower cost than single satellite systems. This paper proposes a concept for a satellite swarm using a distributed subarray configuration based on a 2D normal probability distribution. The swarm comprises multiple small satellites acting as subarrays of a big aperture array limited by a radius of 20000 wavelengths working at a central frequency of 19 GHz. The main advantage of this approach is that the distributed subarrays can provide extremely directive beams and beamforming capabilities that are not possible using a conventional antenna and satellite design. The proposed swarm concept is analyzed, and the simulation results show that the radiation pattern achieves a beamwidth as narrow as 0.0015-degrees with a maximum side lobe level of 18.8 dB and a grating lobe level of 14.8 dB. This concept can be used for high data rates applications or emergency systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Empirical-Validation-of-the-Impedance-Based-RIS-Channel-Model-in-an-Indoor-Scattering-Environment"><a href="#Empirical-Validation-of-the-Impedance-Based-RIS-Channel-Model-in-an-Indoor-Scattering-Environment" class="headerlink" title="Empirical Validation of the Impedance-Based RIS Channel Model in an Indoor Scattering Environment"></a>Empirical Validation of the Impedance-Based RIS Channel Model in an Indoor Scattering Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12628">http://arxiv.org/abs/2311.12628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Placido Mursia, Taghrid Mazloum, Frederic Munoz, Vincenzo Sciancalepore, Gabriele Gradoni, Raffaele D Errico, Marco Di Renzo, Xavier Costa-Perez, Antonio Clemente, Geoffroy Lerosey</li>
<li>for:  validate a recently-proposed impedance-based RIS channel model</li>
<li>methods:  exploit real-life channel measurements and discrete array of loaded dipoles</li>
<li>results:  superior performance compared to reference schemes<details>
<summary>Abstract</summary>
Ensuring the precision of channel modeling plays a pivotal role in the development of wireless communication systems, and this requirement remains a persistent challenge within the realm of networks supported by Reconfigurable Intelligent Surfaces (RIS). Achieving a comprehensive and reliable understanding of channel behavior in RIS-aided networks is an ongoing and complex issue that demands further exploration. In this paper, we empirically validate a recently-proposed impedance-based RIS channel model that accounts for the mutual coupling at the antenna array and precisely models the presence of scattering objects within the environment as a discrete array of loaded dipoles. To this end, we exploit real-life channel measurements collected in an office environment to demonstrate the validity of such a model and its applicability in a practical scenario. Finally, we provide numerical results demonstrating that designing the RIS configuration based upon such model leads to superior performance as compared to reference schemes.
</details>
<details>
<summary>摘要</summary>
ensuring the precision of channel modeling plays a crucial role in the development of wireless communication systems, and this requirement remains a persistent challenge within the realm of networks supported by Reconfigurable Intelligent Surfaces (RIS). achieving a comprehensive and reliable understanding of channel behavior in RIS-aided networks is an ongoing and complex issue that demands further exploration. in this paper, we empirically validate a recently-proposed impedance-based RIS channel model that accounts for the mutual coupling at the antenna array and precisely models the presence of scattering objects within the environment as a discrete array of loaded dipoles. to this end, we exploit real-life channel measurements collected in an office environment to demonstrate the validity of such a model and its applicability in a practical scenario. finally, we provide numerical results demonstrating that designing the RIS configuration based upon such model leads to superior performance as compared to reference schemes.Note that Simplified Chinese is also known as "简化字" or "简化字" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Framework-for-Pulse-Shaping-on-Delay-Doppler-Plane"><a href="#A-Unified-Framework-for-Pulse-Shaping-on-Delay-Doppler-Plane" class="headerlink" title="A Unified Framework for Pulse-Shaping on Delay-Doppler Plane"></a>A Unified Framework for Pulse-Shaping on Delay-Doppler Plane</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12543">http://arxiv.org/abs/2311.12543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohsen Bayat, Arman Farhang</li>
<li>for: 本研究旨在探讨延迟-多普勒多普勒复用技术的研究，特别是不同束缚技巧的相互关系和特性。</li>
<li>methods: 本文使用了循环和线性束缚技巧分类Delay-Doppler多普勒复用技术，并提出了一个统一的框架，以便更深入地了解不同束缚技巧的属性、相互关系和区别。</li>
<li>results: 本文提出了一个通用的输入输出关系，用于描述束缚技巧对有效通道的影响。此外，提出了一种简单的模式器结构，用于实现延迟-多普勒平面束缚。此外，本文还提出了一种可以降低循环束缚信号的OOB强度和提高循环和线性束缚技巧的BER性能的技术。最后，本文对不同束缚技巧进行了比较，并使用了不同的性能指标进行评估。<details>
<summary>Abstract</summary>
Delay-Doppler multiplexing has recently stirred a great deal of attention in research community. While multiple studies have investigated pulse-shaping aspects of this technology, it is challenging to identify the relationships between different pulse-shaping techniques and their properties. Hence, in this paper, we classify these techniques into two types, namely, circular and linear pulse-shaping. This paves the way towards the development of a unified framework that brings deep insights into the properties, similarities, and distinctions of different pulse-shaping techniques. This framework reveals that the recently emerged waveform orthogonal delay-Doppler multiplexing (ODDM) is a linear pulse-shaping technique with an interesting staircase spectral behaviour. Using this framework, we derive a generalized input-output relationship that captures the influence of pulse-shaping on the effective channel. We also introduce a unified modem for delay-Doppler plane pulse-shaping that leads to the proposal of fast convolution based low-complexity structures. Based on our complexity analysis, the proposed modem structures are substantially simpler than the existing ones in the literature. Furthermore, we propose effective techniques that not only reduce the out-of-band (OOB) emissions of circularly pulse-shaped signals but also improve the bit-error-rate (BER) performance of both circular and linear pulse-shaping techniques. Finally, we extensively compare different pulse-shaping techniques using various performance metrics.
</details>
<details>
<summary>摘要</summary>
延迟-多普勒多普勒多普勒（DDM）在研究社区中引起了很大的关注。虽然许多研究已经研究了这种技术的推波形方面，但是很难确定不同推波形技术之间的关系。因此，在这篇论文中，我们将这些技术分为两类：圆形推波形和直线推波形。这些分类提供了一个统一的框架，可以带来深入的理解不同推波形技术的性质、相似性和区别。这个框架显示了最近出现的抽象幂函数多普勒多普勒多普勒（ODDM）是一种直线推波形技术，其spectral behavior exhibits an interesting staircase pattern.使用这个框架，我们得到了一个总结性的输入输出关系，可以捕捉推波形对有效通道的影响。我们还提出了一种统一的模式机制，可以实现延迟-多普勒平面推波形。根据我们的复杂度分析，提出的模式机制比现有Literature中的模式机制更加简单。此外，我们还提出了一些有效的技术，可以不仅减少圆拱推波形信号的外围干扰（OOB）泄漏，还可以提高圆拱和直线推波形技术的比特错误率（BER）性能。最后，我们对不同推波形技术进行了广泛的比较，使用了多种表现指标。
</details></li>
</ul>
<hr>
<h2 id="Wearable-Technologies-for-Monitoring-Upper-Extremity-Functions-During-Daily-Life-in-Neurologically-Impaired-Individuals"><a href="#Wearable-Technologies-for-Monitoring-Upper-Extremity-Functions-During-Daily-Life-in-Neurologically-Impaired-Individuals" class="headerlink" title="Wearable Technologies for Monitoring Upper Extremity Functions During Daily Life in Neurologically Impaired Individuals"></a>Wearable Technologies for Monitoring Upper Extremity Functions During Daily Life in Neurologically Impaired Individuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12513">http://arxiv.org/abs/2311.12513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tommaso Proietti, Andrea Bandini<br>for: This review focuses on wearable technologies to monitor upper extremity (UE) function in neurologically impaired individuals during daily life activities.methods: The review categorizes different sensors, data collection, and data processing approaches employed in wearable technologies for monitoring UE function. The majority of studies used inertial measurement units and accelerometers to collect kinematics, and most analyses were performed offline.results: Although wearable technology shows potential in monitoring UE function in real-life scenarios, an ideal solution that combines non-intrusiveness, lightweight design, detailed hand and finger movement capture, contextual information, extended recording duration, ease of use, and privacy protection remains an elusive goal. A growing necessity for a multimodal approach in capturing comprehensive data on UE function during real-life activities is highlighted.<details>
<summary>Abstract</summary>
Neurological disorders, including stroke, spinal cord injuries, multiple sclerosis, and Parkinson's disease, generally lead to diminished upper extremity (UE) function, impacting individuals' independence and quality of life. Traditional assessments predominantly focus on standardized clinical tasks, offering limited insights into real-life UE performance. In this context, this review focuses on wearable technologies as a promising solution to monitor UE function in neurologically impaired individuals during daily life activities. Our primary objective is to categorize the different sensors, data collection and data processing approaches employed. What comes to light is that the majority of studies involved stroke survivors, and predominantly employed inertial measurement units and accelerometers to collect kinematics. Most analyses in these studies were performed offline, focusing on activity duration and frequency as key metrics. Although wearable technology shows potential in monitoring UE function in real-life scenarios, an ideal solution that combines non-intrusiveness, lightweight design, detailed hand and finger movement capture, contextual information, extended recording duration, ease of use, and privacy protection remains an elusive goal. Furthermore, it stands out a growing necessity for a multimodal approach in capturing comprehensive data on UE function during real-life activities to enhance the personalization of rehabilitation strategies and ultimately improve outcomes for these individuals.
</details>
<details>
<summary>摘要</summary>
神经系统疾病，包括中风、脊梁 травмы、多发性硬化和 Parkinson 病，通常导致上肢功能减退，影响个人独立和生活质量。传统评估主要集中在标准临床任务上，很少提供实际生活活动中 UE 功能的深入了解。在这个上下文中，本文关注穿戴技术作为监测 UE 功能的有前途解决方案。我们的主要目标是描述不同感应器、数据采集和处理方法的应用。发现大多数研究都关注中风幸存者，主要使用不动力测量单元和加速计收集 kinematics。大多数分析都是在线进行，关注活动持续时间和频率作为关键指标。虽然穿戴技术在实际生活情况中监测 UE 功能表现出潜在的潜力，但是理想的解决方案仍然是一个逃亡的目标，它应该具备不侵入、轻量、详细手夹和手指运动捕捉、上下文信息、长时间采集、易用性和隐私保护等特点。此外，随着个人化复健策略的需求增加，需要一种多模式方法来捕捉 UE 功能的全面数据，以提高复健策略的个性化和最终实现患者的成果。
</details></li>
</ul>
<hr>
<h2 id="A-study-on-Satellite-to-Ground-Propagation-in-Urban-Environment"><a href="#A-study-on-Satellite-to-Ground-Propagation-in-Urban-Environment" class="headerlink" title="A study on Satellite-to-Ground Propagation in Urban Environment"></a>A study on Satellite-to-Ground Propagation in Urban Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12500">http://arxiv.org/abs/2311.12500</a></li>
<li>repo_url: None</li>
<li>paper_authors: N. Cenni, V. Degli-Esposti, E. M. Vitucci, F. Fuschini, M. Barbiroli</li>
<li>for: 本文是为了研究未来6G无线网络中非地球网络的重要作用，以及与地面网络的合作，而写的。</li>
<li>methods: 本文使用了射线轨迹模拟工具来分析卫星到地面通信频谱的主要射线扩散机制，以及卫星位置对K因子的影响。</li>
<li>results: 研究发现，在非直线视野情况下，非规则反射是主要的射线扩散机制。此外，K因子在高度角度上显示一个轻微增长趋势，与之前的研究不同。<details>
<summary>Abstract</summary>
Non-Terrestrial Networks are going to play an important role in future 6G wireless networks to enhance global connectivity a performance in cooperation with terrestrial networks. In order to properly design and deploy non-terrestrial networks, the satellite-to-ground channel must be properly characterized, with particular focus on the urban environment. This paper uses a Ray-Tracing simulation tool to analyze the primary propagation mechanisms and the behaviour of the Rician K-factor as a function of satellite position in a reference urban environment. Non-specular reflection due to surface irregularities emerges as a primary propagation mechanism in non-line-of-sight cases. Additionally, the Rician K-factor shows a slightly increasing trend with elevation angle, in contrast to previous studies.
</details>
<details>
<summary>摘要</summary>
未来的6G无线网络中，非地球网络将扮演重要的角色，以提高全球连接性和性能，并在合作地球网络的基础之上进行设计和部署。为了正确设计和部署非地球网络，卫星到地面通信频道必须得到正确的特征化，特别是在都市环境中。这篇文章使用了射线追踪模拟工具来分析卫星到地面通信的主要媒体传播机制，以及卫星位置的参数对Rician K-因子的影响。在非直线视野情况下，非规则反射是主要的媒体传播机制。此外，Rician K-因子在高角度角度上显示了一个轻微增长趋势，与先前的研究不同。
</details></li>
</ul>
<hr>
<h2 id="Constellation-Shaping-under-Phase-Noise-Impairment-for-Sub-THz-Communications"><a href="#Constellation-Shaping-under-Phase-Noise-Impairment-for-Sub-THz-Communications" class="headerlink" title="Constellation Shaping under Phase Noise Impairment for Sub-THz Communications"></a>Constellation Shaping under Phase Noise Impairment for Sub-THz Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12433">http://arxiv.org/abs/2311.12433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dileepa Marasinghe, Le Hang Nguyen, Jafar Mohammadi, Yejian Chen, Thorsten Wild, Nandana Rajatheva</li>
<li>for: 本研究旨在开掘Sub-THz频段的潜在通信应用，并解决射频硬件缺陷带来的问题。</li>
<li>methods: 本文使用单报域频域均衡(SC-FDE)波形，并通过 геометрически设计常量图来提高波形的鲁棒性和PAPR性能。</li>
<li>results: 本文通过数学优化方法，设计出一种具有减少干扰的、低PAPR SC-FDE波形，并实现了在实际情况下的数值稳定性。<details>
<summary>Abstract</summary>
The large untapped spectrum in the sub-THz allows for ultra-high throughput communication to realize many seemingly impossible applications in 6G. One of the challenges in radio communications in sub-THz is the hardware impairments. Specifically, phase noise is one key hardware impairment, which is accentuated as we increase the frequency and bandwidth. Furthermore, the modest output power of the sub-THz power amplifier demands limits on peak to average power ratio (PAPR) signal design. Single carrier frequency domain equalization (SC-FDE) waveform has been identified as a suitable candidate for sub-THz, although some challenges such as phase noise and PAPR still remain to be tackled. In this work, we design a phase noise robust, low PAPR SC-FDE waveform by geometrically shaping the constellation under practical conditions. We formulate the waveform optimization problem in its augmented Lagrangian form and use a back-propagation-inspired technique to obtain a constellation design that is numerically robust to phase noise, while maintaining a low PAPR.
</details>
<details>
<summary>摘要</summary>
“这个大型未发掘频率视盘允许极高吞吐通信，实现6G中许多看似不可能的应用。Radio通信在sub-THz频率下一个挑战是硬件障碍。具体而言，相位噪音是一个关键的硬件障碍，随着频率和宽度的增加，它会变得更加明显。此外，sub-THz增益器的输出功率较低，需要限制峰值至平均功率比（PAPR）信号设计。Single carrier频域均衡（SC-FDE）波形已被识别为sub-THz的适合选择，但是还需要解决相位噪音和PAPR等问题。在这个工作中，我们设计了一个相位噪音抗性、低PAPR SC-FDE波形，通过对实际情况下的几何形状塑造constellation来进行优化。我们将波形优化问题转化为增强Lagrangian形式，使用back-propagation类似技术来获得一个numerically Robust的constellation设计，具有对相位噪音的抗性，同时保持低PAPR。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-Frame-Structure-Design-of-OTFS-for-Multi-tasks-Communications"><a href="#A-Hybrid-Frame-Structure-Design-of-OTFS-for-Multi-tasks-Communications" class="headerlink" title="A Hybrid Frame Structure Design of OTFS for Multi-tasks Communications"></a>A Hybrid Frame Structure Design of OTFS for Multi-tasks Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12390">http://arxiv.org/abs/2311.12390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pu Yuan, Jin Liu, Dajie Jiang, Fei Qin</li>
<li>for: 该论文旨在开发一种混合帧结构，以优化高移动enario下的时频分布多普通频率调制 (OTFS) 和orthogonal frequency division multiplexing (OFDM) 的时域多普通频率调制 (OFDM) 的并行多普通频率调制 (OFDM) 在时域多普通频率调制 (OTFS) 和OFDM 之间的混合。</li>
<li>methods: 该论文使用了一种hybrid frame structure，其中OTFS 和 OFDM 在时域上是独立的，以便在不同的应用场景中进行选择。同时，该论文还提出了一种实用的算法来 mitigate the inter symbol interference (ISI)  между OTFS 和 OFDM。</li>
<li>results: 数据结果表明，该 hybrid frame structure 可以在不同的应用场景中提供优化的性能，并且可以适应不同的延迟需求。同时，该论文还提供了一些实用的算法来 mitigate the ISI 问题。<details>
<summary>Abstract</summary>
Orthogonal time frequency space (OTFS) is a promising waveform in high mobility scenarios for it fully exploits the time-frequency diversity using a discrete Fourier transform (DFT) based two dimensional spreading. However, it trades off the processing latency for performance and may not fulfill the stringent latency requirements in some services. This fact motivates us to design a hybrid frame structure where the OTFS and Orthogonal Frequency Division Multiplexing (OFDM) are orthogonally multiplexed in the time domain, which can adapt to both diversity-preferred and latency-preferred tasks. As we identify that this orthogonality is disrupted after channel coupling, we provide practical algorithms to mitigate the inter symbol interference between (ISI) the OTFS and OFDM, and the numerical results ensure the effectiveness of the hybrid frame structure.
</details>
<details>
<summary>摘要</summary>
高速场景中的正交时频空间（OTFS）是一种有前途的波形，它完全利用时频多样性使用基于快速傅立叶变换（DFT）的二维扩散。然而，它与处理延迟成本贸然，可能不满足一些服务的延迟要求。这种情况激发了我们设计一种混合帧结构，其中OTFS和分多谱分配多路复用（OFDM）在时间频谱上是正交的，可以适应多样性和延迟两种任务。我们发现在通道紧凑后，这种正交性受到干扰，因此我们提供了实用的算法来 Mitigate the inter symbol interference between the OTFS and OFDM，并且数值结果证明了混合帧结构的效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/eess.SP_2023_11_21/" data-id="clpxp6cem01ihee889eedcuaw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/eess.AS_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T14:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/eess.AS_2023_11_20/">eess.AS - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-does-end-to-end-speech-recognition-training-impact-speech-enhancement-artifacts"><a href="#How-does-end-to-end-speech-recognition-training-impact-speech-enhancement-artifacts" class="headerlink" title="How does end-to-end speech recognition training impact speech enhancement artifacts?"></a>How does end-to-end speech recognition training impact speech enhancement artifacts?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11599">http://arxiv.org/abs/2311.11599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kazuma Iwamoto, Tsubasa Ochiai, Marc Delcroix, Rintaro Ikeshita, Hiroshi Sato, Shoko Araki, Shigeru Katagiri</li>
<li>for: 本研究旨在探讨对单通道声音提高前端和自动语音识别后端的共同训练对声音提高前端的信号水平特征的影响。</li>
<li>methods: 本研究使用了一种新的方法，即将SE front-end和ASR back-end的训练合并到一起，以降低由单通道SE处理生成的处理损害对ASR的影响。</li>
<li>results: 研究结果表明，对ASRlevel进行SE front-end的训练可以降低artifact错误，但是会增加噪声错误。此外，通过简单地 interpolate the enhanced and observed signals，可以达到降低artifacts和增加噪声的效果，而无需修改SE和ASR模块。这些结果为设计ASR无关的SE front-end提供了更好的理解和一种新的想法。<details>
<summary>Abstract</summary>
Jointly training a speech enhancement (SE) front-end and an automatic speech recognition (ASR) back-end has been investigated as a way to mitigate the influence of \emph{processing distortion} generated by single-channel SE on ASR. In this paper, we investigate the effect of such joint training on the signal-level characteristics of the enhanced signals from the viewpoint of the decomposed noise and artifact errors. The experimental analyses provide two novel findings: 1) ASR-level training of the SE front-end reduces the artifact errors while increasing the noise errors, and 2) simply interpolating the enhanced and observed signals, which achieves a similar effect of reducing artifacts and increasing noise, improves ASR performance without jointly modifying the SE and ASR modules, even for a strong ASR back-end using a WavLM feature extractor. Our findings provide a better understanding of the effect of joint training and a novel insight for designing an ASR agnostic SE front-end.
</details>
<details>
<summary>摘要</summary>
jointly 训练一个抖音减少（SE）前端和一个自动语音识别（ASR）后端，以降低单通道SE生成的处理扭曲对ASR的影响。在这篇论文中，我们研究了这种联合训练对减少噪声和缺陷错误的信号水平特征的影响。实验分析提供了两个新发现：1）ASR级别训练SE前端可以降低缺陷错误，同时增加噪声错误；2）简单地 interpolating 减少和观察到的信号，可以实现降低缺陷和增加噪声的效果，无需修改SE和ASR模块，即使使用一个强大的ASR后端使用WavLM特征提取器。我们的发现为 joint 训练的影响提供了更好的理解，并为设计ASR无关的SE前端提供了一个新的视角。
</details></li>
</ul>
<hr>
<h2 id="Neural-network-based-virtual-microphone-estimation-with-virtual-microphone-and-beamformer-level-multi-task-loss"><a href="#Neural-network-based-virtual-microphone-estimation-with-virtual-microphone-and-beamformer-level-multi-task-loss" class="headerlink" title="Neural network-based virtual microphone estimation with virtual microphone and beamformer-level multi-task loss"></a>Neural network-based virtual microphone estimation with virtual microphone and beamformer-level multi-task loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11595">http://arxiv.org/abs/2311.11595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanako Segawa, Tsubasa Ochiai, Marc Delcroix, Tomohiro Nakatani, Rintaro Ikeshita, Shoko Araki, Takeshi Yamada, Shoji Makino</li>
<li>for: 提高数字微phone数量以提高数字笔记录器的性能</li>
<li>methods: 使用神经网络预测虚拟微phone信号，并使用多任务损失函数组合VM-level和beamformer-level损失函数</li>
<li>results: 在多话者下定制不足的情况下，提出了一种多任务NN-VME方法，实现了33.1%的相对WRER提升和10.8%的相对于先前NN-VME方法的提升。<details>
<summary>Abstract</summary>
Array processing performance depends on the number of microphones available. Virtual microphone estimation (VME) has been proposed to increase the number of microphone signals artificially. Neural network-based VME (NN-VME) trains an NN with a VM-level loss to predict a signal at a microphone location that is available during training but not at inference. However, this training objective may not be optimal for a specific array processing back-end, such as beamforming. An alternative approach is to use a training objective considering the array-processing back-end, such as a loss on the beamformer output. This approach may generate signals optimal for beamforming but not physically grounded. To combine the advantages of both approaches, this paper proposes a multi-task loss for NN-VME that combines both VM-level and beamformer-level losses. We evaluate the proposed multi-task NN-VME on multi-talker underdetermined conditions and show that it achieves a 33.1 % relative WER improvement compared to using only real microphones and 10.8 % compared to using a prior NN-VME approach.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)阵列处理性能取决于可用的麦克风数量。虚拟麦克风估计（VME）已经提出来增加虚拟麦克风信号的数量。基于神经网络的VME（NN-VME）使用一个神经网络，在训练时使用VM级损失来预测在训练过程中可用的麦克风位置上的信号，但在推理时不可用。然而，这种训练目标可能不适合特定的阵列处理后端，例如扩散算法。一种alternative approach是使用包含阵列处理后端的训练目标，例如扩散输出损失。这种方法可能生成适合扩散的信号，但不是物理上的。为了结合两种方法的优点，本文提出了一种多任务损失函数 дляNN-VME，该函数combines VM级和扩散级损失。我们对多话者下的干扰过度的情况进行评估，并显示了使用该方法可以相比使用真实的麦克风和10.8%相比，提高33.1%的相对WRER。
</details></li>
</ul>
<hr>
<h2 id="APNet2-High-quality-and-High-efficiency-Neural-Vocoder-with-Direct-Prediction-of-Amplitude-and-Phase-Spectra"><a href="#APNet2-High-quality-and-High-efficiency-Neural-Vocoder-with-Direct-Prediction-of-Amplitude-and-Phase-Spectra" class="headerlink" title="APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra"></a>APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11545">http://arxiv.org/abs/2311.11545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui-Peng Du, Ye-Xin Lu, Yang Ai, Zhen-Hua Ling<br>for: 提高高质量语音生成的实用性methods: 采用ConvNeXt v2作为后馈网络进行幅度和相位预测，并引入多分辨率检定器（MRD）进行GAN型损失优化results: 在常见配置下（即采样率22.05kHz，spectral frame shift256点，约11.6ms），提出的APNet2 vocoder在比较 HiFi-GAN和iSTFTNet等其他 vocoder的情况下，Synthesized speech质量达到了相同水平，同时具有迅速的推理速度。<details>
<summary>Abstract</summary>
In our previous work, we proposed a neural vocoder called APNet, which directly predicts speech amplitude and phase spectra with a 5 ms frame shift in parallel from the input acoustic features, and then reconstructs the 16 kHz speech waveform using inverse short-time Fourier transform (ISTFT). APNet demonstrates the capability to generate synthesized speech of comparable quality to the HiFi-GAN vocoder but with a considerably improved inference speed. However, the performance of the APNet vocoder is constrained by the waveform sampling rate and spectral frame shift, limiting its practicality for high-quality speech synthesis. Therefore, this paper proposes an improved iteration of APNet, named APNet2. The proposed APNet2 vocoder adopts ConvNeXt v2 as the backbone network for amplitude and phase predictions, expecting to enhance the modeling capability. Additionally, we introduce a multi-resolution discriminator (MRD) into the GAN-based losses and optimize the form of certain losses. At a common configuration with a waveform sampling rate of 22.05 kHz and spectral frame shift of 256 points (i.e., approximately 11.6ms), our proposed APNet2 vocoder outperformed the original APNet and Vocos vocoders in terms of synthesized speech quality. The synthesized speech quality of APNet2 is also comparable to that of HiFi-GAN and iSTFTNet, while offering a significantly faster inference speed.
</details>
<details>
<summary>摘要</summary>
在我们之前的工作中，我们提出了一种神经 vocoder called APNet，它直接预测了speech 幅和相位 спектrum 的 5 ms 帧shift 并在并行地从输入语音特征中预测，然后使用 inverse short-time Fourier transform (ISTFT) 重建 16 kHz 语音波形。APNet 表现出了能够生成与 HiFi-GAN vocoder 相当的质量的合成语音，但是它的推理速度明显提高。然而，APNet 的性能受到波形采样率和 spectral frame shift 的限制，限制了其实际应用的质量。因此，这篇文章提出了 APNet2  vocoder。我们的提议的 APNet2 vocoder 采用 ConvNeXt v2 作为幅和相位预测的背bone 网络，以提高模型的能力。此外，我们还引入了 multi-resolution discriminator (MRD) 到 GAN-based 损失中，并优化了某些损失的形式。在一般配置下（即波形采样率为 22.05 kHz，spectral frame shift 为 256点，约为 11.6ms），我们的提议的 APNet2 vocoder 在与原始 APNet 和 Vocos vocoders 的比较中表现出了较好的合成语音质量。同时，APNet2 的合成语音质量也与 HiFi-GAN 和 iSTFTNet 相当，而且具有了显著 faster 的推理速度。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/eess.AS_2023_11_20/" data-id="clpxp6c9l016lee88f883cbr5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.CV_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T13:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/cs.CV_2023_11_20/">cs.CV - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="HandSight-DeCAF-Improved-Fisher-Vectors-to-Classify-Clothing-Color-and-Texture-with-a-Finger-Mounted-Camera"><a href="#HandSight-DeCAF-Improved-Fisher-Vectors-to-Classify-Clothing-Color-and-Texture-with-a-Finger-Mounted-Camera" class="headerlink" title="HandSight: DeCAF &amp; Improved Fisher Vectors to Classify Clothing Color and Texture with a Finger-Mounted Camera"></a>HandSight: DeCAF &amp; Improved Fisher Vectors to Classify Clothing Color and Texture with a Finger-Mounted Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12225">http://arxiv.org/abs/2311.12225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander J. Medeiros, Lee Stearns, Jon E. Froehlich</li>
<li>for: 解决盲人每天选衣问题，使用手指搭载摄像头和现代分类算法。</li>
<li>methods: 使用DeCAF和改进的抽象报告图像特征进行服装 текстуre 分类。</li>
<li>results: 获得 &gt;95% 的准确率，并提供了一个大量的图像 dataset（HCTD）和现代分类算法的评估。<details>
<summary>Abstract</summary>
We demonstrate the use of DeCAF and Improved Fisher Vector image features to classify clothing texture. The issue of choosing clothes is a problem for the blind every day. This work attempts to solve the issue with a finger-mounted camera and state-of-the-art classification algorithms. To evaluate our solution, we collected 520 close-up images across 29 pieces of clothing. We contribute (1) the HCTD, an image dataset taken with a NanEyeGS camera, a camera small enough to be mounted on the finger, and (2) evaluations of state-of-the-art recognition algorithms applied to our dataset - achieving an accuracy >95%. Throughout the paper, we will discuss previous work, evaluate the current work, and finally, suggest the project's future direction.
</details>
<details>
<summary>摘要</summary>
我们展示了使用DeCAF和改进的鱼雷vector图像特征来分类服装Texture。每天选择衣服是盲人的问题。这项工作尝试解决这个问题通过用户手指上的摄像头和当今最佳分类算法。为评估我们的解决方案，我们收集了520个 close-up图像，涵盖29件不同的服装。我们的贡献包括（1）HCTD dataset，使用 NanEyeGS摄像头拍摄的图像集，该摄像头可以被安装在手指上，以及（2）对我们的数据集进行当今最佳recognition算法的评估，实现了准确率大于95%。在这篇论文中，我们将讨论前一项工作、评估当前工作，并最后提出未来项目的方向。
</details></li>
</ul>
<hr>
<h2 id="DiffAvatar-Simulation-Ready-Garment-Optimization-with-Differentiable-Simulation"><a href="#DiffAvatar-Simulation-Ready-Garment-Optimization-with-Differentiable-Simulation" class="headerlink" title="DiffAvatar: Simulation-Ready Garment Optimization with Differentiable Simulation"></a>DiffAvatar: Simulation-Ready Garment Optimization with Differentiable Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12194">http://arxiv.org/abs/2311.12194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifei Li, Hsiao-yu Chen, Egor Larionov, Nikolaos Sarafianos, Wojciech Matusik, Tuur Stuyck</li>
<li>for: 这个论文的目的是提高数字人体的现实感，以便实现虚拟存在和自定义。</li>
<li>methods: 这个论文使用了差分 simulation 技术来实现人体和服装的共优化。</li>
<li>results: 实验结果表明，这个方法可以生成现实的服装和人体形状，可以方便地应用于下游应用程序。Here’s the breakdown of each point in English:</li>
<li>for: The purpose of this paper is to improve the realism of digital avatars, enabling telepresence applications with self-expression and customization.</li>
<li>methods: The paper uses a novel approach called differentiable simulation to perform body and garment co-optimization.</li>
<li>results: The experimental results show that the proposed approach can generate realistic clothing and body shapes that can be easily used in downstream applications.<details>
<summary>Abstract</summary>
The realism of digital avatars is crucial in enabling telepresence applications with self-expression and customization. A key aspect of this realism originates from the physical accuracy of both a true-to-life body shape and clothing. While physical simulations can produce high-quality, realistic motions for clothed humans, they require precise estimation of body shape and high-quality garment assets with associated physical parameters for cloth simulations. However, manually creating these assets and calibrating their parameters is labor-intensive and requires specialized expertise. To address this gap, we propose DiffAvatar, a novel approach that performs body and garment co-optimization using differentiable simulation. By integrating physical simulation into the optimization loop and accounting for the complex nonlinear behavior of cloth and its intricate interaction with the body, our framework recovers body and garment geometry and extracts important material parameters in a physically plausible way. Our experiments demonstrate that our approach generates realistic clothing and body shape that can be easily used in downstream applications.
</details>
<details>
<summary>摘要</summary>
现实化数字人物的重要性在推动虚拟存在应用中具有自我表达和定制功能。一个关键的这种现实性来自于真实的身体形状和服装的物理准确性。虽然物理模拟可以生成高质量、现实的人类运动，但它们需要精准地估计身体形状和高质量的服装资产，并且需要特殊的专业知识来调整参数。为解决这个差距，我们提出了DiffAvatar，一种新的方法，它通过拥有可微的模拟来实现身体和服装的共优化。我们的框架将物理模拟集成到优化循环中，考虑到织物的复杂非线性行为和身体之间的细腻交互，从而实现了身体和服装的准确物理性。我们的实验表明，我们的方法可以生成现实的衣服和身体形状，可以方便地在下游应用中使用。
</details></li>
</ul>
<hr>
<h2 id="Disentangling-Structure-and-Appearance-in-ViT-Feature-Space"><a href="#Disentangling-Structure-and-Appearance-in-ViT-Feature-Space" class="headerlink" title="Disentangling Structure and Appearance in ViT Feature Space"></a>Disentangling Structure and Appearance in ViT Feature Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12193">http://arxiv.org/abs/2311.12193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narek Tumanyan, Omer Bar-Tal, Shir Amir, Shai Bagon, Tali Dekel</li>
<li>for: The paper is written for transferring the visual appearance of one natural image to another, specifically for generating an image where objects in a source structure image are “painted” with the visual appearance of their semantically related objects in a target appearance image.</li>
<li>methods: The paper uses a pre-trained and fixed Vision Transformer (ViT) model to leverage semantic information and derive novel disentangled representations of structure and appearance. The objective function splices the desired structure and appearance representations together in the space of ViT features.</li>
<li>results: The paper demonstrates high-resolution results on a variety of in-the-wild image pairs, under significant variations in the number of objects, pose, and appearance, without requiring adversarial training or additional input information such as semantic segmentation or correspondences.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是为了将一个自然图像的视觉特征转移到另一个图像上的。特别是，我们的目标是生成一个图像，其中源结构图像中的对象被”涂抹”上目标外观图像中的semantically相关的对象的视觉特征。</li>
<li>methods: 这篇论文使用一个预训练和固定的视觉转换器（ViT）模型，以利用 semantic信息并 deriv出新的分离的结构和外观表示。我们定义了一个目标函数，将愿望的结构和外观表示拼接在ViT特征空间中。</li>
<li>results: 这篇论文在一系列的宽频域自然图像对中 demonstarted高分辨率结果，面对对象的数量、 pose和外观变化，无需对抗恐或额外的输入信息，如semantic分割或对应关系。<details>
<summary>Abstract</summary>
We present a method for semantically transferring the visual appearance of one natural image to another. Specifically, our goal is to generate an image in which objects in a source structure image are "painted" with the visual appearance of their semantically related objects in a target appearance image. To integrate semantic information into our framework, our key idea is to leverage a pre-trained and fixed Vision Transformer (ViT) model. Specifically, we derive novel disentangled representations of structure and appearance extracted from deep ViT features. We then establish an objective function that splices the desired structure and appearance representations, interweaving them together in the space of ViT features. Based on our objective function, we propose two frameworks of semantic appearance transfer -- "Splice", which works by training a generator on a single and arbitrary pair of structure-appearance images, and "SpliceNet", a feed-forward real-time appearance transfer model trained on a dataset of images from a specific domain. Our frameworks do not involve adversarial training, nor do they require any additional input information such as semantic segmentation or correspondences. We demonstrate high-resolution results on a variety of in-the-wild image pairs, under significant variations in the number of objects, pose, and appearance. Code and supplementary material are available in our project page: splice-vit.github.io.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，可以将一个自然图像的视觉特征semantic transfer到另一个图像中。特icularly，我们的目标是将源结构图像中的 объекts "涂抹" 上 Target appearance image中的semantic相关的物体的视觉特征。为了 integrate semantic information into our framework, our key idea is to leverage a pre-trained and fixed Vision Transformer (ViT) model. Specifically, we derive novel disentangled representations of structure and appearance extracted from deep ViT features. We then establish an objective function that splices the desired structure and appearance representations, interweaving them together in the space of ViT features. Based on our objective function, we propose two frameworks of semantic appearance transfer -- "Splice", which works by training a generator on a single and arbitrary pair of structure-appearance images, and "SpliceNet", a feed-forward real-time appearance transfer model trained on a dataset of images from a specific domain. Our frameworks do not involve adversarial training, nor do they require any additional input information such as semantic segmentation or correspondences. We demonstrate high-resolution results on a variety of in-the-wild image pairs, under significant variations in the number of objects, pose, and appearance. Code and supplementary material are available in our project page: splice-vit.github.io.Here's the translation in Traditional Chinese:我们提出了一种方法，可以将一个自然图像的视觉特征semantic transfer到另一个图像中。特别是，我们的目标是将源结构图像中的 objects "涂抹" 上 Target appearance image中的semantic相关的物体的视觉特征。为了 integrate semantic information into our framework, our key idea is to leverage a pre-trained and fixed Vision Transformer (ViT) model. Specifically, we derive novel disentangled representations of structure and appearance extracted from deep ViT features. We then establish an objective function that splices the desired structure and appearance representations, interweaving them together in the space of ViT features. Based on our objective function, we propose two frameworks of semantic appearance transfer -- "Splice", which works by training a generator on a single and arbitrary pair of structure-appearance images, and "SpliceNet", a feed-forward real-time appearance transfer model trained on a dataset of images from a specific domain. Our frameworks do not involve adversarial training, nor do they require any additional input information such as semantic segmentation or correspondences. We demonstrate high-resolution results on a variety of in-the-wild image pairs, under significant variations in the number of objects, pose, and appearance. Code and supplementary material are available in our project page: splice-vit.github.io.
</details></li>
</ul>
<hr>
<h2 id="LABELMAKER-Automatic-Semantic-Label-Generation-from-RGB-D-Trajectories"><a href="#LABELMAKER-Automatic-Semantic-Label-Generation-from-RGB-D-Trajectories" class="headerlink" title="LABELMAKER: Automatic Semantic Label Generation from RGB-D Trajectories"></a>LABELMAKER: Automatic Semantic Label Generation from RGB-D Trajectories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12174">http://arxiv.org/abs/2311.12174</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silvan Weder, Hermann Blum, Francis Engelmann, Marc Pollefeys</li>
<li>for: 该论文主要用于提供一种自动生成2D&#x2F;3D标签框架，以便训练或评估视觉模型。</li>
<li>methods: 该框架基于多种现状顶尖分割模型和神经网络抽象 render，可以自动生成高精度的2D&#x2F;3D标签数据，不需要人工干预。</li>
<li>results: 对比手动标注的ScanNet数据集，该框架可以生成更高精度的标签数据，并自动标注了之前未标注的ARKitScenes数据集。<details>
<summary>Abstract</summary>
Semantic annotations are indispensable to train or evaluate perception models, yet very costly to acquire. This work introduces a fully automated 2D/3D labeling framework that, without any human intervention, can generate labels for RGB-D scans at equal (or better) level of accuracy than comparable manually annotated datasets such as ScanNet. Our approach is based on an ensemble of state-of-the-art segmentation models and 3D lifting through neural rendering. We demonstrate the effectiveness of our LabelMaker pipeline by generating significantly better labels for the ScanNet datasets and automatically labelling the previously unlabeled ARKitScenes dataset. Code and models are available at https://labelmaker.org
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于训练或评估观察模型， semantic annotation 是不可或缺的，但是它们很昂贵。这项工作提出了一个完全自动化的 2D/3D 标注框架，可以在等同于或更高的准确率下生成 RGB-D 扫描数据的标注，不需要人工干预。我们的方法基于 Ensemble 的 state-of-the-art  segmentation 模型和神经渲染的 3D 提升。我们在 LabelMaker 管道中证明了我们的方法的效果，通过生成 ScanNet 数据集中的更好的标注，并自动标注 ARKitScenes 数据集。可以在 https://labelmaker.org 获取代码和模型。Note: "Semantic annotation" in the text refers to the process of labeling objects or scenes in a video or image dataset with their semantic meaning (e.g., "chair", "table", "person", etc.).
</details></li>
</ul>
<hr>
<h2 id="ChemScraper-Graphics-Extraction-Molecular-Diagram-Parsing-and-Annotated-Data-Generation-for-PDF-Images"><a href="#ChemScraper-Graphics-Extraction-Molecular-Diagram-Parsing-and-Annotated-Data-Generation-for-PDF-Images" class="headerlink" title="ChemScraper: Graphics Extraction, Molecular Diagram Parsing, and Annotated Data Generation for PDF Images"></a>ChemScraper: Graphics Extraction, Molecular Diagram Parsing, and Annotated Data Generation for PDF Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12161">http://arxiv.org/abs/2311.12161</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/dprl/graphics-extraction">https://gitlab.com/dprl/graphics-extraction</a></li>
<li>paper_authors: Ayush Kumar Shah, Bryan Manrique Amador, Abhisek Dey, Ming Creekmore, Blake Ocampo, Scott Denmark, Richard Zanibbi</li>
<li>for: 这篇论文是为了提出一种将生成的PDF图像翻译为化学结构表示（CDXML）的方法。</li>
<li>methods: 这种方法使用了 born-digital PDF图像中的Explicit locations和 shapes来提取符号，然后应用简单的图形变换来捕捉图像和化学结构的视觉和化学结构。</li>
<li>results: 作者的方法可以快速（PDF $\rightarrow$ 视觉图 $\rightarrow$ 化学图）转化 born-digital PDF图像，并且不需要GPU、Optical Character Recognition（OCR）或vectorization。在标准准确性测试中，作者的方法可以与SMILES字符串进行高度准确的比较。<details>
<summary>Abstract</summary>
Existing visual parsers for molecule diagrams translate pixel-based raster images such as PNGs to chemical structure representations (e.g., SMILES). However, PDFs created by word processors including \LaTeX{} and Word provide explicit locations and shapes for characters, lines, and polygons. We %introduce a method to extract symbols from born-digital PDF molecule images and then apply simple graph transformations to capture both visual and chemical structure in editable ChemDraw files (CDXML). Our fast ( PDF $\rightarrow$ visual graph $\rightarrow$ chemical graph ) pipeline does not require GPUs, Optical Character Recognition (OCR) or vectorization. We evaluate on standard benchmarks using SMILES strings, along with a novel evaluation that provides graph-based metrics and error compilation using LgEval. The geometric information in born-digital PDFs produces a highly accurate parser, motivating generating training data for visual parsers that recognize from raster images, with extracted graphics, visual structure, and chemical structure as annotations. To do this we render SMILES strings in Indigo, parse molecule structure, and then validate recognized structure to select correct files.
</details>
<details>
<summary>摘要</summary>
现有的视觉解析器 для分子图表示图像（如PNG）可以将图像转换为化学结构表示（如SMILES）。然而，WORD处理器生成的PDF文档提供了显式的字体、线条和多边形的位置和形状信息。我们提出了一种方法，可以从生成的PDF分子图像中提取符号，然后应用简单的图形变换来捕捉图像中的视觉结构和化学结构，并将其保存为可编辑的ChemDraw文件（CDXML）。我们的快速（PDF $\rightarrow$ 视觉图 $\rightarrow$ 化学图）管道不需要GPU、Optical Character Recognition（OCR）或vectorization。我们在标准准确度测试上使用SMILES字符串进行评估，以及一种新的评估方法，使用LgEval进行图形基准测试和错误编译。生成的PDF中的几何信息使得我们的解析器具有非常高的准确率，这引起了生成用于视觉解析器的训练数据的需求，其中包括提取的图形、视觉结构和化学结构作为注释。为此，我们使用Indigo渲染SMILES字符串，解析分子结构，然后验证认出的结构是否正确，以选择正确的文件。
</details></li>
</ul>
<hr>
<h2 id="Model-aware-3D-Eye-Gaze-from-Weak-and-Few-shot-Supervisions"><a href="#Model-aware-3D-Eye-Gaze-from-Weak-and-Few-shot-Supervisions" class="headerlink" title="Model-aware 3D Eye Gaze from Weak and Few-shot Supervisions"></a>Model-aware 3D Eye Gaze from Weak and Few-shot Supervisions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12157">http://arxiv.org/abs/2311.12157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dimitris-christodoulou57/model-aware_3d_eye_gaze">https://github.com/dimitris-christodoulou57/model-aware_3d_eye_gaze</a></li>
<li>paper_authors: Nikola Popovic, Dimitrios Christodoulou, Danda Pani Paudel, Xi Wang, Luc Van Gool</li>
<li>for: 这个论文的目的是提出一种基于弱监睹的3D眼动识别方法，使用眼动 semantic segmentation图像来预测3D眼动。</li>
<li>methods: 该方法使用 transformer 网络架构，并将眼动 semantic segmentation图像和直接监睹的3D眼动vector composite together，以便适应3D眼动模型的预测。</li>
<li>results: 实验结果表明，该方法在多种场景下具有显著的优势，与基eline方法相比，angular gaze error下降约5度。此外，只使用0.05%的3D注解数据可以达到类似于基eline方法的性能。<details>
<summary>Abstract</summary>
The task of predicting 3D eye gaze from eye images can be performed either by (a) end-to-end learning for image-to-gaze mapping or by (b) fitting a 3D eye model onto images. The former case requires 3D gaze labels, while the latter requires eye semantics or landmarks to facilitate the model fitting. Although obtaining eye semantics and landmarks is relatively easy, fitting an accurate 3D eye model on them remains to be very challenging due to its ill-posed nature in general. On the other hand, obtaining large-scale 3D gaze data is cumbersome due to the required hardware setups and computational demands. In this work, we propose to predict 3D eye gaze from weak supervision of eye semantic segmentation masks and direct supervision of a few 3D gaze vectors. The proposed method combines the best of both worlds by leveraging large amounts of weak annotations--which are easy to obtain, and only a few 3D gaze vectors--which alleviate the difficulty of fitting 3D eye models on the semantic segmentation of eye images. Thus, the eye gaze vectors, used in the model fitting, are directly supervised using the few-shot gaze labels. Additionally, we propose a transformer-based network architecture, that serves as a solid baseline for our improvements. Our experiments in diverse settings illustrate the significant benefits of the proposed method, achieving about 5 degrees lower angular gaze error over the baseline, when only 0.05% 3D annotations of the training images are used. The source code is available at https://github.com/dimitris-christodoulou57/Model-aware_3D_Eye_Gaze.
</details>
<details>
<summary>摘要</summary>
“ predicting 3D eye gaze from eye images 可以通过（a）全程学习对图像与视线映射的映射，或者（b）将3D眼模型适配到图像上。前者需要3D gaze标签，而后者需要眼动 semantics或特征点来促进模型适配。虽然获取眼动 semantics 和特征点 Comparatively easy, but fitting an accurate 3D eye model on them remains challenging due to its ill-posed nature in general。另一方面，获取大规模3D gaze数据 cumbersome due to the required hardware setups and computational demands。在这个工作中，我们提出了基于弱级别指导的3D eye gaze预测方法。该方法结合了大量弱级别指导（容易获取）和直接监督一些3D gaze вектор。因此，使用 Direct supervision of a few 3D gaze vectors alleviates the difficulty of fitting 3D eye models on the semantic segmentation of eye images。此外，我们还提出了一种基于 transformer 网络架构的方法，作为我们的提高基础。我们的实验在多种设定下证明了我们的方法具有显著的优势，在使用0.05% 3D注解的训练图像时，angular gaze error 降低约5度。源代码可以在 <https://github.com/dimitris-christodoulou57/Model-aware_3D_Eye_Gaze> 中获取。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-in-Contrast-Enhanced-MR-Image-Translation-with-Multi-Axis-Fusion"><a href="#Uncertainty-Estimation-in-Contrast-Enhanced-MR-Image-Translation-with-Multi-Axis-Fusion" class="headerlink" title="Uncertainty Estimation in Contrast-Enhanced MR Image Translation with Multi-Axis Fusion"></a>Uncertainty Estimation in Contrast-Enhanced MR Image Translation with Multi-Axis Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12153">http://arxiv.org/abs/2311.12153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivo M. Baltruschat, Parvaneh Janbakhshi, Melanie Dohmen, Matthias Lenga</li>
<li>for: 这个论文主要针对的是医学影像转换任务中的知识不确定性评估。</li>
<li>methods: 该论文提出了一种基于多视角图像数据的多轴融合（MAF）模型不确定性评估方法。</li>
<li>results: 对于Synthesizing contrast enhanced T1-weighted images based on native T1, T2和T2-FLAIR scans任务，该方法显示了良好的相对误差和不确定性评估结果（$\rho_{\text healthy} &#x3D; 0.89$）。<details>
<summary>Abstract</summary>
In recent years, deep learning has been applied to a wide range of medical imaging and image processing tasks. In this work, we focus on the estimation of epistemic uncertainty for 3D medical image-to-image translation. We propose a novel model uncertainty quantification method, Multi-Axis Fusion (MAF), which relies on the integration of complementary information derived from multiple views on volumetric image data. The proposed approach is applied to the task of synthesizing contrast enhanced T1-weighted images based on native T1, T2 and T2-FLAIR scans. The quantitative findings indicate a strong correlation ($\rho_{\text healthy} = 0.89$) between the mean absolute image synthetization error and the mean uncertainty score for our MAF method. Hence, we consider MAF as a promising approach to solve the highly relevant task of detecting synthetization failures at inference time.
</details>
<details>
<summary>摘要</summary>
Note:* "epistemic uncertainty" refers to the uncertainty in the knowledge of the model, i.e., the uncertainty in the output of the model due to the limitations of the model's understanding of the input data.* "image-to-image translation" refers to the task of translating an input image from one modality or domain to another, e.g., translating a native T1 scan to a contrast-enhanced T1-weighted image.* "synthesizing" refers to the process of generating a new image based on input data, e.g., synthesizing a contrast-enhanced T1-weighted image based on native T1, T2, and T2-FLAIR scans.* "uncertainty quantification" refers to the process of estimating the uncertainty of a model's output, e.g., estimating the uncertainty of the synthesized image.* "failure detection" refers to the process of detecting when the model's output is incorrect or unreliable, e.g., detecting when the synthesized image is of poor quality or does not accurately represent the input data.
</details></li>
</ul>
<hr>
<h2 id="Applications-of-Large-Scale-Foundation-Models-for-Autonomous-Driving"><a href="#Applications-of-Large-Scale-Foundation-Models-for-Autonomous-Driving" class="headerlink" title="Applications of Large Scale Foundation Models for Autonomous Driving"></a>Applications of Large Scale Foundation Models for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12144">http://arxiv.org/abs/2311.12144</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Huang, Yue Chen, Zhu Li</li>
<li>for: 本研究旨在应用基础模型和大语言模型（LLM）于自动驾驶系统中，以解决现有AI长尾问题。</li>
<li>methods: 本研究使用了基础模型和LLM，包括模拟、世界模型、数据标注和观念规划等方法。</li>
<li>results: 本研究发现，通过结合基础模型和LLM，可以将人类知识、常识和推理应用到自动驾驶系统中，从而解决现有AI长尾问题。<details>
<summary>Abstract</summary>
Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007, autonomous driving has been the most active field of AI applications. Recently powered by large language models (LLMs), chat systems, such as chatGPT and PaLM, emerge and rapidly become a promising direction to achieve artificial general intelligence (AGI) in natural language processing (NLP). There comes a natural thinking that we could employ these abilities to reformulate autonomous driving. By combining LLM with foundation models, it is possible to utilize the human knowledge, commonsense and reasoning to rebuild autonomous driving systems from the current long-tailed AI dilemma. In this paper, we investigate the techniques of foundation models and LLMs applied for autonomous driving, categorized as simulation, world model, data annotation and planning or E2E solutions etc.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "rural" and "urban" challenges are translated as "DARPA Grand Challenges" in Simplified Chinese, as the term "rural" and "urban" are not commonly used in Chinese.* "long-tailed AI dilemma" is translated as "current long-tailed AI dilemma" in Simplified Chinese, as the phrase "long-tailed" is not commonly used in Chinese.* "foundation models" is translated as "基础模型" in Simplified Chinese, as the term "foundation" is not commonly used in Chinese.* "LLMs" is translated as "大语言模型" in Simplified Chinese, as the term "LLM" is not commonly used in Chinese.* "planning or E2E solutions" is translated as "规划或E2E解决方案" in Simplified Chinese, as the term "E2E" is not commonly used in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Fingerspelling-PoseNet-Enhancing-Fingerspelling-Translation-with-Pose-Based-Transformer-Models"><a href="#Fingerspelling-PoseNet-Enhancing-Fingerspelling-Translation-with-Pose-Based-Transformer-Models" class="headerlink" title="Fingerspelling PoseNet: Enhancing Fingerspelling Translation with Pose-Based Transformer Models"></a>Fingerspelling PoseNet: Enhancing Fingerspelling Translation with Pose-Based Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12128">http://arxiv.org/abs/2311.12128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pooya Fayyazsanavi, Negar Nejatishahidin, Jana Kosecka</li>
<li>for: 本研究旨在提高美国手语指写翻译的精度，使用视频在野进行 fingerspelling 翻译。</li>
<li>methods: 该研究利用了更加准确的手姿估计技术，并提出了一种基于 transformer 编码器-解码器模型的新型建议，允许无缝上下文ual word 翻译。此外，研究还添加了一种新的损失函数，以准确预测手写字符串的长度，从而提高训练和推测的性能。</li>
<li>results: 通过了广泛的实验，研究人员表明了其提议的方法在 ChicagoFSWild 和 ChicagoFSWild+ 上的超过 10% 的相对改进。这些结果表明了该方法的有效性，并且可能推动手语翻译的进步。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/pooyafayyaz/Fingerspelling-PoseNet">https://github.com/pooyafayyaz/Fingerspelling-PoseNet</a> 上获取。<details>
<summary>Abstract</summary>
We address the task of American Sign Language fingerspelling translation using videos in the wild. We exploit advances in more accurate hand pose estimation and propose a novel architecture that leverages the transformer based encoder-decoder model enabling seamless contextual word translation. The translation model is augmented by a novel loss term that accurately predicts the length of the finger-spelled word, benefiting both training and inference. We also propose a novel two-stage inference approach that re-ranks the hypotheses using the language model capabilities of the decoder. Through extensive experiments, we demonstrate that our proposed method outperforms the state-of-the-art models on ChicagoFSWild and ChicagoFSWild+ achieving more than 10% relative improvement in performance. Our findings highlight the effectiveness of our approach and its potential to advance fingerspelling recognition in sign language translation. Code is also available at https://github.com/pooyafayyaz/Fingerspelling-PoseNet.
</details>
<details>
<summary>摘要</summary>
我们 Addressing the task of American Sign Language fingerspelling translation using videos in the wild. We exploit advances in more accurate hand pose estimation and propose a novel architecture that leverages the transformer based encoder-decoder model enabling seamless contextual word translation. The translation model is augmented by a novel loss term that accurately predicts the length of the finger-spelled word, benefiting both training and inference. We also propose a novel two-stage inference approach that re-ranks the hypotheses using the language model capabilities of the decoder. Through extensive experiments, we demonstrate that our proposed method outperforms the state-of-the-art models on ChicagoFSWild and ChicagoFSWild+ achieving more than 10% relative improvement in performance. Our findings highlight the effectiveness of our approach and its potential to advance fingerspelling recognition in sign language translation. 码也可以在https://github.com/pooyafayyaz/Fingerspelling-PoseNet 查看。
</details></li>
</ul>
<hr>
<h2 id="Concept-Sliders-LoRA-Adaptors-for-Precise-Control-in-Diffusion-Models"><a href="#Concept-Sliders-LoRA-Adaptors-for-Precise-Control-in-Diffusion-Models" class="headerlink" title="Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models"></a>Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12092">http://arxiv.org/abs/2311.12092</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rohitgandikota/sliders">https://github.com/rohitgandikota/sliders</a></li>
<li>paper_authors: Rohit Gandikota, Joanna Materzynska, Tingrui Zhou, Antonio Torralba, David Bau</li>
<li>for: 这个论文的目的是创建可解释的概念滑块，以便在扩散模型中控制图像生成中的属性。</li>
<li>methods: 这个方法利用了一个低纬度参数方向，以实现一个概念的精确控制，同时尽量减少其他属性的干扰。这个滑块可以通过一小组的提示或样本图像来创建，因此可以为文本或视觉概念创建滑块。</li>
<li>results: 对比之前的编辑技术，我们的滑块显示出更强的target编辑和更低的干扰。我们还展示了滑块的组合和连续调整，以及在StyleGAN中的intuitive编辑。此外，我们发现我们的方法可以帮助解决扩散过程中的一些常见问题，如物体扭曲和手部扭曲。我们的代码、数据和训练滑块可以在<a target="_blank" rel="noopener" href="https://sliders.baulab.info/%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://sliders.baulab.info/上获取。</a><details>
<summary>Abstract</summary>
We present a method to create interpretable concept sliders that enable precise control over attributes in image generations from diffusion models. Our approach identifies a low-rank parameter direction corresponding to one concept while minimizing interference with other attributes. A slider is created using a small set of prompts or sample images; thus slider directions can be created for either textual or visual concepts. Concept Sliders are plug-and-play: they can be composed efficiently and continuously modulated, enabling precise control over image generation. In quantitative experiments comparing to previous editing techniques, our sliders exhibit stronger targeted edits with lower interference. We showcase sliders for weather, age, styles, and expressions, as well as slider compositions. We show how sliders can transfer latents from StyleGAN for intuitive editing of visual concepts for which textual description is difficult. We also find that our method can help address persistent quality issues in Stable Diffusion XL including repair of object deformations and fixing distorted hands. Our code, data, and trained sliders are available at https://sliders.baulab.info/
</details>
<details>
<summary>摘要</summary>
我们提出了一种可解释的概念滑块创建方法，用于在扩散模型中控制特征。我们的方法可以在一个概念方向下确定低维度参数方向，以避免其他特征干扰。我们使用一小集的提示或样本图像来创建滑块，因此滑块方向可以基于文本概念或视觉概念。我们称之为概念滑块，可以高效地组合和连续调整，以实现图像生成的精确控制。在对比前期技术的量化实验中，我们的滑块表现出更强的特定编辑效果，同时干扰下降。我们展示了不同气候、年龄、风格和表情等概念滑块，以及如何将滑块组合以实现更复杂的图像生成。此外，我们发现我们的方法可以帮助解决扩散xl中的持续质量问题，如修复物体扭形和扭formed手部。我们的代码、数据和训练滑块可以在https://sliders.baulab.info/中获取。
</details></li>
</ul>
<hr>
<h2 id="PF-LRM-Pose-Free-Large-Reconstruction-Model-for-Joint-Pose-and-Shape-Prediction"><a href="#PF-LRM-Pose-Free-Large-Reconstruction-Model-for-Joint-Pose-and-Shape-Prediction" class="headerlink" title="PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction"></a>PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12024">http://arxiv.org/abs/2311.12024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Hao Tan, Sai Bi, Yinghao Xu, Fujun Luan, Kalyan Sunkavalli, Wenping Wang, Zexiang Xu, Kai Zhang</li>
<li>for: 这个论文是为了重构3D对象从几个无法定位的图像中，同时估计相机pose，并在1.3秒钟内完成这个任务。</li>
<li>methods: 这个方法使用了自注意机制来交换3D对象token和2D图像token之间的信息，预测每个视角的粗略点云，然后使用可导Perspective-n-Point（PnP）解决器来获取相机pose。</li>
<li>results: 当训练在大量多视图定位数据上（约1M个对象）时，PF-LRM表现出了强泛化能力，并在不同评估数据集上超过基eline方法的姿态预测精度和3D重建质量。此外，我们还证明了这个模型在文本&#x2F;图像-to-3D任务中的应用性，通过快速前向推理。更多信息请访问我们的项目网站：<a target="_blank" rel="noopener" href="https://totoro97.github.io/pf-lrm%E3%80%82">https://totoro97.github.io/pf-lrm。</a><details>
<summary>Abstract</summary>
We propose a Pose-Free Large Reconstruction Model (PF-LRM) for reconstructing a 3D object from a few unposed images even with little visual overlap, while simultaneously estimating the relative camera poses in ~1.3 seconds on a single A100 GPU. PF-LRM is a highly scalable method utilizing the self-attention blocks to exchange information between 3D object tokens and 2D image tokens; we predict a coarse point cloud for each view, and then use a differentiable Perspective-n-Point (PnP) solver to obtain camera poses. When trained on a huge amount of multi-view posed data of ~1M objects, PF-LRM shows strong cross-dataset generalization ability, and outperforms baseline methods by a large margin in terms of pose prediction accuracy and 3D reconstruction quality on various unseen evaluation datasets. We also demonstrate our model's applicability in downstream text/image-to-3D task with fast feed-forward inference. Our project website is at: https://totoro97.github.io/pf-lrm .
</details>
<details>
<summary>摘要</summary>
我们提出了一种无 pose 大型重建模型（PF-LRM），可以从几张无 pose 图像中重建3D对象，甚至在视觉重叠少的情况下，在单个 A100 GPU 上运行时间约为1.3秒。PF-LRM 是一种高度可扩展的方法，通过自我注意块来交换3D对象标记和2D图像标记之间的信息；我们预测每个视图中的粗略点云，然后使用可导式 Perspective-n-Point（PnP）解决方案来获取相机位置。当在大量多视图posed数据上训练时，PF-LRM 显示出强大的跨数据集泛化能力，并在不同评估数据集上超越基线方法的姿态预测精度和3D重建质量。我们还证明了我们的模型在文本/图像到3D任务中的应用性，通过快速 feed-forward 推理来实现。我们的项目网站位于：https://totoro97.github.io/pf-lrm .
</details></li>
</ul>
<hr>
<h2 id="DAS-A-Deformable-Attention-to-Capture-Salient-Information-in-CNNs"><a href="#DAS-A-Deformable-Attention-to-Capture-Salient-Information-in-CNNs" class="headerlink" title="DAS: A Deformable Attention to Capture Salient Information in CNNs"></a>DAS: A Deformable Attention to Capture Salient Information in CNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12091">http://arxiv.org/abs/2311.12091</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farzad Salajegheh, Nader Asadi, Soroush Saryazdi, Sudhir Mudur</li>
<li>for: 提高图像识别和物体检测的性能</li>
<li>methods: 使用弹性卷积和分解卷积实现快速和简单的全 convolutional 方法 DAS，以增强模型对重要信息的访问</li>
<li>results: 在添加 DAS 到流行的 CNN 上进行图像分类和物体检测时，得到了性能提高（比如，Stanford Dogs 上的提高率为4.47%，ImageNet 上的提高率为1.91%，COCO AP 上的提高率为3.3%），超过了其他 CNN 注意机制的性能，使用相同或更少的 FLOPs。<details>
<summary>Abstract</summary>
Convolutional Neural Networks (CNNs) excel in local spatial pattern recognition. For many vision tasks, such as object recognition and segmentation, salient information is also present outside CNN's kernel boundaries. However, CNNs struggle in capturing such relevant information due to their confined receptive fields. Self-attention can improve a model's access to global information but increases computational overhead. We present a fast and simple fully convolutional method called DAS that helps focus attention on relevant information. It uses deformable convolutions for the location of pertinent image regions and separable convolutions for efficiency. DAS plugs into existing CNNs and propagates relevant information using a gating mechanism. Compared to the O(n^2) computational complexity of transformer-style attention, DAS is O(n). Our claim is that DAS's ability to pay increased attention to relevant features results in performance improvements when added to popular CNNs for Image Classification and Object Detection. For example, DAS yields an improvement on Stanford Dogs (4.47%), ImageNet (1.91%), and COCO AP (3.3%) with base ResNet50 backbone. This outperforms other CNN attention mechanisms while using similar or less FLOPs. Our code will be publicly available.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在本地空间模式识别方面表现出色。然而，对于许多视觉任务，如物体识别和分割，salient information 也存在外部 CNN 的核心 boundaries。然而，CNN 很难捕捉这些相关信息，因为它们的捕捉范围太窄。自我注意可以提高模型对全球信息的访问权，但是会增加计算开销。我们提出了一种快速、简单的全 convolutional 方法called DAS，它使用可变尺寸 convolution 来定位相关图像区域，并使用分解 convolution 来提高效率。DAS 可以与现有 CNN 集成，并通过阀门机制将相关信息传递给下一层。相比于 transformer 样式的注意力计算复杂度 O(n^2)，DAS 的计算复杂度为 O(n)。我们的主张是，DAS 能够增加对相关特征的注意力，会在添加到流行的 CNN 上进行图像分类和物体检测中提高性能。例如，DAS 在 Stanford Dogs 上获得了 4.47% 的改进，在 ImageNet 上获得了 1.91% 的改进，并在 COCO AP 上获得了 3.3% 的改进。这超过了其他 CNN 注意力机制，同时使用相同或更少的 FLOPs。我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="FrePolad-Frequency-Rectified-Point-Latent-Diffusion-for-Point-Cloud-Generation"><a href="#FrePolad-Frequency-Rectified-Point-Latent-Diffusion-for-Point-Cloud-Generation" class="headerlink" title="FrePolad: Frequency-Rectified Point Latent Diffusion for Point Cloud Generation"></a>FrePolad: Frequency-Rectified Point Latent Diffusion for Point Cloud Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12090">http://arxiv.org/abs/2311.12090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenliang Zhou, Fangcheng Zhong, Param Hanji, Zhilin Guo, Kyle Fogarty, Alejandro Sztrajman, Hongyun Gao, Cengiz Oztireli</li>
<li>for: 该论文旨在提出一种基于自适应变换的点云生成管线，以实现高质量、多样性和可控的点云数量生成任务。</li>
<li>methods: 该管线使用了一种新的频率纠正模块，通过圆形幂等方法来保持高频域内容，同时学习点云分布。此外，该管线还使用了一种梯度随机过程模型来学习拟合的离散分布。</li>
<li>results: 相比于现有的方法，该管线能够实现高质量、多样性和可控的点云数量生成，同时具有高效的计算性。我们的量化和 качеitative结果都证明了 FrePolad 的 estado-of-the-art 性。<details>
<summary>Abstract</summary>
We propose FrePolad: frequency-rectified point latent diffusion, a point cloud generation pipeline integrating a variational autoencoder (VAE) with a denoising diffusion probabilistic model (DDPM) for the latent distribution. FrePolad simultaneously achieves high quality, diversity, and flexibility in point cloud cardinality for generation tasks while maintaining high computational efficiency. The improvement in generation quality and diversity is achieved through (1) a novel frequency rectification module via spherical harmonics designed to retain high-frequency content while learning the point cloud distribution; and (2) a latent DDPM to learn the regularized yet complex latent distribution. In addition, FrePolad supports variable point cloud cardinality by formulating the sampling of points as conditional distributions over a latent shape distribution. Finally, the low-dimensional latent space encoded by the VAE contributes to FrePolad's fast and scalable sampling. Our quantitative and qualitative results demonstrate the state-of-the-art performance of FrePolad in terms of quality, diversity, and computational efficiency.
</details>
<details>
<summary>摘要</summary>
我们提出了FrePolad：一种结合变量自动编码器（VAE）和杂化扩散概率模型（DDPM）的点云生成管道，用于点云生成任务中的高质量、多样性和可变性。FrePolad同时实现了高效率和低维度的点云生成。我们通过以下两个方法提高生成质量和多样性：1. 通过圆柱幂融合学习点云分布，保留高频内容并减少噪声，实现高质量点云生成。2. 使用杂化扩散模型学习受杂化的幂值分布，以获得规则化但复杂的latent分布。此外，FrePolad支持可变点云Cardinality，通过对latent shape分布进行采样来实现。最后，VAE嵌入的低维度latent空间使得FrePolad的采样速度快且可扩展。我们的量化和质量效果表明FrePolad在质量、多样性和计算效率三个方面具有前所未有的表现。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-HMR-3D-Human-Mesh-Recovery-from-LiDAR"><a href="#LiDAR-HMR-3D-Human-Mesh-Recovery-from-LiDAR" class="headerlink" title="LiDAR-HMR: 3D Human Mesh Recovery from LiDAR"></a>LiDAR-HMR: 3D Human Mesh Recovery from LiDAR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11971">http://arxiv.org/abs/2311.11971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soullessrobot/lidar-hmr">https://github.com/soullessrobot/lidar-hmr</a></li>
<li>paper_authors: Bohao Fan, Wenzhao Zheng, Jianjiang Feng, Jie Zhou</li>
<li>for: 这篇论文旨在计算 sparse LiDAR 点云中的3D人体干树结构。</li>
<li>methods: 该论文提出了一种有效的稀疏到粗糙重建方法，通过估计3D人体姿势和逐渐重建人体干树结构。为更好地利用点云的3D结构信息，该方法使用了一种垂直堆栈Transformer（graphormer）来引入点云特征。</li>
<li>results: 对于三个公共可用的数据库进行了实验，并达到了效果的结果。Here’s the translation in English:</li>
<li>for: This paper aims to estimate the 3D human body mesh from sparse LiDAR point clouds.</li>
<li>methods: The proposed method uses an effective sparse-to-dense reconstruction scheme to reconstruct the 3D human mesh, by estimating a sparse representation of the human (3D human pose) and gradually reconstructing the body mesh. To better leverage the 3D structural information of point clouds, the method employs a cascaded graph transformer (graphormer) to introduce point cloud features during sparse-to-dense reconstruction.</li>
<li>results: Experimental results on three publicly available databases demonstrate the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
In recent years, point cloud perception tasks have been garnering increasing attention. This paper presents the first attempt to estimate 3D human body mesh from sparse LiDAR point clouds. We found that the major challenge in estimating human pose and mesh from point clouds lies in the sparsity, noise, and incompletion of LiDAR point clouds. Facing these challenges, we propose an effective sparse-to-dense reconstruction scheme to reconstruct 3D human mesh. This involves estimating a sparse representation of a human (3D human pose) and gradually reconstructing the body mesh. To better leverage the 3D structural information of point clouds, we employ a cascaded graph transformer (graphormer) to introduce point cloud features during sparse-to-dense reconstruction. Experimental results on three publicly available databases demonstrate the effectiveness of the proposed approach. Code: https://github.com/soullessrobot/LiDAR-HMR/
</details>
<details>
<summary>摘要</summary>
Recently, point cloud perception tasks have been gaining increasing attention. This paper presents the first attempt to estimate 3D human body mesh from sparse LiDAR point clouds. We found that the major challenge in estimating human pose and mesh from point clouds lies in the sparsity, noise, and incompleteness of LiDAR point clouds. To address these challenges, we propose an effective sparse-to-dense reconstruction scheme to reconstruct 3D human mesh. This involves estimating a sparse representation of a human (3D human pose) and gradually reconstructing the body mesh. To better leverage the 3D structural information of point clouds, we employ a cascaded graph transformer (graphormer) to introduce point cloud features during sparse-to-dense reconstruction. Experimental results on three publicly available databases demonstrate the effectiveness of the proposed approach. Code: https://github.com/soullessrobot/LiDAR-HMR/.Here's the translation in Traditional Chinese:近年来，点云识别任务 receiving increasing attention. 本篇文章提出了首次从稀叠 LiDAR 点云中 estimate 3D 人体网格. 我们发现，从点云中 estimate 人姿和网格的主要挑战在于稀叠、噪音和缺失 LiDAR 点云的问题. 面对这些挑战，我们提出了一个有效的稀叠到简的重建方案，从稀叠的人姿中逐步重建人体网格. 为了更好地利用点云的3D 结构资讯，我们使用了弹性的图形变换器 (graphormer) 引入点云特征 During sparse-to-dense reconstruction. 实验结果显示，提出的方法具有效iveness. Code: https://github.com/soullessrobot/LiDAR-HMR/.
</details></li>
</ul>
<hr>
<h2 id="SA-Med2D-20M-Dataset-Segment-Anything-in-2D-Medical-Imaging-with-20-Million-masks"><a href="#SA-Med2D-20M-Dataset-Segment-Anything-in-2D-Medical-Imaging-with-20-Million-masks" class="headerlink" title="SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20 Million masks"></a>SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20 Million masks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11969">http://arxiv.org/abs/2311.11969</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/SAM-Med2D">https://github.com/OpenGVLab/SAM-Med2D</a></li>
<li>paper_authors: Jin Ye, Junlong Cheng, Jianpin Chen, Zhongying Deng, Tianbin Li, Haoyu Wang, Yanzhou Su, Ziyan Huang, Jilong Chen, Lei Jiang, Hui Sun, Min Zhu, Shaoting Zhang, Junjun He, Yu Qiao</li>
<li>For: The paper is written for developing medical artificial intelligence for enhancing diagnosis, medical image analysis, knowledge sharing, and education.* Methods: The paper introduces SA-Med2D-20M, a large-scale segmentation dataset of 2D medical images built upon numerous public and private datasets, which consists of 4.6 million 2D medical images and 19.7 million corresponding masks covering almost the whole body and showing significant diversity.* Results: The paper presents comprehensive statistics of SA-Med2D-20M to facilitate the better use of the dataset, which can help researchers build medical vision foundation models or apply their models to downstream medical applications.<details>
<summary>Abstract</summary>
Segment Anything Model (SAM) has achieved impressive results for natural image segmentation with input prompts such as points and bounding boxes. Its success largely owes to massive labeled training data. However, directly applying SAM to medical image segmentation cannot perform well because SAM lacks medical knowledge -- it does not use medical images for training. To incorporate medical knowledge into SAM, we introduce SA-Med2D-20M, a large-scale segmentation dataset of 2D medical images built upon numerous public and private datasets. It consists of 4.6 million 2D medical images and 19.7 million corresponding masks, covering almost the whole body and showing significant diversity. This paper describes all the datasets collected in SA-Med2D-20M and details how to process these datasets. Furthermore, comprehensive statistics of SA-Med2D-20M are presented to facilitate the better use of our dataset, which can help the researchers build medical vision foundation models or apply their models to downstream medical applications. We hope that the large scale and diversity of SA-Med2D-20M can be leveraged to develop medical artificial intelligence for enhancing diagnosis, medical image analysis, knowledge sharing, and education. The data with the redistribution license is publicly available at https://github.com/OpenGVLab/SAM-Med2D.
</details>
<details>
<summary>摘要</summary>
segments anything model (SAM) 已经取得了天然图像分割的出色结果，使用点和 bounding box 作为输入提示。其成功主要归功于大量标注训练数据。然而，直接将 SAM 应用于医疗图像分割是不可取的，因为 SAM 缺乏医疗知识 -- 它没有使用医疗图像进行训练。为了将医疗知识 integrate 到 SAM 中，我们介绍了 SA-Med2D-20M，一个基于多个公共和私人数据集的大规模分割dataset。它包括 4.6 万个 2D 医疗图像和 19.7 万个相应的mask，覆盖了大部分的身体和显示了显著的多样性。本文描述了 SA-Med2D-20M 中所收集的所有数据集，并详细介绍如何处理这些数据集。此外，我们还提供了 SA-Med2D-20M 的全面统计数据，以便更好地使用我们的数据集，帮助研究人员建立医疗视觉基础模型或将其模型应用到下游医疗应用。我们希望通过 SA-Med2D-20M 的大规模和多样性，为医疗人工智能的发展做出贡献，以便提高诊断、医疗图像分析、知识共享和教育。数据集的红色分布授权是公共可用的，可以在 <https://github.com/OpenGVLab/SAM-Med2D> 上下载。
</details></li>
</ul>
<hr>
<h2 id="What-Can-AutoML-Do-For-Continual-Learning"><a href="#What-Can-AutoML-Do-For-Continual-Learning" class="headerlink" title="What Can AutoML Do For Continual Learning?"></a>What Can AutoML Do For Continual Learning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11963">http://arxiv.org/abs/2311.11963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mert Kilickaya, Joaquin Vanschoren</li>
<li>for: 该论文探讨了AutoML在逐步学习中的潜在应用，具体来说是如何使用AutoML方法来促进逐步学习的更多研究。</li>
<li>methods: 该论文不直接提出新方法，而是通过提出“什么样的AutoML方法可以用于逐步学习”这个问题，探讨了三个关键的研究方向，即使用AutoML方法来实现更动态的逐步学习，挑战了AutoML研究领域的新问题。</li>
<li>results: 该论文未直接提出新方法，但是通过探讨AutoML在逐步学习中的应用，提出了三个关键的研究方向，这些研究方向可能会带来更多的研究和应用。<details>
<summary>Abstract</summary>
This position paper outlines the potential of AutoML for incremental (continual) learning to encourage more research in this direction. Incremental learning involves incorporating new data from a stream of tasks and distributions to learn enhanced deep representations and adapt better to new tasks. However, a significant limitation of incremental learners is that most current techniques freeze the backbone architecture, hyperparameters, and the order & structure of the learning tasks throughout the learning and adaptation process. We strongly believe that AutoML offers promising solutions to address these limitations, enabling incremental learning to adapt to more diverse real-world tasks. Therefore, instead of directly proposing a new method, this paper takes a step back by posing the question: "What can AutoML do for incremental learning?" We outline three key areas of research that can contribute to making incremental learners more dynamic, highlighting concrete opportunities to apply AutoML methods in novel ways as well as entirely new challenges for AutoML research.
</details>
<details>
<summary>摘要</summary>
这份位点论文描述了AutoML在逐渐学习方面的潜在潜力，以促进更多关于这个方向的研究。逐渐学习是指在流动任务和分布中逐渐 incorporating new data，以学习提高深度表示和适应新任务。然而，现有的逐渐学习技术的一个重要限制是，它们在学习和适应过程中冻结了背bone架构、超参数和学习任务的顺序和结构。我们强烈认为，AutoML可以为逐渐学习提供了可能的解决方案，使其能够更好地适应多样化的实际任务。因此，而不是直接提出一种新方法，这篇论文做出了一个问题："AutoML可以做什么为逐渐学习？"我们详细描述了三个关键的研究领域，可以使逐渐学习更加动态，并高亮了可以应用AutoML方法的具体机会以及 entirely new challenges for AutoML research。
</details></li>
</ul>
<hr>
<h2 id="An-Image-is-Worth-Multiple-Words-Multi-attribute-Inversion-for-Constrained-Text-to-Image-Synthesis"><a href="#An-Image-is-Worth-Multiple-Words-Multi-attribute-Inversion-for-Constrained-Text-to-Image-Synthesis" class="headerlink" title="An Image is Worth Multiple Words: Multi-attribute Inversion for Constrained Text-to-Image Synthesis"></a>An Image is Worth Multiple Words: Multi-attribute Inversion for Constrained Text-to-Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11919">http://arxiv.org/abs/2311.11919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aishwarya Agarwal, Srikrishna Karanam, Tripti Shukla, Balaji Vasan Srinivasan</li>
<li>for: 本文的主要目标是使用单个参考图像提取多个特征（如颜色、物体、布局、风格），并生成新样本以这些特征为条件。</li>
<li>methods: 本文提出了一种新的多特征倒拍算法（MATTE），该算法在DDPM模型层级和时间步级上同时学习多个嵌入，以提高特征分离。</li>
<li>results: 本文通过广泛的分析和实验表明，MATTE算法可以更好地分离多个特征，并且可以生成更高质量的样本。<details>
<summary>Abstract</summary>
We consider the problem of constraining diffusion model outputs with a user-supplied reference image. Our key objective is to extract multiple attributes (e.g., color, object, layout, style) from this single reference image, and then generate new samples with them. One line of existing work proposes to invert the reference images into a single textual conditioning vector, enabling generation of new samples with this learned token. These methods, however, do not learn multiple tokens that are necessary to condition model outputs on the multiple attributes noted above. Another line of techniques expand the inversion space to learn multiple embeddings but they do this only along the layer dimension (e.g., one per layer of the DDPM model) or the timestep dimension (one for a set of timesteps in the denoising process), leading to suboptimal attribute disentanglement. To address the aforementioned gaps, the first contribution of this paper is an extensive analysis to determine which attributes are captured in which dimension of the denoising process. As noted above, we consider both the time-step dimension (in reverse denoising) as well as the DDPM model layer dimension. We observe that often a subset of these attributes are captured in the same set of model layers and/or across same denoising timesteps. For instance, color and style are captured across same U-Net layers, whereas layout and color are captured across same timestep stages. Consequently, an inversion process that is designed only for the time-step dimension or the layer dimension is insufficient to disentangle all attributes. This leads to our second contribution where we design a new multi-attribute inversion algorithm, MATTE, with associated disentanglement-enhancing regularization losses, that operates across both dimensions and explicitly leads to four disentangled tokens (color, style, layout, and object).
</details>
<details>
<summary>摘要</summary>
我们考虑到将散布模型的输出受限于使用者提供的参考图像。我们的主要目标是从这个单一的参考图像中提取多个特征（例如颜色、物件、布局、Style），然后产生新的样本。现有的方法包括将参考图像反射为单一的文本条件 vector，以便产生新的样本。但这些方法不会学习多个条件，以调控模型的输出。另一些方法则是扩展反射空间，以学习多个嵌入，但是这些方法只是在层级（例如 DDPM 模型的层）或时间步（一组时间步骤）上进行对应，这会导致不够好的特征分离。为了解决这些问题，我们的第一个贡献是对于哪些特征是在哪个维度中捕捉的，我们考虑了时间步骤维度（在逆推实验中）和 DDPM 模型层级。我们发现，一些特征通常是在同一些层级和/或同一些时间步骤中捕捉的。例如，颜色和风格是在同一些 U-Net 层中捕捉的，而布局和颜色则是在同一些时间步骤中捕捉的。因此，仅仅对于时间步骤维度或层级进行对应是不足以将所有特征分离。这导致我们的第二个贡献，即设计了一个新的多特征反射算法（MATTE），以及相应的分离提升训练损失，以确保四个分离的条件（颜色、风格、布局、物件）。
</details></li>
</ul>
<hr>
<h2 id="Identifying-the-Defective-Detecting-Damaged-Grains-for-Cereal-Appearance-Inspection"><a href="#Identifying-the-Defective-Detecting-Damaged-Grains-for-Cereal-Appearance-Inspection" class="headerlink" title="Identifying the Defective: Detecting Damaged Grains for Cereal Appearance Inspection"></a>Identifying the Defective: Detecting Damaged Grains for Cereal Appearance Inspection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11901">http://arxiv.org/abs/2311.11901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hellodfan/ai4graininsp">https://github.com/hellodfan/ai4graininsp</a></li>
<li>paper_authors: Lei Fan, Yiwen Ding, Dongdong Fan, Yong Wu, Maurice Pagnucco, Yang Song</li>
<li>for:  This paper aims to develop an automated Grain Appearance Inspection (GAI) system to improve the efficiency and accuracy of grain quality evaluation.</li>
<li>methods:  The proposed system uses anomaly detection (AD) to identify damaged grains or unknown objects in grain kernels. The AD model, called AD-GAI, is trained using only normal samples and shows high performance in comparison with advanced AD methods.</li>
<li>results:  The proposed system achieves a speedup of over 20x compared to human experts and shows highly consistent performance with human evaluation. A large-scale dataset of 220K high-quality images of wheat and maize kernels is created and released for future research.<details>
<summary>Abstract</summary>
Cereal grain plays a crucial role in the human diet as a major source of essential nutrients. Grain Appearance Inspection (GAI) serves as an essential process to determine grain quality and facilitate grain circulation and processing. However, GAI is routinely performed manually by inspectors with cumbersome procedures, which poses a significant bottleneck in smart agriculture.   In this paper, we endeavor to develop an automated GAI system:AI4GrainInsp. By analyzing the distinctive characteristics of grain kernels, we formulate GAI as a ubiquitous problem: Anomaly Detection (AD), in which healthy and edible kernels are considered normal samples while damaged grains or unknown objects are regarded as anomalies. We further propose an AD model, called AD-GAI, which is trained using only normal samples yet can identify anomalies during inference. Moreover, we customize a prototype device for data acquisition and create a large-scale dataset including 220K high-quality images of wheat and maize kernels. Through extensive experiments, AD-GAI achieves considerable performance in comparison with advanced AD methods, and AI4GrainInsp has highly consistent performance compared to human experts and excels at inspection efficiency over 20x speedup. The dataset, code and models will be released at https://github.com/hellodfan/AI4GrainInsp.
</details>
<details>
<summary>摘要</summary>
粮食作物在人类饮食中扮演着重要角色，为提供重要营养素的主要来源。然而，粮食质量检测（GAI）通常是由人工检查员 manually进行，这会带来智能农业中的一定瓶颈。在这篇论文中，我们努力开发一个自动化的 GAI 系统：AI4GrainInsp。我们通过分析谷物块的特征，将 GAI 转化为一个普遍问题：异常检测（AD），健康和食用谷物被视为正常样本，而受损谷物或未知物体则被视为异常。我们还提出了一种 AD 模型，called AD-GAI，它通过训练只使用正常样本而能够在推理中检测异常。此外，我们还自定义了一种原型设备 для数据收集，并创建了包括 220 万个高质量谷物块的大规模数据集。经过广泛的实验，AD-GAI 在与先进的 AD 方法进行比较中表现出了显著的性能优势，AI4GrainInsp 的检测效果与人工专家相当，并且在速度方面高于人工检测的 20 倍。数据集、代码和模型将在 GitHub 上发布。
</details></li>
</ul>
<hr>
<h2 id="SniffyArt-The-Dataset-of-Smelling-Persons"><a href="#SniffyArt-The-Dataset-of-Smelling-Persons" class="headerlink" title="SniffyArt: The Dataset of Smelling Persons"></a>SniffyArt: The Dataset of Smelling Persons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11888">http://arxiv.org/abs/2311.11888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathias Zinnen, Azhar Hussian, Hang Tran, Prathmesh Madhu, Andreas Maier, Vincent Christlein</li>
<li>for: 这篇论文的目的是为了开发一个具有人体姿势和肢体关键点的历史艺术作品中的臭味姿势识别方法。</li>
<li>methods: 这篇论文使用了一个名为SniffyArt的数据集，该数据集包含1941名人物在441幅历史艺术作品中的捕捉。每个人物都有一个紧靠的盒子 bounding box，17个姿势关键点和一个姿势标签。通过这些注释，数据集允许开发混合类型的识别方法。</li>
<li>results: 论文还提供了一个基线分析，评估了代表性的检测、关键点估计和分类任务的性能，展示了结合关键点估计和臭味姿势分类的潜在可能性。SniffyArt数据集为未来研究提供了一个坚实的基础，可以推动人姿和臭味维度分析在历史艺术作品中的进一步发展。<details>
<summary>Abstract</summary>
Smell gestures play a crucial role in the investigation of past smells in the visual arts yet their automated recognition poses significant challenges. This paper introduces the SniffyArt dataset, consisting of 1941 individuals represented in 441 historical artworks. Each person is annotated with a tightly fitting bounding box, 17 pose keypoints, and a gesture label. By integrating these annotations, the dataset enables the development of hybrid classification approaches for smell gesture recognition. The datasets high-quality human pose estimation keypoints are achieved through the merging of five separate sets of keypoint annotations per person. The paper also presents a baseline analysis, evaluating the performance of representative algorithms for detection, keypoint estimation, and classification tasks, showcasing the potential of combining keypoint estimation with smell gesture classification. The SniffyArt dataset lays a solid foundation for future research and the exploration of multi-task approaches leveraging pose keypoints and person boxes to advance human gesture and olfactory dimension analysis in historical artworks.
</details>
<details>
<summary>摘要</summary>
< span> Investigation of past smells in the visual arts relies heavily on smell gestures, yet automated recognition poses significant challenges. This paper introduces the SniffyArt dataset, consisting of 1941 individuals represented in 441 historical artworks. Each person is annotated with a tightly fitting bounding box, 17 pose keypoints, and a gesture label. By integrating these annotations, the dataset enables the development of hybrid classification approaches for smell gesture recognition. The dataset's high-quality human pose estimation keypoints are achieved through the merging of five separate sets of keypoint annotations per person. The paper also presents a baseline analysis, evaluating the performance of representative algorithms for detection, keypoint estimation, and classification tasks, showcasing the potential of combining keypoint estimation with smell gesture classification. The SniffyArt dataset lays a solid foundation for future research and the exploration of multi-task approaches leveraging pose keypoints and person boxes to advance human gesture and olfactory dimension analysis in historical artworks.</ span>Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Multi-Task-Faces-MTF-Data-Set-A-Legally-and-Ethically-Compliant-Collection-of-Face-Images-for-Various-Classification-Tasks"><a href="#Multi-Task-Faces-MTF-Data-Set-A-Legally-and-Ethically-Compliant-Collection-of-Face-Images-for-Various-Classification-Tasks" class="headerlink" title="Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks"></a>Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11882">http://arxiv.org/abs/2311.11882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ramihaf/mtf_data_set">https://github.com/ramihaf/mtf_data_set</a></li>
<li>paper_authors: Rami Haffar, David Sánchez, Josep Domingo-Ferrer</li>
<li>for: 这个论文是为了提供一个多任务面部数据集（MTF），用于多种分类任务，包括识别、年龄、性别和种族等。</li>
<li>methods: 这个论文使用了公共可用的明星图片来收集数据，并且严格遵循了版权法规。数据集被精心挑选和处理，以满足不同的分类任务。</li>
<li>results: 论文中提供了五种深度学习模型在MTF数据集上的性能分析，包括识别、年龄、性别和种族等多个任务。同时，论文还对raw网络上的数据进行了处理和分析，以评估模型在不同的数据上的性能。<details>
<summary>Abstract</summary>
Human facial data hold tremendous potential to address a variety of classification problems, including face recognition, age estimation, gender identification, emotion analysis, and race classification. However, recent privacy regulations, such as the EU General Data Protection Regulation and others, have restricted the ways in which human images may be collected and used for research. As a result, several previously published data sets containing human faces have been removed from the internet due to inadequate data collection methods that failed to meet privacy regulations. Data sets consisting of synthetic data have been proposed as an alternative, but they fall short of accurately representing the real data distribution. On the other hand, most available data sets are labeled for just a single task, which limits their applicability. To address these issues, we present the Multi-Task Faces (MTF) image data set, a meticulously curated collection of face images designed for various classification tasks, including face recognition, as well as race, gender, and age classification. The MTF data set has been ethically gathered by leveraging publicly available images of celebrities and strictly adhering to copyright regulations. In this paper, we present this data set and provide detailed descriptions of the followed data collection and processing procedures. Furthermore, we evaluate the performance of five deep learning (DL) models on the MTF data set across the aforementioned classification tasks. Additionally, we compare the performance of DL models over the processed MTF data and over raw data crawled from the internet. The reported results constitute a baseline for further research employing these data. The MTF data set can be accessed through the following link (please cite the present paper if you use the data set): https://github.com/RamiHaf/MTF_data_set
</details>
<details>
<summary>摘要</summary>
人类脸部数据具有巨大的潜力，可以解决多种分类问题，包括人脸识别、年龄估计、性别确定、情感分析和种族分类。然而，最近的隐私法规，如欧盟通用数据保护条例等，限制了人类图像的收集和使用方式。这导致了一些以前发布在互联网上的人脸数据集被下载，因为这些数据集的收集方法不符合隐私法规。同时，大多数可用的数据集仅适用于单个任务，这限制了它们的可 reuse。为解决这些问题，我们提出了多任务脸(MTF)图像数据集，这是一个仔细精心收集的人脸图像集，适用于多种分类任务，包括人脸识别、种族、性别和年龄分类。MTF数据集通过公开的 célèbres的图像来收集，严格遵循版权法规。在这篇文章中，我们介绍了这个数据集，并提供了数据收集和处理过程的详细描述。此外，我们还评估了五种深度学习（DL）模型在MTF数据集上的性能，以及模型在处理后的MTF数据集和互联网上爬取的原始数据集上的性能。报告的结果可作为后续研究使用这些数据集的基eline。MTF数据集可以通过以下链接访问：https://github.com/RamiHaf/MTF_data_set。（请参考本文中的报告来使用这些数据集。）
</details></li>
</ul>
<hr>
<h2 id="VLM-Eval-A-General-Evaluation-on-Video-Large-Language-Models"><a href="#VLM-Eval-A-General-Evaluation-on-Video-Large-Language-Models" class="headerlink" title="VLM-Eval: A General Evaluation on Video Large Language Models"></a>VLM-Eval: A General Evaluation on Video Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11865">http://arxiv.org/abs/2311.11865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuailin Li, Yuang Zhang, Yucheng Zhao, Qiuyue Wang, Fan Jia, Yingfei Liu, Tiancai Wang</li>
<li>for: 这个论文的目的是为视频大语言模型（LLM）进行全面评估。</li>
<li>methods: 这篇论文使用了多种视频任务，包括标题写作、问答、检索和动作识别等，并使用了传统度量标准和GPT基于的评估方法来评估响应质量。它还提出了一个简单的基线：Video-LLaVA，该基线使用了单一的直线投影，并超越了现有的视频 LLM。</li>
<li>results: 这篇论文发现，使用只需要几百个视频教程对象进行微调的方法可以在驾驶场景中获得激发人理解和计算能力。此外，它还证明了视频 LLM 的评估可以在实际场景中扩展。<details>
<summary>Abstract</summary>
Despite the rapid development of video Large Language Models (LLMs), a comprehensive evaluation is still absent. In this paper, we introduce a unified evaluation that encompasses multiple video tasks, including captioning, question and answering, retrieval, and action recognition. In addition to conventional metrics, we showcase how GPT-based evaluation can match human-like performance in assessing response quality across multiple aspects. We propose a simple baseline: Video-LLaVA, which uses a single linear projection and outperforms existing video LLMs. Finally, we evaluate video LLMs beyond academic datasets, which show encouraging recognition and reasoning capabilities in driving scenarios with only hundreds of video-instruction pairs for fine-tuning. We hope our work can serve as a unified evaluation for video LLMs, and help expand more practical scenarios. The evaluation code will be available soon.
</details>
<details>
<summary>摘要</summary>
尽管视频大语言模型（LLM）的快速发展，但全面评估仍然缺失。在这篇论文中，我们提出了一种涵盖多个视频任务的综合评估，包括标注、问答、检索和动作识别。除了传统的度量器，我们显示了如何使用GPT基于的评估匹配人类水平评估Response质量在多个方面。我们提出了一个简单的基线：视频-LLaVA，它使用单个直线投影，并超过现有的视频LLM。最后，我们评估视频LLM在外部数据集上，显示了鼓励人的识别和推理能力，只需要undreds of video-instruction pairs进行微调。我们希望我们的工作能为视频LLM提供一个统一的评估，并帮助扩展更多实际场景。评估代码将很快 disponible。
</details></li>
</ul>
<hr>
<h2 id="GP-NeRF-Generalized-Perception-NeRF-for-Context-Aware-3D-Scene-Understanding"><a href="#GP-NeRF-Generalized-Perception-NeRF-for-Context-Aware-3D-Scene-Understanding" class="headerlink" title="GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding"></a>GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11863">http://arxiv.org/abs/2311.11863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Li, Dingwen Zhang, Yalun Dai, Nian Liu, Lechao Cheng, Jingfeng Li, Jingdong Wang, Junwei Han</li>
<li>for: 本研究旨在提高3D场景理解和表示 tasks中的下游任务，即semantic prediction和instance segmentation。</li>
<li>methods: 我们提出了一种新的渠道Generalized Perception NeRF（GP-NeRF），它将通用 segmentation 模型和NeRF合并在一个框架下，以便在3D场景中提高context-aware的理解。我们还引入了 transformers 来聚合辐射和 semantic embedding 领域的信息，以便在新的视图下渲染这两个领域。此外，我们还提出了两种自适应机制，即Semantic Distill Loss和Depth-Guided Semantic Distill Loss，以提高semantic field的精度和 geometric consistency。</li>
<li>results: 我们在两个任务上进行了实验比较（semantic segmentation和instance segmentation），使用了both synthetic和real-world datasets。结果显示，我们的方法在Generalized semantic segmentation、fine-tuning semantic segmentation和instance segmentation任务中的性能比SOTA方法高出6.94%、11.76%和8.47%。<details>
<summary>Abstract</summary>
Applying NeRF to downstream perception tasks for scene understanding and representation is becoming increasingly popular. Most existing methods treat semantic prediction as an additional rendering task, \textit{i.e.}, the "label rendering" task, to build semantic NeRFs. However, by rendering semantic/instance labels per pixel without considering the contextual information of the rendered image, these methods usually suffer from unclear boundary segmentation and abnormal segmentation of pixels within an object. To solve this problem, we propose Generalized Perception NeRF (GP-NeRF), a novel pipeline that makes the widely used segmentation model and NeRF work compatibly under a unified framework, for facilitating context-aware 3D scene perception. To accomplish this goal, we introduce transformers to aggregate radiance as well as semantic embedding fields jointly for novel views and facilitate the joint volumetric rendering of both fields. In addition, we propose two self-distillation mechanisms, i.e., the Semantic Distill Loss and the Depth-Guided Semantic Distill Loss, to enhance the discrimination and quality of the semantic field and the maintenance of geometric consistency. In evaluation, we conduct experimental comparisons under two perception tasks (\textit{i.e.} semantic and instance segmentation) using both synthetic and real-world datasets. Notably, our method outperforms SOTA approaches by 6.94\%, 11.76\%, and 8.47\% on generalized semantic segmentation, finetuning semantic segmentation, and instance segmentation, respectively.
</details>
<details>
<summary>摘要</summary>
通过应用NeRF到下游识别任务中，以提高场景理解和表示的能力，现在越来越普遍。大多数现有方法都会对 semantic prediction 视为额外的渲染任务，即“标签渲染”任务，以建立semantic NeRFs。然而，由于不考虑渲染图像中的上下文信息，这些方法通常会出现不清晰的边界分割和对象内部像素的异常分割问题。为解决这个问题，我们提出了通用识别NeRF（GP-NeRF），一种新的管道，使得通用的分割模型和NeRF在一个统一框架下工作，以便实现上下文意识的3D场景识别。为达到这个目标，我们引入了 transformers，以便在新视图下对光谱和semantic embedding场景进行并行汇聚。此外，我们还提出了两种自适应机制，即Semantic Distill Loss和Depth-Guided Semantic Distill Loss，以提高semantic场景的精度和质量。在评估中，我们通过对semantic和实例分割任务进行实验比较，使用了 sintetic和实际数据集。可见，我们的方法在Generalized semantic segmentation、fine-tuning semantic segmentation和实例分割任务中，相比SOTA方法，提高了6.94%、11.76%和8.47%。
</details></li>
</ul>
<hr>
<h2 id="LION-Empowering-Multimodal-Large-Language-Model-with-Dual-Level-Visual-Knowledge"><a href="#LION-Empowering-Multimodal-Large-Language-Model-with-Dual-Level-Visual-Knowledge" class="headerlink" title="LION : Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge"></a>LION : Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11860">http://arxiv.org/abs/2311.11860</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rshaojimmy/jiutian">https://github.com/rshaojimmy/jiutian</a></li>
<li>paper_authors: Gongwei Chen, Leyang Shen, Rui Shao, Xiang Deng, Liqiang Nie</li>
<li>for: 这个论文主要是为了提高多模态大语言模型（MLLM）的性能，使其能够更好地理解和使用多种多样的信息。</li>
<li>methods: 这篇论文提出了一种两级视觉知识增强策略，包括进程式地 integrate 细化的空间意识视觉知识，以及软提示高级别 semantic 视觉证据。</li>
<li>results: 对多个多模态benchmark进行了广泛的实验，并表明该模型在VSRCIDEr等任务上具有显著的提高（比如VSRCIDEr上提高5%，TextCaps上提高3%，RefCOCOg上提高5%）。<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) have endowed LLMs with the ability to perceive and understand multi-modal signals. However, most of the existing MLLMs mainly adopt vision encoders pretrained on coarsely aligned image-text pairs, leading to insufficient extraction and reasoning of visual knowledge. To address this issue, we devise a dual-Level vIsual knOwledge eNhanced Multimodal Large Language Model (LION), which empowers the MLLM by injecting visual knowledge in two levels. 1) Progressive incorporation of fine-grained spatial-aware visual knowledge. We design a vision aggregator cooperated with region-level vision-language (VL) tasks to incorporate fine-grained spatial-aware visual knowledge into the MLLM. To alleviate the conflict between image-level and region-level VL tasks during incorporation, we devise a dedicated stage-wise instruction-tuning strategy with mixture-of-adapters. This progressive incorporation scheme contributes to the mutual promotion between these two kinds of VL tasks. 2) Soft prompting of high-level semantic visual evidence. We facilitate the MLLM with high-level semantic visual evidence by leveraging diverse image tags. To mitigate the potential influence caused by imperfect predicted tags, we propose a soft prompting method by embedding a learnable token into the tailored text instruction. Comprehensive experiments on several multi-modal benchmarks demonstrate the superiority of our model (e.g., improvement of 5% accuracy on VSR and 3% CIDEr on TextCaps over InstructBLIP, 5% accuracy on RefCOCOg over Kosmos-2).
</details>
<details>
<summary>摘要</summary>
多Modal大型自然语言模型（MLLMs）已经赋予大型自然语言模型（LLMs）可以感知和理解多Modal信号。然而，大多数现有的 MLLMs 主要采用先天Alignment的视觉编码器，导致视觉知识的抽取和理解不充分。为解决这个问题，我们设计了两级视觉知识增强的多Modal大型自然语言模型（LION），它使得 MLLM 具有更好的视觉知识抽取和理解能力。1. 细化空间意识视觉知识的进行式整合。我们设计了一个与区域级视觉语言（VL）任务相结合的视觉汇集器，以整合细化空间意识的视觉知识到 MLLM 中。为了解决图像级和区域级 VL 任务之间的冲突，我们提出了一种适应器混合策略和 mixture-of-adapters。这种进行式整合方案对这两种 VL 任务产生了互相促进的效果。2. 软提示高级Semantic视觉证据。我们为 MLLM 提供高级Semantic视觉证据，通过利用多种图像标签。为了减少预测标签的不准确性的影响，我们提出了一种软提示方法，通过在专门设计的文本指令中嵌入学习的token。经过了多种多Modal benchmark 的实验，我们的模型在 VSR 和 TextCaps 上比 InstructBLIP 高5%，在 RefCOCOg 上高3%，在 Kosmos-2 上高5%。
</details></li>
</ul>
<hr>
<h2 id="FATURA-A-Multi-Layout-Invoice-Image-Dataset-for-Document-Analysis-and-Understanding"><a href="#FATURA-A-Multi-Layout-Invoice-Image-Dataset-for-Document-Analysis-and-Understanding" class="headerlink" title="FATURA: A Multi-Layout Invoice Image Dataset for Document Analysis and Understanding"></a>FATURA: A Multi-Layout Invoice Image Dataset for Document Analysis and Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11856">http://arxiv.org/abs/2311.11856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmoud Limam, Marwa Dhiaf, Yousri Kessentini</li>
<li>For: The paper is written for researchers in the field of document analysis and understanding.* Methods: The paper uses a dataset called FATURA, which is a highly diverse dataset featuring multi-layout, annotated invoice document images.* Results: The paper provides comprehensive benchmarks for various document analysis and understanding tasks and conducts experiments under diverse training and evaluation scenarios.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了探讨文档分析和理解领域的研究人员而写的。</li>
<li>methods: 这篇论文使用了一个名为FATURA的 dataset，该dataset是一个多format的、注释的发票文档图像集。</li>
<li>results: 这篇论文提供了多种文档分析和理解任务的全面的标准准测试数据，并在不同的训练和评估场景下进行了实验。<details>
<summary>Abstract</summary>
Document analysis and understanding models often require extensive annotated data to be trained. However, various document-related tasks extend beyond mere text transcription, requiring both textual content and precise bounding-box annotations to identify different document elements. Collecting such data becomes particularly challenging, especially in the context of invoices, where privacy concerns add an additional layer of complexity. In this paper, we introduce FATURA, a pivotal resource for researchers in the field of document analysis and understanding. FATURA is a highly diverse dataset featuring multi-layout, annotated invoice document images. Comprising $10,000$ invoices with $50$ distinct layouts, it represents the largest openly accessible image dataset of invoice documents known to date. We also provide comprehensive benchmarks for various document analysis and understanding tasks and conduct experiments under diverse training and evaluation scenarios. The dataset is freely accessible at https://zenodo.org/record/8261508, empowering researchers to advance the field of document analysis and understanding.
</details>
<details>
<summary>摘要</summary>
In this paper, we introduce FATURA, a groundbreaking resource for researchers in the field of document analysis and understanding. FATURA is a highly diverse dataset featuring multi-layout, annotated invoice document images. Comprising 10,000 invoices with 50 distinct layouts, it represents the largest openly accessible image dataset of invoice documents known to date.We also provide comprehensive benchmarks for various document analysis and understanding tasks and conduct experiments under diverse training and evaluation scenarios. The dataset is freely accessible at <https://zenodo.org/record/8261508>, empowering researchers to advance the field of document analysis and understanding.
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-Bioplausible-Neuron-for-Spiking-Neural-Networks-for-Event-Based-Vision"><a href="#Asynchronous-Bioplausible-Neuron-for-Spiking-Neural-Networks-for-Event-Based-Vision" class="headerlink" title="Asynchronous Bioplausible Neuron for Spiking Neural Networks for Event-Based Vision"></a>Asynchronous Bioplausible Neuron for Spiking Neural Networks for Event-Based Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11853">http://arxiv.org/abs/2311.11853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanket Kachole, Hussain Sajwani, Fariborz Baghaei Naeini, Dimitrios Makris, Yahya Zweiri</li>
<li>for: 这个研究旨在提出一种具有生物灵感的神经网络，以提高视觉数据处理效率，降低能源消耗。</li>
<li>methods: 研究使用了 asynchronous bioplausible neuron（ABN），一种动态脉搏机制，以自动调整输入信号的变化。</li>
<li>results: 实验结果显示，ABN能够优化图像分类和 segmentation 的性能，维护神经平衡，并提高能效性。<details>
<summary>Abstract</summary>
Spiking Neural Networks (SNNs) offer a biologically inspired approach to computer vision that can lead to more efficient processing of visual data with reduced energy consumption. However, maintaining homeostasis within these networks is challenging, as it requires continuous adjustment of neural responses to preserve equilibrium and optimal processing efficiency amidst diverse and often unpredictable input signals. In response to these challenges, we propose the Asynchronous Bioplausible Neuron (ABN), a dynamic spike firing mechanism to auto-adjust the variations in the input signal. Comprehensive evaluation across various datasets demonstrates ABN's enhanced performance in image classification and segmentation, maintenance of neural equilibrium, and energy efficiency.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）提供一种生物体发展的视觉处理方法，可以实现更高效的数据处理和降低能源消耗。然而，保持神经网络的HOMEOSTASIS是挑战，因为需要不断调整神经响应以维持平衡和最佳处理效率面对多样化和随机的输入信号。为解决这些挑战，我们提议使用异步生物可能性神经元（ABN），一种动态脉冲发射机制来自动调整输入信号的变化。经过了不同的数据集的全面评估，ABN在图像分类和分割方面表现出了更好的表现，同时保持神经网络的平衡和能效性。
</details></li>
</ul>
<hr>
<h2 id="Entangled-View-Epipolar-Information-Aggregation-for-Generalizable-Neural-Radiance-Fields"><a href="#Entangled-View-Epipolar-Information-Aggregation-for-Generalizable-Neural-Radiance-Fields" class="headerlink" title="Entangled View-Epipolar Information Aggregation for Generalizable Neural Radiance Fields"></a>Entangled View-Epipolar Information Aggregation for Generalizable Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11845">http://arxiv.org/abs/2311.11845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tatakai1/evenerf">https://github.com/tatakai1/evenerf</a></li>
<li>paper_authors: Zhiyuan Min, Yawei Luo, Wei Yang, Yuesong Wang, Yi Yang</li>
<li>for: 本研究旨在提高NeRF模型的常规化能力，使其直接从新场景中生成新视角图像，不需要重新训练场景特定的NeRF模型。</li>
<li>methods: 我们提出了一种名为EVE-NeRF的Entangled View-Epipolar Information Aggregation方法，它在拼接多视图特征时注入场景不变的外观连续性和几何一致性约束，以提高3D表示的普适性。</li>
<li>results: 我们的方法在多种评估场景中达到了状态的表现，比起单一维度的拼接，杂合网络更好地保持了3D场景的几何和外观重建精度。<details>
<summary>Abstract</summary>
Generalizable NeRF can directly synthesize novel views across new scenes, eliminating the need for scene-specific retraining in vanilla NeRF. A critical enabling factor in these approaches is the extraction of a generalizable 3D representation by aggregating source-view features. In this paper, we propose an Entangled View-Epipolar Information Aggregation method dubbed EVE-NeRF. Different from existing methods that consider cross-view and along-epipolar information independently, EVE-NeRF conducts the view-epipolar feature aggregation in an entangled manner by injecting the scene-invariant appearance continuity and geometry consistency priors to the aggregation process. Our approach effectively mitigates the potential lack of inherent geometric and appearance constraint resulting from one-dimensional interactions, thus further boosting the 3D representation generalizablity. EVE-NeRF attains state-of-the-art performance across various evaluation scenarios. Extensive experiments demonstate that, compared to prevailing single-dimensional aggregation, the entangled network excels in the accuracy of 3D scene geometry and appearance reconstruction.Our project page is https://github.com/tatakai1/EVENeRF.
</details>
<details>
<summary>摘要</summary>
通用的NeRF可以直接生成新场景中的新视图，从而消除普通的NeRFScene-specific retraining。一个关键的优化因子在这些方法中是提取一个通用的3D表示。在这篇论文中，我们提议一种拓展视图-轴线信息汇集方法，名为EVE-NeRF。与现有方法不同，EVE-NeRF在汇集视图和轴线信息时采用杂合的方式，通过注入场景不变的外观继续性和几何约束约束，从而有效地消除一维交互中的可能的内置几何和外观约束缺失，从而进一步提高3D表示的通用性。EVE-NeRF实现了最新的性能标准在各种评估场景中。广泛的实验表明，相比于现有的单一维度汇集，杂合网络在3D场景几何和外观重建精度方面具有明显的优势。我们的项目页面是<https://github.com/tatakai1/EVENeRF>.
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Multispectral-Segmentation-with-Representations-Generated-by-Reinforcement-Learning"><a href="#Few-shot-Multispectral-Segmentation-with-Representations-Generated-by-Reinforcement-Learning" class="headerlink" title="Few-shot Multispectral Segmentation with Representations Generated by Reinforcement Learning"></a>Few-shot Multispectral Segmentation with Representations Generated by Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11827">http://arxiv.org/abs/2311.11827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dilith Jayakody, Thanuja Ambegoda</li>
<li>for: 提高几个示例数据集上的多spectral图像分割性能</li>
<li>methods: 使用 reinforcement learning 生成表达来生成特定类分割的表达，并将其用于更新数据集和进行分割</li>
<li>results: 在多个多spectral数据集上证明了提高分割性能的效果<details>
<summary>Abstract</summary>
The task of multispectral image segmentation (segmentation of images with numerous channels/bands, each capturing a specific range of wavelengths of electromagnetic radiation) has been previously explored in contexts with large amounts of labeled data. However, these models tend not to generalize well to datasets of smaller size. In this paper, we propose a novel approach for improving few-shot segmentation performance on multispectral images using reinforcement learning to generate representations. These representations are generated in the form of mathematical expressions between channels and are tailored to the specific class being segmented. Our methodology involves training an agent to identify the most informative expressions, updating the dataset using these expressions, and then using the updated dataset to perform segmentation. Due to the limited length of the expressions, the model receives useful representations without any added risk of overfitting. We evaluate the effectiveness of our approach on several multispectral datasets and demonstrate its effectiveness in boosting the performance of segmentation algorithms.
</details>
<details>
<summary>摘要</summary>
在多spectral图像分割任务中，我们已经曾经利用大量标注数据进行过研究。然而，这些模型通常无法通用于小型数据集。在这篇论文中，我们提出了一种新的方法，用于在多spectral图像上提高少量shot分割性能使用反射学习生成表示。这些表示是通过Channel之间的数学表达来生成的，并且特制于具体的分割类。我们的方法包括使用代理人来确定最有用的表达，更新数据集使用这些表达，然后使用更新后的数据集进行分割。由于表达的长度有限，模型能够获得有用的表示，而不会额外风险过拟合。我们对多spectral数据集进行了评估，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Inverse-Rendering-of-Complex-Facade-via-Aerial-3D-Scanning"><a href="#Holistic-Inverse-Rendering-of-Complex-Facade-via-Aerial-3D-Scanning" class="headerlink" title="Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning"></a>Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11825">http://arxiv.org/abs/2311.11825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan Xie, Rengan Xie, Rong Li, Kai Huang, Pengju Qiao, Jingsen Zhu, Xu Yin, Qi Ye, Wei Hua, Yuchi Huo, Hujun Bao</li>
<li>for: 用于 facade 的 geometry, lighting, and material 重建</li>
<li>methods: 使用 neural signed distance fields (SDFs) 和三种适应策略：semantic regularization、frequency-aware geometry regularization 和 visibility probe-based scheme</li>
<li>results: 实现 physically based 和 photorealistic 的 novel-view rendering、relighting 和 editing，并在实际环境中超越之前的方法。<details>
<summary>Abstract</summary>
In this work, we use multi-view aerial images to reconstruct the geometry, lighting, and material of facades using neural signed distance fields (SDFs). Without the requirement of complex equipment, our method only takes simple RGB images captured by a drone as inputs to enable physically based and photorealistic novel-view rendering, relighting, and editing. However, a real-world facade usually has complex appearances ranging from diffuse rocks with subtle details to large-area glass windows with specular reflections, making it hard to attend to everything. As a result, previous methods can preserve the geometry details but fail to reconstruct smooth glass windows or verse vise. In order to address this challenge, we introduce three spatial- and semantic-adaptive optimization strategies, including a semantic regularization approach based on zero-shot segmentation techniques to improve material consistency, a frequency-aware geometry regularization to balance surface smoothness and details in different surfaces, and a visibility probe-based scheme to enable efficient modeling of the local lighting in large-scale outdoor environments. In addition, we capture a real-world facade aerial 3D scanning image set and corresponding point clouds for training and benchmarking. The experiment demonstrates the superior quality of our method on facade holistic inverse rendering, novel view synthesis, and scene editing compared to state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们使用多视图飞行图像来重建建筑外墙的几何、照明和材质。我们的方法只需要简单的RGB图像， captured by a drone，作为输入，以实现物理基于的、 photorealistic 新视图渲染、重新照明和编辑。然而，实际世界中的facade通常具有复杂的外观，从柔软的岩石到大面积的玻璃窗户的镜面反射，这会使得 previous methods 难以同时 preserve geometry details 和 reconstruction smooth glass windows。为 Addressing this challenge，我们引入三个空间和semantic-adaptive optimization strategies，包括基于zero-shot segmentation技术的semantic regularizationapproach，频率意识geometry regularization，和基于可见探针的 scheme。此外，我们还capture了一个真实世界facade飞行3D扫描图像集和相应的点云数据用于训练和参考。实验结果表明，我们的方法在facade holistic inverse rendering、新视图合成和场景编辑方面具有较高的质量，比state-of-the-art baselines。
</details></li>
</ul>
<hr>
<h2 id="Cross-View-Graph-Consistency-Learning-for-Invariant-Graph-Representations"><a href="#Cross-View-Graph-Consistency-Learning-for-Invariant-Graph-Representations" class="headerlink" title="Cross-View Graph Consistency Learning for Invariant Graph Representations"></a>Cross-View Graph Consistency Learning for Invariant Graph Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11821">http://arxiv.org/abs/2311.11821</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Chen, Zhiming Li, Hua Mao, Wai Lok Woo, Xi Peng</li>
<li>for: This paper is written for analyzing graph-structured data and learning invariant graph representations for link prediction.</li>
<li>methods: The paper proposes a cross-view graph consistency learning (CGCL) method that uses two complementary augmented views to derive an incomplete graph structure, and then learns invariant graph representations through a cross-view training scheme.</li>
<li>results: The paper achieves competitive results on graph datasets in comparisons with several state-of-the-art algorithms, demonstrating the effectiveness of the proposed CGCL method.Here’s the Chinese version of the three information points:</li>
<li>for: 这篇论文是为了分析图structured数据而写的，并且学习图结构中的不变性表示以便预测链接。</li>
<li>methods: 该篇论文提出了跨视图图一致学习(CGCL)方法，通过两个补充的增强视图来 derivation incomplete图结构，然后通过跨视图训练方案来学习不变性表示。</li>
<li>results: 纸上提供了一些比较竞争力强的结果，证明了提案的CGCL方法的有效性。<details>
<summary>Abstract</summary>
Graph representation learning is fundamental for analyzing graph-structured data. Exploring invariant graph representations remains a challenge for most existing graph representation learning methods. In this paper, we propose a cross-view graph consistency learning (CGCL) method that learns invariant graph representations for link prediction. First, two complementary augmented views are derived from an incomplete graph structure through a bidirectional graph structure augmentation scheme. This augmentation scheme mitigates the potential information loss that is commonly associated with various data augmentation techniques involving raw graph data, such as edge perturbation, node removal, and attribute masking. Second, we propose a CGCL model that can learn invariant graph representations. A cross-view training scheme is proposed to train the proposed CGCL model. This scheme attempts to maximize the consistency information between one augmented view and the graph structure reconstructed from the other augmented view. Furthermore, we offer a comprehensive theoretical CGCL analysis. This paper empirically and experimentally demonstrates the effectiveness of the proposed CGCL method, achieving competitive results on graph datasets in comparisons with several state-of-the-art algorithms.
</details>
<details>
<summary>摘要</summary>
GRAPH 表示学习是数据结构化的数据分析的基础。寻找不变的 GRAPH 表示仍然是现有 GRAPH 表示学习方法的挑战。在这篇论文中，我们提出了跨视图 GRAPH 一致学习（CGCL）方法，用于预测链接。首先，通过双向 GRAPH 结构增强方案，从不完整的 GRAPH 结构中 derivation 出两个补充的视图。这种增强方案可以减少 raw GRAPH 数据的各种数据增强技术中的信息损失，例如边干扰、节点移除和特征遮盖。其次，我们提出了一种 CGCL 模型，可以学习不变的 GRAPH 表示。我们提出了一种跨视图训练方案，用于训练提订的 CGCL 模型。这种方案尝试通过将一个增强视图与另一个视图中的 GRAPH 结构匹配来最大化两个视图之间的一致信息。此外，我们还提供了 CGCL 的完整理论分析。本文通过实验和实证证明了提订的 CGCL 方法的效果，在比较了多个状态前的算法中达到了竞争性的结果。
</details></li>
</ul>
<hr>
<h2 id="CrackCLF-Automatic-Pavement-Crack-Detection-based-on-Closed-Loop-Feedback"><a href="#CrackCLF-Automatic-Pavement-Crack-Detection-based-on-Closed-Loop-Feedback" class="headerlink" title="CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop Feedback"></a>CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11815">http://arxiv.org/abs/2311.11815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chong Li, Zhun Fan, Ying Chen, Huibiao Lin, Laura Moretti, Giuseppe Loprencipe, Weihua Sheng, Kelvin C. P. Wang</li>
<li>for:  automatic pavement crack detection</li>
<li>methods:  encoder-decoder framework with closed-loop feedback and generative adversarial networks</li>
<li>results:  outperforms other methods on three public datasets, with the ability to correct errors and adapt to changes in the environmentHere’s the full text in Simplified Chinese:</li>
<li>for:  automatic pavement crack detection</li>
<li>methods: 使用encoder-decoder框架和循环反馈，以及生成对抗网络</li>
<li>results: 在三个公共数据集上取得了更高的性能，并能自动 correect错误和适应环境变化<details>
<summary>Abstract</summary>
Automatic pavement crack detection is an important task to ensure the functional performances of pavements during their service life. Inspired by deep learning (DL), the encoder-decoder framework is a powerful tool for crack detection. However, these models are usually open-loop (OL) systems that tend to treat thin cracks as the background. Meanwhile, these models can not automatically correct errors in the prediction, nor can it adapt to the changes of the environment to automatically extract and detect thin cracks. To tackle this problem, we embed closed-loop feedback (CLF) into the neural network so that the model could learn to correct errors on its own, based on generative adversarial networks (GAN). The resulting model is called CrackCLF and includes the front and back ends, i.e. segmentation and adversarial network. The front end with U-shape framework is employed to generate crack maps, and the back end with a multi-scale loss function is used to correct higher-order inconsistencies between labels and crack maps (generated by the front end) to address open-loop system issues. Empirical results show that the proposed CrackCLF outperforms others methods on three public datasets. Moreover, the proposed CLF can be defined as a plug and play module, which can be embedded into different neural network models to improve their performances.
</details>
<details>
<summary>摘要</summary>
自动路面裂隙检测是一项重要任务，以确保路面在服务寿命中的功能性能。受深度学习（DL）的激发，编码-解码框架成为了裂隙检测的powerful工具。然而，这些模型通常是开 loop（OL）系统，它们会将薄裂隙视为背景。同时，这些模型无法自动更正预测错误，也无法适应环境变化自动提取和检测薄裂隙。为解决这个问题，我们将closed-loop反馈（CLF） embedding到神经网络中，使模型可以通过生成 adversarial networks（GAN）学习自动更正错误。得到的模型被称为CrackCLF，它包括前端和后端，即分 segmentation和对抗网络。前端采用U型框架生成裂隙地图，而后端使用多尺度损失函数来更正高阶不一致性 между标签和裂隙地图（生成前端），以解决开 loop系统问题。实验结果表明，提议的CrackCLF在三个公共数据集上表现出色，并且可以作为插件模块，嵌入不同神经网络模型以提高其性能。
</details></li>
</ul>
<hr>
<h2 id="Robot-Hand-Eye-Calibration-using-Structure-from-Motion"><a href="#Robot-Hand-Eye-Calibration-using-Structure-from-Motion" class="headerlink" title="Robot Hand-Eye Calibration using Structure-from-Motion"></a>Robot Hand-Eye Calibration using Structure-from-Motion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11808">http://arxiv.org/abs/2311.11808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Andreff, Radu Horaud, Bernard Espiau</li>
<li>for: 这个论文提出了一种新的 flexible 手眼协调方法，而大多数现有的手眼协调技术都需要使用协调器，并且与摄像头定位方法相结合。</li>
<li>methods: 我们结合了结构从运动和知道的机器人运动，并证明该解可以得到在线形式。这个解不仅解决了普通扭矩运动的问题，还可以处理纯翻译、纯旋转和平面运动等特殊运动。</li>
<li>results: 我们进行了大量的实验，并比较了该方法与现有的方法。结果表明，该方法的质量具有较高的精度和稳定性。<details>
<summary>Abstract</summary>
In this paper we propose a new flexible method for hand-eye calibration. The vast majority of existing hand-eye calibration techniques requires a calibration rig which is used in conjunction with camera pose estimation methods. Instead, we combine structure-from-motion with known robot motions and we show that the solution can be obtained in linear form. The latter solves for both the hand-eye parameters and for the unknown scale factor inherent with structure-from-motion methods. The algebraic analysis that is made possible with such a linear formulation allows to investigate not only the well known case of general screw motions but also such singular motions as pure translations, pure rotations, and planar motions. In essence, the robot-mounted camera looks to an unknown rigid layout, tracks points over an image sequence and estimates the camera-to-robot relationship. Such a self calibration process is relevant for unmanned vehicles, robots working in remote places, and so forth. We conduct a large number of experiments which validate the quality of the method by comparing it with existing ones.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的灵活手眼准备方法。大多数现有的手眼准备技术都需要使用准备机构，并与摄像头位置估计方法结合使用。而我们则将结构从运动与知道机器人运动相结合，并证明该解可以表示为线性形式。这种线性表述使得我们可以对不同类型的运动进行数学分析，包括普通旋转、平面运动和纯粹翻译等特殊运动。在实际应用中，机器人搭载的摄像头将看到未知的固定布局，跟踪图像序列中的点并估计摄像头和机器人之间的关系。这种自动准备过程对无人车、远程工作的机器人等有益。我们进行了大量实验，并与现有方法进行比较，以证明方法的高效性。
</details></li>
</ul>
<hr>
<h2 id="Robust-Tumor-Segmentation-with-Hyperspectral-Imaging-and-Graph-Neural-Networks"><a href="#Robust-Tumor-Segmentation-with-Hyperspectral-Imaging-and-Graph-Neural-Networks" class="headerlink" title="Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural Networks"></a>Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11782">http://arxiv.org/abs/2311.11782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mayar Lotfy, Anna Alperovich, Tommaso Giannantonio, Bjorn Barz, Xiaohan Zhang, Felix Holm, Nassir Navab, Felix Boehm, Carolin Schwamborn, Thomas K. Hoffmann, Patrick J. Schuler<br>for:* This paper aims to improve the accuracy of tumor segmentation in hyperspectral imaging (HSI) for surgical cancer resection.methods:* The proposed method combines hyperspectral imaging (HSI) with graph neural networks (GNNs) to leverage the spatial context of tiles for more robust and smoother segmentation.* The method uses a convolutional neural network (CNN) to extract features for each tile within the graph, and incorporates local image quality metrics into the loss function to enhance the training procedure’s robustness.results:* The proposed method significantly outperforms context-agnostic approaches in accurately distinguishing between healthy and tumor tissues, even in images from previously unseen patients.* The carefully designed loss function, accounting for local image quality, results in additional improvements.Here is the Chinese translation of the three key points:for:* 这篇论文目标是在医学激光成像（HSI）中提高肿瘤分割的准确率，以便更好地进行手术治疗。methods:* 提议的方法是将HSI与图 neural network（GNN）结合起来，利用图中块的空间Context来提高分割的稳定性和准确性。* 方法使用一个卷积神经网络（CNN）来提取每个块内图的特征，并在训练过程中同时训练后续的GNN。results:* 提议的方法在与无关的方法进行比较时，能够更好地分割健康和肿瘤组织，包括在之前未看到的患者的图像中。* 经过精心设计的损失函数，包括地方图像质量指标，可以进一步提高训练过程的稳定性。<details>
<summary>Abstract</summary>
Segmenting the boundary between tumor and healthy tissue during surgical cancer resection poses a significant challenge. In recent years, Hyperspectral Imaging (HSI) combined with Machine Learning (ML) has emerged as a promising solution. However, due to the extensive information contained within the spectral domain, most ML approaches primarily classify individual HSI (super-)pixels, or tiles, without taking into account their spatial context. In this paper, we propose an improved methodology that leverages the spatial context of tiles for more robust and smoother segmentation. To address the irregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate context information across neighboring regions. The features for each tile within the graph are extracted using a Convolutional Neural Network (CNN), which is trained simultaneously with the subsequent GNN. Moreover, we incorporate local image quality metrics into the loss function to enhance the training procedure's robustness against low-quality regions in the training images. We demonstrate the superiority of our proposed method using a clinical ex vivo dataset consisting of 51 HSI images from 30 patients. Despite the limited dataset, the GNN-based model significantly outperforms context-agnostic approaches, accurately distinguishing between healthy and tumor tissues, even in images from previously unseen patients. Furthermore, we show that our carefully designed loss function, accounting for local image quality, results in additional improvements. Our findings demonstrate that context-aware GNN algorithms can robustly find tumor demarcations on HSI images, ultimately contributing to better surgery success and patient outcome.
</details>
<details>
<summary>摘要</summary>
医学图像分割是肿瘤除除术中的一大挑战。近年来，快照 спектраль成像（HSI）与机器学习（ML）的结合已经出现为扩展可能性。然而，由于spectral domain中的信息过度充沛，大多数ML方法仅将HSI（超）像素或块分类，不考虑其空间上的相互关系。在这篇论文中，我们提出了改进的方法，利用块之间的空间关系来提供更加稳定和准确的分割。为了处理块的不规则形状，我们使用图像神经网络（GNN）将相邻区域之间的信息传播。每个块在图中EXTRACT特征使用卷积神经网络（CNN），并同时训练后续的GNN。此外，我们将图像质量指标添加到损失函数中，以提高训练过程的稳定性。我们在30名患者的51张医学图像上进行了临床外ivo的实验，并证明我们提出的GNN基于方法在上述Context-agnostic方法之上显著提高了分割精度。此外，我们还发现我们 precisely设计的损失函数，考虑到本地图像质量，会提供额外的改进。我们的发现表明，在HSI图像上使用Context-aware GNN算法可以稳定地找到肿瘤分界，从而对患者的手术成功和疾病结果产生正面的影响。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-deep-learning-for-mapping-forest-dominant-height-by-fusing-GEDI-with-earth-observation-data"><a href="#Multimodal-deep-learning-for-mapping-forest-dominant-height-by-fusing-GEDI-with-earth-observation-data" class="headerlink" title="Multimodal deep learning for mapping forest dominant height by fusing GEDI with earth observation data"></a>Multimodal deep learning for mapping forest dominant height by fusing GEDI with earth observation data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11777">http://arxiv.org/abs/2311.11777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Man Chen, Wenquan Dong, Hao Yu, Iain Woodhouse, Casey M. Ryan, Haoyu Liu, Selena Georgiou, Edward T. A. Mitchard</li>
<li>for: 这个研究旨在使用多源Remote sensing数据和深度学习模型精准地映射高分辨率森林高度。</li>
<li>methods: 我们提出了一种基于多Modal attention remote sensing network（MARSNet）的新深度学习框架，使用GEDI数据、Setinel-1数据、ALOS-2 PALSAR-2数据、Sentinel-2光学数据和其他数据。 MARSNet包括每种Remote sensing数据模式的单独编码器来提取多尺度特征，以及共享解码器来融合特征和估计高度。</li>
<li>results: 我们的研究表明，MARSNet可以高效地估计森林主要高度，R2为0.62，RMSE为2.82米，超过了广泛使用的随机森林方法（R2&#x3D;0.55，RMSE&#x3D;3.05米）。此外，我们使用训练好的MARSNet模型生成了10米分辨率的墙壁到墙壁地域高度图像，并通过独立验证使用场地测量结果，MARSNet得到了R2&#x3D;0.58和RMSE&#x3D;3.76米的结果，与随机森林基准值（R2&#x3D;0.41，RMSE&#x3D;4.37米）相比，表明MARSNet的精度更高。<details>
<summary>Abstract</summary>
The integration of multisource remote sensing data and deep learning models offers new possibilities for accurately mapping high spatial resolution forest height. We found that GEDI relative heights (RH) metrics exhibited strong correlation with the mean of the top 10 highest trees (dominant height) measured in situ at the corresponding footprint locations. Consequently, we proposed a novel deep learning framework termed the multi-modal attention remote sensing network (MARSNet) to estimate forest dominant height by extrapolating dominant height derived from GEDI, using Setinel-1 data, ALOS-2 PALSAR-2 data, Sentinel-2 optical data and ancillary data. MARSNet comprises separate encoders for each remote sensing data modality to extract multi-scale features, and a shared decoder to fuse the features and estimate height. Using individual encoders for each remote sensing imagery avoids interference across modalities and extracts distinct representations. To focus on the efficacious information from each dataset, we reduced the prevalent spatial and band redundancies in each remote sensing data by incorporating the extended spatial and band reconstruction convolution modules in the encoders. MARSNet achieved commendable performance in estimating dominant height, with an R2 of 0.62 and RMSE of 2.82 m, outperforming the widely used random forest approach which attained an R2 of 0.55 and RMSE of 3.05 m. Finally, we applied the trained MARSNet model to generate wall-to-wall maps at 10 m resolution for Jilin, China. Through independent validation using field measurements, MARSNet demonstrated an R2 of 0.58 and RMSE of 3.76 m, compared to 0.41 and 4.37 m for the random forest baseline. Our research demonstrates the effectiveness of a multimodal deep learning approach fusing GEDI with SAR and passive optical imagery for enhancing the accuracy of high resolution dominant height estimation.
</details>
<details>
<summary>摘要</summary>
“多源Remote数据和深度学习模型的整合可以提供高分辨率森林高度的新可能性。我们发现GEDI相对高度（RH）指标与场景中最高10棵树（主对高）的平均值 exhibited strong correlation。因此，我们提出了一个名为多模式注意深度测量网络（MARSNet）的新深度学习框架，用于估计森林主对高。MARSNet包括每个遥感数据模式的分别Encoder来提取多尺度特征，以及共同的解码器来融合特征和估计高度。这些Encoder对每个遥感数据模式进行分别对应，以避免模式之间的干扰和提取特有的表现。为了避免每个遥感数据模式的空间和频率统计重复，我们在Encoder中添加了扩展空间和频率重建卷积模组。MARSNet在主对高估计中表现了优异的成绩，R2为0.62，RMSE为2.82米，比较 Random Forest方法的R2为0.55，RMSE为3.05米。最后，我们将训练好的 MARSNet 模型应用到了 Jilin 地区的壁垒壁垒地图上，以10米resolution进行估计。通过独立验证使用场地测量，MARSNet exhibited R2为0.58，RMSE为3.76米，与Random Forest基eline的R2为0.41，RMSE为4.37米相比。我们的研究显示了多模式深度学习方法，融合 GEDI 、SAR 和过程式光学图像，可以提高高分辨率主对高估计的精度。”
</details></li>
</ul>
<hr>
<h2 id="Practical-cross-sensor-color-constancy-using-a-dual-mapping-strategy"><a href="#Practical-cross-sensor-color-constancy-using-a-dual-mapping-strategy" class="headerlink" title="Practical cross-sensor color constancy using a dual-mapping strategy"></a>Practical cross-sensor color constancy using a dual-mapping strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11773">http://arxiv.org/abs/2311.11773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Yue, Minchen Wei</li>
<li>for: 提出了一种基于双映射策略的图像照明估计方法，该方法只需要一个简单的白点测试传感器，并且可以在照明估计和图像重建之间进行快速转换。</li>
<li>methods: 该方法使用了图像重建和照明估计两个映射，然后使用轻量级多层感知神经网络（MLP）模型进行优化。</li>
<li>results: 该方法可以快速实现图像照明估计，并且可以减少传感器差异和提高性能，仅需要一小段的训练时间（约0.003 MB的内存和1小时的训练时间）和快速执行（约0.3 ms和1 ms在GPU和CPU上），并且不敏感于输入图像分辨率。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) have been widely used for illumination estimation, which is time-consuming and requires sensor-specific data collection. Our proposed method uses a dual-mapping strategy and only requires a simple white point from a test sensor under a D65 condition. This allows us to derive a mapping matrix, enabling the reconstructions of image data and illuminants. In the second mapping phase, we transform the re-constructed image data into sparse features, which are then optimized with a lightweight multi-layer perceptron (MLP) model using the re-constructed illuminants as ground truths. This approach effectively reduces sensor discrepancies and delivers performance on par with leading cross-sensor methods. It only requires a small amount of memory (~0.003 MB), and takes ~1 hour training on an RTX3070Ti GPU. More importantly, the method can be implemented very fast, with ~0.3 ms and ~1 ms on a GPU or CPU respectively, and is not sensitive to the input image resolution. Therefore, it offers a practical solution to the great challenges of data recollection that is faced by the industry.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）广泛应用于照明估计，这是时间费时且需要特定传感器数据采集。我们的提议方法采用双映射策略，只需要一个简单的白点数据集来自测传感器，并在D65条件下进行映射。这使得我们可以 derivate一个映射矩阵，启用图像数据和照明的重建。在第二个映射阶段，我们将重建的图像数据转换为稀疏特征，然后使用轻量级多层感知器（MLP）模型进行优化，使用重建的照明作为真实值。这种方法可以有效减少传感器差异，并提供与前列横跨传感器方法相当的性能。它只需要一小Amount of memory（约0.003 MB），并在RTX3070Ti GPU上训练约1小时。此外，该方法具有快速实现的特点，在GPU和CPU上分别需要0.3毫秒和1毫秒的时间，并不敏感于输入图像分辨率。因此，它提供了实际的解决方案，避免了业界面估计数据收集的大问题。
</details></li>
</ul>
<hr>
<h2 id="A-Good-Feature-Extractor-Is-All-You-Need-for-Weakly-Supervised-Learning-in-Histopathology"><a href="#A-Good-Feature-Extractor-Is-All-You-Need-for-Weakly-Supervised-Learning-in-Histopathology" class="headerlink" title="A Good Feature Extractor Is All You Need for Weakly Supervised Learning in Histopathology"></a>A Good Feature Extractor Is All You Need for Weakly Supervised Learning in Histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11772">http://arxiv.org/abs/2311.11772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Wölflein, Dyke Ferber, Asier Rabasco Meneghetti, Omar S. M. El Nahhas, Daniel Truhn, Zunamys I. Carrero, David J. Harrison, Ognjen Arandjelović, Jakob N. Kather</li>
<li>for: 这 paper 的目的是evaluating the robustness of public pathology SSL feature extractors and identifying the most suitable feature extractors for clinical applications.</li>
<li>methods: 这 paper 使用了多种方法，包括 slide-level prediction tasks in a weakly supervised setting with external validation cohorts, and an empirical evaluation of publicly available feature extractors.</li>
<li>results: 这 paper 的结果表明 that omitting stain normalization and image augmentations does not compromise downstream performance, while incurring substantial savings in memory and compute. Additionally, the top-performing feature extractors are remarkably robust to variations in stain and augmentations in their latent space.<details>
<summary>Abstract</summary>
Deep learning is revolutionising pathology, offering novel opportunities in disease prognosis and personalised treatment. Historically, stain normalisation has been a crucial preprocessing step in computational pathology pipelines, and persists into the deep learning era. Yet, with the emergence of feature extractors trained using self-supervised learning (SSL) on diverse pathology datasets, we call this practice into question. In an empirical evaluation of publicly available feature extractors, we find that omitting stain normalisation and image augmentations does not compromise downstream performance, while incurring substantial savings in memory and compute. Further, we show that the top-performing feature extractors are remarkably robust to variations in stain and augmentations like rotation in their latent space. Contrary to previous patch-level benchmarking studies, our approach emphasises clinical relevance by focusing on slide-level prediction tasks in a weakly supervised setting with external validation cohorts. This work represents the most comprehensive robustness evaluation of public pathology SSL feature extractors to date, involving more than 6,000 training runs across nine tasks, five datasets, three downstream architectures, and various preprocessing setups. Our findings stand to streamline digital pathology workflows by minimising preprocessing needs and informing the selection of feature extractors.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Non-Contact-NIR-PPG-Sensing-through-Large-Sequence-Signal-Regression"><a href="#Non-Contact-NIR-PPG-Sensing-through-Large-Sequence-Signal-Regression" class="headerlink" title="Non-Contact NIR PPG Sensing through Large Sequence Signal Regression"></a>Non-Contact NIR PPG Sensing through Large Sequence Signal Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11757">http://arxiv.org/abs/2311.11757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timothy Hanley, Dara Golden, Robyn Maxwell, Ashkan Parsi, Joseph Lemley</li>
<li>for: 这个论文是为了演示一种新的非接触感知技术，用于从 Near Infra-Red (NIR) 视频中提取心率信号。</li>
<li>methods: 这个论文使用了一种 alternating Convolution Attention Network (CAN) 架构，通过对 NIR 视频序列进行卷积和注意力重叠来进行感知。</li>
<li>results: 这个论文使用了两个公共可用的数据集，通过对这些数据集进行训练，实现了对 NIR 视频中心率信号的高精度预测。训练结果表明，使用这种 CAN 架构可以在 NIR 视频中提取高精度的心率信号，MAE 为 0.99 bpm。<details>
<summary>Abstract</summary>
Non-Contact sensing is an emerging technology with applications across many industries from driver monitoring in vehicles to patient monitoring in healthcare. Current state-of-the-art implementations focus on RGB video, but this struggles in varying/noisy light conditions and is almost completely unfeasible in the dark. Near Infra-Red (NIR) video, however, does not suffer from these constraints. This paper aims to demonstrate the effectiveness of an alternative Convolution Attention Network (CAN) architecture, to regress photoplethysmography (PPG) signal from a sequence of NIR frames. A combination of two publicly available datasets, which is split into train and test sets, is used for training the CAN. This combined dataset is augmented to reduce overfitting to the 'normal' 60 - 80 bpm heart rate range by providing the full range of heart rates along with corresponding videos for each subject. This CAN, when implemented over video cropped to the subject's head, achieved a Mean Average Error (MAE) of just 0.99 bpm, proving its effectiveness on NIR video and the architecture's feasibility to regress an accurate signal output.
</details>
<details>
<summary>摘要</summary>
非接触感测是一种emerging技术，应用于多个行业，从车辆驾驶员监测到医疗保健行业的患者监测。当前状态的实现主要基于RGB视频，但这在不同/噪音的照明条件下受到限制，而且在黑暗中基本无法实现。然而，近红外（NIR）视频不受这些限制。这篇论文目的是提出一种alternative Convolution Attention Network（CAN）架构，用于从NIR视频序列中回归血氧检测信号（PPG）信号。使用两个公共可用的数据集，通过将其分成训练和测试集，进行了训练CAN。这个合并的数据集通过提供每个主题的完整的心率范围，从而降低了预测到“常见”60-80bpm心率范围的溢出。这个CAN，当应用于对主题的头部视频进行裁剪后，实现了 Mean Average Error（MAE）为0.99bpm，证明了其在NIR视频和架构上的可行性和回归精度的输出信号。
</details></li>
</ul>
<hr>
<h2 id="AdvGen-Physical-Adversarial-Attack-on-Face-Presentation-Attack-Detection-Systems"><a href="#AdvGen-Physical-Adversarial-Attack-on-Face-Presentation-Attack-Detection-Systems" class="headerlink" title="AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems"></a>AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11753">http://arxiv.org/abs/2311.11753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Amrit Patnaik, Shivali Chansoriya, Anil K. Jain, Anoop M. Namboodiri</li>
<li>for: 防止面部识别系统在真实世界中受到攻击，因为攻击者可以通过修改捕捉到的图像来诱导系统进行误认。</li>
<li>methods: 我们提出了一种基于生成对抗网络的自动化攻击策略，可以在物理世界场景下生成攻击图像，并在四个数据集和十个国家级人脸识别系统上进行了广泛的测试。</li>
<li>results: 我们的攻击策略可以在物理世界场景下达到82.01%的攻击成功率，并在实际Physical环境中进行了实验验证。<details>
<summary>Abstract</summary>
Evaluating the risk level of adversarial images is essential for safely deploying face authentication models in the real world. Popular approaches for physical-world attacks, such as print or replay attacks, suffer from some limitations, like including physical and geometrical artifacts. Recently, adversarial attacks have gained attraction, which try to digitally deceive the learning strategy of a recognition system using slight modifications to the captured image. While most previous research assumes that the adversarial image could be digitally fed into the authentication systems, this is not always the case for systems deployed in the real world. This paper demonstrates the vulnerability of face authentication systems to adversarial images in physical world scenarios. We propose AdvGen, an automated Generative Adversarial Network, to simulate print and replay attacks and generate adversarial images that can fool state-of-the-art PADs in a physical domain attack setting. Using this attack strategy, the attack success rate goes up to 82.01%. We test AdvGen extensively on four datasets and ten state-of-the-art PADs. We also demonstrate the effectiveness of our attack by conducting experiments in a realistic, physical environment.
</details>
<details>
<summary>摘要</summary>
evaluating the risk level of adversarial images is essential for safely deploying face authentication models in the real world. popular approaches for physical-world attacks, such as print or replay attacks, suffer from some limitations, like including physical and geometrical artifacts. recently, adversarial attacks have gained attraction, which try to digitally deceive the learning strategy of a recognition system using slight modifications to the captured image. while most previous research assumes that the adversarial image could be digitally fed into the authentication systems, this is not always the case for systems deployed in the real world. this paper demonstrates the vulnerability of face authentication systems to adversarial images in physical world scenarios. we propose advgen, an automated generative adversarial network, to simulate print and replay attacks and generate adversarial images that can fool state-of-the-art padss in a physical domain attack setting. using this attack strategy, the attack success rate goes up to 82.01%. we test advgen extensively on four datasets and ten state-of-the-art padss. we also demonstrate the effectiveness of our attack by conducting experiments in a realistic, physical environment.Here's the translation in Traditional Chinese:评估对于攻击性图像的风险水平是在实际应用中部署人脸识别系统的必要条件。传统的物理攻击方法，如印刷或重播攻击，受到一些限制，例如包括物理和几何学性错误。过去的研究多数假设可以将攻击图像直接传入识别系统，但这不一定适用于实际应用中的系统。本文展示了面部识别系统对于攻击图像在实际世界场景中的脆弱性。我们提出了AdvGen，一个自动生成的对抗网络，来模拟印刷和重播攻击，生成可以诱导面部识别系统的攻击图像。使用这种攻击策略，攻击成功率可以达到82.01%。我们对四个数据集和十个现代PADS进行了广泛的测试。我们还证明了我们的攻击的有效性，通过在实际、物理环境中进行实验。
</details></li>
</ul>
<hr>
<h2 id="Fuzzy-Information-Seeded-Region-Growing-for-Automated-Lesions-After-Stroke-Segmentation-in-MR-Brain-Images"><a href="#Fuzzy-Information-Seeded-Region-Growing-for-Automated-Lesions-After-Stroke-Segmentation-in-MR-Brain-Images" class="headerlink" title="Fuzzy Information Seeded Region Growing for Automated Lesions After Stroke Segmentation in MR Brain Images"></a>Fuzzy Information Seeded Region Growing for Automated Lesions After Stroke Segmentation in MR Brain Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11742">http://arxiv.org/abs/2311.11742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mawio02/fisrg-for-automated-lesion-after-stroke-segmentation-in-mri">https://github.com/mawio02/fisrg-for-automated-lesion-after-stroke-segmentation-in-mri</a></li>
<li>paper_authors: Mario Pascual González</li>
<li>for:  stroke lesion segmentation from brain MRI images</li>
<li>methods:  Fuzzy Information Seeded Region Growing (FISRG) algorithm</li>
<li>results:  highest Dice score of 94.2%, with an average Dice score of 88.1% in the third experiment, indicating effective segmentation of stroke lesions.<details>
<summary>Abstract</summary>
In the realm of medical imaging, precise segmentation of stroke lesions from brain MRI images stands as a critical challenge with significant implications for patient diagnosis and treatment. Addressing this, our study introduces an innovative approach using a Fuzzy Information Seeded Region Growing (FISRG) algorithm. Designed to effectively delineate the complex and irregular boundaries of stroke lesions, the FISRG algorithm combines fuzzy logic with Seeded Region Growing (SRG) techniques, aiming to enhance segmentation accuracy.   The research involved three experiments to optimize the FISRG algorithm's performance, each focusing on different parameters to improve the accuracy of stroke lesion segmentation. The highest Dice score achieved in these experiments was 94.2\%, indicating a high degree of similarity between the algorithm's output and the expert-validated ground truth. Notably, the best average Dice score, amounting to 88.1\%, was recorded in the third experiment, highlighting the efficacy of the algorithm in consistently segmenting stroke lesions across various slices.   Our findings reveal the FISRG algorithm's strengths in handling the heterogeneity of stroke lesions. However, challenges remain in areas of abrupt lesion topology changes and in distinguishing lesions from similar intensity brain regions. The results underscore the potential of the FISRG algorithm in contributing significantly to advancements in medical imaging analysis for stroke diagnosis and treatment.
</details>
<details>
<summary>摘要</summary>
在医学成像领域，精准地从脑MRI图像中分割中风损害的 segmentation 作为一项关键挑战，对患者诊断和治疗具有重要意义。我们的研究报告了一种新的方法，即基于模糊逻辑和种子区域生长（FISRG）算法。这种算法旨在准确地界定中风损害的复杂和不规则边界，并通过结合模糊逻辑和种子区域生长（SRG）技术，提高分割精度。我们的研究进行了三个实验来优化FISRG算法的性能，每个实验都关注不同的参数来提高中风损害分割的准确率。实验中最高的 dice 分数为 94.2%，表明算法的输出与专家验证的真实值之间存在高度的相似性。而第三个实验的平均 dice 分数为 88.1%，表明算法在不同的slice中具有高度的稳定性，并能够一致地分割中风损害。我们的发现表明FISRG算法在处理中风损害的多样性方面具有优异的能力。然而，在突然的损害 topology 变化和类似intensity脑区域的区分方面仍然存在挑战。结果表明FISRG算法在医学成像分析中具有广泛的应用前景，对stroke诊断和治疗具有重要意义。
</details></li>
</ul>
<hr>
<h2 id="On-the-Importance-of-Large-Objects-in-CNN-Based-Object-Detection-Algorithms"><a href="#On-the-Importance-of-Large-Objects-in-CNN-Based-Object-Detection-Algorithms" class="headerlink" title="On the Importance of Large Objects in CNN Based Object Detection Algorithms"></a>On the Importance of Large Objects in CNN Based Object Detection Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11714">http://arxiv.org/abs/2311.11714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Ben Saad, Gabriele Facciolo, Axel Davy</li>
<li>for: 提高对象检测器的性能，特别是小对象的检测 scores。</li>
<li>methods: 引入一个基于对象面积的权重项到训练损失函数中，以便更加强调大对象的学习特征。</li>
<li>results: 在COCO val 2017上，与 InternImage-T 模型结合使用我们的方法可以提高对象检测器的总性能 (+2 p.p. on small objects, +2 p.p. on medium objects, +4 p.p. on large objects)。 Additionally, we conduct additional experiments and ablation studies to confirm the robustness of our findings.<details>
<summary>Abstract</summary>
Object detection models, a prominent class of machine learning algorithms, aim to identify and precisely locate objects in images or videos. However, this task might yield uneven performances sometimes caused by the objects sizes and the quality of the images and labels used for training. In this paper, we highlight the importance of large objects in learning features that are critical for all sizes. Given these findings, we propose to introduce a weighting term into the training loss. This term is a function of the object area size. We show that giving more weight to large objects leads to improved detection scores across all object sizes and so an overall improvement in Object Detectors performances (+2 p.p. of mAP on small objects, +2 p.p. on medium and +4 p.p. on large on COCO val 2017 with InternImage-T). Additional experiments and ablation studies with different models and on a different dataset further confirm the robustness of our findings.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:对象检测模型，一种常见的机器学习算法，目的是在图像或视频中准确地识别和定位对象。然而，这个任务可能会导致不均匀的性能，这可能是因为对象的大小以及用于训练的图像和标签的质量。在这篇文章中，我们强调大对象在学习特征上的重要性，这些特征是所有大小对象都需要的。基于这些发现，我们提议在训练损失函数中添加一个面积大小相关的权重项。我们显示，对大对象的权重更重，会导致所有对象大小上的检测分数提高 (+2 p.p. of mAP on small objects, +2 p.p. on medium and +4 p.p. on large on COCO val 2017 with InternImage-T)。附加的实验和缺省研究表明我们的发现是可靠的。
</details></li>
</ul>
<hr>
<h2 id="GS-SLAM-Dense-Visual-SLAM-with-3D-Gaussian-Splatting"><a href="#GS-SLAM-Dense-Visual-SLAM-with-3D-Gaussian-Splatting" class="headerlink" title="GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting"></a>GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11700">http://arxiv.org/abs/2311.11700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chi Yan, Delin Qu, Dong Wang, Dan Xu, Zhigang Wang, Bin Zhao, Xuelong Li</li>
<li>for: 这个论文是为了提出一种基于3D Gaussian表示的同时定位和地图生成（SLAM）系统。</li>
<li>methods: 这个方法使用了实时可导渲染 Rendering 管道，以提高地图优化和RGB-D重渲染的速度。它还提出了一种适应扩展策略，以有效地重建新观察到的场景几何结构，并改进了已经观察到的区域的地图。</li>
<li>results: 该方法在Replica和TUM-RGBD数据集上实现了与现有实时方法相当的竞争性表现，并且在运行时间和稳定性方面具有明显的优势。<details>
<summary>Abstract</summary>
In this paper, we introduce $\textbf{GS-SLAM}$ that first utilizes 3D Gaussian representation in the Simultaneous Localization and Mapping (SLAM) system. It facilitates a better balance between efficiency and accuracy. Compared to recent SLAM methods employing neural implicit representations, our method utilizes a real-time differentiable splatting rendering pipeline that offers significant speedup to map optimization and RGB-D re-rendering. Specifically, we propose an adaptive expansion strategy that adds new or deletes noisy 3D Gaussian in order to efficiently reconstruct new observed scene geometry and improve the mapping of previously observed areas. This strategy is essential to extend 3D Gaussian representation to reconstruct the whole scene rather than synthesize a static object in existing methods. Moreover, in the pose tracking process, an effective coarse-to-fine technique is designed to select reliable 3D Gaussian representations to optimize camera pose, resulting in runtime reduction and robust estimation. Our method achieves competitive performance compared with existing state-of-the-art real-time methods on the Replica, TUM-RGBD datasets. The source code will be released soon.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们引入了$\textbf{GS-SLAM}$，它首先利用了3D高斯函数表示在同时地标注和地图（SLAM）系统中。它使得更好地寻求效率和准确之间的平衡。相比最近的SLAM方法使用神经网络卷积表示，我们的方法使用了实时可导渲染管道，从而提供了显著的速度提升，用于地图优化和RGB-D重新渲染。具体来说，我们提出了适应扩展策略，将新的或噪声3D高斯函数添加到重构新观察到的场景几何，以提高已观察区域的地图。这种策略是对3D高斯函数表示扩展到重构整个场景而不是Synthesize静止物体的现有方法。此外，在摄像头跟踪过程中，我们设计了一种有效的过滤策略，选择可靠的3D高斯函数表示，以优化摄像头pose，从而实现时间缩短和稳定估计。我们的方法在实时实现的State-of-the-art方法上达到了竞争性表现。我们即将发布源代码。
</details></li>
</ul>
<hr>
<h2 id="Cut-and-Paste-Subject-Driven-Video-Editing-with-Attention-Control"><a href="#Cut-and-Paste-Subject-Driven-Video-Editing-with-Attention-Control" class="headerlink" title="Cut-and-Paste: Subject-Driven Video Editing with Attention Control"></a>Cut-and-Paste: Subject-Driven Video Editing with Attention Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11697">http://arxiv.org/abs/2311.11697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Zuo, Zhao Zhang, Yan Luo, Yang Zhao, Haijun Zhang, Yi Yang, Meng Wang</li>
<li>for: 这个 paper 是为了提出一种基于文本指导的Semantic Video editing方法，以便在视频编辑中具有更高精度的控制，并且能够保留视频背景。</li>
<li>methods: 该 paper 使用了一种称为 Cut-and-Paste 的新框架，它利用文本指导和补充图像来进行 Semantic Video editing。具体来说，该方法使用了 cross attention 控制方法来限制编辑区域，以保持视频背景和空间时间一致性。</li>
<li>results: 该 paper 的实验结果表明，相比于现有的方法，Cut-and-Paste 方法能够更好地控制视频编辑，并且能够保留视频背景。这些结果是基于量化和主观评价的。<details>
<summary>Abstract</summary>
This paper presents a novel framework termed Cut-and-Paste for real-word semantic video editing under the guidance of text prompt and additional reference image. While the text-driven video editing has demonstrated remarkable ability to generate highly diverse videos following given text prompts, the fine-grained semantic edits are hard to control by plain textual prompt only in terms of object details and edited region, and cumbersome long text descriptions are usually needed for the task. We therefore investigate subject-driven video editing for more precise control of both edited regions and background preservation, and fine-grained semantic generation. We achieve this goal by introducing an reference image as supplementary input to the text-driven video editing, which avoids racking your brain to come up with a cumbersome text prompt describing the detailed appearance of the object. To limit the editing area, we refer to a method of cross attention control in image editing and successfully extend it to video editing by fusing the attention map of adjacent frames, which strikes a balance between maintaining video background and spatio-temporal consistency. Compared with current methods, the whole process of our method is like ``cut" the source object to be edited and then ``paste" the target object provided by reference image. We demonstrate that our method performs favorably over prior arts for video editing under the guidance of text prompt and extra reference image, as measured by both quantitative and subjective evaluations.
</details>
<details>
<summary>摘要</summary>
To achieve this, we introduce a reference image as supplementary input to the text-driven video editing process. This helps avoid the need for detailed text prompts describing object appearance, allowing for more intuitive and efficient editing. Additionally, we extend a cross-attention control method from image editing to video editing, fusing attention maps of adjacent frames to maintain video background and spatio-temporal consistency.Our Cut-and-Paste method is like "cutting" the source object to be edited and "pasting" the target object from the reference image. We demonstrate that our method outperforms prior arts in terms of both quantitative and subjective evaluations.
</details></li>
</ul>
<hr>
<h2 id="Clarity-ChatGPT-An-Interactive-and-Adaptive-Processing-System-for-Image-Restoration-and-Enhancement"><a href="#Clarity-ChatGPT-An-Interactive-and-Adaptive-Processing-System-for-Image-Restoration-and-Enhancement" class="headerlink" title="Clarity ChatGPT: An Interactive and Adaptive Processing System for Image Restoration and Enhancement"></a>Clarity ChatGPT: An Interactive and Adaptive Processing System for Image Restoration and Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11695">http://arxiv.org/abs/2311.11695</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanyan Wei, Zhao Zhang, Jiahuan Ren, Xiaogang Xu, Richang Hong, Yi Yang, Shuicheng Yan, Meng Wang</li>
<li>for: 提高图像修复和优化（IRE）方法的通用能力和交互功能，解决现有IRE方法的限制性和不足。</li>
<li>methods: 提出了一种基于对话智能的 transformative 系统 Clarity ChatGPT，结合了多种IRE方法，可自动探测图像异常类型并选择合适的修复方法，或者基于用户反馈进行迭代生成满意结果。</li>
<li>results: 在实验studies中，Clarity ChatGPT 能够有效提高IRE方法的通用能力和交互功能，并填补现有视力语言模型的低级域 gap。<details>
<summary>Abstract</summary>
The generalization capability of existing image restoration and enhancement (IRE) methods is constrained by the limited pre-trained datasets, making it difficult to handle agnostic inputs such as different degradation levels and scenarios beyond their design scopes. Moreover, they are not equipped with interactive mechanisms to consider user preferences or feedback, and their end-to-end settings cannot provide users with more choices. Faced with the above-mentioned IRE method's limited performance and insufficient interactivity, we try to solve it from the engineering and system framework levels. Specifically, we propose Clarity ChatGPT-a transformative system that combines the conversational intelligence of ChatGPT with multiple IRE methods. Clarity ChatGPT can automatically detect image degradation types and select appropriate IRE methods to restore images, or iteratively generate satisfactory results based on user feedback. Its innovative features include a CLIP-powered detector for accurate degradation classification, no-reference image quality evaluation for performance evaluation, region-specific processing for precise enhancements, and advanced fusion techniques for optimal restoration results. Clarity ChatGPT marks a significant advancement in integrating language and vision, enhancing image-text interactions, and providing a robust, high-performance IRE solution. Our case studies demonstrate that Clarity ChatGPT effectively improves the generalization and interaction capabilities in the IRE, and also fills the gap in the low-level domain of the existing vision-language model.
</details>
<details>
<summary>摘要</summary>
现有的图像修复和改善（IRE）方法的通用能力受到先前训练数据的限制，这使得它们处理不同的降低水平和场景变得困难。此外，它们没有交互机制来考虑用户偏好或反馈，其端到端设置也无法提供更多的选择。面临以上问题的IRE方法表现不佳，我们尝试解决它从工程和系统框架的角度。我们提出了明亮ChatGPT-一个将语言智能和多种IRE方法结合的转变系统。明亮ChatGPT可以自动检测图像降低类型并选择合适的IRE方法来修复图像，或者基于用户反馈进行迭代生成满意的结果。它的创新特点包括CLIP驱动的检测器以确定准确的降低类型，无参图像质量评价来评估性能，区域特定的处理以实现精细的改善，以及高级融合技术来实现优化的修复结果。明亮ChatGPT对整合语言和视觉，提高图像文本交互，并提供了一个robust、高性能的IRE解决方案。我们的案例研究表明，明亮ChatGPT可以有效地提高IRE的通用和交互能力，同时填补现有视力语言模型的低级域空白。
</details></li>
</ul>
<hr>
<h2 id="Segment-Together-A-Versatile-Paradigm-for-Semi-Supervised-Medical-Image-Segmentation"><a href="#Segment-Together-A-Versatile-Paradigm-for-Semi-Supervised-Medical-Image-Segmentation" class="headerlink" title="Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image Segmentation"></a>Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11686">http://arxiv.org/abs/2311.11686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingjie Zeng, Yutong Xie, Zilin Lu, Mengkang Lu, Yicheng Wu, Yong Xia<br>for: 这篇论文的目的是提出一个新的多任务 semi-supervised 架构，以实现医疗影像分类 tasks 中的资料欠缺问题，并且可以将多个数据集合到一个统一的模型中，以便更好地利用无标的数据。methods: 这篇论文使用了一个动态任务推问设计，可以在不同的数据集上灵活地推问不同的目标，以及一个实验室实现的 cutmix 策略来增强模型的准确性。此外，这篇论文还引入了一个内部协调的一致性约束，以使用无标的数据更好地对模型进行训练。results: 这篇论文的实验结果显示，VerSemi 模型可以在四个公共标准 benchmark 上实现比第二最佳方法的大幅提升（例如，平均提升 2.69% Dice 值），实现新的 SOTA 性能在 semi-supervised 医疗影像分类中。<details>
<summary>Abstract</summary>
Annotation scarcity has become a major obstacle for training powerful deep-learning models for medical image segmentation, restricting their deployment in clinical scenarios. To address it, semi-supervised learning by exploiting abundant unlabeled data is highly desirable to boost the model training. However, most existing works still focus on limited medical tasks and underestimate the potential of learning across diverse tasks and multiple datasets. Therefore, in this paper, we introduce a \textbf{Ver}satile \textbf{Semi}-supervised framework (VerSemi) to point out a new perspective that integrates various tasks into a unified model with a broad label space, to exploit more unlabeled data for semi-supervised medical image segmentation. Specifically, we introduce a dynamic task-prompted design to segment various targets from different datasets. Next, this unified model is used to identify the foreground regions from all labeled data, to capture cross-dataset semantics. Particularly, we create a synthetic task with a cutmix strategy to augment foreground targets within the expanded label space. To effectively utilize unlabeled data, we introduce a consistency constraint. This involves aligning aggregated predictions from various tasks with those from the synthetic task, further guiding the model in accurately segmenting foreground regions during training. We evaluated our VerSemi model on four public benchmarking datasets. Extensive experiments demonstrated that VerSemi can consistently outperform the second-best method by a large margin (e.g., an average 2.69\% Dice gain on four datasets), setting new SOTA performance for semi-supervised medical image segmentation. The code will be released.
</details>
<details>
<summary>摘要</summary>
annotation scarcity has become a major obstacle for training powerful deep-learning models for medical image segmentation, restricting their deployment in clinical scenarios. To address it, semi-supervised learning by exploiting abundant unlabeled data is highly desirable to boost the model training. However, most existing works still focus on limited medical tasks and underestimate the potential of learning across diverse tasks and multiple datasets. Therefore, in this paper, we introduce a VERsatile semi-supervised framework (VerSemi) to point out a new perspective that integrates various tasks into a unified model with a broad label space, to exploit more unlabeled data for semi-supervised medical image segmentation. Specifically, we introduce a dynamic task-prompted design to segment various targets from different datasets. Next, this unified model is used to identify the foreground regions from all labeled data, to capture cross-dataset semantics. Particularly, we create a synthetic task with a cutmix strategy to augment foreground targets within the expanded label space. To effectively utilize unlabeled data, we introduce a consistency constraint. This involves aligning aggregated predictions from various tasks with those from the synthetic task, further guiding the model in accurately segmenting foreground regions during training. We evaluated our VerSemi model on four public benchmarking datasets. Extensive experiments demonstrated that VerSemi can consistently outperform the second-best method by a large margin (e.g., an average 2.69\% Dice gain on four datasets), setting new SOTA performance for semi-supervised medical image segmentation. The code will be released.Here's the translation in Traditional Chinese:annotation scarcity has become a major obstacle for training powerful deep-learning models for medical image segmentation, restricting their deployment in clinical scenarios. To address it, semi-supervised learning by exploiting abundant unlabeled data is highly desirable to boost the model training. However, most existing works still focus on limited medical tasks and underestimate the potential of learning across diverse tasks and multiple datasets. Therefore, in this paper, we introduce a VERsatile semi-supervised framework (VerSemi) to point out a new perspective that integrates various tasks into a unified model with a broad label space, to exploit more unlabeled data for semi-supervised medical image segmentation. Specifically, we introduce a dynamic task-prompted design to segment various targets from different datasets. Next, this unified model is used to identify the foreground regions from all labeled data, to capture cross-dataset semantics. Particularly, we create a synthetic task with a cutmix strategy to augment foreground targets within the expanded label space. To effectively utilize unlabeled data, we introduce a consistency constraint. This involves aligning aggregated predictions from various tasks with those from the synthetic task, further guiding the model in accurately segmenting foreground regions during training. We evaluated our VerSemi model on four public benchmarking datasets. Extensive experiments demonstrated that VerSemi can consistently outperform the second-best method by a large margin (e.g., an average 2.69\% Dice gain on four datasets), setting new SOTA performance for semi-supervised medical image segmentation. The code will be released.
</details></li>
</ul>
<hr>
<h2 id="Pyramid-Diffusion-for-Fine-3D-Large-Scene-Generation"><a href="#Pyramid-Diffusion-for-Fine-3D-Large-Scene-Generation" class="headerlink" title="Pyramid Diffusion for Fine 3D Large Scene Generation"></a>Pyramid Diffusion for Fine 3D Large Scene Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12085">http://arxiv.org/abs/2311.12085</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Yuheng-SWJTU/pyramid-discrete-diffusion">https://github.com/Yuheng-SWJTU/pyramid-discrete-diffusion</a></li>
<li>paper_authors: Yuheng Liu, Xinke Li, Xueting Li, Lu Qi, Chongshou Li, Ming-Hsuan Yang</li>
<li>for: 本研究旨在Addressing the challenges of directly transferring 2D techniques to 3D scene generation, and proposing a novel approach for high-quality 3D scene generation.</li>
<li>methods: 本研究提出了一种多尺度模型（Pyramid Discrete Diffusion，PDD），可以逐步生成高质量的3D场景，从粗略到细节。</li>
<li>results: 实验覆盖了无条件和条件生成两种情况，并得到了吸引人的结果，证明模型在生成真实和细腻的3D场景方面具有效果和稳定性。<details>
<summary>Abstract</summary>
Directly transferring the 2D techniques to 3D scene generation is challenging due to significant resolution reduction and the scarcity of comprehensive real-world 3D scene datasets. To address these issues, our work introduces the Pyramid Discrete Diffusion model (PDD) for 3D scene generation. This novel approach employs a multi-scale model capable of progressively generating high-quality 3D scenes from coarse to fine. In this way, the PDD can generate high-quality scenes within limited resource constraints and does not require additional data sources. To the best of our knowledge, we are the first to adopt the simple but effective coarse-to-fine strategy for 3D large scene generation. Our experiments, covering both unconditional and conditional generation, have yielded impressive results, showcasing the model's effectiveness and robustness in generating realistic and detailed 3D scenes. Our code will be available to the public.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用 Pyramid Discrete Diffusion 模型（PDD）进行三维场景生成是一项挑战，因为它会导致场景的分辨率减少，并且有限的实际三维场景数据。为解决这些问题，我们的工作提出了一种新的方法：逐步生成高质量的三维场景。在这种方法中，PDD 可以逐步生成高质量的场景，并且不需要额外的数据源。我们知道，我们是首次采用简单 yet 有效的粗化到细化策略来进行大型三维场景生成。我们的实验，涵盖无条件生成和条件生成，具有吸引人的效果和稳定性，证明了 PDD 模型的可行性和可靠性。我们的代码将对公众开放。
</details></li>
</ul>
<hr>
<h2 id="PMP-Swin-Multi-Scale-Patch-Message-Passing-Swin-Transformer-for-Retinal-Disease-Classification"><a href="#PMP-Swin-Multi-Scale-Patch-Message-Passing-Swin-Transformer-for-Retinal-Disease-Classification" class="headerlink" title="PMP-Swin: Multi-Scale Patch Message Passing Swin Transformer for Retinal Disease Classification"></a>PMP-Swin: Multi-Scale Patch Message Passing Swin Transformer for Retinal Disease Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11669">http://arxiv.org/abs/2311.11669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihan Yang, Zhiming Cheng, Tengjin Weng, Shucheng He, Yaqi Wang, Xin Ye, Shuai Wang</li>
<li>for: 预测眼病诊断，提高诊断精度。</li>
<li>methods: 基于Message Passing机制的Patch Message Passing模块，以global交互强制特异性特征，并采用多种缩放的PatchSize进行多级划分。</li>
<li>results: 与现有方法比较，实现了remarkable的性能。<details>
<summary>Abstract</summary>
Retinal disease is one of the primary causes of visual impairment, and early diagnosis is essential for preventing further deterioration. Nowadays, many works have explored Transformers for diagnosing diseases due to their strong visual representation capabilities. However, retinal diseases exhibit milder forms and often present with overlapping signs, which pose great difficulties for accurate multi-class classification. Therefore, we propose a new framework named Multi-Scale Patch Message Passing Swin Transformer for multi-class retinal disease classification. Specifically, we design a Patch Message Passing (PMP) module based on the Message Passing mechanism to establish global interaction for pathological semantic features and to exploit the subtle differences further between different diseases. Moreover, considering the various scale of pathological features we integrate multiple PMP modules for different patch sizes. For evaluation, we have constructed a new dataset, named OPTOS dataset, consisting of 1,033 high-resolution fundus images photographed by Optos camera and conducted comprehensive experiments to validate the efficacy of our proposed method. And the results on both the public dataset and our dataset demonstrate that our method achieves remarkable performance compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
retinal disease 是一种主要导致视力障碍的原因，早期诊断非常重要，以防止更进一步的恶化。现在，许多研究已经利用 Transformers 进行疾病诊断，因为它们具有强的视觉表示能力。然而，肠眼病的表现相对软，常常出现 overlap 的症状，这会带来精度的多类分类困难。因此，我们提出了一种新的框架，即多尺度缝 Message Passing Swin Transformer，用于多类肠眼病分类。特别是，我们设计了一个缝 Message Passing（PMP）模块，基于消息传递机制，以确立全局交互，激发不同疾病之间的微妙差异。此外，考虑到不同尺度的病理特征，我们将多个 PMP 模块结合在一起，用于不同的缝size。为了评估我们的提议方法，我们建立了一个新的数据集，名为 OPTOS 数据集，包含 1,033 个高分辨率肠眼图像，通过 Optos 摄像机拍摄，并进行了全面的实验来验证我们的提议方法的效果。结果表明，我们的方法在公共数据集和我们自己的数据集上均表现出色，胜过当前的状态对照方法。
</details></li>
</ul>
<hr>
<h2 id="ODDR-Outlier-Detection-Dimension-Reduction-Based-Defense-Against-Adversarial-Patches"><a href="#ODDR-Outlier-Detection-Dimension-Reduction-Based-Defense-Against-Adversarial-Patches" class="headerlink" title="ODDR: Outlier Detection &amp; Dimension Reduction Based Defense Against Adversarial Patches"></a>ODDR: Outlier Detection &amp; Dimension Reduction Based Defense Against Adversarial Patches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12084">http://arxiv.org/abs/2311.12084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nandish Chattopadhyay, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique<br>for:This paper aims to mitigate the effects of patch-based adversarial attacks on machine learning models.methods:The proposed method, ODDR, uses a three-stage pipeline consisting of Fragmentation, Segregation, and Neutralization. Outlier detection techniques are used to identify and segregate anomalous features associated with adversarial perturbations, and dimension reduction methods are applied to mitigate the impact of these perturbations.results:ODDR effectively mitigates patch-based adversarial attacks, with robust accuracies matching or lying within a small range of clean accuracies, and only a marginal compromise of 1-2% in performance on clean samples. The method outperforms other defenses, demonstrating its effectiveness.Here is the simplified Chinese text for the three key points:for:这篇论文目的是为了 Mitigate patch-based adversarial attacks 对机器学习模型的影响。methods:提议的方法 ODDR 使用了一个三个阶段的管道，包括 Fragmentation、Segregation 和 Neutralization。它使用 outlier detection 技术来标识和分离 adversarial perturbations 对图像的异常特征，并使用 dimension reduction 方法来减少这些异常特征对模型的影响。results:ODDR 有效地 Mitigate patch-based adversarial attacks，Robust accuracy 与 clean accuracy 之间几乎相同，并且只有一个微小的牺牲（1-2%）。与其他防御方法相比，ODDR 表现更佳。<details>
<summary>Abstract</summary>
Adversarial attacks are a major deterrent towards the reliable use of machine learning models. A powerful type of adversarial attacks is the patch-based attack, wherein the adversarial perturbations modify localized patches or specific areas within the images to deceive the trained machine learning model. In this paper, we introduce Outlier Detection and Dimension Reduction (ODDR), a holistic defense mechanism designed to effectively mitigate patch-based adversarial attacks. In our approach, we posit that input features corresponding to adversarial patches, whether naturalistic or otherwise, deviate from the inherent distribution of the remaining image sample and can be identified as outliers or anomalies. ODDR employs a three-stage pipeline: Fragmentation, Segregation, and Neutralization, providing a model-agnostic solution applicable to both image classification and object detection tasks. The Fragmentation stage parses the samples into chunks for the subsequent Segregation process. Here, outlier detection techniques identify and segregate the anomalous features associated with adversarial perturbations. The Neutralization stage utilizes dimension reduction methods on the outliers to mitigate the impact of adversarial perturbations without sacrificing pertinent information necessary for the machine learning task. Extensive testing on benchmark datasets and state-of-the-art adversarial patches demonstrates the effectiveness of ODDR. Results indicate robust accuracies matching and lying within a small range of clean accuracies (1%-3% for classification and 3%-5% for object detection), with only a marginal compromise of 1%-2% in performance on clean samples, thereby significantly outperforming other defenses.
</details>
<details>
<summary>摘要</summary>
机器学习模型面临着严重的抗击攻击的威胁。许多抗击攻击中最具攻击力的是覆盖式攻击，即在图像中添加小量攻击干扰以让机器学习模型进行误分类。在这篇论文中，我们介绍了一种名为异常检测和维度减少（ODDR）的总体防御机制，用于有效地抵御覆盖式攻击。我们认为，受攻击的图像特征（自然或者不自然的攻击干扰）与图像的主要特征分布不同，可以被识别为异常或者异常值。ODDR使用三个阶段管道：分割、分类和中和，提供了对机器学习任务无关的解决方案，适用于图像分类和物体检测任务。分割阶段将样本分割成多个块，以便于后续的分类阶段。在这个阶段，异常检测技术将攻击干扰相关的异常特征分离出来。中和阶段使用维度减少方法对异常特征进行中和，以降低攻击干扰的影响，同时保留必要的信息以确保机器学习任务的正确性。我们对标准的攻击 dataset 和最新的攻击干扰进行了广泛的测试，结果显示ODDR具有优秀的效果。结果表明，ODDR 可以保持和清理样本中的净度（1%-3%  для分类和3%-5%  для物体检测），只有较小的牺牲（1%-2%），而其他防御机制则需要更大的牺牲。
</details></li>
</ul>
<hr>
<h2 id="OmniSeg3D-Omniversal-3D-Segmentation-via-Hierarchical-Contrastive-Learning"><a href="#OmniSeg3D-Omniversal-3D-Segmentation-via-Hierarchical-Contrastive-Learning" class="headerlink" title="OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive Learning"></a>OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11666">http://arxiv.org/abs/2311.11666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Ying, Yixuan Yin, Jinzhi Zhang, Fan Wang, Tao Yu, Ruqi Huang, Lu Fang</li>
<li>for: 实现全面理解3D场景，需要一种通用的3D分割方法，可以同时分割多种对象，无论对象数量多少或类别多少，而且能够反映内在的层次结构。</li>
<li>methods: 我们提出了OmniSeg3D方法，它是一种通过层次对比学习框架将多视图不一致的2D分割映射到一致的3D特征场，以实现全面的3D分割和层次结构理解。</li>
<li>results: 我们的方法能够在高质量3D分割和准确的层次结构理解方面达到杰出的效果，并且提供了一个便捷的图形用户界面，以便用户在多种场景中进行自由交互。<details>
<summary>Abstract</summary>
Towards holistic understanding of 3D scenes, a general 3D segmentation method is needed that can segment diverse objects without restrictions on object quantity or categories, while also reflecting the inherent hierarchical structure. To achieve this, we propose OmniSeg3D, an omniversal segmentation method aims for segmenting anything in 3D all at once. The key insight is to lift multi-view inconsistent 2D segmentations into a consistent 3D feature field through a hierarchical contrastive learning framework, which is accomplished by two steps. Firstly, we design a novel hierarchical representation based on category-agnostic 2D segmentations to model the multi-level relationship among pixels. Secondly, image features rendered from the 3D feature field are clustered at different levels, which can be further drawn closer or pushed apart according to the hierarchical relationship between different levels. In tackling the challenges posed by inconsistent 2D segmentations, this framework yields a global consistent 3D feature field, which further enables hierarchical segmentation, multi-object selection, and global discretization. Extensive experiments demonstrate the effectiveness of our method on high-quality 3D segmentation and accurate hierarchical structure understanding. A graphical user interface further facilitates flexible interaction for omniversal 3D segmentation.
</details>
<details>
<summary>摘要</summary>
为了实现全面的3D场景理解，我们需要一种通用的3D分割方法，可以无Restriction地分割多种对象，同时还能够反映Scene中的自然层次结构。为此，我们提出了OmniSeg3D方法，它目标是同时分割所有3D场景中的任何对象。我们的关键发现是通过对多视图不一致的2D分割进行层次对比学习框架，将多级关系模型为像素之间的层次关系。我们首先设计了一种新的层次表示，基于类型无关的2D分割来表示多级关系。其次，我们从3D特征场景中生成的图像特征进行层次归一化，并将归一化后的特征分割成不同层次。在解决不一致2D分割的挑战时，这个框架实现了一个全局一致的3D特征场景，从而实现了层次分割、多对象选择和全球精度分割。我们的实验证明了OmniSeg3D方法的有效性，可以实现高质量的3D分割和准确的层次结构理解。此外，我们还提供了一个图形用户界面，以便用户通过价值Omniversal 3D分割。
</details></li>
</ul>
<hr>
<h2 id="PanBench-Towards-High-Resolution-and-High-Performance-Pansharpening"><a href="#PanBench-Towards-High-Resolution-and-High-Performance-Pansharpening" class="headerlink" title="PanBench: Towards High-Resolution and High-Performance Pansharpening"></a>PanBench: Towards High-Resolution and High-Performance Pansharpening</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12083">http://arxiv.org/abs/2311.12083</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiying Wang, Xuechao Zou, Kai Li, Junliang Xing, Pin Tao</li>
<li>for: 这篇论文是为了探讨远程感知领域中的笔划合成问题，即将低分辨率多spectral图像与高分辨率灰度图像集成成一个高分辨率图像，以提高远程感知数据分析中的精度。</li>
<li>methods: 这篇论文提出了一种新的笔划合成网络（CMFNet），使用了级联多尺度融合技术，以实现高精度的笔划合成。</li>
<li>results: 论文通过了广泛的实验，证明了CMFNet的效果是非常高，可以在远程感知领域中提高笔划合成的精度。<details>
<summary>Abstract</summary>
Pansharpening, a pivotal task in remote sensing, involves integrating low-resolution multispectral images with high-resolution panchromatic images to synthesize an image that is both high-resolution and retains multispectral information. These pansharpened images enhance precision in land cover classification, change detection, and environmental monitoring within remote sensing data analysis. While deep learning techniques have shown significant success in pansharpening, existing methods often face limitations in their evaluation, focusing on restricted satellite data sources, single scene types, and low-resolution images. This paper addresses this gap by introducing PanBench, a high-resolution multi-scene dataset containing all mainstream satellites and comprising 5,898 pairs of samples. Each pair includes a four-channel (RGB + near-infrared) multispectral image of 256x256 pixels and a mono-channel panchromatic image of 1,024x1,024 pixels. To achieve high-fidelity synthesis, we propose a Cascaded Multiscale Fusion Network (CMFNet) for Pansharpening. Extensive experiments validate the effectiveness of CMFNet. We have released the dataset, source code, and pre-trained models in the supplementary, fostering further research in remote sensing.
</details>
<details>
<summary>摘要</summary>
Remote sensing 中的缩进任务之一是束合低分辨率多spectral图像与高分辨率独立图像，以生成高分辨率的图像，同时保留多spectral信息。这些缩进图像可以增强远程感知数据分类、变化探测和环境监测中的精度。深度学习技术在缩进中已经表现出了显著的成功，但现有方法常面临评估限制，包括固定卫星数据源、单个场景类型和低分辨率图像。本文填补这个空白，通过介绍 PanBench 高分辨率多场景数据集，该数据集包含所有主流卫星，包括 5,898 对样本。每对样本包括一个四通道 (RGB + near-infrared) 多spectral图像，分辨率为 256x256 像素，以及一个单通道独立图像，分辨率为 1,024x1,024 像素。为实现高准确性束合，我们提议一种顺序多尺度融合网络 (CMFNet)。广泛的实验证明了 CMFNet 的有效性。我们在补充中发布了数据集、源代码和预训练模型，欢迎更多的研究人员进行远程感知领域的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Spatio-Temporal-Context-for-Temporally-Consistent-Robust-3D-Human-Motion-Recovery-from-Monocular-Videos"><a href="#Enhanced-Spatio-Temporal-Context-for-Temporally-Consistent-Robust-3D-Human-Motion-Recovery-from-Monocular-Videos" class="headerlink" title="Enhanced Spatio-Temporal Context for Temporally Consistent Robust 3D Human Motion Recovery from Monocular Videos"></a>Enhanced Spatio-Temporal Context for Temporally Consistent Robust 3D Human Motion Recovery from Monocular Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11662">http://arxiv.org/abs/2311.11662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sushovan Chanda, Amogh Tiwari, Lokender Tiwari, Brojeshwar Bhowmick, Avinash Sharma, Hrishav Barua</li>
<li>for:  Temporally consistent 3D human body pose, shape, and motion estimation from monocular videos.</li>
<li>methods: Body-aware feature representation, per-frame pose and camera initialization, spatio-temporal feature aggregation using self-similarity and self-attention, and LSTM refinement.</li>
<li>results: Significantly lower acceleration error and outperformance over existing state-of-the-art methods in complex scenarios like partial occlusion, complex poses, and low illumination.Here’s the Chinese translation:</li>
<li>for: 从单目视频中提取一致的3D人体姿态、形状和运动信息。</li>
<li>methods: 使用人体意识的特征表示、每帧姿态和摄像头初始化、基于自相似和自注意的体部特征综合、以及LSTM精度调整。</li>
<li>results: 在复杂的场景下（如部分遮挡、复杂的姿态和低照明）表现出明显低于加速误差和超越现有状态的方法。<details>
<summary>Abstract</summary>
Recovering temporally consistent 3D human body pose, shape and motion from a monocular video is a challenging task due to (self-)occlusions, poor lighting conditions, complex articulated body poses, depth ambiguity, and limited availability of annotated data. Further, doing a simple perframe estimation is insufficient as it leads to jittery and implausible results. In this paper, we propose a novel method for temporally consistent motion estimation from a monocular video. Instead of using generic ResNet-like features, our method uses a body-aware feature representation and an independent per-frame pose and camera initialization over a temporal window followed by a novel spatio-temporal feature aggregation by using a combination of self-similarity and self-attention over the body-aware features and the perframe initialization. Together, they yield enhanced spatiotemporal context for every frame by considering remaining past and future frames. These features are used to predict the pose and shape parameters of the human body model, which are further refined using an LSTM. Experimental results on the publicly available benchmark data show that our method attains significantly lower acceleration error and outperforms the existing state-of-the-art methods over all key quantitative evaluation metrics, including complex scenarios like partial occlusion, complex poses and even relatively low illumination.
</details>
<details>
<summary>摘要</summary>
recuperar la pose y el movimiento temporales consistentes del cuerpo humano en una videomonocular es un desafío debido a (auto-oclusión), condiciones de iluminación pobres, poses corporales articuladas complejas, ambigüedad de profundidad y la limitada disponibilidad de datos annotados. Además, una estimación simple por frame no es suficiente ya que lleva a resultados jittery e implausibles. En este artículo, propusimos un método novel para la estimación de la motion consistente en una videomonocular. En lugar de utilizar características genericas de ResNet, nuestro método utiliza una representación de características corporal-consciente y una inicialización de pose y cámara independiente por ventana temporal, seguida de una agregación de características espacio-temporal innovadora utilizando una combinación de self-similarity y self-attention sobre las características corporal-conscientes y la inicialización por frame. Juntos, они proporcionan un contexto espacio-temporal mejorado para cada marco considerando los marcos restantes en el pasado y el futuro. Estas características se utilizan para predecir los parámetros de pose y forma del modelo de cuerpo humano, que se refinan utilizando un LSTM. Los resultados experimentales en los datos de referencia públicos muestran que nuestro método tiene un error de aceleración significativamente menor y supera a los métodos estado-de-la-arte existentes en todas las métricas cuantitativas clave, incluyendo escenarios complejos como la ocultación parcial, poses corporales complejas y hasta una iluminación relativamente baja.
</details></li>
</ul>
<hr>
<h2 id="Double-Condensing-Attention-Condenser-Leveraging-Attention-in-Deep-Learning-to-Detect-Skin-Cancer-from-Skin-Lesion-Images"><a href="#Double-Condensing-Attention-Condenser-Leveraging-Attention-in-Deep-Learning-to-Detect-Skin-Cancer-from-Skin-Lesion-Images" class="headerlink" title="Double-Condensing Attention Condenser: Leveraging Attention in Deep Learning to Detect Skin Cancer from Skin Lesion Images"></a>Double-Condensing Attention Condenser: Leveraging Attention in Deep Learning to Detect Skin Cancer from Skin Lesion Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11656">http://arxiv.org/abs/2311.11656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chi-en Amy Tai, Elizabeth Janes, Chris Czarnecki, Alexander Wong</li>
<li>for: 这paper是为了检测皮肤癌症的皮肤变性图像而写的。</li>
<li>methods: 这paper使用了一种叫做Double-Condensing Attention Condensers（DC-AC）的自注意网络结构，以便更快速地计算。</li>
<li>results: 这paper介绍了一种特化于皮肤癌症检测的深度学习模型，其中使用了DC-AC自注意网络结构，并且公开发布了这个模型以便让科学家在抗癌战中获得更多的助手。<details>
<summary>Abstract</summary>
Skin cancer is the most common type of cancer in the United States and is estimated to affect one in five Americans. Recent advances have demonstrated strong performance on skin cancer detection, as exemplified by state of the art performance in the SIIM-ISIC Melanoma Classification Challenge; however these solutions leverage ensembles of complex deep neural architectures requiring immense storage and compute costs, and therefore may not be tractable. A recent movement for TinyML applications is integrating Double-Condensing Attention Condensers (DC-AC) into a self-attention neural network backbone architecture to allow for faster and more efficient computation. This paper explores leveraging an efficient self-attention structure to detect skin cancer in skin lesion images and introduces a deep neural network design with DC-AC customized for skin cancer detection from skin lesion images. The final model is publicly available as a part of a global open-source initiative dedicated to accelerating advancement in machine learning to aid clinicians in the fight against cancer.
</details>
<details>
<summary>摘要</summary>
美国最常见的癌症是皮肤癌，据估计每一个美国人中有一个在五个人会患癌。最新的进展表明在皮肤癌检测方面存在强大的表现，如SIIM-ISIC皮肤癌分类挑战赛的国际首席表现，但这些解决方案具有复杂的深度神经网络架构，需要巨量的存储和计算成本，因此可能不太可能。最近，对于微型机器学习（TinyML）应用而言，把双层凝聚注意力压缩（DC-AC） integrate into a self-attention neural network backbone architecture可以实现更快和高效的计算。这篇论文探讨了使用高效的自注意结构来检测皮肤癌，并提出了一种特化于皮肤癌检测的深度神经网络设计，使用DC-AC。最终模型已经公开发布，并成为全球开源的机器学习推进医生在抗癌斗争中的工具。
</details></li>
</ul>
<hr>
<h2 id="Cancer-Net-PCa-Data-An-Open-Source-Benchmark-Dataset-for-Prostate-Cancer-Clinical-Decision-Support-using-Synthetic-Correlated-Diffusion-Imaging-Data"><a href="#Cancer-Net-PCa-Data-An-Open-Source-Benchmark-Dataset-for-Prostate-Cancer-Clinical-Decision-Support-using-Synthetic-Correlated-Diffusion-Imaging-Data" class="headerlink" title="Cancer-Net PCa-Data: An Open-Source Benchmark Dataset for Prostate Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data"></a>Cancer-Net PCa-Data: An Open-Source Benchmark Dataset for Prostate Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11647">http://arxiv.org/abs/2311.11647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hayden Gunraj, Chi-en Amy Tai, Alexander Wong</li>
<li>for:  This paper is written for the purpose of introducing an open-source benchmark dataset of volumetric correlated diffusion imaging (CDI$^s$) data for prostate cancer (PCa) patients, with the goal of advancing research efforts in machine learning and imaging for PCa diagnosis and treatment.</li>
<li>methods:  The paper uses CDI$^s$ imaging data from a patient cohort of 200 cases, along with full annotations (gland masks, tumor masks, and PCa diagnosis for each tumor). The authors analyze the demographic and label region diversity of the dataset for potential biases.</li>
<li>results:  The paper introduces Cancer-Net PCa-Data, the first-ever public dataset of CDI$^s$ imaging data for PCa, which is an open-source benchmark dataset for researchers to use in developing and evaluating machine learning models for PCa diagnosis and treatment. The dataset is diverse and comprehensive, with 200 patient cases and full annotations, and has the potential to aid clinicians in the global fight against cancer.<details>
<summary>Abstract</summary>
The recent introduction of synthetic correlated diffusion (CDI$^s$) imaging has demonstrated significant potential in the realm of clinical decision support for prostate cancer (PCa). CDI$^s$ is a new form of magnetic resonance imaging (MRI) designed to characterize tissue characteristics through the joint correlation of diffusion signal attenuation across different Brownian motion sensitivities. Despite the performance improvement, the CDI$^s$ data for PCa has not been previously made publicly available. In our commitment to advance research efforts for PCa, we introduce Cancer-Net PCa-Data, an open-source benchmark dataset of volumetric CDI$^s$ imaging data of PCa patients. Cancer-Net PCa-Data consists of CDI$^s$ volumetric images from a patient cohort of 200 patient cases, along with full annotations (gland masks, tumor masks, and PCa diagnosis for each tumor). We also analyze the demographic and label region diversity of Cancer-Net PCa-Data for potential biases. Cancer-Net PCa-Data is the first-ever public dataset of CDI$^s$ imaging data for PCa, and is a part of the global open-source initiative dedicated to advancement in machine learning and imaging research to aid clinicians in the global fight against cancer.
</details>
<details>
<summary>摘要</summary>
Recent introduction of synthetic correlated diffusion (CDI$^s$) imaging has shown significant potential in clinical decision support for prostate cancer (PCa). CDI$^s$ is a new form of magnetic resonance imaging (MRI) that characterizes tissue characteristics through joint correlation of diffusion signal attenuation across different Brownian motion sensitivities. Although CDI$^s$ data for PCa has not been publicly available before, we are committed to advancing research efforts for PCa and introduce Cancer-Net PCa-Data, an open-source benchmark dataset of volumetric CDI$^s$ imaging data for PCa patients. Cancer-Net PCa-Data includes CDI$^s$ volumetric images from a patient cohort of 200 cases, along with full annotations (gland masks, tumor masks, and PCa diagnosis for each tumor). We also analyze the demographic and label region diversity of Cancer-Net PCa-Data for potential biases. Cancer-Net PCa-Data is the first public dataset of CDI$^s$ imaging data for PCa and is part of the global open-source initiative dedicated to advancing machine learning and imaging research to aid clinicians in the global fight against cancer.
</details></li>
</ul>
<hr>
<h2 id="CastDet-Toward-Open-Vocabulary-Aerial-Object-Detection-with-CLIP-Activated-Student-Teacher-Learning"><a href="#CastDet-Toward-Open-Vocabulary-Aerial-Object-Detection-with-CLIP-Activated-Student-Teacher-Learning" class="headerlink" title="CastDet: Toward Open Vocabulary Aerial Object Detection with CLIP-Activated Student-Teacher Learning"></a>CastDet: Toward Open Vocabulary Aerial Object Detection with CLIP-Activated Student-Teacher Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11646">http://arxiv.org/abs/2311.11646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Li, Weiwei Guo, Dunyun He, Jiaqi Zhou, Yuze Gao, Wenxian Yu<br>for:This paper focuses on open-vocabulary object detection (OVD) in aerial images, which enables the characterization of new objects beyond training categories on the earth surface without annotating training images for these new categories.methods:The proposed CastDet framework is an end-to-end student-teacher open-vocabulary object detection framework that leverages the CLIP model as an extra omniscient teacher of rich knowledge into the student-teacher self-learning process. The framework also employs a dynamic label queue technique to maintain high-quality pseudo labels during batch training and mitigate label imbalance.results:The proposed CastDet achieves superior open-vocabulary detection performance, with an HM (Harmonic Mean) of 40.0, outperforming previous methods Detic&#x2F;ViLD by 26.9&#x2F;21.1 on the VisDroneZSD dataset.<details>
<summary>Abstract</summary>
Object detection in aerial images is a pivotal task for various earth observation applications, whereas current algorithms learn to detect only a pre-defined set of object categories demanding sufficient bounding-box annotated training samples and fail to detect novel object categories. In this paper, we consider open-vocabulary object detection (OVD) in aerial images that enables the characterization of new objects beyond training categories on the earth surface without annotating training images for these new categories. The performance of OVD depends on the quality of class-agnostic region proposals and pseudo-labels that can generalize well to novel object categories. To simultaneously generate high-quality proposals and pseudo-labels, we propose CastDet, a CLIP-activated student-teacher open-vocabulary object Detection framework. Our end-to-end framework within the student-teacher mechanism employs the CLIP model as an extra omniscient teacher of rich knowledge into the student-teacher self-learning process. By doing so, our approach boosts novel object proposals and classification. Furthermore, we design a dynamic label queue technique to maintain high-quality pseudo labels during batch training and mitigate label imbalance. We conduct extensive experiments on multiple existing aerial object detection datasets, which are set up for the OVD task. Experimental results demonstrate our CastDet achieving superior open-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean), which outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于地球观测应用，空中图像中的对象检测是一项重要任务，而当前算法只能学习预定的对象类别，需要充足的 bounding-box 注释样本，无法检测新的对象类别。在这篇论文中，我们考虑了开放词汇对象检测（OVD）在空中图像中，可以在地球表面上无需注释训练样本中检测新的对象类别。OVD 的性能取决于高质量的类型不敏感区域提案和 Pseudo-label，这些可以很好地泛化到新的对象类别。为了同时生成高质量的提案和 Pseudo-label，我们提出了 CastDet，一个基于 CLIP 的学生教师开放词汇对象检测框架。我们的端到端框架在学生教师机制中使用 CLIP 模型作为额外的宏观知识的教师，从而提高新对象提案和分类。此外，我们设计了动态标签队列技术，以保持批处理训练期间高质量的 Pseudo-label。我们对多个现有的空中对象检测数据集进行了广泛的实验，并证明我们的 CastDet 在开放词汇对象检测任务中表现出色，例如在 VisDroneZSD 数据集上达到 40.0 HM（和律mean），比前方法 Detic/ViLD 提高 26.9/21.1。Note: "HM" stands for "Harmonic Mean", which is a measure of the performance of object detection algorithms.
</details></li>
</ul>
<hr>
<h2 id="Video-Face-Re-Aging-Toward-Temporally-Consistent-Face-Re-Aging"><a href="#Video-Face-Re-Aging-Toward-Temporally-Consistent-Face-Re-Aging" class="headerlink" title="Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging"></a>Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11642">http://arxiv.org/abs/2311.11642</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyugorithm/VFRAN">https://github.com/kyugorithm/VFRAN</a></li>
<li>paper_authors: Abdul Muqeet, Kyuchul Lee, Bumsoo Kim, Yohan Hong, Hyungrae Lee, Woonggon Kim, Kwang Hee Lee</li>
<li>for: 修改视频中人脸年龄，以达到目标年龄</li>
<li>methods: 提出了一种新的人脸视频重新年龄化方法，包括一种新的人脸数据集和一种基eline架构，以及三种专门为视频重新年龄化测试的度量</li>
<li>results: 对公共数据集进行了广泛的实验，并 показа出方法在年龄变化和时间一致性方面的优于现有方法<details>
<summary>Abstract</summary>
Video face re-aging deals with altering the apparent age of a person to the target age in videos. This problem is challenging due to the lack of paired video datasets maintaining temporal consistency in identity and age. Most re-aging methods process each image individually without considering the temporal consistency of videos. While some existing works address the issue of temporal coherence through video facial attribute manipulation in latent space, they often fail to deliver satisfactory performance in age transformation. To tackle the issues, we propose (1) a novel synthetic video dataset that features subjects across a diverse range of age groups; (2) a baseline architecture designed to validate the effectiveness of our proposed dataset, and (3) the development of three novel metrics tailored explicitly for evaluating the temporal consistency of video re-aging techniques. Our comprehensive experiments on public datasets, such as VFHQ and CelebV-HQ, show that our method outperforms the existing approaches in terms of both age transformation and temporal consistency.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Video face re-aging 征�到将人体表现出target age的年龄，这个问题具有挑战性，因为缺乏具有时间一致性的人脸视频对应数据集。大多数现有方法不考虑视频的时间一致性，对每帧图像进行处理。有些现有方法通过在幽默空间进行视频人脸特征修饰来解决问题，但它们经常无法提供满意的年龄转换表现。为了解决这些问题，我们提议：1. 一个新的人造视频数据集，包含不同年龄群体的人体；2. 一个基线架构，用于验证我们的提议数据集的效果；3. 三个专门为视频重新年龄评价的新指标。我们对公共数据集，如VFHQ和CelebV-HQ进行了全面的实验，结果显示，我们的方法在年龄转换和时间一致性两个方面都超过了现有方法。Translation notes:* 征�到 (chèng zhì da) means "to achieve" or "to reach" in Chinese.* 人体 (rén tǐ) means "person" in Chinese.* 表现 (biǎo xiǎng) means "to show" or "to exhibit" in Chinese.* 年龄 (nián jì) means "age" in Chinese.* 时间 (shí jian) means "time" in Chinese.* 一致性 (yī chéng xìng) means "consistency" or "coherence" in Chinese.* 幽默 (yōu mó) means "latent" or "hidden" in Chinese.* 特征 (tè shē) means "feature" or "characteristic" in Chinese.* 修饰 (xiū shī) means "to modify" or "to alter" in Chinese.* 满意 (mǎn yì) means "satisfactory" or "pleasing" in Chinese.* 评价 (píng jì) means "evaluation" or "assessment" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Reti-Diff-Illumination-Degradation-Image-Restoration-with-Retinex-based-Latent-Diffusion-Model"><a href="#Reti-Diff-Illumination-Degradation-Image-Restoration-with-Retinex-based-Latent-Diffusion-Model" class="headerlink" title="Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model"></a>Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11638">http://arxiv.org/abs/2311.11638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chunminghe/reti-diff">https://github.com/chunminghe/reti-diff</a></li>
<li>paper_authors: Chunming He, Chengyu Fang, Yulun Zhang, Kai Li, Longxiang Tang, Chenyu You, Fengyang Xiao, Zhenhua Guo, Xiu Li</li>
<li>For: 提高降低图像质量的阈值环境照明照片的可见性和稳定性。* Methods: 利用扩散模型（DM）在紧凑的幽默空间中生成简洁导向假设，并 introduce a novel solution called Reti-Diff for the IDIR task, which includes two key components: Retinex-based latent DM (RLDM) and Retinex-guided transformer (RGformer).* Results: 比较 existing methods 在三个 IDIR 任务上表现出色，以及下游应用程序中的表现。<details>
<summary>Abstract</summary>
Illumination degradation image restoration (IDIR) techniques aim to improve the visibility of degraded images and mitigate the adverse effects of deteriorated illumination. Among these algorithms, diffusion model (DM)-based methods have shown promising performance but are often burdened by heavy computational demands and pixel misalignment issues when predicting the image-level distribution. To tackle these problems, we propose to leverage DM within a compact latent space to generate concise guidance priors and introduce a novel solution called Reti-Diff for the IDIR task. Reti-Diff comprises two key components: the Retinex-based latent DM (RLDM) and the Retinex-guided transformer (RGformer). To ensure detailed reconstruction and illumination correction, RLDM is empowered to acquire Retinex knowledge and extract reflectance and illumination priors. These priors are subsequently utilized by RGformer to guide the decomposition of image features into their respective reflectance and illumination components. Following this, RGformer further enhances and consolidates the decomposed features, resulting in the production of refined images with consistent content and robustness to handle complex degradation scenarios. Extensive experiments show that Reti-Diff outperforms existing methods on three IDIR tasks, as well as downstream applications. Code will be available at \url{https://github.com/ChunmingHe/Reti-Diff}.
</details>
<details>
<summary>摘要</summary>
ILLUMINATION DEGRADATION IMAGE RESTORATION（IDIR）技术目的是提高受损图像的可见度和减轻照明衰减的不良影响。其中的扩散模型（DM）基本方法具有良好的表现，但它们常受到重复计算和像素不对齐问题的困扰，尤其是在预测图像级别分布时。为解决这些问题，我们提议利用DM在紧凑的尺度空间内运行，生成简洁的指导假设。这种方法被称为Reti-Diff。Reti-Diff包括两个关键组件：Retinex基于的秘密DM（RLDM）和Retinex引导的变换器（RGformer）。为确保细节重建和照明更正，RLDM被赋予Retinex知识，从而提取反射和照明假设。这些假设后来被RGformer使用，以导引图像特征的分解为其各自的反射和照明组件。接下来，RGformer进一步加强和卷积这些分解的特征，从而生成了更加细腻和稳定的图像，可以满足复杂的受损enario。实验表明，Reti-Diff在三个IDIR任务上的表现都高于现有方法，同时在下游应用中也达到了更好的效果。代码将在 \url{https://github.com/ChunmingHe/Reti-Diff} 上提供。
</details></li>
</ul>
<hr>
<h2 id="Generating-Realistic-Counterfactuals-for-Retinal-Fundus-and-OCT-Images-using-Diffusion-Models"><a href="#Generating-Realistic-Counterfactuals-for-Retinal-Fundus-and-OCT-Images-using-Diffusion-Models" class="headerlink" title="Generating Realistic Counterfactuals for Retinal Fundus and OCT Images using Diffusion Models"></a>Generating Realistic Counterfactuals for Retinal Fundus and OCT Images using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11629">http://arxiv.org/abs/2311.11629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indu Ilanchezian, Valentyn Boreiko, Laura Kühlewein, Ziwei Huang, Murat Seçkin Ayhan, Matthias Hein, Lisa Koch, Philipp Berens</li>
<li>for: 用于解释临床决策或评估alternatives</li>
<li>methods: 使用一种扩散模型和一种对抗性鲁棒分类器，生成高度真实的对比图像和OCT B-scan</li>
<li>results: 用户研究发现，使用我们的方法生成的对比图像比之前的方法生成的更真实，甚至与真实图像难以分辨<details>
<summary>Abstract</summary>
Counterfactual reasoning is often used in a clinical setting to explain decisions or weigh alternatives. Therefore, for imaging based modalities such as ophthalmology, it would be beneficial to be able to create counterfactual images, illustrating the answer to the question: "If the subject had had diabetic retinopathy, how would the fundus image have looked?" Here, we demonstrate that using a diffusion model in combination with an adversarially robust classifier trained on retinal disease classification tasks enables generation of highly realistic counterfactuals of retinal fundus images and optical coherence tomorgraphy (OCT) B-scans. Ideally, these classifiers encode the salient features indicative for each disease class and can steer the diffusion model to show realistic disease signs or remove disease-related lesions in a realistic way. Importantly, in a user study, domain experts found the counterfactuals generated using our method significantly more realistic than counterfactuals generated from a previous method, and even indistiguishable from realistic images.
</details>
<details>
<summary>摘要</summary>
ounterfactual 理智 often 用于 clinical  setting  to explain decisions 或 weigh alternatives. Therefore, for imaging based modalities such as ophthalmology, it would be beneficial to be able to create counterfactual images, illustrating the answer to the question: "If the subject had had diabetic retinopathy, how would the fundus image have looked?" Here, we demonstrate that using a diffusion model in combination with an adversarially robust classifier trained on retinal disease classification tasks enables generation of highly realistic counterfactuals of retinal fundus images and optical coherence tomography (OCT) B-scans. Ideally, these classifiers encode the salient features indicative for each disease class and can steer the diffusion model to show realistic disease signs or remove disease-related lesions in a realistic way. Importantly, in a user study, domain experts found the counterfactuals generated using our method significantly more realistic than counterfactuals generated from a previous method, and even indistinguishable from realistic images.Note that Simplified Chinese is used here, as it is the more widely used standard for Chinese writing in mainland China. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="Semantic-Preserved-Point-based-Human-Avatar"><a href="#Semantic-Preserved-Point-based-Human-Avatar" class="headerlink" title="Semantic-Preserved Point-based Human Avatar"></a>Semantic-Preserved Point-based Human Avatar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11614">http://arxiv.org/abs/2311.11614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixiang Lin, Jianke Zhu</li>
<li>for: 提高 AR&#x2F;VR 和数字娱乐领域中人类模拟体验的现实感，该论文首次提出了一种点基式人类模板，涵盖了数字人类表达范围的全部。</li>
<li>methods: 该模型使用两个多层感知（MLP）来模型 pose-dependent deformation 和直线皮剂（LBS）的 weights。人体外观表示采用解码器和每个点附加的特征。与其他 alternatives 的隐式方法不同，点方向表示方式不仅提供了更直观的人类模板动画模型方法，还能够显著降低训练和推理时间。</li>
<li>results: 该方法的实验结果表明其有效性。<details>
<summary>Abstract</summary>
To enable realistic experience in AR/VR and digital entertainment, we present the first point-based human avatar model that embodies the entirety expressive range of digital humans. We employ two MLPs to model pose-dependent deformation and linear skinning (LBS) weights. The representation of appearance relies on a decoder and the features that attached to each point. In contrast to alternative implicit approaches, the oriented points representation not only provides a more intuitive way to model human avatar animation but also significantly reduces both training and inference time. Moreover, we propose a novel method to transfer semantic information from the SMPL-X model to the points, which enables to better understand human body movements. By leveraging the semantic information of points, we can facilitate virtual try-on and human avatar composition through exchanging the points of same category across different subjects. Experimental results demonstrate the efficacy of our presented method.
</details>
<details>
<summary>摘要</summary>
为提供真实的AR/VR和数字娱乐体验，我们介绍了首个点基的人类化模型，涵盖了整个数字人类表达范围。我们使用两个多层感知（MLP）来模型 pose-dependent deformation和直线皮床（LBS）weights。人物外表表示 rely on decoder 和每个点附加的特征。与替代的隐式方法不同，点云表示不仅提供了更直观的人物动画模型化方法，还可以显著减少训练和推断时间。此外，我们提出了一种将SMPL-X模型中的 semantics 信息传递到点上的新方法，使得更好地理解人体动作。通过利用点上的semantic信息，我们可以实现虚拟试穿和人物组合 durch exchange 点的同类Category 的不同主体。实验结果表明我们提出的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="CurriculumLoc-Enhancing-Cross-Domain-Geolocalization-through-Multi-Stage-Refinement"><a href="#CurriculumLoc-Enhancing-Cross-Domain-Geolocalization-through-Multi-Stage-Refinement" class="headerlink" title="CurriculumLoc: Enhancing Cross-Domain Geolocalization through Multi-Stage Refinement"></a>CurriculumLoc: Enhancing Cross-Domain Geolocalization through Multi-Stage Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11604">http://arxiv.org/abs/2311.11604</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/npupilab/curriculumloc">https://github.com/npupilab/curriculumloc</a></li>
<li>paper_authors: Boni Hu, Lin Chen, Runjian Chen, Shuhui Bu, Pengcheng Han, Haowei Li</li>
<li>for: 这篇论文旨在提出一个可靠且可扩展的可视地对照对应方法，以实现实际的可视地对照 зада务。</li>
<li>methods: 这篇论文使用了一个精心设计的多阶段精度提高管线，以及一种全球 semantic 意识和本地几何验证的关键点检测和描述方法。</li>
<li>results: 实验结果显示，这篇论文的方法可以实现高精度的可视地对照，并且在两个不同的距离度量上创下新的高 recall@1 纪录值。<details>
<summary>Abstract</summary>
Visual geolocalization is a cost-effective and scalable task that involves matching one or more query images, taken at some unknown location, to a set of geo-tagged reference images. Existing methods, devoted to semantic features representation, evolving towards robustness to a wide variety between query and reference, including illumination and viewpoint changes, as well as scale and seasonal variations. However, practical visual geolocalization approaches need to be robust in appearance changing and extreme viewpoint variation conditions, while providing accurate global location estimates. Therefore, inspired by curriculum design, human learn general knowledge first and then delve into professional expertise. We first recognize semantic scene and then measure geometric structure. Our approach, termed CurriculumLoc, involves a delicate design of multi-stage refinement pipeline and a novel keypoint detection and description with global semantic awareness and local geometric verification. We rerank candidates and solve a particular cross-domain perspective-n-point (PnP) problem based on these keypoints and corresponding descriptors, position refinement occurs incrementally. The extensive experimental results on our collected dataset, TerraTrack and a benchmark dataset, ALTO, demonstrate that our approach results in the aforementioned desirable characteristics of a practical visual geolocalization solution. Additionally, we achieve new high recall@1 scores of 62.6% and 94.5% on ALTO, with two different distances metrics, respectively. Dataset, code and trained models are publicly available on https://github.com/npupilab/CurriculumLoc.
</details>
<details>
<summary>摘要</summary>
Visual地理位置定位是一项经济可行和可扩展的任务，即将一组或多组查询图像，取自未知位置，与一组准备了地理标记的参考图像进行匹配。现有方法主要关注semantic特征表示，逐渐向多样化 между查询和参考图像的鲁棒性进化，包括照明和视角变化、比例和季节变化。然而，实际 visual地理位置定位应用需要对应变化和极端视角变化的鲁棒性，同时提供准确的全球位置估计。因此，我们受到curriculum设计的 inspirited，人类在学习通用知识后，才能专注于专业专长。我们首先识别semantic场景，然后测量几何结构。我们的方法，称之为CurriculumLoc，包括细致的多Stage刷新管道和一种新型的关键点检测和描述，具有全球semantic认知和本地几何验证。我们在这些关键点和对应描述符基础上进行重新排名，并解决一个特定的 across-domain perspective-n-point（PnP）问题，在这个过程中，位置精度进行逐渐调整。我们的实验结果表明，我们的方法具有上述实际 visual地理位置定位应用中需要的愉悦特性。此外，我们在ALTO标准 dataset上取得了新的高 recall@1 分数为62.6%和94.5%，分别使用两种距离度量。数据集、代码和训练模型都可以在https://github.com/npupilab/CurriculumLoc上获得。
</details></li>
</ul>
<hr>
<h2 id="Deep-Equilibrium-Diffusion-Restoration-with-Parallel-Sampling"><a href="#Deep-Equilibrium-Diffusion-Restoration-with-Parallel-Sampling" class="headerlink" title="Deep Equilibrium Diffusion Restoration with Parallel Sampling"></a>Deep Equilibrium Diffusion Restoration with Parallel Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11600">http://arxiv.org/abs/2311.11600</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caojiezhang/deqir">https://github.com/caojiezhang/deqir</a></li>
<li>paper_authors: Jiezhang Cao, Yue Shi, Kai Zhang, Yulun Zhang, Radu Timofte, Luc Van Gool</li>
<li>for: 这 paper 的目的是重新思考基于扩散模型的图像修复方法，通过改进 sampling 链来减少计算成本并且提高图像修复质量。</li>
<li>methods: 这 paper 使用了 deep equilibrium 固定点系统来解决 diffusion-based IR 模型中的问题，并提出了一种基于 analytical solution 的单个图像 sampling 方法，以便在平行化的方式下进行图像修复。</li>
<li>results: 实验结果表明，这 paper 提出的方法可以在典型的 IR 任务和实际应用中达到高质量的图像修复，并且可以快速计算梯度和初始化优化。<details>
<summary>Abstract</summary>
Diffusion-based image restoration (IR) methods aim to use diffusion models to recover high-quality (HQ) images from degraded images and achieve promising performance. Due to the inherent property of diffusion models, most of these methods need long serial sampling chains to restore HQ images step-by-step. As a result, it leads to expensive sampling time and high computation costs. Moreover, such long sampling chains hinder understanding the relationship between the restoration results and the inputs since it is hard to compute the gradients in the whole chains. In this work, we aim to rethink the diffusion-based IR models through a different perspective, i.e., a deep equilibrium (DEQ) fixed point system. Specifically, we derive an analytical solution by modeling the entire sampling chain in diffusion-based IR models as a joint multivariate fixed point system. With the help of the analytical solution, we are able to conduct single-image sampling in a parallel way and restore HQ images without training. Furthermore, we compute fast gradients in DEQ and found that initialization optimization can boost performance and control the generation direction. Extensive experiments on benchmarks demonstrate the effectiveness of our proposed method on typical IR tasks and real-world settings. The code and models will be made publicly available.
</details>
<details>
<summary>摘要</summary>
Diffusion-based image restoration（IR）方法目标是使用扩散模型来恢复高质量（HQ）图像从降低图像中，并达到了可以的表现。由于扩散模型的内在性质，大多数这些方法需要长串行样本链来恢复HQ图像步骤。这会导致样本时间昂贵和计算成本高。此外，这些长串行样本链使得理解恢复结果和输入之间的关系困难，因为计算整个链上的梯度很难。在这种工作中，我们想要重新思考扩散基于IR模型的方法，即深度平衡（DEQ）固定点系统。我们特别是使用扩散模型整个样本链的联合多变量固定点系统来 derivate一个分析解。通过分析解，我们可以在平行样本中进行单图像恢复，并不需要训练。此外，我们在DEQ中计算了快速的梯度，并发现初始化优化可以提高性能并控制生成方向。我们对典型的IR任务和实际场景进行了广泛的实验，并证明了我们的提出的方法的有效性。代码和模型将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Predicting-urban-tree-cover-from-incomplete-point-labels-and-limited-background-information"><a href="#Predicting-urban-tree-cover-from-incomplete-point-labels-and-limited-background-information" class="headerlink" title="Predicting urban tree cover from incomplete point labels and limited background information"></a>Predicting urban tree cover from incomplete point labels and limited background information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11592">http://arxiv.org/abs/2311.11592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Ankit Kariryaa, Venkanna Babu Guthula, Christian Igel, Stefan Oehmcke</li>
<li>for: 这 paper 是为了提高城市树木的识别和映射，以便更好地了解城市微气候和城市居民的物理和心理健康。</li>
<li>methods: 该 paper 使用深度学习方法来映射城市树木在高分辨率飞行图像中，使用有限的数据集和深度学习来实现。</li>
<li>results: 该 paper 在 Hamburg, Germany 进行了实验，显示系统可以生成城市树木覆盖率图像，不需要提供树木分割。系统的性能会逐渐下降，如果不使用开源地理数据库。<details>
<summary>Abstract</summary>
Trees inside cities are important for the urban microclimate, contributing positively to the physical and mental health of the urban dwellers. Despite their importance, often only limited information about city trees is available. Therefore in this paper, we propose a method for mapping urban trees in high-resolution aerial imagery using limited datasets and deep learning. Deep learning has become best-practice for this task, however, existing approaches rely on large and accurately labelled training datasets, which can be difficult and expensive to obtain. However, often noisy and incomplete data may be available that can be combined and utilized to solve more difficult tasks than those datasets were intended for. This paper studies how to combine accurate point labels of urban trees along streets with crowd-sourced annotations from an open geographic database to delineate city trees in remote sensing images, a task which is challenging even for humans. To that end, we perform semantic segmentation of very high resolution aerial imagery using a fully convolutional neural network. The main challenge is that our segmentation maps are sparsely annotated and incomplete. Small areas around the point labels of the street trees coming from official and crowd-sourced data are marked as foreground class. Crowd-sourced annotations of streets, buildings, etc. define the background class. Since the tree data is incomplete, we introduce a masking to avoid class confusion. Our experiments in Hamburg, Germany, showed that the system is able to produce tree cover maps, not limited to trees along streets, without providing tree delineations. We evaluated the method on manually labelled trees and show that performance drastically deteriorates if the open geographic database is not used.
</details>
<details>
<summary>摘要</summary>
urban 内部的树木对城市微气候有积极影响，为城市居民的物理和心理健康做出正面贡献。然而，有限的城市树木信息 frequently 不足，因此在这篇论文中，我们提出了一种使用有限数据集和深度学习方法来映射城市树木在高分辨率飞行图像中的方法。深度学习已成为最佳实践，但现有的方法通常需要大量、准确地标注数据，这可能是 expensive 和困难的。然而，可能存在噪声和不完整的数据，这些数据可以组合并利用来解决更加复杂的任务。本文研究了如何将精确的城市树木点标签与开源地理数据库中的人工标注结合使用，以在遥感图像中划分城市树木，这是人类也难以完成的任务。为此，我们使用了全 convolutional neural network 进行semantic segmentation 的高分辨率飞行图像。主要挑战在于我们的分类图像 sparse 和不完整。小区域附近街道树木的点标签来自官方和开源数据库，被定义为前景类。人工标注的街道、建筑等定义背景类。由于树木数据不完整，我们引入了masking来避免分类混淆。我们在 Hamburg, Germany 进行了实验，发现系统可以生成不限于街道上的树木覆盖率图像，而不需提供树木划分。我们对手动标注的树木进行了评估，并发现如果不使用开源地理数据库，系统性能会下降很快。
</details></li>
</ul>
<hr>
<h2 id="FreeKD-Knowledge-Distillation-via-Semantic-Frequency-Prompt"><a href="#FreeKD-Knowledge-Distillation-via-Semantic-Frequency-Prompt" class="headerlink" title="FreeKD: Knowledge Distillation via Semantic Frequency Prompt"></a>FreeKD: Knowledge Distillation via Semantic Frequency Prompt</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12079">http://arxiv.org/abs/2311.12079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Zhang, Tao Huang, Jiaming Liu, Tao Jiang, Kuan Cheng, Shanghang Zhang</li>
<li>for: 该论文主要针对卷积批处理任务（ dense prediction tasks）中的知识填充（knowledge distillation）问题，旨在提高学生模型的性能。</li>
<li>methods: 该论文提出了一种基于频谱频谱（frequency domain）的知识填充方法，称为“FreeKD”，它通过在教师模型中插入频谱推荐（Frequency Prompt）来吸收频谱上的 semantic context，并通过Pixel-wise频谱面（pixel-wise frequency mask）来定位关键的像素点。</li>
<li>results: 该论文的实验结果表明，FreeKD方法可以在 dense prediction tasks 中提高学生模型的性能，并且比传统的空间基于的知识填充方法（spatial-based distillation methods）更加稳定和robust。<details>
<summary>Abstract</summary>
Knowledge distillation (KD) has been applied to various tasks successfully, and mainstream methods typically boost the student model via spatial imitation losses. However, the consecutive downsamplings induced in the spatial domain of teacher model is a type of corruption, hindering the student from analyzing what specific information needs to be imitated, which results in accuracy degradation. To better understand the underlying pattern of corrupted feature maps, we shift our attention to the frequency domain. During frequency distillation, we encounter a new challenge: the low-frequency bands convey general but minimal context, while the high are more informative but also introduce noise. Not each pixel within the frequency bands contributes equally to the performance. To address the above problem: (1) We propose the Frequency Prompt plugged into the teacher model, absorbing the semantic frequency context during finetuning. (2) During the distillation period, a pixel-wise frequency mask is generated via Frequency Prompt, to localize those pixel of interests (PoIs) in various frequency bands. Additionally, we employ a position-aware relational frequency loss for dense prediction tasks, delivering a high-order spatial enhancement to the student model. We dub our Frequency Knowledge Distillation method as FreeKD, which determines the optimal localization and extent for the frequency distillation. Extensive experiments demonstrate that FreeKD not only outperforms spatial-based distillation methods consistently on dense prediction tasks (e.g., FreeKD brings 3.8 AP gains for RepPoints-R50 on COCO2017 and 4.55 mIoU gains for PSPNet-R18 on Cityscapes), but also conveys more robustness to the student. Notably, we also validate the generalization of our approach on large-scale vision models (e.g., DINO and SAM).
</details>
<details>
<summary>摘要</summary>
知识塑化（KD）已经成功应用于多种任务，主流方法通常通过空间模仿损失提高学生模型。然而，在教师模型中的连续下采样induced的空间频谱损害是一种损害，使学生无法分析需要被模仿的具体信息，从而导致精度下降。为了更好地理解下频谱损害的下游特征，我们将注意力集中在频谱频率上。在频谱塑化过程中，我们遇到了一个新的挑战：低频带 convey通用但是有限的信息，而高频带更加有用但也会引入噪音。不是每个像素在频谱带中都有相同的贡献。为了解决以上问题，我们提出了频谱提醒（Frequency Prompt），在教师模型中捕捉频谱语义上下文的 semantic frequency context  durante el finetuning。在塑化期间，我们通过频谱提醒生成了一个像素级别的频谱面积掩码，以确定在不同频谱带中的关键像素（PoIs）。此外，我们采用了一种位置感知的相关频谱损失，为精密预测任务提供高阶空间提高。我们称之为FreeKD，它确定了塑化的优化本地化和范围。广泛的实验表明，FreeKD不仅在精密预测任务上（例如，FreeKD在COCO2017上提高了RepPoints-R50的AP值3.8，在Cityscapes上提高了PSPNet-R18的mIoU值4.55），而且传递了更加Robustness到学生。另外，我们还验证了我们的方法在大规模视觉模型（例如，DINO和SAM）上的普适性。
</details></li>
</ul>
<hr>
<h2 id="AKConv-Convolutional-Kernel-with-Arbitrary-Sampled-Shapes-and-Arbitrary-Number-of-Parameters"><a href="#AKConv-Convolutional-Kernel-with-Arbitrary-Sampled-Shapes-and-Arbitrary-Number-of-Parameters" class="headerlink" title="AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary Number of Parameters"></a>AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary Number of Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11587">http://arxiv.org/abs/2311.11587</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cv-zhangxin/akconv">https://github.com/cv-zhangxin/akconv</a></li>
<li>paper_authors: Xin Zhang, Yingze Song, Tingting Song, Degang Yang, Yichen Ye, Jie Zhou, Liming Zhang</li>
<li>for: 这 paper 是为了解决标准 convolutional operation 中的两个缺陷而提出的，即 local window 的限制和固定的 convolutional kernel 大小。</li>
<li>methods: 这 paper 提出了 Alterable Kernel Convolution (AKConv)，一种可变参数和样式的 convolutional operation，通过新的坐标生成算法定义初始位置，并通过偏移来适应目标变化。</li>
<li>results: 对于 COCO2017、VOC 7+12 和 VisDrone-DET2021 等 dataset，AKConv 能够提高 объек 检测性能，并且可以作为替换 convolutional operation 来提高网络性能。<details>
<summary>Abstract</summary>
Neural networks based on convolutional operations have achieved remarkable results in the field of deep learning, but there are two inherent flaws in standard convolutional operations. On the one hand, the convolution operation be confined to a local window and cannot capture information from other locations, and its sampled shapes is fixed. On the other hand, the size of the convolutional kernel is fixed to k $\times$ k, which is a fixed square shape, and the number of parameters tends to grow squarely with size. It is obvious that the shape and size of targets are various in different datasets and at different locations. Convolutional kernels with fixed sample shapes and squares do not adapt well to changing targets. In response to the above questions, the Alterable Kernel Convolution (AKConv) is explored in this work, which gives the convolution kernel an arbitrary number of parameters and arbitrary sampled shapes to provide richer options for the trade-off between network overhead and performance. In AKConv, we define initial positions for convolutional kernels of arbitrary size by means of a new coordinate generation algorithm. To adapt to changes for targets, we introduce offsets to adjust the shape of the samples at each position. Moreover, we explore the effect of the neural network by using the AKConv with the same size and different initial sampled shapes. AKConv completes the process of efficient feature extraction by irregular convolutional operations and brings more exploration options for convolutional sampling shapes. Object detection experiments on representative datasets COCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of AKConv. AKConv can be used as a plug-and-play convolutional operation to replace convolutional operations to improve network performance. The code for the relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv.
</details>
<details>
<summary>摘要</summary>
神经网络基于卷积操作已经在深度学习中取得了惊人的成果，但标准卷积操作存在两个内在的缺陷。一方面，卷积操作只能在本地窗口中进行，无法捕捉其他位置的信息，而且采样形状是固定的。另一方面，卷积核心的大小是固定的，即k x k，这是一个固定的方正形状，而参数的数量呈平方增长。这是不合理的，因为目标的形状和位置在不同的数据集和位置上是多样的。标准卷积核心的固定采样形状和大小不能适应变化的目标。为了解决这些问题，本文提出了可变卷积（AKConv），它允许卷积核心有可变的参数数量和采样形状，以提供更多的质量和性能之间的质量。在AKConv中，我们使用新的坐标生成算法来定义卷积核心的初始位置。为了适应目标的变化，我们引入偏移量来调整采样形状。此外，我们还研究了使用AKConv的效果，包括使用相同大小的AKConv和不同初始采样形状。AKConv完tes了不规则卷积操作的效果，并提供了更多的卷积采样形状的exploration option。在COCO2017、VOC 7+12和VisDrone-DET2021等代表性数据集上，对象检测实验全面展示了AKConv的优势。AKConv可以作为替换标准卷积操作的卷积操作来提高网络性能。相关任务的代码可以在https://github.com/CV-ZhangXin/AKConv中找到。
</details></li>
</ul>
<hr>
<h2 id="SeaDSC-A-video-based-unsupervised-method-for-dynamic-scene-change-detection-in-unmanned-surface-vehicles"><a href="#SeaDSC-A-video-based-unsupervised-method-for-dynamic-scene-change-detection-in-unmanned-surface-vehicles" class="headerlink" title="SeaDSC: A video-based unsupervised method for dynamic scene change detection in unmanned surface vehicles"></a>SeaDSC: A video-based unsupervised method for dynamic scene change detection in unmanned surface vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11580">http://arxiv.org/abs/2311.11580</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linh Trinh, Ali Anwar, Siegfried Mercelis</li>
<li>For: This paper is focused on detecting dynamic scene changes in Unmanned Surface Vehicles (USVs) using video data.* Methods: The proposed method utilizes a modified VQ-VAE-2 generative picture model for feature extraction and a novel similarity scoring technique for comparing consecutive frames.* Results: The authors demonstrate the efficiency of their technique on a nautical video dataset called RoboWhaler, showing the effectiveness of their approach in detecting dynamic scene changes.<details>
<summary>Abstract</summary>
Recently, there has been an upsurge in the research on maritime vision, where a lot of works are influenced by the application of computer vision for Unmanned Surface Vehicles (USVs). Various sensor modalities such as camera, radar, and lidar have been used to perform tasks such as object detection, segmentation, object tracking, and motion planning. A large subset of this research is focused on the video analysis, since most of the current vessel fleets contain the camera's onboard for various surveillance tasks. Due to the vast abundance of the video data, video scene change detection is an initial and crucial stage for scene understanding of USVs. This paper outlines our approach to detect dynamic scene changes in USVs. To the best of our understanding, this work represents the first investigation of scene change detection in the maritime vision application. Our objective is to identify significant changes in the dynamic scenes of maritime video data, particularly those scenes that exhibit a high degree of resemblance. In our system for dynamic scene change detection, we propose completely unsupervised learning method. In contrast to earlier studies, we utilize a modified cutting-edge generative picture model called VQ-VAE-2 to train on multiple marine datasets, aiming to enhance the feature extraction. Next, we introduce our innovative similarity scoring technique for directly calculating the level of similarity in a sequence of consecutive frames by utilizing grid calculation on retrieved features. The experiments were conducted using a nautical video dataset called RoboWhaler to showcase the efficient performance of our technique.
</details>
<details>
<summary>摘要</summary>
近些年来，marine vision领域内有一场势在浮现的研究活动，其中许多研究受到计算机视觉在无人水面车（USV）上的应用的影响。不同的感知modalities，如摄像头、雷达和激光雷达，都被用于实现对象检测、分割、跟踪和运动规划等任务。大多数当前的船舶舰队都装备了船舶上的摄像头，因此视频分析在这些研究中占据了一个重要的位置。由于视频数据的庞大量，视频场景变化检测是USV视频分析中的初始和关键阶段。本文介绍了我们对USV动态场景变化检测的方法。到目前为止，这是marine vision应用中首次对场景变化检测的研究。我们的目标是在USV动态场景中检测出显著变化，特别是那些场景具有高度的相似性。在我们的系统中，我们提出了一种完全无监督学习方法。与先前的研究不同，我们使用了修改后的VQ-VAE-2模型来在多个海洋数据集上训练，以提高特征提取。然后，我们介绍了我们的创新的相似度评分技术，通过在检索到的特征上进行格子计算来直接计算连续帧之间的相似度水平。实验使用了名为RoboWhaler的海洋视频数据集，以展示我们的技术的高效性。
</details></li>
</ul>
<hr>
<h2 id="A-3D-Multi-Style-Cross-Modality-Segmentation-Framework-for-Segmenting-Vestibular-Schwannoma-and-Cochlea"><a href="#A-3D-Multi-Style-Cross-Modality-Segmentation-Framework-for-Segmenting-Vestibular-Schwannoma-and-Cochlea" class="headerlink" title="A 3D Multi-Style Cross-Modality Segmentation Framework for Segmenting Vestibular Schwannoma and Cochlea"></a>A 3D Multi-Style Cross-Modality Segmentation Framework for Segmenting Vestibular Schwannoma and Cochlea</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11578">http://arxiv.org/abs/2311.11578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuzhou Zhuang</li>
<li>for: 本研究旨在用Multi-style Cross-modality Segmentation方法精确地分类 vestibular schwannoma和cochlea区域在无标注hrT2扫描中，以便提高肿瘤诊断和治疗的精度。</li>
<li>methods: 本研究使用了3D多式 Cross-modality Segmentation框架，包括多式转换和自学习分类阶段。首先，使用min-max normalization、voxel size resampling和center cropping来调整ceT1和hrT2扫描的像素大小和中心位置，以获得固定大小的子体积 для训练。接着，使用多种转换网络来超越intensity distribution差异 between多modal扫描。最后，使用nnU-Net框架和iterative自学习方法使用pseudo-labels来在目标领域进行自学习分类。</li>
<li>results: 在crossMoDA2023验证集上，本研究的方法获得了Promising results，mean DSC值为72.78%和80.64%，ASSD值为5.85 mm和0.25 mm дляVS肿瘤和cochlea区域，分别。此外，for intra-和extra-meatal区域，本研究的方法获得了DSC值为59.77%和77.14%。<details>
<summary>Abstract</summary>
The crossMoDA2023 challenge aims to segment the vestibular schwannoma (sub-divided into intra- and extra-meatal components) and cochlea regions of unlabeled hrT2 scans by leveraging labeled ceT1 scans. In this work, we proposed a 3D multi-style cross-modality segmentation framework for the crossMoDA2023 challenge, including the multi-style translation and self-training segmentation phases. Considering heterogeneous distributions and various image sizes in multi-institutional scans, we first utilize the min-max normalization, voxel size resampling, and center cropping to obtain fixed-size sub-volumes from ceT1 and hrT2 scans for training. Then, we perform the multi-style image translation phase to overcome the intensity distribution discrepancy between unpaired multi-modal scans. Specifically, we design three different translation networks with 2D or 2.5D inputs to generate multi-style and realistic target-like volumes from labeled ceT1 volumes. Finally, we perform the self-training volumetric segmentation phase in the target domain, which employs the nnU-Net framework and iterative self-training method using pseudo-labels for training accurate segmentation models in the unlabeled target domain. On the crossMoDA2023 validation dataset, our method produces promising results and achieves the mean DSC values of 72.78% and 80.64% and ASSD values of 5.85 mm and 0.25 mm for VS tumor and cochlea regions, respectively. Moreover, for intra- and extra-meatal regions, our method achieves the DSC values of 59.77% and 77.14%, respectively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>crossMoDA2023挑战目标是将vestibular schwannoma（分为内部和外部颈部组分）和auditory cochlea区域从无标签hrT2扫描图像中分割，通过利用标注ceT1扫描图像。在这个工作中，我们提出了一个3D多样性交叉Modal segmentation框架 дляcrossMoDA2023挑战，包括多样性翻译和自动训练segmentation阶段。 Considering不均分布和多种图像大小在多机构扫描中，我们首先使用最小值最大值归一化、voxel大小调整和中心剪辑以获取固定大小的sub-volumes从ceT1和hrT2扫描图像中进行训练。然后，我们进行多样性图像翻译阶段，以超越intensity分布差异 между多Modal scans。我们设计了三种不同的翻译网络，其中两个是2D或2.5D输入，以生成多样性和实际的目标类似体积量from标注ceT1体积图像。最后，我们进行自动训练volumetric segmentation阶段，使用nnU-Net框架和迭代自动训练方法使用pseudo-labels进行训练准确的分割模型在无标签目标Domain中。在crossMoDA2023验证集上，我们的方法产生了有前途的结果，得到了 mean DSC 值为72.78%和80.64%，和ASSD值为5.85 mm和0.25 mm дляVS tumor和auditory cochlea区域，分别。此外，对于内部和外部颈部区域，我们的方法得到了 DSC 值为59.77%和77.14%。Note: "vestibular schwannoma" is translated as "vestibular schwannoma" in Simplified Chinese, and "auditory cochlea" is translated as "auditory cochlea" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="CORE-MM-Complex-Open-Ended-Reasoning-Evaluation-For-Multi-Modal-Large-Language-Models"><a href="#CORE-MM-Complex-Open-Ended-Reasoning-Evaluation-For-Multi-Modal-Large-Language-Models" class="headerlink" title="CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models"></a>CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11567">http://arxiv.org/abs/2311.11567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaotian Han, Quanzeng You, Yongfei Liu, Wentao Chen, Huangjie Zheng, Khalil Mrini, Xudong Lin, Yiqi Wang, Bohan Zhai, Jianbo Yuan, Heng Wang, Hongxia Yang</li>
<li>For: The paper aims to evaluate the reasoning capabilities of multi-modal large language models (MLLMs) by creating a new benchmark dataset that focuses on complex reasoning tasks, such as deductive, abductive, and analogical reasoning.* Methods: The authors manually curate a dataset of queries that engage the reasoning capabilities of MLLMs, and incorporate intermediate reasoning steps into their evaluation criteria to assess the models’ ability to generate answers.* Results: The authors evaluate a selection of representative MLLMs using this new benchmark dataset and find that their reasoning capabilities are more accurately measured using this open-ended multi-step elaborate reasoning benchmark, which challenges the models to demonstrate their ability to perform complex reasoning tasks.<details>
<summary>Abstract</summary>
Multi-modal Large Language Models (MLLMs) are increasingly prominent in the field of artificial intelligence. These models not only excel in traditional vision-language tasks but also demonstrate impressive performance in contemporary multi-modal benchmarks. Although many of these benchmarks attempt to holistically evaluate MLLMs, they typically concentrate on basic reasoning tasks, often yielding only simple yes/no or multi-choice responses. These methods naturally lead to confusion and difficulties in conclusively determining the reasoning capabilities of MLLMs. To mitigate this issue, we manually curate a benchmark dataset specifically designed for MLLMs, with a focus on complex reasoning tasks. Our benchmark comprises three key reasoning categories: deductive, abductive, and analogical reasoning. The queries in our dataset are intentionally constructed to engage the reasoning capabilities of MLLMs in the process of generating answers. For a fair comparison across various MLLMs, we incorporate intermediate reasoning steps into our evaluation criteria. In instances where an MLLM is unable to produce a definitive answer, its reasoning ability is evaluated by requesting intermediate reasoning steps. If these steps align with our manual annotations, appropriate scores are assigned. This evaluation scheme resembles methods commonly used in human assessments, such as exams or assignments, and represents what we consider a more effective assessment technique compared with existing benchmarks. We evaluate a selection of representative MLLMs using this rigorously developed open-ended multi-step elaborate reasoning benchmark, designed to challenge and accurately measure their reasoning capabilities. The code and data will be released at https://core-mm.github.io/
</details>
<details>
<summary>摘要</summary>
多modal大型自然语言模型（MLLM）在人工智能领域日益突出。这些模型不仅在传统的视觉语言任务中表现出色，而且在当今的多modal benchmark中也显示出卓越表现。虽然许多这些 benchmark 尝试总体评估 MLLM，但它们通常只集中在基本的理解任务上，常常产生单纯的是或否或多选答案。这些方法自然导致混乱和判定 MLLM 的理解能力困难。为解决这个问题，我们手动精心制作了一个特有的 benchmark 数据集，专门为 MLLM 设计。我们的 benchmark 包括三种关键的理解类别：推理、推理和 analogical reasoning。我们的查询是通过特意设计来让 MLLM 在回答时 engag 其理解能力。为 garantuee fair comparison  across 不同的 MLLM，我们在评估标准中包括中间的推理步骤。在 MLLM 无法生成准确答案的情况下，我们评估其推理能力通过请求中间推理步骤。如果这些步骤与我们的手动注释相符，就会得分。这种评估方法与人类评估方法相似，例如考试或作业，并且代表我们认为更有效的评估方法，相比已有的 benchmark。我们使用这些精心制作的开放式多步逻辑 benchmark 评估一 selección 的代表 MLLM，以挑战并准确测量它们的理解能力。我们的代码和数据将在 <https://core-mm.github.io/> 上发布。
</details></li>
</ul>
<hr>
<h2 id="Does-complimentary-information-from-multispectral-imaging-improve-face-presentation-attack-detection"><a href="#Does-complimentary-information-from-multispectral-imaging-improve-face-presentation-attack-detection" class="headerlink" title="Does complimentary information from multispectral imaging improve face presentation attack detection?"></a>Does complimentary information from multispectral imaging improve face presentation attack detection?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11566">http://arxiv.org/abs/2311.11566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narayan Vetrekar, Raghavendra Ramachandra, Sushma Venkatesh, Jyoti D. Pawar, R. S. Gad</li>
<li>For: The paper is written to study the use of multispectral imaging for detecting presentation attacks in face recognition systems.* Methods: The paper uses a dataset called Face Presentation Attack Multispectral (FPAMS) to evaluate the performance of two fusion methods (image fusion and score fusion) in detecting presentation artifacts.* Results: The paper presents superior performance of the PAD based on the score fusion and image fusion methods, demonstrating the significance of employing multispectral imaging to detect presentation artifacts.Here are the three information points in Simplified Chinese text:* For: 这篇论文是为了研究基于多spectral成像的面 recognition系统中的示范攻击检测。* Methods: 这篇论文使用了一个名为Face Presentation Attack Multispectral (FPAMS)的数据集来评估两种混合方法（图像混合和得分混合）在检测示范 artifacts 中的性能。* Results: 这篇论文显示了基于得分混合和图像混合方法的 PAD 表现出色，证明了在检测示范 artifacts 中使用多spectral成像的重要性。<details>
<summary>Abstract</summary>
Presentation Attack Detection (PAD) has been extensively studied, particularly in the visible spectrum. With the advancement of sensing technology beyond the visible range, multispectral imaging has gained significant attention in this direction. We present PAD based on multispectral images constructed for eight different presentation artifacts resulted from three different artifact species. In this work, we introduce Face Presentation Attack Multispectral (FPAMS) database to demonstrate the significance of employing multispectral imaging. The goal of this work is to study complementary information that can be combined in two different ways (image fusion and score fusion) from multispectral imaging to improve the face PAD. The experimental evaluation results present an extensive qualitative analysis of 61650 sample multispectral images collected for bonafide and artifacts. The PAD based on the score fusion and image fusion method presents superior performance, demonstrating the significance of employing multispectral imaging to detect presentation artifacts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="NePF-Neural-Photon-Field-for-Single-Stage-Inverse-Rendering"><a href="#NePF-Neural-Photon-Field-for-Single-Stage-Inverse-Rendering" class="headerlink" title="NePF: Neural Photon Field for Single-Stage Inverse Rendering"></a>NePF: Neural Photon Field for Single-Stage Inverse Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11555">http://arxiv.org/abs/2311.11555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuen-Yue Tsui, Qin Zou</li>
<li>for:  addressed the ill-posed inverse rendering problem from multi-view images</li>
<li>methods:  introduced a novel single-stage framework called Neural Photon Field (NePF), which fully utilizes the physical implication behind the weight function of neural implicit surfaces and the view-dependent radiance</li>
<li>results:  demonstrated superiority in recovering high-fidelity geometry and visual-plausible material attributes, evaluated on both real and synthetic datasets.Here’s the summary in English for reference:</li>
<li>for: The paper addresses the ill-posed inverse rendering problem from multi-view images.</li>
<li>methods: The paper introduces a novel single-stage framework called Neural Photon Field (NePF), which fully utilizes the physical implication behind the weight function of neural implicit surfaces and the view-dependent radiance.</li>
<li>results: The paper demonstrates the superiority of the proposed approach in recovering high-fidelity geometry and visual-plausible material attributes, evaluated on both real and synthetic datasets.<details>
<summary>Abstract</summary>
We present a novel single-stage framework, Neural Photon Field (NePF), to address the ill-posed inverse rendering from multi-view images. Contrary to previous methods that recover the geometry, material, and illumination in multiple stages and extract the properties from various multi-layer perceptrons across different neural fields, we question such complexities and introduce our method - a single-stage framework that uniformly recovers all properties. NePF achieves this unification by fully utilizing the physical implication behind the weight function of neural implicit surfaces and the view-dependent radiance. Moreover, we introduce an innovative coordinate-based illumination model for rapid volume physically-based rendering. To regularize this illumination, we implement the subsurface scattering model for diffuse estimation. We evaluate our method on both real and synthetic datasets. The results demonstrate the superiority of our approach in recovering high-fidelity geometry and visual-plausible material attributes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的单阶段框架，神经光场（NePF），用于解决多视图图像的逆向渲染问题。与前方法不同，我们的方法不需要在多个层次感知机中提取不同的物理属性，而是通过全面利用神经凝件表面的权重函数和视角依赖的辐射来协调所有属性。此外，我们还提出了一种新的坐标基于的照明模型，用于快速Physically-Based Rendering（PBR）。为了规范这种照明，我们实现了吸收散射模型来估算柔化。我们在真实数据集和 sintetic 数据集上评估了我们的方法，结果显示了我们的方法在高精度的几何和可见性上具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Unearthing-Common-Inconsistency-for-Generalisable-Deepfake-Detection"><a href="#Unearthing-Common-Inconsistency-for-Generalisable-Deepfake-Detection" class="headerlink" title="Unearthing Common Inconsistency for Generalisable Deepfake Detection"></a>Unearthing Common Inconsistency for Generalisable Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11549">http://arxiv.org/abs/2311.11549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Beilin Chu, Xuan Xu, Weike You, Linna Zhou</li>
<li>for: 本研究旨在提出一种能够普适应用于不同涂抹方法的深伪检测方法，以解决现有的深伪检测方法无法普适应用于不同频谱频率频谱频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频��<details>
<summary>Abstract</summary>
Deepfake has emerged for several years, yet efficient detection techniques could generalize over different manipulation methods require further research. While current image-level detection method fails to generalize to unseen domains, owing to the domain-shift phenomenon brought by CNN's strong inductive bias towards Deepfake texture, video-level one shows its potential to have both generalization across multiple domains and robustness to compression. We argue that although distinct face manipulation tools have different inherent bias, they all disrupt the consistency between frames, which is a natural characteristic shared by authentic videos. Inspired by this, we proposed a detection approach by capturing frame inconsistency that broadly exists in different forgery techniques, termed unearthing-common-inconsistency (UCI). Concretely, the UCI network based on self-supervised contrastive learning can better distinguish temporal consistency between real and fake videos from multiple domains. We introduced a temporally-preserved module method to introduce spatial noise perturbations, directing the model's attention towards temporal information. Subsequently, leveraging a multi-view cross-correlation learning module, we extensively learn the disparities in temporal representations between genuine and fake samples. Extensive experiments demonstrate the generalization ability of our method on unseen Deepfake domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Model-Agnostic-Approach-for-Implicit-Neural-Representation-Based-Arbitrary-Scale-Image-Super-Resolution"><a href="#Efficient-Model-Agnostic-Approach-for-Implicit-Neural-Representation-Based-Arbitrary-Scale-Image-Super-Resolution" class="headerlink" title="Efficient Model Agnostic Approach for Implicit Neural Representation Based Arbitrary-Scale Image Super-Resolution"></a>Efficient Model Agnostic Approach for Implicit Neural Representation Based Arbitrary-Scale Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12077">http://arxiv.org/abs/2311.12077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Jae Oh, Jihun Kim, Tae Hyun Kim</li>
<li>for: 提高单图超解像的计算效率，无需牺牲重建质量。</li>
<li>methods: 使用混合专家模型，动态分配专家对每个像素进行重建。</li>
<li>results: 比 tradicional方法减少73%的 floating point operations（FLOPs），并且提供相同或更高的峰值信号噪听比（PSNR）。<details>
<summary>Abstract</summary>
Single image super-resolution (SISR) has experienced significant advancements, primarily driven by deep convolutional networks. Traditional networks, however, are limited to upscaling images to a fixed scale, leading to the utilization of implicit neural functions for generating arbitrarily scaled images. Nevertheless, these methodologies have imposed substantial computational demands as they involve querying every target pixel to a single resource-intensive decoder. In this paper, we introduce a novel and efficient framework, the Mixture of Experts Implicit Super-Resolution (MoEISR), which enables super-resolution at arbitrary scales with significantly increased computational efficiency without sacrificing reconstruction quality. MoEISR dynamically allocates the most suitable decoding expert to each pixel using a lightweight mapper module, allowing experts with varying capacities to reconstruct pixels across regions with diverse complexities. Our experiments demonstrate that MoEISR successfully reduces up to 73% in floating point operations (FLOPs) while delivering comparable or superior peak signal-to-noise ratio (PSNR).
</details>
<details>
<summary>摘要</summary>
单一图像超解析（SISR）在最近已经经历了重要的进步，主要受到深度卷积神经的驱动。然而，传统的神经网络仅能将图像调整到固定比例，从而需要使用隐藏的神经函数来生成自适应比例的图像。不过，这些方法具有较高的计算成本，因为它们需要每个目标像素与单一资源密集的解oder进行询问。在这篇论文中，我们提出了一个新的和高效的框架，即混合专家隐藏超解析（MoEISR），允许在自适应比例下进行超解析，并大幅降低计算成本。MoEISR通过动态分配最适合的解oding专家给每个像素使用轻量级映射模组，让专家具有不同容量进行像素重建。我们的实验结果显示，MoEISR可以成功降低73%的浮点运算（FLOPs），同时保持比或superior的峰峰信号输出比率（PSNR）。
</details></li>
</ul>
<hr>
<h2 id="Event-Camera-Data-Dense-Pre-training"><a href="#Event-Camera-Data-Dense-Pre-training" class="headerlink" title="Event Camera Data Dense Pre-training"></a>Event Camera Data Dense Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11533">http://arxiv.org/abs/2311.11533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Yang, Liyuan Pan, Liu Liu</li>
<li>for: 本研究旨在为 dense prediction 任务预训练神经网络，使用事件摄像头数据。</li>
<li>methods: 我们的方法仅使用事件数据进行训练，并利用事件图像中的事件特征进行自动归一化，以捕捉事件图像中的相似性关系。</li>
<li>results: 我们的方法在 dense prediction 下投入 transfer learning 性能较高，特别是在 DSEC-Flow 比赛中，单个模型占据了挑战性的首位。<details>
<summary>Abstract</summary>
This paper introduces a self-supervised learning framework designed for pre-training neural networks tailored to dense prediction tasks using event camera data. Our approach utilizes solely event data for training.   Transferring achievements from dense RGB pre-training directly to event camera data yields subpar performance. This is attributed to the spatial sparsity inherent in an event image (converted from event data), where many pixels do not contain information. To mitigate this sparsity issue, we encode an event image into event patch features, automatically mine contextual similarity relationships among patches, group the patch features into distinctive contexts, and enforce context-to-context similarities to learn discriminative event features.   For training our framework, we curate a synthetic event camera dataset featuring diverse scene and motion patterns. Transfer learning performance on downstream dense prediction tasks illustrates the superiority of our method over state-of-the-art approaches. Notably, our single model secured the top position in the challenging DSEC-Flow benchmark.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Generalized-Category-Discovery-in-Semantic-Segmentation"><a href="#Generalized-Category-Discovery-in-Semantic-Segmentation" class="headerlink" title="Generalized Category Discovery in Semantic Segmentation"></a>Generalized Category Discovery in Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11525">http://arxiv.org/abs/2311.11525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jethropeng/gcdss">https://github.com/jethropeng/gcdss</a></li>
<li>paper_authors: Zhengyuan Peng, Qijian Tian, Jianqing Xu, Yizhang Jin, Xuequan Lu, Xin Tan, Yuan Xie, Lizhuang Ma</li>
<li>for: 这篇论文探索了一个新的设定，即通用类别发现（Generalized Category Discovery，GCD），企从已知类别的图像推导未知类别。不同于先前的新类别发现（Novel Category Discovery，NCD），这个设定不需要每个未知类别都存在于每个未知图像中。此外，我们扩展了分类的范围，让它包括整个图像。</li>
<li>methods: 我们提出了一个简单 yet effective的框架，将GCDSS挑战转换为一个面块分类任务。此外，我们开发了一个基eline方法，即邻居关系导向面块分类算法（NeRG-MaskCA），来进行面块分类。</li>
<li>results: 我们的方法显示了GCDSS的可行性和可能性，并且可以在未知图像中发现和分类新的类别。我们使用我们的方法生成的假标签作为真实标签，以便训练其他模型，从而允许它们在未知类别上进行分类。这构成了更多研究的基础，扩展 semantic segmentation 的应用范围。<details>
<summary>Abstract</summary>
This paper explores a novel setting called Generalized Category Discovery in Semantic Segmentation (GCDSS), aiming to segment unlabeled images given prior knowledge from a labeled set of base classes. The unlabeled images contain pixels of the base class or novel class. In contrast to Novel Category Discovery in Semantic Segmentation (NCDSS), there is no prerequisite for prior knowledge mandating the existence of at least one novel class in each unlabeled image. Besides, we broaden the segmentation scope beyond foreground objects to include the entire image. Existing NCDSS methods rely on the aforementioned priors, making them challenging to truly apply in real-world situations. We propose a straightforward yet effective framework that reinterprets the GCDSS challenge as a task of mask classification. Additionally, we construct a baseline method and introduce the Neighborhood Relations-Guided Mask Clustering Algorithm (NeRG-MaskCA) for mask categorization to address the fragmentation in semantic representation. A benchmark dataset, Cityscapes-GCD, derived from the Cityscapes dataset, is established to evaluate the GCDSS framework. Our method demonstrates the feasibility of the GCDSS problem and the potential for discovering and segmenting novel object classes in unlabeled images. We employ the generated pseudo-labels from our approach as ground truth to supervise the training of other models, thereby enabling them with the ability to segment novel classes. It paves the way for further research in generalized category discovery, broadening the horizons of semantic segmentation and its applications. For details, please visit https://github.com/JethroPeng/GCDSS
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Few-shot-Out-of-Distribution-Detection"><a href="#Towards-Few-shot-Out-of-Distribution-Detection" class="headerlink" title="Towards Few-shot Out-of-Distribution Detection"></a>Towards Few-shot Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12076">http://arxiv.org/abs/2311.12076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuqing Dong, Yongbin Gao, Heng Zhou, Jun Cen, Yifan Yao, Sook Yoon, Park Dong Sun</li>
<li>for: 提高 open-world 智能系统 的可靠性，即 out-of-distribution (OOD) 检测。</li>
<li>methods: 引入了一个新的几shot OOD 检测benchmark，并进行了实验研究，发现ParameterEfficient Fine-Tuning (PEFT) 策略在几shot OOD 检测任务中表现更好，包括完全 Fine-Tuning 和线性探索 Tuning。</li>
<li>results: 研究发现，在 fine-tuning 过程中可能会产生一些关键信息，这些信息对 OOD 检测非常重要，因此提出了一种方法，即 DomainSpecific and General Knowledge Fusion (DSGF)，以提高几shot OOD 检测能力。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is critical for ensuring the reliability of open-world intelligent systems. Despite the notable advancements in existing OOD detection methodologies, our study identifies a significant performance drop under the scarcity of training samples. In this context, we introduce a novel few-shot OOD detection benchmark, carefully constructed to address this gap. Our empirical analysis reveals the superiority of ParameterEfficient Fine-Tuning (PEFT) strategies, such as visual prompt tuning and visual adapter tuning, over conventional techniques, including fully fine-tuning and linear probing tuning in the few-shot OOD detection task. Recognizing some crucial information from the pre-trained model, which is pivotal for OOD detection, may be lost during the fine-tuning process, we propose a method termed DomainSpecific and General Knowledge Fusion (DSGF). This approach is designed to be compatible with diverse fine-tuning frameworks. Our experiments show that the integration of DSGF significantly enhances the few-shot OOD detection capabilities across various methods and fine-tuning methodologies, including fully fine-tuning, visual adapter tuning, and visual prompt tuning. The code will be released.
</details>
<details>
<summary>摘要</summary>
外部数据（OOD）检测是智能系统的可靠性 garantia 的关键。 despite notable advancements in existing OOD detection methodologies, our study identifies a significant performance drop under the scarcity of training samples. In this context, we introduce a novel few-shot OOD detection benchmark, carefully constructed to address this gap. Our empirical analysis reveals the superiority of ParameterEfficient Fine-Tuning (PEFT) strategies, such as visual prompt tuning and visual adapter tuning, over conventional techniques, including fully fine-tuning and linear probing tuning in the few-shot OOD detection task. Recognizing some crucial information from the pre-trained model, which is pivotal for OOD detection, may be lost during the fine-tuning process, we propose a method termed DomainSpecific and General Knowledge Fusion (DSGF). This approach is designed to be compatible with diverse fine-tuning frameworks. Our experiments show that the integration of DSGF significantly enhances the few-shot OOD detection capabilities across various methods and fine-tuning methodologies, including fully fine-tuning, visual adapter tuning, and visual prompt tuning. The code will be released.Here's the text in Traditional Chinese:外部数据（OOD）检测是智能系统的可靠性 garantia 的关键。 despite notable advancements in existing OOD detection methodologies, our study identifies a significant performance drop under the scarcity of training samples. In this context, we introduce a novel few-shot OOD detection benchmark, carefully constructed to address this gap. Our empirical analysis reveals the superiority of ParameterEfficient Fine-Tuning (PEFT) strategies, such as visual prompt tuning and visual adapter tuning, over conventional techniques, including fully fine-tuning and linear probing tuning in the few-shot OOD detection task. Recognizing some crucial information from the pre-trained model, which is pivotal for OOD detection, may be lost during the fine-tuning process, we propose a method termed DomainSpecific and General Knowledge Fusion (DSGF). This approach is designed to be compatible with diverse fine-tuning frameworks. Our experiments show that the integration of DSGF significantly enhances the few-shot OOD detection capabilities across various methods and fine-tuning methodologies, including fully fine-tuning, visual adapter tuning, and visual prompt tuning. The code will be released.
</details></li>
</ul>
<hr>
<h2 id="Liver-Tumor-Prediction-with-Advanced-Attention-Mechanisms-Integrated-into-a-Depth-Based-Variant-Search-Algorithm"><a href="#Liver-Tumor-Prediction-with-Advanced-Attention-Mechanisms-Integrated-into-a-Depth-Based-Variant-Search-Algorithm" class="headerlink" title="Liver Tumor Prediction with Advanced Attention Mechanisms Integrated into a Depth-Based Variant Search Algorithm"></a>Liver Tumor Prediction with Advanced Attention Mechanisms Integrated into a Depth-Based Variant Search Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11520">http://arxiv.org/abs/2311.11520</a></li>
<li>repo_url: None</li>
<li>paper_authors: P. Kalaiselvi, S. Anusuya</li>
<li>for: 预测肝脏癌症</li>
<li>methods: 使用卷积神经网络（CNN）和深度基于变体搜索算法（CNN-DS-AM），并含有进一步的注意力机制</li>
<li>results: 提高预测肝脏癌症的准确率和可靠性，高于其他当前领域方法<details>
<summary>Abstract</summary>
In recent days, Deep Learning (DL) techniques have become an emerging transformation in the field of machine learning, artificial intelligence, computer vision, and so on. Subsequently, researchers and industries have been highly endorsed in the medical field, predicting and controlling diverse diseases at specific intervals. Liver tumor prediction is a vital chore in analyzing and treating liver diseases. This paper proposes a novel approach for predicting liver tumors using Convolutional Neural Networks (CNN) and a depth-based variant search algorithm with advanced attention mechanisms (CNN-DS-AM). The proposed work aims to improve accuracy and robustness in diagnosing and treating liver diseases. The anticipated model is assessed on a Computed Tomography (CT) scan dataset containing both benign and malignant liver tumors. The proposed approach achieved high accuracy in predicting liver tumors, outperforming other state-of-the-art methods. Additionally, advanced attention mechanisms were incorporated into the CNN model to enable the identification and highlighting of regions of the CT scans most relevant to predicting liver tumors. The results suggest that incorporating attention mechanisms and a depth-based variant search algorithm into the CNN model is a promising approach for improving the accuracy and robustness of liver tumor prediction. It can assist radiologists in their diagnosis and treatment planning. The proposed system achieved a high accuracy of 95.5% in predicting liver tumors, outperforming other state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
现在的日子里，深度学习（DL）技术已成为机器学习、人工智能、计算机视觉等领域的一种emerging transformation。随后，研究人员和产业在医疗领域中高度支持，预测和控制多种疾病。肝肿瘤预测是分析和治疗肝病的重要任务。本文提出了一种使用卷积神经网络（CNN）和深度基本变体搜索算法（CNN-DS-AM）的新方法，以提高肝肿瘤预测的准确性和稳定性。该方法采用了CT扫描图像 dataset，包括了正常和肿瘤肝肿瘤。Results suggest that incorporating attention mechanisms and a depth-based variant search algorithm into the CNN model is a promising approach for improving the accuracy and robustness of liver tumor prediction. It can assist radiologists in their diagnosis and treatment planning, with an accuracy of 95.5% in predicting liver tumors, outperforming other state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Seeing-through-the-Mask-Multi-task-Generative-Mask-Decoupling-Face-Recognition"><a href="#Seeing-through-the-Mask-Multi-task-Generative-Mask-Decoupling-Face-Recognition" class="headerlink" title="Seeing through the Mask: Multi-task Generative Mask Decoupling Face Recognition"></a>Seeing through the Mask: Multi-task Generative Mask Decoupling Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11512">http://arxiv.org/abs/2311.11512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaohui Wang, Sufang Zhang, Jianteng Peng, Xinyi Wang, Yandong Guo</li>
<li>for: 本研究旨在提高面Recognition系统在受到 occlusion 影响时的性能，解决现有系统在 occluded scenes 下表现不佳的问题。</li>
<li>methods: 本研究提出了 Multi-task gEnerative mask dEcoupling face Recognition (MEER) 网络，该网络可以同时处理 occlusion 和 identity 相关的表示，从可见的 facial 部分提取更加纯净的 identity 特征，并通过 join-training 策略实现不受 occlusion 影响的 face synthesis。</li>
<li>results: 实验表明，MEER 可以在实际和synthetic occlusions benchmarks 上进行面Recognition，并且在 occluded scenes 下表现较为出色，超过了现有方法的性能。<details>
<summary>Abstract</summary>
The outbreak of COVID-19 pandemic make people wear masks more frequently than ever. Current general face recognition system suffers from serious performance degradation,when encountering occluded scenes. The potential reason is that face features are corrupted by occlusions on key facial regions. To tackle this problem, previous works either extract identity-related embeddings on feature level by additional mask prediction, or restore the occluded facial part by generative models. However, the former lacks visual results for model interpretation, while the latter suffers from artifacts which may affect downstream recognition. Therefore, this paper proposes a Multi-task gEnerative mask dEcoupling face Recognition (MEER) network to jointly handle these two tasks, which can learn occlusionirrelevant and identity-related representation while achieving unmasked face synthesis. We first present a novel mask decoupling module to disentangle mask and identity information, which makes the network obtain purer identity features from visible facial components. Then, an unmasked face is restored by a joint-training strategy, which will be further used to refine the recognition network with an id-preserving loss. Experiments on masked face recognition under realistic and synthetic occlusions benchmarks demonstrate that the MEER can outperform the state-ofthe-art methods.
</details>
<details>
<summary>摘要</summary>
COVID-19 疫情爆发使人们更常穿戴口罩，现有普通面部识别系统在遇到遮挡场景时表现出了严重的性能下降。 这可能是因为面部特征被遮挡的关键区域所致。为解决这个问题，前一些作品可以在特征层提取人类相关的嵌入，或者使用生成模型恢复遮挡的面部部分。然而，前一些作品缺乏可视化结果，而后者可能会出现artefacts，这些artefacts可能会影响下游识别。因此，本文提出了一种多任务生成式面部隐藏减少网络（MEER），该网络可以同时处理这两个任务，学习遮挡不相关的人类特征表示，并实现不遮挡的面部合成。我们首先提出了一种新的面部隐藏模块，该模块可以分离面部和身份信息，使网络从可见的面部组件中获得纯净的身份特征。然后，我们使用联合训练策略恢复无遮挡的面部，该面部将被用来改进识别网络，并使用id保持损失进行补做。实验结果表明，MEER可以在实际和synthetic occlusion benchmark上超越当前的状态OF-THE-ART方法。
</details></li>
</ul>
<hr>
<h2 id="BadCLIP-Dual-Embedding-Guided-Backdoor-Attack-on-Multimodal-Contrastive-Learning"><a href="#BadCLIP-Dual-Embedding-Guided-Backdoor-Attack-on-Multimodal-Contrastive-Learning" class="headerlink" title="BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning"></a>BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12075">http://arxiv.org/abs/2311.12075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyuan Liang, Mingli Zhu, Aishan Liu, Baoyuan Wu, Xiaochun Cao, Ee-Chien Chang</li>
<li>for: 本研究旨在提高模型版权保护和防御力，通过研究后门攻击。</li>
<li>methods: 本文使用了 dual-embedding 指导架构和 Bayesian 规则，实现了不易被检测的后门攻击。</li>
<li>results: 对比州对抗后门攻击的基eline，本文的攻击效果更高 (+45.3% ASR)，这些防御策略在实际应用中基本无效。<details>
<summary>Abstract</summary>
Studying backdoor attacks is valuable for model copyright protection and enhancing defenses. While existing backdoor attacks have successfully infected multimodal contrastive learning models such as CLIP, they can be easily countered by specialized backdoor defenses for MCL models. This paper reveals the threats in this practical scenario that backdoor attacks can remain effective even after defenses and introduces the \emph{\toolns} attack, which is resistant to backdoor detection and model fine-tuning defenses. To achieve this, we draw motivations from the perspective of the Bayesian rule and propose a dual-embedding guided framework for backdoor attacks. Specifically, we ensure that visual trigger patterns approximate the textual target semantics in the embedding space, making it challenging to detect the subtle parameter variations induced by backdoor learning on such natural trigger patterns. Additionally, we optimize the visual trigger patterns to align the poisoned samples with target vision features in order to hinder the backdoor unlearning through clean fine-tuning. Extensive experiments demonstrate that our attack significantly outperforms state-of-the-art baselines (+45.3% ASR) in the presence of SoTA backdoor defenses, rendering these mitigation and detection strategies virtually ineffective. Furthermore, our approach effectively attacks some more rigorous scenarios like downstream tasks. We believe that this paper raises awareness regarding the potential threats associated with the practical application of multimodal contrastive learning and encourages the development of more robust defense mechanisms.
</details>
<details>
<summary>摘要</summary>
To achieve this, we draw motivations from the Bayesian rule and propose a dual-embedding guided framework for backdoor attacks. Specifically, we ensure that visual trigger patterns approximate the textual target semantics in the embedding space, making it challenging to detect the subtle parameter variations induced by backdoor learning on such natural trigger patterns. Additionally, we optimize the visual trigger patterns to align the poisoned samples with target vision features in order to hinder the backdoor unlearning through clean fine-tuning.Our extensive experiments show that our attack significantly outperforms state-of-the-art baselines (+45.3% ASR) in the presence of SoTA backdoor defenses, rendering these mitigation and detection strategies virtually ineffective. Furthermore, our approach effectively attacks some more rigorous scenarios like downstream tasks. We believe that this paper raises awareness regarding the potential threats associated with the practical application of multimodal contrastive learning and encourages the development of more robust defense mechanisms.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.CV_2023_11_20/" data-id="clpxp6c2o00nkee887o0v7s6m" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.AI_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T12:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/cs.AI_2023_11_20/">cs.AI - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Provable-Representation-with-Efficient-Planning-for-Partially-Observable-Reinforcement-Learning"><a href="#Provable-Representation-with-Efficient-Planning-for-Partially-Observable-Reinforcement-Learning" class="headerlink" title="Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning"></a>Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12244">http://arxiv.org/abs/2311.12244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongming Zhang, Tongzheng Ren, Chenjun Xiao, Dale Schuurmans, Bo Dai</li>
<li>for: 解决实际探索学习问题中state信息只能部分 observable，导致基本假设不成立，从而影响性能。</li>
<li>methods: 利用表示视图，提出一种可行的探索学习算法，并提供了对 partial observations 的理论分析，以确保算法的统计效率。</li>
<li>results: 实验表明，提出的算法可以在多种 benchmark 上超越现有的表现，因此推动可靠的探索学习向更实际应用。<details>
<summary>Abstract</summary>
In real-world reinforcement learning problems, the state information is often only partially observable, which breaks the basic assumption in Markov decision processes, and thus, leads to inferior performances. Partially Observable Markov Decision Processes have been introduced to explicitly take the issue into account for learning, exploration, and planning, but presenting significant computational and statistical challenges. To address these difficulties, we exploit the representation view, which leads to a coherent design framework for a practically tractable reinforcement learning algorithm upon partial observations. We provide a theoretical analysis for justifying the statistical efficiency of the proposed algorithm. We also empirically demonstrate the proposed algorithm can surpass state-of-the-art performance with partial observations across various benchmarks, therefore, pushing reliable reinforcement learning towards more practical applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="InteraSSort-Interactive-Assortment-Planning-Using-Large-Language-Models"><a href="#InteraSSort-Interactive-Assortment-Planning-Using-Large-Language-Models" class="headerlink" title="InteraSSort: Interactive Assortment Planning Using Large Language Models"></a>InteraSSort: Interactive Assortment Planning Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12241">http://arxiv.org/abs/2311.12241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saketh Reddy Karra, Theja Tulabandhula</li>
<li>for: 这个论文主要针对的是电商和零售业中的购物策略规划问题，即如何通过互动对话来帮助店长做出优化的决策。</li>
<li>methods: 该论文提出了一种互动购物策略规划框架，称为InteraSSort，该框架通过结合大语言模型和优化工具来帮助店长在互动对话中做出优化的决策。</li>
<li>results:  experiments 表明，InteraSSort 可以帮助店长做出更加精准和个性化的决策，并且可以扩展到多种操作管理挑战。<details>
<summary>Abstract</summary>
Assortment planning, integral to multiple commercial offerings, is a key problem studied in e-commerce and retail settings. Numerous variants of the problem along with their integration into business solutions have been thoroughly investigated in the existing literature. However, the nuanced complexities of in-store planning and a lack of optimization proficiency among store planners with strong domain expertise remain largely overlooked. These challenges frequently necessitate collaborative efforts with multiple stakeholders which often lead to prolonged decision-making processes and significant delays. To mitigate these challenges and capitalize on the advancements of Large Language Models (LLMs), we propose an interactive assortment planning framework, InteraSSort that augments LLMs with optimization tools to assist store planners in making decisions through interactive conversations. Specifically, we develop a solution featuring a user-friendly interface that enables users to express their optimization objectives as input text prompts to InteraSSort and receive tailored optimized solutions as output. Our framework extends beyond basic functionality by enabling the inclusion of additional constraints through interactive conversation, facilitating precise and highly customized decision-making. Extensive experiments demonstrate the effectiveness of our framework and potential extensions to a broad range of operations management challenges.
</details>
<details>
<summary>摘要</summary>
产品排编规划是电商和零售业中关键的问题，它在多种商业服务中发挥重要作用。现有文献中已经进行了详细的研究和分析。然而，在门店规划中存在许多复杂的特点，以及门店规划人员具有强定领域专业知识的问题，这些问题经常需要多方合作和讨论，导致决策过程延长，延迟。为了解决这些挑战，我们提出一种互动式排编规划框架，即InteraSSort，该框架通过与大语言模型（LLM）的合作，为门店规划人员提供互动式会话的优化解决方案。specifically，我们开发了一个用户友好的界面，允许用户通过输入文本提示来表达优化目标，并从InteraSSort获得适应性的优化解决方案。我们的框架不仅具有基本功能，还允许通过互动会话中的添加约束，实现精准和个性化的决策。我们的实验证明了我们的框架的有效性和扩展性，并可应用于多种运维管理挑战。
</details></li>
</ul>
<hr>
<h2 id="Ontological-Reasoning-over-Shy-and-Warded-Datalog-for-Streaming-based-Architectures-technical-report"><a href="#Ontological-Reasoning-over-Shy-and-Warded-Datalog-for-Streaming-based-Architectures-technical-report" class="headerlink" title="Ontological Reasoning over Shy and Warded Datalog$+&#x2F;-$ for Streaming-based Architectures (technical report)"></a>Ontological Reasoning over Shy and Warded Datalog$+&#x2F;-$ for Streaming-based Architectures (technical report)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12236">http://arxiv.org/abs/2311.12236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teodoro Baldazzi, Luigi Bellomarini, Marco Favorito, Emanuel Sallinger</li>
<li>for: 这篇论文关注在现代化的 Ontological Reasoning 系统中，具体是使用 Datalog$+&#x2F;- $语言扩展 Datalog，以提高推理效率和计算复杂性的 equilibrio。</li>
<li>methods: 这篇论文使用了现代reasoner的实现经验，如volcano-iterator架构，以实现有限内存占用和好scalability。</li>
<li>results: 这篇论文介绍了两种非常有潜力和可追加的语言，namely Shy和Warded Datalog$+&#x2F;- $，并基于它们的理论基础，提出了新的推理技巧，以便高效地解决实际场景中的 Ontological Reasoning 问题。<details>
<summary>Abstract</summary>
Recent years witnessed a rising interest towards Datalog-based ontological reasoning systems, both in academia and industry. These systems adopt languages, often shared under the collective name of Datalog$+/-$, that extend Datalog with the essential feature of existential quantification, while introducing syntactic limitations to sustain reasoning decidability and achieve a good trade-off between expressive power and computational complexity. From an implementation perspective, modern reasoners borrow the vast experience of the database community in developing streaming-based data processing systems, such as volcano-iterator architectures, that sustain a limited memory footprint and good scalability. In this paper, we focus on two extremely promising, expressive, and tractable languages, namely, Shy and Warded Datalog$+/-$. We leverage their theoretical underpinnings to introduce novel reasoning techniques, technically, "chase variants", that are particularly fit for efficient reasoning in streaming-based architectures. We then implement them in Vadalog, our reference streaming-based engine, to efficiently solve ontological reasoning tasks over real-world settings.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:近年来，有越来越多的关注于基于Datalog的 ontological reasoning系统，在学术和产业中。这些系统使用语言，通常被称为Datalog$+/-$, 它们扩展了Datalog，添加了存在量化，同时保持可 decidability 和计算复杂性的平衡。从实现角度来看，现代推理器借鉴了数据库社区对流处理系统的开发经验，如火山迭代架构，以保持有限内存占用和良好的扩展性。在这篇论文中，我们关注两种极其有前途和表达力强的语言，即Shy和Warded Datalog$+/-$.我们利用它们的理论基础，引入了新的推理技术，即"追踪变种"，这些技术特别适合流处理基础结构中高效的推理。然后，我们在Vadalog，我们的参考流处理基础结构中，实现了这些技术，以高效地解决了实际应用中的 ontological reasoning问题。
</details></li>
</ul>
<hr>
<h2 id="NeuroPrompts-An-Adaptive-Framework-to-Optimize-Prompts-for-Text-to-Image-Generation"><a href="#NeuroPrompts-An-Adaptive-Framework-to-Optimize-Prompts-for-Text-to-Image-Generation" class="headerlink" title="NeuroPrompts: An Adaptive Framework to Optimize Prompts for Text-to-Image Generation"></a>NeuroPrompts: An Adaptive Framework to Optimize Prompts for Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12229">http://arxiv.org/abs/2311.12229</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shachar Rosenman, Vasudev Lal, Phillip Howard</li>
<li>for: 提高文本到图像生成模型的生成质量，减少人工引擎的干预。</li>
<li>methods: 使用受控文本解码与适应的语言模型，自动提高用户的提示，以提高文本到图像生成的质量。</li>
<li>results: 通过对大量人工引擎生成的提示进行分析和优化，自动生成高质量的提示，以提高文本到图像生成的质量。<details>
<summary>Abstract</summary>
Despite impressive recent advances in text-to-image diffusion models, obtaining high-quality images often requires prompt engineering by humans who have developed expertise in using them. In this work, we present NeuroPrompts, an adaptive framework that automatically enhances a user's prompt to improve the quality of generations produced by text-to-image models. Our framework utilizes constrained text decoding with a pre-trained language model that has been adapted to generate prompts similar to those produced by human prompt engineers. This approach enables higher-quality text-to-image generations and provides user control over stylistic features via constraint set specification. We demonstrate the utility of our framework by creating an interactive application for prompt enhancement and image generation using Stable Diffusion. Additionally, we conduct experiments utilizing a large dataset of human-engineered prompts for text-to-image generation and show that our approach automatically produces enhanced prompts that result in superior image quality. We make our code, a screencast video demo and a live demo instance of NeuroPrompts publicly available.
</details>
<details>
<summary>摘要</summary>
尽管最近的文本到图像扩散模型已经很出色地进步，但是获得高质量图像 Frequently requires human expertise in using these models. 在这项工作中，我们介绍NeuroPrompts，一个可靠的框架，可以自动提高用户提示的质量，以提高文本到图像模型生成的质量。我们的框架使用了约束文本解码，并利用预训练的自然语言模型，生成类似于人类提示工程师生成的提示。这种方法可以提高文本到图像生成的质量，并提供用户控制风格特征的功能，通过约束集定。我们在创建了一个交互式应用程序，用于提示增强和图像生成，并在大量人类工程师生成的提示集合上进行了实验，并证明了我们的方法可以自动生成提高图像质量的提示。我们将我们的代码、屏幕捕捉视频和实时示例 instances of NeuroPrompts 公开 disponibles。
</details></li>
</ul>
<hr>
<h2 id="Fast-Inner-Product-Algorithms-and-Architectures-for-Deep-Neural-Network-Accelerators"><a href="#Fast-Inner-Product-Algorithms-and-Architectures-for-Deep-Neural-Network-Accelerators" class="headerlink" title="Fast Inner-Product Algorithms and Architectures for Deep Neural Network Accelerators"></a>Fast Inner-Product Algorithms and Architectures for Deep Neural Network Accelerators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12224">http://arxiv.org/abs/2311.12224</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/trevorpogue/algebraic-nnhw">https://github.com/trevorpogue/algebraic-nnhw</a></li>
<li>paper_authors: Trevor E. Pogue, Nicola Nicolici</li>
<li>For: The paper is written for improving the performance of machine learning (ML) models by proposing a new algorithm called Free-pipeline Fast Inner Product (FFIP) and its hardware architecture.* Methods: The paper uses an under-explored fast inner-product algorithm (FIP) proposed by Winograd in 1968, and implements it for the first time in an ML accelerator. The authors also propose a new algorithm called FFIP and a generalized architecture that improves FIP’s clock frequency and throughput for a similar hardware cost.* Results: The paper shows that FFIP can be seamlessly incorporated into traditional fixed-point systolic array ML accelerators to achieve the same throughput with half the number of multiply-accumulate (MAC) units, or it can double the maximum systolic array size that can fit onto devices with a fixed hardware budget. The authors also demonstrate that their FFIP implementation for non-sparse ML models with 8 to 16-bit fixed-point inputs achieves higher throughput and compute efficiency than the best-in-class prior solutions on the same type of compute platform.Here are the three key points in Simplified Chinese:* For: 本文是为了提高机器学习（ML）模型的性能，提出了一种新的算法called Free-pipeline Fast Inner Product（FFIP）和其硬件体系结构。* Methods: 本文使用了一种尚未得到充分研究的快速内积算法（FIP），并在 ML 加速器中实现了它。作者们还提出了一种新的算法called FFIP 和一种通用的体系结构，可以提高 FIP 的时钟频率和吞吐量，同时保持相同的硬件成本。* Results: 本文表明，FFIP 可以轻松地与传统的 fixed-point systolic array ML 加速器集成，以 достиieving the same throughput with half the number of multiply-accumulate（MAC）单元，或者 doubles the maximum systolic array size that can fit onto devices with a fixed hardware budget。作者们还证明了他们的 FFIP 实现对非零杂质 ML 模型的 8 到 16 位 fixed-point 输入实现了更高的throughput和计算效率，比最佳类型的计算平台上的先前解决方案更好。<details>
<summary>Abstract</summary>
We introduce a new algorithm called the Free-pipeline Fast Inner Product (FFIP) and its hardware architecture that improve an under-explored fast inner-product algorithm (FIP) proposed by Winograd in 1968. Unlike the unrelated Winograd minimal filtering algorithms for convolutional layers, FIP is applicable to all machine learning (ML) model layers that can mainly decompose to matrix multiplication, including fully-connected, convolutional, recurrent, and attention/transformer layers. We implement FIP for the first time in an ML accelerator then present our FFIP algorithm and generalized architecture which inherently improve FIP's clock frequency and, as a consequence, throughput for a similar hardware cost. Finally, we contribute ML-specific optimizations for the FIP and FFIP algorithms and architectures. We show that FFIP can be seamlessly incorporated into traditional fixed-point systolic array ML accelerators to achieve the same throughput with half the number of multiply-accumulate (MAC) units, or it can double the maximum systolic array size that can fit onto devices with a fixed hardware budget. Our FFIP implementation for non-sparse ML models with 8 to 16-bit fixed-point inputs achieves higher throughput and compute efficiency than the best-in-class prior solutions on the same type of compute platform.
</details>
<details>
<summary>摘要</summary>
我们介绍一种新的算法 called Free-pipeline Fast Inner Product (FFIP) 和其硬件架构，该算法可以提高Winograd在1968年提出的快速内积算法（FIP）的性能。与涉及到卷积层的Winograd最小滤波算法不同，FIP可以应用于所有机器学习（ML）模型层，包括完全连接层、卷积层、回卷层和注意力/转换器层。我们在ML加速器上实现了FIP，然后提出了我们的FFIP算法和通用架构，这两者都可以提高FIP的时钟频率和通过put，同时具有相同的硬件成本。最后，我们对FIP和FFIP算法和架构进行了特定于ML的优化。我们展示了FFIP可以轻松地与传统的 fixes-point systolic array ML加速器结合使用，以实现同样的throughput，但使用的MAC单元数量减半，或者 doublesystolic array的最大大小，可以在设备上匹配的硬件预算内。我们对具有8到16位Fixed-point输入的非稀盐ML模型进行了实现，并取得了与同类 compute平台上的最佳前一solution相同或更高的throughput和计算效率。
</details></li>
</ul>
<hr>
<h2 id="Digital-Twin-Based-User-Centric-Edge-Continual-Learning-in-Integrated-Sensing-and-Communication"><a href="#Digital-Twin-Based-User-Centric-Edge-Continual-Learning-in-Integrated-Sensing-and-Communication" class="headerlink" title="Digital Twin-Based User-Centric Edge Continual Learning in Integrated Sensing and Communication"></a>Digital Twin-Based User-Centric Edge Continual Learning in Integrated Sensing and Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12223">http://arxiv.org/abs/2311.12223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shisheng Hu, Jie Gao, Xinyu Huang, Mushu Li, Kaige Qu, Conghao Zhou, Xuemin, Shen</li>
<li>for: 这篇论文旨在提出一个基于数位双（DT）的使用者中心方法，用于处理感应数据，并实现高精度和有效资源使用。</li>
<li>methods: 这篇论文使用了一个轻量级的深度神经网络（DNN）和一个移动边缘计算（MEC）服务器，并将感应数据上传到服务器进行更高精度的处理。为了处理数据漂移，服务器会在必要时更新轻量级DNN， referred to as continual learning。</li>
<li>results: 经过实验显示，提出的DT基于方法可以实现 computation cost minimization，并且在执行DNN基于人姿识别任务时表现出色。<details>
<summary>Abstract</summary>
In this paper, we propose a digital twin (DT)-based user-centric approach for processing sensing data in an integrated sensing and communication (ISAC) system with high accuracy and efficient resource utilization. The considered scenario involves an ISAC device with a lightweight deep neural network (DNN) and a mobile edge computing (MEC) server with a large DNN. After collecting sensing data, the ISAC device either processes the data locally or uploads them to the server for higher-accuracy data processing. To cope with data drifts, the server updates the lightweight DNN when necessary, referred to as continual learning. Our objective is to minimize the long-term average computation cost of the MEC server by optimizing two decisions, i.e., sensing data offloading and sensing data selection for the DNN update. A DT of the ISAC device is constructed to predict the impact of potential decisions on the long-term computation cost of the server, based on which the decisions are made with closed-form formulas. Experiments on executing DNN-based human motion recognition tasks are conducted to demonstrate the outstanding performance of the proposed DT-based approach in computation cost minimization.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了基于数字双（DT）的用户中心的方法，用于处理感知数据在集成感知通信（ISAC）系统中，并且具有高精度和有效资源利用。我们考虑的场景是一个具有轻量级深度学习网络（DNN）的ISAC设备，以及一个具有大型DNN的移动边缘计算（MEC）服务器。在收集感知数据后，ISAC设备会选择是在本地处理数据，或者上传到服务器进行更高精度的数据处理。为了应对数据漂移，服务器会在必要时更新轻量级DNN，称为 kontinual learning。我们的目标是将MEC服务器的长期平均计算成本降低到最低水平，通过优化两个决策：感知数据上载和感知数据选择，以便更新DNN。一个DT的ISAC设备是建立，以预测可能的决策对MEC服务器的长期计算成本产生的影响，并根据这些预测结果，制定了关闭式公式来做出决策。我们对执行基于DNN的人体运动识别任务进行了实验，以证明我们提出的DT-基于方法在计算成本减少方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Defense-semantics-of-argumentation-revisit"><a href="#Defense-semantics-of-argumentation-revisit" class="headerlink" title="Defense semantics of argumentation: revisit"></a>Defense semantics of argumentation: revisit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12207">http://arxiv.org/abs/2311.12207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Beishui Liao, Leendert van der Torre</li>
<li>for: 本研究提出了一种新的 semantics，即防御 semantics，用于杜氏抽象论证框架中的一种受到部分防御的论证 triple encoding。</li>
<li>methods: 本研究使用了防御 semantics 来研究批判的自我攻击和三角形的批判，并提出了一种新的防御相等性的定义。</li>
<li>results: 本研究发现了一些不可满足的防御，并提出了一种基于防御 semantics 的论证概要化方法。<details>
<summary>Abstract</summary>
In this paper we introduce a novel semantics, called defense semantics, for Dung's abstract argumentation frameworks in terms of a notion of (partial) defence, which is a triple encoding that one argument is (partially) defended by another argument via attacking the attacker of the first argument. In terms of defense semantics, we show that defenses related to self-attacked arguments and arguments in 3-cycles are unsatifiable under any situation and therefore can be removed without affecting the defense semantics of an AF. Then, we introduce a new notion of defense equivalence of AFs, and compare defense equivalence with standard equivalence and strong equivalence, respectively. Finally, by exploiting defense semantics, we define two kinds of reasons for accepting arguments, i.e., direct reasons and root reasons, and a notion of root equivalence of AFs that can be used in argumentation summarization.
</details>
<details>
<summary>摘要</summary>
在本文中，我们引入了一种新的 semantics，即防御 semantics，用于杜нг的抽象口头论证框架中的一种幂等，其中一个Argument被另一个Argument部分防御，通过攻击该Argument的攻击者。在防御 semantics 中，我们表明了自我攻击的论证和3-cycle中的论证是不可满足的，因此可以无需考虑这些论证。然后，我们引入了一种新的论证相等性（defense equivalence），并与标准相等性和强相等性进行比较。最后，通过利用防御 semantics，我们定义了两种接受论证的理由：直接理由和根理由，以及一种论证相等性的概念，可以用于口头论证概要化。
</details></li>
</ul>
<hr>
<h2 id="Nepotistically-Trained-Generative-AI-Models-Collapse"><a href="#Nepotistically-Trained-Generative-AI-Models-Collapse" class="headerlink" title="Nepotistically Trained Generative-AI Models Collapse"></a>Nepotistically Trained Generative-AI Models Collapse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12202">http://arxiv.org/abs/2311.12202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matyas Bohacek, Hany Farid</li>
<li>for: 这个论文主要用于探讨人工智能图像生成器 retrained 后的表现。</li>
<li>methods: 该论文使用了大量的人工生成内容来训练 AI 图像生成器，并在这些模型 retrained 后发现它们会生成高度扭曲的图像。</li>
<li>results: 研究发现， retrained 后的模型会生成高度扭曲的图像，并且这种扭曲不仅限于使用的文本提示，而且会影响整个图像的表现。此外，已经恶化的模型即使在重新训练于真实图像上也难以恢复原状。<details>
<summary>Abstract</summary>
Trained on massive amounts of human-generated content, AI (artificial intelligence) image synthesis is capable of reproducing semantically coherent images that match the visual appearance of its training data. We show that when retrained on even small amounts of their own creation, these generative-AI models produce highly distorted images. We also show that this distortion extends beyond the text prompts used in retraining, and that once poisoned, the models struggle to fully heal even after retraining on only real images.
</details>
<details>
<summary>摘要</summary>
<<SYS>>用大量人工生成的内容训练，AI图像生成器可以生成具有Semantic coherence的图像，与训练数据的视觉外观相匹配。我们显示，当 retrained  наeven small amounts of their own creation，这些生成-AI模型会生成高度扭曲的图像。我们还显示，这种扭曲不仅局限于用于 retrained 的文本提示，而且这些模型一旦被毒化，即使在仅使用真实图像进行重训练，也难以完全恢复。Note: "毒化" (poisoned) in the text refers to the situation where the AI model is trained on inappropriate or misleading data, which can cause the model to produce distorted or incorrect output.
</details></li>
</ul>
<hr>
<h2 id="PhysGaussian-Physics-Integrated-3D-Gaussians-for-Generative-Dynamics"><a href="#PhysGaussian-Physics-Integrated-3D-Gaussians-for-Generative-Dynamics" class="headerlink" title="PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics"></a>PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12198">http://arxiv.org/abs/2311.12198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyi Xie, Zeshun Zong, Yuxin Qiu, Xuan Li, Yutao Feng, Yin Yang, Chenfanfu Jiang</li>
<li>for: PhysGaussian is a new method for achieving high-quality novel motion synthesis by integrating physically grounded Newtonian dynamics within 3D Gaussians.</li>
<li>methods: PhysGaussian employs a custom Material Point Method (MPM) to enrich 3D Gaussian kernels with physically meaningful kinematic deformation and mechanical stress attributes, all evolved in line with continuum mechanics principles.</li>
<li>results: The method demonstrates exceptional versatility across a wide variety of materials, showcasing its strong capabilities in creating diverse visual content with novel viewpoints and movements.Here is the same information in Simplified Chinese text:</li>
<li>for: PhysGaussian 是一种新的方法，用于实现高质量的新动作 sintesis，通过在3D Gaussians 中绑定物理基础 Newtonian 动力学。</li>
<li>methods: PhysGaussian 使用自定义的 Material Point Method (MPM)，以抽象 3D Gaussian 函数中的物理意义的剪枝减压和机械压缩特性，所有在continuum mechanics 原理下演化。</li>
<li>results: PhysGaussian 方法在各种材料上显示出了强大的多样性，包括弹簧体、金属、非牛顿流体和尘埃材料，并且能够创造出多种视觉内容，包括新的视角和运动。<details>
<summary>Abstract</summary>
We introduce PhysGaussian, a new method that seamlessly integrates physically grounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel motion synthesis. Employing a custom Material Point Method (MPM), our approach enriches 3D Gaussian kernels with physically meaningful kinematic deformation and mechanical stress attributes, all evolved in line with continuum mechanics principles. A defining characteristic of our method is the seamless integration between physical simulation and visual rendering: both components utilize the same 3D Gaussian kernels as their discrete representations. This negates the necessity for triangle/tetrahedron meshing, marching cubes, "cage meshes," or any other geometry embedding, highlighting the principle of "what you see is what you simulate (WS$^2$)." Our method demonstrates exceptional versatility across a wide variety of materials--including elastic entities, metals, non-Newtonian fluids, and granular materials--showcasing its strong capabilities in creating diverse visual content with novel viewpoints and movements. Our project page is at: https://xpandora.github.io/PhysGaussian/
</details>
<details>
<summary>摘要</summary>
我们介绍PhysGaussian，一种新的方法，可以内置物理基础的新顿动力学在3D Gaussian中实现高质量的新动作 sintesis。我们的方法使用自定义的物点方法（MPM），将3D Gaussian kernel给予物理意义的几何对象和机械压力属性，并与流体力学原理一致地进行演算。PhysGaussian的一个特点是让visual rendering和物理 simulated互相使用同一个3D Gaussian kernel作为粗糙表示，这标志着"你看到的就是你实际上实现"的原则（WS$^2）。我们的方法在不同材料中展示了出色的多样性，包括弹性体、金属、非新顿流体和尘质物质，并证明了它在创造多种视角和运动的丰富可见性。我们的项目页面位于：https://xpandora.github.io/PhysGaussian/
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-and-post-test-probability"><a href="#ChatGPT-and-post-test-probability" class="headerlink" title="ChatGPT and post-test probability"></a>ChatGPT and post-test probability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12188">http://arxiv.org/abs/2311.12188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel J. Weisenthal</li>
<li>for: 这篇论文旨在测试ChatGPT是否能够进行形式概率医疗诊断推理，以及如何使用Bayes规则进行医疗诊断。</li>
<li>methods: 这篇论文使用ChatGPT进行推理，并提供了一些医疗诊断查询，以测试ChatGPT的能力。</li>
<li>results: 研究发现，当医疗诊断查询中使用医疗特有的词汇时，ChatGPT的错误率会增加。然而，通过几何工程来设计提示，可以帮助ChatGPT部分避免这些错误。<details>
<summary>Abstract</summary>
Reinforcement learning-based large language models, such as ChatGPT, are believed to have potential to aid human experts in many domains, including healthcare. There is, however, little work on ChatGPT's ability to perform a key task in healthcare: formal, probabilistic medical diagnostic reasoning. This type of reasoning is used, for example, to update a pre-test probability to a post-test probability. In this work, we probe ChatGPT's ability to perform this task. In particular, we ask ChatGPT to give examples of how to use Bayes rule for medical diagnosis. Our prompts range from queries that use terminology from pure probability (e.g., requests for a "posterior probability") to queries that use terminology from the medical diagnosis literature (e.g., requests for a "post-test probability"). We show how the introduction of medical variable names leads to an increase in the number of errors that ChatGPT makes. Given our results, we also show how one can use prompt engineering to facilitate ChatGPT's partial avoidance of these errors. We discuss our results in light of recent commentaries on sensitivity and specificity. We also discuss how our results might inform new research directions for large language models.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型，如ChatGPT，believed to have potential to aid human experts in many domains, including healthcare. However, there is little work on ChatGPT's ability to perform a key task in healthcare: 形式抽象医学诊断思维。这种思维是用于更新先前概率到后测概率的。在这项工作中，我们探究ChatGPT的能力来执行这个任务。我们问ChatGPT给出医学诊断中使用杯因之则的示例。我们的提示从普适概率中的词汇（例如，"后测概率"）到医学诊断文献中的词汇（例如，"后测概率"）。我们发现，在医学变量名导入后，ChatGPT的错误率增加。根据我们的结果，我们还示出了如何使用提示工程来facilitate ChatGPT的部分避免错误。我们讨论我们的结果与最近的敏感性和特点的评论相关。我们还讨论如何将我们的结果引入新的大语言模型研究方向。
</details></li>
</ul>
<hr>
<h2 id="Common-good-practices-measuring-trust-in-HRI"><a href="#Common-good-practices-measuring-trust-in-HRI" class="headerlink" title="Common (good) practices measuring trust in HRI"></a>Common (good) practices measuring trust in HRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12182">http://arxiv.org/abs/2311.12182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Holthaus, Alessandra Rossi</li>
<li>for: 本研究旨在探讨人们对机器人的信任程度，以便更好地理解人机合作的情境和满意度。</li>
<li>methods: 本研究使用了现有的信任量测试方法，包括文本描述和图像测试，以衡量人们对机器人的信任程度。</li>
<li>results: 研究发现，人们对机器人的信任程度受到许多因素的影响，包括机器人的能力和可靠性、交互情境和任务等。同时，研究还发现现有的信任量测试方法存在一些不足之处，需要进一步的改进和扩展。<details>
<summary>Abstract</summary>
Trust in robots is widely believed to be imperative for the adoption of robots into people's daily lives. It is, therefore, understandable that the literature of the last few decades focuses on measuring how much people trust robots -- and more generally, any agent - to foster such trust in these technologies. Researchers have been exploring how people trust robot in different ways, such as measuring trust on human-robot interactions (HRI) based on textual descriptions or images without any physical contact, during and after interacting with the technology. Nevertheless, trust is a complex behaviour, and it is affected and depends on several factors, including those related to the interacting agents (e.g. humans, robots, pets), itself (e.g. capabilities, reliability), the context (e.g. task), and the environment (e.g. public spaces vs private spaces vs working spaces). In general, most roboticists agree that insufficient levels of trust lead to a risk of disengagement while over-trust in technology can cause over-reliance and inherit dangers, for example, in emergency situations. It is, therefore, very important that the research community has access to reliable methods to measure people's trust in robots and technology. In this position paper, we outline current methods and their strengths, identify (some) weakly covered aspects and discuss the potential for covering a more comprehensive amount of factors influencing trust in HRI.
</details>
<details>
<summary>摘要</summary>
信任机器人被广泛认为是人工智能技术的采用的关键因素。因此，文献上最近几十年的研究都集中在测量人们对机器人的信任——更广泛地说，任何代理人——以促进这些技术的采用。研究人员在不同的方式测量人们对机器人的信任，例如基于文本描述或图像无physical contact的人机交互（HRI）中的信任。然而，信任是复杂的行为，它受到多种因素的影响和依赖，包括交互代理人（如人、机器人、宠物）、自身（如能力、可靠性）、 Context（如任务）和环境（如公共空间、私人空间、工作空间）。大多数机器人学家认为，不足的信任会导致技术离别，而过度信任可能会导致过度依赖和固有危险，例如在紧急情况下。因此，研究社区需要可靠的方法来测量人们对机器人的信任。在这篇Position paper中，我们介绍当前的方法和其优点，识别一些不足的方面，并讨论涵盖更广泛的信任因素的潜在可能性。
</details></li>
</ul>
<hr>
<h2 id="Conditional-Modeling-Based-Automatic-Video-Summarization"><a href="#Conditional-Modeling-Based-Automatic-Video-Summarization" class="headerlink" title="Conditional Modeling Based Automatic Video Summarization"></a>Conditional Modeling Based Automatic Video Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12159">http://arxiv.org/abs/2311.12159</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Hong Huang, Chao-Han Huck Yang, Pin-Yu Chen, Min-Hung Chen, Marcel Worring</li>
<li>for: 缩短视频自动化，以保留关键信息并传达整个故事的核心。</li>
<li>methods: 基于人类创建真实视频摘要的知识，提出了一种新的视频摘要方法，包括多个有意义的随机变量和共同分布来描述视频摘要的关键组成部分。</li>
<li>results: 对常用的视频摘要数据集进行了广泛的实验，并 показа了该方法可以超过现有方法，达到视频摘要的州OF-THE-ART性能。<details>
<summary>Abstract</summary>
The aim of video summarization is to shorten videos automatically while retaining the key information necessary to convey the overall story. Video summarization methods mainly rely on visual factors, such as visual consecutiveness and diversity, which may not be sufficient to fully understand the content of the video. There are other non-visual factors, such as interestingness, representativeness, and storyline consistency that should also be considered for generating high-quality video summaries. Current methods do not adequately take into account these non-visual factors, resulting in suboptimal performance. In this work, a new approach to video summarization is proposed based on insights gained from how humans create ground truth video summaries. The method utilizes a conditional modeling perspective and introduces multiple meaningful random variables and joint distributions to characterize the key components of video summarization. Helper distributions are employed to improve the training of the model. A conditional attention module is designed to mitigate potential performance degradation in the presence of multi-modal input. The proposed video summarization method incorporates the above innovative design choices that aim to narrow the gap between human-generated and machine-generated video summaries. Extensive experiments show that the proposed approach outperforms existing methods and achieves state-of-the-art performance on commonly used video summarization datasets.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a new approach to video summarization based on insights from human-created ground truth summaries. Our method uses a conditional modeling perspective and introduces multiple meaningful random variables and joint distributions to characterize the key components of video summarization. We also employ helper distributions to improve the training of the model. A conditional attention module is designed to mitigate potential performance degradation in the presence of multi-modal input.Our proposed video summarization method incorporates several innovative design choices that aim to narrow the gap between human-generated and machine-generated video summaries. Extensive experiments show that our approach outperforms existing methods and achieves state-of-the-art performance on commonly used video summarization datasets.
</details></li>
</ul>
<hr>
<h2 id="User-Like-Bots-for-Cognitive-Automation-A-Survey"><a href="#User-Like-Bots-for-Cognitive-Automation-A-Survey" class="headerlink" title="User-Like Bots for Cognitive Automation: A Survey"></a>User-Like Bots for Cognitive Automation: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12154">http://arxiv.org/abs/2311.12154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Habtom Kahsay Gidey, Peter Hillmann, Andreas Karcher, Alois Knoll</li>
<li>for: 本研究旨在探讨软件机器人的高级通用智能工程，以及如何通过认知架构支持这些工程。</li>
<li>methods: 本研究使用了许多不同的认知架构，以探讨它们如何支持软件机器人的智能行为。</li>
<li>results: 研究发现，使用认知架构可以帮助软件机器人更好地理解和利用多个虚拟环境的便利功能，从而实现更高级的自主智能行为。<details>
<summary>Abstract</summary>
Software bots have attracted increasing interest and popularity in both research and society. Their contributions span automation, digital twins, game characters with conscious-like behavior, and social media. However, there is still a lack of intelligent bots that can adapt to web environments' variability and dynamic nature. Unlike human users, they have difficulty understanding and exploiting the affordances across multiple virtual environments.   Despite the hype, bots with human user-like cognition do not currently exist. Chatbots, for instance, lack situational awareness on the digital platforms where they operate, preventing them from enacting meaningful and autonomous intelligent behavior similar to human users.   In this survey, we aim to explore the role of cognitive architectures in supporting efforts towards engineering software bots with advanced general intelligence. We discuss how cognitive architectures can contribute to creating intelligent software bots. Furthermore, we highlight key architectural recommendations for the future development of autonomous, user-like cognitive bots.
</details>
<details>
<summary>摘要</summary>
软件机器人在研究和社会中受到越来越多的关注和欢迎。它们的贡献包括自动化、数字双胞胎、游戏角色具有意识型行为和社交媒体。然而，目前还缺乏智能机器人，能够适应网络环境的变化和动态性。与人类用户不同，机器人困难理解和利用多个虚拟环境中的便利。尽管有很多赞美，但是机器人与人类用户类似的认知仍然不存在。聊天机器人，例如，在数字平台上缺乏情况意识，使其无法展现出类似人类用户的智能行为。在本调查中，我们想要探索软件机器人的高级通用智能的工程准备。我们讨论了如何使用认知架构来支持高级通用智能机器人的开发。此外，我们也强调了未来开发自主、用户类似认知机器人的关键建筑方案。
</details></li>
</ul>
<hr>
<h2 id="Teaching-Robots-to-Build-Simulations-of-Themselves"><a href="#Teaching-Robots-to-Build-Simulations-of-Themselves" class="headerlink" title="Teaching Robots to Build Simulations of Themselves"></a>Teaching Robots to Build Simulations of Themselves</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12151">http://arxiv.org/abs/2311.12151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhang Hu, Jiong Lin, Hod Lipson</li>
<li>for: robots to plan and estimate the outcomes of prospective actions without physically executing them</li>
<li>methods: self-supervised learning framework using brief raw video data</li>
<li>results: accurate motion planning and detection of abnormalities&#x2F;recovery from damage<details>
<summary>Abstract</summary>
Simulation enables robots to plan and estimate the outcomes of prospective actions without the need to physically execute them. We introduce a self-supervised learning framework to enable robots model and predict their morphology, kinematics and motor control using only brief raw video data, eliminating the need for extensive real-world data collection and kinematic priors. By observing their own movements, akin to humans watching their reflection in a mirror, robots learn an ability to simulate themselves and predict their spatial motion for various tasks. Our results demonstrate that this self-learned simulation not only enables accurate motion planning but also allows the robot to detect abnormalities and recover from damage.
</details>
<details>
<summary>摘要</summary>
使用模拟可以让机器人规划和估算未来行动的结果，不需要物理执行。我们介绍了一种自我超级学习框架，使机器人通过短暴露视频数据自学模型和预测自己的形态、运动和动力控制，从而消除了大量实际世界数据收集和遥感估计。机器人通过观察自己的运动，类似于人类在镜中观察自己，学习了模拟自己的能力，并且可以准确规划运动和检测异常。我们的结果表明，自学 simulate 不仅允许精准的运动规划，还允许机器人恢复自身损害。
</details></li>
</ul>
<hr>
<h2 id="Mixing-Denoising-Generalizable-Occupancy-Networks"><a href="#Mixing-Denoising-Generalizable-Occupancy-Networks" class="headerlink" title="Mixing-Denoising Generalizable Occupancy Networks"></a>Mixing-Denoising Generalizable Occupancy Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12125">http://arxiv.org/abs/2311.12125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amine Ouasfi, Adnane Boukhayma</li>
<li>for: 这篇论文旨在探讨如何使用多层感知（MLP）来实现三维形状重建从点云数据中，并以快速的前向传播来实现推理。</li>
<li>methods: 该论文使用了一种新的方法，即将MLP用于编码本地特征，而不是 convolutional neural networks（CNN）。这种方法可以减少模型的参数数量，并通过在推理过程中使用减噪正则化来提高模型的泛化能力。</li>
<li>results: 根据论文的结果，使用MLP编码本地特征和减噪正则化可以在三维形状重建 task 上达到比使用 CNN 更高的性能，并且使用的模型参数数量只是使用 CNN 的一半。<details>
<summary>Abstract</summary>
While current state-of-the-art generalizable implicit neural shape models rely on the inductive bias of convolutions, it is still not entirely clear how properties emerging from such biases are compatible with the task of 3D reconstruction from point cloud. We explore an alternative approach to generalizability in this context. We relax the intrinsic model bias (i.e. using MLPs to encode local features as opposed to convolutions) and constrain the hypothesis space instead with an auxiliary regularization related to the reconstruction task, i.e. denoising. The resulting model is the first only-MLP locally conditioned implicit shape reconstruction from point cloud network with fast feed forward inference. Point cloud borne features and denoising offsets are predicted from an exclusively MLP-made network in a single forward pass. A decoder predicts occupancy probabilities for queries anywhere in space by pooling nearby features from the point cloud order-invariantly, guided by denoised relative positional encoding. We outperform the state-of-the-art convolutional method while using half the number of model parameters.
</details>
<details>
<summary>摘要</summary>
当前最新的通用隐藏型神经形态模型，它们靠 inductive bias 来实现通用性。然而，这些特性如何与点云 reconstruction 任务相容，仍然不是 entirely clear。我们explore 一种 alternativeto 通用性的方法。我们将本地特征编码使用 MLP 而不是 convolutions，并使用 auxiliary regularization 来约束假设空间。这导致了首个只有 MLP 的本地条件隐藏形态重建从点云网络，具有快速前向推理。从点云中生成的特征和denoising offset 都是通过 exclusively MLP-made 网络在单个前进 pass 预测的。一个解码器在空间中任意位置预测 queries 的占据概率，通过 pooling  nearby features 从点云中order-invariantly，以denoised relative positional encoding 为导航。我们在使用一半数量的模型参数时超越了状态的 convolutional 方法。
</details></li>
</ul>
<hr>
<h2 id="Hourglass-Tokenizer-for-Efficient-Transformer-Based-3D-Human-Pose-Estimation"><a href="#Hourglass-Tokenizer-for-Efficient-Transformer-Based-3D-Human-Pose-Estimation" class="headerlink" title="Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation"></a>Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12028">http://arxiv.org/abs/2311.12028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhao Li, Mengyuan Liu, Hong Liu, Pichao Wang, Jialun Cai, Nicu Sebe</li>
<li>for: 这个论文目的是提出一种高效的Transformers-based 3D人姿估计方法，以提高资源受限的设备上的计算效率。</li>
<li>methods: 这个方法使用了一种名为Hourglass Tokenizer (HoT)的插件和恢复框架，包括干扰减少和恢复Token Pruning Cluster (TPC)和Token Recovering Attention (TRA)等技术，以提高模型的效率。</li>
<li>results: 对于两个标准数据集（Human3.6M和MPI-INF-3DHP）的实验结果表明，这种方法可以同时实现高效和准确的3D人姿估计，比原始VPT模型更高效，并且可以适应资源受限的设备。例如，在应用于MotionBERT和MixSTE模型上，HoT可以将计算量减少约50% без损失精度，或者减少约40%的计算量，仅减少精度0.2%。<details>
<summary>Abstract</summary>
Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a plug-and-play pruning-and-recovering framework, called Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose estimation from videos. Our HoT begins with pruning pose tokens of redundant frames and ends with recovering full-length tokens, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. To effectively achieve this, we propose a token pruning cluster (TPC) that dynamically selects a few representative tokens with high semantic diversity while eliminating the redundancy of video frames. In addition, we develop a token recovering attention (TRA) to restore the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and MPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and estimation accuracy compared to the original VPT models. For instance, applying to MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs without sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop, respectively. Our source code will be open-sourced.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Transformers 已经成功应用于视频基于三维人体姿态估计领域。然而，高计算成本使得这些视频pose transformers (VPTs) 在有限资源设备上无法实现。在这篇论文中，我们提出了一个插件化剪辑恢复框架，called Hourglass Tokenizer (HoT)，用于高效的 transformer 基于三维人体姿态估计从视频中。我们的 HoT 从剪辑姿态token 的剪辑框架中开始，并结束于恢复全长姿态token，从而在转换器中减少一些姿态token，提高模型的效率。为了实现这一点，我们提出了一个姿态剪辑集 (TPC)，可以动态选择一些具有高Semantic 多样性的姿态token，同时消除视频帧中的重复性。此外，我们开发了一个姿态恢复注意力 (TRA)，以便基于选择的姿态token 还原细致的空间时间信息，从而扩展网络输出到原始的全长时间分辨率，以便快速的推理。我们的实验表明，对于 Human3.6M 和 MPI-INF-3DHP 两个标准数据集，我们的方法可以实现高效和估计精度，比如对于 MotionBERT 和 MixSTE 模型，我们的 HoT 可以将 FLOPs 减少约 50% 不 sacrificing 精度，或者将 FLOPs 减少约 40% 只有 0.2% 精度下降。我们的源代码将被开源。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="GPQA-A-Graduate-Level-Google-Proof-Q-A-Benchmark"><a href="#GPQA-A-Graduate-Level-Google-Proof-Q-A-Benchmark" class="headerlink" title="GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark"></a>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12022">http://arxiv.org/abs/2311.12022</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idavidrein/gpqa">https://github.com/idavidrein/gpqa</a></li>
<li>paper_authors: David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman</li>
<li>for: 这个论文的目的是提供一个高难度的多选问答集，用于测试人工智能系统的能力和超越人类水平。</li>
<li>methods: 论文使用了448个生物、物理和化学领域专家写的多选问题，并确保这些问题的质量非常高，难度极大。</li>
<li>results: 论文发现，即使使用最新的GPT-4模型，AI系统的答案准确率只有39%，而专家和非专家评审人员的答案准确率分别为65%和34%。这表明AI系统需要更多的监督和审核，以确保它们可以提供可靠的信息。<details>
<summary>Abstract</summary>
We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are "Google-proof"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.
</details>
<details>
<summary>摘要</summary>
我们提供了GPQA数据集，包含448个多选问题，由领域专家写作生物、物理和化学领域。我们确保这些问题的质量非常高，极其困难：有或者在追求PhD的专家只有65%的准确率（74%不计算明显的错误），而高水平的非专家验证人员只有34%的准确率，尽管他们平均花费超过30分钟，并且有无限时间在网上查询（即问题是"Google-proof"）。这些问题也对当前AI系统来说很困难，我们最强的GPT-4基础模型只达39%的准确率。如果我们想用未来的AI系统来帮助我们回答非常困难的问题，例如在发展新科学知识时，我们需要开发可扩展的监督方法，使人类可以监督AI系统的输出，这可能是非常困难，即使监督人员本身具备高水平的技能和知识。GPQA的困难程度不仅对非专家和前沿AI系统来说，也可以为我们进行可扩展的监督实验，我们希望通过这些实验找到一种可靠地从AI系统获取真实信息的方法，以便在AI系统超越人类能力时，人类专家可以得到可靠的信息。
</details></li>
</ul>
<hr>
<h2 id="Steering-Responsible-AI-A-Case-for-Algorithmic-Pluralism"><a href="#Steering-Responsible-AI-A-Case-for-Algorithmic-Pluralism" class="headerlink" title="Steering Responsible AI: A Case for Algorithmic Pluralism"></a>Steering Responsible AI: A Case for Algorithmic Pluralism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12010">http://arxiv.org/abs/2311.12010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefaan G. Verhulst</li>
<li>for: 这篇论文探讨人工智能中立性的问题，通过现有的媒体多元性和媒体媒体多元性的学术研究。</li>
<li>methods: 该论文使用现有的媒体多元性和媒体媒体多元性的学术研究来探讨人工智能中立性。</li>
<li>results: 该论文提出了对algorithmic pluralism的描述，并评估了这种概念的机遇和挑战。<details>
<summary>Abstract</summary>
In this paper, I examine questions surrounding AI neutrality through the prism of existing literature and scholarship about mediation and media pluralism. Such traditions, I argue, provide a valuable theoretical framework for how we should approach the (likely) impending era of AI mediation. In particular, I suggest examining further the notion of algorithmic pluralism. Contrasting this notion to the dominant idea of algorithmic transparency, I seek to describe what algorithmic pluralism may be, and present both its opportunities and challenges. Implemented thoughtfully and responsibly, I argue, Algorithmic or AI pluralism has the potential to sustain the diversity, multiplicity, and inclusiveness that are so vital to democracy.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我通过现有的文献和学术研究关于媒介和多元媒体来探讨人工智能中立性的问题。这些传统，我 Argument that they provide a valuable theoretical framework for how we should approach the (likely) impending era of AI mediation. 特别是，我 suggets examining further the notion of algorithmic pluralism. 对于 dominant idea of algorithmic transparency，我 seek to describe what algorithmic pluralism may be, and present both its opportunities and challenges. 如果实施得当和负责任，我 Argument that algorithmic or AI pluralism has the potential to sustain the diversity, multiplicity, and inclusiveness that are so vital to democracy.Note: Please keep in mind that the translation is done by a machine and may not be perfect. Also, the grammar and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="BrainWash-A-Poisoning-Attack-to-Forget-in-Continual-Learning"><a href="#BrainWash-A-Poisoning-Attack-to-Forget-in-Continual-Learning" class="headerlink" title="BrainWash: A Poisoning Attack to Forget in Continual Learning"></a>BrainWash: A Poisoning Attack to Forget in Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11995">http://arxiv.org/abs/2311.11995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Abbasi, Parsa Nooralinejad, Hamed Pirsiavash, Soheil Kolouri</li>
<li>for: 本研究旨在探讨深度学习中的连续学习方法在面对敌意攻击时的抵触性。</li>
<li>methods: 本研究提出了一种新的数据损害方法，称为“BrainWash”，可以让连续学习模型忘记先前学习的任务。该方法不需要攻击者有过去任务的数据访问权限，只需要使用当前模型参数和最新任务的数据即可。</li>
<li>results: 实验结果表明，BrainWash方法可以成功地让连续学习模型忘记先前学习的任务，并且可以让模型在不同的常规化学习方法下表现出较差的性能。<details>
<summary>Abstract</summary>
Continual learning has gained substantial attention within the deep learning community, offering promising solutions to the challenging problem of sequential learning. Yet, a largely unexplored facet of this paradigm is its susceptibility to adversarial attacks, especially with the aim of inducing forgetting. In this paper, we introduce "BrainWash," a novel data poisoning method tailored to impose forgetting on a continual learner. By adding the BrainWash noise to a variety of baselines, we demonstrate how a trained continual learner can be induced to forget its previously learned tasks catastrophically, even when using these continual learning baselines. An important feature of our approach is that the attacker requires no access to previous tasks' data and is armed merely with the model's current parameters and the data belonging to the most recent task. Our extensive experiments highlight the efficacy of BrainWash, showcasing degradation in performance across various regularization-based continual learning methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>> simultaeneously learning has gained substantial attention within the deep learning community, offering promising solutions to the challenging problem of sequential learning. Yet, a largely unexplored facet of this paradigm is its susceptibility to adversarial attacks, especially with the aim of inducing forgetting. In this paper, we introduce "BrainWash," a novel data poisoning method tailored to impose forgetting on a continual learner. By adding the BrainWash noise to a variety of baselines, we demonstrate how a trained continual learner can be induced to forget its previously learned tasks catastrophically, even when using these continual learning baselines. An important feature of our approach is that the attacker requires no access to previous tasks' data and is armed merely with the model's current parameters and the data belonging to the most recent task. Our extensive experiments highlight the efficacy of BrainWash, showcasing degradation in performance across various regularization-based continual learning methods.Translated by Google Translate.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Lip-Segmentation-Techniques-in-Computer-Vision-A-Comparative-Analysis"><a href="#Exploring-Lip-Segmentation-Techniques-in-Computer-Vision-A-Comparative-Analysis" class="headerlink" title="Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis"></a>Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11992">http://arxiv.org/abs/2311.11992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro B. S. Masur, Francisco Braulio Oliveira, Lucas Moreira Medino, Emanuel Huber, Milene Haraguchi Padilha, Cassio de Alcantara, Renata Sellaro</li>
<li>for:  lip segmentation  lip reading</li>
<li>methods:  EHANet Mask2Former BiSeNet V2 PIDNet STDC1</li>
<li>results:  Mask2Former EHANet 具有最好的性能， BiSeNet V2 表现竞争力强， PIDNet 具有最高的报告率，但精度较低。<details>
<summary>Abstract</summary>
Lip segmentation is crucial in computer vision, especially for lip reading. Despite extensive face segmentation research, lip segmentation has received limited attention. The aim of this study is to compare state-of-the-art lip segmentation models using a standardized setting and a publicly available dataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and STDC1, are qualitatively selected based on their reported performance, inference time, code availability, recency, and popularity. The CelebAMask-HQ dataset, comprising manually annotated face images, is used to fairly assess the lip segmentation performance of the selected models. Inference experiments are conducted on a Raspberry Pi4 to emulate limited computational resources. The results show that Mask2Former and EHANet have the best performances in terms of mIoU score. BiSeNet V2 demonstrate competitive performance, while PIDNet excels in recall but has lower precision. Most models present inference time ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with PIDNet having the lowest mean inference time. This study provides a comprehensive evaluation of lip segmentation models, highlighting their performance and inference times. The findings contribute to the development of lightweight techniques and establish benchmarks for future advances in lip segmentation, especially in IoT and edge computing scenarios.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>> lip 分 segmentation 是计算机视觉中非常重要的一环，特别是 lip 读。despite 广泛的 face 分 segmentation 研究，lip 分 segmentation 却收到了有限的关注。本研究的目标是 Comparing state-of-the-art lip 分 segmentation 模型，使用标准化的设定和公共可用的数据集进行评估。 Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and STDC1, are qualitatively selected based on their reported performance, inference time, code availability, recency, and popularity. The CelebAMask-HQ dataset, comprising manually annotated face images, is used to fairly assess the lip 分 segmentation performance of the selected models. Inference experiments are conducted on a Raspberry Pi4 to emulate limited computational resources. The results show that Mask2Former and EHANet have the best performances in terms of mIoU score. BiSeNet V2 demonstrates competitive performance, while PIDNet excels in recall but has lower precision. Most models present inference time ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with PIDNet having the lowest mean inference time. This study provides a comprehensive evaluation of lip 分 segmentation models, highlighting their performance and inference times. The findings contribute to the development of lightweight techniques and establish benchmarks for future advances in lip 分 segmentation, especially in IoT and edge computing scenarios.
</details></li>
</ul>
<hr>
<h2 id="Categorizing-the-Visual-Environment-and-Analyzing-the-Visual-Attention-of-Dogs"><a href="#Categorizing-the-Visual-Environment-and-Analyzing-the-Visual-Attention-of-Dogs" class="headerlink" title="Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs"></a>Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11988">http://arxiv.org/abs/2311.11988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shreyas Sundara Raman, Madeline H. Pelgrim, Daphna Buchsbaum, Thomas Serre</li>
<li>for: 这个论文旨在研究狗的视觉行为和与physical world的互动。</li>
<li>methods: 研究者使用了头戴式眼动追踪设备收集了11只狗在日常户外环境中的视觉注意力数据，并使用了MaskRCNN来自动分类狗的视觉固定。</li>
<li>results: 研究发现，狗具有对汽车、植物、路面和建筑设备的更多视觉注意力，而它们之间没有很大差异。这些结果为了理解狗的视觉行为和与physical world的互动提供了重要的信息。<details>
<summary>Abstract</summary>
Dogs have a unique evolutionary relationship with humans and serve many important roles e.g. search and rescue, blind assistance, emotional support. However, few datasets exist to categorize visual features and objects available to dogs, as well as how dogs direct their visual attention within their environment. We collect and study a dataset with over 11,698 gazes to categorize the objects available to be gazed at by 11 dogs in everyday outdoor environments i.e. a walk around a college campus and urban area. We explore the availability of these object categories and the visual attention of dogs over these categories using a head mounted eye tracking apparatus. A small portion (approx. 600 images or < 20% of total dataset) of the collected data is used to fine tune a MaskRCNN for the novel image domain to segment objects present in the scene, enabling further statistical analysis on the visual gaze tendencies of dogs. The MaskRCNN, with eye tracking apparatus, serves as an end to end model for automatically classifying the visual fixations of dogs. The fine tuned MaskRCNN performs far better than chance. There are few individual differences between the 11 dogs and we observe greater visual fixations on buses, plants, pavement, and construction equipment. This work takes a step towards understanding visual behavior of dogs and their interaction with the physical world.
</details>
<details>
<summary>摘要</summary>
狗有独特的进化关系与人类，扮演许多重要的角色，如搜索救援、残疾人帮助、情感支持等。然而，有很少的数据集可以分类狗视觉中的视觉特征和对象，以及狗在环境中如何 dirige 其视觉注意力。我们收集和研究了一个数据集，包含11个狗在日常户外环境中 gaze 的11,698个视觉 fixation，包括大学校园和城市区域的行走。我们研究了这些对象类别的可用性，以及狗在这些类别中的视觉注意力使用头戴式眼动追踪设备。一小部分（约600张图像，即 <20% 的总数据集）的数据用于练化一个MaskRCNN模型，以便在新的图像领域中进行自动物体分类，从而进一步统计狗视觉倾向的统计分析。MaskRCNN模型，具有眼动追踪设备，serve为狗视觉自动分类的终端模型。练化后的MaskRCNN表现远胜准Random。我们发现11只狗之间存在很少的个体差异，而狗更多地围注视汽车、植物、路面和建筑设备。这项工作为了理解狗视觉行为和它们与物理世界的互动而做出了一步。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Previous-Facial-Action-Units-Knowledge-for-Emotion-Recognition-on-Faces"><a href="#Leveraging-Previous-Facial-Action-Units-Knowledge-for-Emotion-Recognition-on-Faces" class="headerlink" title="Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces"></a>Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11980">http://arxiv.org/abs/2311.11980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro B. S. Masur, Willams Costa, Lucas S. Figueredo, Veronica Teichrieb</li>
<li>for: 本研究旨在提高人机交互的效果，使机器能够理解人们的情感。</li>
<li>methods: 本研究使用了 convolutional neural networks (CNNs) 和 Facial Action Units (AUs) 技术来识别情感。</li>
<li>results: 研究提出了一种基于 Facial Action Coding System (FACS) 的机器学习方法，以提高多个cue情感识别的精度。<details>
<summary>Abstract</summary>
People naturally understand emotions, thus permitting a machine to do the same could open new paths for human-computer interaction. Facial expressions can be very useful for emotion recognition techniques, as these are the biggest transmitters of non-verbal cues capable of being correlated with emotions. Several techniques are based on Convolutional Neural Networks (CNNs) to extract information in a machine learning process. However, simple CNNs are not always sufficient to locate points of interest on the face that can be correlated with emotions. In this work, we intend to expand the capacity of emotion recognition techniques by proposing the usage of Facial Action Units (AUs) recognition techniques to recognize emotions. This recognition will be based on the Facial Action Coding System (FACS) and computed by a machine learning system. In particular, our method expands over EmotiRAM, an approach for multi-cue emotion recognition, in which we improve over their facial encoding module.
</details>
<details>
<summary>摘要</summary>
人们自然地理解情感，因此让机器也能够同样理解可以开启新的人机交互方式。人脸表情是情感识别技术中最大的非语言表达，可以与情感相关。一些技术基于卷积神经网络（CNN）来提取信息，但简单的CNN不一定能够找到与情感相关的面部特征。在这种工作中，我们计划通过使用表情动作单元（AU）识别技术来识别情感。这种识别基于人脸动作编码系统（FACS），由机器学习系统进行计算。具体来说，我们的方法在EmotiRAM方法中的面部编码模块上进行了改进。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Supervision-Levels-Trade-Offs-for-Infrared-Based-People-Counting"><a href="#Evaluating-Supervision-Levels-Trade-Offs-for-Infrared-Based-People-Counting" class="headerlink" title="Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting"></a>Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11974">http://arxiv.org/abs/2311.11974</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Latortue, Moetez Kdayem, Fidel A Guerrero Peña, Eric Granger, Marco Pedersoli</li>
<li>for: 人数计算（人 counting）</li>
<li>methods: 使用深度人脸检测器（deep person counting architectures）和Convolutional Neural Networks（CNN）</li>
<li>results: 使用CNN Image-Level模型可以达到与YOLO探测器和点级模型相当的人数计算结果，同时提供更高的帧率和相似的模型参数量。<details>
<summary>Abstract</summary>
Object detection models are commonly used for people counting (and localization) in many applications but require a dataset with costly bounding box annotations for training. Given the importance of privacy in people counting, these models rely more and more on infrared images, making the task even harder. In this paper, we explore how weaker levels of supervision can affect the performance of deep person counting architectures for image classification and point-level localization. Our experiments indicate that counting people using a CNN Image-Level model achieves competitive results with YOLO detectors and point-level models, yet provides a higher frame rate and a similar amount of model parameters.
</details>
<details>
<summary>摘要</summary>
人数检测模型广泛用于人数计算和本地化在多种应用中，但是需要贵重的 bounding box 标注数据来训练。由于隐私问题的重要性，这些模型越来越依赖于 Infrared 图像，使任务变得更加困难。在这篇论文中，我们研究如何弱一级超级视觉模型对深度人数计算架构的影响。我们的实验表明，使用 CNN 图像级别模型来计算人数可以达到与 YOLO 检测器和点级模型相同的性能水平，同时提供更高的帧率和相似的模型参数。
</details></li>
</ul>
<hr>
<h2 id="NNG-Mix-Improving-Semi-supervised-Anomaly-Detection-with-Pseudo-anomaly-Generation"><a href="#NNG-Mix-Improving-Semi-supervised-Anomaly-Detection-with-Pseudo-anomaly-Generation" class="headerlink" title="NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation"></a>NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11961">http://arxiv.org/abs/2311.11961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/donghao51/nng-mix">https://github.com/donghao51/nng-mix</a></li>
<li>paper_authors: Hao Dong, Gaëtan Frusque, Yue Zhao, Eleni Chatzi, Olga Fink</li>
<li>for: 这篇论文主要应用在预测罕见事件和异常数据中，包括网络入侵检测、金融诈欺检测和基础设施和工业系统中的异常检测。</li>
<li>methods: 这篇论文提出了一个新的扩展方法，名为 Nearest Neighbor Gaussian Mixup (NNG-Mix)，可以将有限量的标签异常数据与大量的无标签数据混合，以生成更多的伪异常数据。</li>
<li>results: 经过广泛的实验，该扩展方法在57个 benchmark 数据集上表现出色，与其他数据扩展方法相比，它可以提高预测异常数据的性能。<details>
<summary>Abstract</summary>
Anomaly detection (AD) is essential in identifying rare and often critical events in complex systems, finding applications in fields such as network intrusion detection, financial fraud detection, and fault detection in infrastructure and industrial systems. While AD is typically treated as an unsupervised learning task due to the high cost of label annotation, it is more practical to assume access to a small set of labeled anomaly samples from domain experts, as is the case for semi-supervised anomaly detection. Semi-supervised and supervised approaches can leverage such labeled data, resulting in improved performance. In this paper, rather than proposing a new semi-supervised or supervised approach for AD, we introduce a novel algorithm for generating additional pseudo-anomalies on the basis of the limited labeled anomalies and a large volume of unlabeled data. This serves as an augmentation to facilitate the detection of new anomalies. Our proposed algorithm, named Nearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information from both labeled and unlabeled data to generate pseudo-anomalies. We compare the performance of this novel algorithm with commonly applied augmentation techniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various existing semi-supervised and supervised anomaly detection algorithms on the original training data along with the generated pseudo-anomalies. Through extensive experiments on 57 benchmark datasets in ADBench, reflecting different data types, we demonstrate that NNG-Mix outperforms other data augmentation methods. It yields significant performance improvements compared to the baselines trained exclusively on the original training data. Notably, NNG-Mix yields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP datasets in ADBench. Our source code will be available at https://github.com/donghao51/NNG-Mix.
</details>
<details>
<summary>摘要</summary>
anomaly detection (AD) 是必备的在复杂系统中发现罕见和重要事件的工具，应用于网络入侵检测、财务诈骗检测和基础设施和工业系统的故障检测等领域。由于 AD 通常被视为无监督学习任务，因此在实际应用中很难获得大量标注数据。但是，在半监督和监督学习方面，可以利用这些标注数据，从而提高性能。在这篇文章中，我们不是提出一种新的半监督或监督学习方法，而是提出一种新的算法，可以生成更多的 Pseudo-anomaly，以便检测新的异常。我们称之为 Nearest Neighbor Gaussian Mixup (NNG-Mix)。NNG-Mix 算法可以有效地利用标注数据和无标注数据之间的信息，生成 Pseudo-anomaly。我们与常见的混合和剪辑技术进行比较，并通过在不同的数据类型上进行广泛的实验，证明 NNG-Mix 算法在 ADBench 上的57 个标准数据集上具有显著的性能优势。相比基eline 在原始训练数据上进行训练时，NNG-Mix 可以提供 Up to 16.4%、8.8% 和 8.0% 的性能提升。它的源代码将在 GitHub 上公开。
</details></li>
</ul>
<hr>
<h2 id="Correlated-Attention-in-Transformers-for-Multivariate-Time-Series"><a href="#Correlated-Attention-in-Transformers-for-Multivariate-Time-Series" class="headerlink" title="Correlated Attention in Transformers for Multivariate Time Series"></a>Correlated Attention in Transformers for Multivariate Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11959">http://arxiv.org/abs/2311.11959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quang Minh Nguyen, Lam M. Nguyen, Subhro Das</li>
<li>for: 这个论文是为了解决多变量时间序列（MTS）分析中的问题，如金融、气候科学和医疗等领域的实际应用。</li>
<li>methods: 论文提出了一种新的相关注意机制，可以快速发现时间序列中的特征wise关系，同时可以融合在现有的Transformer模型中使用，以提高效率。</li>
<li>results: 对于多种任务，如填充、异常检测和分类，与基本Transformer模型相比，相关注意机制可以提供更好的性能，并且在各种实验中 consistently 表现出优于基本Transformer模型。<details>
<summary>Abstract</summary>
Multivariate time series (MTS) analysis prevails in real-world applications such as finance, climate science and healthcare. The various self-attention mechanisms, the backbone of the state-of-the-art Transformer-based models, efficiently discover the temporal dependencies, yet cannot well capture the intricate cross-correlation between different features of MTS data, which inherently stems from complex dynamical systems in practice. To this end, we propose a novel correlated attention mechanism, which not only efficiently captures feature-wise dependencies, but can also be seamlessly integrated within the encoder blocks of existing well-known Transformers to gain efficiency improvement. In particular, correlated attention operates across feature channels to compute cross-covariance matrices between queries and keys with different lag values, and selectively aggregate representations at the sub-series level. This architecture facilitates automated discovery and representation learning of not only instantaneous but also lagged cross-correlations, while inherently capturing time series auto-correlation. When combined with prevalent Transformer baselines, correlated attention mechanism constitutes a better alternative for encoder-only architectures, which are suitable for a wide range of tasks including imputation, anomaly detection and classification. Extensive experiments on the aforementioned tasks consistently underscore the advantages of correlated attention mechanism in enhancing base Transformer models, and demonstrate our state-of-the-art results in imputation, anomaly detection and classification.
</details>
<details>
<summary>摘要</summary>
多变量时间序列（MTS）分析在现实应用中广泛存在，如金融、气候科学和医疗等领域。各种自注意机制，是现代Transformer模型的核心，高效地发现时间相关性，但无法好地捕捉MTS数据中不同特征之间的复杂相关性，这些相关性在实践中来自复杂的动态系统。为此，我们提出了一种新的相关注意机制，不仅高效地捕捉特征间的相关性，还可以轻松地与现有的Transformer模型集成，以提高效率。具体来说，相关注意机制在特征通道之间计算特征查询和特征键之间的差值 cov Matrix，并选择ively Representations at the sub-series level。这种架构使得自动发现和表征学习不同特征之间的不仅当前响应，还包括延迟响应，而且自然地捕捉时间序列自相关。当与普遍的Transformer基线模型结合使用时，相关注意机制组成了更好的encoder-only架构，适用于广泛的任务，如填充、异常检测和分类。extensive experiment表明，相关注意机制在改进基Transformer模型的情况下，在填充、异常检测和分类任务中具有明显的优势，并实现了我们的国际前进result。
</details></li>
</ul>
<hr>
<h2 id="FinanceBench-A-New-Benchmark-for-Financial-Question-Answering"><a href="#FinanceBench-A-New-Benchmark-for-Financial-Question-Answering" class="headerlink" title="FinanceBench: A New Benchmark for Financial Question Answering"></a>FinanceBench: A New Benchmark for Financial Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11944">http://arxiv.org/abs/2311.11944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, Bertie Vidgen</li>
<li>for: The paper is written to evaluate the performance of large language models (LLMs) on open book financial question answering (QA).</li>
<li>methods: The paper uses a test suite called FinanceBench, which consists of 10,231 questions about publicly traded companies, to evaluate the performance of 16 state-of-the-art LLM configurations. The authors manually reviewed the answers to the questions (n&#x3D;2,400) and found that existing LLMs have clear limitations for financial QA.</li>
<li>results: The authors found that GPT-4-Turbo, a popular LLM, incorrectly answered or refused to answer 81% of questions when used with a retrieval system. While augmentation techniques such as using longer context windows can improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. All models examined exhibited weaknesses such as hallucinations, which limit their suitability for use by enterprises.<details>
<summary>Abstract</summary>
FinanceBench is a first-of-its-kind test suite for evaluating the performance of LLMs on open book financial question answering (QA). It comprises 10,231 questions about publicly traded companies, with corresponding answers and evidence strings. The questions in FinanceBench are ecologically valid and cover a diverse set of scenarios. They are intended to be clear-cut and straightforward to answer to serve as a minimum performance standard. We test 16 state of the art model configurations (including GPT-4-Turbo, Llama2 and Claude2, with vector stores and long context prompts) on a sample of 150 cases from FinanceBench, and manually review their answers (n=2,400). The cases are available open-source. We show that existing LLMs have clear limitations for financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81% of questions. While augmentation techniques such as using longer context window to feed in relevant evidence improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. We find that all models examined exhibit weaknesses, such as hallucinations, that limit their suitability for use by enterprises.
</details>
<details>
<summary>摘要</summary>
金融桌面（FinanceBench）是一个首创性的测试集，用于评估大数据语言模型（LLM）在公开的财务问答（QA）领域的表现。其包含10,231个公开交易公司的问题，以及相应的答案和证据串。 FinanceBench 中的问题是生物地 Valid，覆盖了多样化的场景。它们是为了提供最低性能标准，易于答题。我们在 FinanceBench 中采样 150 个案例，测试了 16 个现状之最模型配置（包括 GPT-4-Turbo、Llama2 和 Claude2，以及 vector store 和长 context prompts），并 manually 复查其答案（n = 2,400）。案例可以在开源的形式下获得。我们发现现有的 LLM 在财务 QA 领域存在明显的限制。例如，GPT-4-Turbo 在使用检索系统时 incorrectly 答题或拒绝答题 81% 的问题。而使用 longer context window 来接受相关证据的增强技术可以提高表现，但是这些技术在企业环境中不可能实现因为增加的延迟，无法支持更大的财务文档。我们发现所有模型受测都存在一些弱点，如幻化，这限制了它们在企业环境中的适用性。
</details></li>
</ul>
<hr>
<h2 id="Ovarian-Cancer-Data-Analysis-using-Deep-Learning-A-Systematic-Review-from-the-Perspectives-of-Key-Features-of-Data-Analysis-and-AI-Assurance"><a href="#Ovarian-Cancer-Data-Analysis-using-Deep-Learning-A-Systematic-Review-from-the-Perspectives-of-Key-Features-of-Data-Analysis-and-AI-Assurance" class="headerlink" title="Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance"></a>Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11932">http://arxiv.org/abs/2311.11932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker<br>for:* 这些研究主要是为了检测和诊断卵巢癌。methods:* 大多数研究使用了基于样本的 Deep Learning 技术，并且只有一些研究使用了混合数据（临床或ómics数据）进行集成分析。results:* 只有一小部分的研究（仅8.3%） validate their models 使用外部和多样化的数据集，表明需要进一步 validate 模型。* 卵巢癌数据分析中的人工智能确保（AIAs）处于非常早期的阶段，只有2.1% 的研究直接考虑 AIA 通过解释性。<details>
<summary>Abstract</summary>
Background and objectives: By extracting this information, Machine or Deep Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and cancer researchers in discovering patterns and relationships from complex data sets. Many DL-based analyses on ovarian cancer (OC) data have recently been published. These analyses are highly diverse in various aspects of cancer (e.g., subdomain(s) and cancer type they address) and data analysis features. However, a comprehensive understanding of these analyses in terms of these features and AI assurance (AIA) is currently lacking. This systematic review aims to fill this gap by examining the existing literature and identifying important aspects of OC data analysis using DL, explicitly focusing on the key features and AI assurance perspectives. Methods: The PRISMA framework was used to conduct comprehensive searches in three journal databases. Only studies published between 2015 and 2023 in peer-reviewed journals were included in the analysis. Results: In the review, a total of 96 DL-driven analyses were examined. The findings reveal several important insights regarding DL-driven ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on detection and diagnosis, while no study addressed the prediction and prevention of OC. - The analyses were predominantly based on samples from a non-diverse population (75% (72/96 studies)), limited to a geographic location or country. - Only a small proportion of studies (only 33% (32/96)) performed integrated analyses, most of which used homogeneous data (clinical or omics). - Notably, a mere 8.3% (8/96) of the studies validated their models using external and diverse data sets, highlighting the need for enhanced model validation, and - The inclusion of AIA in cancer data analysis is in a very early stage; only 2.1% (2/96) explicitly addressed AIA through explainability.
</details>
<details>
<summary>摘要</summary>
背景和目标：通过提取这些信息，机器学习或深度学习（ML/DL）基于自主数据分析工具可以帮助临床医生和癌症研究人员发现复杂数据集中的模式和关系。在最近几年内，有许多基于深度学习的OC数据分析研究被发表。这些研究在各种方面（如亚Domain和癌种）和数据分析特点上很多样。然而，对这些研究的全面理解，特别是在关键特征和人工智能保障（AI保障）方面，目前缺乏了一个全面的认知。本系统性文献综述旨在填补这一空白，通过检查现有文献，了解OC数据分析中使用DL的重要方面和AI保障视角。方法：使用PRISMA框架进行全面搜索，仅包括2015年至2023年在同行评审 журна尔上发表的研究。结果：在这次综述中，总共检查了96项DL驱动的分析。结果显示了一些关于OC数据分析的重要发现： - 大多数研究（71%，68项中）是关于检测和诊断，而没有一项关于预测和预防OC的研究。 - 这些分析主要基于来自非多样化人口（75%，72项中）的样本，限制在某个地理位置或国家。 - 只有一小部分研究（仅33%，32项中）执行了集成分析，大多数使用同类数据（临床或生物 markers）。 - 需要注意的是，只有8.3%（8项中）的研究 Validated其模型使用外部和多样化数据集，表明需要进一步提高模型验证。 - 在癌症数据分析中，AI保障处于非常早期阶段，只有2.1%（2项中）显式地考虑了AI保障，通过解释性来实现。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-Fitness-Exercise-Recognition-from-Doppler-Measurements-by-Domain-adaption-and-Few-Shot-Learning"><a href="#Generalization-of-Fitness-Exercise-Recognition-from-Doppler-Measurements-by-Domain-adaption-and-Few-Shot-Learning" class="headerlink" title="Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning"></a>Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11910">http://arxiv.org/abs/2311.11910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biying Fu, Naser Damer, Florian Kirchbuchner, Arjan Kuijper</li>
<li>for: 本研究旨在提高智能手机应用程序的全身运动识别精度，并研究如何在实际应用中适应不同用户、环境和设备变化。</li>
<li>methods: 本研究使用了商业OFF-THE-SHELF智能手机和ultrasound Doppler探测技术，并提出了两种小数据适应技术来提高模型泛化性。</li>
<li>results: 对比基eline，使用小数据适应技术可以提高全身运动识别精度，并且在不同用户、环境和设备下的 recognize accuracy 提高了2-6倍。<details>
<summary>Abstract</summary>
In previous works, a mobile application was developed using an unmodified commercial off-the-shelf smartphone to recognize whole-body exercises. The working principle was based on the ultrasound Doppler sensing with the device built-in hardware. Applying such a lab-environment trained model on realistic application variations causes a significant drop in performance, and thus decimate its applicability. The reason of the reduced performance can be manifold. It could be induced by the user, environment, and device variations in realistic scenarios. Such scenarios are often more complex and diverse, which can be challenging to anticipate in the initial training data. To study and overcome this issue, this paper presents a database with controlled and uncontrolled subsets of fitness exercises. We propose two concepts to utilize small adaption data to successfully improve model generalization in an uncontrolled environment, increasing the recognition accuracy by two to six folds compared to the baseline for different users.
</details>
<details>
<summary>摘要</summary>
在前一些研究中，我们已经开发了一款基于商业化手机的移动应用程序，用于识别全身运动。工作原理基于商业手机内置的射频雷达感测。但在实际应用中，使用未修改的商业手机进行识别，因为环境、用户和设备的变化，会导致性能下降，从而减少其实用性。这种性能下降的原因可能是多方面的，包括用户、环境和设备变化。这些变化在实际场景中经常更加复杂和多样化，可能难以预测在初始训练数据中。为了研究和解决这个问题，本文提出了一个包含控制和无控制subset的健身运动数据库。我们还提出了两种概念，用于利用小量适应数据来提高模型在无控制环境中的泛化性，提高识别精度两到六倍 compared to基eline для不同的用户。
</details></li>
</ul>
<hr>
<h2 id="Continual-Learning-Applications-and-the-Road-Forward"><a href="#Continual-Learning-Applications-and-the-Road-Forward" class="headerlink" title="Continual Learning: Applications and the Road Forward"></a>Continual Learning: Applications and the Road Forward</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11908">http://arxiv.org/abs/2311.11908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eli Verwimp, Rahaf Aljundi, Shai Ben-David, Matthias Bethge, Andrea Cossu, Alexander Gepperth, Tyler L. Hayes, Eyke Hüllermeier, Christopher Kanan, Dhireesha Kudithipudi, Christoph H. Lampert, Martin Mundt, Razvan Pascanu, Adrian Popescu, Andreas S. Tolias, Joost van de Weijer, Bing Liu, Vincenzo Lomonaco, Tinne Tuytelaars, Gido M. van de Ven</li>
<li>for: 这个论文的目的是解释为何应该关注连续学习，并展示了现代机器学习模型在新数据上积累知识的重要性。</li>
<li>methods: 这篇论文使用了最新的连续学习论文，以及现代机器学习模型的研究来支持自己的 Argument。</li>
<li>results: 这篇论文的结论是，连续学习将成为未来机器学习领域中不可或缺的一部分，并且需要进一步的研究以满足未来的需求。<details>
<summary>Abstract</summary>
Continual learning is a sub-field of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: "Why should one care about continual learning in the first place?". We set the stage by surveying recent continual learning papers published at three major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model-editing, personalization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Explaining-Deep-Learning-Models-for-Age-related-Gait-Classification-based-on-time-series-acceleration"><a href="#Explaining-Deep-Learning-Models-for-Age-related-Gait-Classification-based-on-time-series-acceleration" class="headerlink" title="Explaining Deep Learning Models for Age-related Gait Classification based on time series acceleration"></a>Explaining Deep Learning Models for Age-related Gait Classification based on time series acceleration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12089">http://arxiv.org/abs/2311.12089</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xzheng93/explainable_dl">https://github.com/xzheng93/explainable_dl</a></li>
<li>paper_authors: Xiaoping Zheng, Bert Otten, Michiel F Reneman, Claudine JC Lamoth<br>for:This study aimed to enhance transparency in deep learning-based gait classification for aged-related gait patterns using Explainable Artificial Intelligence.methods:The study used a dataset of 244 subjects, including 129 adults and 115 older adults (age&gt;65), who performed a 3-minute walking task while wearing accelerometers at the lumbar segment L3. The study used deep learning models, including convolutional neural networks (CNN) and gated recurrent units (GRU), to classify adult and older adult groups. SHAP was employed to explain the models’ predictions.results:The study found that both CNN and GRU assigned higher SHAP values to the data from vertical and walking directions, particularly emphasizing data around heel contact, spanning from the terminal swing to loading response phases. GRU did not treat every stride equally, and CNN accurately distinguished between adults and older adults based on the characteristics of a single stride’s data. The study found that data around heel contact emerged as most critical, suggesting differences in acceleration and deceleration patterns during walking between different age groups.Here is the format you requested:for: 这些paper是为了做什么？methods: 这个paper使用了哪些方法？results: 这个paper得到了什么结果？I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Gait analysis holds significant importance in monitoring daily health, particularly among older adults. Advancements in sensor technology enable the capture of movement in real-life environments and generate big data. Machine learning, notably deep learning (DL), shows promise to use these big data in gait analysis. However, the inherent black-box nature of these models poses challenges for their clinical application. This study aims to enhance transparency in DL-based gait classification for aged-related gait patterns using Explainable Artificial Intelligence, such as SHAP.   A total of 244 subjects, comprising 129 adults and 115 older adults (age>65), were included. They performed a 3-minute walking task while accelerometers were affixed to the lumbar segment L3. DL models, convolutional neural network (CNN) and gated recurrent unit (GRU), were trained using 1-stride and 8-stride accelerations, respectively, to classify adult and older adult groups. SHAP was employed to explain the models' predictions.   CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC of 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and an AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher SHAP values to the data from vertical and walking directions, particularly emphasizing data around heel contact, spanning from the terminal swing to loading response phases. Furthermore, SHAP values indicated that GRU did not treat every stride equally.   CNN accurately distinguished between adults and older adults based on the characteristics of a single stride's data. GRU achieved accurate classification by considering the relationships and subtle differences between strides. In both models, data around heel contact emerged as most critical, suggesting differences in acceleration and deceleration patterns during walking between different age groups.
</details>
<details>
<summary>摘要</summary>
跑步分析对日常健康监测具有重要意义，特别是对老年人而言。随着感测技术的发展，我们可以在真实环境中记录和生成大量数据。深度学习（DL）显示出在这些大量数据中使用的潜在优势。然而，深度学习模型的黑盒特性带来了临床应用中的挑战。本研究旨在通过可解释人工智能（AI）技术，如SHAP，提高DL基于走姿分类的透明度。本研究共包括244名参与者，其中129名成年人和115名老年人（年龄超过65岁）。他们在L3脊梁上附加加速计，并完成3分钟步行任务。使用1步和8步加速度训练深度神经网络（CNN）和闭合循环单元（GRU）模型，分别进行成年人和老年人组的分类。SHAP技术用于解释模型预测结果。CNN实现了满意的表现，准确率为81.4%，AUC为0.89，GRU则表现出了有前途的结果，准确率为84.5%，AUC为0.94。SHAP分析表明，CNN和GRU都将 vertical和步行方向的数据作为优先级，特别是在脚部接触阶段（从终端摆动阶段到加速响应阶段）。此外，SHAP值表明GRU不会对每步数据进行平等对待。CNN可以通过单步数据的特征来正确地分类成年人和老年人。GRU则通过考虑步行过程中的关系和细微差异来准确地分类。在两个模型中，脚部接触阶段的数据 emerge as most critical，表明在不同年龄组之间走姿的加速和减速差异存在。
</details></li>
</ul>
<hr>
<h2 id="Towards-Exploratory-Reformulation-of-Constraint-Models"><a href="#Towards-Exploratory-Reformulation-of-Constraint-Models" class="headerlink" title="Towards Exploratory Reformulation of Constraint Models"></a>Towards Exploratory Reformulation of Constraint Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11868">http://arxiv.org/abs/2311.11868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ian Miguel, András Z. Salamon, Christopher Stone</li>
<li>for: 本研究旨在提出一种exploratory reformulation系统，用于寻找最佳的约束模型，以提高问题的解决效率。</li>
<li>methods: 本研究使用了一种基于改进的方法，通过从初始模型开始，逐步地重新表述模型，以优化模型的性能。</li>
<li>results: 研究已经做出了一些进展，包括开发出一种基于refinement的方法，以及实现了一种可以自动生成模型的系统。<details>
<summary>Abstract</summary>
It is well established that formulating an effective constraint model of a problem of interest is crucial to the efficiency with which it can subsequently be solved. Following from the observation that it is difficult, if not impossible, to know a priori which of a set of candidate models will perform best in practice, we envisage a system that explores the space of models through a process of reformulation from an initial model, guided by performance on a set of training instances from the problem class under consideration. We plan to situate this system in a refinement-based approach, where a user writes a constraint specification describing a problem above the level of abstraction at which many modelling decisions are made. In this position paper we set out our plan for an exploratory reformulation system, and discuss progress made so far.
</details>
<details>
<summary>摘要</summary>
已经确立了，制定一个有效的约束模型是解决问题的关键，以便更高效地解决问题。从观察到，不可能在先知道哪一个候选模型会在实践中表现最好，我们想要一个系统可以在一个初始模型的基础上进行重新表述，以便根据训练实例集的性能进行指导。我们计划将这个系统放在一种改进型方法中，其中用户可以在许多模型决策之上写一个约束规范，描述问题。在这篇观点文章中，我们阐述了我们的探索重新表述系统计划，以及已经完成的进度。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Emissions-and-Energy-Efficiency-in-Mixed-Traffic-Control-at-Unsignalized-Intersections"><a href="#Analyzing-Emissions-and-Energy-Efficiency-in-Mixed-Traffic-Control-at-Unsignalized-Intersections" class="headerlink" title="Analyzing Emissions and Energy Efficiency in Mixed Traffic Control at Unsignalized Intersections"></a>Analyzing Emissions and Energy Efficiency in Mixed Traffic Control at Unsignalized Intersections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11866">http://arxiv.org/abs/2311.11866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Villarreal, Dawei Wang, Jia Pan, Weizi Li</li>
<li>For: This paper aims to reduce transportation-related emissions, specifically at signalized intersections, by employing mixed traffic control eco-driving strategies using robot vehicles (RVs).* Methods: The paper uses emissions analysis on unsignalized intersections with complex, real-world topologies and traffic demands, where RVs are used to reduce waiting times and congestion.* Results: The paper finds that with at least 10% RV penetration rate, RVs can reduce fuel consumption and NOx emissions by up to 27% and 28%, respectively, and with at least 30% RVs, CO and HC emissions can be reduced by up to 42% and 43%, respectively. Additionally, RVs can reduce emissions across the whole network.<details>
<summary>Abstract</summary>
Greenhouse gas emissions have dramatically risen since the early 1900s with U.S. transportation generating 28% of the U.S' emissions. As such, there is interest in reducing transportation-related emissions. Specifically, sustainability research has sprouted around signalized intersections as intersections allow different streams of traffic to cross and change directions. Recent research has developed mixed traffic control eco-driving strategies at signalized intersections to decrease emissions. However, the inherent structure of a signalized intersection generates increased emissions by creating frequent acceleration/deceleration events, excessive idling from traffic congestion, and stop-and-go waves. Thus, we believe unsignalized intersections hold potential for further sustainability improvements. In this work, we provide an emissions analysis on unsignalized intersections with complex, real-world topologies and traffic demands where mixed traffic control strategies are employed by robot vehicles (RVs) to reduce waiting times and congestion. We find with at least 10% RV penetration rate, RVs generate less fuel consumption and NOx emissions than signalized intersections by up to 27% and 28%, respectively. With at least 30% RVs, CO and HC emissions are reduced by up to 42% and 43%, respectively. Additionally, RVs can reduce emissions across the whole network despite only employing their strategies at the intersections.
</details>
<details>
<summary>摘要</summary>
美国交通部门自20世纪初期以来，绿色气体排放已经有了很大增长。为了降低交通相关排放，可持续发展研究在信号灯交叉口上进行了大量的研究。特别是在信号灯交叉口上，杂交控制驾驶技术的研究已经得到了广泛的应用。然而，信号灯交叉口的内置结构会导致更多的加速/减速事件、交通堵塞导致的停靠时间过长、以及往返波。因此，我们认为不信号灯交叉口具有更多的可持续发展可能性。在这个工作中，我们对无信号灯交叉口进行了排放分析，并采用了机器人车（RV）实施杂交控制策略来减少等待时间和堵塞。我们发现，当RV占用率至少为10%时，RV比信号灯交叉口排放更少的柴油消耗和NOx排放，分别下降27%和28%。当RV占用率至少为30%时，CO和HC排放也下降了42%和43%。此外，RV可以在整个网络中减少排放，即使只在交叉口上采用杂交控制策略。
</details></li>
</ul>
<hr>
<h2 id="Establishing-Central-Sensitization-Inventory-Cut-off-Values-in-patients-with-Chronic-Low-Back-Pain-by-Unsupervised-Machine-Learning"><a href="#Establishing-Central-Sensitization-Inventory-Cut-off-Values-in-patients-with-Chronic-Low-Back-Pain-by-Unsupervised-Machine-Learning" class="headerlink" title="Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning"></a>Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11862">http://arxiv.org/abs/2311.11862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xzheng93/csi_cutoff_establishment">https://github.com/xzheng93/csi_cutoff_establishment</a></li>
<li>paper_authors: Xiaoping Zheng, Claudine JC Lamoth, Hans Timmerman, Ebert Otten, Michiel F Reneman<br>for: 这个研究旨在确定chronic low back pain (CLBP)的患者群体中，Central Sensitization Inventory (CSI)的优化阈值，考虑到性别因素和疼痛状况的影响。methods: 这个研究使用了四种不supervised clustering方法来确定CSI中的HACS相关模式，并通过内部和外部指标评估 clustering性能。然后，通过 Receiver Operating Characteristic (ROC)分析确定最佳阈值。results: 研究发现， Hierarchical Clustering 方法得到最佳结果，可以将患者分为三个群体：健康组、CLBP with low HACS level 组和 CLBP with high HACS level 组。对于全体群体，优化阈值为 35，对于女性，阈值为 34，对于男性，阈值为 35。这些结果表明，CLBP 患者的优化阈值为 35。<details>
<summary>Abstract</summary>
Human Assumed Central Sensitization is involved in the development and maintenance of chronic low back pain (CLBP). The Central Sensitization Inventory (CSI) was developed to evaluate the presence of HACS, with a cut-off value of 40/100 based on patients with chronic pain. However, various factors including pain conditions (e.g., CLBP), and gender may influence this cut-off value. For chronic pain condition such as CLBP, unsupervised clustering approaches can take these factors into consideration and automatically learn the HACS-related patterns. Therefore, this study aimed to determine the cut-off values for a Dutch-speaking population with CLBP, considering the total group and stratified by gender based on unsupervised machine learning. In this study, questionnaire data covering pain, physical, and psychological aspects were collected from patients with CLBP and aged-matched pain-free adults (referred to as healthy controls, HC). Four clustering approaches were applied to identify HACS-related clusters based on the questionnaire data and gender. The clustering performance was assessed using internal and external indicators. Subsequently, receiver operating characteristic analysis was conducted on the best clustering results to determine the optimal cut-off values. The study included 151 subjects, consisting of 63 HCs and 88 patients with CLBP. Hierarchical clustering yielded the best results, identifying three clusters: healthy group, CLBP with low HACS level, and CLBP with high HACS level groups. Based on the low HACS levels group (including HC and CLBP with low HACS level) and high HACS level group, the cut-off value for the overall groups were 35, 34 for females, and 35 for. The findings suggest that the optimal cut-off values for CLBP is 35. The gender-related cut-off values should be interpreted with caution due to the unbalanced gender distribution in the sample.
</details>
<details>
<summary>摘要</summary>
人类假设中央敏感性（HACS）参与了慢性低脊梁疼痛（CLBP）的发展和维持。中央敏感性评估器（CSI）是用来评估HACS存在的存在，其分别为40/100，基于患有慢性疼痛的患者。然而，不同的因素，包括疼痛状况（例如CLBP）和性别可能影响这个分别值。为了慢性疼痛状况如CLBP，无监督聚类方法可以考虑这些因素并自动发现HACS相关的模式。因此，本研究的目的是在荷兰语言社区中确定CLBP患者的分别值，并根据性别进行分类。在本研究中，收集了疼痛、物理和心理方面的问卷数据，从患有CLBP的患者和年龄匹配的疼痛自适应人（HC）中收集数据。四种聚类方法被应用于基于问卷数据和性别 Identify HACS相关的聚类。聚类性被评估使用内部和外部指标。后续，基于最佳聚类结果进行 receiver operating characteristic 分析，以确定优化的分别值。研究包括151名参与者，包括63名HC和88名CLBP患者。层次聚类得到最佳结果，并将患者分为三个群体：健康组、CLBP低HACS水平组和 CLBP高HACS水平组。根据低HACS水平组（包括HC和CLBP低HACS水平）和高HACS水平组，总体分别值为35，女性分别值为34，男性分别值为35。结论表明，CLBP的最佳分别值为35。性别相关的分别值应该进行注意，因为样本中性别分布不均衡。
</details></li>
</ul>
<hr>
<h2 id="Generating-Valid-and-Natural-Adversarial-Examples-with-Large-Language-Models"><a href="#Generating-Valid-and-Natural-Adversarial-Examples-with-Large-Language-Models" class="headerlink" title="Generating Valid and Natural Adversarial Examples with Large Language Models"></a>Generating Valid and Natural Adversarial Examples with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11861">http://arxiv.org/abs/2311.11861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen</li>
<li>for: 这篇论文的目的是提出一种基于深度学习的自然语言处理（NLP）模型，特别是预训练语言模型（PLM）的攻击方法。</li>
<li>methods: 该方法包括两个阶段：首先，通过对words进行重要性排名，找到最容易遭受攻击的words；然后，使用大语言模型（LLM）提取的同义词来替换这些words。</li>
<li>results: 对于Movie Review（MR）、IMDB和Yelp Review Polarity等 dataset，LLM-Attack模型在对比基eline adversarial attack模型时表现出了显著的优势，在人工和GPT-4评估中也表现出了显著的提升。该模型可以生成有效、自然的攻击示例，保持语义意义、 grammaticality和人类隐身性。<details>
<summary>Abstract</summary>
Deep learning-based natural language processing (NLP) models, particularly pre-trained language models (PLMs), have been revealed to be vulnerable to adversarial attacks. However, the adversarial examples generated by many mainstream word-level adversarial attack models are neither valid nor natural, leading to the loss of semantic maintenance, grammaticality, and human imperceptibility. Based on the exceptional capacity of language understanding and generation of large language models (LLMs), we propose LLM-Attack, which aims at generating both valid and natural adversarial examples with LLMs. The method consists of two stages: word importance ranking (which searches for the most vulnerable words) and word synonym replacement (which substitutes them with their synonyms obtained from LLMs). Experimental results on the Movie Review (MR), IMDB, and Yelp Review Polarity datasets against the baseline adversarial attack models illustrate the effectiveness of LLM-Attack, and it outperforms the baselines in human and GPT-4 evaluation by a significant margin. The model can generate adversarial examples that are typically valid and natural, with the preservation of semantic meaning, grammaticality, and human imperceptibility.
</details>
<details>
<summary>摘要</summary>
深度学习基于自然语言处理（NLP）模型，特别是预训练语言模型（PLM），已经被揭示为易受到敌意攻击的。然而，由多数主流单词水平攻击模型生成的攻击示例通常不是有效的，导致 semantic maintenance、grammaticality 和人类不可见性的失去。基于大语言模型（LLM）的异常 capacities of language understanding and generation，我们提出了 LLM-Attack，这是一种生成有效和自然的攻击示例的方法。该方法包括两个阶段：单词重要性排名（搜索最易受到攻击的单词）和单词同义补充（使用 LLM 获取的单词同义补充替换它们）。实验结果表明，对 MR、IMDB 和 Yelp Review Polarity 数据集进行比较，LLM-Attack 高效地超越了基eline adversarial attack模型，在人类和 GPT-4 评估中也具有显著的优势。LLM-Attack 可以生成有效、自然的攻击示例，保持 semantics 的意义、 grammaticality 和人类不可见性。
</details></li>
</ul>
<hr>
<h2 id="Kandinsky-Conformal-Prediction-Efficient-Calibration-of-Image-Segmentation-Algorithms"><a href="#Kandinsky-Conformal-Prediction-Efficient-Calibration-of-Image-Segmentation-Algorithms" class="headerlink" title="Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms"></a>Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11837">http://arxiv.org/abs/2311.11837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joren Brunekreef, Eric Marcus, Ray Sheombarsing, Jan-Jakob Sonke, Jonas Teuwen<br>for: 这个研究是用于提高像素分类器的准确性和可靠性。methods: 这个方法使用了内在结构调整（Inductive Conformal Prediction）来整理像素分类器的预测结果，并且通过调整像素分类器的对应预测结果，以提高预测的准确性和可靠性。results: 这个研究发现，使用内在结构调整法可以将像素分类器的准确性和可靠性提高，并且在具有限制的数据情况下（如医疗领域），可以更好地利用可用数据进行整理。<details>
<summary>Abstract</summary>
Image segmentation algorithms can be understood as a collection of pixel classifiers, for which the outcomes of nearby pixels are correlated. Classifier models can be calibrated using Inductive Conformal Prediction, but this requires holding back a sufficiently large calibration dataset for computing the distribution of non-conformity scores of the model's predictions. If one only requires only marginal calibration on the image level, this calibration set consists of all individual pixels in the images available for calibration. However, if the goal is to attain proper calibration for each individual pixel classifier, the calibration set consists of individual images. In a scenario where data are scarce (such as the medical domain), it may not always be possible to set aside sufficiently many images for this pixel-level calibration. The method we propose, dubbed ``Kandinsky calibration'', makes use of the spatial structure present in the distribution of natural images to simultaneously calibrate the classifiers of ``similar'' pixels. This can be seen as an intermediate approach between marginal (imagewise) and conditional (pixelwise) calibration, where non-conformity scores are aggregated over similar image regions, thereby making more efficient use of the images available for calibration. We run experiments on segmentation algorithms trained and calibrated on subsets of the public MS-COCO and Medical Decathlon datasets, demonstrating that Kandinsky calibration method can significantly improve the coverage. When compared to both pixelwise and imagewise calibration on little data, the Kandinsky method achieves much lower coverage errors, indicating the data efficiency of the Kandinsky calibration.
</details>
<details>
<summary>摘要</summary>
Image segmentation算法可以理解为一组像素分类器，其中邻近像素的结果相关。类ifier模型可以通过卷积学习进行准确化，但需要一个够大的准确化数据集来计算模型预测结果的分布。如果只需要图像水平的准确化，则准确化数据集包括所有可用于准确化的像素。但如果目标是为每个个像素分类器进行准确化，则准确化数据集包括个别图像。在数据稀缺的情况下（如医疗领域），可能无法将够多的图像用于这种像素级准确化。我们提议的“卡金斯基准确化”方法（Kandinsky calibration）利用自然图像分布中的空间结构，同时准确化“相似”像素的分类器。这可以看作是 между像素级和图像级准确化之间的中间方法，其中不符合分布的分数聚合在相似图像区域上，从而更有效地利用可用于准确化的图像。我们在使用MS-COCO和医疗十字数据集训练和准确化的segmentation算法上进行了实验，并证明了卡金斯基准确化方法可以显著提高覆盖率。与像素级和图像级准确化相比，卡金斯基准确化方法在有限的数据情况下表现出远远更低的覆盖错误，表明了卡金斯基准确化方法在数据效率方面的优势。
</details></li>
</ul>
<hr>
<h2 id="System-2-Attention-is-something-you-might-need-too"><a href="#System-2-Attention-is-something-you-might-need-too" class="headerlink" title="System 2 Attention (is something you might need too)"></a>System 2 Attention (is something you might need too)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11829">http://arxiv.org/abs/2311.11829</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danderfer/Comp_Sci_Sem_2">https://github.com/danderfer/Comp_Sci_Sem_2</a></li>
<li>paper_authors: Jason Weston, Sainbayar Sukhbaatar</li>
<li>for: 提高Transformer基于大语言模型（LLM）中的软注意力，以避免在 latent representation中包含不相关信息，从而提高下一个 Token 的生成质量。</li>
<li>methods: 我们提出了 System 2 Attention（S2A），它利用 LLM 的自然语言理解能力和指令执行能力，以决定需要注意的内容。 S2A 首先重新生成输入上下文，并将其限制为只包含相关信息，然后对重新生成的上下文进行注意。</li>
<li>results: 在三个任务中（包括问答、数学问题和长篇生成），S2A 比标准注意力基于 LLM 高效，提高了事实性和 объекivity，降低了奉承性。<details>
<summary>Abstract</summary>
Soft attention in Transformer-based Large Language Models (LLMs) is susceptible to incorporating irrelevant information from the context into its latent representations, which adversely affects next token generations. To help rectify these issues, we introduce System 2 Attention (S2A), which leverages the ability of LLMs to reason in natural language and follow instructions in order to decide what to attend to. S2A regenerates the input context to only include the relevant portions, before attending to the regenerated context to elicit the final response. In experiments, S2A outperforms standard attention-based LLMs on three tasks containing opinion or irrelevant information, QA, math word problems and longform generation, where S2A increases factuality and objectivity, and decreases sycophancy.
</details>
<details>
<summary>摘要</summary>
transformer-based large language models (LLMs) 的软注意力容易受到上下文中不相关信息的影响，这会对下一个 Token 生成产生负面影响。为了解决这些问题，我们介绍 System 2 Attention (S2A)，它利用 LLMs 的自然语言理解能力和遵循 instrucions 来决定需要注意的内容。S2A 将输入上下文重新生成为只包含相关部分，然后对重新生成的上下文进行注意，以获得最终响应。在实验中，S2A 比标准注意力基于 LLMs 在三个任务中表现出色，包括问答、数学问题和长文生成，S2A 可以提高事实性和公正性，而减少卖舌。
</details></li>
</ul>
<hr>
<h2 id="Graph-Variational-Embedding-Collaborative-Filtering"><a href="#Graph-Variational-Embedding-Collaborative-Filtering" class="headerlink" title="Graph Variational Embedding Collaborative Filtering"></a>Graph Variational Embedding Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11824">http://arxiv.org/abs/2311.11824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narges Sadat Fazeli Dehkordi, Hadi Zare, Parham Moradi, Mahdi Jalili</li>
<li>for: 提高用户体验，如在电商、音乐等应用中。</li>
<li>methods: 使用图变量嵌入方法，即图变量自适应编码器，将用户-项目交互 captured into更加训练可能的特征推广。</li>
<li>results: 对比基于Random embedding的方法，提出了图变量嵌入CF（GVECF）框架，实现了更好的特征传播和层次GCN协同推荐，最终在 recall 和 NDCG 指标上达到了13.78%的提升。<details>
<summary>Abstract</summary>
The customization of recommended content to users holds significant importance in enhancing user experiences across a wide spectrum of applications such as e-commerce, music, and shopping. Graph-based methods have achieved considerable performance by capturing user-item interactions. However, these methods tend to utilize randomly constructed embeddings in the dataset used for training the recommender, which lacks any user preferences. Here, we propose the concept of variational embeddings as a means of pre-training the recommender system to improve the feature propagation through the layers of graph convolutional networks (GCNs). The graph variational embedding collaborative filtering (GVECF) is introduced as a novel framework to incorporate representations learned through a variational graph auto-encoder which are embedded into a GCN-based collaborative filtering. This approach effectively transforms latent high-order user-item interactions into more trainable vectors, ultimately resulting in better performance in terms of recall and normalized discounted cumulative gain(NDCG) metrics. The experiments conducted on benchmark datasets demonstrate that our proposed method achieves up to 13.78% improvement in the recall over the test data.
</details>
<details>
<summary>摘要</summary>
Customization of recommended content to users is crucial in enhancing user experiences in various applications, such as e-commerce, music, and shopping. Graph-based methods have shown significant performance by capturing user-item interactions. However, these methods often rely on randomly constructed embeddings in the training dataset, which neglects user preferences. To address this issue, we propose the concept of variational embeddings as a means of pre-training the recommender system to improve feature propagation through graph convolutional networks (GCNs). We introduce the graph variational embedding collaborative filtering (GVECF) as a novel framework that incorporates representations learned through a variational graph auto-encoder into a GCN-based collaborative filtering. This approach effectively transforms latent high-order user-item interactions into more trainable vectors, resulting in better performance in terms of recall and normalized discounted cumulative gain (NDCG) metrics. Experimental results on benchmark datasets demonstrate that our proposed method achieves up to 13.78% improvement in recall over the test data.
</details></li>
</ul>
<hr>
<h2 id="Generalized-super-resolution-4D-Flow-MRI-–-using-ensemble-learning-to-extend-across-the-cardiovascular-system"><a href="#Generalized-super-resolution-4D-Flow-MRI-–-using-ensemble-learning-to-extend-across-the-cardiovascular-system" class="headerlink" title="Generalized super-resolution 4D Flow MRI – using ensemble learning to extend across the cardiovascular system"></a>Generalized super-resolution 4D Flow MRI – using ensemble learning to extend across the cardiovascular system</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11819">http://arxiv.org/abs/2311.11819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Ericsson, Adam Hjalmarsson, Muhammad Usman Akbar, Edward Ferdian, Mia Bonini, Brandon Hardy, Jonas Schollenberger, Maria Aristova, Patrick Winter, Nicholas Burris, Alexander Fyrdahl, Andreas Sigfridsson, Susanne Schnell, C. Alberto Figueroa, David Nordsletten, Alistair A. Young, David Marlevi</li>
<li>for: 这项研究的目的是探讨4D流体磁共振成像（4D Flow MRI）的超解像能力是否可以在不同的cardiovascular领域中广泛应用。</li>
<li>methods: 该研究使用了不同的 convolutional base 和ensemble learning来评估SR 4D Flow MRI的一致性，并使用了synthetic数据生成在三个不同的领域（心血管、大动脉和脑血管）进行评估。</li>
<li>results: 研究结果表明， ensemble learning可以在不同的领域中提高SR性能，并可以准确地预测高分辨率的速度从低分辨率的输入数据中。同时，优化的网络也可以从下采样的实际数据中恢复原始分辨率的速度，以及生成严格的SR-图像。<details>
<summary>Abstract</summary>
4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive measurement technique capable of quantifying blood flow across the cardiovascular system. While practical use is limited by spatial resolution and image noise, incorporation of trained super-resolution (SR) networks has potential to enhance image quality post-scan. However, these efforts have predominantly been restricted to narrowly defined cardiovascular domains, with limited exploration of how SR performance extends across the cardiovascular system; a task aggravated by contrasting hemodynamic conditions apparent across the cardiovasculature. The aim of our study was to explore the generalizability of SR 4D Flow MRI using a combination of heterogeneous training sets and dedicated ensemble learning. With synthetic training data generated across three disparate domains (cardiac, aortic, cerebrovascular), varying convolutional base and ensemble learners were evaluated as a function of domain and architecture, quantifying performance on both in-silico and acquired in-vivo data from the same three domains. Results show that both bagging and stacking ensembling enhance SR performance across domains, accurately predicting high-resolution velocities from low-resolution input data in-silico. Likewise, optimized networks successfully recover native resolution velocities from downsampled in-vivo data, as well as show qualitative potential in generating denoised SR-images from clinical level input data. In conclusion, our work presents a viable approach for generalized SR 4D Flow MRI, with ensemble learning extending utility across various clinical areas of interest.
</details>
<details>
<summary>摘要</summary>
四维流体磁共振成像（4D Flow MRI）是一种非侵入性测量技术，可量化心血管系统中血液流动的量。 although practical use is limited by spatial resolution and image noise, incorporating trained super-resolution (SR) networks has the potential to enhance image quality post-scan. However, these efforts have been mainly focused on narrowly defined cardiovascular domains, with limited exploration of how SR performance extends across the cardiovascular system; a task that is exacerbated by the contrasting hemodynamic conditions present across the cardiovasculature.我们的研究的目标是探索SR 4D Flow MRI的通用性，使用不同域的训练集和专门的集成学习来评估其性能。我们使用了三个不同的域（心脏、大动脉和脑血管）中的 sintetic 训练数据，以及不同的卷积基和集成学习算法，对域和结构进行评估，以确定它们在不同域中的性能。结果表明，bagging和stacking ensemble  ensemble 能够在不同域上提高SR性能，从低分辨率输入数据中预测高分辨率速度，并且在实际水平上成功地恢复原始分辨率速度。此外，优化的网络还可以生成净化后的SR图像从临床水平的输入数据中。总之，我们的研究提出了一种可行的通用SR 4D Flow MRI方法，使用集成学习来扩展其应用范围。这种方法可以在不同的临床领域中实现高质量的SR成像，并且可以帮助解决血液流动的诊断和评估问题。
</details></li>
</ul>
<hr>
<h2 id="Improving-Real-Estate-Appraisal-with-POI-Integration-and-Areal-Embedding"><a href="#Improving-Real-Estate-Appraisal-with-POI-Integration-and-Areal-Embedding" class="headerlink" title="Improving Real Estate Appraisal with POI Integration and Areal Embedding"></a>Improving Real Estate Appraisal with POI Integration and Areal Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11812">http://arxiv.org/abs/2311.11812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumin Han, Youngjun Park, Sonia Sabir, Jisun An, Dongman Lee</li>
<li>for: 本研究主要针对两个重要挑战，第一是探讨 Points of Interest (POI) 对房屋价值的影响，并提出了一个涵盖性强的数据驱动方法来选择特征。第二是将路网基于的 Areal Embedding 应用于房地产评估，以提高空间理解。</li>
<li>methods: 本研究提出了一个修改后的 POI 特征提取方法，并讨论了每个 POI 对房屋价值评估的影响。然后，我们提出了一个基于掩盖多头注意力的折衣多项式预测模型（AMMASI），它在扩展现有的 ASI 模型的基础上，运用掩盖多头注意力来捕捉地理邻居房屋和相似特征房屋的特征。</li>
<li>results: 我们的模型在现有基eline上出现了明显的提升，并且还提供了未来优化房地产评估方法的可能性。<details>
<summary>Abstract</summary>
Despite advancements in real estate appraisal methods, this study primarily focuses on two pivotal challenges. Firstly, we explore the often-underestimated impact of Points of Interest (POI) on property values, emphasizing the necessity for a comprehensive, data-driven approach to feature selection. Secondly, we integrate road-network-based Areal Embedding to enhance spatial understanding for real estate appraisal. We first propose a revised method for POI feature extraction, and discuss the impact of each POI for house price appraisal. Then we present the Areal embedding-enabled Masked Multihead Attention-based Spatial Interpolation for House Price Prediction (AMMASI) model, an improvement upon the existing ASI model, which leverages masked multi-head attention on geographic neighbor houses and similar-featured houses. Our model outperforms current baselines and also offers promising avenues for future optimization in real estate appraisal methodologies.
</details>
<details>
<summary>摘要</summary>
尽管现有的房地产评估方法有所进步，这种研究主要关注两个重要挑战。首先，我们研究点位 интерес（POI）对房产价值的影响，强调需要一种全面、数据驱动的特征选择方法。其次，我们将路网基于的区域嵌入技术与房产评估相结合，以提高地理理解。我们首先提出了一种POI特征提取方法，然后讨论每个POI对房价评估的影响。接着，我们介绍了使用做废字符串嵌入的掩码多头注意力加速器（AMMASI）模型，这是现有ASI模型的改进，可以更好地利用地理相似特征和邻居房屋的特征。我们的模型在现有基准点上表现出色，并且还提供了未来房地产评估方法的优秀可能性。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-and-Explainable-Law-a-Hybrid-Methodology"><a href="#Large-Language-Models-and-Explainable-Law-a-Hybrid-Methodology" class="headerlink" title="Large Language Models and Explainable Law: a Hybrid Methodology"></a>Large Language Models and Explainable Law: a Hybrid Methodology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11811">http://arxiv.org/abs/2311.11811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Billi, Alessandro Parenti, Giuseppe Pisano, Marco Sanchi</li>
<li>for: 提高法律系统的可用性、使用性和解释性，协助建构一种民主和利益相关的法律技术视角。</li>
<li>methods: 开发了一种方法，用于将高级编程语言中的解释转化为自然语言，以便各种用户快速、明了、访问法律技术。</li>
<li>results: 研究人员通过这些解释，赋予非专业人员执行复杂的法律任务的能力，通过自动化法律比较，对同一个事实进行多种规则基于的推理。<details>
<summary>Abstract</summary>
The paper advocates for LLMs to enhance the accessibility, usage and explainability of rule-based legal systems, contributing to a democratic and stakeholder-oriented view of legal technology. A methodology is developed to explore the potential use of LLMs for translating the explanations produced by rule-based systems, from high-level programming languages to natural language, allowing all users a fast, clear, and accessible interaction with such technologies. The study continues by building upon these explanations to empower laypeople with the ability to execute complex juridical tasks on their own, using a Chain of Prompts for the autonomous legal comparison of different rule-based inferences, applied to the same factual case.
</details>
<details>
<summary>摘要</summary>
文章强调LLM可以提高法律系统的可用性、使用性和解释性，从而推动法律技术具有民主和利益相关的视角。文章提出了一种方法来探讨LLM可以将高级编程语言生成的解释翻译成自然语言，以便所有用户快速、清晰地与这些技术进行交互。研究继续发展了这些解释，以使非专业人士通过自动化的法律比较，执行复杂的法律任务。Here's a word-for-word translation of the text in Traditional Chinese:文章强调LLM可以提高法律系统的可用性、使用性和解释性，从而推动法律技术具有民主和利益相关的视角。文章提出了一种方法来探讨LLM可以将高级编程语言生成的解释翻译成自然语言，以便所有用户快速、清晰地与这些技术进行交互。研究继续发展了这些解释，以使非专业人士通过自动化的法律比较，执行复杂的法律任务。
</details></li>
</ul>
<hr>
<h2 id="DocPedia-Unleashing-the-Power-of-Large-Multimodal-Model-in-the-Frequency-Domain-for-Versatile-Document-Understanding"><a href="#DocPedia-Unleashing-the-Power-of-Large-Multimodal-Model-in-the-Frequency-Domain-for-Versatile-Document-Understanding" class="headerlink" title="DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding"></a>DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11810">http://arxiv.org/abs/2311.11810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Feng, Qi Liu, Hao Liu, Wengang Zhou, Houqiang Li, Can Huang</li>
<li>for:  DocPedia is a novel large multimodal model (LMM) for versatile OCR-free document understanding.</li>
<li>methods: DocPedia directly processes visual input in the frequency domain rather than the pixel space, using a limited number of visual tokens to capture a greater amount of visual and textual information.</li>
<li>results: Extensive experiments conducted on various benchmarks confirm the effectiveness and superior performance of DocPedia over other methods.Here’s the simplified Chinese text in the format you requested:</li>
<li>for:  DocPedia 是一种 novel large multimodal model (LMM)  для多样化 OCR-free 文档理解。</li>
<li>methods: DocPedia 直接在频谱空间处理视觉输入，使用有限数量的视觉 токен来捕捉更多的视觉和文本信息。</li>
<li>results: 广泛的实验表明 DocPedia 的效果和其他方法相比较高。<details>
<summary>Abstract</summary>
This work presents DocPedia, a novel large multimodal model (LMM) for versatile OCR-free document understanding, capable of parsing images up to 2,560$\times$2,560 resolution. Unlike existing work either struggle with high-resolution documents or give up the large language model thus vision or language ability constrained, our DocPedia directly processes visual input in the frequency domain rather than the pixel space. The unique characteristic enables DocPedia to capture a greater amount of visual and textual information using a limited number of visual tokens. To consistently enhance both perception and comprehension abilities of our model, we develop a dual-stage training strategy and enrich instructions/annotations of all training tasks covering multiple document types. Extensive quantitative and qualitative experiments conducted on various publicly available benchmarks confirm the mutual benefits of jointly learning perception and comprehension tasks. The results provide further evidence of the effectiveness and superior performance of our DocPedia over other methods.
</details>
<details>
<summary>摘要</summary>
这个工作介绍了 DocPedia，一种新型的大型多模态模型（LMM），能够无需OCR进行多种文档理解，并且可以处理高分辨率图像（最大2560×2560像素）。与现有的工作不同， DocPedia直接在频谱空间处理视觉输入，而不是像素空间，这使得它能够更好地捕捉更多的视觉和文本信息，只需使用有限的视觉符号。为了不断提高模型的感知和理解能力，我们提出了双Stage训练策略，并对所有训练任务进行了丰富的指令/注释增强。经验证明，这种方法可以同时提高模型的感知和理解能力。广泛的量化和质量测试表明，我们的 DocPedia在其他方法的基础上表现更出色。
</details></li>
</ul>
<hr>
<h2 id="Age-Friendly-Route-Planner-Calculating-Comfortable-Routes-for-Senior-Citizens"><a href="#Age-Friendly-Route-Planner-Calculating-Comfortable-Routes-for-Senior-Citizens" class="headerlink" title="Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens"></a>Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11802">http://arxiv.org/abs/2311.11802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andoni Aranguren, Eneko Osaba, Silvia Urra-Uriarte, Patricia Molina-Costa</li>
<li>for: 本研究旨在提高老年人在城市中的体验，通过开发一款适应老年人的路径规划器。</li>
<li>methods: 该规划器使用了多个变量来评估路径的年龄友好程度，包括路径上的设施数量、舒适元素的存在和避免恶劣路段。</li>
<li>results: 本研究示出了适应老年人的路径规划器可以提供个性化的路径，并且可以帮助创建适应老年人的路径。<details>
<summary>Abstract</summary>
The application of routing algorithms to real-world situations is a widely studied research topic. Despite this, routing algorithms and applications are usually developed for a general purpose, meaning that certain groups, such as ageing people, are often marginalized due to the broad approach of the designed algorithms. This situation may pose a problem in cities which are suffering a slow but progressive ageing of their populations. With this motivation in mind, this paper focuses on describing our implemented Age-Friendly Route Planner, whose goal is to improve the experience in the city for senior citizens. In order to measure the age-friendliness of a route, several variables have been deemed, such as the number of amenities along the route, the amount of comfortable elements found, or the avoidance of sloppy sections. In this paper, we describe one of the main features of the Age-Friendly Route Planner: the preference-based routes, and we also demonstrate how it can contribute to the creation of adapted friendly routes.
</details>
<details>
<summary>摘要</summary>
Routing算法在实际应用中是广泛研究的研究主题。然而，routing算法和应用通常是为普遍目标设计的，导致certain groups，如年龄增长的人群，因为设计的算法过广而被排除在外。这种情况可能在年龄增长的城市中带来问题。基于这种动机，这篇论文主要关注描述我们实施的年龄友好路径规划器，以提高城市内的老年人体验。为了测量路径年龄友好程度，我们考虑了许多变量，如路径上的设施数量、舒适元素的存在量或恶势力的避免。在这篇论文中，我们介绍了 preference-based路径的一个主要特点，并示例如何该功能可以为创造适应友好路径做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Igniting-Language-Intelligence-The-Hitchhiker’s-Guide-From-Chain-of-Thought-Reasoning-to-Language-Agents"><a href="#Igniting-Language-Intelligence-The-Hitchhiker’s-Guide-From-Chain-of-Thought-Reasoning-to-Language-Agents" class="headerlink" title="Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents"></a>Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11797">http://arxiv.org/abs/2311.11797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zoeyyao27/cot-igniting-agent">https://github.com/zoeyyao27/cot-igniting-agent</a></li>
<li>paper_authors: Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, Hai Zhao</li>
<li>For: The paper discusses the chain-of-thought (CoT) reasoning techniques used in large language models (LLMs) and their applications in developing autonomous language agents.* Methods: The paper explores the foundational mechanics of CoT techniques, including their efficacy and the paradigm shift in CoT reasoning.* Results: The paper discusses the merits of CoT reasoning, including its ability to enhance interpretability, controllability, and flexibility, and its potential for generalization, efficiency, customization, scaling, and safety.Here are the three key points in Simplified Chinese text:* For: 这篇论文讨论了大语言模型（LLM）中的链条思维（CoT）技术，以及它们在语言代理人的发展中的应用。* Methods: 论文探讨了CoT技术的基础机制，包括它的有效性和CoT思维的 парадиг shift。* Results: 论文讨论了CoT思维的优点，包括它的解释性、可控性、灵活性和普遍性，以及其在不同领域中的应用前景。<details>
<summary>Abstract</summary>
Large language models (LLMs) have dramatically enhanced the field of language intelligence, as demonstrably evidenced by their formidable empirical performance across a spectrum of complex reasoning tasks. Additionally, theoretical proofs have illuminated their emergent reasoning capabilities, providing a compelling showcase of their advanced cognitive abilities in linguistic contexts. Critical to their remarkable efficacy in handling complex reasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning techniques, obliging them to formulate intermediate steps en route to deriving an answer. The CoT reasoning approach has not only exhibited proficiency in amplifying reasoning performance but also in enhancing interpretability, controllability, and flexibility. In light of these merits, recent research endeavors have extended CoT reasoning methodologies to nurture the development of autonomous language agents, which adeptly adhere to language instructions and execute actions within varied environments. This survey paper orchestrates a thorough discourse, penetrating vital research dimensions, encompassing: (i) the foundational mechanics of CoT techniques, with a focus on elucidating the circumstances and justification behind its efficacy; (ii) the paradigm shift in CoT; and (iii) the burgeoning of language agents fortified by CoT approaches. Prospective research avenues envelop explorations into generalization, efficiency, customization, scaling, and safety. This paper caters to a wide audience, including beginners seeking comprehensive knowledge of CoT reasoning and language agents, as well as experienced researchers interested in foundational mechanics and engaging in cutting-edge discussions on these topics. A repository for the related papers is available at https://github.com/Zoeyyao27/CoT-Igniting-Agent.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经对语言智能领域产生了巨大的影响，这可以通过它们在复杂的推理任务上表现出色来证明。此外，理论证明也揭示了它们在语言上的高级认知能力。LLMs 利用了Chain of Thought（CoT）推理技术，这使得它们在得出答案之前需要形ulate 中间步骤。CoT 推理方法不仅提高了推理性能，还提高了可读性、可控性和灵活性。由于这些优点， latest research efforts 将 CoT 推理方法应用于语言代理人的开发，以便这些代理人能够遵循语言指令并在不同环境中执行操作。本文协调了一个全面的讨论，涵盖：（i）CoT 技术的基础机理，强调解释 CoT 的效果的原因和情况；（ii）CoT 推理方法的变革；以及（iii）通过 CoT 方法强化语言代理人的发展。未来研究的可能性包括探索 generalization、效率、自定义、扩展和安全。这篇文章适合各种读者，包括想要了解 CoT 推理和语言代理人的新手和经验研究者。相关论文库可以在 https://github.com/Zoeyyao27/CoT-Igniting-Agent 找到。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Boundaries-A-Comprehensive-Survey-of-Transferable-Attacks-on-AI-Systems"><a href="#Beyond-Boundaries-A-Comprehensive-Survey-of-Transferable-Attacks-on-AI-Systems" class="headerlink" title="Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems"></a>Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11796">http://arxiv.org/abs/2311.11796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan</li>
<li>for: 本研究旨在探讨智能系统中的传染攻击，尤其是在Cyber-Physical Security领域。</li>
<li>methods: 本文综述了不同领域中的传染攻击，包括图像、文本、图гра、音频和视频等领域。同时，本文还分析了不同的攻击方法，包括数据、过程、模型和系统等方面。</li>
<li>results: 本文发现了许多传染攻击可以在不同的领域中进行应用，并且这些攻击可以对智能系统的安全性产生很大的影响。此外，本文还提出了一些可能的研究方向，以便更好地探讨传染攻击的领域。<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) systems such as autonomous vehicles, facial recognition, and speech recognition systems are increasingly integrated into our daily lives. However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks. In particular, numerous attacks are designed to target a particular model or system, yet their effects can spread to additional targets, referred to as transferable attacks. Although considerable efforts have been directed toward developing transferable attacks, a holistic understanding of the advancements in transferable attacks remains elusive. In this paper, we comprehensively explore learning-based attacks from the perspective of transferability, particularly within the context of cyber-physical security. We delve into different domains -- the image, text, graph, audio, and video domains -- to highlight the ubiquitous and pervasive nature of transferable attacks. This paper categorizes and reviews the architecture of existing attacks from various viewpoints: data, process, model, and system. We further examine the implications of transferable attacks in practical scenarios such as autonomous driving, speech recognition, and large language models (LLMs). Additionally, we outline the potential research directions to encourage efforts in exploring the landscape of transferable attacks. This survey offers a holistic understanding of the prevailing transferable attacks and their impacts across different domains.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）系统如自动驾驶、人脸识别和语音识别系统在我们日常生活中越来越普遍。然而，尽管它们的实用性，这些AI系统却易受到各种攻击，如对抗攻击、后门攻击、数据毒品攻击、成员推理攻击、模型反向攻击和模型窃取攻击。特别是，许多攻击是专门设计为targeting a particular model or system，但它们的效果可以扩散到其他目标，称为可传递性攻击。虽然有大量的努力在开发可传递性攻击方面，但总的来说，对这些攻击的全面理解仍然不够。在这篇论文中，我们全面探讨基于学习的攻击，特别是在Cyber-Physical Security（Cyber-Physical Security）领域中的可传递性攻击。我们在不同的领域（图像、文本、图ogram、音频、视频）中探讨了可传递性攻击的普遍和普遍性。这篇论文将攻击的架构从不同的视角进行分类和评论，包括数据、过程、模型和系统的视角。我们还考虑了可传递性攻击在实际场景中的影响，如自动驾驶、语音识别和大型自然语言模型（LLMs）。此外，我们还提出了可能的研究方向，以便在探索可传递性攻击的领域进行更多的努力。这篇论文提供了可传递性攻击的全面理解，并对不同领域中的可传递性攻击产生了影响。
</details></li>
</ul>
<hr>
<h2 id="PhytNet-–-Tailored-Convolutional-Neural-Networks-for-Custom-Botanical-Data"><a href="#PhytNet-–-Tailored-Convolutional-Neural-Networks-for-Custom-Botanical-Data" class="headerlink" title="PhytNet – Tailored Convolutional Neural Networks for Custom Botanical Data"></a>PhytNet – Tailored Convolutional Neural Networks for Custom Botanical Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12088">http://arxiv.org/abs/2311.12088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jamie R. Sykes, Katherine Denby, Daniel W. Franks</li>
<li>for: This paper is written for the purpose of developing a new deep learning model for automated disease, weed, and crop classification in agriculture, specifically using computer vision techniques.</li>
<li>methods: The paper uses a novel dataset of infrared cocoa tree images and develops a new convolutional neural network (CNN) architecture called PhytNet. The authors also compare the performance of PhytNet with existing CNN architectures like ResNet and EfficientNet.</li>
<li>results: The paper demonstrates the development and performance of PhytNet on a specific dataset of cocoa tree images. The results show that PhytNet displays excellent attention to relevant features, no overfitting, and an exceptionally low computation cost, making it a promising candidate for rapid disease or plant classification, or precise localisation of disease symptoms for autonomous systems.<details>
<summary>Abstract</summary>
Automated disease, weed and crop classification with computer vision will be invaluable in the future of agriculture. However, existing model architectures like ResNet, EfficientNet and ConvNeXt often underperform on smaller, specialised datasets typical of such projects. We address this gap with informed data collection and the development of a new CNN architecture, PhytNet. Utilising a novel dataset of infrared cocoa tree images, we demonstrate PhytNet's development and compare its performance with existing architectures. Data collection was informed by analysis of spectroscopy data, which provided useful insights into the spectral characteristics of cocoa trees. Such information could inform future data collection and model development. Cocoa was chosen as a focal species due to the diverse pathology of its diseases, which pose significant challenges for detection. ResNet18 showed some signs of overfitting, while EfficientNet variants showed distinct signs of overfitting. By contrast, PhytNet displayed excellent attention to relevant features, no overfitting, and an exceptionally low computation cost (1.19 GFLOPS). As such PhytNet is a promising candidate for rapid disease or plant classification, or precise localisation of disease symptoms for autonomous systems.
</details>
<details>
<summary>摘要</summary>
自动化疾病、植物和作物分类使用计算机视觉将在农业未来非常重要。然而，现有的模型架构如ResNet、EfficientNet和ConvNeXt经常在小型特殊数据集上表现不佳。我们通过了 informed data collection和开发新的CNN架构，即PhytNet，解决这个问题。我们使用了一个新的红外巧克力树图像集来证明PhytNet的发展和与现有架构进行比较。数据收集是根据谱spectroscopy数据进行分析，提供了有用的信息，例如巧克力树的spectral特征。这种信息可能会在未来的数据收集和模型开发中提供帮助。巧克力是我们选择的关键种类，因为它的疾病多样化和诊断具有挑战性。ResNet18显示了一定程度的过拟合，而EfficientNet变种显示了明显的过拟合。相比之下，PhytNet具有优秀的注意力特征，没有过拟合，计算成本非常低（1.19 GFLOPS）。因此，PhytNet是一个有前途的 кандидат，用于快速的疾病或植物分类，或精确的疾病 симптом的自动化识别。
</details></li>
</ul>
<hr>
<h2 id="Responsible-AI-Research-Needs-Impact-Statements-Too"><a href="#Responsible-AI-Research-Needs-Impact-Statements-Too" class="headerlink" title="Responsible AI Research Needs Impact Statements Too"></a>Responsible AI Research Needs Impact Statements Too</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11776">http://arxiv.org/abs/2311.11776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandra Olteanu, Michael Ekstrand, Carlos Castillo, Jina Suh</li>
<li>for: The paper is written to explore the potential unintended and adverse consequences of responsible artificial intelligence (RAI), ethical AI, and ethics in AI.</li>
<li>methods: The paper uses a qualitative research approach, including a literature review and expert interviews, to identify potential risks and challenges associated with RAI, ethical AI, and ethics in AI.</li>
<li>results: The paper highlights several potential unintended and adverse consequences of RAI, ethical AI, and ethics in AI, including the risk of reinforcing existing biases and power imbalances, the potential for unintended consequences of AI systems, and the need for careful consideration of ethical issues in AI development and deployment.<details>
<summary>Abstract</summary>
All types of research, development, and policy work can have unintended, adverse consequences - work in responsible artificial intelligence (RAI), ethical AI, or ethics in AI is no exception.
</details>
<details>
<summary>摘要</summary>
所有类型的研究、开发和政策工作都可能有意外、不良影响 - 负责任人工智能（RAI）、伦理AI或AI伦理都不例外。Note that "负责任人工智能" (RAI) is a term used in China to refer to "ethical AI" or "responsible AI".
</details></li>
</ul>
<hr>
<h2 id="Intelligent-methods-for-business-rule-processing-State-of-the-art"><a href="#Intelligent-methods-for-business-rule-processing-State-of-the-art" class="headerlink" title="Intelligent methods for business rule processing: State-of-the-art"></a>Intelligent methods for business rule processing: State-of-the-art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11775">http://arxiv.org/abs/2311.11775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cristiano André da Costa, Uélison Jean Lopes dos Santos, Eduardo Souza dos Reis, Rodolfo Stoffel Antunes, Henrique Chaves Pacheco, Thaynã da Silva França, Rodrigo da Rosa Righi, Jorge Luis Victória Barbosa, Franklin Jebadoss, Jorge Montalvao, Rogerio Kunkel</li>
<li>for: 这篇论文主要用于介绍最新的智能技术在业务规则处理方面的应用。</li>
<li>methods: 论文采用了涵义检索和机器学习等智能方法进行研究。</li>
<li>results: 论文对市场前十家供应商和其主要解决方案进行了审查和分析。<details>
<summary>Abstract</summary>
In this article, we provide an overview of the latest intelligent techniques used for processing business rules. We have conducted a comprehensive survey of the relevant literature on robot process automation, with a specific focus on machine learning and other intelligent approaches. Additionally, we have examined the top vendors in the market and their leading solutions to tackle this issue.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提供了对最新的智能技术处理商业规则的概述。我们进行了对相关文献的全面调查，具体强调机器学习和其他智能方法。此外，我们还评估了市场上领先的供应商和他们的主要解决方案。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Unseen-Potential-of-Graph-Learning-through-MLPs-Effective-Graph-Learners-Using-Propagation-Embracing-MLPs"><a href="#Unveiling-the-Unseen-Potential-of-Graph-Learning-through-MLPs-Effective-Graph-Learners-Using-Propagation-Embracing-MLPs" class="headerlink" title="Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs"></a>Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11759">http://arxiv.org/abs/2311.11759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong-Min Shin, Won-Yong Shin</li>
<li>for: 本研究旨在使用多层感知器（MLP）解决 semi-supervised 节点分类问题，通过在教师图神经网络（GNN）的知识填充（KD）下训练学生 MLP。先前的研究主要集中在在 KD 过程中匹配教师和学生模型的输出概率分布上，尚未系统地研究如何在 KD 过程中显式地注入结构信息。</li>
<li>methods: 我们提出了 Propagate &amp; Distill（P&amp;D）方法，它在教师 GNN 的输出上进行了传播，然后进行 KD。P&amp;D 可以被解释为一种简化的 inverse propagation 的过程，它可以让学生 MLP 显式地学习特征变换 T 和卷积 $\Pi$。</li>
<li>results: 通过对实际世界 benchmark 数据集进行了广泛的评估，我们证明了 P&amp;D 的效果，并表明了学生 MLP 的性能得到了进一步提高。<details>
<summary>Abstract</summary>
Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve semi-supervised node classification on graphs, by training a student MLP by knowledge distillation (KD) from a teacher graph neural network (GNN). While previous studies have focused mostly on training the student MLP by matching the output probability distributions between the teacher and student models during KD, it has not been systematically studied how to inject the structural information in an explicit and interpretable manner. Inspired by GNNs that separate feature transformation $T$ and propagation $\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\Pi$. Although this can be achieved by applying the inverse propagation $\Pi^{-1}$ before distillation from the teacher GNN, it still comes with a high computational cost from large matrix multiplications during training. To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing further performance boost of the student MLP.
</details>
<details>
<summary>摘要</summary>
Inspired by GNNs that separate feature transformation $T$ and propagation $\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\Pi$. This can be achieved by applying the inverse propagation $\Pi^{-1}$ before distillation from the teacher GNN, but this comes with a high computational cost from large matrix multiplications during training.To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing a further performance boost of the student MLP.
</details></li>
</ul>
<hr>
<h2 id="LSTM-CNN-An-efficient-diagnostic-network-for-Parkinson’s-disease-utilizing-dynamic-handwriting-analysis"><a href="#LSTM-CNN-An-efficient-diagnostic-network-for-Parkinson’s-disease-utilizing-dynamic-handwriting-analysis" class="headerlink" title="LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis"></a>LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11756">http://arxiv.org/abs/2311.11756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Wang, Junqing Huang, Sven Nomm, Marianna Chatzakou, Kadri Medijainen, Aaro Toomela, Michael Ruzhansky<br>for: 这个研究的目的是提出一种基于深度学习的动手写分析方法，以提供早期诊断 Parkinson 病的 объектив标准。methods: 该方法采用了一种混合深度学习approach，结合了LSTM和CNN两种不同的神经网络模型，以提高分类精度和计算效率。results: 实验结果表明，提出的方法在新的 DraWritePD 数据集上达到了96.2%的高精度分类率，并在 PaHaW 数据集上达到了90.7%的高精度分类率。此外，该方法还具有轻量级的参数和计算量，可以在几十万个样本上进行实时推理。<details>
<summary>Abstract</summary>
Background and objectives: Dynamic handwriting analysis, due to its non-invasive and readily accessible nature, has recently emerged as a vital adjunctive method for the early diagnosis of Parkinson's disease. In this study, we design a compact and efficient network architecture to analyse the distinctive handwriting patterns of patients' dynamic handwriting signals, thereby providing an objective identification for the Parkinson's disease diagnosis.   Methods: The proposed network is based on a hybrid deep learning approach that fully leverages the advantages of both long short-term memory (LSTM) and convolutional neural networks (CNNs). Specifically, the LSTM block is adopted to extract the time-varying features, while the CNN-based block is implemented using one-dimensional convolution for low computational cost. Moreover, the hybrid model architecture is continuously refined under ablation studies for superior performance. Finally, we evaluate the proposed method with its generalization under a five-fold cross-validation, which validates its efficiency and robustness.   Results: The proposed network demonstrates its versatility by achieving impressive classification accuracies on both our new DraWritePD dataset ($96.2\%$) and the well-established PaHaW dataset ($90.7\%$). Moreover, the network architecture also stands out for its excellent lightweight design, occupying a mere $0.084$M of parameters, with a total of only $0.59$M floating-point operations. It also exhibits near real-time CPU inference performance, with inference times ranging from $0.106$ to $0.220$s.   Conclusions: We present a series of experiments with extensive analysis, which systematically demonstrate the effectiveness and efficiency of the proposed hybrid neural network in extracting distinctive handwriting patterns for precise diagnosis of Parkinson's disease.
</details>
<details>
<summary>摘要</summary>
背景和目标：动态手写分析因为其不侵入性和Ready accessible的特点，最近在诊断parkinson病的早期诊断中得到了广泛应用。在本研究中，我们设计了一个紧凑型和高效的网络架构，以分析患者的动态手写信号特征，从而提供一种对parkinson病诊断的 объектив标准。方法：提议的网络采用了一种混合深度学习方法，旨在挖掘患者的动态手写特征。具体来说，LSTM块被采用来提取时变特征，而CNN基于的块则是通过一维 convolution来实现低计算成本。此外，我们还进行了一系列的ablation study，以进一步提高表现。最后，我们使用五fold Cross-Validation进行评估，以验证提议的方法的可行性和稳定性。结果：提议的网络在我们的新的DraWritePD数据集上达到了96.2%的分类精度，同时在已知的PaHaW数据集上也达到了90.7%的分类精度。此外，该网络架构还具有优秀的轻量级设计，占用约0.084个参数，总计约0.59亿浮点运算。它还表现出了几乎实时的CPU执行时间，执行时间在0.106-0.220秒之间。结论：我们通过了一系列的实验和分析，系统地证明了提议的混合神经网络在诊断parkinson病的精度和效率。
</details></li>
</ul>
<hr>
<h2 id="A-Large-Scale-Car-Parts-LSCP-Dataset-for-Lightweight-Fine-Grained-Detection"><a href="#A-Large-Scale-Car-Parts-LSCP-Dataset-for-Lightweight-Fine-Grained-Detection" class="headerlink" title="A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection"></a>A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11754">http://arxiv.org/abs/2311.11754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Jie, Zhong Yilin, Cao Qianqian</li>
<li>for: 本研究旨在提供一个大规模、细化的汽车AI数据集，用于探索汽车部件检测任务中的可能性。</li>
<li>methods: 本研究使用了自然摄像头和在线网站收集的84,162张图像，并提出了一种新的半监督自动标注方法，以及一种基于预训练检测器的针对性提升技术。</li>
<li>results: 研究人员通过使用许多轻量级YOLO系列检测器进行精细的汽车部件检测，并证明了数据集的有效性。<details>
<summary>Abstract</summary>
Automotive related datasets have previously been used for training autonomous driving systems or vehicle classification tasks. However, there is a lack of datasets in the field of automotive AI for car parts detection, and most available datasets are limited in size and scope, struggling to cover diverse scenarios. To address this gap, this paper presents a large-scale and fine-grained automotive dataset consisting of 84,162 images for detecting 12 different types of car parts. This dataset was collected from natural cameras and online websites which covers various car brands, scenarios, and shooting angles. To alleviate the burden of manual annotation, we propose a novel semi-supervised auto-labeling method that leverages state-of-the-art pre-trained detectors. Moreover, we study the limitations of the Grounding DINO approach for zero-shot labeling. Finally, we evaluate the effectiveness of our proposed dataset through fine-grained car parts detection by training several lightweight YOLO-series detectors.
</details>
<details>
<summary>摘要</summary>
自动驾驶系统或车型分类任务上使用了汽车相关数据集。然而，车部AI领域内有数据集缺失，现有数据集大多受限，缺乏多样化场景的覆盖。为了填补这一空白，本文提出了一个大规模、细致的汽车数据集，包含12种不同的车部类型的84,162张图像。这个数据集来自于自然摄像头和在线网站，覆盖了多种车型、场景和拍摄角度。为了避免手动标注的劳动ious burden，我们提出了一种新的半supervised自动标注方法，利用了当前领先的预训练检测器。此外，我们研究了零shot标签Grounding DINO的局限性。最后，我们通过使用多种轻量级YOLO系列检测器进行细致的车部检测来评估我们提出的数据集的有效性。
</details></li>
</ul>
<hr>
<h2 id="Sparse4D-v3-Advancing-End-to-End-3D-Detection-and-Tracking"><a href="#Sparse4D-v3-Advancing-End-to-End-3D-Detection-and-Tracking" class="headerlink" title="Sparse4D v3: Advancing End-to-End 3D Detection and Tracking"></a>Sparse4D v3: Advancing End-to-End 3D Detection and Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11722">http://arxiv.org/abs/2311.11722</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linxuewu/sparse4d">https://github.com/linxuewu/sparse4d</a></li>
<li>paper_authors: Xuewu Lin, Zixiang Pei, Tianwei Lin, Lichao Huang, Zhizhong Su</li>
<li>for: 这篇论文主要针对 autonomous driving 视觉系统中的 3D 检测和跟踪两个基本任务进行深入研究，基于 Sparse4D 框架。</li>
<li>methods: 本文引入了两个辅助训练任务（时间实例净化和质量评估），并提出了分离注意力的方法，从而对检测性能进行了重要改进。</li>
<li>results: 经验表明，在 nuScenes 测试集上，我们的提出改进可以获得显著提高，包括 mAP 、NDS 和 AMOTA 的提高率。最佳模型在 nuScenes 测试集上达到了 71.9% NDS 和 67.7% AMOTA。<details>
<summary>Abstract</summary>
In autonomous driving perception systems, 3D detection and tracking are the two fundamental tasks. This paper delves deeper into this field, building upon the Sparse4D framework. We introduce two auxiliary training tasks (Temporal Instance Denoising and Quality Estimation) and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. Additionally, we extend the detector into a tracker using a straightforward approach that assigns instance ID during inference, further highlighting the advantages of query-based algorithms. Extensive experiments conducted on the nuScenes benchmark validate the effectiveness of the proposed improvements. With ResNet50 as the backbone, we witnessed enhancements of 3.0\%, 2.2\%, and 7.6\% in mAP, NDS, and AMOTA, achieving 46.9\%, 56.1\%, and 49.0\%, respectively. Our best model achieved 71.9\% NDS and 67.7\% AMOTA on the nuScenes test set. Code will be released at \url{https://github.com/linxuewu/Sparse4D}.
</details>
<details>
<summary>摘要</summary>
自动驾驶视觉系统中，3D探测和跟踪是两个基本任务。这篇论文将深入探讨这一领域，基于Sparse4D框架。我们引入了两个辅助训练任务（时间实例干净和质量估计），并提出了分离注意力的方法，导致探测性能得到了显著提高。此外，我们将探测器转换成跟踪器，使用简单的方法，在推理时分配实例ID，进一步发挥了查询基于算法的优势。我们在nuScenes benchmark上进行了广泛的实验， validate了我们提出的改进方法的效果。使用ResNet50作为背景网络，我们在mAP、NDS和AMOTA中提高了3.0\%、2.2\%和7.6\%，分别达到了46.9\%、56.1\%和49.0\%。我们的最佳模型在nuScenes测试集上达到了71.9\%的NDS和67.7\%的AMOTA。代码将在 GitHub上发布，详细信息请参考 \url{https://github.com/linxuewu/Sparse4D}.
</details></li>
</ul>
<hr>
<h2 id="Can-we-infer-the-presence-of-Differential-Privacy-in-Deep-Learning-models’-weights-Towards-more-secure-Deep-Learning"><a href="#Can-we-infer-the-presence-of-Differential-Privacy-in-Deep-Learning-models’-weights-Towards-more-secure-Deep-Learning" class="headerlink" title="Can we infer the presence of Differential Privacy in Deep Learning models’ weights? Towards more secure Deep Learning"></a>Can we infer the presence of Differential Privacy in Deep Learning models’ weights? Towards more secure Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11717">http://arxiv.org/abs/2311.11717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xehartnort/dp-from-weights">https://github.com/xehartnort/dp-from-weights</a></li>
<li>paper_authors: Jiménez-López, Daniel, Rodríguez-Barroso, Nuria, Luzón, M. Victoria, Herrera, Francisco</li>
<li>for: 保护数据和模型免受攻击，确保数据隐私。</li>
<li>methods: 使用Diff Privacy Stochastic Gradient Descent（DP-SGD）实现数据隐私。</li>
<li>results: 通过分析模型参数，可以判断模型是否在训练过程中使用了Diff Privacy，不需要信任模型提供者。<details>
<summary>Abstract</summary>
Differential Privacy (DP) is a key property to protect data and models from integrity attacks. In the Deep Learning (DL) field, it is commonly implemented through the Differentially Private Stochastic Gradient Descent (DP-SGD). However, when a model is shared or released, there is no way to check whether it is differentially private, that is, it required to trust the model provider. This situation poses a problem when data privacy is mandatory, specially with current data regulations, as the presence of DP can not be certificated consistently by any third party. Thus, we face the challenge of determining whether a DL model has been trained with DP, according to the title question: Can we infer the presence of Differential Privacy in Deep Learning models' weights? Since the DP-SGD significantly changes the training process of a DL model, we hypothesize that DP leaves an imprint in the weights of a DL model, which can be used to predict whether a model has been trained with DP regardless of its architecture and the training dataset. In this paper, we propose to employ the imprint in model weights of using DP to infer the presence of DP training in a DL model. To substantiate our hypothesis, we developed an experimental methodology based on two datasets of weights of DL models, each with models with and without DP training and a meta-classifier to infer whether DP was used in the training process of a DL model, by accessing its weights. We accomplish both, the removal of the requirement of a trusted model provider and a strong foundation for this interesting line of research. Thus, our contribution is an additional layer of security on top of the strict private requirements of DP training in DL models, towards to DL models.
</details>
<details>
<summary>摘要</summary>
diffeential privacy (DP) 是一种保护数据和模型的重要性能。在深度学习（DL）领域，通常通过差分 private stochastic gradient descent (DP-SGD) 实现。但当模型被分享或发布时，没有方式来检查该模型是否具有差分隐私，即需要信任模型提供者。这种情况对于数据隐私是必要的，特别是现有的数据法规，因为差分隐私的存在无法被第三方证明。因此，我们面临着判断一个深度学习模型是否在训练过程中使用差分隐私的挑战。根据标题提问，我们问：可以通过深度学习模型的参数来推断它是否在差分隐私训练中？因为差分-SGD 对深度学习模型的训练过程进行了重要变化，我们假设差分隐私会留下在深度学习模型的参数中的印记，可以用来预测该模型是否在差分隐私训练中，无论其架构和训练数据。在这篇论文中，我们提议使用差分隐私训练中模型参数中的印记来判断深度学习模型是否在差分隐私训练中。为了证实我们的假设，我们采用了一种实验方法，该方法基于两个深度学习模型参数的数据集，每个数据集包含具有和不具有差分隐私训练的模型，以及一个元类фика器来预测深度学习模型是否在差分隐私训练中。通过这种方法，我们成功地 removeds了需要信任模型提供者的要求，并提供了一种强大的基础 для这一有趣的研究领域。因此，我们的贡献是在差分隐私训练中添加了一层安全性，以加强深度学习模型的隐私保护。
</details></li>
</ul>
<hr>
<h2 id="Control-in-Hybrid-Chatbots"><a href="#Control-in-Hybrid-Chatbots" class="headerlink" title="Control in Hybrid Chatbots"></a>Control in Hybrid Chatbots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11701">http://arxiv.org/abs/2311.11701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Thomas Rüdel, Jochen L. Leidner</li>
<li>for: 商业规则引擎和嵌入式神经语音助手的集成</li>
<li>methods: 使用商业规则引擎和嵌入式神经网络模型的集成方式，以实现更高水平的控制和避免模型“幻觉”现象</li>
<li>results: 研究人员通过实践和分析，发现这种集成方式可以提供更高的控制级别和更好的性能，同时避免模型“幻觉”现象的出现<details>
<summary>Abstract</summary>
Customer data typically is held in database systems, which can be seen as rule-based knowledge base, whereas businesses increasingly want to benefit from the capabilities of large, pre-trained language models.   In this technical report, we describe a case study of how a commercial rule engine and an integrated neural chatbot may be integrated, and what level of control that particular integration mode leads to. We also discuss alternative ways (including past ways realized in other systems) how researchers strive to maintain control and avoid what has recently been called model "hallucination".
</details>
<details>
<summary>摘要</summary>
客户数据通常被存储在数据库系统中，可以看作为规则基本知识库。而企业正在寻求利用大量预训练语言模型的能力。在这份技术报告中，我们描述了一个商业规则引擎和一个集成的神经网络聊天机器人的集成方式，该集成方式导致了什么样的控制水平。我们还讨论了其他方法（包括过去在其他系统中实现的方法）如何维护控制并避免最近被称为“模型幻觉”的问题。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Low-rank-Adaptation-of-Pre-trained-Language-Models"><a href="#Sparse-Low-rank-Adaptation-of-Pre-trained-Language-Models" class="headerlink" title="Sparse Low-rank Adaptation of Pre-trained Language Models"></a>Sparse Low-rank Adaptation of Pre-trained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11696">http://arxiv.org/abs/2311.11696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsinghuac3i/sora">https://github.com/tsinghuac3i/sora</a></li>
<li>paper_authors: Ning Ding, Xingtai Lv, Qiaosen Wang, Yulin Chen, Bowen Zhou, Zhiyuan Liu, Maosong Sun</li>
<li>for: 提高 fine-tuning 大型自然语言模型的效率和效iveness</li>
<li>methods: 增加 LoRA 方法的灵活性，通过动态调整归一化级别来控制约束维度</li>
<li>results: SoRA 可以与其他基eline相比，即使剩下 70% 参数和 70% 训练时间，也可以获得更好的表现<details>
<summary>Abstract</summary>
Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of non-zero parameters on the model's memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.
</details>
<details>
<summary>摘要</summary>
大量语言模型的精细调整已被广泛研究，以提高效率和表现。LoRA方法在这些研究中具有重要地位，假设适应过程是低维度的。虽然LoRA已经表现出色，但它使用固定和不可变的内在维度，可能不是理想的选择。我们认为需要更 flexible的适应方式，于是我们扩展了LoRA方法，并将其称为SoRA。在训练阶段，我们通过在训练过程中使用适应器来控制维度的卡达利度，使得SoRA模块在执行过程中可以动态地调整其内在维度。在推理阶段，我们可以根据适应器的输出来决定是否保留每个SoRA模块中的参数块。我们的方法可以强化LoRA的表现力，同时efficiently 控制参数的数量。我们还引入了一个缩短调度器来考虑SoRA模块中参数的数量对模型的记忆和泛化造成的影响。我们的实验结果表明，SoRA可以在70% retained parameters和70% 训练时间下超越其他基elines。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Text-Retrieval-with-Progressive-Learning"><a href="#Towards-Robust-Text-Retrieval-with-Progressive-Learning" class="headerlink" title="Towards Robust Text Retrieval with Progressive Learning"></a>Towards Robust Text Retrieval with Progressive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11691">http://arxiv.org/abs/2311.11691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Wu, Yulei Qin, Enwei Zhang, Zihan Xu, Yuting Gao, Ke Li, Xing Sun</li>
<li>for: This paper aims to improve the performance of large language models (LLMs) in retrieving up-to-date and domain-specific information by proposing a progressively learned embeddings (PEG) model.</li>
<li>methods: The PEG model uses a progressive learning mechanism that dynamically modulates its attention to samples throughout the entire training process, and it is trained on more than 100 million data covering various tasks and domains.</li>
<li>results: The PEG model outperforms state-of-the-art embeddings in retrieving true positives, demonstrating its significant potential for applications in LLMs.<details>
<summary>Abstract</summary>
Retrieval augmentation has become an effective solution to empower large language models (LLMs) with external and verified knowledge sources from the database, which overcomes the limitations and hallucinations of LLMs in handling up-to-date and domain-specific information. However, existing embedding models for text retrieval usually have three non-negligible limitations. First, the number and diversity of samples in a batch are too restricted to supervise the modeling of textual nuances at scale. Second, the high proportional noise are detrimental to the semantic correctness and consistency of embeddings. Third, the equal treatment to easy and difficult samples would cause sub-optimum convergence of embeddings with poorer generalization. In this paper, we propose the PEG, a progressively learned embeddings for robust text retrieval. Specifically, we increase the training in-batch negative samples to 80,000, and for each query, we extracted five hard negatives. Concurrently, we incorporated a progressive learning mechanism, enabling the model to dynamically modulate its attention to the samples throughout the entire training process. Additionally, PEG is trained on more than 100 million data, encompassing a wide range of domains (e.g., finance, medicine, and tourism) and covering various tasks (e.g., question-answering, machine reading comprehension, and similarity matching). Extensive experiments conducted on C-MTEB and DuReader demonstrate that PEG surpasses state-of-the-art embeddings in retrieving true positives, highlighting its significant potential for applications in LLMs. Our model is publicly available at https://huggingface.co/TownsWu/PEG.
</details>
<details>
<summary>摘要</summary>
大量语言模型（LLM）的问题解决方法之一是使用数据库中的可靠和证明的知识来强化LLM，这种方法可以超越LLM在处理最新和域pecific信息方面的局限性和偏见。然而，现有的文本检索嵌入模型通常具有三种不可忽略的限制。首先，批处理中的样本数量和多样性太少，无法全面supervise模型处理文本细节的各种变化。其次，高卷积噪音会导致嵌入的semantic正确性和一致性受到损害。第三，对于易于处理和困难处理的样本进行相同的处理会导致嵌入的优化不佳，从而影响其总体性能。在这篇论文中，我们提出了Progressive Embeddings for Robust Text Retrieval（PEG）模型，用于解决这些限制。具体来说，我们增加了批处理中的负样本数量至80,000，并对每个查询选择五个困难的负样本。同时，我们还实现了一种进程学习机制，使得模型可以在整个训练过程中动态调整对样本的注意力。此外，PEG模型在1000万多个数据上进行训练，覆盖了多个领域（如金融、医学和旅游等）和多种任务（如问答、机器阅读理解和相似性匹配等）。我们在C-MTEB和DuReader上进行了广泛的实验，显示PEG模型在检索真正正确的样本方面表现出色， highlighting its significant potential for LLM applications。我们的模型可以在https://huggingface.co/TownsWu/PEG中找到。
</details></li>
</ul>
<hr>
<h2 id="Refactoring-Programs-Using-Large-Language-Models-with-Few-Shot-Examples"><a href="#Refactoring-Programs-Using-Large-Language-Models-with-Few-Shot-Examples" class="headerlink" title="Refactoring Programs Using Large Language Models with Few-Shot Examples"></a>Refactoring Programs Using Large Language Models with Few-Shot Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11690">http://arxiv.org/abs/2311.11690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Yusuke Oda, Jun Suzuki, Makoto Morishita, Yutaka Watanobe</li>
<li>for: 提高程序维护和安全性，促进编程学习</li>
<li>methods: 使用大语言模型GPT-3.5提出简化版Python程序，透过几何映射学习</li>
<li>results: 95.68%的程序可以通过生成10个候选程序来简化，减少平均 cyclomatic complexity 17.35%，减少平均行数25.84%，且有出色的代码格式化能力，但也有一些不必要的行为，如删除或翻译注释。<details>
<summary>Abstract</summary>
A less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. However, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. To mitigate this, we demonstrate the application of using a large language model (LLM), GPT-3.5, to suggest less complex versions of the user-written Python program, aiming to encourage users to learn how to write better programs. We propose a method to leverage the prompting with few-shot examples of the LLM by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. The quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. Furthermore, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.
</details>
<details>
<summary>摘要</summary>
一个较简单且直观的程式是一个重要的因素，可以提高程式的维护和写作安全、无错程式的能力。然而，由于工作负担重大和可能会破坏正常运行的程式，因此开发者对程式 refactoring 的态度不够积极，从而导致学习机会的损失。为了解决这个问题，我们示范了使用大型自然语言模型（LLM）GPT-3.5，可以建议使用者写的 Python 程式中更加简单的版本，以便帮助使用者学习写更好的程式。我们提出了一种方法，利用LLM的提示，选择每个目标程式问题最适合的代码 refactoring 示例，根据先前评估的提示一个例子。根据量化评估，95.68%的程式可以通过生成10个候选者，实现了17.35%的减少平均顶点复杂度和25.84%的减少平均行数。此外，量化评估还表明了代码格式化的出色能力，而不必要的行为，如删除或翻译注解，也被观察到。
</details></li>
</ul>
<hr>
<h2 id="Causal-Structure-Learning-Supervised-by-Large-Language-Model"><a href="#Causal-Structure-Learning-Supervised-by-Large-Language-Model" class="headerlink" title="Causal Structure Learning Supervised by Large Language Model"></a>Causal Structure Learning Supervised by Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11689">http://arxiv.org/abs/2311.11689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tymadara/ils-csl">https://github.com/tymadara/ils-csl</a></li>
<li>paper_authors: Taiyu Ban, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, Huanhuan Chen</li>
<li>for: 提高 causal discovery 的精度和效率，使用 Large Language Models (LLMs) 增强 causal structure learning (CSL)</li>
<li>methods: 提出了 Iterative LLM Supervised CSL (ILS-CSL) 框架，将 LLM-based causal inference 融合到 CSL 中，通过反馈机制提高 causal DAG 的精度和 robustness</li>
<li>results: 在 eight 个实际数据集上进行了 comprehensive 评估，显示 ILS-CSL 的性能更高，创造了新的标准 для CSL 效率，并展示了其在 causal discovery 领域的潜在进步<details>
<summary>Abstract</summary>
Causal discovery from observational data is pivotal for deciphering complex relationships. Causal Structure Learning (CSL), which focuses on deriving causal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast DAG spaces and data sparsity. The integration of Large Language Models (LLMs), recognized for their causal reasoning capabilities, offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences. However, existing approaches utilizing LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses. In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process, refining the causal DAG using feedback from LLMs. This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies. Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery. The codes are available at \url{https://github.com/tyMadara/ILS-CSL}.
</details>
<details>
<summary>摘要</summary>
causal discovery from observational data 是解释复杂关系的关键。 causal Structure Learning (CSL) 是 deriv ing causal Directed Acyclic Graphs (DAGs) from data 的方法，面临的挑战包括庞大 DAG 空间和数据稀缺。 将 Large Language Models (LLMs)  integrate into CSL 提供了一个有前途的方向， LLMS 被认可为具有 causal 推理能力。 however, existing approaches using LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses。 In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework。 ILS-CSL 创新地将 LLM-based causal inference 与 CSL 集成在迭代过程中，通过 LLM 反馈来约束 causal DAG。 这种方法不仅更有效使用 LLM 资源，还生成了更加可靠和高质量的结构约束，与之前的方法相比。 our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery。 codes are available at \url{https://github.com/tyMadara/ILS-CSL}.
</details></li>
</ul>
<hr>
<h2 id="ViP-Mixer-A-Convolutional-Mixer-for-Video-Prediction"><a href="#ViP-Mixer-A-Convolutional-Mixer-for-Video-Prediction" class="headerlink" title="ViP-Mixer: A Convolutional Mixer for Video Prediction"></a>ViP-Mixer: A Convolutional Mixer for Video Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11683">http://arxiv.org/abs/2311.11683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zheng, Ziang Peng, Yuan Cao, Hongming Shan, Junping Zhang</li>
<li>for: 预测未来帧数据，提高视频预测精度。</li>
<li>methods: 使用卷积混合器模型视频的空间时间演化，并将各个维度之间的关系充分利用。</li>
<li>results: 在三个标准视频数据集上实现新的最佳预测性能。<details>
<summary>Abstract</summary>
Video prediction aims to predict future frames from a video's previous content. Existing methods mainly process video data where the time dimension mingles with the space and channel dimensions from three distinct angles: as a sequence of individual frames, as a 3D volume in spatiotemporal coordinates, or as a stacked image where frames are treated as separate channels. Most of them generally focus on one of these perspectives and may fail to fully exploit the relationships across different dimensions. To address this issue, this paper introduces a convolutional mixer for video prediction, termed ViP-Mixer, to model the spatiotemporal evolution in the latent space of an autoencoder. The ViP-Mixers are stacked sequentially and interleave feature mixing at three levels: frames, channels, and locations. Extensive experiments demonstrate that our proposed method achieves new state-of-the-art prediction performance on three benchmark video datasets covering both synthetic and real-world scenarios.
</details>
<details>
<summary>摘要</summary>
视频预测目标是预测视频的未来帧。现有方法主要处理视频数据，其时间维度杂mix With space和channel维度，从三个不同的角度来看：为个帧序列，为三维空间时间坐标，或者为堆叠的图像，帧被视为不同的通道。大多数它们通常只关注一个这些视角，可能会不全面利用不同维度之间的关系。为解决这个问题，本文提出了一种基于卷积混合的视频预测方法，称为ViP-Mixer，用于模型视频的空间时间演化在自适应Encoder中的幂空间。ViP-Mixer堆叠在一起，并在三级Feature混合：帧、通道和位置。广泛的实验证明，我们提出的方法在三个标准视频数据集上实现了新的最佳预测性能，覆盖了synthetic和实际场景。
</details></li>
</ul>
<hr>
<h2 id="MGCT-Mutual-Guided-Cross-Modality-Transformer-for-Survival-Outcome-Prediction-using-Integrative-Histopathology-Genomic-Features"><a href="#MGCT-Mutual-Guided-Cross-Modality-Transformer-for-Survival-Outcome-Prediction-using-Integrative-Histopathology-Genomic-Features" class="headerlink" title="MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features"></a>MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11659">http://arxiv.org/abs/2311.11659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingxin Liu, Yunzan Liu, Hui Cui, Chunquan Li, Jiquan Ma<br>for:* The paper is written to propose a new deep learning-based computational pathology method for prognosticating cancer patients using whole slide images (WSIs) and genomic features.methods:* The proposed method, called Mutual-Guided Cross-Modality Transformer (MGCT), uses a weakly-supervised, attention-based multimodal learning framework to combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment.results:* The experiments conducted using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA) consistently show that MGCT outperforms the state-of-the-art (SOTA) methods.<details>
<summary>Abstract</summary>
The rapidly emerging field of deep learning-based computational pathology has shown promising results in utilizing whole slide images (WSIs) to objectively prognosticate cancer patients. However, most prognostic methods are currently limited to either histopathology or genomics alone, which inevitably reduces their potential to accurately predict patient prognosis. Whereas integrating WSIs and genomic features presents three main challenges: (1) the enormous heterogeneity of gigapixel WSIs which can reach sizes as large as 150,000x150,000 pixels; (2) the absence of a spatially corresponding relationship between histopathology images and genomic molecular data; and (3) the existing early, late, and intermediate multimodal feature fusion strategies struggle to capture the explicit interactions between WSIs and genomics. To ameliorate these issues, we propose the Mutual-Guided Cross-Modality Transformer (MGCT), a weakly-supervised, attention-based multimodal learning framework that can combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment. To validate the effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA). Extensive experimental results consistently emphasize that MGCT outperforms the state-of-the-art (SOTA) methods.
</details>
<details>
<summary>摘要</summary>
深度学习计算生物学领域在使用整个扫描图像（WSIs）对肿瘤病人进行预测中已经显示了扎实的成果。然而，大多数预测方法都受限于历史学或基因学单独使用，这会导致预测病人预测的精度受到限制。而将WSIs和基因特征结合起来则存在三个主要挑战：（1）WSIs的巨大多样性，可以达到150,000x150,000像素的大小；（2）历史学图像和基因分子数据之间没有空间相对关系；（3）现有的早期、晚期和中期多Modal特征融合策略难以捕捉肿瘤微环境中的基因-生理相互作用。为了解决这些问题，我们提出了弱型监督的注意力基本多Modal学习框架——综合型响应器（MGCT），可以结合历史学特征和基因特征来模型肿瘤微环境中的基因-生理相互作用。为验证MGCT的效果，我们在TCGA数据集上进行了大量实验，结果表明MGCT在肿瘤预测方面具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Peeking-Inside-the-Schufa-Blackbox-Explaining-the-German-Housing-Scoring-System"><a href="#Peeking-Inside-the-Schufa-Blackbox-Explaining-the-German-Housing-Scoring-System" class="headerlink" title="Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System"></a>Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11655">http://arxiv.org/abs/2311.11655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean-Robin Kern, Gunnar Stevens, Erik Dethier, Sidra Naveed, Fatemeh Alizadeh, Delong Du, Md Shajalal</li>
<li>for: 这个研究旨在为德国的信用评分系统（Schufa）开发可解释的人工智能解释，以满足用户的信息需求和期望。</li>
<li>methods: 这个研究使用了推测设计方法，让商业信息学生想象出了为租客和房东提供住房信贷分数解释的用户界面。</li>
<li>results: 初步发现结果表明，尽管有一些通用的需求，但也有因角色和实际情况而冲突的需求。这些发现提供了未来人类中心的XAI研究的可能性。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence is a concept aimed at making complex algorithms transparent to users through a uniform solution. Researchers have highlighted the importance of integrating domain specific contexts to develop explanations tailored to end users. In this study, we focus on the Schufa housing scoring system in Germany and investigate how users information needs and expectations for explanations vary based on their roles. Using the speculative design approach, we asked business information students to imagine user interfaces that provide housing credit score explanations from the perspectives of both tenants and landlords. Our preliminary findings suggest that although there are general needs that apply to all users, there are also conflicting needs that depend on the practical realities of their roles and how credit scores affect them. We contribute to Human centered XAI research by proposing future research directions that examine users explanatory needs considering their roles and agencies.
</details>
<details>
<summary>摘要</summary>
人工智能可解释（Explainable Artificial Intelligence）是一种概念，旨在为用户提供复杂算法的通用解释。研究人员认为，在发展解释时应该考虑域专业上下文。在这项研究中，我们关注德国的信用评分系统（Schufa），并调查了用户信息需求和对解释的期望是如何因role而异。我们使用推想设计方法，请商业信息学生想象提供住房信用评分解释的用户界面，从租户和地产业者两个角度出发。我们的初步发现结果表明，虽然有一些共同的需求，但也有因role而异的需求，这些需求取决于各自的角色和信用评分对其造成的实际影响。我们的研究贡献了人类中心的XAI研究，并提出了未来研究的方向，旨在考虑用户的角色和权力，以更好地满足用户的解释需求。
</details></li>
</ul>
<hr>
<h2 id="Web-News-Timeline-Generation-with-Extended-Task-Prompting"><a href="#Web-News-Timeline-Generation-with-Extended-Task-Prompting" class="headerlink" title="Web News Timeline Generation with Extended Task Prompting"></a>Web News Timeline Generation with Extended Task Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11652">http://arxiv.org/abs/2311.11652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sha Wang, Yuchen Li, Hanhua Xiao, Lambert Deng, Yanfei Dong</li>
<li>for: 这个研究的目的是为了生成新闻时间线，以提供全面和Contextual的事件发展趋势。</li>
<li>methods: 这个研究使用了扩展的任务提示技术来提高传统自然语言处理（NLP）技术的效果。</li>
<li>results: 研究表明，通过添加更多的任务提示，可以提高NLP技术对不同新闻数据集的效果，使新闻时间线生成成为职业使用的现实。<details>
<summary>Abstract</summary>
The creation of news timeline is essential for a comprehensive and contextual understanding of events as they unfold over time. This approach aids in discerning patterns and trends that might be obscured when news is viewed in isolation. By organizing news in a chronological sequence, it becomes easier to track the development of stories, understand the interrelation of events, and grasp the broader implications of news items. This is particularly helpful in sectors like finance and insurance, where timely understanding of the event development-ranging from extreme weather to political upheavals and health crises-is indispensable for effective risk management. While traditional natural language processing (NLP) techniques have had some success, they often fail to capture the news with nuanced relevance that are readily apparent to domain experts, hindering broader industry integration. The advance of Large Language Models (LLMs) offers a renewed opportunity to tackle this challenge. However, direct prompting LLMs for this task is often ineffective. Our study investigates the application of an extended task prompting technique to assess past news relevance. We demonstrate that enhancing conventional prompts with additional tasks boosts their effectiveness on various news dataset, rendering news timeline generation practical for professional use. This work has been deployed as a publicly accessible browser extension which is adopted within our network.
</details>
<details>
<summary>摘要</summary>
创建新闻时间轴是对事件的全面和Contextual理解的关键，帮助揭示事件发展的趋势和patterns。通过将新闻按时间顺序排序，可以轻松跟踪事件的发展，理解事件之间的相互关系，并捕捉新闻项目的更大意义。特别是在金融和保险领域，时间线新闻生成对于有效的风险管理至关重要，因为它可以帮助早发现和理解extreme weather、政治动荡和健康危机等事件的发展。传统的自然语言处理（NLP）技术有一定的成功，但它们经常无法捕捉域专家所看到的细微相关性，从而阻碍了更广泛的行业 интеграción。大语言模型（LLMs）的进步提供了一个新的机会，以解决这个挑战。然而，直接推 prompt LLMs 这种任务通常是不 efective。我们的研究探讨了在扩展任务推动技术下对过去新闻 relevance 的评估。我们示出，通过提高传统推送的效果，可以在不同的新闻数据集上提高新闻时间轴生成的实用性，使其成为职业使用的实际应用。这项工作已经被部署为公共可访问的浏览器扩展，并被我们的网络所采纳。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-healthy-population-variability-in-deep-learning-unsupervised-anomaly-detection-in-brain-FDG-PET"><a href="#Leveraging-healthy-population-variability-in-deep-learning-unsupervised-anomaly-detection-in-brain-FDG-PET" class="headerlink" title="Leveraging healthy population variability in deep learning unsupervised anomaly detection in brain FDG PET"></a>Leveraging healthy population variability in deep learning unsupervised anomaly detection in brain FDG PET</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12081">http://arxiv.org/abs/2311.12081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maëlys Solal, Ravi Hassanaly, Ninon Burgos</li>
<li>for: 这篇论文的目的是为了开发一种基于无监督学习的脑成像数据分析方法，以检测脑成像中的各种异常。</li>
<li>methods: 这篇论文使用了一种基于Z-score的方法，将健康人群的脑成像模型与患者的脑成像进行比较，以检测异常。</li>
<li>results: 这篇论文的实验结果显示，这种方法可以精准地检测阿兹海默症相关的异常。<details>
<summary>Abstract</summary>
Unsupervised anomaly detection is a popular approach for the analysis of neuroimaging data as it allows to identify a wide variety of anomalies from unlabelled data. It relies on building a subject-specific model of healthy appearance to which a subject's image can be compared to detect anomalies. In the literature, it is common for anomaly detection to rely on analysing the residual image between the subject's image and its pseudo-healthy reconstruction. This approach however has limitations partly due to the pseudo-healthy reconstructions being imperfect and to the lack of natural thresholding mechanism. Our proposed method, inspired by Z-scores, leverages the healthy population variability to overcome these limitations. Our experiments conducted on FDG PET scans from the ADNI database demonstrate the effectiveness of our approach in accurately identifying Alzheimer's disease related anomalies.
</details>
<details>
<summary>摘要</summary>
不监督异常检测是脑成像数据分析中广泛使用的方法，因为它可以从无标注数据中识别各种异常。它基于建立个体特定的健康模型，并将个体图像与这个模型进行比较，以检测异常。在文献中，异常检测通常基于分析个体图像与其 Pseudo-健康重建图像之间的差异。然而，这种方法有一些限制，其中之一是 Pseudo-健康重建图像不准确，另一个是缺乏自然的阈值分割机制。我们提出的方法， Drawing inspiration from Z-scores，利用健康人群的变化来超越这些限制。我们在 ADNI 数据库中的FDG PET扫描实验结果表明，我们的方法可以准确地识别阿尔茨heimer病相关的异常。
</details></li>
</ul>
<hr>
<h2 id="A-novel-transformer-based-approach-for-soil-temperature-prediction"><a href="#A-novel-transformer-based-approach-for-soil-temperature-prediction" class="headerlink" title="A novel transformer-based approach for soil temperature prediction"></a>A novel transformer-based approach for soil temperature prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11626">http://arxiv.org/abs/2311.11626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammet Mucahit Enes Yurtsever, Ayhan Kucukmanisa, Zeynep Hilal Kilimci</li>
<li>for: 这研究旨在预测土壤温度，以便更好地了解高山冰川的能量、动力学、水文过程、生态稳定性、土壤、水和农作物的管理。</li>
<li>methods: 本研究使用了变换器模型，这是首次应用变换器模型预测土壤温度。实验使用了FLUXNET站点，模型使用五种不同的变换器模型，即简单变换器、信息变换器、自动变换器、重构变换器和ETS变换器。</li>
<li>results: 实验结果表明，使用变换器模型可以为预测土壤温度做出重要贡献，并确定新的州对比。相比深度学习方法和文献研究，本研究的效果更好。<details>
<summary>Abstract</summary>
Soil temperature is one of the most significant parameters that plays a crucial role in glacier energy, dynamics of mass balance, processes of surface hydrological, coaction of glacier-atmosphere, nutrient cycling, ecological stability, the management of soil, water, and field crop. In this work, we introduce a novel approach using transformer models for the purpose of forecasting soil temperature prediction. To the best of our knowledge, the usage of transformer models in this work is the very first attempt to predict soil temperature. Experiments are carried out using six different FLUXNET stations by modeling them with five different transformer models, namely, Vanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To demonstrate the effectiveness of the proposed model, experiment results are compared with both deep learning approaches and literature studies. Experiment results show that the utilization of transformer models ensures a significant contribution to the literature, thence determining the new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
土壤温度是冰川能源中最重要的参数之一，它对冰川动力、质量平衡、表面水文过程、冰川-大气相互作用、营养征回循环、生态稳定性等具有关键作用。在这个工作中，我们提出了一种新的方法，利用转换器模型来预测土壤温度。根据我们所知，这是第一次使用转换器模型预测土壤温度的尝试。我们在六个FLUXNET站上进行了六个不同的转换器模型，分别是粉丝转换器、信息转换器、自动转换器、改进转换器和ETS转换器。为证明我们提出的模型的效果，我们与深度学习方法和文献研究进行了比较。实验结果表明，通过使用转换器模型可以做出显著贡献，因此确定了新的状态体。
</details></li>
</ul>
<hr>
<h2 id="Taiyi-A-Bilingual-Fine-Tuned-Large-Language-Model-for-Diverse-Biomedical-Tasks"><a href="#Taiyi-A-Bilingual-Fine-Tuned-Large-Language-Model-for-Diverse-Biomedical-Tasks" class="headerlink" title="Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks"></a>Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11608">http://arxiv.org/abs/2311.11608</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dutir-bionlp/taiyi-llm">https://github.com/dutir-bionlp/taiyi-llm</a></li>
<li>paper_authors: Ling Luo, Jinzhong Ning, Yingwen Zhao, Zhijun Wang, Zeyuan Ding, Peng Chen, Weiru Fu, Qinyu Han, Guangtao Xu, Yunzhi Qiu, Dinghao Pan, Jiru Li, Hao Li, Wenduo Feng, Senbo Tu, Yuqi Liu, Zhihao Yang, Jian Wang, Yuanyuan Sun, Hongfei Lin</li>
<li>for: This paper is focused on developing a bilingual language model (Taiyi) for diverse biomedical natural language processing tasks in both English and Chinese.</li>
<li>methods: The authors use a two-stage fine-tuning strategy to optimize the model’s performance across various tasks, and they use a comprehensive collection of biomedical text mining datasets to evaluate the model’s performance.</li>
<li>results: The authors show that Taiyi achieves superior performance compared to general language models on 13 test sets covering named entity recognition, relation extraction, text classification, and question answering tasks. Additionally, the authors demonstrate the model’s potential for bilingual biomedical multi-tasking through a case study involving additional biomedical NLP tasks.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这篇论文是为了开发一个双语语言模型（Taiyi），用于多种生物医学自然语言处理任务。</li>
<li>methods: 作者使用了两个阶段的超参数调整策略，以优化模型的性能 across 多种任务。</li>
<li>results: 作者表明，Taiyi 比普通语言模型在 13 个测试集上表现出色，包括命名实体识别、关系抽取、文本分类和问答任务。此外，作者通过一个案例研究，展示了 Taiyi 在多语言生物医学多任务中的可能性。<details>
<summary>Abstract</summary>
Recent advancements in large language models (LLMs) have shown promising results across a variety of natural language processing (NLP) tasks. The application of LLMs to specific domains, such as biomedicine, has achieved increased attention. However, most biomedical LLMs focus on enhancing performance in monolingual biomedical question answering and conversation tasks. To further investigate the effectiveness of the LLMs on diverse biomedical NLP tasks in different languages, we present Taiyi, a bilingual (English and Chinese) fine-tuned LLM for diverse biomedical tasks. In this work, we first curated a comprehensive collection of 140 existing biomedical text mining datasets across over 10 task types. Subsequently, a two-stage strategy is proposed for supervised fine-tuning to optimize the model performance across varied tasks. Experimental results on 13 test sets covering named entity recognition, relation extraction, text classification, question answering tasks demonstrate Taiyi achieves superior performance compared to general LLMs. The case study involving additional biomedical NLP tasks further shows Taiyi's considerable potential for bilingual biomedical multi-tasking. The source code, datasets, and model for Taiyi are freely available at https://github.com/DUTIR-BioNLP/Taiyi-LLM.
</details>
<details>
<summary>摘要</summary>
现代大语言模型（LLM）的进步已经在各种自然语言处理（NLP）任务中显示出色的结果。将LLM应用到特定领域，如生物医学，已经吸引了更多的关注。然而，大多数生物医学LLM都是专门针对单语言生物医学问答和对话任务进行提升性能。为了进一步调查LLM在不同语言的生物医学NLP任务中的效果，我们提出了 Taiyi，一个英文和中文双语精度调整的大语言模型。在这种工作中，我们首先绘制了140个现有的生物医学文本挖掘数据集，涵盖了10多种任务类型。然后，我们提议了一种两阶段的监督微调策略，以便在不同任务中优化模型的性能。实验结果表明，Taiyi在13个测试集上（包括命名实体识别、关系抽取、文本分类、问答任务）表现出色，比普通的LLM更高。此外，在进一步的生物医学NLP任务中，Taiyi还表现出了很好的多任务优势。Taiyi的源代码、数据集和模型可以免费下载于https://github.com/DUTIR-BioNLP/Taiyi-LLM。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-based-malware-detection-for-IoT-devices-using-control-flow-data"><a href="#Machine-learning-based-malware-detection-for-IoT-devices-using-control-flow-data" class="headerlink" title="Machine learning-based malware detection for IoT devices using control-flow data"></a>Machine learning-based malware detection for IoT devices using control-flow data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11605">http://arxiv.org/abs/2311.11605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gergely Hevesi<br>for: This thesis project aims to provide better security for IoT devices using machine learning algorithms and reverse engineering tools.methods: The proposed method consists of two phases: (1) extracting control-flow related data using static binary analysis, and (2) classifying binary executables as malicious or benign using a neural network model.results: The method is trained using a dataset of malicious and benign ARM applications, and is able to detect malware with high accuracy.<details>
<summary>Abstract</summary>
Embedded devices are specialised devices designed for one or only a few purposes. They are often part of a larger system, through wired or wireless connection. Those embedded devices that are connected to other computers or embedded systems through the Internet are called Internet of Things (IoT for short) devices.   With their widespread usage and their insufficient protection, these devices are increasingly becoming the target of malware attacks. Companies often cut corners to save manufacturing costs or misconfigure when producing these devices. This can be lack of software updates, ports left open or security defects by design. Although these devices may not be as powerful as a regular computer, their large number makes them suitable candidates for botnets. Other types of IoT devices can even cause health problems since there are even pacemakers connected to the Internet. This means, that without sufficient defence, even directed assaults are possible against people.   The goal of this thesis project is to provide better security for these devices with the help of machine learning algorithms and reverse engineering tools. Specifically, I study the applicability of control-flow related data of executables for malware detection. I present a malware detection method with two phases. The first phase extracts control-flow related data using static binary analysis. The second phase classifies binary executables as either malicious or benign using a neural network model. I train the model using a dataset of malicious and benign ARM applications.
</details>
<details>
<summary>摘要</summary>
特殊设备（embedded devices）是专门设计用于一些或只有几个用途的设备。它们通常是大型系统的一部分，通过硬件或无线连接。这些与其他计算机或嵌入式系统通过互联网连接的特殊设备被称为互联网物品（IoT for short）设备。由于它们的广泛使用和不充分保护，这些设备在不断增长的Malware攻击目标。公司经常为了降低生产成本或配置不当，导致这些设备缺乏软件更新、开放的端口或设计上的安全漏洞。尽管这些设备可能不如常见的计算机强大，但由于它们的大量使用，它们成为了黑客的目标。此外，一些IoT设备甚至可能对人们健康造成威胁，因为有些 pacemakers 已经连接到互联网。这意味着，如果不充分防御，甚至可能发生对人的targeted攻击。本论文的目标是通过机器学习算法和反向工程工具来提供更好的安全保护 для这些设备。 Specifically，我研究控制流相关数据的应用可能性，以提出一种两相阶段的恶意软件检测方法。第一相阶段使用静态二进制分析提取控制流相关数据。第二相阶段使用神经网络模型将二进制执行文件分类为恶意或正常。我使用一个基于恶意和正常 ARM 应用的数据集进行训练。
</details></li>
</ul>
<hr>
<h2 id="A-Multi-In-Single-Out-Network-for-Video-Frame-Interpolation-without-Optical-Flow"><a href="#A-Multi-In-Single-Out-Network-for-Video-Frame-Interpolation-without-Optical-Flow" class="headerlink" title="A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow"></a>A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11602">http://arxiv.org/abs/2311.11602</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/J911/MISO-VFI">https://github.com/J911/MISO-VFI</a></li>
<li>paper_authors: Jaemin Lee, Minseok Seo, Sangwoo Lee, Hyobin Park, Dong-Geol Choi</li>
<li>for: 这种纸是用于优化视频帧 interpolate的方法，以提高视频帧 interpolate的精度和效果。</li>
<li>methods: 这种方法不是使用传统的运动范围估计，而是使用多个输入帧并将其混合成一帧输出，从而更好地处理 occlusion 和非线性运动。此外，我们还提出了一种新的运动观察损失函数，使得这种方法更好地捕捉视频帧中的空间时间相关性。</li>
<li>results: 我们的方法在 Vimeo90K、Middlebury 和 UCF101 等视频帧 interpolate benchmark 上达到了状态机器的 результаты，与现有方法相比，具有显著的性能差距。<details>
<summary>Abstract</summary>
In general, deep learning-based video frame interpolation (VFI) methods have predominantly focused on estimating motion vectors between two input frames and warping them to the target time. While this approach has shown impressive performance for linear motion between two input frames, it exhibits limitations when dealing with occlusions and nonlinear movements. Recently, generative models have been applied to VFI to address these issues. However, as VFI is not a task focused on generating plausible images, but rather on predicting accurate intermediate frames between two given frames, performance limitations still persist. In this paper, we propose a multi-in-single-out (MISO) based VFI method that does not rely on motion vector estimation, allowing it to effectively model occlusions and nonlinear motion. Additionally, we introduce a novel motion perceptual loss that enables MISO-VFI to better capture the spatio-temporal correlations within the video frames. Our MISO-VFI method achieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and UCF101, with a significant performance gap compared to existing approaches.
</details>
<details>
<summary>摘要</summary>
通常，深度学习基于视频帧 interpolate（VFI）方法都是估算两个输入帧之间的运动 вектор，并将其折叠到目标时间。这种方法在线性运动时 exhibits 出色的表现，但是在遮挡和非线性运动时存在局限性。在最近，生成模型被应用于 VFI 以解决这些问题。然而，由于 VFI 不是一个关注生成可信worth images 的任务，而是预测两个输入帧之间的准确中间帧，因此性能还是有限。在这篇论文中，我们提出了一种多入一出（MISO）基于 VFI 方法，不需要运动 вектор估算，因此可以有效地处理遮挡和非线性运动。此外，我们还引入了一种新的运动感知损失，使得 MISO-VFI 更好地捕捉视频帧中的空间-时间相关性。我们的 MISO-VFI 方法在 Vimeo90K、Middlebury 和 UCF101 视频帧 interpolate 测试benchmark上达到了当前最佳的结果，与现有方法相比，具有显著的性能差距。
</details></li>
</ul>
<hr>
<h2 id="DesignGPT-Multi-Agent-Collaboration-in-Design"><a href="#DesignGPT-Multi-Agent-Collaboration-in-Design" class="headerlink" title="DesignGPT: Multi-Agent Collaboration in Design"></a>DesignGPT: Multi-Agent Collaboration in Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11591">http://arxiv.org/abs/2311.11591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu Qiu, Chunlei Chai</li>
<li>for: 这项研究旨在应对生产设计过程中的生成AI面临的挑战，如界面使用性和交互模式。</li>
<li>methods: 研究人员采用了设计思维和设计过程，开发了多代理人合作框架DesignGPT，该框架使用人工智能代理人模拟设计公司不同职位的角色，并允许人类设计师与其进行自然语言协作。</li>
<li>results: 实验结果显示，相比单独使用的AI工具，DesignGPT可以提高设计师的表现， highlighting the potential of 将多代理人系统集成到产品方案设计中。<details>
<summary>Abstract</summary>
Generative AI faces many challenges when entering the product design workflow, such as interface usability and interaction patterns. Therefore, based on design thinking and design process, we developed the DesignGPT multi-agent collaboration framework, which uses artificial intelligence agents to simulate the roles of different positions in the design company and allows human designers to collaborate with them in natural language. Experimental results show that compared with separate AI tools, DesignGPT improves the performance of designers, highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate english text to simplified chinese产生式AI在产品设计 workflow 中遇到许多挑战，如界面可用性和互动模式。因此，基于设计思维和设计过程，我们开发了 DesignGPT 多代理协作框架，使用人工智能代理模拟不同的设计公司位置，让人类设计师和其在自然语言中合作。实验结果显示，相比单独的 AI 工具，DesignGPT 提高了设计师的性能， highlighting 将多代理系统应用于产品方案设计中的潜在价值。Note: "产生式AI" is a term used in China to refer to generative AI, and "设计公司" means "design company" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Advancing-Urban-Renewal-An-Automated-Approach-to-Generating-Historical-Arcade-Facades-with-Stable-Diffusion-Models"><a href="#Advancing-Urban-Renewal-An-Automated-Approach-to-Generating-Historical-Arcade-Facades-with-Stable-Diffusion-Models" class="headerlink" title="Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models"></a>Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11590">http://arxiv.org/abs/2311.11590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheyuan Kuang, Jiaxin Zhang, Yiying Huang, Yunqin Li</li>
<li>for: 历史街区更新和转化过程中保留历史城市质感非常重要，特别是在知名的建筑和历史遗产地区。这些区域拥有多样化的建筑风格，传统上需要广泛的初步研究，常常导致主观的结果。</li>
<li>methods: 我们的研究引入了一种新的方法，利用稳定扩散模型（Stable Diffusion Models）来自动生成历史拱廊建筑图像，并通过文本描述来控制样式。我们分类和标记了多种拱廊风格，并构建了许多真实的拱廊建筑图像集。我们训练了多个低级 adaptation（LoRA）模型来控制生成图像的艺术性，并补充了ControlNet模型以提高精度和 AUTHENTICITY。</li>
<li>results: 我们的方法得到了高级别的精度、AUTHENTICITY和多样性，显示了在实际城市更新项目中的潜在潜力。这种新的方法可以更有效率地替代传统的城市更新设计过程，解决不authentic的图像细节、缺乏精度和限制的样式多样性问题。未来的研究可以考虑将这种二维图像生成技术与三维模型技术集成，为历史街区的建筑改造提供更全面的解决方案。<details>
<summary>Abstract</summary>
Urban renewal and transformation processes necessitate the preservation of the historical urban fabric, particularly in districts known for their architectural and historical significance. These regions, with their diverse architectural styles, have traditionally required extensive preliminary research, often leading to subjective results. However, the advent of machine learning models has opened up new avenues for generating building facade images. Despite this, creating high-quality images for historical district renovations remains challenging, due to the complexity and diversity inherent in such districts. In response to these challenges, our study introduces a new methodology for automatically generating images of historical arcade facades, utilizing Stable Diffusion models conditioned on textual descriptions. By classifying and tagging a variety of arcade styles, we have constructed several realistic arcade facade image datasets. We trained multiple low-rank adaptation (LoRA) models to control the stylistic aspects of the generated images, supplemented by ControlNet models for improved precision and authenticity. Our approach has demonstrated high levels of precision, authenticity, and diversity in the generated images, showing promising potential for real-world urban renewal projects. This new methodology offers a more efficient and accurate alternative to conventional design processes in urban renewal, bypassing issues of unconvincing image details, lack of precision, and limited stylistic variety. Future research could focus on integrating this two-dimensional image generation with three-dimensional modeling techniques, providing a more comprehensive solution for renovating architectural facades in historical districts.
</details>
<details>
<summary>摘要</summary>
都市更新和转化过程中需要保留历史城市胶囊，特别是那些建筑和历史意义极高的区域。这些区域具有多样化的建筑风格，传统上需要广泛的初步研究，经常导致主观的结果。然而，机器学习模型的出现开创了新的可能性，可以生成建筑立面图像。然而，为历史区域重新建设而生成高质量图像仍然是挑战，因为这些区域的复杂性和多样性。为解决这些挑战，我们的研究提出了一种新的方法，利用稳定扩散模型 Conditioned on 文本描述来自动生成历史街区立面图像。我们根据不同的街区风格进行分类和标注，并构建了许多真实的街区立面图像数据集。我们使用多个低级 adaptive （LoRA）模型控制生成图像的艺术性方面，并补充了 ControlNet 模型以提高精度和authenticity。我们的方法已经显示了高度的精度、authenticity 和多样性，表现出了潜在的应用潜力。这种新的方法可以为都市更新项目提供更高效和准确的替代方案，通过 circumventing 问题，例如不寓实的图像细节、缺乏精度和限制的艺术风格多样性。未来的研究可能会集成这种二维图像生成技术和三维模型技术，为历史区域的建筑立面重新建设提供更全面的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Decoupled-DETR-For-Few-shot-Object-Detection"><a href="#Decoupled-DETR-For-Few-shot-Object-Detection" class="headerlink" title="Decoupled DETR For Few-shot Object Detection"></a>Decoupled DETR For Few-shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11570">http://arxiv.org/abs/2311.11570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Shangguan, Lian Huai, Tong Liu, Xingqun Jiang</li>
<li>for: 提高几个样本 object detection（FSOD）的性能，解决数据匮乏问题。</li>
<li>methods: 提出一种基于DETR的FSOD模型，通过分离类别的参数和尝试不同类型的跳过连接来提高模型性能。</li>
<li>results: 在PASCAL VOC和MSCOCO等常用 dataset 上测试，提出的模型能够稳定地提高 Fine-tuning 和 meta-learning 下的性能，与最新的工作相比达到最高得分。<details>
<summary>Abstract</summary>
Few-shot object detection (FSOD), an efficient method for addressing the severe data-hungry problem, has been extensively discussed. Current works have significantly advanced the problem in terms of model and data. However, the overall performance of most FSOD methods still does not fulfill the desired accuracy. In this paper we improve the FSOD model to address the severe issue of sample imbalance and weak feature propagation. To alleviate modeling bias from data-sufficient base classes, we examine the effect of decoupling the parameters for classes with sufficient data and classes with few samples in various ways. We design a base-novel categories decoupled DETR (DeDETR) for FSOD. We also explore various types of skip connection between the encoder and decoder for DETR. Besides, we notice that the best outputs could come from the intermediate layer of the decoder instead of the last layer; therefore, we build a unified decoder module that could dynamically fuse the decoder layers as the output feature. We evaluate our model on commonly used datasets such as PASCAL VOC and MSCOCO. Our results indicate that our proposed module could achieve stable improvements of 5% to 10% in both fine-tuning and meta-learning paradigms and has outperformed the highest score in recent works.
</details>
<details>
<summary>摘要</summary>
“几枚shot物类探测（FSOD），一种高效的方法来解决严重的数据饵问题，已经被广泛讨论。现有的工作对这个问题进行了重要的进步，但大多数FSOD方法的总性表现仍未能满足预期的精度。在这篇论文中，我们改进FSOD模型，以解决严重的样本不均衡和弱feature传播问题。为了从数据充足的基础类别中避免模型偏见，我们考虑了各种方法来隔离具有充足数据的类别和具有少数数据的类别的参数。我们设计了基于类别分类的DETR（DeDETR）模型来进行FSOD。此外，我们发现最佳的输出可能来自decoder层的中途层而不是最后层，因此我们建立了一个统一的decoder模组，可以动态地融合decoder层的输出特征。我们将我们的模型评估在常用的PASCAL VOC和MSCOCO datasets上，结果显示我们的提案模组可以在精度调整和元学习模式下稳定地提高5%至10%的表现，并且超过了最近的最高得分。”
</details></li>
</ul>
<hr>
<h2 id="Replay-enhanced-Continual-Reinforcement-Learning"><a href="#Replay-enhanced-Continual-Reinforcement-Learning" class="headerlink" title="Replay-enhanced Continual Reinforcement Learning"></a>Replay-enhanced Continual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11557">http://arxiv.org/abs/2311.11557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiantian Zhang, Kevin Zehua Shen, Zichuan Lin, Bo Yuan, Xueqian Wang, Xiu Li, Deheng Ye</li>
<li>for: 避免 catastrophic forgetting 在 continual reinforcement learning 中</li>
<li>methods: 使用 replay-enhanced method，包括 adaptive normalization 和 policy distillation</li>
<li>results: 在 Continual World benchmark 上表现出色，比 purely perfect memory replay 好，并且与 state-of-the-art continual learning methods 相当或更好<details>
<summary>Abstract</summary>
Replaying past experiences has proven to be a highly effective approach for averting catastrophic forgetting in supervised continual learning. However, some crucial factors are still largely ignored, making it vulnerable to serious failure, when used as a solution to forgetting in continual reinforcement learning, even in the context of perfect memory where all data of previous tasks are accessible in the current task. On the one hand, since most reinforcement learning algorithms are not invariant to the reward scale, the previously well-learned tasks (with high rewards) may appear to be more salient to the current learning process than the current task (with small initial rewards). This causes the agent to concentrate on those salient tasks at the expense of generality on the current task. On the other hand, offline learning on replayed tasks while learning a new task may induce a distributional shift between the dataset and the learned policy on old tasks, resulting in forgetting. In this paper, we introduce RECALL, a replay-enhanced method that greatly improves the plasticity of existing replay-based methods on new tasks while effectively avoiding the recurrence of catastrophic forgetting in continual reinforcement learning. RECALL leverages adaptive normalization on approximate targets and policy distillation on old tasks to enhance generality and stability, respectively. Extensive experiments on the Continual World benchmark show that RECALL performs significantly better than purely perfect memory replay, and achieves comparable or better overall performance against state-of-the-art continual learning methods.
</details>
<details>
<summary>摘要</summary>
重新播放过去的经验被证明是预学批处理中维持快速学习的高效方法。然而，一些重要的因素仍然被忽视，使其在重复学习中容易出现严重的失败。在现在的任务中，由于大多数学习算法不具有奖励缩放的不变性，以前的任务（高奖）可能会在当前任务（初始奖）中显得更加吸引人，导致代理人偏向这些鲜明的任务，而忽略当前任务。另一方面，在学习新任务时， reuse 批处理过去的任务可能会导致批处理集和学习策略之间的分布差异，从而导致忘记。在本文中，我们介绍了 RECALL，一种增强现有批处理方法的方法，以提高新任务的抽象和稳定性。RECALL 利用了adaptive normalization的 approximate targets和policy distillation on old tasks来提高多任务学习的灵活性和稳定性。我们在 Continual World  benchmark 上进行了广泛的实验，发现 RECALL 比纯粹的完美记忆播放更好，并与现状顶尖的 continual learning 方法相比，达到了相似或更好的总性表现。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Prompting-Large-Language-Models-as-Explainable-Metrics"><a href="#Exploring-Prompting-Large-Language-Models-as-Explainable-Metrics" class="headerlink" title="Exploring Prompting Large Language Models as Explainable Metrics"></a>Exploring Prompting Large Language Models as Explainable Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11552">http://arxiv.org/abs/2311.11552</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics">https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics</a></li>
<li>paper_authors: Ghazaleh Mahmoudi</li>
<li>for: 提出了一种针对自然语言处理（NLP）领域摘要任务的可解释评估策略，使用大语言模型（LLMs）作为评估指标。</li>
<li>methods: 提出了零批量基于提示的策略，并在实验中采用了少量和零量的方法。</li>
<li>results: 实验结果表明，LLMs 在 NLP 领域，特别是摘要任务中，具有扎实的可解释评估能力，并且可以在少量和零量的情况下达到可观的性能。Prompt-based strategy的最佳提示表现达到了人工评估的克ен德拉度相对值0.477。代码和结果在 GitHub 上公开发布。<details>
<summary>Abstract</summary>
This paper describes the IUST NLP Lab submission to the Prompting Large Language Models as Explainable Metrics Shared Task at the Eval4NLP 2023 Workshop on Evaluation & Comparison of NLP Systems. We have proposed a zero-shot prompt-based strategy for explainable evaluation of the summarization task using Large Language Models (LLMs). The conducted experiments demonstrate the promising potential of LLMs as evaluation metrics in Natural Language Processing (NLP), particularly in the field of summarization. Both few-shot and zero-shot approaches are employed in these experiments. The performance of our best provided prompts achieved a Kendall correlation of 0.477 with human evaluations in the text summarization task on the test data. Code and results are publicly available on GitHub.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了我们在Eval4NLP 2023工作坊上提交的Prompting Large Language Models as Explainable Metrics Shared Task的实验报告。我们提议了一种零批量基于提示的方法来评估摘要任务中的大自然语言模型（LLMs）。我们进行了实验，并证明了LLMs在自然语言处理（NLP）领域，特别是摘要任务中的表现有扎实的潜力。我们在几个shot和零shot的情况下都使用了这些提示。实验结果显示，我们提供的最佳提示的性能达到了人工评估数据上的Kendall相关性0.477。代码和结果在GitHub上公开可用。
</details></li>
</ul>
<hr>
<h2 id="Which-AI-Technique-Is-Better-to-Classify-Requirements-An-Experiment-with-SVM-LSTM-and-ChatGPT"><a href="#Which-AI-Technique-Is-Better-to-Classify-Requirements-An-Experiment-with-SVM-LSTM-and-ChatGPT" class="headerlink" title="Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT"></a>Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11547">http://arxiv.org/abs/2311.11547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelkarim El-Hajjami, Nicolas Fafin, Camille Salinesi</li>
<li>for: 这paper的目的是评估大自然语言模型（LLM）在需求工程（RE）中的应用，特别是在需求分类方面。</li>
<li>methods: 本paper使用了多种实验评估了三种ChatGPT模型（text-davinci-003、gpt-3.5-turbo、gpt-4）在零shot和几shot Setting下的表现，并进行了对比分析。</li>
<li>results: 研究发现，ChatGPT在需求分类方面的表现比LSTM更好，但在分类非功能需求（NFR）方面，SVM的表现更好。此外，研究发现在大多数情况下，几shot Setting不一定能够提高表现，有时甚至会下降。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Context and motivation: Recently, Large Language Models (LLMs) like ChatGPT have demonstrated remarkable proficiency in various Natural Language Processing (NLP) tasks. Their application in Requirements Engineering (RE), especially in requirements classification, has gained increasing interest. Question/problem: In our research, we conducted an extensive empirical evaluation of ChatGPT models including text-davinci-003, gpt-3.5-turbo, and gpt-4 in both zero-shot and few-shot settings for requirements classification. The question arises as to how these models compare to traditional classification methods, specifically Support Vector Machine (SVM) and Long Short-Term Memory (LSTM). Principal ideas/results: Based on five diverse datasets, our results show that ChatGPT consistently outperforms LSTM, and while ChatGPT is more effective than SVM in classifying functional requirements (FR), SVM is better in classifying non-functional requirements (NFR). Our results also show that contrary to our expectations, the few-shot setting does not always lead to enhanced performance; in most instances, it was found to be suboptimal. Contribution: Our findings underscore the potential of LLMs in the RE domain, suggesting that they could play a pivotal role in future software engineering processes, particularly as tools to enhance requirements classification.
</details>
<details>
<summary>摘要</summary>
Context and motivation: 近些年来，大型自然语言模型（LLM）如ChatGPT在自然语言处理（NLP）方面的表现很出色，其应用于需求工程（RE）领域，特别是需求分类，引起了越来越多的关注。问题/问题：在我们的研究中，我们进行了大量的实验性评估，包括文本达尔文-003、gpt-3.5-turbo和gpt-4等ChatGPT模型，在零shot和几shot设置下进行了需求分类。问题是如何与传统的分类方法相比，特别是支持向量机（SVM）和长期记忆（LSTM）？主要想法/结果：根据五个多样化的数据集，我们的结果显示，ChatGPT在FR和NFR之间的分类表现相对较好，而SVM在NFR中的表现更好。此外，我们发现，在大多数情况下，几shot设置不一定是最佳的，反而有时会下降性能。贡献：我们的发现表明了LLM在RE领域的潜力， suggesting that they could play a crucial role in future software engineering processes, particularly as tools to enhance requirements classification.
</details></li>
</ul>
<hr>
<h2 id="Data-driven-project-planning-An-integrated-network-learning-and-constraint-relaxation-approach-in-favor-of-scheduling"><a href="#Data-driven-project-planning-An-integrated-network-learning-and-constraint-relaxation-approach-in-favor-of-scheduling" class="headerlink" title="Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling"></a>Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11542">http://arxiv.org/abs/2311.11542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Izack Cohen</li>
<li>for: 这项研究旨在支持数据驱动的项目规划，帮助项目规划人员在项目规划和资源调配方面做出更好的决策。</li>
<li>methods: 该研究提出了一种数据驱动的项目规划方法，包括从历史记录中学习项目网络，发现项目中的时间约束，并在多个项目计划变体中寻找最佳的项目计划。</li>
<li>results: 该研究使用两个实际项目数据集，显示了该方法可以为项目规划人员提供显著的灵活性（最多减少项目 kritical path 26%），以便调整项目计划和时间表。<details>
<summary>Abstract</summary>
Our focus is on projects, i.e., business processes, which are emerging as the economic drivers of our times. Differently from day-to-day operational processes that do not require detailed planning, a project requires planning and resource-constrained scheduling for coordinating resources across sub- or related projects and organizations. A planner in charge of project planning has to select a set of activities to perform, determine their precedence constraints, and schedule them according to temporal project constraints. We suggest a data-driven project planning approach for classes of projects such as infrastructure building and information systems development projects. A project network is first learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, from which one has to be selected, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for: 1) decoding a project variation such that it forms a new project plan, and 2) applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation. Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.
</details>
<details>
<summary>摘要</summary>
First, a project network is learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, from which one has to be selected, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for:1. Decoding a project variation so that it forms a new project plan, and2. Applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation.Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.
</details></li>
</ul>
<hr>
<h2 id="A-New-Approach-to-Intuitionistic-Fuzzy-Decision-Making-Based-on-Projection-Technology-and-Cosine-Similarity-Measure"><a href="#A-New-Approach-to-Intuitionistic-Fuzzy-Decision-Making-Based-on-Projection-Technology-and-Cosine-Similarity-Measure" class="headerlink" title="A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure"></a>A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11539">http://arxiv.org/abs/2311.11539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Yang, Wei Su</li>
<li>for: 这个论文的目的是提出一种基于投影技术和偏好相似度度量的多属性决策方法和医疗诊断方法，用于处理基于Intuitionistic Fuzzy Set（IFS）的不确定和不完整信息。</li>
<li>methods: 该方法使用了投影技术和偏好相似度度量来评估IFS之间的相似性。具体来说，该方法首先将IFS转换成一个高维空间中的点集，然后使用投影技术将这些点集投影到一个低维空间中，最后使用偏好相似度度量来评估这些点集之间的相似性。</li>
<li>results:  compare with existed methods, the proposed method can identify the optimal scheme more accurately. In medical diagnosis area, it can quickly diagnose disease. The proposed method enriches the exist-ing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets(IVIFSs) as well.<details>
<summary>Abstract</summary>
For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy number(IFN). Intuitionistic fuzzy set (IFS) plays an important role in dealing with un-certain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which con-siders the direction and length of IFSs at the same time, is first proposed in this paper. The objective of the presented pa-per is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some exist-ing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In medical diagnosis area, it can be used to quickly diagnose disease. The proposed method enriches the exist-ing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets(IVIFSs) as well.
</details>
<details>
<summary>摘要</summary>
For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy numbers (IFN). Intuitionistic fuzzy sets (IFS) play an important role in dealing with uncertain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which considers the direction and length of IFSs at the same time, is proposed in this paper for the first time. The objective of the presented paper is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some existing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In the medical diagnosis area, it can be used to quickly diagnose diseases. The proposed method enriches the existing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets (IVIFSs) as well.Here's the word-for-word translation of the text into Simplified Chinese:为多Attribute决策问题，alternatives的不同属性信息给出为Intuitionistic Fuzzy Number(IFN)的形式。Intuitionistic Fuzzy Set(IFS)在处理不确定和不完整信息方面发挥重要作用。IFS的相似度度量在IFS中 Always是研究热点。本文提出了一种基于投影技术和cosine相似度度量的IFS相似度度量，这种度量考虑了IFS的方向和长度同时。本文的目标是使用投影技术和cosine相似度度量来解决IFS下的多Attribute决策问题和医学诊断问题。一些例子用于比较提出的算法和现有方法的比较结果，结果显示，提出的算法是有效的，可以准确地确定优化方案。在医学诊断领域，它可以快速诊断疾病。提出的方法riches存在相似度度量方法，并可以应用于不仅IFS，还有其他间隔值Intuitionistic Fuzzy Set(IVIFS)。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Prompt-Injection-Risks-in-200-Custom-GPTs"><a href="#Assessing-Prompt-Injection-Risks-in-200-Custom-GPTs" class="headerlink" title="Assessing Prompt Injection Risks in 200+ Custom GPTs"></a>Assessing Prompt Injection Risks in 200+ Custom GPTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11538">http://arxiv.org/abs/2311.11538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Yu, Yuhang Wu, Dong Shu, Mingyu Jin, Xinyu Xing</li>
<li>for: 这研究旨在阐述用户自定义GPT模型时存在的安全漏洞，以及这些漏洞的可能的 Mitigation 策略。</li>
<li>methods: 该研究通过对超过200个用户自定义GPT模型进行了广泛的靶场测试，并通过对这些系统的敏感Prompt进行了攻击，以证明这些系统容易受到攻击。</li>
<li>results: 该研究发现，通过提示攻击，敏感Prompt可以被提取，并且可以访问上传的文件。这些发现告诉我们，在设计和部署自定义GPT模型时，需要建立Robust的安全框架，以避免安全和隐私问题。<details>
<summary>Abstract</summary>
In the rapidly evolving landscape of artificial intelligence, ChatGPT has been widely used in various applications. The new feature: customization of ChatGPT models by users to cater to specific needs has opened new frontiers in AI utility. However, this study reveals a significant security vulnerability inherent in these user-customized GPTs: prompt injection attacks. Through comprehensive testing of over 200 user-designed GPT models via adversarial prompts, we demonstrate that these systems are susceptible to prompt injections. Through prompt injection, an adversary can not only extract the customized system prompts but also access the uploaded files. This paper provides a first-hand analysis of the prompt injection, alongside the evaluation of the possible mitigation of such attacks. Our findings underscore the urgent need for robust security frameworks in the design and deployment of customizable GPT models. The intent of this paper is to raise awareness and prompt action in the AI community, ensuring that the benefits of GPT customization do not come at the cost of compromised security and privacy.
</details>
<details>
<summary>摘要</summary>
在人工智能领域的快速发展中，ChatGPT已广泛应用于多种应用程序。新的特性：用户自定义ChatGPT模型以满足特定需求，打开了新的人工智能实用性前iers。然而，这项研究发现了自定义GPT模型中的一定安全漏洞：提示插入攻击。通过对超过200个用户定制GPT模型进行广泛测试，我们证实了这些系统受到提示插入攻击的漏洞。通过提示插入，敌对者不仅可以提取自定义系统提示，还可以访问上传文件。本文提供了首次的提示插入分析，以及可能的 Mitigation 策略的评估。我们的发现强调了在设计和部署自定义GPT模型时需要建立Robust 安全框架，以确保人工智能技术的发展不受安全和隐私问题的限制。本文的目的是逐itung 人工智能社区，提醒他们不要因为自定义GPT模型的好处而忽略安全和隐私问题的重要性。
</details></li>
</ul>
<hr>
<h2 id="ADAPTER-RL-Adaptation-of-Any-Agent-using-Reinforcement-Learning"><a href="#ADAPTER-RL-Adaptation-of-Any-Agent-using-Reinforcement-Learning" class="headerlink" title="ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning"></a>ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11537">http://arxiv.org/abs/2311.11537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhao Jin, Greg Slabaugh, Simon Lucas</li>
<li>for: 该论文旨在探讨 reinforcement learning (DRL)  Agent 如何适应外部任务，并解决过拟合、忘记和样本不足等问题。</li>
<li>methods: 该论文提出了一种基于 adapter 的适应策略，并在 nanoRTS 环境中进行实验，证明了该策略可以提高基础 Agent 的训练效率和性能。</li>
<li>results: 该论文的实验结果表明，使用 adapter 可以提高基础 Agent 的性能，并且可以与先前训练过的神经网络和规则基础 Agent 集成，以便捕捉人类专家的知识。<details>
<summary>Abstract</summary>
Deep Reinforcement Learning (DRL) agents frequently face challenges in adapting to tasks outside their training distribution, including issues with over-fitting, catastrophic forgetting and sample inefficiency. Although the application of adapters has proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper delves into the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and improvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy (RTS) game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.
</details>
<details>
<summary>摘要</summary>
深度强化学习（DRL）代理频繁面临外部任务适应问题，包括过拟合、致命忘记和样本不足。 although adapters have proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper explores the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and improvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy (RTS) game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.Here's the translation in Traditional Chinese:深度强化学习（DRL）代理频繁面临外部任务适应问题，包括过拟合、致命忘记和样本不足。 although adapters have proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper explores the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and improvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy (RTS) game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.
</details></li>
</ul>
<hr>
<h2 id="Optimal-Hyperparameter-ε-for-Adaptive-Stochastic-Optimizers-through-Gradient-Histograms"><a href="#Optimal-Hyperparameter-ε-for-Adaptive-Stochastic-Optimizers-through-Gradient-Histograms" class="headerlink" title="Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers through Gradient Histograms"></a>Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers through Gradient Histograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11532">http://arxiv.org/abs/2311.11532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gustavo Silva, Paul Rodriguez</li>
<li>for: 这个论文的目的是为了研究和分析适应性优化器的优化器论文，尤其是 Adam 优化器的一些小优化器参数的影响。</li>
<li>methods: 该论文使用了 gradient histogram  Framework 来分析和证明适应性优化器的优化器参数的优化性和关系。</li>
<li>results: 该论文提出了一种基于 gradient histogram 的新算法，可以自动优化 safeguard 参数 $\epsilon$ 的搜索空间，以便更好地找到最佳值。<details>
<summary>Abstract</summary>
Optimizers are essential components for successfully training deep neural network models. In order to achieve the best performance from such models, designers need to carefully choose the optimizer hyperparameters. However, this can be a computationally expensive and time-consuming process. Although it is known that all optimizer hyperparameters must be tuned for maximum performance, there is still a lack of clarity regarding the individual influence of minor priority hyperparameters, including the safeguard factor $\epsilon$ and momentum factor $\beta$, in leading adaptive optimizers (specifically, those based on the Adam optimizers). In this manuscript, we introduce a new framework based on gradient histograms to analyze and justify important attributes of adaptive optimizers, such as their optimal performance and the relationships and dependencies among hyperparameters. Furthermore, we propose a novel gradient histogram-based algorithm that automatically estimates a reduced and accurate search space for the safeguard hyperparameter $\epsilon$, where the optimal value can be easily found.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a new framework based on gradient histograms to analyze and justify important attributes of adaptive optimizers, such as their optimal performance and the relationships and dependencies among hyperparameters. Furthermore, we introduce a novel gradient histogram-based algorithm that automatically estimates a reduced and accurate search space for the safeguard hyperparameter $\epsilon$, making it easy to find the optimal value.
</details></li>
</ul>
<hr>
<h2 id="GPT-in-Data-Science-A-Practical-Exploration-of-Model-Selection"><a href="#GPT-in-Data-Science-A-Practical-Exploration-of-Model-Selection" class="headerlink" title="GPT in Data Science: A Practical Exploration of Model Selection"></a>GPT in Data Science: A Practical Exploration of Model Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11516">http://arxiv.org/abs/2311.11516</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathalia Nascimento, Cristina Tavares, Paulo Alencar, Donald Cowan</li>
<li>for: 本研究旨在探讨大语言模型（LLMs）在处理结构化数据和增强数据科学过程中的可能性，以及这种结合的可靠性和决策方法的问题。</li>
<li>methods: 本研究使用了一种变量模型来描述这些因素，并使用了小型数据集来评估模型和实现的规则。</li>
<li>results: 研究发现，GPT-4的模型选择建议受到了多种因素的指导，包括数据的性质、问题的类型、性能指标、计算资源、可解释性 vs 准确性、数据假设和伦理考虑。这些因素的权重不同，决定了模型选择的结果。<details>
<summary>Abstract</summary>
There is an increasing interest in leveraging Large Language Models (LLMs) for managing structured data and enhancing data science processes. Despite the potential benefits, this integration poses significant questions regarding their reliability and decision-making methodologies. It highlights the importance of various factors in the model selection process, including the nature of the data, problem type, performance metrics, computational resources, interpretability vs accuracy, assumptions about data, and ethical considerations. Our objective is to elucidate and express the factors and assumptions guiding GPT-4's model selection recommendations. We employ a variability model to depict these factors and use toy datasets to evaluate both the model and the implementation of the identified heuristics. By contrasting these outcomes with heuristics from other platforms, our aim is to determine the effectiveness and distinctiveness of GPT-4's methodology. This research is committed to advancing our comprehension of AI decision-making processes, especially in the realm of model selection within data science. Our efforts are directed towards creating AI systems that are more transparent and comprehensible, contributing to a more responsible and efficient practice in data science.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型（LLMs）在数据管理和数据科学过程中的潜在应用，人们对其可靠性和决策方法的问题日益增加。这些问题提出了许多因素在选择模型过程中的重要性，包括数据的性质、问题的类型、性能指标、计算资源、解释性vs准确率、数据假设以及伦理考虑。我们的目标是解释和表达引导GPT-4选择模型的因素和假设。我们使用变量模型来描述这些因素，并使用小型数据集来评估模型和标记出的规则。通过与其他平台的假设进行比较，我们的目标是确定GPT-4的方法的效果和特点。这项研究旨在提高我们对人工智能决策过程的理解，特别是数据科学中模型选择的领域。我们的努力是创造更加透明和可读的AI系统，以便更负责任和高效地实践数据科学。
</details></li>
</ul>
<hr>
<h2 id="MultiLoRA-Democratizing-LoRA-for-Better-Multi-Task-Learning"><a href="#MultiLoRA-Democratizing-LoRA-for-Better-Multi-Task-Learning" class="headerlink" title="MultiLoRA: Democratizing LoRA for Better Multi-Task Learning"></a>MultiLoRA: Democratizing LoRA for Better Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11501">http://arxiv.org/abs/2311.11501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Wang, Yu Lin, Xiaodong Zeng, Guannan Zhang</li>
<li>for: 这个论文的目的是提高LoRA模型在多任务场景中的适应性和性能。</li>
<li>methods: 这个论文使用了LoRA模型的水平扩展和初始化参数变换来减少最高特征值的影响，从而实现更好的多任务适应性。</li>
<li>results: 与单个LoRAcounterpart和精度调整相比，MultiLoRA模型在多个benchmark和模型缩放上表现出色，只需要2.5%的额外参数。进一步的分析发现MultiLoRA模型的weight更新矩阵中有更多的低级特征值贡献。<details>
<summary>Abstract</summary>
LoRA achieves remarkable resource efficiency and comparable performance when adapting LLMs for specific tasks. Since ChatGPT demonstrated superior performance on various tasks, there has been a growing desire to adapt one model for all tasks. However, the explicit low-rank of LoRA limits the adaptation performance in complex multi-task scenarios. LoRA is dominated by a small number of top singular vectors while fine-tuning decomposes into a set of less important unitary transforms. In this paper, we propose MultiLoRA for better multi-task adaptation by reducing the dominance of top singular vectors observed in LoRA. MultiLoRA scales LoRA modules horizontally and change parameter initialization of adaptation matrices to reduce parameter dependency, thus yields more balanced unitary subspaces. We unprecedentedly construct specialized training data by mixing datasets of instruction follow, natural language understanding, world knowledge, to cover semantically and syntactically different samples. With only 2.5% of additional parameters, MultiLoRA outperforms single LoRA counterparts and fine-tuning on multiple benchmarks and model scales. Further investigation into weight update matrices of MultiLoRA exhibits reduced dependency on top singular vectors and more democratic unitary transform contributions.
</details>
<details>
<summary>摘要</summary>
LoRA 实现了非常出色的资源效率和相对性，当适应特定任务时。由于 ChatGPT 在多种任务上显示出了优秀表现，因此有越来越多的人想要适应一个模型 для所有任务。然而，LoRA 的明确低纬度限制了复杂多任务场景中的适应性能。LoRA 由一小数量的Top singular vectors 控制，而 fine-tuning  decomposition 为一组 less important 的单位变换。在这篇论文中，我们提议 MultiLoRA 来改进多任务适应性能。MultiLoRA 将 LoRA 模块拓宽到 Horizontal 方向，并改变适应矩阵的参数初始化，以减少参数依赖性，因此实现更加平衡的单位空间。我们首次混合了 instrucion follow、自然语言理解、世界知识等数据集，以覆盖semantically和syntactically不同的样本。尽管只增加了2.5%的参数，MultiLoRA 仍然超过了单个 LoRA 对手和 fine-tuning 多个benchmark和模型Scale。进一步的调查表明，MultiLoRA 的weight update 矩阵中具有减少 top singular vectors 的依赖性和更多的democratic 单位变换贡献。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-in-Machine-Learning-on-the-Interplay-with-Explainability-Predictive-Performances-and-Models"><a href="#Interpretability-in-Machine-Learning-on-the-Interplay-with-Explainability-Predictive-Performances-and-Models" class="headerlink" title="Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models"></a>Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11491">http://arxiv.org/abs/2311.11491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Leblanc, Pascal Germain</li>
<li>for: 提高机器学习模型的理解和应用</li>
<li>methods: 通过对机器学习术语的分析和讨论，摘要了对机器学习模型的理解和应用的关系</li>
<li>results: 挑战了一些关于机器学习模型的理解和应用的假设和误解，并提出了一些新的思路和方法来提高机器学习模型的理解和应用<details>
<summary>Abstract</summary>
Interpretability has recently gained attention in the field of machine learning, for it is crucial when it comes to high-stakes decisions or troubleshooting. This abstract concept is hard to grasp and has been associated, over time, with many labels and preconceived ideas. In this position paper, in order to clarify some misunderstandings regarding interpretability, we discuss its relationship with significant concepts in machine learning: explainability, predictive performances, and machine learning models. For instance, we challenge the idea that interpretability and explainability are substitutes to one another, or that a fixed degree of interpretability can be associated with a given machine learning model.
</details>
<details>
<summary>摘要</summary>
优先级化的Machine Learning领域中，可解性（Interpretability）在最近几年来受到了关注，因为它在高风险决策或疑难解答中具有重要性。这个抽象的概念很难理解，而且在时间的推移中，与多种标签和先入为主的想法相关联。在这篇position paper中，我们希望通过讨论可解性与机器学习模型之间的关系，以及与预测性能和其他核心概念的关系，来清楚一些有关可解性的误解。例如，我们挑战了认为可解性和解释性是纯粹的替代品，或者一个固定的可解性水平可以与某种机器学习模型相关联。
</details></li>
</ul>
<hr>
<h2 id="A-Multi-Center-Study-on-the-Adaptability-of-a-Shared-Foundation-Model-for-Electronic-Health-Records"><a href="#A-Multi-Center-Study-on-the-Adaptability-of-a-Shared-Foundation-Model-for-Electronic-Health-Records" class="headerlink" title="A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records"></a>A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11483">http://arxiv.org/abs/2311.11483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Lawrence Guo, Jason Fries, Ethan Steinberg, Scott Lanyon Fleming, Keith Morse, Catherine Aftandilian, Jose Posada, Nigam Shah, Lillian Sung<br>for: 这种研究旨在检验基础模型在不同医院之间是否可以进行共享和适应，以提高AI在医疗领域的可扩展性和成本效益。methods: 这个研究使用了一个已经发布的结构化医疗记录基础模型($FM_{SM}$)，通过在长期医疗记录数据上进行训练，来评估基础模型在不同医院的适应性。研究还使用了两个不同的医院的EHR数据集，包括Stanford医学院的2.57万名患者的 longitudinal医疗记录数据和MIMIC-IV数据集。results: 研究发现，通过继续在本地数据上进行预训练，可以大幅提高基础模型的适应性和任务适应性，而无需大量的本地训练数据。此外，基础模型在8个临床预测任务上的表现也证明了其在不同医院之间的适应性。<details>
<summary>Abstract</summary>
Foundation models hold promise for transforming AI in healthcare by providing modular components that are easily adaptable to downstream healthcare tasks, making AI development more scalable and cost-effective. Structured EHR foundation models, trained on coded medical records from millions of patients, demonstrated benefits including increased performance with fewer training labels, and improved robustness to distribution shifts. However, questions remain on the feasibility of sharing these models across different hospitals and their performance for local task adaptation. This multi-center study examined the adaptability of a recently released structured EHR foundation model ($FM_{SM}$), trained on longitudinal medical record data from 2.57M Stanford Medicine patients. Experiments were conducted using EHR data at The Hospital for Sick Children and MIMIC-IV. We assessed both adaptability via continued pretraining on local data, and task adaptability compared to baselines of training models from scratch at each site, including a local foundation model. We evaluated the performance of these models on 8 clinical prediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$ matched the performance of GBM models locally trained on all data while providing a 13% improvement in settings with few task-specific training labels. With continued pretraining on local data, label efficiency substantially improved, such that $FM_{SM}$ required fewer than 1% of training examples to match the fully trained GBM's performance. Continued pretraining was also 60 to 90% more sample-efficient than training local foundation models from scratch. Our findings show that adapting shared EHR foundation models across hospitals provides improved prediction performance at less cost, underscoring the utility of base foundation models as modular components to streamline the development of healthcare AI.
</details>
<details>
<summary>摘要</summary>
基础模型在医疗领域的应用拥有潜在的优势，它们可以提供可重用的组件，使AI开发变得更加扩展和成本效果。使用结构化医疗记录数据进行训练的基础模型($FM_{SM}$)，已经在医疗任务上显示出了多种优点，包括使用 fewer 的训练标签和更好的分布shift的Robustness。然而，共享这些模型在不同医院中的可行性以及其对本地任务适应性的性能仍然存在问题。本多中心研究检查了这种基础模型的适应性，通过在医疗儿童医院和MIMIC-IV数据集上进行实验。我们通过继续预训这些模型地方数据来评估其适应性和任务适应性，并与基于 scratch 训练的本地模型进行比较。我们对8种临床预测任务进行了评估。在两个数据集中，适应 $FM_{SM} $ 与基于GBM模型的本地训练相比，提供了13%的提升，而且在具有少量任务特定训练标签的情况下，适应 $FM_{SM} $ 只需要 fewer than 1%的训练示例来匹配完全训练的GBM模型的性能。继续预训使得样本效率明显提高，例如，$FM_{SM}$ 只需要 fewer than 1%的训练示例来匹配完全训练的GBM模型的性能。此外，继续预训还比基于 scratch 训练的本地模型采样更加高效，60%-90%。我们的发现表明，在医疗机构之间共享基础模型可以提供更好的预测性能，同时降低开发成本，从而赞成基础模型作为医疗AI开发的模块化组件。
</details></li>
</ul>
<hr>
<h2 id="Meta-Prompting-for-AGI-Systems"><a href="#Meta-Prompting-for-AGI-Systems" class="headerlink" title="Meta Prompting for AGI Systems"></a>Meta Prompting for AGI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11482">http://arxiv.org/abs/2311.11482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meta-prompting/meta-prompting">https://github.com/meta-prompting/meta-prompting</a></li>
<li>paper_authors: Yifan Zhang</li>
<li>for: 本研究探讨了一种新的技术——Meta Prompting，它改变了大型语言模型（LLM）、多 modal基础模型和人工智能系统如何解决问题和 интерпретирова数据的方式。</li>
<li>methods: Meta Prompting 基于类型理论和类型理论，强调信息结构和 sintaxis，提供了一种独特的框架，超越传统内容强调的方法。</li>
<li>results: 本研究表明，Meta Prompting 在多种 AI 应用中具有优势，特别是在复杂的问题解决方面。它能够将复杂的问题破解成可管理的子问题，实现了Token效率和 fair comparison在问题解决方面的优势。此外，本研究还推广了 Meta Prompting 到多 modal基础模型设置，实现了不同数据类型的集成，如图像、音频和视频，并提出了在这些数据类型之间的挑战和潜在的应用前景。<details>
<summary>Abstract</summary>
This paper presents an in-depth exploration of Meta Prompting, a novel technique that revolutionizes the way large language models (LLMs), multi-modal foundation models, and AI systems approach problem-solving and data interpretation. Meta Prompting, rooted in type theory and category theory, prioritizes the structure and syntax of information, providing a unique framework that transcends traditional content-focused methods. We delve into the formal definitions of Meta Prompting, contrasting it with Few-Shot Prompting, and highlight its applicability and superiority in various AI applications.   Key to this exploration is the expansion of Meta Prompting into the realm of complex reasoning. Here, we demonstrate how this technique adeptly breaks down intricate problems into manageable sub-problems, facilitating a step-by-step, detailed approach to problem-solving. This method proves especially advantageous in terms of token efficiency and offering a fair comparison in problem-solving scenarios, standing out against few-shot example approaches.   Furthermore, the paper breaks new ground by extending Meta Prompting into multi-modal foundation model settings. This extension addresses the integration of diverse data types, such as images, audio, and video, within the structured framework of Meta Prompting, highlighting both the challenges and the vast potential of this approach in handling complex, multi-faceted data (The code is available at https://github.com/meta-prompting/meta-prompting).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Empowering-remittance-management-in-the-digitised-landscape-A-real-time-Data-Driven-Decision-Support-with-predictive-abilities-for-financial-transactions"><a href="#Empowering-remittance-management-in-the-digitised-landscape-A-real-time-Data-Driven-Decision-Support-with-predictive-abilities-for-financial-transactions" class="headerlink" title="Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions"></a>Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11476">http://arxiv.org/abs/2311.11476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rashikala Weerawarna, Shah J Miah</li>
<li>for: 这项研究是为了为区块链技术（BT）驱动的财付转场景下的决策支持系统设计一个数据驱动的预测决策支持方法。</li>
<li>methods: 该研究采用了 teoría-generating 设计科学研究（DSR）方法，通过对交易大数据的分析，揭示了预测 capability 的emergence。该方法结合了预测分析和机器学习（ML），实现了实时的财付转监测，帮助管理决策者在适应 digitized 的区块链 oriented 财付转公司面临的挑战时作出更好的决策。</li>
<li>results: 该研究不仅增强了财付转公司的安全性，还为未来的预测决策支持解决方案提供了基础，扩展了 predictive analytics 的潜在应用领域。此外，通过实施 artifact 的 theory，DSR 方法得到了进一步的发展和深入的 theory 发展在信息系统领域。<details>
<summary>Abstract</summary>
The advent of Blockchain technology (BT) revolutionised the way remittance transactions are recorded. Banks and remittance organisations have shown a growing interest in exploring blockchain's potential advantages over traditional practices. This paper presents a data-driven predictive decision support approach as an innovative artefact designed for the blockchain-oriented remittance industry. Employing a theory-generating Design Science Research (DSR) approach, we have uncovered the emergence of predictive capabilities driven by transactional big data. The artefact integrates predictive analytics and Machine Learning (ML) to enable real-time remittance monitoring, empowering management decision-makers to address challenges in the uncertain digitised landscape of blockchain-oriented remittance companies. Bridging the gap between theory and practice, this research not only enhances the security of the remittance ecosystem but also lays the foundation for future predictive decision support solutions, extending the potential of predictive analytics to other domains. Additionally, the generated theory from the artifact's implementation enriches the DSR approach and fosters grounded and stakeholder theory development in the information systems domain.
</details>
<details>
<summary>摘要</summary>
随着区块链技术（BT）的出现，财务转移交易的记录方式发生了革命。银行和财务转移机构对区块链的潜在优势表示了增加的兴趣。这篇论文描述了一种数据驱动的预测决策支持方法，作为区块链 Orientated 财务转移industry 的创新艺ifact。通过使用理论生成的设计科学研究（DSR）方法，我们揭示了交易大数据驱动的预测能力的出现。该艺ifact结合预测分析和机器学习（ML），以实时监控财务转移，让管理决策者能够在不确定的区块链 Orientated 财务转移公司 digitized 景观中 Address 挑战。将理论与实践相连，这项研究不仅提高了财务转移生态系统的安全性，还为未来的预测决策支持解决方案 lay 基础，扩展预测分析的潜在应用领域。此外，艺ifact的实施生成了理论，扩充了DSR方法，并为信息系统领域的grounded 和参与者理论发展提供了基础。
</details></li>
</ul>
<hr>
<h2 id="CSGNN-Conquering-Noisy-Node-labels-via-Dynamic-Class-wise-Selection"><a href="#CSGNN-Conquering-Noisy-Node-labels-via-Dynamic-Class-wise-Selection" class="headerlink" title="CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection"></a>CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11473">http://arxiv.org/abs/2311.11473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Li, Zhen Tan, Kai Shu, Zongsheng Cao, Yu Kong, Huan Liu<br>for: 这篇论文的目的是提出一种新的graph neural network（GNN）选择方法，以提高GNN在graph上的表现学习。methods: 本篇论文使用了一种新的邻居总和 latent space，以适应不同类别的范例选择。具体来说，这篇论文使用了一种动态类别选择机制，通过类别概率的调整，对不同类别的范例进行适应性选择。此外，本篇论文还使用了一种内部阶层学习方法，以避免过滤错误的范例。results: 根据实验结果，CSGNN比顶尖方法更高效和更稳定，具体来说，CSGNN在零散测验中的表现比顶尖方法高出30%以上。此外，CSGNN还能够在不同类别的范例上提高表现，并且能够避免过滤错误的范例。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have emerged as a powerful tool for representation learning on graphs, but they often suffer from overfitting and label noise issues, especially when the data is scarce or imbalanced. Different from the paradigm of previous methods that rely on single-node confidence, in this paper, we introduce a novel Class-wise Selection for Graph Neural Networks, dubbed CSGNN, which employs a neighbor-aggregated latent space to adaptively select reliable nodes across different classes. Specifically, 1) to tackle the class imbalance issue, we introduce a dynamic class-wise selection mechanism, leveraging the clustering technique to identify clean nodes based on the neighbor-aggregated confidences. In this way, our approach can avoid the pitfalls of biased sampling which is common with global threshold techniques. 2) To alleviate the problem of noisy labels, built on the concept of the memorization effect, CSGNN prioritizes learning from clean nodes before noisy ones, thereby iteratively enhancing model performance while mitigating label noise. Through extensive experiments, we demonstrate that CSGNN outperforms state-of-the-art methods in terms of both effectiveness and robustness.
</details>
<details>
<summary>摘要</summary>
格点神经网络（GNNs）已经成为图像 Representation Learning 的强大工具，但它们经常受到过拟合和标签噪声问题的影响，特别是数据稀缺或不均衡时。与先前的方法不同，我们在本文中引入了一种新的类别选择方法，称为 CSGNN，它使用邻居积分的隐藏空间来适应不同类型的可靠节点选择。具体来说，我们解决了类别不均衡问题的方法是，通过 clustering 技术来识别干净的节点，基于邻居积分的信任度。这种方法可以避免全球阈值技术中的偏袋 sampling 问题。此外，我们使用了 memorization effect 的概念，在不同类型的节点上偏好学习干净的节点，从而逐步提高模型性能，同时缓解标签噪声。我们在广泛的实验中证明了 CSGNN 可以与当前状态的方法相比，在效果和稳定性两个方面具有优势。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.AI_2023_11_20/" data-id="clpxp6bxm007nee88e5rz2a65" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
