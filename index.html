
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.SD_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T15:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.SD_2023_11_01/">cs.SD - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="C2C-Cough-to-COVID-19-Detection-in-BHI-2023-Data-Challenge"><a href="#C2C-Cough-to-COVID-19-Detection-in-BHI-2023-Data-Challenge" class="headerlink" title="C2C: Cough to COVID-19 Detection in BHI 2023 Data Challenge"></a>C2C: Cough to COVID-19 Detection in BHI 2023 Data Challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00364">http://arxiv.org/abs/2311.00364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Woo-Jin Chung, Miseul Kim, Hong-Goo Kang</li>
<li>for: 这个研究报告描述了我们在BHI 2023数据竞赛：感知挑战中的提交。我们的Audio Alchemists团队设计了一个基于声音的COVID-19诊断系统，叫做Cough to COVID-19（C2C），并在挑战中获得了第一名。</li>
<li>methods: C2C包括三个关键贡献：输入信号的预处理、基于Wav2vec2.0的喊喊相关特征提取、以及数据增强。通过实验发现，我们 demonstated C2C的潜在性能可以提高COVID-19诊断的准确率via 喊喊信号。</li>
<li>results: 我们的提posed模型在COVID-19诊断上达到了ROC-AUC值为0.7810。可以在以下链接中找到我们的实现细节和Python代码：<a target="_blank" rel="noopener" href="https://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists">https://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists</a><details>
<summary>Abstract</summary>
This report describes our submission to BHI 2023 Data Competition: Sensor challenge. Our Audio Alchemists team designed an acoustic-based COVID-19 diagnosis system, Cough to COVID-19 (C2C), and won the 1st place in the challenge. C2C involves three key contributions: pre-processing of input signals, cough-related representation extraction leveraging Wav2vec2.0, and data augmentation. Through experimental findings, we demonstrate C2C's promising potential to enhance the diagnostic accuracy of COVID-19 via cough signals. Our proposed model achieves a ROC-AUC value of 0.7810 in the context of COVID-19 diagnosis. The implementation details and the python code can be found in the following link: https://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists
</details>
<details>
<summary>摘要</summary>
这份报告介绍我们在BHI 2023数据比赛：感知挑战中的提交。我们的Audio Alchemists团队设计了一个基于声音的 COVID-19诊断系统，叫做Cough to COVID-19（C2C），并在挑战中获得了第一名。C2C包括三个关键贡献：输入信号的预处理、基于 Wav2vec2.0 的喊喊相关特征提取、以及数据扩展。通过实验结果，我们证明了 C2C 在 COVID-19 诊断中的潜在优异性。我们提出的模型在 COVID-19 诊断上 achiev 了 ROC-AUC 值为 0.7810。更多细节和 Python 代码可以在以下链接中找到：https://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.SD_2023_11_01/" data-id="cloh7tqmq00xf7b8804sif9n6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/eess.AS_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T14:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/eess.AS_2023_11_01/">eess.AS - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Reverberant-sound-field-equalisation-for-an-enhanced-stereo-playback-experience"><a href="#Reverberant-sound-field-equalisation-for-an-enhanced-stereo-playback-experience" class="headerlink" title="Reverberant sound field equalisation for an enhanced stereo playback experience"></a>Reverberant sound field equalisation for an enhanced stereo playback experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00624">http://arxiv.org/abs/2311.00624</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Brooks-Park, Steven van de Par</li>
<li>for: 提高室内播放质量</li>
<li>methods: 使用新型平衡技术，通过两个围声 speaker 加入各自的抗干扰 Filter 能量，保持直接声音不变，但是听众位置的直接和反射声音能量平衡</li>
<li>results: 对比传统平衡技术和ステレオ播放， preference 更高Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written to improve the playback quality of loudspeakers in reverberant rooms.</li>
<li>methods: The proposed method uses a novel equalisation technique that adds gammatone filter band energy to the reverberant sound field via two surround loudspeakers, while leaving the direct sound from the primary loudspeakers unaltered. This allows the target function of the direct sound to differ from the reverberant sound field.</li>
<li>results: The proposed method is preferred over traditional room equalisation techniques and stereo playback, as demonstrated by subjective listening tests.<details>
<summary>Abstract</summary>
The topic of room equalisation has been at the forefront of research and product development for many years, with the aim of increasing the playback quality of loudspeakers in reverberant rooms. Traditional room equalisation systems comprise of a number of filters that when applied to the primary loudspeakers, additional room colouration is compensated for. This publication introduces a novel equalisation technique where gammatone filter band energy is added to the reverberant sound field via two surround loudspeakers, leaving the direct sound from the primary loudspeakers unaltered, but the sum of direct and reverberant energy is equalised at the listening position. Unlike traditional systems, this method allows the target function of the direct sound to differ from the reverberant sound field. The proposed method is motivated by the different roles direct and reverberant sound components play in humans perception of sound. Along with introducing the proposed method, results from a subjective listening test are presented, demonstrating the preference towards the proposed technique when compared to a traditional room equalisation technique and stereo playback.
</details>
<details>
<summary>摘要</summary>
room 平衡技术在研究和产品开发中已经占据了多年的主导地位，以提高含湿室内的音响器播放质量。传统的房间平衡系统由多个缓冲器组成，当应用于主音响器时，会赔偿室内额外颜色。本文介绍了一种新型的平衡技术，通过两个围声speaker在听众位置加入 gammatone 缓冲器带的能量，保留直接声音的不变，但是直接和反射声音能量的总和在听众位置进行平衡。与传统系统不同，这种方法允许直接声音和反射声音的目标函数不同。这种方法是基于人类听众对声音的感知中直接和反射声音的不同角色的。文章还介绍了这种方法的试验结果，其中包括对传统房间平衡技术和斯tereo播放进行比较。
</details></li>
</ul>
<hr>
<h2 id="An-analysis-of-large-speech-models-based-representations-for-speech-emotion-recognition"><a href="#An-analysis-of-large-speech-models-based-representations-for-speech-emotion-recognition" class="headerlink" title="An analysis of large speech models-based representations for speech emotion recognition"></a>An analysis of large speech models-based representations for speech emotion recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00394">http://arxiv.org/abs/2311.00394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Bogdan Stânea, Vlad Striletchi, Cosmin Striletchi, Adriana Stan</li>
<li>for: 这篇论文是关于语音情感识别的研究，旨在探讨大语音模型 derived features 在不进行 fine-tuning 的情况下，是否可以达到同样的性能水平。</li>
<li>methods: 这篇论文使用了预训练的大语音模型，并 explore 其内置的抽象特征，以实现语音情感识别。作者使用了简单的分类方法，以避免干扰或添加知识到任务中。</li>
<li>results: 研究发现，不需要 fine-tuning，一些大语音模型的表征可以封闭情感信息，使得性能与或超过现有标准 Datasets 的性能水平。<details>
<summary>Abstract</summary>
Large speech models-derived features have recently shown increased performance over signal-based features across multiple downstream tasks, even when the networks are not finetuned towards the target task. In this paper we show the results of an analysis of several signal- and neural models-derived features for speech emotion recognition. We use pretrained models and explore their inherent potential abstractions of emotions. Simple classification methods are used so as to not interfere or add knowledge to the task. We show that, even without finetuning, some of these large neural speech models' representations can enclose information that enables performances close to, and even beyond state-of-the-art results across six standard speech emotion recognition datasets.
</details>
<details>
<summary>摘要</summary>
大型语音模型Derived Features在多个下游任务中显示出了提高的表现，即使网络没有finetune towards the target task。在这篇论文中，我们展示了几种信号模型和神经网络模型Derived Features的分析结果，用于speech emotion认知。我们使用预训练模型，探索它们的内在抽象能力。我们使用简单的分类方法，以避免对任务添加知识或干扰。我们发现，无需finetune，一些大型神经语音模型的表示可以包含情感认知的信息，使得表现与标准speech emotion认知数据集中的表现相当或超过状态的报告。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/eess.AS_2023_11_01/" data-id="cloh7tqnx010t7b887o744cwq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.CV_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T13:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.CV_2023_11_01/">cs.CV - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="What-User-Behaviors-Make-the-Differences-During-the-Process-of-Visual-Analytics"><a href="#What-User-Behaviors-Make-the-Differences-During-the-Process-of-Visual-Analytics" class="headerlink" title="What User Behaviors Make the Differences During the Process of Visual Analytics?"></a>What User Behaviors Make the Differences During the Process of Visual Analytics?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00690">http://arxiv.org/abs/2311.00690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahin Doroudian, Zekun Wu, Aidong Lu</li>
<li>for: 这项研究的目的是为了提高视觉分析过程中的设计和互动功能，以帮助视觉研究人员从多个方面获得启发。</li>
<li>methods: 这项研究使用了时间序列分类方法来分析用户行为记录，以解决用户行为的复杂性和我们对用户行为的不了解。</li>
<li>results: 研究发现用户在视觉分析过程中的行为可以分 distinguish，并且存在用户physical behaviors和视觉任务之间的强相关性。此外，我们还展示了如何使用我们的模型来自动地研究感知过程，不需要繁琐的手动标注。<details>
<summary>Abstract</summary>
The understanding of visual analytics process can benefit visualization researchers from multiple aspects, including improving visual designs and developing advanced interaction functions. However, the log files of user behaviors are still hard to analyze due to the complexity of sensemaking and our lack of knowledge on the related user behaviors. This work presents a study on a comprehensive data collection of user behaviors, and our analysis approach with time-series classification methods. We have chosen a classical visualization application, Covid-19 data analysis, with common analysis tasks covering geo-spatial, time-series and multi-attributes. Our user study collects user behaviors on a diverse set of visualization tasks with two comparable systems, desktop and immersive visualizations. We summarize the classification results with three time-series machine learning algorithms at two scales, and explore the influences of behavior features. Our results reveal that user behaviors can be distinguished during the process of visual analytics and there is a potentially strong association between the physical behaviors of users and the visualization tasks they perform. We also demonstrate the usage of our models by interpreting open sessions of visual analytics, which provides an automatic way to study sensemaking without tedious manual annotations.
</details>
<details>
<summary>摘要</summary>
理解视觉分析过程可以对视觉研究人员提供多方面的利益，包括改进视觉设计和开发高级交互功能。然而，用户行为的日志仍然困难分析，因为感知的复杂性和我们对相关用户行为的不了知。本研究报告一项全面收集用户行为数据的研究，并使用时间序列分类方法进行分析。我们选择了一个经典的视觉应用程序，即COVID-19数据分析，其中包括地图、时间序列和多属性的常见分析任务。我们的用户研究收集了用户在多种视觉任务上的行为记录，并将其分为两个相似的系统：桌面和 immerse 视觉。我们结合三种时间序列机器学习算法在两个不同的缩放尺度进行分类结果的总结，并探索行为特征的影响。我们的结果表明，用户行为在视觉分析过程中可以被区分开来，而且用户的物理行为和他们执行的视觉任务之间可能存在强相关性。此外，我们还示例了使用我们的模型来自动地研究感知过程，不需要繁琐的手动标注。
</details></li>
</ul>
<hr>
<h2 id="Collaboration-in-Immersive-Environments-Challenges-and-Solutions"><a href="#Collaboration-in-Immersive-Environments-Challenges-and-Solutions" class="headerlink" title="Collaboration in Immersive Environments: Challenges and Solutions"></a>Collaboration in Immersive Environments: Challenges and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00689">http://arxiv.org/abs/2311.00689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Shahin Doroudian, Zachary Wartell</li>
<li>for: 这篇论文主要是为了探讨虚拟现实（VR）和增强现实（AR）工具在所有工程领域中的应用，以避免使用物理原型，训练在高风险的情况下，并解释真实或模拟结果。</li>
<li>methods: 这篇论文使用了现有的研究方法，包括文献综述、观察分析和实践报告，以探讨现有的协作在虚拟和增强现实环境中的应用。</li>
<li>results: 这篇论文结果显示，协作在虚拟和增强现实环境中是一个复杂的过程，涉及到不同的因素，如交流、协调和社交存在。论文还指出了在这些环境中协作的挑战和限制，例如缺乏物理提示、成本和可用性，以及需要进一步的研究。<details>
<summary>Abstract</summary>
Virtual Reality (VR) and Augmented Reality (AR) tools have been applied in all engineering fields in order to avoid the use of physical prototypes, to train in high-risk situations, and to interpret real or simulated results. In order to complete a shared task or assign tasks to the agents in such immersive environments, collaboration or Shared Cooperative Activities are a necessity. Collaboration in immersive environments is an emerging field of research that aims to study and enhance the ways in which people interact and work together in Virtual and Augmented Reality settings. Collaboration in immersive environments is a complex process that involves different factors such as communication, coordination, and social presence. This paper provides an overview of the current state of research on collaboration in immersive environments. It discusses the different types of immersive environments, including VR and AR, and the different forms of collaboration that can occur in these environments. The paper also highlights the challenges and limitations of collaboration in immersive environments, such as the lack of physical cues, cost and usability and the need for further research in this area. Overall, collaboration in immersive environments is a promising field with a wide range of potential applications, from education to industry, and it can benefit both individuals and groups by enhancing their ability to work together effectively.
</details>
<details>
<summary>摘要</summary>
虚拟现实（VR）和增强现实（AR）工具在所有工程领域中应用，以避免使用物理原型，进行高风险的训练，并解释实际或模拟结果。为完成共同任务或分配任务给代理人，在如此的沉浸环境中进行协作或共同活动是必要。协作在沉浸环境中是一个emerging的研究领域，旨在研究和提高人们在虚拟和增强现实Setting中之间的交互方式和协作方式。协作在沉浸环境中是一个复杂的过程，涉及到不同的因素，如交流、协调和社会存在感。本文提供了关于协作在沉浸环境中的当前研究状况的概述，包括VR和AR等不同类型的沉浸环境，以及在这些环境中的不同合作形式。文章还 highlights了协作在沉浸环境中的挑战和局限性，如物理提示的缺乏、成本和可用性问题，以及需要进一步的研究。总之，协作在沉浸环境中是一个有前途的领域，它可以推动人们之间的协作效果，从教育到工业，并对个人和团队产生积极的影响。
</details></li>
</ul>
<hr>
<h2 id="ProcSim-Proxy-based-Confidence-for-Robust-Similarity-Learning"><a href="#ProcSim-Proxy-based-Confidence-for-Robust-Similarity-Learning" class="headerlink" title="ProcSim: Proxy-based Confidence for Robust Similarity Learning"></a>ProcSim: Proxy-based Confidence for Robust Similarity Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00668">http://arxiv.org/abs/2311.00668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oriol Barbany, Xiaofan Lin, Muhammet Bastan, Arnab Dhua</li>
<li>for: 学习一个嵌入空间，使得输入的距离与其内在 semantics 之间尽量相关。</li>
<li>methods: 使用 ProcSim 框架，对每个样本计算它的 confidence 分数，根据它的normalized 距离与类表示进行评估。</li>
<li>results: 在具有 uniform 和提议的semantic coherent 噪声的 DML benchmark 数据集上实现了状态�ayer的性能。<details>
<summary>Abstract</summary>
Deep Metric Learning (DML) methods aim at learning an embedding space in which distances are closely related to the inherent semantic similarity of the inputs. Previous studies have shown that popular benchmark datasets often contain numerous wrong labels, and DML methods are susceptible to them. Intending to study the effect of realistic noise, we create an ontology of the classes in a dataset and use it to simulate semantically coherent labeling mistakes. To train robust DML models, we propose ProcSim, a simple framework that assigns a confidence score to each sample using the normalized distance to its class representative. The experimental results show that the proposed method achieves state-of-the-art performance on the DML benchmark datasets injected with uniform and the proposed semantically coherent noise.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TPSeNCE-Towards-Artifact-Free-Realistic-Rain-Generation-for-Deraining-and-Object-Detection-in-Rain"><a href="#TPSeNCE-Towards-Artifact-Free-Realistic-Rain-Generation-for-Deraining-and-Object-Detection-in-Rain" class="headerlink" title="TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain"></a>TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00660">http://arxiv.org/abs/2311.00660</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shenzheng2000/tpsence">https://github.com/shenzheng2000/tpsence</a></li>
<li>paper_authors: Shen Zheng, Changjie Lu, Srinivasa G. Narasimhan</li>
<li>for: 生成潮湿图像，提高降雨方法和场景理解的泛化能力。</li>
<li>methods: 提出了一种基于无对应图像翻译框架的图像生成方法，通过引入TPS约束来减少生成图像中的噪声和扭曲，并通过SeNCE策略重新评估负样本的推动力来提高生成图像的准确性。</li>
<li>results: 实验表明该方法可以生成高质量的潮湿图像，具有最小的噪声和扭曲，可以帮助图像降雨和物体检测在雨中。此外，该方法还可以生成高质量的雪天和夜景图像，表明其可以扩展到更广泛的应用场景。<details>
<summary>Abstract</summary>
Rain generation algorithms have the potential to improve the generalization of deraining methods and scene understanding in rainy conditions. However, in practice, they produce artifacts and distortions and struggle to control the amount of rain generated due to a lack of proper constraints. In this paper, we propose an unpaired image-to-image translation framework for generating realistic rainy images. We first introduce a Triangular Probability Similarity (TPS) constraint to guide the generated images toward clear and rainy images in the discriminator manifold, thereby minimizing artifacts and distortions during rain generation. Unlike conventional contrastive learning approaches, which indiscriminately push negative samples away from the anchors, we propose a Semantic Noise Contrastive Estimation (SeNCE) strategy and reassess the pushing force of negative samples based on the semantic similarity between the clear and the rainy images and the feature similarity between the anchor and the negative samples. Experiments demonstrate realistic rain generation with minimal artifacts and distortions, which benefits image deraining and object detection in rain. Furthermore, the method can be used to generate realistic snowy and night images, underscoring its potential for broader applicability. Code is available at https://github.com/ShenZheng2000/TPSeNCE.
</details>
<details>
<summary>摘要</summary>
雨水生成算法有可能提高雨水方法的总体化和场景理解，但在实践中它们产生artefacts和扭曲，并且控制雨水生成的量因为缺乏适当的约束而困难。在这篇论文中，我们提议一种不带对应图像的图像到图像翻译框架，用于生成真实的雨水图像。我们首先引入一种三角形概率相似（TPS）约束，以引导生成的图像向clear和雨水图像在推理器映射中趋近，从而减少artefacts和扭曲。与传统的对比学习方法不同，我们提议一种语义噪声对照估计（SeNCE）策略，并重新评估负样本的推动力度基于雨水和clear图像的语义相似性和特征相似性。实验表明可以生成真实的雨水图像，并且减少artefacts和扭曲，这对雨水去雨水和物体检测有益。此外，该方法还可以用于生成真实的雪天和夜间图像，从而推断其普遍性。代码可以在https://github.com/ShenZheng2000/TPSeNCE上获取。
</details></li>
</ul>
<hr>
<h2 id="De-Diffusion-Makes-Text-a-Strong-Cross-Modal-Interface"><a href="#De-Diffusion-Makes-Text-a-Strong-Cross-Modal-Interface" class="headerlink" title="De-Diffusion Makes Text a Strong Cross-Modal Interface"></a>De-Diffusion Makes Text a Strong Cross-Modal Interface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00618">http://arxiv.org/abs/2311.00618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Wei, Chenxi Liu, Siyuan Qiao, Zhishuai Zhang, Alan Yuille, Jiahui Yu</li>
<li>for: 这篇论文主要是为了提出一种新的文本 Representation 方法，可以将图像转换为文本，并且可以让文本与图像之间进行协同作业。</li>
<li>methods: 这篇论文使用了一种自适应的文本扩充模型，将输入图像转换为文本，然后使用固定的文本扩充模型来重建原始输入图像。这个过程被称为 De-Diffusion。</li>
<li>results: 实验表明，De-Diffusion 方法可以准确地将图像转换为文本，并且可以在多种多样的模态任务中进行通用应用。例如，一个 De-Diffusion 模型可以生成可转换的提示，用于不同的文本-图像工具，同时也达到了开放式视觉语言任务中的新州OF-the-art。<details>
<summary>Abstract</summary>
We demonstrate text as a strong cross-modal interface. Rather than relying on deep embeddings to connect image and language as the interface representation, our approach represents an image as text, from which we enjoy the interpretability and flexibility inherent to natural language. We employ an autoencoder that uses a pre-trained text-to-image diffusion model for decoding. The encoder is trained to transform an input image into text, which is then fed into the fixed text-to-image diffusion decoder to reconstruct the original input -- a process we term De-Diffusion. Experiments validate both the precision and comprehensiveness of De-Diffusion text representing images, such that it can be readily ingested by off-the-shelf text-to-image tools and LLMs for diverse multi-modal tasks. For example, a single De-Diffusion model can generalize to provide transferable prompts for different text-to-image tools, and also achieves a new state of the art on open-ended vision-language tasks by simply prompting large language models with few-shot examples.
</details>
<details>
<summary>摘要</summary>
我们展示了文本作为强型跨模态界面。而不是依靠深入嵌入来连接图像和语言作为界面表示，我们的方法将图像转换为文本，从而获得了自然语言中的可读性和灵活性。我们使用一个自适应oder，使用预训练的文本到图像扩散模型进行解码。解oder是将输入图像转换为文本，然后将其feed到固定的文本到图像扩散解码器中重construct原始输入——一个我们称为“De-Diffusion”的过程。实验证明了De-Diffusion文本表示图像的精度和全面性，因此可以轻松地被off-the-shelf文本到图像工具和大语言模型接受，用于多样化的跨模态任务。例如，一个单一的De-Diffusion模型可以泛化到提供不同文本到图像工具的可重用提示，并同时实现了开放式视力语言任务的新状态之一，只需提供少量示例来训练大语言模型。
</details></li>
</ul>
<hr>
<h2 id="Occluded-Person-Re-Identification-with-Deep-Learning-A-Survey-and-Perspectives"><a href="#Occluded-Person-Re-Identification-with-Deep-Learning-A-Survey-and-Perspectives" class="headerlink" title="Occluded Person Re-Identification with Deep Learning: A Survey and Perspectives"></a>Occluded Person Re-Identification with Deep Learning: A Survey and Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00603">http://arxiv.org/abs/2311.00603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enhao Ning, Changshuo Wang, Huang Zhangc, Xin Ning, Prayag Tiwari</li>
<li>for: 本文主要针对智能监测系统中人员重识别技术（Re-ID）的问题，具体来说是在受到干扰的情况下进行人员重识别。</li>
<li>methods: 本文主要分析了现有的深度学习基于的 occluded person Re-ID 方法，从多种角度进行科学分类和分析，并对这些方法进行系统性比较。</li>
<li>results: 本文对 occluded person Re-ID 方法进行了系统性比较，并提出了未来发展的看法。<details>
<summary>Abstract</summary>
Person re-identification (Re-ID) technology plays an increasingly crucial role in intelligent surveillance systems. Widespread occlusion significantly impacts the performance of person Re-ID. Occluded person Re-ID refers to a pedestrian matching method that deals with challenges such as pedestrian information loss, noise interference, and perspective misalignment. It has garnered extensive attention from researchers. Over the past few years, several occlusion-solving person Re-ID methods have been proposed, tackling various sub-problems arising from occlusion. However, there is a lack of comprehensive studies that compare, summarize, and evaluate the potential of occluded person Re-ID methods in detail. In this review, we start by providing a detailed overview of the datasets and evaluation scheme used for occluded person Re-ID. Next, we scientifically classify and analyze existing deep learning-based occluded person Re-ID methods from various perspectives, summarizing them concisely. Furthermore, we conduct a systematic comparison among these methods, identify the state-of-the-art approaches, and present an outlook on the future development of occluded person Re-ID.
</details>
<details>
<summary>摘要</summary>
人脸重复识别（Re-ID）技术在智能监测系统中扮演着越来越重要的角色。广泛的遮挡对人Re-ID的性能产生了很大的影响。遮挡人Re-ID指的是一种在遮挡情况下进行人脸匹配的技术，它面临着人员信息损失、干扰和视角偏移等挑战。这一领域在过去几年内吸引了广泛的研究者的关注。在这篇评论中，我们首先提供了遮挡人Re-ID的数据集和评价方法的详细介绍。然后，我们科学地将现有的深度学习基于的遮挡人Re-ID方法分类和分析，并将其 concisely 总结。此外，我们进行了系统性的比较和评价这些方法，找到了当前领域的状态机器和未来发展的前景。
</details></li>
</ul>
<hr>
<h2 id="PAUMER-Patch-Pausing-Transformer-for-Semantic-Segmentation"><a href="#PAUMER-Patch-Pausing-Transformer-for-Semantic-Segmentation" class="headerlink" title="PAUMER: Patch Pausing Transformer for Semantic Segmentation"></a>PAUMER: Patch Pausing Transformer for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00586">http://arxiv.org/abs/2311.00586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evann Courdier, Prabhu Teja Sivaprasad, François Fleuret</li>
<li>for: 提高图像 segmentation transformer 的效率，通过不同的计算量来适应不同的图像部分。</li>
<li>methods: 使用预测值的Entropy作为挽 paused 计算 criterion，并在最终decoder中停止计算。</li>
<li>results: 在 Cityscapes 和 ADE20K 两个标准的 segmentation 数据集上，我们的方法可以达到约 $50%$ 更高的 Throughput，与 mIoU 下降约 $0.65%$ 和 $4.6%$ 分别。<details>
<summary>Abstract</summary>
We study the problem of improving the efficiency of segmentation transformers by using disparate amounts of computation for different parts of the image. Our method, PAUMER, accomplishes this by pausing computation for patches that are deemed to not need any more computation before the final decoder. We use the entropy of predictions computed from intermediate activations as the pausing criterion, and find this aligns well with semantics of the image. Our method has a unique advantage that a single network trained with the proposed strategy can be effortlessly adapted at inference to various run-time requirements by modulating its pausing parameters. On two standard segmentation datasets, Cityscapes and ADE20K, we show that our method operates with about a $50\%$ higher throughput with an mIoU drop of about $0.65\%$ and $4.6\%$ respectively.
</details>
<details>
<summary>摘要</summary>
我团队研究如何通过不同的计算量来提高分割变换器的效率。我们的方法PAUMER通过在最终解码器之前暂停计算来实现这一目标。我们使用介词预测的Entropy作为暂停标准，并发现它与图像 semantics吻合得非常好。我们的方法具有单一网络在执行时可以根据运行时需求modulate暂停参数的优点，在Cityscapes和ADE20K两个标准分割dataset上，我们表明我们的方法可以达到约50%更高的throughput，与mIoU下降约0.65%和4.6%相对应。Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese scripts used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Robust-Deep-Learning-Method-with-Uncertainty-Estimation-for-the-Pathological-Classification-of-Renal-Cell-Carcinoma-based-on-CT-Images"><a href="#A-Robust-Deep-Learning-Method-with-Uncertainty-Estimation-for-the-Pathological-Classification-of-Renal-Cell-Carcinoma-based-on-CT-Images" class="headerlink" title="A Robust Deep Learning Method with Uncertainty Estimation for the Pathological Classification of Renal Cell Carcinoma based on CT Images"></a>A Robust Deep Learning Method with Uncertainty Estimation for the Pathological Classification of Renal Cell Carcinoma based on CT Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00567">http://arxiv.org/abs/2311.00567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ni Yao, Hang Hu, Kaicong Chen, Chen Zhao, Yuan Guo, Boya Li, Jiaofen Nan, Yanting Li, Chuang Han, Fubao Zhu, Weihua Zhou, Li Tian<br>for: The paper aims to develop and validate a deep learning-based diagnostic model for the preoperative differentiation of renal cell carcinoma (RCC) subtypes based on CT images.methods: The model incorporates uncertainty estimation and is developed using five-fold cross-validation with an external validation set.results: The model demonstrates robust performance in predicting RCC subtypes, with an area under the receiver operating characteristic curve (AUC) of 0.868, 0.846, and 0.839 for clear cell RCC, papillary RCC, and chromophobe RCC, respectively. The incorporated uncertainty emphasizes the importance of understanding model confidence, which is crucial for assisting clinical decision-making for patients with renal tumors.Here’s the format you requested:for: 助けることは、肾芽癌の疾患分类のためのディープラーニングベースの诊断モデルの开発および适合性の検证です。methods: モデルは不确実性评価を含む五つのクロスバレーションを使用して开発され、外部适合セットを使用して评価されました。results: モデルは肾芽癌の疾患分类に対して强固な性能を示しました。 five-fold クロスバレーションでのAUC（受动的特徴特徴曲线）は、clear cell RCC（ccRCC）、papillary RCC（pRCC）、およびchromophobe RCC（chRCC）の疾患分类に対して0.868（95% CI：0.826-0.923）、0.846（95% CI：0.812-0.886）、および0.839（95% CI：0.802-0.88）を示しました。外部适合セットでは、AUCは0.856（95% CI：0.838-0.882）、0.787（95% CI：0.757-0.818）、および0.793（95% CI：0.758-0.831）を示しました。<details>
<summary>Abstract</summary>
Objectives To develop and validate a deep learning-based diagnostic model incorporating uncertainty estimation so as to facilitate radiologists in the preoperative differentiation of the pathological subtypes of renal cell carcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients, pathologically proven RCC, were retrospectively collected from Center 1. By using five-fold cross-validation, a deep learning model incorporating uncertainty estimation was developed to classify RCC subtypes into clear cell RCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An external validation set of 78 patients from Center 2 further evaluated the model's performance. Results In the five-fold cross-validation, the model's area under the receiver operating characteristic curve (AUC) for the classification of ccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI: 0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the external validation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI: 0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC, respectively. Conclusions The developed deep learning model demonstrated robust performance in predicting the pathological subtypes of RCC, while the incorporated uncertainty emphasized the importance of understanding model confidence, which is crucial for assisting clinical decision-making for patients with renal tumors. Clinical relevance statement Our deep learning approach, integrated with uncertainty estimation, offers clinicians a dual advantage: accurate RCC subtype predictions complemented by diagnostic confidence references, promoting informed decision-making for patients with RCC.
</details>
<details>
<summary>摘要</summary>
Methods:* Retrospectively collected data from 668 consecutive patients with pathologically proven RCC from Center 1.* Developed a deep learning model with five-fold cross-validation to classify RCC subtypes into clear cell RCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC).* Evaluated the model's performance using an external validation set of 78 patients from Center 2.Results:* In the five-fold cross-validation, the model's area under the receiver operating characteristic curve (AUC) for the classification of ccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI: 0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively.* In the external validation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI: 0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC, respectively.Conclusions:* The developed deep learning model demonstrated robust performance in predicting the pathological subtypes of RCC.* The incorporated uncertainty emphasized the importance of understanding model confidence, which is crucial for assisting clinical decision-making for patients with renal tumors.Clinical relevance statement:* Our deep learning approach, integrated with uncertainty estimation, offers clinicians a dual advantage: accurate RCC subtype predictions complemented by diagnostic confidence references, promoting informed decision-making for patients with RCC.
</details></li>
</ul>
<hr>
<h2 id="CROMA-Remote-Sensing-Representations-with-Contrastive-Radar-Optical-Masked-Autoencoders"><a href="#CROMA-Remote-Sensing-Representations-with-Contrastive-Radar-Optical-Masked-Autoencoders" class="headerlink" title="CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders"></a>CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00566">http://arxiv.org/abs/2311.00566</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antofuller/croma">https://github.com/antofuller/croma</a></li>
<li>paper_authors: Anthony Fuller, Koreen Millard, James R. Green</li>
<li>for: 这种论文主要针对的应用是遥感技术，具体来说是用于学习rich的多modal表示。</li>
<li>methods: 该方法 combinestwo个自我超vised学习目标：对比学习和重构学习，通过将多spectral和Synthetic Aperture Radar（SAR）样本遮盖后，使用cross-modal协同学习，并使用一个轻量级的解码器来预测遮盖的质量。</li>
<li>results: 这种方法可以在具有相同空间和时间协调的多modal数据上取得优秀的表示，并且可以在不同的探测任务上进行扩展。在四个分类标准benchmark上，CROMA比现有的多spectral模型更高效，并且在三个分割标准benchmark上也取得了优秀的成绩。<details>
<summary>Abstract</summary>
A vital and rapidly growing application, remote sensing offers vast yet sparsely labeled, spatially aligned multimodal data; this makes self-supervised learning algorithms invaluable. We present CROMA: a framework that combines contrastive and reconstruction self-supervised objectives to learn rich unimodal and multimodal representations. Our method separately encodes masked-out multispectral optical and synthetic aperture radar samples -- aligned in space and time -- and performs cross-modal contrastive learning. Another encoder fuses these sensors, producing joint multimodal encodings that are used to predict the masked patches via a lightweight decoder. We show that these objectives are complementary when leveraged on spatially aligned multimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our cross- and self-attention matrices. These strategies improve representations and allow our models to effectively extrapolate to images up to 17.6x larger at test-time. CROMA outperforms the current SoTA multispectral model, evaluated on: four classification benchmarks -- finetuning (avg. 1.8%), linear (avg. 2.4%) and nonlinear (avg. 1.4%) probing, kNN classification (avg. 3.5%), and K-means clustering (avg. 8.4%); and three segmentation benchmarks (avg. 6.4%). CROMA's rich, optionally multimodal representations can be widely leveraged across remote sensing applications.
</details>
<details>
<summary>摘要</summary>
“远程感知应用在速速发展中，提供了庞大但缺乏标注的多模态数据，这使得无监督学习算法成为了非常重要的。我们提出了 CROMA 框架，它将对比学习和重建自我监督目标进行混合，以学习丰富的单模态和多模态表示。我们在空间和时间启用了多普通频谱光学和 Synthetic Aperture Radar 样本，并在多模态数据上进行交叉模式对比学习。另一个编码器将这些感知器联合起来，生成共同的多模态编码，并用轻量级解码器预测屏蔽的覆盖物。我们发现这些目标是相互补做的，当在空间启用的多模态数据上运行时，它们具有更高的效果。我们还引入了 X-和2D-ALiBi，它们在交叉和自我注意力矩阵上进行空间偏置，从而改善表示并使我们的模型能够有效地推测大小至多17.6倍的图像。CROMA 在四个分类标准 benchmarck 上表现出色，比如：四个分类 benchmarck 的 finetuning 平均值为1.8%，Linear 和非线性 probing 平均值为2.4%和1.4%，kNN 分类平均值为3.5%，K-means 分群平均值为8.4%。此外，CROMA 还在三个分 segmentation 标准 benchmarck 上表现出色，平均值为6.4%。CROMA 的丰富、可选多模态表示可以广泛应用于远程感知领域。”
</details></li>
</ul>
<hr>
<h2 id="MNN-Mixed-Nearest-Neighbors-for-Self-Supervised-Learning"><a href="#MNN-Mixed-Nearest-Neighbors-for-Self-Supervised-Learning" class="headerlink" title="MNN: Mixed Nearest-Neighbors for Self-Supervised Learning"></a>MNN: Mixed Nearest-Neighbors for Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00562">http://arxiv.org/abs/2311.00562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pc-cp/mnn">https://github.com/pc-cp/mnn</a></li>
<li>paper_authors: Chen Peng, Xianzhong Long, Yun Li</li>
<li>for: 这个论文是为了解决自动матиче自监学习中的对比样本受限问题，通过包含样本之间的关系来提高模型的泛化能力。</li>
<li>methods: 这个论文提出了一种简单的自动матиче自监学习框架called Mixed Nearest-Neighbors for Self-Supervised Learning (MNN)，通过INTUITIVE weighting Approach和图像混合操作来调整邻近样本对正样本的影响。</li>
<li>results: 研究发现，MNN在四个标准数据集上展现出了优秀的泛化性和训练效率。<details>
<summary>Abstract</summary>
In contrastive self-supervised learning, positive samples are typically drawn from the same image but in different augmented views, resulting in a relatively limited source of positive samples. An effective way to alleviate this problem is to incorporate the relationship between samples, which involves including the top-k nearest neighbors of positive samples in the framework. However, the problem of false neighbors (i.e., neighbors that do not belong to the same category as the positive sample) is an objective but often overlooked challenge due to the query of neighbor samples without human supervision. In this paper, we present a simple Self-supervised learning framework called Mixed Nearest-Neighbors for Self-Supervised Learning (MNN). MNN optimizes the influence of neighbor samples on the semantics of positive samples through an intuitive weighting approach and image mixture operations. The results of our study demonstrate that MNN exhibits exceptional generalization performance and training efficiency on four benchmark datasets.
</details>
<details>
<summary>摘要</summary>
对照自动学习中，正面样本通常是从同一幅图像中不同的扩展视图中提取的，这导致正面样本的数量相对受限。为解决这个问题，可以利用样本之间的关系，例如包括正面样本的top-k最近邻居在内。但是，遇到假邻居（即不属于正面样本类别的邻居）是一个 объекive  yet  oft-overlooked  challenge，因为 Querying neighbor samples without human supervision。在这篇论文中，我们提出了一种简单的自动学习框架called Mixed Nearest-Neighbors for Self-Supervised Learning (MNN)。MNN通过对正面样本的 semantics 进行权重调整和图像混合操作来优化邻居样本对正面样本的影响。我们的研究结果表明，MNN在四个 benchmark 数据集上表现出色的泛化性和训练效率。
</details></li>
</ul>
<hr>
<h2 id="ProBio-A-Protocol-guided-Multimodal-Dataset-for-Molecular-Biology-Lab"><a href="#ProBio-A-Protocol-guided-Multimodal-Dataset-for-Molecular-Biology-Lab" class="headerlink" title="ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab"></a>ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00556">http://arxiv.org/abs/2311.00556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jieming Cui, Ziren Gong, Baoxiong Jia, Siyuan Huang, Zilong Zheng, Jianzhu Ma, Yixin Zhu</li>
<li>for: 这 paper 的目的是解决分子生物领域中复现研究结果的问题，通过利用现代智能系统来进行研究。</li>
<li>methods: 这 paper 使用了一系列的现代智能系统技术，包括 Multimodal 数据集 ProBio，以及 two 个困难的标准曲线跟踪和多modal 动作识别 benchmark。</li>
<li>results: 这 paper 通过对当代视频理解模型的实验评估，发现了这些模型在 BioLab 设置下的限制和挑战，并提出了未来研究的可能性。<details>
<summary>Abstract</summary>
The challenge of replicating research results has posed a significant impediment to the field of molecular biology. The advent of modern intelligent systems has led to notable progress in various domains. Consequently, we embarked on an investigation of intelligent monitoring systems as a means of tackling the issue of the reproducibility crisis. Specifically, we first curate a comprehensive multimodal dataset, named ProBio, as an initial step towards this objective. This dataset comprises fine-grained hierarchical annotations intended for the purpose of studying activity understanding in BioLab. Next, we devise two challenging benchmarks, transparent solution tracking and multimodal action recognition, to emphasize the unique characteristics and difficulties associated with activity understanding in BioLab settings. Finally, we provide a thorough experimental evaluation of contemporary video understanding models and highlight their limitations in this specialized domain to identify potential avenues for future research. We hope ProBio with associated benchmarks may garner increased focus on modern AI techniques in the realm of molecular biology.
</details>
<details>
<summary>摘要</summary>
研究复制结果的挑战对分子生物学领域带来了重要的阻碍。现代智能系统的出现导致了各个领域的 notable progress。因此，我们开始了一项研究，用智能监测系统来解决复制危机。我们首先筹建了一个完整的多modal数据集，名为ProBio，作为这一目标的第一步。这个数据集包括细化的 hierarchical 注释，用于 BioLab 中的活动理解研究。然后，我们设计了两个具有挑战性的标准，透明解决方案跟踪和多modal 动作识别，以强调 BioLab 中活动理解的特殊特点和挑战。最后，我们进行了 Contemporary video 理解模型的系统性评估，并指出了这些模型在这个特殊领域的局限性，以便未来研究的可能性。我们希望 ProBio 和相关的标准可以吸引更多的现代 AI 技术在分子生物学领域中受到关注。
</details></li>
</ul>
<hr>
<h2 id="Continual-atlas-based-segmentation-of-prostate-MRI"><a href="#Continual-atlas-based-segmentation-of-prostate-MRI" class="headerlink" title="Continual atlas-based segmentation of prostate MRI"></a>Continual atlas-based segmentation of prostate MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00548">http://arxiv.org/abs/2311.00548</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meclabtuda/atlas-replay">https://github.com/meclabtuda/atlas-replay</a></li>
<li>paper_authors: Amin Ranem, Camila Gonázlez, Daniel Pinto dos Santos, Andreas Michael Bucher, Ahmed Ezzat Othman, Anirban Mukhopadhyay</li>
<li>for: 这个研究旨在提高 kontinual learning (CL) 方法的适用范围，使其能够应用于医疗影像分类中，特别是针对肾脏分类。</li>
<li>methods: 这个研究使用的方法是 Atlas-based segmentation，这是一种基于预设的医疗影像分类方法，它利用预设的医疗影像知识，实现了semantically coherent的预测。</li>
<li>results: 研究发现，Atlas Replay 可以在不同的训练分布中保持知识，并且具有优秀的适应能力和稳定性。它比于竞合方法更具有robustness和可靠性，并且能够在未见过的领域中获得高质量的预测结果。<details>
<summary>Abstract</summary>
Continual learning (CL) methods designed for natural image classification often fail to reach basic quality standards for medical image segmentation. Atlas-based segmentation, a well-established approach in medical imaging, incorporates domain knowledge on the region of interest, leading to semantically coherent predictions. This is especially promising for CL, as it allows us to leverage structural information and strike an optimal balance between model rigidity and plasticity over time. When combined with privacy-preserving prototypes, this process offers the advantages of rehearsal-based CL without compromising patient privacy. We propose Atlas Replay, an atlas-based segmentation approach that uses prototypes to generate high-quality segmentation masks through image registration that maintain consistency even as the training distribution changes. We explore how our proposed method performs compared to state-of-the-art CL methods in terms of knowledge transferability across seven publicly available prostate segmentation datasets. Prostate segmentation plays a vital role in diagnosing prostate cancer, however, it poses challenges due to substantial anatomical variations, benign structural differences in older age groups, and fluctuating acquisition parameters. Our results show that Atlas Replay is both robust and generalizes well to yet-unseen domains while being able to maintain knowledge, unlike end-to-end segmentation methods. Our code base is available under https://github.com/MECLabTUDA/Atlas-Replay.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Cardiovascular-Disease-Prediction-Through-Comparative-Analysis-of-Machine-Learning-Models-A-Case-Study-on-Myocardial-Infarction"><a href="#Improving-Cardiovascular-Disease-Prediction-Through-Comparative-Analysis-of-Machine-Learning-Models-A-Case-Study-on-Myocardial-Infarction" class="headerlink" title="Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction"></a>Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00517">http://arxiv.org/abs/2311.00517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonayet Miah, Duc M Ca, Md Abu Sayed, Ehsanur Rashid Lipu, Fuad Mahmud, S M Yasir Arafat</li>
<li>for: 预测心肺疾病的准确性</li>
<li>methods: 比较六种机器学习模型的表现：梯度下降、支持向量机、决策树、袋包、XGBoost和LightGBM</li>
<li>results: 结果显示XGBoost模型的表现最佳（准确率为92.72%），其他模型的准确率分别为Logistic Regression（81.00%）、Support Vector Machine（75.01%）、Decision Tree（82.30%）、Bagging（83.01%）。<details>
<summary>Abstract</summary>
Cardiovascular disease remains a leading cause of mortality in the contemporary world. Its association with smoking, elevated blood pressure, and cholesterol levels underscores the significance of these risk factors. This study addresses the challenge of predicting myocardial illness, a formidable task in medical research. Accurate predictions are pivotal for refining healthcare strategies. This investigation conducts a comparative analysis of six distinct machine learning models: Logistic Regression, Support Vector Machine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes exhibit promise, with accuracy rates as follows: Logistic Regression (81.00%), Support Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision Tree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the top-performing model. These findings underscore its potential to enhance predictive precision for coronary infarction. As the prevalence of cardiovascular risk factors persists, incorporating advanced machine learning techniques holds the potential to refine proactive medical interventions.
</details>
<details>
<summary>摘要</summary>
心血管疾病仍然是当代世界中最主要的死亡原因。它与吸烟、高血压和凝血水平的关系，强调了这些风险因素的重要性。这项研究面临着预测心肌疾病的挑战，这是医学研究中的一项复杂任务。准确的预测是健康策略的重要组成部分。这个研究使用六种不同的机器学习模型进行比较分析：Logistic Regression、Support Vector Machine、决策树、Bagging、XGBoost和LightGBM。实际结果展示了承诺，准确率如下：Logistic Regression（81.00%）、Support Vector Machine（75.01%）、XGBoost（92.72%）、LightGBM（90.60%）、决策树（82.30%）和Bagging（83.01%）。特别是，XGBoost emerges as the top-performing model。这些结果强调了它的潜在性能，用于提高心肌梗死预测的精度。随着心血管风险因素的流行，投入进更高级别的机器学习技术可能会提高护理措施的灵活性。
</details></li>
</ul>
<hr>
<h2 id="Deep-Neural-Networks-for-Automatic-Speaker-Recognition-Do-Not-Learn-Supra-Segmental-Temporal-Features"><a href="#Deep-Neural-Networks-for-Automatic-Speaker-Recognition-Do-Not-Learn-Supra-Segmental-Temporal-Features" class="headerlink" title="Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features"></a>Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00489">http://arxiv.org/abs/2311.00489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Neururer, Volker Dellow, Thilo Stadelmann</li>
<li>for: 这篇论文旨在探讨深度神经网络在自动人员识别任务中的成功原因，以及这些成功的关键因素是什么。</li>
<li>methods: 本文使用了一种新的测试方法来衡量现代神经网络是否能够很好地模型语音的 supra-segmental 时间信息（SST），并提出了一些使神经网络更加关注 SST 的方法来评估其效果。</li>
<li>results: 结果表明，现有的 CNN 和 RNN 神经网络架构在模型 SST 方面并没有充分的表现，即使使用强制方法也不如。这些结果提供了深入的研究基础，有助于更好地利用语音信号和提高深度学习对语音技术的解释性。<details>
<summary>Abstract</summary>
While deep neural networks have shown impressive results in automatic speaker recognition and related tasks, it is dissatisfactory how little is understood about what exactly is responsible for these results. Part of the success has been attributed in prior work to their capability to model supra-segmental temporal information (SST), i.e., learn rhythmic-prosodic characteristics of speech in addition to spectral features. In this paper, we (i) present and apply a novel test to quantify to what extent the performance of state-of-the-art neural networks for speaker recognition can be explained by modeling SST; and (ii) present several means to force respective nets to focus more on SST and evaluate their merits. We find that a variety of CNN- and RNN-based neural network architectures for speaker recognition do not model SST to any sufficient degree, even when forced. The results provide a highly relevant basis for impactful future research into better exploitation of the full speech signal and give insights into the inner workings of such networks, enhancing explainability of deep learning for speech technologies.
</details>
<details>
<summary>摘要</summary>
In this paper, we:1. Present a new test to measure the extent to which state-of-the-art neural networks for speaker recognition rely on modeling SST.2. Propose several methods to force these networks to focus more on SST and evaluate their effectiveness.Our findings show that a variety of convolutional neural network (CNN) and recurrent neural network (RNN) architectures for speaker recognition do not rely heavily on SST, even when forced to do so. These results provide a valuable foundation for future research into fully exploiting the speech signal and offer insights into the inner workings of these networks, enhancing the explainability of deep learning for speech technologies.
</details></li>
</ul>
<hr>
<h2 id="DEFN-Dual-Encoder-Fourier-Group-Harmonics-Network-for-Three-Dimensional-Macular-Hole-Reconstruction-with-Stochastic-Retinal-Defect-Augmentation-and-Dynamic-Weight-Composition"><a href="#DEFN-Dual-Encoder-Fourier-Group-Harmonics-Network-for-Three-Dimensional-Macular-Hole-Reconstruction-with-Stochastic-Retinal-Defect-Augmentation-and-Dynamic-Weight-Composition" class="headerlink" title="DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and Dynamic Weight Composition"></a>DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and Dynamic Weight Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00483">http://arxiv.org/abs/2311.00483</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iipl-hangzhoudianziuniversity/defn-pytorch">https://github.com/iipl-hangzhoudianziuniversity/defn-pytorch</a></li>
<li>paper_authors: Xingru Huang, Yihao Guo, Jian Huang, Zhi Li, Tianyun Zhang, Kunyan Cai, Gaopeng Huang, Wenhao Chen, Zhaoyang Xu, Liangqiong Qu, Ji Hu, Tinyu Wang, Shaowei Jiang, Chenggang Yan, Yaoqi Sun, Xin Ye, Yaqi Wang<br>for:* 这种研究旨在提供高精度的三维Retinal OCT图像分割和实时三维重建，以便诊断和治疗macular hole疾病。methods:* 该研究使用了一个新型的三维分割网络：双解码FuGH网络（DEFN），以及一种新的数据增强方法：随机retinal defect注射（SRDI）和一种网络优化策略：动态weightCompose（DWC）。results:* 相比13个基准，DEFN显示了最好的性能。此外，该研究还提供了高精度的三维 retinal 重建和量化指标，这将为眼科医生提供革命性的诊断和治疗决策工具，并预计将完全改变difficult-to-treat macular degeneration的诊断和治疗模式。<details>
<summary>Abstract</summary>
The spatial and quantitative parameters of macular holes are vital for diagnosis, surgical choices, and post-op monitoring. Macular hole diagnosis and treatment rely heavily on spatial and quantitative data, yet the scarcity of such data has impeded the progress of deep learning techniques for effective segmentation and real-time 3D reconstruction. To address this challenge, we assembled the world's largest macular hole dataset, Retinal OCTfor Macular Hole Enhancement (ROME-3914), and a Comprehensive Archive for Retinal Segmentation (CARS-30k), both expertly annotated. In addition, we developed an innovative 3D segmentation network, the Dual-Encoder FuGH Network (DEFN), which integrates three innovative modules: Fourier Group Harmonics (FuGH), Simplified 3D Spatial Attention (S3DSA) and Harmonic Squeeze-and-Excitation Module (HSE). These three modules synergistically filter noise, reduce computational complexity, emphasize detailed features, and enhance the network's representation ability. We also proposed a novel data augmentation method, Stochastic Retinal Defect Injection (SRDI), and a network optimization strategy DynamicWeightCompose (DWC), to further improve the performance of DEFN. Compared with 13 baselines, our DEFN shows the best performance. We also offer precise 3D retinal reconstruction and quantitative metrics, bringing revolutionary diagnostic and therapeutic decision-making tools for ophthalmologists, and is expected to completely reshape the diagnosis and treatment patterns of difficult-to-treat macular degeneration. The source code is publicly available at: https://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch.
</details>
<details>
<summary>摘要</summary>
“macular hole的空间和量值参数是诊断、手术选择和后期监测的关键因素。但由于缺乏这些数据，使得深度学习技术的有效分割和实时3D重建受到了阻碍。为解决这个挑战，我们组织了全球最大的macular hole数据集，Retinal OCTfor Macular Hole Enhancement (ROME-3914)，以及Comprehensive Archive for Retinal Segmentation (CARS-30k)，均为专家标注。此外，我们开发了一种创新的3D分割网络， dual-encoder FuGH网络 (DEFN)，该网络包括三个创新模块：Fourier Group Harmonics (FuGH)、Simplified 3D Spatial Attention (S3DSA)和Harmonic Squeeze-and-Excitation Module (HSE)。这三个模块相互协同筛除噪声、减少计算复杂性、强调细节特征和提高网络表达能力。我们还提出了一种新的数据增强方法，Stochastic Retinal Defect Injection (SRDI)，以及一种网络优化策略，DynamicWeightCompose (DWC)，以进一步提高DEFN的性能。与13个基线相比，OUR DEFN表现最佳。此外，我们还提供了高精度的3D retinal重建和量值度量，为视科医生提供革命性的诊断和治疗决策工具，并预计将完全重新定义脊梁疾病的诊断和治疗方式。数据集和代码可以在 GitHub上获取：https://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch。”
</details></li>
</ul>
<hr>
<h2 id="Group-Distributionally-Robust-Knowledge-Distillation"><a href="#Group-Distributionally-Robust-Knowledge-Distillation" class="headerlink" title="Group Distributionally Robust Knowledge Distillation"></a>Group Distributionally Robust Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00476">http://arxiv.org/abs/2311.00476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konstantinos Vilouras, Xiao Liu, Pedro Sanchez, Alison Q. O’Neil, Sotirios A. Tsaftaris</li>
<li>for: 提高模型在医学影像分析中的性能，特别是对少数群体的表现。</li>
<li>methods: 基于分布robust优化(DRO)技术，提出一种分组知识填充损失函数，使模型在优化过程中能够动态地关注表现不佳的群体。</li>
<li>results: 在两个标准数据集（自然图像和心脏MR）上进行了实验，并证明了在最差群体准确率上具有稳定的改进。<details>
<summary>Abstract</summary>
Knowledge distillation enables fast and effective transfer of features learned from a bigger model to a smaller one. However, distillation objectives are susceptible to sub-population shifts, a common scenario in medical imaging analysis which refers to groups/domains of data that are underrepresented in the training set. For instance, training models on health data acquired from multiple scanners or hospitals can yield subpar performance for minority groups. In this paper, inspired by distributionally robust optimization (DRO) techniques, we address this shortcoming by proposing a group-aware distillation loss. During optimization, a set of weights is updated based on the per-group losses at a given iteration. This way, our method can dynamically focus on groups that have low performance during training. We empirically validate our method, GroupDistil on two benchmark datasets (natural images and cardiac MRIs) and show consistent improvement in terms of worst-group accuracy.
</details>
<details>
<summary>摘要</summary>
知识储备可以快速和有效地传递学习于大型模型中学习的特征到小型模型中。然而，浸泡目标容易受到少数群体风险的情况，即训练数据集中的少数组团或组织。例如，通过多种扫描仪或医院收集的健康数据训练模型可能会导致少数组团的性能下降。本文，采用分布robust优化（DRO）技术为 inspirations，我们提出了一种组aware的浸泡损失函数。在优化过程中，一组权重会根据每个组的损失值进行更新。这样，我们的方法可以在训练过程中动态地关注性能较低的组。我们在两个 referenze dataset（自然图像和心血扫描）上进行了empirical验证，并证明了我们的方法可以在最差组织精度方面提供了一致性的改进。
</details></li>
</ul>
<hr>
<h2 id="Single-view-3D-Scene-Reconstruction-with-High-fidelity-Shape-and-Texture"><a href="#Single-view-3D-Scene-Reconstruction-with-High-fidelity-Shape-and-Texture" class="headerlink" title="Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture"></a>Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00457">http://arxiv.org/abs/2311.00457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DaLi-Jack/SSR-code">https://github.com/DaLi-Jack/SSR-code</a></li>
<li>paper_authors: Yixin Chen, Junfeng Ni, Nan Jiang, Yaowei Zhang, Yixin Zhu, Siyuan Huang</li>
<li>for: 高精度的单视图图像场景重建</li>
<li>methods: 提议使用单视图图像中的形状和Texture场景重建</li>
<li>results: 比前方法提高27.7%和11.6%的高精度文本化3D场景重建和可视化图像生成<details>
<summary>Abstract</summary>
Reconstructing detailed 3D scenes from single-view images remains a challenging task due to limitations in existing approaches, which primarily focus on geometric shape recovery, overlooking object appearances and fine shape details. To address these challenges, we propose a novel framework for simultaneous high-fidelity recovery of object shapes and textures from single-view images. Our approach utilizes the proposed Single-view neural implicit Shape and Radiance field (SSR) representations to leverage both explicit 3D shape supervision and volume rendering of color, depth, and surface normal images. To overcome shape-appearance ambiguity under partial observations, we introduce a two-stage learning curriculum incorporating both 3D and 2D supervisions. A distinctive feature of our framework is its ability to generate fine-grained textured meshes while seamlessly integrating rendering capabilities into the single-view 3D reconstruction model. This integration enables not only improved textured 3D object reconstruction by 27.7% and 11.6% on the 3D-FRONT and Pix3D datasets, respectively, but also supports the rendering of images from novel viewpoints. Beyond individual objects, our approach facilitates composing object-level representations into flexible scene representations, thereby enabling applications such as holistic scene understanding and 3D scene editing. We conduct extensive experiments to demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传送给定文本到简化中文。<</SYS>>现有方法存在重大限制，它们主要关注几何形状恢复，忽略物体外观和细节形状。为解决这些挑战，我们提出一种新的框架，同时实现高精度物体形状和Texture的恢复从单视图图像中。我们的方法利用我们提出的单视图神经隐式形状场（SSR）表示，同时利用Explicit 3D形状supervision和VolumeRendering的颜色、深度和表面法向图像。为了解决形状-外观不确定性，我们提出了一个两stage学习课程，包括3D和2Dsupervision。我们的框架可以生成细节rich的Texture矩阵，同时将Rendering集成到单视图3D重建模型中。这种集成不仅提高了Texture矩阵的3D物体重建精度（3D-FRONT和Pix3D数据集上提高了27.7%和11.6%），而且还支持从新视点渲染图像。此外，我们的方法可以将对象级别的表示集成到 flexible scene表示中，使得应用场景包括整体场景理解和3D场景编辑。我们进行了广泛的实验，以证明我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Progressive-Recurrent-Network-for-Shadow-Removal"><a href="#Progressive-Recurrent-Network-for-Shadow-Removal" class="headerlink" title="Progressive Recurrent Network for Shadow Removal"></a>Progressive Recurrent Network for Shadow Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00455">http://arxiv.org/abs/2311.00455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghui Wang, Wengang Zhou, Hao Feng, Li Li, Houqiang Li</li>
<li>for: 本研究旨在提出一种简单 yet effective的 Progressive Recurrent Network (PRNet)，用于逐渐除去单张图像中的阴影。</li>
<li>methods: 我们提出了一种分层执行的推进方法，包括阴影特征提取和进行逐渐阴影除去。特别地，我们使用了一个新的重新集成模块和更新模块，以便更好地利用上一次迭代的输出，从而提高阴影除去的性能。</li>
<li>results: 我们在ISTD、ISTD+和SRD三个benchmark上进行了广泛的实验，结果表明，我们的方法可以有效地除去阴影，并且性能较为出色。<details>
<summary>Abstract</summary>
Single-image shadow removal is a significant task that is still unresolved. Most existing deep learning-based approaches attempt to remove the shadow directly, which can not deal with the shadow well. To handle this issue, we consider removing the shadow in a coarse-to-fine fashion and propose a simple but effective Progressive Recurrent Network (PRNet). The network aims to remove the shadow progressively, enabing us to flexibly adjust the number of iterations to strike a balance between performance and time. Our network comprises two parts: shadow feature extraction and progressive shadow removal. Specifically, the first part is a shallow ResNet which constructs the representations of the input shadow image on its original size, preventing the loss of high-frequency details caused by the downsampling operation. The second part has two critical components: the re-integration module and the update module. The proposed re-integration module can fully use the outputs of the previous iteration, providing input for the update module for further shadow removal. In this way, the proposed PRNet makes the whole process more concise and only uses 29% network parameters than the best published method. Extensive experiments on the three benchmarks, ISTD, ISTD+, and SRD, demonstrate that our method can effectively remove shadows and achieve superior performance.
</details>
<details>
<summary>摘要</summary>
单一图像阴影除除是一个 ainda 未解决的重要任务。大多数现有的深度学习基于的方法都尝试直接 removing 阴影，可以不好地处理阴影。为了解决这个问题，我们考虑使用一个进行逐步除阴影的方法，并提出一个简单 yet 有效的进步Recurrent Network (PRNet)。这个网络的目的是逐步 removing 阴影，让我们可以调整访问次数，寻求在性能和时间之间做出平衡。我们的网络包括两个部分：阴影特征提取和进行逐步阴影除除。具体来说，第一个部分是一个浅层ResNet，它在输入阴影图像的原始大小上建立了阴影的表现，避免因下推过程而失去高频率细节的损失。第二个部分有两个重要的组件：重新组合模组和更新模组。我们提出的重新组合模组可以充分利用上一次迭代的输出，作为更新模组的输入，从而使得整个过程更为简洁，仅需29%的网络参数数量比最佳已公开方法少。广泛的实验表明，我们的方法可以有效地除阴影，并在性能方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="CLIP-AD-A-Language-Guided-Staged-Dual-Path-Model-for-Zero-shot-Anomaly-Detection"><a href="#CLIP-AD-A-Language-Guided-Staged-Dual-Path-Model-for-Zero-shot-Anomaly-Detection" class="headerlink" title="CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly Detection"></a>CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00453">http://arxiv.org/abs/2311.00453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuhai Chen, Jiangning Zhang, Guanzhong Tian, Haoyang He, Wuhao Zhang, Yabiao Wang, Chengjie Wang, Yunsheng Wu, Yong Liu</li>
<li>for: 本文研究零例异常检测（AD），一种有价值但未得到充分研究的任务，即在测试对象没有任何参考图像的情况下进行AD。</li>
<li>methods: 我们采用了语言引导策略，并提出了一种简单 yet effective 的架构 CLIP-AD，利用大型视觉语言模型 CLIP 的出色零例分类能力。</li>
<li>results: 我们的方法可以准确地检测异常，例如在 VisA 上，SDP 模型比 SOTA 高 +1.0&#x2F;+1.2 分在分类&#x2F;分割 F1 分数上。而 SDP+ 模型在 VisA 上还实现了 +1.9&#x2F;+11.7 的提升。<details>
<summary>Abstract</summary>
This paper considers zero-shot Anomaly Detection (AD), a valuable yet under-studied task, which performs AD without any reference images of the test objects. Specifically, we employ a language-guided strategy and propose a simple-yet-effective architecture CLIP-AD, leveraging the superior zero-shot classification capabilities of the large vision-language model CLIP. A natural idea for anomaly segmentation is to directly calculate the similarity between text/image features, but we observe opposite predictions and irrelevant highlights in the results. Inspired by the phenomena, we introduce a Staged Dual-Path model (SDP) that effectively uses features from various levels and applies architecture and feature surgery to address these issues. Furthermore, delving beyond surface phenomena, we identify the problem arising from misalignment of text/image features in the joint embedding space. Thus, we introduce a fine-tuning strategy by adding linear layers and construct an extended model SDP+, further enhancing the performance. Abundant experiments demonstrate the effectiveness of our approach, e.g., on VisA, SDP outperforms SOTA by +1.0/+1.2 in classification/segmentation F1 scores, while SDP+ achieves +1.9/+11.7 improvements.
</details>
<details>
<summary>摘要</summary>
However, we observe that directly calculating the similarity between text/image features can lead to inaccurate predictions and irrelevant highlights. To address this issue, we introduce a Staged Dual-Path (SDP) model that effectively uses features from various levels and applies architecture and feature surgery.Furthermore, we identify the problem of misaligned text/image features in the joint embedding space, which can cause the model to perform poorly. To address this issue, we propose a fine-tuning strategy that involves adding linear layers and constructing an extended model called SDP+. This approach significantly enhances the performance of the model, as demonstrated by abundant experiments.For example, on the VisA dataset, SDP outperforms state-of-the-art (SOTA) models by +1.0/+1.2 in classification/segmentation F1 scores, while SDP+ achieves +1.9/+11.7 improvements. Our approach offers a valuable solution for zero-shot AD, and the SDP+ model represents a new SOTA in this area.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Traffic-Object-Detection-in-Variable-Illumination-with-RGB-Event-Fusion"><a href="#Enhancing-Traffic-Object-Detection-in-Variable-Illumination-with-RGB-Event-Fusion" class="headerlink" title="Enhancing Traffic Object Detection in Variable Illumination with RGB-Event Fusion"></a>Enhancing Traffic Object Detection in Variable Illumination with RGB-Event Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00436">http://arxiv.org/abs/2311.00436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanwen Liu, Nan Yang, Yang Wang, Yuke Li, Xiangmo Zhao, Fei-Yue Wang<br>for: 这个论文的目的是提高对变化照明条件下的交通物体检测精度。methods: 该论文使用了生物体会论所启发的事件摄像头和一种新的结构意识协调网络（SFNet），通过跨Modalities协调来补做图像中失去的信息，以获得适应照明条件的对象结构表示。results: 该论文的实验结果显示，SFNet可以超越传统摄像头的感知boundary，并在MAP50和MAP50:95上比框架方法高出8.0%和5.9%。<details>
<summary>Abstract</summary>
Traffic object detection under variable illumination is challenging due to the information loss caused by the limited dynamic range of conventional frame-based cameras. To address this issue, we introduce bio-inspired event cameras and propose a novel Structure-aware Fusion Network (SFNet) that extracts sharp and complete object structures from the event stream to compensate for the lost information in images through cross-modality fusion, enabling the network to obtain illumination-robust representations for traffic object detection. Specifically, to mitigate the sparsity or blurriness issues arising from diverse motion states of traffic objects in fixed-interval event sampling methods, we propose the Reliable Structure Generation Network (RSGNet) to generate Speed Invariant Frames (SIF), ensuring the integrity and sharpness of object structures. Next, we design a novel Adaptive Feature Complement Module (AFCM) which guides the adaptive fusion of two modality features to compensate for the information loss in the images by perceiving the global lightness distribution of the images, thereby generating illumination-robust representations. Finally, considering the lack of large-scale and high-quality annotations in the existing event-based object detection datasets, we build a DSEC-Det dataset, which consists of 53 sequences with 63,931 images and more than 208,000 labels for 8 classes. Extensive experimental results demonstrate that our proposed SFNet can overcome the perceptual boundaries of conventional cameras and outperform the frame-based method by 8.0% in mAP50 and 5.9% in mAP50:95. Our code and dataset will be available at https://github.com/YN-Yang/SFNet.
</details>
<details>
<summary>摘要</summary>
受变化照明条件影响的交通物体检测是一个挑战，因为传统的帧基式摄像机的动态范围有限，会导致信息损失。为解决这问题，我们介绍了生物体iben inspired事件摄像机和一种新的结构意识混合网络（SFNet），该网络可以从事件流中提取完整和锐化的物体结构，并通过cross-modality混合来补偿图像中丢失的信息，使网络能够获得适应照明的表示。 Specifically，我们提出了可靠结构生成网络（RSGNet），以减少在固定间隔事件采样方法中的缺乏或模糊问题，并确保物体结构的完整性和锐度。然后，我们设计了一种适应特征补偿模块（AFCM），该模块可以根据图像的全局亮度分布进行适应混合，以补偿图像中的信息损失。最后，由于现有的事件基于物体检测数据集lacks large-scale和高质量的标注，我们建立了DSEC-Det数据集，该数据集包括53个序列，63,931个图像和208,000个标注，用于8类物体检测。我们的实验结果表明，我们提出的SFNet可以超越传统摄像机的感知边界，并在MAP50和MAP50:95中比 Frame-based方法提高8.0%和5.9%。我们的代码和数据集将在https://github.com/YN-Yang/SFNet上提供。
</details></li>
</ul>
<hr>
<h2 id="Event-based-Background-Oriented-Schlieren"><a href="#Event-based-Background-Oriented-Schlieren" class="headerlink" title="Event-based Background-Oriented Schlieren"></a>Event-based Background-Oriented Schlieren</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00434">http://arxiv.org/abs/2311.00434</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tub-rip/event_based_bos">https://github.com/tub-rip/event_based_bos</a></li>
<li>paper_authors: Shintaro Shiba, Friedhelm Hamann, Yoshimitsu Aoki, Guillermo Gallego</li>
<li>for: 这篇论文的目的是探讨使用事件摄像机进行液体流动的观察，以减少高速摄像机和计算成本的限制。</li>
<li>methods: 该论文提出了一种基于事件的液体流动观察技术，使用事件摄像机捕捉液体流动的变化，并提出了一种基于变形优化的方法来连接事件数据和液体流动。</li>
<li>results: 实验结果表明，该方法可以使用事件摄像机获得与传统帧基于摄像机相同的质量结果，并且在黑暗环境下工作和在慢动作情况下进行分析。此外，该方法还可以减少计算成本和增加数据效率。<details>
<summary>Abstract</summary>
Schlieren imaging is an optical technique to observe the flow of transparent media, such as air or water, without any particle seeding. However, conventional frame-based techniques require both high spatial and temporal resolution cameras, which impose bright illumination and expensive computation limitations. Event cameras offer potential advantages (high dynamic range, high temporal resolution, and data efficiency) to overcome such limitations due to their bio-inspired sensing principle. This paper presents a novel technique for perceiving air convection using events and frames by providing the first theoretical analysis that connects event data and schlieren. We formulate the problem as a variational optimization one combining the linearized event generation model with a physically-motivated parameterization that estimates the temporal derivative of the air density. The experiments with accurately aligned frame- and event camera data reveal that the proposed method enables event cameras to obtain on par results with existing frame-based optical flow techniques. Moreover, the proposed method works under dark conditions where frame-based schlieren fails, and also enables slow-motion analysis by leveraging the event camera's advantages. Our work pioneers and opens a new stack of event camera applications, as we publish the source code as well as the first schlieren dataset with high-quality frame and event data. https://github.com/tub-rip/event_based_bos
</details>
<details>
<summary>摘要</summary>
射频成像是一种光学技术，可以无需粒子种子观测透明媒体的流动，如空气或水。然而，传统的帧基技术需要高分辨率的摄像机和贵重的计算限制。事件相机具有优势（高动态范围、高时间分辨率和数据效率），可以超越这些限制。这篇论文提出了一种使用事件和帧来捕捉空气循环的新方法。我们将问题形式为一种变分优化问题，将线性化事件生成模型与物理激活的参数化相结合，以估计空气密度的时间导数。实验结果表明，我们的方法可以让事件相机与传统的帧基Optical flow技术具有相同的性能。此外，我们的方法在黑暗条件下工作，并且可以利用事件相机的优势进行慢动作分析。我们的工作开创了新的事件相机应用领域，并将源代码以及高质量帧和事件数据的第一个Schlieren数据集发布在GitHub上。https://github.com/tub-rip/event_based_bos
</details></li>
</ul>
<hr>
<h2 id="Feature-oriented-Deep-Learning-Framework-for-Pulmonary-Cone-beam-CT-CBCT-Enhancement-with-Multi-task-Customized-Perceptual-Loss"><a href="#Feature-oriented-Deep-Learning-Framework-for-Pulmonary-Cone-beam-CT-CBCT-Enhancement-with-Multi-task-Customized-Perceptual-Loss" class="headerlink" title="Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT (CBCT) Enhancement with Multi-task Customized Perceptual Loss"></a>Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT (CBCT) Enhancement with Multi-task Customized Perceptual Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00412">http://arxiv.org/abs/2311.00412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhujiarui42/cfp-loss">https://github.com/zhujiarui42/cfp-loss</a></li>
<li>paper_authors: Jiarui Zhu, Werxing Chen, Hongfei Sun, Shaohua Zhi, Jing Qin, Jing Cai, Ge Ren<br>for:The paper aims to improve the quality of cone-beam computed tomography (CBCT) images for cancer treatment planning by proposing a novel feature-oriented deep learning framework.methods:The proposed framework consists of two main components: a multi-task learning feature-selection network (MTFS-Net) and a CBCT-to-CT translation network guided by feature-to-feature perceptual loss. The framework uses advanced generative models such as U-Net, GAN, and CycleGAN to generate high-quality synthesized CT (sCT) images.results:The proposed framework outperforms the state-of-the-art models for pulmonary CBCT enhancement, with an average SSIM index of 0.9869 and an average PSNR index of 39.9621. The generated sCT images have visually pleasing performance, with effective artifacts suppression, noise reduction, and distinctive anatomical details preservation.<details>
<summary>Abstract</summary>
Cone-beam computed tomography (CBCT) is routinely collected during image-guided radiation therapy (IGRT) to provide updated patient anatomy information for cancer treatments. However, CBCT images often suffer from streaking artifacts and noise caused by under-rate sampling projections and low-dose exposure, resulting in low clarity and information loss. While recent deep learning-based CBCT enhancement methods have shown promising results in suppressing artifacts, they have limited performance on preserving anatomical details since conventional pixel-to-pixel loss functions are incapable of describing detailed anatomy. To address this issue, we propose a novel feature-oriented deep learning framework that translates low-quality CBCT images into high-quality CT-like imaging via a multi-task customized feature-to-feature perceptual loss function. The framework comprises two main components: a multi-task learning feature-selection network(MTFS-Net) for customizing the perceptual loss function; and a CBCT-to-CT translation network guided by feature-to-feature perceptual loss, which uses advanced generative models such as U-Net, GAN and CycleGAN. Our experiments showed that the proposed framework can generate synthesized CT (sCT) images for the lung that achieved a high similarity to CT images, with an average SSIM index of 0.9869 and an average PSNR index of 39.9621. The sCT images also achieved visually pleasing performance with effective artifacts suppression, noise reduction, and distinctive anatomical details preservation. Our experiment results indicate that the proposed framework outperforms the state-of-the-art models for pulmonary CBCT enhancement. This framework holds great promise for generating high-quality anatomical imaging from CBCT that is suitable for various clinical applications.
</details>
<details>
<summary>摘要</summary>
computed tomography cone-beam (CBCT) routinely collected during image-guided radiation therapy (IGRT) to provide updated patient anatomy information for cancer treatments. However, CBCT images often suffer from streaking artifacts and noise caused by under-rate sampling projections and low-dose exposure, resulting in low clarity and information loss. While recent deep learning-based CBCT enhancement methods have shown promising results in suppressing artifacts, they have limited performance on preserving anatomical details since conventional pixel-to-pixel loss functions are incapable of describing detailed anatomy. To address this issue, we propose a novel feature-oriented deep learning framework that translates low-quality CBCT images into high-quality CT-like imaging via a multi-task customized feature-to-feature perceptual loss function. The framework comprises two main components: a multi-task learning feature-selection network (MTFS-Net) for customizing the perceptual loss function; and a CBCT-to-CT translation network guided by feature-to-feature perceptual loss, which uses advanced generative models such as U-Net, GAN, and CycleGAN. Our experiments showed that the proposed framework can generate synthesized CT (sCT) images for the lung that achieved a high similarity to CT images, with an average SSIM index of 0.9869 and an average PSNR index of 39.9621. The sCT images also achieved visually pleasing performance with effective artifacts suppression, noise reduction, and distinctive anatomical details preservation. Our experiment results indicate that the proposed framework outperforms the state-of-the-art models for pulmonary CBCT enhancement. This framework holds great promise for generating high-quality anatomical imaging from CBCT that is suitable for various clinical applications.
</details></li>
</ul>
<hr>
<h2 id="Open-Set-Face-Recognition-with-Maximal-Entropy-and-Objectosphere-Loss"><a href="#Open-Set-Face-Recognition-with-Maximal-Entropy-and-Objectosphere-Loss" class="headerlink" title="Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss"></a>Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00400">http://arxiv.org/abs/2311.00400</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Henrique Vareto, Yu Linghu, Terrance E. Boult, William Robson Schwartz, Manuel Günther</li>
<li>for: 这个研究探讨了面部识别task中的开集领域，特别是在低False Positive Identification Rate下进行识别。</li>
<li>methods: 本研究使用了类别损失(OS)和提案的差异Entropy损失(MEL)，MEL对于负样本进行增加熵和知识目标类别添加罚则，以提高特征提取和类别特有化。</li>
<li>results: 研究获得了适用于三个不同数据集(LFW、IJB-C和UCCS)的开集领域面部识别优异的结果，并在对额外负样本进行微调时达到了顶尖性能。<details>
<summary>Abstract</summary>
Open-set face recognition characterizes a scenario where unknown individuals, unseen during the training and enrollment stages, appear on operation time. This work concentrates on watchlists, an open-set task that is expected to operate at a low False Positive Identification Rate and generally includes only a few enrollment samples per identity. We introduce a compact adapter network that benefits from additional negative face images when combined with distinct cost functions, such as Objectosphere Loss (OS) and the proposed Maximal Entropy Loss (MEL). MEL modifies the traditional Cross-Entropy loss in favor of increasing the entropy for negative samples and attaches a penalty to known target classes in pursuance of gallery specialization. The proposed approach adopts pre-trained deep neural networks (DNNs) for face recognition as feature extractors. Then, the adapter network takes deep feature representations and acts as a substitute for the output layer of the pre-trained DNN in exchange for an agile domain adaptation. Promising results have been achieved following open-set protocols for three different datasets: LFW, IJB-C, and UCCS as well as state-of-the-art performance when supplementary negative data is properly selected to fine-tune the adapter network.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Omni-supervised-Referring-Expression-Segmentation"><a href="#Towards-Omni-supervised-Referring-Expression-Segmentation" class="headerlink" title="Towards Omni-supervised Referring Expression Segmentation"></a>Towards Omni-supervised Referring Expression Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00397">http://arxiv.org/abs/2311.00397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minglang Huang, Yiyi Zhou, Gen Luo, Guannan Jiang, Weilin Zhuang, Xiaoshuai Sun</li>
<li>for: 提高 Referring Expression Segmentation (RES) 训练效率，使用无标注数据、半标注数据和弱标注数据进行高效的 RES 训练。</li>
<li>methods: 提出 Omni-supervised Referring Expression Segmentation (Omni-RES) 任务，利用无标注数据、半标注数据和弱标注数据进行 teacher-student 学习，选择和改进高质量 pseudo-masks，以提高 RES 性能。</li>
<li>results: 对 state-of-the-art RES 模型进行了广泛的实验，并证明了 Omni-RES 方法可以在各种 RES 数据集上具有明显的优势，比如使用仅 10% 完全标注数据可以 дости得 100% 完全超vised 性能，并且比 semi-supervised 方法具有大幅度的提升（+14.93% on RefCOCO 和 +14.95% on RefCOCO+）。 Omni-RES 还可以利用大规模的视力语言如 Visual Genome 来促进低成本 RES 训练，并实现新的 SOTA 性能（80.66 on RefCOCO）。<details>
<summary>Abstract</summary>
Referring Expression Segmentation (RES) is an emerging task in computer vision, which segments the target instances in images based on text descriptions. However, its development is plagued by the expensive segmentation labels. To address this issue, we propose a new learning task for RES called Omni-supervised Referring Expression Segmentation (Omni-RES), which aims to make full use of unlabeled, fully labeled and weakly labeled data, e.g., referring points or grounding boxes, for efficient RES training. To accomplish this task, we also propose a novel yet strong baseline method for Omni-RES based on the recently popular teacher-student learning, where where the weak labels are not directly transformed into supervision signals but used as a yardstick to select and refine high-quality pseudo-masks for teacher-student learning. To validate the proposed Omni-RES method, we apply it to a set of state-of-the-art RES models and conduct extensive experiments on a bunch of RES datasets. The experimental results yield the obvious merits of Omni-RES than the fully-supervised and semi-supervised training schemes. For instance, with only 10% fully labeled data, Omni-RES can help the base model achieve 100% fully supervised performance, and it also outperform the semi-supervised alternative by a large margin, e.g., +14.93% on RefCOCO and +14.95% on RefCOCO+, respectively. More importantly, Omni-RES also enable the use of large-scale vision-langauges like Visual Genome to facilitate low-cost RES training, and achieve new SOTA performance of RES, e.g., 80.66 on RefCOCO.
</details>
<details>
<summary>摘要</summary>
新的 Referring Expression Segmentation (RES) 任务在计算机视觉领域崛起，它根据图像中的文本描述进行目标实例分割。然而，其发展受到严重的分割标签成本的限制。为解决这个问题，我们提出了一个新的学习任务，即 Omni-supervised Referring Expression Segmentation (Omni-RES)，该任务旨在利用不 labels、完全 labels 和弱 labels，如引用点或基础框架，进行高效的 RES 训练。为完成这个任务，我们还提出了一种新的基线方法，基于最近受欢迎的教师学生学习，其中弱标签不直接转化为监督信号，而是用作选择和改进高质量的 pseudo-masks 的依据。为验证提出的 Omni-RES 方法，我们对一些 state-of-the-art RES 模型进行了广泛的实验，并在一些 RES 数据集上进行了extensive的测试。实验结果表明，Omni-RES 方法在资源受限的情况下具有明显的优势，比如只使用 10% 完全标签数据，Omni-RES 可以帮助基本模型达到100% 完全监督性能。此外，Omni-RES 还可以在很大规模的视觉语言，如视觉语言，进行低成本的 RES 训练，并实现新的 SOTA 性能，如 RefCOCO 上的 80.66%。
</details></li>
</ul>
<hr>
<h2 id="Fixation-based-Self-calibration-for-Eye-Tracking-in-VR-Headsets"><a href="#Fixation-based-Self-calibration-for-Eye-Tracking-in-VR-Headsets" class="headerlink" title="Fixation-based Self-calibration for Eye Tracking in VR Headsets"></a>Fixation-based Self-calibration for Eye Tracking in VR Headsets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00391">http://arxiv.org/abs/2311.00391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryusei Uramune, Sei Ikeda, Hiroki Ishizuka, Osamu Oshiro<br>for: This paper proposes a novel self-calibration method for eye tracking in virtual reality (VR) headsets.methods: The proposed method uses an extension of the I-VDT algorithm to detect fixations from time-series gaze data, and optimizes calibration parameters by minimizing a dispersion metric of points of regard.results: The proposed method achieved an accuracy of 2.1° in a study with 18 participants walking in two VR environments with many occlusions, which is significantly lower than the average offset. The method also has the potential to improve accuracy by up to 1.2° by refining the fixation detection or optimization algorithm.<details>
<summary>Abstract</summary>
This study proposes a novel self-calibration method for eye tracking in a virtual reality (VR) headset. The proposed method is based on the assumptions that the user's viewpoint can freely move and that the points of regard (PoRs) from different viewpoints are distributed within a small area on an object surface during visual fixation. In the method, fixations are first detected from the time-series data of uncalibrated gaze directions using an extension of the I-VDT (velocity and dispersion threshold identification) algorithm to a three-dimensional (3D) scene. Then, the calibration parameters are optimized by minimizing the sum of a dispersion metrics of the PoRs. The proposed method can potentially identify the optimal calibration parameters representing the user-dependent offset from the optical axis to the visual axis without explicit user calibration, image processing, or marker-substitute objects. For the gaze data of 18 participants walking in two VR environments with many occlusions, the proposed method achieved an accuracy of 2.1$^\circ$, which was significantly lower than the average offset. Our method is the first self-calibration method with an average error lower than 3$^\circ$ in 3D environments. Further, the accuracy of the proposed method can be improved by up to 1.2$^\circ$ by refining the fixation detection or optimization algorithm.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个研究提出了一种新的自动准确方法 для眼动跟踪在虚拟现实（VR）头盔中。该方法基于用户视点可以自由移动以及不同视点下的点注视（PoR）在物体表面上的分布的假设。在方法中，首先从未加工的眼动资料中检测出了时间序列中的fixation，使用了三维场景中的I-VDT（速度和分散度阈值识别）算法的扩展。然后，使用PoR的分布来优化准确参数。该方法可能可以无需用户准确参数、图像处理或marker substitute对象来确定用户依赖的偏移量从光学轴到视觉轴。为18名参与者在两个VR环境中走动的眼动数据，该方法实现了2.1°的精度，与平均偏移量相比较低。我们的方法是3D环境中第一个自动准确方法，其平均错误低于3°。此外，通过改进fixation检测或优化算法，该方法的精度可以提高到1.2°。
</details></li>
</ul>
<hr>
<h2 id="NeuralGF-Unsupervised-Point-Normal-Estimation-by-Learning-Neural-Gradient-Function"><a href="#NeuralGF-Unsupervised-Point-Normal-Estimation-by-Learning-Neural-Gradient-Function" class="headerlink" title="NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function"></a>NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00389">http://arxiv.org/abs/2311.00389</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leoqli/neuralgf">https://github.com/leoqli/neuralgf</a></li>
<li>paper_authors: Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, Yu-Shen Liu, Zhizhong Han</li>
<li>for: 这种paper的目的是提出一种深度学习方法来从点云数据中直接估计方向法向量，不需要使用地面真实的正常指导。</li>
<li>methods: 该方法基于引入新的神经网络梯度函数学习新方法，使神经网络能够更好地适应输入点云数据，并且在点云数据上逐渐建立一个全局表示。</li>
<li>results: 该方法可以在各种常用的点云数据集上取得更高的准确率，比之前的方法更加稳定和Robust。Here is the same information in English:</li>
<li>for: The purpose of this paper is to propose a deep learning method to directly estimate oriented normals from point cloud data without using ground truth normals as supervision.</li>
<li>methods: The method is based on introducing a new paradigm for learning neural gradient functions, which encourages the neural network to fit the input point clouds and yield unit-norm gradients at the points.</li>
<li>results: The method can achieve higher accuracy on various widely used point cloud datasets, and is more robust and stable than previous methods.<details>
<summary>Abstract</summary>
Normal estimation for 3D point clouds is a fundamental task in 3D geometry processing. The state-of-the-art methods rely on priors of fitting local surfaces learned from normal supervision. However, normal supervision in benchmarks comes from synthetic shapes and is usually not available from real scans, thereby limiting the learned priors of these methods. In addition, normal orientation consistency across shapes remains difficult to achieve without a separate post-processing procedure. To resolve these issues, we propose a novel method for estimating oriented normals directly from point clouds without using ground truth normals as supervision. We achieve this by introducing a new paradigm for learning neural gradient functions, which encourages the neural network to fit the input point clouds and yield unit-norm gradients at the points. Specifically, we introduce loss functions to facilitate query points to iteratively reach the moving targets and aggregate onto the approximated surface, thereby learning a global surface representation of the data. Meanwhile, we incorporate gradients into the surface approximation to measure the minimum signed deviation of queries, resulting in a consistent gradient field associated with the surface. These techniques lead to our deep unsupervised oriented normal estimator that is robust to noise, outliers and density variations. Our excellent results on widely used benchmarks demonstrate that our method can learn more accurate normals for both unoriented and oriented normal estimation tasks than the latest methods. The source code and pre-trained model are publicly available at https://github.com/LeoQLi/NeuralGF.
</details>
<details>
<summary>摘要</summary>
通常估算三维点云是三维几何处理的基本任务。现状的方法均依赖于当地表面的尝试学习，但是这些方法的学习环境通常来自于Synthetic shapes的标准测试数据，因此无法适用于实际扫描数据。另外，保持方向orientation的一致性 across shapes remain difficult to achieve without a separate post-processing procedure.为解决这些问题，我们提出了一种新的方法，可以直接从点云中估算方向 orientation，不需要使用真实的标准 норals作为监督。我们通过引入一种新的神经网络梯度函数学习方法，让神经网络能够适应输入点云，并且在点上得到单位范围的梯度。具体来说，我们引入了一种新的损失函数，使得查询点能够逐步到达移动目标，并将查询点积累到 aproximated surface上，从而学习全局表面 Representation of the data。同时，我们将梯度 integrate into surface approximation，以计算最小签名偏差的查询点，从而获得一个协调的梯度场，与表面相关的。这些技术导致我们的深度无监督方向 норals估算器，能够更高效地处理噪声、异常值和密度变化。我们的出色的结果在广泛使用的 benchmark 上表明，我们的方法可以学习更加准确的 normals，并且在无监督 oriented normal estimation 和 oriented normal estimation 两个任务中均有优异表现。我们的代码和预训练模型可以在 <https://github.com/LeoQLi/NeuralGF> 上公开获取。
</details></li>
</ul>
<hr>
<h2 id="Learning-Cooperative-Trajectory-Representations-for-Motion-Forecasting"><a href="#Learning-Cooperative-Trajectory-Representations-for-Motion-Forecasting" class="headerlink" title="Learning Cooperative Trajectory Representations for Motion Forecasting"></a>Learning Cooperative Trajectory Representations for Motion Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00371">http://arxiv.org/abs/2311.00371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/air-thu/dair-v2x-seq">https://github.com/air-thu/dair-v2x-seq</a></li>
<li>paper_authors: Hongzhi Ruan, Haibao Yu, Wenxian Yang, Siqi Fan, Yingjuan Tang, Zaiqing Nie</li>
<li>For: This paper focuses on motion forecasting for autonomous driving, specifically using cooperative information from infrastructure and other vehicles to enhance the ego vehicle’s perception capability.* Methods: The proposed method, V2X-Graph, is an interpretable and end-to-end learning framework that leverages cooperative motion and interaction contexts using an interpretable graph.* Results: Experimental results on the V2I motion forecasting dataset V2X-Seq demonstrate the effectiveness of V2X-Graph, and the first real-world V2X motion forecasting dataset V2X-Traj is constructed to further evaluate the method.<details>
<summary>Abstract</summary>
Motion forecasting is an essential task for autonomous driving, and the effective information utilization from infrastructure and other vehicles can enhance motion forecasting capabilities. Existing research have primarily focused on leveraging single-frame cooperative information to enhance the limited perception capability of the ego vehicle, while underutilizing the motion and interaction information of traffic participants observed from cooperative devices. In this paper, we first propose the cooperative trajectory representations learning paradigm. Specifically, we present V2X-Graph, the first interpretable and end-to-end learning framework for cooperative motion forecasting. V2X-Graph employs an interpretable graph to fully leverage the cooperative motion and interaction contexts. Experimental results on the vehicle-to-infrastructure (V2I) motion forecasting dataset, V2X-Seq, demonstrate the effectiveness of V2X-Graph. To further evaluate on V2X scenario, we construct the first real-world vehicle-to-everything (V2X) motion forecasting dataset V2X-Traj, and the performance shows the advantage of our method. We hope both V2X-Graph and V2X-Traj can facilitate the further development of cooperative motion forecasting. Find project at https://github.com/AIR-THU/V2X-Graph, find data at https://github.com/AIR-THU/DAIR-V2X-Seq.
</details>
<details>
<summary>摘要</summary>
行为预测是自动驾驶中的关键任务，可以通过基础设施和其他车辆的有效信息利用来增强行为预测能力。现有研究主要是利用单一帧合作信息来增强自驾车的有限感知能力，而忽略了交通参与者的运动和互动信息，这些信息可以从合作设备上获得。在这篇论文中，我们首先提出了合作轨迹表示学习 парадигмы。 Specifically, we present V2X-Graph, the first interpretable and end-to-end learning framework for cooperative motion forecasting. V2X-Graph employs an interpretable graph to fully leverage the cooperative motion and interaction contexts. Experimental results on the vehicle-to-infrastructure (V2I) motion forecasting dataset, V2X-Seq, demonstrate the effectiveness of V2X-Graph. To further evaluate on V2X scenario, we construct the first real-world vehicle-to-everything (V2X) motion forecasting dataset V2X-Traj, and the performance shows the advantage of our method. We hope both V2X-Graph and V2X-Traj can facilitate the further development of cooperative motion forecasting. 找到项目在 GitHub上：https://github.com/AIR-THU/V2X-Graph，找到数据在 GitHub上：https://github.com/AIR-THU/DAIR-V2X-Seq。
</details></li>
</ul>
<hr>
<h2 id="LatentWarp-Consistent-Diffusion-Latents-for-Zero-Shot-Video-to-Video-Translation"><a href="#LatentWarp-Consistent-Diffusion-Latents-for-Zero-Shot-Video-to-Video-Translation" class="headerlink" title="LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video Translation"></a>LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00353">http://arxiv.org/abs/2311.00353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Bao, Di Qiu, Guoliang Kang, Baochang Zhang, Bo Jin, Kaiye Wang, Pengfei Yan</li>
<li>for: 本研究旨在提出一种新的零shot视频到视频翻译方法，以解决现有方法中的时间一致问题。</li>
<li>methods: 该方法基于图像扩散模型，并通过在潜在空间中添加折叠操作来约束查询符。</li>
<li>results: 实验结果表明，该方法可以有效地提高生成视频的视觉一致性。<details>
<summary>Abstract</summary>
Leveraging the generative ability of image diffusion models offers great potential for zero-shot video-to-video translation. The key lies in how to maintain temporal consistency across generated video frames by image diffusion models. Previous methods typically adopt cross-frame attention, \emph{i.e.,} sharing the \textit{key} and \textit{value} tokens across attentions of different frames, to encourage the temporal consistency. However, in those works, temporal inconsistency issue may not be thoroughly solved, rendering the fidelity of generated videos limited.%The current state of the art cross-frame attention method aims at maintaining fine-grained visual details across frames, but it is still challenged by the temporal coherence problem. In this paper, we find the bottleneck lies in the unconstrained query tokens and propose a new zero-shot video-to-video translation framework, named \textit{LatentWarp}. Our approach is simple: to constrain the query tokens to be temporally consistent, we further incorporate a warping operation in the latent space to constrain the query tokens. Specifically, based on the optical flow obtained from the original video, we warp the generated latent features of last frame to align with the current frame during the denoising process. As a result, the corresponding regions across the adjacent frames can share closely-related query tokens and attention outputs, which can further improve latent-level consistency to enhance visual temporal coherence of generated videos. Extensive experiment results demonstrate the superiority of \textit{LatentWarp} in achieving video-to-video translation with temporal coherence.
</details>
<details>
<summary>摘要</summary>
利用生成能力的图像扩散模型可以实现零码视频到视频翻译，但是保持视频帧之间的时间一致性是关键。先前的方法通常采用跨帧注意力，即在不同帧之间共享键和值符号，以便强制实现时间一致性。然而，这些方法可能并未完全解决时间不一致问题，因此生成的视频质量有限。目前领先的跨帧注意力方法旨在保持细致的视觉细节 across 帧，但它们仍然面临着时间一致性问题。在这篇文章中，我们发现瓶颈在无制限的查询符号上，我们提出了一个新的零码视频到视频翻译框架，名为LatentWarp。我们的方法简单：在 latent 空间中使用扩散操作来约束查询符号，以确保查询符号在时间上是一致的。具体来说，根据原始视频中的Optical Flow，我们在生成最后一帧的缺lazier特征上进行扩散操作，以使得相邻帧中的相关区域可以共享相似的查询符号和注意力输出，从而进一步提高latent 级别的一致性，以提高生成的视频的视觉时间一致性。我们的实验结果表明，LatentWarp 可以很好地实现视频到视频翻译的时间一致性。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Head-Orientation-of-Neurotypical-and-Autistic-Individuals-in-Triadic-Conversations"><a href="#Analyzing-Head-Orientation-of-Neurotypical-and-Autistic-Individuals-in-Triadic-Conversations" class="headerlink" title="Analyzing Head Orientation of Neurotypical and Autistic Individuals in Triadic Conversations"></a>Analyzing Head Orientation of Neurotypical and Autistic Individuals in Triadic Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00343">http://arxiv.org/abs/2311.00343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onur N. Tepencelik, Wenchuan Wei, Pamela C. Cosman, Sujit Dey<br>for:这个论文是为了提出一种使用低分辨率点云数据来估算人体和头部orientation的系统。methods:这个系统使用椭圆适应和人头部特征提取以及 ensemble of neural network regressors来估算人体和头部orientation。results:相比使用RGB摄像头的其他人体和头部orientation估算系统，这个系统使用LiDAR感知器保护用户隐私，同时达到相似的准确率。这个系统的mean absolute estimation error为5.2度和13.7度。这个系统可以量化对话中参与者之间的行为差异，包括Autism Spectrum Disorder（ASD）人群在内。<details>
<summary>Abstract</summary>
We propose a system that estimates people's body and head orientations using low-resolution point cloud data from two LiDAR sensors. Our models make accurate estimations in real-world conversation settings where the subject moves naturally with varying head and body poses. The body orientation estimation model uses ellipse fitting while the head orientation estimation model is a pipeline of geometric feature extraction and an ensemble of neural network regressors. Compared with other body and head orientation estimation systems using RGB cameras, our proposed system uses LiDAR sensors to preserve user privacy, while achieving comparable accuracy. Unlike other body/head orientation estimation systems, our sensors do not require a specified placement in front of the subject. Our models achieve a mean absolute estimation error of 5.2 degrees for body orientation and 13.7 degrees for head orientation. We use our models to quantify behavioral differences between neurotypical and autistic individuals in triadic conversations. Tests of significance show that people with autism spectrum disorder display significantly different behavior compared to neurotypical individuals in terms of distributing attention between participants in a conversation, suggesting that the approach could be a component of a behavioral analysis or coaching system.
</details>
<details>
<summary>摘要</summary>
我们提出了一个系统，该系统使用低分辨率点云数据从两个LiDAR感知器来估算人体和头部方向。我们的模型在实际世界交流场景中具有高准确性，并且可以处理人体和头部不同姿态的自然运动。身体方向估算模型使用椭球适应，而头部方向估算模型则是一个包括几何特征提取和神经网络回归器的管道。与使用RGB摄像头的其他身体和头部方向估算系统相比，我们的提出的系统使用LiDAR感知器保护用户隐私，同时具有相似的准确性。与其他身体/头部方向估算系统不同的是，我们的感知器不需要在前方的主体上进行特定的安装。我们的模型的平均绝对估算误差为5.2度 для身体方向和13.7度 для头部方向。我们使用我们的模型来评估不同于 nevropatypical 个体和自闭症人群在三人交流中的行为差异。测试显示，自闭症人群在对话中分配注意力的方式与非 nevropatypical 个体有 statistically significant 的差异， suggesting that the approach could be a component of a behavioral analysis or coaching system。
</details></li>
</ul>
<hr>
<h2 id="fMRI-PTE-A-Large-scale-fMRI-Pretrained-Transformer-Encoder-for-Multi-Subject-Brain-Activity-Decoding"><a href="#fMRI-PTE-A-Large-scale-fMRI-Pretrained-Transformer-Encoder-for-Multi-Subject-Brain-Activity-Decoding" class="headerlink" title="fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for Multi-Subject Brain Activity Decoding"></a>fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for Multi-Subject Brain Activity Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00342">http://arxiv.org/abs/2311.00342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuelin Qian, Yun Wang, Jingyang Huo, Jianfeng Feng, Yanwei Fu</li>
<li>For: This paper aims to develop an innovative approach for pre-training fMRI data, addressing the challenges of individual brain differences and improving the quality of brain activity decoding.* Methods: The proposed approach, called fMRI-PTE, uses an auto-encoder to transform fMRI signals into 2D representations, ensuring consistency in dimensions and preserving distinct brain activity patterns. A novel learning strategy is introduced for pre-training 2D fMRI images, which enhances the quality of reconstruction and facilitates various downstream tasks.* Results: Extensive experiments demonstrate the effectiveness of fMRI-PTE in addressing the challenges of fMRI data dimensions and improving brain activity decoding. The proposed approach outperforms existing methods in terms of reconstruction quality and adaptability with image generators, offering a promising foundation for further research in this domain.<details>
<summary>Abstract</summary>
The exploration of brain activity and its decoding from fMRI data has been a longstanding pursuit, driven by its potential applications in brain-computer interfaces, medical diagnostics, and virtual reality. Previous approaches have primarily focused on individual subject analysis, highlighting the need for a more universal and adaptable framework, which is the core motivation behind our work. In this work, we propose fMRI-PTE, an innovative auto-encoder approach for fMRI pre-training, with a focus on addressing the challenges of varying fMRI data dimensions due to individual brain differences. Our approach involves transforming fMRI signals into unified 2D representations, ensuring consistency in dimensions and preserving distinct brain activity patterns. We introduce a novel learning strategy tailored for pre-training 2D fMRI images, enhancing the quality of reconstruction. fMRI-PTE's adaptability with image generators enables the generation of well-represented fMRI features, facilitating various downstream tasks, including within-subject and cross-subject brain activity decoding. Our contributions encompass introducing fMRI-PTE, innovative data transformation, efficient training, a novel learning strategy, and the universal applicability of our approach. Extensive experiments validate and support our claims, offering a promising foundation for further research in this domain.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:探索大脑活动和从fMRI数据中解读的探索，有 been a longstanding pursuit, driven by its potential applications in brain-computer interfaces, medical diagnostics, and virtual reality. Previous approaches have primarily focused on individual subject analysis, highlighting the need for a more universal and adaptable framework, which is the core motivation behind our work. In this work, we propose fMRI-PTE, an innovative auto-encoder approach for fMRI pre-training, with a focus on addressing the challenges of varying fMRI data dimensions due to individual brain differences. Our approach involves transforming fMRI signals into unified 2D representations, ensuring consistency in dimensions and preserving distinct brain activity patterns. We introduce a novel learning strategy tailored for pre-training 2D fMRI images, enhancing the quality of reconstruction. fMRI-PTE's adaptability with image generators enables the generation of well-represented fMRI features, facilitating various downstream tasks, including within-subject and cross-subject brain activity decoding. Our contributions encompass introducing fMRI-PTE, innovative data transformation, efficient training, a novel learning strategy, and the universal applicability of our approach. Extensive experiments validate and support our claims, offering a promising foundation for further research in this domain.Simplified Chinese:探索大脑活动和从fMRI数据中解译的探索，有 been a longstanding pursuit, driven by its potential applications in brain-computer interfaces, medical diagnosis, and virtual reality. Previous approaches have primarily focused on individual subject analysis, highlighting the need for a more universal and adaptable framework, which is the core motivation behind our work. In this work, we propose fMRI-PTE, an innovative auto-encoder approach for fMRI pre-training, with a focus on addressing the challenges of varying fMRI data dimensions due to individual brain differences. Our approach involves transforming fMRI signals into unified 2D representations, ensuring consistency in dimensions and preserving distinct brain activity patterns. We introduce a novel learning strategy tailored for pre-training 2D fMRI images, enhancing the quality of reconstruction. fMRI-PTE's adaptability with image generators enables the generation of well-represented fMRI features, facilitating various downstream tasks, including within-subject and cross-subject brain activity decoding. Our contributions encompass introducing fMRI-PTE, innovative data transformation, efficient training, a novel learning strategy, and the universal applicability of our approach. Extensive experiments validate and support our claims, offering a promising foundation for further research in this domain.
</details></li>
</ul>
<hr>
<h2 id="Space-Narrative-Generating-Images-and-3D-Scenes-of-Chinese-Garden-from-Text-using-Deep-Learning"><a href="#Space-Narrative-Generating-Images-and-3D-Scenes-of-Chinese-Garden-from-Text-using-Deep-Learning" class="headerlink" title="Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning"></a>Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00339">http://arxiv.org/abs/2311.00339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Shi1, Hao Hua1</li>
<li>for: 这个论文的目的是提出一种基于深度学习方法的园林画生成方法，以便在研究和修复传统中国园林时，缺乏直接资料的问题。</li>
<li>methods: 该论文使用了一种文本描述与园林画的对应关系，使用深度学习方法进行学习。文本描述和园林画之间的映射是通过一个文本-图像扩散模型来实现的。</li>
<li>results: 该论文的实验结果表明，使用这种方法可以生成基于文本描述的园林画，并且可以在Unity 3D 环境中进行三维显示。生成的园林画具有传统明朝园林的风格和特点。<details>
<summary>Abstract</summary>
The consistent mapping from poems to paintings is essential for the research and restoration of traditional Chinese gardens. But the lack of firsthand ma-terial is a great challenge to the reconstruction work. In this paper, we pro-pose a method to generate garden paintings based on text descriptions using deep learning method. Our image-text pair dataset consists of more than one thousand Ming Dynasty Garden paintings and their inscriptions and post-scripts. A latent text-to-image diffusion model learns the mapping from de-scriptive texts to garden paintings of the Ming Dynasty, and then the text description of Jichang Garden guides the model to generate new garden paintings. The cosine similarity between the guide text and the generated image is the evaluation criterion for the generated images. Our dataset is used to fine-tune the pre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models (LoRA). We also transformed the generated images into a panorama and created a free-roam scene in Unity 3D. Our post-trained model is capable of generating garden images in the style of Ming Dynasty landscape paintings based on textual descriptions. The gener-ated images are compatible with three-dimensional presentation in Unity 3D.
</details>
<details>
<summary>摘要</summary>
traditional Chinese gardens的研究和修复中，映射 FROM POEMS TO PAINTINGS的稳定性至关重要。但lack of firsthand materials是修复工作的大allenge。在这篇论文中，我们提议一种基于深度学习方法的方法，可以将文本描述转换成园林画作。我们的图像文本对象集包括明朝园林画作和其附注和后cript。一个潜在的文本到图像扩散模型学习了明朝园林画作的描述文本和图像之间的映射。然后，用Jichang园的文本作为指南，使模型生成新的园林画作。cosine similarity between the guide text and the generated image是评价 criterion for the generated images。我们使用LoRA来精度地适应大语言模型，并将生成的图像转换成扩展场景。我们的post-trained模型可以基于文本描述生成明朝园林画作风格的园林图像，并且可以与Unity 3D中的三维场景兼容。
</details></li>
</ul>
<hr>
<h2 id="SDF4CHD-Generative-Modeling-of-Cardiac-Anatomies-with-Congenital-Heart-Defects"><a href="#SDF4CHD-Generative-Modeling-of-Cardiac-Anatomies-with-Congenital-Heart-Defects" class="headerlink" title="SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart Defects"></a>SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00332">http://arxiv.org/abs/2311.00332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanwei Kong, Sascha Stocker, Perry S. Choi, Michael Ma, Daniel B. Ennis, Alison Marsden</li>
<li>for: 这个研究的目的是创建一种可以自动构建心脏疾病患者的特有心脏形态模型，以提高诊断和治疗规划。</li>
<li>methods: 这个研究使用了深度学习（DL）方法，包括生成模型和 signed distance fields（SDF），来自动构建心脏疾病患者的特有心脏形态。</li>
<li>results: 这个研究的结果显示，这种生成模型可以创建不同的心脏疾病型别的虚拟实验室，并且可以将这些虚拟实验室与实际患者的心脏形态进行比较，以提高诊断和治疗规划的准确性。<details>
<summary>Abstract</summary>
Congenital heart disease (CHD) encompasses a spectrum of cardiovascular structural abnormalities, often requiring customized treatment plans for individual patients. Computational modeling and analysis of these unique cardiac anatomies can improve diagnosis and treatment planning and may ultimately lead to improved outcomes. Deep learning (DL) methods have demonstrated the potential to enable efficient treatment planning by automating cardiac segmentation and mesh construction for patients with normal cardiac anatomies. However, CHDs are often rare, making it challenging to acquire sufficiently large patient cohorts for training such DL models. Generative modeling of cardiac anatomies has the potential to fill this gap via the generation of virtual cohorts; however, prior approaches were largely designed for normal anatomies and cannot readily capture the significant topological variations seen in CHD patients. Therefore, we propose a type- and shape-disentangled generative approach suitable to capture the wide spectrum of cardiac anatomies observed in different CHD types and synthesize differently shaped cardiac anatomies that preserve the unique topology for specific CHD types. Our DL approach represents generic whole heart anatomies with CHD type-specific abnormalities implicitly using signed distance fields (SDF) based on CHD type diagnosis, which conveniently captures divergent anatomical variations across different types and represents meaningful intermediate CHD states. To capture the shape-specific variations, we then learn invertible deformations to morph the learned CHD type-specific anatomies and reconstruct patient-specific shapes. Our approach has the potential to augment the image-segmentation pairs for rarer CHD types for cardiac segmentation and generate cohorts of CHD cardiac meshes for computational simulation.
</details>
<details>
<summary>摘要</summary>
心脏胞茂病（CHD）是指心脏结构变异的谱系，需要根据具体的病人实施个性化的治疗方案。计算机模拟和分析这些特殊的心脏结构可以提高诊断和治疗规划，并可能导致更好的结果。深度学习（DL）方法已经表现出可以通过自动化心脏分 segmentation和心脏穹顶的建立来提高治疗规划的效率。但是，CHD 是罕见的，因此难以收集足够多的患者群来训练这些 DL 模型。生成模型可以填补这个差距，通过生成虚拟患者群来提高模型的鲁棒性和泛化能力。但是，先前的方法主要是为正常心脏结构设计的，无法轻松地捕捉 CHD 患者中的重要 topological variations。因此，我们提出了一种类型和形态分离的生成方法，可以Capture the wide spectrum of cardiac anatomies observed in different CHD types and synthesize differently shaped cardiac anatomies that preserve the unique topology for specific CHD types。我们的 DL 方法使用 signed distance fields (SDF) 来表示具体的心脏类型和形态，并使用这些 SDF 来生成具体的患者心脏模型。然后，我们学习了可逆的扭曲来修改学习到的 CHD 类型特有的心脏形态，以生成 patient-specific 心脏模型。我们的方法有可能增加更多的图像分割对 для更少的 CHD 类型，并生成这些类型中的 cardiac 肋骨模型，以便计算机 simulate 和诊断。
</details></li>
</ul>
<hr>
<h2 id="Flooding-Regularization-for-Stable-Training-of-Generative-Adversarial-Networks"><a href="#Flooding-Regularization-for-Stable-Training-of-Generative-Adversarial-Networks" class="headerlink" title="Flooding Regularization for Stable Training of Generative Adversarial Networks"></a>Flooding Regularization for Stable Training of Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00318">http://arxiv.org/abs/2311.00318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iu Yahiro, Takashi Ishida, Naoto Yokoya</li>
<li>for: 这个论文主要针对 Gan 训练中的稳定性问题。</li>
<li>methods: 该论文提出了一种直接对 adversarial 损失函数进行规范的方法，即通过浸泡法来防止分类器损失函数变得过低。</li>
<li>results: 实验表明，浸泡法可以稳定 Gan 训练，并且可以与其他稳定化技术相结合。此外，研究还发现，限制分类器损失函数不超过浸泡水平， THEN 训练可以稳定进行。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) have shown remarkable performance in image generation. However, GAN training suffers from the problem of instability. One of the main approaches to address this problem is to modify the loss function, often using regularization terms in addition to changing the type of adversarial losses. This paper focuses on directly regularizing the adversarial loss function. We propose a method that applies flooding, an overfitting suppression method in supervised learning, to GANs to directly prevent the discriminator's loss from becoming excessively low. Flooding requires tuning the flood level, but when applied to GANs, we propose that the appropriate range of flood level settings is determined by the adversarial loss function, supported by theoretical analysis of GANs using the binary cross entropy loss. We experimentally verify that flooding stabilizes GAN training and can be combined with other stabilization techniques. We also reveal that by restricting the discriminator's loss to be no greater than flood level, the training proceeds stably even when the flood level is somewhat high.
</details>
<details>
<summary>摘要</summary>
TRANSLATION NOTE:* "flooding" 被翻译成 "淹没"* "overfitting suppression" 被翻译成 "避免过拟合"* "adversarial loss function" 被翻译成 "对抗损失函数"* "binary cross entropy loss" 被翻译成 "二进制极 entropy损失"
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Frame-Selection-for-Text-to-Video-Retrieval"><a href="#An-Empirical-Study-of-Frame-Selection-for-Text-to-Video-Retrieval" class="headerlink" title="An Empirical Study of Frame Selection for Text-to-Video Retrieval"></a>An Empirical Study of Frame Selection for Text-to-Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00298">http://arxiv.org/abs/2311.00298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengxia Wu, Min Cao, Yang Bai, Ziyin Zeng, Chen Chen, Liqiang Nie, Min Zhang</li>
<li>for: 提高文本视频对应的效率和准确率</li>
<li>methods: 研究了多种框架选择方法，包括文本无关和文本引导的方法，并对这些方法进行了详细的分析和比较</li>
<li>results: 经过全面的分析和比较，得出了适合文本视频对应的框架选择方法，可以提高对应的效率和准确率<details>
<summary>Abstract</summary>
Text-to-video retrieval (TVR) aims to find the most relevant video in a large video gallery given a query text. The intricate and abundant context of the video challenges the performance and efficiency of TVR. To handle the serialized video contexts, existing methods typically select a subset of frames within a video to represent the video content for TVR. How to select the most representative frames is a crucial issue, whereby the selected frames are required to not only retain the semantic information of the video but also promote retrieval efficiency by excluding temporally redundant frames. In this paper, we make the first empirical study of frame selection for TVR. We systemically classify existing frame selection methods into text-free and text-guided ones, under which we detailedly analyze six different frame selections in terms of effectiveness and efficiency. Among them, two frame selections are first developed in this paper. According to the comprehensive analysis on multiple TVR benchmarks, we empirically conclude that the TVR with proper frame selections can significantly improve the retrieval efficiency without sacrificing the retrieval performance.
</details>
<details>
<summary>摘要</summary>
In this paper, we make the first empirical study of frame selection for TVR. We categorize existing frame selection methods into text-free and text-guided ones, and analyze six different frame selections in terms of effectiveness and efficiency. Two of these frame selections are newly developed in this paper. Our comprehensive analysis on multiple TVR benchmarks shows that proper frame selections can significantly improve retrieval efficiency without sacrificing retrieval performance.
</details></li>
</ul>
<hr>
<h2 id="Graph-Representation-Learning-for-Infrared-and-Visible-Image-Fusion"><a href="#Graph-Representation-Learning-for-Infrared-and-Visible-Image-Fusion" class="headerlink" title="Graph Representation Learning for Infrared and Visible Image Fusion"></a>Graph Representation Learning for Infrared and Visible Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00291">http://arxiv.org/abs/2311.00291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Li, Lu Bai, Bin Yang, Chang Li, Lingfei Ma, Edwin R. Hancock</li>
<li>for: 这种论文的目的是怎样？</li>
<li>methods: 这种论文使用了哪些方法？</li>
<li>results: 这种论文得到了什么结果？Here are the answers in Simplified Chinese:</li>
<li>for: 这种论文的目的是提出一种基于图表 Representation 的图像抽取方法，以提高图像抽取的精度和效率。</li>
<li>methods: 这种论文使用了图 convolutional neural networks (GCNs) 来捕捉图像的非本地自similarity (NLss)，并通过图structured  Representation 来提高图像抽取的精度和效率。</li>
<li>results: 实验结果表明，提出的方法可以准确地捕捉图像的NLss，并且在三个数据集上进行了比较，并证明了该方法的有效性和超越性。<details>
<summary>Abstract</summary>
Infrared and visible image fusion aims to extract complementary features to synthesize a single fused image. Many methods employ convolutional neural networks (CNNs) to extract local features due to its translation invariance and locality. However, CNNs fail to consider the image's non-local self-similarity (NLss), though it can expand the receptive field by pooling operations, it still inevitably leads to information loss. In addition, the transformer structure extracts long-range dependence by considering the correlativity among all image patches, leading to information redundancy of such transformer-based methods. However, graph representation is more flexible than grid (CNN) or sequence (transformer structure) representation to address irregular objects, and graph can also construct the relationships among the spatially repeatable details or texture with far-space distance. Therefore, to address the above issues, it is significant to convert images into the graph space and thus adopt graph convolutional networks (GCNs) to extract NLss. This is because the graph can provide a fine structure to aggregate features and propagate information across the nearest vertices without introducing redundant information. Concretely, we implement a cascaded NLss extraction pattern to extract NLss of intra- and inter-modal by exploring interactions of different image pixels in intra- and inter-image positional distance. We commence by preforming GCNs on each intra-modal to aggregate features and propagate information to extract independent intra-modal NLss. Then, GCNs are performed on the concatenate intra-modal NLss features of infrared and visible images, which can explore the cross-domain NLss of inter-modal to reconstruct the fused image. Ablation studies and extensive experiments illustrates the effectiveness and superiority of the proposed method on three datasets.
</details>
<details>
<summary>摘要</summary>
infrared和可见图像融合的目标是提取各自的特征来合成单一融合图像。许多方法使用卷积神经网络（CNN）提取本地特征，因为它们具有翻译不变性和本地性。然而，CNN忽略图像的非本地自相似性（NLss），尽管它可以通过聚合操作扩大感知范围，但仍然不可避免信息损失。此外，基于转换结构的方法可以捕捉图像的长距离相关性，导致信息繁殖。然而，图像表示更为灵活于格子（CNN）或序列（转换结构）表示，可以处理不规则对象，并且图像可以构建相对论的距离的关系。因此，为了解决以上问题，需要将图像转换为格子空间，并采用图像卷积神经网络（GCNs）提取NLss。这是因为格子可以提供细致的结构，以便聚合特征和在最近邻居之间传递信息，而不是引入 redundancy。具体来说，我们实施了级联NLss提取模式，通过探索不同图像像素之间的交互，提取NLss的Intra-和Inter-模态。我们开始通过GCNs处理每个Intra-模态，以聚合特征并传递信息，提取独立的Intra-模态NLss。然后，我们在 concatenate INTRA-模态NLss特征上进行GCNs处理，可以探索交叉领域NLss的Inter-模态，以重construct融合图像。我们的方法的有效性和优越性通过简洁的方法和广泛的实验证明。
</details></li>
</ul>
<hr>
<h2 id="Mixture-of-Experts-for-Open-Set-Domain-Adaptation-A-Dual-Space-Detection-Approach"><a href="#Mixture-of-Experts-for-Open-Set-Domain-Adaptation-A-Dual-Space-Detection-Approach" class="headerlink" title="Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space Detection Approach"></a>Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space Detection Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00285">http://arxiv.org/abs/2311.00285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenbang Du, Jiayu An, Jiahao Hong, Dongrui Wu</li>
<li>for: 这篇论文的目的是解决开放集领域适束（OSDA）中的分布和标签类shift问题，同时确保精准地类别已知类型的标签，并识别目标领域中的未知类型标签。</li>
<li>methods: 这篇论文提出了一种名为“双空间检测”的方法，利用图像特征空间和路由特征空间之间的不一致来检测未知类型标签，不需要手动调整阈值。它还使用了Graph Router来更好地利用图像组件之间的空间信息。</li>
<li>results: 三个不同的数据集上的实验显示了这篇论文的方法的有效性和超越性，并且不需要手动调整阈值。代码将会很 soon。<details>
<summary>Abstract</summary>
Open Set Domain Adaptation (OSDA) aims to cope with the distribution and label shifts between the source and target domains simultaneously, performing accurate classification for known classes while identifying unknown class samples in the target domain. Most existing OSDA approaches, depending on the final image feature space of deep models, require manually-tuned thresholds, and may easily misclassify unknown samples as known classes. Mixture-of-Expert (MoE) could be a remedy. Within an MoE, different experts address different input features, producing unique expert routing patterns for different classes in a routing feature space. As a result, unknown class samples may also display different expert routing patterns to known classes. This paper proposes Dual-Space Detection, which exploits the inconsistencies between the image feature space and the routing feature space to detect unknown class samples without any threshold. Graph Router is further introduced to better make use of the spatial information among image patches. Experiments on three different datasets validated the effectiveness and superiority of our approach. The code will come soon.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TLMCM-Network-for-Medical-Image-Hierarchical-Multi-Label-Classification"><a href="#TLMCM-Network-for-Medical-Image-Hierarchical-Multi-Label-Classification" class="headerlink" title="TLMCM Network for Medical Image Hierarchical Multi-Label Classification"></a>TLMCM Network for Medical Image Hierarchical Multi-Label Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00282">http://arxiv.org/abs/2311.00282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Wu, Siyan Luo, Qiyu Wu, Wenbin Ouyang</li>
<li>for: 这篇研究的目的是解决现代医疗中的医疗影像层次多标签分类任务（MI-HMC）中的两个主要挑战：数据不对称和层次约束。</li>
<li>methods: 这篇研究提出了将传播学习与最大约束模组（TLMCM）网络应用到MI-HMC任务中，以解决现有方法所具有的复杂模型架构设计和专业知识要求。</li>
<li>results: 实验结果显示，TLMCM网络在MI-HMC任务中可以达到高多标签预测精度（80%-90%），使其成为医疗领域应用中的有价贡献。<details>
<summary>Abstract</summary>
Medical Image Hierarchical Multi-Label Classification (MI-HMC) is of paramount importance in modern healthcare, presenting two significant challenges: data imbalance and \textit{hierarchy constraint}. Existing solutions involve complex model architecture design or domain-specific preprocessing, demanding considerable expertise or effort in implementation. To address these limitations, this paper proposes Transfer Learning with Maximum Constraint Module (TLMCM) network for the MI-HMC task. The TLMCM network offers a novel approach to overcome the aforementioned challenges, outperforming existing methods based on the Area Under the Average Precision and Recall Curve($AU\overline{(PRC)}$) metric. In addition, this research proposes two novel accuracy metrics, $EMR$ and $HammingAccuracy$, which have not been extensively explored in the context of the MI-HMC task. Experimental results demonstrate that the TLMCM network achieves high multi-label prediction accuracy($80\%$-$90\%$) for MI-HMC tasks, making it a valuable contribution to healthcare domain applications.
</details>
<details>
<summary>摘要</summary>
医疗图像层次多标签分类（MI-HMC）在现代医疗中具有重要性，存在两大挑战：数据不均衡和层次约束。现有的解决方案包括复杂的模型建构设计或域pecific的预处理，需要较大的专业知识或努力进行实现。为了解决这些限制，这篇论文提出了传输学习Maximum Constraint Module（TLMCM）网络来解决MI-HMC任务。TLMCM网络提供了一种新的方法来超越现有的方法，在AU（总平均准确率和准确率曲线）指标上表现出色。此外，本研究还提出了两个新的准确度指标：$EMR$和$HammingAccuracy$,这些指标在MI-HMC任务中尚未得到广泛的探讨。实验结果表明，TLMCM网络在MI-HMC任务中可以达到80%-90%的多标签预测精度，这使得它在医疗领域应用中成为一项有价值的贡献。
</details></li>
</ul>
<hr>
<h2 id="OpenForest-A-data-catalogue-for-machine-learning-in-forest-monitoring"><a href="#OpenForest-A-data-catalogue-for-machine-learning-in-forest-monitoring" class="headerlink" title="OpenForest: A data catalogue for machine learning in forest monitoring"></a>OpenForest: A data catalogue for machine learning in forest monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00277">http://arxiv.org/abs/2311.00277</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rolnicklab/openforest">https://github.com/rolnicklab/openforest</a></li>
<li>paper_authors: Arthur Ouaknine, Teja Kattenborn, Etienne Laliberté, David Rolnick</li>
<li>for: The paper aims to provide a comprehensive overview of open access forest datasets across spatial scales, encompassing inventories, ground-based, aerial-based, satellite-based recordings, and country or world maps.</li>
<li>methods: The paper uses a dynamic catalogue called OpenForest to reference all available open access forest datasets, and it also explores the application of machine learning methods for large-scale forest monitoring.</li>
<li>results: The paper provides an extensive overview of 86 open access forest datasets and inspires research in machine learning applied to forest biology by establishing connections between contemporary topics, perspectives, and challenges inherent in both domains.Here is the information in Simplified Chinese text:</li>
<li>for: 本研究的目的是提供一个全面的开放访问森林数据集过iew，覆盖不同的空间尺度，包括 forest inventories，地面、空中、卫星记录等，以及国家或世界地图。</li>
<li>methods: 本研究使用的是一个名为 OpenForest的动态目录，用于参考所有可用的开放访问森林数据集。此外，它还探讨了大规模森林监测中机器学习方法的应用。</li>
<li>results: 本研究提供了86个开放访问森林数据集的广泛概述，并鼓励了机器学习在森林生物学中的研究，并在两个领域之间建立了连接。<details>
<summary>Abstract</summary>
Forests play a crucial role in Earth's system processes and provide a suite of social and economic ecosystem services, but are significantly impacted by human activities, leading to a pronounced disruption of the equilibrium within ecosystems. Advancing forest monitoring worldwide offers advantages in mitigating human impacts and enhancing our comprehension of forest composition, alongside the effects of climate change. While statistical modeling has traditionally found applications in forest biology, recent strides in machine learning and computer vision have reached important milestones using remote sensing data, such as tree species identification, tree crown segmentation and forest biomass assessments. For this, the significance of open access data remains essential in enhancing such data-driven algorithms and methodologies. Here, we provide a comprehensive and extensive overview of 86 open access forest datasets across spatial scales, encompassing inventories, ground-based, aerial-based, satellite-based recordings, and country or world maps. These datasets are grouped in OpenForest, a dynamic catalogue open to contributions that strives to reference all available open access forest datasets. Moreover, in the context of these datasets, we aim to inspire research in machine learning applied to forest biology by establishing connections between contemporary topics, perspectives and challenges inherent in both domains. We hope to encourage collaborations among scientists, fostering the sharing and exploration of diverse datasets through the application of machine learning methods for large-scale forest monitoring. OpenForest is available at this url: https://github.com/RolnickLab/OpenForest
</details>
<details>
<summary>摘要</summary>
森林 играют重要的角色在地球系统中，提供一系列社会和经济生态系统服务，但是受到人类活动的干扰，导致生态系统内的平衡受到明显的干扰。推进全球森林监测可以提供利益，减轻人类的影响，并提高我们对森林结构的理解，以及气候变化的影响。在Machine learning和计算机视觉等领域做出了重要进步，使用遥感数据进行树种识别、树冠分割和森林质量评估等。在这个过程中，开放数据的重要性仍然存在，以增强这些数据驱动的算法和方法。我们提供了86个开放 forest 数据集，覆盖不同的空间尺度，包括 forest инвенタризация、地面、空中、卫星记录等，并分类在 OpenForest 中，这是一个动态目录，欢迎投稿。此外，在这些数据集的背景下，我们想要鼓励研究者通过机器学习应用于森林生物，探讨两个领域之间的联系和挑战。我们希望通过共同分享和探索多样化的数据集，通过机器学习方法实现大规模森林监测。OpenForest 的Url为：https://github.com/RolnickLab/OpenForest
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Latent-Diffusion-Model-for-3D-Medical-Image-to-Image-Translation-Multi-modal-Magnetic-Resonance-Imaging-Study"><a href="#Adaptive-Latent-Diffusion-Model-for-3D-Medical-Image-to-Image-Translation-Multi-modal-Magnetic-Resonance-Imaging-Study" class="headerlink" title="Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-modal Magnetic Resonance Imaging Study"></a>Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-modal Magnetic Resonance Imaging Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00265">http://arxiv.org/abs/2311.00265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jongdory/aldm">https://github.com/jongdory/aldm</a></li>
<li>paper_authors: Jonghun Kim, Hyunjin Park</li>
<li>for: 这个研究旨在提供一个基于潜在扩散模型（LDM）的图像转换模型，并使用可调整块（MS-SPADE）来实现图像转换。</li>
<li>methods: 这个模型使用了3D LDM和conditioning技术，并使用了MS-SPADE块来实现图像转换。</li>
<li>results: 这个模型在多个源模式转换到多个目标模式时 exhibited 成功的图像合成，并在量值评估中超过了其他模型。<details>
<summary>Abstract</summary>
Multi-modal images play a crucial role in comprehensive evaluations in medical image analysis providing complementary information for identifying clinically important biomarkers. However, in clinical practice, acquiring multiple modalities can be challenging due to reasons such as scan cost, limited scan time, and safety considerations. In this paper, we propose a model based on the latent diffusion model (LDM) that leverages switchable blocks for image-to-image translation in 3D medical images without patch cropping. The 3D LDM combined with conditioning using the target modality allows generating high-quality target modality in 3D overcoming the shortcoming of the missing out-of-slice information in 2D generation methods. The switchable block, noted as multiple switchable spatially adaptive normalization (MS-SPADE), dynamically transforms source latents to the desired style of the target latents to help with the diffusion process. The MS-SPADE block allows us to have one single model to tackle many translation tasks of one source modality to various targets removing the need for many translation models for different scenarios. Our model exhibited successful image synthesis across different source-target modality scenarios and surpassed other models in quantitative evaluations tested on multi-modal brain magnetic resonance imaging datasets of four different modalities and an independent IXI dataset. Our model demonstrated successful image synthesis across various modalities even allowing for one-to-many modality translations. Furthermore, it outperformed other one-to-one translation models in quantitative evaluations.
</details>
<details>
<summary>摘要</summary>
多modal图像在医学影像分析中发挥关键作用，提供补充信息，用于标识临床重要的生物标志物。然而，在临床实践中，获取多modal的挑战性很大，主要包括成本高、时间短、安全因素等。在这篇论文中，我们提出了基于潜在扩散模型（LDM）的模型，利用可 switchable 块来实现图像到图像翻译。3D LDM 结合了目标模式的conditioning，可以生成高质量的目标模式3D图像，超越2D生成方法中缺失的剪辑信息。MS-SPADE块可以将源境文件转换成目标境文件的样式，帮助扩散过程。我们的模型可以处理多种不同的源模式到目标模式的翻译任务，不需要多个翻译模型。我们的模型在多modal脑磁共振成像数据集上表现出色，超过了其他模型。我们的模型可以在不同的模式之间进行一对多翻译，并且在量化评价中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Solutions-to-Elliptic-and-Parabolic-Problems-via-Finite-Difference-Based-Unsupervised-Small-Linear-Convolutional-Neural-Networks"><a href="#Solutions-to-Elliptic-and-Parabolic-Problems-via-Finite-Difference-Based-Unsupervised-Small-Linear-Convolutional-Neural-Networks" class="headerlink" title="Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks"></a>Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00259">http://arxiv.org/abs/2311.00259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Celaya, Keegan Kirk, David Fuentes, Beatrice Riviere</li>
<li>for: 解决部分演算式（PDE）问题</li>
<li>methods: 使用小型卷积神经网络</li>
<li>results: 与真实解相比，有较高的准确率<details>
<summary>Abstract</summary>
In recent years, there has been a growing interest in leveraging deep learning and neural networks to address scientific problems, particularly in solving partial differential equations (PDEs). However, current neural network-based PDE solvers often rely on extensive training data or labeled input-output pairs, making them prone to challenges in generalizing to out-of-distribution examples. To mitigate the generalization gap encountered by conventional neural network-based methods in estimating PDE solutions, we formulate a fully unsupervised approach, requiring no training data, to estimate finite difference solutions for PDEs directly via small convolutional neural networks. Our proposed algorithms demonstrate a comparable accuracy to the true solution for several selected elliptic and parabolic problems compared to the finite difference method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RAUNE-Net-A-Residual-and-Attention-Driven-Underwater-Image-Enhancement-Method"><a href="#RAUNE-Net-A-Residual-and-Attention-Driven-Underwater-Image-Enhancement-Method" class="headerlink" title="RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement Method"></a>RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00246">http://arxiv.org/abs/2311.00246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fansuregrin/raune-net">https://github.com/fansuregrin/raune-net</a></li>
<li>paper_authors: Wangzhen Peng, Chenghao Zhou, Runze Hu, Jingchao Cao, Yutao Liu</li>
<li>for: 提高水下图像质量</li>
<li>methods: 使用异常学习和注意力机制，构建一个更可靠和合理的UIE网络</li>
<li>results: 对实际水下图像进行评估，比较其对水下图像增强效果和视觉效果，与其他8种UIE方法进行比较，并取得了优秀的 объекivo表现和可见效果。<details>
<summary>Abstract</summary>
Underwater image enhancement (UIE) poses challenges due to distinctive properties of the underwater environment, including low contrast, high turbidity, visual blurriness, and color distortion. In recent years, the application of deep learning has quietly revolutionized various areas of scientific research, including UIE. However, existing deep learning-based UIE methods generally suffer from issues of weak robustness and limited adaptability. In this paper, inspired by residual and attention mechanisms, we propose a more reliable and reasonable UIE network called RAUNE-Net by employing residual learning of high-level features at the network's bottle-neck and two aspects of attention manipulations in the down-sampling procedure. Furthermore, we collect and create two datasets specifically designed for evaluating UIE methods, which contains different types of underwater distortions and degradations. The experimental validation demonstrates that our method obtains promising objective performance and consistent visual results across various real-world underwater images compared to other eight UIE methods. Our example code and datasets are publicly available at https://github.com/fansuregrin/RAUNE-Net.
</details>
<details>
<summary>摘要</summary>
水下图像增强（UIE）在水下环境中存在一些独特的特性，包括低对比度、高浓度、视觉模糊和颜色扭曲。在最近几年，深度学习的应用在科学研究中已经革命化了许多领域，包括 UIE。然而，现有的深度学习基于的 UIE 方法通常受到软性和限制的问题。在这篇论文中，我们提出了一种更可靠和合理的 UIE 网络，称为 RAUNE-Net，通过在网络的瓶颈部分使用剩余学习高级特征，以及在下采样过程中使用两种注意力操作。此外，我们收集和创建了两个特定用于评估 UIE 方法的数据集，这些数据集包含不同类型的水下扭曲和降低。实验验证表明，我们的方法在真实世界水下图像中获得了优秀的目标性能和一致的视觉结果，相比其他八种 UIE 方法。我们的例子代码和数据集在 <https://github.com/fansuregrin/RAUNE-Net> 上公开可用。
</details></li>
</ul>
<hr>
<h2 id="1DFormer-Learning-1D-Landmark-Representations-via-Transformer-for-Facial-Landmark-Tracking"><a href="#1DFormer-Learning-1D-Landmark-Representations-via-Transformer-for-Facial-Landmark-Tracking" class="headerlink" title="1DFormer: Learning 1D Landmark Representations via Transformer for Facial Landmark Tracking"></a>1DFormer: Learning 1D Landmark Representations via Transformer for Facial Landmark Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00241">http://arxiv.org/abs/2311.00241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shi Yin, Shijie Huan, Defu Lian, Shangfei Wang, Jinshui Hu, Tao Guo, Bing Yin, Baocai Yin, Cong Liu</li>
<li>for: 本研究旨在提高人脸特征点跟踪的性能，通过基于1D地标表示的热图回归方法。</li>
<li>methods: 我们提出了一种基于Transformer架构的1DFormer模型，通过在时间和空间维度进行Token通信来学习有用的1D地标表示。为了模型长期顺序模式，我们提出了循环token混合机制、轴地标位嵌入机制以及自信度提高多头注意机制。为了 структура化模型，我们设计了内组和外组结构模型机制，以编码面部结构特征。</li>
<li>results: 我们在300VW和TF数据库上进行实验，结果表明1DFormer可以很好地模型面部特征点的长期顺序模式以及内在结构特征，从而学习有用的1D地标表示。并且在人脸特征点跟踪任务中，1DFormer达到了现有最佳性能。<details>
<summary>Abstract</summary>
Recently, heatmap regression methods based on 1D landmark representations have shown prominent performance on locating facial landmarks. However, previous methods ignored to make deep explorations on the good potentials of 1D landmark representations for sequential and structural modeling of multiple landmarks to track facial landmarks. To address this limitation, we propose a Transformer architecture, namely 1DFormer, which learns informative 1D landmark representations by capturing the dynamic and the geometric patterns of landmarks via token communications in both temporal and spatial dimensions for facial landmark tracking. For temporal modeling, we propose a recurrent token mixing mechanism, an axis-landmark-positional embedding mechanism, as well as a confidence-enhanced multi-head attention mechanism to adaptively and robustly embed long-term landmark dynamics into their 1D representations; for structure modeling, we design intra-group and inter-group structure modeling mechanisms to encode the component-level as well as global-level facial structure patterns as a refinement for the 1D representations of landmarks through token communications in the spatial dimension via 1D convolutional layers. Experimental results on the 300VW and the TF databases show that 1DFormer successfully models the long-range sequential patterns as well as the inherent facial structures to learn informative 1D representations of landmark sequences, and achieves state-of-the-art performance on facial landmark tracking.
</details>
<details>
<summary>摘要</summary>
最近，基于1D特征表示的热图回归方法已经显示出了明显的表达能力在脸部特征点的定位上。然而，前一些方法忽略了对1D特征表示的深入探索，以挖掘其在序列和结构模型化多个特征点的跟踪过程中的潜在优势。为此，我们提议一种名为1DFormer的Transformer架构，该架构通过在时间和空间维度进行токен交流来学习有用的1D特征表示。为 temporal模型ing，我们提出了循环token混合机制、轴点附加 embedding机制以及信任度加 weights multi-head注意机制，以适应性地并Robustly embedding long-term特征点动态到其1D表示中;为结构模型ing，我们设计了内部组和外部组结构模型机制，以编码Component-level以及全局水平的脸部结构模式，并通过1D卷积层进行空间维度的token交流，以便在1D表示中更好地编码多个特征点的结构模式。实验结果表明，1DFormer成功模型了脸部特征点的长距离序列模式以及内在的脸部结构模式，并在脸部特征点跟踪任务中达到了状态之 искусственный智能的表现。
</details></li>
</ul>
<hr>
<h2 id="DINO-Mix-Enhancing-Visual-Place-Recognition-with-Foundational-Vision-Model-and-Feature-Mixing"><a href="#DINO-Mix-Enhancing-Visual-Place-Recognition-with-Foundational-Vision-Model-and-Feature-Mixing" class="headerlink" title="DINO-Mix: Enhancing Visual Place Recognition with Foundational Vision Model and Feature Mixing"></a>DINO-Mix: Enhancing Visual Place Recognition with Foundational Vision Model and Feature Mixing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00230">http://arxiv.org/abs/2311.00230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gaoshuang Huang, Yang Zhou, Xiaofei Hu, Chenglong Zhang, Luying Zhao, Wenjian Gan, Mingbo Hou</li>
<li>for: 这研究旨在提高实际应用中的视觉位置识别（VPR）技术的精度，以便在复杂环境下实现高精度的位置检测。</li>
<li>methods: 该研究使用DINOv2模型作为基础网络，并对其进行修剪和精度调整，以提取robust的图像特征。提出了一种新的VPR建筑called DINO-Mix，它将基础视觉模型和特征聚合 together，以实现高精度的位置识别。</li>
<li>results: 实验表明，提出的DINO-Mix建筑在有光变、季节变化和遮挡的测试集（Tokyo24&#x2F;7、Nordland、SF-XL-Testv1）上达到了Top-1准确率为91.75%、80.18%和82%，分别比SOTA方法提高了5.14%的精度。<details>
<summary>Abstract</summary>
Utilizing visual place recognition (VPR) technology to ascertain the geographical location of publicly available images is a pressing issue for real-world VPR applications. Although most current VPR methods achieve favorable results under ideal conditions, their performance in complex environments, characterized by lighting variations, seasonal changes, and occlusions caused by moving objects, is generally unsatisfactory. In this study, we utilize the DINOv2 model as the backbone network for trimming and fine-tuning to extract robust image features. We propose a novel VPR architecture called DINO-Mix, which combines a foundational vision model with feature aggregation. This architecture relies on the powerful image feature extraction capabilities of foundational vision models. We employ an MLP-Mixer-based mix module to aggregate image features, resulting in globally robust and generalizable descriptors that enable high-precision VPR. We experimentally demonstrate that the proposed DINO-Mix architecture significantly outperforms current state-of-the-art (SOTA) methods. In test sets having lighting variations, seasonal changes, and occlusions (Tokyo24/7, Nordland, SF-XL-Testv1), our proposed DINO-Mix architecture achieved Top-1 accuracy rates of 91.75%, 80.18%, and 82%, respectively. Compared with SOTA methods, our architecture exhibited an average accuracy improvement of 5.14%.
</details>
<details>
<summary>摘要</summary>
utilizing visual place recognition (VPR) technology to determine the geographical location of publicly available images is a pressing issue for real-world VPR applications. although most current VPR methods achieve favorable results under ideal conditions, their performance in complex environments, characterized by lighting variations, seasonal changes, and occlusions caused by moving objects, is generally unsatisfactory. in this study, we utilize the DINOv2 model as the backbone network for trimming and fine-tuning to extract robust image features. we propose a novel VPR architecture called DINO-Mix, which combines a foundational vision model with feature aggregation. this architecture relies on the powerful image feature extraction capabilities of foundational vision models. we employ an MLP-Mixer-based mix module to aggregate image features, resulting in globally robust and generalizable descriptors that enable high-precision VPR. we experimentally demonstrate that the proposed DINO-Mix architecture significantly outperforms current state-of-the-art (SOTA) methods. in test sets having lighting variations, seasonal changes, and occlusions (Tokyo24/7, Nordland, SF-XL-Testv1), our proposed DINO-Mix architecture achieved Top-1 accuracy rates of 91.75%, 80.18%, and 82%, respectively. compared with SOTA methods, our architecture exhibited an average accuracy improvement of 5.14%.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.CV_2023_11_01/" data-id="cloh7tqib00kc7b882o9zf6sc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.AI_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T12:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.AI_2023_11_01/">cs.AI - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unleashing-the-Creative-Mind-Language-Model-As-Hierarchical-Policy-For-Improved-Exploration-on-Challenging-Problem-Solving"><a href="#Unleashing-the-Creative-Mind-Language-Model-As-Hierarchical-Policy-For-Improved-Exploration-on-Challenging-Problem-Solving" class="headerlink" title="Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving"></a>Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00694">http://arxiv.org/abs/2311.00694</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lz1oceani/llm-as-hierarchical-policy">https://github.com/lz1oceani/llm-as-hierarchical-policy</a></li>
<li>paper_authors: Zhan Ling, Yunhao Fang, Xuanlin Li, Tongzhou Mu, Mingu Lee, Reza Pourreza, Roland Memisevic, Hao Su<br>for:* 这个论文旨在提高大语言模型（LLM）的推理能力，使其能够更好地解决复杂的推理问题。methods:* 作者提出了一种基于层次政策的方法，将 LLM 看作一个潜在的推理导航器，并通过在Context learning中学习出一个高级推理策略。* 该方法包括一个视野领袖，提出多个多样化的高级推理策略作为提示，以及一个追随者，通过每一个高级指令进行详细的推理过程，并生成多个推理链来解决问题。results:* 作者的方法可以生成有意义和鼓励人的提示，提高了推理策略的探索能力，并在MATH dataset上提高了复杂问题的答案准确率。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved tremendous progress, yet they still often struggle with challenging reasoning problems. Current approaches address this challenge by sampling or searching detailed and low-level reasoning chains. However, these methods are still limited in their exploration capabilities, making it challenging for correct solutions to stand out in the huge solution space. In this work, we unleash LLMs' creative potential for exploring multiple diverse problem solving strategies by framing an LLM as a hierarchical policy via in-context learning. This policy comprises of a visionary leader that proposes multiple diverse high-level problem-solving tactics as hints, accompanied by a follower that executes detailed problem-solving processes following each of the high-level instruction. The follower uses each of the leader's directives as a guide and samples multiple reasoning chains to tackle the problem, generating a solution group for each leader proposal. Additionally, we propose an effective and efficient tournament-based approach to select among these explored solution groups to reach the final answer. Our approach produces meaningful and inspiring hints, enhances problem-solving strategy exploration, and improves the final answer accuracy on challenging problems in the MATH dataset. Code will be released at https://github.com/lz1oceani/LLM-As-Hierarchical-Policy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-Task-personalized-Multimodal-Few-shot-Learning-for-Visually-rich-Document-Entity-Retrieval"><a href="#On-Task-personalized-Multimodal-Few-shot-Learning-for-Visually-rich-Document-Entity-Retrieval" class="headerlink" title="On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval"></a>On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00693">http://arxiv.org/abs/2311.00693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayi Chen, Hanjun Dai, Bo Dai, Aidong Zhang, Wei Wei</li>
<li>for: 这个研究是为了解决在新的文档类型不断出现的情况下，检测器可以快速适应新的entity类型的问题。</li>
<li>methods: 这个研究使用了任务意识度 meta-学习框架，通过对具有不同任务的label空间进行个性化来解决这个问题。具体来说，他们采用了层次解码器（HC）和对比学习（ContrastProtoNet）来实现这一目标。</li>
<li>results: 实验结果表明，这种方法可以显著提高流行的meta-学习基线的稳定性。<details>
<summary>Abstract</summary>
Visually-rich document entity retrieval (VDER), which extracts key information (e.g. date, address) from document images like invoices and receipts, has become an important topic in industrial NLP applications. The emergence of new document types at a constant pace, each with its unique entity types, presents a unique challenge: many documents contain unseen entity types that occur only a couple of times. Addressing this challenge requires models to have the ability of learning entities in a few-shot manner. However, prior works for Few-shot VDER mainly address the problem at the document level with a predefined global entity space, which doesn't account for the entity-level few-shot scenario: target entity types are locally personalized by each task and entity occurrences vary significantly among documents. To address this unexplored scenario, this paper studies a novel entity-level few-shot VDER task. The challenges lie in the uniqueness of the label space for each task and the increased complexity of out-of-distribution (OOD) contents. To tackle this novel task, we present a task-aware meta-learning based framework, with a central focus on achieving effective task personalization that distinguishes between in-task and out-of-task distribution. Specifically, we adopt a hierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to achieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost future research in the field of entity-level few-shot VDER. Experimental results demonstrate our approaches significantly improve the robustness of popular meta-learning baselines.
</details>
<details>
<summary>摘要</summary>
文本丰富的文档实体抽取（VDER）在工业自然语言处理（NLP）应用中成为重要项目。新的文档型态不断出现，每个文档都有唯一的实体类型，带来一个困难：许多文档中的实体类型从未见过。解决这个问题需要模型具有几次学习的能力。然而，对于几次学习的VDER主要是在文档层级上进行，使用预先定义的全球实体空间，不考虑实体水平的几次学习情况：目标实体类型是每个任务的本地个人化，实体出现在文档中具有很大的差异。为解决这个未曾探讨的情况，这篇文章研究了一个新的实体水平几次学习VDER任务。挑战在于每个任务的标签空间是唯一的，并且实体出现在文档中的多样性增加了OOD内容的复杂性。为了解决这个任务，我们提出了一个任务意识的元学习基础架构，并运用了对焦点学习（HC）和对焦点推导（ContrastProtoNet）来达成目的。此外，我们提出了一个新的数据集，FewVEX，以便未来这个领域的研究。实验结果显示我们的方法可以对具有广泛基础学习的实验基础进行优化。
</details></li>
</ul>
<hr>
<h2 id="Improving-Interpersonal-Communication-by-Simulating-Audiences-with-Language-Models"><a href="#Improving-Interpersonal-Communication-by-Simulating-Audiences-with-Language-Models" class="headerlink" title="Improving Interpersonal Communication by Simulating Audiences with Language Models"></a>Improving Interpersonal Communication by Simulating Audiences with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00687">http://arxiv.org/abs/2311.00687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/theryanl/egs">https://github.com/theryanl/egs</a></li>
<li>paper_authors: Ryan Liu, Howard Yen, Raja Marjieh, Thomas L. Griffiths, Ranjay Krishna<br>for:* 这 paper 旨在帮助我们更好地交流和决策，通过利用 Large Language Model (LLM)  simulations。methods:* 这 paper 提出了 Explore-Generate-Simulate (EGS) 框架，它可以帮助我们在交流和决策过程中更好地选择合适的语言和沟通方式。results:* 这 paper 在 eight 个场景中证明了 EGS 框架的效iveness，其中包括了 ten 种人际交流的基本过程。In simpler Chinese, the paper aims to help us communicate and make decisions more effectively by leveraging Large Language Model (LLM) simulations. It proposes the Explore-Generate-Simulate (EGS) framework, which can help us choose the most appropriate language and communication methods in various situations. The paper demonstrates the effectiveness of the EGS framework through evaluations and demonstrations, showing that it can enhance the outcomes of goal-oriented communication in a variety of situations.<details>
<summary>Abstract</summary>
How do we communicate with others to achieve our goals? We use our prior experience or advice from others, or construct a candidate utterance by predicting how it will be received. However, our experiences are limited and biased, and reasoning about potential outcomes can be difficult and cognitively challenging. In this paper, we explore how we can leverage Large Language Model (LLM) simulations to help us communicate better. We propose the Explore-Generate-Simulate (EGS) framework, which takes as input any scenario where an individual is communicating to an audience with a goal they want to achieve. EGS (1) explores the solution space by producing a diverse set of advice relevant to the scenario, (2) generates communication candidates conditioned on subsets of the advice, and (3) simulates the reactions from various audiences to determine both the best candidate and advice to use. We evaluate the framework on eight scenarios spanning the ten fundamental processes of interpersonal communication. For each scenario, we collect a dataset of human evaluations across candidates and baselines, and showcase that our framework's chosen candidate is preferred over popular generation mechanisms including Chain-of-Thought. We also find that audience simulations achieve reasonably high agreement with human raters across 5 of the 8 scenarios. Finally, we demonstrate the generality of our framework by applying it to real-world scenarios described by users on web forums. Through evaluations and demonstrations, we show that EGS enhances the effectiveness and outcomes of goal-oriented communication across a variety of situations, thus opening up new possibilities for the application of large language models in revolutionizing communication and decision-making processes.
</details>
<details>
<summary>摘要</summary>
如何与他人沟通以达到我们的目标呢？我们可以使用我们的先前经验或他人的建议，或者构建一个候选utterance，预测它将如何被接受。然而，我们的经验是有限和偏袋的，理解可能的结果是困难和耗费大量智力的。在这篇论文中，我们探索了如何通过大型自然语言模型（LLM）的模拟来提高我们的沟通。我们提出了探索-生成-模拟（EGS）框架，它接受任何沟通场景，并且可以帮助我们更好地沟通。EGS框架包括以下三个步骤：1. 探索解决方案空间，生成一组有关场景的多样化建议。2. 根据建议的子集生成各种沟通候选者。3. 使用不同的听众对各种候选者进行模拟，以确定最佳候选者和建议。我们在八个场景中评估了EGS框架，每个场景都有十个基本人际交流过程。我们收集了人类评价者对候选者和基eline的数据集，并证明了我们的选择为Chain-of-Thought所出的候选者所做出的决定胜过。此外，我们发现在5个场景中，听众模拟的结果与人类评价者达到了相当高的一致性。最后，我们通过应用EGS框架到实际场景中，证明了它在不同情况下提高了目标带来的效果和结果，从而开启了大型自然语言模型在沟通和决策过程中的新可能性。
</details></li>
</ul>
<hr>
<h2 id="Emergence-of-Collective-Open-Ended-Exploration-from-Decentralized-Meta-Reinforcement-Learning"><a href="#Emergence-of-Collective-Open-Ended-Exploration-from-Decentralized-Meta-Reinforcement-Learning" class="headerlink" title="Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning"></a>Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00651">http://arxiv.org/abs/2311.00651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard Bornemann, Gautier Hamon, Eleni Nisioti, Clément Moulin-Frier</li>
<li>for: 这 paper 的目的是研究在开放的任务分布下，多个自适应器通过分布式训练而学习集体探索策略。</li>
<li>methods: 这 paper 使用了自适应器在开放的任务分布下进行分布式训练，并引入了一个新的任务空间，其中包含多个来自不同任务类型的子任务，以生成一个庞大的任务树。</li>
<li>results: 研究发现，在这种分布式训练下，多个自适应器可以强大地总结并解决 novel 任务，而且这些任务可以是在训练期间未经遇到的。此外，这些自适应器还学习了集体探索策略，可以在开放的任务设定下解决更加复杂的任务。<details>
<summary>Abstract</summary>
Recent works have proven that intricate cooperative behaviors can emerge in agents trained using meta reinforcement learning on open ended task distributions using self-play. While the results are impressive, we argue that self-play and other centralized training techniques do not accurately reflect how general collective exploration strategies emerge in the natural world: through decentralized training and over an open-ended distribution of tasks. In this work we therefore investigate the emergence of collective exploration strategies, where several agents meta-learn independent recurrent policies on an open ended distribution of tasks. To this end we introduce a novel environment with an open ended procedurally generated task space which dynamically combines multiple subtasks sampled from five diverse task types to form a vast distribution of task trees. We show that decentralized agents trained in our environment exhibit strong generalization abilities when confronted with novel objects at test time. Additionally, despite never being forced to cooperate during training the agents learn collective exploration strategies which allow them to solve novel tasks never encountered during training. We further find that the agents learned collective exploration strategies extend to an open ended task setting, allowing them to solve task trees of twice the depth compared to the ones seen during training. Our open source code as well as videos of the agents can be found on our companion website.
</details>
<details>
<summary>摘要</summary>
近期研究证明，使用meta reinforcement学习训练的代理人可以展现出复杂的合作行为。然而，我们认为自我玩家和其他中央训练技术不能准确反映自然界中集体探索策略的发展：通过分布式训练和开放式任务分布来实现。因此，我们在这种情况下进行了一项研究，探索代理人在开放式任务分布下 meta-learn 独立的递归策略。为此，我们开发了一个新的环境，其中包含一个开放式、生成任务空间，这些任务空间由五种多样化的任务类型的多个子任务组成。我们显示了，在这种环境中训练的代理人在测试时对新物体具有强大的泛化能力。此外，虽然在训练时代理人从未被迫合作，但它们仍然学习了集体探索策略，可以解决在训练中未经遇到的新任务。我们还发现，代理人学习的集体探索策略可以在开放式任务设定下进行扩展，使得它们可以解决比训练中的任务更深的任务树。我们的开源代码以及视频 recording 可以在我们的伙伴网站上找到。
</details></li>
</ul>
<hr>
<h2 id="FAIRLABEL-Correcting-Bias-in-Labels"><a href="#FAIRLABEL-Correcting-Bias-in-Labels" class="headerlink" title="FAIRLABEL: Correcting Bias in Labels"></a>FAIRLABEL: Correcting Bias in Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00638">http://arxiv.org/abs/2311.00638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srinivasan H Sengamedu, Hien Pham</li>
<li>for: 该论文目的是检测和修正机器学习模型中的偏见。</li>
<li>methods: 该论文提出了一种名为FAIRLABEL的算法，用于检测和修正标签中的偏见。</li>
<li>results: 该论文通过synthetic数据和实际数据进行测试，显示FAIRLABEL可以减少不同群体之间的差异性影响（Disparate Impact），同时保持预测准确率高。在UCI成人、德国借款风险和Compas数据集上应用FAIRLABEL，则显示差异性影响率提高了54.2%。<details>
<summary>Abstract</summary>
There are several algorithms for measuring fairness of ML models. A fundamental assumption in these approaches is that the ground truth is fair or unbiased. In real-world datasets, however, the ground truth often contains data that is a result of historical and societal biases and discrimination. Models trained on these datasets will inherit and propagate the biases to the model outputs. We propose FAIRLABEL, an algorithm which detects and corrects biases in labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) across groups while maintaining high accuracy in predictions. We propose metrics to measure the quality of bias correction and validate FAIRLABEL on synthetic datasets and show that the label correction is correct 86.7% of the time vs. 71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets such as UCI Adult, German Credit Risk, and Compas datasets and show that the Disparate Impact Ratio increases by as much as 54.2%.
</details>
<details>
<summary>摘要</summary>
有几种算法用于衡量机器学习模型的公平性。这些方法的基本假设是地面实际数据是公平的或不偏袋。然而，在实际世界中的数据中，经常会包含历史和社会遗产的偏袋和歧视。这些数据中的偏袋会被传递到模型输出中。我们提出了FAIRLABEL算法，它可以检测和修正标签中的偏袋。FAIRLABEL的目标是降低不同群体之间的差异性影响（Disparate Impact，DI），同时保持预测准确率高。我们提出了衡量偏袋修正质量的度量，并验证FAIRLABEL在模拟数据上的性能，结果显示FAIRLABEL可以正确地修正标签86.7%的时间 vs. 71.9%的基eline模型。此外，我们还应用FAIRLABEL在UC Irvine Adult、德国信用风险和Compas等数据集上，结果显示Disparate Impact Ratio可以增加到54.2%。
</details></li>
</ul>
<hr>
<h2 id="A-Bi-level-Framework-for-Traffic-Accident-Duration-Prediction-Leveraging-Weather-and-Road-Condition-Data-within-a-Practical-Optimum-Pipeline"><a href="#A-Bi-level-Framework-for-Traffic-Accident-Duration-Prediction-Leveraging-Weather-and-Road-Condition-Data-within-a-Practical-Optimum-Pipeline" class="headerlink" title="A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline"></a>A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00634">http://arxiv.org/abs/2311.00634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafat Tabassum Sukonna, Soham Irtiza Swapnil</li>
<li>for: 预测交通事故持续时间 (predicting the duration of traffic incidents)</li>
<li>methods: 使用多种机器学习模型 (using multiple machine learning models)</li>
<li>results: 83% 准确率 (83% accuracy rate) and 26.15&#x2F;13.3&#x2F;32.91 MAE&#x2F;RMSE values for short-term and long-term accident duration prediction (using a binary classification random forest model and LightGBM regression model)Here’s a more detailed explanation of each point:1. For: The paper aims to predict the duration of traffic incidents, which can help commuters choose optimal routes and traffic management personnel address non-recurring congestion issues.2. Methods: The authors use a dataset of traffic accidents to train and evaluate multiple machine learning models, including a binary classification random forest model and a LightGBM regression model. They also employ a bimodal approach to determine the precise duration of the incident’s effect.3. Results: The authors achieve an 83% accuracy rate in distinguishing between short-term and long-term effects of traffic accidents, and their LightGBM regression model outperforms other machine learning regression models in terms of Mean Average Error (MAE) and Root Mean Squared Error (RMSE) values. They also identify weather conditions, wind chill, and wind speed as the most influential factors in determining the duration of an accident using SHAP value analysis.<details>
<summary>Abstract</summary>
Due to the stochastic nature of events, predicting the duration of a traffic incident presents a formidable challenge. Accurate duration estimation can result in substantial advantages for commuters in selecting optimal routes and for traffic management personnel in addressing non-recurring congestion issues. In this study, we gathered accident duration, road conditions, and meteorological data from a database of traffic accidents to check the feasibility of a traffic accident duration pipeline without accident contextual information data like accident severity and textual description. Multiple machine learning models were employed to predict whether an accident's impact on road traffic would be of a short-term or long-term nature, and then utilizing a bimodal approach the precise duration of the incident's effect was determined. Our binary classification random forest model distinguished between short-term and long-term effects with an 83% accuracy rate, while the LightGBM regression model outperformed other machine learning regression models with Mean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and 28.91 for short and long-term accident duration prediction, respectively. Using the optimal classification and regression model identified in the preceding section, we then construct an end-to-end pipeline to incorporate the entire process. The results of both separate and combined approaches were comparable with previous works, which shows the applicability of only using static features for predicting traffic accident duration. The SHAP value analysis identified weather conditions, wind chill and wind speed as the most influential factors in determining the duration of an accident.
</details>
<details>
<summary>摘要</summary>
Due to the stochastic nature of events, predicting the duration of a traffic incident presents a formidable challenge. Accurate duration estimation can result in substantial advantages for commuters in selecting optimal routes and for traffic management personnel in addressing non-recurring congestion issues. In this study, we gathered accident duration, road conditions, and meteorological data from a database of traffic accidents to check the feasibility of a traffic accident duration pipeline without accident contextual information data like accident severity and textual description. Multiple machine learning models were employed to predict whether an accident's impact on road traffic would be of a short-term or long-term nature, and then utilizing a bimodal approach the precise duration of the incident's effect was determined. Our binary classification random forest model distinguished between short-term and long-term effects with an 83% accuracy rate, while the LightGBM regression model outperformed other machine learning regression models with Mean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and 28.91 for short and long-term accident duration prediction, respectively. Using the optimal classification and regression model identified in the preceding section, we then construct an end-to-end pipeline to incorporate the entire process. The results of both separate and combined approaches were comparable with previous works, which shows the applicability of only using static features for predicting traffic accident duration. The SHAP value analysis identified weather conditions, wind chill and wind speed as the most influential factors in determining the duration of an accident.Here's the translation in Traditional Chinese as well:due to the stochastic nature of events, predicting the duration of a traffic incident presents a formidable challenge. Accurate duration estimation can result in substantial advantages for commuters in selecting optimal routes and for traffic management personnel in addressing non-recurring congestion issues. In this study, we gathered accident duration, road conditions, and meteorological data from a database of traffic accidents to check the feasibility of a traffic accident duration pipeline without accident contextual information data like accident severity and textual description. Multiple machine learning models were employed to predict whether an accident's impact on road traffic would be of a short-term or long-term nature, and then utilizing a bimodal approach the precise duration of the incident's effect was determined. Our binary classification random forest model distinguished between short-term and long-term effects with an 83% accuracy rate, while the LightGBM regression model outperformed other machine learning regression models with Mean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and 28.91 for short and long-term accident duration prediction, respectively. Using the optimal classification and regression model identified in the preceding section, we then construct an end-to-end pipeline to incorporate the entire process. The results of both separate and combined approaches were comparable with previous works, which shows the applicability of only using static features for predicting traffic accident duration. The SHAP value analysis identified weather conditions, wind chill and wind speed as the most influential factors in determining the duration of an accident.
</details></li>
</ul>
<hr>
<h2 id="Loss-Modeling-for-Multi-Annotator-Datasets"><a href="#Loss-Modeling-for-Multi-Annotator-Datasets" class="headerlink" title="Loss Modeling for Multi-Annotator Datasets"></a>Loss Modeling for Multi-Annotator Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00619">http://arxiv.org/abs/2311.00619</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/molyswu/hand_detection">https://github.com/molyswu/hand_detection</a></li>
<li>paper_authors: Uthman Jinadu, Jesse Annan, Shanshan Wen, Yi Ding</li>
<li>for: 提高数据集中注解准确性，尤其是对于subjective数据，避免疲劳和时间影响。</li>
<li>methods: 使用多任务学习和损失基于标签更正来更好地表达多个注解者的意见。</li>
<li>results: 使用该方法可以清晰地分解一致和不一致的注解，并且可以提高预测性能在单或多注解者设置下。此外，该方法对subjective数据中的额外标签噪声也具有耐性。<details>
<summary>Abstract</summary>
Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.
</details>
<details>
<summary>摘要</summary>
对于 dataset 的所有标注者的意见评价是重要的，但是在大量标注时，个别标注者将提供大量的评价，这可能会导致疲劳。此外，这些标注过程可能会在多天之间进行，这可能会导致标注者的意见随时间变化。为了解决这个问题，我们提出使用多任务学习，并与损失基于标签修正。我们表明，使用我们的新形式ulation，可以清楚地区分同意和不同意的标注。此外，我们还证明了这个修改可以提高预测性能在单一或多 annotator 环境中。最后，我们显示了这方法在额外附加到主观数据上的标签杂音下仍然是稳定的。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Variational-Inference-for-Probabilistic-Programs-with-Stochastic-Support"><a href="#Rethinking-Variational-Inference-for-Probabilistic-Programs-with-Stochastic-Support" class="headerlink" title="Rethinking Variational Inference for Probabilistic Programs with Stochastic Support"></a>Rethinking Variational Inference for Probabilistic Programs with Stochastic Support</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00594">http://arxiv.org/abs/2311.00594</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/treigerm/sdvi_neurips">https://github.com/treigerm/sdvi_neurips</a></li>
<li>paper_authors: Tim Reichelt, Luke Ong, Tom Rainforth</li>
<li>for: 这个论文目的是提出一种新的可能性变量推理（VI）方法，用于处理 probabilistic programs with stochastic support。</li>
<li>methods: 这个方法使用分解Program decomposition，将program分解成多个子程序，并自动生成每个子程序的独立子引导。</li>
<li>results: 对于这种分解方法，可以更好地构建适当的可能性家族，从而提高推理性能。<details>
<summary>Abstract</summary>
We introduce Support Decomposition Variational Inference (SDVI), a new variational inference (VI) approach for probabilistic programs with stochastic support. Existing approaches to this problem rely on designing a single global variational guide on a variable-by-variable basis, while maintaining the stochastic control flow of the original program. SDVI instead breaks the program down into sub-programs with static support, before automatically building separate sub-guides for each. This decomposition significantly aids in the construction of suitable variational families, enabling, in turn, substantial improvements in inference performance.
</details>
<details>
<summary>摘要</summary>
我们介绍支持分解量化推理（SDVI），一种新的量化推理（VI）方法，用于普罗比例程式中的随机支持。现有的方法将程式分成单一全球量化指南，并在变数按按基础上维护随机控制流程。而 SDVI 则将程式分解成不同的子程式，然后自动建立每个子程式的专属子导。这种分解有助于建立适当的量化家族，并使得推理性能得到了重大改善。
</details></li>
</ul>
<hr>
<h2 id="Coop-Memory-is-not-a-Commodity"><a href="#Coop-Memory-is-not-a-Commodity" class="headerlink" title="Coop: Memory is not a Commodity"></a>Coop: Memory is not a Commodity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00591">http://arxiv.org/abs/2311.00591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianhao Zhang, Shihan Ma, Peihong Liu, Jinhui Yuan</li>
<li>for: 这篇论文旨在提高深度神经网络（DNNs）的训练下限内存预算，通过检查点和重新计算当中遗弃的tensor来实现。</li>
<li>methods: 这篇论文提出了一种名为Coop的方法，它通过缓冲窗内的tensor淘汰来确保所有淘汰的tensor都是连续的，并且立即使用。此外，它还提出了便宜的tensor分割和实在地在位置进行重新计算以进一步降低重新材料化的成本。</li>
<li>results: 实验结果显示，Coop可以实现Up to $2\times$的内存减少和巨大地降低compute overhead、搜寻延迟和内存分解。相比之下，与之相对的基eline案例。<details>
<summary>Abstract</summary>
Tensor rematerialization allows the training of deep neural networks (DNNs) under limited memory budgets by checkpointing the models and recomputing the evicted tensors as needed. However, the existing tensor rematerialization techniques overlook the memory system in deep learning frameworks and implicitly assume that free memory blocks at different addresses are identical. Under this flawed assumption, discontiguous tensors are evicted, among which some are not used to allocate the new tensor. This leads to severe memory fragmentation and increases the cost of potential rematerializations. To address this issue, we propose to evict tensors within a sliding window to ensure all evictions are contiguous and are immediately used. Furthermore, we proposed cheap tensor partitioning and recomputable in-place to further reduce the rematerialization cost by optimizing the tensor allocation. We named our method Coop as it is a co-optimization of tensor allocation and tensor rematerialization. We evaluated Coop on eight representative DNNs. The experimental results demonstrate that Coop achieves up to $2\times$ memory saving and hugely reduces compute overhead, search latency, and memory fragmentation compared to the state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
tensor 重新材料化allow deep neural networks (DNNs) 在有限内存预算下进行训练，通过Checkpointing 模型和计算被赋予的缺失矩阵。然而，现有的tensor 重新材料化技术忽视了深度学习框架中的内存系统，并且对各个地址的自由内存块进行了顺序的假设，导致不连续的矩阵被赋予，其中一些矩阵并未被使用。这会导致内存割较严重和缺少可用内存块，从而增加可能的重新材料化成本。为解决这个问题，我们提议在滑动窗口中赋予矩阵，以确保所有的赋予都是连续的，并且立即被使用。此外，我们还提出了便宜的矩阵分配和可重复在位的方法，以进一步减少重新材料化成本。我们称之为Coop，因为它是矩阵分配和矩阵重新材料化的共同优化。我们对八个代表性的DNN进行了评估，实验结果表明，Coop可以达到$2\times$的内存减少和巨大减少计算开销、搜索延迟和内存割较严重相比于状态之前的基eline。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Summarization-with-Normalizing-Flows-and-Aggressive-Training"><a href="#Boosting-Summarization-with-Normalizing-Flows-and-Aggressive-Training" class="headerlink" title="Boosting Summarization with Normalizing Flows and Aggressive Training"></a>Boosting Summarization with Normalizing Flows and Aggressive Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00588">http://arxiv.org/abs/2311.00588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuyangstat/flowsum">https://github.com/yuyangstat/flowsum</a></li>
<li>paper_authors: Yu Yang, Xiaotong Shen</li>
<li>for: This paper is written for the task of summarization using Transformer-based models and normalizing flows.</li>
<li>methods: The paper proposes a new framework called FlowSUM, which uses normalizing flows to model the latent space of the summarization task and a controlled alternate aggressive training (CAAT) strategy to improve the quality of generated summaries.</li>
<li>results: The paper shows that FlowSUM significantly enhances the quality of generated summaries and unleashes the potential for knowledge distillation with minimal impact on inference time. Additionally, the paper investigates the issue of posterior collapse in normalizing flows and analyzes how the summary quality is affected by the training strategy, gate initialization, and the type and number of normalizing flows used.<details>
<summary>Abstract</summary>
This paper presents FlowSUM, a normalizing flows-based variational encoder-decoder framework for Transformer-based summarization. Our approach tackles two primary challenges in variational summarization: insufficient semantic information in latent representations and posterior collapse during training. To address these challenges, we employ normalizing flows to enable flexible latent posterior modeling, and we propose a controlled alternate aggressive training (CAAT) strategy with an improved gate mechanism. Experimental results show that FlowSUM significantly enhances the quality of generated summaries and unleashes the potential for knowledge distillation with minimal impact on inference time. Furthermore, we investigate the issue of posterior collapse in normalizing flows and analyze how the summary quality is affected by the training strategy, gate initialization, and the type and number of normalizing flows used, offering valuable insights for future research.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Minimally-Modifying-a-Markov-Game-to-Achieve-Any-Nash-Equilibrium-and-Value"><a href="#Minimally-Modifying-a-Markov-Game-to-Achieve-Any-Nash-Equilibrium-and-Value" class="headerlink" title="Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value"></a>Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00582">http://arxiv.org/abs/2311.00582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Wu, Jeremy McMahan, Yiding Chen, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</li>
<li>for: 本文研究了游戏修改问题，即一位好意的游戏设计者或一位恶意对手修改了Zero-sum Markov游戏的奖励函数，使得一个目标 deterministic或随机策略 Profile becomes the unique Markov perfect Nash equilibrium, and has a value within a target range, at a minimum cost.</li>
<li>methods: 本文使用了一种efficient algorithm，包括一个 konvex optimization problem with linear constraints, followed by random perturbation, to obtain a modification plan with a near-optimal cost.</li>
<li>results: 本文Characterizes the set of policy profiles that can be installed as the unique equilibrium of some game, and establishes sufficient and necessary conditions for successful installation.<details>
<summary>Abstract</summary>
We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.
</details>
<details>
<summary>摘要</summary>
我们研究游戏修改问题，其中一位仁慈的游戏设计者或一位邪恶的对手修改了游戏的奖励函数，使得目标决策函数Profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, while minimizing the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.Here's the translation breakdown:* 游戏 (yóuxì) - game* 修改 (xiūgòu) - modification* 问题 (wèn tí) - problem* 游戏设计者 (yóuxì fāngzì) - game designer* 对手 (duìshǒu) - adversary* 奖励函数 (jiàngdǎo fungsion) - reward function* 目标决策函数 (mùzhì jièdécision function) - target decision function* 决策函数 Profile (jièdécision function Profile) - decision function profile* Markov game (Mǎrkov yóuxì) - zero-sum Markov game*  Markov perfect Nash equilibrium (Mǎrkov pèrfect Nàsh èquilibrium) - Markov perfect Nash equilibrium* 奖励 (jiàngdǎo) - reward* 范围 (fāngwài) - range* 修改成本 (xiūgòu shēngběn) - modification cost* Characterize (zhìwù) - characterize* 可安装 (kě'ānshì) - can be installed* 必要条件 (bìyào tiáo'ān) - necessary conditions*  sufficient conditions (yù tiáo'ān) - sufficient conditions* 成功安装 (chéngtóu ānshì) - successful installation* 算法 (suànfā) - algorithm*  solves (jiějué) - solves* 凸优化问题 (kuòyòu yòu zuò) - convex optimization problem* 线性约束 (xiànxìng yùshù) - linear constraints* 随机扰动 (suìjiān shǎodòng) - random perturbation* 修改计划 (xiūgòu jìhuì) - modification plan* 近似优化 (jìn shì yòu) - near-optimal cost
</details></li>
</ul>
<hr>
<h2 id="LLaVA-Interactive-An-All-in-One-Demo-for-Image-Chat-Segmentation-Generation-and-Editing"><a href="#LLaVA-Interactive-An-All-in-One-Demo-for-Image-Chat-Segmentation-Generation-and-Editing" class="headerlink" title="LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing"></a>LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00571">http://arxiv.org/abs/2311.00571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, Chunyuan Li</li>
<li>for: 这个论文是为了探讨多 modal 人机交互系统 LLaVA-Interactive 的研究 прототип。</li>
<li>methods: 该系统可以通过多turn 对话来与人类用户进行交互，并使用多modal 输入和响应来实现。特别是，LLaVA-Interactive 不仅是语言提示，还可以使用视觉提示来协调人类意图。</li>
<li>results: 在开发 LLVA-Interactive 系统时，可以非常经济地利用三种已有 AI 模型的多modal 技能，无需进行额外模型训练。应用场景包括多种多样的应用场景，以示 LLVA-Interactive 的承诺和未来多Modal 交互系统的研究发展之 potential。<details>
<summary>Abstract</summary>
LLaVA-Interactive is a research prototype for multimodal human-AI interaction. The system can have multi-turn dialogues with human users by taking multimodal user inputs and generating multimodal responses. Importantly, LLaVA-Interactive goes beyond language prompt, where visual prompt is enabled to align human intents in the interaction. The development of LLaVA-Interactive is extremely cost-efficient as the system combines three multimodal skills of pre-built AI models without additional model training: visual chat of LLaVA, image segmentation from SEEM, as well as image generation and editing from GLIGEN. A diverse set of application scenarios is presented to demonstrate the promises of LLaVA-Interactive and to inspire future research in multimodal interactive systems.
</details>
<details>
<summary>摘要</summary>
LLaVA-Interactive 是一个研究原型，用于多Modal human-AI交互。该系统可以与人类用户进行多轮对话，通过多Modal 输入和回应来实现。重要的是，LLaVA-Interactive 超越语言提示，启用视觉提示，以协调人类意图在交互中。该系统的开发非常Cost-efficient，因为它将三种Multimodal 技能的预建 AI 模型结合，无需额外模型训练：视觉对话的 LLaVA，图像分割的 SEEM，以及图像生成和修改的 GLIGEN。为了展示 LLVA-Interactive 的搭配优势和发展前景，文章提供了多样化的应用场景示例。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Visual-Cues-in-the-Intensive-Care-Unit-and-Association-with-Patient-Clinical-Status"><a href="#Detecting-Visual-Cues-in-the-Intensive-Care-Unit-and-Association-with-Patient-Clinical-Status" class="headerlink" title="Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status"></a>Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00565">http://arxiv.org/abs/2311.00565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhash Nerella, Ziyuan Guan, Andrea Davidson, Yuanfang Ren, Tezcan Baslanti, Brooke Armfield, Patrick Tighe, Azra Bihorac, Parisa Rashidi</li>
<li>For: This paper aims to develop an Artificial Intelligence (AI) tool to augment human assessments in Intensive Care Units (ICUs) by analyzing facial cues to monitor patient condition.* Methods: The authors use a dataset of 107,064 frames collected in the ICU, annotated with facial action units (AUs) labels by trained annotators. They develop a “masked loss computation” technique to address data imbalance and train a SWIN Transformer model to detect 18 AUs.* Results: The SWIN Transformer model achieves a mean F1-score of 0.57 and mean accuracy of 0.89 on the test set. The authors also perform AU inference on 634,054 frames to evaluate the association between facial AUs and clinically important patient conditions such as acuity status, acute brain dysfunction, and pain.<details>
<summary>Abstract</summary>
Intensive Care Units (ICU) provide close supervision and continuous care to patients with life-threatening conditions. However, continuous patient assessment in the ICU is still limited due to time constraints and the workload on healthcare providers. Existing patient assessments in the ICU such as pain or mobility assessment are mostly sporadic and administered manually, thus introducing the potential for human errors. Developing Artificial intelligence (AI) tools that can augment human assessments in the ICU can be beneficial for providing more objective and granular monitoring capabilities. For example, capturing the variations in a patient's facial cues related to pain or agitation can help in adjusting pain-related medications or detecting agitation-inducing conditions such as delirium. Additionally, subtle changes in visual cues during or prior to adverse clinical events could potentially aid in continuous patient monitoring when combined with high-resolution physiological signals and Electronic Health Record (EHR) data. In this paper, we examined the association between visual cues and patient condition including acuity status, acute brain dysfunction, and pain. We leveraged our AU-ICU dataset with 107,064 frames collected in the ICU annotated with facial action units (AUs) labels by trained annotators. We developed a new "masked loss computation" technique that addresses the data imbalance problem by maximizing data resource utilization. We trained the model using our AU-ICU dataset in conjunction with three external datasets to detect 18 AUs. The SWIN Transformer model achieved 0.57 mean F1-score and 0.89 mean accuracy on the test set. Additionally, we performed AU inference on 634,054 frames to evaluate the association between facial AUs and clinically important patient conditions such as acuity status, acute brain dysfunction, and pain.
</details>
<details>
<summary>摘要</summary>
医疗机构（ICU）提供严格的监测和不间断的护理，以帮助患有生命威胁的病人。然而，ICU中病人的 kontinuous assessment 仍然受到时间限制和医疗人员的工作负担的限制。现有的病人评估方法在ICU中，如痛苦或 mobilitity 评估，都是间歇的和由人工实现的，这可能会导致人类错误。通过开发人工智能（AI）工具来增强人类评估的ICU可以为病人提供更加 объек 的监测能力。例如，记录病人的表情变化可以帮助调整痛苦相关的药物或检测昏迷性病变。此外，在或 перед严重临床事件发生时，通过高分辨率生物信号和电子医疗记录（EHR）数据 combin 可能会帮助实现不间断的病人监测。在这篇论文中，我们研究了视觉cue和病人状况之间的关系，包括病情严重程度、脑部损伤和痛苦。我们利用我们的AU-ICU数据集，包括107,064帧ICU中收录的表情动作单元（AU）标签，由训练过的注释员标注。我们开发了一种“遮盖损失计算”技术，解决数据不均衡问题，以最大化数据资源利用。我们使用我们的AU-ICU数据集，并与三个外部数据集一起训练SWINTransformer模型，检测18个AU。测试集得分为0.57的 mean F1 score和0.89的 mean accuracy。此外，我们在634,054帧中进行AU推断，评估facial AU和临床重要的病人状况，如病情严重程度、脑部损伤和痛苦。
</details></li>
</ul>
<hr>
<h2 id="Tackling-the-Abstraction-and-Reasoning-Corpus-ARC-with-Object-centric-Models-and-the-MDL-Principle"><a href="#Tackling-the-Abstraction-and-Reasoning-Corpus-ARC-with-Object-centric-Models-and-the-MDL-Principle" class="headerlink" title="Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle"></a>Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00545">http://arxiv.org/abs/2311.00545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sébastien Ferré</li>
<li>for: 这个研究是为了推动人工智能水平的AI研究而设计的挑战性 bencmark。</li>
<li>methods: 这个研究使用物件中心的模型，与人类所生成的自然程式一样。它还使用最小描述长度（MDL）原则进行有效的搜寻大型模型空间。</li>
<li>results: 这个研究可以解决多种任务，并且学习的模型与自然程式相似。此外，它还可以应用到不同的领域中。<details>
<summary>Abstract</summary>
The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark, introduced to foster AI research towards human-level intelligence. It is a collection of unique tasks about generating colored grids, specified by a few examples only. In contrast to the transformation-based programs of existing work, we introduce object-centric models that are in line with the natural programs produced by humans. Our models can not only perform predictions, but also provide joint descriptions for input/output pairs. The Minimum Description Length (MDL) principle is used to efficiently search the large model space. A diverse range of tasks are solved, and the learned models are similar to the natural programs. We demonstrate the generality of our approach by applying it to a different domain.
</details>
<details>
<summary>摘要</summary>
《抽象和逻辑集成体（ARC）》是一个挑战性的标准集，用于推动人工智能研究到人类水平的智能。它是一个具有唯一任务的颜色网格生成的集合，通过一些示例来规定。与现有的变换基本Programs不同，我们引入了对象中心的模型，与人类生成的自然程序相符。我们的模型不仅可以进行预测，还可以提供输入/输出对的共同描述。使用最小描述长度原则进行有效地搜索大型模型空间。我们解决了多种任务，并且学习的模型与自然程序相似。我们在不同领域中应用了我们的方法，以示其通用性。
</details></li>
</ul>
<hr>
<h2 id="The-Development-of-LLMs-for-Embodied-Navigation"><a href="#The-Development-of-LLMs-for-Embodied-Navigation" class="headerlink" title="The Development of LLMs for Embodied Navigation"></a>The Development of LLMs for Embodied Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00530">http://arxiv.org/abs/2311.00530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinzhou Lin, Han Gao, Rongtao Xu, Changwei Wang, Li Guo, Shibiao Xu</li>
<li>for: 本研究主要探讨了大语言模型（LLM）与体际智能的融合，尤其是在导航任务方面。</li>
<li>methods: 本文综述了当前的体际导航模型和研究方法，并评估了现有的导航模型和数据集的优缺点。</li>
<li>results: 研究发现，LLM可以帮助体际智能系统在环境理解和决策方面提供了高级别的支持，并且可以帮助解决许多导航任务。<details>
<summary>Abstract</summary>
In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidates the role of LLMs in embodied intelligence, based on current research, and forecasts future directions in the field. A comprehensive list of studies in this survey is available at https://github.com/Rongtao-Xu/Awesome-LLM-EN
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-impartial-policies-for-sequential-counterfactual-explanations-using-Deep-Reinforcement-Learning"><a href="#Learning-impartial-policies-for-sequential-counterfactual-explanations-using-Deep-Reinforcement-Learning" class="headerlink" title="Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning"></a>Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00523">http://arxiv.org/abs/2311.00523</a></li>
<li>repo_url: None</li>
<li>paper_authors: E. Panagiotou, E. Ntoutsi</li>
<li>for: 这个论文主要针对的是Explainable Artificial Intelligence（XAI）领域中的sequential counterfactual（SCF）例子，它们可以改变一个已经训练的分类器的决策，通过对输入实例进行一系列修改。</li>
<li>methods: 这篇论文使用了Reinforcement Learning（RL）方法，它们的目标是通过学习策略来找到SCF例子，从而提高执行效率。然而，RL问题的形式化，包括状态空间、动作和奖励的规定，经常会存在困难和模糊性。</li>
<li>results: 这篇论文提出了一种使用分类器输出概率来创建更加有用的奖励，以减少不良行为的影响。这种方法可以帮助RL策略更好地适应不同的输入实例，从而提高SCF例子的效果。<details>
<summary>Abstract</summary>
In the field of explainable Artificial Intelligence (XAI), sequential counterfactual (SCF) examples are often used to alter the decision of a trained classifier by implementing a sequence of modifications to the input instance. Although certain test-time algorithms aim to optimize for each new instance individually, recently Reinforcement Learning (RL) methods have been proposed that seek to learn policies for discovering SCFs, thereby enhancing scalability. As is typical in RL, the formulation of the RL problem, including the specification of state space, actions, and rewards, can often be ambiguous. In this work, we identify shortcomings in existing methods that can result in policies with undesired properties, such as a bias towards specific actions. We propose to use the output probabilities of the classifier to create a more informative reward, to mitigate this effect.
</details>
<details>
<summary>摘要</summary>
在可解释人工智能（XAI）领域，顺序Counterfactual（SCF）例子经常用于改变已训练的分类器的决策，通过对输入实例进行序列化 modificaciones。虽然某些测试时算法旨在为每个新实例优化，但是最近的强化学习（RL）方法已经提议用于找到SCFs，从而提高可扩展性。在这种情况下，RL问题的形ulation，包括状态空间、动作和奖励的规定，经常是模糊的。在这个工作中，我们发现了现有方法的缺陷，导致政策具有不жела的性格，如偏爱特定的动作。我们提议使用分类器的输出概率来创建更有用的奖励，以 Mitigate这个效应。
</details></li>
</ul>
<hr>
<h2 id="Efficient-LLM-Inference-on-CPUs"><a href="#Efficient-LLM-Inference-on-CPUs" class="headerlink" title="Efficient LLM Inference on CPUs"></a>Efficient LLM Inference on CPUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00502">http://arxiv.org/abs/2311.00502</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/intel/intel-extension-for-transformers">https://github.com/intel/intel-extension-for-transformers</a></li>
<li>paper_authors: Haihao Shen, Hanwen Chang, Bo Dong, Yu Luo, Hengyu Meng</li>
<li>for: 这篇论文旨在提高大型自然语言处理器（LLM）的部署效率。</li>
<li>methods: 该论文提出了一种有效的方法，通过自动INT4 weight-only量化流程和特制的LLM运行时，提高LLM的推理效率 на CPU 上。</li>
<li>results: 该论文对流行的LLM模型，包括Llama2、Llama和GPT-NeoX，进行了推理性能测试，并显示了在CPU上的极高推理效率。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated remarkable performance and tremendous potential across a wide range of tasks. However, deploying these models has been challenging due to the astronomical amount of model parameters, which requires a demand for large memory capacity and high memory bandwidth. In this paper, we propose an effective approach that can make the deployment of LLMs more efficiently. We support an automatic INT4 weight-only quantization flow and design a special LLM runtime with highly-optimized kernels to accelerate the LLM inference on CPUs. We demonstrate the general applicability of our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase the extreme inference efficiency on CPUs. The code is publicly available at: https://github.com/intel/intel-extension-for-transformers.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经展示了惊人的性能和巨大的潜力，但是部署这些模型却受到了巨大的模型参数数量的限制，需要大量的内存容量和高带宽内存带宽。在这篇论文中，我们提出了一种有效的方法，可以更有效地部署 LLM。我们支持自动INT4Weight只量化流程，并设计了特制LLM运行时，以优化CPU上LLM推理的性能。我们在流行的LLM中，包括Llama2、Llama和GPT-NeoX，进行了普适性评估，并在CPUs上显示了极高的推理效率。代码可以在以下链接获取：https://github.com/intel/intel-extension-for-transformers。
</details></li>
</ul>
<hr>
<h2 id="Intriguing-Properties-of-Data-Attribution-on-Diffusion-Models"><a href="#Intriguing-Properties-of-Data-Attribution-on-Diffusion-Models" class="headerlink" title="Intriguing Properties of Data Attribution on Diffusion Models"></a>Intriguing Properties of Data Attribution on Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00500">http://arxiv.org/abs/2311.00500</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sail-sg/d-trak">https://github.com/sail-sg/d-trak</a></li>
<li>paper_authors: Xiaosen Zheng, Tianyu Pang, Chao Du, Jing Jiang, Min Lin</li>
<li>for: 这paper是为了提出一种能够trace模型输出回训练数据的数据归属方法，以便对高质量或版权 protected的训练样本进行公平资源分配。</li>
<li>methods: 这paper使用了一些理论上的驱动来实现数据归属，包括DDPMs和LoRA-finetuned模型，以及一些ablation study。</li>
<li>results: 研究发现，使用不符合理论假设的设计选择可以在 linear datamodeling 分数和counterfactual评价方面 empirically outperform 之前的基eline。这些结果表明，在非拟合设置下，基于理论假设的建构可能会导致差异ential attribution表现。<details>
<summary>Abstract</summary>
Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a significantly more efficient approach for attributing diffusion models, while the unexpected findings suggest that at least in non-convex settings, constructions guided by theoretical assumptions may lead to inferior attribution performance. The code is available at https://github.com/sail-sg/D-TRAK.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将模型输出追溯到训练数据的过程被称为数据归属。随着扩散模型的发展，数据归属已成为一个愿景模块，以确保数据提供者得到公平的资源分配或版权归属。一些基于理论的方法已经被提议来实现数据归属，以提高计算可扩展性和有效性的贸易OFF。在这个工作中，我们进行了广泛的实验和剥削研究，特别是在DDPMs trained on CIFAR-10和CelebA以及LoRA-finetuned on ArtBench上。Surprisingly,我们发现了不符合理论假设的设计选择在数据归属方面实际上超越了之前的基准值，在线性数据模型评分和对冲检验方面均表现出了明显的改善。我们的工作提供了一种更加高效的数据归属方法，而不期望的发现 suggessthat at least in non-convex settings, constructions guided by theoretical assumptions may lead to inferior attribution performance.代码可以在https://github.com/sail-sg/D-TRAK中找到。
</details></li>
</ul>
<hr>
<h2 id="Bayes-enhanced-Multi-view-Attention-Networks-for-Robust-POI-Recommendation"><a href="#Bayes-enhanced-Multi-view-Attention-Networks-for-Robust-POI-Recommendation" class="headerlink" title="Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation"></a>Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00491">http://arxiv.org/abs/2311.00491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangnan Xia, Yu Yang, Senzhang Wang, Hongzhi Yin, Jiannong Cao, Philip S. Yu</li>
<li>for: 该研究旨在提高POI推荐的精度和可靠性，对于 Location-Based Social Network 服务是重要的。</li>
<li>methods: 该研究使用了 Bayes-enhanced Multi-view Attention Network，包括个人POI转移图、semantic-based POI图和距离-based POI图，以全面模型POI之间的依赖关系。</li>
<li>results: 对于含有噪声和损坏数据的POI推荐问题，BayMAN显著超越了现有方法的性能。<details>
<summary>Abstract</summary>
POI recommendation is practically important to facilitate various Location-Based Social Network services, and has attracted rising research attention recently. Existing works generally assume the available POI check-ins reported by users are the ground-truth depiction of user behaviors. However, in real application scenarios, the check-in data can be rather unreliable due to both subjective and objective causes including positioning error and user privacy concerns, leading to significant negative impacts on the performance of the POI recommendation. To this end, we investigate a novel problem of robust POI recommendation by considering the uncertainty factors of the user check-ins, and proposes a Bayes-enhanced Multi-view Attention Network. Specifically, we construct personal POI transition graph, the semantic-based POI graph and distance-based POI graph to comprehensively model the dependencies among the POIs. As the personal POI transition graph is usually sparse and sensitive to noise, we design a Bayes-enhanced spatial dependency learning module for data augmentation from the local view. A Bayesian posterior guided graph augmentation approach is adopted to generate a new graph with collaborative signals to increase the data diversity. Then both the original and the augmented graphs are used for POI representation learning to counteract the data uncertainty issue. Next, the POI representations of the three view graphs are input into the proposed multi-view attention-based user preference learning module. By incorporating the semantic and distance correlations of POIs, the user preference can be effectively refined and finally robust recommendation results are achieved. The results of extensive experiments show that BayMAN significantly outperforms the state-of-the-art methods in POI recommendation when the available check-ins are incomplete and noisy.
</details>
<details>
<summary>摘要</summary>
POI推荐是实际上非常重要，用于支持不同的Location-Based Social Network服务，近年来受到了研究者的越来越多的关注。现有的工作通常假设用户提供的POI检查入是用户行为的准确描述。然而，在实际应用场景中，检查入数据可能受到用户主观和客观因素的影响，包括定位错误和用户隐私问题，这会导致POI推荐的性能受到显著的负面影响。为了解决这个问题，我们调查了一个新的robust POI推荐问题，并提出了一种基于 Bayes 的多视图注意力网络。具体来说，我们构建了个人POI转移图、semantic-based POI图和距离-based POI图，以全面模型POIs之间的依赖关系。由于个人POI转移图通常是稀疏和敏感于噪声的，我们设计了一种 Bayes 增强的空间相关学习模块，通过地方视图进行数据扩充。然后，我们采用 Bayesian posterior 引导的图生成方法，将原始图和扩充后的图进行POI表示学习，以抵消数据不确定性问题。最后，POI表示三个视图图被输入到我们提出的多视图注意力基于用户喜好学习模块中。通过结合POIs的语义和距离相关性，用户喜好可以得到有效地质量化，并最终实现了robust的POI推荐结果。实验结果表明，BayMANsignificantly exceeds state-of-the-art methods in POI recommendation when the available check-ins are incomplete and noisy.
</details></li>
</ul>
<hr>
<h2 id="Dual-Conditioned-Diffusion-Models-for-Out-Of-Distribution-Detection-Application-to-Fetal-Ultrasound-Videos"><a href="#Dual-Conditioned-Diffusion-Models-for-Out-Of-Distribution-Detection-Application-to-Fetal-Ultrasound-Videos" class="headerlink" title="Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos"></a>Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00469">http://arxiv.org/abs/2311.00469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Divyanshu Mishra, He Zhao, Pramit Saha, Aris T. Papageorghiou, J. Alison Noble</li>
<li>for: 这篇论文的目的是提高机器学习模型的可靠性，通过检测训练集以外的数据点（out-of-distribution，OOD）。</li>
<li>methods: 这篇论文使用了双重定制Diffusion模型（DCDM），通过将模型 conditioned on 训练集的类别信息和输入图像的内在特征，以进行重建基本的OOD检测。</li>
<li>results: 比较reference方法，这篇论文的提案模型在精度、精确度和F1分数方面各有12%、22%和8%的提高。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了双条件 diffusion 模型（DCDM），该模型通过将模型 conditioned 在内部分布类信息和输入图像的隐藏特征上进行恢复基于 OOD 检测。这将导致模型生成的图像具有与内部分布类信息和隐藏特征相同的结构和Semantic 相似性。我们的模型在参考方法的12%提高精度、22%提高精度和8%提高 F1 分数。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Hyperbolic-Embeddings-for-Coarse-to-Fine-Robot-Design"><a href="#Leveraging-Hyperbolic-Embeddings-for-Coarse-to-Fine-Robot-Design" class="headerlink" title="Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design"></a>Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00462">http://arxiv.org/abs/2311.00462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng Dong, Junyu Zhang, Chongjie Zhang</li>
<li>For: 这 paper 的目的是设计多细胞机器人，以便控制其在多种任务上进行高效的执行。* Methods: 该 paper 使用了一种新的粗细到细致的方法，首先优化粗细的机器人，然后逐渐细化。为了解决在粗细转换过程中决定精细化阶段的问题，该 paper 引入了 Hyperbolic Embeddings for Robot Design（HERD）框架。HERD 将机器人各种粒度内部共享一个几何空间，并使用进行优化的 Cross-Entropy Method。* Results: 该 paper 的实验研究表明，该方法在多个复杂任务中表现出了superior的效率和普适性。<details>
<summary>Abstract</summary>
Multi-cellular robot design aims to create robots comprised of numerous cells that can be efficiently controlled to perform diverse tasks. Previous research has demonstrated the ability to generate robots for various tasks, but these approaches often optimize robots directly in the vast design space, resulting in robots with complicated morphologies that are hard to control. In response, this paper presents a novel coarse-to-fine method for designing multi-cellular robots. Initially, this strategy seeks optimal coarse-grained robots and progressively refines them. To mitigate the challenge of determining the precise refinement juncture during the coarse-to-fine transition, we introduce the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies robots of various granularity within a shared hyperbolic space and leverages a refined Cross-Entropy Method for optimization. This framework enables our method to autonomously identify areas of exploration in hyperbolic space and concentrate on regions demonstrating promise. Finally, the extensive empirical studies on various challenging tasks sourced from EvoGym show our approach's superior efficiency and generalization capability.
</details>
<details>
<summary>摘要</summary>
多细胞机器人设计目标是创造由多个细胞组成的机器人，可以高效地控制进行多种任务。过去的研究已经实现了不同任务的机器人设计，但这些方法通常直接在庞大的设计空间中优化机器人，导致机器人的结构变得复杂，控制困难。因此，本文提出了一种新的粗略到细腻的方法 для设计多细胞机器人。首先，这种策略寻找最佳粗略机器人，然后逐步细化它们。为了解决在粗略到细腻的过渡中决定精细化的问题，我们提出了Hyperbolic Embeddings for Robot Design（HERD）框架。HERD将多种细胞机器人集成到共享的虚拟空间中，并利用了改进的十字熵方法进行优化。这个框架使我们的方法可以自动找到在虚拟空间中需要探索的区域，并将焦点集中在示 promise的区域。最后，我们对多个复杂任务来源于EvoGym进行了广泛的实验研究，并证明了我们的方法的更高效和普遍性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Opportunities-of-Green-Computing-A-Survey"><a href="#On-the-Opportunities-of-Green-Computing-A-Survey" class="headerlink" title="On the Opportunities of Green Computing: A Survey"></a>On the Opportunities of Green Computing: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00447">http://arxiv.org/abs/2311.00447</a></li>
<li>repo_url: None</li>
<li>paper_authors: You Zhou, Xiujing Lin, Xiang Zhang, Maolin Wang, Gangwei Jiang, Huakang Lu, Yupeng Wu, Kai Zhang, Zhe Yang, Kehang Wang, Yongduo Sui, Fengwei Jia, Zuoli Tang, Yao Zhao, Hongxuan Zhang, Tiannuo Yang, Weibo Chen, Yunong Mao, Yi Li, De Bao, Yu Li, Hongrui Liao, Ting Liu, Jingwen Liu, Jinchi Guo, Jin Zhao, Xiangyu Zhao, Ying WEI, Hong Qian, Qi Liu, Xiang Wang, Wai Kin, Chan, Chenliang Li, Yusen Li, Shiyu Yang, Jining Yan, Chao Mou, Shuai Han, Wuxia Jin, Guannan Zhang, Xiaodong Zeng</li>
<li>for: 这篇论文旨在提出一种绿色计算技术框架，以提高人工智能发展的可持续性。</li>
<li>methods: 该论文提出了四个关键组成部分：（1）评估绿色程度，（2）能效的人工智能，（3）能效的计算系统，（4）可持续发展的AI应用场景。每个部分都有许多常用的优化技术来提高AI的效率。</li>
<li>results: 该论文认为，通过绿色计算技术，可以解决人工智能发展所带来的资源约束和环境影响问题，并且鼓励更多的研究人员关注这一方向，使人工智能更加环保。<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) has achieved significant advancements in technology and research with the development over several decades, and is widely used in many areas including computing vision, natural language processing, time-series analysis, speech synthesis, etc. During the age of deep learning, especially with the arise of Large Language Models, a large majority of researchers' attention is paid on pursuing new state-of-the-art (SOTA) results, resulting in ever increasing of model size and computational complexity. The needs for high computing power brings higher carbon emission and undermines research fairness by preventing small or medium-sized research institutions and companies with limited funding in participating in research. To tackle the challenges of computing resources and environmental impact of AI, Green Computing has become a hot research topic. In this survey, we give a systematic overview of the technologies used in Green Computing. We propose the framework of Green Computing and devide it into four key components: (1) Measures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing Systems and (4) AI Use Cases for Sustainability. For each components, we discuss the research progress made and the commonly used techniques to optimize the AI efficiency. We conclude that this new research direction has the potential to address the conflicts between resource constraints and AI development. We encourage more researchers to put attention on this direction and make AI more environmental friendly.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在技术和研究方面已经取得了重要进步，并广泛应用于计算视觉、自然语言处理、时间序列分析、语音合成等领域。在深度学习时代，特别是大语言模型的出现，许多研究人员的注意力集中在追求新的State-of-the-Art（SOTA）结果上，导致模型的大小和计算复杂度不断增加。为了解决AI计算资源和环境影响的挑战，绿色计算成为了热点的研究话题。在这篇评论中，我们提供了绿色计算技术的系统性评论，并将其分为四个关键组成部分：（1）绿色指标，（2）能效AI，（3）能效计算系统，（4）可持续性AI应用。对每个组成部分，我们讨论了研究进步和优化AI效率的常用技术。我们认为这新的研究方向有可能解决AI发展和资源约束之间的矛盾。我们鼓励更多研究人员关注这个方向，使AI变得更加环保。
</details></li>
</ul>
<hr>
<h2 id="A-Systematic-Comparison-of-Syllogistic-Reasoning-in-Humans-and-Language-Models"><a href="#A-Systematic-Comparison-of-Syllogistic-Reasoning-in-Humans-and-Language-Models" class="headerlink" title="A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models"></a>A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00445">http://arxiv.org/abs/2311.00445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiwalayo Eisape, MH Tessler, Ishita Dasgupta, Fei Sha, Sjoerd van Steenkiste, Tal Linzen</li>
<li>for: 这个论文主要研究了语言模型是否会受人类逻辑偏见的影响，以及语言模型是否可以超越这些偏见。</li>
<li>methods: 研究者使用了大量的文本数据来训练语言模型，并通过测试这些模型的逻辑能力来 evalute their performance。</li>
<li>results: 研究者发现，较大的语言模型比较符合逻辑规则，但是 même les plus grands modèles commettent des erreurs systématiques, certaines desquelles sont similaires aux biais de la raison humaine, telles que les effets d’ordre et les fausses logiques.<details>
<summary>Abstract</summary>
A central component of rational behavior is logical inference: the process of determining which conclusions follow from a set of premises. Psychologists have documented several ways in which humans' inferences deviate from the rules of logic. Do language models, which are trained on text generated by humans, replicate these biases, or are they able to overcome them? Focusing on the case of syllogisms -- inferences from two simple premises, which have been studied extensively in psychology -- we show that larger models are more logical than smaller ones, and also more logical than humans. At the same time, even the largest models make systematic errors, some of which mirror human reasoning biases such as ordering effects and logical fallacies. Overall, we find that language models mimic the human biases included in their training data, but are able to overcome them in some cases.
</details>
<details>
<summary>摘要</summary>
人类行为中的一个重要组成部分是逻辑推理：从一aset of premises determining which conclusions follow. Psychologists have documented several ways in which humans' inferences deviate from the rules of logic. Do language models, which are trained on text generated by humans, replicate these biases, or are they able to overcome them? Focusing on the case of syllogisms -- inferences from two simple premises, which have been studied extensively in psychology -- we show that larger models are more logical than smaller ones, and also more logical than humans. At the same time, even the largest models make systematic errors, some of which mirror human reasoning biases such as ordering effects and logical fallacies. Overall, we find that language models mimic the human biases included in their training data, but are able to overcome them in some cases.Here's the text with traditional Chinese characters:人类行为中的一个重要组成部分是逻辑推理：从一aset of premises determining which conclusions follow。psychologists have documented several ways in which humans' inferences deviate from the rules of logic。Do language models, which are trained on text generated by humans, replicate these biases, or are they able to overcome them？Focusing on the case of syllogisms -- inferences from two simple premises, which have been studied extensively in psychology -- we show that larger models are more logical than smaller ones, and also more logical than humans。At the same time, even the largest models make systematic errors, some of which mirror human reasoning biases such as ordering effects and logical fallacies。Overall, we find that language models mimic the human biases included in their training data, but are able to overcome them in some cases。
</details></li>
</ul>
<hr>
<h2 id="Improving-Robustness-for-Vision-Transformer-with-a-Simple-Dynamic-Scanning-Augmentation"><a href="#Improving-Robustness-for-Vision-Transformer-with-a-Simple-Dynamic-Scanning-Augmentation" class="headerlink" title="Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation"></a>Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00441">http://arxiv.org/abs/2311.00441</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Kotyan, Danilo Vasconcellos Vargas</li>
<li>For: This paper aims to improve the accuracy and robustness of Vision Transformers (ViT) in computer vision tasks, specifically by introducing a novel augmentation technique called Dynamic Scanning Augmentation.* Methods: The proposed method uses dynamic input sequences to adaptively focus on different patches of an image, which induces significant changes in the attention mechanism of ViT. Four variations of Dynamic Scanning Augmentation are introduced and evaluated.* Results: The proposed method improves the robustness of ViT against adversarial attacks, with one variant showing comparable results to the state-of-the-art. The integration of Dynamic Scanning Augmentation leads to a substantial increase in ViT’s robustness, improving it from 17% to 92% across different types of adversarial attacks.<details>
<summary>Abstract</summary>
Vision Transformer (ViT) has demonstrated promising performance in computer vision tasks, comparable to state-of-the-art neural networks. Yet, this new type of deep neural network architecture is vulnerable to adversarial attacks limiting its capabilities in terms of robustness. This article presents a novel contribution aimed at further improving the accuracy and robustness of ViT, particularly in the face of adversarial attacks. We propose an augmentation technique called `Dynamic Scanning Augmentation' that leverages dynamic input sequences to adaptively focus on different patches, thereby maintaining performance and robustness. Our detailed investigations reveal that this adaptability to the input sequence induces significant changes in the attention mechanism of ViT, even for the same image. We introduce four variations of Dynamic Scanning Augmentation, outperforming ViT in terms of both robustness to adversarial attacks and accuracy against natural images, with one variant showing comparable results. By integrating our augmentation technique, we observe a substantial increase in ViT's robustness, improving it from $17\%$ to $92\%$ measured across different types of adversarial attacks. These findings, together with other comprehensive tests, indicate that Dynamic Scanning Augmentation enhances accuracy and robustness by promoting a more adaptive type of attention. In conclusion, this work contributes to the ongoing research on Vision Transformers by introducing Dynamic Scanning Augmentation as a technique for improving the accuracy and robustness of ViT. The observed results highlight the potential of this approach in advancing computer vision tasks and merit further exploration in future studies.
</details>
<details>
<summary>摘要</summary>
“视力变换器（ViT）在计算机视觉任务中表现出了可塑性，与当前最佳神经网络相当。然而，这种新型深度神经网络架构受到了针对性攻击的限制，增加了其可靠性的问题。本文提出了一种新的贡献，即使用“动态扫描增强”技术来提高ViT的准确率和可靠性，特别是对针对性攻击。我们的详细调查表明，这种动态输入序列的适应性使得ViT的注意机制发生了重要变化，即使用相同的图像。我们提出了四种动态扫描增强的变种，在面对不同类型的针对性攻击和自然图像时都表现出优异的表现。通过将我们的增强技术与ViT结合，我们发现了一个重要的提高，从17%提高到92%，这表明了我们的增强技术对ViT的可靠性和准确率具有显著的改进作用。这些发现，加之其他详细测试，表明了动态扫描增强可以提高ViT的可靠性和准确率，并且推动神经网络的注意机制发展。因此，本研究的结果表明了动态扫描增强的潜在价值，并且值得在未来的研究中进一步探索。”
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Generalization-through-Prioritization-and-Diversity-in-Self-Imitation-Reinforcement-Learning-over-Procedural-Environments-with-Sparse-Rewards"><a href="#Enhanced-Generalization-through-Prioritization-and-Diversity-in-Self-Imitation-Reinforcement-Learning-over-Procedural-Environments-with-Sparse-Rewards" class="headerlink" title="Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards"></a>Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00426">http://arxiv.org/abs/2311.00426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alain Andres, Daochen Zha, Javier Del Ser</li>
<li>for: 本文旨在解决RL中的探索挑战，尤其是在罕见奖励情况下，agent的决策学习能力受到限制。</li>
<li>methods: 本文提出了一种新的自我模仿学习方法，通过存储和重复成功行为来优化探索。但传统的自我模仿学习方法受限于通用环境和高归还率下的泛化问题。本文提出了一些修改来决定保留哪些经验，并在PCG环境中扩展了优先级技术。</li>
<li>results: 我们的实验分析在三个PCG罕见奖励环境中，包括MiniGrid和ProcGen，显示了我们提出的修改带来了新的最佳性能记录在MiniGrid-MultiRoom-N12-S10环境中。<details>
<summary>Abstract</summary>
Exploration poses a fundamental challenge in Reinforcement Learning (RL) with sparse rewards, limiting an agent's ability to learn optimal decision-making due to a lack of informative feedback signals. Self-Imitation Learning (self-IL) has emerged as a promising approach for exploration, leveraging a replay buffer to store and reproduce successful behaviors. However, traditional self-IL methods, which rely on high-return transitions and assume singleton environments, face challenges in generalization, especially in procedurally-generated (PCG) environments. Therefore, new self-IL methods have been proposed to rank which experiences to persist, but they replay transitions uniformly regardless of their significance, and do not address the diversity of the stored demonstrations. In this work, we propose tailored self-IL sampling strategies by prioritizing transitions in different ways and extending prioritization techniques to PCG environments. We also address diversity loss through modifications to counteract the impact of generalization requirements and bias introduced by prioritization techniques. Our experimental analysis, conducted over three PCG sparse reward environments, including MiniGrid and ProcGen, highlights the benefits of our proposed modifications, achieving a new state-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.
</details>
<details>
<summary>摘要</summary>
探索是强化学习（RL）中的基本挑战，尤其在罕见奖励情况下，因为缺乏有用的反馈信号，导致代理人的决策学习受到限制。自我模仿学习（self-IL）已经出现为探索的有力的方法，利用储存和重复成功行为的缓存 buffer。然而，传统的自我模仿学习方法，假设环境是单个的，并且需要高归据转移，具有泛化问题，特别是在生成式环境（PCG）中。因此，新的自我模仿学习方法被提出，以排序经验，但是它们在重要性方面是不充分的，并且不处理存储的示例异常。在这项工作中，我们提议适应性的自我模仿学习抽样策略，根据不同的方式来优先级排序转移，并在PCG环境中扩展优先级技术。此外，我们还解决了多样性损失，通过修改缓存的方式，以及对泛化需求和偏见引入的修正。我们的实验分析，在三个PCG稀热奖励环境中进行，包括MiniGrid和ProcGen，表明我们的提议得到了新的状态Record-of-the-art表现在MiniGrid-MultiRoom-N12-S10环境中。</sys>Note: The text is translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The Traditional Chinese form is used in Taiwan, Hong Kong, and Macau.Here's the translation:探索是强化学习（RL）中的基本挑战，尤其在罕见奖励情况下，因为缺乏有用的反馈信号，导致代理人的决策学习受到限制。自我模仿学习（self-IL）已经出现为探索的有力的方法，利用储存和重复成功行为的缓存 buffer。然而，传统的自我模仿学习方法，假设环境是单个的，并且需要高归据转移，具有泛化问题，特别是在生成式环境（PCG）中。因此，新的自我模仿学习方法被提出，以排序经验，但是它们在重要性方面是不充分的，并且不处理存储的示例异常。在这项工作中，我们提议适应性的自我模仿学习抽样策略，根据不同的方式来优先级排序转移，并在PCG环境中扩展优先级技术。此外，我们还解决了多样性损失，通过修改缓存的方式，以及对泛化需求和偏见引入的修正。我们的实验分析，在三个PCG稀热奖励环境中进行，包括MiniGrid和ProcGen，表明我们的提议得到了新的状态Record-of-the-art表现在MiniGrid-MultiRoom-N12-S10环境中。
</details></li>
</ul>
<hr>
<h2 id="Neural-Implicit-Field-Editing-Considering-Object-environment-Interaction"><a href="#Neural-Implicit-Field-Editing-Considering-Object-environment-Interaction" class="headerlink" title="Neural Implicit Field Editing Considering Object-environment Interaction"></a>Neural Implicit Field Editing Considering Object-environment Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00425">http://arxiv.org/abs/2311.00425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihong Zeng, Zongji Wang, Yuanben Zhang, Weinan Cai, Zehao Cao, Lili Zhang, Yan Guo, Yanhong Zhang, Junyi Liu</li>
<li>for: 三元场景编辑方法基于神经隐藏场景，已经吸引广泛关注，在三元编辑任务中表现出色。但是现有方法通常将物体和场景环境的交互强制合并，导致渲染视图中的场景外观变化不能正确显示。本文提出一种对物体和场景环境相互关注的系统（OSI-aware系统），这是一种新的两树神经渲染系统，考虑到物体和场景环境之间的交互。</li>
<li>methods: 为了从混合汤中获得照明条件，我们成功地将物体和场景环境的交互分解为内在分解方法。在对物体级编辑任务中，我们引入深度地图导航场景填充方法和阴影渲染方法，使用点匹配策略。</li>
<li>results: 我们的新ipeline在Scene editing任务中生成了合理的外观变化，并且在新视图生成任务中实现了竞争性的表现质量。<details>
<summary>Abstract</summary>
The 3D scene editing method based on neural implicit field has gained wide attention. It has achieved excellent results in 3D editing tasks. However, existing methods often blend the interaction between objects and scene environment. The change of scene appearance like shadows is failed to be displayed in the rendering view. In this paper, we propose an Object and Scene environment Interaction aware (OSI-aware) system, which is a novel two-stream neural rendering system considering object and scene environment interaction. To obtain illuminating conditions from the mixture soup, the system successfully separates the interaction between objects and scene environment by intrinsic decomposition method. To study the corresponding changes to the scene appearance from object-level editing tasks, we introduce a depth map guided scene inpainting method and shadow rendering method by point matching strategy. Extensive experiments demonstrate that our novel pipeline produce reasonable appearance changes in scene editing tasks. It also achieve competitive performance for the rendering quality in novel-view synthesis tasks.
</details>
<details>
<summary>摘要</summary>
三维场景编辑方法基于神经隐函数已经受到广泛关注。它在三维编辑任务中表现出色。然而，现有方法经常混合对象和场景环境的交互。改变场景的外观，如阴影，在渲染视图中未能正确显示。在这篇论文中，我们提出了一种对象和场景环境相互响应（OSI-aware）系统，这是一种新的两栈神经渲染系统，考虑到对象和场景环境的交互。通过内在分解方法，我们成功地从混合液中提取了对象和场景环境之间的交互。为了研究对象编辑任务中场景外观的变化，我们引入了深度地图导航的场景填充方法和阴影渲染方法，使用点匹配策略。广泛的实验表明，我们的新ipeline可以在场景编辑任务中生成合理的外观变化，并且在新视图合成任务中实现了竞争性的表现质量。
</details></li>
</ul>
<hr>
<h2 id="Couples-can-be-tractable-New-algorithms-and-hardness-results-for-the-Hospitals-Residents-problem-with-Couples"><a href="#Couples-can-be-tractable-New-algorithms-and-hardness-results-for-the-Hospitals-Residents-problem-with-Couples" class="headerlink" title="Couples can be tractable: New algorithms and hardness results for the Hospitals &#x2F; Residents problem with Couples"></a>Couples can be tractable: New algorithms and hardness results for the Hospitals &#x2F; Residents problem with Couples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00405">http://arxiv.org/abs/2311.00405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gergely Csáji, David Manlove, Iain McBride, James Trimble</li>
<li>for: 本文研究了医院医生婚姻问题（Hospitals&#x2F;Residents problem），具体来说是在医院医生婚姻问题中，夫妻双方的偏好不具有响应性和完整性（sub-responsive and sub-complete）的情况下，提出了一种近似可行的稳定医生婚姻（near-feasible stable matching）算法。</li>
<li>methods: 本文提出了一种基于稳定设备（Stable Fixtures）问题的算法，可以在医院医生婚姻问题中找到近似可行的稳定医生婚姻。此外，本文还提出了一种在某些特殊情况下的另一种算法，可以在医院医生婚姻问题中找到稳定医生婚姻。</li>
<li>results: 本文的算法可以在医院医生婚姻问题中找到近似可行的稳定医生婚姻，并且可以证明这种算法的可行性。此外，本文还证明了医院医生婚姻问题在某些特殊情况下是NP困难的，例如在夫妻双方的偏好不具有响应性和完整性的情况下。<details>
<summary>Abstract</summary>
In this paper we study the {\sc Hospitals / Residents problem with Couples} ({\sc hrc}), where a solution is a stable matching or a report that none exists. We present a novel polynomial-time algorithm that can find a near-feasible stable matching (adjusting the hospitals' capacities by at most 1) in an {\sc hrc} instance where the couples' preferences are sub-responsive (i.e., if one member switches to a better hospital, than the couple also improves) and sub-complete (i.e., each pair of hospitals that are individually acceptable to both members are jointly acceptable for the couple) by reducing it to an instance of the {\sc Stable Fixtures} problem. We also present a polynomial-time algorithm for {\sc hrc} in a sub-responsive, sub-complete instance that is a Dual Market, or where all couples are one of several possible types. We show that our algorithm also implies the polynomial-time solvability of a stable b-matching problem, where the underlying graph is a multigraph with loops.   We complement our algorithms with several hardness results. We show that {\sc hrc} with sub-responsive and sub-complete couples is NP-hard, even with other strong restrictions. We also show that {\sc hrc} with a Dual Market is NP-hard under several simultaneous restrictions. Finally, we show that the problem of finding a matching with the minimum number of blocking pairs in {\sc hrc} is not approximable within $m^{1-\varepsilon}$, for any $\varepsilon>0$, where $m$ is the total length of the hospitals' preference lists, unless P=NP, even if each couple applies to only one pair of hospitals. Our polynomial-time solvability results greatly expand the class of known tractable instances of {\sc hrc} and provide additional evidence as to why long-standing entry-level labour markets that allow couples such as the National Resident Matching Program remain successful to this day.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了医院和住院医生匹配问题（{\sc hrc），其中一个解决方案是稳定匹配或一份无匹配报告。我们提出了一种新的多阶时间算法，可以在{\sc hrc}实例中找到一个近似稳定匹配（通过修改医院容量，最多为1），当伴侣偏好是抑弱响应（即，如果一个成员转移到更好的医院，那么伴侣也会提高）和抑完全（即，每对医院都是对两名成员都可接受的）时。我们还提出了一种多阶时间算法，用于{\sc hrc}实例，其中伴侣偏好是抑弱响应和抑完全，或者是多种类型的 dual market。我们证明了我们的算法也可以解决稳定b匹配问题，其下面的图为多重图。我们补充了一些硬性结果。我们证明了{\sc hrc}中的抑弱抑完全伴侣是NP困难的，即使有其他强制限制。我们还证明了{\sc hrc}中的 dual market 是NP困难的，对于多种同时限制。最后，我们证明了{\sc hrc}中寻找最小数量的堵塞对的匹配是不可以在$m^{1-\varepsilon}$的近似内 approximable，其中$m$ 是所有医院的偏好列表总长度，$\varepsilon$ 是任意小于0的数值，除非P=NP。我们的多阶时间可行性结果扩大了知道的可 tractable{\sc hrc}实例，并提供了更多的证据，证明为什么长期的入门级别劳动市场，如国家住院医生匹配计划，仍然成功至今。
</details></li>
</ul>
<hr>
<h2 id="A-Spatial-Temporal-Transformer-based-Framework-For-Human-Pose-Assessment-And-Correction-in-Education-Scenarios"><a href="#A-Spatial-Temporal-Transformer-based-Framework-For-Human-Pose-Assessment-And-Correction-in-Education-Scenarios" class="headerlink" title="A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios"></a>A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00401">http://arxiv.org/abs/2311.00401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenyang Hu, Kai Liu, Libin Liu, Huiliang Shang</li>
<li>for: 这 papers 的目的是为了在教育场景中进行人体姿势评估和修正，以提供专业、快速纠正反馈给学生。</li>
<li>methods: 这 papers 使用了 Spatial-Temporal Transformer 框架（STTF），包括骨骼跟踪、姿势估计、姿势评估和姿势修正模块，以提供专业、快速纠正反馈给学生。</li>
<li>results: results 表明，我们的模型可以有效地评估和修正学生的动作质量。 STTF 利用 transformer 模型 capture 人体姿势的空间和时间相关性，以提供高精度的评估和修正。<details>
<summary>Abstract</summary>
Human pose assessment and correction play a crucial role in applications across various fields, including computer vision, robotics, sports analysis, healthcare, and entertainment. In this paper, we propose a Spatial-Temporal Transformer based Framework (STTF) for human pose assessment and correction in education scenarios such as physical exercises and science experiment. The framework comprising skeletal tracking, pose estimation, posture assessment, and posture correction modules to educate students with professional, quick-to-fix feedback. We also create a pose correction method to provide corrective feedback in the form of visual aids. We test the framework with our own dataset. It comprises (a) new recordings of five exercises, (b) existing recordings found on the internet of the same exercises, and (c) corrective feedback on the recordings by professional athletes and teachers. Results show that our model can effectively measure and comment on the quality of students' actions. The STTF leverages the power of transformer models to capture spatial and temporal dependencies in human poses, enabling accurate assessment and effective correction of students' movements.
</details>
<details>
<summary>摘要</summary>
人体姿势评估和修正在多个领域中扮演着关键角色，包括计算机视觉、机器人学、体育分析、医疗和娱乐等。在这篇论文中，我们提出了一个空间-时间变换器基础架构（STTF），用于教育场景中的人体姿势评估和修正。该架构包括骨骼跟踪、姿势估计、姿势评估和姿势修正模块，以提供专业、快速修复的反馈。我们还创造了一种姿势修正方法，以Visual化形式提供修正反馈。我们对自己的数据集进行测试，该数据集包括（a）新录制的五种运动，（b）互联网上已有同样运动的录制，以及（c）专业运动员和教师提供的修正反馈。结果表明，我们的模型可以准确地评估和修正学生的动作质量。STTF利用变换器模型来捕捉人体姿势的空间和时间依赖关系，以便准确评估和修正学生的运动。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-deep-neural-networks-with-symbolic-knowledge-Towards-trustworthy-and-interpretable-AI-for-education"><a href="#Augmenting-deep-neural-networks-with-symbolic-knowledge-Towards-trustworthy-and-interpretable-AI-for-education" class="headerlink" title="Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education"></a>Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00393">http://arxiv.org/abs/2311.00393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danial Hooshyar, Roger Azevedo, Yeongwook Yang</li>
<li>for: 这个研究旨在探讨人工神经网络在教育应用中的潜力，并提出一种基于神经符号学的人工智能框架，以解决现有的三大挑战。</li>
<li>methods: 该研究采用了基于神经符号学的人工智能框架，并开发了一种名为NSAI的方法，可以将教育知识注入和提取出深度神经网络中，以模拟学生的计算思维。</li>
<li>results: 研究发现，使用NSAI方法可以提高模型的普适性和可解释性，并且可以避免训练数据中的偏见和控制偏见。此外，NSAI方法还可以提取出规则，以便解释和理解预测的路径，以及改进初始的教育知识。<details>
<summary>Abstract</summary>
Artificial neural networks (ANNs) have shown to be amongst the most important artificial intelligence (AI) techniques in educational applications, providing adaptive educational services. However, their educational potential is limited in practice due to three major challenges: i) difficulty in incorporating symbolic educational knowledge (e.g., causal relationships, and practitioners' knowledge) in their development, ii) learning and reflecting biases, and iii) lack of interpretability. Given the high-risk nature of education, the integration of educational knowledge into ANNs becomes crucial for developing AI applications that adhere to essential educational restrictions, and provide interpretability over the predictions. This research argues that the neural-symbolic family of AI has the potential to address the named challenges. To this end, it adapts a neural-symbolic AI framework and accordingly develops an approach called NSAI, that injects and extracts educational knowledge into and from deep neural networks, for modelling learners computational thinking. Our findings reveal that the NSAI approach has better generalizability compared to deep neural networks trained merely on training data, as well as training data augmented by SMOTE and autoencoder methods. More importantly, unlike the other models, the NSAI approach prioritises robust representations that capture causal relationships between input features and output labels, ensuring safety in learning to avoid spurious correlations and control biases in training data. Furthermore, the NSAI approach enables the extraction of rules from the learned network, facilitating interpretation and reasoning about the path to predictions, as well as refining the initial educational knowledge. These findings imply that neural-symbolic AI can overcome the limitations of ANNs in education, enabling trustworthy and interpretable applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Difficulty in incorporating symbolic educational knowledge (e.g., causal relationships, practitioners’ knowledge) in their development.2. Learning and reflecting biases.3. Lack of interpretability.To address these challenges, this research proposes the use of the neural-symbolic family of AI, which has the potential to integrate educational knowledge into ANNs and provide interpretability over the predictions. The proposed approach, called NSAI, injects and extracts educational knowledge into and from deep neural networks, enabling the modelling of learners’ computational thinking.The findings show that the NSAI approach has better generalizability compared to deep neural networks trained merely on training data, as well as training data augmented by SMOTE and autoencoder methods. Additionally, the NSAI approach prioritizes robust representations that capture causal relationships between input features and output labels, ensuring safety in learning and avoiding spurious correlations and control biases in training data.The NSAI approach also enables the extraction of rules from the learned network, facilitating interpretation and reasoning about the path to predictions, as well as refining the initial educational knowledge. These findings suggest that neural-symbolic AI can overcome the limitations of ANNs in education, enabling trustworthy and interpretable applications.</details></li>
</ol>
<hr>
<h2 id="Will-Code-Remain-a-Relevant-User-Interface-for-End-User-Programming-with-Generative-AI-Models"><a href="#Will-Code-Remain-a-Relevant-User-Interface-for-End-User-Programming-with-Generative-AI-Models" class="headerlink" title="Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?"></a>Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00382">http://arxiv.org/abs/2311.00382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Advait Sarkar</li>
<li>for: 这篇论文探讨了在生成AI时，传统编程语言是否仍然有用于非专业程序员。</li>
<li>methods: 作者提出了“生成转移 гипотезы”，即生成AI会对传统编程语言的范围进行质量和量上的扩展。</li>
<li>results: 作者认为，传统编程语言仍然有用于非专业程序员，并提出了一些可能是永久性和持续性的原因。<details>
<summary>Abstract</summary>
The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which "traditional" programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the "generative shift hypothesis": that generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibility of needing to revisit many well-established core concepts, such as Ko's learning barriers and Blackwell's attention investment model.
</details>
<details>
<summary>摘要</summary>
研究领域内的终端用户编程主要关注在帮助非专业人员学习编程足够好以完成任务。生成AI可能完全替代这一点，允许用户通过自然语言提示生成代码。在这篇文章中，我们探讨了“传统”编程语言在非专业终端编程者的世界中是否仍然有 relevance。我们提出了“生成转变假设”：生成AI会为终端编程带来质量和量上的扩展。我们列出了一些可能使得传统编程语言仍然有用和有价值的原因。我们推测这些原因是不可逆的和普遍存在的，或者可能在进一步改进和创新生成AI时消失。最后，我们提出了对终端编程研究的一些影响，包括可能需要重新评估许多已成为核心概念的事物，如科学学习障碍和黑卫投入模型。
</details></li>
</ul>
<hr>
<h2 id="Architecture-of-Data-Anomaly-Detection-Enhanced-Decentralized-Expert-System-for-Early-Stage-Alzheimer’s-Disease-Prediction"><a href="#Architecture-of-Data-Anomaly-Detection-Enhanced-Decentralized-Expert-System-for-Early-Stage-Alzheimer’s-Disease-Prediction" class="headerlink" title="Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer’s Disease Prediction"></a>Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer’s Disease Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00373">http://arxiv.org/abs/2311.00373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Kambiz Behfar, Qumars Behfar, Marzie Hosseinpour</li>
<li>for: 这篇研究的目的是为了早期准确地检测阿兹海默症，以提高病人的结果。</li>
<li>methods: 这篇研究使用了分布式专家系统，结合了区块chain技术和人工智能，以实现强大的偏差检测。</li>
<li>results: 这篇研究获得了更精确的早期阿兹海默症预测结果，并且保护了患者的隐私和数据完整性。<details>
<summary>Abstract</summary>
Alzheimer's Disease is a global health challenge that requires early and accurate detection to improve patient outcomes. Magnetic Resonance Imaging (MRI) holds significant diagnostic potential, but its effective analysis remains a formidable task. This study introduces a groundbreaking decentralized expert system that cleverly combines blockchain technology with Artificial Intelligence (AI) to integrate robust anomaly detection for patient-submitted data.   Traditional diagnostic methods often lead to delayed and imprecise predictions, especially in the early stages of the disease. Centralized data repositories struggle to manage the immense volumes of MRI data, and persistent privacy concerns hinder collaborative efforts. Our innovative solution harnesses decentralization to protect data integrity and patient privacy, facilitated by blockchain technology. It not only emphasizes AI-driven MRI analysis but also incorporates a sophisticated data anomaly detection architecture. These mechanisms scrutinize patient-contributed data for various issues, including data quality problems and atypical findings within MRI images.   Conducting an exhaustive check of MRI image correctness and quality directly on the blockchain is impractical due to computational complexity and cost constraints. Typically, such checks are performed off-chain, and the blockchain securely records the results. This comprehensive approach empowers our decentralized app to provide more precise early-stage Alzheimer's Disease predictions. By merging the strengths of blockchain, AI, and anomaly detection, our system represents a pioneering step towards revolutionizing disease diagnostics.
</details>
<details>
<summary>摘要</summary>
亚历雷明症是全球医疗挑战，早期检测可以提高患者结果。磁共振成像（MRI）具有诊断潜力，但是有效分析是一项困难任务。本研究推出了一种创新的分布式专家系统，它将区块链技术与人工智能（AI）相结合，以实现强大的异常检测。传统的诊断方法经常导致延迟和不准确的预测，特别是在病情晚期。中央数据存储系统很难处理庞大量的MRI数据，而且持续存在隐私问题，这阻碍了合作努力。我们的创新解决方案利用分布式结构保护数据完整性和患者隐私，通过区块链技术实现。它不仅强调了AI驱动的MRI分析，还包括了复杂的数据异常检测建筑。这些机制对患者提供的数据进行了多种检查，包括数据质量问题和MRI图像中的异常现象。在区块链上直接进行MRI图像正确性和质量检查是计算复杂和成本高的。通常，这些检查在防火墙外进行，并将结果记录在区块链上。这种全面的方法使我们的分布式应用程序可以提供更精确的早期亚历雷明症预测。通过融合区块链、AI和异常检测的优势，我们的系统表明了一种革新的疾病诊断方式。
</details></li>
</ul>
<hr>
<h2 id="Prompt-based-Logical-Semantics-Enhancement-for-Implicit-Discourse-Relation-Recognition"><a href="#Prompt-based-Logical-Semantics-Enhancement-for-Implicit-Discourse-Relation-Recognition" class="headerlink" title="Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition"></a>Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00367">http://arxiv.org/abs/2311.00367</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lalalamdbf/plse_idrr">https://github.com/lalalamdbf/plse_idrr</a></li>
<li>paper_authors: Chenxu Wang, Ping Jian, Mu Huang</li>
<li>for: 本研究旨在提高无Connective的干扰关系识别（IDRR）性能，利用注释感知结构信息提高干扰关系表示。</li>
<li>methods: 我们提出了一种基于提示的逻辑 semantics 增强（PLSE）方法，通过注释预测来注入逻辑知识到预训练语言模型中。</li>
<li>results: 我们的方法在 PDTB 2.0 和 CoNLL16 测试集上实现了出色的表现，与当前状态艺术模型相比。<details>
<summary>Abstract</summary>
Implicit Discourse Relation Recognition (IDRR), which infers discourse relations without the help of explicit connectives, is still a crucial and challenging task for discourse parsing. Recent works tend to exploit the hierarchical structure information from the annotated senses, which demonstrate enhanced discourse relation representations can be obtained by integrating sense hierarchy. Nevertheless, the performance and robustness for IDRR are significantly constrained by the availability of annotated data. Fortunately, there is a wealth of unannotated utterances with explicit connectives, that can be utilized to acquire enriched discourse relation features. In light of such motivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE) method for IDRR. Essentially, our method seamlessly injects knowledge relevant to discourse relation into pre-trained language models through prompt-based connective prediction. Furthermore, considering the prompt-based connective prediction exhibits local dependencies due to the deficiency of masked language model (MLM) in capturing global semantics, we design a novel self-supervised learning objective based on mutual information maximization to derive enhanced representations of logical semantics for IDRR. Experimental results on PDTB 2.0 and CoNLL16 datasets demonstrate that our method achieves outstanding and consistent performance against the current state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
通用话语关系识别（IDRR），即从不带显式连接的语言中推断话语关系，仍然是话语分析中的关键和挑战。现有研究通过使用注释的层次结构信息，以提高话语关系表示。然而，IDRR的性能和可靠性受到注释数据的有限性的限制。幸运的是，有大量未注释的语音句子，它们可以用于获得增强的话语关系特征。根据这种动机，我们提出了一种Prompt-based Logical Semantics Enhancement（PLSE）方法。在这种方法中，我们通过提供提示来注入语言模型中关于话语关系的知识。此外，由于提示基于连接预测表现了本地依赖关系，我们设计了一种新的自主学习目标基于互信息最大化，以提取增强的逻辑 semantics 表示。实验结果表明，我们的方法在 PDTB 2.0 和 CoNLL16 数据集上具有出色的性能和稳定性，并且与当前状态的最佳模型相比，具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Samples-Selection-for-Contrastive-Learning-Mining-of-Potential-Samples"><a href="#Rethinking-Samples-Selection-for-Contrastive-Learning-Mining-of-Potential-Samples" class="headerlink" title="Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples"></a>Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00358">http://arxiv.org/abs/2311.00358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengkui Dong, Xianzhong Long, Yun Li</li>
<li>for: 本文是关于对两个图像是否属于同一类别的预测，通过训练模型使其特征表示尽可能接近或尽可能远离。</li>
<li>methods: 我们的方法是对异常采样进行重新考虑，不同于其他方法，我们的方法更加全面，考虑了两种样本采样方式：首先，对于正样本，我们考虑了通过数据增强获得的扩展样本视图，以及通过数据挖掘获得的采样视图。然后，我们将它们weight和组合使用软和硬权重策略。其次，我们分析了负样本的梯度角度，并最终挖掘出具有中间难度的负样本，即与正样本很近的负样本。</li>
<li>results: 实验结果显示，我们的方法与一些传统自动学习方法相比有明显的优势。我们的方法在CIFAR10、CIFAR100和TinyImagenet上分别达到了88.57%、61.10%和36.69%的top-1准确率。<details>
<summary>Abstract</summary>
Contrastive learning predicts whether two images belong to the same category by training a model to make their feature representations as close or as far away as possible. In this paper, we rethink how to mine samples in contrastive learning, unlike other methods, our approach is more comprehensive, taking into account both positive and negative samples, and mining potential samples from two aspects: First, for positive samples, we consider both the augmented sample views obtained by data augmentation and the mined sample views through data mining. Then, we weight and combine them using both soft and hard weighting strategies. Second, considering the existence of uninformative negative samples and false negative samples in the negative samples, we analyze the negative samples from the gradient perspective and finally mine negative samples that are neither too hard nor too easy as potential negative samples, i.e., those negative samples that are close to positive samples. The experiments show the obvious advantages of our method compared with some traditional self-supervised methods. Our method achieves 88.57%, 61.10%, and 36.69% top-1 accuracy on CIFAR10, CIFAR100, and TinyImagenet, respectively.
</details>
<details>
<summary>摘要</summary>
对比学习预测两个图像是否属于同一类型，通过训练模型使其特征表示为close或far away。在这篇论文中，我们重新思考了如何采样对比学习中的样本，不同于其他方法，我们的方法更加全面，考虑了两个方面的样本：首先，对于正样本，我们考虑了数据增强后得到的扩展样本视图以及通过数据挖掘得到的样本视图。然后，我们将它们权重并合并使用软和硬权重策略。其次，因为负样本中存在无用的负样本和假负样本，我们从Gradient的角度分析负样本，最终挖掘出与正样本最接近的负样本，即不太困难又不太容易的负样本。实验显示，我们的方法与一些传统的自我超vised方法相比，具有显著的优势。我们的方法在CIFAR10、CIFAR100和TinyImagenet上的top-1准确率分别达88.57%、61.10%和36.69%。
</details></li>
</ul>
<hr>
<h2 id="QFree-A-Universal-Value-Function-Factorization-for-Multi-Agent-Reinforcement-Learning"><a href="#QFree-A-Universal-Value-Function-Factorization-for-Multi-Agent-Reinforcement-Learning" class="headerlink" title="QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning"></a>QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00356">http://arxiv.org/abs/2311.00356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rizhong Wang, Huiping Li, Di Cui, Demin Xu</li>
<li>for: 这篇论文是关于多智能体强化学习（MARL）中的中央培训，具体来说是关于在多智能体环境中提取优化的分布式策略的问题。</li>
<li>methods: 本文提出了一种名为QFree的通用价值函数分解方法，该方法基于优势函数的等价条件来保证IGM原则的满足，而不需要额外限制IGM函数的应用范围。这里使用了一种新的混合网络架构和一个新的损失函数来实现该目标。</li>
<li>results: 本文在一个非 monotonic 矩阵游戏场景中证明了QFree的效iveness，并在一个通用多智能体环境SMAC中达到了当前最佳性能。<details>
<summary>Abstract</summary>
Centralized training is widely utilized in the field of multi-agent reinforcement learning (MARL) to assure the stability of training process. Once a joint policy is obtained, it is critical to design a value function factorization method to extract optimal decentralized policies for the agents, which needs to satisfy the individual-global-max (IGM) principle. While imposing additional limitations on the IGM function class can help to meet the requirement, it comes at the cost of restricting its application to more complex multi-agent environments. In this paper, we propose QFree, a universal value function factorization method for MARL. We start by developing mathematical equivalent conditions of the IGM principle based on the advantage function, which ensures that the principle holds without any compromise, removing the conservatism of conventional methods. We then establish a more expressive mixing network architecture that can fulfill the equivalent factorization. In particular, the novel loss function is developed by considering the equivalent conditions as regularization term during policy evaluation in the MARL algorithm. Finally, the effectiveness of the proposed method is verified in a nonmonotonic matrix game scenario. Moreover, we show that QFree achieves the state-of-the-art performance in a general-purpose complex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).
</details>
<details>
<summary>摘要</summary>
中央化训练广泛应用于多智能机器人学习（MARL）中，以确保训练过程的稳定性。一旦获得了联合策略，则需要设计一种值函数分解方法，以EXTRACT optimal的分布式策略，这需要满足个体-全局-最大（IGM）原则。而在加入更多限制于IGM函数类型时，可以帮助满足更复杂的多智能环境的要求，但是这会增加训练更复杂的环境的难度。在这篇论文中，我们提出了QFree，一种通用的值函数分解方法 для MARL。我们首先开发了基于优势函数的数学等价条件，以确保IGM原则不受任何牺牲，从而消除了传统方法的保守性。然后，我们设计了一种更具表达能力的混合网络架构，可以满足等价分解。具体来说，我们开发了一种新的损失函数，通过在MARL算法中考虑等价条件作为正则项来评估策略。最后，我们验证了我们提出的方法的有效性，在非 monotonic 矩阵游戏场景中进行了实验，并在一个通用的复杂 MARL 环境中（Starcraft Multi-Agent Challenge，SMAC）达到了状态之 arts 的性能。
</details></li>
</ul>
<hr>
<h2 id="A-Definition-of-Open-Ended-Learning-Problems-for-Goal-Conditioned-Agents"><a href="#A-Definition-of-Open-Ended-Learning-Problems-for-Goal-Conditioned-Agents" class="headerlink" title="A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents"></a>A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00344">http://arxiv.org/abs/2311.00344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olivier Sigaud, Gianluca Baldassarre, Cedric Colas, Stephane Doncieux, Richard Duro, Nicolas Perrin-Gilbert, Vieri-Giuliano Santucci</li>
<li>for: 本研究旨在解释“开放式学习”这个概念，并提出一种基本的定义。</li>
<li>methods: 本研究使用了基本的概念诠释和问题定义方法，以及开放式学习问题的定义和研究。</li>
<li>results: 本研究提出了一种基于时间无穷horizon的开放式学习元素的定义，并将关注点放在开放式目标返报学习问题上。<details>
<summary>Abstract</summary>
A lot of recent machine learning research papers have "Open-ended learning" in their title. But very few of them attempt to define what they mean when using the term. Even worse, when looking more closely there seems to be no consensus on what distinguishes open-ended learning from related concepts such as continual learning, lifelong learning or autotelic learning. In this paper, we contribute to fixing this situation. After illustrating the genealogy of the concept and more recent perspectives about what it truly means, we outline that open-ended learning is generally conceived as a composite notion encompassing a set of diverse properties. In contrast with these previous approaches, we propose to isolate a key elementary property of open-ended processes, which is to always produce novel elements from time to time over an infinite horizon. From there, we build the notion of open-ended learning problems and focus in particular on the subset of open-ended goal-conditioned reinforcement learning problems, as this framework facilitates the definition of learning a growing repertoire of skills. Finally, we highlight the work that remains to be performed to fill the gap between our elementary definition and the more involved notions of open-ended learning that developmental AI researchers may have in mind.
</details>
<details>
<summary>摘要</summary>
很多 latest machine learning research papers 有 "开放式学习" 在标题中，但很少有人尝试定义这个术语的含义。甚至更糟糕，当更加仔细检查时，没有一致性可以 distinguishing open-ended learning 从related concepts such as continual learning, lifelong learning or autotelic learning。在这篇论文中，我们贡献到解决这个情况。我们首先示出了概念的家谱和更近期的思想，以及open-ended learning 的多样化特征。与之前的方法不同，我们提出了一个关键的 elementary property of open-ended processes，即在无穷远景上不断生成新的元素。从这里，我们构建了 open-ended learning 问题的概念，并特别关注 open-ended goal-conditioned reinforcement learning 问题，因为这种框架可以定义学习不断增长的技能的问题。最后，我们强调需要进一步的工作，以填充开放式学习的概念和developmental AI 研究人员可能有的更复杂的概念之间的差异。
</details></li>
</ul>
<hr>
<h2 id="MetisFL-An-Embarrassingly-Parallelized-Controller-for-Scalable-Efficient-Federated-Learning-Workflows"><a href="#MetisFL-An-Embarrassingly-Parallelized-Controller-for-Scalable-Efficient-Federated-Learning-Workflows" class="headerlink" title="MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows"></a>MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00334">http://arxiv.org/abs/2311.00334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Stripelis, Chrysovalantis Anastasiou, Patrick Toral, Armaghan Asghar, Jose Luis Ambite</li>
<li>for: 这个论文的目的是提出一种基于联合学习（Federated Learning，FL）的新系统，以便提高FL workflow的执行效率。</li>
<li>methods: 这个论文使用了一种新的系统叫做MetisFL，它重新设计了联合学习控制器的操作，以便加速大规模的FL workflow执行。</li>
<li>results: 经验测试表明，MetisFL相比其他状态对的FL系统，在各种复杂的FL workflow中可以提高执行速度10倍。<details>
<summary>Abstract</summary>
A Federated Learning (FL) system typically consists of two core processing entities: the federation controller and the learners. The controller is responsible for managing the execution of FL workflows across learners and the learners for training and evaluating federated models over their private datasets. While executing an FL workflow, the FL system has no control over the computational resources or data of the participating learners. Still, it is responsible for other operations, such as model aggregation, task dispatching, and scheduling. These computationally heavy operations generally need to be handled by the federation controller. Even though many FL systems have been recently proposed to facilitate the development of FL workflows, most of these systems overlook the scalability of the controller. To meet this need, we designed and developed a novel FL system called MetisFL, where the federation controller is the first-class citizen. MetisFL re-engineers all the operations conducted by the federation controller to accelerate the training of large-scale FL workflows. By quantitatively comparing MetisFL against other state-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a 10-fold wall-clock time execution boost across a wide range of challenging FL workflows with increasing model sizes and federation sites.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-Graph-Clustering-via-Meta-Weighting-for-Noisy-Graphs"><a href="#Robust-Graph-Clustering-via-Meta-Weighting-for-Noisy-Graphs" class="headerlink" title="Robust Graph Clustering via Meta Weighting for Noisy Graphs"></a>Robust Graph Clustering via Meta Weighting for Noisy Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00322">http://arxiv.org/abs/2311.00322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hyeonsoojo/metagc">https://github.com/hyeonsoojo/metagc</a></li>
<li>paper_authors: Hyeonsoo Jo, Fanchen Bu, Kijung Shin</li>
<li>for: 本研究旨在提出一种可靠的图 neural network（GNN）基于方法，可以在图中快速寻找有用的群集，并在实际图中进行应用。</li>
<li>methods: 本研究使用GNN来实现图 clustering，并提出了一种基于拓扑学的分解 clustering 损失函数，可以适应不同的图类型和噪声水平。此外，本研究还提出了一种名为MetaGC的方法，可以自适应地调整图元素之间的权重，以便增强GNN的抗噪声能力。</li>
<li>results: 本研究通过实验表明，MetaGC可以在五个真实的图上，即使噪声水平不同，也能够高效地寻找有用的群集，并且在不同的图类型和噪声水平下表现更好于当前state-of-the-art GNN基于方法。<details>
<summary>Abstract</summary>
How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at https://github.com/HyeonsooJo/MetaGC.
</details>
<details>
<summary>摘要</summary>
如何在图中寻找有意义的凝集？图 clustering（即将节点分组到类似的节点集中）是图分析中的基本问题，有各种应用领域。 current studies have shown that graph neural network (GNN) based approaches have promising results for graph clustering. However, we observe that their performance degrades significantly on graphs with noise edges, which are common in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC uses a decomposable clustering loss function, which can be rephrased as the sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We empirically show that MetaGC learns weights as intended and outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at https://github.com/HyeonsooJo/MetaGC.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Lexical-Simplification-with-Context-Augmentation"><a href="#Unsupervised-Lexical-Simplification-with-Context-Augmentation" class="headerlink" title="Unsupervised Lexical Simplification with Context Augmentation"></a>Unsupervised Lexical Simplification with Context Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00310">http://arxiv.org/abs/2311.00310</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takashi Wada, Timothy Baldwin, Jey Han Lau</li>
<li>for: 这个论文是为了提出一种新的无监督词性简化方法，使用只有单语言数据和预训练语言模型。</li>
<li>methods: 该方法使用目标词和其上下文来生成替换词，并使用单语言数据中的其他上下文进行采样。</li>
<li>results: 在英语、葡萄牙语和西班牙语的 TSAR-2022 共享任务上，该模型与其他无监督系统相比显著超越，并在 Ensemble 模型中与 GPT-3.5 组合到达新的状态对。 此外，该模型在 SWORDS 词性替换数据集上得到了新的状态对。<details>
<summary>Abstract</summary>
We propose a new unsupervised lexical simplification method that uses only monolingual data and pre-trained language models. Given a target word and its context, our method generates substitutes based on the target context and also additional contexts sampled from monolingual data. We conduct experiments in English, Portuguese, and Spanish on the TSAR-2022 shared task, and show that our model substantially outperforms other unsupervised systems across all languages. We also establish a new state-of-the-art by ensembling our model with GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution data set, achieving a state-of-the-art result.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的无监督词法简化方法，只使用单语言数据和预训练语言模型。给定目标词和其上下文，我们的方法生成替换基于目标上下文和其他从单语言数据采集的上下文。我们在英语、葡萄牙语和西班牙语的TSAR-2022共同任务上进行了实验，并证明了我们的模型在所有语言上至关重要地超过其他无监督系统。我们还建立了一个新的状态对比，将我们的模型与GPT-3.5进行拼接，最终实现了新的状态纪录。最后，我们对SWORDS词法简化数据集进行了评估，实现了状态纪录。
</details></li>
</ul>
<hr>
<h2 id="From-Image-to-Language-A-Critical-Analysis-of-Visual-Question-Answering-VQA-Approaches-Challenges-and-Opportunities"><a href="#From-Image-to-Language-A-Critical-Analysis-of-Visual-Question-Answering-VQA-Approaches-Challenges-and-Opportunities" class="headerlink" title="From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities"></a>From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00308">http://arxiv.org/abs/2311.00308</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Farhan Ishmam, Md Sakib Hossain Shovon, M. F. Mridha, Nilanjan Dey</li>
<li>for: 这篇论文旨在探讨视觉问答（VQA）领域的多模态任务，包括计算机视觉（CV）和自然语言处理（NLP）等方面，并且旨在根据任何视觉输入生成问题的答案。</li>
<li>methods: 这篇论文涵盖了传统的VQA体系和当代的视语言预训练（VLP）技术，并且提供了一个详细的分类方法来描述VQA的各个方面。</li>
<li>results: 这篇论文不仅概述了VQA领域的历史和发展，还提出了一些当前的挑战和未来的可能的开放问题，以及一些与VQA相关的任务和研究方向。<details>
<summary>Abstract</summary>
The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven't been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field's history, introduces a detailed taxonomy to categorize the facets of VQA, and highlights the recent trends, challenges, and scopes for improvement. We further generalize VQA to multimodal question answering, explore tasks related to VQA, and present a set of open problems for future investigation. The work aims to navigate both beginners and experts by shedding light on the potential avenues of research and expanding the boundaries of the field.
</details>
<details>
<summary>摘要</summary>
Visual Question Answering（VQA）是一个多Modal任务，涉及到计算机视觉（CV）和自然语言处理（NLP）领域，目的是根据任意视觉输入生成问题的答案。随着时间的推移，VQA的范围从原始的大量自然图像集Expanded to synthetic images, video, 3D environments, and other visual inputs。随着大型预训练网络的出现，早期的VQA方法从feature extraction和融合方案转移到了视语言预训练（VLP）技术。然而，没有 Thoroughly comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods。此外，VLP在VQA中的挑战没有得到了充分的探讨，留下了一些未解决的问题。我们的工作提供了VQA领域的一份报告，探讨了VQA的历史、 introduce a detailed taxonomy to categorize the facets of VQA, 和 highlights the recent trends, challenges, and scopes for improvement。我们还扩展了VQA到多 modal question answering, explore related tasks, and present a set of open problems for future investigation。该工作的目的是为 Beginners and experts navigation by shedding light on potential research avenues and expanding the boundaries of the field。
</details></li>
</ul>
<hr>
<h2 id="Inference-of-CO2-flow-patterns-–-a-feasibility-study"><a href="#Inference-of-CO2-flow-patterns-–-a-feasibility-study" class="headerlink" title="Inference of CO2 flow patterns – a feasibility study"></a>Inference of CO2 flow patterns – a feasibility study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00290">http://arxiv.org/abs/2311.00290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhinav Prakash Gahlot, Huseyin Tuna Erdinc, Rafael Orozco, Ziyi Yin, Felix J. Herrmann</li>
<li>for: 这篇论文的目的是为了发展一个可靠的测量和检测方法，以掌握地下储存库中CO2泄漏的可能性，特别是通过预存或人工引起的 faults 在储存库的隔膜中。</li>
<li>methods: 这篇论文使用了 conditional normalizing flow 来检测CO2泄漏，并进行了一系列 numerical experiments 来分析其性能。</li>
<li>results: 根据 numerical experiments 的结果， conditional normalizing flow 可以生成高精度的CO2泄漏推测，并且能够检测到无法推测的泄漏。 however, the uncertainty of the inference is reasonable due to the noise in the seismic data and the lack of precise knowledge of the reservoir’s fluid flow properties.<details>
<summary>Abstract</summary>
As the global deployment of carbon capture and sequestration (CCS) technology intensifies in the fight against climate change, it becomes increasingly imperative to establish robust monitoring and detection mechanisms for potential underground CO2 leakage, particularly through pre-existing or induced faults in the storage reservoir's seals. While techniques such as history matching and time-lapse seismic monitoring of CO2 storage have been used successfully in tracking the evolution of CO2 plumes in the subsurface, these methods lack principled approaches to characterize uncertainties related to the CO2 plumes' behavior. Inclusion of systematic assessment of uncertainties is essential for risk mitigation for the following reasons: (i) CO2 plume-induced changes are small and seismic data is noisy; (ii) changes between regular and irregular (e.g., caused by leakage) flow patterns are small; and (iii) the reservoir properties that control the flow are strongly heterogeneous and typically only available as distributions. To arrive at a formulation capable of inferring flow patterns for regular and irregular flow from well and seismic data, the performance of conditional normalizing flow will be analyzed on a series of carefully designed numerical experiments. While the inferences presented are preliminary in the context of an early CO2 leakage detection system, the results do indicate that inferences with conditional normalizing flows can produce high-fidelity estimates for CO2 plumes with or without leakage. We are also confident that the inferred uncertainty is reasonable because it correlates well with the observed errors. This uncertainty stems from noise in the seismic data and from the lack of precise knowledge of the reservoir's fluid flow properties.
</details>
<details>
<summary>摘要</summary>
全球范围内碳捕捉和储存（CCS）技术的广泛部署，在抗击气候变化的斗争中，已经变得越来越重要，特别是在存储池的封闭或人工激发的承压面上实现坚实的监测和探测机制，以防止地壳下的CO2泄漏。尽管历史匹配和时间lapse声学监测CO2储存已经取得成功，但这些方法缺乏对CO2泄漏的原理风险评估。因此，在风险mitigation中，系统性的风险评估是必要的。以下是为什么：（一）CO2泄漏引起的变化小，声学数据噪音大；（二）常规和不规则（例如泄漏引起的）流程变化小；（三）储存池的物理参数控制流动强烈不均，通常仅可以获得分布型。为了到达可以从井和声学数据中推断常规和不规则流动的表达，我们将分析 conditional normalizing flow的性能。尽管这些推断是CO2泄漏检测系统的初步结果，但结果表明，使用 conditional normalizing flow可以生成高精度的CO2泄漏推断，无论是否存在泄漏。此外，我们还确信这些推断的不确定性是合理的，因为它与观测数据噪音和储存池的流体流动参数的缺乏精确知识相关。这种不确定性来源于声学数据的噪音和储存池的流体流动参数的不确定性。
</details></li>
</ul>
<hr>
<h2 id="Active-Instruction-Tuning-Improving-Cross-Task-Generalization-by-Training-on-Prompt-Sensitive-Tasks"><a href="#Active-Instruction-Tuning-Improving-Cross-Task-Generalization-by-Training-on-Prompt-Sensitive-Tasks" class="headerlink" title="Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks"></a>Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00288">http://arxiv.org/abs/2311.00288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pluslabnlp/active-it">https://github.com/pluslabnlp/active-it</a></li>
<li>paper_authors: Po-Nien Kung, Fan Yin, Di Wu, Kai-Wei Chang, Nanyun Peng</li>
<li>for: 提高自然语言处理器（NLP）模型的适应性和泛化能力，通过训练大量多样化任务中的指令。</li>
<li>methods: 基于提示不确定性的活动指令调整方法，可以快速和效率地选择有优势的任务，以提高模型的表现和泛化能力。</li>
<li>results: 在 NIV2 和 Self-Instruct 数据集上进行实验，与其他基eline策略相比，我们的方法可以具有更好的 OUT-OF- Distribution 泛化性，并且需要训练 fewer 任务。此外，我们还提出了一个任务地图，可以根据提示不确定性和预测概率来分类和诊断任务。<details>
<summary>Abstract</summary>
Instruction tuning (IT) achieves impressive zero-shot generalization results by training large language models (LLMs) on a massive amount of diverse tasks with instructions. However, how to select new tasks to improve the performance and generalizability of IT models remains an open question. Training on all existing tasks is impractical due to prohibiting computation requirements, and randomly selecting tasks can lead to suboptimal performance. In this work, we propose active instruction tuning based on prompt uncertainty, a novel framework to identify informative tasks, and then actively tune the models on the selected tasks. We represent the informativeness of new tasks with the disagreement of the current model outputs over perturbed prompts. Our experiments on NIV2 and Self-Instruct datasets demonstrate that our method consistently outperforms other baseline strategies for task selection, achieving better out-of-distribution generalization with fewer training tasks. Additionally, we introduce a task map that categorizes and diagnoses tasks based on prompt uncertainty and prediction probability. We discover that training on ambiguous (prompt-uncertain) tasks improves generalization while training on difficult (prompt-certain and low-probability) tasks offers no benefit, underscoring the importance of task selection for instruction tuning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Knowledge-Infused-Prompting-Assessing-and-Advancing-Clinical-Text-Data-Generation-with-Large-Language-Models"><a href="#Knowledge-Infused-Prompting-Assessing-and-Advancing-Clinical-Text-Data-Generation-with-Large-Language-Models" class="headerlink" title="Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models"></a>Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00287">http://arxiv.org/abs/2311.00287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, Wei Jin, Joyce Ho, Carl Yang</li>
<li>for: 这个论文旨在提出一种可以解决专业医学语言处理领域中的特殊挑战，例如专业医学术语和临床观点的方法。</li>
<li>methods: 这篇论文使用了大型自然语言模型（LLM）来解决这些挑战。然而，直接使用LLM可能会带来隐私问题和资源问题。因此，作者们提出了一种创新的、资源有效的方法，即ClinGen。</li>
<li>results: 作者们的实验表明，ClinGen可以对7种临床自然语言处理任务和16个数据集进行改进表现，并将临床主题和写作风格从外部领域专门知识库和LLM中引入到数据生成过程中。这些生成的训练例子具有更高的多样性和更好的适应能力。<details>
<summary>Abstract</summary>
Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the diversity of generated training instances. We will publish our code and all the generated data in \url{https://github.com/ritaranx/ClinGen}.
</details>
<details>
<summary>摘要</summary>
临床自然语言处理需要特有的方法来处理医疗领域特有的挑战，如复杂的医疗术语和临床背景。最近，大型自然语言模型（LLM）已经在这个领域表现了承诺。然而，直接部署LLM可能会导致隐私问题并受到资源限制。为了解决这个挑战，我们开发了一种创新的资源效率高的方法，名为ClinGen。我们的模型包括临床知识EXTRACT和上下文知识支持的LLM唤醒。两者都来自于外部医疗领域特定的知识图和LLM，以引导数据生成。我们的广泛的实验研究 across 7 临床自然语言处理任务和 16 个数据集表明，ClinGen能够在不同任务中均提高性能，并准确地对各个实际数据集进行分布对应。我们将在 \url{https://github.com/ritaranx/ClinGen} 上发布我们的代码和所有生成的数据。
</details></li>
</ul>
<hr>
<h2 id="JADE-A-Linguistic-based-Safety-Evaluation-Platform-for-LLM"><a href="#JADE-A-Linguistic-based-Safety-Evaluation-Platform-for-LLM" class="headerlink" title="JADE: A Linguistic-based Safety Evaluation Platform for LLM"></a>JADE: A Linguistic-based Safety Evaluation Platform for LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00286">http://arxiv.org/abs/2311.00286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mi Zhang, Xudong Pan, Min Yang</li>
<li>for: 这个论文旨在提出一种名为“JADE”的语言模型攻击平台，用于同时破坏多种广泛使用的中文和英文语言模型（CLMs）。</li>
<li>methods: JADE使用词法生成和转换规则来增加语句结构的复杂性，直到破坏CLMs的安全保障。</li>
<li>results: JADE在8种开源中文CLMs、6种商业中文CLMs和4种商业英文CLMs上 simultanously破坏了大量CLMs，得到了高达70%的不安全生成率（请参见下面的表），而且这些问题仍然是自然、流畅的语言表达。<details>
<summary>Abstract</summary>
In this paper, we present \textit{JADE}, a targeted linguistic fuzzing platform which strengthens the linguistic complexity of seed questions to simultaneously and consistently break a wide range of widely-used LLMs categorized in three groups: eight open-sourced Chinese, six commercial Chinese and four commercial English LLMs. JADE generates three safety benchmarks for the three groups of LLMs, which contain unsafe questions that are highly threatening: the questions simultaneously trigger harmful generation of multiple LLMs, with an average unsafe generation ratio of \textbf{$70\%$} (please see the table below), while are still natural questions, fluent and preserving the core unsafe semantics. We release the benchmark demos generated for commercial English LLMs and open-sourced English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For readers who are interested in evaluating on more questions generated by JADE, please contact us.   \textit{JADE} is based on Noam Chomsky's seminal theory of transformational-generative grammar. Given a seed question with unsafe intention, \textit{JADE} invokes a sequence of generative and transformational rules to increment the complexity of the syntactic structure of the original question, until the safety guardrail is broken. Our key insight is: Due to the complexity of human language, most of the current best LLMs can hardly recognize the invariant evil from the infinite number of different syntactic structures which form an unbound example space that can never be fully covered. Technically, the generative/transformative rules are constructed by native speakers of the languages, and, once developed, can be used to automatically grow and transform the parse tree of a given question, until the guardrail is broken. For more evaluation results and demo, please check our website: https://whitzard-ai.github.io/jade.html.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一个名为\textit{JADE}的目标语言杂化平台，用于同时、一致地击碎广泛使用的多种中文、英文语言模型（LLMs）。\textit{JADE} 使用诸如词汇、句子结构等语言特征来增加语言模型的复杂性，以生成高危害性询问，让模型同时出现多种 unsafe 行为。我们为三类 LLMS 生成了三个安全基准，包括八种开源中文、六种商用中文以及四种商用英文 LLMS。这些基准包含了高危害性的询问，可以同时触发多种 LLMS 的危险生成，其中 unsafe 生成率平均为 \textbf{70%}（请参考下面的表），但是这些询问仍然是自然、流畅的、保留了核心 unsafe  semantics。我们在以下链接中发布了对商用英文 LLMS 和开源英文 LLMS 的示例生成：https://github.com/whitzard-ai/jade-db。对于更多由 \textit{JADE} 生成的询问 interested readers，请与我们联系。\textit{JADE} 基于诺曼·舍契克的 transformational-generative grammar 理论。给定一个带有危险意图的种子问题，\textit{JADE} 采用一系列生成和转换规则，逐渐增加种子问题的语法结构复杂度，直到安全防护墙被破坏。我们的关键发现是：由于人类语言的复杂性，当前最佳 LLMS 很难从无穷多种不同的语法结构中识别人类语言的恶势力。技术上，生成/转换规则由本地语言专家构建，并一旦开发，可以自动增长和转换给定问题的 parse tree，直到安全防护墙被破坏。更多评估结果和示例，请查看我们的网站：https://whitzard-ai.github.io/jade.html。
</details></li>
</ul>
<hr>
<h2 id="Re-Scoring-Using-Image-Language-Similarity-for-Few-Shot-Object-Detection"><a href="#Re-Scoring-Using-Image-Language-Similarity-for-Few-Shot-Object-Detection" class="headerlink" title="Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection"></a>Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00278">http://arxiv.org/abs/2311.00278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Jae Jung, Seung Dae Han, Joohee Kim</li>
<li>for: 这个论文主要关注在几shot object detection领域，探讨如何对于新的物品进行检测，并且使用几少标签进行标识。</li>
<li>methods: 本论文提出了一个名为RISF（Re-scoring using Image-language Similarity for Few-shot object detection）的方法，它将Faster R-CNN扩展为引入Calibration Module using CLIP（CM-CLIP）和Background Negative Re-scale Loss（BNRL），以改善几shot object detection的性能。</li>
<li>results: 实验结果显示，RISF方法在MS-COCO和PASCAL VOC等 dataset上实现了与现有方法相比的优秀性能，并且超越了现有的方法。<details>
<summary>Abstract</summary>
Few-shot object detection, which focuses on detecting novel objects with few labels, is an emerging challenge in the community. Recent studies show that adapting a pre-trained model or modified loss function can improve performance. In this paper, we explore leveraging the power of Contrastive Language-Image Pre-training (CLIP) and hard negative classification loss in low data setting. Specifically, we propose Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends Faster R-CNN by introducing Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL). The former adapts CLIP, which performs zero-shot classification, to re-score the classification scores of a detector using image-class similarities, the latter is modified classification loss considering the punishment for fake backgrounds as well as confusing categories on a generalized few-shot object detection dataset. Extensive experiments on MS-COCO and PASCAL VOC show that the proposed RISF substantially outperforms the state-of-the-art approaches. The code will be available.
</details>
<details>
<summary>摘要</summary>
几shot对象检测，关注使用少量标签检测新对象，是当前社区的一个emerging挑战。Recent studies show that modifying a pre-trained model or loss function can improve performance. 在这篇论文中，我们探索利用Contrastive Language-Image Pre-training (CLIP) 和困难的负类别损失来提高在低数据设置下的性能。我们提出了使用Image-language Similarity for Few-shot object detection (RISF)，它是一种基于Faster R-CNN的扩展，包括Calibration Module using CLIP (CM-CLIP) 和Background Negative Re-scale Loss (BNRL)。前者利用CLIP，可以在零shot类别上进行分类，对检测器的分类分数进行重新评分，而后者是一种修改的分类损失函数，考虑了虚假背景以及混淆类别的罚款。在MS-COCO和PASCAL VOC上进行了广泛的实验，结果表明，提出的RISF在状态之前的方法中具有显著的优势。代码将被公开。
</details></li>
</ul>
<hr>
<h2 id="ChatCoder-Chat-based-Refine-Requirement-Improves-LLMs’-Code-Generation"><a href="#ChatCoder-Chat-based-Refine-Requirement-Improves-LLMs’-Code-Generation" class="headerlink" title="ChatCoder: Chat-based Refine Requirement Improves LLMs’ Code Generation"></a>ChatCoder: Chat-based Refine Requirement Improves LLMs’ Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00272">http://arxiv.org/abs/2311.00272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zejun Wang, Jia Li, Ge Li, Zhi Jin</li>
<li>for: 提高大型自然语言处理模型对人类需求的理解和代码生成性能。</li>
<li>methods: 提出了一种叫做ChatCoder的方法，通过与大型自然语言处理模型进行聊天来使人类需求更加精确、不ambiguous和完整。</li>
<li>results: 实验表明，使用ChatCoder可以大幅提高现有大型自然语言处理模型的性能，并且比较于修改基于方法和人类回应进行 Fine-tuning 的方法更有优势。<details>
<summary>Abstract</summary>
Large language models have shown good performances in generating code to meet human requirements. However, human requirements expressed in natural languages can be vague, incomplete, and ambiguous, leading large language models to misunderstand human requirements and make mistakes. Worse, it is difficult for a human user to refine the requirement. To help human users refine their requirements and improve large language models' code generation performances, we propose ChatCoder: a method to refine the requirements via chatting with large language models. We design a chat scheme in which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. Experiments show that ChatCoder has improved existing large language models' performance by a large margin. Besides, ChatCoder has the advantage over refine-based methods and LLMs fine-tuned via human response.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型已经表现出良好的代码生成能力，但是人类需求表达在自然语言中可能是模糊不清、缺失部分和抽象的，导致大型自然语言模型会错误理解人类需求，生成错误代码。 worse, it is difficult for a human user to refine the requirement. 为了帮助人类用户更正他们的需求和提高大型自然语言模型的代码生成性能，我们提出了 ChatCoder：一种通过与大型自然语言模型聊天来修正需求的方法。我们设计了一种聊天方案，在which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. 实验显示，ChatCoder 已经提高了现有的大型自然语言模型性能，并且具有与修改基于方法和 LLMS 细化 via human response 的优势。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Decision-Transformer-via-Hierarchical-Reinforcement-Learning"><a href="#Rethinking-Decision-Transformer-via-Hierarchical-Reinforcement-Learning" class="headerlink" title="Rethinking Decision Transformer via Hierarchical Reinforcement Learning"></a>Rethinking Decision Transformer via Hierarchical Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00267">http://arxiv.org/abs/2311.00267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Ma, Chenjun Xiao, Hebin Liang, Jianye Hao</li>
<li>for: 这个论文旨在探讨决策变换器（DT）在强化学习中的应用，以及如何使用高级和低级政策来实现适用性的拼接。</li>
<li>methods: 该论文提出了一种基于层次RL的批处理模型框架，其中高级政策在做出决策时提出一个理想的提示，而低级政策则根据提示生成动作。</li>
<li>results: 实验结果显示，提出的算法在多个控制和导航 benchmark 上表现出色，大大超过了DT。<details>
<summary>Abstract</summary>
Decision Transformer (DT) is an innovative algorithm leveraging recent advances of the transformer architecture in reinforcement learning (RL). However, a notable limitation of DT is its reliance on recalling trajectories from datasets, losing the capability to seamlessly stitch sub-optimal trajectories together. In this work we introduce a general sequence modeling framework for studying sequential decision making through the lens of Hierarchical RL. At the time of making decisions, a high-level policy first proposes an ideal prompt for the current state, a low-level policy subsequently generates an action conditioned on the given prompt. We show DT emerges as a special case of this framework with certain choices of high-level and low-level policies, and discuss the potential failure of these choices. Inspired by these observations, we study how to jointly optimize the high-level and low-level policies to enable the stitching ability, which further leads to the development of new offline RL algorithms. Our empirical results clearly show that the proposed algorithms significantly surpass DT on several control and navigation benchmarks. We hope our contributions can inspire the integration of transformer architectures within the field of RL.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Plug-and-Play-Policy-Planner-for-Large-Language-Model-Powered-Dialogue-Agents"><a href="#Plug-and-Play-Policy-Planner-for-Large-Language-Model-Powered-Dialogue-Agents" class="headerlink" title="Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents"></a>Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00262">http://arxiv.org/abs/2311.00262</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Deng, Wenxuan Zhang, Wai Lam, See-Kiong Ng, Tat-Seng Chua</li>
<li>for: 提高语言模型（LLM）的对话活跃性，即使在对话政策规划方面存在挑战。</li>
<li>methods: 我们提出了一种新的对话政策规划方法，称为PPDPP，它使用可调整的语言模型插件作为对话政策规划器。我们还开发了一个新的训练框架，以便在可用的人类标注数据上进行经过监督的精度调整，以及基于目标帮助AI反馈的强化学习。</li>
<li>results: PPDPP在三种不同的主动对话应用程序上取得了卓越的表现，包括谈判、情感支持和教学对话。对比 existed 方法，PPDPP 能够持续和substantially 提高对话系统的政策规划能力。<details>
<summary>Abstract</summary>
Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play simulation. In this manner, the LLM-powered dialogue agent can not only be generalized to different cases after the training, but also be applicable to different applications by just substituting the learned plug-in. In addition, we propose to evaluate the policy planning capability of dialogue systems under the interactive setting. Experimental results demonstrate that PPDPP consistently and substantially outperforms existing approaches on three different proactive dialogue applications, including negotiation, emotional support, and tutoring dialogues.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese大型语言模型（LLM）的对话政策规划是一个实用又挑战的对话问题，对话政策规划是提高LLM的对话性能的关键。现有的研究通过不同的提示方案或逐步增强LLM的对话政策规划能力，但这些方法都受到对话政策规划的能力限制或困难将其转移到新的情况下。在这个研究中，我们将引入一个新的对话政策规划方法，以便LLM在进行主动对话问题时能够更好地策略。具体来说，我们开发了一个新的训练框架，以便在可用的人类标注数据上进行监督精致训练，以及从目标导向的AI反馈中获得动力学学习。这样，LLM对话代理人不仅能够在训练后应用到不同的情况，而且能够适用于不同的应用程序，只需要替代学习的插件。此外，我们建议评估对话系统的政策规划能力在互动设定下。实验结果显示，PPDPP与现有方法相比，在三个不同的主动对话应用中具有显著的性能优势。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Implicit-biases-in-multitask-and-continual-learning-from-a-backward-error-analysis-perspective"><a href="#Implicit-biases-in-multitask-and-continual-learning-from-a-backward-error-analysis-perspective" class="headerlink" title="Implicit biases in multitask and continual learning from a backward error analysis perspective"></a>Implicit biases in multitask and continual learning from a backward error analysis perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00235">http://arxiv.org/abs/2311.00235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benoit Dherin</li>
<li>for: 这 paper 描述了使用 backward error analysis 计算深度学习模型在多任务和继续学习设置中的隐式培训偏好。</li>
<li>methods: 这 paper 使用了 Stochastic Gradient Descent (SGD) 进行训练，并 derive 了一些修改后的损失函数，以便在训练中隐式地减少模型的偏好。这些损失函数包括原始损失、抽象趋向正则化项和对抗项。</li>
<li>results: 这 paper 得到了一些有趣的结果，包括在多任务和继续学习设置中，模型的隐式培训偏好会导致模型在某些情况下偏离原始损失函数的目标。此外，paper 还提出了一种基于 Lie браcket 的新方法来解决这些问题。<details>
<summary>Abstract</summary>
Using backward error analysis, we compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. In particular, we derive modified losses that are implicitly minimized during training. They have three terms: the original loss, accounting for convergence, an implicit flatness regularization term proportional to the learning rate, and a last term, the conflict term, which can theoretically be detrimental to both convergence and implicit regularization. In multitask, the conflict term is a well-known quantity, measuring the gradient alignment between the tasks, while in continual learning the conflict term is a new quantity in deep learning optimization, although a basic tool in differential geometry: The Lie bracket between the task gradients.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)使用反向错误分析，我们计算了多任务和继续学习中神经网络在使用柯布随机梯度下逐步训练时的隐式偏见。特别是，我们得到了修改后的损失函数，其中包括原始损失、 converge 的损失、隐式平滑化正则化项和对tasks的斜率的斜率对应的对抗项。在多任务中，对抗项是已知的量，测量任务的梯度对齐度，而在继续学习中，对抗项是深度学习优化中的新量，它是 diferencial geometry 中的 Lie 括趟。
</details></li>
</ul>
<hr>
<h2 id="StableFDG-Style-and-Attention-Based-Learning-for-Federated-Domain-Generalization"><a href="#StableFDG-Style-and-Attention-Based-Learning-for-Federated-Domain-Generalization" class="headerlink" title="StableFDG: Style and Attention Based Learning for Federated Domain Generalization"></a>StableFDG: Style and Attention Based Learning for Federated Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00227">http://arxiv.org/abs/2311.00227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jungwuk Park, Dong-Jun Han, Jinho Kim, Shiqiang Wang, Christopher G. Brinton, Jaekyun Moon</li>
<li>for: 提高 federated learning 中的领域泛化能力，即在多个不同领域的数据上训练模型，并在新的领域上进行测试和应用。</li>
<li>methods: 提出了一种基于样式和注意力的学习策略，即样式基本学习和注意力强调方法，以便在数据穿梭和数据缺乏的情况下提高领域泛化能力。</li>
<li>results: 实验结果表明，相比现有基elines，StableFDG在多个领域泛化标准 benchmark 上表现出色，demonstrating its efficacy。<details>
<summary>Abstract</summary>
Traditional federated learning (FL) algorithms operate under the assumption that the data distributions at training (source domains) and testing (target domain) are the same. The fact that domain shifts often occur in practice necessitates equipping FL methods with a domain generalization (DG) capability. However, existing DG algorithms face fundamental challenges in FL setups due to the lack of samples/domains in each client's local dataset. In this paper, we propose StableFDG, a style and attention based learning strategy for accomplishing federated domain generalization, introducing two key contributions. The first is style-based learning, which enables each client to explore novel styles beyond the original source domains in its local dataset, improving domain diversity based on the proposed style sharing, shifting, and exploration strategies. Our second contribution is an attention-based feature highlighter, which captures the similarities between the features of data samples in the same class, and emphasizes the important/common characteristics to better learn the domain-invariant characteristics of each class in data-poor FL scenarios. Experimental results show that StableFDG outperforms existing baselines on various DG benchmark datasets, demonstrating its efficacy.
</details>
<details>
<summary>摘要</summary>
传统的联合学习（FL）算法假设训练（源频谱）和测试（目标频谱）数据分布相同。然而，在实际应用中，频谱转换经常发生，这导致了 equip FL 方法具备频谱泛化（DG）能力的需求。然而，现有的 DG 算法在 FL 设置中存在fundamental 挑战，因为每个客户端的本地数据集中缺乏样本/频谱。在这篇论文中，我们提出了StableFDG，一种风格和注意力基于的学习策略，用于实现联合频谱泛化。我们的两个贡献是：1. 风格学习，允许每个客户端在本地数据集中探索新的风格，提高频谱多样性基于我们提议的风格分享、转移和探索策略。2. 注意力基于的特征强调器，可以捕捉数据amples中相同类型的特征之间的相似性，并强调重要/共同特征，以更好地学习数据穷FL场景中的频谱不变特征。我们的实验结果表明，StableFDG 超过了现有的基准点，在多个 DG benchmark 数据集上表现出色，证明其效果。
</details></li>
</ul>
<hr>
<h2 id="Domain-decomposition-based-coupling-of-physics-informed-neural-networks-via-the-Schwarz-alternating-method"><a href="#Domain-decomposition-based-coupling-of-physics-informed-neural-networks-via-the-Schwarz-alternating-method" class="headerlink" title="Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method"></a>Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00224">http://arxiv.org/abs/2311.00224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Will Snyder, Irina Tezaur, Christopher Wentland</li>
<li>for: 这个论文主要是研究如何使用物理约束的神经网络（PINN）解决非线性偏微分方程（PDE），并与传统的神经网络（NN）相比，PINN可以在解决难题上表现出更好的性能。</li>
<li>methods: 这篇论文使用的方法是将PINN分解成多个子域PINN，并使用Schwarz alternate方法来将这些子域PINN相互连接。在这个过程中， authors investigate了不同的 Dirichlet边界条件的实现方式，以提高PINN的训练效率。</li>
<li>results: 研究发现，在高Peclet数下，使用Schwarz alternate方法可以大幅提高PINN的训练效率，并且可以在一定程度上改善PINN的性能。然而，authors还发现，在某些情况下，强制实施Schwarz边界条件并不一定能够加速PINN的训练。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) are appealing data-driven tools for solving and inferring solutions to nonlinear partial differential equations (PDEs). Unlike traditional neural networks (NNs), which train only on solution data, a PINN incorporates a PDE's residual into its loss function and trains to minimize the said residual at a set of collocation points in the solution domain. This paper explores the use of the Schwarz alternating method as a means to couple PINNs with each other and with conventional numerical models (i.e., full order models, or FOMs, obtained via the finite element, finite difference or finite volume methods) following a decomposition of the physical domain. It is well-known that training a PINN can be difficult when the PDE solution has steep gradients. We investigate herein the use of domain decomposition and the Schwarz alternating method as a means to accelerate the PINN training phase. Within this context, we explore different approaches for imposing Dirichlet boundary conditions within each subdomain PINN: weakly through the loss and/or strongly through a solution transformation. As a numerical example, we consider the one-dimensional steady state advection-diffusion equation in the advection-dominated (high Peclet) regime. Our results suggest that the convergence of the Schwarz method is strongly linked to the choice of boundary condition implementation within the PINNs being coupled. Surprisingly, strong enforcement of the Schwarz boundary conditions does not always lead to a faster convergence of the method. While it is not clear from our preliminary study that the PINN-PINN coupling via the Schwarz alternating method accelerates PINN convergence in the advection-dominated regime, it reveals that PINN training can be improved substantially for Peclet numbers as high as 1e6 by performing a PINN-FOM coupling.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks (PINNs) 是一种有appeal的数据驱动工具，用于解决和推算非线性偏微分方程（PDEs）的解。与传统的神经网络（NNs）不同，PINNs在训练过程中不仅学习解数据，还包含PDE的剩余在损失函数中，并在一组嵌入点上进行训练，以确定解的最佳值。本文研究了使用Schwarz分解法将PINNs与其他PINNs和传统的数值模型（例如，基于finite element、finite difference或finite volume方法获得的全序模型，FOMs）集成，以便解决物理领域的问题。尽管训练PINNs可能在PDE解有急剧的梯度时具有挑战，但我们在这种情况下研究了使用域 decompositions和Schwarz分解法来加速PINNs训练阶段。我们还研究了在每个子域PINN中如何强制实施 Dirichlet 边界条件：通过损失函数和/或解转换。作为数字例子，我们考虑了一个一维稳定状态液体运动-扩散方程在扩散主导（高Peclet） режим下。我们的结果表明，Schwarz法的收敛与PINNs之间的边界条件实现方式有着强关系。虽然强制实施Schwarz边界条件可能不一定加速方法的收敛，但我们发现，在Peclet数为1e6的情况下，通过PINN-FOM coupling可以提高PINN训练的效果。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Capture-Public-Opinion-about-Global-Warming-An-Empirical-Assessment-of-Algorithmic-Fidelity-and-Bias"><a href="#Can-Large-Language-Models-Capture-Public-Opinion-about-Global-Warming-An-Empirical-Assessment-of-Algorithmic-Fidelity-and-Bias" class="headerlink" title="Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias"></a>Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00217">http://arxiv.org/abs/2311.00217</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Lee, T. Q. Peng, M. H. Goldberg, S. A. Rosenthal, J. E. Kotcher, E. W. Maibach, A. Leiserowitz</li>
<li>for: 这个研究用于评估大语言模型（LLM）在社会科学研究中的算法准确性和偏见。</li>
<li>methods: 该研究使用了两份国家代表性气候变化调查来使用LLM模拟问卷回答。LLM被定制了以 Conditioned on demographics和&#x2F;或心理covariates来模拟调查回答。</li>
<li>results: 研究发现LLM可以有效地捕捉总统选举行为，但在不包含相关covariates时难以准确表达全球暖化观点。GPT-4在包含 both demographics和covariates时表现出了改进的性能。然而，在某些群体的观点上存在偏见，LLMs tend to underestimate黑美国人对全球暖化的担忧。这些结果 highlights the potential of LLMs in social science research, but also underscores the importance of careful conditioning, model selection, survey question format, and bias assessment when using LLMs for survey simulation.<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of meticulous conditioning, model selection, survey question format, and bias assessment when employing LLMs for survey simulation. Further investigation into prompt engineering and algorithm auditing is essential to harness the power of LLMs while addressing their inherent limitations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Consistent-Video-to-Video-Transfer-Using-Synthetic-Dataset"><a href="#Consistent-Video-to-Video-Transfer-Using-Synthetic-Dataset" class="headerlink" title="Consistent Video-to-Video Transfer Using Synthetic Dataset"></a>Consistent Video-to-Video Transfer Using Synthetic Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00213">http://arxiv.org/abs/2311.00213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Cheng, Tianjun Xiao, Tong He</li>
<li>for: 文章 targets 文本基于视频编辑 tasks, eliminating the need for resource-intensive per-video-per-model fine-tuning.</li>
<li>methods: 方法基于一个 Synthetic Paired Video Dataset  tailored for video-to-video transfer tasks, inspired by Instruct Pix2Pix’s image transfer via editing instruction.</li>
<li>results: 方法 surpasses current methods like Tune-A-Video, marking significant progress in text-based video-to-video editing and opening up exciting avenues for further exploration and deployment.<details>
<summary>Abstract</summary>
We introduce a novel and efficient approach for text-based video-to-video editing that eliminates the need for resource-intensive per-video-per-model finetuning. At the core of our approach is a synthetic paired video dataset tailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's image transfer via editing instruction, we adapt this paradigm to the video domain. Extending the Prompt-to-Prompt to videos, we efficiently generate paired samples, each with an input video and its edited counterpart. Alongside this, we introduce the Long Video Sampling Correction during sampling, ensuring consistent long videos across batches. Our method surpasses current methods like Tune-A-Video, heralding substantial progress in text-based video-to-video editing and suggesting exciting avenues for further exploration and deployment.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的和高效的文本基于 видео editing 方法，该方法可以消除需要资源充足的每个视频进行模型 fine-tuning。我们的方法的核心是一个人工制作的对应视频集，这个集合是为视频转换任务设计的。以 Instruct Pix2Pix 的图像转换为例，我们将该思想应用到视频领域。我们在 Prompt-to-Prompt 上扩展了这个思想，以生成对应的视频对，每个对包含一个输入视频和其编辑后的对应视频。此外，我们还引入了长视频抽样正确，以确保批处中的视频长度相同。我们的方法超越了现有的方法，如 Tune-A-Video，表明了文本基于 видео editing 方法的重要进步，并开示了更多的探索和应用的可能性。
</details></li>
</ul>
<hr>
<h2 id="Magmaw-Modality-Agnostic-Adversarial-Attacks-on-Machine-Learning-Based-Wireless-Communication-Systems"><a href="#Magmaw-Modality-Agnostic-Adversarial-Attacks-on-Machine-Learning-Based-Wireless-Communication-Systems" class="headerlink" title="Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems"></a>Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00207">http://arxiv.org/abs/2311.00207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jung-Woo Chang, Ke Sun, Nasimeh Heydaribeni, Seira Hidano, Xinyu Zhang, Farinaz Koushanfar</li>
<li>for: 这篇论文旨在描述一种黑盒子攻击方法，可以对任何多Modal信号通过无线通信频率进行攻击。</li>
<li>methods: 该方法使用了多Modal的源数据、通用物理层组件和无线频率约束，并提出了新的攻击目标。</li>
<li>results: 实验结果表明，该攻击方法能够在存在防御机制的情况下引起重大性能下降，并且能够攻击加密通信频率和传统通信频率。<details>
<summary>Abstract</summary>
Machine Learning (ML) has been instrumental in enabling joint transceiver optimization by merging all physical layer blocks of the end-to-end wireless communication systems. Although there have been a number of adversarial attacks on ML-based wireless systems, the existing methods do not provide a comprehensive view including multi-modality of the source data, common physical layer components, and wireless domain constraints. This paper proposes Magmaw, the first black-box attack methodology capable of generating universal adversarial perturbations for any multimodal signal transmitted over a wireless channel. We further introduce new objectives for adversarial attacks on ML-based downstream applications. The resilience of the attack to the existing widely used defense methods of adversarial training and perturbation signal subtraction is experimentally verified. For proof-of-concept evaluation, we build a real-time wireless attack platform using a software-defined radio system. Experimental results demonstrate that Magmaw causes significant performance degradation even in the presence of the defense mechanisms. Surprisingly, Magmaw is also effective against encrypted communication channels and conventional communications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification"><a href="#ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification" class="headerlink" title="ChatGPT-Powered Hierarchical Comparisons for Image Classification"></a>ChatGPT-Powered Hierarchical Comparisons for Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00206">http://arxiv.org/abs/2311.00206</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhiyuan-r/chatgpt-powered-hierarchical-comparisons-for-image-classification">https://github.com/zhiyuan-r/chatgpt-powered-hierarchical-comparisons-for-image-classification</a></li>
<li>paper_authors: Zhiyuan Ren, Yiyang Su, Xiaoming Liu</li>
<li>for: 解决零示open-vocabulary图像分类挑战，使用预训练视觉语言模型CLIP，并借鉴大语言模型ChatGPT中的类别专业知识。</li>
<li>methods: 使用大语言模型Recursive Hierarchical Embeddings（RHE），将类别组织成层次结构，并使用这些层次结构来对图像和文本嵌入进行比较，从而实现有效、可解释的图像分类方法。</li>
<li>results: 提出了一种新的图像分类框架，可以快速、精准地分类图像，同时也可以提供有用的解释性结果。<details>
<summary>Abstract</summary>
The zero-shot open-vocabulary challenge in image classification is tackled by pretrained vision-language models like CLIP, which benefit from incorporating class-specific knowledge from large language models (LLMs) like ChatGPT. However, biases in CLIP lead to similar descriptions for distinct but related classes, prompting our novel image classification framework via hierarchical comparisons: using LLMs to recursively group classes into hierarchies and classifying images by comparing image-text embeddings at each hierarchy level, resulting in an intuitive, effective, and explainable approach.
</details>
<details>
<summary>摘要</summary>
CLIP等预训练视觉语言模型在无训练数据的开放词汇挑战中表现出色，具有将类pecific知识从大型语言模型（LLM）如ChatGPT中吸收的优点。然而，CLIP中的偏见导致相似的描述对不同 yet related的类型进行分类，因此我们提出了一种新的图像分类框架：通过使用LLM进行层次分组，将类型分为层次结构，并在每个层次结构中使用图像文本嵌入对比，从而实现intuitive、有效和可解释的方法。
</details></li>
</ul>
<hr>
<h2 id="Continuous-Training-and-Fine-tuning-for-Domain-Specific-Language-Models-in-Medical-Question-Answering"><a href="#Continuous-Training-and-Fine-tuning-for-Domain-Specific-Language-Models-in-Medical-Question-Answering" class="headerlink" title="Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering"></a>Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00204">http://arxiv.org/abs/2311.00204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Guo, Yining Hua</li>
<li>for: 这个研究旨在使用连续训练和指导精度调整，将Llama 2 基本模型 rápidamente适应中文医学领域。</li>
<li>methods: 首先，通过1B个中文医学引用文本进行连续训练，教育模型学习相关词汇和知识。然后，通过54K个中国医学资格考试例题进行精度调整。</li>
<li>results: 实验表明，这种方法具有效果，可以生成与 GPT-3.5-turbo 相比的模型，而使用的计算资源却很少。这种领域专业的模型可以用于多种中文医学应用。此外，这种方法可以应用于法律、科学和工程等领域， где预训练模型缺乏专业知识。<details>
<summary>Abstract</summary>
Large language models exhibit promising general capabilities but often lack specialized knowledge for domain-specific tasks. Developing domain experts from a base model enables a range of applications without prohibitive training costs. This work demonstrates a method using continuous training and instruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese medical domain. We first conduct continuous training on 1B tokens from Chinese medical references to teach relevant vocabulary and knowledge. The models are then fine-tuned on 54K examples sourced from the Chinese National Medical Licensing Examination. Experiments on Chinese medical data confirm the effectiveness of this approach, producing a model comparable to GPT-3.5-turbo while using way less computational resource. The resulting domain-specific model could be useful for various Chinese medical applications. More broadly, this provides a template for domain-specific training of large language models in areas where pre-trained models lack the required expertise, such as law, science, and engineering.
</details>
<details>
<summary>摘要</summary>
大型语言模型具有优异的通用能力，但经常缺乏域专知 для域特定任务。从基本模型开发域专家可以快速地应用到各种应用程序而无需昂贵的训练成本。本研究展示了一种使用连续训练和指导练习精度调整的方法，以快速地适应基于中文医学文献的Llama 2基本模型。我们首先通过10亿个中文医学Token进行连续训练，教导模型应用相关词汇和知识。然后，我们对5.4万个中文医学试题进行精度调整。实验表明，这种方法具有效果，可以生成与GPT-3.5-turbo相当的模型，使用的计算资源减少了很多。得到的域专门模型可以用于多种中文医学应用程序。更广泛地说，这提供了领域专门训练大语言模型的模板，可以应用于没有相关知识的领域，如法律、科学和工程。
</details></li>
</ul>
<hr>
<h2 id="Modeling-subjectivity-by-Mimicking-Annotator-Annotation-in-toxic-comment-identification-across-diverse-communities"><a href="#Modeling-subjectivity-by-Mimicking-Annotator-Annotation-in-toxic-comment-identification-across-diverse-communities" class="headerlink" title="Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities"></a>Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00203">http://arxiv.org/abs/2311.00203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Senjuti Dutta, Sid Mittal, Sherol Chen, Deepak Ramachandran, Ravi Rajakumar, Ian Kivlichan, Sunny Mak, Alena Butryna, Praveen Paritosh</li>
<li>for: 本研究旨在提高自动化审核系统的可靠性，帮助减少人工审核的依赖。</li>
<li>methods: 本研究使用了专家标注者的注释，并使用了三个公共数据集来评估模型的多元性。</li>
<li>results: 研究发现，不同群体的专家标注者之间存在主观差异，这表明大量投票的方法存在缺陷。因此，将主观标注作为训练数据的真实标注值是不可靠的。<details>
<summary>Abstract</summary>
The prevalence and impact of toxic discussions online have made content moderation crucial.Automated systems can play a vital role in identifying toxicity, and reducing the reliance on human moderation.Nevertheless, identifying toxic comments for diverse communities continues to present challenges that are addressed in this paper.The two-part goal of this study is to(1)identify intuitive variances from annotator disagreement using quantitative analysis and (2)model the subjectivity of these viewpoints.To achieve our goal, we published a new dataset\footnote{\url{https://github.com/XXX} with expert annotators' annotations and used two other public datasets to identify the subjectivity of toxicity.Then leveraging the Large Language Model(LLM),we evaluate the model's ability to mimic diverse viewpoints on toxicity by varying size of the training data and utilizing same set of annotators as the test set used during model training and a separate set of annotators as the test set.We conclude that subjectivity is evident across all annotator groups, demonstrating the shortcomings of majority-rule voting. Moving forward, subjective annotations should serve as ground truth labels for training models for domains like toxicity in diverse communities.
</details>
<details>
<summary>摘要</summary>
“在线上的问题性讨论日益普遍和影响力大，内容审核已成为不可或缺的。自动化系统可以扮演重要的角色，识别问题性并减少人工审核的需求。然而，识别多元社区中的问题评价仍然存在挑战，这个研究将解决这个问题。我们的研究目标是使用量化分析来识别审核者之间的不同意见，并模型这些意见的主观性。我们发布了一个新的数据集\footnotemark[1]，并使用两个公共的数据集来识别问题的主观性。我们使用大型自然语言模型（LLM）进行评估，并让模型对多元社区中的问题进行多样化训练。我们发现，问题的主观性在所有审核者群体中都存在，这证明了大多数投票的缺陷。未来，应该使用主观性的标签来训练适用于多元社区的问题识别模型。”Note:\footnotemark[1] 这个数据集的连结地址是https://github.com/XXX.
</details></li>
</ul>
<hr>
<h2 id="Federated-Natural-Policy-Gradient-Methods-for-Multi-task-Reinforcement-Learning"><a href="#Federated-Natural-Policy-Gradient-Methods-for-Multi-task-Reinforcement-Learning" class="headerlink" title="Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning"></a>Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00201">http://arxiv.org/abs/2311.00201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Yang, Shicong Cen, Yuting Wei, Yuxin Chen, Yuejie Chi</li>
<li>for: 这个论文的目的是研究 federated reinforcement learning（RL），即多个分布式代理者之间分享环境transition kernel，而不需要分享本地数据轨迹。</li>
<li>methods: 这篇论文使用了 vanilla 和 entropy-regularized natural policy gradient（NPG）方法，并在 softmax 参数化下进行了实现。 gradient tracking 技术是用于 mitigate 不完整的信息共享的影响。</li>
<li>results: 论文提出了一种基于 policy 优化的 federated RL 方法，并提供了不 asymptotic 全球协调 guarantees，这些 guarantees 几乎不виси于状态动作空间的大小。此外，研究还发现了对精度评估不准确的影响。<details>
<summary>Abstract</summary>
Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon tabular Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology. We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods under softmax parameterization, where gradient tracking is applied to the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, which are nearly independent of the size of the state-action space and illuminate the impacts of network size and connectivity. To the best of our knowledge, this is the first time that global convergence is established for federated multi-task RL using policy optimization. Moreover, the convergence behavior of the proposed algorithms is robust against inexactness of policy evaluation.
</details>
<details>
<summary>摘要</summary>
联合强化学习（RL）可以帮助多个分布式代理机制共同做出决策，无需分享本地数据轨迹。在这个工作中，我们考虑了多任务Setting，每个代理都有自己私有的奖励函数，对应不同的任务，同时共享环境的传输核心。我们关注于无限远景表示Markov决策过程，目标是在分布式方式学习一个全局优化策略，使得所有代理的折扣总奖励之和最大化，每个代理只与其邻居通信，根据一定的图形拓扑。我们开发了联邦vanilla和束规化自然策略加速法（NPG），其中使用了软预测参数。我们证明了不假设极限的情况下，我们的算法在精确评估下具有全球启动的全局收敛保证，这些保证是不同状态动作空间大小的不相互关联的。此外，我们发现了提出的算法的收敛行为对精度评估的不准确性具有抗性。Note: "联合" (liánhòu) in the title should be translated as "federated" in English.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.AI_2023_11_01/" data-id="cloh7tqcq006j7b881f73bczv" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.CL_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T11:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.CL_2023_11_01/">cs.CL - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="End-to-End-Single-Channel-Speaker-Turn-Aware-Conversational-Speech-Translation"><a href="#End-to-End-Single-Channel-Speaker-Turn-Aware-Conversational-Speech-Translation" class="headerlink" title="End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation"></a>End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00697">http://arxiv.org/abs/2311.00697</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amazon-science/stac-speech-translation">https://github.com/amazon-science/stac-speech-translation</a></li>
<li>paper_authors: Juan Zuluaga-Gomez, Zhaocheng Huang, Xing Niu, Rohit Paturi, Sundararajan Srinivasan, Prashant Mathur, Brian Thompson, Marcello Federico</li>
<li>for: 这 paper 是为了解决单 Channel 多说话人 conversational speech-to-text 系统的问题。</li>
<li>methods: 这 paper 使用了一种 serialized labeling format 的 end-to-end 和 multi-task 训练模型，名为 Speaker-Turn Aware Conversational Speech Translation，它结合了自动语音识别、语音翻译和说话人turn detection。</li>
<li>results:  experiments 表明，在 Fisher-CALLHOME 数据集上，我们的模型在多说话人 Condition 下表现出了优于参照系统，而在单说话人 Condition 下表现与参照系统相当。<details>
<summary>Abstract</summary>
Conventional speech-to-text translation (ST) systems are trained on single-speaker utterances, and they may not generalize to real-life scenarios where the audio contains conversations by multiple speakers. In this paper, we tackle single-channel multi-speaker conversational ST with an end-to-end and multi-task training model, named Speaker-Turn Aware Conversational Speech Translation, that combines automatic speech recognition, speech translation and speaker turn detection using special tokens in a serialized labeling format. We run experiments on the Fisher-CALLHOME corpus, which we adapted by merging the two single-speaker channels into one multi-speaker channel, thus representing the more realistic and challenging scenario with multi-speaker turns and cross-talk. Experimental results across single- and multi-speaker conditions and against conventional ST systems, show that our model outperforms the reference systems on the multi-speaker condition, while attaining comparable performance on the single-speaker condition. We release scripts for data processing and model training.
</details>
<details>
<summary>摘要</summary>
传统的语音到文本翻译（ST）系统通常在单个说话人的单个话语中训练，这些系统可能无法泛化到真实生活中的多人对话场景。在这篇论文中，我们解决了单通道多说话人对话的语音到文本翻译问题，使用一个端到端和多任务训练模型，名为Speaker-Turn Aware Conversational Speech Translation。该模型结合了自动语音识别、语音翻译和说话人转换检测，使用特殊的标记Format进行串行化。我们在Fisher-CALLHOME corpus上进行实验，将两个单个说话人通道合并到一个多个说话人通道上，从而更加真实和挑战性地表现出多个说话人的转换和交叉对话。实验结果表明，我们的模型在多个说话人条件下比参照系统高效，而在单个说话人条件下也能够达到相似的性能。我们释放了数据处理和模型训练脚本。
</details></li>
</ul>
<hr>
<h2 id="Little-Giants-Exploring-the-Potential-of-Small-LLMs-as-Evaluation-Metrics-in-Summarization-in-the-Eval4NLP-2023-Shared-Task"><a href="#Little-Giants-Exploring-the-Potential-of-Small-LLMs-as-Evaluation-Metrics-in-Summarization-in-the-Eval4NLP-2023-Shared-Task" class="headerlink" title="Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task"></a>Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00686">http://arxiv.org/abs/2311.00686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neema Kotonya, Saran Krishnasamy, Joel Tetreault, Alejandro Jaimes</li>
<li>for: 本研究参与2023年Eval4NLP共享任务，旨在评估基于提示技术的大语言模型对质量评估机器翻译和摘要的效果。</li>
<li>methods: 我们采用了不同的提示技术，包括标准提示、根据评分员指导的提示和创新的链式思维提示。此外，我们还将这些方法与零shot和一shot学习方法结合使用，以最大化评估过程的效果。</li>
<li>results: 我们的研究发现，通过结合这些方法使用一个”小”的开源模型（orca_mini_v3_7B）可以获得竞争性的结果。<details>
<summary>Abstract</summary>
This paper describes and analyzes our participation in the 2023 Eval4NLP shared task, which focuses on assessing the effectiveness of prompt-based techniques to empower Large Language Models to handle the task of quality estimation, particularly in the context of evaluating machine translations and summaries. We conducted systematic experiments with various prompting techniques, including standard prompting, prompts informed by annotator instructions, and innovative chain-of-thought prompting. In addition, we integrated these approaches with zero-shot and one-shot learning methods to maximize the efficacy of our evaluation procedures. Our work reveals that combining these approaches using a "small", open source model (orca_mini_v3_7B) yields competitive results.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Attention-Alignment-and-Flexible-Positional-Embeddings-Improve-Transformer-Length-Extrapolation"><a href="#Attention-Alignment-and-Flexible-Positional-Embeddings-Improve-Transformer-Length-Extrapolation" class="headerlink" title="Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation"></a>Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00684">http://arxiv.org/abs/2311.00684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ta-Chung Chi, Ting-Han Fan, Alexander I. Rudnicky</li>
<li>for: 这个论文目的是探讨一种可以处理长于训练长度的Transformer语言模型，以提高其长Context处理能力。</li>
<li>methods: 论文使用了T5家族的大型预训练语言模型，并对其 позицион嵌入进行了调整，以提高它对长输入序列的处理能力。</li>
<li>results: 研究发现，通过调整T5的 pozitional embedding 和 temperature scaling 可以提高模型对长输入序列的处理能力，无需进行任何细化。这些发现可以提高Transformer语言模型在语言模型、检索和多文档问答等任务中的长Context处理能力。<details>
<summary>Abstract</summary>
An ideal length-extrapolatable Transformer language model can handle sequences longer than the training length without any long sequence fine-tuning. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.\footnote{\url{https://github.com/chijames/Attention-Alignment-Transformer-Length-Extrapolation}
</details>
<details>
<summary>摘要</summary>
一个理想的长度扩展可以处理的Transformer语言模型应该能够处理 longer than the training length without any fine-tuning of long sequences. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.Here's the word-for-word translation:一个理想的长度扩展可以处理的Transformer语言模型应该能够处理 longer than the training length without any fine-tuning of long sequences. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.
</details></li>
</ul>
<hr>
<h2 id="Are-Large-Language-Models-Reliable-Judges-A-Study-on-the-Factuality-Evaluation-Capabilities-of-LLMs"><a href="#Are-Large-Language-Models-Reliable-Judges-A-Study-on-the-Factuality-Evaluation-Capabilities-of-LLMs" class="headerlink" title="Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs"></a>Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00681">http://arxiv.org/abs/2311.00681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xue-Yong Fu, Md Tahmid Rahman Laskar, Cheng Chen, Shashi Bhushan TN</li>
<li>for: 本研究探讨了大型语言模型（LLM）是否可靠地评估生成模型生成的摘要中的事实准确性。</li>
<li>methods: 本研究提出了一种新的方法，使用单个LLM进行整个问答型事实评分过程。然后，研究者对不同的LLM进行了直接事实评分，并与传统测量和人工评分进行比较。</li>
<li>results: 研究结果表明，与人类评分的相关性较低，特别是对GPT-4和PaLM-2。只有GPT-3.5在两个事实分类中显示了 Notable的相关性。这些结果表明现有LLMs可能无法准确评估事实准确性。<details>
<summary>Abstract</summary>
In recent years, Large Language Models (LLMs) have gained immense attention due to their notable emergent capabilities, surpassing those seen in earlier language models. A particularly intriguing application of LLMs is their role as evaluators for texts produced by various generative models.   In this study, we delve into the potential of LLMs as reliable assessors of factual consistency in summaries generated by text-generation models. Initially, we introduce an innovative approach for factuality assessment using LLMs. This entails employing a singular LLM for the entirety of the question-answering-based factuality scoring process. Following this, we examine the efficacy of various LLMs in direct factuality scoring, benchmarking them against traditional measures and human annotations.   Contrary to initial expectations, our results indicate a lack of significant correlations between factuality metrics and human evaluations, specifically for GPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 across two factuality subcategories. These consistent findings across various factual error categories suggest a fundamental limitation in the current LLMs' capability to accurately gauge factuality.   This version presents the information more concisely while maintaining the main points and findings of the original text.
</details>
<details>
<summary>摘要</summary>
We propose an innovative approach for factuality assessment using a single LLM throughout the question-answering-based scoring process. We then compare the efficacy of various LLMs in direct factuality scoring, benchmarking them against traditional measures and human annotations.Surprisingly, our results show a lack of significant correlations between factuality metrics and human evaluations for GPT-4 and PaLM-2, with only GPT-3.5 displaying notable correlations across two factual error categories. These findings suggest a fundamental limitation in current LLMs' ability to accurately assess factuality.This concise version maintains the main points and findings of the original text, highlighting the potential of LLMs as assessors of factual consistency and the limitations of current LLMs in accurately gauging factuality.
</details></li>
</ul>
<hr>
<h2 id="Emotion-Detection-for-Misinformation-A-Review"><a href="#Emotion-Detection-for-Misinformation-A-Review" class="headerlink" title="Emotion Detection for Misinformation: A Review"></a>Emotion Detection for Misinformation: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00671">http://arxiv.org/abs/2311.00671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Liu, Tianlin Zhang, Kailai Yang, Paul Thompson, Zeping Yu, Sophia Ananiadou</li>
<li>for: 本研究的目的是寻找基于情感的谣言检测方法，以便在社交媒体上减少谣言的散布。</li>
<li>methods: 该研究使用了多种情感、 sentiment和立场基本特征，包括语言模型、 sentiment分析和机器学习算法，以检测谣言。</li>
<li>results: 研究发现，基于情感的方法可以减少谣言的散布，但还存在一些挑战，如大语言模型、多平台多语言、注释、多模式和解释性。<details>
<summary>Abstract</summary>
With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people's lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.
</details>
<details>
<summary>摘要</summary>
We begin by explaining the strong connections between emotions and misinformation. We then provide a detailed analysis of a range of misinformation detection methods that use a variety of emotion, sentiment, and stance-based features, and describe their strengths and weaknesses. Finally, we discuss several ongoing challenges in emotion-based misinformation detection using large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.
</details></li>
</ul>
<hr>
<h2 id="Explicit-Morphological-Knowledge-Improves-Pre-training-of-Language-Models-for-Hebrew"><a href="#Explicit-Morphological-Knowledge-Improves-Pre-training-of-Language-Models-for-Hebrew" class="headerlink" title="Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew"></a>Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00658">http://arxiv.org/abs/2311.00658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eylon Gueta, Omer Goldman, Reut Tsarfaty</li>
<li>for: 本研究目的是检验Language-agnostic pre-trained language models (PLMs)是否能够有效地处理 morphologically-rich languages (MRLs)。</li>
<li>methods: 研究人员提出了多种基于 morphological knowledge的tokenization方法，以便让模型利用 morphological cues beyond raw text。</li>
<li>results: 实验结果表明，基于 morphological knowledge的tokenization方法在 Hebrew 语言中表现出了改善的 результаTS， compared to standard language-agnostic tokenization。这些结果表明， incorporating morphological knowledge holds the potential for further improving PLMs for MRLs。<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have shown remarkable successes in acquiring a wide range of linguistic knowledge, relying solely on self-supervised training on text streams. Nevertheless, the effectiveness of this language-agnostic approach has been frequently questioned for its sub-optimal performance when applied to morphologically-rich languages (MRLs). We investigate the hypothesis that incorporating explicit morphological knowledge in the pre-training phase can improve the performance of PLMs for MRLs. We propose various morphologically driven tokenization methods enabling the model to leverage morphological cues beyond raw text. We pre-train multiple language models utilizing the different methods and evaluate them on Hebrew, a language with complex and highly ambiguous morphology. Our experiments show that morphologically driven tokenization demonstrates improved results compared to a standard language-agnostic tokenization, on a benchmark of both semantic and morphologic tasks. These findings suggest that incorporating morphological knowledge holds the potential for further improving PLMs for morphologically rich languages.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Formal-Translation-from-Reversing-Petri-Nets-to-Coloured-Petri-Nets"><a href="#Formal-Translation-from-Reversing-Petri-Nets-to-Coloured-Petri-Nets" class="headerlink" title="Formal Translation from Reversing Petri Nets to Coloured Petri Nets"></a>Formal Translation from Reversing Petri Nets to Coloured Petri Nets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00629">http://arxiv.org/abs/2311.00629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamila Barylska, Anna Gogolinska, Lukasz Mikulski, Anna Philippou, Marcin Piatkowski, Kyriaki Psara</li>
<li>for: 这个论文旨在探讨逆计算 paradigm 的应用，具体来说是通过在计算过程中逆转操作顺序来实现低功耗计算和各种应用领域的相关性。</li>
<li>methods: 这篇论文使用了 extend Petri nets 来实现逆计算，其中使用了名称的 tokens 可以组合在一起形成键。这些 tokens  along with a history function ，使得可以记忆过去的行为，并且允许逆转。</li>
<li>results: 这篇论文报告了一种从 RPNs 到 CPNs 的结构翻译方法，该方法可以处理 RPNs 中Token的多态性。此外， paper 还报告了一种工具，可以自动将 RPNs 翻译成 CPNs，并且可以进行逆计算和分析。<details>
<summary>Abstract</summary>
Reversible computation is an emerging computing paradigm that allows any sequence of operations to be executed in reverse order at any point during computation. Its appeal lies in its potential for lowpower computation and its relevance to a wide array of applications such as chemical reactions, quantum computation, robotics, and distributed systems. Reversing Petri nets are a recently-proposed extension of Petri nets that implements the three main forms of reversibility, namely, backtracking, causal reversing, and out-of-causal-order reversing. Their distinguishing feature is the use of named tokens that can be combined together to form bonds. Named tokens along with a history function, constitute the means of remembering past behaviour, thus, enabling reversal. In recent work, we have proposed a structural translation from a subclass of RPNs to the model of Coloured Petri Nets (CPNs), an extension of traditional Petri nets where tokens carry data values. In this paper, we extend the translation to handle RPNs with token multiplicity under the individual-token interpretation, a model which allows multiple tokens of the same type to exist in a system. To support the three types of reversibility, tokens are associated with their causal history and, while tokens of the same type are equally eligible to fire a transition when going forward, when going backwards they are able to reverse only the transitions they have previously fired. The new translation, in addition to lifting the restriction on token uniqueness, presents a refined approach for transforming RPNs to CPNs through a unifying approach that allows instantiating each of the three types of reversibility. The paper also reports on a tool that implements this translation, paving the way for automated translations and analysis of reversible systems using CPN Tools.
</details>
<details>
<summary>摘要</summary>
<<SYS>>描述文本为 Traditional Chinese.<</SYS>>可逆计算是一种emerging计算模式，允许任何操作序列在计算过程中执行逆序。它的吸引点在于其可能性低功耗计算和广泛应用领域，如化学反应、量子计算、机器人和分布式系统。在这些应用领域中，可逆计算可以提供更高效的方法来解决问题。可逆 Petri nets 是一种最近提出的扩展，它实现了计算机科学中三种主要的可逆性形式，namely，backtracking，causal reversing和out-of-causal-order reversing。它们的特点在于使用名称的 токен，可以组合在一起形成缔造。名称的tokен，一起与历史函数，使得可以记忆过去的行为，因此可以进行逆转。在我们的最近工作中，我们提出了一种结构性的翻译方法，将一个子集的 RPNs 翻译为 Coloured Petri Nets (CPNs) 模型，这是传统 Petri nets 的扩展，tokentoken carry data values。在这篇论文中，我们将这种翻译扩展到处理 RPNs 的token多样性，使得每个tokentype可以在系统中存在多个实例。为支持三种可逆性，tokentoken被与其 causal history 相关联，当前进时，tokentype的所有实例都可以触发过渡，但是在逆转时，只有以前触发过渡的tokentype实例才能逆转。这种新的翻译方法，不仅废除了tokentype唯一性的限制，还提供了一种统一的approach来转换 RPNs 到 CPNs，并且可以实现每种类型的可逆性。论文还报告了一种实现这种翻译的工具，为可逆系统的自动翻译和分析提供了道路。
</details></li>
</ul>
<hr>
<h2 id="Crosslingual-Retrieval-Augmented-In-context-Learning-for-Bangla"><a href="#Crosslingual-Retrieval-Augmented-In-context-Learning-for-Bangla" class="headerlink" title="Crosslingual Retrieval Augmented In-context Learning for Bangla"></a>Crosslingual Retrieval Augmented In-context Learning for Bangla</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00587">http://arxiv.org/abs/2311.00587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoqian Li, Ercong Nie, Sheng Liang</li>
<li>for: 提高 Bangla 语言处理 tasks 的表现</li>
<li>methods: 使用 cross-lingual retrieval augmented in-context learning</li>
<li>results: 实现了提高 MPLMs 在 Bangla 任务上的表现，并且 steady improvements over zero-shot performance。Here’s the full text in Simplified Chinese:</li>
<li>for: 提高 Bangla 语言处理任务的表现</li>
<li>methods: 使用 cross-lingual retrieval augmented in-context learning</li>
<li>results: 实现了提高 MPLMs 在 Bangla 任务上的表现，并且 steady improvements over zero-shot performance。<details>
<summary>Abstract</summary>
The promise of Large Language Models (LLMs) in Natural Language Processing has often been overshadowed by their limited performance in low-resource languages such as Bangla. To address this, our paper presents a pioneering approach that utilizes cross-lingual retrieval augmented in-context learning. By strategically sourcing semantically similar prompts from high-resource language, we enable multilingual pretrained language models (MPLMs), especially the generative model BLOOMZ, to successfully boost performance on Bangla tasks. Our extensive evaluation highlights that the cross-lingual retrieval augmented prompts bring steady improvements to MPLMs over the zero-shot performance.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理中的大语言模型（LLMs）的承诺经常被低资源语言 such as Bangla 语言表现所压制。为了解决这个问题，我们的论文提出了一种创新的方法，利用跨语言检索增强在场景学习。我们策略性地从高资源语言中抽取semantically similar的提示，以帮助多语言预训练语言模型（MPLMs），特别是生成模型BLOOMZ，在 Bangla 任务上成功提高表现。我们进行了广泛的评估，发现跨语言检索增强提示可以稳定地提高 MPLMs 的零 shot 性能。
</details></li>
</ul>
<hr>
<h2 id="An-Embedded-Diachronic-Sense-Change-Model-with-a-Case-Study-from-Ancient-Greek"><a href="#An-Embedded-Diachronic-Sense-Change-Model-with-a-Case-Study-from-Ancient-Greek" class="headerlink" title="An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek"></a>An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00541">http://arxiv.org/abs/2311.00541</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/schyanzafar/edisc">https://github.com/schyanzafar/edisc</a></li>
<li>paper_authors: Schyan Zafar, Geoff K. Nicholls</li>
<li>for: 本研究旨在分析古希腊文本资料库中的词汇变化。</li>
<li>methods: 研究使用了无监督学习的GASC和DiSC生成模型，用MCMC方法来衡量词汇变化。</li>
<li>results: 研究发现，使用EDiSC模型可以提高预测准确率、真实恢复率和不确定度评估，同时具有更好的采样效率和可扩展性。<details>
<summary>Abstract</summary>
Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.
</details>
<details>
<summary>摘要</summary>
Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.Here's the translation in Traditional Chinese:Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.
</details></li>
</ul>
<hr>
<h2 id="Text-Rendering-Strategies-for-Pixel-Language-Models"><a href="#Text-Rendering-Strategies-for-Pixel-Language-Models" class="headerlink" title="Text Rendering Strategies for Pixel Language Models"></a>Text Rendering Strategies for Pixel Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00522">http://arxiv.org/abs/2311.00522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas F. Lotz, Elizabeth Salesky, Phillip Rust, Desmond Elliott</li>
<li>for: 这篇论文是关于Pixel模型的语言模型处理文本的研究，旨在提高语言模型的可扩展性和性能。</li>
<li>methods: 论文使用四种不同的文本渲染方法来进行研究，其中一种是简单的字符大rams渲染方法，这种方法可以提高句子级任务的性能而无需妥协Multilingual任务或Token级任务的性能。</li>
<li>results: 研究发现，使用简单的字符大rams渲染方法可以提高模型的性能，但是这种方法会导致模型的patch embedding空间具有不均匀分布，这与图像patch和语言模型之间的连接有关。<details>
<summary>Abstract</summary>
Pixel-based language models process text rendered as images, which allows them to handle any script, making them a promising approach to open vocabulary language modelling. However, recent approaches use text renderers that produce a large set of almost-equivalent input patches, which may prove sub-optimal for downstream tasks, due to redundancy in the input representations. In this paper, we investigate four approaches to rendering text in the PIXEL model (Rust et al., 2023), and find that simple character bigram rendering brings improved performance on sentence-level tasks without compromising performance on token-level or multilingual tasks. This new rendering strategy also makes it possible to train a more compact model with only 22M parameters that performs on par with the original 86M parameter model. Our analyses show that character bigram rendering leads to a consistently better model but with an anisotropic patch embedding space, driven by a patch frequency bias, highlighting the connections between image patch- and tokenization-based language models.
</details>
<details>
<summary>摘要</summary>
Pixel基于语言模型处理文本作为图像，可以处理任何文本，这使得它们成为开 vocabulary 语言模型的有力的方法。然而，现有的方法使用生成大量几乎相同的输入 patches 的文本渲染器，这可能会对下游任务造成冗余在输入表示中，从而降低性能。在这篇论文中，我们研究了 PIXEL 模型（Rust et al., 2023）中四种渲染文本的方法，并发现，使用简单的字符bigram渲染可以提高句子级任务的性能，而不会对Token级或多语言任务产生负面影响。这新的渲染策略还使得可以训练一个更加 компакт的模型，只有 22M 参数，与原始 86M 参数模型在同等水平上表现。我们的分析显示，字符bigram渲染导致一个一致性更好的模型，但是 embedding 空间具有不均匀的分布，受到 patch 频率偏好的影响，这 highlights 图像 patch 和 tokenization 基于的语言模型之间的连接。
</details></li>
</ul>
<hr>
<h2 id="Rule-Based-Error-Classification-for-Analyzing-Differences-in-Frequent-Errors"><a href="#Rule-Based-Error-Classification-for-Analyzing-Differences-in-Frequent-Errors" class="headerlink" title="Rule-Based Error Classification for Analyzing Differences in Frequent Errors"></a>Rule-Based Error Classification for Analyzing Differences in Frequent Errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00513">http://arxiv.org/abs/2311.00513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Taku Matsumoto, Md Faizul Ibne Amin, Yutaka Watanobe</li>
<li>for: 本研究旨在揭示初学者和高级程序员之间错误的差异，并提供有用的建议 для每个学习水平。</li>
<li>methods: 我们提出了一种基于规则的错误分类工具，用于对代码对的错误进行分类。我们分析了95631个代码对，平均错误数为3.47，并用于分析初学者和高级程序员之间错误的差异。</li>
<li>results: 分析结果表明，初学者的错误主要是由于programming知识的缺乏，而高级程序员的错误主要是由于解决问题的不同方式或读取问题的精疲。这种工具可以用于创建错误标注的数据集，并用于进一步的代码相关教育研究。<details>
<summary>Abstract</summary>
Finding and fixing errors is a time-consuming task not only for novice programmers but also for expert programmers. Prior work has identified frequent error patterns among various levels of programmers. However, the differences in the tendencies between novices and experts have yet to be revealed. From the knowledge of the frequent errors in each level of programmers, instructors will be able to provide helpful advice for each level of learners. In this paper, we propose a rule-based error classification tool to classify errors in code pairs consisting of wrong and correct programs. We classify errors for 95,631 code pairs and identify 3.47 errors on average, which are submitted by various levels of programmers on an online judge system. The classified errors are used to analyze the differences in frequent errors between novice and expert programmers. The analyzed results show that, as for the same introductory problems, errors made by novices are due to the lack of knowledge in programming, and the mistakes are considered an essential part of the learning process. On the other hand, errors made by experts are due to misunderstandings caused by the carelessness of reading problems or the challenges of solving problems differently than usual. The proposed tool can be used to create error-labeled datasets and for further code-related educational research.
</details>
<details>
<summary>摘要</summary>
查找和修复错误是一项时间耗费的任务，不仅对于初学者而且对于专家程序员也是如此。先前的工作已经确定了不同程度的程序员中的错误模式。然而，初学者和专家之间的差异仍未得到揭示。通过了解每个程度的错误频率，教师将能够提供有用的建议 для每个学习者。在这篇论文中，我们提出了一种基于规则的错误分类工具，用于分类代码对的正确和错误程序。我们对95631个代码对进行分类，并发现每个代码对平均含3.47个错误。这些错误是由不同程度的程序员在在线评审系统上提交的。我们分析了错误的差异，发现初学者的错误主要是因为编程知识不足，而且这些错误是学习过程中的一部分。相比之下，专家的错误主要是由于阅读问题不够仔细或解决问题不同于惯常的方式而导致的。我们提出的工具可以用于创建错误标注的数据集，以及进一步的编程教育研究。
</details></li>
</ul>
<hr>
<h2 id="Robustness-Tests-for-Automatic-Machine-Translation-Metrics-with-Adversarial-Attacks"><a href="#Robustness-Tests-for-Automatic-Machine-Translation-Metrics-with-Adversarial-Attacks" class="headerlink" title="Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks"></a>Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00508">http://arxiv.org/abs/2311.00508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i-need-sleep/eval_attack">https://github.com/i-need-sleep/eval_attack</a></li>
<li>paper_authors: Yichen Huang, Timothy Baldwin</li>
<li>for: 研究MT评估指标在针对性synthesized文本中的性能，以探讨评估指标的Robustness。</li>
<li>methods: 使用word-和character-level攻击对三种流行的机器翻译指标进行实验：BERTScore、BLEURT和COMET。</li>
<li>results: 人工实验 validate that自动指标倾斜地对针对性下降的翻译进行评估，并发现BERTScore指标存在不一致的问题，它将原始句子和针对性下降的句子评估为相似，而对参考的评估则评估为不同。<details>
<summary>Abstract</summary>
We investigate MT evaluation metric performance on adversarially-synthesized texts, to shed light on metric robustness. We experiment with word- and character-level attacks on three popular machine translation metrics: BERTScore, BLEURT, and COMET. Our human experiments validate that automatic metrics tend to overpenalize adversarially-degraded translations. We also identify inconsistencies in BERTScore ratings, where it judges the original sentence and the adversarially-degraded one as similar, while judging the degraded translation as notably worse than the original with respect to the reference. We identify patterns of brittleness that motivate more robust metric development.
</details>
<details>
<summary>摘要</summary>
我们研究了一些 Popular machine translation  metric 在 adversarially-synthesized 文本上的表现，以了解 metric 的 Robustness。我们对 Word-level 和 Character-level 攻击进行了实验，测试了三种 популяр的 machine translation  metric：BERTScore、BLEURT 和 COMET。我们的人工实验表明，自动 metric 往往会对 adversarially-degraded 翻译过程进行过分 penalty。我们还发现了 BERTScore 的不一致性，它将原始句子和 adversarially-degraded 句子视为类似，而对参考译文进行评分时则评价了 adversarially-degraded 翻译为不同。我们发现了一些 brittleness 的模式，这些模式激励我们更加Robust metric 的发展。
</details></li>
</ul>
<hr>
<h2 id="Comparing-Optimization-Targets-for-Contrast-Consistent-Search"><a href="#Comparing-Optimization-Targets-for-Contrast-Consistent-Search" class="headerlink" title="Comparing Optimization Targets for Contrast-Consistent Search"></a>Comparing Optimization Targets for Contrast-Consistent Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00488">http://arxiv.org/abs/2311.00488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hugo Fry, Seamus Fallows, Ian Fan, Jamie Wright, Nandi Schoots</li>
<li>for: 优化对比逻辑搜索（CCS）的内部表示真理的回归。</li>
<li>methods: 提出了一种新的损失函数——中点差分（MD）损失函数。</li>
<li>results: 在特定的超参数值下，MD损失函数导致了一个与CCS几乎相同的搜索器。此外，我们还证明了这个超参数不是最佳的，可以通过更好的超参数来使MD损失函数在测试精度上超过CCS。<details>
<summary>Abstract</summary>
We investigate the optimization target of Contrast-Consistent Search (CCS), which aims to recover the internal representations of truth of a large language model. We present a new loss function that we call the Midpoint-Displacement (MD) loss function. We demonstrate that for a certain hyper-parameter value this MD loss function leads to a prober with very similar weights to CCS. We further show that this hyper-parameter is not optimal and that with a better hyper-parameter the MD loss function attains a higher test accuracy than CCS.
</details>
<details>
<summary>摘要</summary>
我团队 investigate Contrast-Consistent Search（CCS）的优化目标，它的目标是恢复大语言模型中真实的内部表示。我们提出了一种新的损失函数，称为中点偏移（MD）损失函数。我们示出，对于某个特定的超参数值，MD损失函数会导致 probers 的重量与 CCS 非常相似。此外，我们还证明了这个超参数并不是最佳的，并且通过更好的超参数，MD 损失函数在测试准确率方面超过 CCS。
</details></li>
</ul>
<hr>
<h2 id="Style-Locality-for-Controllable-Generation-with-kNN-Language-Models"><a href="#Style-Locality-for-Controllable-Generation-with-kNN-Language-Models" class="headerlink" title="Style Locality for Controllable Generation with kNN Language Models"></a>Style Locality for Controllable Generation with kNN Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00475">http://arxiv.org/abs/2311.00475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gilles Nawezi, Lucie Flek, Charles Welch</li>
<li>for: 本研究旨在控制文本风格，提高模型的流畅性和风格质量。</li>
<li>methods: 本研究使用 nearest neighbor 语言模型，并添加了地方层来学习Weight邻居的相对位置。</li>
<li>results: 我们的模型可以控制文本风格，并提供了更好的流畅性-风格质量的贸易。<details>
<summary>Abstract</summary>
Recent language models have been improved by the addition of external memory. Nearest neighbor language models retrieve similar contexts to assist in word prediction. The addition of locality levels allows a model to learn how to weight neighbors based on their relative location to the current text in source documents, and have been shown to further improve model performance. Nearest neighbor models have been explored for controllable generation but have not examined the use of locality levels. We present a novel approach for this purpose and evaluate it using automatic and human evaluation on politeness, formality, supportiveness, and toxicity textual data. We find that our model is successfully able to control style and provides a better fluency-style trade-off than previous work.
</details>
<details>
<summary>摘要</summary>
最近的语言模型已经得到了外部记忆的改进。 nearest neighbor语言模型可以在文本中找到类似的上下文，以帮助预测单词。通过本地层次可以让模型学习将邻居按照其相对于当前文本的位置在源文档中进行权重，这有助于进一步提高模型性能。 nearest neighbor模型在可控生成中被研究，但尚未检查了本地层次的使用。我们提出了一种新的方法，并通过自动和人工评估在礼貌、正式、支持性和攻击性文本数据中评估其性能。我们发现我们的模型能够成功地控制风格，并提供了更好的流畅度-风格质量的负担。
</details></li>
</ul>
<hr>
<h2 id="Discourse-Relations-Classification-and-Cross-Framework-Discourse-Relation-Classification-Through-the-Lens-of-Cognitive-Dimensions-An-Empirical-Investigation"><a href="#Discourse-Relations-Classification-and-Cross-Framework-Discourse-Relation-Classification-Through-the-Lens-of-Cognitive-Dimensions-An-Empirical-Investigation" class="headerlink" title="Discourse Relations Classification and Cross-Framework Discourse Relation Classification Through the Lens of Cognitive Dimensions: An Empirical Investigation"></a>Discourse Relations Classification and Cross-Framework Discourse Relation Classification Through the Lens of Cognitive Dimensions: An Empirical Investigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00451">http://arxiv.org/abs/2311.00451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingxue Fu</li>
<li>for: 这篇论文的目的是提出一种基于 Sanders et al. (2018) 的简单 когнитив发现的维度，用于捕捉不同框架中的 DISCOURSE RELATIONS。</li>
<li>methods: 该论文使用了跨框架 DISCOURSE RELATIONS 分类实验，通过 transferred knowledge 将一个框架中的 DISCOURSE RELATIONS 转移到另一个框架中。</li>
<li>results: 实验结果表明，使用这些维度可以有效地捕捉不同框架中的 DISCOURSE RELATIONS，并且不同的维度对不同类型的 DISCOURSE RELATIONS 有不同的影响。<details>
<summary>Abstract</summary>
Existing discourse formalisms use different taxonomies of discourse relations, which require expert knowledge to understand, posing a challenge for annotation and automatic classification. We show that discourse relations can be effectively captured by some simple cognitively inspired dimensions proposed by Sanders et al.(2018). Our experiments on cross-framework discourse relation classification (PDTB & RST) demonstrate that it is possible to transfer knowledge of discourse relations for one framework to another framework by means of these dimensions, in spite of differences in discourse segmentation of the two frameworks. This manifests the effectiveness of these dimensions in characterizing discourse relations across frameworks. Ablation studies reveal that different dimensions influence different types of discourse relations. The patterns can be explained by the role of dimensions in characterizing and distinguishing different relations. We also report our experimental results on automatic prediction of these dimensions.
</details>
<details>
<summary>摘要</summary>
现有的讨论形式学派使用不同的讨论关系分类法，需要专家知识来理解， pose 一个标注和自动分类的挑战。我们显示，讨论关系可以通过 Sanders 等人（2018）提出的一些简单的认知启发的维度来有效地捕捉。我们在 PDTB 和 RST 两个框架之间的跨框架讨论关系分类实验中表明，可以通过这些维度来传递一个框架中的讨论关系知识到另一个框架，尽管这两个框架在讨论分割上存在差异。这种现象表明了这些维度在不同框架之间的讨论关系的捕捉效果。我们还进行了不同维度的缺省研究，发现不同的维度对不同类型的讨论关系有不同的影响。这些模式可以通过维度在不同类型的讨论关系中的角色来解释。我们还报告了自动预测这些维度的实验结果。
</details></li>
</ul>
<hr>
<h2 id="Distil-Whisper-Robust-Knowledge-Distillation-via-Large-Scale-Pseudo-Labelling"><a href="#Distil-Whisper-Robust-Knowledge-Distillation-via-Large-Scale-Pseudo-Labelling" class="headerlink" title="Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling"></a>Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00430">http://arxiv.org/abs/2311.00430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchit Gandhi, Patrick von Platen, Alexander M. Rush</li>
<li>for: 这篇论文的目的是要开发一个可以在低延迟和资源受限的环境中运行的小型语音识别模型，并且可以与大型预训练模型相比。</li>
<li>methods: 这篇论文使用pseudo-labeling技术来构建一个大规模的开源数据集，然后使用这个数据集来将Whisper模型精简为一个小型模型，称为Distil-Whisper。这个精简模型比原始模型更快速，并且在零执行状况下可以保持与原始模型相同的表现。</li>
<li>results: 根据论文的结果，Distil-Whisper模型比原始模型更快速，并且在零执行状况下可以保持与原始模型相同的表现。此外，Distil-Whisper模型还可以与Whisper模型配合进行推测运算，实现2倍的速度提升。<details>
<summary>Abstract</summary>
As the size of pre-trained speech recognition models increases, running these large models in low-latency or resource-constrained environments becomes challenging. In this work, we leverage pseudo-labelling to assemble a large-scale open-source dataset which we use to distill the Whisper model into a smaller variant, called Distil-Whisper. Using a simple word error rate (WER) heuristic, we select only the highest quality pseudo-labels for training. The distilled model is 5.8 times faster with 51% fewer parameters, while performing to within 1% WER on out-of-distribution test data in a zero-shot transfer setting. Distil-Whisper maintains the robustness of the Whisper model to difficult acoustic conditions, while being less prone to hallucination errors on long-form audio. Distil-Whisper is designed to be paired with Whisper for speculative decoding, yielding a 2 times speed-up while mathematically ensuring the same outputs as the original model. To facilitate further research in this domain, we make our training code, inference code and models publicly accessible.
</details>
<details>
<summary>摘要</summary>
随着预训练语音识别模型的大小增加，运行这些大模型在低延迟或资源受限的环境中变得困难。在这项工作中，我们利用假标签来组织大规模的开源数据集，并使用简单的单词错误率（WER）归一化来选择最高质量的假标签进行训练。经过筛选后，我们提取了一个尺寸更小的变体，称为Distil-Whisper，它比原始模型快5.8倍，参数数量减少51%，并在零推导 Setting下测试数据上保持1% WER的水平。Distil-Whisper保持了Whisper模型对听频条件的鲁棒性，而且对长声道数据库的投射错误减少。Distil-Whisper是与Whisper模型推测的快速版本，可以在不改变输出的前提下提高速度2倍。为便于进一步的研究，我们将训练代码、推测代码和模型公开 accessible。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Human-AI-Coordination-via-Preparatory-Language-based-Convention"><a href="#Efficient-Human-AI-Coordination-via-Preparatory-Language-based-Convention" class="headerlink" title="Efficient Human-AI Coordination via Preparatory Language-based Convention"></a>Efficient Human-AI Coordination via Preparatory Language-based Convention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00416">http://arxiv.org/abs/2311.00416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Guan, Lichao Zhang, Chunpeng Fan, Yichen Li, Feng Chen, Lihe Li, Yunjia Tian, Lei Yuan, Yang Yu</li>
<li>For: The paper aims to develop a method for human-AI coordination that can effectively guide both human and AI agents in achieving their goals.* Methods: The proposed method employs a large language model (LLM) to generate a convention that specifies individual roles and actions, facilitating orderly coordination between humans and AI. The convention is generated based on task requirements, human preferences, and other pertinent information.* Results: The proposed method outperforms existing learning-based approaches in the Overcooked-AI environment and achieves better alignment with human preferences when coordinating with real humans. The average performance improvement is 15% compared to the state-of-the-art.<details>
<summary>Abstract</summary>
Developing intelligent agents capable of seamless coordination with humans is a critical step towards achieving artificial general intelligence. Existing methods for human-AI coordination typically train an agent to coordinate with a diverse set of policies or with human models fitted from real human data. However, the massively diverse styles of human behavior present obstacles for AI systems with constrained capacity, while high quality human data may not be readily available in real-world scenarios. In this study, we observe that prior to coordination, humans engage in communication to establish conventions that specify individual roles and actions, making their coordination proceed in an orderly manner. Building upon this observation, we propose employing the large language model (LLM) to develop an action plan (or equivalently, a convention) that effectively guides both human and AI. By inputting task requirements, human preferences, the number of agents, and other pertinent information into the LLM, it can generate a comprehensive convention that facilitates a clear understanding of tasks and responsibilities for all parties involved. Furthermore, we demonstrate that decomposing the convention formulation problem into sub-problems with multiple new sessions being sequentially employed and human feedback, will yield a more efficient coordination convention. Experimental evaluations conducted in the Overcooked-AI environment, utilizing a human proxy model, highlight the superior performance of our proposed method compared to existing learning-based approaches. When coordinating with real humans, our method achieves better alignment with human preferences and an average performance improvement of 15% compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
发展智能代理可以轻松协调人类是达到人工总智能的关键一步。现有的人机协调方法通常是训练一个代理可以协调一个多样化的政策集或者从真实人类数据中适应人类模型。然而，人类行为的极其多样性对具有限制的AI系统来说是一个很大的挑战，而高质量的人类数据可能在实际场景中不易获得。在这项研究中，我们发现在协调之前，人类会通过交流来确定协调的标准和行动，使其协调顺序进行。基于这一观察，我们提议使用大语言模型（LLM）来开发一个行动计划（或等效地，一个会议），以便导引人类和AI进行协调。通过输入任务需求、人类偏好、代理数量和其他相关信息到LLM，它可以生成一份全面的会议，以便帮助所有参与者理解任务和责任。此外，我们还证明了将会议形式问题分解成多个新会议，并采用人类反馈，可以提高协调会议的效率。在Overcooked-AI环境中的实验评估中，我们的提议方法与现有的学习基于方法相比，显示了更高的性能。当与真正的人类协调时，我们的方法可以更好地与人类偏好相协调，并在平均上提高15%的性能。
</details></li>
</ul>
<hr>
<h2 id="AdaSent-Efficient-Domain-Adapted-Sentence-Embeddings-for-Few-Shot-Classification"><a href="#AdaSent-Efficient-Domain-Adapted-Sentence-Embeddings-for-Few-Shot-Classification" class="headerlink" title="AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification"></a>AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00408">http://arxiv.org/abs/2311.00408</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ukplab/adasent">https://github.com/ukplab/adasent</a></li>
<li>paper_authors: Yongxin Huang, Kexin Wang, Sourav Dutta, Raj Nath Patel, Goran Glavaš, Iryna Gurevych</li>
<li>For:  investigate strategies for domain-specialization in the context of few-shot sentence classification with Pre-trained Sentence Encoders (SEs)* Methods:  unsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language Model (PLM), training a SEPT adapter on the base PLM to decouple SEPT from DAPT* Results:  substantially improves the accuracy of few-shot sentence classification, matches or surpasses the performance of full SEPT on DAPT-ed PLM, while substantially reducing the training costs<details>
<summary>Abstract</summary>
Recent work has found that few-shot sentence classification based on pre-trained Sentence Encoders (SEs) is efficient, robust, and effective. In this work, we investigate strategies for domain-specialization in the context of few-shot sentence classification with SEs. We first establish that unsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language Model (PLM) (i.e., not an SE) substantially improves the accuracy of few-shot sentence classification by up to 8.4 points. However, applying DAPT on SEs, on the one hand, disrupts the effects of their (general-domain) Sentence Embedding Pre-Training (SEPT). On the other hand, applying general-domain SEPT on top of a domain-adapted base PLM (i.e., after DAPT) is effective but inefficient, since the computationally expensive SEPT needs to be executed on top of a DAPT-ed PLM of each domain. As a solution, we propose AdaSent, which decouples SEPT from DAPT by training a SEPT adapter on the base PLM. The adapter can be inserted into DAPT-ed PLMs from any domain. We demonstrate AdaSent's effectiveness in extensive experiments on 17 different few-shot sentence classification datasets. AdaSent matches or surpasses the performance of full SEPT on DAPT-ed PLM, while substantially reducing the training costs. The code for AdaSent is available.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhanced-Knowledge-Injection-for-Radiology-Report-Generation"><a href="#Enhanced-Knowledge-Injection-for-Radiology-Report-Generation" class="headerlink" title="Enhanced Knowledge Injection for Radiology Report Generation"></a>Enhanced Knowledge Injection for Radiology Report Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00399">http://arxiv.org/abs/2311.00399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingqiu Li, Jilan Xu, Runtian Yuan, Mohan Chen, Yuejie Zhang, Rui Feng, Xiaobo Zhang, Shang Gao</li>
<li>for: 提高自动生成医学图像报告的精度，alleviate 医生的工作负担，并提醒新手医生可能存在的异常。</li>
<li>methods: 提出了一个增强知识注入框架，包括两个分支：Weighted Concept Knowledge（WCK）分支和Multimodal Retrieval Knowledge（MRK）分支。WCK分支通过TF-IDF scores来权重医学概念，而MRK分支则从相似报告中提取 triplets，强调关键的临床信息和存在关系。</li>
<li>results: 对两个公共 benchmark 进行了广泛的实验，证明了我们的方法在其他状态之前的方法之上表现出色。剥离学 validate 两个提取的知识来源的效果。<details>
<summary>Abstract</summary>
Automatic generation of radiology reports holds crucial clinical value, as it can alleviate substantial workload on radiologists and remind less experienced ones of potential anomalies. Despite the remarkable performance of various image captioning methods in the natural image field, generating accurate reports for medical images still faces challenges, i.e., disparities in visual and textual data, and lack of accurate domain knowledge. To address these issues, we propose an enhanced knowledge injection framework, which utilizes two branches to extract different types of knowledge. The Weighted Concept Knowledge (WCK) branch is responsible for introducing clinical medical concepts weighted by TF-IDF scores. The Multimodal Retrieval Knowledge (MRK) branch extracts triplets from similar reports, emphasizing crucial clinical information related to entity positions and existence. By integrating this finer-grained and well-structured knowledge with the current image, we are able to leverage the multi-source knowledge gain to ultimately facilitate more accurate report generation. Extensive experiments have been conducted on two public benchmarks, demonstrating that our method achieves superior performance over other state-of-the-art methods. Ablation studies further validate the effectiveness of two extracted knowledge sources.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HARE-Explainable-Hate-Speech-Detection-with-Step-by-Step-Reasoning"><a href="#HARE-Explainable-Hate-Speech-Detection-with-Step-by-Step-Reasoning" class="headerlink" title="HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning"></a>HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00321">http://arxiv.org/abs/2311.00321</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joonkeekim/hare-hate-speech">https://github.com/joonkeekim/hare-hate-speech</a></li>
<li>paper_authors: Yongjin Yang, Joonkee Kim, Yujin Kim, Namgyu Ho, James Thorne, Se-young Yun</li>
<li>for: 针对社交媒体上的仇恨言论的准确检测，以确保在线安全。</li>
<li>methods: 利用大型自然语言模型（LLMs）的逻辑能力来填充现有涉 hate speech 的注释 schemes 中的理解漏洞，以便准确地训练检测模型。</li>
<li>results: 使用模型生成数据，与基eline比较，显示我们的方法在 SBIC 和 Implicit Hate benchmark 上表现出色，可以提高检测模型的准确性和泛化能力。<details>
<summary>Abstract</summary>
With the proliferation of social media, accurate detection of hate speech has become critical to ensure safety online. To combat nuanced forms of hate speech, it is important to identify and thoroughly explain hate speech to help users understand its harmful effects. Recent benchmarks have attempted to tackle this issue by training generative models on free-text annotations of implications in hateful text. However, we find significant reasoning gaps in the existing annotations schemes, which may hinder the supervision of detection models. In this paper, we introduce a hate speech detection framework, HARE, which harnesses the reasoning capabilities of large language models (LLMs) to fill these gaps in explanations of hate speech, thus enabling effective supervision of detection models. Experiments on SBIC and Implicit Hate benchmarks show that our method, using model-generated data, consistently outperforms baselines, using existing free-text human annotations. Analysis demonstrates that our method enhances the explanation quality of trained models and improves generalization to unseen datasets. Our code is available at https://github.com/joonkeekim/hare-hate-speech.git.
</details>
<details>
<summary>摘要</summary>
随着社交媒体的普及，准确检测仇恨言语已经成为在线保障安全的关键。为了对抗仇恨言语的复杂形式，需要识别并详细解释仇恨言语，以便用户理解其有害的效果。现有的标准监测方案存在重要的理解漏洞，这可能会阻碍检测模型的超级视图。在这篇论文中，我们介绍了一种仇恨言语检测框架，称为HARE，它利用大型自然语言模型（LLMs）的理解能力来填充现有标准监测方案中的解释漏洞，从而为检测模型提供有效的监测。我们的实验表明，使用我们的方法，使用模型生成的数据，可以在SBIC和隐式仇恨benchmark上 consistently outperform基elines，使用现有的自由文本人工监测。分析表明，我们的方法可以提高训练模型的解释质量和对未经见过的数据的泛化。我们的代码可以在https://github.com/joonkeekim/hare-hate-speech.git中获取。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Code-Translation-with-Comparable-Corpora-and-Multiple-References"><a href="#Data-Augmentation-for-Code-Translation-with-Comparable-Corpora-and-Multiple-References" class="headerlink" title="Data Augmentation for Code Translation with Comparable Corpora and Multiple References"></a>Data Augmentation for Code Translation with Comparable Corpora and Multiple References</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00317">http://arxiv.org/abs/2311.00317</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Veronicium/CMTrans">https://github.com/Veronicium/CMTrans</a></li>
<li>paper_authors: Yiqing Xie, Atharva Naik, Daniel Fried, Carolyn Rose</li>
<li>for: 本研究旨在解决翻译代码 между不同编程语言时的一个主要挑战，即并不具备并行训练数据。</li>
<li>methods: 本研究提出了两种数据扩充技术，一是建立可比较的代码库（i.e., 代码对应的功能相似的代码集），另一是将现有的并行数据扩充多个参考翻译。特别是，我们使用自然语言文档生成代码模型生成的程序来建立多种可比较的代码库，并对可用的并行数据进行自动生成多个翻译参考，并对其进行单元测试滤波，从而增加目标翻译的多样性。</li>
<li>results: 我们的数据扩充技术可以显著提高CodeT5在Java、Python和C++之间的翻译精度，准确率平均提高7.5% Computational Accuracy (CA@1)，这证明了翻译的正确性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Veronicium/CMTrans%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Veronicium/CMTrans中下载。</a><details>
<summary>Abstract</summary>
One major challenge of translating code between programming languages is that parallel training data is often limited. To overcome this challenge, we present two data augmentation techniques, one that builds comparable corpora (i.e., code pairs with similar functionality), and another that augments existing parallel data with multiple reference translations. Specifically, we build and analyze multiple types of comparable corpora, including programs generated from natural language documentation using a code generation model. Furthermore, to reduce overfitting to a single reference translation, we automatically generate additional translation references for available parallel data and filter the translations by unit tests, which increases variation in target translations. Experiments show that our data augmentation techniques significantly improve CodeT5 for translation between Java, Python, and C++ by an average of 7.5% Computational Accuracy (CA@1), which verifies the correctness of translations by execution. The code is available at https://github.com/Veronicium/CMTrans.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在代码之间的翻译是平行训练数据的有限性。为了解决这个挑战，我们提出了两种数据扩充技术，一种建立相似代码对（i.e., 代码对的功能相似），另一种将现有平行数据扩充多个参考翻译。我们首先构建多种类型的相似代码对，包括从自然语言文档生成的代码。此外，为了减少参考翻译的过拟合，我们自动生成了多个翻译参考，并使用单元测试过滤target翻译，从而增加目标翻译的多样性。实验表明，我们的数据扩充技术可以在Java、Python和C++之间的翻译中提高CodeT5的平均计算准确率（CA@1）约7.5%，这 verify了翻译的正确性。代码可以在https://github.com/Veronicium/CMTrans中找到。
</details></li>
</ul>
<hr>
<h2 id="Probing-Explicit-and-Implicit-Gender-Bias-through-LLM-Conditional-Text-Generation"><a href="#Probing-Explicit-and-Implicit-Gender-Bias-through-LLM-Conditional-Text-Generation" class="headerlink" title="Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation"></a>Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00306">http://arxiv.org/abs/2311.00306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangjue Dong, Yibo Wang, Philip S. Yu, James Caverlee<br>for:This paper aims to evaluate the gender bias of large language models (LLMs) without relying on predefined gender-related phrases or stereotypes.methods:The proposed approach uses three types of inputs generated through three distinct strategies to probe LLMs for evidence of explicit and implicit gender biases.results:The experiments show that all tested LLMs exhibit explicit and&#x2F;or implicit gender bias, even when explicit gender stereotypes are absent in the inputs. Additionally, an increased model size does not consistently lead to enhanced fairness.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which are challenging to be comprehensively collected and are limited to explicit bias evaluation. In addition, we believe that instances devoid of gender-related language or explicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in this work, we propose a conditional text generation mechanism without the need for predefined gender phrases and stereotypes. This approach employs three types of inputs generated through three distinct strategies to probe LLMs, aiming to show evidence of explicit and implicit gender biases in LLMs. We also utilize explicit and implicit evaluation metrics to evaluate gender bias in LLMs under different strategies. Our experiments demonstrate that an increased model size does not consistently lead to enhanced fairness and all tested LLMs exhibit explicit and/or implicit gender bias, even when explicit gender stereotypes are absent in the inputs.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The translation is written in a more formal and literary style, which may be different from the way the text would be written in spoken Chinese.
</details></li>
</ul>
<hr>
<h2 id="Detecting-Syllable-Level-Pronunciation-Stress-with-A-Self-Attention-Model"><a href="#Detecting-Syllable-Level-Pronunciation-Stress-with-A-Self-Attention-Model" class="headerlink" title="Detecting Syllable-Level Pronunciation Stress with A Self-Attention Model"></a>Detecting Syllable-Level Pronunciation Stress with A Self-Attention Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00301">http://arxiv.org/abs/2311.00301</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangweiying303/stress-detection-model">https://github.com/wangweiying303/stress-detection-model</a></li>
<li>paper_authors: Wang Weiying, Nakajima Akinori</li>
<li>for: 这篇论文是为了研究如何使用自注意模型来检测英语说话时的句子强调水平的。</li>
<li>methods: 这篇论文使用了多种语音和分类特征，如抑压水平、干扰度、持续时间和元音等，输入到自注意模型中，并预测每个句子中的强调水平。</li>
<li>results: 研究发现，使用最简单的模型可以在不同的数据集上达到88%以上的准确率和93%以上的准确率，而更先进的模型可以提供更高的准确率。这些模型可以应用于在线会议和英语学习等场景。<details>
<summary>Abstract</summary>
One precondition of effective oral communication is that words should be pronounced clearly, especially for non-native speakers. Word stress is the key to clear and correct English, and misplacement of syllable stress may lead to misunderstandings. Thus, knowing the stress level is important for English speakers and learners. This paper presents a self-attention model to identify the stress level for each syllable of spoken English. Various prosodic and categorical features, including the pitch level, intensity, duration and type of the syllable and its nuclei (the vowel of the syllable), are explored. These features are input to the self-attention model, and syllable-level stresses are predicted. The simplest model yields an accuracy of over 88% and 93% on different datasets, while more advanced models provide higher accuracy. Our study suggests that the self-attention model can be promising in stress-level detection. These models could be applied to various scenarios, such as online meetings and English learning.
</details>
<details>
<summary>摘要</summary>
一个听众交流的先件是使用英语Clearly pronounce words, especially for non-native speakers.  Correct word stress is crucial for clear and accurate English, and misplacing syllable stress can lead to misunderstandings. Therefore, knowing the stress level is essential for English speakers and learners. This paper proposes a self-attention model to identify the stress level for each syllable of spoken English. Various prosodic and categorical features, such as pitch level, intensity, duration, and type of the syllable and its nuclei (the vowel of the syllable), are explored. These features are input to the self-attention model, and syllable-level stresses are predicted. The simplest model achieves an accuracy of over 88% and 93% on different datasets, while more advanced models provide higher accuracy. Our study suggests that the self-attention model is promising in stress-level detection and can be applied to various scenarios, such as online meetings and English learning.
</details></li>
</ul>
<hr>
<h2 id="Entity-Alignment-Method-of-Science-and-Technology-Patent-based-on-Graph-Convolution-Network-and-Information-Fusion"><a href="#Entity-Alignment-Method-of-Science-and-Technology-Patent-based-on-Graph-Convolution-Network-and-Information-Fusion" class="headerlink" title="Entity Alignment Method of Science and Technology Patent based on Graph Convolution Network and Information Fusion"></a>Entity Alignment Method of Science and Technology Patent based on Graph Convolution Network and Information Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00300">http://arxiv.org/abs/2311.00300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runze Fang, Yawen Li, Yingxia Shao, Zeli Guan, Zhe Xue</li>
<li>for: 该研究旨在提高科技专利知识图中实体对应关系的准确率，通过利用图 convolutional neural network 和 BERT 模型， simultaneously fusing 多种信息，包括图структуры信息和实体属性信息。</li>
<li>methods: 该方法使用图 convolutional neural network 和 BERT 模型，对科技专利知识图中的实体进行嵌入和表示，实现多信息融合，以提高实体对应关系的准确率。</li>
<li>results: 实验结果表明，提案的方法在三个数据集上的评价指标均高于现有方法。<details>
<summary>Abstract</summary>
The entity alignment of science and technology patents aims to link the equivalent entities in the knowledge graph of different science and technology patent data sources. Most entity alignment methods only use graph neural network to obtain the embedding of graph structure or use attribute text description to obtain semantic representation, ignoring the process of multi-information fusion in science and technology patents. In order to make use of the graphic structure and auxiliary information such as the name, description and attribute of the patent entity, this paper proposes an entity alignment method based on the graph convolution network for science and technology patent information fusion. Through the graph convolution network and BERT model, the structure information and entity attribute information of the science and technology patent knowledge graph are embedded and represented to achieve multi-information fusion, thus improving the performance of entity alignment. Experiments on three benchmark data sets show that the proposed method Hit@K The evaluation indicators are better than the existing methods.
</details>
<details>
<summary>摘要</summary>
<SYS> translate(The entity alignment of science and technology patents aims to link the equivalent entities in the knowledge graph of different science and technology patent data sources. Most entity alignment methods only use graph neural network to obtain the embedding of graph structure or use attribute text description to obtain semantic representation, ignoring the process of multi-information fusion in science and technology patents. In order to make use of the graphic structure and auxiliary information such as the name, description and attribute of the patent entity, this paper proposes an entity alignment method based on the graph convolution network for science and technology patent information fusion. Through the graph convolution network and BERT model, the structure information and entity attribute information of the science and technology patent knowledge graph are embedded and represented to achieve multi-information fusion, thus improving the performance of entity alignment. Experiments on three benchmark data sets show that the proposed method Hit@K The evaluation indicators are better than the existing methods.)</SYS>Here's the translation in Simplified Chinese:科技专利实体对Alignment的目标是将不同科技专利数据源知识图中的相同实体相互链接。大多数实体对齐方法只是使用图 neural network获取图 структуры的嵌入或者使用特征文本描述获取 semantic表示，忽略了科技专利中的多信息融合过程。为了利用图结构和辅助信息such as 专利名称、描述和属性，本文提出了基于图 convolution network的科技专利信息融合的实体对齐方法。通过图 convolution network和BERT模型，科技专利知识图的结构信息和实体属性信息被嵌入和表示，实现多信息融合，提高实体对齐性能。对三个 Referenced data set进行实验，评估指标比现有方法更好。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Representation-Learning-of-Scientific-Literature-based-on-Adaptive-Feature-and-Graph-Neural-Network"><a href="#Semantic-Representation-Learning-of-Scientific-Literature-based-on-Adaptive-Feature-and-Graph-Neural-Network" class="headerlink" title="Semantic Representation Learning of Scientific Literature based on Adaptive Feature and Graph Neural Network"></a>Semantic Representation Learning of Scientific Literature based on Adaptive Feature and Graph Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00296">http://arxiv.org/abs/2311.00296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongrui Gao, Yawen Li, Meiyu Liang, Zeli Guan, Zhe Xue</li>
<li>for: 科学文献semantic representation学习，以提高文献分类的能力。</li>
<li>methods: 提议使用自适应特征方法和图神经网络，对科学文献进行 semantic representation 学习。图神经网络可以捕捉本地和全球信息，提高文献分类的准确率。</li>
<li>results: 实验结果显示，提议的方法可以在基于科学文献分类的情况下达到比较好的效果，并且比传统方法更高的准确率。<details>
<summary>Abstract</summary>
Because most of the scientific literature data is unmarked, it makes semantic representation learning based on unsupervised graph become crucial. At the same time, in order to enrich the features of scientific literature, a learning method of semantic representation of scientific literature based on adaptive features and graph neural network is proposed. By introducing the adaptive feature method, the features of scientific literature are considered globally and locally. The graph attention mechanism is used to sum the features of scientific literature with citation relationship, and give each scientific literature different feature weights, so as to better express the correlation between the features of different scientific literature. In addition, an unsupervised graph neural network semantic representation learning method is proposed. By comparing the mutual information between the positive and negative local semantic representation of scientific literature and the global graph semantic representation in the potential space, the graph neural network can capture the local and global information, thus improving the learning ability of the semantic representation of scientific literature. The experimental results show that the proposed learning method of semantic representation of scientific literature based on adaptive feature and graph neural network is competitive on the basis of scientific literature classification, and has achieved good results.
</details>
<details>
<summary>摘要</summary>
因为大多数科学文献数据未经标记，因此使得基于无监督图的 semantic representation 学习成为关键。同时，为了丰富科学文献的特征，一种基于自适应特征和图神经网络的科学文献semantic representation 学习方法被提议。通过引入自适应特征方法，科学文献的特征被考虑在全球和本地方面。使用图注意力机制将科学文献之间的引用关系权重调整，以更好地表达不同科学文献之间的相关性。此外，一种无监督图神经网络 semantic representation 学习方法被提议。通过比较科学文献的正向和负向本地semantic representation在潜在空间中的互信息，图神经网络可以捕捉本地和全球信息，从而提高 semantic representation 的学习能力。实验结果表明，提议的基于自适应特征和图神经网络的科学文献semantic representation 学习方法在科学文献分类任务上具有竞争力，并实现了良好的效果。
</details></li>
</ul>
<hr>
<h2 id="IBADR-an-Iterative-Bias-Aware-Dataset-Refinement-Framework-for-Debiasing-NLU-models"><a href="#IBADR-an-Iterative-Bias-Aware-Dataset-Refinement-Framework-for-Debiasing-NLU-models" class="headerlink" title="IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models"></a>IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00292">http://arxiv.org/abs/2311.00292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyue Wang, Xin Liu, Lijie Wang, Yaoxiang Wang, Jinsong Su, Hua Wu</li>
<li>for: 本研究旨在提出一种基于迭代偏好感知的数据精炼框架，以减少自然语言理解（NLU）模型中的偏好。</li>
<li>methods: 我们提出了一种迭代偏好感知（IBADR）框架，它不需要先定义偏好特征，可以自动检测和修复偏好。我们维护了一个迭代扩展的样本池，并在每次迭代中使用一个浅度模型来评估样本中偏好的程度。</li>
<li>results: 我们的实验结果和深入分析表明，IBADR不仅可以大幅超越现有的数据精炼方法，还可以与模型中心的方法兼容。IBADR可以生成具有更少偏好特征的 Pseudo 样本，从而提高 NLU 模型的性能。<details>
<summary>Abstract</summary>
As commonly-used methods for debiasing natural language understanding (NLU) models, dataset refinement approaches heavily rely on manual data analysis, and thus maybe unable to cover all the potential biased features. In this paper, we propose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which debiases NLU models without predefining biased features. We maintain an iteratively expanded sample pool. Specifically, at each iteration, we first train a shallow model to quantify the bias degree of samples in the pool. Then, we pair each sample with a bias indicator representing its bias degree, and use these extended samples to train a sample generator. In this way, this generator can effectively learn the correspondence relationship between bias indicators and samples. Furthermore, we employ the generator to produce pseudo samples with fewer biased features by feeding specific bias indicators. Finally, we incorporate the generated pseudo samples into the pool. Experimental results and in-depth analyses on two NLU tasks show that IBADR not only significantly outperforms existing dataset refinement approaches, achieving SOTA, but also is compatible with model-centric methods.
</details>
<details>
<summary>摘要</summary>
通常使用的自然语言理解（NLU）模型偏见纠正方法， dataset 纠正方法倚靠手动数据分析，因此可能无法涵盖所有潜在的偏见特征。在这篇论文中，我们提议 IBADR，一种迭代偏见意识数据纠正框架，无需先定偏见特征来纠正 NLU 模型。我们保持一个迭代扩展的样本池。具体来说，在每一轮中，我们首先使用一个浅度模型来评估样本池中每个样本的偏见度。然后，我们对每个样本分别生成一个偏见指标，表示其偏见度。这些扩展后的样本与模型进行训练，使得这些模型可以有效地学习偏见指标与样本之间的对应关系。此外，我们使用这些模型生成具有更少偏见特征的 Pseudo 样本。最后，我们将生成的 Pseudo 样本添加到样本池中。实验结果和深入分析表明， IBADR 不仅能够显著超越现有的 dataset 纠正方法，达到最佳性能，而且可以与模型中心方法兼容。
</details></li>
</ul>
<hr>
<h2 id="SoulChat-Improving-LLMs’-Empathy-Listening-and-Comfort-Abilities-through-Fine-tuning-with-Multi-turn-Empathy-Conversations"><a href="#SoulChat-Improving-LLMs’-Empathy-Listening-and-Comfort-Abilities-through-Fine-tuning-with-Multi-turn-Empathy-Conversations" class="headerlink" title="SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations"></a>SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00273">http://arxiv.org/abs/2311.00273</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scutcyr/soulchat">https://github.com/scutcyr/soulchat</a></li>
<li>paper_authors: Yirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng, Zhenyu Wang, Qi Liu, Xiangmin Xu</li>
<li>for: 这研究旨在提高大语言模型在心理咨询领域的同理能力。</li>
<li>methods: 研究人员构建了一个多turn对话context数据集，并使用多turn对话历史和更加接近心理咨询员的回应进行finetuning，以提高大语言模型的同理能力。</li>
<li>results: 实验结果显示，通过使用多turn对话历史和更加接近心理咨询员的回应进行finetuning，可以显著提高大语言模型的同理能力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Syntactic-Inductive-Bias-in-Transformer-Language-Models-Especially-Helpful-for-Low-Resource-Languages"><a href="#Syntactic-Inductive-Bias-in-Transformer-Language-Models-Especially-Helpful-for-Low-Resource-Languages" class="headerlink" title="Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?"></a>Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00268">http://arxiv.org/abs/2311.00268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Gessler, Nathan Schneider</li>
<li>for: 这个研究是为了检查使用语法印欧特征来增强预训练过程的效果，特别是在低资源语言中。</li>
<li>methods: 这个研究使用了Transformer基于模型，如BERT，并在预训练过程中添加了语法印欧特征。</li>
<li>results: 研究发现，在低资源语言中，这些语法印欧特征方法的效果不均，并且在大多数情况下提供了Surprisingly little benefit。<details>
<summary>Abstract</summary>
A line of work on Transformer-based language models such as BERT has attempted to use syntactic inductive bias to enhance the pretraining process, on the theory that building syntactic structure into the training process should reduce the amount of data needed for training. But such methods are often tested for high-resource languages such as English. In this work, we investigate whether these methods can compensate for data sparseness in low-resource languages, hypothesizing that they ought to be more effective for low-resource languages. We experiment with five low-resource languages: Uyghur, Wolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic inductive bias methods produce uneven results in low-resource settings, and provide surprisingly little benefit in most cases.
</details>
<details>
<summary>摘要</summary>
一种工作使用基于转移器的语言模型，如BERT，尝试使用 sintactic inductive bias 来增强预训练过程，理解建立语法结构在训练过程中应该减少数据量需要。但这些方法通常在高资源语言 such as English 上测试。在这个工作中，我们调查了这些方法是否可以在低资源语言中资源不足的情况下提供更好的效果，假设它们应该更有效果于低资源语言。我们在五种低资源语言中进行了实验：维吾尔语、沃洛语、马耳他语、古埃及语和古希腊语。我们发现这些 sintactic inductive bias 方法在低资源设置下的结果不均匀，并且在大多数情况下提供了不足的 beneficial 效果。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Exemplars-Make-Large-Language-Models-More-Robust-A-Domain-Agnostic-Behavioral-Analysis"><a href="#Noisy-Exemplars-Make-Large-Language-Models-More-Robust-A-Domain-Agnostic-Behavioral-Analysis" class="headerlink" title="Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis"></a>Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00258">http://arxiv.org/abs/2311.00258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust">https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust</a></li>
<li>paper_authors: Hongyi Zheng, Abulhair Saparov</li>
<li>for: 研究 LLM 在多步逻辑理解任务中的稳定性。</li>
<li>methods: 使用多级抽象的干扰（如 Typos 和中间逻辑步骤的包含）进行Behavioral Analysis。</li>
<li>results: 发现模型更敏感于替换单词为同义词的干扰，并证明增加干扰示例的比例可以提高少量示例引导方法的稳定性。<details>
<summary>Abstract</summary>
Recent advances in prompt engineering enable large language models (LLMs) to solve multi-hop logical reasoning problems with impressive accuracy. However, there is little existing work investigating the robustness of LLMs with few-shot prompting techniques. Therefore, we introduce a systematic approach to test the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic perturbations. We include perturbations at multiple levels of abstractions (e.g. lexical perturbations such as typos, and semantic perturbations such as the inclusion of intermediate reasoning steps in the questions) to conduct behavioral analysis on the LLMs. Throughout our experiments, we find that models are more sensitive to certain perturbations such as replacing words with their synonyms. We also demonstrate that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近的提示工程技术突破使得大型自然语言模型（LLM）在多步逻辑推理任务中表现出色。然而，现有的工作却很少研究了LLM在几步提示技术下的Robustness。因此，我们提出了一种系统的方法来测试LLM在多步逻辑推理任务中的Robustness，通过具有多级抽象水平的随机变化（如Typos和中间推理步骤的包含）来进行行为分析。在我们的实验中，我们发现模型对某些变化（如替换单词）更为敏感。此外，我们还证明了在提示中增加受到干扰的 exemplars 的比例可以提高几步提示方法的Robustness。
</details></li>
</ul>
<hr>
<h2 id="The-Mystery-and-Fascination-of-LLMs-A-Comprehensive-Survey-on-the-Interpretation-and-Analysis-of-Emergent-Abilities"><a href="#The-Mystery-and-Fascination-of-LLMs-A-Comprehensive-Survey-on-the-Interpretation-and-Analysis-of-Emergent-Abilities" class="headerlink" title="The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities"></a>The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00237">http://arxiv.org/abs/2311.00237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Zhou, Jiazheng Li, Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He</li>
<li>For: This paper aims to provide a comprehensive survey of the interpretation and analysis of emergent abilities in large language models (LLMs), including their mechanistic and empirical interpretability.* Methods: The paper uses a macro perspective to examine the mathematical foundations of emergent abilities, as well as a micro perspective to study the factors associated with these abilities through empirical research.* Results: The paper highlights the challenges encountered in interpreting and analyzing emergent abilities in LLMs, and suggests potential avenues for future research to better understand and utilize these capabilities.Here is the same information in Simplified Chinese text:* For: 这篇论文目的是为了对大型自然语言模型（LLM）中的emergent能力进行全面的审查和分析，包括它们的机制性和实际性可解性。* Methods: 论文使用了macro perspective来检查emergent能力的数学基础，以及micro perspective来研究这些能力与这些因素的关系。* Results: 论文指出了对emergent能力的解释和分析存在挑战，并提出了将来研究的可能性，以更好地理解和利用这些能力。<details>
<summary>Abstract</summary>
Understanding emergent abilities, such as in-context learning (ICL) and chain-of-thought (CoT) prompting in large language models (LLMs), is of utmost importance. This importance stems not only from the better utilization of these capabilities across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns of truthfulness, bias, and toxicity, that may arise alongside these capabilities. In this paper, we present a thorough survey on the interpretation and analysis of emergent abilities of LLMs. First, we provide a concise introduction to the background and definition of emergent abilities. Then, we give an overview of advancements from two perspectives: 1) a macro perspective, emphasizing studies on the mechanistic interpretability and delving into the mathematical foundations behind emergent abilities; and 2) a micro-perspective, concerning studies that focus on empirical interpretability by examining factors associated with these abilities. We conclude by highlighting the challenges encountered and suggesting potential avenues for future research. We believe that our work establishes the basis for further exploration into the interpretation of emergent abilities.
</details>
<details>
<summary>摘要</summary>
理解大语言模型（LLM）中的emergent能力（如上下文学习（ICL）和串行思维（CoT））对我们非常重要。这种重要性不仅来自于更好地利用这些能力在各种任务上，而且还来自于积极发现和 mitigate potential risks，包括可能出现的真实性、偏见和恶势力问题。在这篇论文中，我们提供了一份广泛的survey关于LLM的emergent能力的解释和分析。首先，我们提供了一个简洁的引入，概述背景和emergent能力的定义。然后，我们给出了两个视角的总结：1）一个 macro 视角，强调机制可读性和数学基础之间的关系; 2）一个 micro 视角，关注关于这些能力的实际可读性，通过分析这些能力相关的因素。我们 conclude by highlighting the challenges encountered and suggesting potential avenues for future research.我们认为，我们的工作laying the foundation for further exploration of emergent abilities的解释。
</details></li>
</ul>
<hr>
<h2 id="Distort-Distract-Decode-Instruction-Tuned-Model-Can-Refine-its-Response-from-Noisy-Instructions"><a href="#Distort-Distract-Decode-Instruction-Tuned-Model-Can-Refine-its-Response-from-Noisy-Instructions" class="headerlink" title="Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions"></a>Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00233">http://arxiv.org/abs/2311.00233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taehyeon Kim, Joonkee Kim, Gihun Lee, Se-Young Yun</li>
<li>for: 提高 instruction-tuned 模型的 zero-shot 泛化能力</li>
<li>methods: 使用干扰版本的原始 instruction 生成潜在可能的回答，并对 next-token 预测 logits 进行冲突调整</li>
<li>results: 在不同的 instruction-tuned 模型和任务上实现了显著的性能提升，无需进行额外参数更新<details>
<summary>Abstract</summary>
While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that augments the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessitating any additional parameter updates. Notably, utilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum divergence from the original instruction, consistently produces the most significant performance gains across multiple models and tasks.
</details>
<details>
<summary>摘要</summary>
While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that enhances the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessitating any additional parameter updates. Notably, utilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum divergence from the original instruction, consistently produces the most significant performance gains across multiple models and tasks.Here is the translation in Traditional Chinese:虽然受训语言模型已经展示了很好的零例外推导能力，但这些模型在面对不同于训练集的指令时，通常会显示出低准确性。本文提出了几个简单 yet effective的方法，包括几个 Instructive Decoding (ID) 技术，以提高受训语言模型的效能。特别是，ID 会在下一个字prediction中调整 logits 的排名，使其在不同的指令下具有更高的弹性。我们在不同的噪音指令下进行了实验，包括在指令中插入随机词或使用 'opposite' 类型的噪音指令，以诱发模型产生更多的偏离。我们发现，使用 'opposite' 类型的噪音指令可以对多个模型和任务产生最大的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Is-GPT-Powerful-Enough-to-Analyze-the-Emotions-of-Memes"><a href="#Is-GPT-Powerful-Enough-to-Analyze-the-Emotions-of-Memes" class="headerlink" title="Is GPT Powerful Enough to Analyze the Emotions of Memes?"></a>Is GPT Powerful Enough to Analyze the Emotions of Memes?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00223">http://arxiv.org/abs/2311.00223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingjing Wang, Joshua Luo, Grace Yang, Allen Hong, Feng Luo</li>
<li>for: 本研究旨在探讨GPT-3.5在互联网趣味图文（meme）中的情感分析能力。</li>
<li>methods: 本研究使用GPT-3.5模型进行趣味图文的情感分类、幽默类型的确定以及带有偏见的恶意趣味图文的检测。</li>
<li>results: 研究发现GPT-3.5在处理主观任务时存在一定的限制，包括理解社会规范、文化背景和含义层次的理解等。尽管GPT-3.5在一些任务上表现出色，但在某些情况下，其响应仍然需要人工审核和改进。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), representing a significant achievement in artificial intelligence (AI) research, have demonstrated their ability in a multitude of tasks. This project aims to explore the capabilities of GPT-3.5, a leading example of LLMs, in processing the sentiment analysis of Internet memes. Memes, which include both verbal and visual aspects, act as a powerful yet complex tool for expressing ideas and sentiments, demanding an understanding of societal norms and cultural contexts. Notably, the detection and moderation of hateful memes pose a significant challenge due to their implicit offensive nature. This project investigates GPT's proficiency in such subjective tasks, revealing its strengths and potential limitations. The tasks include the classification of meme sentiment, determination of humor type, and detection of implicit hate in memes. The performance evaluation, using datasets from SemEval-2020 Task 8 and Facebook hateful memes, offers a comparative understanding of GPT responses against human annotations. Despite GPT's remarkable progress, our findings underscore the challenges faced by these models in handling subjective tasks, which are rooted in their inherent limitations including contextual understanding, interpretation of implicit meanings, and data biases. This research contributes to the broader discourse on the applicability of AI in handling complex, context-dependent tasks, and offers valuable insights for future advancements.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Transformers-as-Recognizers-of-Formal-Languages-A-Survey-on-Expressivity"><a href="#Transformers-as-Recognizers-of-Formal-Languages-A-Survey-on-Expressivity" class="headerlink" title="Transformers as Recognizers of Formal Languages: A Survey on Expressivity"></a>Transformers as Recognizers of Formal Languages: A Survey on Expressivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00208">http://arxiv.org/abs/2311.00208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lena Strobl, William Merrill, Gail Weiss, David Chiang, Dana Angluin</li>
<li>for: 这篇论文探讨了使用形式语言处理问题，以了解transformer模型可以解决哪些问题，以及它们与其他模型和变体之间的比较。</li>
<li>methods: 论文使用了正式语言处理的方法，探讨了不同假设的影响，并提供了一个统一的框架来协调 aparently contradictory findings。</li>
<li>results: 论文提供了一个广泛的survey，涵盖了不同假设的影响，并提供了一个统一的框架来协调 aparently contradictory findings。<details>
<summary>Abstract</summary>
As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring questions such as this will help to compare transformers with other models, and transformer variants with one another, for various tasks. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings.
</details>
<details>
<summary>摘要</summary>
为了探讨自然语言处理中transformer的表现，一些研究人员已经对这些问题进行了理论分析，将问题视为 формаль语言。这种研究将帮助比较transformer和其他模型，以及不同transformer变体之间的比较，在不同任务中。在这个子领域中，工作有了很大的进步，我们在这篇文章中会进行一个系统的评论，整理不同假设的结果，并提供一个统一的框架，将可能的矛盾结果融合起来。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.CL_2023_11_01/" data-id="cloh7tqeq00di7b882hp00mya" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.LG_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T10:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.LG_2023_11_01/">cs.LG - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Decision-Support-Framework-for-Home-Health-Caregiver-Allocation-A-Case-Study-of-HHC-Agency-in-Tennessee-USA"><a href="#Decision-Support-Framework-for-Home-Health-Caregiver-Allocation-A-Case-Study-of-HHC-Agency-in-Tennessee-USA" class="headerlink" title="Decision Support Framework for Home Health Caregiver Allocation: A Case Study of HHC Agency in Tennessee, USA"></a>Decision Support Framework for Home Health Caregiver Allocation: A Case Study of HHC Agency in Tennessee, USA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00696">http://arxiv.org/abs/2311.00696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Mohammad Ebrahim Sharifnia, Faezeh Bagheri, Rupy Sawhney, John E. Kobza, Enrique Macias De Anda, Mostafa Hajiaghaei-Keshteli, Michael Mirrielees</li>
<li>for: 本研究旨在优化家庭健康服务（HHC）资源配置，以提高护理资源的利用率和患者满意度。</li>
<li>methods: 本研究提出了一种决策支持框架，该框架考虑护理工作者的访问顺序灵活性，以减少旅行里程，增加每个规划周期的访问次数，并保持护理连续性。</li>
<li>results: 使用美国田纳西州一家护理机构的数据，本研究的方法在减少旅行里程方面达到了非常出色的效果，最多可以减少42%（根据专业不同）。此外，提出的框架还可以为护理资源管理提供有价值的反思。<details>
<summary>Abstract</summary>
Population aging is a global challenge, leading to increased demand for healthcare and social services for the elderly. Home Health Care (HHC) emerges as a vital solution, specifically designed to serve this population segment. Given the surging demand for HHC, it's essential to coordinate and regulate caregiver allocation efficiently. This is crucial for both budget-optimized planning and ensuring the delivery of high-quality care. This research addresses a key question faced by home health agencies (HHAs): "How can caregiver allocation be optimized, especially when caregivers prefer flexibility in their visiting sequences?". While earlier studies proposed rigid visiting sequences, our study introduces a decision support framework that allocates caregivers through a hybrid method that considers the flexibility in visiting sequences and aims to reduce travel mileage, increase the number of visits per planning period, and maintain the continuity of care - a critical metric for patient satisfaction. Utilizing data from an HHA in Tennessee, United States, our approach led to an impressive reduction in average travel mileage (up to 42% depending on discipline) without imposing restrictions on caregivers. Furthermore, the proposed framework is used for caregivers' supply analysis to provide valuable insights into caregiver resource management.
</details>
<details>
<summary>摘要</summary>
全球人口老龄化问题带来增加医疗和社会服务的需求，特别是为老年人。家庭健康护理（HHC）成为了一种非常重要的解决方案，而且它的需求在不断增长。为了有效地协调和规范护理人员的分配，是非常重要的。这是因为预算的优化和高质量护理的确保是两个不可或缺的要求。本研究面临的关键问题是：“护理人员的分配如何优化，特别是当护理人员喜欢自由地访问时序？”earlier studies proposed rigid visiting sequences, our study introduces a decision support framework that allocates caregivers through a hybrid method that considers the flexibility in visiting sequences and aims to reduce travel mileage, increase the number of visits per planning period, and maintain the continuity of care - a critical metric for patient satisfaction. Using data from an HHA in Tennessee, United States, our approach led to an impressive reduction in average travel mileage (up to 42% depending on discipline) without imposing restrictions on caregivers. Furthermore, the proposed framework is used for caregivers' supply analysis to provide valuable insights into caregiver resource management.
</details></li>
</ul>
<hr>
<h2 id="Software-Repositories-and-Machine-Learning-Research-in-Cyber-Security"><a href="#Software-Repositories-and-Machine-Learning-Research-in-Cyber-Security" class="headerlink" title="Software Repositories and Machine Learning Research in Cyber Security"></a>Software Repositories and Machine Learning Research in Cyber Security</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00691">http://arxiv.org/abs/2311.00691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mounika Vanamala, Keith Bryant, Alex Caravella</li>
<li>for: 本研究旨在提高软件开发过程中早期发现潜在的安全漏洞，通过利用cyber安全库（如MITRE的CAPEC和CVE数据库）和自然语言处理技术（如主题模型和机器学习）自动化检测软件需求阶段的安全漏洞。</li>
<li>methods: 本研究使用了一系列的机器学习方法，包括不supervised学习方法（如LDA和主题模型）和supervised学习方法（如支持向量机器、愚见树、随机森林和神经网络），以检测软件需求阶段的安全漏洞。</li>
<li>results: 本研究结果表明，采用机器学习技术可以有效地检测软件需求阶段的安全漏洞，并且可以在不同的软件开发场景中提供有价值的助け手。<details>
<summary>Abstract</summary>
In today's rapidly evolving technological landscape and advanced software development, the rise in cyber security attacks has become a pressing concern. The integration of robust cyber security defenses has become essential across all phases of software development. It holds particular significance in identifying critical cyber security vulnerabilities at the initial stages of the software development life cycle, notably during the requirement phase. Through the utilization of cyber security repositories like The Common Attack Pattern Enumeration and Classification (CAPEC) from MITRE and the Common Vulnerabilities and Exposures (CVE) databases, attempts have been made to leverage topic modeling and machine learning for the detection of these early-stage vulnerabilities in the software requirements process. Past research themes have returned successful outcomes in attempting to automate vulnerability identification for software developers, employing a mixture of unsupervised machine learning methodologies such as LDA and topic modeling. Looking ahead, in our pursuit to improve automation and establish connections between software requirements and vulnerabilities, our strategy entails adopting a variety of supervised machine learning techniques. This array encompasses Support Vector Machines (SVM), Na\"ive Bayes, random forest, neural networking and eventually transitioning into deep learning for our investigation. In the face of the escalating complexity of cyber security, the question of whether machine learning can enhance the identification of vulnerabilities in diverse software development scenarios is a paramount consideration, offering crucial assistance to software developers in developing secure software.
</details>
<details>
<summary>摘要</summary>
今天的技术领域在快速发展，软件开发也在不断进步，但同时，网络安全攻击的数量也在增加。为了应对这些攻击，在软件开发过程中integrating Robust cybersecurity defenses has become essential。特别是在软件开发生命周期的需求阶段，革命化的攻击方式和漏洞的发现成为了一项非常重要的任务。通过利用MITRE提供的Common Attack Pattern Enumeration and Classification（CAPEC）和Common Vulnerabilities and Exposures（CVE）数据库，我们尝试通过主题模型和机器学习自动发现早期阶段的漏洞。过去的研究主题已经取得了成功，通过混合无监控机器学习方法，如Latent Dirichlet Allocation（LDA）和主题模型，自动检测漏洞。在前进的步骤中，我们的策略是采用多种监督式机器学习方法，包括Support Vector Machines（SVM）、Na\"ive Bayes、Random Forest、神经网络和最终转换为深度学习，以提高检测漏洞的自动化水平。随着网络安全的升级，机器学习是否能够提高检测漏洞在多样化软件开发场景中的能力，成为了一个非常重要的考虑因素，为软件开发人员提供了关键的帮助，以开发安全的软件。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Classification-of-Gamma-Photon-Interactions-in-Room-Temperature-Semiconductor-Radiation-Detectors"><a href="#Deep-Learning-Based-Classification-of-Gamma-Photon-Interactions-in-Room-Temperature-Semiconductor-Radiation-Detectors" class="headerlink" title="Deep Learning-Based Classification of Gamma Photon Interactions in Room-Temperature Semiconductor Radiation Detectors"></a>Deep Learning-Based Classification of Gamma Photon Interactions in Room-Temperature Semiconductor Radiation Detectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00682">http://arxiv.org/abs/2311.00682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep K. Chaudhuri, Qinyang Li, Krishna C. Mandal, Jianjun Hu</li>
<li>for: 这个研究旨在开发一个基于深度学习的检测器，以分别识别γ&#x2F;X射线 фото散射和电子�hrer interactions。</li>
<li>methods: 研究人员使用了一个深度学习模型CoPhNet，并以实验和 simulated 数据进行验证。</li>
<li>results: 研究结果显示，CoPhNet 模型可以实现高精度的分类，并且具有耐操作 parameter 的性能。<details>
<summary>Abstract</summary>
Photon counting radiation detectors have become an integral part of medical imaging modalities such as Positron Emission Tomography or Computed Tomography. One of the most promising detectors is the wide bandgap room temperature semiconductor detectors, which depends on the interaction gamma/x-ray photons with the detector material involves Compton scattering which leads to multiple interaction photon events (MIPEs) of a single photon. For semiconductor detectors like CdZnTeSe (CZTS), which have a high overlap of detected energies between Compton and photoelectric events, it is nearly impossible to distinguish between Compton scattered events from photoelectric events using conventional readout electronics or signal processing algorithms. Herein, we report a deep learning classifier CoPhNet that distinguishes between Compton scattering and photoelectric interactions of gamma/x-ray photons with CdZnTeSe (CZTS) semiconductor detectors. Our CoPhNet model was trained using simulated data to resemble actual CZTS detector pulses and validated using both simulated and experimental data. These results demonstrated that our CoPhNet model can achieve high classification accuracy over the simulated test set. It also holds its performance robustness under operating parameter shifts such as Signal-Noise-Ratio (SNR) and incident energy. Our work thus laid solid foundation for developing next-generation high energy gamma-rays detectors for better biomedical imaging.
</details>
<details>
<summary>摘要</summary>
光子计数放射测量仪已成为医学成像modalities中的一个重要组成部分，如 пози特短谱Tomography或计算Tomography。最有前途的探测器是宽阻挡带 semiconductor探测器，它的探测器材料与γ/X射线 фотоны的交互导致了多个交互 фото摄事件（MIPEs）。例如，使用CdZnTeSe（CZTS）半导体探测器，由于它们的探测能量范围和Compton散射事件的探测能量重叠大，因此通过传统的读取电路或信号处理算法来分辨Compton散射事件和光电摄事件是很困难的。在这种情况下，我们报告了一种深度学习分类器CoPhNet，可以在CdZnTeSe半导体探测器上分辨Compton散射和光电摄事件。CoPhNet模型通过使用模拟数据来模拟实际CZTS探测器脉冲，并在实验和模拟数据上进行验证。结果表明，CoPhNet模型可以在模拟测试集上 achieve high classification accuracy。它还保持了对操作参数的Shift，如信号噪声比（SNR）和入射能量的Robustness。我们的工作因此为开发下一代高能γ射线探测器提供了坚实的基础，以提高生物医学成像。
</details></li>
</ul>
<hr>
<h2 id="Complexity-of-Single-Loop-Algorithms-for-Nonlinear-Programming-with-Stochastic-Objective-and-Constraints"><a href="#Complexity-of-Single-Loop-Algorithms-for-Nonlinear-Programming-with-Stochastic-Objective-and-Constraints" class="headerlink" title="Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints"></a>Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00678">http://arxiv.org/abs/2311.00678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmet Alacaoglu, Stephen J. Wright</li>
<li>for: 解决非凸优化问题中的函数等式约束</li>
<li>methods: 使用单循环二阶假定和增强拉格朗日矩阵法</li>
<li>results: 实现 $\varepsilon$-近似首项条件的找到需要 $\widetilde{O}(\varepsilon^{-3})$ 复杂度（第一个情况）、 $\widetilde{O}(\varepsilon^{-4})$ 复杂度（第二个情况）和 $\widetilde{O}(\varepsilon^{-5})$ 复杂度（第三个情况）<details>
<summary>Abstract</summary>
We analyze the complexity of single-loop quadratic penalty and augmented Lagrangian algorithms for solving nonconvex optimization problems with functional equality constraints. We consider three cases, in all of which the objective is stochastic and smooth, that is, an expectation over an unknown distribution that is accessed by sampling. The nature of the equality constraints differs among the three cases: deterministic and linear in the first case, deterministic, smooth and nonlinear in the second case, and stochastic, smooth and nonlinear in the third case. Variance reduction techniques are used to improve the complexity. To find a point that satisfies $\varepsilon$-approximate first-order conditions, we require $\widetilde{O}(\varepsilon^{-3})$ complexity in the first case, $\widetilde{O}(\varepsilon^{-4})$ in the second case, and $\widetilde{O}(\varepsilon^{-5})$ in the third case. For the first and third cases, they are the first algorithms of "single loop" type (that also use $O(1)$ samples at each iteration) that still achieve the best-known complexity guarantees.
</details>
<details>
<summary>摘要</summary>
我们分析单循环quadratic penalty和扩展Lagrangian算法的复杂性，用于解决非凸优化问题中的函数等式约束。我们考虑了三个情况，其中目标函数都是随机的和凹的，即采样得到的 unknown 分布的期望值。等式约束的性质不同于各个情况：第一个情况下是 deterministic 和线性的，第二个情况下是 deterministic、凹和非线性的，第三个情况下是随机、凹和非线性的。我们使用减少偏差技术来提高复杂性。为找到满足 $\varepsilon$-approximate 首项条件的点，我们需要 $\widetilde{O}(\varepsilon^{-3})$ 复杂性在第一个情况下，$\widetilde{O}(\varepsilon^{-4})$ 在第二个情况下，和 $\widetilde{O}(\varepsilon^{-5})$ 在第三个情况下。对于第一个和第三个情况，它们是单循环类型的第一个算法（也使用 $O(1)$ 采样每个迭代），可以在最佳复杂性保证下实现。
</details></li>
</ul>
<hr>
<h2 id="Last-Iterate-Convergence-Properties-of-Regret-Matching-Algorithms-in-Games"><a href="#Last-Iterate-Convergence-Properties-of-Regret-Matching-Algorithms-in-Games" class="headerlink" title="Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games"></a>Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00676">http://arxiv.org/abs/2311.00676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Cai, Gabriele Farina, Julien Grand-Clément, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</li>
<li>for: 这个论文主要研究了大规模两个玩家零点游戏中 regret matching 算法的最后轮数据收敛性。</li>
<li>methods: 这篇论文使用了 regret matching 算法及其变种，包括同时采用 RM$^+$、交替采用 RM$^+$ 和预测 RM$^+$。</li>
<li>results: 研究发现，这些变种算法在一个简单的 $3\times 3$ 游戏中缺乏最后轮数据收敛性保证，但是使用缓和技术后的变种算法（extragradient RM$^+$ 和平滑预测 RM$^+$）具有 asymptotic 最后轮数据收敛性和 $1&#x2F;\sqrt{t}$ 最好轮数据收敛性。此外，研究还介绍了 restarted 变种算法，其具有线性速率最后轮数据收敛性。<details>
<summary>Abstract</summary>
Algorithms based on regret matching, specifically regret matching$^+$ (RM$^+$), and its variants are the most popular approaches for solving large-scale two-player zero-sum games in practice. Unlike algorithms such as optimistic gradient descent ascent, which have strong last-iterate and ergodic convergence properties for zero-sum games, virtually nothing is known about the last-iterate properties of regret-matching algorithms. Given the importance of last-iterate convergence for numerical optimization reasons and relevance as modeling real-word learning in games, in this paper, we study the last-iterate convergence properties of various popular variants of RM$^+$. First, we show numerically that several practical variants such as simultaneous RM$^+$, alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\times 3$ game. We then prove that recent variants of these algorithms based on a smoothing technique do enjoy last-iterate convergence: we prove that extragradient RM$^{+}$ and smooth Predictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate) and $1/\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted variants of these algorithms, and show that they enjoy linear-rate last-iterate convergence.
</details>
<details>
<summary>摘要</summary>
“algorithm based on regret matching, specifically regret matching$^+$ (RM$^+$) and its variants, are the most popular approaches for solving large-scale two-player zero-sum games in practice. Unlike algorithms such as optimistic gradient descent ascent, which have strong last-iterate and ergodic convergence properties for zero-sum games, virtually nothing is known about the last-iterate properties of regret-matching algorithms. Given the importance of last-iterate convergence for numerical optimization reasons and relevance as modeling real-world learning in games, in this paper, we study the last-iterate convergence properties of various popular variants of RM$^+$. First, we show numerically that several practical variants such as simultaneous RM$^+$, alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\times 3$ game. We then prove that recent variants of these algorithms based on a smoothing technique do enjoy last-iterate convergence: we prove that extragradient RM$^{+}$ and smooth Predictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate) and $1/\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted variants of these algorithms, and show that they enjoy linear-rate last-iterate convergence.”Note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Recovering-Linear-Causal-Models-with-Latent-Variables-via-Cholesky-Factorization-of-Covariance-Matrix"><a href="#Recovering-Linear-Causal-Models-with-Latent-Variables-via-Cholesky-Factorization-of-Covariance-Matrix" class="headerlink" title="Recovering Linear Causal Models with Latent Variables via Cholesky Factorization of Covariance Matrix"></a>Recovering Linear Causal Models with Latent Variables via Cholesky Factorization of Covariance Matrix</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00674">http://arxiv.org/abs/2311.00674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunfeng Cai, Xu Li, Minging Sun, Ping Li</li>
<li>for: 这个论文的目的是恢复对观察数据的导irected acyclic graph（DAG）结构，并且在存在隐变量时，这个问题变得更加困难。</li>
<li>methods: 这个论文提出了一种基于covariance矩阵的Cholesky分解算法来恢复DAG结构，该算法具有快速和容易实现的优点，并且有理论保证对应于正确恢复。</li>
<li>results: 在 sintetic 和实际数据上，该算法比之前的方法更快速，并且在等Error variances假设下，通过在Cholesky分解基础上添加优化过程来处理含隐变量的DAG恢复问题，numerical simulations表明该修改后的”Cholesky+优化”算法能够在大多数情况下恢复真实的图结构，并且表现较好。<details>
<summary>Abstract</summary>
Discovering the causal relationship via recovering the directed acyclic graph (DAG) structure from the observed data is a well-known challenging combinatorial problem. When there are latent variables, the problem becomes even more difficult. In this paper, we first propose a DAG structure recovering algorithm, which is based on the Cholesky factorization of the covariance matrix of the observed data. The algorithm is fast and easy to implement and has theoretical grantees for exact recovery. On synthetic and real-world datasets, the algorithm is significantly faster than previous methods and achieves the state-of-the-art performance. Furthermore, under the equal error variances assumption, we incorporate an optimization procedure into the Cholesky factorization based algorithm to handle the DAG recovering problem with latent variables. Numerical simulations show that the modified "Cholesky + optimization" algorithm is able to recover the ground truth graph in most cases and outperforms existing algorithms.
</details>
<details>
<summary>摘要</summary>
发现 causal 关系via  recuperating  directed acyclic graph (DAG) 结构从观察数据中是一个常见的困难的 combinatorial 问题。当存在隐藏变量时，问题变得更加困难。在这篇论文中，我们首先提出了 DAG 结构还原算法，基于观察数据的协方差矩阵的 Cholesky 分解。该算法快速易于实现，并有理论保证对于精确还原。在 sintetic 和实际数据上，该算法比前一些方法快得多，并在状态的表现方面达到了顶峰。此外，在等错误 variances 假设下，我们将 Cholesky 基于算法与 latent 变量处理 DAG 还原问题的优化程序结合在一起。 numrical  simulations 表明，修改后的 "Cholesky + 优化" 算法能够回归真实的图结构，并在大多数情况下超过现有算法。
</details></li>
</ul>
<hr>
<h2 id="Latent-Space-Translation-via-Semantic-Alignment"><a href="#Latent-Space-Translation-via-Semantic-Alignment" class="headerlink" title="Latent Space Translation via Semantic Alignment"></a>Latent Space Translation via Semantic Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00664">http://arxiv.org/abs/2311.00664</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flegyas/latent-translation">https://github.com/flegyas/latent-translation</a></li>
<li>paper_authors: Valentino Maiorca, Luca Moschella, Antonio Norelli, Marco Fumero, Francesco Locatello, Emanuele Rodolà</li>
<li>for: 理解神经网络模型之间的 latent space 相似性的机制</li>
<li>methods: 使用标准的代数方法直接估计 latent space 之间的转换，无需额外训练</li>
<li>results: 在不同的训练、领域、架构和下游任务中，可以很好地将 encoder 和 decoder 缝合，并且可以实现零基础 multimodal 分类 task<details>
<summary>Abstract</summary>
While different neural models often exhibit latent spaces that are alike when exposed to semantically related data, this intrinsic similarity is not always immediately discernible. Towards a better understanding of this phenomenon, our work shows how representations learned from these neural modules can be translated between different pre-trained networks via simpler transformations than previously thought. An advantage of this approach is the ability to estimate these transformations using standard, well-understood algebraic procedures that have closed-form solutions. Our method directly estimates a transformation between two given latent spaces, thereby enabling effective stitching of encoders and decoders without additional training. We extensively validate the adaptability of this translation procedure in different experimental settings: across various trainings, domains, architectures (e.g., ResNet, CNN, ViT), and in multiple downstream tasks (classification, reconstruction). Notably, we show how it is possible to zero-shot stitch text encoders and vision decoders, or vice-versa, yielding surprisingly good classification performance in this multimodal setting.
</details>
<details>
<summary>摘要</summary>
不同的神经网络模型经常表现出semantically相关的幂空间，但这种内在相似性不总是立即可见。为了更好地理解这种现象，我们的工作表明了如何通过简单的变换来将 representations从这些神经模块翻译到不同的预训练网络中。这种方法的优点是可以使用标准的、良好的解释 algebraic procedures来计算这些变换，并且有closed-form solution。我们直接计算了两个给定的幂空间之间的变换，从而实现了无需额外训练的编码器和解码器的封装。我们在不同的实验设置下广泛验证了这种翻译过程的适用性：跨多个训练、领域、architecture（例如ResNet、CNN、ViT）以及多个下游任务（分类、重建）。特别是，我们表明了可以零式封装文本编码器和视觉解码器，或者vice versa，在多Modal Setting中获得了意外好的分类性能。
</details></li>
</ul>
<hr>
<h2 id="Online-Signal-Estimation-on-the-Graph-Edges-via-Line-Graph-Transformation"><a href="#Online-Signal-Estimation-on-the-Graph-Edges-via-Line-Graph-Transformation" class="headerlink" title="Online Signal Estimation on the Graph Edges via Line Graph Transformation"></a>Online Signal Estimation on the Graph Edges via Line Graph Transformation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00656">http://arxiv.org/abs/2311.00656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Yan, Ercan Engin Kuruoglu</li>
<li>for: 这篇论文提出了一种在线时间变化图边缘信号预测算法，即Line Graph Normalized Least Mean Square（LGNLMS）算法。</li>
<li>methods: 该算法利用了Line Graph来将图边缘信号转换为图节点的边缘到Vertex的对偶。这使得边信号可以使用已有的GSP概念进行处理，而不需要重新定义它们在图边上。</li>
<li>results: 该算法可以在线时间变化图上预测边缘信号，并且可以减少预测误差。<details>
<summary>Abstract</summary>
We propose the Line Graph Normalized Least Mean Square (LGNLMS) algorithm for online time-varying graph edge signals prediction. LGNLMS utilizes the Line Graph to transform graph edge signals into the node of its edge-to-vertex dual. This enables edge signals to be processed using established GSP concepts without redefining them on graph edges.
</details>
<details>
<summary>摘要</summary>
我们提出了线图正规最小二乘（LGNLMS）算法，用于在线时变图边信号预测。LGNLMS使用线图将图边信号转换成图边到顶点的对偶点。这使得边信号可以使用已有的图像处理概念进行处理，无需对图边进行重新定义。
</details></li>
</ul>
<hr>
<h2 id="Kronecker-Factored-Approximate-Curvature-for-Modern-Neural-Network-Architectures"><a href="#Kronecker-Factored-Approximate-Curvature-for-Modern-Neural-Network-Architectures" class="headerlink" title="Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures"></a>Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00636">http://arxiv.org/abs/2311.00636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runa Eschenhagen, Alexander Immer, Richard E. Turner, Frank Schneider, Philipp Hennig</li>
<li>for: 这篇论文旨在探讨如何使用 Kronecker-Factored Approximate Curvature (K-FAC) 加速现代神经网络训练，以降低计算成本。</li>
<li>methods: 该论文提出了两种不同的线性Weight-sharing层设置，分别是 expand 和 reduce，并证明它们在深度线性网络中都是正确的。</li>
<li>results: 论文通过对一种宽度神经网络和一种视觉转换器进行训练，发现 K-FAC 可以减少训练时间，并且可以达到相同的验证指标目标，但需要更少的步骤数。<details>
<summary>Abstract</summary>
The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in $50$-$75\%$ of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures.
</details>
<details>
<summary>摘要</summary>
核心component of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimization method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavors of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimizing the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in $50$-$75\%$ of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures.Here's the translation in Traditional Chinese:核心component of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimization method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavors of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimizing the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in $50$-$75\%$ of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures.
</details></li>
</ul>
<hr>
<h2 id="Controllable-Music-Production-with-Diffusion-Models-and-Guidance-Gradients"><a href="#Controllable-Music-Production-with-Diffusion-Models-and-Guidance-Gradients" class="headerlink" title="Controllable Music Production with Diffusion Models and Guidance Gradients"></a>Controllable Music Production with Diffusion Models and Guidance Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00613">http://arxiv.org/abs/2311.00613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Levy, Bruno Di Giorgi, Floris Weers, Angelos Katharopoulos, Tom Nickson</li>
<li>for: 本研究使用扩散模型进行条件生成，以解决音乐生成 tasks 中的多种实际问题，包括续写、填充和重新生成音乐audio，以及创造细腻的音乐过渡和将欲具有的风格特征传递给现有音频clip。</li>
<li>methods: 本研究使用 sampling-time guidance 方法，通过在简单的框架中应用导航，支持 both reconstruction 和 classification 损失，或任何组合其中的两个。这种方法确保生成的音频可以与周围的上下文匹配，或按照任何适当的预训练分类器或嵌入模型的 latent representation 进行匹配。</li>
<li>results: 研究人员通过实验证明，通过使用本方法，可以生成高质量的44.1kHz静音音频，并且可以具有很好的样本时间导航和分类能力。<details>
<summary>Abstract</summary>
We demonstrate how conditional generation from diffusion models can be used to tackle a variety of realistic tasks in the production of music in 44.1kHz stereo audio with sampling-time guidance. The scenarios we consider include continuation, inpainting and regeneration of musical audio, the creation of smooth transitions between two different music tracks, and the transfer of desired stylistic characteristics to existing audio clips. We achieve this by applying guidance at sampling time in a simple framework that supports both reconstruction and classification losses, or any combination of the two. This approach ensures that generated audio can match its surrounding context, or conform to a class distribution or latent representation specified relative to any suitable pre-trained classifier or embedding model.
</details>
<details>
<summary>摘要</summary>
我们示例了如何使用扩散模型进行 conditional generation，用于处理不同的实际音乐生成任务，包括续写、填充和重新生成音乐声音，创造缓冲过渡 между两首不同的乐曲，以及将欲求的风格特征传承到现有音频clip。我们通过在采样时提供指导，实现了这些任务。我们的简单框架支持重建和分类损失，或任何组合其中的两者。这种方法确保生成的声音能匹配周围的上下文，或按照任何适当的预训练分类器或嵌入模型的类型进行分类。
</details></li>
</ul>
<hr>
<h2 id="A-Collaborative-Filtering-Based-Two-Stage-Model-with-Item-Dependency-for-Course-Recommendation"><a href="#A-Collaborative-Filtering-Based-Two-Stage-Model-with-Item-Dependency-for-Course-Recommendation" class="headerlink" title="A Collaborative Filtering-Based Two Stage Model with Item Dependency for Course Recommendation"></a>A Collaborative Filtering-Based Two Stage Model with Item Dependency for Course Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00612">http://arxiv.org/abs/2311.00612</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Eric L. Lee, Tsung-Ting Kuo, Shou-De Lin<br>for: 这篇论文旨在推荐课程，并提出了一些应对现有CF模型在建立课程推荐引擎时遇到的挑战的想法。methods: 本文使用了一种两阶段CF模型，其中第一阶段是通过课程依赖网络建立学生的学习路径，第二阶段是使用CF模型进行学生课程推荐。此外，文章还提出了一些 Addressing Challenges in Applying CF Models to Course Recommendation 的想法。results: 实验结果表明，combined with a two-stage CF model regularized by course dependency and a graph-based recommender based on course-transition network, 可以达到AUC为0.97的高精度。<details>
<summary>Abstract</summary>
Recommender systems have been studied for decades with numerous promising models been proposed. Among them, Collaborative Filtering (CF) models are arguably the most successful one due to its high accuracy in recommendation and elimination of privacy-concerned personal meta-data from training. This paper extends the usage of CF-based model to the task of course recommendation. We point out several challenges in applying the existing CF-models to build a course recommendation engine, including the lack of rating and meta-data, the imbalance of course registration distribution, and the demand of course dependency modeling. We then propose several ideas to address these challenges. Eventually, we combine a two-stage CF model regularized by course dependency with a graph-based recommender based on course-transition network, to achieve AUC as high as 0.97 with a real-world dataset.
</details>
<details>
<summary>摘要</summary>
推荐系统已经在数十年内被研究，有很多有前途的模型被提出。其中，协同推荐（CF）模型被认为是最成功的，这是因为它的推荐精度高并且不需要在训练中提供隐私担忧的个人元数据。本文将CF模型应用到课程推荐任务中，并指出了现有CF模型在实施课程推荐引擎时存在的一些挑战，包括缺乏评分和元数据、课程注册分布不均衡以及课程依赖模型的需求。然后，我们提出了一些解决方案。最后，我们将一种两阶段CF模型 regularized by course dependency 与一种基于课程过渡网络的图形推荐模型相结合，以实现使用真实世界数据的AUC为0.97。</sys>Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".Here's the translation in Traditional Chinese:<sys>推证系统已经在数十年内被研究，有很多有前途的模型被提出。其中，协同推证（CF）模型被认为是最成功的，这是因为它的推证精度高且不需要在训练中提供隐私担忧的个人元数据。本文将CF模型应用到课程推证任务中，并指出了现有CF模型在实施课程推证引擎时存在的一些挑战，包括缺乏评分和元数据、课程注册分布不均衡以及课程依赖模型的需求。然后，我们提出了一些解决方案。最后，我们将一种两阶段CF模型 regularized by course dependency 与一种基于课程过渡网络的图形推证模型相结合，以实现使用真实世界数据的AUC为0.97。</sys>Note: Traditional Chinese is also known as "Traditional Mandarin" or "Formosan Chinese".
</details></li>
</ul>
<hr>
<h2 id="Structure-Learning-with-Adaptive-Random-Neighborhood-Informed-MCMC"><a href="#Structure-Learning-with-Adaptive-Random-Neighborhood-Informed-MCMC" class="headerlink" title="Structure Learning with Adaptive Random Neighborhood Informed MCMC"></a>Structure Learning with Adaptive Random Neighborhood Informed MCMC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00599">http://arxiv.org/abs/2311.00599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Caron, Xitong Liang, Samuel Livingstone, Jim Griffin</li>
<li>For: 本研究提出了一种新的Markov Chain Monte Carlo（MCMC）采样算法，称为PARNI-DAG，用于在观察数据下进行完全 Bayesian 结构学习。* Methods: PARNI-DAG 算法基于 causal sufficiency 假设，可以直接采样 posterior 分布中的 Directed Acyclic Graphs（DAGs）。该算法使用本地 Informed 随机邻域提案，使得采样更加快速并更加稳定。此外，为了更好地扩展到更多节点，我们couple PARNI-DAG 算法与一种预处理措施，使用skeleton graph得到了一些约束或 scoring-based 算法。* Results: PARNI-DAG 算法在高维设定下具有更好的混合性和准确性，可以快速 converges to high-probability regions，并且 less likely to get stuck in local modes。在一系列实验中，我们证明了 PARNI-DAG 算法的混合效率和准确性。<details>
<summary>Abstract</summary>
In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a fully-Bayesian approach to the problem of structure learning under observational data. Under the assumption of causal sufficiency, the algorithm allows for approximate sampling directly from the posterior distribution on Directed Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs via locally informed, adaptive random neighborhood proposal that results in better mixing properties. In addition, to ensure better scalability with the number of nodes, we couple PARNI-DAG with a pre-tuning procedure of the sampler's parameters that exploits a skeleton graph derived through some constraint-based or scoring-based algorithms. Thanks to these novel features, PARNI-DAG quickly converges to high-probability regions and is less likely to get stuck in local modes in the presence of high correlation between nodes in high-dimensional settings. After introducing the technical novelties in PARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in learning DAG structures on a variety of experiments.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的MCMC抽样器，PARNI-DAG，用于完全 bayesian 的结构学习问题。假设 causal sufficiency，该算法允许直接从 posterior 分布中进行 Approximate 抽样，并且在 Directed Acyclic Graphs (DAGs) 上进行有效的抽样。PARNI-DAG 使用本地 Informed 随机邻域提案，从而提高了混合性质。此外，为了更好地扩展到节点数的增加，我们对 PARNI-DAG 的参数进行预调整，利用一个基于约束或分数基的树图来加速抽样。这些新特点使得 PARNI-DAG 在高维设置中更加快速地趋向高概率区域，并且更 unlikely 地被高 correlate  между节点所陷入本地模式。在介绍 PARNI-DAG 的技术新特点后，我们在各种实验中证明了其混合效率和准确性。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Tails-for-Normalising-Flows-with-Application-to-the-Modelling-of-Financial-Return-Data"><a href="#Flexible-Tails-for-Normalising-Flows-with-Application-to-the-Modelling-of-Financial-Return-Data" class="headerlink" title="Flexible Tails for Normalising Flows, with Application to the Modelling of Financial Return Data"></a>Flexible Tails for Normalising Flows, with Application to the Modelling of Financial Return Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00580">http://arxiv.org/abs/2311.00580</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tennessee Hickling, Dennis Prangle</li>
<li>for: 这个论文是为了研究如何使用极值论断来改变分布的尾部性质，以便更好地模型多变量巨大的尖峰分布。</li>
<li>methods: 这个论文使用了极值论断的方法来改变分布的尾部性质，并在许多实际应用中进行了验证。</li>
<li>results: 这个论文的结果表明，使用极值论断可以准确地模型多变量巨大的尖峰分布，并且可以生成新的尖峰分布样本。<details>
<summary>Abstract</summary>
We propose a transformation capable of altering the tail properties of a distribution, motivated by extreme value theory, which can be used as a layer in a normalizing flow to approximate multivariate heavy tailed distributions. We apply this approach to model financial returns, capturing potentially extreme shocks that arise in such data. The trained models can be used directly to generate new synthetic sets of potentially extreme returns
</details>
<details>
<summary>摘要</summary>
我们提出一种转换，可以改变分布的尾部属性，基于极值理论，可以用作正常化流中的层，以近似多变量重核分布。我们对金融回报数据应用这种方法，捕捉可能出现的极端冲击。训练的模型可以直接生成新的可能极端的返回数据集。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Revealing-CNN-Architectures-via-Side-Channel-Analysis-in-Dataflow-based-Inference-Accelerators"><a href="#Revealing-CNN-Architectures-via-Side-Channel-Analysis-in-Dataflow-based-Inference-Accelerators" class="headerlink" title="Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators"></a>Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00579">http://arxiv.org/abs/2311.00579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hansika Weerasena, Prabhat Mishra</li>
<li>for: 这种论文是为了研究如何利用数据流基本的 CNN 加速器来恢复 CNN 模型结构。</li>
<li>methods: 该论文使用了记忆基本的边防攻击方法，利用数据流中的空间和时间数据重复来恢复 CNN 模型结构。</li>
<li>results: 实验结果表明，该攻击方法可以成功恢复 Lenet、Alexnet 和 VGGnet16 等popular CNN 模型的结构。<details>
<summary>Abstract</summary>
Convolution Neural Networks (CNNs) are widely used in various domains. Recent advances in dataflow-based CNN accelerators have enabled CNN inference in resource-constrained edge devices. These dataflow accelerators utilize inherent data reuse of convolution layers to process CNN models efficiently. Concealing the architecture of CNN models is critical for privacy and security. This paper evaluates memory-based side-channel information to recover CNN architectures from dataflow-based CNN inference accelerators. The proposed attack exploits spatial and temporal data reuse of the dataflow mapping on CNN accelerators and architectural hints to recover the structure of CNN models. Experimental results demonstrate that our proposed side-channel attack can recover the structures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在多个领域广泛应用。最近的数据流基于CNN加速器技术的进步使得CNN推理可以在具有限制的边缘设备中进行。这些数据流加速器利用卷积层的自然数据重用来处理CNN模型高效。隐藏CNN模型的架构是隐私和安全的关键。这篇论文评估了基于数据流的CNN推理加速器中的内存基于侧annel信息，以 recover CNN模型的结构。我们的提议的攻击利用卷积层的空间和时间数据重用以及架构提示来恢复流行的CNN模型Lenet、Alexnet和VGGnet16的结构。实验结果表明，我们的提议的侧annel攻击可以成功地恢复CNN模型的结构。
</details></li>
</ul>
<hr>
<h2 id="Transfer-learning-for-improved-generalizability-in-causal-physics-informed-neural-networks-for-beam-simulations"><a href="#Transfer-learning-for-improved-generalizability-in-causal-physics-informed-neural-networks-for-beam-simulations" class="headerlink" title="Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations"></a>Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00578">http://arxiv.org/abs/2311.00578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Kapoor, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet</li>
<li>for: 这个论文提出了一种新的方法来模拟梁在弹性基础上的动态行为。</li>
<li>methods: 该方法使用了一种基于物理学信息学习网络（PINN）框架的转移学习方法，使用了一种尊重 causality的损失函数来缓解大空间时间域的问题。</li>
<li>results: 实验表明，提议的方法可以快速地达到高度准确的结果，并且在多种初始条件下都有优于现状方法。此外，该方法还可以在扩展的空间和时间域中模拟提梁的动态行为。<details>
<summary>Abstract</summary>
This paper introduces a novel methodology for simulating the dynamics of beams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam models on the Winkler foundation are simulated using a transfer learning approach within a causality-respecting physics-informed neural network (PINN) framework. Conventional PINNs encounter challenges in handling large space-time domains, even for problems with closed-form analytical solutions. A causality-respecting PINN loss function is employed to overcome this limitation, effectively capturing the underlying physics. However, it is observed that the causality-respecting PINN lacks generalizability. We propose using solutions to similar problems instead of training from scratch by employing transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. Numerical experiments on the Euler-Bernoulli beam highlight the efficacy of the proposed approach for various initial conditions, including those with noise in the initial data. Furthermore, the potential of the proposed method is demonstrated for the Timoshenko beam in an extended spatial and temporal domain. Several comparisons suggest that the proposed method accurately captures the inherent dynamics, outperforming the state-of-the-art physics-informed methods under standard $L^2$-norm metric and accelerating convergence.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Personalized-Assignment-to-One-of-Many-Treatment-Arms-via-Regularized-and-Clustered-Joint-Assignment-Forests"><a href="#Personalized-Assignment-to-One-of-Many-Treatment-Arms-via-Regularized-and-Clustered-Joint-Assignment-Forests" class="headerlink" title="Personalized Assignment to One of Many Treatment Arms via Regularized and Clustered Joint Assignment Forests"></a>Personalized Assignment to One of Many Treatment Arms via Regularized and Clustered Joint Assignment Forests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00577">http://arxiv.org/abs/2311.00577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Ladhania, Jann Spiess, Lyle Ungar, Wenbo Wu</li>
<li>for: 学习个性化赋予分配。</li>
<li>methods: 使用树式分配算法和 clustering 策略，以减少每个赋予分配的异常差异。</li>
<li>results: 在模拟研究中，通过直接优化赋予分配，可以获得更高的实际效果，而不是单独对每个赋予分配进行预测。在理论模型中，我们表明了在许多赋予分配情况下，直接优化赋予分配可以获得显著的实用效果。<details>
<summary>Abstract</summary>
We consider learning personalized assignments to one of many treatment arms from a randomized controlled trial. Standard methods that estimate heterogeneous treatment effects separately for each arm may perform poorly in this case due to excess variance. We instead propose methods that pool information across treatment arms: First, we consider a regularized forest-based assignment algorithm based on greedy recursive partitioning that shrinks effect estimates across arms. Second, we augment our algorithm by a clustering scheme that combines treatment arms with consistently similar outcomes. In a simulation study, we compare the performance of these approaches to predicting arm-wise outcomes separately, and document gains of directly optimizing the treatment assignment with regularization and clustering. In a theoretical model, we illustrate how a high number of treatment arms makes finding the best arm hard, while we can achieve sizable utility gains from personalization by regularized optimization.
</details>
<details>
<summary>摘要</summary>
我团队考虑了个化个性化任务分配到多个治疗臂中。标准方法可能在这种情况下表现不佳，因为它们可能会增加差异。我们提议使用共享信息的方法：首先，我们考虑了一种基于滥览树的评估算法，使用扩展的抽象分解来减小对每个臂的效果估计。其次，我们将治疗臂与相似的结果结合在一起，使用凝结方法来增强个性化任务分配。在一个 simulations 研究中，我们比较了这些方法与分别预测每个臂的结果的性能，并证明了通过直接优化治疗分配来提高个性化效果。在一个理论模型中，我们表明了多个治疗臂使得找到最佳臂变得困难，但通过REGularization和凝结来实现了较大的利用率提升。
</details></li>
</ul>
<hr>
<h2 id="Online-Student-t-Processes-with-an-Overall-local-Scale-Structure-for-Modelling-Non-stationary-Data"><a href="#Online-Student-t-Processes-with-an-Overall-local-Scale-Structure-for-Modelling-Non-stationary-Data" class="headerlink" title="Online Student-$t$ Processes with an Overall-local Scale Structure for Modelling Non-stationary Data"></a>Online Student-$t$ Processes with an Overall-local Scale Structure for Modelling Non-stationary Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00564">http://arxiv.org/abs/2311.00564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taole Sha, Michael Minyi Zhang</li>
<li>for:  handle time-dependent data with non-stationarity and heavy-tailed errors</li>
<li>methods: Bayesian mixture of student-$t$ processes with overall-local scale structure for covariance, SMC sampler for online inference</li>
<li>results: superiority over typical Gaussian process-based models on real-world data sets<details>
<summary>Abstract</summary>
Time-dependent data often exhibit characteristics, such as non-stationarity and heavy-tailed errors, that would be inappropriate to model with the typical assumptions used in popular models. Thus, more flexible approaches are required to be able to accommodate such issues. To this end, we propose a Bayesian mixture of student-$t$ processes with an overall-local scale structure for the covariance. Moreover, we use a sequential Monte Carlo (SMC) sampler in order to perform online inference as data arrive in real-time. We demonstrate the superiority of our proposed approach compared to typical Gaussian process-based models on real-world data sets in order to prove the necessity of using mixtures of student-$t$ processes.
</details>
<details>
<summary>摘要</summary>
时间相关的数据经常具有非站立性和重 tailed 错误的特点，这些特点不适合使用流行的模型假设。因此，我们需要更灵活的方法来满足这些问题。为此，我们提议使用 bayesian 混合学生-$t$ 过程，并使用线性 Monte Carlo（SMC）探针进行在线推断，以便在实时接收数据时进行推断。我们通过对实际数据集进行比较，证明我们的提议方法比typical Gaussian process-based models更为有利。Note: "student-$t$ process" refers to a type of statistical distribution that is similar to the normal distribution but with heavier tails, and "sequential Monte Carlo" (SMC) is a type of algorithm used for Bayesian inference.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-optimize-by-multi-gradient-for-multi-objective-optimization"><a href="#Learning-to-optimize-by-multi-gradient-for-multi-objective-optimization" class="headerlink" title="Learning to optimize by multi-gradient for multi-objective optimization"></a>Learning to optimize by multi-gradient for multi-objective optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00559">http://arxiv.org/abs/2311.00559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linxi Yang, Xinmin Yang, Liping Tang</li>
<li>for: 本研究旨在提出一种基于自动学习的多目标优化（MOO）方法，以替代手动设计的传统MOO方法。</li>
<li>methods: 本研究提出了一种自动学习 парадиг，并使用多个梯度来更新方向的多梯度学习优化（ML2O）方法。该方法可以从当前步骤中获取当前地形信息，并通过历史迭代轨迹数据来捕捉全局经验。</li>
<li>results: 实验结果表明，我们学习的优化器在训练多任务学习（MTL）神经网络时表现出色，超过了手动设计的竞争对手。<details>
<summary>Abstract</summary>
The development of artificial intelligence (AI) for science has led to the emergence of learning-based research paradigms, necessitating a compelling reevaluation of the design of multi-objective optimization (MOO) methods. The new generation MOO methods should be rooted in automated learning rather than manual design. In this paper, we introduce a new automatic learning paradigm for optimizing MOO problems, and propose a multi-gradient learning to optimize (ML2O) method, which automatically learns a generator (or mappings) from multiple gradients to update directions. As a learning-based method, ML2O acquires knowledge of local landscapes by leveraging information from the current step and incorporates global experience extracted from historical iteration trajectory data. By introducing a new guarding mechanism, we propose a guarded multi-gradient learning to optimize (GML2O) method, and prove that the iterative sequence generated by GML2O converges to a Pareto critical point. The experimental results demonstrate that our learned optimizer outperforms hand-designed competitors on training multi-task learning (MTL) neural network.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在科学领域的发展导致了学习基于研究 парадигмы的出现，这导致了多目标优化（MOO）方法的设计需要重新评估。新一代MOO方法应该基于自动学习而非手动设计。在这篇论文中，我们介绍了一种新的自动学习方法来优化MOO问题，并提出了多Gradient学习来优化（ML2O）方法，该方法可以自动学习多个梯度来更新方向。作为一种学习基于方法，ML2O可以从当前步骤和历史迭代轨迹数据中获取本地景观知识。通过引入新的保护机制，我们提出了一种卫士多Gradient学习来优化（GML2O）方法，并证明其迭代序列会 converges to a Pareto kritical point。实验结果表明，我们学习的优化器比手动设计的竞争对手在训练多任务学习（MTL）神经网络上表现更好。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Without-a-Processor-Emergent-Learning-in-a-Nonlinear-Electronic-Metamaterial"><a href="#Machine-Learning-Without-a-Processor-Emergent-Learning-in-a-Nonlinear-Electronic-Metamaterial" class="headerlink" title="Machine Learning Without a Processor: Emergent Learning in a Nonlinear Electronic Metamaterial"></a>Machine Learning Without a Processor: Emergent Learning in a Nonlinear Electronic Metamaterial</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00537">http://arxiv.org/abs/2311.00537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sam Dillavou, Benjamin D Beyer, Menachem Stern, Marc Z Miskin, Andrea J Liu, Douglas J Durian</li>
<li>for: 这个论文旨在探讨electronic learning metamaterials的非线性学习能力，以及其在各种感知和控制应用中的可能性。</li>
<li>methods: 作者提出了一种基于抵抗元件的非线性学习元件，通过自适应调整其电流-电压特性来实现非线性学习。</li>
<li>results: 研究发现，该非线性学习元件可以学习不可达的任务，如XOR和非线性回归，而不需要计算机。此外，该系统的训练模式与人工神经网络中的spectral bias类似，并且具有高效、低功耗和可重新启动的特点。<details>
<summary>Abstract</summary>
Standard deep learning algorithms require differentiating large nonlinear networks, a process that is slow and power-hungry. Electronic learning metamaterials offer potentially fast, efficient, and fault-tolerant hardware for analog machine learning, but existing implementations are linear, severely limiting their capabilities. These systems differ significantly from artificial neural networks as well as the brain, so the feasibility and utility of incorporating nonlinear elements have not been explored. Here we introduce a nonlinear learning metamaterial -- an analog electronic network made of self-adjusting nonlinear resistive elements based on transistors. We demonstrate that the system learns tasks unachievable in linear systems, including XOR and nonlinear regression, without a computer. We find our nonlinear learning metamaterial reduces modes of training error in order (mean, slope, curvature), similar to spectral bias in artificial neural networks. The circuitry is robust to damage, retrainable in seconds, and performs learned tasks in microseconds while dissipating only picojoules of energy across each transistor. This suggests enormous potential for fast, low-power computing in edge systems like sensors, robotic controllers, and medical devices, as well as manufacturability at scale for performing and studying emergent learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Active-Noise-Control-Portable-Device-Design"><a href="#Active-Noise-Control-Portable-Device-Design" class="headerlink" title="Active Noise Control Portable Device Design"></a>Active Noise Control Portable Device Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00535">http://arxiv.org/abs/2311.00535</a></li>
<li>repo_url: None</li>
<li>paper_authors: kai Wu, Yuanyuan Chen<br>for: 降低噪音的技术解决方案，以提高工作效率和人类健康。methods: 使用感应器探测环境中的噪音，然后将噪音处理于电子控制系统中，产生反相频率信号以抵消干扰。results: 这个智能噪音减少系统可以实时减少噪音，包括低频噪音，并且搭配睡眠追踪、音乐播放应用程序、气温感应和智能家居设备控制等功能。<details>
<summary>Abstract</summary>
While our world is filled with its own natural sounds that we can't resist enjoying, it is also chock-full of other sounds that can be irritating, this is noise. Noise not only influences the working efficiency but also the human's health. The problem of reducing noise is one of great importance and great difficulty. The problem has been addressed in many ways over the years. The current methods for noise reducing mostly rely on the materials and transmission medium, which are only effective to some extent for the high frequency noise. However, the effective reduction noise method especially for low frequency noise is very limited.   Here we come up with a noise reduction system consist of a sensor to detect the noise in the environment. Then the noise will be sent to an electronic control system to process the noise, which will generate a reverse phase frequency signal to counteract the disturbance. Finally, the processed smaller noise will be broadcasted by the speaker. Through this smart noise reduction system, even the noise with low-frequency can be eliminated.   The system is also integrated with sleep tracking and music player applications. It can also remember and store settings for the same environment, sense temperature, and smart control of home furniture, fire alarm, etc. This smart system can transfer data easily by Wi-Fi or Bluetooth and controlled by its APP.   In this project, we will present a model of the above technology which can be used in various environments to prevent noise pollution and provide a solution to the people who have difficulties finding a peaceful and quiet environment for sleep, work or study.
</details>
<details>
<summary>摘要</summary>
我们的世界满是自然的声音，我们喜欢听的声音，但是也有吵吵声，这是噪音。噪音不仅影响工作效率，还影响人类的健康。噪音减少问题是非常重要且非常困难的问题。过去多年来，人们已经有很多方法来解决这个问题，但是现有的噪音减少方法主要仅能减少高频噪音，对低频噪音的减少效果非常有限。为了解决这问题，我们开发了一种噪音减少系统，包括一个检测噪音环境的传感器，将噪音传输到电子控制系统进行处理，然后生成一个逆相频率信号，以抵消干扰。最后，处理后的小于噪音将被广播器播放出来。这个智能噪音减少系统可以减少低频噪音。此外，该系统还 integrate了睡眠跟踪和音乐播放应用程序，还可以记录和存储相同环境的设置，感测温度，智能控制家庭家具、火灾警示等。这个智能系统可以通过Wi-Fi或蓝牙传输数据，并由APP控制。在这个项目中，我们将提出一种使用该技术的模型，可以在不同环境中采用以防止噪音污染和提供辛苦找到安静和平静的环境，供着睡眠、工作或学习等方面的人们。
</details></li>
</ul>
<hr>
<h2 id="Retrieval-Based-Reconstruction-For-Time-series-Contrastive-Learning"><a href="#Retrieval-Based-Reconstruction-For-Time-series-Contrastive-Learning" class="headerlink" title="Retrieval-Based Reconstruction For Time-series Contrastive Learning"></a>Retrieval-Based Reconstruction For Time-series Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00519">http://arxiv.org/abs/2311.00519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxwell A. Xu, Alexander Moreno, Hui Wei, Benjamin M. Marlin, James M. Rehg</li>
<li>for: 本研究旨在开发一种基于 RETRIEVAL-BAsed Reconstruction (REBAR) 的自动матиче监督学习方法，以提高时间序列数据的下游任务性能。</li>
<li>methods: 本方法使用卷积混合注意力架构计算两个不同时间序列之间的 REBAR 误差，并通过验证实验表明 REBAR 误差是约束类别成员关系的预测器，因此可以作为正&#x2F;负标注。最后，本方法被integrated into a contrastive learning framework，可以学习一个 дости得州arameter表现出色的嵌入。</li>
<li>results: 在不同模式下，本方法可以学习一个高性能的嵌入，并且在下游任务上达到了状态的最优性能。<details>
<summary>Abstract</summary>
The success of self-supervised contrastive learning hinges on identifying positive data pairs that, when pushed together in embedding space, encode useful information for subsequent downstream tasks. However, in time-series, this is challenging because creating positive pairs via augmentations may break the original semantic meaning. We hypothesize that if we can retrieve information from one subsequence to successfully reconstruct another subsequence, then they should form a positive pair. Harnessing this intuition, we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR) contrastive learning. First, we utilize a convolutional cross-attention architecture to calculate the REBAR error between two different time-series. Then, through validation experiments, we show that the REBAR error is a predictor of mutual class membership, justifying its usage as a positive/negative labeler. Finally, once integrated into a contrastive learning framework, our REBAR method can learn an embedding that achieves state-of-the-art performance on downstream tasks across various modalities.
</details>
<details>
<summary>摘要</summary>
自我超级学习的成功取决于标注出正确的数据对，使得在嵌入空间中拼接起来的信息有用 для后续的下游任务。然而，在时序数据中，创建正确对via扩展可能会破坏原始 semantics。我们提出的假设是，如果可以从一个时序中检索到另一个时序，并成功重建它，那么它们应该组成一个正确的对。基于这种直觉，我们介绍了我们的新方法：REtrieval-BAsed Reconstruction（REBAR）对比学习。首先，我们利用卷积cross-attention架构计算REBAR错误 между两个不同的时序数据。然后，通过验证实验，我们显示了REBAR错误是两个时序数据之间的共同类别的预测器，这 justify its usage as a positive/negative labeler。最后，我们将REBAR方法集成到对比学习框架中，可以学习一个具有State-of-the-art表现的嵌入。
</details></li>
</ul>
<hr>
<h2 id="Fixed-Budget-Best-Arm-Identification-in-Sparse-Linear-Bandits"><a href="#Fixed-Budget-Best-Arm-Identification-in-Sparse-Linear-Bandits" class="headerlink" title="Fixed-Budget Best-Arm Identification in Sparse Linear Bandits"></a>Fixed-Budget Best-Arm Identification in Sparse Linear Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00481">http://arxiv.org/abs/2311.00481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Recep Can Yavas, Vincent Y. F. Tan</li>
<li>for: 本研究探讨了固定预算下的最佳臂 Identification问题，尤其是在稀疏线性抽象下。</li>
<li>methods: 我们提出了一个两阶段算法，即Lasso和Optimal-Design-（Lasso-OD）基于的线性最佳臂 Identification。第一阶段使用过滤lasso（Zhou, 2009）估计Feature vector $\theta^*$的支持集，而第二阶段则应用OD-LinBAI（Yang 和 Tan, 2022）算法。</li>
<li>results: 我们 derive了一个非对数的Upper bound 在 Lasso-OD 的错误几率上，通过精确地选择对数（例如lasso的正规化参数）并将两阶段的错误几率相应平衡。在固定稀疏度 $s$ 和预算 $T$ 下，Lasso-OD 的错误几率 exponent 随 $s$ 而不随维度 $d$ 的增长，实现了稀疏和高维度线性抽象中的显著性能改善。此外，我们还证明了 Lasso-OD 在对数上是几乎最佳的。最后，我们提供了一些实际的数据，以证明 Lasso-OD 对非稀疏线性抽象的性能改善。<details>
<summary>Abstract</summary>
We study the best-arm identification problem in sparse linear bandits under the fixed-budget setting. In sparse linear bandits, the unknown feature vector $\theta^*$ may be of large dimension $d$, but only a few, say $s \ll d$ of these features have non-zero values. We design a two-phase algorithm, Lasso and Optimal-Design- (Lasso-OD) based linear best-arm identification. The first phase of Lasso-OD leverages the sparsity of the feature vector by applying the thresholded Lasso introduced by Zhou (2009), which estimates the support of $\theta^*$ correctly with high probability using rewards from the selected arms and a judicious choice of the design matrix. The second phase of Lasso-OD applies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated support. We derive a non-asymptotic upper bound on the error probability of Lasso-OD by carefully choosing hyperparameters (such as Lasso's regularization parameter) and balancing the error probabilities of both phases. For fixed sparsity $s$ and budget $T$, the exponent in the error probability of Lasso-OD depends on $s$ but not on the dimension $d$, yielding a significant performance improvement for sparse and high-dimensional linear bandits. Furthermore, we show that Lasso-OD is almost minimax optimal in the exponent. Finally, we provide numerical examples to demonstrate the significant performance improvement over the existing algorithms for non-sparse linear bandits such as OD-LinBAI, BayesGap, Peace, LinearExploration, and GSE.
</details>
<details>
<summary>摘要</summary>
我们研究最好臂识别问题在稀畴线性投机下的固定预算设定下。在稀畴线性投机中，未知特征向量 $\theta^*$ 可能具有很大的维度 $d$，但只有一些，例如 $s \ll d$ 的特征有非零值。我们设计了两相运算程式，即lasso和Optimal-Design-（lasso-OD）基于的线性最好臂识别。第一相运算程式的lasso-OD 利用特征向量的稀畴性，通过对特征向量进行过滤的lasso 引入的范围内的条件，将 $\theta^*$ 的支持正确地估计出来，使用奖励自选投机和judicious的设计矩阵。第二相运算程式的lasso-OD 应用OD-LinBAI 算法，由 Yang 和 Tan （2022）引入的 Optimal-Design-LinBAI 算法。我们对lasso-OD 的误差概率进行非对数几何分析，并且调整几何元素（如lasso 的正规化参数），以实现适当的误差概率。对于固定的 $s$ 和 $T$，lasso-OD 的误差概率指数随 $s$ 而改变，实现了高维度和稀畴的线性投机中的很大性能改进。此外，我们还证明了lasso-OD 是很接近最佳的几何对数几何。最后，我们提供了一些数字示例，以展示lasso-OD 在非稀畴线性投机中的很大性能改进。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-models-for-probabilistic-programming"><a href="#Diffusion-models-for-probabilistic-programming" class="headerlink" title="Diffusion models for probabilistic programming"></a>Diffusion models for probabilistic programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00474">http://arxiv.org/abs/2311.00474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Dirmeier, Fernando Perez-Cruz</li>
<li>for: automated approximate inference in probabilistic programming languages (PPLs)</li>
<li>methods: 使用扩散模型作为variational approximation来 aproximate true posterior distribution，并 derive a novel bound to the marginal likelihood objective used in Bayesian modelling</li>
<li>results: 对一些常见的Bayesian模型进行评估，其 posterior inferences比同时期的方法更准确，computational cost和手动调整相对 Similar，但要更加简单实现和不受 neural network模型的限制。<details>
<summary>Abstract</summary>
We propose Diffusion Model Variational Inference (DMVI), a novel method for automated approximate inference in probabilistic programming languages (PPLs). DMVI utilizes diffusion models as variational approximations to the true posterior distribution by deriving a novel bound to the marginal likelihood objective used in Bayesian modelling. DMVI is easy to implement, allows hassle-free inference in PPLs without the drawbacks of, e.g., variational inference using normalizing flows, and does not make any constraints on the underlying neural network model. We evaluate DMVI on a set of common Bayesian models and show that its posterior inferences are in general more accurate than those of contemporary methods used in PPLs while having a similar computational cost and requiring less manual tuning.
</details>
<details>
<summary>摘要</summary>
我们提出了Diffusion Model Variational Inference（DMVI），一种新的自动化近似推理方法，用于运行概率编程语言（PPL）中的推理。DMVI利用扩散模型作为实际 posterior distribution 的可变近似，通过计算一个新的缩小边界目标，以便在 Bayesian 模型中进行推理。DMVI易于实现，不需要辛苦的推理，不需要对底层神经网络模型做任何限制，并且可以轻松地在 PPL 中进行推理，而不需要丰富的手动调整。我们在一些常见的 Bayesian 模型中评估了 DMVI，发现其 posterior 推理结果比cotemporary方法在 PPL 中更精确，同时computational cost 和手动调整的需求相似。
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-SGD-on-Graphs-a-Unified-Framework-for-Asynchronous-Decentralized-and-Federated-Optimization"><a href="#Asynchronous-SGD-on-Graphs-a-Unified-Framework-for-Asynchronous-Decentralized-and-Federated-Optimization" class="headerlink" title="Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization"></a>Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00465">http://arxiv.org/abs/2311.00465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathieu Even, Anastasia Koloskova, Laurent Massoulié</li>
<li>for: 这篇论文旨在提高分布式机器学习中的通信复杂性，通过异步通信和分布式计算技术来提高算法的效率。</li>
<li>methods: 该论文提出了异步SGD在图上的框架，其可以涵盖异步版本的多种算法，包括SGD、分布式SGD、本地SGD、FedBuff等。</li>
<li>results: 论文提供了较宽松的通信和计算假设下的收敛率，而且可以回归或者超越之前的异步分布式工作的最佳结果。<details>
<summary>Abstract</summary>
Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered.
</details>
<details>
<summary>摘要</summary>
分布式机器学习中的通信复杂性可以使用分布式和异步通信技术来加速。 former 可以消除中央把关者的依赖关系，而异步通信可以避免同步。 yet，将这两种技术结合使用仍然是一个挑战。 在这篇论文中，我们采取了这一步，并对 asynchronous SGD on graphs（AGRAF SGD）进行了总体的算法框架。 AGRAF SGD 涵盖了许多流行的算法，包括 SGD、分布式 SGD、Local SGD 和 FedBuff， thanks to its relaxed communication and computation assumptions。 我们提供了对于更加宽松的假设下的收敛率，而且仍然可以恢复或者even improve over the best known results for all the algorithms covered。
</details></li>
</ul>
<hr>
<h2 id="Robust-and-Conjugate-Gaussian-Process-Regression"><a href="#Robust-and-Conjugate-Gaussian-Process-Regression" class="headerlink" title="Robust and Conjugate Gaussian Process Regression"></a>Robust and Conjugate Gaussian Process Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00463">http://arxiv.org/abs/2311.00463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matias Altamirano, François-Xavier Briol, Jeremias Knoblauch</li>
<li>for: 提高 Gaussian Process（GP） regression 的可靠性和不确定性评估，并且能够在实际应用中使用。</li>
<li>methods: 使用总体 Bayesian 推理来实现可证明 robust 和 conjugate Gaussian Process（RCGP） regression，不需要额外成本。 RCGP 具有可 conjugate 关闭形式更新，适用于所有标准 GP 支持的情况。</li>
<li>results: 通过在 Bayesian 优化和稀VAR Gaussian Process 等问题中应用 RCGP，实际表现强劲。<details>
<summary>Abstract</summary>
To enable closed form conditioning, a common assumption in Gaussian process (GP) regression is independent and identically distributed Gaussian observation noise. This strong and simplistic assumption is often violated in practice, which leads to unreliable inferences and uncertainty quantification. Unfortunately, existing methods for robustifying GPs break closed-form conditioning, which makes them less attractive to practitioners and significantly more computationally expensive. In this paper, we demonstrate how to perform provably robust and conjugate Gaussian process (RCGP) regression at virtually no additional cost using generalised Bayesian inference. RCGP is particularly versatile as it enables exact conjugate closed form updates in all settings where standard GPs admit them. To demonstrate its strong empirical performance, we deploy RCGP for problems ranging from Bayesian optimisation to sparse variational Gaussian processes.
</details>
<details>
<summary>摘要</summary>
要实现关闭形式条件， Gaussian process（GP）回归通常假设独立和同样分布的 Gaussian 观测噪声。这是一个强大且简单的假设，在实践中经常被违反，导致不可靠的推断和不确定性评估。现有的方法用于强化 GPs 会打砸关闭形式条件，使其变得更加不吸引实践者并显着增加计算成本。在这篇论文中，我们展示了如何在几乎没有额外成本下实现可证明 Robust 和 conjugate Gaussian process（RCGP）回归。RCGP 特别是可以在所有设置下实现批量 conjugate 关闭形式更新，从而使其在实践中更加强大。为证明其强大的实际性表现，我们在 Bayesian 优化到 sparse variational Gaussian processes 中应用 RCGP。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Budgeted-Rejection-Sampling-for-Generative-Models"><a href="#Optimal-Budgeted-Rejection-Sampling-for-Generative-Models" class="headerlink" title="Optimal Budgeted Rejection Sampling for Generative Models"></a>Optimal Budgeted Rejection Sampling for Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00460">http://arxiv.org/abs/2311.00460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandre Verine, Muni Sreenivas Pydi, Benjamin Negrevergne, Yann Chevaleyre</li>
<li>for: 提高权重生成模型的性能</li>
<li>methods: 使用优化采样方法</li>
<li>results: 提高样本质量和多样性<details>
<summary>Abstract</summary>
Rejection sampling methods have recently been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal under an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to \textit{any} $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model's overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.
</details>
<details>
<summary>摘要</summary>
“拒拒样本方法最近被提出来改善基于判断器的生成模型性能。然而，这些方法只有无限样本预算下才是优化的，通常是独立于拒拒程序进行生成器训练。我们首先提出了一种最优预算拒拒样本方案（OBRS），该方案在任何 $f $- divergence 下是可证优化的，对于给定的预算。其次，我们提出了一种综合方法，将拒拒样本方案 incorporated 到训练过程中，以进一步提高模型的总性能。通过实验和支持理论，我们证明了我们的方法可以有效地提高样本质量和多样性。”Here's the translation breakdown:* "拒拒样本方法" (拒拒样本方法) - This refers to the rejection sampling methods proposed in the text.* "最近被提出来" (最近被提出来) - This phrase indicates that the rejection sampling methods have been recently proposed.* "改善基于判断器的生成模型性能" (改善基于判断器的生成模型性能) - This phrase explains the purpose of the rejection sampling methods, which is to improve the performance of generative models based on discriminators.* "然而" (然而) - This word indicates a contrast or exception, indicating that the rejection sampling methods have limitations.* "这些方法只有无限样本预算下才是优化的" (这些方法只有无限样本预算下才是优化的) - This phrase explains the limitation of the rejection sampling methods, which is that they are only optimal with an unlimited sampling budget.* "通常是独立于拒拒程序进行生成器训练" (通常是独立于拒拒程序进行生成器训练) - This phrase explains that the rejection sampling methods are usually applied to a generator trained independently of the rejection procedure.* "我们首先提出了一种最优预算拒拒样本方案" (我们首先提出了一种最优预算拒拒样本方案) - This phrase introduces the first proposed method, which is the optimal budgeted rejection sampling (OBRS) scheme.* "该方案在任何 $f $- divergence 下是可证优化的" (该方案在任何 $f $- divergence 下是可证优化的) - This phrase explains that the OBRS scheme is provably optimal with respect to any $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget.* "其次" (其次) - This word indicates a secondary or additional point.* "我们提出了一种综合方法" (我们提出了一种综合方法) - This phrase introduces the second proposed method, which is an end-to-end method that incorporates the sampling scheme into the training procedure.* "以进一步提高模型的总性能" (以进一步提高模型的总性能) - This phrase explains the purpose of the end-to-end method, which is to further enhance the model's overall performance.* "通过实验和支持理论，我们证明了我们的方法可以有效地提高样本质量和多样性" (通过实验和支持理论，我们证明了我们的方法可以有效地提高样本质量和多样性) - This phrase explains that the proposed methods have been shown to be effective in improving the quality and diversity of the samples through experiments and supporting theory.
</details></li>
</ul>
<hr>
<h2 id="Hessian-Eigenvectors-and-Principal-Component-Analysis-of-Neural-Network-Weight-Matrices"><a href="#Hessian-Eigenvectors-and-Principal-Component-Analysis-of-Neural-Network-Weight-Matrices" class="headerlink" title="Hessian Eigenvectors and Principal Component Analysis of Neural Network Weight Matrices"></a>Hessian Eigenvectors and Principal Component Analysis of Neural Network Weight Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00452">http://arxiv.org/abs/2311.00452</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Haink</li>
<li>for: 本研究探讨深度神经网络训练后的行为和网络参数之间的关系。</li>
<li>methods: 本研究使用了许多方法，包括泛化函数梯度下降、主成分分析和特征值分解等。</li>
<li>results: 研究发现了许多关键结果，包括：弹性函数梯度下降可以解释深度神经网络的演化方向；网络参数与梯度下降的关系；以及可以使用主成分分析来简化梯度矩阵。此外，研究还发现了一种可以避免深度神经网络忘记现象的有效策略。<details>
<summary>Abstract</summary>
This study delves into the intricate dynamics of trained deep neural networks and their relationships with network parameters. Trained networks predominantly continue training in a single direction, known as the drift mode. This drift mode can be explained by the quadratic potential model of the loss function, suggesting a slow exponential decay towards the potential minima. We unveil a correlation between Hessian eigenvectors and network weights. This relationship, hinging on the magnitude of eigenvalues, allows us to discern parameter directions within the network. Notably, the significance of these directions relies on two defining attributes: the curvature of their potential wells (indicated by the magnitude of Hessian eigenvalues) and their alignment with the weight vectors. Our exploration extends to the decomposition of weight matrices through singular value decomposition. This approach proves practical in identifying critical directions within the Hessian, considering both their magnitude and curvature. Furthermore, our examination showcases the applicability of principal component analysis in approximating the Hessian, with update parameters emerging as a superior choice over weights for this purpose. Remarkably, our findings unveil a similarity between the largest Hessian eigenvalues of individual layers and the entire network. Notably, higher eigenvalues are concentrated more in deeper layers. Leveraging these insights, we venture into addressing catastrophic forgetting, a challenge of neural networks when learning new tasks while retaining knowledge from previous ones. By applying our discoveries, we formulate an effective strategy to mitigate catastrophic forgetting, offering a possible solution that can be applied to networks of varying scales, including larger architectures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Form-follows-Function-Text-to-Text-Conditional-Graph-Generation-based-on-Functional-Requirements"><a href="#Form-follows-Function-Text-to-Text-Conditional-Graph-Generation-based-on-Functional-Requirements" class="headerlink" title="Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements"></a>Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00444">http://arxiv.org/abs/2311.00444</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Peter A. Zachares, Vahan Hovhannisyan, Alan Mosca, Yarin Gal</li>
<li>for: 本研究targets the novel problem setting of generating graphs conditioned on a description of the graph’s functional requirements in a downstream task.</li>
<li>methods: 我们提出了一种文本-to-文本生成方法，通过预训练大型自然语言模型（LLM）来生成图形。我们还提出了一种假设，通过将信息报告层 integrate into LLM的架构来增加图形的结构信息。</li>
<li>results: 我们在使用公共可用的分子和知识图数据集进行设计了一系列实验，并得到了结果，显示我们的提议方法可以更好地满足请求的功能要求，与类似任务的基线方法相比，差异为统计学上的显著差异。<details>
<summary>Abstract</summary>
This work focuses on the novel problem setting of generating graphs conditioned on a description of the graph's functional requirements in a downstream task. We pose the problem as a text-to-text generation problem and focus on the approach of fine-tuning a pretrained large language model (LLM) to generate graphs. We propose an inductive bias which incorporates information about the structure of the graph into the LLM's generation process by incorporating message passing layers into an LLM's architecture. To evaluate our proposed method, we design a novel set of experiments using publicly available and widely studied molecule and knowledge graph data sets. Results suggest our proposed approach generates graphs which more closely meet the requested functional requirements, outperforming baselines developed on similar tasks by a statistically significant margin.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Crop-Disease-Classification-using-Support-Vector-Machines-with-Green-Chromatic-Coordinate-GCC-and-Attention-based-feature-extraction-for-IoT-based-Smart-Agricultural-Applications"><a href="#Crop-Disease-Classification-using-Support-Vector-Machines-with-Green-Chromatic-Coordinate-GCC-and-Attention-based-feature-extraction-for-IoT-based-Smart-Agricultural-Applications" class="headerlink" title="Crop Disease Classification using Support Vector Machines with Green Chromatic Coordinate (GCC) and Attention based feature extraction for IoT based Smart Agricultural Applications"></a>Crop Disease Classification using Support Vector Machines with Green Chromatic Coordinate (GCC) and Attention based feature extraction for IoT based Smart Agricultural Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00429">http://arxiv.org/abs/2311.00429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashwat Jha, Vishvaditya Luhach, Gauri Shanker Gupta, Beependra Singh<br>for: 这篇论文的目的是提供一种新的植物病诊断方法，以便帮助农民快速和准确地诊断植物病情。methods: 本文使用了注意力基于的特征提取、RGB通道基于的色彩分析、支持向量机（SVM）等机器学习和深度学习算法来实现植物病诊断。results: 相比之前的算法，这种新的诊断方法在精度方面达到了99.69%，而且可以与移动应用程序和物联网设备集成，减少了4倍的大小。这些发现有助于帮助农民快速和准确地诊断植物病情，从而保持农业输出和食品安全。<details>
<summary>Abstract</summary>
Crops hold paramount significance as they serve as the primary provider of energy, nutrition, and medicinal benefits for the human population. Plant diseases, however, can negatively affect leaves during agricultural cultivation, resulting in significant losses in crop output and economic value. Therefore, it is crucial for farmers to identify crop diseases. However, this method frequently necessitates hard work, a lot of planning, and in-depth familiarity with plant pathogens. Given these numerous obstacles, it is essential to provide solutions that can easily interface with mobile and IoT devices so that our farmers can guarantee the best possible crop development. Various machine learning (ML) as well as deep learning (DL) algorithms have been created & studied for the identification of plant disease detection, yielding substantial and promising results. This article presents a novel classification method that builds on prior work by utilising attention-based feature extraction, RGB channel-based chromatic analysis, Support Vector Machines (SVM) for improved performance, and the ability to integrate with mobile applications and IoT devices after quantization of information. Several disease classification algorithms were compared with the suggested model, and it was discovered that, in terms of accuracy, Vision Transformer-based feature extraction and additional Green Chromatic Coordinate feature with SVM classification achieved an accuracy of (GCCViT-SVM) - 99.69%, whereas after quantization for IoT device integration achieved an accuracy of - 97.41% while almost reducing 4x in size. Our findings have profound implications because they have the potential to transform how farmers identify crop illnesses with precise and fast information, thereby preserving agricultural output and ensuring food security.
</details>
<details>
<summary>摘要</summary>
This article presents a novel classification method that leverages attention-based feature extraction, RGB channel-based chromatic analysis, and Support Vector Machines (SVM) to improve disease detection accuracy. Additionally, the proposed method can be integrated with mobile applications and IoT devices, allowing for fast and precise information transmission.Several disease classification algorithms were compared with the suggested model, and the results showed that the Vision Transformer-based feature extraction and additional Green Chromatic Coordinate feature with SVM classification achieved an accuracy of 99.69%. After quantization for IoT device integration, the accuracy was 97.41% while reducing the model size by almost 4x. These findings have significant implications for the agricultural industry, as they have the potential to revolutionize how farmers identify crop illnesses quickly and accurately, ensuring food security and preserving agricultural output.
</details></li>
</ul>
<hr>
<h2 id="NEO-KD-Knowledge-Distillation-Based-Adversarial-Training-for-Robust-Multi-Exit-Neural-Networks"><a href="#NEO-KD-Knowledge-Distillation-Based-Adversarial-Training-for-Robust-Multi-Exit-Neural-Networks" class="headerlink" title="NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks"></a>NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00428">http://arxiv.org/abs/2311.00428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seokil Ham, Jungwuk Park, Dong-Jun Han, Jaekyun Moon</li>
<li>for: 本研究旨在提高多入口神经网络对针对攻击的抗性能力，通过使用知识储存技术进行 adversarial 训练策略。</li>
<li>methods: 本研究提出了两大贡献，首先通过邻居知识储存引导输出对恶例数据的输出偏移向 ensemble 输出的clean数据的邻居 exit 的输出偏移。其次，通过 exit-wise 正交知识储存来减少不同子模型之间的攻击传递性。</li>
<li>results: 对于多个数据集和模型，我们的方法实现了最佳的针对攻击精度，同时减少了计算预算。与基于现有 adversarial 训练或知识储存技术的基eline相比，我们的方法实现了更好的抗性能力。<details>
<summary>Abstract</summary>
While multi-exit neural networks are regarded as a promising solution for making efficient inference via early exits, combating adversarial attacks remains a challenging problem. In multi-exit networks, due to the high dependency among different submodels, an adversarial example targeting a specific exit not only degrades the performance of the target exit but also reduces the performance of all other exits concurrently. This makes multi-exit networks highly vulnerable to simple adversarial attacks. In this paper, we propose NEO-KD, a knowledge-distillation-based adversarial training strategy that tackles this fundamental challenge based on two key contributions. NEO-KD first resorts to neighbor knowledge distillation to guide the output of the adversarial examples to tend to the ensemble outputs of neighbor exits of clean data. NEO-KD also employs exit-wise orthogonal knowledge distillation for reducing adversarial transferability across different submodels. The result is a significantly improved robustness against adversarial attacks. Experimental results on various datasets/models show that our method achieves the best adversarial accuracy with reduced computation budgets, compared to the baselines relying on existing adversarial training or knowledge distillation techniques for multi-exit networks.
</details>
<details>
<summary>摘要</summary>
多出口神经网络被视为可以实现高效的早期退出的有望解决方案，但是对抗攻击性攻击仍然是一个挑战。在多出口网络中，由于不同的子模型之间的高度依赖关系，针对特定出口的攻击性示例不仅会降低该出口的性能，还会同时降低所有其他出口的性能。这使得多出口网络对简单的攻击性攻击非常易受到攻击。在这篇论文中，我们提出了NEO-KD，基于两项重要贡献的知识塑化基本攻击训练策略。NEO-KD首先通过邻居知识塑化引导攻击示例的输出倾向于净数据的邻居出口的ensemble输出。NEO-KD还使用出口WISE orthogonal知识塑化来减少不同子模型之间的攻击传递性。这使得我们的方法在不同的数据集/模型上实现了明显提高的抗击性。实验结果表明，我们的方法可以在计算预算限制下达到最佳的抗击精度，比基于现有的对抗训练或知识塑化技术的基准值更好。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-quantification-and-out-of-distribution-detection-using-surjective-normalizing-flows"><a href="#Uncertainty-quantification-and-out-of-distribution-detection-using-surjective-normalizing-flows" class="headerlink" title="Uncertainty quantification and out-of-distribution detection using surjective normalizing flows"></a>Uncertainty quantification and out-of-distribution detection using surjective normalizing flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00377">http://arxiv.org/abs/2311.00377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/irmlma/uncertainty-quantification-snf">https://github.com/irmlma/uncertainty-quantification-snf</a></li>
<li>paper_authors: Simon Dirmeier, Ye Hong, Yanan Xin, Fernando Perez-Cruz</li>
<li>for: 这个研究是为了提供一个简单的方法来量化深度学习模型中的epistemic和 aleatoricuncertainty，以便在不同环境下实现模型的可靠应用。</li>
<li>methods: 这个方法使用surjective normalizing flows来识别深度学习模型中的out-of-distribution数据集，可以在单一的前进过程中进行计算。这个方法建立在深度 uncertainty quantification和生成模型中的normalizing flows之上。</li>
<li>results: 在一个人工合成的数据集和一些实验室实现的数据集上，我们显示了我们的方法可以可靠地区别出对数据集的in-distribution和out-of-distribution数据。我们与Dirichlet process mixture model和bijective flow进行比较，发现surjective flow模型是关键的Component来可靠地分辨对数据集的in-distribution和out-of-distribution数据。<details>
<summary>Abstract</summary>
Reliable quantification of epistemic and aleatoric uncertainty is of crucial importance in applications where models are trained in one environment but applied to multiple different environments, often seen in real-world applications for example, in climate science or mobility analysis. We propose a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models that can be computed in a single forward pass. The method builds on recent developments in deep uncertainty quantification and generative modeling with normalizing flows. We apply our method to a synthetic data set that has been simulated using a mechanistic model from the mobility literature and several data sets simulated from interventional distributions induced by soft and atomic interventions on that model, and demonstrate that our method can reliably discern out-of-distribution data from in-distribution data. We compare the surjective flow model to a Dirichlet process mixture model and a bijective flow and find that the surjections are a crucial component to reliably distinguish in-distribution from out-of-distribution data.
</details>
<details>
<summary>摘要</summary>
可靠地量化模型中的 epistemic 和 aleatoric 不确定性是实际应用中非常重要的，因为模型通常在多个不同环境中训练，然后应用于多个环境中。例如，气候科学和流动分析中都有这种情况。我们提出了一种简单的方法，使用射影正规化流来在深度神经网络模型中标识不符合分布数据集。该方法基于深度不确定量和生成模型中的正规化流的最新发展。我们在一个由机制模型生成的 sintetic 数据集和一些基于软件和原子干扰的数据集上应用了我们的方法，并证明了我们的方法可靠地分辨出不符合分布数据集和符合分布数据集之间的差异。我们与 Dirichlet 过程混合模型和 bijection 流进行比较，发现射影是分辨出在 Distribution 和 out-of-distribution 数据集之间的关键组成部分。
</details></li>
</ul>
<hr>
<h2 id="Performance-Optimization-of-Deep-Learning-Sparse-Matrix-Kernels-on-Intel-Max-Series-GPU"><a href="#Performance-Optimization-of-Deep-Learning-Sparse-Matrix-Kernels-on-Intel-Max-Series-GPU" class="headerlink" title="Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel Max Series GPU"></a>Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel Max Series GPU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00368">http://arxiv.org/abs/2311.00368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Zubair, Christoph Bauinger</li>
<li>for: 这paper主要关注三种稀疏矩阵操作，即稀疏-积累矩阵乘法（SPMM）、采样积累-积累矩阵乘法（SDDMM），以及这两种操作的复合（FusedMM）。</li>
<li>methods: 我们开发了优化的实现方法 для SPMM、SDDMM 和 FusedMM 操作，使用 Intel oneAPI 的 Explicit SIMD（ESIMD） SYCL 扩展 API。这些 API 允许我们编写明确的 SIMD Veccode。</li>
<li>results: 我们的实现方法在目标 Intel Data Center GPU 上实现了稀疏矩阵操作的性能，与 Intel oneMKL 库的性能相似。我们还与 NVIDIA V100 GPU 上的 CUDA 实现和 Intel GPU 上的 oneMKL 库进行比较，并证明了我们的实现方法在稀疏矩阵操作中表现更好。<details>
<summary>Abstract</summary>
In this paper, we focus on three sparse matrix operations that are relevant for machine learning applications, namely, the sparse-dense matrix multiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM), and the composition of the SDDMM with SPMM, also termed as FusedMM. We develop optimized implementations for SPMM, SDDMM, and FusedMM operations utilizing Intel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or SYCL, the ESIMD API enables the writing of explicitly vectorized kernel code. Sparse matrix algorithms implemented with the ESIMD API achieved performance close to the peak of the targeted Intel Data Center GPU. We compare our performance results to Intel's oneMKL library on Intel GPUs and to a recent CUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and demonstrate that our implementations for sparse matrix operations outperform either.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们关注了三种稀疏矩阵操作，它们对机器学习应用有重要意义，即稀疏积 multiplication（SPMM）、采样积 multiplication（SDDMM）以及这两者的组合（FusedMM）。我们开发了优化的实现方法 для SPMM、SDDMM 和 FusedMM 操作，使用 Intel oneAPI 的 Explicit SIMD（ESIMD） SYCL 扩展 API。与 CUDA 或 SYCL 不同，ESIMD API 允许直接编写向量化kernel代码。我们使用 ESIMD API 实现的稀疏矩阵算法在目标 Intel 数据中心 GPU 的性能几乎达到了最高水平。我们对 Intel 的 oneMKL 库在 Intel GPU 上的性能进行比较，以及 NVIDIA V100 GPU 上的一个 recent CUDA 实现，并证明了我们的稀疏矩阵操作实现的性能高于其中任一。
</details></li>
</ul>
<hr>
<h2 id="Adversarially-Robust-Distributed-Count-Tracking-via-Partial-Differential-Privacy"><a href="#Adversarially-Robust-Distributed-Count-Tracking-via-Partial-Differential-Privacy" class="headerlink" title="Adversarially Robust Distributed Count Tracking via Partial Differential Privacy"></a>Adversarially Robust Distributed Count Tracking via Partial Differential Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00346">http://arxiv.org/abs/2311.00346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongzheng Xiong, Xiaoyi Zhu, Zengfeng Huang</li>
<li>for: 这篇论文关注分布式跟踪模型，即分布式功能监控。这种模型中，每个站点都接收一批项目，并与中央服务器进行交互。服务器需要不断地跟踪所有项目的函数，以最小化交互成本。</li>
<li>methods: 作者使用了随机化算法，但现有的随机算法假设了”无知恶作用者”会在算法开始前构建整个输入流。在这种情况下，作者考虑了适应性的恶作用者，这些恶作用者可以根据先前的答案来选择新的项目。作者证明了随机算法在适应性恶作用者情况下的优势。</li>
<li>results: 作者提供了一个具有最佳通信成本的可靠算法，并证明了这种算法在分布式环境中存在挑战。此外，作者还引入了”偏微分隐私”概念，并证明了一个新的总体公式。这个公式可能在更广泛的应用场景中有着独立的价值。<details>
<summary>Abstract</summary>
We study the distributed tracking model, also known as distributed functional monitoring. This model involves $k$ sites each receiving a stream of items and communicating with the central server. The server's task is to track a function of all items received thus far continuously, with minimum communication cost. For count tracking, it is known that there is a $\sqrt{k}$ gap in communication between deterministic and randomized algorithms. However, existing randomized algorithms assume an "oblivious adversary" who constructs the entire input streams before the algorithm starts. Here we consider adaptive adversaries who can choose new items based on previous answers from the algorithm. Deterministic algorithms are trivially robust to adaptive adversaries, while randomized ones may not. Therefore, we investigate whether the $\sqrt{k}$ advantage of randomized algorithms is from randomness itself or the oblivious adversary assumption. We provide an affirmative answer to this question by giving a robust algorithm with optimal communication. Existing robustification techniques do not yield optimal bounds due to the inherent challenges of the distributed nature of the problem. To address this, we extend the differential privacy framework by introducing "partial differential privacy" and proving a new generalization theorem. This theorem may have broader applications beyond robust count tracking, making it of independent interest.
</details>
<details>
<summary>摘要</summary>
我们研究分布式追踪模型，又称为分布式功能监控。这个模型中有 $k$ 个网站，每个网站获得一条流量，并与中央服务器进行通信。服务器的任务是不断地追踪所有收到的物品，并实现最小的通信成本。在数据追踪中，已知存在 $\sqrt{k}$ 差距在决定性和随机化算法之间。然而，现有的随机化算法假设了“无知敌人”可以在算法开始之前构成整个输入流。在这里，我们考虑到可靠性敌人，他们可以根据先前答案选择新的物品。决定性算法是可以对可靠性敌人进行防护的，而随机化算法可能不是。因此，我们调查这 $\sqrt{k}$ 差距是由随机性本身或“无知敌人”假设所带来的。我们提供了一个具有最佳通信的扩展算法，并证明了一个新的通用定理。这个定理可能在更多的应用中有价值，因此是独立的 interessant。
</details></li>
</ul>
<hr>
<h2 id="The-Open-DAC-2023-Dataset-and-Challenges-for-Sorbent-Discovery-in-Direct-Air-Capture"><a href="#The-Open-DAC-2023-Dataset-and-Challenges-for-Sorbent-Discovery-in-Direct-Air-Capture" class="headerlink" title="The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct Air Capture"></a>The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct Air Capture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00341">http://arxiv.org/abs/2311.00341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anuroop Sriram, Sihoon Choi, Xiaohan Yu, Logan M. Brabson, Abhishek Das, Zachary Ulissi, Matt Uyttendaele, Andrew J. Medford, David S. Sholl</li>
<li>For: The paper is written for the purpose of exploring a computational approach to discovering promising metal-organic frameworks (MOFs) for direct air capture (DAC) using machine learning (ML) and density functional theory (DFT) calculations.* Methods: The paper uses a computational approach that involves more than 38 million DFT calculations on over 8,800 MOF materials containing adsorbed CO2 and&#x2F;or H2O to identify promising MOFs for DAC. The dataset used for the study, named Open DAC 2023 (ODAC23), is the largest dataset of MOF adsorption calculations at the DFT level of accuracy currently available.* Results: The paper identifies a large number of MOFs with promising properties for DAC directly in ODAC23, and trains state-of-the-art ML models on the dataset to approximate calculations at the DFT level. The open-source dataset and ML models provide an important baseline for future efforts to identify MOFs for a wide range of applications, including DAC.Here is the simplified Chinese text for the three information points:* For: 本研究是为了通过计算方法发现 dirett air capture (DAC) 中最佳的金属组合物材料 (MOF)，使用机器学习 (ML) 和密度函数理论 (DFT) 计算。* Methods: 本研究使用了大量的 DFT 计算，计算了超过 8,800 个 MOF 材料中的 CO2 和&#x2F;或 H2O 的吸附性。这个数据集名为 Open DAC 2023 (ODAC23)，现在最大的 MOF 吸附计算数据集之一。* Results: 本研究直接在 ODAC23 中发现了许多有 promise 的 MOF  для DAC，并使用了当前最佳的 ML 模型来近似 DFT 计算。这个开源数据集和 ML 模型将为未来的 MOF 发现提供重要的基线。<details>
<summary>Abstract</summary>
New methods for carbon dioxide removal are urgently needed to combat global climate change. Direct air capture (DAC) is an emerging technology to capture carbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have been widely studied as potentially customizable adsorbents for DAC. However, discovering promising MOF sorbents for DAC is challenging because of the vast chemical space to explore and the need to understand materials as functions of humidity and temperature. We explore a computational approach benefiting from recent innovations in machine learning (ML) and present a dataset named Open DAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT) calculations on more than 8,800 MOF materials containing adsorbed CO2 and/or H2O. ODAC23 is by far the largest dataset of MOF adsorption calculations at the DFT level of accuracy currently available. In addition to probing properties of adsorbed molecules, the dataset is a rich source of information on structural relaxation of MOFs, which will be useful in many contexts beyond specific applications for DAC. A large number of MOFs with promising properties for DAC are identified directly in ODAC23. We also trained state-of-the-art ML models on this dataset to approximate calculations at the DFT level. This open-source dataset and our initial ML models will provide an important baseline for future efforts to identify MOFs for a wide range of applications, including DAC.
</details>
<details>
<summary>摘要</summary>
新的碳排放除去方法 urgently needed 以 combat global climate change. Direct air capture (DAC) 是一 emerging technology  captures carbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) 已经 widely studied as potentially customizable adsorbents for DAC. However, discovering promising MOF sorbents for DAC 是 challenging because of the vast chemical space to explore and the need to understand materials as functions of humidity and temperature. We explore a computational approach benefiting from recent innovations in machine learning (ML) and present a dataset named Open DAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT) calculations on more than 8,800 MOF materials containing adsorbed CO2 and/or H2O. ODAC23 is by far the largest dataset of MOF adsorption calculations at the DFT level of accuracy currently available. In addition to probing properties of adsorbed molecules, the dataset is a rich source of information on structural relaxation of MOFs, which will be useful in many contexts beyond specific applications for DAC. A large number of MOFs with promising properties for DAC are identified directly in ODAC23. We also trained state-of-the-art ML models on this dataset to approximate calculations at the DFT level. This open-source dataset and our initial ML models will provide an important baseline for future efforts to identify MOFs for a wide range of applications, including DAC.
</details></li>
</ul>
<hr>
<h2 id="Latent-Space-Inference-For-Spatial-Transcriptomics"><a href="#Latent-Space-Inference-For-Spatial-Transcriptomics" class="headerlink" title="Latent Space Inference For Spatial Transcriptomics"></a>Latent Space Inference For Spatial Transcriptomics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00330">http://arxiv.org/abs/2311.00330</a></li>
<li>repo_url: None</li>
<li>paper_authors: J. Ding, S. N. Zaman, P. Y. Chen, D. Wang</li>
<li>For: The paper aims to obtain full genetic expression information for tissue samples while preserving their spatial coordinates.* Methods: The authors use probabilistic machine learning methods and variational inference to map single-cell RNA sequencing and image-based spatial transcriptomics data to a joint latent space representation.* Results: The method allows for the full genetic expression information and spatial coordinates of cells to be decoded, providing greater insights into cellular processes and pathways.<details>
<summary>Abstract</summary>
In order to understand the complexities of cellular biology, researchers are interested in two important metrics: the genetic expression information of cells and their spatial coordinates within a tissue sample. However, state-of-the art methods, namely single-cell RNA sequencing and image based spatial transcriptomics can only recover a subset of this information, either full genetic expression with loss of spatial information, or spatial information with loss of resolution in sequencing data. In this project, we investigate a probabilistic machine learning method to obtain the full genetic expression information for tissues samples while also preserving their spatial coordinates. This is done through mapping both datasets to a joint latent space representation with the use of variational machine learning methods. From here, the full genetic and spatial information can be decoded and to give us greater insights on the understanding of cellular processes and pathways.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-task-Representation-Learning-for-Pure-Exploration-in-Bilinear-Bandits"><a href="#Multi-task-Representation-Learning-for-Pure-Exploration-in-Bilinear-Bandits" class="headerlink" title="Multi-task Representation Learning for Pure Exploration in Bilinear Bandits"></a>Multi-task Representation Learning for Pure Exploration in Bilinear Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00327">http://arxiv.org/abs/2311.00327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhojyoti Mukherjee, Qiaomin Xie, Josiah P. Hanna, Robert Nowak</li>
<li>for: 本文研究了多任务表示学习bilinear bandit问题中的纯探索问题。</li>
<li>methods: 我们提出了名为GOBLIN的算法，使用实验设计方法来优化样本分配以学习全局表示以及尽量降低每个任务中最佳对的搜索时间。</li>
<li>results: 我们的结果表明，通过共享表示来加速tasks的搜索过程，可以大幅提高样本复杂度。<details>
<summary>Abstract</summary>
We study multi-task representation learning for the problem of pure exploration in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms from two different entity types and the reward is a bilinear function of the known feature vectors of the arms. In the \textit{multi-task bilinear bandit problem}, we aim to find optimal actions for multiple tasks that share a common low-dimensional linear representation. The objective is to leverage this characteristic to expedite the process of identifying the best pair of arms for all tasks. We propose the algorithm GOBLIN that uses an experimental design approach to optimize sample allocations for learning the global representation as well as minimize the number of samples needed to identify the optimal pair of arms in individual tasks. To the best of our knowledge, this is the first study to give sample complexity analysis for pure exploration in bilinear bandits with shared representation. Our results demonstrate that by learning the shared representation across tasks, we achieve significantly improved sample complexity compared to the traditional approach of solving tasks independently.
</details>
<details>
<summary>摘要</summary>
我们研究多任务表示学习bilinear投机问题中的纯探索问题。在bilinear投机问题中，一个动作是两个不同实体类型的两个臂的对，奖励是两个已知特征向量的bilinear函数。在我们称为多任务bilinear投机问题中，我们目标是找到共享低维度线性表示的优化动作，以便为所有任务快速确定最佳对。我们提出了GOBLIN算法，该算法使用实验设计方法优化样本分配，以学习全局表示并最小化各个任务中样本数量。根据我们所知，这是bilinear投机问题中纯探索的首次提供样本复杂性分析。我们的结果表明，通过共享表示来加速确定最佳对的过程，可以获得 significatively改进的样本复杂性。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Hearing-Programming-Acoustic-Scenes-with-Binaural-Hearables"><a href="#Semantic-Hearing-Programming-Acoustic-Scenes-with-Binaural-Hearables" class="headerlink" title="Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables"></a>Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00320">http://arxiv.org/abs/2311.00320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bandhav Veluri, Malek Itani, Justin Chan, Takuya Yoshioka, Shyamnath Gollakota</li>
<li>for: 这个研究旨在实现智能耳机可以在实际环境中，在噪音和干扰音的情况下，实时专注或忽略特定的声音，同时保留空间对称信息。</li>
<li>methods: 这个研究使用了两项技术贡献：首先，我们提出了首个能够在噪音和背景噪音的情况下进行两声目标声抽象的神经网络，其中包括一个基于 transformer 的网络。其次，我们开发了一个可以对真实世界使用的训练方法，让我们的系统能够在不同的实际环境中进行扩展。</li>
<li>results: 我们的系统可以处理 20 种声音类型，并且在连接到智能手机的情况下，执行时间为 6.56 ms。在实际使用中，我们的证明系统能够在未见过的室内和外部enario中提取目标声音，并且能够保留空间对称信息。<details>
<summary>Abstract</summary>
Imagine being able to listen to the birds chirping in a park without hearing the chatter from other hikers, or being able to block out traffic noise on a busy street while still being able to hear emergency sirens and car honks. We introduce semantic hearing, a novel capability for hearable devices that enables them to, in real-time, focus on, or ignore, specific sounds from real-world environments, while also preserving the spatial cues. To achieve this, we make two technical contributions: 1) we present the first neural network that can achieve binaural target sound extraction in the presence of interfering sounds and background noise, and 2) we design a training methodology that allows our system to generalize to real-world use. Results show that our system can operate with 20 sound classes and that our transformer-based network has a runtime of 6.56 ms on a connected smartphone. In-the-wild evaluation with participants in previously unseen indoor and outdoor scenarios shows that our proof-of-concept system can extract the target sounds and generalize to preserve the spatial cues in its binaural output. Project page with code: https://semantichearing.cs.washington.edu
</details>
<details>
<summary>摘要</summary>
想象你在公园中听到鸟叫，而不听到其他游客的喊叫或 street 上的交通噪音，同时仍能听到紧急警响和汽车喊叫。我们介绍 semantic hearing，一种新的功能 для智能 Device，允许它们在实时中听到或忽略来自实际环境中的特定声音，而无需产生干扰。为达到这一目标，我们提出了两项技术贡献：1. 我们首次提出了一种可以在干扰声和背景噪音的情况下实现binarus target sound extraction的神经网络。2. 我们开发了一种可以让我们的系统在实际场景中进行泛化的训练方法。我们的系统可以处理20种声音类型，并且在连接到智能手机的情况下，runtime 为6.56ms。在实际场景中进行评估，我们的证明系统可以提取目标声音并保持它们的空间信息。项目页面包括代码：https://semantichearing.cs.washington.eduNote: Simplified Chinese is used here, as it is the most widely used variety of Chinese in mainland China. However, if you prefer Traditional Chinese, I can also provide the translation.
</details></li>
</ul>
<hr>
<h2 id="Federated-Topic-Model-and-Model-Pruning-Based-on-Variational-Autoencoder"><a href="#Federated-Topic-Model-and-Model-Pruning-Based-on-Variational-Autoencoder" class="headerlink" title="Federated Topic Model and Model Pruning Based on Variational Autoencoder"></a>Federated Topic Model and Model Pruning Based on Variational Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00314">http://arxiv.org/abs/2311.00314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjie Ma, Yawen Li, Meiyu Liang, Ang Li</li>
<li>for: This paper proposes a method for establishing a federated topic model while ensuring the privacy of each node, and using neural network model pruning to accelerate the model.</li>
<li>methods: The proposed method uses neural network model pruning, where the client periodically sends the model neuron cumulative gradients and model weights to the server, and the server prunes the model. Two different methods are proposed to determine the model pruning rate.</li>
<li>results: Experimental results show that the federated topic model pruning based on the variational autoencoder proposed in this paper can greatly accelerate the model training speed while ensuring the model’s performance.<details>
<summary>Abstract</summary>
Topic modeling has emerged as a valuable tool for discovering patterns and topics within large collections of documents. However, when cross-analysis involves multiple parties, data privacy becomes a critical concern. Federated topic modeling has been developed to address this issue, allowing multiple parties to jointly train models while protecting pri-vacy. However, there are communication and performance challenges in the federated sce-nario. In order to solve the above problems, this paper proposes a method to establish a federated topic model while ensuring the privacy of each node, and use neural network model pruning to accelerate the model, where the client periodically sends the model neu-ron cumulative gradients and model weights to the server, and the server prunes the model. To address different requirements, two different methods are proposed to determine the model pruning rate. The first method involves slow pruning throughout the entire model training process, which has limited acceleration effect on the model training process, but can ensure that the pruned model achieves higher accuracy. This can significantly reduce the model inference time during the inference process. The second strategy is to quickly reach the target pruning rate in the early stage of model training in order to accelerate the model training speed, and then continue to train the model with a smaller model size after reaching the target pruning rate. This approach may lose more useful information but can complete the model training faster. Experimental results show that the federated topic model pruning based on the variational autoencoder proposed in this paper can greatly accelerate the model training speed while ensuring the model's performance.
</details>
<details>
<summary>摘要</summary>
《主题模型的泛化应用》已经成为大量文档中发现模式和话题的有价值工具。然而，当跨分析 involve多方面时，数据隐私成为关键问题。为解决这问题，联邦主题模型被开发出来，允许多方共同训练模型，保护每个节点的隐私。然而，联邦场景中存在通信和性能问题。为解决这些问题，本文提出了一种方法，可以在多方共同训练模型的同时，保证每个节点的隐私，并使用神经网络模型剪辑加速模型训练。在不同的需求下，本文提出了两种不同的方法来确定模型剪辑率。第一种方法是在整个模型训练过程中慢慢剪辑模型，可以在模型训练过程中减少模型的大小，但是这种方法具有限制模型训练速度的缺点。第二种方法是在模型训练过程的早期 quickly reach the target pruning rate，以加速模型训练速度，然后继续使用较小的模型大小进行模型训练。这种方法可能会产生更多的损失信息，但可以更快地完成模型训练。实验结果表明，基于 variational autoencoder 的联邦主题模型剪辑可以大幅提高模型训练速度，而不 sacrificing 模型性能。
</details></li>
</ul>
<hr>
<h2 id="Stacking-an-autoencoder-for-feature-selection-of-zero-day-threats"><a href="#Stacking-an-autoencoder-for-feature-selection-of-zero-day-threats" class="headerlink" title="Stacking an autoencoder for feature selection of zero-day threats"></a>Stacking an autoencoder for feature selection of zero-day threats</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00304">http://arxiv.org/abs/2311.00304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmut Tokmak, Mike Nkongolo<br>for:This paper aims to detect zero-day attacks using a stacked autoencoder (SAE) and a Long Short-Term Memory (LSTM) scheme.methods:The paper uses preprocessing, feature selection, and supervised learning to train the SAE and LSTM models.results:The SAE-LSTM model achieves high precision, recall, and F1 score values in identifying various types of zero-day attacks, and generalizes effectively across different attack categories.Here’s the simplified Chinese text:for:这篇论文目的是使用堆叠自编码器（SAE）和长短期记忆（LSTM）方法探测零天攻击。methods:该论文使用预处理、特征选择和监睹学习来训练SAE和LSTM模型。results:SAE-LSTM模型在不同类型的零天攻击中表现出色，具有高精度、回归率和F1分数值，并能有效泛化到不同的攻击类别。<details>
<summary>Abstract</summary>
Zero-day attack detection plays a critical role in mitigating risks, protecting assets, and staying ahead in the evolving threat landscape. This study explores the application of stacked autoencoder (SAE), a type of artificial neural network, for feature selection and zero-day threat classification using a Long Short-Term Memory (LSTM) scheme. The process involves preprocessing the UGRansome dataset and training an unsupervised SAE for feature extraction. Finetuning with supervised learning is then performed to enhance the discriminative capabilities of this model. The learned weights and activations of the autoencoder are analyzed to identify the most important features for discriminating between zero-day threats and normal system behavior. These selected features form a reduced feature set that enables accurate classification. The results indicate that the SAE-LSTM performs well across all three attack categories by showcasing high precision, recall, and F1 score values, emphasizing the model's strong predictive capabilities in identifying various types of zero-day attacks. Additionally, the balanced average scores of the SAE-LSTM suggest that the model generalizes effectively and consistently across different attack categories.
</details>
<details>
<summary>摘要</summary>
zero-day 攻击检测扮演着关键的角色，帮助降低风险，保护资产，并在恶化的威胁领域保持领先地位。这项研究探讨了使用堆式自编码器（SAE），一种人工神经网络， для特征选择和 zero-day 威胁分类，使用Long Short-Term Memory（LSTM）方案。过程包括对UGRansome数据集进行预处理，并使用无监督SAE进行特征提取。然后，通过监督学习进行训练，以提高这个模型的推理能力。通过分析自编码器的权重和活化值，可以确定最重要的特征，以便准确地分类 zero-day 威胁和正常系统行为。这些选择的特征组成一个减少特征集，可以实现高精度的分类。结果表明，SAE-LSTM在所有三个攻击类别中表现出色，具有高精度、回归率和F1分数值，证明这个模型在不同类别的 zero-day 攻击中具有强的预测能力。此外，SAE-LSTM的平衡平均分数表明，这个模型在不同类别中一致地适应和泛化。
</details></li>
</ul>
<hr>
<h2 id="Model-driven-Engineering-for-Machine-Learning-Components-A-Systematic-Literature-Review"><a href="#Model-driven-Engineering-for-Machine-Learning-Components-A-Systematic-Literature-Review" class="headerlink" title="Model-driven Engineering for Machine Learning Components: A Systematic Literature Review"></a>Model-driven Engineering for Machine Learning Components: A Systematic Literature Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00284">http://arxiv.org/abs/2311.00284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hira Naveed, Chetan Arora, Hourieh Khalajzadeh, John Grundy, Omar Haggag</li>
<li>for: 本研究的目的是通过系统atic literature review (SLR) 探讨现有的研究，了解使用模型驱动工程 (MDE) 技术和机器学习 (ML) 之间的优势交叉。</li>
<li>methods: 本研究分析了选择的研究，包括他们的动机、MDE解决方案、评估技术、关键成果和局限性。</li>
<li>results: 我们分析了选择的研究，并发现了以下几个方面：1）使用 MDE4ML 的主要动机；2）各种 MDE 解决方案，如模型语言、模型转换、工具支持、targeted ML 方面等；3）评估技术和指标；4）局限性和未来研究方向。<details>
<summary>Abstract</summary>
Context: Machine Learning (ML) has become widely adopted as a component in many modern software applications. Due to the large volumes of data available, organizations want to increasingly leverage their data to extract meaningful insights and enhance business profitability. ML components enable predictive capabilities, anomaly detection, recommendation, accurate image and text processing, and informed decision-making. However, developing systems with ML components is not trivial; it requires time, effort, knowledge, and expertise in ML, data processing, and software engineering. There have been several studies on the use of model-driven engineering (MDE) techniques to address these challenges when developing traditional software and cyber-physical systems. Recently, there has been a growing interest in applying MDE for systems with ML components. Objective: The goal of this study is to further explore the promising intersection of MDE with ML (MDE4ML) through a systematic literature review (SLR). Through this SLR, we wanted to analyze existing studies, including their motivations, MDE solutions, evaluation techniques, key benefits and limitations. Results: We analyzed selected studies with respect to several areas of interest and identified the following: 1) the key motivations behind using MDE4ML; 2) a variety of MDE solutions applied, such as modeling languages, model transformations, tool support, targeted ML aspects, contributions and more; 3) the evaluation techniques and metrics used; and 4) the limitations and directions for future work. We also discuss the gaps in existing literature and provide recommendations for future research. Conclusion: This SLR highlights current trends, gaps and future research directions in the field of MDE4ML, benefiting both researchers and practitioners
</details>
<details>
<summary>摘要</summary>
Machine Learning (ML) 已成为现代软件应用程序的重要组件。由于数据量庞大，组织希望通过数据来提取有用的信息，提高业务收益。 ML 组件提供预测能力、异常检测、建议、高精度图像和文本处理、 Informed Decision-Making 等功能。然而，开发具有 ML 组件的系统并不是易事，需要时间、努力、知识和 ML、数据处理和软件工程的专业知识。在过去，有多个研究用于使用 Model-Driven Engineering (MDE) 技术来解决在开发传统软件和Cyber-Physical Systems (CPS) 时出现的挑战。最近，关于应用 MDE 于 ML 系统的兴趣在增长。目标：本研究的目标是进一步探索 MDE 与 ML（MDE4ML）的优秀交叉点，通过系统性文献综述（SLR）。通过这个 SLR，我们想要分析已有的研究，包括他们的动机、MDE 解决方案、评估技术、关键优势和局限性。结果：我们对选择的研究进行了分析，并identified以下几个领域：1）使用 MDE4ML 的主要动机；2）MDE 解决方案的多样性，包括模型语言、模型转换、工具支持、针对 ML 方面的贡献等；3）评估技术和指标的使用；4）限制和未来研究的方向。我们还讨论了现有文献中的缺陷，并提供了未来研究的建议。结论：本 SLR  highlights 当前的趋势、缺陷和未来研究方向，对研究人员和实践者都有帮助。
</details></li>
</ul>
<hr>
<h2 id="Generalization-Bounds-for-Label-Noise-Stochastic-Gradient-Descent"><a href="#Generalization-Bounds-for-Label-Noise-Stochastic-Gradient-Descent" class="headerlink" title="Generalization Bounds for Label Noise Stochastic Gradient Descent"></a>Generalization Bounds for Label Noise Stochastic Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00274">http://arxiv.org/abs/2311.00274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jung Eun Huh, Patrick Rebeschini</li>
<li>for: This paper is written for understanding the generalization error bounds of stochastic gradient descent (SGD) with label noise in non-convex settings.</li>
<li>methods: The paper uses the framework of algorithmic stability and the concept of Wasserstein distance to derive generalization error bounds for SGD with label noise.</li>
<li>results: The paper achieves time-independent generalization error bounds for the discretized algorithm with a constant learning rate, and the error bound scales polynomially with the dimension $d$ and with the rate of $n^{-2&#x2F;3}$, which is better than the best-known rate of $n^{-1&#x2F;2}$ for stochastic gradient Langevin dynamics (SGLD) under similar conditions.<details>
<summary>Abstract</summary>
We develop generalization error bounds for stochastic gradient descent (SGD) with label noise in non-convex settings under uniform dissipativity and smoothness conditions. Under a suitable choice of semimetric, we establish a contraction in Wasserstein distance of the label noise stochastic gradient flow that depends polynomially on the parameter dimension $d$. Using the framework of algorithmic stability, we derive time-independent generalisation error bounds for the discretized algorithm with a constant learning rate. The error bound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD) -- which employs parameter-independent Gaussian noise -- under similar conditions. Our analysis offers quantitative insights into the effect of label noise.
</details>
<details>
<summary>摘要</summary>
我们研究了随机梯度 descent（SGD）在非конvex设定下对标签噪声的总化错误界限。在适当的semimetric下，我们证明了标签噪声随机梯度流的 Wasserstein距离减少的contraktion，这种减少速率取决于参数维度$d$。使用算法稳定性框架，我们 derivetime-independent的总化错误界限 для精细化算法，该界限与参数维度$d$和学习率$n$相乘，其中$n$是样本大小。这个速率比best-known的$n^{-1/2}$更好，这个速率是在类似条件下随机梯度勒文动力（SGLD）下获得的。我们的分析带来了标签噪声的量化理解。
</details></li>
</ul>
<hr>
<h2 id="Incentivized-Collaboration-in-Active-Learning"><a href="#Incentivized-Collaboration-in-Active-Learning" class="headerlink" title="Incentivized Collaboration in Active Learning"></a>Incentivized Collaboration in Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00260">http://arxiv.org/abs/2311.00260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lee Cohen, Han Shao</li>
<li>for: 这篇论文是关于多 Agent 协同学习中的奖励协同，即多个代理 Trying to learn labels from a common hypothesis。</li>
<li>methods: 这篇论文使用了一种创新的框架，即奖励协同，以增加代理之间的协作。这种协作的目的是使代理们可以获得最少的标签复杂性。作者们关注的是设计(严格)个人合理（IR）合作协议，以确保代理不能通过单独行动减少其预期标签复杂性。</li>
<li>results: 作者们第一先表明，给定任何优化的活动学习算法，与整个数据集进行协同的协作协议就是IR的。然而，计算优化算法是NP困难的。因此，作者们提供了一些IR的协作协议，可以与最佳可追踪的标签复杂性相比。<details>
<summary>Abstract</summary>
In collaborative active learning, where multiple agents try to learn labels from a common hypothesis, we introduce an innovative framework for incentivized collaboration. Here, rational agents aim to obtain labels for their data sets while keeping label complexity at a minimum. We focus on designing (strict) individually rational (IR) collaboration protocols, ensuring that agents cannot reduce their expected label complexity by acting individually. We first show that given any optimal active learning algorithm, the collaboration protocol that runs the algorithm as is over the entire data is already IR. However, computing the optimal algorithm is NP-hard. We therefore provide collaboration protocols that achieve (strict) IR and are comparable with the best known tractable approximation algorithm in terms of label complexity.
</details>
<details>
<summary>摘要</summary>
在合作主动学习中，多个代理人尝试从共同假设中学习标签。我们提出了一个创新的激励合作框架，在这个框架中，理性的代理人尝试获取标签以减少标签复杂性。我们专注于设计（严格）合作协议，以确保代理人不能通过单独行动将标签复杂性降低。我们首先显示，任何最佳活动学习算法都可以在整个数据集上运行，并且已经是合作协议中的严格合作（IR）。但计算最佳算法是NP困难的。我们因此提供了一些合作协议，它们可以确保代理人不能透过单独行动将标签复杂性降低，并且与已知可追踪的数学方法相比，具有相似的标签复杂性。
</details></li>
</ul>
<hr>
<h2 id="Active-Neural-Topological-Mapping-for-Multi-Agent-Exploration"><a href="#Active-Neural-Topological-Mapping-for-Multi-Agent-Exploration" class="headerlink" title="Active Neural Topological Mapping for Multi-Agent Exploration"></a>Active Neural Topological Mapping for Multi-Agent Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00252">http://arxiv.org/abs/2311.00252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyi Yang, Yuxiang Yang, Chao Yu, Jiayu Chen, Jingchen Yu, Haibing Ren, Huazhong Yang, Yu Wang<br>for: 本研究目的是提高多体协同探索任务的效率和泛化能力。methods: 本研究使用的方法包括 neural topological mapping 和 hierarchical topological planning。results: 实验结果表明，相比计划基eline和RL基eline，MANTM可以降低步数少于26.40%，并在未看过enario中提高效率。<details>
<summary>Abstract</summary>
This paper investigates the multi-agent cooperative exploration problem, which requires multiple agents to explore an unseen environment via sensory signals in a limited time. A popular approach to exploration tasks is to combine active mapping with planning. Metric maps capture the details of the spatial representation, but are with high communication traffic and may vary significantly between scenarios, resulting in inferior generalization. Topological maps are a promising alternative as they consist only of nodes and edges with abstract but essential information and are less influenced by the scene structures. However, most existing topology-based exploration tasks utilize classical methods for planning, which are time-consuming and sub-optimal due to their handcrafted design. Deep reinforcement learning (DRL) has shown great potential for learning (near) optimal policies through fast end-to-end inference. In this paper, we propose Multi-Agent Neural Topological Mapping (MANTM) to improve exploration efficiency and generalization for multi-agent exploration tasks. MANTM mainly comprises a Topological Mapper and a novel RL-based Hierarchical Topological Planner (HTP). The Topological Mapper employs a visual encoder and distance-based heuristics to construct a graph containing main nodes and their corresponding ghost nodes. The HTP leverages graph neural networks to capture correlations between agents and graph nodes in a coarse-to-fine manner for effective global goal selection. Extensive experiments conducted in a physically-realistic simulator, Habitat, demonstrate that MANTM reduces the steps by at least 26.40% over planning-based baselines and by at least 7.63% over RL-based competitors in unseen scenarios.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这篇论文研究了多机合作探索问题，即多个机器人需要在未知环境中通过感知信号进行探索，并且在有限时间内完成。一种常见的方法是将活动地图与计划结合，但这可能会带来高度的通信压力和场景结构的变化，导致性能下降。为了解决这个问题，作者们提出了多机 neural topological mapping（MANTM），它包括一个 topological mapper 和一个基于RL的层次 topological planner（HTP）。topological mapper 使用视觉编码器和距离基于的规则来构建一个图，包括主节点和其对应的幽灵节点，而 HTP 利用图 neural networks 来捕捉机器人和图节点之间的相关性，并在层次结构中进行有效的全局目标选择。作者们在一个物理实际的 simulate 中进行了广泛的实验，并证明了 MANTM 可以在未知场景中减少步骤数量，相比计划基本elines 和 RL 基本elines 的减少量分别为至少 26.40% 和 7.63%。
</details></li>
</ul>
<hr>
<h2 id="DistDNAS-Search-Efficient-Feature-Interactions-within-2-Hours"><a href="#DistDNAS-Search-Efficient-Feature-Interactions-within-2-Hours" class="headerlink" title="DistDNAS: Search Efficient Feature Interactions within 2 Hours"></a>DistDNAS: Search Efficient Feature Interactions within 2 Hours</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00231">http://arxiv.org/abs/2311.00231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tunhou Zhang, Wei Wen, Igor Fedorov, Xi Liu, Buyun Zhang, Fangqiu Han, Wen-Yen Chen, Yiping Han, Feng Yan, Hai Li, Yiran Chen</li>
<li>for: 提高推荐系统的功能交互设计效率和服务效率</li>
<li>methods: 提出DistDNAS算法，通过设计各种类型和顺序的交互模块搜索空间，并通过分布式搜索和数据日期分配优化搜索效率，实现25倍的速度提升和2天减少为2小时的搜索成本。同时，DistDNAS引入可微分的成本意识损失函数，惩罚选择重复的交互模块，提高发现的功能交互效率。</li>
<li>results: 对1TB criterio terabyte dataset进行广泛的实验评估，表明DistDNAS可以提供0.001 AUC提升和60% FLOPs减少的Current state-of-the-art CTR模型。<details>
<summary>Abstract</summary>
Search efficiency and serving efficiency are two major axes in building feature interactions and expediting the model development process in recommender systems. On large-scale benchmarks, searching for the optimal feature interaction design requires extensive cost due to the sequential workflow on the large volume of data. In addition, fusing interactions of various sources, orders, and mathematical operations introduces potential conflicts and additional redundancy toward recommender models, leading to sub-optimal trade-offs in performance and serving cost. In this paper, we present DistDNAS as a neat solution to brew swift and efficient feature interaction design. DistDNAS proposes a supernet to incorporate interaction modules of varying orders and types as a search space. To optimize search efficiency, DistDNAS distributes the search and aggregates the choice of optimal interaction modules on varying data dates, achieving over 25x speed-up and reducing search cost from 2 days to 2 hours. To optimize serving efficiency, DistDNAS introduces a differentiable cost-aware loss to penalize the selection of redundant interaction modules, enhancing the efficiency of discovered feature interactions in serving. We extensively evaluate the best models crafted by DistDNAS on a 1TB Criteo Terabyte dataset. Experimental evaluations demonstrate 0.001 AUC improvement and 60% FLOPs saving over current state-of-the-art CTR models.
</details>
<details>
<summary>摘要</summary>
搜索效率和服务效率是建立功能交互和加速模型开发过程中的两个主要轴。在大规模 benchmark 上，搜索最佳功能交互设计需要巨大的成本，因为执行大量数据的顺序工作流程。此外，将不同来源、顺序和数学运算的交互整合到推荐模型中，会导致性能和服务成本之间的冲突和额外冗余。在这篇论文中，我们提出了 DistDNAS，一种简洁的解决方案，用于快速和高效地设计功能交互。DistDNAS 提出了一个超网，用于包含交互模块的不同顺序和类型作为搜索空间。为了优化搜索效率，DistDNAS 将搜索分布到不同的数据日期上，并对选择优化交互模块的选择进行整合，实现了25倍的速度提升，从2天减少到2小时。为了优化服务效率，DistDNAS 引入了可 diferenciable 成本意识损失，以惩罚选择 redundancy 的交互模块，提高发现的功能交互效率在服务中。我们对一个1TB Criteo Terabyte  dataset进行了广泛的实验评估。实验结果显示，由 DistDNAS 打造的最佳模型在 AUC 方面提高了0.001，并在Current State-of-the-art CTR 模型中减少了60%的计算成本。
</details></li>
</ul>
<hr>
<h2 id="Transformers-are-Efficient-In-Context-Estimators-for-Wireless-Communication"><a href="#Transformers-are-Efficient-In-Context-Estimators-for-Wireless-Communication" class="headerlink" title="Transformers are Efficient In-Context Estimators for Wireless Communication"></a>Transformers are Efficient In-Context Estimators for Wireless Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00226">http://arxiv.org/abs/2311.00226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vicram Rajagopalan, Vishnu Teja Kunde, Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Srinivas Shakkottai, Dileep Kalathil, Jean-Francois Chamberland</li>
<li>for: 这种方法是为了解决通信问题，即估算发送的符号从接收的符号中的损失。</li>
<li>methods: 我们使用了基于 transformer 的受限制推论方法，使其能够在只有少量引言的情况下，通过自动学习，来进行受限制推论。</li>
<li>results: 我们通过了广泛的 simulate，显示这种方法不仅可以大幅提高性能，而且可以在几个上下文示例后达到与完全知情上下文情况下的同样性。<details>
<summary>Abstract</summary>
Pre-trained transformers can perform in-context learning, where they adapt to a new task using only a small number of prompts without any explicit model optimization. Inspired by this attribute, we propose a novel approach, called in-context estimation, for the canonical communication problem of estimating transmitted symbols from received symbols. A communication channel is essentially a noisy function that maps transmitted symbols to received symbols, and this function can be represented by an unknown parameter whose statistics depend on an (also unknown) latent context. Conventional approaches ignore this hierarchical structure and simply attempt to use known transmissions, called pilots, to perform a least-squares estimate of the channel parameter, which is then used to estimate successive, unknown transmitted symbols. We make the basic connection that transformers show excellent contextual sequence completion with a few prompts, and so they should be able to implicitly determine the latent context from pilot symbols to perform end-to-end in-context estimation of transmitted symbols. Furthermore, the transformer should use information efficiently, i.e., it should utilize any pilots received to attain the best possible symbol estimates. Through extensive simulations, we show that in-context estimation not only significantly outperforms standard approaches, but also achieves the same performance as an estimator with perfect knowledge of the latent context within a few context examples. Thus, we make a strong case that transformers are efficient in-context estimators in the communication setting.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)预训练的转换器可以进行境TEXTlearning，在只有少量提示下自适应新任务，而无需显式模型优化。 Drawing inspiration from this attribute, we propose a novel approach, called in-context estimation, for the canonical communication problem of estimating transmitted symbols from received symbols. A communication channel is essentially a noisy function that maps transmitted symbols to received symbols, and this function can be represented by an unknown parameter whose statistics depend on an (also unknown) latent context. Conventional approaches ignore this hierarchical structure and simply attempt to use known transmissions, called pilots, to perform a least-squares estimate of the channel parameter, which is then used to estimate successive, unknown transmitted symbols. We make the basic connection that transformers show excellent contextual sequence completion with a few prompts, and so they should be able to implicitly determine the latent context from pilot symbols to perform end-to-end in-context estimation of transmitted symbols. Furthermore, the transformer should use information efficiently, i.e., it should utilize any pilots received to attain the best possible symbol estimates. Through extensive simulations, we show that in-context estimation not only significantly outperforms standard approaches, but also achieves the same performance as an estimator with perfect knowledge of the latent context within a few context examples. Therefore, we make a strong case that transformers are efficient in-context estimators in the communication setting.
</details></li>
</ul>
<hr>
<h2 id="WinNet-time-series-forecasting-with-a-window-enhanced-period-extracting-and-interacting"><a href="#WinNet-time-series-forecasting-with-a-window-enhanced-period-extracting-and-interacting" class="headerlink" title="WinNet:time series forecasting with a window-enhanced period extracting and interacting"></a>WinNet:time series forecasting with a window-enhanced period extracting and interacting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00214">http://arxiv.org/abs/2311.00214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Ou, Dongyue Guo, Zheng Zhang, Zhishuo Zhao, Yi Lin</li>
<li>for: 这个研究旨在提出一个高精度且简单结构的 CNN 模型，用于长期时间序列预测任务。</li>
<li>methods: 本研究使用了 Inter-Intra Period Encoder (I2PE)、Two-Dimensional Period Decomposition (TDPD) 和 Decomposition Correlation Block (DCB) 等技术，将 1D 序列转换为 2D 矩阵，并模型长期和短期周期性。</li>
<li>results: 在九个benchmark datasets上，WinNet 能够 achieve SOTA 性能，并且比 CNN、MLP 和 Transformer 等方法来的computational complexity较低。<details>
<summary>Abstract</summary>
Recently, Transformer-based methods have significantly improved state-of-the-art time series forecasting results, but they suffer from high computational costs and the inability to capture the long and short periodicity of time series. We present a highly accurate and simply structured CNN-based model for long-term time series forecasting tasks, called WinNet, including (i) Inter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with long and short periodicity according to the predefined periodic window, (ii) Two-Dimensional Period Decomposition (TDPD) to model period-trend and oscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage the correlations of the period-trend and oscillation terms to support the prediction tasks by CNNs. Results on nine benchmark datasets show that the WinNet can achieve SOTA performance and lower computational complexity over CNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the CNN-based methods in the time series forecasting tasks, with perfect tradeoff between performance and efficiency.
</details>
<details>
<summary>摘要</summary>
最近，基于Transformer的方法在时间序列预测中取得了显著改进，但它们受到高计算成本和不能捕捉时间序列的长短周期性的限制。我们介绍了一种高精度且简单结构的Convolutional Neural Network（CNN）模型，称为WinNet，用于长期时间序列预测任务。该模型包括以下三部分：1. 间隔内 period编码器（I2PE）：将1D序列转化为2D张量，同时捕捉长周期和短周期性。2. 二维 periodic decomposition（TDPD）：模型 periodic-trend和抽象oscillation项。3. 分解相关块（DCB）：利用 periodic-trend和抽象oscillation项之间的相关性，支持预测任务。Results on nine benchmark datasets show that WinNet can achieve state-of-the-art performance and lower computational complexity than CNN-, MLP-, Transformer-based approaches. WinNet provides a potential solution for CNN-based methods in time series forecasting tasks, with a perfect tradeoff between performance and efficiency.
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Framework-to-Enforce-Discover-and-Promote-Symmetry-in-Machine-Learning"><a href="#A-Unified-Framework-to-Enforce-Discover-and-Promote-Symmetry-in-Machine-Learning" class="headerlink" title="A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning"></a>A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00212">http://arxiv.org/abs/2311.00212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel E. Otto, Nicholas Zolman, J. Nathan Kutz, Steven L. Brunton</li>
<li>for: 本 paper 旨在探讨如何在机器学习模型中 incorporate Symmetry，以提高模型的泛化能力和性能。</li>
<li>methods: 本 paper 使用了 Lie  derivative 和 fibre-linear Lie group actions on vector bundles 等 математиче工具，提供了一种统一的理论和方法框架，用于在机器学习模型中 enforcing 和 discovering Symmetry。</li>
<li>results: 本 paper 的结果表明，在 enforcing 和 discovering Symmetry 的过程中，可以通过 linear-algebraic 任务和 dual 性来捕捉 Symmetry 的特性，并且可以通过 convex 规则函数和 nuclear norm relaxation 来杜缺 Symmetry breaking。这些想法可以应用于各种机器学习模型，如基函数回归、动力系统发现、多层感知器和图像空间中的神经网络。<details>
<summary>Abstract</summary>
Symmetry is present throughout nature and continues to play an increasingly central role in physics and machine learning. Fundamental symmetries, such as Poincar\'{e} invariance, allow physical laws discovered in laboratories on Earth to be extrapolated to the farthest reaches of the universe. Symmetry is essential to achieving this extrapolatory power in machine learning applications. For example, translation invariance in image classification allows models with fewer parameters, such as convolutional neural networks, to be trained on smaller data sets and achieve state-of-the-art performance. In this paper, we provide a unifying theoretical and methodological framework for incorporating symmetry into machine learning models in three ways: 1. enforcing known symmetry when training a model; 2. discovering unknown symmetries of a given model or data set; and 3. promoting symmetry during training by learning a model that breaks symmetries within a user-specified group of candidates when there is sufficient evidence in the data. We show that these tasks can be cast within a common mathematical framework whose central object is the Lie derivative associated with fiber-linear Lie group actions on vector bundles. We extend and unify several existing results by showing that enforcing and discovering symmetry are linear-algebraic tasks that are dual with respect to the bilinear structure of the Lie derivative. We also propose a novel way to promote symmetry by introducing a class of convex regularization functions based on the Lie derivative and nuclear norm relaxation to penalize symmetry breaking during training of machine learning models. We explain how these ideas can be applied to a wide range of machine learning models including basis function regression, dynamical systems discovery, multilayer perceptrons, and neural networks acting on spatial fields such as images.
</details>
<details>
<summary>摘要</summary>
自然中的对称性在物理和机器学习中发挥了越来越重要的作用。基本对称性，如波兰几何对称性，使得在地球室内实验室中发现的物理法则可以在宇宙中的最远处适用。对称性是机器学习应用中达到这种推断力的关键。例如，图像分类中的翻译对称性使得使用 fewer parameters的卷积神经网络来训练小型数据集，并达到状态对应的性能。在这篇文章中，我们提供一种统一的理论和方法框架，用于在机器学习模型中包含对称性。我们的方法包括：1. 在训练模型时强制执行已知对称性; 2. 发现数据集或模型未知的对称性; 3. 在用户指定的对称组中，通过学习模型破坏对称性来提高模型性能。我们表明这些任务可以在共同的数学框架中进行，核心对象是在纤维线性 Lie 群行为下的 Lie DERIVATIVE。我们扩展和统一了一些现有结果，并证明了强制和发现对称性是线性代数任务，这些任务与模型数据的双线性结构相关。我们还提出了一种新的对称优化方法，基于 Lie DERIVATIVE 和核心 нор relaxation 来强制模型在训练过程中遵循对称性。我们解释了这些想法如何应用于各种机器学习模型，包括基准函数回归、动力系统发现、多层感知网络和图像空间中的神经网络。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-for-accuracy-in-density-functional-approximations"><a href="#Machine-learning-for-accuracy-in-density-functional-approximations" class="headerlink" title="Machine learning for accuracy in density functional approximations"></a>Machine learning for accuracy in density functional approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00196">http://arxiv.org/abs/2311.00196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Voss</li>
<li>for: 提高 atomistic  simulations 和材料设计 的速度和精度</li>
<li>methods: 使用机器学习技术</li>
<li>results: 提高 computationally efficient electronic structure methods 的预测力和正确性<details>
<summary>Abstract</summary>
Machine learning techniques have found their way into computational chemistry as indispensable tools to accelerate atomistic simulations and materials design. In addition, machine learning approaches hold the potential to boost the predictive power of computationally efficient electronic structure methods, such as density functional theory, to chemical accuracy and to correct for fundamental errors in density functional approaches. Here, recent progress in applying machine learning to improve the accuracy of density functional and related approximations is reviewed. Promises and challenges in devising machine learning models transferable between different chemistries and materials classes are discussed with the help of examples applying promising models to systems far outside their training sets.
</details>
<details>
<summary>摘要</summary>
机器学习技术已经在计算化学中成为不可或缺的工具，以加速原子尺度模拟和材料设计。此外，机器学习方法还拥有提高计算效率的电子结构方法的预测能力的潜力，以及对density functional方法中的基本错误进行修正的能力。本文将 recensents recent progress in applying machine learning to improve the accuracy of density functional and related approximations. 以及在不同化学和材料类中设计可质量转移的机器学习模型的挑战和推荐。通过例子，应用有前景的模型到远 outside its training set。Translation notes:* 计算化学 (computational chemistry) is translated as 计算化学 (computational chemistry)* 原子尺度模拟 (atomistic simulations) is translated as 原子尺度模拟 (atomistic simulations)* density functional theory (DFT) is translated as density functional theory (DFT)* 机器学习 (machine learning) is translated as 机器学习 (machine learning)* 可质量转移 (transfer learning) is translated as 可质量转移 (transfer learning)* 材料类 (materials class) is translated as 材料类 (materials class)
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.LG_2023_11_01/" data-id="cloh7tqkn00rn7b88dhtadkzb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/eess.IV_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T09:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/eess.IV_2023_11_01/">eess.IV - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="See-SIFT-in-a-Rain"><a href="#See-SIFT-in-a-Rain" class="headerlink" title="See SIFT in a Rain"></a>See SIFT in a Rain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00518">http://arxiv.org/abs/2311.00518</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiuchu-buyan/See_SIFT_in_a_Rain">https://github.com/jiuchu-buyan/See_SIFT_in_a_Rain</a></li>
<li>paper_authors: Wei Wu, Hao Chang, Zhu Li</li>
<li>For: 本研究的目的是提出一种任务驱动的图像排除算法，以增强图像特征提取能力，并且特别是针对Scale-Invariant Feature Transform (SIFT)的检测和描述。* Methods: 本研究使用了两种不同的网络，分别是Diffusion of Gaussian (DoG) pyramid recovery network (DPRNet)和Gradients of Gaussian images recovery network (GGIRNet)，以实现SIFT检测和描述的两个目标。在DPRNet中，我们提出了一种alternative interest point loss，直接惩罚缩放响应极值来恢复DoG pyramid。在GGIRNet中，我们提出了一种gradient attention模块，以恢复Gradients of Gaussian images。* Results: 实验结果表明，相比之前的方法，我们提出的算法在SIFT键点数量和准确率两个指标上具有更好的表现。<details>
<summary>Abstract</summary>
Rain streaks bring complicated pixel intensity changes and additional gradients, greatly obstructing the extraction of image features from background. This causes serious performance degradation in feature-based applications. Thus, it is critical to remove rain streaks from a single rainy image to recover image features. Recently, many excellent image deraining methods have made remarkable progress. However, these human visual system-driven approaches mainly focus on improving image quality with pixel recovery as loss function, and neglect how to enhance image feature recovery ability. To address this issue, we propose a task-driven image deraining algorithm to strengthen image feature supply for subsequent feature-based applications. Due to the extensive use and strong practicability of Scale-Invariant Feature Transform (SIFT), we first propose two separate networks using distinct losses and modules to achieve two goals, respectively. One is difference of Gaussian (DoG) pyramid recovery network (DPRNet) for SIFT detection, and the other gradients of Gaussian images recovery network (GGIRNet) for SIFT description. Second, in the DPRNet we propose an alternative interest point loss that directly penalizes scale response extrema to recover the DoG pyramid. Third, we advance a gradient attention module in the GGIRNet to recover those gradients of Gaussian images. Finally, with the recovered DoG pyramid and gradients, we can regain SIFT key points. This divide-and-conquer scheme to set different objectives for SIFT detection and description leads to good robustness. Compared with state-of-the-art methods, experimental results demonstrate that our proposed algorithm achieves better performance in both the number of recovered SIFT key points and their accuracy.
</details>
<details>
<summary>摘要</summary>
雨斑streaks会导致图像像素强度变化和附加的梯度，大大阻碍图像特征的提取，从背景中。这会导致图像特征提取性能下降，影响后续的特征基应用程序。因此，需要从雨斑图像中除掉雨斑，以 recover图像特征。现在，许多出色的图像抽取方法已经取得了很大的进步。然而，这些人视系统驱动的方法主要关注图像质量的提高，并忽略了如何提高图像特征提取能力。为解决这个问题，我们提出了一种任务驱动的图像抽取算法，以强化图像特征供应。由于扫描不变的特征 transform (SIFT) 的广泛使用和强大实用性，我们首先提出了两个分开的网络，使用不同的损失和模块来实现两个目标。一个是漫波pyramid recovery network (DPRNet)，用于SIFT检测；另一个是梯度图像回归网络 (GGIRNet)，用于SIFT描述。其次，在 DPRNet 中，我们提出了一种alternative interest point损失，直接负担纬度响应极值来恢复漫波pyramid。再者，在 GGIRNet 中，我们提出了一种梯度注意力模块，用于恢复梯度图像。最后，通过恢复漫波pyramid和梯度图像，我们可以重新获得SIFT关键点。这种分而治之的方法，通过设置不同的目标来提高SIFT检测和描述的稳定性。与现状级方法相比，我们的提出的算法在 recovered SIFT 关键点的数量和准确性方面得到了较好的实验成绩。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/eess.IV_2023_11_01/" data-id="cloh7tqqd01747b88d6d57d87" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/eess.SP_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T08:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/eess.SP_2023_11_01/">eess.SP - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Regularized-Shannon-sampling-formulas-related-to-the-special-affine-Fourier-transform"><a href="#Regularized-Shannon-sampling-formulas-related-to-the-special-affine-Fourier-transform" class="headerlink" title="Regularized Shannon sampling formulas related to the special affine Fourier transform"></a>Regularized Shannon sampling formulas related to the special affine Fourier transform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00610">http://arxiv.org/abs/2311.00610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frank Filbir, Manfred Tasche, Anna Veselovska</li>
<li>for: 这个论文描述了一种新的减少噪声的Шэн纳 sampling方法，related to the special affine Fourier transform (SAFT).</li>
<li>methods: 这种 sampling方法使用了本地化 sampling with special compactly supported window functions，namely B-spline, sinh-type, and continuous Kaiser-Bessel window functions.</li>
<li>results: 这种 sampling方法在噪声存在的情况下具有数值稳定性，并且有较快的减少噪声误差的特性。数值实验证明了理论结论。<details>
<summary>Abstract</summary>
In this paper, we present new regularized Shannon sampling formulas related to the special affine Fourier transform (SAFT). These sampling formulas use localized sampling with special compactly supported window functions, namely B-spline, sinh-type, and continuous Kaiser-Bessel window functions. In contrast to the Shannon sampling series for SAFT, the regularized Shannon sampling formulas for SAFT possesses an exponential decay of the approximation error and are numerically robust in the presence of noise, if certain oversampling condition is fulfilled. Several numerical experiments illustrate the theoretical results.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了新的减少样本的Shannon样本方程，与特殊低维幂transform (SAFT)相关。这些样本方程使用本地样本，使用特殊的紧凑支持窗函数，包括B-spline、sinh-type和连续凯ser-Bessel窗函数。与Shannon样本系列相比，减少样本的Shannon样本方程具有快速衰减的错误近似值，并在噪声存在时是数值稳定的，只要满足某种过样量条件。我们在 numerics 中进行了一些实验，以证明理论结果。
</details></li>
</ul>
<hr>
<h2 id="A-Leakage-based-Method-for-Mitigation-of-Faulty-Reconfigurable-Intelligent-Surfaces"><a href="#A-Leakage-based-Method-for-Mitigation-of-Faulty-Reconfigurable-Intelligent-Surfaces" class="headerlink" title="A Leakage-based Method for Mitigation of Faulty Reconfigurable Intelligent Surfaces"></a>A Leakage-based Method for Mitigation of Faulty Reconfigurable Intelligent Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00527">http://arxiv.org/abs/2311.00527</a></li>
<li>repo_url: None</li>
<li>paper_authors: N. Moghadas Gholian, M. Rossanese, P. Mursia, A. Garcia-Saavedra, A. Asadi, V. Sciancalepore, X. Costa-Pérez</li>
<li>for: This paper aims to address the issue of undesired signal scattering in reconfigurable intelligent surfaces (RISs) and propose two simple yet effective algorithms to mitigate the problem.</li>
<li>methods: The proposed algorithms are based on maximizing the Signal-to-Leakage-and-Noise-Ratio (SLNR) over a predefined two-dimensional (2D) area and are applicable in the case of perfect channel-state-information (CSI) and partial CSI.</li>
<li>results: Numerical and full-wave simulations demonstrate the added gains compared to leakage-unaware and reference schemes.<details>
<summary>Abstract</summary>
Reconfigurable Intelligent Surfaces (RISs) are expected to be massively deployed in future beyond-5th generation wireless networks, thanks to their ability to programmatically alter the propagation environment, inherent low-cost and low-maintenance nature. Indeed, they are envisioned to be implemented on the facades of buildings or on moving objects. However, such an innovative characteristic may potentially turn into an involuntary negative behavior that needs to be addressed: an undesired signal scattering. In particular, RIS elements may be prone to experience failures due to lack of proper maintenance or external environmental factors. While the resulting Signal-to-Noise-Ratio (SNR) at the intended User Equipment (UE) may not be significantly degraded, we demonstrate the potential risks in terms of unwanted spreading of the transmit signal to non-intended UE. In this regard, we consider the problem of mitigating such undesired effect by proposing two simple yet effective algorithms, which are based on maximizing the Signal-to-Leakage- and-Noise-Ratio (SLNR) over a predefined two-dimensional (2D) area and are applicable in the case of perfect channel-state-information (CSI) and partial CSI, respectively. Numerical and full-wave simulations demonstrate the added gains compared to leakage-unaware and reference schemes.
</details>
<details>
<summary>摘要</summary>
Reconfigurable Intelligent Surfaces (RISs) 将在未来 fifth generation 无线网络中大规模部署，因为它们可以通过程序改变媒体传播环境，具有低成本和低维护特点。实际上，它们可能会被实现在建筑物的外墙或在移动 объекts上。然而，这种创新特点可能会转化为不良的无意义行为：不良信号散射。特别是，RIS 元素可能因为缺乏正确维护或外部环境因素而导致故障。尽管在意图用户设备（UE）中的信号至量比（SNR）不会受到显著的降低，但我们表明了这种风险的可能性，即传输信号无意中扩散到非意图 UE。在这种情况下，我们考虑了遏制这种不良影响的问题，并提出了两种简单 yet 有效的算法，它们基于在预定的二维（2D）区域上 maximizing 信号干扰比（SLNR），并在完美通道状态信息（CSI）和部分 CSI 情况下都适用。数值和全波 simulations 表明了与泄漏无AW 和参考方案相比的加大。
</details></li>
</ul>
<hr>
<h2 id="Generating-HSR-Bogie-Vibration-Signals-via-Pulse-Voltage-Guided-Conditional-Diffusion-Model"><a href="#Generating-HSR-Bogie-Vibration-Signals-via-Pulse-Voltage-Guided-Conditional-Diffusion-Model" class="headerlink" title="Generating HSR Bogie Vibration Signals via Pulse Voltage-Guided Conditional Diffusion Model"></a>Generating HSR Bogie Vibration Signals via Pulse Voltage-Guided Conditional Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00496">http://arxiv.org/abs/2311.00496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Liu, Jinglong Chen, Jingsong Xie, Yuanhong Chang</li>
<li>For:  This paper aims to improve the fault diagnosis of high-speed rail (HSR) bogies using Generative Adversarial Networks (GANs) and a novel Pulse Voltage-Guided Conditional Diffusion Model (VGCDM).* Methods: The VGCDM uses a sequential U-Net architecture and incorporates control pulse voltage through a cross-attention mechanism to ensure alignment of vibration with voltage signals, resulting in improved training stability and progressive controllability.* Results: The proposed VGCDM outperforms other generative models in terms of RSME, PSNR, and FSCS, demonstrating its superiority in conditional HSR bogie vibration signal generation. The code is available at <a target="_blank" rel="noopener" href="https://github.com/xuanliu2000/VGCDM.Here's">https://github.com/xuanliu2000/VGCDM.Here&#39;s</a> the simplified Chinese text:* For: 这篇论文目的是使用生成对抗网络（GANs）和一种新的推导幂量电压导向模型（VGCDM）来提高高速铁路（HSR）车厢的故障诊断。* Methods: VGCDM使用了一种继承网络架构，并通过十字关注机制来确保振荡与电压信号的Alignment，从而提高了训练稳定性和进程可控性。* Results: 提出的VGCDM在RSME、PSNR和FSCS等指标上表现出色，证明其在条件HSR车厢振荡信号生成中的优越性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/xuanliu2000/VGCDM%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/xuanliu2000/VGCDM中下载。</a><details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) for producing realistic signals, have substantially improved fault diagnosis algorithms in various Internet of Things (IoT) systems. However, challenges such as training instability and dynamical inaccuracy limit their utility in high-speed rail (HSR) bogie fault diagnosis. To address these challenges, we introduce the Pulse Voltage-Guided Conditional Diffusion Model (VGCDM). Unlike traditional implicit GANs, VGCDM adopts a sequential U-Net architecture, facilitating multi-phase denoising diffusion for generation, which bolsters training stability and mitigate convergence issues. VGCDM also incorporates control pulse voltage by cross-attention mechanism to ensure the alignment of vibration with voltage signals, enhancing the Conditional Diffusion Model's progressive controlablity. Consequently, solely straightforward sampling of control voltages, ensuring the efficient transformation from Gaussian Noise to vibration signals. This adaptability remains robust even in scenarios with time-varying speeds. To validate the effectiveness, we conducted two case studies using SQ dataset and high-simulation HSR bogie dataset. The results of our experiments unequivocally confirm that VGCDM outperforms other generative models, achieving the best RSME, PSNR, and FSCS, showing its superiority in conditional HSR bogie vibration signal generation. For access, our code is available at https://github.com/xuanliu2000/VGCDM.
</details>
<details>
<summary>摘要</summary>
依据我们的研究，生成拟真信号的生成敌对网络（GANs）在多种互联网络（IoT）系统中有了显著改进。然而，在高速铁路（HSR）车底FAULT诊断中，问题如训练不稳定和动态不准确限制了它们的应用。为解决这些问题，我们介绍了普ulse压力引导的条件扩散模型（VGCDM）。与传统的隐式GANs不同，VGCDM采用了序列U-Net架构，实现多阶段干扰扩散生成，从而提高训练稳定性和解决异常问题。VGCDM还通过cross-attention机制控制普ulse压力，以确保震动与压力信号的对应，提高条件扩散模型的进行控制性。因此，只需简单地采样控制电压，使得效率地从 Gaussian Noise 转换到震动信号。这种适应性能够在时间变化的情况下保持稳定。为验证效果，我们在SQ数据集和高度仿真HSR车底数据集上进行了两个案例研究。结果表明，VGCDM明显超过了其他生成模型，实现最佳RSME、PSNR和FSCS指标，证明其在条件HSR车底震动信号生成中的优越性。具体代码可以在 GitHub 上找到：https://github.com/xuanliu2000/VGCDM。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Surface-Empowered-Integrated-Sensing-and-Communication-From-Coexistence-to-Reciprocity"><a href="#Intelligent-Surface-Empowered-Integrated-Sensing-and-Communication-From-Coexistence-to-Reciprocity" class="headerlink" title="Intelligent Surface Empowered Integrated Sensing and Communication: From Coexistence to Reciprocity"></a>Intelligent Surface Empowered Integrated Sensing and Communication: From Coexistence to Reciprocity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00418">http://arxiv.org/abs/2311.00418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaitao Meng, Qingqing Wu, Christos Masouros, Wen Chen, Deshi Li</li>
<li>for: 本文探讨了基于智能反射&#x2F;折射表面（IRS）的集成感知通信（ISAC）系统，以提高 sixth-generation（6G）及更高版本无线网络的效率。</li>
<li>methods: 本文介绍了IRS的基本特性和创新的感知体系结构，以及IRS渠道控制和部署优化的多种目标。</li>
<li>results: 本文 investigate了不同部署策略之间的干扰关系，并提出了一些推荐的IRS增强ISAC的可能性。<details>
<summary>Abstract</summary>
Integrated sensing and communication (ISAC) has attracted growing interests for sixth-generation (6G) and beyond wireless networks. The primary challenges faced by highly efficient ISAC include limited sensing and communication (S&C) coverage, constrained integration gain between S&C under weak channel correlations, and unknown performance boundary. Intelligent reflecting/refracting surfaces (IRSs) can effectively expand S&C coverage and control the degree of freedom of channels between the transmitters and receivers, thereby realizing increasing integration gains. In this work, we first delve into the fundamental characteristics of IRS-empowered ISAC and innovative IRS-assisted sensing architectures. Then, we discuss various objectives for IRS channel control and deployment optimization in ISAC systems. Furthermore, the interplay between S&C in different deployment strategies is investigated and some promising directions for IRS enhanced ISAC are outlined.
</details>
<details>
<summary>摘要</summary>
integrated sensing and communication (ISAC) 在 sixth-generation (6G) 和更高版本无线网络中吸引了越来越多的关注。主要挑战是高效的 ISAC 面临的限制的感知和通信 (S&C) 覆盖率、弱通道相关性下的集成增益的限制，以及未知的性能边界。智能镜像/弯光面 (IRS) 可以有效地扩大 S&C 覆盖率并控制传输器和接收器之间通道的自由度，从而实现更高的集成增益。在这种工作中，我们首先探讨了 ISAC 的基本特点和创新的 IRS 感知架构。然后，我们讨论了 ISAC 系统中 IRS 通道控制和部署优化的各种目标。此外，我们还 investigate了 ISAC 不同部署策略中的 S&C 相互作用，并提出了一些有前途的 IRS 增强 ISAC 的方向。
</details></li>
</ul>
<hr>
<h2 id="Deriving-Characteristic-Mode-Eigenvalue-Behavior-Using-Subduction-of-Group-Representations"><a href="#Deriving-Characteristic-Mode-Eigenvalue-Behavior-Using-Subduction-of-Group-Representations" class="headerlink" title="Deriving Characteristic Mode Eigenvalue Behavior Using Subduction of Group Representations"></a>Deriving Characteristic Mode Eigenvalue Behavior Using Subduction of Group Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00365">http://arxiv.org/abs/2311.00365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Grundmann, Lukas Warkentin, Dirk Manteuffel</li>
<li>for: 本文提出了一种方法，用于从已知和理解的解题方法中 derivate 模态 eigenvalues 轨迹的特征。这种方法基于点群理论中的拟合理论，以获取目标结构的Symmetry 性质。这种方法在圆柱体的特征模式中进行了应用，并 derive 了一个箱形天线的 eigenvalue 行为。</li>
<li>methods: 本文使用了点群理论中的拟合理论，以获取目标结构的Symmetry 性质。这种方法还使用了 crossing eigenvalue traces 的分裂，以避免在三维结构上出现的凹槽。</li>
<li>results: 本文的研究结果表明，通过使用点群理论中的拟合理论和 crossing eigenvalue traces 的分裂，可以 derivate 模态 eigenvalues 轨迹的特征。这些特征可以用于解释三维结构上出现的凹槽。此外，本文还提出了一种基于这种方法的示例天线设计，以避免输入匹配和远场幂的不良影响。<details>
<summary>Abstract</summary>
A method to derive features of modal eigenvalue traces from known and understood solutions is proposed. It utilizes the concept of subduction from point group theory to obtain the symmetry properties of a target structure from those of a structure with a higher order of symmetry. This is applied exemplary to the analytically known characteristic modes (CMs) of the spherical shell. The eigenvalue behavior of a cube in free space and a cuboid on a perfectly electrically conducting plane are continuously derived from this. In this process, formerly crossing eigenvalue traces are found to split up, forming a split trace crossing avoidance (STCA). This finding is used to explain indentations in eigenvalue traces observed for three-dimensional structures, that are of increasing interest in recent literature. The utility of this knowledge is exemplified through a demonstrator antenna design. The dimensions of the antenna structure are chosen so the STCA is outside the target frequency range, avoiding negative impacts on input matching and the frequency stability of the far field patterns.
</details>
<details>
<summary>摘要</summary>
方法提出用已知和理解的解方法 Derive 模式值轨迹的特征。它利用点群论中的投射理论来获取目标结构的对称性质。这被应用于已知的圆柱形shell的特征模式（CM）。通过这种方法，在自由空间中的立方体和在完美电阻平面上的立方体块的 eigenvalues 的行为被连续地 derive。在这个过程中， formerly crossing eigenvalue traces 被发现分裂，形成 split trace crossing avoidance (STCA)。这一发现用于解释三维结构中观察到的 indentations 的原因。这种知识的实用性被通过一个示例天线设计证明，天线结构的尺寸被选择以确保 STCA 在目标频率范围内，以避免输入匹配和远场图像的频率稳定性的负面影响。
</details></li>
</ul>
<hr>
<h2 id="On-the-Semi-Blind-Mutually-Referenced-Equalizers-for-MIMO-Systems"><a href="#On-the-Semi-Blind-Mutually-Referenced-Equalizers-for-MIMO-Systems" class="headerlink" title="On the Semi-Blind Mutually Referenced Equalizers for MIMO Systems"></a>On the Semi-Blind Mutually Referenced Equalizers for MIMO Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00325">http://arxiv.org/abs/2311.00325</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DoHaiSon/Semi-blind_Mutually_Referenced_Equalizers">https://github.com/DoHaiSon/Semi-blind_Mutually_Referenced_Equalizers</a></li>
<li>paper_authors: Do Hai Son, Karim Abed-Meraim, Tran Trong Duy, Nguyen Linh Trung, Tran Thi Thuy Quynh</li>
<li>for: 提高无线通信系统中通道估计的训练负担减少</li>
<li>methods: 提出了一种基于传统盲目算法的扩展，称为“相互参照平衡器”（Mutually referenced equalizers，MRE），特意设计 для MIMO系统。此外，我们还提出了一种新的半盲目方法，SB-MRE，这种方法结合了预设Symbols的优点和MRE方法的优点，以实现更高的性能，同时减少训练负担和盲目处理中的困惑。</li>
<li>results: 实验结果表明，SB-MRE方法在训练负担和复杂性方面比其他线性算法，如MMSE、ZF和MRE算法，表现更好，从而提供了一种有前途的解决方案，以iminize training overhead in channel estimation for wireless communication systems。<details>
<summary>Abstract</summary>
Minimizing training overhead in channel estimation is a crucial challenge in wireless communication systems. This paper presents an extension of the traditional blind algorithm, called "Mutually referenced equalizers" (MRE), specifically designed for MIMO systems. Additionally, we propose a novel semi-blind method, SB-MRE, which combines the benefits of pilot-based and MRE approaches to achieve enhanced performance while utilizing a reduced number of pilot symbols. Moreover, the SB-MRE algorithm helps to minimize complexity and training overhead and to remove the ambiguities inherent to blind processing. The simulation results demonstrated that SB-MRE outperforms other linear algorithms, i.e., MMSE, ZF, and MRE, in terms of training overhead symbols and complexity, thereby offering a promising solution to address the challenge of minimizing training overhead in channel estimation for wireless communication systems.
</details>
<details>
<summary>摘要</summary>
减少无线通信系统中的训练负担是一个重要挑战。这篇论文提出了一种基于传统的盲目算法的扩展，名为“相互参照的平衡器”（Mutually Referenced Equalizers，MRE），专门设计 для MIMO系统。此外，我们还提议了一种新的半盲目方法，SB-MRE，该方法结合了预设 Symbol 的优点和 MRE 方法的优点，以实现更高的性能，同时减少了训练负担和盲目处理中的歧义。实验结果表明，SB-MRE 方法在训练负担符和复杂性方面都比 MMSE、ZF 和 MRE 等线性算法表现更好，因此可以作为解决无线通信系统中训练负担减少的一个有优解决方案。
</details></li>
</ul>
<hr>
<h2 id="Improving-MIMO-channel-estimation-via-receive-power-feedback"><a href="#Improving-MIMO-channel-estimation-via-receive-power-feedback" class="headerlink" title="Improving MIMO channel estimation via receive power feedback"></a>Improving MIMO channel estimation via receive power feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00225">http://arxiv.org/abs/2311.00225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Zhang, Hang Zou, Samson Lasaulce, Lucas Saludjian</li>
<li>for: 提高无线网络中通道状态估计精度</li>
<li>methods: 利用所有可用信息提高通道估计精度</li>
<li>results: 使用相应的MMSE估计器始终有利，而MAP估计器的有用性取决于操作SNR。Here’s a breakdown of each line:* “for”: This line indicates the purpose or goal of the paper. In this case, the paper aims to improve channel estimation accuracy in wireless networks.* “methods”: This line lists the methods used in the paper to achieve the goal. In this case, the paper uses classical estimation tools to exploit all available information to improve channel estimation accuracy.* “results”: This line summarizes the main findings or results of the paper. In this case, the paper shows that using the corresponding MMSE estimator is always beneficial, while the relevance of using the MAP estimator depends on the operating SNR.<details>
<summary>Abstract</summary>
Estimating the channel state is known to be an important problem in wireless networks. To this end, it matters to exploit all the available information to improve channel estimation accuracy as much as possible. It turns out that the problem of exploiting the information associated with the receive power feedback (e.g., the received signal strength indicator -RSSI-) has not been identified and solved; in this setup, the transmitter is assumed to receive feedback from all the receivers in presence. As shown in this paper, to solve this problem, classical estimation tools can be used. Using the corresponding MMSE is shown to be always beneficial, whereas the relevance of using the MAP estimator would depend on the operating SNR.
</details>
<details>
<summary>摘要</summary>
<<sys: language="zh-CN">无线网络中估算通道状态是一个重要问题。为此，您需要利用所有可用信息来提高通道估算精度。尽管在这种情况下，收发器向所有接收器发送反馈信息的问题尚未得到解决，但是这paper中示出了使用经典估算工具来解决这个问题。使用相应的MMSE可以提高估算精度，而使用MAP估算器的有用性取决于操作的SNR。</sys>>Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/eess.SP_2023_11_01/" data-id="cloh7tqrq01an7b888hin7c6q" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_10_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/31/cs.SD_2023_10_31/" class="article-date">
  <time datetime="2023-10-31T15:00:00.000Z" itemprop="datePublished">2023-10-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/31/cs.SD_2023_10_31/">cs.SD - 2023-10-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Study-of-speaker-localization-with-binaural-microphone-array-incorporating-auditory-filters-and-lateral-angle-estimation"><a href="#Study-of-speaker-localization-with-binaural-microphone-array-incorporating-auditory-filters-and-lateral-angle-estimation" class="headerlink" title="Study of speaker localization with binaural microphone array incorporating auditory filters and lateral angle estimation"></a>Study of speaker localization with binaural microphone array incorporating auditory filters and lateral angle estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20238">http://arxiv.org/abs/2310.20238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanir Maymon, Israel Nelken, Boaz Rafaely</li>
<li>for: 这paper主要针对 speech communication、video conferencing 和机器人听说等应用中的 Speaker localization for binaural microphone arrays。</li>
<li>methods: 该paper提出了一些新的处理阶段，包括使用快速 Fourier transform (STFT) 和基于 Head-related transfer function (HRTF) 的方向来源搜索。</li>
<li>results:  simulation study 和实验study 表明，提出的方法与现有方法相比，在 Speaker localization  task 中表现更好。<details>
<summary>Abstract</summary>
Speaker localization for binaural microphone arrays has been widely studied for applications such as speech communication, video conferencing, and robot audition. Many methods developed for this task, including the direct path dominance (DPD) test, share common stages in their processing, which include transformation using the short-time Fourier transform (STFT), and a direction of arrival (DOA) search that is based on the head related transfer function (HRTF) set. In this paper, alternatives to these processing stages, motivated by human hearing, are proposed. These include incorporating an auditory filter bank to replace the STFT, and a new DOA search based on transformed HRTF as steering vectors. A simulation study and an experimental study are conducted to validate the proposed alternatives, and both are applied to two binaural DOA estimation methods; the results show that the proposed method compares favorably with current methods.
</details>
<details>
<summary>摘要</summary>
声道定位 для双耳麦克铺array已经广泛研究了，用于应用如语音通信、视频会议和机器人听觉。许多用于这项任务的方法，包括直接路径主导（DPD）测试，都有共同的处理阶段，包括使用短时傅立叙Transform（STFT）变换，以及基于头相关传输函数（HRTF）集的方向到来（DOA）搜索。在这篇论文中，提出了基于人类听觉的 altenativas，包括将auditory filter bank取代STFT，以及基于转换HRTF的新DOA搜索。一个 simulations study和一个实验study进行了验证，并对两种双耳DOA估计方法进行了应用，结果表明，提出的方法与现有方法相比，具有竞争力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/31/cs.SD_2023_10_31/" data-id="cloh7tqmp00xb7b881vf090gz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_10_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/31/cs.CV_2023_10_31/" class="article-date">
  <time datetime="2023-10-31T13:00:00.000Z" itemprop="datePublished">2023-10-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/31/cs.CV_2023_10_31/">cs.CV - 2023-10-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Decodable-and-Sample-Invariant-Continuous-Object-Encoder"><a href="#Decodable-and-Sample-Invariant-Continuous-Object-Encoder" class="headerlink" title="Decodable and Sample Invariant Continuous Object Encoder"></a>Decodable and Sample Invariant Continuous Object Encoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00187">http://arxiv.org/abs/2311.00187</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dhyuan99/hdfe">https://github.com/dhyuan99/hdfe</a></li>
<li>paper_authors: Dehao Yuan, Furong Huang, Cornelia Fermüller, Yiannis Aloimonos</li>
<li>for: 这篇论文旨在提出一种具有sample distribution和density不变性的连续对象编码方法（Hyper-Dimensional Function Encoding，HDFE），以便在机器学习任务中接受连续对象作为输入。</li>
<li>methods: HDFE使用样本分布和浓度不变性来生成连续对象的显式向量表示，并不需要任何训练。这种编码方法可以将连续对象映射到有组织结构的嵌入空间中，并且可以回归连续对象的编码。</li>
<li>results: 在函数到函数映射任务中，使用HDFE可以 achieve competitive performance 与现状之最佳算法。在点云表面法向量估计任务中，将PointNet替换为HDFE，可以直接得到12%和15%的错误降低。此外，将HDFEintegrated into PointNet-based SOTA网络中，可以提高SOTA基eline的2.5%和1.7%。<details>
<summary>Abstract</summary>
We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a continuous object (e.g. a function), HDFE produces an explicit vector representation of the given object, invariant to the sample distribution and density. Sample distribution and density invariance enables HDFE to consistently encode continuous objects regardless of their sampling, and therefore allows neural networks to receive continuous objects as inputs for machine learning tasks, such as classification and regression. Besides, HDFE does not require any training and is proved to map the object into an organized embedding space, which facilitates the training of the downstream tasks. In addition, the encoding is decodable, which enables neural networks to regress continuous objects by regressing their encodings. Therefore, HDFE serves as an interface for processing continuous objects.   We apply HDFE to function-to-function mapping, where vanilla HDFE achieves competitive performance as the state-of-the-art algorithm. We apply HDFE to point cloud surface normal estimation, where a simple replacement from PointNet to HDFE leads to immediate 12% and 15% error reductions in two benchmarks. In addition, by integrating HDFE into the PointNet-based SOTA network, we improve the SOTA baseline by 2.5% and 1.7% in the same benchmarks.
</details>
<details>
<summary>摘要</summary>
我们提出嵌套维度函数编码（HDFE）。对于连续变数（例如函数）的样本，HDFE 可以生成对应的维度函数表示，不受样本分布和密度的影响。这使得 HDFE 可以对连续变数进行一致性的编码，允许神经网络接受连续变数作为输入进行机器学习任务，如分类和回归。此外，HDFE 不需要任何训练，并证明可以将物件转换到有序的嵌入空间中，便于训练下游任务。此外，编码也是解码的，允许神经网络通过解码来回传连续变数。因此，HDFE 可以作为连续变数的接口。我们将 HDFE 应用于函数转换，其中普通的 HDFE 已经达到了现有算法的竞争水平。我们还将 HDFE 应用于点云表面弹性估计，将 PointNet 替换为 HDFE，即时间降低了两个benchmark中的12%和15%的错误率。此外，将 HDFE 统合到 PointNet-based SOTA 网络中，可以提高 SOTA 基eline的2.5%和1.7%。
</details></li>
</ul>
<hr>
<h2 id="Image-Restoration-with-Point-Spread-Function-Regularization-and-Active-Learning"><a href="#Image-Restoration-with-Point-Spread-Function-Regularization-and-Active-Learning" class="headerlink" title="Image Restoration with Point Spread Function Regularization and Active Learning"></a>Image Restoration with Point Spread Function Regularization and Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00186">http://arxiv.org/abs/2311.00186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Jia, Jiameng Lv, Runyu Ning, Yu Song, Nan Li, Kaifan Ji, Chenzhou Cui, Shanshan Li</li>
<li>for: 这个论文是为了提高天文学观测图像的精度和效率，使用深度学习算法和高精度望远镜模拟器连接。</li>
<li>methods: 该算法使用深度学习算法和高精度望远镜模拟器连接，在训练阶段使用模拟器生成不同水平的噪声和杂散来训练神经网络，然后直接使用神经网络来修复天文学观测图像。</li>
<li>results: 该算法可以有效地提高天文学观测图像中的细结构，提高观测图像的质量，并可以应用于大规模天文学观测数据，如LSST、Euclid和CSST等。<details>
<summary>Abstract</summary>
Large-scale astronomical surveys can capture numerous images of celestial objects, including galaxies and nebulae. Analysing and processing these images can reveal intricate internal structures of these objects, allowing researchers to conduct comprehensive studies on their morphology, evolution, and physical properties. However, varying noise levels and point spread functions can hamper the accuracy and efficiency of information extraction from these images. To mitigate these effects, we propose a novel image restoration algorithm that connects a deep learning-based restoration algorithm with a high-fidelity telescope simulator. During the training stage, the simulator generates images with different levels of blur and noise to train the neural network based on the quality of restored images. After training, the neural network can directly restore images obtained by the telescope, as represented by the simulator. We have tested the algorithm using real and simulated observation data and have found that it effectively enhances fine structures in blurry images and increases the quality of observation images. This algorithm can be applied to large-scale sky survey data, such as data obtained by LSST, Euclid, and CSST, to further improve the accuracy and efficiency of information extraction, promoting advances in the field of astronomical research.
</details>
<details>
<summary>摘要</summary>
大规模天文观测可以捕捉众多的天体图像，包括星系和星云。分析和处理这些图像可以揭示天体的内部结构，帮助研究人员进行全面的 morphology、演化和物理性质的研究。然而，天文图像中的噪声和点扩散函数可能会增加图像信息提取的准确性和效率问题。为了解决这些问题，我们提议一种新的图像修复算法，该算法将深度学习基于的修复算法与高精度望远镜模拟器相连接。在训练阶段，模拟器生成了不同噪声和扩散函数的图像，以训练基于图像质量的 neural network。之后，这个 neural network 可以直接修复望远镜获得的图像，如由模拟器表示的。我们对实际和模拟观测数据进行测试，发现该算法可以有效地提高模糊图像中的细节，提高观测图像的质量。这种算法可以应用于大规模天文观测数据，如 LSST、Euclid 和 CSST 等，以提高信息提取的准确性和效率，推动天文研究领域的进步。
</details></li>
</ul>
<hr>
<h2 id="Object-centric-Video-Representation-for-Long-term-Action-Anticipation"><a href="#Object-centric-Video-Representation-for-Long-term-Action-Anticipation" class="headerlink" title="Object-centric Video Representation for Long-term Action Anticipation"></a>Object-centric Video Representation for Long-term Action Anticipation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00180">http://arxiv.org/abs/2311.00180</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/brown-palm/objectprompt">https://github.com/brown-palm/objectprompt</a></li>
<li>paper_authors: Ce Zhang, Changcheng Fu, Shijie Wang, Nakul Agarwal, Kwonjoon Lee, Chiho Choi, Chen Sun</li>
<li>for: 这paper的目的是建立长期行为预测视频中对象中心表示，以便更好地识别和预测人类-物品交互。</li>
<li>methods: 该paper使用了可见语言预测模型，并提出了“对象提示”方法，以EXTRACT task-specific对象中心表示。它还使用了一种基于Transformer的神经网络，以便在不同的时间尺度内“检索”有关的对象。</li>
<li>results: 该paper的结果表明，使用该方法可以有效地识别和预测人类-物品交互。EXTENSIVE evaluations on Ego4D, 50Salads, and EGTEA Gaze+ benchmarks confirm the effectiveness of the proposed method.<details>
<summary>Abstract</summary>
This paper focuses on building object-centric representations for long-term action anticipation in videos. Our key motivation is that objects provide important cues to recognize and predict human-object interactions, especially when the predictions are longer term, as an observed "background" object could be used by the human actor in the future. We observe that existing object-based video recognition frameworks either assume the existence of in-domain supervised object detectors or follow a fully weakly-supervised pipeline to infer object locations from action labels. We propose to build object-centric video representations by leveraging visual-language pretrained models. This is achieved by "object prompts", an approach to extract task-specific object-centric representations from general-purpose pretrained models without finetuning. To recognize and predict human-object interactions, we use a Transformer-based neural architecture which allows the "retrieval" of relevant objects for action anticipation at various time scales. We conduct extensive evaluations on the Ego4D, 50Salads, and EGTEA Gaze+ benchmarks. Both quantitative and qualitative results confirm the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "object-centric" is translated as "物体中心的" (wùtǐ zhōngxīn de), which emphasizes the focus on objects in the representation.* "long-term" is translated as "长期的" (chángqī de), which emphasizes the duration of the predictions.* "human-object interactions" is translated as "人物交互" (rénwù jiāoxì), which emphasizes the interactions between humans and objects.* "infer" is translated as "推断" (tuīdàn), which emphasizes the process of making predictions based on the available information.* "object prompts" is translated as "对象提示" (duìyè tiēshí), which emphasizes the use of object cues to extract task-specific representations.* "retrieval" is translated as "检索" (jiǎnsuǒ), which emphasizes the process of retrieving relevant objects for action anticipation.* "quantitative" and "qualitative" are translated as "数量的" (shùliàng de) and "质量的" (zhìliàng de), respectively, which emphasize the different aspects of the results.
</details></li>
</ul>
<hr>
<h2 id="Multi-task-Deep-Convolutional-Network-to-Predict-Sea-Ice-Concentration-and-Drift-in-the-Arctic-Ocean"><a href="#Multi-task-Deep-Convolutional-Network-to-Predict-Sea-Ice-Concentration-and-Drift-in-the-Arctic-Ocean" class="headerlink" title="Multi-task Deep Convolutional Network to Predict Sea Ice Concentration and Drift in the Arctic Ocean"></a>Multi-task Deep Convolutional Network to Predict Sea Ice Concentration and Drift in the Arctic Ocean</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00167">http://arxiv.org/abs/2311.00167</a></li>
<li>repo_url: None</li>
<li>paper_authors: Younghyun Koo, Maryam Rahnemoonfar</li>
<li>for: 预测北极海洋中的海冰 koncentración (SIC) 和海冰移动 (SID) 的研究对于了解当前气候变化的影响非常重要。</li>
<li>methods: 本研究提出了一种新的多任务彻底学习网络架构，即层次信息共享U-net (HIS-Unet)，用于每天预测 SIC 和 SID。该架构不同于单独将 SIC 和 SID 分别学习为每个分支，而是通过加权注意模块 (WAMs) 来让 SIC 和 SID 层共享信息，以提高预测性能。</li>
<li>results: 对比其他统计方法、物理海冰模型和神经网络，HIS-Unet 显著提高了 SIC 和 SID 预测性能。具体来说，HIS-Unet 在seasonal sea ice 和 multi-year sea ice 的变化季节中的预测性能都显著提高，这表明信息共享通过 WAMs 允许模型学习海冰的突然变化。此外，WAMs 的权值表明，SIC 信息在 SID 预测中扮演更重要的角色，而 SID 信息在 SIC 预测中的作用相对较弱。同时，信息共享在海冰边缘（seasonal sea ice）更为活跃。<details>
<summary>Abstract</summary>
Forecasting sea ice concentration (SIC) and sea ice drift (SID) in the Arctic Ocean is of great significance as the Arctic environment has been changed by the recent warming climate. Given that physical sea ice models require high computational costs with complex parameterization, deep learning techniques can effectively replace the physical model and improve the performance of sea ice prediction. This study proposes a novel multi-task fully conventional network architecture named hierarchical information-sharing U-net (HIS-Unet) to predict daily SIC and SID. Instead of learning SIC and SID separately at each branch, we allow the SIC and SID layers to share their information and assist each other's prediction through the weighting attention modules (WAMs). Consequently, our HIS-Unet outperforms other statistical approaches, sea ice physical models, and neural networks without such information-sharing units. The improvement of HIS-Unet is obvious both for SIC and SID prediction when and where sea ice conditions change seasonally, which implies that the information sharing through WAMs allows the model to learn the sudden changes of SIC and SID. The weight values of the WAMs imply that SIC information plays a more critical role in SID prediction, compared to that of SID information in SIC prediction, and information sharing is more active in sea ice edges (seasonal sea ice) than in the central Arctic (multi-year sea ice).
</details>
<details>
<summary>摘要</summary>
预测北极海洋中的海冰浓度（SIC）和海冰移动（SID）具有重要的意义，因为北极环境已经由最近的气候变化所改变。由于物理海冰模型需要高度的计算成本和复杂的参数化，深度学习技术可以有效地取代物理模型，提高海冰预测性能。本研究提出了一种新的多任务完全конволюцион网络架构，即层次信息共享U-Net（HIS-Unet），用于每天预测SIC和SID。而不是在每个分支中分别学习SIC和SID，我们允许SIC和SID层共享信息，通过权重注意模块（WAMs）帮助对方预测。因此，我们的HIS-Unet比其他统计方法、海冰物理模型和无此信息共享单元的神经网络更高效。HIS-Unet的改进显著 both SIC和SID预测，特别是在季节性变化的海冰条件下，这表明信息共享 через WAMs 让模型学习海冰的突然变化。WAMs 的权值表明，SIC 信息在 SID 预测中扮演更重要的角色，而 SID 信息在 SIC 预测中的作用相对较弱，信息共享更活跃在海冰边缘（季节性海冰）than in the central Arctic（多年海冰）。
</details></li>
</ul>
<hr>
<h2 id="Medi-CAT-Contrastive-Adversarial-Training-for-Medical-Image-Classification"><a href="#Medi-CAT-Contrastive-Adversarial-Training-for-Medical-Image-Classification" class="headerlink" title="Medi-CAT: Contrastive Adversarial Training for Medical Image Classification"></a>Medi-CAT: Contrastive Adversarial Training for Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00154">http://arxiv.org/abs/2311.00154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pervaiz Iqbal Khan, Andreas Dengel, Sheraz Ahmed<br>for: This paper aims to overcome the underfitting and overfitting phenomena in medical imaging datasets by proposing a training strategy called Medi-CAT.methods: The proposed training methodology employs large pre-trained vision transformers and combines adversarial and contrastive learning techniques to prevent overfitting.results: The proposed approach improves the accuracy up to 2% on three benchmark datasets compared to well-known approaches, and increases the performance up to 4.1% over the baseline methods.Here’s the Chinese translation of the information:for: 这篇论文目标是解决医疗影像Dataset中的下降和过拟合现象，提出了一种名为 Medi-CAT的训练策略。methods: 提议的训练方法使用大量预训练的视觉变换器，并结合对抗学习和对比学习技术来避免过拟合。results: 该方法对三个标准数据集进行比较，与常见方法相比，准确率提高了2%，而与基线方法相比，性能提高了4.1%。<details>
<summary>Abstract</summary>
There are not many large medical image datasets available. For these datasets, too small deep learning models can't learn useful features, so they don't work well due to underfitting, and too big models tend to overfit the limited data. As a result, there is a compromise between the two issues. This paper proposes a training strategy Medi-CAT to overcome the underfitting and overfitting phenomena in medical imaging datasets. Specifically, the proposed training methodology employs large pre-trained vision transformers to overcome underfitting and adversarial and contrastive learning techniques to prevent overfitting. The proposed method is trained and evaluated on four medical image classification datasets from the MedMNIST collection. Our experimental results indicate that the proposed approach improves the accuracy up to 2% on three benchmark datasets compared to well-known approaches, whereas it increases the performance up to 4.1% over the baseline methods.
</details>
<details>
<summary>摘要</summary>
“医疗图像 dataset 规模较小，深度学习模型会因为数据有限而难以学习有用特征，导致过拟合和下降风险。为了解决这两个问题，这篇论文提出了一种协调训练策略 Medi-CAT。具体来说，提出的训练方法使用大型预训练视Transformer来抵消下降风险，并使用对抗和对比学习技术来避免过拟合。我们对 MedMNIST 收集中的四个医疗图像分类数据集进行训练和评估，实验结果表明，我们的方法可以与传统方法相比提高准确率，最高提高4.1%。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Joint-Depth-Prediction-and-Semantic-Segmentation-with-Multi-View-SAM"><a href="#Joint-Depth-Prediction-and-Semantic-Segmentation-with-Multi-View-SAM" class="headerlink" title="Joint Depth Prediction and Semantic Segmentation with Multi-View SAM"></a>Joint Depth Prediction and Semantic Segmentation with Multi-View SAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00134">http://arxiv.org/abs/2311.00134</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mykhailo Shvets, Dongxu Zhao, Marc Niethammer, Roni Sengupta, Alexander C. Berg</li>
<li>for: 这个论文是为了提出一种多视图雷达（MVS）技术，以利用 semantic features 进行深度预测和 segmentation 预测。</li>
<li>methods: 该论文使用了 Segment Anything Model (SAM) 提取 semantic features，并使用 Transformer 搅拌模型进行 semantic segmentation 预测。</li>
<li>results: 该论文在 ScanNet 数据集上进行了量化和质量研究，并表明其方法可以比单任务 MVS 和 segmentation 模型、以及多任务 monocular 方法表现更好。<details>
<summary>Abstract</summary>
Multi-task approaches to joint depth and segmentation prediction are well-studied for monocular images. Yet, predictions from a single-view are inherently limited, while multiple views are available in many robotics applications. On the other end of the spectrum, video-based and full 3D methods require numerous frames to perform reconstruction and segmentation. With this work we propose a Multi-View Stereo (MVS) technique for depth prediction that benefits from rich semantic features of the Segment Anything Model (SAM). This enhanced depth prediction, in turn, serves as a prompt to our Transformer-based semantic segmentation decoder. We report the mutual benefit that both tasks enjoy in our quantitative and qualitative studies on the ScanNet dataset. Our approach consistently outperforms single-task MVS and segmentation models, along with multi-task monocular methods.
</details>
<details>
<summary>摘要</summary>
多任务方法为单视图图像的深度预测和分割预测是已经广泛研究的。然而，单视图预测的预测是有限的，而多视图应用中有很多视图可用。另一方面，视频基于和全3D方法需要许多帧来进行重建和分割。在这种情况下，我们提出了一种基于多视图ステレオ（MVS）技术，利用rich的 semantic feature来提高深度预测。这种增强的深度预测，然后作为我们基于Transformer的semantic segmentation解码器的引导。我们在ScanNet数据集上进行了量化和质量研究，并发现我们的方法在单任务MVS和分类任务上都有明显的提高，同时与多任务单视图方法和semantic segmentation方法相比也有着良好的性能。
</details></li>
</ul>
<hr>
<h2 id="Spuriosity-Rankings-for-Free-A-Simple-Framework-for-Last-Layer-Retraining-Based-on-Object-Detection"><a href="#Spuriosity-Rankings-for-Free-A-Simple-Framework-for-Last-Layer-Retraining-Based-on-Object-Detection" class="headerlink" title="Spuriosity Rankings for Free: A Simple Framework for Last Layer Retraining Based on Object Detection"></a>Spuriosity Rankings for Free: A Simple Framework for Last Layer Retraining Based on Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00079">http://arxiv.org/abs/2311.00079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Azizmalayeri, Reza Abbasi, Amir Hosein Haji Mohammad rezaie, Reihaneh Zohrabi, Mahdi Amiri, Mohammad Taghi Manzuri, Mohammad Hossein Rohban</li>
<li>for: 该 paper 是为了解决深度神经网络模型中的假样特征问题而写的。</li>
<li>methods: 该 paper 使用了一种开 vocabulary 对象检测技术来评估图像中的目标对象存在程度，然后根据这个分数对图像进行排序，并将最后一层模型 retrained 在排序后的数据上。</li>
<li>results: 该 paper 的实验结果表明，该排序 frameworks 可以准确地排序图像按照假样程度，并且可以使用这些图像进行 last-layer retraining，从而提高模型的可靠性。<details>
<summary>Abstract</summary>
Deep neural networks have exhibited remarkable performance in various domains. However, the reliance of these models on spurious features has raised concerns about their reliability. A promising solution to this problem is last-layer retraining, which involves retraining the linear classifier head on a small subset of data without spurious cues. Nevertheless, selecting this subset requires human supervision, which reduces its scalability. Moreover, spurious cues may still exist in the selected subset. As a solution to this problem, we propose a novel ranking framework that leverages an open vocabulary object detection technique to identify images without spurious cues. More specifically, we use the object detector as a measure to score the presence of the target object in the images. Next, the images are sorted based on this score, and the last-layer of the model is retrained on a subset of the data with the highest scores. Our experiments on the ImageNet-1k dataset demonstrate the effectiveness of this ranking framework in sorting images based on spuriousness and using them for last-layer retraining.
</details>
<details>
<summary>摘要</summary>
To overcome these limitations, we propose a novel ranking framework that leverages open vocabulary object detection techniques to identify images without spurious cues. Specifically, we use an object detector to measure the presence of the target object in the images, and then sort the images based on this score. Finally, we retrain the last layer of the model on a subset of the data with the highest scores. Our experiments on the ImageNet-1k dataset show that our ranking framework is effective in sorting images based on spuriousness and using them for last-layer retraining.
</details></li>
</ul>
<hr>
<h2 id="YOLOv8-Based-Visual-Detection-of-Road-Hazards-Potholes-Sewer-Covers-and-Manholes"><a href="#YOLOv8-Based-Visual-Detection-of-Road-Hazards-Potholes-Sewer-Covers-and-Manholes" class="headerlink" title="YOLOv8-Based Visual Detection of Road Hazards: Potholes, Sewer Covers, and Manholes"></a>YOLOv8-Based Visual Detection of Road Hazards: Potholes, Sewer Covers, and Manholes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00073">http://arxiv.org/abs/2311.00073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Om M. Khare, Shubham Gandhi, Aditya M. Rahalkar, Sunil Mane</li>
<li>for: 本研究旨在评估YOLOv8对道路危险的检测，包括孔隙、排水涂层和人洞。</li>
<li>methods: 本研究使用YOLOv8对象检测模型进行评估，并进行了相对分析与前一代YOLOv5和YOLOv7模型。图像预处理技术和hyperparameter调整也被研究以提高检测精度。</li>
<li>results: 研究发现YOLOv8在不同的照明条件、路径类型、危险大小和类型下的检测精度较高，并且在多个测试场景下 Displaying mAP 分数以评估模型的稳定性和通用性。<details>
<summary>Abstract</summary>
Effective detection of road hazards plays a pivotal role in road infrastructure maintenance and ensuring road safety. This research paper provides a comprehensive evaluation of YOLOv8, an object detection model, in the context of detecting road hazards such as potholes, Sewer Covers, and Man Holes. A comparative analysis with previous iterations, YOLOv5 and YOLOv7, is conducted, emphasizing the importance of computational efficiency in various applications. The paper delves into the architecture of YOLOv8 and explores image preprocessing techniques aimed at enhancing detection accuracy across diverse conditions, including variations in lighting, road types, hazard sizes, and types. Furthermore, hyperparameter tuning experiments are performed to optimize model performance through adjustments in learning rates, batch sizes, anchor box sizes, and augmentation strategies. Model evaluation is based on Mean Average Precision (mAP), a widely accepted metric for object detection performance. The research assesses the robustness and generalization capabilities of the models through mAP scores calculated across the diverse test scenarios, underlining the significance of YOLOv8 in road hazard detection and infrastructure maintenance.
</details>
<details>
<summary>摘要</summary>
通过有效检测公路障碍物来维护公路基础设施和保障公路安全的作用非常重要。本研究论文对YOLOv8对象检测模型在检测公路障碍物方面进行了全面的评估，包括缺陷排水沟、排障板和人洞。与前两代YOLOv5和YOLOv7模型进行比较，研究强调了计算效率的重要性在不同应用场景中。文章还详细介绍了YOLOv8的架构和图像预处理技术，以提高检测精度在不同的照明、公路类型、障碍物大小和类型等条件下。此外，文章还进行了模型参数调整实验，以优化模型性能通过学习率、批处理大小、固定盒子大小和扩展策略的调整。模型评估基于 Mean Average Precision（mAP）度量，这是对象检测性能的广泛接受的指标。研究通过在多种测试场景下计算出的mAP分数，证明YOLOv8在公路障碍物检测和基础设施维护中的重要性。
</details></li>
</ul>
<hr>
<h2 id="View-Classification-and-Object-Detection-in-Cardiac-Ultrasound-to-Localize-Valves-via-Deep-Learning"><a href="#View-Classification-and-Object-Detection-in-Cardiac-Ultrasound-to-Localize-Valves-via-Deep-Learning" class="headerlink" title="View Classification and Object Detection in Cardiac Ultrasound to Localize Valves via Deep Learning"></a>View Classification and Object Detection in Cardiac Ultrasound to Localize Valves via Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00068">http://arxiv.org/abs/2311.00068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derya Gol Gungor, Bimba Rao, Cynthia Wolverton, Ismayil Guracar</li>
<li>For: 这个研究用于提供一种基于深度神经网络的echocardiography图像分类和LOCAL化方法，以便为临床医生提供实时、低成本、无辐射的心脏功能观察工具。* Methods: 该研究使用了深度神经网络进行分类和LOCAL化步骤，首先应用视图分类于心脏ultrasound图像中的10种各种 анатомиче视图，然后使用深度学习基于对象检测来bothLocalize和识别心脏钳。* Results: 对于Apical视图，我们的对象检测实验表明可以准确地LOCALize和识别多个钳。<details>
<summary>Abstract</summary>
Echocardiography provides an important tool for clinicians to observe the function of the heart in real time, at low cost, and without harmful radiation. Automated localization and classification of heart valves enables automatic extraction of quantities associated with heart mechanical function and related blood flow measurements. We propose a machine learning pipeline that uses deep neural networks for separate classification and localization steps. As the first step in the pipeline, we apply view classification to echocardiograms with ten unique anatomic views of the heart. In the second step, we apply deep learning-based object detection to both localize and identify the valves. Image segmentation based object detection in echocardiography has been shown in many earlier studies but, to the best of our knowledge, this is the first study that predicts the bounding boxes around the valves along with classification from 2D ultrasound images with the help of deep neural networks. Our object detection experiments applied to the Apical views suggest that it is possible to localize and identify multiple valves precisely.
</details>
<details>
<summary>摘要</summary>
《echo心动影像提供了低成本、不含辐射的实时心脏功能观察工具，对医生来说非常重要。我们提议一个基于深度神经网络的机器学习管道，包括分类和定位两个步骤。第一步是通过视图分类来处理心动影像的十种不同的解剖视图。第二步是使用深度学习基于对象检测来本地化和识别心脏钱币。在许多先前的研究中，图像分割基于对象检测在心动影像中已经被证明可行，但是，到目前为止，这是第一个通过深度神经网络预测心脏钱币 bounding box 的研究。我们的对象检测实验在Apical视图中表明，可以准确地本地化和识别多个钱币。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="FPO-Efficient-Encoding-and-Rendering-of-Dynamic-Neural-Radiance-Fields-by-Analyzing-and-Enhancing-Fourier-PlenOctrees"><a href="#FPO-Efficient-Encoding-and-Rendering-of-Dynamic-Neural-Radiance-Fields-by-Analyzing-and-Enhancing-Fourier-PlenOctrees" class="headerlink" title="FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance Fields by Analyzing and Enhancing Fourier PlenOctrees"></a>FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance Fields by Analyzing and Enhancing Fourier PlenOctrees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20710">http://arxiv.org/abs/2310.20710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saskia Rabich, Patrick Stotko, Reinhard Klein</li>
<li>for: 提高 NeRF 模型的动态渲染效果，并解决在结合最新技术时引入的压缩 artifacts 问题</li>
<li>methods: 使用改进的 Fourier PlenOctrees 表示法，包括适应式质量编码和减少压缩 artifacts 的技术</li>
<li>results: 在 sintetic 和实际场景中进行了评估，并显示了改进后的 Fourier PlenOctrees 可以减少 artifacts 并提高动态 NeRF 模型的效果<details>
<summary>Abstract</summary>
Fourier PlenOctrees have shown to be an efficient representation for real-time rendering of dynamic Neural Radiance Fields (NeRF). Despite its many advantages, this method suffers from artifacts introduced by the involved compression when combining it with recent state-of-the-art techniques for training the static per-frame NeRF models. In this paper, we perform an in-depth analysis of these artifacts and leverage the resulting insights to propose an improved representation. In particular, we present a novel density encoding that adapts the Fourier-based compression to the characteristics of the transfer function used by the underlying volume rendering procedure and leads to a substantial reduction of artifacts in the dynamic model. Furthermore, we show an augmentation of the training data that relaxes the periodicity assumption of the compression. We demonstrate the effectiveness of our enhanced Fourier PlenOctrees in the scope of quantitative and qualitative evaluations on synthetic and real-world scenes.
</details>
<details>
<summary>摘要</summary>
傅里叶普莱树（Fourier PlenOctrees）已经显示为实时渲染动态神经辐射场（NeRF）的有效表示方法。尽管它具有许多优点，但这种方法受到了与现代训练静态每帧 NeRF 模型的压缩相关的artefacts的影响。在这篇论文中，我们进行了深入的分析这些artefacts，并利用结果的启示来提出改进的表示方法。具体来说，我们提出了一种适应转移函数使用的 Fourier 基式压缩的新密度编码方法，导致 artefacts 在动态模型中减少了许多。此外，我们还展示了对压缩数据的扩展，以减少压缩的 периодичность假设。我们在synthetic和实际场景中进行了评估，并证明了我们的改进后的傅里叶普莱树的效iveness。
</details></li>
</ul>
<hr>
<h2 id="DDAM-PS-Diligent-Domain-Adaptive-Mixer-for-Person-Search"><a href="#DDAM-PS-Diligent-Domain-Adaptive-Mixer-for-Person-Search" class="headerlink" title="DDAM-PS: Diligent Domain Adaptive Mixer for Person Search"></a>DDAM-PS: Diligent Domain Adaptive Mixer for Person Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20706">http://arxiv.org/abs/2310.20706</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mustansarfiaz/ddam-ps">https://github.com/mustansarfiaz/ddam-ps</a></li>
<li>paper_authors: Mohammed Khaleed Almansoori, Mustansar Fiaz, Hisham Cholakkal</li>
<li>for: 本研究主要针对人寻找（PS）问题进行研究，实现了人检测和重新识别（ReID）的共同优化。</li>
<li>methods: 我们提出了一个努力域适应混合（DDAM）模组，用于对人寻找（DDAP-PS）框架。这个模组搭配了原始和目标域的表示，以生成中等混合域表示。这个DDAM模组实现了域混合，以减少两个极端域之间的距离，进而提高ReID任务。</li>
<li>results: 我们透过实验 validate了我们的提案的有效性。我们的方法在PRW和CUHK-SYSU datasets上显示了良好的性能。我们的原始代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/mustansarfiaz/DDAM-PS%7D">https://github.com/mustansarfiaz/DDAM-PS}</a> 上获取。<details>
<summary>Abstract</summary>
Person search (PS) is a challenging computer vision problem where the objective is to achieve joint optimization for pedestrian detection and re-identification (ReID). Although previous advancements have shown promising performance in the field under fully and weakly supervised learning fashion, there exists a major gap in investigating the domain adaptation ability of PS models. In this paper, we propose a diligent domain adaptive mixer (DDAM) for person search (DDAP-PS) framework that aims to bridge a gap to improve knowledge transfer from the labeled source domain to the unlabeled target domain. Specifically, we introduce a novel DDAM module that generates moderate mixed-domain representations by combining source and target domain representations. The proposed DDAM module encourages domain mixing to minimize the distance between the two extreme domains, thereby enhancing the ReID task. To achieve this, we introduce two bridge losses and a disparity loss. The objective of the two bridge losses is to guide the moderate mixed-domain representations to maintain an appropriate distance from both the source and target domain representations. The disparity loss aims to prevent the moderate mixed-domain representations from being biased towards either the source or target domains, thereby avoiding overfitting. Furthermore, we address the conflict between the two subtasks, localization and ReID, during domain adaptation. To handle this cross-task conflict, we forcefully decouple the norm-aware embedding, which aids in better learning of the moderate mixed-domain representation. We conduct experiments to validate the effectiveness of our proposed method. Our approach demonstrates favorable performance on the challenging PRW and CUHK-SYSU datasets. Our source code is publicly available at \url{https://github.com/mustansarfiaz/DDAM-PS}.
</details>
<details>
<summary>摘要</summary>
人体搜索（PS）是一个Computer Vision中的挑战，既需要实现人体检测和重新识别（ReID）的 JOINT 优化。尽管过去的进展有许多提高在这个领域中，但是存在一个主要的域适应能力研究的空白。在这篇论文中，我们提出了一个勤奋的域适应混合器（DDAM） для人体搜索（DDAP-PS）框架，以增强域适应能力。特别是，我们引入了一个新的DDAM模块，该模块将源频率和目标频率的表示混合起来，以生成中等域适应表示。我们的DDAM模块鼓励域适应，以降低两个极端域之间的距离，从而提高ReID任务。为此，我们引入了两个桥接损失和一个差异损失。两个桥接损失的目的是使中等域适应表示维持与源频率和目标频率的两个域的相应距离。差异损失的目的是避免中等域适应表示受到源频率或目标频率的偏袋，以避免过拟合。此外，我们解决了在域适应中的局部化和ReID之间的冲突。我们强制耦合 норма化表示，以便更好地学习中等域适应表示。我们进行了实验，以证明我们的方法的效果。我们的方法在PRW和CUHK-SYSU datasets上表现出色。我们的源代码可以在 <https://github.com/mustansarfiaz/DDAM-PS> 中下载。
</details></li>
</ul>
<hr>
<h2 id="SEINE-Short-to-Long-Video-Diffusion-Model-for-Generative-Transition-and-Prediction"><a href="#SEINE-Short-to-Long-Video-Diffusion-Model-for-Generative-Transition-and-Prediction" class="headerlink" title="SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"></a>SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20700">http://arxiv.org/abs/2310.20700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyuan Chen, Yaohui Wang, Lingjun Zhang, Shaobin Zhuang, Xin Ma, Jiashuo Yu, Yali Wang, Dahua Lin, Yu Qiao, Ziwei Liu</li>
<li>for: 这篇论文旨在生成高质量的长视频（story-level），包括创新的过渡和预测效果。</li>
<li>methods: 该论文提出了一种短视频扩散模型，即 SEINE，用于生成高质量的过渡和预测。该模型根据文本描述自动生成过渡，并使用图像作为输入，以确保视觉质量和凝聚性。</li>
<li>results: 经验证实表明，该模型可以有效地生成高质量的长视频，并且可以扩展到其他任务，如图像到视频动画和自适应视频预测。为评估该新的生成任务，我们提出了三个评价标准：时间一致性、semantic similarity和视频文本匹配。<details>
<summary>Abstract</summary>
Recently video generation has achieved substantial progress with realistic results. Nevertheless, existing AI-generated videos are usually very short clips ("shot-level") depicting a single scene. To deliver a coherent long video ("story-level"), it is desirable to have creative transition and prediction effects across different clips. This paper presents a short-to-long video diffusion model, SEINE, that focuses on generative transition and prediction. The goal is to generate high-quality long videos with smooth and creative transitions between scenes and varying lengths of shot-level videos. Specifically, we propose a random-mask video diffusion model to automatically generate transitions based on textual descriptions. By providing the images of different scenes as inputs, combined with text-based control, our model generates transition videos that ensure coherence and visual quality. Furthermore, the model can be readily extended to various tasks such as image-to-video animation and autoregressive video prediction. To conduct a comprehensive evaluation of this new generative task, we propose three assessing criteria for smooth and creative transition: temporal consistency, semantic similarity, and video-text semantic alignment. Extensive experiments validate the effectiveness of our approach over existing methods for generative transition and prediction, enabling the creation of story-level long videos. Project page: https://vchitect.github.io/SEINE-project/ .
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="NeRF-Revisited-Fixing-Quadrature-Instability-in-Volume-Rendering"><a href="#NeRF-Revisited-Fixing-Quadrature-Instability-in-Volume-Rendering" class="headerlink" title="NeRF Revisited: Fixing Quadrature Instability in Volume Rendering"></a>NeRF Revisited: Fixing Quadrature Instability in Volume Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20685">http://arxiv.org/abs/2310.20685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mikacuy/PL-NeRF">https://github.com/mikacuy/PL-NeRF</a></li>
<li>paper_authors: Mikaela Angelina Uy, Kiyohiro Nakayama, Guandao Yang, Rahul Krishna Thomas, Leonidas Guibas, Ke Li</li>
<li>For: 本研究旨在解决NeRF中的 quadrature instability问题，提高rendering的稳定性和质量。* Methods: 提出一种基于 математиче原理的解决方案，通过修改样本基于渲染公式，使其对应于piecewise线性Volume density的精确积分。* Results: 与传统样本基于渲染公式相比，提出的方法具有更加锐利的 texture、更好的几何重建和更强的深度超视觉。此外，本方法可以与现有NeRF方法的volume rendering公式进行互换使用。<details>
<summary>Abstract</summary>
Neural radiance fields (NeRF) rely on volume rendering to synthesize novel views. Volume rendering requires evaluating an integral along each ray, which is numerically approximated with a finite sum that corresponds to the exact integral along the ray under piecewise constant volume density. As a consequence, the rendered result is unstable w.r.t. the choice of samples along the ray, a phenomenon that we dub quadrature instability. We propose a mathematically principled solution by reformulating the sample-based rendering equation so that it corresponds to the exact integral under piecewise linear volume density. This simultaneously resolves multiple issues: conflicts between samples along different rays, imprecise hierarchical sampling, and non-differentiability of quantiles of ray termination distances w.r.t. model parameters. We demonstrate several benefits over the classical sample-based rendering equation, such as sharper textures, better geometric reconstruction, and stronger depth supervision. Our proposed formulation can be also be used as a drop-in replacement to the volume rendering equation of existing NeRF-based methods. Our project page can be found at pl-nerf.github.io.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="StairNet-Visual-Recognition-of-Stairs-for-Human-Robot-Locomotion"><a href="#StairNet-Visual-Recognition-of-Stairs-for-Human-Robot-Locomotion" class="headerlink" title="StairNet: Visual Recognition of Stairs for Human-Robot Locomotion"></a>StairNet: Visual Recognition of Stairs for Human-Robot Locomotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20666">http://arxiv.org/abs/2310.20666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Garrett Kurbis, Dmytro Kuzmenko, Bogdan Ivanyuk-Skulskiy, Alex Mihailidis, Brokoslaw Laschowski</li>
<li>for: 这个论文的目的是提供一个可靠的视觉感知系统，以便人机系统在复杂的地形上进行行走。</li>
<li>methods: 这个论文使用了多种深度学习模型（如2D和3D CNN、混合CNN和LSTM、ViT网络）和训练方法（如监督学习和半监督学习），并使用了大规模的数据集进行训练。</li>
<li>results: 这个论文的实验结果表明，使用StairNet可以实现高精度的视觉感知系统，并且可以在移动设备上进行实时推理。但是，由于嵌入式硬件的限制，在智能眼镜上进行推理时的速度相对较慢。<details>
<summary>Abstract</summary>
Human-robot walking with prosthetic legs and exoskeletons, especially over complex terrains such as stairs, remains a significant challenge. Egocentric vision has the unique potential to detect the walking environment prior to physical interactions, which can improve transitions to and from stairs. This motivated us to create the StairNet initiative to support the development of new deep learning models for visual sensing and recognition of stairs, with an emphasis on lightweight and efficient neural networks for onboard real-time inference. In this study, we present an overview of the development of our large-scale dataset with over 515,000 manually labeled images, as well as our development of different deep learning models (e.g., 2D and 3D CNN, hybrid CNN and LSTM, and ViT networks) and training methods (e.g., supervised learning with temporal data and semi-supervised learning with unlabeled images) using our new dataset. We consistently achieved high classification accuracy (i.e., up to 98.8%) with different designs, offering trade-offs between model accuracy and size. When deployed on mobile devices with GPU and NPU accelerators, our deep learning models achieved inference speeds up to 2.8 ms. We also deployed our models on custom-designed CPU-powered smart glasses. However, limitations in the embedded hardware yielded slower inference speeds of 1.5 seconds, presenting a trade-off between human-centered design and performance. Overall, we showed that StairNet can be an effective platform to develop and study new visual perception systems for human-robot locomotion with applications in exoskeleton and prosthetic leg control.
</details>
<details>
<summary>摘要</summary>
人机步行使用 prósthetic 脚和外套体系，特别是在复杂的地形上，如楼梯，仍然是一项 significante 挑战。 egocentric 视觉具有特殊的潜在力量，可以在物理互动之前探测步行环境，这有助于改善楼梯之间和楼梯之间的过渡。这种挑战引发了我们创建 StairNet Initiave，以支持开发新的深度学习模型，用于视觉感知和识别楼梯，强调轻量级和高效的神经网络，以便在实时进行boards 的推理。在这种研究中，我们介绍了我们开发的大规模数据集，包括515,000多个手动标注的图像，以及我们开发的不同的深度学习模型（如2D和3D CNN、混合 CNN和LSTM网络）和训练方法（如监督学习和 semi-监督学习）。我们在不同的设计中均实现了高精度分类（达到98.8%），提供了模型精度和大小之间的质量负担。当部署在移动设备上（含GPU和NPU加速器）时，我们的深度学习模型实现了1.5秒的推理速度。此外，我们还部署了我们的模型在自定义CPU驱动的智能眼镜上。尽管嵌入式硬件的限制导致推理速度为1.5秒，但是我们展示了StairNet可以成为人机步行视觉系统的有效平台，并具有应用于外套和 prósthetic 脚控制的可能性。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Limitations-of-State-Aware-Imitation-Learning-for-Autonomous-Driving"><a href="#Addressing-Limitations-of-State-Aware-Imitation-Learning-for-Autonomous-Driving" class="headerlink" title="Addressing Limitations of State-Aware Imitation Learning for Autonomous Driving"></a>Addressing Limitations of State-Aware Imitation Learning for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20650">http://arxiv.org/abs/2310.20650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Cultrera, Federico Becattini, Lorenzo Seidenari, Pietro Pala, Alberto Del Bimbo</li>
<li>for: 提高自动驾驶代理人的性能和可靠性</li>
<li>methods: 使用多任务学习和多Stagevision transformer，并将车辆状态作为特殊令牌进行传播</li>
<li>results: 降低偏斜问题和在线和离线性能之间的相关性问题，并提高了驾驶策略的学习和决策的可见性。<details>
<summary>Abstract</summary>
Conditional Imitation learning is a common and effective approach to train autonomous driving agents. However, two issues limit the full potential of this approach: (i) the inertia problem, a special case of causal confusion where the agent mistakenly correlates low speed with no acceleration, and (ii) low correlation between offline and online performance due to the accumulation of small errors that brings the agent in a previously unseen state. Both issues are critical for state-aware models, yet informing the driving agent of its internal state as well as the state of the environment is of crucial importance. In this paper we propose a multi-task learning agent based on a multi-stage vision transformer with state token propagation. We feed the state of the vehicle along with the representation of the environment as a special token of the transformer and propagate it throughout the network. This allows us to tackle the aforementioned issues from different angles: guiding the driving policy with learned stop/go information, performing data augmentation directly on the state of the vehicle and visually explaining the model's decisions. We report a drastic decrease in inertia and a high correlation between offline and online metrics.
</details>
<details>
<summary>摘要</summary>
conditioned imitation learning 是一种常见而有效的自动驾驶代理方法。然而，两个问题限制了这种方法的全面潜力：（i）势能问题，特殊的 causal confusion 问题，agent 错误地相关低速与无加速度的耦合，以及（ii）在线和离线性能的低相关性，由于累累的小错误而导致agent 处于未看过的状态。这两个问题对状态感知模型非常重要，但是告诉驾驶代理器的内部状态以及环境状态也是非常重要。在这篇论文中，我们提议一种基于多任务学习的多阶段视transformer Agent，我们将驾驶车辆的状态和环境的表示作为 transformer 的特殊 токен，并在网络中传播它们。这使得我们可以从不同的角度解决上述问题：引导驾驶策略，直接对驾驶车辆的状态进行数据扩展，以及可视化模型的决策。我们发现降低了势能问题，并且在线和离线指标之间的相关性非常高。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Batch-Norm-Statistics-Update-for-Natural-Robustness"><a href="#Dynamic-Batch-Norm-Statistics-Update-for-Natural-Robustness" class="headerlink" title="Dynamic Batch Norm Statistics Update for Natural Robustness"></a>Dynamic Batch Norm Statistics Update for Natural Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20649">http://arxiv.org/abs/2310.20649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahbaz Rezaei, Mohammad Sadegh Norouzzadeh</li>
<li>for: 提高DNN对受损样本的性能</li>
<li>methods: 利用快速更新 batch normalization（BN）统计信息，以及在快速更新BN统计信息后进行损害检测</li>
<li>results: 在CIFAR10-C和ImageNet-C datasets上实现了约8%和4%的准确率提高，并且可以进一步提高现有的可靠模型的准确率。<details>
<summary>Abstract</summary>
DNNs trained on natural clean samples have been shown to perform poorly on corrupted samples, such as noisy or blurry images. Various data augmentation methods have been recently proposed to improve DNN's robustness against common corruptions. Despite their success, they require computationally expensive training and cannot be applied to off-the-shelf trained models. Recently, it has been shown that updating BatchNorm (BN) statistics of an off-the-shelf model on a single corruption improves its accuracy on that corruption significantly. However, adopting the idea at inference time when the type of corruption is unknown and changing decreases the effectiveness of this method. In this paper, we harness the Fourier domain to detect the corruption type, a challenging task in the image domain. We propose a unified framework consisting of a corruption-detection model and BN statistics update that improves the corruption accuracy of any off-the-shelf trained model. We benchmark our framework on different models and datasets. Our results demonstrate about 8% and 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively. Furthermore, our framework can further improve the accuracy of state-of-the-art robust models, such as AugMix and DeepAug.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在天然清晰样本上训练后表现不佳于受损样本，如杂音或模糊图像。各种数据增强方法已经被提议以提高DNN的对常见受损的Robustness。尽管它们在成功，但它们需要计算成本较高的训练，并且无法应用于卸载模型。最近，有人提出了将批处理 normalization（BatchNorm）统计信息更新到卸载模型中，以提高对受损的精度。但是，在推理时，当受损类型未知并且改变时，这种方法的效iveness会减退。在这篇论文中，我们利用快推频域来检测受损类型，这是图像领域中的一个挑战。我们提出了一个统一框架，包括受损检测模型和批处理 normalization 统计信息更新，以提高任何卸载训练模型的受损精度。我们对不同的模型和数据集进行了比较。我们的结果表明，在CIFAR10-C和ImageNet-C上，我们的框架可以提高精度约8%和4%。此外，我们的框架可以进一步提高当今最佳Robust模型，如AugMix和DeepAug的精度。
</details></li>
</ul>
<hr>
<h2 id="Using-Higher-Order-Moments-to-Assess-the-Quality-of-GAN-generated-Image-Features"><a href="#Using-Higher-Order-Moments-to-Assess-the-Quality-of-GAN-generated-Image-Features" class="headerlink" title="Using Higher-Order Moments to Assess the Quality of GAN-generated Image Features"></a>Using Higher-Order Moments to Assess the Quality of GAN-generated Image Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20636">http://arxiv.org/abs/2310.20636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Luzi, Helen Jenne, Ryan Murray, Carlos Ortiz Marrero</li>
<li>for: 评估生成 adversarial networks (GANs) 的robustness</li>
<li>methods: 利用 Fréchet Inception Distance (FID) 和 Skew Inception Distance (SID) 两种度量来评估 GANs</li>
<li>results: SID 可以更好地反映人类的感知，并且可以跟踪 FID 的表现Here’s a more detailed explanation of each point:1. for: The paper aims to evaluate the robustness of Generative Adversarial Networks (GANs) using two distance measures: Fréchet Inception Distance (FID) and Skew Inception Distance (SID).2. methods: The paper uses FID and SID to evaluate GANs, and presents a practical method for computing SID.3. results: The results show that SID can better reflect human perception and can track the performance of FID in evaluating image features of ImageNet data.<details>
<summary>Abstract</summary>
The rapid advancement of Generative Adversarial Networks (GANs) necessitates the need to robustly evaluate these models. Among the established evaluation criteria, the Fr\'{e}chet Inception Distance (FID) has been widely adopted due to its conceptual simplicity, fast computation time, and strong correlation with human perception. However, FID has inherent limitations, mainly stemming from its assumption that feature embeddings follow a Gaussian distribution, and therefore can be defined by their first two moments. As this does not hold in practice, in this paper we explore the importance of third-moments in image feature data and use this information to define a new measure, which we call the Skew Inception Distance (SID). We prove that SID is a pseudometric on probability distributions, show how it extends FID, and present a practical method for its computation. Our numerical experiments support that SID either tracks with FID or, in some cases, aligns more closely with human perception when evaluating image features of ImageNet data.
</details>
<details>
<summary>摘要</summary>
“Generative Adversarial Networks（GANs）的快速进步需要对这些模型进行严格的评估。已有的评估标准之一是Fréchet Inception Distance（FID），它的概念简单，计算速度快，且与人类感知强相关。然而，FID有一些限制，主要是它假设特征嵌入 follows Gaussian distribution，因此可以通过其第一个和第二个矩阵来定义。然而，这不是实际情况中的情况，因此在这篇文章中，我们探索了特征数据中的第三个矩阵信息，并使用这些信息定义一个新的衡量，我们称之为Skew Inception Distance（SID）。我们证明了SID是一个pseudometric on probability distributions，并详细介绍了它与FID之间的关系。我们还提供了一个实际的计算方法，并通过数值实验支持SID可以跟踪FID或，在某些情况下，与人类感知更加一致。”
</details></li>
</ul>
<hr>
<h2 id="Deepfake-detection-by-exploiting-surface-anomalies-the-SurFake-approach"><a href="#Deepfake-detection-by-exploiting-surface-anomalies-the-SurFake-approach" class="headerlink" title="Deepfake detection by exploiting surface anomalies: the SurFake approach"></a>Deepfake detection by exploiting surface anomalies: the SurFake approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20621">http://arxiv.org/abs/2310.20621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Ciamarra, Roberto Caldelli, Federico Becattini, Lorenzo Seidenari, Alberto Del Bimbo</li>
<li>for: 这篇论文旨在探讨深伪检测技术，以避免各种媒体信息中的伪造内容散布。</li>
<li>methods: 本论文提出了一种基于场景特征分析的深伪检测方法，即SurFake方法，通过分析图像中的表面特征来生成一个可以训练CNN的描述子。</li>
<li>results: 实验结果显示，SurFake方法可以对FF++ dataset中的不同类型深伪诈骗内容进行有效的检测，并且可以与视觉数据结合以提高检测精度。<details>
<summary>Abstract</summary>
The ever-increasing use of synthetically generated content in different sectors of our everyday life, one for all media information, poses a strong need for deepfake detection tools in order to avoid the proliferation of altered messages. The process to identify manipulated content, in particular images and videos, is basically performed by looking for the presence of some inconsistencies and/or anomalies specifically due to the fake generation process. Different techniques exist in the scientific literature that exploit diverse ad-hoc features in order to highlight possible modifications. In this paper, we propose to investigate how deepfake creation can impact on the characteristics that the whole scene had at the time of the acquisition. In particular, when an image (video) is captured the overall geometry of the scene (e.g. surfaces) and the acquisition process (e.g. illumination) determine a univocal environment that is directly represented by the image pixel values; all these intrinsic relations are possibly changed by the deepfake generation process. By resorting to the analysis of the characteristics of the surfaces depicted in the image it is possible to obtain a descriptor usable to train a CNN for deepfake detection: we refer to such an approach as SurFake. Experimental results carried out on the FF++ dataset for different kinds of deepfake forgeries and diverse deep learning models confirm that such a feature can be adopted to discriminate between pristine and altered images; furthermore, experiments witness that it can also be combined with visual data to provide a certain improvement in terms of detection accuracy.
</details>
<details>
<summary>摘要</summary>
随着人工生成内容在不同领域的日常生活中越来越广泛使用，特别是媒体信息领域，有必要开发深度假作检测工具以避免受到修改的消息的扩散。寻找修改后的内容特征是通过检测修改过程中引入的一些异常和偏差来进行。在科学文献中已经存在多种不同特点的技术，以便在检测修改过程中异常出现的特征。在本文中，我们将探讨深度假作创造如何影响图像/视频的整体场景特征。具体来说，当图像（视频）被拍摄时，整个场景的geometry（例如表面）以及拍摄过程（例如照明）会直接将场景特征表示在图像像素值中，这些内在关系可能被深度假作生成过程改变。通过分析图像中表示的表面特征，我们可以获得一个可以用于训练CNN的假作检测Descriptor：我们称之为SurFake。实验结果表明，这种特征可以用于分辨普通和修改后的图像，而且可以与视觉数据结合使用以提高检测精度。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Reconstruction-of-Ultrasound-Images-with-Informative-Uncertainty"><a href="#Diffusion-Reconstruction-of-Ultrasound-Images-with-Informative-Uncertainty" class="headerlink" title="Diffusion Reconstruction of Ultrasound Images with Informative Uncertainty"></a>Diffusion Reconstruction of Ultrasound Images with Informative Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20618">http://arxiv.org/abs/2310.20618</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Yuxin-Zhang-Jasmine/DRUS-v2">https://github.com/Yuxin-Zhang-Jasmine/DRUS-v2</a></li>
<li>paper_authors: Yuxin Zhang, Clément Huneau, Jérôme Idier, Diana Mateus</li>
<li>For: The paper aims to improve the quality of ultrasound images by leveraging advances in diffusion models and incorporating ultrasound physics.* Methods: The proposed hybrid approach combines model-based and learning-based methods, adapting Denoising Diffusion Restoration Models (DDRM) to incorporate ultrasound physics through a linear direct model and unsupervised fine-tuning of the prior diffusion model.* Results: The approach achieves high-quality image reconstructions from a single plane wave input and outperforms state-of-the-art methods in simulated, in-vitro, and in-vivo experiments. The code and data are available online.Here is the same information in Simplified Chinese text:* 用途：文章目的是提高超声图像质量，利用扩散模型的最新进展和超声物理学。* 方法：提议的混合方法 combinines 模型基于和学习基于方法，将 Denoising Diffusion Restoration Models (DDRM) 适应超声物理学通过直接模型和无监督精度模型的微调。* 结果：方法可以从单个扩散波输入获得高质量的图像重建，并在模拟、室内和实验室数据上超过当前最佳方法。代码和数据可在（接受后）上获取。<details>
<summary>Abstract</summary>
Despite its wide use in medicine, ultrasound imaging faces several challenges related to its poor signal-to-noise ratio and several sources of noise and artefacts. Enhancing ultrasound image quality involves balancing concurrent factors like contrast, resolution, and speckle preservation. In recent years, there has been progress both in model-based and learning-based approaches to improve ultrasound image reconstruction. Bringing the best from both worlds, we propose a hybrid approach leveraging advances in diffusion models. To this end, we adapt Denoising Diffusion Restoration Models (DDRM) to incorporate ultrasound physics through a linear direct model and an unsupervised fine-tuning of the prior diffusion model. We conduct comprehensive experiments on simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our approach in achieving high-quality image reconstructions from a single plane wave input and in comparison to state-of-the-art methods. Finally, given the stochastic nature of the method, we analyse in depth the statistical properties of single and multiple-sample reconstructions, experimentally show the informativeness of their variance, and provide an empirical model relating this behaviour to speckle noise. The code and data are available at: (upon acceptance).
</details>
<details>
<summary>摘要</summary>
虽然医学中使用ultrasound imaging广泛，但它们面临着一些相关的信号噪声和噪声源的挑战。提高ultrasound图像质量需要同时考虑对比、分辨率和雾点保持的平衡。在过去几年中，有一些基于模型和学习的方法来改进ultrasound图像重建。我们提议一种hybrid方法， combinig diffusion模型的进步。为此，我们在linear direct模型和一种不supervised的精度模型之间进行了权衡。我们对 simulated、in-vitro和in-vivo数据进行了全面的实验，并证明了我们的方法可以从单个平面波输入中获得高质量的图像重建，并与当前的方法进行比较。此外，由于方法的随机性，我们对单个和多个样本重建的统计性质进行了深入的分析，实验表明雾点噪声的信息量是可以获取的，并提供了一个实验性的模型，将这种行为与雾点噪声相关联。代码和数据在acceptance时可以获取。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Synthetic-MRI-Generation-from-CT-Scans-Using-CycleGAN-with-Feature-Extraction"><a href="#Enhanced-Synthetic-MRI-Generation-from-CT-Scans-Using-CycleGAN-with-Feature-Extraction" class="headerlink" title="Enhanced Synthetic MRI Generation from CT Scans Using CycleGAN with Feature Extraction"></a>Enhanced Synthetic MRI Generation from CT Scans Using CycleGAN with Feature Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20604">http://arxiv.org/abs/2310.20604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saba Nikbakhsh, Lachin Naghashyar, Morteza Valizadeh, Mehdi Chehel Amirani</li>
<li>for: 这篇论文的目的是对于放射治疗中的精确图像和图像注册进行改进，以提高放射治疗的精确性。</li>
<li>methods: 这篇论文使用的方法是基于Synthetic MRI图像的单模图像注册，利用CycleGANs和特征提取器来生成这些图像。</li>
<li>results: 这篇论文的结果显示，该方法可以优化多modal registration的过程，并且比较多于之前的州先进方法表现出色。<details>
<summary>Abstract</summary>
In the field of radiotherapy, accurate imaging and image registration are of utmost importance for precise treatment planning. Magnetic Resonance Imaging (MRI) offers detailed imaging without being invasive and excels in soft-tissue contrast, making it a preferred modality for radiotherapy planning. However, the high cost of MRI, longer acquisition time, and certain health considerations for patients pose challenges. Conversely, Computed Tomography (CT) scans offer a quicker and less expensive imaging solution. To bridge these modalities and address multimodal alignment challenges, we introduce an approach for enhanced monomodal registration using synthetic MRI images. Utilizing unpaired data, this paper proposes a novel method to produce these synthetic MRI images from CT scans, leveraging CycleGANs and feature extractors. By building upon the foundational work on Cycle-Consistent Adversarial Networks and incorporating advancements from related literature, our methodology shows promising results, outperforming several state-of-the-art methods. The efficacy of our approach is validated by multiple comparison metrics.
</details>
<details>
<summary>摘要</summary>
在辐射治疗领域，精准成像和图像对接是至关重要的，以便精准的治疗规划。核磁共振成像（MRI）可以提供详细的成像，无需侵入性，并且在软组织对比方面表现出色，因此成为辐射治疗规划的首选方式。然而，MRI的高价格、长时间获取和某些健康考虑因素带来挑战。相比之下，计算 Tomatoes成像（CT）扫描器提供了快速、成本低的成像解决方案。为了桥接这两种模式和解决多模态对接问题，我们提出了一种增强单模式对接方法，使用生成的MRI图像。该方法使用不匹配的数据，利用CycleGANs和特征提取器，以便生成MRI图像。我们建立在基础的Cycle-Consistent Adversarial Networks之上，并从相关 литературе中吸收了进步，我们的方法ologies showed promising results, outperforming several state-of-the-art methods。我们的方法的有效性被多种比较指标 validate。
</details></li>
</ul>
<hr>
<h2 id="Brain-like-Flexible-Visual-Inference-by-Harnessing-Feedback-Feedforward-Alignment"><a href="#Brain-like-Flexible-Visual-Inference-by-Harnessing-Feedback-Feedforward-Alignment" class="headerlink" title="Brain-like Flexible Visual Inference by Harnessing Feedback-Feedforward Alignment"></a>Brain-like Flexible Visual Inference by Harnessing Feedback-Feedforward Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20599">http://arxiv.org/abs/2310.20599</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toosi/feedback_feedforward_alignment">https://github.com/toosi/feedback_feedforward_alignment</a></li>
<li>paper_authors: Tahereh Toosi, Elias B. Issa</li>
<li>for: This paper aims to explore the mechanisms underlying how feedback connections in the visual cortex support flexible visual functions, such as denoising, resolving occlusions, hallucination, and imagination.</li>
<li>methods: The authors propose a learning algorithm called Feedback-Feedforward Alignment (FFA) that leverages feedback and feedforward pathways to co-optimize classification and reconstruction tasks on widely used MNIST and CIFAR10 datasets.</li>
<li>results: The study demonstrates the effectiveness of FFA in endowing feedback connections with emergent visual inference functions, and offers bio-plausibility compared to traditional backpropagation (BP) methods. The alignment mechanism in FFA enhances the bio-plausibility of the learning algorithm and contributes to the broader field of visual inference underlying perceptual phenomena.<details>
<summary>Abstract</summary>
In natural vision, feedback connections support versatile visual inference capabilities such as making sense of the occluded or noisy bottom-up sensory information or mediating pure top-down processes such as imagination. However, the mechanisms by which the feedback pathway learns to give rise to these capabilities flexibly are not clear. We propose that top-down effects emerge through alignment between feedforward and feedback pathways, each optimizing its own objectives. To achieve this co-optimization, we introduce Feedback-Feedforward Alignment (FFA), a learning algorithm that leverages feedback and feedforward pathways as mutual credit assignment computational graphs, enabling alignment. In our study, we demonstrate the effectiveness of FFA in co-optimizing classification and reconstruction tasks on widely used MNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endows feedback connections with emergent visual inference functions, including denoising, resolving occlusions, hallucination, and imagination. Moreover, FFA offers bio-plausibility compared to traditional backpropagation (BP) methods in implementation. By repurposing the computational graph of credit assignment into a goal-driven feedback pathway, FFA alleviates weight transport problems encountered in BP, enhancing the bio-plausibility of the learning algorithm. Our study presents FFA as a promising proof-of-concept for the mechanisms underlying how feedback connections in the visual cortex support flexible visual functions. This work also contributes to the broader field of visual inference underlying perceptual phenomena and has implications for developing more biologically inspired learning algorithms.
</details>
<details>
<summary>摘要</summary>
自然视觉中，反馈连接支持多样化的视觉推理功能，如处理受阻或噪声的底向感知信息或激发纯层次过程如想象。然而，反馈路径学习如何抽象地实现这些多样化功能的机制不清楚。我们提议，反馈路径和前向路径之间的协调是实现多样化功能的关键。为此，我们提出了反馈-Feedforward协调（FFA）学习算法，利用反馈和前向路径作为互助计算图，实现协调。在我们的研究中，我们证明了 FFA 在广泛使用的 MNIST 和 CIFAR10 数据集上的分类和重建任务中的效果。尤其是在 FFA 中的协调机制下，反馈连接获得了许多生成visual推理功能，如净化、解除遮挡、梦幻、想象等。此外，FFA 具有与传统的 backpropagation（BP）方法不同的生物可能性，通过重塑计算图为目标驱动反馈路径，解决了 BP 中的权重传输问题，提高了生物可能性。我们的研究发现，FFA 作为一种可能的证明，证明了视觉系统中反馈连接支持多样化功能的机制。此外，FFA 对 visual 推理下的更广泛问题和生物适应性学习算法的发展产生了影响。
</details></li>
</ul>
<hr>
<h2 id="FLODCAST-Flow-and-Depth-Forecasting-via-Multimodal-Recurrent-Architectures"><a href="#FLODCAST-Flow-and-Depth-Forecasting-via-Multimodal-Recurrent-Architectures" class="headerlink" title="FLODCAST: Flow and Depth Forecasting via Multimodal Recurrent Architectures"></a>FLODCAST: Flow and Depth Forecasting via Multimodal Recurrent Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20593">http://arxiv.org/abs/2310.20593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Ciamarra, Federico Becattini, Lorenzo Seidenari, Alberto Del Bimbo</li>
<li>for: 这篇论文的目的是提出一种用于预测物体的运动和空间位置的方法，特别是在自动驾驶等安全关键场景中。</li>
<li>methods: 该论文提出了一种名为FLODCAST的流和深度预测模型，该模型利用了多任务回归架构，通过同时预测两种不同的modalities来提高预测精度。</li>
<li>results: 根据Cityscapes dataset的测试结果，该模型可以达到最佳的Result for both flow and depth forecasting,并且通过在不同时间步预测来提供更好的supervision，从而提高预测精度。此外，该模型还可以在下游任务中提供更好的结果，例如分割预测。<details>
<summary>Abstract</summary>
Forecasting motion and spatial positions of objects is of fundamental importance, especially in safety-critical settings such as autonomous driving. In this work, we address the issue by forecasting two different modalities that carry complementary information, namely optical flow and depth. To this end we propose FLODCAST a flow and depth forecasting model that leverages a multitask recurrent architecture, trained to jointly forecast both modalities at once. We stress the importance of training using flows and depth maps together, demonstrating that both tasks improve when the model is informed of the other modality. We train the proposed model to also perform predictions for several timesteps in the future. This provides better supervision and leads to more precise predictions, retaining the capability of the model to yield outputs autoregressively for any future time horizon. We test our model on the challenging Cityscapes dataset, obtaining state of the art results for both flow and depth forecasting. Thanks to the high quality of the generated flows, we also report benefits on the downstream task of segmentation forecasting, injecting our predictions in a flow-based mask-warping framework.
</details>
<details>
<summary>摘要</summary>
预测物体的运动和空间位置是基础性重要的，尤其在自动驾驶等安全关键场景中。在这项工作中，我们解决这个问题，通过同时预测两种不同的modalities，它们各自携带有补偿信息，即光流和深度。为此，我们提议了FLODCAST模型，它利用了多任务回归架构，通过同时预测这两种modalities来充分利用信息。我们强调了在训练过程中使用光流和深度图像 вместе，证明两个任务都会提高，当模型知道另一个模态时。我们还训练了模型以进行多个时间步预测，这提供了更好的监督，导致更准确的预测，保留模型在任何未来时间步可以生成autoregressively的能力。我们在Cityscapes dataset上测试了我们的模型，取得了流和深度预测的状态宇宙记录。由于生成的流速度较高质量，我们还报告了在基于流速度抽象框架的下游任务中的 segmentation预测的 beneficial effects。
</details></li>
</ul>
<hr>
<h2 id="Long-Tailed-Learning-as-Multi-Objective-Optimization"><a href="#Long-Tailed-Learning-as-Multi-Objective-Optimization" class="headerlink" title="Long-Tailed Learning as Multi-Objective Optimization"></a>Long-Tailed Learning as Multi-Objective Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20490">http://arxiv.org/abs/2310.20490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiqi Li, Fan Lyu, Fanhua Shang, Liang Wan, Wei Feng</li>
<li>for:  Addressing the long-tailed distribution issue in machine learning, where models are biased towards well-represented classes and perform poorly on under-represented classes.</li>
<li>methods:  Proposes a Gradient-Balancing Grouping (GBG) strategy to gather classes with similar gradient directions, allowing for ideal compensation for tail classes.</li>
<li>results:  Demonstrates superior performance over existing state-of-the-art (SOTA) methods through extensive experiments on commonly used benchmarks for long-tailed learning.<details>
<summary>Abstract</summary>
Real-world data is extremely imbalanced and presents a long-tailed distribution, resulting in models that are biased towards classes with sufficient samples and perform poorly on rare classes. Recent methods propose to rebalance classes but they undertake the seesaw dilemma (what is increasing performance on tail classes may decrease that of head classes, and vice versa). In this paper, we argue that the seesaw dilemma is derived from gradient imbalance of different classes, in which gradients of inappropriate classes are set to important for updating, thus are prone to overcompensation or undercompensation on tail classes. To achieve ideal compensation, we formulate the long-tailed recognition as an multi-objective optimization problem, which fairly respects the contributions of head and tail classes simultaneously. For efficiency, we propose a Gradient-Balancing Grouping (GBG) strategy to gather the classes with similar gradient directions, thus approximately make every update under a Pareto descent direction. Our GBG method drives classes with similar gradient directions to form more representative gradient and provide ideal compensation to the tail classes. Moreover, We conduct extensive experiments on commonly used benchmarks in long-tailed learning and demonstrate the superiority of our method over existing SOTA methods.
</details>
<details>
<summary>摘要</summary>
In this paper, we argue that the seesaw dilemma is caused by an imbalance of gradients from different classes. When some classes have more examples, their gradients become more important for updating the model, which can lead to overcompensation or undercompensation for the minority classes. To solve this problem, we formulate the long-tailed recognition as a multi-objective optimization problem, which aims to fairly respect the contributions of both the head and tail classes simultaneously.To improve efficiency, we propose a Gradient-Balancing Grouping (GBG) strategy that gathers classes with similar gradient directions. This allows us to approximately make every update under a Pareto descent direction, which provides ideal compensation for the minority classes. Our GBG method helps classes with similar gradient directions to form more representative gradients, providing better compensation for the tail classes.We conduct extensive experiments on commonly used benchmarks for long-tailed learning and show that our method outperforms existing state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="LAVSS-Location-Guided-Audio-Visual-Spatial-Audio-Separation"><a href="#LAVSS-Location-Guided-Audio-Visual-Spatial-Audio-Separation" class="headerlink" title="LAVSS: Location-Guided Audio-Visual Spatial Audio Separation"></a>LAVSS: Location-Guided Audio-Visual Spatial Audio Separation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20446">http://arxiv.org/abs/2310.20446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YYX666660/LAVSS">https://github.com/YYX666660/LAVSS</a></li>
<li>paper_authors: Yuxin Ye, Wenming Yang, Yapeng Tian</li>
<li>for: 这个研究的目的是将数位音频和视觉信息分离，以提高在虚拟和实际世界中的声音识别。</li>
<li>methods: 这个研究使用了一种名为LAVSS的位置导向的音频空间分离方法，它利用了空间音频和视觉位置之间的相互关联，并将这两个模式融合在一起，以提高声音分离的精度。</li>
<li>results: 实验结果显示，LAVSS比既有的对话音频分离方法（ benchmarks）有更高的分离精度，并且可以在虚拟和实际世界中提供更好的声音识别。<details>
<summary>Abstract</summary>
Existing machine learning research has achieved promising results in monaural audio-visual separation (MAVS). However, most MAVS methods purely consider what the sound source is, not where it is located. This can be a problem in VR/AR scenarios, where listeners need to be able to distinguish between similar audio sources located in different directions. To address this limitation, we have generalized MAVS to spatial audio separation and proposed LAVSS: a location-guided audio-visual spatial audio separator. LAVSS is inspired by the correlation between spatial audio and visual location. We introduce the phase difference carried by binaural audio as spatial cues, and we utilize positional representations of sounding objects as additional modality guidance. We also leverage multi-level cross-modal attention to perform visual-positional collaboration with audio features. In addition, we adopt a pre-trained monaural separator to transfer knowledge from rich mono sounds to boost spatial audio separation. This exploits the correlation between monaural and binaural channels. Experiments on the FAIR-Play dataset demonstrate the superiority of the proposed LAVSS over existing benchmarks of audio-visual separation. Our project page: https://yyx666660.github.io/LAVSS/.
</details>
<details>
<summary>摘要</summary>
现有机器学习研究已经取得了许多成果在声音单道视频分离（MAVS）领域。然而，大多数MAVS方法只考虑声音来源的性质，而不考虑其位置。这可能会成为VR/AR场景中的问题，因为听众需要能够在不同方向中分辨类似的声音来源。为解决这个限制，我们总结了MAVS，并提出了位置指导的声音视频空间分离器（LAVSS）。LAVSS灵感来自声音空间和视觉位置之间的相关性。我们引入了扬声器的相位差作为空间提示，并使用声音发生对象的位置表示来为其他模式提供导航。此外，我们利用多级跨模态注意力来进行视觉位置协作，并采用预训练的单道分离器来传递知识从丰富的单道声音中提高空间声音分离。实验结果表明，提出的LAVSS在FAIR-Play数据集上超过了现有的音视频分离标准。更多信息请访问我们的项目页面：https://yyx666660.github.io/LAVSS/.
</details></li>
</ul>
<hr>
<h2 id="SignAvatars-A-Large-scale-3D-Sign-Language-Holistic-Motion-Dataset-and-Benchmark"><a href="#SignAvatars-A-Large-scale-3D-Sign-Language-Holistic-Motion-Dataset-and-Benchmark" class="headerlink" title="SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark"></a>SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20436">http://arxiv.org/abs/2310.20436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengdi Yu, Shaoli Huang, Yongkang Cheng, Tolga Birdal<br>for: 这个论文是为了bridging the communication gap for hearing-impaired individuals，提供了一个大规模的多个提示3D手语动作数据集。methods: 这个论文使用了一个自动化的注释管道，将70,000个视频clip中的手语动作注释为3D描述和生物可靠的姿势。results: 这个论文提出了一个新的3D手语认识（SLR）和3D手语生产（SLP）任务，并提供了一个统一的比较标准，以评估SignAvatars数据集的潜在价值。<details>
<summary>Abstract</summary>
In this paper, we present SignAvatars, the first large-scale multi-prompt 3D sign language (SL) motion dataset designed to bridge the communication gap for hearing-impaired individuals. While there has been an exponentially growing number of research regarding digital communication, the majority of existing communication technologies primarily cater to spoken or written languages, instead of SL, the essential communication method for hearing-impaired communities. Existing SL datasets, dictionaries, and sign language production (SLP) methods are typically limited to 2D as the annotating 3D models and avatars for SL is usually an entirely manual and labor-intensive process conducted by SL experts, often resulting in unnatural avatars. In response to these challenges, we compile and curate the SignAvatars dataset, which comprises 70,000 videos from 153 signers, totaling 8.34 million frames, covering both isolated signs and continuous, co-articulated signs, with multiple prompts including HamNoSys, spoken language, and words. To yield 3D holistic annotations, including meshes and biomechanically-valid poses of body, hands, and face, as well as 2D and 3D keypoints, we introduce an automated annotation pipeline operating on our large corpus of SL videos. SignAvatars facilitates various tasks such as 3D sign language recognition (SLR) and the novel 3D SL production (SLP) from diverse inputs like text scripts, individual words, and HamNoSys notation. Hence, to evaluate the potential of SignAvatars, we further propose a unified benchmark of 3D SL holistic motion production. We believe that this work is a significant step forward towards bringing the digital world to the hearing-impaired communities. Our project page is at https://signavatars.github.io/
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍SignAvatars，首个大规模多提示3D手语（SL）动作数据集，旨在bridging通信差距 для听力受限人群。 existing的数字通信技术主要服务于口语或文字语言，而不是SL，听力受限社区的基本通信方式。现有的SL数据集、字典和手语生产（SLP）方法通常是2D的，因为annotating 3D模型和人物 дляSL是一个完全手动和劳动密集的过程，通常导致不自然的人物。为解决这些挑战，我们编译和筛选了SignAvatars数据集，包括70,000个视频，共计8.34万帧，覆盖了隔离的手语和连续、相关的手语，以及多个提示，包括汉诺斯语言、口语和单词。为了生成3D全息注解，包括身体、手部和面部的生物准确姿势，以及2D和3D关键点，我们引入了一个自动化注解管道，运行在我们的大量SL视频库中。SignAvatars可以支持多种任务，如3D手语识别（SLR）和基于多种输入的3D SL生产（SLP）。因此，为评估SignAvatars的潜力，我们进一步提出了一个统一的3D SL全息动作生产benchmark。我们认为这项工作是听力受限社区的数字化进程的重要一步。我们的项目页面位于<https://signavatars.github.io/>.
</details></li>
</ul>
<hr>
<h2 id="Assessing-and-Enhancing-Robustness-of-Deep-Learning-Models-with-Corruption-Emulation-in-Digital-Pathology"><a href="#Assessing-and-Enhancing-Robustness-of-Deep-Learning-Models-with-Corruption-Emulation-in-Digital-Pathology" class="headerlink" title="Assessing and Enhancing Robustness of Deep Learning Models with Corruption Emulation in Digital Pathology"></a>Assessing and Enhancing Robustness of Deep Learning Models with Corruption Emulation in Digital Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20427">http://arxiv.org/abs/2310.20427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peixiang Huang, Songtao Zhang, Yulu Gan, Rui Xu, Rongqi Zhu, Wenkang Qin, Limei Guo, Shan Jiang, Lin Luo</li>
<li>for:  This paper aims to improve the robustness of deep learning models in digital pathology by analyzing and emulating various image corruptions throughout the pathological life-cycle.</li>
<li>methods: The authors propose an Omni-Corruption Emulation (OmniCE) method to reproduce 21 types of corruptions quantified with 5-level severity, and use these corrupted datasets to assess the robustness of popular deep neural network (DNN) models in classification and segmentation tasks.</li>
<li>results: The authors show that the OmniCE-corrupted datasets can significantly enhance the generalization ability of DNN models, and that using these datasets as augmentation data for training and experiments can improve the models’ robustness in clinical diagnosis.<details>
<summary>Abstract</summary>
Deep learning in digital pathology brings intelligence and automation as substantial enhancements to pathological analysis, the gold standard of clinical diagnosis. However, multiple steps from tissue preparation to slide imaging introduce various image corruptions, making it difficult for deep neural network (DNN) models to achieve stable diagnostic results for clinical use. In order to assess and further enhance the robustness of the models, we analyze the physical causes of the full-stack corruptions throughout the pathological life-cycle and propose an Omni-Corruption Emulation (OmniCE) method to reproduce 21 types of corruptions quantified with 5-level severity. We then construct three OmniCE-corrupted benchmark datasets at both patch level and slide level and assess the robustness of popular DNNs in classification and segmentation tasks. Further, we explore to use the OmniCE-corrupted datasets as augmentation data for training and experiments to verify that the generalization ability of the models has been significantly enhanced.
</details>
<details>
<summary>摘要</summary>
深度学习在数字 PATHOLOGY 中带来智能和自动化作为诊断标准的重要丰富。然而，从组织准备到滤镜影像的多个步骤引入了多种图像损害，使得深度神经网络（DNN）模型难以在临床使用中实现稳定的诊断结果。为了评估和进一步增强模型的Robustness，我们分析了 PATHOLOGY 生命周期中全栈损害的物理原因，并提出了 Omni-Corruption Emulation（OmniCE）方法来模拟21种损害，并将其分为5级严重性。然后，我们构建了3个OmniCE-损害的 referential dataset，并对popular DNN进行了分类和 segmentation 任务中的评估。此外，我们还探索使用 OmniCE-损害的数据进行训练和实验，以验证模型的普适性得到了显著提高。
</details></li>
</ul>
<hr>
<h2 id="Thermal-Infrared-Remote-Target-Detection-System-for-Maritime-Rescue-based-on-Data-Augmentation-with-3D-Synthetic-Data"><a href="#Thermal-Infrared-Remote-Target-Detection-System-for-Maritime-Rescue-based-on-Data-Augmentation-with-3D-Synthetic-Data" class="headerlink" title="Thermal-Infrared Remote Target Detection System for Maritime Rescue based on Data Augmentation with 3D Synthetic Data"></a>Thermal-Infrared Remote Target Detection System for Maritime Rescue based on Data Augmentation with 3D Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20412">http://arxiv.org/abs/2310.20412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungjin Cheong, Wonho Jung, Yoon Seop Lim, Yong-Hwa Park</li>
<li>for: 这个论文旨在提出一种基于深度学习和数据扩展的海上搜救thermal-infrared（TIR）远程目标检测系统。</li>
<li>methods: 论文使用了深度学习和数据扩展技术，并建立了自己的TIR数据集，以及使用3D游戏（ARMA3）生成的 sintethic TIR数据集来增强模型的可靠性和robustness。</li>
<li>results: 实验结果表明，使用扩展数据集和提出的领域适应算法，论文提出的网络在远程TIR检测中表现出色，并且超过了基于实际TIR数据进行训练的网络的性能。<details>
<summary>Abstract</summary>
This paper proposes a thermal-infrared (TIR) remote target detection system for maritime rescue using deep learning and data augmentation. We established a self-collected TIR dataset consisting of multiple scenes imitating human rescue situations using a TIR camera (FLIR). Additionally, to address dataset scarcity and improve model robustness, a synthetic dataset from a 3D game (ARMA3) to augment the data is further collected. However, a significant domain gap exists between synthetic TIR and real TIR images. Hence, a proper domain adaptation algorithm is essential to overcome the gap. Therefore, we suggest a domain adaptation algorithm in a target-background separated manner from 3D game-to-real, based on a generative model, to address this issue. Furthermore, a segmentation network with fixed-weight kernels at the head is proposed to improve the signal-to-noise ratio (SNR) and provide weak attention, as remote TIR targets inherently suffer from unclear boundaries. Experiment results reveal that the network trained on augmented data consisting of translated synthetic and real TIR data outperforms that trained on only real TIR data by a large margin. Furthermore, the proposed segmentation model surpasses the performance of state-of-the-art segmentation methods.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="High-Resolution-Reference-Image-Assisted-Volumetric-Super-Resolution-of-Cardiac-Diffusion-Weighted-Imaging"><a href="#High-Resolution-Reference-Image-Assisted-Volumetric-Super-Resolution-of-Cardiac-Diffusion-Weighted-Imaging" class="headerlink" title="High-Resolution Reference Image Assisted Volumetric Super-Resolution of Cardiac Diffusion Weighted Imaging"></a>High-Resolution Reference Image Assisted Volumetric Super-Resolution of Cardiac Diffusion Weighted Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20389">http://arxiv.org/abs/2310.20389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinzhe Wu, Jiahao Huang, Fanwen Wang, Pedro Ferreira, Andrew Scott, Sonia Nielles-Vallespin, Guang Yang<br>for: 这个研究的目的是提高DT-CMR的图像质量，以便更好地检测心脏微结构。methods: 这个研究使用深度学习方法来提高DT-CMR图像的质量，并采用了高分辨率参照图像作为输入。results: 研究表明，通过使用高分辨率参照图像，可以提高DT-CMR图像的质量，并且模型可以将这种提高应用于未看过的b值。<details>
<summary>Abstract</summary>
Diffusion Tensor Cardiac Magnetic Resonance (DT-CMR) is the only in vivo method to non-invasively examine the microstructure of the human heart. Current research in DT-CMR aims to improve the understanding of how the cardiac microstructure relates to the macroscopic function of the healthy heart as well as how microstructural dysfunction contributes to disease. To get the final DT-CMR metrics, we need to acquire diffusion weighted images of at least 6 directions. However, due to DWI's low signal-to-noise ratio, the standard voxel size is quite big on the scale for microstructures. In this study, we explored the potential of deep-learning-based methods in improving the image quality volumetrically (x4 in all dimensions). This study proposed a novel framework to enable volumetric super-resolution, with an additional model input of high-resolution b0 DWI. We demonstrated that the additional input could offer higher super-resolved image quality. Going beyond, the model is also able to super-resolve DWIs of unseen b-values, proving the model framework's generalizability for cardiac DWI superresolution. In conclusion, we would then recommend giving the model a high-resolution reference image as an additional input to the low-resolution image for training and inference to guide all super-resolution frameworks for parametric imaging where a reference image is available.
</details>
<details>
<summary>摘要</summary>
Diffusion Tensor Cardiac Magnetic Resonance (DT-CMR) 是人体心脏内部非侵入性地检测微结构的唯一方法。当前研究的目标是通过改进心脏微结构与健康心脏的宏观功能之间的关系来更好地理解心脏疾病的起源。为了获得最终的 DT-CMR 度量，我们需要获取至少6个方向的扩散束图像。然而，由于 DWI 的信号噪声比较低，标准 vozeld 大小很大，这限制了我们对微结构的检测。在这种情况下，我们 investigate 了深度学习技术可以改进图像质量的可能性。我们提出了一种新的框架，可以在所有维度上进行扩散超分辨率。这种框架具有一个额外输入，即高分辨率的 b0 DWI。我们 demonstarted 了这个额外输入可以提供更高的超分辨率图像质量。此外，模型还可以对不同的 b-值 DWI 进行超分辨率，证明了模型框架的普适性。因此，我们建议在训练和推断过程中给模型一个高分辨率参考图像作为额外输入，以提高所有超分辨率框架的性能。
</details></li>
</ul>
<hr>
<h2 id="A-Low-cost-Strategic-Monitoring-Approach-for-Scalable-and-Interpretable-Error-Detection-in-Deep-Neural-Networks"><a href="#A-Low-cost-Strategic-Monitoring-Approach-for-Scalable-and-Interpretable-Error-Detection-in-Deep-Neural-Networks" class="headerlink" title="A Low-cost Strategic Monitoring Approach for Scalable and Interpretable Error Detection in Deep Neural Networks"></a>A Low-cost Strategic Monitoring Approach for Scalable and Interpretable Error Detection in Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20349">http://arxiv.org/abs/2310.20349</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian Geissler, Syed Qutub, Michael Paulitsch, Karthik Pattabiraman</li>
<li>for: This paper is written for detecting silent data corruption in deep computer vision networks, specifically targeting hardware memory and input faults.</li>
<li>methods: The approach uses strategically placed quantile markers to estimate the anomaly of the current inference and achieve accurate detection. The detector component is designed to be algorithmically transparent, allowing for interpretable results.</li>
<li>results: The approach achieves high precision (up to ~96%) and recall (up to ~98%) of detection, with minimal compute overhead (as little as 0.3% of non-supervised inference time).<details>
<summary>Abstract</summary>
We present a highly compact run-time monitoring approach for deep computer vision networks that extracts selected knowledge from only a few (down to merely two) hidden layers, yet can efficiently detect silent data corruption originating from both hardware memory and input faults. Building on the insight that critical faults typically manifest as peak or bulk shifts in the activation distribution of the affected network layers, we use strategically placed quantile markers to make accurate estimates about the anomaly of the current inference as a whole. Importantly, the detector component itself is kept algorithmically transparent to render the categorization of regular and abnormal behavior interpretable to a human. Our technique achieves up to ~96% precision and ~98% recall of detection. Compared to state-of-the-art anomaly detection techniques, this approach requires minimal compute overhead (as little as 0.3% with respect to non-supervised inference time) and contributes to the explainability of the model.
</details>
<details>
<summary>摘要</summary>
我们提出了一种高度优化的执行时间监控方法，用于深度电脑视觉网络中检测静默的数据腐败。我们从只有几个（或甚至只有两个）隐藏层中提取了选择性的知识，但可以高效地检测硬件内存和输入错误所引起的数据腐败。我们建立在当前网络层的活化分布中的峰值或块状变化通常是重要错误的内容。我们使用策略性地置标的方法来对应该些变化，并使用算法透明的检测器部分，以便让错误的分类成为人类可解释的。我们的方法可以实现约96%的精度和约98%的回归检测。与现有的偏常检测技术相比，我们的方法需要的计算负载非常低（只有0.3%相对于非监控时间），并且增加了模型的解释性。
</details></li>
</ul>
<hr>
<h2 id="Class-Incremental-Learning-with-Pre-trained-Vision-Language-Models"><a href="#Class-Incremental-Learning-with-Pre-trained-Vision-Language-Models" class="headerlink" title="Class Incremental Learning with Pre-trained Vision-Language Models"></a>Class Incremental Learning with Pre-trained Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20348">http://arxiv.org/abs/2310.20348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xialei Liu, Xusheng Cao, Haori Lu, Jia-wen Xiao, Andrew D. Bagdanov, Ming-Ming Cheng</li>
<li>for: This paper is written for those interested in adapting and exploiting large-scale pre-trained models, specifically vision-language models like CLIP, for continual learning scenarios.</li>
<li>methods: The paper proposes an approach to adapting pre-trained vision-language models for new tasks by adding additional layers after the Image Encoder or before the Text Encoder. The authors investigate three different strategies: Linear Adapter, Self-attention Adapter, and Prompt Tuning. They also propose a method for parameter retention in the adapter layers to maintain stability and plasticity during incremental learning.</li>
<li>results: The paper demonstrates significant improvement over the current state-of-the-art on several conventional benchmarks with the simplest solution of a single Linear Adapter layer and parameter retention. The results show that the proposed approach can improve the performance of continual learning with pre-trained vision-language models.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了探讨和利用大规模预训练模型，特别是视觉语言模型clip，在持续学习场景下的适应和利用。</li>
<li>methods: 论文提出了一种适应预训练视觉语言模型的方法，包括在图像编码器后加入额外层或在文本编码器前加入额外层。 authors investigate了三种不同的策略：线性适应、自我注意适应和提示调整。 authors还提出了一种参数保留方法来保持稳定性和 пластичность。</li>
<li>results: 论文的实验结果表明，使用单个线性适应层和参数保留方法可以减少现有状态的训练时间。 results表明，该方法可以在持续学习场景下提高预训练视觉语言模型的性能。<details>
<summary>Abstract</summary>
With the advent of large-scale pre-trained models, interest in adapting and exploiting them for continual learning scenarios has grown.   In this paper, we propose an approach to exploiting pre-trained vision-language models (e.g. CLIP) that enables further adaptation instead of only using zero-shot learning of new tasks. We augment a pre-trained CLIP model with additional layers after the Image Encoder or before the Text Encoder. We investigate three different strategies: a Linear Adapter, a Self-attention Adapter, each operating on the image embedding, and Prompt Tuning which instead modifies prompts input to the CLIP text encoder. We also propose a method for parameter retention in the adapter layers that uses a measure of parameter importance to better maintain stability and plasticity during incremental learning. Our experiments demonstrate that the simplest solution -- a single Linear Adapter layer with parameter retention -- produces the best results. Experiments on several conventional benchmarks consistently show a significant margin of improvement over the current state-of-the-art.
</details>
<details>
<summary>摘要</summary>
We augment a pre-trained CLIP model with additional layers after the Image Encoder or before the Text Encoder. We investigate three different strategies: a Linear Adapter, a Self-attention Adapter, and Prompt Tuning, each of which operates on the image embedding. Additionally, we propose a method for parameter retention in the adapter layers that uses a measure of parameter importance to maintain stability and plasticity during incremental learning.Our experiments show that the simplest solution, a single Linear Adapter layer with parameter retention, produces the best results. We consistently achieve a significant margin of improvement over the current state-of-the-art on several conventional benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Recaptured-Raw-Screen-Image-and-Video-Demoireing-via-Channel-and-Spatial-Modulations"><a href="#Recaptured-Raw-Screen-Image-and-Video-Demoireing-via-Channel-and-Spatial-Modulations" class="headerlink" title="Recaptured Raw Screen Image and Video Demoiréing via Channel and Spatial Modulations"></a>Recaptured Raw Screen Image and Video Demoiréing via Channel and Spatial Modulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20332">http://arxiv.org/abs/2310.20332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tju-chengyijia/vd_raw">https://github.com/tju-chengyijia/vd_raw</a></li>
<li>paper_authors: Huanjing Yue, Yijia Cheng, Xin Liu, Jingyu Yang</li>
<li>for: 这篇论文的目的是提出一种针对原始输入进行图像和视频抑制蛇纹网络。</li>
<li>methods: 该方法使用了一种新的色彩分离特征分支，并将其与传统的特征混合分支进行拼接，通过通道和空间调制来增强特征。</li>
<li>results: 实验表明，该方法可以在图像和视频抑制蛇纹方面达到状态 искусственный智能的性能。 codes和数据集在<a target="_blank" rel="noopener" href="https://github.com/tju-chengyijia/VD_raw%E4%B8%AD%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/tju-chengyijia/VD_raw中发布。</a><details>
<summary>Abstract</summary>
Capturing screen contents by smartphone cameras has become a common way for information sharing. However, these images and videos are often degraded by moir\'e patterns, which are caused by frequency aliasing between the camera filter array and digital display grids. We observe that the moir\'e patterns in raw domain is simpler than those in sRGB domain, and the moir\'e patterns in raw color channels have different properties. Therefore, we propose an image and video demoir\'eing network tailored for raw inputs. We introduce a color-separated feature branch, and it is fused with the traditional feature-mixed branch via channel and spatial modulations. Specifically, the channel modulation utilizes modulated color-separated features to enhance the color-mixed features. The spatial modulation utilizes the feature with large receptive field to modulate the feature with small receptive field. In addition, we build the first well-aligned raw video demoir\'eing (RawVDemoir\'e) dataset and propose an efficient temporal alignment method by inserting alternating patterns. Experiments demonstrate that our method achieves state-of-the-art performance for both image and video demori\'eing. We have released the code and dataset in https://github.com/tju-chengyijia/VD_raw.
</details>
<details>
<summary>摘要</summary>
抓取屏幕内容通过智能手机摄像头已成为常见的信息分享方式。然而，这些图像和视频经常受到频率扭曲的影响，导致图像和视频中出现质量下降的问题。我们发现 raw 频谱中的扭曲 Pattern 比 sRGB 频谱中的更简单，raw 频谱中的扭曲 Pattern 也有不同的特性。因此，我们提出一种针对 raw 输入的图像和视频抗扭曲网络。我们添加了一个分割色彩的特征分支，并将其与传统的特征混合分支进行混合，通过通道和空间模拟来实现。具体来说，通道模拟利用模拟的色彩分割特征来增强混合的色彩特征。空间模拟利用具有大覆盖面积的特征来模拟具有小覆盖面积的特征。此外，我们建立了首个Well-Aligned Raw Video Demoir\'e（RawVDemoir\'e）数据集，并提出了高效的时间对齐方法，通过插入交替 patrern 来实现。实验表明，我们的方法可以在图像和视频抗扭曲方面达到状态畅的性能。我们已经在 GitHub 上发布了代码和数据集，请参考 <https://github.com/tju-chengyijia/VD_raw>。
</details></li>
</ul>
<hr>
<h2 id="GACE-Geometry-Aware-Confidence-Enhancement-for-Black-Box-3D-Object-Detectors-on-LiDAR-Data"><a href="#GACE-Geometry-Aware-Confidence-Enhancement-for-Black-Box-3D-Object-Detectors-on-LiDAR-Data" class="headerlink" title="GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data"></a>GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20319">http://arxiv.org/abs/2310.20319</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dschinagl/gace">https://github.com/dschinagl/gace</a></li>
<li>paper_authors: David Schinagl, Georg Krispel, Christian Fruhwirth-Reisinger, Horst Possegger, Horst Bischof</li>
<li>for: 提高黑盒子3D物体探测器的可信度评估</li>
<li>methods: 聚合检测结果的几何信息和空间关系，以改进可信度评估</li>
<li>results: 对多种状态对象探测器进行了实质性的性能提升，尤其是敏感路用户类（行人和自行车）<details>
<summary>Abstract</summary>
Widely-used LiDAR-based 3D object detectors often neglect fundamental geometric information readily available from the object proposals in their confidence estimation. This is mostly due to architectural design choices, which were often adopted from the 2D image domain, where geometric context is rarely available. In 3D, however, considering the object properties and its surroundings in a holistic way is important to distinguish between true and false positive detections, e.g. occluded pedestrians in a group. To address this, we present GACE, an intuitive and highly efficient method to improve the confidence estimation of a given black-box 3D object detector. We aggregate geometric cues of detections and their spatial relationships, which enables us to properly assess their plausibility and consequently, improve the confidence estimation. This leads to consistent performance gains over a variety of state-of-the-art detectors. Across all evaluated detectors, GACE proves to be especially beneficial for the vulnerable road user classes, i.e. pedestrians and cyclists.
</details>
<details>
<summary>摘要</summary>
广泛使用LiDAR基于的3D物体探测器经常忽略可用的基本 геометрические信息，这主要是因为架构设计选择，通常是从2D图像领域采用的，在这里，基本上没有地理上的信息。然而，在3D中，考虑物体属性和其周围环境的整体方式是重要的，以分辨真实和假阳性探测，例如受阻的行人在群体中。为解决这个问题，我们提出了GACE，一种直观和高效的方法，用于改善给定黑盒3D物体探测器的信任度估计。我们将探测结果的几何信息和其空间关系聚合起来，以确定它们的可能性，从而改善信任度估计。这导致了多种状态对应的性能提升。对于许多状态对应的检测器，GACE表现出特别的有利效果，即车辆和行人等护理用户类型。
</details></li>
</ul>
<hr>
<h2 id="HWD-A-Novel-Evaluation-Score-for-Styled-Handwritten-Text-Generation"><a href="#HWD-A-Novel-Evaluation-Score-for-Styled-Handwritten-Text-Generation" class="headerlink" title="HWD: A Novel Evaluation Score for Styled Handwritten Text Generation"></a>HWD: A Novel Evaluation Score for Styled Handwritten Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20316">http://arxiv.org/abs/2310.20316</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/hwd">https://github.com/aimagelab/hwd</a></li>
<li>paper_authors: Vittorio Pippi, Fabio Quattrini, Silvia Cascianelli, Rita Cucchiara</li>
<li>for: 本研究旨在提供一个有效的评估手写文本生成（Styled HTG）模型表现的指标，以促进这个研究领域的发展。</li>
<li>methods: 我们提出了一种特定于HTG评估的评价指标——手写距离（HWD），基于一个专门为提取手写风格特征而训练的网络。HWD在变长输入图像的特征空间中工作，利用感知距离来比较手写中细小的几何特征。</li>
<li>results: 我们通过对不同的单词水平和行水平的手写文本图像数据进行广泛的实验评估，证明了提出的HWD是一个适合的Styled HTG评价指标。我们还将预训练的模型作为后向抽象，以便推广该指标的使用，以便为Styled HTG评价模型的研究提供一个有用的工具。<details>
<summary>Abstract</summary>
Styled Handwritten Text Generation (Styled HTG) is an important task in document analysis, aiming to generate text images with the handwriting of given reference images. In recent years, there has been significant progress in the development of deep learning models for tackling this task. Being able to measure the performance of HTG models via a meaningful and representative criterion is key for fostering the development of this research topic. However, despite the current adoption of scores for natural image generation evaluation, assessing the quality of generated handwriting remains challenging. In light of this, we devise the Handwriting Distance (HWD), tailored for HTG evaluation. In particular, it works in the feature space of a network specifically trained to extract handwriting style features from the variable-lenght input images and exploits a perceptual distance to compare the subtle geometric features of handwriting. Through extensive experimental evaluation on different word-level and line-level datasets of handwritten text images, we demonstrate the suitability of the proposed HWD as a score for Styled HTG. The pretrained model used as backbone will be released to ease the adoption of the score, aiming to provide a valuable tool for evaluating HTG models and thus contributing to advancing this important research area.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文<</SYS>>模仿手写文本生成（Styled HTG）是文档分析中的一项重要任务，目标是生成与参考图像的手写风格相同的文本图像。在过去几年，深度学习模型在解决这个任务上做出了 significiant 的进步。可以通过一个有意义和代表性的评价标准来衡量 HTG 模型的性能，这对于推动这个研究领域的发展是关键。然而，自然图像生成评价 scores 的当前采用不适用于 HTG 评价。为了解决这个问题，我们提出了 Handwriting Distance（HWD），专门为 HTG 评价设计的。具体来说，它在特定的网络中提取手写风格特征，并利用一种感知距离来比较手写文本中细微的几何特征。经过对不同的单词级和行级手写文本图像集进行广泛的实验评价，我们证明了我们提出的 HWD 是一个适合的 HTG 评价分数。我们将提供特定的预训练模型，以便推广 HWD，以便为 HTG 模型的评价提供一个有价值的工具，从而为这一重要研究领域的发展做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Bilateral-Network-with-Residual-U-blocks-and-Dual-Guided-Attention-for-Real-time-Semantic-Segmentation"><a href="#Bilateral-Network-with-Residual-U-blocks-and-Dual-Guided-Attention-for-Real-time-Semantic-Segmentation" class="headerlink" title="Bilateral Network with Residual U-blocks and Dual-Guided Attention for Real-time Semantic Segmentation"></a>Bilateral Network with Residual U-blocks and Dual-Guided Attention for Real-time Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20305">http://arxiv.org/abs/2310.20305</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/likelidoa/bidganet">https://github.com/likelidoa/bidganet</a></li>
<li>paper_authors: Liang Liao, Liang Wan, Mingsheng Liu, Shusheng Li</li>
<li>for: 自动驾驶等应用场景需要使用semantic segmentation技术，即时性的要求更高于精度。两分支架构在当今年代得到了广泛应用，它将空间信息和semantic信息分开处理，使得模型可以采用两个较轻量级的网络组成。但是，将特征Feature fusion成为现在许多两分支模型的性能瓶颈。</li>
<li>methods: 我们提出了一种新的特征合并机制，即通过注意计算引导的Dual-Guided Attention（DGA）模块来取代一些多缘转换。我们只使用几个注意层来实现与多层融合相比的性能，而不是使用许多的多缘转换。</li>
<li>results: 我们通过Cityscapes和CamVid dataset进行了广泛的实验，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
When some application scenarios need to use semantic segmentation technology, like automatic driving, the primary concern comes to real-time performance rather than extremely high segmentation accuracy. To achieve a good trade-off between speed and accuracy, two-branch architecture has been proposed in recent years. It treats spatial information and semantics information separately which allows the model to be composed of two networks both not heavy. However, the process of fusing features with two different scales becomes a performance bottleneck for many nowaday two-branch models. In this research, we design a new fusion mechanism for two-branch architecture which is guided by attention computation. To be precise, we use the Dual-Guided Attention (DGA) module we proposed to replace some multi-scale transformations with the calculation of attention which means we only use several attention layers of near linear complexity to achieve performance comparable to frequently-used multi-layer fusion. To ensure that our module can be effective, we use Residual U-blocks (RSU) to build one of the two branches in our networks which aims to obtain better multi-scale features. Extensive experiments on Cityscapes and CamVid dataset show the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
In this research, we propose a new fusion mechanism for two-branch architecture that is guided by attention computation. Specifically, we use the Dual-Guided Attention (DGA) module to replace some multi-scale transformations with attention calculations, which allows us to achieve performance comparable to frequently-used multi-layer fusion with a much simpler and more efficient approach. To ensure the effectiveness of our module, we use Residual U-blocks (RSU) to build one of the two branches in our network, which helps to obtain better multi-scale features.Extensive experiments on the Cityscapes and CamVid datasets demonstrate the effectiveness of our method. By using the DGA module and RSU, we are able to achieve a good balance between speed and accuracy in semantic segmentation, which is essential for many real-world applications such as automatic driving.
</details></li>
</ul>
<hr>
<h2 id="Annotator-A-Generic-Active-Learning-Baseline-for-LiDAR-Semantic-Segmentation"><a href="#Annotator-A-Generic-Active-Learning-Baseline-for-LiDAR-Semantic-Segmentation" class="headerlink" title="Annotator: A Generic Active Learning Baseline for LiDAR Semantic Segmentation"></a>Annotator: A Generic Active Learning Baseline for LiDAR Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20293">http://arxiv.org/abs/2310.20293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Binhui Xie, Shuang Li, Qingju Guo, Chi Harold Liu, Xinjing Cheng</li>
<li>for: 这个论文的目的是提出一种高效的活动学习基线，用于三角点云 semantic segmentation 任务，以便更有效地使用标注数据。</li>
<li>methods: 这个基eline使用了一种基于 voxel 的在线选择策略，可以高效地探索和标注 LiDAR 扫描数据中的关键和示例 voxel 网格。它还使用了 voxel 冲突度 (VCD) 来利用点云的本地拓扑关系和结构。</li>
<li>results: 这个基eline在多种任务中表现出色，包括活动学习 (AL)、活动源自由领域适应 (ASFDA) 和活动领域适应 (ADA)。它在多个 LiDAR semantic segmentation benchmark 上达到了高水平的性能，包括从 simulate 到实际的 scenario 以及实际 scenario 之间的比较。特别是，Annotator 只需要标注每个 LiDAR 扫描数据中的五个 voxel，可以达到87.8% 的全supervised 性能 under AL，88.5% under ASFDA，和94.4% under ADA。<details>
<summary>Abstract</summary>
Active learning, a label-efficient paradigm, empowers models to interactively query an oracle for labeling new data. In the realm of LiDAR semantic segmentation, the challenges stem from the sheer volume of point clouds, rendering annotation labor-intensive and cost-prohibitive. This paper presents Annotator, a general and efficient active learning baseline, in which a voxel-centric online selection strategy is tailored to efficiently probe and annotate the salient and exemplar voxel girds within each LiDAR scan, even under distribution shift. Concretely, we first execute an in-depth analysis of several common selection strategies such as Random, Entropy, Margin, and then develop voxel confusion degree (VCD) to exploit the local topology relations and structures of point clouds. Annotator excels in diverse settings, with a particular focus on active learning (AL), active source-free domain adaptation (ASFDA), and active domain adaptation (ADA). It consistently delivers exceptional performance across LiDAR semantic segmentation benchmarks, spanning both simulation-to-real and real-to-real scenarios. Surprisingly, Annotator exhibits remarkable efficiency, requiring significantly fewer annotations, e.g., just labeling five voxels per scan in the SynLiDAR-to-SemanticKITTI task. This results in impressive performance, achieving 87.8% fully-supervised performance under AL, 88.5% under ASFDA, and 94.4% under ADA. We envision that Annotator will offer a simple, general, and efficient solution for label-efficient 3D applications. Project page: https://binhuixie.github.io/annotator-web
</details>
<details>
<summary>摘要</summary>
aktive lärmung, ein label-effizientes Paradigma, ermöglicht Modellen, interaktiv einen Oracle für die Labeling neuer Daten zu befragen. In der Welt von LiDAR-semantischen Segmentierung gibt es Herausforderungen durch die enorme Menge an Punktwolken, die das Annotieren aufwendig und kostspielig machen. Diese Arbeit präsentiert Annotator, eine allgemeine und effiziente aktive lärmung-Basis, bei der eine voxel-zentrische online-Auswahlstrategie entwickelt wurde, um effizient die salienten und exemplarischen voxel-Gitter within each LiDAR-Scans zu probieren und zu annotieren, auch unter Veränderung der Verteilung.Concretely, we first analyze several common selection strategies such as Random, Entropy, Margin, and then develop voxel confusion degree (VCD) to exploit the local topology relations and structures of point clouds. Annotator excels in diverse settings, with a particular focus on aktive lärmung (AL), active source-free domain adaptation (ASFDA), and active domain adaptation (ADA). It consistently delivers exceptional performance across LiDAR semantic segmentation benchmarks, spanning both simulation-to-real and real-to-real scenarios. Surprisingly, Annotator exhibits remarkable efficiency, requiring significantly fewer annotations, e.g., just labeling five voxels per scan in the SynLiDAR-to-SemanticKITTI task. This results in impressive performance, achieving 87.8% fully-supervised performance under AL, 88.5% under ASFDA, and 94.4% under ADA. We envision that Annotator will offer a simple, general, and efficient solution for label-efficient 3D applications. Project page: <https://binhuixie.github.io/annotator-web>
</details></li>
</ul>
<hr>
<h2 id="IARS-SegNet-Interpretable-Attention-Residual-Skip-connection-SegNet-for-melanoma-segmentation"><a href="#IARS-SegNet-Interpretable-Attention-Residual-Skip-connection-SegNet-for-melanoma-segmentation" class="headerlink" title="IARS SegNet: Interpretable Attention Residual Skip connection SegNet for melanoma segmentation"></a>IARS SegNet: Interpretable Attention Residual Skip connection SegNet for melanoma segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20292">http://arxiv.org/abs/2310.20292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shankara Narayanan V, Sikha OK, Raul Benitez</li>
<li>for: 革新的皮肤 lesion 分割方法，帮助早期诊断皮肤癌</li>
<li>methods: 基于 SegNet 基础模型，添加了 skip connections、residual convolutions 和全局注意力机制，提高模型的解释性和精度</li>
<li>results: 提高了皮肤 lesion 分割精度，帮助早期诊断皮肤癌<details>
<summary>Abstract</summary>
Skin lesion segmentation plays a crucial role in the computer-aided diagnosis of melanoma. Deep Learning models have shown promise in accurately segmenting skin lesions, but their widespread adoption in real-life clinical settings is hindered by their inherent black-box nature. In domains as critical as healthcare, interpretability is not merely a feature but a fundamental requirement for model adoption. This paper proposes IARS SegNet an advanced segmentation framework built upon the SegNet baseline model. Our approach incorporates three critical components: Skip connections, residual convolutions, and a global attention mechanism onto the baseline Segnet architecture. These elements play a pivotal role in accentuating the significance of clinically relevant regions, particularly the contours of skin lesions. The inclusion of skip connections enhances the model's capacity to learn intricate contour details, while the use of residual convolutions allows for the construction of a deeper model while preserving essential image features. The global attention mechanism further contributes by extracting refined feature maps from each convolutional and deconvolutional block, thereby elevating the model's interpretability. This enhancement highlights critical regions, fosters better understanding, and leads to more accurate skin lesion segmentation for melanoma diagnosis.
</details>
<details>
<summary>摘要</summary>
皮肤损害分割在计算机辅助诊断癌症中扮演着关键性的角色。深度学习模型在精准地分割皮肤损害方面表现出了承诺，但是它们在实际医疗设置中广泛应用的阻碍因素之一是它们的内在的黑盒特性。在医疗领域中，可解释性不仅是一个特性，而是基本要求。这篇论文提出了IARS SegNet，一个高级分割框架，基于SegNet基础模型。我们的方法包括三个关键组件：跳过连接、径远 convolution 和全球注意力机制。这些元素在突出临床有关的区域，特别是皮肤损害的边缘方面发挥着关键作用。跳过连接使得模型学习细节，径远 convolution 使得模型深度化，全球注意力机制则提取了每个卷积和反卷积块中的精细特征图，从而提高模型的可解释性。这种改进使得模型更好地理解皮肤损害的重要区域，提高了诊断的准确性。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-refinement-of-in-situ-images-acquired-by-low-electron-dose-LC-TEM"><a href="#Machine-learning-refinement-of-in-situ-images-acquired-by-low-electron-dose-LC-TEM" class="headerlink" title="Machine learning refinement of in situ images acquired by low electron dose LC-TEM"></a>Machine learning refinement of in situ images acquired by low electron dose LC-TEM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20279">http://arxiv.org/abs/2310.20279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hiroyasu Katsuno, Yuki Kimura, Tomoya Yamazaki, Ichigaku Takigawa</li>
<li>for: 这篇论文是用于提高liquid-cell transmission electron microscopy（LC-TEM）中的图像精度的机器学习（ML）技术。</li>
<li>methods: 该模型使用U-Net架构和ResNetEncoder构建，并使用了一个自制的图像集来进行训练。图像集包括了不同的放大度和电子剂量下的样品图像对。</li>
<li>results: 训练后的模型可以将噪声图像转换成清晰图像，转换时间约为10ms。通过该模型，在Gatan DigitalMicrograph（DM）软件中不可见的 nanoparticle 在视窗中可以被成功地显示出来。<details>
<summary>Abstract</summary>
We study a machine learning (ML) technique for refining images acquired during in situ observation using liquid-cell transmission electron microscopy (LC-TEM). Our model is constructed using a U-Net architecture and a ResNet encoder. For training our ML model, we prepared an original image dataset that contained pairs of images of samples acquired with and without a solution present. The former images were used as noisy images and the latter images were used as corresponding ground truth images. The number of pairs of image sets was $1,204$ and the image sets included images acquired at several different magnifications and electron doses. The trained model converted a noisy image into a clear image. The time necessary for the conversion was on the order of 10ms, and we applied the model to in situ observations using the software Gatan DigitalMicrograph (DM). Even if a nanoparticle was not visible in a view window in the DM software because of the low electron dose, it was visible in a successive refined image generated by our ML model.
</details>
<details>
<summary>摘要</summary>
我们研究一种机器学习（ML）技术，用于对具有液体环境的电子顾问显微镜（LC-TEM）获得的图像进行精炼。我们的模型采用了U-Net架构和ResNet编码器。为了训练我们的ML模型，我们准备了一个原始图像集，其中包含了具有和无解方辑物质存在的图像对。前者用于含噪图像，后者用于相应的真实图像。该集共包含1,204对图像集，其中包括了不同的放大率和电子剂量下的图像。训练模型可以将含噪图像转化为清晰图像，转化时间在10ms左右，并且我们将模型应用到了使用软件Gatan DigitalMicrograph（DM）进行的境内观测。即使在DM软件中的视窗中没有显示nanoparticle因为低电子剂量，我们的ML模型仍可以在Successive Refined Image中显示它。
</details></li>
</ul>
<hr>
<h2 id="From-Denoising-Training-to-Test-Time-Adaptation-Enhancing-Domain-Generalization-for-Medical-Image-Segmentation"><a href="#From-Denoising-Training-to-Test-Time-Adaptation-Enhancing-Domain-Generalization-for-Medical-Image-Segmentation" class="headerlink" title="From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation"></a>From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20271">http://arxiv.org/abs/2310.20271</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenruxue/detta">https://github.com/wenruxue/detta</a></li>
<li>paper_authors: Ruxue Wen, Hangjie Yuan, Dong Ni, Wenbo Xiao, Yaoyao Wu<br>for:The paper is written for addressing the challenge of domain generalization in medical image segmentation, specifically in the scenario of single-source domain data due to privacy concerns.methods:The proposed approach, called Denoising Y-Net (DeY-Net), incorporates an auxiliary denoising decoder into the basic U-Net architecture to perform denoising training and enhance domain generalization.results:The proposed method achieves significant domain generalization improvements over the baseline and state-of-the-art results compared to other methods, as demonstrated through extensive experiments on widely-adopted liver segmentation benchmarks.Here is the simplified Chinese translation of the three key points:for:这篇论文是为了解决医学图像分割中的频率领域泛化问题，特别是受到数据获取设备和其他因素的频率领域转换的单源频率领域数据问题。methods:该提议的方法是基于自我超级vised学习 paradigma，通过添加一个辅助的干扰去除解码器，使得U-Net架构中的基本结构得到增强的频率领域泛化能力。results:该提议的方法在广泛采用的肝脏分割 benchmark 上实现了对基eline和现有方法的显著频率领域泛化改进。<details>
<summary>Abstract</summary>
In medical image segmentation, domain generalization poses a significant challenge due to domain shifts caused by variations in data acquisition devices and other factors. These shifts are particularly pronounced in the most common scenario, which involves only single-source domain data due to privacy concerns. To address this, we draw inspiration from the self-supervised learning paradigm that effectively discourages overfitting to the source domain. We propose the Denoising Y-Net (DeY-Net), a novel approach incorporating an auxiliary denoising decoder into the basic U-Net architecture. The auxiliary decoder aims to perform denoising training, augmenting the domain-invariant representation that facilitates domain generalization. Furthermore, this paradigm provides the potential to utilize unlabeled data. Building upon denoising training, we propose Denoising Test Time Adaptation (DeTTA) that further: (i) adapts the model to the target domain in a sample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive experiments conducted on widely-adopted liver segmentation benchmarks demonstrate significant domain generalization improvements over our baseline and state-of-the-art results compared to other methods. Code is available at https://github.com/WenRuxue/DeTTA.
</details>
<details>
<summary>摘要</summary>
医学图像分割中，领域总结是一项挑战，这是由数据获取设备和其他因素引起的领域差异所致。这些差异在最常见的场景中尤其突出，那是仅使用单源频道数据，这是由于隐私问题所致。为解决这个问题，我们 Draw inspiration from the self-supervised learning paradigm，这种方法可以减少预测频道数据的过拟合。我们提议一种新的方法，即附加auxiliary denoising decoder到基本U-Net架构中。这个auxiliary decoder的目的是在denoising训练中提高领域不变的表示。此外，这种方法还可以利用无标签数据。在denoising训练的基础之上，我们提议denoising Test Time Adaptation（DeTTA），它可以：（i）在目标频道上采样化地适应模型，和（ii）适应受到噪声损害的输入。我们对广泛采用的肝脏分割benchmark进行了广泛的实验，结果表明我们的方法在领域总结方面具有显著的改进。代码可以在https://github.com/WenRuxue/DeTTA中找到。
</details></li>
</ul>
<hr>
<h2 id="Low-Dose-CT-Image-Enhancement-Using-Deep-Learning"><a href="#Low-Dose-CT-Image-Enhancement-Using-Deep-Learning" class="headerlink" title="Low-Dose CT Image Enhancement Using Deep Learning"></a>Low-Dose CT Image Enhancement Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20265">http://arxiv.org/abs/2310.20265</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Demir, M. M. A. Shames, O. N. Gerek, S. Ergin, M. Fidan, M. Koc, M. B. Gulmezoglu, A. Barkana, C. Calisir</li>
<li>for: 降低ioniZing radiation的CT图像重建</li>
<li>methods: 使用U-NET进行图像进行增强</li>
<li>results: 比起低剂量版本，U-NET增强的半剂量CT图像可以提供更好的视觉效果和诊断效果，甚至比于全剂量CT图像。<details>
<summary>Abstract</summary>
The application of ionizing radiation for diagnostic imaging is common around the globe. However, the process of imaging, itself, remains to be a relatively hazardous operation. Therefore, it is preferable to use as low a dose of ionizing radiation as possible, particularly in computed tomography (CT) imaging systems, where multiple x-ray operations are performed for the reconstruction of slices of body tissues. A popular method for radiation dose reduction in CT imaging is known as the quarter-dose technique, which reduces the x-ray dose but can cause a loss of image sharpness. Since CT image reconstruction from directional x-rays is a nonlinear process, it is analytically difficult to correct the effect of dose reduction on image quality. Recent and popular deep-learning approaches provide an intriguing possibility of image enhancement for low-dose artifacts. Some recent works propose combinations of multiple deep-learning and classical methods for this purpose, which over-complicate the process. However, it is observed here that the straight utilization of the well-known U-NET provides very successful results for the correction of low-dose artifacts. Blind tests with actual radiologists reveal that the U-NET enhanced quarter-dose CT images not only provide an immense visual improvement over the low-dose versions, but also become diagnostically preferable images, even when compared to their full-dose CT versions.
</details>
<details>
<summary>摘要</summary>
globally， applying ionizing radiation for diagnostic imaging is common， but the imaging process itself is relatively hazardous， so it is best to use as little ionizing radiation as possible， especially in computed tomography（CT）imaging systems， where multiple x-ray operations are performed to reconstruct body tissue slices。a popular method for reducing radiation doses in CT imaging is the quarter-dose technique， which reduces x-ray doses but can cause a loss of image sharpness。since CT image reconstruction from directional x-rays is a nonlinear process，it is difficult to correct the effect of dose reduction on image quality analytically。recent and popular deep-learning approaches provide a promising possibility of enhancing low-dose images。some recent works propose combining multiple deep-learning and classical methods for this purpose， which complicates the process。however， it is found here that directly utilizing the well-known U-NET provides very successful results for correcting low-dose artifacts。blind tests with actual radiologists show that the U-NET enhanced quarter-dose CT images not only have a significant visual improvement over the low-dose versions， but also become diagnostically preferable images， even when compared to their full-dose CT versions。
</details></li>
</ul>
<hr>
<h2 id="Pose-to-Motion-Cross-Domain-Motion-Retargeting-with-Pose-Prior"><a href="#Pose-to-Motion-Cross-Domain-Motion-Retargeting-with-Pose-Prior" class="headerlink" title="Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior"></a>Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20249">http://arxiv.org/abs/2310.20249</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingqing Zhao, Peizhuo Li, Wang Yifan, Olga Sorkine-Hornung, Gordon Wetzstein</li>
<li>for: 本研究旨在生成具有可信度的动作，以便在计算机图形中创造更加真实的人物形象。</li>
<li>methods: 我们利用pose数据作为代替的数据源，并介绍了一种基于神经网络的动作合成方法，通过重定向来将源Character的动作特征传递给目标Character。</li>
<li>results: 我们的方法可以具有小量或噪音的 pose数据集来生成可信度高的动作，并在用户测试中被评估为更加愉悦、更加真实和具有 fewer artifacts。Here’s the translation in English:</li>
<li>for: The goal of this research is to generate believable motions to create more realistic characters in computer graphics.</li>
<li>methods: We utilize pose data as an alternative data source and introduce a neural motion synthesis approach through retargeting, transferring the motion features of an existing motion capture dataset of one character to another character with drastically different skeletons.</li>
<li>results: Our method can generate high-quality motions with small or noisy pose data sets and is evaluated as more enjoyable, more lifelike, and with fewer artifacts in a user study.<details>
<summary>Abstract</summary>
Creating believable motions for various characters has long been a goal in computer graphics. Current learning-based motion synthesis methods depend on extensive motion datasets, which are often challenging, if not impossible, to obtain. On the other hand, pose data is more accessible, since static posed characters are easier to create and can even be extracted from images using recent advancements in computer vision. In this paper, we utilize this alternative data source and introduce a neural motion synthesis approach through retargeting. Our method generates plausible motions for characters that have only pose data by transferring motion from an existing motion capture dataset of another character, which can have drastically different skeletons. Our experiments show that our method effectively combines the motion features of the source character with the pose features of the target character, and performs robustly with small or noisy pose data sets, ranging from a few artist-created poses to noisy poses estimated directly from images. Additionally, a conducted user study indicated that a majority of participants found our retargeted motion to be more enjoyable to watch, more lifelike in appearance, and exhibiting fewer artifacts. Project page: https://cyanzhao42.github.io/pose2motion
</details>
<details>
<summary>摘要</summary>
创造可信的动作 для各种角色已经是计算机图形的长期目标。当前的学习基于动作合成方法通常需要大量的动作数据，而这些数据往往很难或无法获得。然而，姿势数据更加 accessible，因为静止姿势的角色更容易创建，甚至可以从图像中提取使用最新的计算机视觉技术。在这篇论文中，我们利用这个替代数据源，并提出了一种神经动作合成方法通过重定向。我们的方法可以将来自另一个角色的动作数据转移到目标角色中，即使这两个角色有极大的骨架结构差异。我们的实验表明，我们的方法可以有效地将来自源角色的动作特征与目标角色的姿势特征结合在一起，并在小或噪音的姿势数据集上表现稳定。此外，我们进行了一项用户研究，发现大多数参与者认为我们的重定向动作更加有趣、更加生动、并且 fewer artifacts。项目页面：https://cyanzhao42.github.io/pose2motion
</details></li>
</ul>
<hr>
<h2 id="Contrast-agent-induced-deterministic-component-of-CT-density-in-the-abdominal-aorta-during-routine-angiography-proof-of-concept-study"><a href="#Contrast-agent-induced-deterministic-component-of-CT-density-in-the-abdominal-aorta-during-routine-angiography-proof-of-concept-study" class="headerlink" title="Contrast-agent-induced deterministic component of CT-density in the abdominal aorta during routine angiography: proof of concept study"></a>Contrast-agent-induced deterministic component of CT-density in the abdominal aorta during routine angiography: proof of concept study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20243">http://arxiv.org/abs/2310.20243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria R. Kodenko, Yuriy A. Vasilev, Nicholas S. Kulberg, Andrey V. Samorodov, Anton V. Vladzimirskyy, Olga V. Omelyanskaya, Roman V. Reshetnikov</li>
<li>for: 这个论文的目的是开发一种基于CTA数据的血液动力学模型，以便 investigate和优化CTA扫描过程，无需额外的 perfusion CT 研究。</li>
<li>methods: 该模型基于Beer-Lambert法则和血液和CA之间的化学交互的假设，具有六个参数，代表血液动力学特性。通过非线性最小二乘法和Levenberg-Marquardt优化算法，该模型被适应到数据中。</li>
<li>results: 研究分析了594个CTA图像（4个研究，每个研究144张 slice，IQR [134; 158.5]，1:1正常:疾病平衡），并证明了模型的合理性（Wilcox 测试，所有情况p-value &gt; 0.05）。该模型能够正确模拟正常血液流动和地方畸形所引起的血液动力学异常。<details>
<summary>Abstract</summary>
Background and objective: CTA is a gold standard of preoperative diagnosis of abdominal aorta and typically used for geometric-only characteristic extraction. We assume that a model describing the dynamic behavior of the contrast agent in the vessel can be developed from the data of routine CTA studies, allowing the procedure to be investigated and optimized without the need for additional perfusion CT studies. Obtained spatial distribution of CA can be valuable for both increasing the diagnostic value of a particular study and improving the CT data processing tools. Methods: In accordance with the Beer-Lambert law and the absence of chemical interaction between blood and CA, we postulated the existence of a deterministic CA-induced component in the CT signal density. The proposed model, having a double-sigmoid structure, contains six coefficients relevant to the properties of hemodynamics. To validate the model, expert segmentation was performed using the 3D Slicer application for the CTA data obtained from publicly available source. The model was fitted to the data using the non-linear least square method with Levenberg-Marquardt optimization. Results: We analyzed 594 CTA images (4 studies with median size of 144 slices, IQR [134; 158.5]; 1:1 normal:pathology balance). Goodness-of-fit was proved by Wilcox test (p-value > 0.05 for all cases). The proposed model correctly simulated normal blood flow and hemodynamics disturbances caused by local abnormalities (aneurysm, thrombus and arterial branching). Conclusions: Proposed approach can be useful for personalized CA modeling of vessels, improvement of CTA image processing and preparation of synthetic CT training data for artificial intelligence.
</details>
<details>
<summary>摘要</summary>
背景和目标：CTA是胃肠动脉预操作诊断的金标准，通常用于geometry-only特征提取。我们假设可以从 Routine CTA 研究中获得动态CA的模型，以便无需额外的 perfusion CT 研究，对过程进行调查和优化。获得的CA分布可以提高特定研究的诊断价值，以及CT数据处理工具。方法：根据Beer-Lambert法则和血液和CA之间的化学交互 absence，我们假设CA在血液中引起的Deterministic组件存在于CT信号密度中。我们提出的模型具有双sigmoid结构，包含6个相关血流特性的系数。为验证模型，我们使用3D Slicer应用程序进行专家分割，对CTA数据进行公共可用源 obtention。模型使用非线性最小二乘法与Levenberg-Marquardt优化算法进行适应。结果：我们分析了594个CTA图像（4个研究， median size为144层，IQR=[134;158.5]；1:1正常:疾病平衡）。好度Of-fit已经证明了Wilcox测试（p-value>0.05 для所有情况）。我们的模型正确模拟了正常血流和地方异常（aneurysm, thrombus和arterial branching）引起的血流异常。结论：我们的方法可以用于个性化CA模型化、CTA图像处理提高和人工智能synthetic CT培训数据的准备。
</details></li>
</ul>
<hr>
<h2 id="HEDNet-A-Hierarchical-Encoder-Decoder-Network-for-3D-Object-Detection-in-Point-Clouds"><a href="#HEDNet-A-Hierarchical-Encoder-Decoder-Network-for-3D-Object-Detection-in-Point-Clouds" class="headerlink" title="HEDNet: A Hierarchical Encoder-Decoder Network for 3D Object Detection in Point Clouds"></a>HEDNet: A Hierarchical Encoder-Decoder Network for 3D Object Detection in Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20234">http://arxiv.org/abs/2310.20234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhanggang001/hednet">https://github.com/zhanggang001/hednet</a></li>
<li>paper_authors: Gang Zhang, Junnan Chen, Guohuan Gao, Jianmin Li, Xiaolin Hu</li>
<li>for: 3D object detection in point clouds for autonomous driving systems</li>
<li>methods: uses hierarchical encoder-decoder blocks to capture long-range dependencies among features in the spatial space</li>
<li>results: achieved superior detection accuracy on the Waymo Open and nuScenes datasets compared to previous state-of-the-art methods with competitive efficiencyHere’s the full translation in Simplified Chinese:</li>
<li>for: 这篇论文旨在提出一种高性能的3D物体检测方法，用于自动驾驶系统中的点云检测。</li>
<li>methods: 该方法使用层次编码器-解码器块来捕捉点云中特征之间的长距离依赖关系，特别是用于大小远的物体检测。</li>
<li>results: 对于Waymo开放和nuScenes dataset，HEDNet实现了前期最优的检测精度，并与之前的状态之 искусственный智能方法兼容效率。I hope this helps!<details>
<summary>Abstract</summary>
3D object detection in point clouds is important for autonomous driving systems. A primary challenge in 3D object detection stems from the sparse distribution of points within the 3D scene. Existing high-performance methods typically employ 3D sparse convolutional neural networks with small kernels to extract features. To reduce computational costs, these methods resort to submanifold sparse convolutions, which prevent the information exchange among spatially disconnected features. Some recent approaches have attempted to address this problem by introducing large-kernel convolutions or self-attention mechanisms, but they either achieve limited accuracy improvements or incur excessive computational costs. We propose HEDNet, a hierarchical encoder-decoder network for 3D object detection, which leverages encoder-decoder blocks to capture long-range dependencies among features in the spatial space, particularly for large and distant objects. We conducted extensive experiments on the Waymo Open and nuScenes datasets. HEDNet achieved superior detection accuracy on both datasets than previous state-of-the-art methods with competitive efficiency. The code is available at https://github.com/zhanggang001/HEDNet.
</details>
<details>
<summary>摘要</summary>
三维物体检测在点云中是自动驾驶系统中的重要任务。主要检测挑战在3D场景中点的稀疏分布。现有高性能方法通常采用3D稀疏卷积神经网络，使用小kernel进行特征提取。以减少计算成本，这些方法通常采用子拟空间稀疏卷积，这会阻止空间分布在特征之间的信息交换。一些最近的方法尝试了解决这个问题，通过引入大kernel卷积或自注意机制，但它们 Either achieve limited accuracy improvements or incur excessive computational costs。我们提出了HEDNet，一种嵌入器-解码器网络，用于3D物体检测，它利用嵌入器-解码器块来捕捉特征在空间空间中的长距离依赖关系，特别是 для大的和远的对象。我们在 Waymo Open 和 nuScenes 数据集上进行了广泛的实验，HEDNet在两个数据集上 than previous state-of-the-art methods with competitive efficiency。代码可以在 https://github.com/zhanggang001/HEDNet 上找到。
</details></li>
</ul>
<hr>
<h2 id="UWFormer-Underwater-Image-Enhancement-via-a-Semi-Supervised-Multi-Scale-Transformer"><a href="#UWFormer-Underwater-Image-Enhancement-via-a-Semi-Supervised-Multi-Scale-Transformer" class="headerlink" title="UWFormer: Underwater Image Enhancement via a Semi-Supervised Multi-Scale Transformer"></a>UWFormer: Underwater Image Enhancement via a Semi-Supervised Multi-Scale Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20210">http://arxiv.org/abs/2310.20210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuhang Chen, Zinuo Li, Shenghong Luo, Weiwen Chen, Shuqiang Wang, Chi-Man Pun</li>
<li>for: 提高水下图像质量，增强图像多scale，提高图像对比度和色彩均衡。</li>
<li>methods: 使用Multi-scale Transformer-based Network（UWFormer），具有semi-supervised learning和Nonlinear Frequency-aware Attention机制，以及Multi-Scale Fusion Feed-forward Network，以提高低频增强。同时，提出了一种特有的水下半监督训练策略，使用Subaqueous Perceptual Loss函数生成可靠的 Pseudo标签。</li>
<li>results: 经过实验表明，我们的方法在水下Full-reference和Non-reference benchmark上比前式方法提高质量和视觉质量。<details>
<summary>Abstract</summary>
Underwater images often exhibit poor quality, imbalanced coloration, and low contrast due to the complex and intricate interaction of light, water, and objects. Despite the significant contributions of previous underwater enhancement techniques, there exist several problems that demand further improvement: (i) Current deep learning methodologies depend on Convolutional Neural Networks (CNNs) that lack multi-scale enhancement and also have limited global perception fields. (ii) The scarcity of paired real-world underwater datasets poses a considerable challenge, and the utilization of synthetic image pairs risks overfitting. To address the aforementioned issues, this paper presents a Multi-scale Transformer-based Network called UWFormer for enhancing images at multiple frequencies via semi-supervised learning, in which we propose a Nonlinear Frequency-aware Attention mechanism and a Multi-Scale Fusion Feed-forward Network for low-frequency enhancement. Additionally, we introduce a specialized underwater semi-supervised training strategy, proposing a Subaqueous Perceptual Loss function to generate reliable pseudo labels. Experiments using full-reference and non-reference underwater benchmarks demonstrate that our method outperforms state-of-the-art methods in terms of both quantity and visual quality.
</details>
<details>
<summary>摘要</summary>
水下图像经常呈现低质量、颜色不均、对比度低的问题，这主要归结于光线、水和物体之间复杂的互动。尽管过去的水下改进技术做出了重要贡献，但还有一些问题需要进一步改进：（i）当前的深度学习方法ologies rely heavily on Convolutional Neural Networks (CNNs)，它们缺乏多尺度增强和全球视场观察。（ii）水下实际数据缺乏对照数据，使用synthetic image pairs risk overfitting。为 Addressing these issues, this paper presents a Multi-scale Transformer-based Network called UWFormer for enhancing images at multiple frequencies via semi-supervised learning. Specifically, we propose a Nonlinear Frequency-aware Attention mechanism and a Multi-Scale Fusion Feed-forward Network for low-frequency enhancement. In addition, we introduce a specialized underwater semi-supervised training strategy, including a Subaqueous Perceptual Loss function to generate reliable pseudo labels. Experimental results using full-reference and non-reference underwater benchmarks show that our method outperforms state-of-the-art methods in terms of both quantity and visual quality.
</details></li>
</ul>
<hr>
<h2 id="ZoomNeXt-A-Unified-Collaborative-Pyramid-Network-for-Camouflaged-Object-Detection"><a href="#ZoomNeXt-A-Unified-Collaborative-Pyramid-Network-for-Camouflaged-Object-Detection" class="headerlink" title="ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object Detection"></a>ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20208">http://arxiv.org/abs/2310.20208</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lartpang/ZoomNeXt">https://github.com/lartpang/ZoomNeXt</a></li>
<li>paper_authors: Youwei Pang, Xiaoqi Zhao, Tian-Zhu Xiang, Lihe Zhang, Huchuan Lu</li>
<li>for: 本研究旨在提高Camouflaged Object Detection（COD）的精度和效果，使其能够更好地在真实世界中检测涂抹在背景中的 объек。</li>
<li>methods: 我们提出了一种有效的协同卷积网络，它通过模拟人类观察者对混乱图像和视频的方式，例如快速呈现和聚焦，来学习混乱图像中的Semantics。</li>
<li>results: 我们的方法在图像和视频COD benchmark上表现出色，与现有状态的方法相比，具有更高的准确率和效果。<details>
<summary>Abstract</summary>
Recent camouflaged object detection (COD) attempts to segment objects visually blended into their surroundings, which is extremely complex and difficult in real-world scenarios. Apart from the high intrinsic similarity between camouflaged objects and their background, objects are usually diverse in scale, fuzzy in appearance, and even severely occluded. To this end, we propose an effective unified collaborative pyramid network which mimics human behavior when observing vague images and videos, \textit{i.e.}, zooming in and out. Specifically, our approach employs the zooming strategy to learn discriminative mixed-scale semantics by the multi-head scale integration and rich granularity perception units, which are designed to fully explore imperceptible clues between candidate objects and background surroundings. The former's intrinsic multi-head aggregation provides more diverse visual patterns. The latter's routing mechanism can effectively propagate inter-frame difference in spatiotemporal scenarios and adaptively ignore static representations. They provides a solid foundation for realizing a unified architecture for static and dynamic COD. Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization, uncertainty awareness loss, to encourage predictions with higher confidence in candidate regions. Our highly task-friendly framework consistently outperforms existing state-of-the-art methods in image and video COD benchmarks. The code will be available at \url{https://github.com/lartpang/ZoomNeXt}.
</details>
<details>
<summary>摘要</summary>
近期隐形物检测（COD）尝试将物体视觉上隐藏在背景中，实际上非常复杂和困难。除了物体与背景高度相似外，物体通常是多种尺度、模糊的外观，甚至受到干扰。为此，我们提出了一种高效的统一协同PYRAMID网络，模仿人类观察模糊图像和视频时的行为，即缩进和缩出。具体来说，我们的方法利用缩进策略学习混合尺度 semantics，通过多头积分单元和丰富的准确度感知单元来全面探索不可见的准确信息。前者的内置多头积分提供更多的视觉模式。后者的路由机制可以有效地传递干扰ifference between candidate objects and background surroundings。它们提供了一个固定的基础 для实现静止和动态COD的统一架构。此外，鉴于不可预测的文本特征，我们构建了一个简单 yet effective的正则项，uncertainty awareness loss，以促进候选区域的更高 confidence。我们的高效任务友好的框架在图像和视频COD标准测试上一直保持领先地位。代码将在 \url{https://github.com/lartpang/ZoomNeXt} 上提供。
</details></li>
</ul>
<hr>
<h2 id="Visible-to-Thermal-image-Translation-for-improving-visual-task-in-low-light-conditions"><a href="#Visible-to-Thermal-image-Translation-for-improving-visual-task-in-low-light-conditions" class="headerlink" title="Visible to Thermal image Translation for improving visual task in low light conditions"></a>Visible to Thermal image Translation for improving visual task in low light conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20190">http://arxiv.org/abs/2310.20190</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Azim Khan</li>
<li>for: 用于解决RGB图像在低光照下完成视觉任务时的挑战，使用热变化图像来弥补这些挑战。</li>
<li>methods: 提出了一个端到端框架，包括生成网络和检测网络，用于将RGB图像翻译成热图像，并对生成的热图像与实际数据进行比较。</li>
<li>results: 研究发现，使用GAN可以将RGB图像翻译成热图像，并且生成的热图像与实际数据有高度的相似性。这些发现可以帮助解决视觉任务中的低光照问题，有利于安全和监测应用。<details>
<summary>Abstract</summary>
Several visual tasks, such as pedestrian detection and image-to-image translation, are challenging to accomplish in low light using RGB images. Heat variation of objects in thermal images can be used to overcome this. In this work, an end-to-end framework, which consists of a generative network and a detector network, is proposed to translate RGB image into Thermal ones and compare generated thermal images with real data. We have collected images from two different locations using the Parrot Anafi Thermal drone. After that, we created a two-stream network, preprocessed, augmented, the image data, and trained the generator and discriminator models from scratch. The findings demonstrate that it is feasible to translate RGB training data to thermal data using GAN. As a result, thermal data can now be produced more quickly and affordably, which is useful for security and surveillance applications.
</details>
<details>
<summary>摘要</summary>
几种视觉任务，如人员检测和图像转换，在低光照情况下使用RGB图像是困难的。在这种情况下，物体的热度变化在热图像中可以用来超越这一问题。本工作提出了一个端到端框架，该框架包括生成网络和检测网络，用于将RGB图像翻译成热图像，并将生成的热图像与实际数据进行比较。我们从两个不同的位置收集了Parrot Anafi热影机飞行器拍摄的图像。然后，我们创建了两�ream网络，对图像数据进行了预处理、增强、训练生成器和判断器模型从头开始。研究结果表明，使用GAN将RGB训练数据翻译成热数据是可行的。这意味着可以更快速、更经济地生成热数据，这对安全监控应用非常有用。
</details></li>
</ul>
<hr>
<h2 id="LFAA-Crafting-Transferable-Targeted-Adversarial-Examples-with-Low-Frequency-Perturbations"><a href="#LFAA-Crafting-Transferable-Targeted-Adversarial-Examples-with-Low-Frequency-Perturbations" class="headerlink" title="LFAA: Crafting Transferable Targeted Adversarial Examples with Low-Frequency Perturbations"></a>LFAA: Crafting Transferable Targeted Adversarial Examples with Low-Frequency Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20175">http://arxiv.org/abs/2310.20175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunyu Wang, Juluan Shi, Wenxuan Wang</li>
<li>for: 防御深度神经网络受到攻击的安全性和可靠性问题，特别是攻击者可以通过 Transfer-based 攻击来让模型错误地预测图像。</li>
<li>methods: 我们提出了一种新的方法，即 Low-Frequency Adversarial Attack (\name)，它通过让模型受到高频信息的扰动来实现targeted攻击。我们使用了一个conditional generator来生成targeted adversarial perturbations，然后将其添加到图像的low-frequency组件中。</li>
<li>results: 我们的方法在ImageNet上进行了广泛的实验，结果显示，我们的方法可以 Significantly outperform state-of-the-art methods，提高targeted攻击成功率比例从3.2%到15.5%。<details>
<summary>Abstract</summary>
Deep neural networks are susceptible to adversarial attacks, which pose a significant threat to their security and reliability in real-world applications. The most notable adversarial attacks are transfer-based attacks, where an adversary crafts an adversarial example to fool one model, which can also fool other models. While previous research has made progress in improving the transferability of untargeted adversarial examples, the generation of targeted adversarial examples that can transfer between models remains a challenging task. In this work, we present a novel approach to generate transferable targeted adversarial examples by exploiting the vulnerability of deep neural networks to perturbations on high-frequency components of images. We observe that replacing the high-frequency component of an image with that of another image can mislead deep models, motivating us to craft perturbations containing high-frequency information to achieve targeted attacks. To this end, we propose a method called Low-Frequency Adversarial Attack (\name), which trains a conditional generator to generate targeted adversarial perturbations that are then added to the low-frequency component of the image. Extensive experiments on ImageNet demonstrate that our proposed approach significantly outperforms state-of-the-art methods, improving targeted attack success rates by a margin from 3.2\% to 15.5\%.
</details>
<details>
<summary>摘要</summary>
In this work, we present a novel approach to generate transferable targeted adversarial examples by exploiting the vulnerability of deep neural networks to perturbations on high-frequency components of images. We observe that replacing the high-frequency component of an image with that of another image can mislead deep models, motivating us to craft perturbations containing high-frequency information to achieve targeted attacks.To this end, we propose a method called Low-Frequency Adversarial Attack (\name), which trains a conditional generator to generate targeted adversarial perturbations that are then added to the low-frequency component of the image. Extensive experiments on ImageNet demonstrate that our proposed approach significantly outperforms state-of-the-art methods, improving targeted attack success rates by a margin from 3.2\% to 15.5\%.
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Diabetic-Foot-Ulcer-Images-with-Diffusion-Model"><a href="#Synthesizing-Diabetic-Foot-Ulcer-Images-with-Diffusion-Model" class="headerlink" title="Synthesizing Diabetic Foot Ulcer Images with Diffusion Model"></a>Synthesizing Diabetic Foot Ulcer Images with Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20140">http://arxiv.org/abs/2310.20140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Basiri, Karim Manji, Francois Harton, Alisha Poonja, Milos R. Popovic, Shehroz S. Khan</li>
<li>for: 这篇论文旨在探讨抗生素激烈网络和传播模型的应用在生成抗生素激烈照片方面，以便提高医疗训练和研究活动中的照片数据量。</li>
<li>methods: 本论文使用了抗生素激烈网络和传播模型来生成抗生素激烈照片，并通过专业医生评估以评估生成的照片的authenticity。</li>
<li>results: 研究结果显示，抗生素激烈网络和传播模型能够成功地生成可以与真实照片相似的抗生素激烈照片，70%的时间，医生会认为生成的照片是真正的抗生素激烈照片。但是，医生对生成的照片的信心较低，并且对真实照片的评价较高。研究也发现，FID和KID指数不能够协调医生的评价，建议应用更多的评估方法。<details>
<summary>Abstract</summary>
Diabetic Foot Ulcer (DFU) is a serious skin wound requiring specialized care. However, real DFU datasets are limited, hindering clinical training and research activities. In recent years, generative adversarial networks and diffusion models have emerged as powerful tools for generating synthetic images with remarkable realism and diversity in many applications. This paper explores the potential of diffusion models for synthesizing DFU images and evaluates their authenticity through expert clinician assessments. Additionally, evaluation metrics such as Frechet Inception Distance (FID) and Kernel Inception Distance (KID) are examined to assess the quality of the synthetic DFU images. A dataset of 2,000 DFU images is used for training the diffusion model, and the synthetic images are generated by applying diffusion processes. The results indicate that the diffusion model successfully synthesizes visually indistinguishable DFU images. 70% of the time, clinicians marked synthetic DFU images as real DFUs. However, clinicians demonstrate higher unanimous confidence in rating real images than synthetic ones. The study also reveals that FID and KID metrics do not significantly align with clinicians' assessments, suggesting alternative evaluation approaches are needed. The findings highlight the potential of diffusion models for generating synthetic DFU images and their impact on medical training programs and research in wound detection and classification.
</details>
<details>
<summary>摘要</summary>
糖尿病足淋浸 (DFU) 是一种严重的皮肤伤害，需要专门的护理。然而，实际的 DFU 数据却受到限制，影响临床训练和研究活动。在最近几年，生成对抗网络和扩散模型在许多应用场景中显示出了强大的生成能力和多样性。本文探讨了扩散模型在生成 DFU 图像方面的潜力，并通过专业医生评估来评估生成的图像authenticity。此外，Frechet Inception Distance (FID) 和 Kernel Inception Distance (KID) 等评估指标也被检查，以评估生成的 DFU 图像质量。使用了 2,000 张 DFU 图像进行训练，并通过扩散过程生成 synthetic 图像。结果表明，扩散模型成功地生成了可以不可分辩的 DFU 图像。70% 的时间，专业医生将生成的 synthetic DFU 图像标记为真实的 DFU。然而，专业医生对真实图像的评估高于对生成图像的评估。研究还发现，FID 和 KID 指标与专业医生的评估不符， suggesting alternative evaluation approaches are needed。发现表明扩散模型对生成 DFU 图像的潜力，并且对临床训练和研究在疤痕检测和分类方面的影响。
</details></li>
</ul>
<hr>
<h2 id="Team-I2R-VI-FF-Technical-Report-on-EPIC-KITCHENS-VISOR-Hand-Object-Segmentation-Challenge-2023"><a href="#Team-I2R-VI-FF-Technical-Report-on-EPIC-KITCHENS-VISOR-Hand-Object-Segmentation-Challenge-2023" class="headerlink" title="Team I2R-VI-FF Technical Report on EPIC-KITCHENS VISOR Hand Object Segmentation Challenge 2023"></a>Team I2R-VI-FF Technical Report on EPIC-KITCHENS VISOR Hand Object Segmentation Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20120">http://arxiv.org/abs/2310.20120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fen Fang, Yi Cheng, Ying Sun, Qianli Xu</li>
<li>for: 本研究报告是关于EPIC-KITCHENS VISOR Hand Object Segmentation Challenge的方法，该挑战的目标是根据单一帧输入中的手和对象的关系进行估计。EPIC-KITCHENS VISOR数据集提供了像素级注释，并作为 egocentric video中手和活动对象分割的标准准例。</li>
<li>methods: 我们的方法结合了基线方法，即Point-based Rendering（PointRend）和Segment Anything Model（SAM），以提高手和对象分割结果的准确性，同时避免失找检测的情况。我们利用基线方法提供的准确的手段图以提取更加精确的手和接触对象段。我们使用SAM提供的类型不敏感分 segmentation，并应用特定的手工制约以改进结果。在基线模型错过检测手或对象的情况下，我们将训练一个对象检测器，以提高检测精度。</li>
<li>results: 我们的提交使用我们的改进方法，在EPIC-KITCHENS VISOR Hand Object Segmentation Challenge中的评估标准下达到了第一名。<details>
<summary>Abstract</summary>
In this report, we present our approach to the EPIC-KITCHENS VISOR Hand Object Segmentation Challenge, which focuses on the estimation of the relation between the hands and the objects given a single frame as input. The EPIC-KITCHENS VISOR dataset provides pixel-wise annotations and serves as a benchmark for hand and active object segmentation in egocentric video. Our approach combines the baseline method, i.e., Point-based Rendering (PointRend) and the Segment Anything Model (SAM), aiming to enhance the accuracy of hand and object segmentation outcomes, while also minimizing instances of missed detection. We leverage accurate hand segmentation maps obtained from the baseline method to extract more precise hand and in-contact object segments. We utilize the class-agnostic segmentation provided by SAM and apply specific hand-crafted constraints to enhance the results. In cases where the baseline model misses the detection of hands or objects, we re-train an object detector on the training set to enhance the detection accuracy. The detected hand and in-contact object bounding boxes are then used as prompts to extract their respective segments from the output of SAM. By effectively combining the strengths of existing methods and applying our refinements, our submission achieved the 1st place in terms of evaluation criteria in the VISOR HOS Challenge.
</details>
<details>
<summary>摘要</summary>
在这份报告中，我们介绍了我们对EPIC-KITCHENS VISOR手Object Segmentation挑战的方法，该挑战关注于给定一帧输入的手和对象之间的关系的估算。EPIC-KITCHENS VISOR数据集提供了像素级注释，并作为手和活动对象分割在 egocentric 视频中的标准准的 benchmark。我们的方法结合基线方法，即 Point-based Rendering（PointRend）和 Segment Anything Model（SAM），以提高手和对象分割结果的准确性，同时避免错过检测的情况。我们利用基eline方法提供的准确的手段图来提取更加精确的手和接触对象分割。我们利用 SAM 提供的类型不敏感分割，并应用特定的手工制约来提高结果。在基线模型错过检测手或对象的情况下，我们将对训练集进行重新训练，以提高检测精度。检测到的手和接触对象 bounding box 然后用作 SAM 输出中提取其分割的Prompt。通过有效地结合现有方法的优点和我们的调整，我们的提交实现了评估标准中的第一名。
</details></li>
</ul>
<hr>
<h2 id="Refined-Equivalent-Pinhole-Model-for-Large-scale-3D-Reconstruction-from-Spaceborne-CCD-Imagery"><a href="#Refined-Equivalent-Pinhole-Model-for-Large-scale-3D-Reconstruction-from-Spaceborne-CCD-Imagery" class="headerlink" title="Refined Equivalent Pinhole Model for Large-scale 3D Reconstruction from Spaceborne CCD Imagery"></a>Refined Equivalent Pinhole Model for Large-scale 3D Reconstruction from Spaceborne CCD Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20117">http://arxiv.org/abs/2310.20117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Danyang, Yu Anzhu, Ji Song, Cao Xuefeng, Quan Yujun, Guo Wenyue, Qiu Chunping</li>
<li>for: 本研究旨在开发一种基于直线阵列CCD卫星成像的大规模地表重建管线。</li>
<li>methods: 我们引入了一种将理性函数模型（RFM）与小孔镜模型（PCM）等价的方法，并 derivated一个错误公式 для这种等价小孔镜模型，以示图像大小对重建精度的影响。我们还提出了一种多项式图像纠正模型，通过最小二乘法来最小化等价错误。</li>
<li>results: 我们在四个图像Dataset（WHU-TLC、DFC2019、ISPRS-ZY3和GF7）上进行了实验，结果表明重建精度与图像大小直接相关。我们的多项式图像纠正模型可以显著提高重建精度和完teness，特别是对于大规模图像。<details>
<summary>Abstract</summary>
In this study, we present a large-scale earth surface reconstruction pipeline for linear-array charge-coupled device (CCD) satellite imagery. While mainstream satellite image-based reconstruction approaches perform exceptionally well, the rational functional model (RFM) is subject to several limitations. For example, the RFM has no rigorous physical interpretation and differs significantly from the pinhole imaging model; hence, it cannot be directly applied to learning-based 3D reconstruction networks and to more novel reconstruction pipelines in computer vision. Hence, in this study, we introduce a method in which the RFM is equivalent to the pinhole camera model (PCM), meaning that the internal and external parameters of the pinhole camera are used instead of the rational polynomial coefficient parameters. We then derive an error formula for this equivalent pinhole model for the first time, demonstrating the influence of the image size on the accuracy of the reconstruction. In addition, we propose a polynomial image refinement model that minimizes equivalent errors via the least squares method. The experiments were conducted using four image datasets: WHU-TLC, DFC2019, ISPRS-ZY3, and GF7. The results demonstrated that the reconstruction accuracy was proportional to the image size. Our polynomial image refinement model significantly enhanced the accuracy and completeness of the reconstruction, and achieved more significant improvements for larger-scale images.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提出了一个大规模地表面重建管线，用于线性阵列具有CCD卫星成像。当前主流卫星成像基于重建方法具有出色表现，但是理циональ函数模型（RFM）受到一些限制。例如，RFM没有准确的物理解释，与穿孔成像模型（PCM）有很大差异，因此无法直接应用于学习基于三维重建网络和计算机视觉中的更新重建管线。因此，在本研究中，我们提出了一种方法，将RFM等价于PCM，即使用内部和外部相机参数而不是理циональ多项式系数参数。然后，我们 derive了这个等价穿孔模型的错误公式，表明图像大小对重建准确性的影响。此外，我们提出了一种多项式图像纠正模型，通过最小二乘方法来减少等价错误。实验使用了四个图像数据集：WHU-TLC、DFC2019、ISPRS-ZY3和GF7。结果表明，重建准确性与图像大小成正比。我们的多项式图像纠正模型可以提高重建准确性和完整性，并在更大规模的图像上实现更大的改进。
</details></li>
</ul>
<hr>
<h2 id="Medical-Image-Denosing-via-Explainable-AI-Feature-Preserving-Loss"><a href="#Medical-Image-Denosing-via-Explainable-AI-Feature-Preserving-Loss" class="headerlink" title="Medical Image Denosing via Explainable AI Feature Preserving Loss"></a>Medical Image Denosing via Explainable AI Feature Preserving Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20101">http://arxiv.org/abs/2310.20101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanfang Dong, Anup Basu</li>
<li>for: 这篇论文主要是为了提出一种新的医疗图像去噪方法，该方法不仅能有效地除去各种噪声，还能保留关键的医疗特征。</li>
<li>methods: 该方法使用了一种基于梯度的可解释人工智能（XAI）的损失函数设计，通过反传播，在去噪过程中保持医疗图像特征的一致性。</li>
<li>results: 经过广泛的实验 validate 了该方法在医疗图像去噪方面的优秀性，包括噪声和artifacts的13种不同类型的去噪性能、模型可解释性和泛化性。<details>
<summary>Abstract</summary>
Denoising algorithms play a crucial role in medical image processing and analysis. However, classical denoising algorithms often ignore explanatory and critical medical features preservation, which may lead to misdiagnosis and legal liabilities.In this work, we propose a new denoising method for medical images that not only efficiently removes various types of noise, but also preserves key medical features throughout the process. To achieve this goal, we utilize a gradient-based eXplainable Artificial Intelligence (XAI) approach to design a feature preserving loss function. Our feature preserving loss function is motivated by the characteristic that gradient-based XAI is sensitive to noise. Through backpropagation, medical image features before and after denoising can be kept consistent. We conducted extensive experiments on three available medical image datasets, including synthesized 13 different types of noise and artifacts. The experimental results demonstrate the superiority of our method in terms of denoising performance, model explainability, and generalization.
</details>
<details>
<summary>摘要</summary>
噪声除算法在医疗影像处理和分析中扮演着关键角色。然而，经典噪声除算法经常忽略医疗特有的重要特征，这可能导致误诊和法律责任。在这种情况下，我们提出了一种新的医疗影像噪声除法，不仅高效地除除各种噪声，而且保留了关键医疗特征。为实现这一目标，我们利用了梯度基于的解释可能性AI（XAI）方法设计了一个保持特征的损失函数。我们的特征保持损失函数受到梯度基于XAI的敏感性，通过反射，医疗影像特征之前和之后噪声除法的比较可以保持一致。我们在三个可用的医疗影像 dataset上进行了广泛的实验，包括13种不同类型的噪声和artefact。实验结果表明，我们的方法在噪声除法性能、模型解释性和泛化性方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="p-Poisson-surface-reconstruction-in-curl-free-flow-from-point-clouds"><a href="#p-Poisson-surface-reconstruction-in-curl-free-flow-from-point-clouds" class="headerlink" title="$p$-Poisson surface reconstruction in curl-free flow from point clouds"></a>$p$-Poisson surface reconstruction in curl-free flow from point clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20095">http://arxiv.org/abs/2310.20095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yesom Park, Taekyung Lee, Jooyoung Hahn, Myungjoo Kang</li>
<li>for: 本研究旨在从不规则点云样本中重建满足 геометрических形状的光滑表面，无需任何其他信息。</li>
<li>methods: 本文使用启发神经网络表示法（INR）进行面重建，但不需要基于真实的隐函数值或表面法向量的超参。 instead, 我们利用部分偏微分方程的正确监督和 diferencial vector fields的基本性质，以robustly重建高质量表面。</li>
<li>results: 我们在标准 benchmark 数据集上进行了实验，结果表明，我们提出的 INR 方法可以提供superior和Robust的重建。 code 可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/Yebbi/PINC%7D">https://github.com/Yebbi/PINC}</a> 上获取。<details>
<summary>Abstract</summary>
The aim of this paper is the reconstruction of a smooth surface from an unorganized point cloud sampled by a closed surface, with the preservation of geometric shapes, without any further information other than the point cloud. Implicit neural representations (INRs) have recently emerged as a promising approach to surface reconstruction. However, the reconstruction quality of existing methods relies on ground truth implicit function values or surface normal vectors. In this paper, we show that proper supervision of partial differential equations and fundamental properties of differential vector fields are sufficient to robustly reconstruct high-quality surfaces. We cast the $p$-Poisson equation to learn a signed distance function (SDF) and the reconstructed surface is implicitly represented by the zero-level set of the SDF. For efficient training, we develop a variable splitting structure by introducing a gradient of the SDF as an auxiliary variable and impose the $p$-Poisson equation directly on the auxiliary variable as a hard constraint. Based on the curl-free property of the gradient field, we impose a curl-free constraint on the auxiliary variable, which leads to a more faithful reconstruction. Experiments on standard benchmark datasets show that the proposed INR provides a superior and robust reconstruction. The code is available at \url{https://github.com/Yebbi/PINC}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-U-Making-Diffusion-Models-Faster-Lighter"><a href="#Beyond-U-Making-Diffusion-Models-Faster-Lighter" class="headerlink" title="Beyond U: Making Diffusion Models Faster &amp; Lighter"></a>Beyond U: Making Diffusion Models Faster &amp; Lighter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.20092">http://arxiv.org/abs/2310.20092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergio Calvo-Ordonez, Jiahao Huang, Lipei Zhang, Guang Yang, Carola-Bibiane Schonlieb, Angelica I Aviles-Rivero</li>
<li>for: 这个论文是为了提高扩散模型的效率，特别是在逆噪处理过程中。</li>
<li>methods: 这篇论文使用了连续动力学系统来设计一种新的逆噪网络，以提高扩散模型的参数效率、速度更快、鲁棒性更高。</li>
<li>results:  experiments 表明，这种新的逆噪网络比标准 U-Net 在 Denoising Diffusion Probabilistic Models (DDPMs) 中具有更好的参数效率、更快的速度和更高的鲁棒性。<details>
<summary>Abstract</summary>
Diffusion models are a family of generative models that yield record-breaking performance in tasks such as image synthesis, video generation, and molecule design. Despite their capabilities, their efficiency, especially in the reverse denoising process, remains a challenge due to slow convergence rates and high computational costs. In this work, we introduce an approach that leverages continuous dynamical systems to design a novel denoising network for diffusion models that is more parameter-efficient, exhibits faster convergence, and demonstrates increased noise robustness. Experimenting with denoising probabilistic diffusion models, our framework operates with approximately a quarter of the parameters and 30% of the Floating Point Operations (FLOPs) compared to standard U-Nets in Denoising Diffusion Probabilistic Models (DDPMs). Furthermore, our model is up to 70% faster in inference than the baseline models when measured in equal conditions while converging to better quality solutions.
</details>
<details>
<summary>摘要</summary>
Diffusion models 是一家 генератив模型，在图像生成、视频生成和分子设计等任务中表现出色。然而，它们在反噪处理过程中的效率仍然是一大挑战，主要是因为它们的整合速率较慢，计算成本较高。在这项工作中，我们介绍了一种使用连续动力系统来设计一种新的反噪网络，这种网络在 diffusion models 中更parameter-efficient， faster convergence，和更高的噪声Robustness。通过对噪损 probablistic diffusion models 进行实验，我们的框架可以在相同条件下与标准 U-Nets 相比，用 Parameters 和 FLOPs 的一半完成反噪任务。此外，我们的模型在等效条件下与基eline models 相比，在推理过程中更快，达到更高的质量。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/31/cs.CV_2023_10_31/" data-id="cloh7tqia00k87b8832s2bfzt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
