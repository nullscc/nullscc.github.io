
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-09-09 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Symplectic Structure-Aware Hamiltonian (Graph) Embeddings paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.04885 repo_url: None paper_authors: Jiaxu Liu, Xinping Yi, Tianle Zhang, Xiaowei Huang For: 本文旨在提出一种基于哈密顿">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-09-09">
<meta property="og:url" content="https://nullscc.github.io/2023/09/09/cs.LG_2023_09_09/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Symplectic Structure-Aware Hamiltonian (Graph) Embeddings paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.04885 repo_url: None paper_authors: Jiaxu Liu, Xinping Yi, Tianle Zhang, Xiaowei Huang For: 本文旨在提出一种基于哈密顿">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-09T10:00:00.000Z">
<meta property="article:modified_time" content="2023-09-14T20:38:18.634Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.LG_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T10:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-09-09
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Symplectic-Structure-Aware-Hamiltonian-Graph-Embeddings"><a href="#Symplectic-Structure-Aware-Hamiltonian-Graph-Embeddings" class="headerlink" title="Symplectic Structure-Aware Hamiltonian (Graph) Embeddings"></a>Symplectic Structure-Aware Hamiltonian (Graph) Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04885">http://arxiv.org/abs/2309.04885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxu Liu, Xinping Yi, Tianle Zhang, Xiaowei Huang</li>
<li>For: 本文旨在提出一种基于哈密顿系统的图 neural network（GNN）方法，以便更好地适应不同的图数据集。* Methods: 本文使用了里曼尼亚优化在射影Stiefel manifold上进行自适应学习，以便在训练中自动地适应不同的图数据集，而不需要进行广泛的超参数调整。此外，本文还保留了能量的Physically meaningful during training,以确保协助拟合更加准确。* Results: 本文通过对多种图数据集进行node classification任务的实验，证明SAH-GNN在适应性和性能方面表现出色，并且在不同的图数据集上具有更好的一致性。<details>
<summary>Abstract</summary>
In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. In this work, we present SAH-GNN, a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure during training, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training such that the implicit Hamiltonian system is physically meaningful. To this end, we empirically validate SAH-GNN's superior performance and adaptability in node classification tasks across multiple types of graph datasets.
</details>
<details>
<summary>摘要</summary>
传统的图 neural network (GNN) 假设 fixed embedding manifold 通常限制它们对多种图形态的适应性。最近，哈密顿系统适应 GNN 被提出来解决图 embeddings 的动态性，通过在节点特征更新中包含物理法则。在这项工作中，我们提出了 SAH-GNN，一种新的方法，可以扩展哈密顿动力学中的node feature更新。不同于现有的哈密顿适应 GNN，SAH-GNN 使用 Riemannian 优化在 симплекс Stiefel  manifold 上对固有的 симплекс结构进行自适应学习，从而超越现有的哈密顿 GNN 对标准哈密顿结构的固定假设。这种创新允许 SAH-GNN 在多种图数据集上自动适应不同的图类型，而无需进行详细的 гипер参数调整。此外，它在训练中保留能量，使得隐式的哈密顿系统具有物理意义。为此，我们在多种图数据集上验证了 SAH-GNN 的superior表现和适应性。
</details></li>
</ul>
<hr>
<h2 id="A-Gentle-Introduction-to-Gradient-Based-Optimization-and-Variational-Inequalities-for-Machine-Learning"><a href="#A-Gentle-Introduction-to-Gradient-Based-Optimization-and-Variational-Inequalities-for-Machine-Learning" class="headerlink" title="A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning"></a>A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04877">http://arxiv.org/abs/2309.04877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha S. Wadia, Yatin Dandi, Michael I. Jordan</li>
<li>for: 这篇论文旨在探讨机器学习领域的进展，以及它们在决策和多代人问题中的应用。</li>
<li>methods: 论文使用的方法包括落差点和 monotone 游戏，以及更一般的变量不等式。</li>
<li>results: 论文提供了一些新的加速算法的设计方法，以及对这些算法的收敛证明。但是，论文的主要重点是提供动机和直觉，而不是严格的证明。<details>
<summary>Abstract</summary>
The rapid progress in machine learning in recent years has been based on a highly productive connection to gradient-based optimization. Further progress hinges in part on a shift in focus from pattern recognition to decision-making and multi-agent problems. In these broader settings, new mathematical challenges emerge that involve equilibria and game theory instead of optima. Gradient-based methods remain essential -- given the high dimensionality and large scale of machine-learning problems -- but simple gradient descent is no longer the point of departure for algorithm design. We provide a gentle introduction to a broader framework for gradient-based algorithms in machine learning, beginning with saddle points and monotone games, and proceeding to general variational inequalities. While we provide convergence proofs for several of the algorithms that we present, our main focus is that of providing motivation and intuition.
</details>
<details>
<summary>摘要</summary>
“近年来机器学习的快速进步主要基于高度产生的梯度下降优化。未来的进步受到一定程度受到决策和多代人问题的转移。在这些更广泛的设置下，新的数学挑战出现，涉及到均衡和游戏理论而不是最优点。梯度下降方法仍然是必不可少的——由于机器学习问题的高维度和大规模——但简单的梯度下降不再是算法设计的出发点。我们提供了一种渐进的框架 для梯度基于算法在机器学习中，从锥点和均衡游戏开始，然后进行总变量不等式。虽然我们提供了一些算法的收敛证明，但我们的主要关注点是提供动机和直觉。”Note that Simplified Chinese is a romanization of Chinese, and the actual Chinese characters may be different.
</details></li>
</ul>
<hr>
<h2 id="Approximating-ReLU-on-a-Reduced-Ring-for-Efficient-MPC-based-Private-Inference"><a href="#Approximating-ReLU-on-a-Reduced-Ring-for-Efficient-MPC-based-Private-Inference" class="headerlink" title="Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference"></a>Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04875">http://arxiv.org/abs/2309.04875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiwan Maeng, G. Edward Suh</li>
<li>for: 这个论文的目的是提出一个名为 HummingBird 的多方 computation（MPC）框架，以实现在不可信服务器上进行隐私数据的机器学习推导，并且大大减少 ReLU 评估 overhead。</li>
<li>methods: HummingBird 使用一个子集位元来评估 ReLU，并通过理论分析确定不需要的位元，以减少通信。它还具有高效的搜索引擎，可以对秘密分享中的位元进行有效地排序和搁置。</li>
<li>results: HummingBird 在一个实际的多服务器 MPC 设置中，可以实现从 2.03 到 2.67 倍的终端执行时间优化，而不会导致精度下降。在允许一定精度下降的情况下，HummingBird 可以实现更高的优化，达到 8.64 倍的终端执行时间优化。<details>
<summary>Abstract</summary>
Secure multi-party computation (MPC) allows users to offload machine learning inference on untrusted servers without having to share their privacy-sensitive data. Despite their strong security properties, MPC-based private inference has not been widely adopted in the real world due to their high communication overhead. When evaluating ReLU layers, MPC protocols incur a significant amount of communication between the parties, making the end-to-end execution time multiple orders slower than its non-private counterpart.   This paper presents HummingBird, an MPC framework that reduces the ReLU communication overhead significantly by using only a subset of the bits to evaluate ReLU on a smaller ring. Based on theoretical analyses, HummingBird identifies bits in the secret share that are not crucial for accuracy and excludes them during ReLU evaluation to reduce communication. With its efficient search engine, HummingBird discards 87--91% of the bits during ReLU and still maintains high accuracy. On a real MPC setup involving multiple servers, HummingBird achieves on average 2.03--2.67x end-to-end speedup without introducing any errors, and up to 8.64x average speedup when some amount of accuracy degradation can be tolerated, due to its up to 8.76x communication reduction.
</details>
<details>
<summary>摘要</summary>
安全多方计算（MPC）允许用户在不信任的服务器上执行机器学习推理，而不需要将隐私敏感数据分享。尽管它们具有强安全性质，但MPC基于私有推理还没有在实际世界中广泛采用，主要是因为它们的通信 overhead 过高。在评估 ReLU 层时，MPC 协议在党中产生了很大的通信量，使得总端到终点执行时间比非私有 counterpart 多出多个次数。本文介绍了 HummingBird，一个基于 MPC 框架，可以在 ReLU 评估中减少通信 overhead 。HummingBird 根据理论分析，在秘密分享中标识不必要的位 bits，并在 ReLU 评估中排除它们，从而减少通信。HummingBird 还具有高效的搜索引擎，可以在 ReLU 评估中抛弃 87--91% 的位 bits，并仍保持高精度。在多服务器 MPC 环境中，HummingBird 平均 achiev 2.03--2.67 倍的终点到终点速度提升，而无错误。在某些情况下可以tolerate 一定的精度下降，HummingBird 可以在 8.64 倍的通信减少情况下实现最高 8.76 倍的速度提升。
</details></li>
</ul>
<hr>
<h2 id="Approximation-Results-for-Gradient-Descent-trained-Neural-Networks"><a href="#Approximation-Results-for-Gradient-Descent-trained-Neural-Networks" class="headerlink" title="Approximation Results for Gradient Descent trained Neural Networks"></a>Approximation Results for Gradient Descent trained Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04860">http://arxiv.org/abs/2309.04860</a></li>
<li>repo_url: None</li>
<li>paper_authors: G. Welper</li>
<li>for: 本文提供了对各种 Sobolev 平滑函数的神经网络学习的约数保证，使用梯度流进行训练，并且使用 continueous $L_2(\mathbb{S}^{d-1})$-norm 来度量错误。</li>
<li>methods: 本文使用了神经网络的层WISE gradient flow，并且只有第二层（非极值层）使用了神经凝结函数（NTK）来确定梯度流的速度。</li>
<li>results: 本文得到了一系列的约数保证，包括 Sobolev 平滑函数的approximation guarantee，并且发现在一定的under-parametrized regime下，神经网络的学习率可以更高，但是在这个regime下，神经网络的approximation rate会比标准的approximation方法（如 wavelet 方法）更差。<details>
<summary>Abstract</summary>
The paper contains approximation guarantees for neural networks that are trained with gradient flow, with error measured in the continuous $L_2(\mathbb{S}^{d-1})$-norm on the $d$-dimensional unit sphere and targets that are Sobolev smooth. The networks are fully connected of constant depth and increasing width. Although all layers are trained, the gradient flow convergence is based on a neural tangent kernel (NTK) argument for the non-convex second but last layer. Unlike standard NTK analysis, the continuous error norm implies an under-parametrized regime, possible by the natural smoothness assumption required for approximation. The typical over-parametrization re-enters the results in form of a loss in approximation rate relative to established approximation methods for Sobolev smooth functions.
</details>
<details>
<summary>摘要</summary>
文章提供了用梯度流 optimize 的神经网络的近似保证，错误量 measured 在 continues $L_2(\mathbb{S}^{d-1})$-norm 上 $d$-dimensional 单位球体上，目标函数是 Sobolev 的幂函数。神经网络是完全连接的常量深度和增长宽度。although 所有层都是训练的，梯度流整合基于非 conjugate 的 second but last layer 的 neural tangent kernel (NTK) argument。与标准 NTK 分析不同，Continuous error norm 导致了 under-parametrized  режим，可能由 natural smoothness assumption 所需的 approximation。typical over-parametrization 重新入场 result 中的 loss  approximations rate 相对于 established approximation methods for Sobolev smooth functions。
</details></li>
</ul>
<hr>
<h2 id="Reverse-Engineering-Decoding-Strategies-Given-Blackbox-Access-to-a-Language-Generation-System"><a href="#Reverse-Engineering-Decoding-Strategies-Given-Blackbox-Access-to-a-Language-Generation-System" class="headerlink" title="Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"></a>Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04858">http://arxiv.org/abs/2309.04858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daphne Ippolito, Nicholas Carlini, Katherine Lee, Milad Nasr, Yun William Yu</li>
<li>for: 本研究旨在逆向工程语言模型生成文本的方法，以便掌握生成文本的参数。</li>
<li>methods: 本研究使用逆向工程方法来掌握语言模型生成文本的方法，包括top-$k$和核心采样等方法。</li>
<li>results: 研究发现，使用逆向工程方法可以准确地掌握语言模型生成文本的参数，并且可以揭示生成文本中的偏见。<details>
<summary>Abstract</summary>
Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-$k$ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).
</details>
<details>
<summary>摘要</summary>
neural language models 是越来越常被用在 API 和网站中，允许用户输入提示并返回生成的文本。许多这些系统并不公布生成参数。在这篇论文中，我们提出了一些方法来反引出生成文本的解码方法（即 top-$k$ 或核心抽样）。我们可以找出哪种解码策略被使用，这有关检测生成文本的意义。此外，找出解码策略的过程可以暴露模型预测分布的偏见。我们对一些开源语言模型家族和生产系统（如 ChatGPT）进行了攻击。
</details></li>
</ul>
<hr>
<h2 id="AmbientFlow-Invertible-generative-models-from-incomplete-noisy-measurements"><a href="#AmbientFlow-Invertible-generative-models-from-incomplete-noisy-measurements" class="headerlink" title="AmbientFlow: Invertible generative models from incomplete, noisy measurements"></a>AmbientFlow: Invertible generative models from incomplete, noisy measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04856">http://arxiv.org/abs/2309.04856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Varun A. Kelkar, Rucha Deshpande, Arindam Banerjee, Mark A. Anastasio</li>
<li>for: 这篇论文旨在提出一种直接从含有噪声和缺失数据的方式学习流基型生成模型的框架。</li>
<li>methods: 该方法使用变分 Bayesian 方法建立流基型生成模型。</li>
<li>results: 数学实验表明，AmbientFlow 能够正确地学习物体分布。此外，AmbientFlow 在下游推理任务中的图像重建 task 中表现出色。<details>
<summary>Abstract</summary>
Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of AmbientFlow in correctly learning the object distribution. The utility of AmbientFlow in a downstream inference task of image reconstruction is demonstrated.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化字符串。<</SYS>>生成模型在成像科学中得到了广泛的应用，如图像重建、后 sampling 和数据分享。流基本生成模型尤其吸引人因为它们可以追踪性地提供精确的概率估计以及快速、便宜、多样的样本。但是训练这些模型需要一个大、高质量的对象数据集。在计算成像应用中，通常很难获得这些数据，因为需要长时间的获取或高剂量的辐射剂量，而获取噪音或部分观测这些对象的数据更加可能。在这项工作中，我们提出了 AmbientFlow，一个框架用于直接从噪音和不完整数据中学习流基本生成模型。使用变分 Bayesian 方法，我们提出了一种新的框架用于从噪音和不完整数据中建立流基本生成模型。广泛的数学实验表明 AmbientFlow 可以正确地学习对象分布。在下游推理任务中的图像重建中，AmbientFlow 的实用性得到了证明。
</details></li>
</ul>
<hr>
<h2 id="Speech-Emotion-Recognition-with-Distilled-Prosodic-and-Linguistic-Affect-Representations"><a href="#Speech-Emotion-Recognition-with-Distilled-Prosodic-and-Linguistic-Affect-Representations" class="headerlink" title="Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations"></a>Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04849">http://arxiv.org/abs/2309.04849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debaditya Shome, Ali Etemad</li>
<li>for: The paper is written for speech emotion recognition (SER) and proposes a novel framework called EmoDistill.</li>
<li>methods: The paper uses cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech, and only uses a stream of speech signals during inference to perform unimodal SER.</li>
<li>results: The paper achieves state-of-the-art performance on the IEMOCAP benchmark, with unweighted accuracy of 77.49% and weighted accuracy of 78.91%. Detailed ablation studies demonstrate the impact of each component of the proposed method.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了推动语音情感识别（SER）而写的，并提出了一种新的框架 called EmoDistill。</li>
<li>methods: 这篇论文在训练时使用了跨Modal知识传递来学习语音中情感的强大语言和 просодические表示，并只在推理时使用了一流 Speech 信号来实现单模 SER。</li>
<li>results: 这篇论文在 IEMOCAP benchmark 上实现了 state-of-the-art 性能，具体的数据如下：不weighted 精度为 77.49%，weighted 精度为 78.91%。详细的ablation 研究还示出了每个方法的影响。<details>
<summary>Abstract</summary>
We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.
</details>
<details>
<summary>摘要</summary>
我们提出了EmotionDistill，一种新的语音情感识别（SER）框架，它利用跨模态知识填充在训练时期来学习语音中的强大情感和语音表达。在推断时，我们的方法只需要一束语音信号来进行单模态SER，从而降低计算负担和避免运行时转写和语音特征提取错误。在训练时，我们的方法在教师模型的 embedding 和 logit 两级填充信息，从两个预训练的 Prosodic 和 Linguistic 教师模型，这些模型在 SER 上进行了精心调整。实验表明，我们的方法在 IEMOCAP  bencmark 上比其他单模态和多模态技术高出较大幅度，并达到了状态之artefact的性能，即不加权的准确率为 77.49%，加权的准确率为 78.91%。详细的抽象研究表明了我们的方法中每个组件的影响。
</details></li>
</ul>
<hr>
<h2 id="Verifiable-Reinforcement-Learning-Systems-via-Compositionality"><a href="#Verifiable-Reinforcement-Learning-Systems-via-Compositionality" class="headerlink" title="Verifiable Reinforcement Learning Systems via Compositionality"></a>Verifiable Reinforcement Learning Systems via Compositionality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06420">http://arxiv.org/abs/2309.06420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrus Neary, Aryaman Singh Samyal, Christos Verginis, Murat Cubuktepe, Ufuk Topcu</li>
<li>for: 这个 paper 是为了描述一种可靠和可组合的 reinforcement learning (RL) 框架，用于将多个 RL 子系统组合成一个总任务。</li>
<li>methods: 这个框架包括一个高级模型，用于规划和分析子系统的组合，以及多个低级子系统，每个子系统都是一个深度学习 RL 代理人，运行于偏见 Observability 下。</li>
<li>results: 作者们提供了理论结果，证明如果每个子系统学习一个满足其子任务规范的策略，那么其组合就可以满足总任务规范。同时，如果子任务规范无法被满足， authors 则提供了一种自动更新子任务规范的方法，以适应观察到的缺陷。这种方法形式为高级模型中的优化问题。实验结果表明该框架在具有全 observability 和 partial observability、整数和连续状态空间、抽象和随机动力等多种环境下都能够展示其特点。<details>
<summary>Abstract</summary>
We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaranteeing that if each subsystem learns a policy satisfying its subtask specification, then their composition is guaranteed to satisfy the overall task specification. Conversely, if the subtask specifications cannot all be satisfied by the learned policies, we present a method, formulated as the problem of finding an optimal set of parameters in the high-level model, to automatically update the subtask specifications to account for the observed shortcomings. The result is an iterative procedure for defining subtask specifications, and for training the subsystems to meet them. Experimental results demonstrate the presented framework's novel capabilities in environments with both full and partial observability, discrete and continuous state and action spaces, as well as deterministic and stochastic dynamics.
</details>
<details>
<summary>摘要</summary>
我们提出了一个渐进的强化学习框架，其中一个集合强化学习子系统，每个子系统都学习完成一个分离的子任务，这些子系统被组合以完成总任务。该框架包括一个高级模型，表示为Parametric Markov决策过程，用于规划和分析子系统的组合。每个子系统都是一个深度学习强化学习代理，在受限性观察下运行。通过定义子系统之间的接口，该框架允许自动将任务规范分解成各个子任务规范，例如：达到目标集的状态的概率大于或等于0.95。这样做了，可以独立地培训和测试每个子系统。我们提供了理论结果，证明如果每个子系统学习满足其子任务规范，那么其组合就会满足总任务规范。相反，如果子任务规范无法通过学习的策略满足，我们提出了一种方法，即在高级模型中寻找优化参数的问题，以自动更新子任务规范，以适应观察到的缺陷。结果是一种循环的过程，用于定义子任务规范，并培训子系统以满足它们。实验结果表明提出的框架在拥有完全和受限性观察，整数和连续状态和动作空间，以及决定性和随机动力学的环境中具有新的可能性。
</details></li>
</ul>
<hr>
<h2 id="HAct-Out-of-Distribution-Detection-with-Neural-Net-Activation-Histograms"><a href="#HAct-Out-of-Distribution-Detection-with-Neural-Net-Activation-Histograms" class="headerlink" title="HAct: Out-of-Distribution Detection with Neural Net Activation Histograms"></a>HAct: Out-of-Distribution Detection with Neural Net Activation Histograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04837">http://arxiv.org/abs/2309.04837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudeepta Mondal, Ganesh Sundaramoorthi</li>
<li>for: 检测已经训练过的神经网络模型对于未知数据的检测</li>
<li>methods: 使用一种新的描述符——HAct - 活化 histogram，对神经网络层的输出值进行检测</li>
<li>results: 在多个OOD图像分类 benchmark上显示了高度准确性，比之前的状态对照方法提高20.66%的假阳性率（在同样的TPR&#x3D;95%下），计算复杂性低、实现容易，适用于在实际中的在线监控已经训练过的神经网络模型。<details>
<summary>Abstract</summary>
We propose a simple, efficient, and accurate method for detecting out-of-distribution (OOD) data for trained neural networks, a potential first step in methods for OOD generalization. We propose a novel descriptor, HAct - activation histograms, for OOD detection, that is, probability distributions (approximated by histograms) of output values of neural network layers under the influence of incoming data. We demonstrate that HAct is significantly more accurate than state-of-the-art on multiple OOD image classification benchmarks. For instance, our approach achieves a true positive rate (TPR) of 95% with only 0.05% false-positives using Resnet-50 on standard OOD benchmarks, outperforming previous state-of-the-art by 20.66% in the false positive rate (at the same TPR of 95%). The low computational complexity and the ease of implementation make HAct suitable for online implementation in monitoring deployed neural networks in practice at scale.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Global-Convergence-of-Receding-Horizon-Policy-Search-in-Learning-Estimator-Designs"><a href="#Global-Convergence-of-Receding-Horizon-Policy-Search-in-Learning-Estimator-Designs" class="headerlink" title="Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs"></a>Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04831">http://arxiv.org/abs/2309.04831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiangyuan-zhang/learningkf">https://github.com/xiangyuan-zhang/learningkf</a></li>
<li>paper_authors: Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Başar</li>
<li>for: 本研究开发了一个名为“推导 horizon policy gradient”（RHPG）算法，用于学习最佳的线性估计设计，即卡尔曼统计（KF）。</li>
<li>methods: RHPG算法将 vanilla PG（或任何其他政策搜寻方向）与动态计划外圈组合，将无限时间KF问题转换为一系列静态估计问题，并且可以保证全球对称性。</li>
<li>results: RHPG算法可以在不知情系统的情况下，不需要任何开始值，并且不需要目标系统是开 Loop稳定的情况下，实现全球对称性。此外，研究人员还提供了优化问题的分析和数据点的保证。<details>
<summary>Abstract</summary>
We introduce the receding-horizon policy gradient (RHPG) algorithm, the first PG algorithm with provable global convergence in learning the optimal linear estimator designs, i.e., the Kalman filter (KF). Notably, the RHPG algorithm does not require any prior knowledge of the system for initialization and does not require the target system to be open-loop stable. The key of RHPG is that we integrate vanilla PG (or any other policy search directions) into a dynamic programming outer loop, which iteratively decomposes the infinite-horizon KF problem that is constrained and non-convex in the policy parameter into a sequence of static estimation problems that are unconstrained and strongly-convex, thus enabling global convergence. We further provide fine-grained analyses of the optimization landscape under RHPG and detail the convergence and sample complexity guarantees of the algorithm. This work serves as an initial attempt to develop reinforcement learning algorithms specifically for control applications with performance guarantees by utilizing classic control theory in both algorithmic design and theoretical analyses. Lastly, we validate our theories by deploying the RHPG algorithm to learn the Kalman filter design of a large-scale convection-diffusion model. We open-source the code repository at \url{https://github.com/xiangyuan-zhang/LearningKF}.
</details>
<details>
<summary>摘要</summary>
我们介绍了往返Horizon Policy Gradient（RHPG）算法，是第一个可证地全球化 converge 的Policy Gradient（PG）算法，用于学习最佳的线性估计设计（即Kalman Filter，KF）。特别是，RHPG算法不需要任何系统开关的启动知识，并且不需要目标系统是开loop稳定。RHPG的关键在于将vanilla PG（或任何其他policy搜索方向）integrated into a dynamic programming outer loop，将无限期KF问题分解为一系列静止估计问题，从而实现全球化 converge。我们还提供了细部分析估计的Optimization landscape under RHPG，并详细说明算法的数据Complexity和数据对称性。这个工作作为开发基于控制应用的循环学习算法，并通过使用 класи控制理论在算法设计和理论分析中使用。最后，我们验证了我们的理论，通过将RHPG算法应用于大规模的对流扩散模型中来学习Kalman filter设计。我们将代码存储在 GitHub 上，请见 \url{https://github.com/xiangyuan-zhang/LearningKF}.
</details></li>
</ul>
<hr>
<h2 id="Correcting-sampling-biases-via-importancereweighting-for-spatial-modeling"><a href="#Correcting-sampling-biases-via-importancereweighting-for-spatial-modeling" class="headerlink" title="Correcting sampling biases via importancereweighting for spatial modeling"></a>Correcting sampling biases via importancereweighting for spatial modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04824">http://arxiv.org/abs/2309.04824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boris Prokhorov, Diana Koldasbayeva, Alexey Zaytsev</li>
<li>for:  This paper aims to address the problem of distribution bias in machine learning models for spatial data, particularly in environmental studies.</li>
<li>methods: The authors propose an approach based on importance sampling to obtain an unbiased estimate of the target error. They use importance sampling technique and kernel density estimation to reweigh errors at each sample point and neutralize the shift.</li>
<li>results: The authors validate the effectiveness of their approach using artificial data that resemble real-world spatial datasets. Their findings demonstrate the advantages of the proposed approach for the estimation of the target error, offering a solution to the distribution shift problem. The overall error of predictions decreased from 7% to just 2% and gets smaller for larger samples.Here’s the same information in Traditional Chinese:</li>
<li>for: 这篇论文的目的是解决机器学习模型在空间数据中的分布偏见问题，特别是在环境研究中。</li>
<li>methods: 作者提出一种基于重要抽样的方法，以获得不偏的目标错误估计。他们使用重要抽样技术和核密度估计来重新衡量错误的重要性，并neutralize偏移。</li>
<li>results: 作者使用实验数据验证了他们的方法，结果显示了这种方法在目标错误估计中的优势。错误率从7%降至2%，并且随着样本规模的增加而减少。<details>
<summary>Abstract</summary>
In machine learning models, the estimation of errors is often complex due to distribution bias, particularly in spatial data such as those found in environmental studies. We introduce an approach based on the ideas of importance sampling to obtain an unbiased estimate of the target error. By taking into account difference between desirable error and available data, our method reweights errors at each sample point and neutralizes the shift. Importance sampling technique and kernel density estimation were used for reweighteing. We validate the effectiveness of our approach using artificial data that resemble real-world spatial datasets. Our findings demonstrate advantages of the proposed approach for the estimation of the target error, offering a solution to a distribution shift problem. Overall error of predictions dropped from 7% to just 2% and it gets smaller for larger samples.
</details>
<details>
<summary>摘要</summary>
在机器学习模型中，错误估计通常受到分布偏见的影响，特别是在环境学研究中的空间数据中。我们介绍了基于重要性抽样的方法，以获取不偏的目标错误估计。通过考虑愿望的错误和可用数据之间的差异，我们的方法在每个样点重新权重错误。我们使用重要性抽样技术和核密度估计来实现重新权重。我们使用人工数据，模拟现实世界的空间数据集，以验证我们的方法的效果。我们的发现表明，我们的方法可以减少预测错误的总错误率，从7%降至2%，并且随着样本规模增加，错误率变得更加小。
</details></li>
</ul>
<hr>
<h2 id="ABC-Easy-as-123-A-Blind-Counter-for-Exemplar-Free-Multi-Class-Class-agnostic-Counting"><a href="#ABC-Easy-as-123-A-Blind-Counter-for-Exemplar-Free-Multi-Class-Class-agnostic-Counting" class="headerlink" title="ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting"></a>ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04820">http://arxiv.org/abs/2309.04820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael A. Hobley, Victor A. Prisacariu</li>
<li>for: 本研究旨在提供一种不需要类例或图像中只含一种对象的情况下，能够对多种对象进行分类不受限制的 counting 方法。</li>
<li>methods: 该方法基于一个新的 paradigm，即在批量计数阶段不需要用例来引导计数，而是在计数后找到对应的类别示例来帮助用户理解生成的输出。</li>
<li>results: 对于 MCAC 数据集，该方法可以与 contemporary methods 相比，而无需人工循环注解。此外，该方法还可以在 FSC-147 数据集上达到类似的性能。<details>
<summary>Abstract</summary>
Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的类型不承诺的计数方法只能 Count objects of a specific class, which has limited utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset.中文简体版：传统的类型不承诺的计数方法只能 Count objects of a specific class, 这限制了其在多个领域的应用 utility. 先前的工作受到了限制，因为它们需要 Either a set of examples of the type to be counted or that the image contains only a single type of object. 这些缺点中的一个重要因素是缺乏适用于多种对象的计数的数据集。 To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset.
</details></li>
</ul>
<hr>
<h2 id="Detecting-Violations-of-Differential-Privacy-for-Quantum-Algorithms"><a href="#Detecting-Violations-of-Differential-Privacy-for-Quantum-Algorithms" class="headerlink" title="Detecting Violations of Differential Privacy for Quantum Algorithms"></a>Detecting Violations of Differential Privacy for Quantum Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04819">http://arxiv.org/abs/2309.04819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ji Guan, Wang Fang, Mingyu Huang, Mingsheng Ying</li>
<li>for: This paper aims to provide a formal framework for detecting violations of differential privacy in quantum algorithms, and to develop a detection algorithm that can automatically generate bugging information when a violation is reported.</li>
<li>methods: The proposed algorithm uses Tensor Networks, a highly efficient data structure, and is executed on TensorFlow Quantum and TorchQuantum, the quantum extensions of TensorFlow and PyTorch respectively.</li>
<li>results: The algorithm is effective and efficient, as demonstrated by experimental results on realistic quantum computers, including quantum supremacy algorithms, quantum machine learning models, quantum approximate optimization algorithms, and variational quantum eigensolvers with up to 21 quantum bits.<details>
<summary>Abstract</summary>
Quantum algorithms for solving a wide range of practical problems have been proposed in the last ten years, such as data search and analysis, product recommendation, and credit scoring. The concern about privacy and other ethical issues in quantum computing naturally rises up. In this paper, we define a formal framework for detecting violations of differential privacy for quantum algorithms. A detection algorithm is developed to verify whether a (noisy) quantum algorithm is differentially private and automatically generate bugging information when the violation of differential privacy is reported. The information consists of a pair of quantum states that violate the privacy, to illustrate the cause of the violation. Our algorithm is equipped with Tensor Networks, a highly efficient data structure, and executed both on TensorFlow Quantum and TorchQuantum which are the quantum extensions of famous machine learning platforms -- TensorFlow and PyTorch, respectively. The effectiveness and efficiency of our algorithm are confirmed by the experimental results of almost all types of quantum algorithms already implemented on realistic quantum computers, including quantum supremacy algorithms (beyond the capability of classical algorithms), quantum machine learning models, quantum approximate optimization algorithms, and variational quantum eigensolvers with up to 21 quantum bits.
</details>
<details>
<summary>摘要</summary>
近十年内，有许多关于解决实际问题的量子算法提议，如数据搜索和分析、产品推荐和借记评分。随着量子计算技术的发展，关注隐私和其他伦理问题的担忧自然而生。本文提出了一种形式化的检测方案，用于检测量子算法中的不同敏感度隐私泄露。我们开发了一种检测算法，用于验证（含噪）量子算法是否遵循不同敏感度隐私原则，并自动生成遵循不同敏感度隐私原则的报警信息。报警信息包括两个量子态，用于说明遵循不同敏感度隐私原则的原因。我们的算法采用了紧凑网络，一种高效的数据结构，并在TensorFlow Quantum和TorchQuantum上执行，这两者分别是классической机器学习平台TensorFlow和PyTorch的量子扩展。我们的实验结果表明，我们的算法在实际量子计算机器上具有高效和高可靠性。
</details></li>
</ul>
<hr>
<h2 id="Good-looking-but-Lacking-Faithfulness-Understanding-Local-Explanation-Methods-through-Trend-based-Testing"><a href="#Good-looking-but-Lacking-Faithfulness-Understanding-Local-Explanation-Methods-through-Trend-based-Testing" class="headerlink" title="Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing"></a>Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05679">http://arxiv.org/abs/2309.05679</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jenniferho97/xai-trend-test">https://github.com/jenniferho97/xai-trend-test</a></li>
<li>paper_authors: Jinwen He, Kai Chen, Guozhu Meng, Jiangshan Zhang, Congyi Li</li>
<li>for: 本研究旨在评估模型决策的解释方法的准确性，并提出三种趋势基于的准确性测试方法，以解决传统测试中随机选择问题。</li>
<li>methods: 本研究使用了多种现有的解释方法，并对其进行了评估。同时，研究人员还提出了三种新的趋势基于的准确性测试方法。</li>
<li>results: 研究人员通过对多种数据集进行测试，发现传统测试方法受到随机选择问题的影响，而新提出的趋势基于测试方法可以更好地评估解释方法的准确性。此外，研究人员还发现，通过使用 faithful explanation methods，可以更好地检测和修复模型的准确性和安全问题。<details>
<summary>Abstract</summary>
While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.
</details>
<details>
<summary>摘要</summary>
在享受深度学习（DL）的伟大成就时，人们也担心DL模型做出的决策，因为DL模型的高度非线性使决策变得极Difficult to understand。因此，袭击如 adversarial attacks 易于实施，但Difficult to detect and explain，这导致了对模型决策的解释方法的研究繁荣。在这篇论文中，我们评估解释方法的准确性，发现传统的准确性测试陷入随机控制问题，即随机选择perform the best， especial for complex data。为了解决这问题，我们提出三种趋势基于的准确性测试，并employs empirical demonstration that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.
</details></li>
</ul>
<hr>
<h2 id="Neural-Latent-Geometry-Search-Product-Manifold-Inference-via-Gromov-Hausdorff-Informed-Bayesian-Optimization"><a href="#Neural-Latent-Geometry-Search-Product-Manifold-Inference-via-Gromov-Hausdorff-Informed-Bayesian-Optimization" class="headerlink" title="Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization"></a>Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04810">http://arxiv.org/abs/2309.04810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitz Saez de Ocariz Borde, Alvaro Arroyo, Ismael Morales, Ingmar Posner, Xiaowen Dong<br>for: 这种研究的目的是提高机器学习模型的性能，通过调整 latent space 的几何结构来更好地模型 latent space 和下游任务之间的关系。methods: 这种方法使用了 hyperbolic 和 spherical space 作为 constant curvature 的 latent space，并使用 Gromov-Hausdorff distance 来比较不同的 latent geometry 的距离。在计算 Gromov-Hausdorff distance 时，我们引入了一种映射函数，以将不同的 manifold 映射到共同的高维抽象空间中，从而使得 comparison  posible。results: 实验表明，这种方法可以减少 query 数量，并且可以有效地搜索出最佳的 latent geometry，以提高机器学习模型的性能。这种方法可以应用于多种模型和下游任务。<details>
<summary>Abstract</summary>
Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Hausdorff distance, we introduce a mapping function that enables the comparison of different manifolds by embedding them in a common high-dimensional ambient space. Finally, we design a graph search space based on the calculated distances between candidate manifolds and use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This is a general method which can be applied to search for the optimal latent geometry for a variety of models and downstream tasks. Extensive experiments on synthetic and real-world datasets confirm the efficacy of our method in identifying the optimal latent geometry for multiple machine learning problems.
</details>
<details>
<summary>摘要</summary>
近期研究表明，机器学习模型的性能可以通过调整秘密空间的几何结构来提高。而不是仅仅采用欧几何空间，研究人员已经提议使用弯曲和球形空间或这些空间的组合来更好地模型秘密空间，从而提高模型性能。然而，对于找到最佳秘密空间的自动化问题尚未受到充分关注。我们在这篇文章中Mathematically定义了这个新的形ulation，并称之为神经秘密空间搜索（NLGS）。更 specifically，我们提出了一种原则性的方法，该方法在最小的查询评估数量下搜索一个由常数曲率模型空间组成的秘密空间。为了实现这一点，我们提出了一种新的距离函数，该函数基于几何 геомет里的Gromov-Hausdorff距离来衡量不同的秘密空间之间的距离。为了计算Gromov-Hausdorff距离，我们引入了一种映射函数，该函数将不同的抽象空间映射到一个共同的高维空间中。最后，我们设计了一个基于计算的距离之间的搜索空间，并使用 Bayesian优化来寻找最佳的秘密空间。这种方法可以应用于多种模型和下游任务中搜索最佳的秘密空间。我们在 sintetic和实际数据集上进行了广泛的实验，并证明了我们的方法可以有效地Identify最佳秘密空间 для多个机器学习问题。
</details></li>
</ul>
<hr>
<h2 id="A-Full-fledged-Commit-Message-Quality-Checker-Based-on-Machine-Learning"><a href="#A-Full-fledged-Commit-Message-Quality-Checker-Based-on-Machine-Learning" class="headerlink" title="A Full-fledged Commit Message Quality Checker Based on Machine Learning"></a>A Full-fledged Commit Message Quality Checker Based on Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04797">http://arxiv.org/abs/2309.04797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/commit-message-collective/beams-commit-message-checker">https://github.com/commit-message-collective/beams-commit-message-checker</a></li>
<li>paper_authors: David Faragó, Michael Färber, Christian Petrov</li>
<li>for: 提高 commits 质量，包括含义和上下文，以便更好地维护和演化软件。</li>
<li>methods: 使用机器学习方法测试 commits 质量，包括遵循最流行的质量指南所有规则。</li>
<li>results: 通过训练和评估当今最佳机器学习模型，可以达到82.9%的 F$_1$ 分数，用于解决最复杂的任务。<details>
<summary>Abstract</summary>
Commit messages (CMs) are an essential part of version control. By providing important context in regard to what has changed and why, they strongly support software maintenance and evolution. But writing good CMs is difficult and often neglected by developers. So far, there is no tool suitable for practice that automatically assesses how well a CM is written, including its meaning and context. Since this task is challenging, we ask the research question: how well can the CM quality, including semantics and context, be measured with machine learning methods? By considering all rules from the most popular CM quality guideline, creating datasets for those rules, and training and evaluating state-of-the-art machine learning models to check those rules, we can answer the research question with: sufficiently well for practice, with the lowest F$_1$ score of 82.9\%, for the most challenging task. We develop a full-fledged open-source framework that checks all these CM quality rules. It is useful for research, e.g., automatic CM generation, but most importantly for software practitioners to raise the quality of CMs and thus the maintainability and evolution speed of their software.
</details>
<details>
<summary>摘要</summary>
版本控制中的提交信息（CM）是软件维护和演化的重要组成部分。它们提供了改变的重要上下文和原因，以支持软件的维护和演化。但是编写好CM是困难的，并且开发者frequently Neglects it。到目前为止，没有一个适合实践的工具可以自动评估CM的质量，包括它的 semantics和context。因此，我们提出了一个研究问题：可以使用机器学习方法来评估CM质量，包括semantics和context？我们考虑了最受欢迎的CM质量指南中的所有规则，创建了相应的数据集，并使用了当前最佳的机器学习模型来检查这些规则。我们发现，使用机器学习方法可以评估CM质量，并且最低的F1分数为82.9%，这是最复杂的任务。我们开发了一个全功能的开源框架，可以检查所有CM质量规则。它不仅有用于研究，例如自动生成CM，而且更重要的是为软件实践人员提高CM质量，从而提高软件的维护和演化速度。
</details></li>
</ul>
<hr>
<h2 id="Stochastic-Gradient-Descent-outperforms-Gradient-Descent-in-recovering-a-high-dimensional-signal-in-a-glassy-energy-landscape"><a href="#Stochastic-Gradient-Descent-outperforms-Gradient-Descent-in-recovering-a-high-dimensional-signal-in-a-glassy-energy-landscape" class="headerlink" title="Stochastic Gradient Descent outperforms Gradient Descent in recovering a high-dimensional signal in a glassy energy landscape"></a>Stochastic Gradient Descent outperforms Gradient Descent in recovering a high-dimensional signal in a glassy energy landscape</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04788">http://arxiv.org/abs/2309.04788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Persia Jana Kamali, Pierfrancesco Urbani</li>
<li>for: 该论文主要研究了Stochastic Gradient Descent（SGD）算法在高维非对称优化问题中的效果，以及SGD与Gradient Descent（GD）算法之间的比较。</li>
<li>methods: 该论文使用了动态均衡理论来分析SGD算法在高维限制下的性能，并对SGD和GD算法进行比较。</li>
<li>results: 研究发现，SGD算法在高维非对称优化问题中表现比GD算法更好，具体来说，SGD算法的恢复阈值在小批处理情况下比GD算法要小。<details>
<summary>Abstract</summary>
Stochastic Gradient Descent (SGD) is an out-of-equilibrium algorithm used extensively to train artificial neural networks. However very little is known on to what extent SGD is crucial for to the success of this technology and, in particular, how much it is effective in optimizing high-dimensional non-convex cost functions as compared to other optimization algorithms such as Gradient Descent (GD). In this work we leverage dynamical mean field theory to analyze exactly its performances in the high-dimensional limit. We consider the problem of recovering a hidden high-dimensional non-linearly encrypted signal, a prototype high-dimensional non-convex hard optimization problem. We compare the performances of SGD to GD and we show that SGD largely outperforms GD. In particular, a power law fit of the relaxation time of these algorithms shows that the recovery threshold for SGD with small batch size is smaller than the corresponding one of GD.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RRCNN-An-Enhanced-Residual-Recursive-Convolutional-Neural-Network-for-Non-stationary-Signal-Decomposition"><a href="#RRCNN-An-Enhanced-Residual-Recursive-Convolutional-Neural-Network-for-Non-stationary-Signal-Decomposition" class="headerlink" title="RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition"></a>RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04782">http://arxiv.org/abs/2309.04782</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhoudafa08/RRCNN_plus">https://github.com/zhoudafa08/RRCNN_plus</a></li>
<li>paper_authors: Feng Zhou, Antonio Cicone, Haomin Zhou</li>
<li>for: 该研究旨在提高非站立波形分解方法，以提高时频分析的精度和效率。</li>
<li>methods: 该研究使用了一种新的差分征分法，即差分征回归神经网络（RRCNN），以及一些深度学习和优化技术来改进非站立波形分解方法。</li>
<li>results: 研究表明，RRCNN可以在大规模信号批处理中实现更稳定的分解，并且可以提高时频分析的精度和效率。<details>
<summary>Abstract</summary>
Time-frequency analysis is an important and challenging task in many applications. Fourier and wavelet analysis are two classic methods that have achieved remarkable success in many fields. They also exhibit limitations when applied to nonlinear and non-stationary signals. To address this challenge, a series of nonlinear and adaptive methods, pioneered by the empirical mode decomposition method have been proposed. Their aim is to decompose a non-stationary signal into quasi-stationary components which reveal better features in the time-frequency analysis. Recently, inspired by deep learning, we proposed a novel method called residual recursive convolutional neural network (RRCNN). Not only RRCNN can achieve more stable decomposition than existing methods while batch processing large-scale signals with low computational cost, but also deep learning provides a unique perspective for non-stationary signal decomposition. In this study, we aim to further improve RRCNN with the help of several nimble techniques from deep learning and optimization to ameliorate the method and overcome some of the limitations of this technique.
</details>
<details>
<summary>摘要</summary>
时频分析是许多应用领域中的重要和挑战性任务。法ouvrier和浪涌分析是经典的方法，在许多领域取得了很大成功。但它们在非线性和不稳定信号处理时表现出限制。为了解决这个挑战，一系列基于实验模式分解方法已经被提出，其目的是将非稳定信号分解成可见更好的时频特征。最近，深度学习的灵感下，我们提出了一种新的方法 called residual recursive convolutional neural network (RRCNN)。除了RRCNN可以在批处理大规模信号时实现更稳定的分解，同时计算成本也很低，而且深度学习带来了非站ARY信号分解的新视角。在这项研究中，我们想使用深度学习和优化技术来改进RRCNN，并解决一些这种技术的限制。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Model-Watermark-via-Reducing-Parametric-Vulnerability"><a href="#Towards-Robust-Model-Watermark-via-Reducing-Parametric-Vulnerability" class="headerlink" title="Towards Robust Model Watermark via Reducing Parametric Vulnerability"></a>Towards Robust Model Watermark via Reducing Parametric Vulnerability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04777">http://arxiv.org/abs/2309.04777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanhaogan/robust-model-watermarking">https://github.com/guanhaogan/robust-model-watermarking</a></li>
<li>paper_authors: Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia</li>
<li>for: 保护深度神经网络（DNN）的版权，防止其被不当使用或盗用。</li>
<li>methods: 使用后门机制（backdoor）进行权利识别，在发布模型时 embed 特定的后门行为，以便在使用模型时能够识别是否有人对模型进行了非法修改或使用。</li>
<li>results: 发现 watermark 可能被移除的问题，并提出了一种 mini-max 形式来恢复 watermark 行为，并在各种 parametric 变化和 watermark-removal 攻击下进行了广泛的实验，证明了该方法可以提高模型 watermarking 的Robustness。<details>
<summary>Abstract</summary>
Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly annotation and computation resources. To protect the copyright of DNNs, backdoor-based ownership verification becomes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is ``stolen'' from them based on the presence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks. Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their watermark behavior. Extensive experiments demonstrate that our method improves the robustness of the model watermarking against parametric changes and numerous watermark-removal attacks. The codes for reproducing our main experiments are available at \url{https://github.com/GuanhaoGan/robust-model-watermarking}.
</details>
<details>
<summary>摘要</summary>
深度神经网络是非常有价值的资产，因为它们在商业上有很大的市场需求和高昂的注入和计算资源成本。为了保护神经网络的版权，在最近几年内，以下行为检查成为了非常流行的方法：在发布神经网络之前，将模型嵌入特定的后门行为。这样，作者可以识别他们的模型是否被“盗”使用，并且可以通过检查后门行为来确定。然而，这些后门嵌入在 watermark 的存在下是易受到移除攻击的。为了更深入了解这一点，我们对参数空间进行了调查，并发现了许多 watermark 已经被移除的模型，这些模型可能容易被用于移除攻击。受这一发现的激发，我们提出了一种最大化-最小化形式来找到这些 watermark 已经被移除的模型，并将其恢复到原始的 watermark 行为。我们的方法可以增强神经网络嵌入的模型水印的可靠性，并对于不同的参数变化和多种水印移除攻击表现出良好的效果。相关的代码可以在 <https://github.com/GuanhaoGan/robust-model-watermarking> 上找到，以便进行重现主要实验。
</details></li>
</ul>
<hr>
<h2 id="AudRandAug-Random-Image-Augmentations-for-Audio-Classification"><a href="#AudRandAug-Random-Image-Augmentations-for-Audio-Classification" class="headerlink" title="AudRandAug: Random Image Augmentations for Audio Classification"></a>AudRandAug: Random Image Augmentations for Audio Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04762">http://arxiv.org/abs/2309.04762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/turab45/audrandaug">https://github.com/turab45/audrandaug</a></li>
<li>paper_authors: Teerath Kumar, Muhammad Turab, Alessandra Mileo, Malika Bendechache, Takfarinas Saber</li>
<li>for: 增强 neural network 训练效果</li>
<li>methods: 随机选择数据增强技术从预定搜索空间</li>
<li>results: 对各种模型和数据集进行实验，发现 AudRandAug 的准确性表现比其他数据增强方法更高。<details>
<summary>Abstract</summary>
Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance." into 简体中文Here's the translation:数据增强已经证明对神经网络训练有效。最近，一种方法叫做RandAug被提出，随机从预定搜索空间中选择数据增强策略。RandAug在图像相关任务上显示了显著性能提升，而且对计算负担占有最小化。然而，没有先前的研究探讨了将RandAug专门应用于音频数据增强，即将音频转换为图像样式。为了填补这个空白，我们介绍了AudRandAug，它是RandAug的音频数据变换版本。AudRandAug从专门的音频搜索空间中选择数据增强策略。为了评估AudRandAug的效果，我们使用了不同的模型和数据集进行实验。我们的发现表明，AudRandAug在准确性性能方面超过了现有的数据增强方法。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Survey-on-Deep-Learning-Techniques-in-Educational-Data-Mining"><a href="#A-Comprehensive-Survey-on-Deep-Learning-Techniques-in-Educational-Data-Mining" class="headerlink" title="A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining"></a>A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04761">http://arxiv.org/abs/2309.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanguo Lin, Hong Chen, Wei Xia, Fan Lin, Pengcheng Wu, Zongyue Wang, Yong Li</li>
<li>for: 这篇论文主要用于系统性地介绍现代教育中使用深度学习技术的教育数据挖掘（EDM）。</li>
<li>methods: 本文使用深度学习技术来分析和模型教育数据，包括知识追踪、不良学生检测、性能预测和个性化推荐等四种教育场景。</li>
<li>results: 本文提供了一系列公共数据集和处理工具，并概括了深度学习在 EDM 中的应用和前景。<details>
<summary>Abstract</summary>
Educational Data Mining (EDM) has emerged as a vital field of research, which harnesses the power of computational techniques to analyze educational data. With the increasing complexity and diversity of educational data, Deep Learning techniques have shown significant advantages in addressing the challenges associated with analyzing and modeling this data. This survey aims to systematically review the state-of-the-art in EDM with Deep Learning. We begin by providing a brief introduction to EDM and Deep Learning, highlighting their relevance in the context of modern education. Next, we present a detailed review of Deep Learning techniques applied in four typical educational scenarios, including knowledge tracing, undesirable student detecting, performance prediction, and personalized recommendation. Furthermore, a comprehensive overview of public datasets and processing tools for EDM is provided. Finally, we point out emerging trends and future directions in this research area.
</details>
<details>
<summary>摘要</summary>
教育数据挖掘（EDM）已经成为现代教育研究的重要领域，利用计算机技术来分析教育数据。随着教育数据的复杂度和多样性的增加，深度学习技术在处理和建模这些数据方面表现出了显著的优势。本文尝试系统地综述现代EDM领域中深度学习的状况。我们首先介绍EDM和深度学习的基本概念，并将其应用于现代教育中的四个典型场景：知识跟踪、不良学生检测、性能预测和个性化推荐。此外，我们还提供了教育数据公共数据集和处理工具的全面回顾。最后，我们讨论了现代教育研究领域的发展趋势和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Gromov-Hausdorff-Distances-for-Comparing-Product-Manifolds-of-Model-Spaces"><a href="#Gromov-Hausdorff-Distances-for-Comparing-Product-Manifolds-of-Model-Spaces" class="headerlink" title="Gromov-Hausdorff Distances for Comparing Product Manifolds of Model Spaces"></a>Gromov-Hausdorff Distances for Comparing Product Manifolds of Model Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05678">http://arxiv.org/abs/2309.05678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitz Saez de Ocariz Borde, Alvaro Arroyo, Ismael Morales, Ingmar Posner, Xiaowen Dong</li>
<li>for: 提高机器学习模型的性能，通过将潜在空间的几何特征与数据结构相匹配。</li>
<li>methods: 使用不同的欧几何空间和圆板空间，或者其组合，并使用图搜索空间来搜索最佳潜在几何。</li>
<li>results: 提出了一种新的距离度量方法，用于 comparing candidate latent geometries，并实现了其计算方法。<details>
<summary>Abstract</summary>
Recent studies propose enhancing machine learning models by aligning the geometric characteristics of the latent space with the underlying data structure. Instead of relying solely on Euclidean space, researchers have suggested using hyperbolic and spherical spaces with constant curvature, or their combinations (known as product manifolds), to improve model performance. However, there exists no principled technique to determine the best latent product manifold signature, which refers to the choice and dimensionality of manifold components. To address this, we introduce a novel notion of distance between candidate latent geometries using the Gromov-Hausdorff distance from metric geometry. We propose using a graph search space that uses the estimated Gromov-Hausdorff distances to search for the optimal latent geometry. In this work we focus on providing a description of an algorithm to compute the Gromov-Hausdorff distance between model spaces and its computational implementation.
</details>
<details>
<summary>摘要</summary>
最近的研究提议通过将 latent space 的几何特征与数据结构相对应来提高机器学习模型的性能。而不是仅仅采用欧几何空间，研究人员建议使用偏折射空间和球形空间，或者这两种空间的组合（称为产品 manifold），以提高模型表现。然而，选择最佳 latent product manifold 签名仍然存在无原则的问题。为解决这个问题，我们提出了一种新的 latent geometry 评估方法，基于 metric geometry 中的 Gromov-Hausdorff 距离。我们建议使用图earch space 来搜索最佳 latent geometry。在这篇文章中，我们将关注提出一种算法来计算 Gromov-Hausdorff 距离 между模型空间，以及其计算实现方法。
</details></li>
</ul>
<hr>
<h2 id="RR-CP-Reliable-Region-Based-Conformal-Prediction-for-Trustworthy-Medical-Image-Classification"><a href="#RR-CP-Reliable-Region-Based-Conformal-Prediction-for-Trustworthy-Medical-Image-Classification" class="headerlink" title="RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification"></a>RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04760">http://arxiv.org/abs/2309.04760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhe Zhang, Shuo Wang, Yejia Zhang, Danny Z. Chen</li>
<li>for:  This paper aims to improve the accuracy and efficiency of conformal prediction (CP) in medical AI decision-making.</li>
<li>methods: The proposed method, Reliable-Region-Based Conformal Prediction (RR-CP), uses a stronger statistical guarantee to achieve a user-specified error rate (e.g., 0.5%) while optimizing the size of the prediction set.</li>
<li>results: Experimental results on five public datasets show that RR-CP performs well, achieving the user-specified error rate significantly more frequently than existing CP methods, with a reasonably small-sized prediction set.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文目标是提高医疗AI决策中的准确率和效率，通过改进准确预测（CP）方法。</li>
<li>methods: 提议的方法是可靠区域基于准确预测（RR-CP），通过更加强的统计保证来实现用户指定的错误率（例如0.5%），同时优化预测集的大小。</li>
<li>results: 实验结果表明，RR-CP在五个公共数据集上表现良好，能够达到用户指定的错误率（例如0.5%），与现有CP方法相比，具有更加小的预测集大小。<details>
<summary>Abstract</summary>
Conformal prediction (CP) generates a set of predictions for a given test sample such that the prediction set almost always contains the true label (e.g., 99.5\% of the time). CP provides comprehensive predictions on possible labels of a given test sample, and the size of the set indicates how certain the predictions are (e.g., a set larger than one is `uncertain'). Such distinct properties of CP enable effective collaborations between human experts and medical AI models, allowing efficient intervention and quality check in clinical decision-making. In this paper, we propose a new method called Reliable-Region-Based Conformal Prediction (RR-CP), which aims to impose a stronger statistical guarantee so that the user-specified error rate (e.g., 0.5\%) can be achieved in the test time, and under this constraint, the size of the prediction set is optimized (to be small). We consider a small prediction set size an important measure only when the user-specified error rate is achieved. Experiments on five public datasets show that our RR-CP performs well: with a reasonably small-sized prediction set, it achieves the user-specified error rate (e.g., 0.5\%) significantly more frequently than exiting CP methods.
</details>
<details>
<summary>摘要</summary>
具有遵循性预测（CP）生成测试样本的集合，其中集合中的标签几乎总是正确的（例如，99.5%的时间）。CP提供了测试样本可能的标签预测，并且预测集合的大小表示预测的置信度（例如，一个集合大于一个是不确定）。这些CP的特点使得人工专家和医疗AI模型之间的合作更加有效，可以快速 intervene和质量检查在临床决策中。在这篇论文中，我们提出了一种新的方法called Reliable-Region-Based Conformal Prediction（RR-CP），该方法的目的是在测试时间内，通过更加强的统计保证，使用户指定的错误率（例如，0.5%）得到实现，并在这个约束下优化预测集合的大小（使其小）。我们认为在实现用户指定的错误率时，小型预测集合是重要的指标。在五个公共数据集上进行了实验，我们的RR-CP表现良好：与其他CP方法相比，它在实现用户指定的错误率（例如，0.5%）时，有reasonably小的预测集合，并且能够达到用户指定的错误率，而其他CP方法则不能达到这个目标。
</details></li>
</ul>
<hr>
<h2 id="Affine-Invariant-Ensemble-Transform-Methods-to-Improve-Predictive-Uncertainty-in-ReLU-Networks"><a href="#Affine-Invariant-Ensemble-Transform-Methods-to-Improve-Predictive-Uncertainty-in-ReLU-Networks" class="headerlink" title="Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in ReLU Networks"></a>Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in ReLU Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04742">http://arxiv.org/abs/2309.04742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diksha Bhandari, Jakiw Pidstrigach, Sebastian Reich</li>
<li>for: 本研究旨在使用适当扩展的ensemble Kalman统计量perform Bayesian推论 для逻辑回传 regression。</li>
<li>methods: 本研究提出了两种互动运行的粒子系统，用于范畴 posterior的抽样，并证明了这些粒子系统在粒子数量趋向无限大时对mean-field限的量化快速传递率。</li>
<li>results: 本研究运用了这些技术，并将其应用于ReLU网络中的preditive uncertainty量化。<details>
<summary>Abstract</summary>
We consider the problem of performing Bayesian inference for logistic regression using appropriate extensions of the ensemble Kalman filter. Two interacting particle systems are proposed that sample from an approximate posterior and prove quantitative convergence rates of these interacting particle systems to their mean-field limit as the number of particles tends to infinity. Furthermore, we apply these techniques and examine their effectiveness as methods of Bayesian approximation for quantifying predictive uncertainty in ReLU networks.
</details>
<details>
<summary>摘要</summary>
我团队考虑使用适当的拓展 Ensemble Kalman 筛子来进行 bayesian 推断，以便更好地评估 ReLU 网络中预测不确定性。我们提出了两种互动的 particle 系统，这些系统可以从 approximate  posterior 中采样，并证明这些互动 particle 系统在粒度趋于无穷时，与其mean-field 限制之间存在量化的减少速率。此外，我们应用这些技术，并对它们在 ReLU 网络中的效果进行了评估。Here's the breakdown of the translation:* "We consider the problem of performing Bayesian inference for logistic regression" becomes 我团队考虑使用适当的拓展 Ensemble Kalman 筛子来进行 bayesian 推断 (wǒ tuán xiāng yù zhī yì yóu yì yóu zhī shì yì yóu bā yì yīn xìng)* "using appropriate extensions of the ensemble Kalman filter" becomes 使用适当的拓展 Ensemble Kalman 筛子 (fù zhī yì yóu yì yóu zhī shì)* "Two interacting particle systems are proposed" becomes 我们提出了两种互动的 particle 系统 (wǒ men tím zhāng le yī yī zhī yì yóu zhī xìng)* "that sample from an approximate posterior" becomes 这些系统可以从 approximate  posterior 中采样 (zhè xiē xìng zhī yì zhī yì yóu zhī xìng)* "and prove quantitative convergence rates of these interacting particle systems to their mean-field limit as the number of particles tends to infinity" becomes 并证明这些互动 particle 系统在粒度趋于无穷时，与其mean-field 限制之间存在量化的减少速率 (ér qiè míng yǐ jīn yǐ zhī yì yóu zhī xìng zhī shì yì yóu)* "Furthermore, we apply these techniques and examine their effectiveness as methods of Bayesian approximation for quantifying predictive uncertainty in ReLU networks" becomes 此外，我们应用这些技术，并对它们在 ReLU 网络中的效果进行了评估 (qí wài, wǒ men yì yì yóu zhī shì yì yóu zhī xìng zhī shì)
</details></li>
</ul>
<hr>
<h2 id="Training-of-Spiking-Neural-Network-joint-Curriculum-Learning-Strategy"><a href="#Training-of-Spiking-Neural-Network-joint-Curriculum-Learning-Strategy" class="headerlink" title="Training of Spiking Neural Network joint Curriculum Learning Strategy"></a>Training of Spiking Neural Network joint Curriculum Learning Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04737">http://arxiv.org/abs/2309.04737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingling Tang, Jielei Chu, Zhiguo Gong, Tianrui Li</li>
<li>For: 提高神经网络模型的生物学可靠性，使其更像人类学习过程。* Methods: 引入课程学习策略（CL）到神经网络中，通过不同难度水平的样本进行自适应训练，提高模型的生物学可靠性和可解释性。* Results: 在静止图像集MNIST、Fashion-MNIST、CIFAR10以及神经元 datasets N-MNIST、CIFAR10-DVS、DVS-Gesture上进行了实验，结果很有 promise。据我们知道，这是首个通过引入CL提高神经网络模型的生物学可靠性的提议。<details>
<summary>Abstract</summary>
Starting with small and simple concepts, and gradually introducing complex and difficult concepts is the natural process of human learning. Spiking Neural Networks (SNNs) aim to mimic the way humans process information, but current SNNs models treat all samples equally, which does not align with the principles of human learning and overlooks the biological plausibility of SNNs. To address this, we propose a CL-SNN model that introduces Curriculum Learning(CL) into SNNs, making SNNs learn more like humans and providing higher biological interpretability. CL is a training strategy that advocates presenting easier data to models before gradually introducing more challenging data, mimicking the human learning process. We use a confidence-aware loss to measure and process the samples with different difficulty levels. By learning the confidence of different samples, the model reduces the contribution of difficult samples to parameter optimization automatically. We conducted experiments on static image datasets MNIST, Fashion-MNIST, CIFAR10, and neuromorphic datasets N-MNIST, CIFAR10-DVS, DVS-Gesture. The results are promising. To our best knowledge, this is the first proposal to enhance the biologically plausibility of SNNs by introducing CL.
</details>
<details>
<summary>摘要</summary>
人类学习的自然过程是从简单到复杂，逐渐引入复杂和困难的概念。神经网络模型（SNN）想要模仿人类信息处理的方式，但现有SNN模型很多样本都受到相同的处理，这并不符合人类学习的原理，而且忽略了SNN的生物可能性。为了解决这个问题，我们提出了CL-SNN模型，该模型将curriculum学习（CL）引入SNN，使SNN更像人类学习的方式，并提供更高的生物可能性。CL是一种训练策略，它认为在训练过程中先给模型推送 easiest样本，然后逐渐增加更复杂的样本，这与人类学习过程相似。我们使用一种自信度感知损失函数来评估和处理不同难度水平的样本。通过学习不同样本的自信度，模型会自动减少最难样本对参数优化的贡献。我们在静止图像集MNIST、Fashion-MNIST、CIFAR10以及神经网络集N-MNIST、CIFAR10-DVS、DVS-Gesture上进行了实验。结果很有前途。我们知道，这是首次通过引入CL来增强SNN的生物可能性的提议。
</details></li>
</ul>
<hr>
<h2 id="A-Spatiotemporal-Deep-Neural-Network-for-Fine-Grained-Multi-Horizon-Wind-Prediction"><a href="#A-Spatiotemporal-Deep-Neural-Network-for-Fine-Grained-Multi-Horizon-Wind-Prediction" class="headerlink" title="A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction"></a>A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04733">http://arxiv.org/abs/2309.04733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hfl15/windpred">https://github.com/hfl15/windpred</a></li>
<li>paper_authors: Fanling Huang, Yangdong Deng</li>
<li>for: 预测风速和方向，帮助多个实际应用如航空和风力发电等，由于天气数据中高度随机性和复杂相关性，预测具有挑战性。</li>
<li>methods: 我们提出了一种新的数据驱动模型，即多个时空网络（MHSTN），用于准确和高效地预测细化风速和方向。MHSTN通过组合多个深度神经网络，以Sequence-to-Sequence（Seq2Seq）脊梁来有效地提取不同数据源的特征，并生成所有站点的多个预测 horizon。</li>
<li>results: 我们的模型在一个中国最繁忙的国际机场的调度平台中已经整合，评估结果表明，我们的模型在竞争对手之上具有显著的优势。<details>
<summary>Abstract</summary>
The prediction of wind in terms of both wind speed and direction, which has a crucial impact on many real-world applications like aviation and wind power generation, is extremely challenging due to the high stochasticity and complicated correlation in the weather data. Existing methods typically focus on a sub-set of influential factors and thus lack a systematic treatment of the problem. In addition, fine-grained forecasting is essential for efficient industry operations, but has been less attended in the literature. In this work, we propose a novel data-driven model, Multi-Horizon SpatioTemporal Network (MHSTN), generally for accurate and efficient fine-grained wind prediction. MHSTN integrates multiple deep neural networks targeting different factors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract features from various data sources and produce multi-horizon predictions for all sites within a given region. MHSTN is composed of four major modules. First, a temporal module fuses coarse-grained forecasts derived by Numerical Weather Prediction (NWP) and historical on-site observation data at stations so as to leverage both global and local atmospheric information. Second, a spatial module exploits spatial correlation by modeling the joint representation of all stations. Third, an ensemble module weighs the above two modules for final predictions. Furthermore, a covariate selection module automatically choose influential meteorological variables as initial input. MHSTN is already integrated into the scheduling platform of one of the busiest international airports of China. The evaluation results demonstrate that our model outperforms competitors by a significant margin.
</details>
<details>
<summary>摘要</summary>
“预测风速和方向的预测，对于许多实际应用来说，如航空业和风力发电等，是极其困难的，因为天气数据中存在高度的随机性和复杂的相关性。现有方法通常只关注一部分影响因素，因此缺乏系统性的处理。另外，细致的预测对于企业操作非常重要，但在文献中得到了更少的关注。在这种情况下，我们提出了一种新的数据驱动模型，即多个时空网络（Multi-Horizon SpatioTemporal Network，MHSTN），用于高精度和高效的细致风预测。MHSTN通过将多个深度神经网络组织成一个序列到序列（Seq2Seq）脊梁，以便从不同数据源中提取特征并生成所有站点的多个时间预测。MHSTN由四个主要模块组成：首先，一个时间模块将数值预测和历史站点观测数据 fusion，以利用全球和地方大气信息；其次，一个空间模块利用空间相关性，模型所有站点的联合表示；第三，一个 ensemble模块为最终预测做权衡；最后，一个 covariate选择模块自动选择影响气象变量为初始输入。MHSTN已经integrated到了中国一个最繁忙的国际机场的调度平台中。评估结果表明，我们的模型在竞争对手之上占据了显著优势。”
</details></li>
</ul>
<hr>
<h2 id="TCGAN-Convolutional-Generative-Adversarial-Network-for-Time-Series-Classification-and-Clustering"><a href="#TCGAN-Convolutional-Generative-Adversarial-Network-for-Time-Series-Classification-and-Clustering" class="headerlink" title="TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering"></a>TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04732">http://arxiv.org/abs/2309.04732</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://bitbucket.org/lynn1/tcgan">https://bitbucket.org/lynn1/tcgan</a></li>
<li>paper_authors: Fanling Huang, Yangdong Deng</li>
<li>for: 本文针对时间序列资料的标本组成，实现分类和对应的目的。</li>
<li>methods: 本文使用了Generative Adversarial Networks (GANs)来学习时间序列资料的层次表现，并将部分训练好的TCGAN组件重复使用来构建表现Encoder，以强化线性识别方法。</li>
<li>results: 本文的实验结果显示，TCGAN比现有的时间序列GAN更快速和准确，并且可以实现简单的分类和对应。此外，TCGAN在具有偏数标签的数据集上也表现出高效性。<details>
<summary>Abstract</summary>
Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.
</details>
<details>
<summary>摘要</summary>
Recent research has shown that supervised Convolutional Neural Networks (CNNs) can learn hierarchical representations from time series data for successful classification. However, these methods require a large amount of labeled data, which can be costly and potentially infeasible to obtain. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. However, it remains unclear how effectively GANs can serve as a general-purpose solution for learning representations for time series recognition, including classification and clustering.Inspired by these considerations, we introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods.We conducted comprehensive experiments on synthetic and real-world datasets. The results show that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.
</details></li>
</ul>
<hr>
<h2 id="Transitions-in-echo-index-and-dependence-on-input-repetitions"><a href="#Transitions-in-echo-index-and-dependence-on-input-repetitions" class="headerlink" title="Transitions in echo index and dependence on input repetitions"></a>Transitions in echo index and dependence on input repetitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04728">http://arxiv.org/abs/2309.04728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Ashwin, Andrea Ceni</li>
<li>for: 这篇论文研究了非自治（即输入驱动）动力系统中的零响应性。它总结了零响应性的定义和不同参数对零响应性的影响。</li>
<li>methods: 作者使用了非自治系统的切换 между一组finite maps的方法，其中每个map具有finite set of hyperbolic equilibrium attractors。</li>
<li>results: 作者发现了外部输入的激励强度对零响应性的影响。当输入强度较小时，零响应性与输入自由系统中的吸引器数量相同。当输入强度较大时，零响应性降低到1。在输入强度较小的 intermediate region 中，零响应性受到输入的更加细微特性的影响。<details>
<summary>Abstract</summary>
The echo index counts the number of simultaneously stable asymptotic responses of a nonautonomous (i.e. input-driven) dynamical system. It generalizes the well-known echo state property for recurrent neural networks - this corresponds to the echo index being equal to one. In this paper, we investigate how the echo index depends on parameters that govern typical responses to a finite-state ergodic external input that forces the dynamics. We consider the echo index for a nonautonomous system that switches between a finite set of maps, where we assume that each map possesses a finite set of hyperbolic equilibrium attractors. We find the minimum and maximum repetitions of each map are crucial for the resulting echo index. Casting our theoretical findings in the RNN computing framework, we obtain that for small amplitude forcing the echo index corresponds to the number of attractors for the input-free system, while for large amplitude forcing, the echo index reduces to one. The intermediate regime is the most interesting; in this region the echo index depends not just on the amplitude of forcing but also on more subtle properties of the input.
</details>
<details>
<summary>摘要</summary>
“弹回指数”（echo index）是非自主（即输入驱动）动力系统中同时稳定 asymptotic response 的数量的一个统计量。它推广了已知的弹回性质（echo property），这corresponds to the echo index being equal to one.在这篇论文中，我们研究了弹回指数如何受到外部输入的Parameter Governance的影响。我们考虑了一个非自主系统，该系统在一个有限个Map之间切换，并假设每个Map具有一个有限多个恒等平衡吸引器。我们发现，输入的最小和最大重复数对弹回指数有关键的。在将我们的理论发现转移到RNN计算框架中，我们得到了以下结论：对于小振幅的刺激，弹回指数与输入自由系统中的吸引器数量相同；对于大振幅的刺激，弹回指数减少到1。 intermediate regime 是最有趣的，在这个区域中，弹回指数不仅受到刺激振幅的影响，还受到输入的更加细微的性质的影响。
</details></li>
</ul>
<hr>
<h2 id="MultiCaM-Vis-Visual-Exploration-of-Multi-Classification-Model-with-High-Number-of-Classes"><a href="#MultiCaM-Vis-Visual-Exploration-of-Multi-Classification-Model-with-High-Number-of-Classes" class="headerlink" title="MultiCaM-Vis: Visual Exploration of Multi-Classification Model with High Number of Classes"></a>MultiCaM-Vis: Visual Exploration of Multi-Classification Model with High Number of Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05676">http://arxiv.org/abs/2309.05676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Syed Ahsan Ali Dilawer, Shah Rukh Humayoun</li>
<li>for: 用于探索多类划分模型中大量类别之间的关系和问题的原因。</li>
<li>methods: 使用交互式视觉分析工具 MultiCaM-Vis，提供了概述+细节并行坐标视图和环形图表示法，以便对实例级别的错误分类进行探索和检查。</li>
<li>results: 在12名参与者的预liminary用户研究中，通过使用 MultiCaM-Vis 工具，参与者能够更好地理解和探索多类划分模型中的问题和关系。<details>
<summary>Abstract</summary>
Visual exploration of multi-classification models with large number of classes would help machine learning experts in identifying the root cause of a problem that occurs during learning phase such as miss-classification of instances. Most of the previous visual analytics solutions targeted only a few classes. In this paper, we present our interactive visual analytics tool, called MultiCaM-Vis, that provides \Emph{overview+detail} style parallel coordinate views and a Chord diagram for exploration and inspection of class-level miss-classification of instances. We also present results of a preliminary user study with 12 participants.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Visual 探索多类型模型的大量类型问题会帮助机器学习专家在学习阶段出现错误的原因。大多数前一代视觉分析解决方案仅针对几个类型。在这篇论文中，我们提出了我们的交互式视觉分析工具 MultiCaM-Vis，它提供了 \Emph{概述+详细} 样式的平行坐标图和一个弦图以便对实例的类别错误进行探索和检查。我们还发布了12名参与者的初步用户研究结果。Note: "概述+详细" (overview+detail) is a common phrase used to describe a visualization that provides both a high-level overview and detailed information.
</details></li>
</ul>
<hr>
<h2 id="SHAPE-A-Sample-adaptive-Hierarchical-Prediction-Network-for-Medication-Recommendation"><a href="#SHAPE-A-Sample-adaptive-Hierarchical-Prediction-Network-for-Medication-Recommendation" class="headerlink" title="SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation"></a>SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05675">http://arxiv.org/abs/2309.05675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sicen Liu, Xiaolong Wang, JIngcheng Du, Yongshuai Hou, Xianbing Zhao, Hui Xu, Hui Wang, Yang Xiang, Buzhou Tang</li>
<li>for: 这个研究旨在提高医疗保健中复杂多疾病的药物建议方法。</li>
<li>methods: 本研究提出了一个名为SHAPE的新型Sample-adaptive Hierarchical medicAtion Prediction nEtwork，以解决上述挑战。特别是，我们设计了一个高效的内部预测器，以将医疗事件中的关系编码为访问水平表现，然后开发了一个滑动学习方法来有效地学习患者水平的长期预测。</li>
<li>results: 我们的模型在一个 benchmark 数据集上进行了广泛的实验，与多个现有的基eline模型进行比较，结果显示了我们的模型在药物建议任务中的超过其他模型的优势。<details>
<summary>Abstract</summary>
Effectively medication recommendation with complex multimorbidity conditions is a critical task in healthcare. Most existing works predicted medications based on longitudinal records, which assumed the information transmitted patterns of learning longitudinal sequence data are stable and intra-visit medical events are serialized. However, the following conditions may have been ignored: 1) A more compact encoder for intra-relationship in the intra-visit medical event is urgent; 2) Strategies for learning accurate representations of the variable longitudinal sequences of patients are different. In this paper, we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork, termed SHAPE, to tackle the above challenges in the medication recommendation task. Specifically, we design a compact intra-visit set encoder to encode the relationship in the medical event for obtaining visit-level representation and then develop an inter-visit longitudinal encoder to learn the patient-level longitudinal representation efficiently. To endow the model with the capability of modeling the variable visit length, we introduce a soft curriculum learning method to assign the difficulty of each sample automatically by the visit length. Extensive experiments on a benchmark dataset verify the superiority of our model compared with several state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
医疗健康提供药物建议是一项重要任务。大多数现有工作是基于长期纪录预测药物，假设长期纪录中传输的信息是稳定的，并且内访医学事件是串行的。然而，以下情况可能被忽略：1）更加压缩的内访集编码器可以更好地编码医学事件中的关系，2）不同的患者的变量长期序列表示是不同的。在这篇论文中，我们提出了一种新的 Sample-adaptive Hierarchical medicAtion Prediction nEtwork（SHAPE），用于解决以上挑战。具体来说，我们设计了一个压缩的内访集编码器，用于编码医学事件中的关系，并开发了一个效果的长期编码器，用于学习患者级别的长期表示。为了让模型能够模拟变量访问长度，我们引入了一种软学习策略，用于自动将每个样本的难度分配给每个访问长度。广泛的实验表明，我们的模型在一个标准 benchmark 数据集上表现出色，胜过了多个现有的基准值。
</details></li>
</ul>
<hr>
<h2 id="Toward-Reproducing-Network-Research-Results-Using-Large-Language-Models"><a href="#Toward-Reproducing-Network-Research-Results-Using-Large-Language-Models" class="headerlink" title="Toward Reproducing Network Research Results Using Large Language Models"></a>Toward Reproducing Network Research Results Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04716">http://arxiv.org/abs/2309.04716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Xiang, Yuling Lin, Mingjun Fang, Bang Huang, Siyong Huang, Ridi Wen, Franck Le, Linghe Kong, Jiwu Shu</li>
<li>for: 本研究旨在提高网络研究结果的复制效率，尤其是在非公开源代码的情况下。</li>
<li>methods: 本研究使用大型自然语言模型（LLMs）来复制网络研究结果。</li>
<li>results: 小规模实验表明，通过提示工程ChatGPT，4名学生 each 复制了不同的网络系统，发表在知名会议和学报上。实验观察和教训，以及未来的开源研究问题，均被报告。<details>
<summary>Abstract</summary>
Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue.
</details>
<details>
<summary>摘要</summary>
重现网络研究结果在学术和工业领域都非常重要。目前最佳实践通常是通过以下三种方法：（1）搜索公共可用的原型；（2）与作者取得私人原型；以及（3）根据出版物的描述手动实现原型。但是，大多数发表在网络研究中的研究不公开原型，私人原型很难获得。因此，大多数重现努力都是基于出版物的手动实现，这是时间和劳动力费时consuming，也容易出错。在这篇论文中，我们勇敢地提出使用emerging大语言模型（LLMs）来重现网络研究结果。具体来说，我们首先证明了这种方法的可行性，通过小规模实验，四名学生每个重现了不同的网络系统，这些系统分别发表在著名的会议和杂志上。我们报告了实验的观察和教训，并讨论了未来的开放研究问题。这项工作没有伦理问题。
</details></li>
</ul>
<hr>
<h2 id="Advantage-Actor-Critic-with-Reasoner-Explaining-the-Agent’s-Behavior-from-an-Exploratory-Perspective"><a href="#Advantage-Actor-Critic-with-Reasoner-Explaining-the-Agent’s-Behavior-from-an-Exploratory-Perspective" class="headerlink" title="Advantage Actor-Critic with Reasoner: Explaining the Agent’s Behavior from an Exploratory Perspective"></a>Advantage Actor-Critic with Reasoner: Explaining the Agent’s Behavior from an Exploratory Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04707">http://arxiv.org/abs/2309.04707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muzhe Guo, Feixu Yu, Tian Lan, Fang Jin</li>
<li>for: 这篇论文旨在提高 actor-critic 模型的可读性和可理解性，使其在具有重要实际影响的决策问题中更能够负责任和可靠。</li>
<li>methods: 该论文提出了一种名为 Advantage Actor-Critic with Reasoner (A2CR) 的新方法，可以轻松应用于 actor-critic 模型中，并使其更加可读性和可理解性。A2CR 包含三个相互连接的网络：政策网络、价值网络和理解器网络。通过预先定义和分类actor的行为目的，A2CR 自动生成了一种更加全面和可读的决策过程理解模型，并提供了一些功能如目的基于的焦点度、早期失败检测和模型监视，以促进负责任和可靠的 RL。</li>
<li>results: 在 Super Mario Bros 环境中进行的评估结果表明，随着 RL 算法的探索水平的增加，Reasoner 预测的标签占比下降于 <code>Breakout&quot;，而 </code>Hovering” 的标签占比增加。此外，根据目的基于的焦点度也更加集中和可理解。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-predicted label proportions decrease for ``Breakout" and increase for ``Hovering" as the exploration level of the RL algorithm intensifies. Additionally, purpose-based saliencies are more focused and comprehensible.
</details>
<details>
<summary>摘要</summary>
强化学习（RL）是一种强大的解决复杂决策问题的工具，但它缺乏透明度和解释性使得在具有重要现实世界影响的领域中具有很大挑战。在这篇论文中，我们提出了一种新的优先级actor-critic（A2CR）模型，可以轻松应用于actor-critic基于的RL模型中，并使其更加解释性。A2CR包括三个相互连接的网络：政策网络、价值网络和理解器网络。通过先定和分类actor的行为目的，A2CR自动生成了一个更加全面和解释性强的RL决策过程的模型。它提供了一系列功能，如目的基于的焦点度、早期失败检测和模型监督，从而推动负责任和可信RL。在动作充满的Super Mario Bros环境中进行的评估结果具有吸引人的发现：理解器预测的标签占比随RL算法的探索水平增加而下降，而在Breakout和Hovering两个任务中，理解器预测的标签占比增加。此外，目的基于的焦点度更加集中和可读。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Disinformation-and-Fake-News-Detection-Using-Fine-Tuned-Large-Language-Model"><a href="#Analysis-of-Disinformation-and-Fake-News-Detection-Using-Fine-Tuned-Large-Language-Model" class="headerlink" title="Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model"></a>Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04704">http://arxiv.org/abs/2309.04704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohdan M. Pavlyshenko</li>
<li>for: 本研究探讨了使用Llama 2大语言模型（LLM）进行假信息分析和新闻干扰检测的可能性。</li>
<li>methods: 本研究使用了PEFT&#x2F;LoRA基于的方法进行精度调整。</li>
<li>results: 经调整后的Llama 2模型可以深入分析文本，揭示复杂的风格和叙述。提取名实体的情感可以作为支持机器学习模型的预测特征。<details>
<summary>Abstract</summary>
The paper considers the possibility of fine-tuning Llama 2 large language model (LLM) for the disinformation analysis and fake news detection. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text on revealing disinformation and propaganda narratives, fact checking, fake news detection, manipulation analytics, extracting named entities with their sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a deep analysis of texts and reveal complex styles and narratives. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models.
</details>
<details>
<summary>摘要</summary>
文章考虑了LLAMA 2大语言模型（LLM）的微调用于假新闻检测和假信息分析。为微调，使用了PEFT/LoRA基于的方法。研究中，模型被微调用以下任务：分析文本，揭露假信息和宣传媒体，实现Fact Checking，假新闻检测，操纵分析，提取名实体的情感。研究结果显示，微调LLAMA 2模型可以深入分析文本，揭示复杂的风格和 narraatives。提取的名实体情感可以作为超参量来预测支持机器学习模型。
</details></li>
</ul>
<hr>
<h2 id="Weak-PDE-LEARN-A-Weak-Form-Based-Approach-to-Discovering-PDEs-From-Noisy-Limited-Data"><a href="#Weak-PDE-LEARN-A-Weak-Form-Based-Approach-to-Discovering-PDEs-From-Noisy-Limited-Data" class="headerlink" title="Weak-PDE-LEARN: A Weak Form Based Approach to Discovering PDEs From Noisy, Limited Data"></a>Weak-PDE-LEARN: A Weak Form Based Approach to Discovering PDEs From Noisy, Limited Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04699">http://arxiv.org/abs/2309.04699</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/punkduckable/weak_pde_learn">https://github.com/punkduckable/weak_pde_learn</a></li>
<li>paper_authors: Robert Stephany, Christopher Earls</li>
<li>for: 该论文旨在开发一种可以从噪声和有限的解析数据中直接找到非线性偏微分方程的探索算法。</li>
<li>methods: 该算法使用适应损失函数基于弱形来训练神经网络， Approximate PDE解而同时确定 governing PDE。</li>
<li>results: 该方法可以快速和稳定地找到各种各样的偏微分方程，并且可以承受噪声。<details>
<summary>Abstract</summary>
We introduce Weak-PDE-LEARN, a Partial Differential Equation (PDE) discovery algorithm that can identify non-linear PDEs from noisy, limited measurements of their solutions. Weak-PDE-LEARN uses an adaptive loss function based on weak forms to train a neural network, $U$, to approximate the PDE solution while simultaneously identifying the governing PDE. This approach yields an algorithm that is robust to noise and can discover a range of PDEs directly from noisy, limited measurements of their solutions. We demonstrate the efficacy of Weak-PDE-LEARN by learning several benchmark PDEs.
</details>
<details>
<summary>摘要</summary>
我们介绍Weak-PDE-LEARN，一个可以从噪音、有限的解析方法获取非线性偏微分方程的探测算法。Weak-PDE-LEARN使用适应损失函数基于弱形式来训练神经网络$U$，以便精度地 aproximate偏微分方程解析，同时也可以直接从噪音、有限的解析方法中找到统治偏微分方程。这种方法具有响应噪音的特点，并且可以直接从噪音、有限的解析方法中找到许多偏微分方程。我们在这篇文章中证明了Weak-PDE-LEARN的有效性，通过学习了一些benchmark偏微分方程。
</details></li>
</ul>
<hr>
<h2 id="Redundancy-Free-Self-Supervised-Relational-Learning-for-Graph-Clustering"><a href="#Redundancy-Free-Self-Supervised-Relational-Learning-for-Graph-Clustering" class="headerlink" title="Redundancy-Free Self-Supervised Relational Learning for Graph Clustering"></a>Redundancy-Free Self-Supervised Relational Learning for Graph Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04694">http://arxiv.org/abs/2309.04694</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yisiyu95/r2fgc">https://github.com/yisiyu95/r2fgc</a></li>
<li>paper_authors: Si-Yu Yi, Wei Ju, Yifang Qin, Xiao Luo, Luchen Liu, Yong-Dao Zhou, Ming Zhang</li>
<li>for: 本文提出了一种新的自然语言深度图 clustering 方法，即 Relational Redundancy-Free Graph Clustering (R$^2$FGC)，用于解决图Structured 数据中的群集分配问题。</li>
<li>methods: 本文使用了自动encoder和图自动encoder来提取图中的属性和结构层次关系信息，并通过保留归一化后的相似节点关系来学习有效的表示。此外，本文还提出了一种简单 yet 有效的策略来解决过滤问题。</li>
<li>results: 对于 widely 使用的 benchmark 数据集，本文的 R$^2$FGC 方法表现出了较高的cluster 性能，超过了现有基线方法。 codes 可以在 <a target="_blank" rel="noopener" href="https://github.com/yisiyu95/R2FGC">https://github.com/yisiyu95/R2FGC</a> 中下载。<details>
<summary>Abstract</summary>
Graph clustering, which learns the node representations for effective cluster assignments, is a fundamental yet challenging task in data analysis and has received considerable attention accompanied by graph neural networks in recent years. However, most existing methods overlook the inherent relational information among the non-independent and non-identically distributed nodes in a graph. Due to the lack of exploration of relational attributes, the semantic information of the graph-structured data fails to be fully exploited which leads to poor clustering performance. In this paper, we propose a novel self-supervised deep graph clustering method named Relational Redundancy-Free Graph Clustering (R$^2$FGC) to tackle the problem. It extracts the attribute- and structure-level relational information from both global and local views based on an autoencoder and a graph autoencoder. To obtain effective representations of the semantic information, we preserve the consistent relation among augmented nodes, whereas the redundant relation is further reduced for learning discriminative embeddings. In addition, a simple yet valid strategy is utilized to alleviate the over-smoothing issue. Extensive experiments are performed on widely used benchmark datasets to validate the superiority of our R$^2$FGC over state-of-the-art baselines. Our codes are available at https://github.com/yisiyu95/R2FGC.
</details>
<details>
<summary>摘要</summary>
GRAPH CLUSTERING, 学习节点表示以实现有效的归类分配, 是数据分析中的基本 yet challenging task 在 recientes years  accompanying 图 neural networks Received considerable attention. However, most existing methods overlook the inherent relational information among the non-independent and non-identically distributed nodes in a graph. Due to the lack of exploration of relational attributes, the semantic information of the graph-structured data fails to be fully exploited which leads to poor clustering performance. In this paper, we propose a novel self-supervised deep graph clustering method named Relational Redundancy-Free Graph Clustering (R$^2$FGC) to tackle the problem. It extracts the attribute- and structure-level relational information from both global and local views based on an autoencoder and a graph autoencoder. To obtain effective representations of the semantic information, we preserve the consistent relation among augmented nodes, whereas the redundant relation is further reduced for learning discriminative embeddings. In addition, a simple yet valid strategy is utilized to alleviate the over-smoothing issue. Extensive experiments are performed on widely used benchmark datasets to validate the superiority of our R$^2$FGC over state-of-the-art baselines. Our codes are available at https://github.com/yisiyu95/R2FGC.
</details></li>
</ul>
<hr>
<h2 id="Flexible-and-Robust-Counterfactual-Explanations-with-Minimal-Satisfiable-Perturbations"><a href="#Flexible-and-Robust-Counterfactual-Explanations-with-Minimal-Satisfiable-Perturbations" class="headerlink" title="Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations"></a>Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04676">http://arxiv.org/abs/2309.04676</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyongjie-ntu/cemsp">https://github.com/wangyongjie-ntu/cemsp</a></li>
<li>paper_authors: Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, Chunyan Miao</li>
<li>for: 提高信息公平和可信worthiness，并为用户提供有用的建议。</li>
<li>methods: 使用Counterfactual Explanations with Minimal Satisfiable Perturbations（CEMSP）方法，该方法通过尝试不同的特征值修改，以实现不同的预测结果。</li>
<li>results: 比较 existing methods，CEMSP 可以提供更加稳定和有用的解释，同时保持 flexibility。<details>
<summary>Abstract</summary>
Counterfactual explanations (CFEs) exemplify how to minimally modify a feature vector to achieve a different prediction for an instance. CFEs can enhance informational fairness and trustworthiness, and provide suggestions for users who receive adverse predictions. However, recent research has shown that multiple CFEs can be offered for the same instance or instances with slight differences. Multiple CFEs provide flexible choices and cover diverse desiderata for user selection. However, individual fairness and model reliability will be damaged if unstable CFEs with different costs are returned. Existing methods fail to exploit flexibility and address the concerns of non-robustness simultaneously. To address these issues, we propose a conceptually simple yet effective solution named Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges. For efficiency, we model the problem as a Boolean satisfiability problem to modify as few features as possible. Additionally, CEMSP is a general framework and can easily accommodate more practical requirements, e.g., casualty and actionability. Compared to existing methods, we conduct comprehensive experiments on both synthetic and real-world datasets to demonstrate that our method provides more robust explanations while preserving flexibility.
</details>
<details>
<summary>摘要</summary>
counterfactual explanations (CFEs) 可以最小化特征向量 modify 来实现不同预测结果的 instance。CFEs 可以增强信息公平和可靠性，并为用户提供不同的建议。然而，最近的研究发现，对同一个 instance 或 slight differences 的 instances 可以提供多个 CFEs。多个 CFEs 提供了多样的选择，涵盖了用户选择的多种需求。然而，个人公平和模型可靠性会受到不稳定 CFEs 的影响。现有方法无法充分利用 flexibility 并同时解决不稳定性问题。为解决这些问题，我们提出了一种概念简单 yet effective 的解决方案，名为 counterfactual explanations with minimal satisfiable perturbations (CEMSP)。具体来说，CEMSP 使用异常特征值的变化来满足 semantically meaningful normal ranges。为了提高效率，我们将问题模型为 Boolean satisfiability problem，以修改最少特征。此外，CEMSP 是一个通用的框架，可以轻松扩展到更加实际的需求，例如 causality 和 actionability。与现有方法相比，我们在 synthetic 和实际数据集上进行了广泛的实验，并证明了我们的方法可以提供更加稳定的解释，同时保持 flexibility。
</details></li>
</ul>
<hr>
<h2 id="Compact-Approximating-Complex-Activation-Functions-for-Secure-Computation"><a href="#Compact-Approximating-Complex-Activation-Functions-for-Secure-Computation" class="headerlink" title="Compact: Approximating Complex Activation Functions for Secure Computation"></a>Compact: Approximating Complex Activation Functions for Secure Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04664">http://arxiv.org/abs/2309.04664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mazharul Islam, Sunpreet S. Arora, Rahul Chatterjee, Peter Rindal, Maliheh Shirvanian</li>
<li>for: 提供隐私保护的深度神经网络（DNN）模型查询服务，使用公共云计算。</li>
<li>methods: 使用现状顶峰技术，生成复杂非线性Activation Functions（AFs）的割辑式多方计算（MPC）技术。</li>
<li>results: 与现状顶峰技术相比，Compact incurs negligible accuracy loss，并且提供2x-5x的计算速度提升。<details>
<summary>Abstract</summary>
Secure multi-party computation (MPC) techniques can be used to provide data privacy when users query deep neural network (DNN) models hosted on a public cloud. State-of-the-art MPC techniques can be directly leveraged for DNN models that use simple activation functions (AFs) such as ReLU. However, DNN model architectures designed for cutting-edge applications often use complex and highly non-linear AFs. Designing efficient MPC techniques for such complex AFs is an open problem.   Towards this, we propose Compact, which produces piece-wise polynomial approximations of complex AFs to enable their efficient use with state-of-the-art MPC techniques. Compact neither requires nor imposes any restriction on model training and results in near-identical model accuracy. We extensively evaluate Compact on four different machine-learning tasks with DNN architectures that use popular complex AFs SiLU, GeLU, and Mish. Our experimental results show that Compact incurs negligible accuracy loss compared to DNN-specific approaches for handling complex non-linear AFs. We also incorporate Compact in two state-of-the-art MPC libraries for privacy-preserving inference and demonstrate that Compact provides 2x-5x speedup in computation compared to the state-of-the-art approximation approach for non-linear functions -- while providing similar or better accuracy for DNN models with large number of hidden layers
</details>
<details>
<summary>摘要</summary>
secure多方 computation（MPC）技术可以用来保证用户在公共云上查询深度神经网络（DNN）模型时的数据隐私。现代MPC技术可以直接应用于使用简单Activation Functions（AFs）的DNN模型，如ReLU。然而，为了满足现代应用的需求，DNN模型的设计通常使用复杂和高度非线性的AFs。设计高效的MPC技术 для这些复杂AFs是一个开放的问题。为了解决这个问题，我们提出了一种名为Compact的方法，该方法生成了分割的多项式近似方法来实现复杂AFs的高效使用。Compact不需要任何限制model的训练，并且不会影响模型的准确性。我们对四个不同的机器学习任务进行了广泛的实验，结果表明，Compact与DNN特有的方法相比，对于处理复杂非线性AFs的精度损失是可以忽略的。我们还将Compactintegrated into两个现代MPC库，并证明了Compact在计算中提供了2-5倍的速度提升，相比之下，现有的近似方法对非线性函数的approximation。Translation notes:* "secure multi-party computation" is translated as "secure多方 computation"* "deep neural network" is translated as "深度神经网络"* "activation functions" is translated as "Activation Functions"* "public cloud" is translated as "公共云"* "state-of-the-art" is translated as "现代"* "mpc techniques" is translated as "MPC技术"* "efficient" is translated as "高效"* "accuracy" is translated as "准确性"* "piece-wise polynomial approximations" is translated as "分割的多项式近似方法"* "near-identical model accuracy" is translated as "相同模型精度"* "machine-learning tasks" is translated as "机器学习任务"* "hidden layers" is translated as "隐藏层"* "approximation approach" is translated as "approximation方法"* "computation" is translated as "计算"Please note that the translation is done using Google Translate and may not be perfect.
</details></li>
</ul>
<hr>
<h2 id="MADLAD-400-A-Multilingual-And-Document-Level-Large-Audited-Dataset"><a href="#MADLAD-400-A-Multilingual-And-Document-Level-Large-Audited-Dataset" class="headerlink" title="MADLAD-400: A Multilingual And Document-Level Large Audited Dataset"></a>MADLAD-400: A Multilingual And Document-Level Large Audited Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04662">http://arxiv.org/abs/2309.04662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sneha Kudugunta, Isaac Caswell, Biao Zhang, Xavier Garcia, Christopher A. Choquette-Choo, Katherine Lee, Derrick Xin, Aditya Kusupati, Romi Stella, Ankur Bapna, Orhan Firat</li>
<li>for: 这个论文是为了介绍一个基于 CommonCrawl 的通用领域 3T 单语言数据集（MADLAD-400），以及该数据集的自我审核限制和数据审核在数据集创建过程中的作用。</li>
<li>methods: 论文使用了公共可用数据进行模型训练，包括一个 10.7B 参数的多语言翻译模型和一个 8B 参数的语言模型，并对不同领域进行评估。</li>
<li>results: 论文发现该模型在不同领域的翻译任务中具有竞争力，并且在少量翻译任务中表现良好。此外，论文还发布了基线模型，以便研究人员进行进一步的研究和应用。<details>
<summary>Abstract</summary>
We introduce MADLAD-400, a manually audited, general domain 3T token monolingual dataset based on CommonCrawl, spanning 419 languages. We discuss the limitations revealed by self-auditing MADLAD-400, and the role data auditing had in the dataset creation process. We then train and release a 10.7B-parameter multilingual machine translation model on 250 billion tokens covering over 450 languages using publicly available data, and find that it is competitive with models that are significantly larger, and report the results on different domains. In addition, we train a 8B-parameter language model, and assess the results on few-shot translation. We make the baseline models available to the research community.
</details>
<details>
<summary>摘要</summary>
我们介绍MADLAD-400，一个人工审核的、通用领域3Token单语言数据集，基于CommonCrawl，覆盖419种语言。我们介绍MADLAD-400自我审核的局限性，以及数据审核在数据集创建过程中的角色。然后，我们使用公共可用数据进行训练，开发了10.7B参数的多语言翻译模型，覆盖超过450种语言，并发现它与许多更大的模型相比竞争性强。此外，我们还训练了8B参数的语言模型，并评估其在少量翻译任务中的表现。我们将基准模型提供给研究社区。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-upper-limb-exoskeleton-using-deep-learning-to-predict-human-intention-for-sensory-feedback-augmentation"><a href="#Intelligent-upper-limb-exoskeleton-using-deep-learning-to-predict-human-intention-for-sensory-feedback-augmentation" class="headerlink" title="Intelligent upper-limb exoskeleton using deep learning to predict human intention for sensory-feedback augmentation"></a>Intelligent upper-limb exoskeleton using deep learning to predict human intention for sensory-feedback augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04655">http://arxiv.org/abs/2309.04655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinwoo Lee, Kangkyu Kwon, Ira Soltis, Jared Matthews, Yoonjae Lee, Hojoong Kim, Lissette Romero, Nathan Zavanelli, Youngjin Kwon, Shinjae Kwon, Jimin Lee, Yewon Na, Sung Hoon Lee, Ki Jun Yu, Minoru Shinohara, Frank L. Hammond, Woon-Hong Yeo<br>for:The paper is written for the purpose of introducing an intelligent upper-limb exoskeleton system that uses cloud-based deep learning to predict human intention for strength augmentation.methods:The exoskeleton system uses embedded soft wearable sensors to collect real-time muscle signals, which are simultaneously computed to determine the user’s intended movement. Cloud-based deep-learning is used to predict four upper-limb joint motions with an average accuracy of 96.2% at a 200-250 millisecond response rate.results:The exoskeleton system is able to augment human strength by 5.15 times on average compared to the unassisted exoskeleton, with an array of soft pneumatics assisting the intended movements by providing 897 newton of force and 78.7 millimeter of displacement at maximum.Here is the format you requested, in Simplified Chinese text:for: 这篇论文是为了介绍一种基于云计算的深度学习技术实现人类意图强化的智能上肢骨丝系统。methods: 该系统使用嵌入式软式感知器收集实时肌肉信号，并同时计算以确定用户的意图运动。云计算的深度学习被用来预测四个上肢关节运动的准确率为96.2%，响应时间为200-250毫秒。results: 该系统能够在 average 情况下为人类提供5.15倍的强度增强，与无助的外套比较。软压缩器可以提供897牛顿的力和78.7毫米的移动距离。<details>
<summary>Abstract</summary>
The age and stroke-associated decline in musculoskeletal strength degrades the ability to perform daily human tasks using the upper extremities. Although there are a few examples of exoskeletons, they need manual operations due to the absence of sensor feedback and no intention prediction of movements. Here, we introduce an intelligent upper-limb exoskeleton system that uses cloud-based deep learning to predict human intention for strength augmentation. The embedded soft wearable sensors provide sensory feedback by collecting real-time muscle signals, which are simultaneously computed to determine the user's intended movement. The cloud-based deep-learning predicts four upper-limb joint motions with an average accuracy of 96.2% at a 200-250 millisecond response rate, suggesting that the exoskeleton operates just by human intention. In addition, an array of soft pneumatics assists the intended movements by providing 897 newton of force and 78.7 millimeter of displacement at maximum. Collectively, the intent-driven exoskeleton can augment human strength by 5.15 times on average compared to the unassisted exoskeleton. This report demonstrates an exoskeleton robot that augments the upper-limb joint movements by human intention based on a machine-learning cloud computing and sensory feedback.
</details>
<details>
<summary>摘要</summary>
人体日常活动需要肢体强度，但年龄和stroke-related decline in musculoskeletal strength会导致这种能力减退。虽有一些 эксоскелетоны，但它们需要人工操作，因为缺乏感知反馈和无法预测人体移动意图。我们介绍了一个智能 upper-limb exoskeleton 系统，使用云端深度学习预测人类意图，以增强人类力量。系统内置软件感知器收集实时肌肉信号，并同时计算用户的意图移动。云端深度学习预测四个 upper-limb 关节运动，准确率为96.2%，响应时间为200-250毫秒，表明系统只遵循人类意图。此外，一个数组软式压缩器帮助实现意图运动，提供897牛顿的力量和78.7毫米的移动距离。总之，基于意图的 exoskeleton 可以增强人类肢体强度5.15倍，比无助 exoskeleton 更高。这篇报告描述了基于机器学习云计算和感知反馈的 exoskeleton 机器人，它可以根据人类意图增强 upper-limb 关节运动。
</details></li>
</ul>
<hr>
<h2 id="Towards-Understanding-Neural-Collapse-The-Effects-of-Batch-Normalization-and-Weight-Decay"><a href="#Towards-Understanding-Neural-Collapse-The-Effects-of-Batch-Normalization-and-Weight-Decay" class="headerlink" title="Towards Understanding Neural Collapse: The Effects of Batch Normalization and Weight Decay"></a>Towards Understanding Neural Collapse: The Effects of Batch Normalization and Weight Decay</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04644">http://arxiv.org/abs/2309.04644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leyan Pan, Xinyuan Cao</li>
<li>For: 研究 neural network 的朴素化现象，即 Neural Collapse。* Methods: 使用批处理normalization和weight decay来调整 neural network 的训练。* Results: 提出了一种 geometrically intuitive 的cosine similarity measure，并提供了对 Neural Collapse 的 theoretically guarantees。 Additionally, the paper shows that Neural Collapse is most significant in models with batch normalization and high weight-decay values.Here’s the full text in Simplified Chinese:* For: 本文研究的是 Neural Collapse，即 neural network 的朴素化现象。* Methods: 本文使用了批处理normalization和weight decay来调整 neural network 的训练。* Results: 本文提出了一种 geometrically intuitive 的cosine similarity measure，并提供了对 Neural Collapse 的 theoretically guarantees。 Additionally, the paper shows that Neural Collapse is most significant in models with batch normalization and high weight-decay values.<details>
<summary>Abstract</summary>
Neural Collapse is a recently observed geometric structure that emerges in the final layer of neural network classifiers. Specifically, Neural Collapse states that at the terminal phase of neural networks training, 1) the intra-class variability of last-layer features tends to zero, 2) the class feature means form an Equiangular Tight Frame (ETF), 3) last-layer class features and weights becomes equal up the scaling, and 4) classification behavior collapses to the nearest class center (NCC) decision rule. This paper investigates the effect of batch normalization and weight decay on the emergence of Neural Collapse. We propose the geometrically intuitive intra-class and inter-class cosine similarity measure which captures multiple core aspects of Neural Collapse. With this measure, we provide theoretical guarantees of Neural Collapse emergence with last-layer batch normalization and weight decay when the regularized cross-entropy loss is near optimal. We also perform further experiments to show that the Neural Collapse is most significant in models with batch normalization and high weight-decay values. Collectively, our results imply that batch normalization and weight decay may be fundamental factors in the emergence of Neural Collapse.
</details>
<details>
<summary>摘要</summary>
neural collapse 是一种最近发现的几何结构，它在神经网络分类器的最后一层出现。具体来说，神经collapse 的三个特点是：1）最后一层特征变量内类差降到零，2）类特征均值形成等角紧凑框（ETF），3）最后一层特征和权重归一化，4）分类行为归一化到最近类中心（NCC）决策规则。本文研究了批 Normalization 和权重衰减对神经collapse 的影响。我们提出了几何直观的内类和间类 косину similarity 度量，该度量捕捉了多个核心方面的神经collapse。通过这个度量，我们提供了理论保证神经collapse 的出现，当整合 cross-entropy 损失接近优化时。我们还进行了更多的实验，证明神经collapse 在模型中具有批 Normalization 和高权重衰减值时最为明显。总的来说，我们的结果表明，批 Normalization 和权重衰减可能是神经collapse 的基本因素。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.LG_2023_09_09/" data-id="clmjn91mz00890j883obv49um" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/09/cs.SD_2023_09_09/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.SD - 2023-09-09
        
      </div>
    </a>
  
  
    <a href="/2023/09/09/eess.IV_2023_09_09/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.IV - 2023-09-09</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">69</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">32</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
