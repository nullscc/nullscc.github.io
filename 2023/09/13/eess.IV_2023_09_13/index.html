
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-09-13 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on Synthetic Data paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.06948 repo_url: None paper_authors: Thomas Germer, Jan Robine, Sebastian Kon">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-09-13">
<meta property="og:url" content="https://nullscc.github.io/2023/09/13/eess.IV_2023_09_13/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on Synthetic Data paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.06948 repo_url: None paper_authors: Thomas Germer, Jan Robine, Sebastian Kon">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-13T09:00:00.000Z">
<meta property="article:modified_time" content="2023-09-14T20:38:20.669Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/eess.IV_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T09:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-09-13
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Limited-Angle-Tomography-Reconstruction-via-Deep-End-To-End-Learning-on-Synthetic-Data"><a href="#Limited-Angle-Tomography-Reconstruction-via-Deep-End-To-End-Learning-on-Synthetic-Data" class="headerlink" title="Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on Synthetic Data"></a>Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06948">http://arxiv.org/abs/2309.06948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Germer, Jan Robine, Sebastian Konietzny, Stefan Harmeling, Tobias Uelwer<br>for:  CT干预像 reconstruction problem methods: 使用深度神经网络，通过大量精心制作的 sintetic data 进行训练results: 能够在30°或40°的极限角度下进行CT干预像重建，并在 Helsinki Tomography Challenge 2022 中获得第一名。<details>
<summary>Abstract</summary>
Computed tomography (CT) has become an essential part of modern science and medicine. A CT scanner consists of an X-ray source that is spun around an object of interest. On the opposite end of the X-ray source, a detector captures X-rays that are not absorbed by the object. The reconstruction of an image is a linear inverse problem, which is usually solved by filtered back projection. However, when the number of measurements is small, the reconstruction problem is ill-posed. This is for example the case when the X-ray source is not spun completely around the object, but rather irradiates the object only from a limited angle. To tackle this problem, we present a deep neural network that is trained on a large amount of carefully-crafted synthetic data and can perform limited-angle tomography reconstruction even for only 30{\deg} or 40{\deg} sinograms. With our approach we won the first place in the Helsinki Tomography Challenge 2022.
</details>
<details>
<summary>摘要</summary>
为解决这个问题，我们提出了一种基于深度神经网络的方法。我们在大量精心制作的 sintetic 数据上训练了一个深度神经网络，可以在只有 30° 或 40° 的扫描角度下进行有限角度 Tomography 重建。我们的方法在 Helsinki Tomography Challenge 2022 中获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="Improving-HEVC-Encoding-of-Rendered-Video-Data-Using-True-Motion-Information"><a href="#Improving-HEVC-Encoding-of-Rendered-Video-Data-Using-True-Motion-Information" class="headerlink" title="Improving HEVC Encoding of Rendered Video Data Using True Motion Information"></a>Improving HEVC Encoding of Rendered Video Data Using True Motion Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06945">http://arxiv.org/abs/2309.06945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Herglotz, David Müller, Andreas Weinlich, Frank Bauer, Michael Ortner, Marc Stamminger, André Kaup</li>
<li>for: 提高计算机生成视频序列的编码过程中的质量</li>
<li>methods: 利用场景中对象的真实运动向量进行增强，包括传统运动估算方法以及计算机生成的运动向量增强</li>
<li>results: 可以获得3.78%的均质量改进<details>
<summary>Abstract</summary>
This paper shows that motion vectors representing the true motion of an object in a scene can be exploited to improve the encoding process of computer generated video sequences. Therefore, a set of sequences is presented for which the true motion vectors of the corresponding objects were generated on a per-pixel basis during the rendering process. In addition to conventional motion estimation methods, it is proposed to exploit the computer generated motion vectors to enhance the ratedistortion performance. To this end, a motion vector mapping method including disocclusion handling is presented. It is shown that mean rate savings of 3.78% can be achieved.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Topology-inspired-Cross-domain-Network-for-Developmental-Cervical-Stenosis-Quantification"><a href="#Topology-inspired-Cross-domain-Network-for-Developmental-Cervical-Stenosis-Quantification" class="headerlink" title="Topology-inspired Cross-domain Network for Developmental Cervical Stenosis Quantification"></a>Topology-inspired Cross-domain Network for Developmental Cervical Stenosis Quantification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06825">http://arxiv.org/abs/2309.06825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenxi Zhang, Yanyang Wang, Yao Wu, Weifei Wu</li>
<li>for: 验证 Developmental Canal Stenosis (DCS) 评估方法的效果，以帮助诊断cervical spondylosis。</li>
<li>methods: 使用深度关键点地图网络，可以在坐标领域或图像领域进行快速和高效的关键点定位。</li>
<li>results: 提出了一种束缚关键点-边界模块和重parameter化模块，可以在坐标领域和图像领域进行跨领域约束，从而提高关键点定位的精度和可靠性。<details>
<summary>Abstract</summary>
Developmental Canal Stenosis (DCS) quantification is crucial in cervical spondylosis screening. Compared with quantifying DCS manually, a more efficient and time-saving manner is provided by deep keypoint localization networks, which can be implemented in either the coordinate or the image domain. However, the vertebral visualization features often lead to abnormal topological structures during keypoint localization, including keypoint distortion with edges and weakly connected structures, which cannot be fully suppressed in either the coordinate or image domain alone. To overcome this limitation, a keypoint-edge and a reparameterization modules are utilized to restrict these abnormal structures in a cross-domain manner. The keypoint-edge constraint module restricts the keypoints on the edges of vertebrae, which ensures that the distribution pattern of keypoint coordinates is consistent with those for DCS quantification. And the reparameterization module constrains the weakly connected structures in image-domain heatmaps with coordinates combined. Moreover, the cross-domain network improves spatial generalization by utilizing heatmaps and incorporating coordinates for accurate localization, which avoids the trade-off between these two properties in an individual domain. Comprehensive results of distinct quantification tasks show the superiority and generability of the proposed Topology-inspired Cross-domain Network (TCN) compared with other competing localization methods.
</details>
<details>
<summary>摘要</summary>
发展隧道狭窄 (DCS) 量化是颈椎病变检测中非常重要的一步。相比手动量化 DCS，深度关键点本地化网络可以提供更加高效和时间节省的方法，可以在坐标领域或图像领域中实现。然而， vertebral 视觉特征可能导致关键点本地化过程中出现异常的 topological 结构，包括关键点扭曲、边缘和弱连接结构，这些结构在坐标领域或图像领域单独处理不能完全消除。为了解决这个限制，我们提出了关键点-边缘约束模块和重parameterization 模块。关键点-边缘约束模块使得关键点的分布协调于 DCS 量化中的分布，而重parameterization 模块在图像领域的热图上使用坐标组合来约束弱连接结构。此外，交叉领域网络可以提高空间泛化性，通过使用热图和坐标组合来准确定位关键点，从而避免在单个领域中的质量规则负担。Results of distinct quantification tasks demonstrate the superiority and generability of our proposed Topology-inspired Cross-domain Network (TCN) compared with other competing localization methods.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-Synthetic-High-Resolution-In-Depth-Imaging-Using-an-Attachable-Dual-element-Endoscopic-Ultrasound-Probe"><a href="#Deep-Learning-based-Synthetic-High-Resolution-In-Depth-Imaging-Using-an-Attachable-Dual-element-Endoscopic-Ultrasound-Probe" class="headerlink" title="Deep Learning-based Synthetic High-Resolution In-Depth Imaging Using an Attachable Dual-element Endoscopic Ultrasound Probe"></a>Deep Learning-based Synthetic High-Resolution In-Depth Imaging Using an Attachable Dual-element Endoscopic Ultrasound Probe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06770">http://arxiv.org/abs/2309.06770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hah Min Lew, Jae Seong Kim, Moon Hwan Lee, Jaegeun Park, Sangyeon Youn, Hee Man Kim, Jihun Kim, Jae Youn Hwang</li>
<li>for: 提高endoscopic ultrasound（EUS）图像的分辨率和吸收深度。</li>
<li>methods: 使用deep learning技术，开发一种新的高分辨率深度扫描镜头，并使用特制的齿轮结构来实现同一个图像平面。</li>
<li>results: 对细菌样品和生物样品进行了测试，并使用多种深度学习模型来生成高分辨率深度图像， thereby demonstrating the feasibility of our approach for clinical unmet needs.<details>
<summary>Abstract</summary>
Endoscopic ultrasound (EUS) imaging has a trade-off between resolution and penetration depth. By considering the in-vivo characteristics of human organs, it is necessary to provide clinicians with appropriate hardware specifications for precise diagnosis. Recently, super-resolution (SR) ultrasound imaging studies, including the SR task in deep learning fields, have been reported for enhancing ultrasound images. However, most of those studies did not consider ultrasound imaging natures, but rather they were conventional SR techniques based on downsampling of ultrasound images. In this study, we propose a novel deep learning-based high-resolution in-depth imaging probe capable of offering low- and high-frequency ultrasound image pairs. We developed an attachable dual-element EUS probe with customized low- and high-frequency ultrasound transducers under small hardware constraints. We also designed a special geared structure to enable the same image plane. The proposed system was evaluated with a wire phantom and a tissue-mimicking phantom. After the evaluation, 442 ultrasound image pairs from the tissue-mimicking phantom were acquired. We then applied several deep learning models to obtain synthetic high-resolution in-depth images, thus demonstrating the feasibility of our approach for clinical unmet needs. Furthermore, we quantitatively and qualitatively analyzed the results to find a suitable deep-learning model for our task. The obtained results demonstrate that our proposed dual-element EUS probe with an image-to-image translation network has the potential to provide synthetic high-frequency ultrasound images deep inside tissues.
</details>
<details>
<summary>摘要</summary>
endoscopic ultrasound（EUS）影像有一种质量和渗透深度之间的交换。由于人体内部的特点，需要为临床医生提供适当的硬件规格，以便精确诊断。近些年来，超分解（SR）ultrasound影像研究，包括深度学习领域中的SR任务，已经被报道用于提高ultrasound影像。然而，大多数这些研究并没有考虑ultrasound影像的特点，而是基于ultrasound影像下采样的传统SR技术。在本研究中，我们提出了一种基于深度学习的高分辨率深度渗透成像探针。我们开发了一种可拆卸的双元EUS探针，其中包括自定义的低频和高频ultrasound传播器。我们还设计了特殊的液压结构，以实现同一个图像平面。我们对使用这种系统进行了评估，并获得了442个ultrasound影像对。我们然后应用了多种深度学习模型，以获得 sintetic高分辨率深度渗透图像，这 demonstartes了我们的方法的可行性。此外，我们进行了量化和质量分析，以选择适合我们任务的深度学习模型。所获结果表明，我们的提案的双元EUS探针与图像译化网络具有深度渗透图像深度 Inside tissues的潜力。
</details></li>
</ul>
<hr>
<h2 id="Improving-Deep-Learning-based-Defect-Detection-on-Window-Frames-with-Image-Processing-Strategies"><a href="#Improving-Deep-Learning-based-Defect-Detection-on-Window-Frames-with-Image-Processing-Strategies" class="headerlink" title="Improving Deep Learning-based Defect Detection on Window Frames with Image Processing Strategies"></a>Improving Deep Learning-based Defect Detection on Window Frames with Image Processing Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06731">http://arxiv.org/abs/2309.06731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorge Vasquez, Hemant K. Sharma, Tomotake Furuhata, Kenji Shimada</li>
<li>for: 这个论文的目的是提高机器视觉系统的检测精度，使其能够更好地检测窗户框中的微小损害，包括损害和擦抹等。</li>
<li>methods: 这个论文使用了机器学习和深度学习（DL）的新的检测方法，包括图像增强和扩展技术，以提高检测精度。</li>
<li>results: 实验结果表明，当使用最佳的数据集时，IPT-加强的UNet模型在检测和分类窗户框中的损害方面表现出色，其中平均的交集 над union（IoU）值达到0.91。<details>
<summary>Abstract</summary>
Detecting subtle defects in window frames, including dents and scratches, is vital for upholding product integrity and sustaining a positive brand perception. Conventional machine vision systems often struggle to identify these defects in challenging environments like construction sites. In contrast, modern vision systems leveraging machine and deep learning (DL) are emerging as potent tools, particularly for cosmetic inspections. However, the promise of DL is yet to be fully realized. A few manufacturers have established a clear strategy for AI integration in quality inspection, hindered mainly by issues like scarce clean datasets and environmental changes that compromise model accuracy. Addressing these challenges, our study presents an innovative approach that amplifies defect detection in DL models, even with constrained data resources. The paper proposes a new defect detection pipeline called InspectNet (IPT-enhanced UNET) that includes the best combination of image enhancement and augmentation techniques for pre-processing the dataset and a Unet model tuned for window frame defect detection and segmentation. Experiments were carried out using a Spot Robot doing window frame inspections . 16 variations of the dataset were constructed using different image augmentation settings. Results of the experiments revealed that, on average, across all proposed evaluation measures, Unet outperformed all other algorithms when IPT-enhanced augmentations were applied. In particular, when using the best dataset, the average Intersection over Union (IoU) values achieved were IPT-enhanced Unet, reaching 0.91 of mIoU.
</details>
<details>
<summary>摘要</summary>
检测窗框中微小损害，包括拥有折叠和擦抹等瑕疵，是维护产品完整性和保持品牌形象的关键。传统的机器视觉系统经常在建筑工地等复杂环境中难以识别这些瑕疵。相反，现代视觉系统 combining机器学习和深度学习（DL）在cosmetic检测方面表现出了很好的潜力。然而，DL的承诺还未被完全实现。一些制造商在质检中使用AI的策略已经初步确定，主要受到数据资源罕见和环境变化的影响。为解决这些挑战，我们的研究提出了一种创新的方法，可以增强DL模型中瑕疵检测的精度，即使数据资源受限。我们的研究报告一种新的瑕疵检测管线，即InspectNet（IPT-enhanced UNET），包括最佳的图像增强和扩展技术 для预处理数据集，以及特地适应窗框瑕疵检测和分割的Unet模型。实验使用Spot Robot进行窗框检测。我们构建了16种不同的数据集，并对各种图像增强设置进行了比较。实验结果显示，当IPT-enhanced增强技术应用于数据集时，Unet模型在所有提出的评价指标上平均高于其他算法。特别是在使用最佳数据集时，Unet模型的平均交集概念（IoU）值达到0.91。
</details></li>
</ul>
<hr>
<h2 id="A-plug-and-play-synthetic-data-deep-learning-for-undersampled-magnetic-resonance-image-reconstruction"><a href="#A-plug-and-play-synthetic-data-deep-learning-for-undersampled-magnetic-resonance-image-reconstruction" class="headerlink" title="A plug-and-play synthetic data deep learning for undersampled magnetic resonance image reconstruction"></a>A plug-and-play synthetic data deep learning for undersampled magnetic resonance image reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06681">http://arxiv.org/abs/2309.06681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Xiao, Zi Wang, Jiefeng Guo, Xiaobo Qu</li>
<li>for: 用于加速MRI扫描，提高医疗诊断效率</li>
<li>methods: 使用深度学习方法进行快速MRI重建，适应不同抽取样本设置</li>
<li>results: 在实验室数据上得到了良好的图像恢复性和稳定性，可视化和量化上都达到了预期效果<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) plays an important role in modern medical diagnostic but suffers from prolonged scan time. Current deep learning methods for undersampled MRI reconstruction exhibit good performance in image de-aliasing which can be tailored to the specific kspace undersampling scenario. But it is very troublesome to configure different deep networks when the sampling setting changes. In this work, we propose a deep plug-and-play method for undersampled MRI reconstruction, which effectively adapts to different sampling settings. Specifically, the image de-aliasing prior is first learned by a deep denoiser trained to remove general white Gaussian noise from synthetic data. Then the learned deep denoiser is plugged into an iterative algorithm for image reconstruction. Results on in vivo data demonstrate that the proposed method provides nice and robust accelerated image reconstruction performance under different undersampling patterns and sampling rates, both visually and quantitatively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/eess.IV_2023_09_13/" data-id="clmjn91r100hz0j883yd83nmj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/13/cs.LG_2023_09_13/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-09-13
        
      </div>
    </a>
  
  
    <a href="/2023/09/12/cs.SD_2023_09_12/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-09-12</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">69</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">32</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
