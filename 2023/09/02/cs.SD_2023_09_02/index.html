
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.SD - 2023-09-02 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Timbre-reserved Adversarial Attack in Speaker Identification paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.00929 repo_url: None paper_authors: Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie for: 防止 spo">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.SD - 2023-09-02">
<meta property="og:url" content="https://nullscc.github.io/2023/09/02/cs.SD_2023_09_02/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Timbre-reserved Adversarial Attack in Speaker Identification paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.00929 repo_url: None paper_authors: Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie for: 防止 spo">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-02T15:00:00.000Z">
<meta property="article:modified_time" content="2023-09-14T20:38:14.927Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.SD_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.SD_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T15:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.SD - 2023-09-02
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Timbre-reserved-Adversarial-Attack-in-Speaker-Identification"><a href="#Timbre-reserved-Adversarial-Attack-in-Speaker-Identification" class="headerlink" title="Timbre-reserved Adversarial Attack in Speaker Identification"></a>Timbre-reserved Adversarial Attack in Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00929">http://arxiv.org/abs/2309.00929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie</li>
<li>for: 防止 spoofing 和 adversarial 攻击，提高 speaker identification 系统的安全性</li>
<li>methods: 使用 adversarial constraint 在 voice conversion 模型的不同训练阶段来生成timbre-reserved adversarial audio</li>
<li>results: 可以控制 voice conversion 模型生成 speaker-wised audio，并且可以骗取 speaker identification 系统Here’s a breakdown of each point:</li>
<li>for: The purpose of the paper is to improve the security of speaker identification systems by preventing spoofing and adversarial attacks.</li>
<li>methods: The proposed method uses an adversarial constraint during the training stages of the voice conversion model to generate timbre-reserved adversarial audio.</li>
<li>results: The proposed method can control the voice conversion model to generate speaker-wised audio, which can fool the speaker identification system.<details>
<summary>Abstract</summary>
As a type of biometric identification, a speaker identification (SID) system is confronted with various kinds of attacks. The spoofing attacks typically imitate the timbre of the target speakers, while the adversarial attacks confuse the SID system by adding a well-designed adversarial perturbation to an arbitrary speech. Although the spoofing attack copies a similar timbre as the victim, it does not exploit the vulnerability of the SID model and may not make the SID system give the attacker's desired decision. As for the adversarial attack, despite the SID system can be led to a designated decision, it cannot meet the specified text or speaker timbre requirements for the specific attack scenarios. In this study, to make the attack in SID not only leverage the vulnerability of the SID model but also reserve the timbre of the target speaker, we propose a timbre-reserved adversarial attack in the speaker identification. We generate the timbre-reserved adversarial audios by adding an adversarial constraint during the different training stages of the voice conversion (VC) model. Specifically, the adversarial constraint is using the target speaker label to optimize the adversarial perturbation added to the VC model representations and is implemented by a speaker classifier joining in the VC model training. The adversarial constraint can help to control the VC model to generate the speaker-wised audio. Eventually, the inference of the VC model is the ideal adversarial fake audio, which is timbre-reserved and can fool the SID system.
</details>
<details>
<summary>摘要</summary>
为了使SID系统的攻击不仅利用SID模型的漏洞，而且保留目标说话人的时征，我们在说话认可中提出了一种时征保留式敌意攻击。我们在不同的训练阶段对语音转换（VC）模型进行不同的训练，并在VC模型的表示上添加了一个敌意约束。specifically，我们使用目标说话人标签来优化敌意干扰添加到VC模型表示上的敌意约束，并通过一个说话分类器参与VC模型训练。这个敌意约束可以帮助控制VC模型生成说话者化的声音。最终，VC模型的推断结果是理想的敌意假声音，它保留了目标说话人的时征，可以诱导SID系统进行错误识别。
</details></li>
</ul>
<hr>
<h2 id="BLSP-Bootstrapping-Language-Speech-Pre-training-via-Behavior-Alignment-of-Continuation-Writing"><a href="#BLSP-Bootstrapping-Language-Speech-Pre-training-via-Behavior-Alignment-of-Continuation-Writing" class="headerlink" title="BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing"></a>BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00916">http://arxiv.org/abs/2309.00916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cwang621/blsp">https://github.com/cwang621/blsp</a></li>
<li>paper_authors: Chen Wang, Minpeng Liao, Zhongqiang Huang, Jinliang Lu, Junhong Wu, Yuchen Liu, Chengqing Zong, Jiajun Zhang</li>
<li>for: 提高大语言模型（LLM）对话语言能力</li>
<li>methods: 提出了一种 Bootstraps Language-Speech Pre-training（BLSP）方法，通过对继续写作为行为对齐来启动语言-语音预训练</li>
<li>results: 实现了将LLM扩展到语音领域，包括语音识别、语音翻译、语音理解和语音对话，甚至在零shot多语言场景下In English, this means:</li>
<li>for: Improving the ability of large language models (LLMs) to understand spoken language</li>
<li>methods: Proposed a method called Bootstraps Language-Speech Pre-training (BLSP) that uses behavior alignment to pre-train LLMs on speech data</li>
<li>results: Achieved the extension of LLMs to the speech domain, including speech recognition, translation, understanding, and conversation, even in zero-shot cross-lingual scenarios.<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) has sparked significant interest in extending their remarkable language capabilities to speech. However, modality alignment between speech and text still remains an open problem. Current solutions can be categorized into two strategies. One is a cascaded approach where outputs (tokens or states) of a separately trained speech recognition system are used as inputs for LLMs, which limits their potential in modeling alignment between speech and text. The other is an end-to-end approach that relies on speech instruction data, which is very difficult to collect in large quantities. In this paper, we address these issues and propose the BLSP approach that Bootstraps Language-Speech Pre-training via behavior alignment of continuation writing. We achieve this by learning a lightweight modality adapter between a frozen speech encoder and an LLM, ensuring that the LLM exhibits the same generation behavior regardless of the modality of input: a speech segment or its transcript. The training process can be divided into two steps. The first step prompts an LLM to generate texts with speech transcripts as prefixes, obtaining text continuations. In the second step, these continuations are used as supervised signals to train the modality adapter in an end-to-end manner. We demonstrate that this straightforward process can extend the capabilities of LLMs to speech, enabling speech recognition, speech translation, spoken language understanding, and speech conversation, even in zero-shot cross-lingual scenarios.
</details>
<details>
<summary>摘要</summary>
LLMs的出现已经引起了扩展其语言能力到语音的兴趣。然而，语音和文本之间的modalities还未得到了解决。现有的解决方案可以分为两种策略。一种是一个垂直的方法，在 separately 训练的语音识别系统的输出（token或状态）被用作 LLMs 的输入，这限制了它们的潜在能力。另一种是一个端到端的方法，它基于语音指令数据，但这些数据很难收集。在这篇论文中，我们解决了这些问题，并提出了 BLSP 方法，即使用行为对齐来启动语言-语音预训练。我们通过学习一个轻量级的modalities adapter，使得 LLM 在不同的输入模式下（语音段或其转录）展现同样的生成行为。我们的训练过程可以分为两步。第一步是让 LLM 在语音转录为 prefix 的情况下生成文本，获得文本续写。第二步是使用这些续写作为监督信号，在端到端方式下培训 modalities adapter。我们展示了这个简单的过程可以扩展 LLM 的能力到语音，实现语音识别、语音翻译、语音理解和语音对话，甚至在零shot cross-lingual enario 下。
</details></li>
</ul>
<hr>
<h2 id="DiCLET-TTS-Diffusion-Model-based-Cross-lingual-Emotion-Transfer-for-Text-to-Speech-–-A-Study-between-English-and-Mandarin"><a href="#DiCLET-TTS-Diffusion-Model-based-Cross-lingual-Emotion-Transfer-for-Text-to-Speech-–-A-Study-between-English-and-Mandarin" class="headerlink" title="DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for Text-to-Speech – A Study between English and Mandarin"></a>DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for Text-to-Speech – A Study between English and Mandarin</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00883">http://arxiv.org/abs/2309.00883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Li, Chenxu Hu, Jian Cong, Xinfa Zhu, Jingbei Li, Qiao Tian, Yuping Wang, Lei Xie<br>for:* 这篇论文主要针对的是如何使用Diffusion模型进行语言跨变的语音合成，以提高语音自然性和情感表达。methods:* 提出了一种基于Diffusion模型的跨语言情感传递方法（DiCLET-TTS），通过将情感从源语言 speaker传递到目标语言 speaker中，提高语音的自然性和情感表达。* 为了解决外语人声问题，提出了一种使用前文 encoder 的语言独立预测器来填充跨语言 target speaker 的语音终端分布。* 为了解决情感表达弱化问题，提出了一种使用 Condition-enhanced DPM decoder 来增强模型对 speaker 和情感的表达能力。results:* 对多种竞争模型进行了跨语言情感传递试验，结果显示 DiCLET-TTS 的表现较为出色，能够提高语音自然性和情感表达。* 对 OP-EDM 的设计进行了分析和评估，结果表明 OP-EDM 可以学习 speaker-irrelevant yet emotion-discriminative embedding，并且对情感表达具有积极的效果。<details>
<summary>Abstract</summary>
While the performance of cross-lingual TTS based on monolingual corpora has been significantly improved recently, generating cross-lingual speech still suffers from the foreign accent problem, leading to limited naturalness. Besides, current cross-lingual methods ignore modeling emotion, which is indispensable paralinguistic information in speech delivery. In this paper, we propose DiCLET-TTS, a Diffusion model based Cross-Lingual Emotion Transfer method that can transfer emotion from a source speaker to the intra- and cross-lingual target speakers. Specifically, to relieve the foreign accent problem while improving the emotion expressiveness, the terminal distribution of the forward diffusion process is parameterized into a speaker-irrelevant but emotion-related linguistic prior by a prior text encoder with the emotion embedding as a condition. To address the weaker emotional expressiveness problem caused by speaker disentanglement in emotion embedding, a novel orthogonal projection based emotion disentangling module (OP-EDM) is proposed to learn the speaker-irrelevant but emotion-discriminative embedding. Moreover, a condition-enhanced DPM decoder is introduced to strengthen the modeling ability of the speaker and the emotion in the reverse diffusion process to further improve emotion expressiveness in speech delivery. Cross-lingual emotion transfer experiments show the superiority of DiCLET-TTS over various competitive models and the good design of OP-EDM in learning speaker-irrelevant but emotion-discriminative embedding.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:近些年来，跨语言 TTS 基于单语言 corpus 的性能有了显著改进，但是跨语言 speech 仍然受到外语口音问题的限制，导致自然性有限。此外，当前的跨语言方法忽略了模型情感，这是非语言信息的不可或缺的一部分。在这篇论文中，我们提出了 DiCLET-TTS，一种基于扩散模型的跨语言情感传递方法，可以将情感从源说话者传递到内语言和跨语言目标说话者。具体来说，为了减轻外语口音问题而提高情感表达度，末端扩散过程的终端分布被参数化为一个不相关于说话者，但是与情感相关的语言预测器的参数。此外，为了解决由说话者分解引起的情感表达度较弱的问题，我们提出了一种新的正交 проекции基本的情感分离模块（OP-EDM），可以学习不相关于说话者，但是能够分离情感的嵌入。此外，我们还引入了增强说话者和情感的Condition-enhanced DPM解oder，以进一步提高情感表达度在语音交流中。跨语言情感传递实验表明 DiCLET-TTS 在多种竞争模型中表现出色，并且OP-EDM在学习不相关于说话者，但是能够分离情感的嵌入方面具有良好的设计。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.SD_2023_09_02/" data-id="clmjn91ob00bp0j88f84fapkb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/03/eess.IV_2023_09_03/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-09-03
        
      </div>
    </a>
  
  
    <a href="/2023/09/02/cs.LG_2023_09_02/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-09-02</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">69</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">32</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
