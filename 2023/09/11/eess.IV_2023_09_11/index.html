
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-09-11 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Designs and Implementations in Neural Network-based Video Coding paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.05846 repo_url: None paper_authors: Yue Li, Junru Li, Chaoyi Lin, Kai Zhang, Li Zhang, Franck Galp">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-09-11">
<meta property="og:url" content="https://nullscc.github.io/2023/09/11/eess.IV_2023_09_11/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Designs and Implementations in Neural Network-based Video Coding paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.05846 repo_url: None paper_authors: Yue Li, Junru Li, Chaoyi Lin, Kai Zhang, Li Zhang, Franck Galp">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-11T09:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T08:57:43.312Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_09_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/11/eess.IV_2023_09_11/" class="article-date">
  <time datetime="2023-09-11T09:00:00.000Z" itemprop="datePublished">2023-09-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-09-11
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Designs-and-Implementations-in-Neural-Network-based-Video-Coding"><a href="#Designs-and-Implementations-in-Neural-Network-based-Video-Coding" class="headerlink" title="Designs and Implementations in Neural Network-based Video Coding"></a>Designs and Implementations in Neural Network-based Video Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05846">http://arxiv.org/abs/2309.05846</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Li, Junru Li, Chaoyi Lin, Kai Zhang, Li Zhang, Franck Galpin, Thierry Dumas, Hongtao Wang, Muhammed Coban, Jacob Ström, Du Liu, Kenneth Andersson</li>
<li>for: 这篇论文主要是关于 neural network-based video coding (NNVC) 的研究和应用。</li>
<li>methods: 这篇论文使用了两种主要的 neural network-based video coding 技术：卷积 neural network-based intra prediction 和卷积 neural network-based in-loop filtering。</li>
<li>results: 对于 random-access、low-delay 和 all-intra 配置，使用了提出的 NN-based coding tools 可以实现 {11.94%, 21.86%, 22.59%} BD-rate reductions 的平均提升。<details>
<summary>Abstract</summary>
The past decade has witnessed the huge success of deep learning in well-known artificial intelligence applications such as face recognition, autonomous driving, and large language model like ChatGPT. Recently, the application of deep learning has been extended to a much wider range, with neural network-based video coding being one of them. Neural network-based video coding can be performed at two different levels: embedding neural network-based (NN-based) coding tools into a classical video compression framework or building the entire compression framework upon neural networks. This paper elaborates some of the recent exploration efforts of JVET (Joint Video Experts Team of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC29) in the name of neural network-based video coding (NNVC), falling in the former category. Specifically, this paper discusses two major NN-based video coding technologies, i.e. neural network-based intra prediction and neural network-based in-loop filtering, which have been investigated for several meeting cycles in JVET and finally adopted into the reference software of NNVC. Extensive experiments on top of the NNVC have been conducted to evaluate the effectiveness of the proposed techniques. Compared with VTM-11.0_nnvc, the proposed NN-based coding tools in NNVC-4.0 could achieve {11.94%, 21.86%, 22.59%}, {9.18%, 19.76%, 20.92%}, and {10.63%, 21.56%, 23.02%} BD-rate reductions on average for {Y, Cb, Cr} under random-access, low-delay, and all-intra configurations respectively.
</details>
<details>
<summary>摘要</summary>
过去一代，深度学习在知名人工智能应用中取得了巨大成功，如面部识别、自动驾驶和大型语言模型如ChatGPT。近些年，深度学习的应用范围已经扩展到了非常广泛，其中包括神经网络基于的视频编码。神经网络基于的视频编码可以在两个不同的水平进行：在经典视频压缩框架中嵌入神经网络基于的编码工具，或者建立整个压缩框架基于神经网络。这篇论文介绍了过去几年，JVET（国际电信标准化组织ITU-T SG 16 WP 3和ISO/IEC JTC 1/SC29联合视频专家小组）在神经网络基于的视频编码（NNVC）方面的一些探索努力。具体来说，这篇论文讨论了JVET在过去几个会议征程中 investigate的两大神经网络基于视频编码技术：神经网络基于内部预测和神经网络基于循环滤波。这两种技术在JVET的参考软件中被采纳，并进行了大量的实验来评估这些技术的效果。相比VTM-11.0_nnvc，NNVC-4.0中的神经网络基于编码工具可以实现{11.94%, 21.86%, 22.59%}、{9.18%, 19.76%, 20.92%}和{10.63%, 21.56%, 23.02%}的BD-rate减少平均值，对于{Y, Cb, Cr} unter random-access、low-delay和all-intra配置分别。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-based-Adversarial-Purification-for-Robust-Deep-MRI-Reconstruction"><a href="#Diffusion-based-Adversarial-Purification-for-Robust-Deep-MRI-Reconstruction" class="headerlink" title="Diffusion-based Adversarial Purification for Robust Deep MRI Reconstruction"></a>Diffusion-based Adversarial Purification for Robust Deep MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05794">http://arxiv.org/abs/2309.05794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sjames40/adversarial-purification-for-mri">https://github.com/sjames40/adversarial-purification-for-mri</a></li>
<li>paper_authors: Ismail Alkhouri, Shijun Liang, Rongrong Wang, Qing Qu, Saiprasad Ravishankar</li>
<li>for: 提高Diffusion模型对MRI重建图像的鲁棒性，增强MRI重建图像的安全性</li>
<li>methods: 利用预训练的Diffusion模型作为对抗干扰器，提高MRI重建图像的对抗性</li>
<li>results: 对比主流防御方法（如对抗训练和随机缓和），我们的提议方法可以更好地提高MRI重建图像的鲁棒性和安全性。<details>
<summary>Abstract</summary>
Deep learning (DL) methods have been extensively employed in magnetic resonance imaging (MRI) reconstruction, demonstrating remarkable performance improvements compared to traditional non-DL methods. However, recent studies have uncovered the susceptibility of these models to carefully engineered adversarial perturbations. In this paper, we tackle this issue by leveraging diffusion models. Specifically, we introduce a defense strategy that enhances the robustness of DL-based MRI reconstruction methods through the utilization of pre-trained diffusion models as adversarial purifiers. Unlike conventional state-of-the-art adversarial defense methods (e.g., adversarial training), our proposed approach eliminates the need to solve a minimax optimization problem to train the image reconstruction model from scratch, and only requires fine-tuning on purified adversarial examples. Our experimental findings underscore the effectiveness of our proposed technique when benchmarked against leading defense methodologies for MRI reconstruction such as adversarial training and randomized smoothing.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）方法已广泛应用于 магни共振成像（MRI）重建，表现出了非常出色的性能提高 compared to traditional non-DL 方法。然而，最近的研究发现，这些模型对特殊设计的恶作剂抗干扰有极高的感受性。在这篇论文中，我们解决这个问题，通过利用扩散模型。我们首先介绍了一种防御策略，通过预训练的扩散模型来增强 DL-based MRI 重建方法的Robustness。与传统的State-of-the-art adversarial defense方法（例如，对抗训练）不同，我们的提议方法不需要解决一个 minimax 优化问题来训练图像重建模型，只需要在纯化的恶作剂例子上进行细调。我们的实验结果表明，我们的提议技术对于 MRI 重建中的防御方法进行了证明，并且比领先的防御方法（如对抗训练和随机滤波）更有效。
</details></li>
</ul>
<hr>
<h2 id="From-Capture-to-Display-A-Survey-on-Volumetric-Video"><a href="#From-Capture-to-Display-A-Survey-on-Volumetric-Video" class="headerlink" title="From Capture to Display: A Survey on Volumetric Video"></a>From Capture to Display: A Survey on Volumetric Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05658">http://arxiv.org/abs/2309.05658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yili Jin, Kaiyuan Hu, Junhua Liu, Fangxin Wang, Xue Liu</li>
<li>for: 这篇论文旨在为探讨volumetric video服务提供一个全面的 literature review，以便更好地理解这个领域的发展趋势和未来研究方向。</li>
<li>methods: 本论文首先提供了volumetric video服务的总体框架，然后详细介绍了volumetric video服务的各个阶段技术，包括捕捉、压缩、传输、渲染和显示等方面的技术。</li>
<li>results: 本论文通过对现有Literature的审核和分析，探讨了volumetric video服务的多种应用场景和未来研究机会，并提供了一些未来研究方向的想法和建议。<details>
<summary>Abstract</summary>
Volumetric video, which offers immersive viewing experiences, is gaining increasing prominence. With its six degrees of freedom, it provides viewers with greater immersion and interactivity compared to traditional videos. Despite their potential, volumetric video services poses significant challenges. This survey conducts a comprehensive review of the existing literature on volumetric video. We firstly provide a general framework of volumetric video services, followed by a discussion on prerequisites for volumetric video, encompassing representations, open datasets, and quality assessment metrics. Then we delve into the current methodologies for each stage of the volumetric video service pipeline, detailing capturing, compression, transmission, rendering, and display techniques. Lastly, we explore various applications enabled by this pioneering technology and we present an array of research challenges and opportunities in the domain of volumetric video services. This survey aspires to provide a holistic understanding of this burgeoning field and shed light on potential future research trajectories, aiming to bring the vision of volumetric video to fruition.
</details>
<details>
<summary>摘要</summary>
三维视频技术在吸引人们的视觉经验方面占据着越来越重要的地位。它的六个自由度使得观众能够更深入地参与到视频中，与传统视频相比，具有更高的吸引力和互动性。然而，三维视频服务也面临着一些挑战。这篇评论通过对现有文献的审核，为读者提供了三维视频服务的全面性评价。我们首先提供了三维视频服务的通用框架，然后讨论了三维视频的前提条件，包括表示、开放数据集和质量评价指标。接着，我们详细介绍了每个三维视频服务管道阶段的方法，包括捕获、压缩、传输、渲染和显示技术。最后，我们探讨了三维视频服务所带来的各种应用，并提出了这一领域的一些研究挑战和机遇。这篇评论的目的是为读者提供三维视频服务领域的总体理解，并且预测未来研究的趋势，以便实现三维视频的未来视野。
</details></li>
</ul>
<hr>
<h2 id="A-survey-on-real-time-3D-scene-reconstruction-with-SLAM-methods-in-embedded-systems"><a href="#A-survey-on-real-time-3D-scene-reconstruction-with-SLAM-methods-in-embedded-systems" class="headerlink" title="A survey on real-time 3D scene reconstruction with SLAM methods in embedded systems"></a>A survey on real-time 3D scene reconstruction with SLAM methods in embedded systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05349">http://arxiv.org/abs/2309.05349</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quentin Picard, Stephane Chevobbe, Mehdi Darouich, Jean-Yves Didier</li>
<li>for: 这篇论文旨在探讨资源受限的硬件平台上实现视觉基于的3D场景重建管线，以及其在实时地图建模和物体识别方面的应用。</li>
<li>methods: 文章描述了一种视觉基于的3D场景重建管线，包括激光雷达、图像和深度感知等多种感知器，以及在资源受限的硬件平台上实现的一系列技术，如缓存管理和吞吐量优化。</li>
<li>results: 文章介绍了在实际应用中的实时性、内存管理和功耗优化，以及在不同粒度的3D场景重建方面的质量和性能评估。<details>
<summary>Abstract</summary>
The 3D reconstruction of simultaneous localization and mapping (SLAM) is an important topic in the field for transport systems such as drones, service robots and mobile AR/VR devices. Compared to a point cloud representation, the 3D reconstruction based on meshes and voxels is particularly useful for high-level functions, like obstacle avoidance or interaction with the physical environment. This article reviews the implementation of a visual-based 3D scene reconstruction pipeline on resource-constrained hardware platforms. Real-time performances, memory management and low power consumption are critical for embedded systems. A conventional SLAM pipeline from sensors to 3D reconstruction is described, including the potential use of deep learning. The implementation of advanced functions with limited resources is detailed. Recent systems propose the embedded implementation of 3D reconstruction methods with different granularities. The trade-off between required accuracy and resource consumption for real-time localization and reconstruction is one of the open research questions identified and discussed in this paper.
</details>
<details>
<summary>摘要</summary>
三维重建（3D reconstruction）是交通系统如无人机、服务机器人和移动AR/VR设备等领域的重要话题。与点云表示相比，基于多面体和 voxel 的三维重建特别有用于高级功能，如避免障碍物或与物理环境交互。本文介绍了资源限制的硬件平台上的视觉基于的三维场景重建管道的实现。实时性、内存管理和低功耗是嵌入式系统的关键要求。一个普通的 SLAM 管道从感知器到三维重建被描述，包括可能的深度学习应用。实现高级功能的限制是讨论的一个开放研究问题。文章还讨论了不同粒度的三维重建方法的嵌入实现，以及实时位置和重建的资源消耗和精度之间的负荷。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/11/eess.IV_2023_09_11/" data-id="clp9qz8e501a8ok88gi6q90vp" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/11/cs.LG_2023_09_11/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-09-11
        
      </div>
    </a>
  
  
    <a href="/2023/09/11/eess.SP_2023_09_11/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.SP - 2023-09-11</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
