
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-09-21 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.12294 repo_url: None paper_authors: Levon Haroutunian, Zhuang">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-09-21">
<meta property="og:url" content="https://nullscc.github.io/2023/09/21/cs.CL_2023_09_21/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.12294 repo_url: None paper_authors: Levon Haroutunian, Zhuang">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-21T11:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T12:35:32.149Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.CL_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T11:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-09-21
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Reranking-for-Natural-Language-Generation-from-Logical-Forms-A-Study-based-on-Large-Language-Models"><a href="#Reranking-for-Natural-Language-Generation-from-Logical-Forms-A-Study-based-on-Large-Language-Models" class="headerlink" title="Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models"></a>Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12294">http://arxiv.org/abs/2309.12294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Levon Haroutunian, Zhuang Li, Lucian Galescu, Philip Cohen, Raj Tumuluri, Gholamreza Haffari</li>
<li>for: 本研究旨在提高大语言模型（LLM）生成的自然语言质量，特别是在自然语言生成从逻辑形式（LF）时的输出质量。</li>
<li>methods: 我们提出了一种生成并重新排序的方法，其包括首先通过提问LLM生成一组候选输出，然后使用任务特定的重新排序模型对其进行重新排序。此外，我们还收集了一个手动抽象的数据集，用于评估不同排名指标和人类判断的对应关系。</li>
<li>results: 我们在三个不同的数据集上进行了广泛的实验，并证明了我们的方法可以提高LLM生成的输出质量，特别是在 semantic consistency 和 fluency 两个维度上。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs). This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations. In this work, we tackle this issue by proposing a novel generate-and-rerank approach. Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model. In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements. The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model. By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics. Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Inspire-the-Large-Language-Model-by-External-Knowledge-on-BioMedical-Named-Entity-Recognition"><a href="#Inspire-the-Large-Language-Model-by-External-Knowledge-on-BioMedical-Named-Entity-Recognition" class="headerlink" title="Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition"></a>Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12278">http://arxiv.org/abs/2309.12278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Bian, Jiaxuan Zheng, Yuyi Zhang, Shanfeng Zhu</li>
<li>for: 这篇论文是为了解决生物医学命名实体识别（BioNER）任务而写的。</li>
<li>methods: 该论文使用链式思维的方法，将NER任务拆分成了实体识别和实体类型决定两个步骤。此外，为了解决LLM缺乏域知识的问题，我们在实体类型决定中注入了实体知识。</li>
<li>results: 实验结果表明，我们的两步 BioNER 方法与之前的几个shot LLMBasis 比较显著提高了表现。此外，含外部知识的 incorporation 也显著提高了实体类型决定性表现。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks. However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER). In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination. Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category. Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline. Additionally, the incorporation of external knowledge significantly enhances entity category determination performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-VTE-Identification-through-Adaptive-NLP-Model-Selection-and-Clinical-Expert-Rule-based-Classifier-from-Radiology-Reports"><a href="#Improving-VTE-Identification-through-Adaptive-NLP-Model-Selection-and-Clinical-Expert-Rule-based-Classifier-from-Radiology-Reports" class="headerlink" title="Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports"></a>Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12273">http://arxiv.org/abs/2309.12273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jamie Deng, Yusen Wu, Hilary Hayssen, Brain Englum, Aman Kankaria, Minerva Mayorga-Carlin, Shalini Sahoo, John Sorkin, Brajesh Lal, Yelena Yesha, Phuong Nguyen</li>
<li>for: 这研究旨在提高无结构（自由文本）医疗报告中的深部静脉血栓（DVT）和肺动脉血栓（PE）识别率，以便更好地治疗 cardiovascular disease。</li>
<li>methods: 这研究使用自然语言处理（NLP）方法，包括深度学习（DL）和NLP模型，以自动识别医疗报告中的VTE事件。</li>
<li>results: 实验结果显示，这模型可以实现97%的准确率和97%的F1分数在预测DVT，以及98.3%的准确率和98.4%的F1分数在预测PE。这些结果证明了这模型的稳定性和其在VTE研究中的潜在贡献。<details>
<summary>Abstract</summary>
Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment. Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports. However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance. This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports. Our experimental results demonstrate the model's efficacy, achieving an impressive 97\% accuracy and 97\% F1 score in predicting DVT, and an outstanding 98.3\% accuracy and 98.4\% F1 score in predicting PE. These findings emphasize the model's robustness and its potential to significantly contribute to VTE research.
</details>
<details>
<summary>摘要</summary>
快速和准确地识别深静脉 tromboembolismo (VTE)，包括深静脉 trombosis (DVT) 和肺动脉 trombosis (PE)，是诊断Cardiovascular disease 的关键。通过自然语言处理（NLP）技术，自动方法在从Retrospective data cohorts 中提取VTE事件已经显示出了可观的进步。然而，因为医疗数据的有限性， radiology report的复杂性和多样性，以及数据不均衡，训练深度学习（DL）和NLP模型是一项挑战。这项研究提出了一种 combining DL 方法，并与数据扩展、适应预训练 NLP 模型选择和临床专家 NLP 规则生成器，以提高无结构（free-text） radiology report中VTE识别的准确性。我们的实验结果表明，该模型在 DVT 预测中达到了97%的准确率和97%的 F1 分数，而在 PE 预测中达到了98.3%的准确率和98.4%的 F1 分数。这些结果证明了模型的稳定性，并且其潜在地对 VTE 研究做出了重要贡献。
</details></li>
</ul>
<hr>
<h2 id="The-Cambridge-Law-Corpus-A-Corpus-for-Legal-AI-Research"><a href="#The-Cambridge-Law-Corpus-A-Corpus-for-Legal-AI-Research" class="headerlink" title="The Cambridge Law Corpus: A Corpus for Legal AI Research"></a>The Cambridge Law Corpus: A Corpus for Legal AI Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12269">http://arxiv.org/abs/2309.12269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Östling, Holli Sargeant, Huiyuan Xie, Ludwig Bull, Alexander Terenin, Leif Jonsson, Måns Magnusson, Felix Steffek</li>
<li>for: 这个论文是为了推广法律人工智能研究而创建的剑桥法律词库（CLC）。</li>
<li>methods: 该词库包含了250,000余个法律案例，主要来自21世纪，但也包括16世纪以前的案例。论文还提供了638个案例的注释，由法律专家进行标注。</li>
<li>results: 通过使用GPT-3、GPT-4和RoBERTa模型进行训练和评估， authors提供了情况出来案例结果抽取的基准。<details>
<summary>Abstract</summary>
We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
</details>
<details>
<summary>摘要</summary>
我们介绍了剑桥法律词库（CLC），一个用于法律人工智能研究的词库。它包含了超过250,000个法律案例，大多数是21世纪的案例，但词库还包括了16世纪的案例。本文发布了词库的首个版本，包括原始文本和元数据。同时，我们提供了638个案例的法律专家标注，用于训练和评估案例结果提取模型。我们还进行了广泛的法律和伦理讨论，以Address the potentially sensitive nature of this material。因此，词库将仅为研究用途发布，受到一定的限制。
</details></li>
</ul>
<hr>
<h2 id="On-the-Relationship-between-Skill-Neurons-and-Robustness-in-Prompt-Tuning"><a href="#On-the-Relationship-between-Skill-Neurons-and-Robustness-in-Prompt-Tuning" class="headerlink" title="On the Relationship between Skill Neurons and Robustness in Prompt Tuning"></a>On the Relationship between Skill Neurons and Robustness in Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12263">http://arxiv.org/abs/2309.12263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Ackermann, Xenia Ohmer</li>
<li>for: 这个论文的目的是研究Prompt Tuning在PLMs中的稳定性，以及这种方法如何在不同任务上进行转移学习。</li>
<li>methods: 作者使用了RoBERTa和T5进行实验，并通过分析Prompt Tuning activates specific neurons in transformer的feed-forward networks，以及这些神经元在不同任务上的表现，来研究Prompt Tuning的稳定性。</li>
<li>results: 研究发现，Prompt Tuning在不同任务上的表现不够稳定，尤其是在对抗数据上。而T5比RoBERTa更高的对抗 robustness可能与模型在对抗数据上活动的相关神经元有关。同时，研究还发现了RoBERTa和T5中的技能神经元，并证明了这些神经元在不同任务上的表现。<details>
<summary>Abstract</summary>
Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these "skill neurons", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data.
</details>
<details>
<summary>摘要</summary>
Prompt Tuning 是一种广泛使用的减少参数的 finetuning 方法 для预训练大语言模型（PLM）。最近，通过 RoBERTa 的实验，提出了 Prompt Tuning 可以活化特定的 neuron 在 transformer 的Feedforward 网络中，这些 neuron 对给定任务是非常预测和选择性的。在这篇文章中，我们研究了 Prompt Tuning 的稳定性，与这些“技能 neuron”相关。我们使用 RoBERTa 和 T5 进行实验，并发现：Prompt Tuning 为特定任务适应性较高，但对 adversarial 数据不够稳定。同时，我们复现了 RoBERTa 中的技能 neuron，并发现 T5 中的技能 neuron 也存在。有趣的是，T5 中的技能 neuron 在非 adversarial 数据上确定的也是最预测性的 neuron 在 adversarial 数据上，而 RoBERTa 中的技能 neuron 不是。我们 conclude  что高度 adversarial 稳定性可能与模型的能力启动相关的技能 neuron 在 adversarial 数据上有关。
</details></li>
</ul>
<hr>
<h2 id="SQUARE-Automatic-Question-Answering-Evaluation-using-Multiple-Positive-and-Negative-References"><a href="#SQUARE-Automatic-Question-Answering-Evaluation-using-Multiple-Positive-and-Negative-References" class="headerlink" title="SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References"></a>SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12250">http://arxiv.org/abs/2309.12250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Gabburo, Siddhant Garg, Rik Koncel Kedziorski, Alessandro Moschitti</li>
<li>for: 评估问答系统的可靠性和效果是非常困难和昂贵的，现有的最可靠的方法是人工标注问答的正确性。</li>
<li>methods: 我们提出了一个新的评估指标：SQuArE（句子级问答回答评估），使用多个参考答案（组合多个正确和错误的参考答案）来评估句子级问答系统。</li>
<li>results: 我们在多个学术和工业数据集上评估了SQuArE，并发现它比前一些基线表现更好，并与人工标注之间有最高的相关性。<details>
<summary>Abstract</summary>
Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations.
</details>
<details>
<summary>摘要</summary>
评估问答系统非常具有挑战性和成本高，人工注解正确答案为问题的最可靠方法。最近的研究（AVA、BEM）表明，基于转换器LM推理器的相似度指标可以有效地评估问答系统，但它们受到单个正确参考答案的限制。我们提议一种新的评估指标：SQuArE（句子级问题答案评估），使用多个参考答案（包括多个正确和错误参考）进行句子级问题评估。我们对多个学术和工业数据集进行了评估，并发现SQuArE超过了之前的基线和人工注解之间的相关性。
</details></li>
</ul>
<hr>
<h2 id="Bridging-the-Gaps-of-Both-Modality-and-Language-Synchronous-Bilingual-CTC-for-Speech-Translation-and-Speech-Recognition"><a href="#Bridging-the-Gaps-of-Both-Modality-and-Language-Synchronous-Bilingual-CTC-for-Speech-Translation-and-Speech-Recognition" class="headerlink" title="Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition"></a>Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12234">http://arxiv.org/abs/2309.12234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Xu, Xiaoqian Liu, Erfeng He, Yuhao Zhang, Qianqian Dong, Tong Xiao, Jingbo Zhu, Dapeng Man, Wu Yang</li>
<li>for: 这项研究旨在提出同步双语Connectionist Temporal Classification（CTC）框架，用于bridging模式和语言之间的差异在语音翻译（ST）任务中。</li>
<li>methods: 我们使用了训练录音和翻译为同时目标的CTC，将audio和文本之间的差异桥接，以及源语言和目标语言之间的差异。我们基于 latest CTC应用的进步，开发了加强版BiL-CTC+，在资源受限的情况下在MuST-C STbenchmark上达到新的州OF-THE-ART表现。</li>
<li>results: 我们的方法不仅在ST任务中实现了新的州OF-THE-ART表现，还显著提高了语音识别性能， demonstarting cross-lingual learning的广泛应用和语音识别的相互关系。<details>
<summary>Abstract</summary>
In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提出了同步双语Connectionist Temporal Classification（CTC）框架，这是一种创新的框架，可以跨越语言和modalities在语音翻译（ST）任务中bridges the gaps。我们利用讲解和翻译作为同时目标，我们的模型可以将音频和文本相互关联，以及源语言和目标语言之间的关联。 builds upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. source code is available at https://github.com/xuchennlp/S2T.
</details></li>
</ul>
<hr>
<h2 id="Towards-Answering-Health-related-Questions-from-Medical-Videos-Datasets-and-Approaches"><a href="#Towards-Answering-Health-related-Questions-from-Medical-Videos-Datasets-and-Approaches" class="headerlink" title="Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches"></a>Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12224">http://arxiv.org/abs/2309.12224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Gupta, Kush Attal, Dina Demner-Fushman</li>
<li>for:  Answering health-related questions asked by the public through visual answers from medical videos.</li>
<li>methods:  Created two large-scale datasets (HealthVidQA-CRF and HealthVidQA-Prompt) and proposed monomodal and multimodal approaches to provide visual answers from medical videos to natural language questions.</li>
<li>results:  Datasets have the potential to enhance the performance of medical visual answer localization tasks, and pre-trained language-vision models may further improve performance.Here’s the Chinese translation:</li>
<li>for:  Answering 公众健康问题通过医疗视频的视觉答案。</li>
<li>methods:  开发了两个大规模数据集（HealthVidQA-CRF 和 HealthVidQA-Prompt），并提出了单模态和多模态方法，以寻找医疗视频中的自然语言问题的视觉答案。</li>
<li>results: 数据集可能提高医疗视answer定位任务的性能，并且可能通过预训练语言视觉模型进一步提高性能。<details>
<summary>Abstract</summary>
The increase in the availability of online videos has transformed the way we access information and knowledge. A growing number of individuals now prefer instructional videos as they offer a series of step-by-step procedures to accomplish particular tasks. The instructional videos from the medical domain may provide the best possible visual answers to first aid, medical emergency, and medical education questions. Toward this, this paper is focused on answering health-related questions asked by the public by providing visual answers from medical videos. The scarcity of large-scale datasets in the medical domain is a key challenge that hinders the development of applications that can help the public with their health-related questions. To address this issue, we first proposed a pipelined approach to create two large-scale datasets: HealthVidQA-CRF and HealthVidQA-Prompt. Later, we proposed monomodal and multimodal approaches that can effectively provide visual answers from medical videos to natural language questions. We conducted a comprehensive analysis of the results, focusing on the impact of the created datasets on model training and the significance of visual features in enhancing the performance of the monomodal and multi-modal approaches. Our findings suggest that these datasets have the potential to enhance the performance of medical visual answer localization tasks and provide a promising future direction to further enhance the performance by using pre-trained language-vision models.
</details>
<details>
<summary>摘要</summary>
随着在线视频的普及，我们获取信息和知识的方式发生了深刻的变革。更多的人现在偏好使用说明视频，因为它们提供了一系列步骤的操作来完成特定任务。医疗领域的 instruccional videos 可以提供最佳的视觉答案，用于医疗问题的第一 aid、紧急情况和医学教育。为此，本文将关注公众提出的健康问题，通过医疗视频提供视觉答案。医疗领域的数据匮乏是主要挑战，这阻碍了应用程序的发展，用于帮助公众解决其健康问题。为解决这个问题，我们首先提出了一种管道方法，用于创建两个大规模数据集：HealthVidQA-CRF 和 HealthVidQA-Prompt。后来，我们提出了单模态和多模态方法，可以有效地从医疗视频中提取视觉答案，并与自然语言问题进行对应。我们对结果进行了全面的分析，注重数据集的创建对模型训练的影响，以及视觉特征在单模态和多模态方法中的重要性。我们的发现表明，这些数据集有potentiality 提高医疗视 Answer Localization 任务的性能，并提供了未来可能性，通过使用预训练语言视觉模型，进一步提高性能。
</details></li>
</ul>
<hr>
<h2 id="Code-Soliloquies-for-Accurate-Calculations-in-Large-Language-Models"><a href="#Code-Soliloquies-for-Accurate-Calculations-in-Large-Language-Models" class="headerlink" title="Code Soliloquies for Accurate Calculations in Large Language Models"></a>Code Soliloquies for Accurate Calculations in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12161">http://arxiv.org/abs/2309.12161</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luffycodes/tutorbot-spock-phys">https://github.com/luffycodes/tutorbot-spock-phys</a></li>
<li>paper_authors: Shashank Sonkar, MyCo Le, Xinghe Chen, Naiming Liu, Debshila Basu Mallick, Richard G. Baraniuk</li>
<li>for: 这paper是为了提高大型语言模型（LLM）后端的开发而写的，具体来说是为了提高学生和ITS之间的互动质量。</li>
<li>methods: 这paper使用了先进的GPT-4模型来生成合成学生教师对话，以便用于精度地准确地训练LLM后端。</li>
<li>results: 这paper的结果表明，使用我们的新的状态full prompt设计可以增强合成对话集的质量，特别是在需要计算的科学概念上。我们的Higgs模型（一个LLaMAfinetune的模型）能够有效地使用Python进行计算，并且通过使用我们生成的代码演讲来提高它的答案的准确性和计算可靠性。<details>
<summary>Abstract</summary>
High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations. If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations. Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses.
</details>
<details>
<summary>摘要</summary>
高品质的对话Dataset是智能教学系统（ITS）的成功开发所需的一个重要组成部分。这些Dataset，当用于调整LLM后端，将会对学生和ITS之间的互动提高质量。一种常见的发展策略是使用进步的GPT-4模型生成 sintetic的学生-教师对话。但是，当这些对话需要复杂的计算时，GPT-4的表现会变差，这是一个重要的限制，它对于这些主题的 utility 有限。为了解决这些挑战，这篇文章提出了一个创新的状态执行Prompt设计。我们的方法生成了一个模拟学生和教师的对话，这两个角色都是由GPT-4 simulate。每个学生回应都会触发GPT-tutorbot的内言（soliloquy），判断其回应是否需要计算。如果是，它会进行Python脚本的scripting，然后使用结果来建立对学生的回应。我们的方法对于计算数量充满的主题特别有助，我们的发现显示，我们的Higgs模型（LLaMA finetuned with我们的新状态执行Prompt设计）能够有效地使用Python进行计算。因此，在我们的Dataset中添加了code soliloquies后，调整Higgs的精度和计算可靠性都会提高。
</details></li>
</ul>
<hr>
<h2 id="How-to-Guides-for-Specific-Audiences-A-Corpus-and-Initial-Findings"><a href="#How-to-Guides-for-Specific-Audiences-A-Corpus-and-Initial-Findings" class="headerlink" title="How-to Guides for Specific Audiences: A Corpus and Initial Findings"></a>How-to Guides for Specific Audiences: A Corpus and Initial Findings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12117">http://arxiv.org/abs/2309.12117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicola Fanton, Agnieszka Falenska, Michael Roth</li>
<li>for: 这篇论文探讨了wikiHow上的指南文章是如何针对不同目标群体而变化的。</li>
<li>methods: 研究者采用了资深分析和计算方法来检测wikiHow上的指南文章是否受到社会偏见和潜伏偏见的影响。</li>
<li>results: 研究结果表明，wikiHow上的指南文章受到了潜伏偏见，且这些偏见随着目标群体的不同而发生变化。<details>
<summary>Abstract</summary>
Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals. However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes. In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience. We conduct two case studies in which we examine qualitative features of texts written for specific audiences. In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods. The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases. We aim to raise awareness of these inequalities as a first step to addressing them in future work.
</details>
<details>
<summary>摘要</summary>
instrucitonal 文本应该考虑目标群体的先前知识和需求，以有效地引导他们达到他们的目标。然而，targeting 特定群体也可能表达不同的社会规范和潜在偏见。在这篇论文中，我们调查了wikiHow的how-to 指南是否因target audience而有所不同。我们进行了两项案例研究，以及一项通用研究，以系统地表明这些差异。我们的研究结果表明，wikiHow的指南，如其他文本类型，受到潜在偏见的影响。我们希望通过这篇论文来启发人们对这些不平等的意识，以便在未来的工作中解决它们。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Computational-Analysis-of-Vagueness-in-Revisions-of-Instructional-Texts"><a href="#A-Computational-Analysis-of-Vagueness-in-Revisions-of-Instructional-Texts" class="headerlink" title="A Computational Analysis of Vagueness in Revisions of Instructional Texts"></a>A Computational Analysis of Vagueness in Revisions of Instructional Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12107">http://arxiv.org/abs/2309.12107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alok Debnath, Michael Roth</li>
<li>for: 本研究旨在分析 revision history 中带有uncertainty的 instruction 的修改。</li>
<li>methods: 研究采用 neural network 模型，对两个版本的 instruction 进行对比，并采用 previous work 中的 pairwise ranking 任务来评价模型的能力。</li>
<li>results: 研究显示，使用 neural network 模型可以准确地分辨两个版本的 instruction，并且与existig baselines 相比，显示出提高的性能。<details>
<summary>Abstract</summary>
WikiHow is an open-domain repository of instructional articles for a variety of tasks, which can be revised by users. In this paper, we extract pairwise versions of an instruction before and after a revision was made. Starting from a noisy dataset of revision histories, we specifically extract and analyze edits that involve cases of vagueness in instructions. We further investigate the ability of a neural model to distinguish between two versions of an instruction in our data by adopting a pairwise ranking task from previous work and showing improvements over existing baselines.
</details>
<details>
<summary>摘要</summary>
WikiHow 是一个开放领域的指南文章存储库，可以由用户修改。在这篇论文中，我们从含有噪声的修订历史数据中提取了对 instrucion 进行了修改的对。我们specifically 提取和分析修订中包含抽象指令的修订。进一步，我们采用了一种对两个 instrucion 版本进行对比的 neural 模型，并证明我们的模型可以在我们的数据集中提高对比性。Note: " instrucion" is a typo in the original text, and I have corrected it to "instruction" in the translation.
</details></li>
</ul>
<hr>
<h2 id="SemEval-2022-Task-7-Identifying-Plausible-Clarifications-of-Implicit-and-Underspecified-Phrases-in-Instructional-Texts"><a href="#SemEval-2022-Task-7-Identifying-Plausible-Clarifications-of-Implicit-and-Underspecified-Phrases-in-Instructional-Texts" class="headerlink" title="SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts"></a>SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12102">http://arxiv.org/abs/2309.12102</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/acidann/claire">https://github.com/acidann/claire</a></li>
<li>paper_authors: Michael Roth, Talita Anthonio, Anna Sauer</li>
<li>for: 这项研究的目的是评估帮助文章的解释是否有效。</li>
<li>methods: 这项研究使用了人工生成的解释和人类的可能性评估来训练参与系统。</li>
<li>results: 参与系统的最佳系统达到了68.9%的准确率，而8个团队的系统描述也被报告。此外，我们还发现了使用最佳参与系统的预测可以在多个可能的解释上达到75.2%的准确率。<details>
<summary>Abstract</summary>
We describe SemEval-2022 Task 7, a shared task on rating the plausibility of clarifications in instructional texts. The dataset for this task consists of manually clarified how-to guides for which we generated alternative clarifications and collected human plausibility judgements. The task of participating systems was to automatically determine the plausibility of a clarification in the respective context. In total, 21 participants took part in this task, with the best system achieving an accuracy of 68.9%. This report summarizes the results and findings from 8 teams and their system descriptions. Finally, we show in an additional evaluation that predictions by the top participating team make it possible to identify contexts with multiple plausible clarifications with an accuracy of 75.2%.
</details>
<details>
<summary>摘要</summary>
我们描述SemEval-2022任务7，这是一个评估 instrucitonal 文本中的解释可能性的共同任务。该任务的数据集包括 manually clarified 的使用指南，我们生成了备用的解释，并收集了人类的可能性评估。参与系统的任务是自动确定解释的可能性在特定上下文中。总共有21个参与者，最佳系统的准确率达到68.9%。这份报告Summarizes 8个团队和他们的系统描述，并在附加评估中表明了最佳参与者的预测可以在多个可能的解释上准确地识别 context 的准确率达到75.2%。
</details></li>
</ul>
<hr>
<h2 id="AceGPT-Localizing-Large-Language-Models-in-Arabic"><a href="#AceGPT-Localizing-Large-Language-Models-in-Arabic" class="headerlink" title="AceGPT, Localizing Large Language Models in Arabic"></a>AceGPT, Localizing Large Language Models in Arabic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12053">http://arxiv.org/abs/2309.12053</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/freedomintelligence/acegpt">https://github.com/freedomintelligence/acegpt</a></li>
<li>paper_authors: Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Ziche Liu, Zhiyi Zhang, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu</li>
<li>for: 本研究旨在开发一个适应阿拉伯语言特点的本地大型自然语言处理模型（LLM），以满足阿拉伯语言speaking community的多样化应用需求。</li>
<li>methods: 该研究提出了一个包装解决方案，包括额外预训练阿拉伯文本，监督精度调整（SFT）使用本地阿拉伯语言指令和GPT-4响应，以及强化学习使用人工智能反馈（RLAIF）的奖励模型，以训练具有当地文化和价值观念的阿拉伯语言LLM。</li>
<li>results: 对于多种测试 benchmark，包括阿拉伯语言 Vicuna-80 和 AlpacaEval 的 instrucion-following benchmark、阿拉伯语言 MMLU 和 EXAMs 的知识 benchmark，以及新提出的阿拉伯文化和价值Alignment benchmark，AceGPT 得到了最高的 SOTA 开放阿拉伯语言 LLM 成绩。尤其是在使用 GPT-4 时，AceGPT 在 Vicuna-80  benchmark 中高于 ChatGPT，尽管这个benchmark的规模相对较小。<details>
<summary>Abstract</summary>
This paper explores the imperative need and methodology for developing a localized Large Language Model (LLM) tailored for Arabic, a language with unique cultural characteristics that are not adequately addressed by current mainstream models like ChatGPT. Key concerns additionally arise when considering cultural sensitivity and local values. To this end, the paper outlines a packaged solution, including further pre-training with Arabic texts, supervised fine-tuning (SFT) using native Arabic instructions and GPT-4 responses in Arabic, and reinforcement learning with AI feedback (RLAIF) using a reward model that is sensitive to local culture and values. The objective is to train culturally aware and value-aligned Arabic LLMs that can serve the diverse application-specific needs of Arabic-speaking communities.   Extensive evaluations demonstrated that the resulting LLM called `\textbf{AceGPT}' is the SOTA open Arabic LLM in various benchmarks, including instruction-following benchmark (i.e., Arabic Vicuna-80 and Arabic AlpacaEval), knowledge benchmark (i.e., Arabic MMLU and EXAMs), as well as the newly-proposed Arabic cultural \& value alignment benchmark. Notably, AceGPT outperforms ChatGPT in the popular Vicuna-80 benchmark when evaluated with GPT-4, despite the benchmark's limited scale. % Natural Language Understanding (NLU) benchmark (i.e., ALUE)   Codes, data, and models are in https://github.com/FreedomIntelligence/AceGPT.
</details>
<details>
<summary>摘要</summary>
这篇论文探讨了需要开发本地化的大语言模型（LLM），以满足阿拉伯语言的独特文化特征，现有主流模型如ChatGPT无法充分考虑。文章还提出了一个套件解决方案，包括额外预训练阿拉伯文本，监督细化（SFT）使用本地阿拉伯指令和GPT-4回答，以及强化学习使用人工智能反馈（RLAIF）的奖励模型，以训练具有本地文化和价值观的阿拉伯语言模型。这些模型可以满足阿拉伯语言社区的多样化应用需求。经过评估， authors 提出了名为 `\textbf{AceGPT}` 的模型，它在不同的测试上达到了最高的表现，包括 instruc-following 测试（i.e., Arabic Vicuna-80和Arabic AlpacaEval）、知识测试（i.e., Arabic MMLU和EXAMs）以及 newly-proposed 阿拉伯文化和价值观念测试。特别是，AceGPT 在 Vicuna-80 测试中，使用 GPT-4 时与 ChatGPT 进行比较，即使测试的规模较小。codes、数据和模型可以在 GitHub 上找到：<https://github.com/FreedomIntelligence/AceGPT>。
</details></li>
</ul>
<hr>
<h2 id="CAMERA-A-Multimodal-Dataset-and-Benchmark-for-Ad-Text-Generation"><a href="#CAMERA-A-Multimodal-Dataset-and-Benchmark-for-Ad-Text-Generation" class="headerlink" title="CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation"></a>CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12030">http://arxiv.org/abs/2309.12030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Mita, Soichiro Murakami, Akihiko Kato, Peinan Zhang</li>
<li>for: 本研究旨在提高自动广告文本生成（ATG）领域的研究，并为其引入了一个重新定义的任务和一个标准评价 bencmark。</li>
<li>methods: 本研究使用了多种方法，包括使用不同类型的预训练语言模型和利用多Modal信息。</li>
<li>results: 研究者通过多个基线模型的评价实验，发现CA Multimodal Evaluation for Ad Text GeneRAtion（CAMERA）数据集能够充分利用多Modal信息，并且可以进行产业综合评价。<details>
<summary>Abstract</summary>
In response to the limitations of manual online ad production, significant research has been conducted in the field of automatic ad text generation (ATG). However, comparing different methods has been challenging because of the lack of benchmarks encompassing the entire field and the absence of well-defined problem sets with clear model inputs and outputs. To address these challenges, this paper aims to advance the field of ATG by introducing a redesigned task and constructing a benchmark. Specifically, we defined ATG as a cross-application task encompassing various aspects of the Internet advertising. As part of our contribution, we propose a first benchmark dataset, CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA), carefully designed for ATG to be able to leverage multi-modal information and conduct an industry-wise evaluation. Furthermore, we demonstrate the usefulness of our proposed benchmark through evaluation experiments using multiple baseline models, which vary in terms of the type of pre-trained language model used and the incorporation of multi-modal information. We also discuss the current state of the task and the future challenges.
</details>
<details>
<summary>摘要</summary>
Traditional online advertising production has limitations, so researchers have been studying automatic ad text generation (ATG) to address these limitations. However, comparing different ATG methods has been difficult due to a lack of benchmarks that cover the entire field and well-defined problem sets with clear inputs and outputs. To solve these problems, this paper aims to advance the field of ATG by introducing a new task and creating a benchmark. Specifically, we define ATG as a cross-application task that includes various aspects of internet advertising. As part of our contribution, we propose a benchmark dataset called CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA), which is carefully designed for ATG and can leverage multi-modal information to conduct an industry-wide evaluation. We also demonstrate the usefulness of our proposed benchmark through evaluation experiments using multiple baseline models, which differ in the type of pre-trained language model used and the incorporation of multi-modal information. Finally, we discuss the current state of the task and future challenges.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Stock-Market-Sentiment-Classification-and-Backtesting-via-Fine-tuned-BERT"><a href="#Stock-Market-Sentiment-Classification-and-Backtesting-via-Fine-tuned-BERT" class="headerlink" title="Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT"></a>Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11979">http://arxiv.org/abs/2309.11979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiashu Lou</li>
<li>for: 本研究的目的是将情感因素纳入量化交易中，以提高交易效率和回换率。</li>
<li>methods: 本研究使用BERT自然语言处理模型进行训练，并将用户评论标题数据网络爬虫，进行数据清洁和处理。</li>
<li>results: 实验结果显示，将情感因素纳入量化交易中，可以提高交易效率和回换率，比基准模型和原始Alpha191模型有73.8%和32.41%的提升。<details>
<summary>Abstract</summary>
With the rapid development of big data and computing devices, low-latency automatic trading platforms based on real-time information acquisition have become the main components of the stock trading market, so the topic of quantitative trading has received widespread attention. And for non-strongly efficient trading markets, human emotions and expectations always dominate market trends and trading decisions. Therefore, this paper starts from the theory of emotion, taking East Money as an example, crawling user comment titles data from its corresponding stock bar and performing data cleaning. Subsequently, a natural language processing model BERT was constructed, and the BERT model was fine-tuned using existing annotated data sets. The experimental results show that the fine-tuned model has different degrees of performance improvement compared to the original model and the baseline model. Subsequently, based on the above model, the user comment data crawled is labeled with emotional polarity, and the obtained label information is combined with the Alpha191 model to participate in regression, and significant regression results are obtained. Subsequently, the regression model is used to predict the average price change for the next five days, and use it as a signal to guide automatic trading. The experimental results show that the incorporation of emotional factors increased the return rate by 73.8\% compared to the baseline during the trading period, and by 32.41\% compared to the original alpha191 model. Finally, we discuss the advantages and disadvantages of incorporating emotional factors into quantitative trading, and give possible directions for further research in the future.
</details>
<details>
<summary>摘要</summary>
随着大数据和计算设备的快速发展，低延迟自动交易平台基于实时信息获取已成为股票交易市场的主要组成部分，因此量化交易的话题受到了广泛关注。而在不强效交易市场中，人类情感和期望总是控制市场趋势和交易决策。因此，本文从情感理论出发，以东方财富为例，从其相应股票板幕中提取用户评论标题数据，并进行数据清洁。然后，构建了自然语言处理模型BERT，并将BERT模型细化使用现有注解数据集。实验结果显示，细化模型在原始模型和基准模型的比较中具有不同程度的性能改进。接着，基于上述模型，提取的用户评论数据被标注为情感方向，并将获得的标签信息与Alpha191模型结合进行回归，并获得了显著的回归结果。然后，使用回归模型预测下一五天的均价变化，并使其作为自动交易的信号导航。实验结果显示，包含情感因素的integration提高了基准期望的回报率73.8%，相比基准期望模型。最后，我们讨论了在量化交易中包含情感因素的优势和缺点，并提出了未来可能的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Scaling-up-COMETKIWI-Unbabel-IST-2023-Submission-for-the-Quality-Estimation-Shared-Task"><a href="#Scaling-up-COMETKIWI-Unbabel-IST-2023-Submission-for-the-Quality-Estimation-Shared-Task" class="headerlink" title="Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task"></a>Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11925">http://arxiv.org/abs/2309.11925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Rei, Nuno M. Guerreiro, José Pombal, Daan van Stigt, Marcos Treviso, Luisa Coheur, José G. C. de Souza, André F. T. Martins</li>
<li>for: 这个论文是为了参加WMT 2023共同任务中的质量估计（QE）任务而写的。</li>
<li>methods: 这个论文使用了COMETKIWI-22模型（Rei et al., 2022b），并在所有任务上进行了多语言方法的探索。</li>
<li>results: 这个论文的 multilingual 方法在所有任务上达到了状态的性能，并与人类评估相关度（Spearman 相关度）之间显示了大幅提升（最多10个Spearman点），同时也超过了第二名的多语言提交。<details>
<summary>Abstract</summary>
We present the joint contribution of Unbabel and Instituto Superior T\'ecnico to the WMT 2023 Shared Task on Quality Estimation (QE). Our team participated on all tasks: sentence- and word-level quality prediction (task 1) and fine-grained error span detection (task 2). For all tasks, we build on the COMETKIWI-22 model (Rei et al., 2022b). Our multilingual approaches are ranked first for all tasks, reaching state-of-the-art performance for quality estimation at word-, span- and sentence-level granularity. Compared to the previous state-of-the-art COMETKIWI-22, we show large improvements in correlation with human judgements (up to 10 Spearman points). Moreover, we surpass the second-best multilingual submission to the shared-task with up to 3.8 absolute points.
</details>
<details>
<summary>摘要</summary>
我们现在报告我们和 Instituto Superior Técnico 在 WMT 2023 共同任务中的合作贡献，我们参加了所有任务：句子和单词水平质量预测（任务 1）以及细致错误探测（任务 2）。对于所有任务，我们基于 COMETKIWI-22 模型（Rei et al., 2022b）。我们的多语言方法在所有任务上排名第一，达到了质量预测的州际先进性，包括单词、句子和span级别的准确性。相比之前的州际先进 COMETKIWI-22，我们显示出了大幅提升与人类评估的相关度（最高达 10 点）。此外，我们超过了共同任务中的第二名多语言提交，差异达到 3.8 个绝对点。
</details></li>
</ul>
<hr>
<h2 id="InstructERC-Reforming-Emotion-Recognition-in-Conversation-with-a-Retrieval-Multi-task-LLMs-Framework"><a href="#InstructERC-Reforming-Emotion-Recognition-in-Conversation-with-a-Retrieval-Multi-task-LLMs-Framework" class="headerlink" title="InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework"></a>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11911">http://arxiv.org/abs/2309.11911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LIN-SHANG/InstructERC">https://github.com/LIN-SHANG/InstructERC</a></li>
<li>paper_authors: Shanglin Lei, Guanting Dong, Xiaoping Wang, Keheng Wang, Sirui Wang</li>
<li>for: 提高对话中情感识别（ERC）的发展，解决了过度适应特定数据集和对话模式的问题。</li>
<li>methods: 提出了一种新的approach，即InstructERC，将ERC任务从推断性框架转换到生成性框架，基于大语言模型（LLM）。</li>
<li>results: InstructERC在三个常用的ERC数据集上 achieve 独特的SOTA，并通过 parameter-efficient 和 data-scaling 实验提供了实践场景中的参考指南。<details>
<summary>Abstract</summary>
The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely   InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based plug-and-play plugin framework significantly outperforms all previous models and achieves comprehensive SOTA on three commonly used ERC datasets. Extensive analysis of parameter-efficient and data-scaling experiments provide empirical guidance for applying InstructERC in practical scenarios. Our code will be released after blind review.
</details>
<details>
<summary>摘要</summary>
developoment of emotion recognition in dialogue (ERC) 被复杂的管道设计所阻碍，导致 ERC 模型经常过拟合特定的数据集和对话模式。在本研究中，我们提出了一种新的方法，即 InstructERC，它将 ERC 任务从描述性框架转换为生成框架，基于大型语言模型（LLM）。InstructERC 具有两个重要贡献：首先，InstructERC 引入了一种简单 yet 有效的检索模板模块，该模块通过 concatenate 历史对话内容、标签声明和情感领域示例来显式地整合多级别对话监督信息。其次，我们引入了两个附加的情感对应任务，即说话人标识和情感预测任务，以impllicitly 模型对话角色关系和未来情感趋势在对话中。我们的 LLM 基于插件框架在三个常用的 ERC 数据集上达到了广泛的 SOTA 水平。我们进行了参数高效和数据扩展的实验，以提供实践场景中应用 InstructERC 的实际指南。我们的代码将在审稿后发布。
</details></li>
</ul>
<hr>
<h2 id="Focal-Inferential-Infusion-Coupled-with-Tractable-Density-Discrimination-for-Implicit-Hate-Speech-Detection"><a href="#Focal-Inferential-Infusion-Coupled-with-Tractable-Density-Discrimination-for-Implicit-Hate-Speech-Detection" class="headerlink" title="Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection"></a>Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11896">http://arxiv.org/abs/2309.11896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lcs2-iiitd/fiadd">https://github.com/lcs2-iiitd/fiadd</a></li>
<li>paper_authors: Sarah Masud, Ashutosh Bajpai, Tanmoy Chakraborty</li>
<li>for: 本研究旨在提高预训练大语言模型（PLM）对含有潜在仇恨语言表达的文本识别的能力，特别是对于含有潜在仇恨语言表达的含义不明确的文本。</li>
<li>methods: 本研究提出了一种新的Focus Inferential Adaptive Density Discrimination（FiADD）框架，将PLMfinetuning管道中的表达更加接近含义的形式，同时提高不同类别之间的间距。</li>
<li>results: 对于三个隐式仇恨语料集，FiADD可以在二元和三元 hate classification任务中获得显著改进，并在掌握含义不明确的三个其他任务中也获得了类似的改进。<details>
<summary>Abstract</summary>
Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in which surface and implied forms differ, and observe similar performance improvement. We analyze the generated latent space to understand its evolution under FiADD, which corroborates the advantage of employing FiADD for implicit hate speech detection.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管预训练的大型自然语言模型（PLM）已经达到了许多NLP任务的状态流行，但它们缺乏对媚扰性表达的理解。这种细微和潜在的媚扰通常会被误分类为非媚扰。各种尝试都在扩展外部上下文或者通过距离基于的度量来增强恶意内容的检测。我们将这两种方法结合并引入FiADD，一种新的集中推理适应性权威度分区框架。FiADD通过将表面形式的潜在媚扰语言更近于其暗示形式，同时提高不同类别间的间距，以提高PLM的训练pipeline。我们在三个潜在媚扰数据集上测试FiADD，并观察到了两个和三个 hate类别分类任务中的显著改进。我们进一步在三个其他任务上进行了测试，即检测嘲笑、讽刺和立场，这些任务中表面和暗示形式不同，并观察到了类似的改进。我们分析生成的潜在空间，以理解FiADD在媚扰语言检测中的优势。
</details></li>
</ul>
<hr>
<h2 id="Is-It-Really-Useful-to-Jointly-Parse-Constituency-and-Dependency-Trees-A-Revisit"><a href="#Is-It-Really-Useful-to-Jointly-Parse-Constituency-and-Dependency-Trees-A-Revisit" class="headerlink" title="Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit"></a>Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11888">http://arxiv.org/abs/2309.11888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanggang Gu, Yang Hou, Zhefeng Wang, Xinyu Duan, Zhenghua Li</li>
<li>for: 这paper是为了同时解析成分树和依赖树而写的，以便更好地表示句子的语法结构。</li>
<li>methods: 这paper使用了一种更高效的解码算法，以及在训练阶段进行共同模型化，以及提出了高阶分数组件来捕捉成分-依赖关系。</li>
<li>results:  compared to previous works, this paper makes progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, (3) proposing high-order scoring components for constituent-dependency interaction, and (4) gaining more insights via in-depth experiments and analysis.<details>
<summary>Abstract</summary>
This work visits the topic of jointly parsing constituency and dependency trees, i.e., to produce compatible constituency and dependency trees simultaneously for input sentences, which is attractive considering that the two types of trees are complementary in representing syntax. Compared with previous works, we make progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, instead of only at the inference phase, (3) proposing high-order scoring components for constituent-dependency interaction, (4) gaining more insights via in-depth experiments and analysis.
</details>
<details>
<summary>摘要</summary>
这个工作探讨了同时解析成分树和依赖树的问题，即为输入句子生成兼容的成分树和依赖树，这是很吸引人的，因为这两种树是 syntax 表示的补充。与前一些工作相比，我们在四个方面做出了进步：1. 采用了非常高效的解码算法，2. 在训练阶段进行同时模型化，而不是只在推断阶段，3. 提出了高阶分数组件来描述成分-依赖关系，4. 通过深入实验和分析获得了更多的发现。
</details></li>
</ul>
<hr>
<h2 id="Syntactic-Variation-Across-the-Grammar-Modelling-a-Complex-Adaptive-System"><a href="#Syntactic-Variation-Across-the-Grammar-Modelling-a-Complex-Adaptive-System" class="headerlink" title="Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System"></a>Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11869">http://arxiv.org/abs/2309.11869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Dunn</li>
<li>for: 这个论文的目的是研究语言是一个复杂的自适应系统，并评估现有的语言研究方法是否能够准确地捕捉语言的复杂性。</li>
<li>methods: 这篇论文使用了系统地模型了英语口语的地方方言变化，并使用了整个语法和各个语法节点的隔离来描述这些变化。</li>
<li>results: 研究结果表明，语法中的各个节点之间存在许多交互，这些交互对于语言变化的理解具有重要意义。此外，研究还发现，在不同的语法节点被考察时，不同的地方方言之间的相似性会有所不同。<details>
<summary>Abstract</summary>
While language is a complex adaptive system, most work on syntactic variation observes a few individual constructions in isolation from the rest of the grammar. This means that the grammar, a network which connects thousands of structures at different levels of abstraction, is reduced to a few disconnected variables. This paper quantifies the impact of such reductions by systematically modelling dialectal variation across 49 local populations of English speakers in 16 countries. We perform dialect classification with both an entire grammar as well as with isolated nodes within the grammar in order to characterize the syntactic differences between these dialects. The results show, first, that many individual nodes within the grammar are subject to variation but, in isolation, none perform as well as the grammar as a whole. This indicates that an important part of syntactic variation consists of interactions between different parts of the grammar. Second, the results show that the similarity between dialects depends heavily on the sub-set of the grammar being observed: for example, New Zealand English could be more similar to Australian English in phrasal verbs but at the same time more similar to UK English in dative phrases.
</details>
<details>
<summary>摘要</summary>
语言是一个复杂的适应系统，大多数语法变化研究通常只关注几个个体构造，即使这些构造在语法 grammar 中处于不同层次的抽象水平之间。这意味着语法，一个连接千个结构的网络，被减少为几个分离的变量。这篇论文使用系统地模型了英语Speakers的地方方言变化，以Characterize这些方言之间的语法差异。我们使用整个语法和语法中各个节点进行地域分类，以Quantify这些变化的影响。结果显示，首先，语法中的多个节点都受到了变化，但是孤立地没有任何节点能够与整个语法一起表现得更好。这表明，语法变化中的一部分是不同部分之间的交互。其次，结果显示，不同地区的方言之间的相似性取决于观察到的语法子集：例如，新西兰英语可能与澳大利亚英语在短语动词方面更相似，而与英国英语在指示语raspects更相似。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Sanitization-of-Large-Language-Models"><a href="#Knowledge-Sanitization-of-Large-Language-Models" class="headerlink" title="Knowledge Sanitization of Large Language Models"></a>Knowledge Sanitization of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11852">http://arxiv.org/abs/2309.11852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yoichi Ishibashi, Hidetoshi Shimodaira</li>
<li>for: 防止语言模型泄露敏感信息</li>
<li>methods: 细化模型，让其生成无害回答</li>
<li>results: successfully mitigated knowledge leakage and preserved overall performance of LLM<details>
<summary>Abstract</summary>
We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique fine-tunes these models, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLM. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations.
</details>
<details>
<summary>摘要</summary>
我们研究了一种知识净化方法，以减轻大语言模型（LLM）中存在的隐私问题。这些模型通过大量网络数据训练，可能会记忆和泄露敏感或 конфиденциаль信息，这会引起严重的安全问题。我们的技术是通过精细地调整这些模型，使其在特定信息 queries 时返回无害的回答，如“我不知道”。我们的实验结果表明，我们的简单方法不仅可以减少特定知识泄露，还可以保持 LL 的总性能。这两点优点共同强化了对抽取攻击的防御，并减少了负面内容的泄露，如幻想。
</details></li>
</ul>
<hr>
<h2 id="A-Discourse-level-Multi-scale-Prosodic-Model-for-Fine-grained-Emotion-Analysis"><a href="#A-Discourse-level-Multi-scale-Prosodic-Model-for-Fine-grained-Emotion-Analysis" class="headerlink" title="A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis"></a>A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11849">http://arxiv.org/abs/2309.11849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xianhao Wei, Jia Jia, Xiang Li, Zhiyong Wu, Ziyi Wang</li>
<li>for: 这个研究旨在预测基于文本层次的细致情感特征，以提高语音合成模型的表达性。</li>
<li>methods: 我们使用一种style transfer模型提取phoneme-level Local Prosody Embedding序列和全局风格嵌入，并提出一种多层次文本Prosodic模型（D-MPM）来利用这些特征。</li>
<li>results: 我们的模型可以更好地预测情感特征，并且在用户评价指标上表现更好 than style transfer模型。<details>
<summary>Abstract</summary>
This paper explores predicting suitable prosodic features for fine-grained emotion analysis from the discourse-level text. To obtain fine-grained emotional prosodic features as predictive values for our model, we extract a phoneme-level Local Prosody Embedding sequence (LPEs) and a Global Style Embedding as prosodic speech features from the speech with the help of a style transfer model. We propose a Discourse-level Multi-scale text Prosodic Model (D-MPM) that exploits multi-scale text to predict these two prosodic features. The proposed model can be used to analyze better emotional prosodic features and thus guide the speech synthesis model to synthesize more expressive speech. To quantitatively evaluate the proposed model, we contribute a new and large-scale Discourse-level Chinese Audiobook (DCA) dataset with more than 13,000 utterances annotated sequences to evaluate the proposed model. Experimental results on the DCA dataset show that the multi-scale text information effectively helps to predict prosodic features, and the discourse-level text improves both the overall coherence and the user experience. More interestingly, although we aim at the synthesis effect of the style transfer model, the synthesized speech by the proposed text prosodic analysis model is even better than the style transfer from the original speech in some user evaluation indicators.
</details>
<details>
<summary>摘要</summary>
To evaluate the proposed model, the authors contribute a new large-scale Discourse-level Chinese Audiobook (DCA) dataset with over 13,000 annotated utterances. Experimental results show that the multi-scale text information effectively predicts prosodic features, and the discourse-level text improves coherence and user experience. Surprisingly, the synthesized speech by the proposed text prosodic analysis model is even better than the style transfer from the original speech in some user evaluation indicators.
</details></li>
</ul>
<hr>
<h2 id="A-Chinese-Prompt-Attack-Dataset-for-LLMs-with-Evil-Content"><a href="#A-Chinese-Prompt-Attack-Dataset-for-LLMs-with-Evil-Content" class="headerlink" title="A Chinese Prompt Attack Dataset for LLMs with Evil Content"></a>A Chinese Prompt Attack Dataset for LLMs with Evil Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11830">http://arxiv.org/abs/2309.11830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengyuan Liu, Fubang Zhao, Lizhi Qing, Yangyang Kang, Changlong Sun, Kun Kuang, Fei Wu</li>
<li>for: 这篇论文主要针对大语言模型（LLMs）的危险攻击和防御问题。</li>
<li>methods: 论文使用了多种黑盒攻击方法，如提示攻击，以测试LLMs的安全性。</li>
<li>results: 试验结果显示，论文引入的中文提示集（CPAD）对 LLMs 有70%的攻击成功率，表明这些提示有效地攻击了 LLMs。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and analysed. We run several well-known Chinese LLMs on our dataset, and the results show that our prompts are significantly harmful to LLMs, with around 70% attack success rate. We will release CPAD to encourage further studies on prompt attack and defense.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在文本理解和生成方面具有重要优势。然而，LLM受到生成危险内容的风险，特别是在应用程序中使用时。现有许多黑盒子攻击方法，如提示攻击，可以改变LLM的行为，让LLM生成意外的答案，包含危险内容。研究人员对提示攻击和LLM防御具有浓厚的兴趣，但是没有公共可用的数据集来评估防御能力。在这篇论文中，我们介绍了一个中文提示攻击数据集（CPAD），用于测试LLM的防御能力。我们的提示包括了三个维度：内容、攻击方法和目标，因此可以轻松地评估和分析回快。我们运行了一些知名的中文LLM在我们的数据集上，结果显示，我们的提示对LLM具有70%攻击成功率。我们将CPAD发布，以便更多的研究人员可以进行提示攻击和防御的研究。
</details></li>
</ul>
<hr>
<h2 id="Word-Embedding-with-Neural-Probabilistic-Prior"><a href="#Word-Embedding-with-Neural-Probabilistic-Prior" class="headerlink" title="Word Embedding with Neural Probabilistic Prior"></a>Word Embedding with Neural Probabilistic Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11824">http://arxiv.org/abs/2309.11824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaogang Ren, Dingcheng Li, Ping Li</li>
<li>for: 提高单词表示学习的词 embedding 模型</li>
<li>methods: 提出了一种可以与单词 embedding 模型集成的 probabilistic prior，使得词 embedding 可以作为概率生成模型来进行规范化。</li>
<li>results: 对多种任务进行了广泛的实验，并显示了提高单词表示的效果。<details>
<summary>Abstract</summary>
To improve word representation learning, we propose a probabilistic prior which can be seamlessly integrated with word embedding models. Different from previous methods, word embedding is taken as a probabilistic generative model, and it enables us to impose a prior regularizing word representation learning. The proposed prior not only enhances the representation of embedding vectors but also improves the model's robustness and stability. The structure of the proposed prior is simple and effective, and it can be easily implemented and flexibly plugged in most existing word embedding models. Extensive experiments show the proposed method improves word representation on various tasks.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "word representation" is translated as "字符表示" (zhì chào biǎo yì)* "probabilistic prior" is translated as "概率先验" (guè shí jiān yì)* "word embedding" is translated as "字符嵌入" (zhì chào fù rù)* "extensive experiments" is translated as "广泛实验" (guǎn fāng shí yan)
</details></li>
</ul>
<hr>
<h2 id="SLHCat-Mapping-Wikipedia-Categories-and-Lists-to-DBpedia-by-Leveraging-Semantic-Lexical-and-Hierarchical-Features"><a href="#SLHCat-Mapping-Wikipedia-Categories-and-Lists-to-DBpedia-by-Leveraging-Semantic-Lexical-and-Hierarchical-Features" class="headerlink" title="SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features"></a>SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11791">http://arxiv.org/abs/2309.11791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyi Wang, Zhenyang Zhang, Jiaxin Qin, Mizuho Iwaihara</li>
<li>for: 解决 CaLiGraph 生成的不完整和粗糙的映射问题，实现一个大规模的知识图库。</li>
<li>methods: 使用ontologyAlignment的方法，利用知识图的结构信息和ontology类名的语言和SemanticSimilarities来发现可信的映射。</li>
<li>results: 比基eline模型准确率高25%，提供一种实际的大规模ontology映射解决方案。<details>
<summary>Abstract</summary>
Wikipedia articles are hierarchically organized through categories and lists, providing one of the most comprehensive and universal taxonomy, but its open creation is causing redundancies and inconsistencies. Assigning DBPedia classes to Wikipedia categories and lists can alleviate the problem, realizing a large knowledge graph which is essential for categorizing digital contents through entity linking and typing. However, the existing approach of CaLiGraph is producing incomplete and non-fine grained mappings. In this paper, we tackle the problem as ontology alignment, where structural information of knowledge graphs and lexical and semantic features of ontology class names are utilized to discover confident mappings, which are in turn utilized for finetuing pretrained language models in a distant supervision fashion. Our method SLHCat consists of two main parts: 1) Automatically generating training data by leveraging knowledge graph structure, semantic similarities, and named entity typing. 2) Finetuning and prompt-tuning of the pre-trained language model BERT are carried out over the training data, to capture semantic and syntactic properties of class names. Our model SLHCat is evaluated over a benchmark dataset constructed by annotating 3000 fine-grained CaLiGraph-DBpedia mapping pairs. SLHCat is outperforming the baseline model by a large margin of 25% in accuracy, offering a practical solution for large-scale ontology mapping.
</details>
<details>
<summary>摘要</summary>
Wikipedia文章通过分类和列表归类，提供了一个最完整和通用的分类体系，但是开放创建导致重复和不一致。将DBPedia类划分到Wikipedia分类和列表中可以解决这个问题，实现大量知识图的构建，这是对数字内容进行分类和类型的关键。然而，现有的CaLiGraph方法产生了不完整和粗糙的映射。在这篇论文中，我们视为ontology对齐，利用知识图结构、语义和命名实体类型的信息，以确定可靠的映射，然后利用远程监督的方式来训练预训练的语言模型。我们的方法SLHCat包括两个主要部分：1. 利用知识图结构、语义相似度和命名实体类型自动生成训练数据。2. 使用训练数据进行远程监督方式来训练和提前训练预训练的语言模型BERT，以捕捉类名的语义和 sintaxis性质。我们的模型SLHCat在一个建立的基准数据集上进行评估，与基eline模型相比，SLHCat的准确率高出25%，提供了一个实用的大规模 Ontology mapping 解决方案。
</details></li>
</ul>
<hr>
<h2 id="ContextRef-Evaluating-Referenceless-Metrics-For-Image-Description-Generation"><a href="#ContextRef-Evaluating-Referenceless-Metrics-For-Image-Description-Generation" class="headerlink" title="ContextRef: Evaluating Referenceless Metrics For Image Description Generation"></a>ContextRef: Evaluating Referenceless Metrics For Image Description Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11710">http://arxiv.org/abs/2309.11710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elisakreiss/contextref">https://github.com/elisakreiss/contextref</a></li>
<li>paper_authors: Elisa Kreiss, Eric Zelikman, Christopher Potts, Nick Haber</li>
<li>for: 本研究用于评估无参考度量测试方法，以便更快地进行进步。</li>
<li>methods: 本研究使用预训练的视觉语言模型来评估图文描述，并提出了 ContextRef  benchmark，用于评估这些方法的对人类喜好性的Alignment。</li>
<li>results: 研究发现，无论使用哪种预训练模型或者 scoring functions，都无法通过 ContextRef 测试。但是，通过精心微调，可以获得显著改进。 ContextRef  remain 一个挑战性的 bencmark，主要归因于图文描述的上下文依赖。<details>
<summary>Abstract</summary>
Referenceless metrics (e.g., CLIPScore) use pretrained vision--language models to assess image descriptions directly without costly ground-truth reference texts. Such methods can facilitate rapid progress, but only if they truly align with human preference judgments. In this paper, we introduce ContextRef, a benchmark for assessing referenceless metrics for such alignment. ContextRef has two components: human ratings along a variety of established quality dimensions, and ten diverse robustness checks designed to uncover fundamental weaknesses. A crucial aspect of ContextRef is that images and descriptions are presented in context, reflecting prior work showing that context is important for description quality. Using ContextRef, we assess a variety of pretrained models, scoring functions, and techniques for incorporating context. None of the methods is successful with ContextRef, but we show that careful fine-tuning yields substantial improvements. ContextRef remains a challenging benchmark though, in large part due to the challenge of context dependence.
</details>
<details>
<summary>摘要</summary>
无参准度量器（例如CLIPScore）使用预训练视语模型直接评估图文描述，而不需要昂贵的参照文本。这些方法可以促进快速进步，但只有如果它们与人类偏好判断相一致。在这篇论文中，我们介绍ContextRef，一个用于评估无参准度量器的benchmark。ContextRef有两个组成部分：人类评分多种已知质量维度，以及十种多样化的Robustness Check，旨在揭示基本弱点。ContextRef中图文的展示是在Context中进行的，这与先前的研究表明，Context对描述质量具有重要作用。使用ContextRef，我们评估了多种预训练模型、分数函数和Context的integiration方法。结果显示，None of the methods是ContextRef中成功的，但我们展示了精细微调可以实现显著改进。ContextRef仍然是一个挑战性的benchmark，主要是因为Context的依赖性。
</details></li>
</ul>
<hr>
<h2 id="Memory-Augmented-LLM-Personalization-with-Short-and-Long-Term-Memory-Coordination"><a href="#Memory-Augmented-LLM-Personalization-with-Short-and-Long-Term-Memory-Coordination" class="headerlink" title="Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination"></a>Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11696">http://arxiv.org/abs/2309.11696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Zhang, Fubang Zhao, Yangyang Kang, Xiaozhong Liu</li>
<li>for: 提高用户特定的自然语言生成结果（User-oriented natural language generation）</li>
<li>methods: 提出了一种新的计算机力学记忆机制，并采用参数效率的精度调整方案进行个性化（Parameter-efficient fine-tuning schema）</li>
<li>results: 实验结果表明提案的方法有效并且超越传统方法（Extensive experimental results demonstrate the effectiveness and superiority of the proposed approach）<details>
<summary>Abstract</summary>
Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable proficiency in comprehending and generating natural language. However, their unpersonalized generation paradigm may result in suboptimal user-specific outcomes. Typically, users converse differently based on their knowledge and preferences. This necessitates the task of enhancing user-oriented LLM which remains unexplored. While one can fully train an LLM for this objective, the resource consumption is unaffordable. Prior research has explored memory-based methods to store and retrieve knowledge to enhance generation without retraining for new queries. However, we contend that a mere memory module is inadequate to comprehend a user's preference, and fully training an LLM can be excessively costly. In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach. To encourage further research into this area, we are releasing a new conversation dataset generated entirely by LLM based on an open-source medical corpus, as well as our implementation code.
</details>
<details>
<summary>摘要</summary>
In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach. To encourage further research in this area, we are releasing a new conversation dataset generated entirely by LLM based on an open-source medical corpus, as well as our implementation code.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.CL_2023_09_21/" data-id="clnsn0veo008xgf889p1z28nk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/21/cs.AI_2023_09_21/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-09-21
        
      </div>
    </a>
  
  
    <a href="/2023/09/21/cs.LG_2023_09_21/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-09-21</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">78</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">35</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">78</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">22</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">150</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
