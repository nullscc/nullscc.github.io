
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-09-21 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.12312 repo_url: https:&#x2F;&#x2F;github.com&#x2F;AlenoWar&#x2F;For-friends1231231230-23092 paper_authors: Jeremy A">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-09-21">
<meta property="og:url" content="https://nullscc.github.io/2023/09/21/cs.AI_2023_09_21/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.12312 repo_url: https:&#x2F;&#x2F;github.com&#x2F;AlenoWar&#x2F;For-friends1231231230-23092 paper_authors: Jeremy A">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-21T12:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T12:35:28.951Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.AI_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T12:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-09-21
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ForceSight-Text-Guided-Mobile-Manipulation-with-Visual-Force-Goals"><a href="#ForceSight-Text-Guided-Mobile-Manipulation-with-Visual-Force-Goals" class="headerlink" title="ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals"></a>ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12312">http://arxiv.org/abs/2309.12312</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AlenoWar/For-friends1231231230-23092">https://github.com/AlenoWar/For-friends1231231230-23092</a></li>
<li>paper_authors: Jeremy A. Collins, Cody Houff, You Liang Tan, Charles C. Kemp</li>
<li>for: 本文描述了一种基于深度学习的文本导引移动抓取系统，可以预测视觉力目标和相应的力目标。</li>
<li>methods: 该系统使用深度神经网络，根据单个RGBD图像和文本提示，确定目标减动器姿态和相应的力目标。</li>
<li>results: 在一个实验中，该系统在不同物体实例和未看过的环境中完成了精准抓取、抽屉打开和物体传递等任务，成功率为81%。在另一个实验中，仅通过视觉服务器而忽略力目标时，成功率降低至45%，这表明力目标可以显著提高性能。<details>
<summary>Abstract</summary>
We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network. Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal). Together, these two components form a visual-force goal. Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots. Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems. When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data. In a separate experiment, relying exclusively on visual servoing and ignoring force goals dropped the success rate from 90% to 45%, demonstrating that force goals can significantly enhance performance. The appendix, videos, code, and trained models are available at https://force-sight.github.io/.
</details>
<details>
<summary>摘要</summary>
我们现在提出了 ForceSight，一种基于文本导引的移动操作系统，该系统使用深度神经网络预测视觉力目标。给定一个RGBD图像和文本提示，ForceSight可以确定摄像头帧中的目标器位（动力目标）以及相关的力（力目标）。这两个组成部分共同形成了视觉力目标。在先前的研究中，使用深度模型输出人类可解释的动力目标可以实现灵活的操作。然而，在这些系统中，力通常被视为低级别执行。当部署在搭载了眼在手RGBD相机的移动操作器时，ForceSight在不同环境中完成了精度抓取、抽屉打开和物品传递等任务，成功率达81%。在另一个实验中，完全依赖于视觉服务并忽略力目标，成功率从90%下降到45%，这表明力目标可以明显提高性能。详细信息、视频、代码和训练模型可以在<https://force-sight.github.io/>上获取。
</details></li>
</ul>
<hr>
<h2 id="LLM-Grounder-Open-Vocabulary-3D-Visual-Grounding-with-Large-Language-Model-as-an-Agent"><a href="#LLM-Grounder-Open-Vocabulary-3D-Visual-Grounding-with-Large-Language-Model-as-an-Agent" class="headerlink" title="LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent"></a>LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12311">http://arxiv.org/abs/2309.12311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianing Yang, Xuweiyi Chen, Shengyi Qian, Nikhil Madaan, Madhavan Iyengar, David F. Fouhey, Joyce Chai</li>
<li>for: 提高家用机器人的3D视觉固定率，使其能够基于环境进行导航、对象搜索和回答问题。</li>
<li>methods: 提出了一种基于大语言模型（LLM）的开放词汇、零shot的3D视觉固定率管道，使用LLM将自然语言查询分解成 semantic constituents，并使用视觉固定工具（如OpenScene或LERF）来确定3D场景中的对象。</li>
<li>results: 在ScanRefer benchmark上进行评估，显示了与状态艺术的零shot固定率表现，尤其是对于复杂的自然语言查询。<details>
<summary>Abstract</summary>
3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment. While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene. The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision. Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy. Our findings indicate that LLMs significantly improve the grounding capability, especially for complex language queries, making LLM-Grounder an effective approach for 3D vision-language tasks in robotics. Videos and interactive demos can be found on the project website https://chat-with-nerf.github.io/ .
</details>
<details>
<summary>摘要</summary>
三维视觉固定是家庭机器人的关键技能，它允许机器人在环境中导航、操作物品以及回答问题。现有的方法通常需要大量标注数据或者具有处理复杂语言查询的限制，而我们提出了LLM-Grounder，一种新的零批量、开 vocabulary 的大语言模型（LLM）基于的三维视觉固定管道。LLM-Grounder 使用 LLM 将复杂的自然语言查询分解成 semantic constituents，然后使用三维场景识别工具，如 OpenScene 或 LERF，确定场景中的物体。LLM 然后评估场景中提议的物体之间的空间和通用感知关系，以确定最终的固定决策。我们的方法不需要任何标注训练数据，可以泛化到新的三维场景和任意文本查询。我们在 ScanRefer benchmark 上进行了评估，并示出了零批量固定精度。我们的发现表明，LLM 可以大幅提高固定能力，特别是对复杂语言查询，使LLM-Grounder 成为三维视觉语言任务中的有效方法。视频和互动示例可以在项目网站 https://chat-with-nerf.github.io/ 找到。
</details></li>
</ul>
<hr>
<h2 id="Rehearsal-Simulating-Conflict-to-Teach-Conflict-Resolution"><a href="#Rehearsal-Simulating-Conflict-to-Teach-Conflict-Resolution" class="headerlink" title="Rehearsal: Simulating Conflict to Teach Conflict Resolution"></a>Rehearsal: Simulating Conflict to Teach Conflict Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12309">http://arxiv.org/abs/2309.12309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Shaikh, Valentino Chai, Michele J. Gelfand, Diyi Yang, Michael S. Bernstein</li>
<li>for: 提高冲突管理技能</li>
<li>methods: 使用 simulate 人工智能对话者进行冲突练习，探索不同的对话路径，并通过Feedback学习冲突解决策略。</li>
<li>results: 在比对组与控制组之间进行实验后，参与者们通过使用 Rehearsal 增强了冲突管理技能，减少了竞争策略的使用率，同时 doubling 合作策略的使用率。<details>
<summary>Abstract</summary>
Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.
</details>
<details>
<summary>摘要</summary>
人际冲突是生活中不可避免的一个不舒适的事实。成功 navigating 冲突是一种技能 -- 可以通过意识的练习学习 -- 但是很少人有效的训练和反馈。为了扩大这种训练的access，我们介绍了 Rehearsal，一个系统，允许用户通过与生动的 simulate 对话者进行模拟冲突，探索不同的对话路径，并通过反馈学习冲突策略。用户可以使用 Rehearsal 练习各种预先定义的冲突场景，从办公室争议到关系问题，或者他们可以创建自己的。为了实现 Rehearsal，我们开发了 IRP 提示，一种基于冲突解决理论中的有力 Interest-Rights-Power（IRP）的方法，用于生成与冲突解决相关的语言模型输出。Rehearsal 使用 IRP 生成对话，引导用户采用不同的对话策略，以帮助他们在困难的对话中减少竞争策略的使用，同时增加合作策略的使用。在一个 between-subjects 评估中，40名参与者在与假对手进行实际冲突后接受了 simulated 训练。与控制组（ receives 同 IRP 理论的讲解材料）相比，参与者通过 Rehearsal 的模拟训练显著改善了他们在无助的冲突中的表现，减少了竞争策略的使用量by 67%，同时 doubling 合作策略的使用。总之，Rehearsal highlights 语言模型的潜在效果iveness 作为人际技能学习和练习的工具。
</details></li>
</ul>
<hr>
<h2 id="LongLoRA-Efficient-Fine-tuning-of-Long-Context-Large-Language-Models"><a href="#LongLoRA-Efficient-Fine-tuning-of-Long-Context-Large-Language-Models" class="headerlink" title="LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"></a>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12307">http://arxiv.org/abs/2309.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dvlab-research/longlora">https://github.com/dvlab-research/longlora</a></li>
<li>paper_authors: Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song Han, Jiaya Jia</li>
<li>for: 这 paper 是为了提高大型语言模型（LLM）的上下文大小，并且减少计算成本。</li>
<li>methods: 这 paper 使用了两种方法来减少计算成本：1) 使用稀疏的局部注意力进行微调，而不是 dense 的全球注意力；2) 修改 LoRA 的参数fficient fine-tuning 策略，以便在训练时使用更小的上下文大小。</li>
<li>results: 这 paper 在多个任务上都显示了优秀的 empirical  результаhat,包括使用 LLaMA2 模型从 7B&#x2F;13B 到 70B，并在单个 8x A100 机器上完成了Context 的扩展。<details>
<summary>Abstract</summary>
We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA demonstrates strong empirical results on various tasks on LLaMA2 models from 7B/13B to 70B. LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like FlashAttention-2. In addition, to make LongLoRA practical, we collect a dataset, LongQA, for supervised fine-tuning. It contains more than 3k long context question-answer pairs.
</details>
<details>
<summary>摘要</summary>
我们介绍了LongLoRA，一种高效的微调方法，可以将预训练的大型自然语言模型（LLM）的上下文大小扩展，而不需要很多计算成本。通常，在训练LLMs时，使用长context大小需要大量的计算时间和GPU资源。例如，在context长度为8192时，自我注意层的计算成本将增加16倍。在这篇论文中，我们提高了LLM的上下文扩展的计算效率，从两个方面进行了优化。一方面，虽然在推理时需要 dense global attention，但是在微调过程中可以使用笔 sparse local attention，从而提高计算效率。我们提出了shift short attention技术，可以快速扩展上下文，同时保持与原始模型的性能相似。另一方面，我们再次检视了参数效率微调环境，发现LoRA在trainable embedding和normalization的前提下，可以很好地扩展上下文。LongLoRA在多个任务上获得了强的实际结果，使用LLaMA2模型从7B/13B到70B。LongLoRA可以在单个8x A100机器上从4k context扩展到100k，或者从70B扩展到32k。LongLoRA可以保持原始模型的结构，与大多数现有技术兼容，如FlashAttention-2。此外，为使LongLoRA实用，我们收集了一个超过3k长context问答对的数据集，名为LongQA。
</details></li>
</ul>
<hr>
<h2 id="Environment-biased-Feature-Ranking-for-Novelty-Detection-Robustness"><a href="#Environment-biased-Feature-Ranking-for-Novelty-Detection-Robustness" class="headerlink" title="Environment-biased Feature Ranking for Novelty Detection Robustness"></a>Environment-biased Feature Ranking for Novelty Detection Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12301">http://arxiv.org/abs/2309.12301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Smeu, Elena Burceanu, Emanuela Haller, Andrei Liviu Nicolicioiu</li>
<li>for: 本研究的目的是robust novelty detection，即检测 semantic content 中的新鲜事物，并在不同环境下保持检测的稳定性。</li>
<li>methods: 本研究使用了一种基于预训练 embedding 和多环境设置的方法，可以 rank 特征按照其环境吸引力。首先，我们计算了每个特征的分布方差变化强度，然后选择高分的特征进行去除，以消除干扰关系并提高总性能。</li>
<li>results: 我们的方法可以在 covariance 和 sub-population shift 两种情况下提高检测性能，在两个实际和 sintetic benchmark 中实现了6%的提高。<details>
<summary>Abstract</summary>
We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task.
</details>
<details>
<summary>摘要</summary>
我们面临着一个robust新鲜度检测问题，我们想检测新鲜度从 semantics 角度来，而不受其他无关因素的变化影响。特别是，我们在多个环境中运行，并确定了与环境相关的特征，而不是与任务相关的内容。因此，我们提出了一种方法，它从预训练 embedding 和多环境设置开始，然后对特征进行排名，以便根据环境注重。首先，我们计算每个特征的分布方差变化分数，以确定它们在不同环境中的分布情况。接着，我们证明了，通过抛弃高分的特征，可以消除干扰关系，并提高总表现，达到6%的提升，包括covariance和sub-population shift两种情况。这种提升可以在真实和 sintetic  benchmark 中实现。
</details></li>
</ul>
<hr>
<h2 id="See-to-Touch-Learning-Tactile-Dexterity-through-Visual-Incentives"><a href="#See-to-Touch-Learning-Tactile-Dexterity-through-Visual-Incentives" class="headerlink" title="See to Touch: Learning Tactile Dexterity through Visual Incentives"></a>See to Touch: Learning Tactile Dexterity through Visual Incentives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12300">http://arxiv.org/abs/2309.12300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Irmak Guzey, Yinlong Dai, Ben Evans, Soumith Chintala, Lerrel Pinto</li>
<li>for: 提高多指 robot 的灵活搔挠能力，使其能够具备人类的灵活搔挠能力。</li>
<li>methods: 使用视觉奖励来优化气肺动作策略，并通过对人类示范的对比来学习视觉表示。</li>
<li>results: 在六个复杂任务中，TAVI 实现了 73% 的成功率，比使用气肺动作和视觉奖励的策略高出 108%，比没有气肺 observational 输入的策略高出 135%。<details>
<summary>Abstract</summary>
Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: https://see-to-touch.github.io/.
</details>
<details>
<summary>摘要</summary>
Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: <https://see-to-touch.github.io/>.Here's the translation in Traditional Chinese:Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: <https://see-to-touch.github.io/>.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Drive-Anywhere"><a href="#Learning-to-Drive-Anywhere" class="headerlink" title="Learning to Drive Anywhere"></a>Learning to Drive Anywhere</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12295">http://arxiv.org/abs/2309.12295</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Ruizhao Zhu, Peng Huang, Eshed Ohn-Bar, Venkatesh Saligrama</li>
<li>for: 本研究旨在提出一种能够快速适应不同地区和交通规则的自动驾驶模型，以满足现代自动驾驶系统的需求。</li>
<li>methods: 该模型使用了条件学习和地理位置信息来适应不同地区的驾驶行为，并通过对照学习对象来快速学习和适应不同的驾驶情况。</li>
<li>results: 研究表明，该模型可以在多个数据集、城市和部署方式下表现出色，比如中央化、半supervised和分布式 Agent 训练方式，并且在 CARLA 上测试中比基eline 高出14%。<details>
<summary>Abstract</summary>
Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic. In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability. In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics. Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner. By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and location-dependent events. We demonstrate the benefits of our AnyD agent across multiple datasets, cities, and scalable deployment paradigms, i.e., centralized, semi-supervised, and distributed agent training. Specifically, AnyD outperforms CIL baselines by over 14% in open-loop evaluation and 30% in closed-loop testing on CARLA.
</details>
<details>
<summary>摘要</summary>
人类驾驶员可以无缝地适应不同地区的条件和道路规则，如左右手交通。然而，现有的自动驾驶模型只能在限定的运行Domain中进行部署，无法考虑不同地区的驾驶行为或模型扩展性。在这种工作中，我们提出AnyD，一种能够快速学习从多元化和全球分布的数据中的 conditional imitation learning（CIL）模型。我们的关键发现是引入高容量的地理位置基于的通道注意力机制，可以有效地适应当地特性，同时也可以数据驱动地模型同地区之间的相似性。通过优化一个对比式学习目标函数，我们的提出的方法可以高效地扩展到自然具有偏斜分布的数据集和地点事件。我们在多个数据集、城市和扩展模型训练方法（中央、半supervised、分布式代理训练）上展示了AnyD代理的优势， Specifically, AnyD比CIL基eline高出14%在开loop评估中和30%在closed-loop测试中。
</details></li>
</ul>
<hr>
<h2 id="The-Reversal-Curse-LLMs-trained-on-“A-is-B”-fail-to-learn-“B-is-A”"><a href="#The-Reversal-Curse-LLMs-trained-on-“A-is-B”-fail-to-learn-“B-is-A”" class="headerlink" title="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"></a>The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12288">http://arxiv.org/abs/2309.12288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lukasberglund/reversal_curse">https://github.com/lukasberglund/reversal_curse</a></li>
<li>paper_authors: Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans</li>
<li>for: 这个论文旨在描述一种语言模型具有的惊人的总结不良现象，即模型在句子的逆向方向上不能自动总结。</li>
<li>methods: 这个论文使用了自动推导大语言模型（LLM）的训练和细化来探讨这种现象。</li>
<li>results: 研究发现，即使模型在句子中具有”A是B”的Pattern，它们也不能自动总结”B是A”的句子。这表明模型存在一种基本的逻辑推理失败，并且不能总结句子中的普遍规律。<details>
<summary>Abstract</summary>
We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as "Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]" and the reverse "Who is Mary Lee Pfeiffer's son?". GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse. Code is available at https://github.com/lukasberglund/reversal_curse.
</details>
<details>
<summary>摘要</summary>
我们揭示了普遍性不足的抽象问题在自动进行语言模型（LLM）中。如果一个模型在“A是B”的句子上训练，那么它不会自动推导到“B是A”的方向。这被称为“推倒祸咒”。例如，如果一个模型在“奥拉夫·舒兹是德国第九任总理”上训练，那么它不会自动回答“谁是德国第九任总理？”的问题。此外，对于正确答案（奥拉夫·舒兹）的概率不高于随机名称。因此，模型表现出基本的逻辑推理失败，不能推导出训练集中 prevailing pattern（即“A是B”发生时，“B是A”更 probable）。我们通过在虚假句子上精细调整GPT-3和Llama-1模型，并证明它们在“Uriah Hawthorne是《abyssal Melodies》的作曲家”这类句子上失败，不能正确回答“abyssal Melodies”的作曲家是谁。推倒祸咒是模型大小和家族的robust，不受数据增强的影响。我们还测试了ChatGPT（GPT-3.5和GPT-4）在关于真实名人的问题上，如“谁是汤米·克鲁塞的妈妈？”和其反向“谁是mary Lee Pfeiffer的儿子？”。GPT-4在前者79%的时间内正确回答问题，比后者33%的时间更高。这显示了逻辑推理的失败，我们假设是由推倒祸咒引起的。代码可以在https://github.com/lukasberglund/reversal_curse上找到。
</details></li>
</ul>
<hr>
<h2 id="MetaMath-Bootstrap-Your-Own-Mathematical-Questions-for-Large-Language-Models"><a href="#MetaMath-Bootstrap-Your-Own-Mathematical-Questions-for-Large-Language-Models" class="headerlink" title="MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"></a>MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12284">http://arxiv.org/abs/2309.12284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu<br>for:这篇论文的目的是提高大型自然语言模型（LLM）在数学领域的理解能力，以解决问题时需要进行复杂的推理过程。methods:论文使用了自然语言生成技术，将数学问题重新写成多种角度，从而创建了一个新的数学问题集合（MetaMathQA），并对LLaMA-2模型进行微调。results:实验结果显示，MetaMath模型在两个流行的数学理解测试 benchmark（GSM8K和MATH）上表现出色，较前一代模型高出11.5%和8.7%。特别是，MetaMath-7B模型在GSM8K上得分66.4%，MATH上得分19.4%。<details>
<summary>Abstract</summary>
Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by $11.5\%$ and $8.7\%$. Particularly, {MetaMath-70B} achieves an accuracy of $82.3\%$ on {GSM8K}, slightly better than {GPT-3.5-Turbo}. We release the {MetaMathQA} dataset, the {MetaMath} models with different model sizes and the training code for public use.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）已经推动了自然语言理解的限制，并表现出了优秀的问题解决能力。 despite the great success, most existing open-source LLMs (eg, LLaMA-2) are still far from satisfactory for solving mathematical problems due to complex reasoning procedures. To bridge this gap, we propose 《MetaMath》, a fine-tuned language model specializing in mathematical reasoning. Specifically, we start by rewriting mathematical questions from multiple perspectives without extra knowledge, resulting in a new dataset called {MetaMathQA}. Then, we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (ie, GSM8K and MATH) for mathematical reasoning show that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves 66.4% on GSM8K and 19.4% on MATH, exceeding the state-of-the-art models of the same size by 11.5% and 8.7%. Particularly, our MetaMath-70B model achieves an accuracy of 82.3% on GSM8K, slightly better than GPT-3.5-Turbo. We release the MetaMathQA dataset, the MetaMath models with different model sizes, and the training code for public use.
</details></li>
</ul>
<hr>
<h2 id="LLMR-Real-time-Prompting-of-Interactive-Worlds-using-Large-Language-Models"><a href="#LLMR-Real-time-Prompting-of-Interactive-Worlds-using-Large-Language-Models" class="headerlink" title="LLMR: Real-time Prompting of Interactive Worlds using Large Language Models"></a>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12276">http://arxiv.org/abs/2309.12276</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asem010/legend-pice">https://github.com/asem010/legend-pice</a></li>
<li>paper_authors: Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier</li>
<li>for: 这个论文是为了描述一种基于大自然语言模型（LLM）的混合现实创作和修改框架，用于实时创建和修改互动型混合现实经验。</li>
<li>methods: 该框架使用了一些新的策略来解决缺乏理想训练数据或需要 sintheziser internal dynamics、intuitive analysis 和高级互动性的情况。它使用文本交互和 Unity 游戏引擎，并包括Scene Understanding、Task Planning、Self-Debugging 和 Memory Management 等技术。</li>
<li>results: 与标准 GPT-4 相比，LLMR 的平均错误率下降至 4 倍。作者们在多个示例世界中证明了 LLMR 的跨平台兼容性，并通过许多创建和修改任务来表明它可以生成和编辑多样化的对象、工具和场景。最后，作者们进行了一项用户研究（N&#x3D;11），发现参与者们对系统有积极的经验，并表示会再次使用它。<details>
<summary>Abstract</summary>
We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
</details>
<details>
<summary>摘要</summary>
我团队推出了混合现实语言大型模型框架（LLMR），用于在实时创建和修改混合现实体验的实时创作和修改。 LLMR 采用了新的策略来解决缺乏理想训练数据或设计目标需要内在动力、直观分析或高级互动的情况。 我们的框架基于文本交互和 Unity 游戏引擎，并包括场景理解、任务规划、自我调试和内存管理等技术。 相比标准 GPT-4，LLMR 的平均错误率下降了4倍。 我们示例了 LLMR 的跨平台兼容性，并对多种创建和修改任务进行了评估，以示其能够生成和修改多样化的对象、工具和场景。 最后，我们进行了一项用户研究（N=11），发现参与者们有积极的体验，并表示他们会再次使用这系统。
</details></li>
</ul>
<hr>
<h2 id="Enabling-Quartile-based-Estimated-Mean-Gradient-Aggregation-As-Baseline-for-Federated-Image-Classifications"><a href="#Enabling-Quartile-based-Estimated-Mean-Gradient-Aggregation-As-Baseline-for-Federated-Image-Classifications" class="headerlink" title="Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications"></a>Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12267">http://arxiv.org/abs/2309.12267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusen Wu, Jamie Deng, Hao Chen, Phuong Nguyen, Yelena Yesha</li>
<li>for: 本研究旨在提出一种名为Estimated Mean Aggregation（EMA）的创新解决方案，用于解决 Federated Learning（FL）系统中数据多样性和安全性问题。</li>
<li>methods: EMA使用trimmed means来有效地处理恶意外异值，同时揭示数据不同性，以确保训练的模型在各客户端数据上具备适应性。</li>
<li>results: EMA在一系列实验中表现出高准确率和地下曲线Area Under the Curve（AUC），相比其他方法，EMA成为FL集成方法评估效果和安全性的基本参考点。EMA的贡献因此为FL系统的效率、安全性和多样性带来了重要的进步。<details>
<summary>Abstract</summary>
Federated Learning (FL) has revolutionized how we train deep neural networks by enabling decentralized collaboration while safeguarding sensitive data and improving model performance. However, FL faces two crucial challenges: the diverse nature of data held by individual clients and the vulnerability of the FL system to security breaches. This paper introduces an innovative solution named Estimated Mean Aggregation (EMA) that not only addresses these challenges but also provides a fundamental reference point as a $\mathsf{baseline}$ for advanced aggregation techniques in FL systems. EMA's significance lies in its dual role: enhancing model security by effectively handling malicious outliers through trimmed means and uncovering data heterogeneity to ensure that trained models are adaptable across various client datasets. Through a wealth of experiments, EMA consistently demonstrates high accuracy and area under the curve (AUC) compared to alternative methods, establishing itself as a robust baseline for evaluating the effectiveness and security of FL aggregation methods. EMA's contributions thus offer a crucial step forward in advancing the efficiency, security, and versatility of decentralized deep learning in the context of FL.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）已经革命化了深度神经网络的训练方式，使得各个客户端的数据可以共同合作，同时保护敏感数据和提高模型性能。然而，FL还面临两个重要挑战：客户端数据的多样性和FL系统的安全性。这篇文章提出了一个创新的解决方案，即估算平均联合（EMA），这个方法不仅能够有效地处理邪恶的偏出现，同时也能够探索数据的多样性，以确保训练出来的模型能够适应不同的客户端数据。通过丰富的实验，EMA证明了它在精确率和投影面积（AUC）方面的优秀性，并成为FL联合方法的基本底线，这让EMA在评估FL联合方法的效iveness和安全性方面提供了一个重要的引用点。EMA的贡献因此为FL技术的效率、安全性和多样性带来了一个重要的进步。
</details></li>
</ul>
<hr>
<h2 id="SALSA-CLRS-A-Sparse-and-Scalable-Benchmark-for-Algorithmic-Reasoning"><a href="#SALSA-CLRS-A-Sparse-and-Scalable-Benchmark-for-Algorithmic-Reasoning" class="headerlink" title="SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning"></a>SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12253">http://arxiv.org/abs/2309.12253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jkminder/salsa-clrs">https://github.com/jkminder/salsa-clrs</a></li>
<li>paper_authors: Julian Minder, Florian Grötschla, Joël Mathys, Roger Wattenhofer</li>
<li>for: 本文提出了一个扩展版的CLRS算法学习benchmark，强调可扩展性和使用稀疏表示。</li>
<li>methods: 本文使用了适应算法从原CLRSbenchmark中，以及新增的分布式和随机算法。</li>
<li>results: 本文进行了广泛的实验评估。<details>
<summary>Abstract</summary>
We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations. Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem. Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale). However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks. Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind. Our approach includes adapted algorithms from the original CLRS benchmark and introduces new problems from distributed and randomized algorithms. Moreover, we perform a thorough empirical evaluation of our benchmark. Code is publicly available at https://github.com/jkminder/SALSA-CLRS.
</details>
<details>
<summary>摘要</summary>
我们介绍一个对CLRS算法学习标准的扩展，强调可扩展性和使用稀疏表示。许多CLRS中的算法需要全球内存或资讯交换，这反映在它的执行模型中，它会建立全连接（不稀疏）图基于下面问题。尽管CLRS的目的是评估学习算法如何对更大的实例进行扩展，但现有的执行模型对于内存需求和时间成本（Difficult to scale）具有显著的限制。然而，许多重要的算法不需要全连接图，这些算法通常是分布式的，与Graph Neural Networks中的讯息传递模式相似。因此，我们提出了SALSA-CLRS，一个CLRS标准的扩展，专注于可扩展性和稀疏性。我们的方法包括原CLRS标准中的修改算法和新问题，并对我们的标准进行了详细的实验评估。代码可以在https://github.com/jkminder/SALSA-CLRS上下载。
</details></li>
</ul>
<hr>
<h2 id="Bad-Actor-Good-Advisor-Exploring-the-Role-of-Large-Language-Models-in-Fake-News-Detection"><a href="#Bad-Actor-Good-Advisor-Exploring-the-Role-of-Large-Language-Models-in-Fake-News-Detection" class="headerlink" title="Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection"></a>Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12247">http://arxiv.org/abs/2309.12247</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ictmcg/arg">https://github.com/ictmcg/arg</a></li>
<li>paper_authors: Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, Peng Qi<br>for: 这篇论文主要研究了大语言模型（LLMs）在假新闻检测方面的潜力。methods: 作者采用了一种名为 adaptive rationale guidance network（ARG）的网络，该网络使用了精心调整的小语言模型（SLMs）和大语言模型（LLMs）来检测假新闻。results: 实验结果显示，作者的方法可以在两个实际数据集上超过三种基eline方法，包括SLM-based、LLM-based和这两种模型的组合。<details>
<summary>Abstract</summary>
Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models.
</details>
<details>
<summary>摘要</summary>
检测假新闻需要一种细腻的多种迹象推理和深刻的现实背景理解，这些检测器基于小语言模型（SLM）的知识和能力限制使得它们的表现还有限。然而，大语言模型（LLM）的最近进步在多种任务中表现出色，但是LLM是否可以帮助检测假新闻仍然未得到充分探索。本文 investigate LLM在假新闻检测中的潜力。我们首先进行实验研究，发现一个成熟的LLM如GPT 3.5可以暴露假新闻并提供愉悦多元理由，但是仍然落后于精通BERT的基本SLM。我们 subsequnt分析发现这种差距是因为LLM无法正确地选择和 инте格 rationales来结论。根据这些发现，我们提出了LLM不能完全取代精通SLM，但可以作为SLM的好助手，提供多元指导性的理由。为实现这一提议，我们设计了一个适应性 rationales 指导网络（ARG），其中SLM可以选择性地从LLM的理由中获得分析新闻的 instruciton。此外，我们还 derivation 一个不需要 rationales 的ARG-D版本，通过浸泡来实现cost-sensitive场景中的服务。我们在两个实际数据集上进行实验，发现ARG和ARG-D都高于三种基eline方法，包括SLM、LLM和小语言模型和大语言模型的组合。
</details></li>
</ul>
<hr>
<h2 id="ChaCha-Leveraging-Large-Language-Models-to-Prompt-Children-to-Share-Their-Emotions-about-Personal-Events"><a href="#ChaCha-Leveraging-Large-Language-Models-to-Prompt-Children-to-Share-Their-Emotions-about-Personal-Events" class="headerlink" title="ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events"></a>ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12244">http://arxiv.org/abs/2309.12244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Woosuk Seo, Chanmo Yang, Young-Ho Kim</li>
<li>for: 本研究旨在开发一个名为ChaCha的谈话机器人，以便儿童通过分享自己的故事和感受来学习表达情感。</li>
<li>methods: 这个研究使用了状态机和大语言模型（LLMs），以保持对话在轨道，同时允许儿童自由发展对话。</li>
<li>results: 经过对20名儿童（年龄在8-12岁）的exploratory研究发现，儿童认为ChaCha是一个亲密的朋友，并将个人故事和感受分享给ChaCha。研究发现，使用LLMs可以设计出适合儿童的谈话机器人，以支持儿童在表达情感方面。<details>
<summary>Abstract</summary>
Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to support children in sharing their emotions.
</details>
<details>
<summary>摘要</summary>
孩子通常通过与他们的家人分享故事和感受来学习识别和表达情感。然而，由于孩子的通信技能还在发展，因此与孩子进行情感交流可以是很困难的。我们提出了 ChaCha，一个聊天机器人，它鼓励和指导孩子分享个人事件和相关的情感。ChaCha结合状态机和大型自然语言模型（LLMs），以保持对话在轨而进行自由化对话。经过20名8-12岁的孩子参与的exploratory研究，我们发现ChaCha可以让孩子 perceive为一个亲密的朋友，并让他们分享各种话题，如家庭旅行和个人成就。根据量化和质化的结果，我们讨论了如何通过LLMs设计为孩子友好的聊天机器人，以支持孩子在表达情感方面。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Artificial-Intelligence-for-Drug-Discovery-and-Development-–-A-Comprehensive-Survey"><a href="#Explainable-Artificial-Intelligence-for-Drug-Discovery-and-Development-–-A-Comprehensive-Survey" class="headerlink" title="Explainable Artificial Intelligence for Drug Discovery and Development – A Comprehensive Survey"></a>Explainable Artificial Intelligence for Drug Discovery and Development – A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12177">http://arxiv.org/abs/2309.12177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roohallah Alizadehsani, Sadiq Hussain, Rene Ripardo Calixto, Victor Hugo C. de Albuquerque, Mohamad Roshanzamir, Mohamed Rahouti, Senthil Kumar Jagatheesaperumal<br>for:* 这篇评论文章旨在提供对XAI技术在药物发现领域的全面了解，以及XAI技术在药物发现中的应用和挑战。methods:* 这篇评论文章总结了目前XAI技术在药物发现领域的状态，包括各种XAI方法的应用和挑战，以及XAI技术在药物发现中的应用。results:* 这篇评论文章结合了XAI技术在药物发现中的应用，包括目标预测、化学物质设计和毒性预测等方面。同时，文章还提出了未来XAI技术在药物发现领域的可能性和挑战。<details>
<summary>Abstract</summary>
The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furthermore, the article suggests potential future research directions for the application of XAI in drug discovery. The aim of this review article is to provide a comprehensive understanding of the current state of XAI in drug discovery and its potential to transform the field.
</details>
<details>
<summary>摘要</summary>
随着人工智能（AI）和机器学习（ML）技术的出现，药物发现领域经历了极具挑战性的变革。然而，随着AI和ML模型的复杂化，需要对这些模型的透明度和可解释性的需求也在增加。解释人工智能（XAI）是一种新的方法，它能够提供更加可解释的机器学习模型预测结果的理解。在过去几年中，对药物发现领域应用XAI技术的兴趣不断增加。本文提供了药物发现领域XAI技术的现状报告，包括不同的XAI方法、其在药物发现中的应用、以及XAI技术在药物发现中的挑战和限制。此外，文章还概述了XAI在药物发现中的应用，包括目标识别、化合物设计和毒性预测。最后，文章还提出了未来对XAI在药物发现领域的研究发展的可能性。本文的目的是为读者提供药物发现领域XAI技术的全面了解，以及其在未来可能带来的变革。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Domain-Adaptation-for-Self-Driving-from-Past-Traversal-Features"><a href="#Unsupervised-Domain-Adaptation-for-Self-Driving-from-Past-Traversal-Features" class="headerlink" title="Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features"></a>Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12140">http://arxiv.org/abs/2309.12140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Travis Zhang, Katie Luo, Cheng Perng Phoo, Yurong You, Wei-Lun Chao, Bharath Hariharan, Mark Campbell, Kilian Q. Weinberger</li>
<li>for: 提高自动驾驶车辆中3D对象检测系统的准确性。</li>
<li>methods: 利用无标签重复游走多个位置来适应新的驾驶环境，并通过计算重复LiDAR扫描数据的统计来导航适应过程。</li>
<li>results: 提高了基于LiDAR的检测模型，使其更适应不同的驾驶环境，并在实际数据集上实现了up to 20点的性能提升，尤其是检测人行和远距离对象。Here’s the translation in English:</li>
<li>for: To improve the accuracy of 3D object detection systems for self-driving cars.</li>
<li>methods: Utilize unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments, and leverage statistics computed from repeated LiDAR scans to guide the adaptation process.</li>
<li>results: Enhance LiDAR-based detection models, making them more adaptable to different driving environments, and achieve up to 20-point performance gain, especially in detecting pedestrians and distant objects, on real-world datasets.<details>
<summary>Abstract</summary>
The rapid development of 3D object detection systems for self-driving cars has significantly improved accuracy. However, these systems struggle to generalize across diverse driving environments, which can lead to safety-critical failures in detecting traffic participants. To address this, we propose a method that utilizes unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments. By incorporating statistics computed from repeated LiDAR scans, we guide the adaptation process effectively. Our approach enhances LiDAR-based detection models using spatial quantized historical features and introduces a lightweight regression head to leverage the statistics for feature regularization. Additionally, we leverage the statistics for a novel self-training process to stabilize the training. The framework is detector model-agnostic and experiments on real-world datasets demonstrate significant improvements, achieving up to a 20-point performance gain, especially in detecting pedestrians and distant objects. Code is available at https://github.com/zhangtravis/Hist-DA.
</details>
<details>
<summary>摘要</summary>
“自驾车3D对象检测系统的快速发展已经显著提高了准确性。然而，这些系统在不同的驾驶环境下难以泛化，这可能会导致检测交通参与者的失败。为解决这个问题，我们提出了一种方法，它利用多个位置的重复旋转进行不标注的多次旋转，以适应新的驾驶环境。我们通过计算重复扫描 LiDAR 的统计数据，有效地导向适应过程。我们的方法可以增强基于 LiDAR 的检测模型，并引入空间量化历史特征来减少特征训练。此外，我们还利用统计数据进行一种新的自动训练过程，以稳定训练。这个框架是检测模型无关的，实验表明，在真实世界 datasets 上，我们的方法可以获得大约 20 个表现指标的提高，特别是检测人行和远距离对象。代码可以在 https://github.com/zhangtravis/Hist-DA 上获取。”Note: The translation is in Simplified Chinese, which is the standard Chinese writing system used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="On-the-relationship-between-Benchmarking-Standards-and-Certification-in-Robotics-and-AI"><a href="#On-the-relationship-between-Benchmarking-Standards-and-Certification-in-Robotics-and-AI" class="headerlink" title="On the relationship between Benchmarking, Standards and Certification in Robotics and AI"></a>On the relationship between Benchmarking, Standards and Certification in Robotics and AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12139">http://arxiv.org/abs/2309.12139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alan F. T. Winfield, Matthew Studley</li>
<li>for: 本文旨在探讨标准、认证和测试 benchmarking 的关系，并 argue 这三个过程是负责任创新的重要组成部分。</li>
<li>methods: 本文使用例子从标准、认证和测试 benchmarking 等领域，探讨这些过程如何相互关联，并为负责任创新提供指导。</li>
<li>results: 本文 argue 通过标准、认证和测试 benchmarking 等过程，可以帮助确保机器人和人工智能系统的负责任创新。<details>
<summary>Abstract</summary>
Benchmarking, standards and certification are closely related processes. Standards can provide normative requirements that robotics and AI systems may or may not conform to. Certification generally relies upon conformance with one or more standards as the key determinant of granting a certificate to operate. And benchmarks are sets of standardised tests against which robots and AI systems can be measured. Benchmarks therefore can be thought of as informal standards. In this paper we will develop these themes with examples from benchmarking, standards and certification, and argue that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation.
</details>
<details>
<summary>摘要</summary>
标准、认证和测试是密切相关的过程。标准可以提供规范要求，机器人和人工智能系统可能或可能不遵循。认证通常基于一个或多个标准来决定授予操作证书。而测试是使用标准化的测试方法来评估机器人和人工智能系统的性能。因此，测试可以被视为非正式的标准。在这篇论文中，我们将通过实例来发展这些主题，并 argue that这三个连接过程不仅是有用的，而且是责任创新的必要条件。
</details></li>
</ul>
<hr>
<h2 id="OSN-MDAD-Machine-Translation-Dataset-for-Arabic-Multi-Dialectal-Conversations-on-Online-Social-Media"><a href="#OSN-MDAD-Machine-Translation-Dataset-for-Arabic-Multi-Dialectal-Conversations-on-Online-Social-Media" class="headerlink" title="OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media"></a>OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12137">http://arxiv.org/abs/2309.12137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatimah Alzamzami, Abdulmotaleb El Saddik</li>
<li>for: 这个论文主要是为了解决阿拉伯语言的社交媒体翻译问题。</li>
<li>methods: 这篇论文使用的方法是基于上述提出的内容翻译指南，通过对英语推文进行上下文翻译，生成四种阿拉伯语方言的转化。</li>
<li>results: 根据作者的实验结果，使用这些方法可以实现高效的阿拉伯语方言翻译。<details>
<summary>Abstract</summary>
While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. While few attempts have been made to build translation datasets for dialectal Arabic, they are domain dependent and are not OSN cultural-language friendly. In this work, we attempt to alleviate these limitations by proposing an online social network-based multidialect Arabic dataset that is crafted by contextually translating English tweets into four Arabic dialects: Gulf, Yemeni, Iraqi, and Levantine. To perform the translation, we followed our proposed guideline framework for content translation, which could be universally applicable for translation between foreign languages and local dialects. We validated the authenticity of our proposed dataset by developing neural MT models for four Arabic dialects. Our results have shown a superior performance of our NMT models trained using our dataset. We believe that our dataset can reliably serve as an Arabic multidialectal translation dataset for informal MT tasks.
</details>
<details>
<summary>摘要</summary>
在英语社交媒体上，资源相对充足，但在阿拉伯语社交媒体上，资源仍然落后。主要原因是阿拉伯语有多种方言，使得社交媒体上的用户通常使用方言而不是标准版本（MSA）。阿拉伯人不使用MSA在日常交流中，而是使用方言版本。这种现象也影响了社交媒体平台上的使用，从而提高了为建立适用于语言依赖应用的AI模型的需求。现有的机器翻译（MT）系统设计 дляMSA无法正确地处理阿拉伯语方言。为此，需要适应社交媒体上的不正式交流方式，并开发MT系统可以有效地处理不同的阿拉伯语方言。与MSA的MT系统进步相比，对阿拉伯语方言的努力很少。尝试了为阿拉伯语方言建立翻译数据集，但这些数据集是域名相关的，并不适合社交媒体文化语言。在这种情况下，我们尝试缓解这些限制，并提出了一个在线社交媒体基础上创建的多方言阿拉伯语数据集。我们采用了我们提出的内部翻译指南，将英语推文翻译成四种阿拉伯语方言：古富、 йемен语、伊拉克语和levantine语。我们验证了我们提出的数据集的 Authenticity，并开发了四种阿拉伯语方言的神经翻译模型。我们的结果表明，我们的NMT模型在使用我们的数据集进行训练时表现出色。我们认为，我们的数据集可靠地作为阿拉伯语多方言翻译数据集来使用。
</details></li>
</ul>
<hr>
<h2 id="A-knowledge-representation-approach-for-construction-contract-knowledge-modeling"><a href="#A-knowledge-representation-approach-for-construction-contract-knowledge-modeling" class="headerlink" title="A knowledge representation approach for construction contract knowledge modeling"></a>A knowledge representation approach for construction contract knowledge modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12132">http://arxiv.org/abs/2309.12132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunmo Zheng, Saika Wong, Xing Su, Yinqiu Tang</li>
<li>for:  automatize construction contract management, reducing human errors and saving time and costs</li>
<li>methods:  uses a nested knowledge representation framework and LLM-assisted contract review pipeline</li>
<li>results:  achieves promising performance in contract risk reviewing, demonstrating the potential of combining LLM and KG for more reliable and interpretable contract management<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的出现提供了前所未有的自动化建筑合同管理机会，可以减少人类错误和成本。然而，LLM可能生成吸引人的 yet inaccurate和 misleading 内容，因为缺乏领域专业知识。为解决这个问题，我们可以将专家驱动的合同知识表示在结构化的方式下，以限制自动合同管理过程。本文介绍了嵌入式合同知识图（NCKG），一种知识表示方法，它使用嵌入结构来捕捉合同知识的复杂性。它包括嵌入结构框架、基于框架的 NCKG  Ontology 和实现方法。此外，我们还介绍了利用外部知识的 LLM 协助合同审核管道。我们的管道实现了合同风险审核中的优秀表现，推照在 LLM 和 KG 的结合下，可以实现更可靠和可解释的合同管理。
</details></li>
</ul>
<hr>
<h2 id="Incentivizing-Massive-Unknown-Workers-for-Budget-Limited-Crowdsensing-From-Off-Line-and-On-Line-Perspectives"><a href="#Incentivizing-Massive-Unknown-Workers-for-Budget-Limited-Crowdsensing-From-Off-Line-and-On-Line-Perspectives" class="headerlink" title="Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives"></a>Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12113">http://arxiv.org/abs/2309.12113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Li, Yuqi Chai, Huan Yang, Pengfei Hu, Lingjie Duan</li>
<li>For: 这个论文是为了解决在具有限制的预算下，面临大量未知工作者的 combinatorial multi-armed bandit (CMAB) 问题。* Methods: 该论文提出了一种基于奖励机制的 Context-Aware CMAB (CACI) 机制，通过在分区的上下文空间中进行exploration-exploitation 质量来办理奖励，以具有效地鼓励大量未知工作者。同时，该机制还在在线设置中进行了扩展，以适应工作者Join或离开系统的动态变化。* Results: 该论文通过理论分析和实验 validate 了其机制的正确性和个人合理性，并且在synthetic和实际数据集上进行了广泛的实验验证。<details>
<summary>Abstract</summary>
Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited. Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves. To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget. We also extend the above basic idea to the on-line setting where unknown workers may join in or depart from the systems dynamically, and propose an on-line version of the CACI mechanism. Specifically, by the exploitation-exploration trade-off in the context space, we learn to estimate the sensing ability of any unknown worker (even it never appeared in the system before) according to its context information. We perform rigorous theoretical analysis to reveal the upper bounds on the regrets of our CACI mechanisms and to prove their truthfulness and individual rationality, respectively. Extensive experiments on both synthetic and real datasets are also conducted to verify the efficacy of our mechanisms.
</details>
<details>
<summary>摘要</summary>
尽管工人的不确定性可以通过标准的Combinatorial Multi-Armed Bandit（CMAB）框架在现有的提议中Address，但我们可能没有足够的预算来实现这种贸易在各个工人之间，特别是当工人的数量很大而预算受限时。此外，标准的CMAB通常假设工人总是在系统中，而工人可能在系统中加入或离开，这意味着我们对个体工人所学的知识不能在它离开系统后应用。为解决这些挑战，在本文中，我们首先提出了OFF-LINE的Context-Aware CMAB-based Incentive（CACI）机制。我们创新地利用了在分割后的上下文空间中的exploration-exploitation贸易，以有效地鼓励大量的未知工人，并且具有很限制的预算。我们还将上述基本想法扩展到在线设置，在系统中动态加入或离开的未知工人上。 Specifically，通过在上下文空间中的利用-exploration贸易，我们可以根据 Context information来估算任何未知工人（即使它从未在系统中出现过）的感知能力。我们进行了严格的理论分析，以揭示我们CACI机制的误差的Upper bound，并证明它们的真实性和个人合理性，分别。我们还进行了大量的实验，以验证我们的机制的有效性。
</details></li>
</ul>
<hr>
<h2 id="PEFTT-Parameter-Efficient-Fine-Tuning-for-low-resource-Tibetan-pre-trained-language-models"><a href="#PEFTT-Parameter-Efficient-Fine-Tuning-for-low-resource-Tibetan-pre-trained-language-models" class="headerlink" title="PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models"></a>PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12109">http://arxiv.org/abs/2309.12109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhou Mingjun, Daiqing Zhuoma, Qun Nuo, Nyima Tashi</li>
<li>for: 这个研究的目的是为了提高 Tibetan NLP 领域中的模型训练效率，以便更好地应用于语言应用程序。</li>
<li>methods: 这个研究使用了三种有效的 fine-tuning 策略，即 “prompt-tuning”、”Adapter lightweight fine-tuning” 和 “prompt-tuning + Adapter fine-tuning”，以提高 Tibetan 语言模型的性能。</li>
<li>results: 实验结果表明，使用这三种 fine-tuning 策略可以在 TNCC-title 数据集上实现显著的改进，为 Tibetan 语言应用程序提供有价值的意义。<details>
<summary>Abstract</summary>
In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions. The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity. However, there has been very little exploration for various low-resource languages, such as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive. Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary. Our research can serve as a reference to fill this crucial gap. Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration. We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: "prompt-tuning," "Adapter lightweight fine-tuning," and "prompt-tuning + Adapter fine-tuning." The experimental results demonstrate significant improvements using these methods, providing valuable insights for advancing Tibetan language applications in the context of pre-trained models.
</details>
<details>
<summary>摘要</summary>
在这个大语言模型（LLM）时代，传统的模型训练已经变得越来越难以想象 для普通用户和机构。研究高资源语言模型的高效微调是一种逐渐受欢迎的趋势，但对低资源语言，如藏语，的研究几乎没有任何探索。因此，研究低资源语言模型的高效微调是非常必要的。在目前没有任何藏语大语言模型的情况下，我们的研究可以填补这一关键的空白。关于藏语自然语言处理（NLP）的研究是罕见和有限的。我们在公共可用的 TNCC-title 数据集上进行了三种高效微调实验："提示微调，" "Adapter 轻量级微调，" 和 "提示微调 + Adapter 微调。"实验结果显示了这些方法的显著改善，为 Tibetan 语言应用在预训练模型的上提供了价值的指导。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Thematic-Investment-with-Prompt-Tuned-Pretrained-Language-Models"><a href="#Accelerating-Thematic-Investment-with-Prompt-Tuned-Pretrained-Language-Models" class="headerlink" title="Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models"></a>Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12075">http://arxiv.org/abs/2309.12075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valentin Leonhard Buchner, Lele Cao, Jan-Christoph Kalo</li>
<li>for: 本研究使用Prompt Tuning方法进行实验，以解决多标签文本分类 задачі中的一些限制。</li>
<li>methods: 本研究使用Prompt Tuning和基eline方法进行比较，以测试它们在多标签文本分类 задачі中的性能和computational efficiency。</li>
<li>results: 研究结果显示，Prompt Tuning方法可以优化PLMs的性能和computational efficiency，并且可以解决多标签文本分类 задачі中的一些限制。<details>
<summary>Abstract</summary>
Prompt Tuning is emerging as a scalable and cost-effective method to fine-tune Pretrained Language Models (PLMs). This study benchmarks the performance and computational efficiency of Prompt Tuning and baseline methods on a multi-label text classification task. This is applied to the use case of classifying companies into an investment firm's proprietary industry taxonomy, supporting their thematic investment strategy. Text-to-text classification with PLMs is frequently reported to outperform classification with a classification head, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens: (a) Generated labels may not match any label in the industry taxonomy; (b) During fine-tuning, multiple labels must be provided in an arbitrary order; (c) The model provides a binary decision for each label, rather than an appropriate confidence score. Limitation (a) is addressed by applying constrained decoding using Trie Search, which slightly improves classification performance. All limitations (a), (b), and (c) are addressed by replacing the PLM's language head with a classification head. This improves performance significantly, while also reducing computational costs during inference. The results indicate the continuing need to adapt state-of-the-art methods to domain-specific tasks, even in the era of PLMs with strong generalization abilities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Benchmarking-quantized-LLaMa-based-models-on-the-Brazilian-Secondary-School-Exam"><a href="#Benchmarking-quantized-LLaMa-based-models-on-the-Brazilian-Secondary-School-Exam" class="headerlink" title="Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam"></a>Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12071">http://arxiv.org/abs/2309.12071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matheus L. O. Santos, Cláudio E. C. Campelo</li>
<li>for: 本研究旨在评估基于7和13亿LLaMA模型的大语言模型（LLMs）在家用硬件上的性能。</li>
<li>methods: 我们使用了一个包含1,006个问题的数据库，来评估这些模型的有效性。我们还测试了这些模型的计算效率，并记录了在一台配备AMD Ryzen 5 3600x处理器的机器上处理查询所需的时间。</li>
<li>results: 我们发现，最佳performing模型在原始葡萄牙语问题上的准确率约为46%，而在其英文翻译中的准确率约为49%。此外，我们发现7和13亿LLMs在这些查询中的计算效率相对较高，它们在一台机器上平均需要20和50秒时间来处理查询。<details>
<summary>Abstract</summary>
Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approximately 20 and 50 seconds, respectively, to process the queries on a machine equipped with an AMD Ryzen 5 3600x processor
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:尽管大型语言模型（LLMs）代表了计算机与人类之间交互的革命，允许建构复杂的问题并对语句进行推理，但它们的使用受到硬件限制。在这项研究中，我们评估了基于7和13亿LLaMA模型的LMMs，经过量化处理并在家用硬件上运行。我们考虑的模型包括Alpaca、Koala和Vicuna。为了评估这些模型的效果，我们创建了包含1,006个问题的ENEM（巴西国家高中考试）数据库。我们的分析表明，最佳表现的模型在原始葡萄牙语问题上达到了约46%的准确率，而在英语翻译中达到了约49%的准确率。此外，我们还评估了这些模型的计算效率，并测量了在一台配备AMD Ryzen 5 3600x处理器的机器上执行查询所需的时间。平均而言，7和13亿LLMs在20和50秒之间执行查询。
</details></li>
</ul>
<hr>
<h2 id="Survey-of-Action-Recognition-Spotting-and-Spatio-Temporal-Localization-in-Soccer-–-Current-Trends-and-Research-Perspectives"><a href="#Survey-of-Action-Recognition-Spotting-and-Spatio-Temporal-Localization-in-Soccer-–-Current-Trends-and-Research-Perspectives" class="headerlink" title="Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer – Current Trends and Research Perspectives"></a>Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer – Current Trends and Research Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12067">http://arxiv.org/abs/2309.12067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karolina Seweryn, Anna Wróblewska, Szymon Łukasik</li>
<li>for: 本文提供了足球动作识别领域的全面回顾，包括动作识别、位置识别和时空动作地址Localization，特别是modalities使用和多modal方法。</li>
<li>methods: 文章详细介绍了公共可用数据源和评价模型性能的度量，同时还探讨了最新的state-of-the-art方法，包括深度学习技术和传统方法。文章特别强调了多modal方法，这些方法将多个源信息 integrate into one model，如视频和音频数据。</li>
<li>results: 文章评论了不同方法的优势和局限性，以及它们在准确性和Robustness方面的潜在提升。最后，文章提出了一些未解决的问题和未来方向，包括多modal方法在足球动作识别领域的潜在推动作用。<details>
<summary>Abstract</summary>
Action scene understanding in soccer is a challenging task due to the complex and dynamic nature of the game, as well as the interactions between players. This article provides a comprehensive overview of this task divided into action recognition, spotting, and spatio-temporal action localization, with a particular emphasis on the modalities used and multimodal methods. We explore the publicly available data sources and metrics used to evaluate models' performance. The article reviews recent state-of-the-art methods that leverage deep learning techniques and traditional methods. We focus on multimodal methods, which integrate information from multiple sources, such as video and audio data, and also those that represent one source in various ways. The advantages and limitations of methods are discussed, along with their potential for improving the accuracy and robustness of models. Finally, the article highlights some of the open research questions and future directions in the field of soccer action recognition, including the potential for multimodal methods to advance this field. Overall, this survey provides a valuable resource for researchers interested in the field of action scene understanding in soccer.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chineseoccer场景理解是一项复杂和动态的任务，由于游戏中玩家之间的互动和多方面的关系。这篇文章提供了全面的概述，分为行为识别、识别和空间时间行为定位，强调modalities使用和多模态方法。我们探讨了公共可用数据源和评估模型性能的度量，并评论了最新的状态艺术方法，包括深度学习技术和传统方法。我们专注于多模态方法，这些方法将多个来源的信息集成，如视频和音频数据，以及表示一种来源的不同方式。我们讨论了方法的优势和局限性，以及它们在准确性和可靠性方面的潜在提高。最后，文章强调了在足球行为识别领域的一些未解决问题和未来方向，包括多模态方法的潜在推动该领域的前景。总之，这篇文章为研究者们关注足球场景理解领域提供了有价值的资源。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Consolidation-of-Word-Embedding-and-Deep-Learning-Techniques-for-Classifying-Anticancer-Peptides-FastText-BiLSTM"><a href="#An-Efficient-Consolidation-of-Word-Embedding-and-Deep-Learning-Techniques-for-Classifying-Anticancer-Peptides-FastText-BiLSTM" class="headerlink" title="An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM"></a>An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12058">http://arxiv.org/abs/2309.12058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onur Karakaya, Zeynep Hilal Kilimci</li>
<li>for: 预防和治疗癌症的抗癌肽（ACPs）</li>
<li>methods: 使用word embedding和深度学习模型进行抗癌肽分类</li>
<li>results: 提出了一种高精度的抗癌肽分类模型，在常用的数据集上达到了新的州OF-THE-ART水平，即ACPs250数据集的准确率为92.50%，独立数据集的准确率为96.15%。<details>
<summary>Abstract</summary>
Anticancer peptides (ACPs) are a group of peptides that exhibite antineoplastic properties. The utilization of ACPs in cancer prevention can present a viable substitute for conventional cancer therapeutics, as they possess a higher degree of selectivity and safety. Recent scientific advancements generate an interest in peptide-based therapies which offer the advantage of efficiently treating intended cells without negatively impacting normal cells. However, as the number of peptide sequences continues to increase rapidly, developing a reliable and precise prediction model becomes a challenging task. In this work, our motivation is to advance an efficient model for categorizing anticancer peptides employing the consolidation of word embedding and deep learning models. First, Word2Vec and FastText are evaluated as word embedding techniques for the purpose of extracting peptide sequences. Then, the output of word embedding models are fed into deep learning approaches CNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework, extensive experiments are carried on widely-used datasets in the literature, ACPs250 and Independent. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for ACPs250 dataset, and 96.15% of accuracy for Independent dataset, thence determining new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
安定肽（ACPs）是一组肽蛋白，具有抗肿瘤性能。使用ACPs在抗癌治疗中可能成为一种可靠的替代方案，因为它们具有更高的选择性和安全性。随着肽序列的数量在快速增长，开发一个可靠和精准的预测模型成为一项挑战。在这种情况下，我们的动机是提出一种高效的分类模型，使用词嵌入和深度学习模型。首先，我们评估了Word2Vec和FastText作为词嵌入技术，以提取肽序列。然后，Word2Vec和FastText模型的输出被 fed into深度学习模型CNN、LSTM、BiLSTM。为证明提案的贡献，我们在文献中常用的数据集上进行了广泛的实验。实验结果表明，我们的模型可以提高分类精度，比领先研究更高。具体来说，使用我们的模型，ACPS250数据集的准确率达92.50%，独立数据集的准确率达96.15%，从而确定新的顶峰。
</details></li>
</ul>
<hr>
<h2 id="BELT-Bootstrapping-Electroencephalography-to-Language-Decoding-and-Zero-Shot-Sentiment-Classification-by-Natural-Language-Supervision"><a href="#BELT-Bootstrapping-Electroencephalography-to-Language-Decoding-and-Zero-Shot-Sentiment-Classification-by-Natural-Language-Supervision" class="headerlink" title="BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision"></a>BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12056">http://arxiv.org/abs/2309.12056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinzhao Zhou, Yiqun Duan, Yu-Cheng Chang, Yu-Kai Wang, Chin-Teng Lin</li>
<li>for: 本研究旨在提出一种基于大规模预训练语言模型的脑语言翻译模型和学习框架（BELT），以解决脑信号解码或脑语言翻译中的限制性问题。</li>
<li>methods: 该模型由深度套件编码器和量化编码器组成，通过对比学习步骤提供自然语言监督，以实现semantic EEG表示。</li>
<li>results: 在两个特征性脑解码任务上，包括脑语言翻译和零扫ENT sentiment classification，OUR模型比基eline模型提高5.45%和over 10%，并在翻译任务上实现42.31% BLEU-1分数和67.32%精度。<details>
<summary>Abstract</summary>
This paper presents BELT, a novel model and learning framework for the pivotal topic of brain-to-language translation research. The translation from noninvasive brain signals into readable natural language has the potential to promote the application scenario as well as the development of brain-computer interfaces (BCI) as a whole. The critical problem in brain signal decoding or brain-to-language translation is the acquisition of semantically appropriate and discriminative EEG representation from a dataset of limited scale and quality. The proposed BELT method is a generic and efficient framework that bootstraps EEG representation learning using off-the-shelf large-scale pretrained language models (LMs). With a large LM's capacity for understanding semantic information and zero-shot generalization, BELT utilizes large LMs trained on Internet-scale datasets to bring significant improvements to the understanding of EEG signals.   In particular, the BELT model is composed of a deep conformer encoder and a vector quantization encoder. Semantical EEG representation is achieved by a contrastive learning step that provides natural language supervision. We achieve state-of-the-art results on two featuring brain decoding tasks including the brain-to-language translation and zero-shot sentiment classification. Specifically, our model surpasses the baseline model on both tasks by 5.45% and over 10% and archives a 42.31% BLEU-1 score and 67.32% precision on the main evaluation metrics for translation and zero-shot sentiment classification respectively.
</details>
<details>
<summary>摘要</summary>
To address this problem, the BELT method leverages off-the-shelf large-scale pretrained language models (LMs) to bootstrap EEG representation learning. With the large capacity of LMs for understanding semantic information and their ability to generalize to new situations, BELT can significantly improve the understanding of EEG signals.The BELT model consists of a deep conformer encoder and a vector quantization encoder. To achieve semantically meaningful EEG representations, a contrastive learning step is used to provide natural language supervision. The model is evaluated on two brain decoding tasks, brain-to-language translation and zero-shot sentiment classification, and achieves state-of-the-art results. Specifically, the model outperforms the baseline model by 5.45% and over 10% on both tasks, with a BLEU-1 score of 42.31% and precision of 67.32% for translation and zero-shot sentiment classification, respectively.
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-driven-Exploration-Strategies-for-Online-Grasp-Learning"><a href="#Uncertainty-driven-Exploration-Strategies-for-Online-Grasp-Learning" class="headerlink" title="Uncertainty-driven Exploration Strategies for Online Grasp Learning"></a>Uncertainty-driven Exploration Strategies for Online Grasp Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12038">http://arxiv.org/abs/2309.12038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitian Shi, Philipp Schillinger, Miroslav Gabriel, Alexander Kuss, Zohar Feldman, Hanna Ziesche, Ngo Anh Vien</li>
<li>for: 本研究旨在提出一种在线学习 grasp 预测方法，以适应 robotic bin picking 中新的抓取enario。</li>
<li>methods: 本方法基于 Reinforcement Learning 的online学习策略，并采用有效的探索策略来改善适应性。</li>
<li>results: 实验结果表明，提出的方法可以在实际的 bin picking 场景中具有显著的改善，并且比传统的在线学习方法具有更高的适应性。<details>
<summary>Abstract</summary>
Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Specifically, the online learning algorithm with an effective exploration strategy can significantly improve its adaptation performance to unseen environment settings. To this end, we first propose to formulate online grasp learning as a RL problem that will allow to adapt both grasp reward prediction and grasp poses. We propose various uncertainty estimation schemes based on Bayesian Uncertainty Quantification and Distributional Ensembles. We carry out evaluations on real-world bin picking scenes of varying difficulty. The objects in the bin have various challenging physical and perceptual characteristics that can be characterized by semi- or total transparency, and irregular or curved surfaces. The results of our experiments demonstrate a notable improvement in the suggested approach compared to conventional online learning methods which incorporate only naive exploration strategies.
</details>
<details>
<summary>摘要</summary>
现有的握取预测方法大多基于离线学习，而忽略了在线适应新抓取场景时的探索式握取学习。在这篇论文中，我们提出了一种新的在线学习握取预测方法，以解决这个问题。特别是，我们提出了一种有效的探索策略，可以显著提高在未经见的环境设置下的适应性。为此，我们首先将在线握取学习转化为一种RL问题，以适应握取奖励预测和握取姿态。我们还提出了多种不确定度估计方法，基于 bayesian不确定度量化和分布 ensemble。我们在实际的 bin picking 场景中进行了评估，结果显示，我们的方法在不同的难度水平下表现出了显著的改善。Here's a word-for-word translation of the text using Traditional Chinese characters:现有的握取预测方法大多基于离线学习，而忽略了在线适应新捕取场景时的探索式握取学习。在这篇论文中，我们提出了一种新的在线学习握取预测方法，以解决这个问题。特别是，我们提出了一种有效的探索策略，可以明显提高在未经见的环境设置下的适应性。为此，我们首先将在线握取学习转换为一个RL问题，以适应握取奖励预测和握取姿势。我们还提出了多种不确定度估计方法，基于 bayesian不确定度量化和分布ensemble。我们在实际的 bin picking 场景中进行了评估，结果显示，我们的方法在不同的难度水平下表现出了明显的改善。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Hypergraph-Structure-Learning-for-Traffic-Flow-Forecasting"><a href="#Dynamic-Hypergraph-Structure-Learning-for-Traffic-Flow-Forecasting" class="headerlink" title="Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting"></a>Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12028">http://arxiv.org/abs/2309.12028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusheng Zhao, Xiao Luo, Wei Ju, Chong Chen, Xian-Sheng Hua, Ming Zhang</li>
<li>for: 预测未来交通情况，基于路网和过去交通情况来预测未来交通状况。</li>
<li>methods: 使用强化图学习方法，抽取高维图 струкural信息，模型交通网络中的动态关系，并通过互动图卷积块来模型不同时间的交通关系。</li>
<li>results: 与竞争对手比较，实验结果表明，提出的 DyHSL 方法在四个流行的交通数据集上具有更高的预测精度和稳定性。<details>
<summary>Abstract</summary>
This paper studies the problem of traffic flow forecasting, which aims to predict future traffic conditions on the basis of road networks and traffic conditions in the past. The problem is typically solved by modeling complex spatio-temporal correlations in traffic data using spatio-temporal graph neural networks (GNNs). However, the performance of these methods is still far from satisfactory since GNNs usually have limited representation capacity when it comes to complex traffic networks. Graphs, by nature, fall short in capturing non-pairwise relations. Even worse, existing methods follow the paradigm of message passing that aggregates neighborhood information linearly, which fails to capture complicated spatio-temporal high-order interactions. To tackle these issues, in this paper, we propose a novel model named Dynamic Hypergraph Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise relationships, our DyHSL extracts hypergraph structural information to model dynamics in the traffic networks, and updates each node representation by aggregating messages from its associated hyperedges. Additionally, to capture high-order spatio-temporal relations in the road network, we introduce an interactive graph convolution block, which further models the neighborhood interaction for each node. Finally, we integrate these two views into a holistic multi-scale correlation extraction module, which conducts temporal pooling with different scales to model different temporal patterns. Extensive experiments on four popular traffic benchmark datasets demonstrate the effectiveness of our proposed DyHSL compared with a broad range of competing baselines.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这篇论文研究了交通流量预测问题，目的是根据过去的道路网络和交通情况预测未来交通情况。传统的方法使用空间时间图内存神经网络（GNN），但其表现仍然不够满意，因为GNN通常在复杂的交通网络上具有有限的表示能力。为解决这个问题，我们在这篇论文中提出了一种名为动态质量结构学习（DyHSL）的新模型，用于预测交通流量。DyHSL使用质量结构信息来模型交通网络中的动态，并为每个节点更新表示信息，通过聚合与其相关的质量结构上的消息。此外，我们还引入了一种互动图卷积块，用于模型每个节点的邻居交互。最后，我们将这两个视角集成到一个整体多级相关提取模块中，并进行不同的时间膨胀来模型不同的时间模式。我们对四个流行的交通测试集进行了广泛的实验，并证明了我们提出的DyHSL在与一系列基线模型进行比较时的效果。
</details></li>
</ul>
<hr>
<h2 id="Demystifying-Visual-Features-of-Movie-Posters-for-Multi-Label-Genre-Identification"><a href="#Demystifying-Visual-Features-of-Movie-Posters-for-Multi-Label-Genre-Identification" class="headerlink" title="Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification"></a>Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12022">http://arxiv.org/abs/2309.12022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Utsav Kumar Nareti, Chandranath Adak, Soumi Chattopadhyay</li>
<li>for: 这 paper 是用于自动多标签电影类型识别，只使用电影海报图像，无需其他文本&#x2F;元数据信息。</li>
<li>methods: 这 paper 使用了深度变换器网络，并添加了概率模块来识别电影类型。</li>
<li>results: 在实验分析中，模型在13882张电影海报图像上表现出了鼓舞人心的result，甚至超过了一些当前主流架构。<details>
<summary>Abstract</summary>
In the film industry, movie posters have been an essential part of advertising and marketing for many decades, and continue to play a vital role even today in the form of digital posters through online, social media and OTT platforms. Typically, movie posters can effectively promote and communicate the essence of a film, such as its genre, visual style/ tone, vibe and storyline cue/ theme, which are essential to attract potential viewers. Identifying the genres of a movie often has significant practical applications in recommending the film to target audiences. Previous studies on movie genre identification are limited to subtitles, plot synopses, and movie scenes that are mostly accessible after the movie release. Posters usually contain pre-release implicit information to generate mass interest. In this paper, we work for automated multi-label genre identification only from movie poster images, without any aid of additional textual/meta-data information about movies, which is one of the earliest attempts of its kind. Here, we present a deep transformer network with a probabilistic module to identify the movie genres exclusively from the poster. For experimental analysis, we procured 13882 number of posters of 13 genres from the Internet Movie Database (IMDb), where our model performances were encouraging and even outperformed some major contemporary architectures.
</details>
<details>
<summary>摘要</summary>
在电影业内，电影海报已经是广告和市场营销的重要组成部分，并且在今天的形式中仍然扮演着重要的角色，包括数字海报通过在线、社交媒体和OTT平台。通常，电影海报可以有效地推广和传达电影的核心元素，如其类型、视觉风格/调子、氛围和故事线索/主题，这些元素都是吸引 posible viewers 的关键。识别电影的类型有很多实际应用，例如推荐电影给target audience。过去的研究主要集中在电影场景、剧本简介和电影片段等，这些信息都是电影发布后才可以获取。海报通常包含在电影发布之前的隐式信息，以便引起大量的兴趣。在这篇论文中，我们采用了自动化多个标签类别识别方法，只使用电影海报图像，不需要任何其他电影相关的文本/元数据信息，这是目前已知的其中之一。我们在实验分析中使用了13882张海报图像，来自互联网电影数据库（IMDb），我们的模型表现很 Encouraging，甚至超过了一些当前的主流架构。
</details></li>
</ul>
<hr>
<h2 id="Safe-Hierarchical-Reinforcement-Learning-for-CubeSat-Task-Scheduling-Based-on-Energy-Consumption"><a href="#Safe-Hierarchical-Reinforcement-Learning-for-CubeSat-Task-Scheduling-Based-on-Energy-Consumption" class="headerlink" title="Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption"></a>Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12004">http://arxiv.org/abs/2309.12004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahya Ramezani, M. Amin Alandihallaj, Jose Luis Sanchez-Lopez, Andreas Hein</li>
<li>for: 优化CubeSat任务调度在低地球轨道（LEO）中</li>
<li>methods: 基于层次强化学习的方法，包括全球任务分布高级政策和实时适应低级政策作为安全机制，同时包括相似注意力基于编码器（SABE） для任务优先级调整和多层扩散器（MLP）估计器 для能量消耗预测</li>
<li>results: 对多个CubeSat配置进行了仿真测试，结果表明层次强化学习方法在任务 converges 和成功率方面具有超越MADDPG模型和随机调度的优势。<details>
<summary>Abstract</summary>
This paper presents a Hierarchical Reinforcement Learning methodology tailored for optimizing CubeSat task scheduling in Low Earth Orbits (LEO). Incorporating a high-level policy for global task distribution and a low-level policy for real-time adaptations as a safety mechanism, our approach integrates the Similarity Attention-based Encoder (SABE) for task prioritization and an MLP estimator for energy consumption forecasting. Integrating this mechanism creates a safe and fault-tolerant system for CubeSat task scheduling. Simulation results validate the Hierarchical Reinforcement Learning superior convergence and task success rate, outperforming both the MADDPG model and traditional random scheduling across multiple CubeSat configurations.
</details>
<details>
<summary>摘要</summary>
本文提出了一种层次优化方法，用于优化 LEO 牛顿级卫星任务调度。该方法包括一个高级策略用于全球任务分配和一个低级策略用于实时调整作为安全机制，并 integrates 类似注意力基于编码器（SABE）用于任务优先级调度和一个 MLP 预测器用于能源消耗预测。通过这种机制，我们构建了一个安全和可靠的 CubeSat 任务调度系统。实验结果表明，层次优化学习超越了 MADDPG 模型和随机调度，在多种 CubeSat 配置下实现了更高的任务成功率。
</details></li>
</ul>
<hr>
<h2 id="LMSYS-Chat-1M-A-Large-Scale-Real-World-LLM-Conversation-Dataset"><a href="#LMSYS-Chat-1M-A-Large-Scale-Real-World-LLM-Conversation-Dataset" class="headerlink" title="LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"></a>LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11998">http://arxiv.org/abs/2309.11998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric. P Xing, Joseph E. Gonzalez, Ion Stoica, Hao Zhang</li>
<li>For: 这个论文的目的是为了研究人们在真实场景中与大型自然语言模型（LLM）进行交互的方式。* Methods: 这篇论文使用了25种当前最先进的LMM进行实际场景中的交互，并从210K个唯一的IP地址中收集了100万个对话。* Results: 论文提供了这个数据集的概述，包括其批处程序、基本统计和话题分布，并通过四个用例展示了这个数据集的多样性和大小，包括开发内容审核模型、建立安全标准、训练遵循 instrux 模型和创建挑战性的问题集。<details>
<summary>Abstract</summary>
Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at \url{https://huggingface.co/datasets/lmsys/lmsys-chat-1m}.
</details>
<details>
<summary>摘要</summary>
我们将介绍一个名为LMSYS-Chat-1M的大规模数据集，它包含25个现代大语言模型在实际场景中的一百万个对话。这个数据集是从我们的Vicuna demo和Chatbot Arena网站上获取的210K个唯一的IP地址。我们将介绍这个数据集的内容，包括它的数据收集过程、基本统计和主题分布，并强调其多样性、原始性和规模。我们还会显示这个数据集的多方位性，包括发展内容审核模型，建立安全参考基准，训练遵循命令的模型，和创建挑战性的问题。我们认为这个数据集将成为大语言模型能力的理解和进步的重要资源。这个数据集现在在\url{https://huggingface.co/datasets/lmsys/lmsys-chat-1m}上公开提供。
</details></li>
</ul>
<hr>
<h2 id="Predictability-and-Comprehensibility-in-Post-Hoc-XAI-Methods-A-User-Centered-Analysis"><a href="#Predictability-and-Comprehensibility-in-Post-Hoc-XAI-Methods-A-User-Centered-Analysis" class="headerlink" title="Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis"></a>Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11987">http://arxiv.org/abs/2309.11987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anahid Jalali, Bernhard Haslhofer, Simone Kriglstein, Andreas Rauber</li>
<li>for: 本研究旨在评估黑盒机器学习模型预测结果的后续解释方法的可解性和预测能力。</li>
<li>methods: 研究使用了两种广泛使用的工具：LIME和SHAP。研究还 investigate了对于用户理解和预测模型行为的影响。</li>
<li>results: 研究发现，SHAP的可解性在模型决策边界附近受到显著降低。此外，对比例解释和错误类型的影响也发现了增加用户理解模型行为的能力。基于研究结果，还提出了未来 posterior explainability 方法的设计建议。<details>
<summary>Abstract</summary>
Post-hoc explainability methods aim to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increased comprehensibility and predictability.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Post-hoc explainability methods aim to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increased comprehensibility and predictability." into Simplified Chinese.翻译文本为简化字的中文：Post-hoc解释方法旨在解释黑盒机器学习模型的预测结果。然而，目前还不清楚用户对提供的解释是否能够准确理解和预测模型的行为。我们通过进行用户研究，评估了两种广泛使用的工具：LIME和SHAP的可 comprendibility和预测能力。此外，我们还研究了对用户的counterfactual解释和错误分类对用户理解和预测模型行为的影响。我们发现，SHAP的可 comprendibility在解释靠近决策边界时显著降低。此外，我们发现，counterfactual解释和错误分类可以帮助用户更好地理解机器学习模型如何做出决策。基于我们的发现，我们还提出了未来post-hoc解释方法的设计建议，以提高可 comprendibility和预测能力。
</details></li>
</ul>
<hr>
<h2 id="Representation-Abstractions-as-Incentives-for-Reinforcement-Learning-Agents-A-Robotic-Grasping-Case-Study"><a href="#Representation-Abstractions-as-Incentives-for-Reinforcement-Learning-Agents-A-Robotic-Grasping-Case-Study" class="headerlink" title="Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study"></a>Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11984">http://arxiv.org/abs/2309.11984</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panagiotis Petropoulakis, Ludwig Gräf, Josip Josifovski, Mohammadhossein Malmir, Alois Knoll</li>
<li>for: 这项研究的目的是探讨RL机器人在不同状态表示方法下解决反极和平面物捕获任务的能力。</li>
<li>methods: 该研究使用了模型基于的方法、数字化的方法和图像基于的方法来表示环境，并对这些方法的影响进行了调查。</li>
<li>results: 研究发现RL机器人使用数字化状态可以与非学习基eline相当，而使用图像基于的状态从预训练环境向量得到的表示 perfoms更好，并且假设任务特定的知识是控制机器人成功的关键因素。<details>
<summary>Abstract</summary>
Choosing an appropriate representation of the environment for the underlying decision-making process of the \gls{RL} agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and compact enough to increase sample efficiency for policy training. Given this outlook, this work examines the effect of various state representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representation abstractions is defined, starting from a model-based approach with complete system knowledge, through hand-crafted numerical, to image-based representations with decreasing level of induced task-specific knowledge. We examine the effects of each representation in the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot. The results show that RL agents using numerical states can perform on par with non-learning baselines. Furthermore, we find that agents using image-based representations from pre-trained environment embedding vectors perform better than end-to-end trained agents, and hypothesize that task-specific knowledge is necessary for achieving convergence and high success rates in robot control. Supplementary material can be found at the project webpage: https://github.com/PetropoulakisPanagiotis/igae.
</details>
<details>
<summary>摘要</summary>
选择合适的环境表示方式 дляRL代理的基础决策过程并不总是 straightforward。状态表示应该包含足够的信息，使代理能够有优决策，同时也应该尽量紧凑，以提高策略训练的示例效率。在这个视角下，本工作研究了不同的状态表示方式对RL代理解决特有的 робо控制任务：把物 grasping。我们定义了一种维度的状态表示抽象continuum，从模型基于的方法（完全系统知识），通过手工制定的数值，到图像基于的表示（减少任务特定知识）。我们研究了每种表示方式对代理解决任务的能力，以及这些策略在真实机器人上的可转移性。结果表明RL代理使用数值状态可以与非学习基线一样高效，而使用图像基于的表示从预训练环境嵌入向量而来的代理，则比末端培训的代理更高效。我们认为任务特定的知识是控制机器人高效和具有高成功率的关键。补充材料可以在项目网页上找到：https://github.com/PetropoulakisPanagiotis/igae。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-the-Evaluating-Framework-for-Natural-Language-Understanding-in-AI-Systems-Language-Acquisition-as-a-Core-for-Future-Metrics"><a href="#Rethinking-the-Evaluating-Framework-for-Natural-Language-Understanding-in-AI-Systems-Language-Acquisition-as-a-Core-for-Future-Metrics" class="headerlink" title="Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics"></a>Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11981">http://arxiv.org/abs/2309.11981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patricio Vera, Pedro Moya, Lisa Barraza</li>
<li>for: 本研究旨在探讨人工智能（AI）领域内大语言模型（LLMs）的进步对传统机器智能评价指标的影响，并提出一种基于语言学习和理解的新评价框架。</li>
<li>methods: 本研究采用了多种学科的优秀成果，包括语言学习和理解、自然语言处理（NLP）等，以探讨传统机器智能评价指标的缺陷和不足，并提出一种更加全面和可持续的评价方法。</li>
<li>results: 本研究提出了一种基于语言学习和理解的新评价框架，可以更好地评价机器智能的能力和表现，并且可以帮助解决传统机器智能评价指标的缺陷和不足。<details>
<summary>Abstract</summary>
In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
</details>
<details>
<summary>摘要</summary>
在人工智能（AI）领域的不断发展中，大型自然语言处理（NLP）模型的前无古人成就，对传统机器智能评估 metric 的形式和内容都提供了机遇。随着机器认知领域已经达到仿制的水平，接下来的核心任务是语言学习和理解。我们的论文提议一种借鉴现代 LLM 的概念shift，强调语言学习，而不是已有的图灵测试。我们的贡献受到了不同领域的出色工作的推动，要保持交往桥梁打开，并提出了更加坚强和可持续的方法。
</details></li>
</ul>
<hr>
<h2 id="Inferring-Capabilities-from-Task-Performance-with-Bayesian-Triangulation"><a href="#Inferring-Capabilities-from-Task-Performance-with-Bayesian-Triangulation" class="headerlink" title="Inferring Capabilities from Task Performance with Bayesian Triangulation"></a>Inferring Capabilities from Task Performance with Bayesian Triangulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11975">http://arxiv.org/abs/2309.11975</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Burden, Konstantinos Voudouris, Ryan Burnell, Danaja Rutar, Lucy Cheke, José Hernández-Orallo</li>
<li>for: 这篇论文旨在Characterizing machine learning models in richer, more meaningful ways, and describing a method to infer the cognitive profile of a system from diverse experimental data.</li>
<li>methods: 该方法使用了 measurement layouts to model how task-instance features interact with system capabilities, and used Bayesian probabilistic programming library PyMC to infer different cognitive profiles for agents in two scenarios.</li>
<li>results: 研究人员通过使用这种方法，能够从非常复杂的数据中推断出系统的能力profile，并在两个场景中显示了 capability-oriented evaluation 的潜力。<details>
<summary>Abstract</summary>
As machine learning models become more general, we need to characterise them in richer, more meaningful ways. We describe a method to infer the cognitive profile of a system from diverse experimental data. To do so, we introduce measurement layouts that model how task-instance features interact with system capabilities to affect performance. These features must be triangulated in complex ways to be able to infer capabilities from non-populational data -- a challenge for traditional psychometric and inferential tools. Using the Bayesian probabilistic programming library PyMC, we infer different cognitive profiles for agents in two scenarios: 68 actual contestants in the AnimalAI Olympics and 30 synthetic agents for O-PIAAGETS, an object permanence battery. We showcase the potential for capability-oriented evaluation.
</details>
<details>
<summary>摘要</summary>
（machine learning models become more general, we need to characterize them in richer, more meaningful ways） machine learning模型变得更加通用，我们需要对其进行更加丰富、有意义的描述。我们介绍了一种方法，用于从多种实验数据中推断系统的认知profile。为此，我们引入了任务实例特征与系统能力之间的测量布局，以影响性能。这些特征需要在复杂的方式进行拟合，以便从非流行数据中推断能力——传统心理测量和推断工具所面临的挑战。使用PyMC的 bayesian概率编程库，我们对 AnimalAI奥运会中的68名实际参赛者和O-PIAAGETS对象永恒测试中的30名 sintetic agents进行了不同的认知 profiling。我们展示了可能性-oriented评估的潜力。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Review-on-Financial-Explainable-AI"><a href="#A-Comprehensive-Review-on-Financial-Explainable-AI" class="headerlink" title="A Comprehensive Review on Financial Explainable AI"></a>A Comprehensive Review on Financial Explainable AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11960">http://arxiv.org/abs/2309.11960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Jie Yeo, Wihan van der Heever, Rui Mao, Erik Cambria, Ranjan Satapathy, Gianmarco Mengaldo</li>
<li>for: 该论文主要旨在提供一种对深度学习模型可读性的比较survey，以便在金融领域内采用可读性AI方法。</li>
<li>methods: 该论文分析了一些提高深度学习模型可读性的方法，并将其分为不同的特征类型。</li>
<li>results: 该论文评估了采用可读性AI方法的问题和挑战，以及未来采用这些方法的未来方向。<details>
<summary>Abstract</summary>
The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）和深度学习模型的成功导致它们在不同领域得到广泛的应用，这主要是因为它们可以处理庞大数据量和学习复杂的模式。然而，由于它们的不可解性，在重要领域如金融和医疗等，决策透明度的问题具有重要性。在这篇论文中，我们提供了深入比较了在金融领域中改进深度学习模型的可解性的方法。我们根据它们的特点分类ify这些可解AI方法，并评估采用可解AI方法的问题和挑战，以及未来适当和重要的方向。
</details></li>
</ul>
<hr>
<h2 id="On-the-Definition-of-Appropriate-Trust-and-the-Tools-that-Come-with-it"><a href="#On-the-Definition-of-Appropriate-Trust-and-the-Tools-that-Come-with-it" class="headerlink" title="On the Definition of Appropriate Trust and the Tools that Come with it"></a>On the Definition of Appropriate Trust and the Tools that Come with it</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11937">http://arxiv.org/abs/2309.11937</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Helena Löfström</li>
<li>for: 本研究旨在评估人工智能交互的效率，包括主观和客观质量方面。</li>
<li>methods: 本研究使用定义适当信任的方法进行评估，并与模型性能评估进行比较，发现两者之间存在强相似性。</li>
<li>results: 本研究提出了一种新的适当信任评估方法，并对用户性能进行了多个方面的评估，包括建议一种测量不确定性和适当信任的方法。<details>
<summary>Abstract</summary>
Evaluating the efficiency of human-AI interactions is challenging, including subjective and objective quality aspects. With the focus on the human experience of the explanations, evaluations of explanation methods have become mostly subjective, making comparative evaluations almost impossible and highly linked to the individual user. However, it is commonly agreed that one aspect of explanation quality is how effectively the user can detect if the predictions are trustworthy and correct, i.e., if the explanations can increase the user's appropriate trust in the model. This paper starts with the definitions of appropriate trust from the literature. It compares the definitions with model performance evaluation, showing the strong similarities between appropriate trust and model performance evaluation. The paper's main contribution is a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper offers several straightforward evaluation methods for different aspects of user performance, including suggesting a method for measuring uncertainty and appropriate trust in regression.
</details>
<details>
<summary>摘要</summary>
评估人类-AI交互的效率具有挑战性，包括主观和客观质量方面。针对解释方法的评估通常受到用户经验的限制，导致对比评估变得困难，同时与个人用户的偏好息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息字。本文从文献中定义了适当信任的定义，并与模型性能评估进行比较，发现这两者之间存在强烈的相似性。本文的主要贡献是一种新的适当信任评估方法，利用定义之间的相似性。文章还提供了不同方面的用户性能评估方法，包括一种用于减迷和适当信任的回归方法。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Recover-for-Safe-Reinforcement-Learning"><a href="#Learning-to-Recover-for-Safe-Reinforcement-Learning" class="headerlink" title="Learning to Recover for Safe Reinforcement Learning"></a>Learning to Recover for Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11907">http://arxiv.org/abs/2309.11907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Wang, Xin Yuan, Qinqing Ren</li>
<li>for: 本文旨在研究如何通过学习算法构建安全控制器，以实现安全的返点学习。</li>
<li>methods: 本文提出了一种三 stage 架构，即 TU-Recovery 架构，包括安全评估器和恢复策略。这些 componenets 共同形成了一个安全控制器，确保任务训练中的安全性。</li>
<li>results: 在一个 robot 导航环境中进行了一系列实验，结果表明，TU-Recovery 在 reward 获取和约束违反方面在任务训练中表现出色，并且 auxiliary reward 可以进一步提高 TU-Recovery 的 reward-to-cost 比例，同时减少约束违反。<details>
<summary>Abstract</summary>
Safety controllers is widely used to achieve safe reinforcement learning. Most methods that apply a safety controller are using handcrafted safety constraints to construct the safety controller. However, when the environment dynamics are sophisticated, handcrafted safety constraints become unavailable. Therefore, it worth to research on constructing safety controllers by learning algorithms. We propose a three-stage architecture for safe reinforcement learning, namely TU-Recovery Architecture. A safety critic and a recovery policy is learned before task training. They form a safety controller to ensure safety in task training. Then a phenomenon induced by disagreement between task policy and recovery policy, called adversarial phenomenon, which reduces learning efficiency and model performance, is described. Auxiliary reward is proposed to mitigate adversarial phenomenon, while help the task policy to learn to recover from high-risk states. A series of experiments are conducted in a robot navigation environment. Experiments demonstrate that TU-Recovery outperforms unconstrained counterpart in both reward gaining and constraint violations during task training, and auxiliary reward further improve TU-Recovery in reward-to-cost ratio by significantly reduce constraint violations.
</details>
<details>
<summary>摘要</summary>
安全控制器广泛应用于安全强化学习。大多数应用安全控制器的方法使用手工安全约束来构建安全控制器。然而，当环境动力学复杂时，手工安全约束成为不可用。因此，研究构建安全控制器的学习算法是有价值的。我们提出了三个阶段的安全强化学习架构，称为TU-Recovery架构。一个安全评价员和一个恢复策略在任务训练之前被学习出来。它们组成一个安全控制器，以确保任务训练中的安全。然后，一种由任务策略和恢复策略之间的不一致现象引起的，称为对抗现象，这会降低学习效率和模型性能。我们提出了auxiliary reward来 mitigate对抗现象，同时帮助任务策略学习从高风险状态恢复。在一个 робот导航环境中进行了一系列实验，实验结果表明，TU-Recovery在增加奖励和约束违反时在任务训练中表现出了比对ounterpart更好的性能，并且auxiliary reward可以进一步提高TU-Recovery的奖励比率。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Heart-Using-Adaptive-Locked-Agnostic-Networks"><a href="#Unlocking-the-Heart-Using-Adaptive-Locked-Agnostic-Networks" class="headerlink" title="Unlocking the Heart Using Adaptive Locked Agnostic Networks"></a>Unlocking the Heart Using Adaptive Locked Agnostic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11899">http://arxiv.org/abs/2309.11899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AstraZeneca/UnlockingHeart">https://github.com/AstraZeneca/UnlockingHeart</a></li>
<li>paper_authors: Sylwia Majchrowska, Anders Hildeman, Philip Teare, Tom Diethe<br>for:* The paper is written for medical imaging applications, specifically for echocardiography datasets.methods:* The paper introduces the Adaptive Locked Agnostic Network (ALAN) method, which uses self-supervised visual feature extraction and a large backbone model to produce anatomically robust semantic self-segmentation.results:* The paper demonstrates that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view. Additionally, the paper designs two downstream models for segmenting a target anatomical region and echocardiogram view classification.Here is the information in Simplified Chinese text:for:* 这篇论文是为医疗影像应用而写的，特别是对于echocardiography dataset。methods:* 这篇论文介绍了Adaptive Locked Agnostic Network（ALAN）方法，该方法使用自动鉴定的视觉特征提取和大型后置网络来生成医学robust的semantic自 segmentation。results:* 这篇论文表明，自动鉴定后置网络可以坚定地标识心脏四室视图中的生物学特征。此外，论文还设计了两个下游模型，一个用于标识目标生物学区域，另一个用于echocardiogram视图分类。<details>
<summary>Abstract</summary>
Supervised training of deep learning models for medical imaging applications requires a significant amount of labeled data. This is posing a challenge as the images are required to be annotated by medical professionals. To address this limitation, we introduce the Adaptive Locked Agnostic Network (ALAN), a concept involving self-supervised visual feature extraction using a large backbone model to produce anatomically robust semantic self-segmentation. In the ALAN methodology, this self-supervised training occurs only once on a large and diverse dataset. Due to the intuitive interpretability of the segmentation, downstream models tailored for specific tasks can be easily designed using white-box models with few parameters. This, in turn, opens up the possibility of communicating the inner workings of a model with domain experts and introducing prior knowledge into it. It also means that the downstream models become less data-hungry compared to fully supervised approaches. These characteristics make ALAN particularly well-suited for resource-scarce scenarios, such as costly clinical trials and rare diseases. In this paper, we apply the ALAN approach to three publicly available echocardiography datasets: EchoNet-Dynamic, CAMUS, and TMED-2. Our findings demonstrate that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view. Building upon this, we design two downstream models, one for segmenting a target anatomical region, and a second for echocardiogram view classification.
</details>
<details>
<summary>摘要</summary>
审核训练深度学习模型 для医疗影像应用需要大量标注数据。然而，由于影像需要由医疗专业人员进行标注，这成为一个挑战。为解决这个限制，我们介绍了自适应锁定agnostic网络（ALAN），它利用大型后骨骼模型进行自我超视觉特征提取，以生成具有体系 robust的 semantic自segmentation。在ALAN方法中，这种自我超视觉训练只在一个大型和多样的数据集上进行一次。由于分割结果的直观解释，下游模型可以轻松地使用白盒模型和少量参数进行定制。这种特点使得ALAN在资源匮乏的情况下特别有优势，例如成本高的临床试验和罕见疾病。在这篇论文中，我们应用ALAN方法于三个公共可用的echo医学数据集：EchoNet-Dynamic、CAMUS和TMED-2。我们的发现表明，自适应锁定agnostic网络可以强健地 identificates心脏四室视图中的 анатомичеSUBREGION。基于这个结果，我们设计了两个下游模型，一个用于分割目标生物学区域，另一个用于echo医学视图类型分类。
</details></li>
</ul>
<hr>
<h2 id="Audio-Contrastive-based-Fine-tuning"><a href="#Audio-Contrastive-based-Fine-tuning" class="headerlink" title="Audio Contrastive based Fine-tuning"></a>Audio Contrastive based Fine-tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11895">http://arxiv.org/abs/2309.11895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Wang, Qibin Liang, Chenghao Xiao, Yizhi Li, Noura Al Moubayed, Chenghua Lin</li>
<li>for: Audio classification tasks, such as speech and sound processing, with a wide range of applications.</li>
<li>methods: 用对照学习的转移性能来提高模型的测试准确性和适应能力。</li>
<li>results: 在不同的audio classification任务中，AudioConFit方法可以实现高度的效果和稳定性，并且在不同的测试数据集上获得了最佳的结果。<details>
<summary>Abstract</summary>
Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
</details>
<details>
<summary>摘要</summary>
音频分类在语音和声音处理任务中扮演着关键角色，具有广泛的应用场景。然而，模型适应训练数据的问题仍然是一大挑战，以避免过拟合。我们基于对比学习的传送性，提出了音频对比细化（AudioConFit），一种高效的方法，具有强大的通用性。实验证明，我们的方法在不同的音频分类任务中具有优秀的效果和稳定性，达到了不同设置下的状态态表现。
</details></li>
</ul>
<hr>
<h2 id="Multi-level-Asymmetric-Contrastive-Learning-for-Medical-Image-Segmentation-Pre-training"><a href="#Multi-level-Asymmetric-Contrastive-Learning-for-Medical-Image-Segmentation-Pre-training" class="headerlink" title="Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training"></a>Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11876">http://arxiv.org/abs/2309.11876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Zeng, Lei Zhu, Xinliang Zhang, Zifeng Tian, Qian Chen, Lujia Jin, Jiayi Wang, Yanye Lu</li>
<li>for: 本文针对医疗影像分类任务提出了一个新的不对称对称学习框架（JCL），以自动扮演验证预训。</li>
<li>methods: 本文提出了一个新的不对称对称学习策略，同时预训encoder和decoder，以提供更好的预设值 для医疗影像分类模型。 multi-level对称损失函数被设计来考虑对于特征水平、影像水平和像素水平的对应关系，以确保encoder和decoder在预训过程中可以学习多个水平的表示。</li>
<li>results: 在多个医疗影像数据集上实验显示，我们的JCL框架比现有的SOTA对称学习策略更高效。<details>
<summary>Abstract</summary>
Contrastive learning, which is a powerful technique for learning image-level representations from unlabeled data, leads a promising direction to dealing with the dilemma between large-scale pre-training and limited labeled data. However, most existing contrastive learning strategies are designed mainly for downstream tasks of natural images, therefore they are sub-optimal and even worse than learning from scratch when directly applied to medical images whose downstream tasks are usually segmentation. In this work, we propose a novel asymmetric contrastive learning framework named JCL for medical image segmentation with self-supervised pre-training. Specifically, (1) A novel asymmetric contrastive learning strategy is proposed to pre-train both encoder and decoder simultaneously in one-stage to provide better initialization for segmentation models. (2) A multi-level contrastive loss is designed to take the correspondence among feature-level, image-level and pixel-level projections, respectively into account to make sure multi-level representations can be learned by the encoder and decoder during pre-training. (3) Experiments on multiple medical image datasets indicate our JCL framework outperforms existing SOTA contrastive learning strategies.
</details>
<details>
<summary>摘要</summary>
对于医疗影像的分类问题，对于大规模预训数据和有限的标签数据的冲突是一个挑战。然而，现有的对比学习策略主要是设计来应用于自然像素，因此它们在医疗影像的下游任务中表现不佳，甚至比起从零学习还差。在这个工作中，我们提出了一个名为JCL的 novel asymmetric对比学习框架，用于医疗影像分类。具体来说，我们提出了以下三个方法：1. 一个新的对比学习策略，同时在一阶段中预训encoder和decoder，以提供更好的初始化 для分类模型。2. 一个多层对比损失函数，用于考虑对于特征层、影像层和像素层的对应关系，以确保encoder和decoder在预训过程中学习到多层表示。3. 在多个医疗影像数据集上进行了实验，结果显示了我们的JCL框架比现有的SOTA对比学习策略更高效。
</details></li>
</ul>
<hr>
<h2 id="Stochastic-stiffness-identification-and-response-estimation-of-Timoshenko-beams-via-physics-informed-Gaussian-processes"><a href="#Stochastic-stiffness-identification-and-response-estimation-of-Timoshenko-beams-via-physics-informed-Gaussian-processes" class="headerlink" title="Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes"></a>Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11875">http://arxiv.org/abs/2309.11875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gledsonrt/pigptimoshenkobeam">https://github.com/gledsonrt/pigptimoshenkobeam</a></li>
<li>paper_authors: Gledson Rodrigo Tondo, Sebastian Rau, Igor Kavrakov, Guido Morgenthal</li>
<li>for: 这篇论文旨在用机器学习模型进行系统识别，特别是Timoshenko梁元件的结构健康监测数据。</li>
<li>methods: 该论文提出了一种基于 Gaussian Process（GP）模型的物理 informed 方法，用于结构参数的 indentification。该模型是一种多输出GP模型，其covariance和cross-covariance函数 Analytical derivation based on the differential equations of deflections, rotations, strains, bending moments, shear forces and applied loads。</li>
<li>results: 对于结构参数的 indentification，使用 Bayesian 格式的最大化 posterior model，通过 Markov chain Monte Carlo 方法进行优化，得到了一个随机模型。此外，该方法还可以用于probabilistic predictions of unobserved responses。实验结果表明，提出的方法可以有效地 indentify结构参数，并且可以融合不同类型和多价信息感知器的数据。结果的质量和不确定性也得到了验证。该方法有广泛的应用前提在结构健康监测（SHM）领域。<details>
<summary>Abstract</summary>
Machine learning models trained with structural health monitoring data have become a powerful tool for system identification. This paper presents a physics-informed Gaussian process (GP) model for Timoshenko beam elements. The model is constructed as a multi-output GP with covariance and cross-covariance kernels analytically derived based on the differential equations for deflections, rotations, strains, bending moments, shear forces and applied loads. Stiffness identification is performed in a Bayesian format by maximising a posterior model through a Markov chain Monte Carlo method, yielding a stochastic model for the structural parameters. The optimised GP model is further employed for probabilistic predictions of unobserved responses. Additionally, an entropy-based method for physics-informed sensor placement optimisation is presented, exploiting heterogeneous sensor position information and structural boundary conditions built into the GP model. Results demonstrate that the proposed approach is effective at identifying structural parameters and is capable of fusing data from heterogeneous and multi-fidelity sensors. Probabilistic predictions of structural responses and internal forces are in closer agreement with measured data. We validate our model with an experimental setup and discuss the quality and uncertainty of the obtained results. The proposed approach has potential applications in the field of structural health monitoring (SHM) for both mechanical and structural systems.
</details>
<details>
<summary>摘要</summary>
机器学习模型使用结构健康监测数据成为了系统识别的强大工具。这篇论文提出了基于Timoshenko梁元素的物理知识泛化过程（GP）模型。该模型是一种多输出GP模型，其covariance和交叉covariancekernel analytically derive了基于摆动、旋转、强度、剪力、应用负荷的偏微分方程。在 bayesian 格式下，通过Markov chain Monte Carlo 方法进行了权重最大化，从而获得了一个随机模型 для结构参数。该优化后的 GP 模型进一步用于 probabilistic 预测未观测Response。此外，本文还提出了基于物理知识的感知器位置优化方法，利用不同类型感知器位置信息和结构边界条件，并将其建入 GP 模型中。结果表明，提出的方法能够有效地识别结构参数，并能够融合不同类型和多优化感知器的数据。probabilistic 预测结构响应和内部力的结果与实验数据更加吻合。我们验证了我们的模型，并讨论了获得的结果的质量和不确定性。该方法在结构健康监测（SHM）领域有广泛的应用前景。
</details></li>
</ul>
<hr>
<h2 id="OSNet-MNetO-Two-Types-of-General-Reconstruction-Architectures-for-Linear-Computed-Tomography-in-Multi-Scenarios"><a href="#OSNet-MNetO-Two-Types-of-General-Reconstruction-Architectures-for-Linear-Computed-Tomography-in-Multi-Scenarios" class="headerlink" title="OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios"></a>OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11858">http://arxiv.org/abs/2309.11858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhisheng Wang, Zihan Deng, Fenglin Liu, Yixing Huang, Haijun Yu, Junning Cui<br>for:* Linear computed tomography (LCT) systems Linear computed tomography (LCT) systems are the focus of this paper, and the authors aim to improve image reconstruction for these systems.methods:*  Backprojection filtration (BPF) algorithm The BPF algorithm is used to weaken projection truncation and image the region of interest (ROI) for LCT.*  Two types of reconstruction architectures are proposed: Overlay-Single Network (OSNet) and Multiple Networks Overlaying (MNetO) These architectures use multiple DBP images to obtain a complete DBP image and train different directional Hilbert filtering models for DBP images of multiple linear scannings, respectively.results:*  OSNet outperforms BPF in various scenarios The OSNet architecture outperforms the traditional BPF algorithm in different scenarios, including interior ROI, complete object, and exterior region beyond field-of-view (FOV).*  ST-pix2pixGAN is superior to pix2pixGAN and CycleGAN The authors introduce a Swin Transformer (ST) block to the generator of pix2pixGAN to extract both local and global features from DBP images at the same time, and ST-pix2pixGAN is found to be superior to pix2pixGAN and CycleGAN.*  MNetO exhibits a few artifacts due to the differences among the multiple models MNetO uses multiple networks to train different directional Hilbert filtering models for DBP images of multiple linear scannings, but it exhibits a few artifacts due to the differences among the multiple models.<details>
<summary>Abstract</summary>
Recently, linear computed tomography (LCT) systems have actively attracted attention. To weaken projection truncation and image the region of interest (ROI) for LCT, the backprojection filtration (BPF) algorithm is an effective solution. However, in BPF for LCT, it is difficult to achieve stable interior reconstruction, and for differentiated backprojection (DBP) images of LCT, multiple rotation-finite inversion of Hilbert transform (Hilbert filtering)-inverse rotation operations will blur the image. To satisfy multiple reconstruction scenarios for LCT, including interior ROI, complete object, and exterior region beyond field-of-view (FOV), and avoid the rotation operations of Hilbert filtering, we propose two types of reconstruction architectures. The first overlays multiple DBP images to obtain a complete DBP image, then uses a network to learn the overlying Hilbert filtering function, referred to as the Overlay-Single Network (OSNet). The second uses multiple networks to train different directional Hilbert filtering models for DBP images of multiple linear scannings, respectively, and then overlays the reconstructed results, i.e., Multiple Networks Overlaying (MNetO). In two architectures, we introduce a Swin Transformer (ST) block to the generator of pix2pixGAN to extract both local and global features from DBP images at the same time. We investigate two architectures from different networks, FOV sizes, pixel sizes, number of projections, geometric magnification, and processing time. Experimental results show that two architectures can both recover images. OSNet outperforms BPF in various scenarios. For the different networks, ST-pix2pixGAN is superior to pix2pixGAN and CycleGAN. MNetO exhibits a few artifacts due to the differences among the multiple models, but any one of its models is suitable for imaging the exterior edge in a certain direction.
</details>
<details>
<summary>摘要</summary>
最近，线性计算 Tomatoes系统（LCT）已经吸引了一些注意。为了弱化投影截断和图像区域内部（ROI）的投影，使用backprojection filtration（BPF）算法是一个有效的解决方案。然而，在LCT中的BPF中，很难实现稳定的内部重建，而且对于DBP图像的LCT，多个旋转finite inversion of Hilbert transform（Hilbert filtering）操作会模糊图像。为了满足LCT的多种重建场景，包括内部ROI、完整的对象和外部区域超出FOV（场景），并且避免旋转Hilbert filtering的操作，我们提出了两种重建建筑。第一种方法是将多个DBP图像 overlay 成一个完整的DBP图像，然后使用一个网络来学习投影过程中的Hilbert filtering函数，被称为Overlay-Single Network（OSNet）。第二种方法是使用多个网络来训练不同的方向的Hilbert filtering模型，并将其重建结果 overlay 在一起，即Multiple Networks Overlaying（MNetO）。在两种建筑中，我们引入了Swin Transformer（ST）块到 pix2pixGAN 生成器中，以同时提取 DBP 图像的本地和全局特征。我们从不同的网络、FOV 大小、像素大小、投影数量、几何增大和处理时间等方面进行了调查。实验结果表明，两种建筑都可以重建图像，OSNet 在多种场景中表现出色，超过 BPF。而ST-pix2pixGAN 比 pix2pixGAN 和 CycleGAN 更高效。MNetO 显示了一些缺陷，但任何一个模型都适用于某些方向的图像重建。
</details></li>
</ul>
<hr>
<h2 id="BitCoin-Bidirectional-Tagging-and-Supervised-Contrastive-Learning-based-Joint-Relational-Triple-Extraction-Framework"><a href="#BitCoin-Bidirectional-Tagging-and-Supervised-Contrastive-Learning-based-Joint-Relational-Triple-Extraction-Framework" class="headerlink" title="BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework"></a>BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11853">http://arxiv.org/abs/2309.11853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luyao He, Zhongbao Zhang, Sen Su, Yuxin Chen</li>
<li>for: 提高关系 triple EXTRACTION（RTE）任务的精度和效率，解决现有方法的一般化和特定性问题。</li>
<li>methods: 提出了一种创新的双向标注和监督对比学习基于的关系 triple EXTRACTION框架（BitCoin），包括多个可能的正例而不仅仅是一个正例，并引入对象和主题之间的偏差项来避免对象和主题之间的过度相似性。</li>
<li>results: 实验结果显示，BitCoin在标准数据集上达到了当前最佳Result，在不同的任务上（包括Normal、SEO、EPO和多关系EXTRACTION）显著提高了F1分数。<details>
<summary>Abstract</summary>
Relation triple extraction (RTE) is an essential task in information extraction and knowledge graph construction. Despite recent advancements, existing methods still exhibit certain limitations. They just employ generalized pre-trained models and do not consider the specificity of RTE tasks. Moreover, existing tagging-based approaches typically decompose the RTE task into two subtasks, initially identifying subjects and subsequently identifying objects and relations. They solely focus on extracting relational triples from subject to object, neglecting that once the extraction of a subject fails, it fails in extracting all triples associated with that subject. To address these issues, we propose BitCoin, an innovative Bidirectional tagging and supervised Contrastive learning based joint relational triple extraction framework. Specifically, we design a supervised contrastive learning method that considers multiple positives per anchor rather than restricting it to just one positive. Furthermore, a penalty term is introduced to prevent excessive similarity between the subject and object. Our framework implements taggers in two directions, enabling triples extraction from subject to object and object to subject. Experimental results show that BitCoin achieves state-of-the-art results on the benchmark datasets and significantly improves the F1 score on Normal, SEO, EPO, and multiple relation extraction tasks.
</details>
<details>
<summary>摘要</summary>
“关系 triple 提取（RTE）是信息提取和知识图建构中的关键任务。尽管最近有所进步，现有方法仍然存在一定的限制。它们只是使用通用预训练模型，未考虑RTE任务的特点。另外，现有的标签化方法通常将RTE任务分解成两个子任务，先确定主题，然后确定 объек 和关系。它们仅专注于从主题到 объек 中提取关系 triple，忽略了如果提取主题失败，那么所有与该主题相关的 triple 都将难以提取。为解决这些问题，我们提出了 BitCoin，一种创新的双向标签和监督对比学习基于的关系 triple 提取框架。具体来说，我们设计了一种监督对比学习方法，考虑多个可能的正例而不是仅仅 restricting 到一个正例。此外，我们引入了一个罚项，以避免主题和 объек 之间的过度相似性。我们的框架实现了两个方向的标签，即从主题到 объек 和从 objet 到主题。实验结果表明，BitCoin 在标准数据集上达到了当前最佳的结果，并在多个关系提取任务上显著提高了 F1 分数。”
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Large-Language-Models-for-Document-grounded-Response-Generation-in-Information-Seeking-Dialogues"><a href="#Evaluating-Large-Language-Models-for-Document-grounded-Response-Generation-in-Information-Seeking-Dialogues" class="headerlink" title="Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues"></a>Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11838">http://arxiv.org/abs/2309.11838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Norbert Braunschweiler, Rama Doddipatla, Simon Keizer, Svetlana Stoyanchev</li>
<li>for: 这个研究是为了研究使用大语言模型（LLMs）like ChatGPT来生成基于文档的响应，特别是在信息寻求对话中。</li>
<li>methods: 这个研究使用了两种方法：ChatCompletion和LlamaIndex。ChatCompletion使用了ChatGPT模型的预training知识，而LlamaIndex则从文档中提取了相关信息。</li>
<li>results: 研究发现，使用LLMs来生成基于文档的响应是不可靠的，因为它们可能包含未在文档中出现的信息，可能是幻想。同时，两种ChatGPT变体的输出被评估为更高，比之前的分享任务赢家系统和人类响应。<details>
<summary>Abstract</summary>
In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses. While both ChatGPT variants are more likely to include information not present in the relevant segments, possibly including a presence of hallucinations, they are rated higher than both the shared task winning system and human responses.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了大型自然语言模型（LLM）如ChatGPT在信息寻求对话中的回答生成。为评估，我们使用MultiDoc2Dial词汇对话 corpus，这是四个社会服务领域的任务型对话，已经在DialDoc 2022 Shared Task中使用。信息寻求对话转归基于多份文档提供相关信息。我们生成对话完成回答，使用两种方法：Chat-Completion和LlamaIndex。ChatCompletion利用ChatGPT模型的先前预测知识，而LlamaIndex也从文档中提取相关信息。由于文档基础回答生成via LLMs无法准确评估，我们进行了人工评估。评估结果显示，两个ChatGPT变体的输出高于分享任务获胜系统和人类回答。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Transformers-for-Wireless-Communications-A-Case-Study-in-Beam-Prediction"><a href="#Multimodal-Transformers-for-Wireless-Communications-A-Case-Study-in-Beam-Prediction" class="headerlink" title="Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction"></a>Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11811">http://arxiv.org/abs/2309.11811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itu-ai-ml-in-5g-challenge/deepsense6g_tii">https://github.com/itu-ai-ml-in-5g-challenge/deepsense6g_tii</a></li>
<li>paper_authors: Yu Tian, Qiyang Zhao, Zine el abidine Kherroubi, Fouzi Boukhalfa, Kebin Wu, Faouzi Bader</li>
<li>for: 本研究旨在提高无线通信高频带的大antenna数组面临的扫描管理问题，通过多模态感知信息（包括摄像头、LiDAR、雷达和GPS）的多模态感知训练deep learning框架。</li>
<li>methods: 本研究使用多模态转换器深度学习框架，将多modal的感知信息经过核心网络提取特征，然后使用transformer编码器学习不同modalities和时间点之间的隐藏关系，生成下一层特征提取的编码器。</li>
<li>results: 实验结果显示，使用图像和GPS数据进行训练的解决方案可以达到78.44%的距离基于准确性，并且在不seen日景和夜景中实现了73%和84%的泛化性。这些结果超过了使用其他modalities和arbitrary数据处理技术，从而证明了转换器在图像和GPS数据上的准确性和泛化性。<details>
<summary>Abstract</summary>
Wireless communications at high-frequency bands with large antenna arrays face challenges in beam management, which can potentially be improved by multimodality sensing information from cameras, LiDAR, radar, and GPS. In this paper, we present a multimodal transformer deep learning framework for sensing-assisted beam prediction. We employ a convolutional neural network to extract the features from a sequence of images, point clouds, and radar raw data sampled over time. At each convolutional layer, we use transformer encoders to learn the hidden relations between feature tokens from different modalities and time instances over abstraction space and produce encoded vectors for the next-level feature extraction. We train the model on a combination of different modalities with supervised learning. We try to enhance the model over imbalanced data by utilizing focal loss and exponential moving average. We also evaluate data processing and augmentation techniques such as image enhancement, segmentation, background filtering, multimodal data flipping, radar signal transformation, and GPS angle calibration. Experimental results show that our solution trained on image and GPS data produces the best distance-based accuracy of predicted beams at 78.44%, with effective generalization to unseen day scenarios near 73% and night scenarios over 84%. This outperforms using other modalities and arbitrary data processing techniques, which demonstrates the effectiveness of transformers with feature fusion in performing radio beam prediction from images and GPS. Furthermore, our solution could be pretrained from large sequences of multimodality wireless data, on fine-tuning for multiple downstream radio network tasks.
</details>
<details>
<summary>摘要</summary>
无线通信在高频段 WITH 大antenna array 面临 beam 管理问题，可能可以通过多模态感知信息 FROM camera, LiDAR, radar, GPS 进行改进。在这篇论文中，我们提出了一种多模态 transformer 深度学习框架 FOR 感知协助的 beam 预测。我们使用卷积神经网络提取图像、点云和雷达原始数据序列中的特征，并在每层卷积层使用 transformer 编码器学习不同模态和时间实例之间的隐藏关系，生成下一层特征提取的编码 вектор。我们使用多模态supervised学习训练模型，并尝试通过使用焦点损失和指数移动平均来增强模型对不均衡数据的适应。我们还评估了数据处理和扩展技术，如图像提升、分割、背景筛选、多模态数据翻转、雷达信号转换和GPS角度准确。实验结果表明，我们基于图像和 GPS 数据训练的解决方案可以在78.44%的距离基于准确率上预测 beam，并且在未看到的日场景中 Near 73% AND 夜场景中超过 84%。这超过了使用其他模式和自由数据处理技术，这表明 transformers 在图像和 GPS 数据上进行 radio beam 预测具有效果，并且可以通过多模态数据进行预训练，并在多个无线网络下执行多种下游任务进行 fine-tuning。
</details></li>
</ul>
<hr>
<h2 id="JobRecoGPT-–-Explainable-job-recommendations-using-LLMs"><a href="#JobRecoGPT-–-Explainable-job-recommendations-using-LLMs" class="headerlink" title="JobRecoGPT – Explainable job recommendations using LLMs"></a>JobRecoGPT – Explainable job recommendations using LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11805">http://arxiv.org/abs/2309.11805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Preetam Ghosh, Vaishali Sadaphal</li>
<li>for: 这个论文是为了推荐适合候选人的工作而写的。</li>
<li>methods: 这篇论文使用了人工智能技术，特别是大语言模型（LLMs）来捕捉原文中的信息，以便更好地推荐适合候选人的工作。</li>
<li>results: 这篇论文 comparing了四种不同的方法，即内容基于的决定方法、LLM指导的方法、LLM无指导的方法以及混合方法，并评估了每种方法的时间需求和性能。<details>
<summary>Abstract</summary>
In today's rapidly evolving job market, finding the right opportunity can be a daunting challenge. With advancements in the field of AI, computers can now recommend suitable jobs to candidates. However, the task of recommending jobs is not same as recommending movies to viewers. Apart from must-have criteria, like skills and experience, there are many subtle aspects to a job which can decide if it is a good fit or not for a given candidate. Traditional approaches can capture the quantifiable aspects of jobs and candidates, but a substantial portion of the data that is present in unstructured form in the job descriptions and resumes is lost in the process of conversion to structured format. As of late, Large Language Models (LLMs) have taken over the AI field by storm with extraordinary performance in fields where text-based data is available. Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form. To this end, we compare performance of four different approaches for job recommendations namely, (i) Content based deterministic, (ii) LLM guided, (iii) LLM unguided, and (iv) Hybrid. In this study, we present advantages and limitations of each method and evaluate their performance in terms of time requirements.
</details>
<details>
<summary>摘要</summary>
Recently, Large Language Models (LLMs) have revolutionized the AI field with extraordinary performance in text-based data. Inspired by their capabilities, we leverage their ability to understand natural language to capture the information that was previously lost during the conversion of unstructured data to a structured form. To achieve this, we compare the performance of four different approaches for job recommendations:1. Content-based deterministic approach2. LLM-guided approach3. LLM unguided approach4. Hybrid approachIn this study, we present the advantages and limitations of each method and evaluate their performance in terms of time requirements.
</details></li>
</ul>
<hr>
<h2 id="DimCL-Dimensional-Contrastive-Learning-For-Improving-Self-Supervised-Learning"><a href="#DimCL-Dimensional-Contrastive-Learning-For-Improving-Self-Supervised-Learning" class="headerlink" title="DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning"></a>DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11782">http://arxiv.org/abs/2309.11782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanh Nguyen, Trung Pham, Chaoning Zhang, Tung Luu, Thang Vu, Chang D. Yoo</li>
<li>for: 提高自动学习（SSL）的表现，增强特征多样性</li>
<li>methods: 维度对冲学习（DimCL），一种在维度方向进行对冲学习而不是批处理方向的新方法</li>
<li>results: 在多个数据集和背景架构上实现了表现的提高，并且发现了困难度感知的特性对其成功起到了关键作用<details>
<summary>Abstract</summary>
Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance improvement by a non-trivial margin on various datasets and backbone architectures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="2DDATA-2D-Detection-Annotations-Transmittable-Aggregation-for-Semantic-Segmentation-on-Point-Cloud"><a href="#2DDATA-2D-Detection-Annotations-Transmittable-Aggregation-for-Semantic-Segmentation-on-Point-Cloud" class="headerlink" title="2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud"></a>2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11755">http://arxiv.org/abs/2309.11755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guan-Cheng Lee</li>
<li>for: 这篇论文目的是提出一种解决多感器模型中精度准确性问题的方法，使得这些模型能够在实际应用中使用。</li>
<li>methods: 这篇论文使用了2D检测注释传输汇聚(\textbf{2DDATA})方法，并设计了一个本地对象分支(\textbf{Local Object Branch})来处理点云数据。</li>
<li>results: 研究人员通过实验证明了他们的简单设计可以传输矩形盒注释信息到3D编码器模型，证明了大型多感器模型与模态特定数据的混合是可能的。<details>
<summary>Abstract</summary>
Recently, multi-modality models have been introduced because of the complementary information from different sensors such as LiDAR and cameras. It requires paired data along with precise calibrations for all modalities, the complicated calibration among modalities hugely increases the cost of collecting such high-quality datasets, and hinder it from being applied to practical scenarios. Inherit from the previous works, we not only fuse the information from multi-modality without above issues, and also exhaust the information in the RGB modality. We introduced the 2D Detection Annotations Transmittable Aggregation(\textbf{2DDATA}), designing a data-specific branch, called \textbf{Local Object Branch}, which aims to deal with points in a certain bounding box, because of its easiness of acquiring 2D bounding box annotations. We demonstrate that our simple design can transmit bounding box prior information to the 3D encoder model, proving the feasibility of large multi-modality models fused with modality-specific data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improve-the-efficiency-of-deep-reinforcement-learning-through-semantic-exploration-guided-by-natural-language"><a href="#Improve-the-efficiency-of-deep-reinforcement-learning-through-semantic-exploration-guided-by-natural-language" class="headerlink" title="Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language"></a>Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11753">http://arxiv.org/abs/2309.11753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhourui Guo, Meng Yao, Yang Yu, Qiyue Yin</li>
<li>for: 本文提出了一种新的方法，用于在RL中选择性地使用oracle，以提高RL的效率。</li>
<li>methods: 本文使用了一种模板问题和答案的方法，通过对 previous interactions 的整合，使用神经网络对当前状态和oracle的编码，并从corpus中检索最相关的问题。</li>
<li>results: 本文在一个物体把握任务上进行了评估，显示了 compared to基线方法，使用oracle可以显著提高RL的效率，减少RL需要进行的交互数量。<details>
<summary>Abstract</summary>
Reinforcement learning is a powerful technique for learning from trial and error, but it often requires a large number of interactions to achieve good performance. In some domains, such as sparse-reward tasks, an oracle that can provide useful feedback or guidance to the agent during the learning process is really of great importance. However, querying the oracle too frequently may be costly or impractical, and the oracle may not always have a clear answer for every situation. Therefore, we propose a novel method for interacting with the oracle in a selective and efficient way, using a retrieval-based approach. We assume that the interaction can be modeled as a sequence of templated questions and answers, and that there is a large corpus of previous interactions available. We use a neural network to encode the current state of the agent and the oracle, and retrieve the most relevant question from the corpus to ask the oracle. We then use the oracle's answer to update the agent's policy and value function. We evaluate our method on an object manipulation task. We show that our method can significantly improve the efficiency of RL by reducing the number of interactions needed to reach a certain level of performance, compared to baselines that do not use the oracle or use it in a naive way.
</details>
<details>
<summary>摘要</summary>
�� Reinforcement learning 是一种强大的学习技术，但它经常需要大量的交互来达到良好的性能。在某些领域，如稀谱奖励任务，一个 oracle 可以提供有用的反馈或指导 для Agent  durante el proceso de aprendizaje。然而，请求 oracle 的频率可能是成本高或实际不切实际的，而且 oracle 并不总是有清晰的答案对每个情况。因此，我们提出了一种新的方法来与 oracle 交互，使用一种检索基本的方法。我们假设交互可以被模型为一个序列化的问题和答案，并且有一大量的前期交互数据库。我们使用神经网络来编码 Agent 和 oracle 的当前状态，并从数据库中检索最相关的问题来问 oracle。然后，我们使用 oracle 的答案来更新 Agent 的政策和价值函数。我们在一个物体抓取任务上评估了我们的方法，并显示了我们的方法可以减少 RL 中交互的次数，以达到一定的性能水平，相比于不使用 oracle 或使用它的做法。
</details></li>
</ul>
<hr>
<h2 id="How-Robust-is-Google’s-Bard-to-Adversarial-Image-Attacks"><a href="#How-Robust-is-Google’s-Bard-to-Adversarial-Image-Attacks" class="headerlink" title="How Robust is Google’s Bard to Adversarial Image Attacks?"></a>How Robust is Google’s Bard to Adversarial Image Attacks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11751">http://arxiv.org/abs/2309.11751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-ml/attack-bard">https://github.com/thu-ml/attack-bard</a></li>
<li>paper_authors: Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu</li>
<li>for: 这研究旨在研究Google的Bard chatbot的抗击型识别器 robustness，以便更好地理解商业多模态大语言模型（MLLMs）中的漏洞。</li>
<li>methods: 我们使用了白盒子代理视觉编码器或 MLLMs 进行攻击，生成了对 Bard 的 adversarial examples，并证明了这些攻击可以让 Bard 输出错误的图像描述。</li>
<li>results: 我们发现，对 Bard 的 adversarial examples 可以达到 22% 的成功率，并且可以攻击其他 MLLMs，如 Bing Chat 和 ERNIE bot。此外，我们还发现了 Bard 的两种防御机制，包括图像检测和图像攻击检测。我们设计了对这些防御机制的攻击，证明了现有的防御机制也是易于绕过的。<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection and toxicity detection of images. We design corresponding attacks to evade these defenses, demonstrating that the current defenses of Bard are also vulnerable. We hope this work can deepen our understanding on the robustness of MLLMs and facilitate future research on defenses. Our code is available at https://github.com/thu-ml/Attack-Bard.
</details>
<details>
<summary>摘要</summary>
多模态大语言模型（MLLMs），尤其是与视觉相结合，在多种多 modal 任务中表现出色。然而，由于视觉模型的不可预测性问题，MLLMs 可能带来更严重的安全和安全风险。在这项工作中，我们研究了Google的Bard，一个与 ChatGPT 竞争的聊天机器人，以更好地理解商业MLLMs 的漏洞。我们发现，通过攻击白盒子代理视觉encoder或 MLLMs，可以生成 adversarial 例子，导致 Bard 输出错误的图像描述，成功率达22%。此外，我们发现这些 adversarial 例子还可以攻击其他 MLLMs，例如 Bing Chat 和 ERNIE 机器人。此外，我们还发现 Bard 具有两种防御机制：脸部检测和图像攻击检测。我们设计了相应的攻击，证明现有防御机制也是易攻击的。我们希望这项工作可以深入我们对 MLLMs 的稳定性和防御机制的理解，并促进未来研究。我们的代码可以在 <https://github.com/thu-ml/Attack-Bard> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Choice-75-A-Dataset-on-Decision-Branching-in-Script-Learning"><a href="#Choice-75-A-Dataset-on-Decision-Branching-in-Script-Learning" class="headerlink" title="Choice-75: A Dataset on Decision Branching in Script Learning"></a>Choice-75: A Dataset on Decision Branching in Script Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11737">http://arxiv.org/abs/2309.11737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyi Joey Hou, Li Zhang, Chris Callison-Burch</li>
<li>for: 本研究旨在探讨日常事件的发展过程。</li>
<li>methods: 本研究使用 Choice-75  benchmark，该 benchmark 包含 75 个场景和超过 600 个enario，以测试智能系统在面对描述性场景时的决策能力。</li>
<li>results: 大型语言模型在总体上表现不错，但在许多困难场景下仍有很大的进攻空间。<details>
<summary>Abstract</summary>
Script learning studies how daily events unfold. Previous works tend to consider a script as a linear sequence of events while ignoring the potential branches that arise due to people's circumstantial choices. We hence propose Choice-75, the first benchmark that challenges intelligent systems to predict decisions given descriptive scenarios, containing 75 scripts and more than 600 scenarios. While large language models demonstrate overall decent performances, there is still notable room for improvement in many hard scenarios.
</details>
<details>
<summary>摘要</summary>
学习脚本研究每日事件的发展。先前的工作通常将脚本视为一个直线性的事件序列，忽略人们因 circumstance 的选择所导致的可能的分支。我们因此提出了 Choice-75，首个挑战智能系统预测基于描述场景的决策，包含75个脚本和超过600个场景。虽然大语言模型在总体上表现不错，但在许多困难场景中仍有很大的改进空间。
</details></li>
</ul>
<hr>
<h2 id="FluentEditor-Text-based-Speech-Editing-by-Considering-Acoustic-and-Prosody-Consistency"><a href="#FluentEditor-Text-based-Speech-Editing-by-Considering-Acoustic-and-Prosody-Consistency" class="headerlink" title="FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency"></a>FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11725">http://arxiv.org/abs/2309.11725</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-s2-lab/fluenteditor">https://github.com/ai-s2-lab/fluenteditor</a></li>
<li>paper_authors: Rui Liu, Jiatian Xi, Ziyue Jiang, Haizhou Li</li>
<li>for: 提高语音编辑技术的自然性和流畅性</li>
<li>methods: 使用fluency-aware训练 критерий，包括音频一致性约束和语调一致性约束</li>
<li>results: 对VCTK数据集进行subjective和objective эксперименты，表明我们的FluentEditor模型在自然性和流畅性方面具有显著优势，Audioamples和代码可以在github上获取<details>
<summary>Abstract</summary>
Text-based speech editing (TSE) techniques are designed to enable users to edit the output audio by modifying the input text transcript instead of the audio itself. Despite much progress in neural network-based TSE techniques, the current techniques have focused on reducing the difference between the generated speech segment and the reference target in the editing region, ignoring its local and global fluency in the context and original utterance. To maintain the speech fluency, we propose a fluency speech editing model, termed \textit{FluentEditor}, by considering fluency-aware training criterion in the TSE training. Specifically, the \textit{acoustic consistency constraint} aims to smooth the transition between the edited region and its neighboring acoustic segments consistent with the ground truth, while the \textit{prosody consistency constraint} seeks to ensure that the prosody attributes within the edited regions remain consistent with the overall style of the original utterance. The subjective and objective experimental results on VCTK demonstrate that our \textit{FluentEditor} outperforms all advanced baselines in terms of naturalness and fluency. The audio samples and code are available at \url{https://github.com/Ai-S2-Lab/FluentEditor}.
</details>
<details>
<summary>摘要</summary>
文本基于的语音修编（TSE）技术是为了让用户通过修改输入文本脚本而不是直接修改音频来编辑语音。虽然现有的神经网络基于TSE技术已经做出了很大的进步，但是现有的技术都是关注在编辑区域中减少生成的语音段与参照标题之间的差异，而忽略了当地和全局的流畅性。为保持语音流畅，我们提议一种流畅语音修编模型，称为“流畅编辑器”，通过考虑流畅意识训练 criterion 在 TSE 训练中来实现。具体来说，“语音一致性约束”是为了使编辑区域和其邻近的语音段之间的过渡变得更加平滑，与真实的语音一致；而“表情一致性约束”则是为了确保在编辑区域中的表情特征与原始语音的整体风格保持一致。对于 VCTK 的实验结果表明，我们的“流畅编辑器”在自然性和流畅性两个方面都超过了所有高级基elines。听音样本和代码可以在 GitHub 上找到：https://github.com/Ai-S2-Lab/FluentEditor。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Aware-Prosodic-Phrasing-for-Expressive-Text-to-Speech"><a href="#Emotion-Aware-Prosodic-Phrasing-for-Expressive-Text-to-Speech" class="headerlink" title="Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech"></a>Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11724">http://arxiv.org/abs/2309.11724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-s2-lab/emopp">https://github.com/ai-s2-lab/emopp</a></li>
<li>paper_authors: Rui Liu, Bin Liu, Haizhou Li</li>
<li>for: 这篇论文的目的是提出一种能够准确地捕捉语音中情感信息的情感意识排序模型（EmoPP），以便更好地表达情感。</li>
<li>methods: 这篇论文使用了对ESD数据集的 объектив观察，以验证情感和排序之间的强相关性。然后，对比了基eline和EmoPP模型，并进行了对比性和主观评价。</li>
<li>results: 研究结果表明，EmoPP模型在情感表达方面表现出色，与基eline模型相比，具有更高的表达效果和准确性。code和音频样本可以在github上下载。<details>
<summary>Abstract</summary>
Prosodic phrasing is crucial to the naturalness and intelligibility of end-to-end Text-to-Speech (TTS). There exist both linguistic and emotional prosody in natural speech. As the study of prosodic phrasing has been linguistically motivated, prosodic phrasing for expressive emotion rendering has not been well studied. In this paper, we propose an emotion-aware prosodic phrasing model, termed \textit{EmoPP}, to mine the emotional cues of utterance accurately and predict appropriate phrase breaks. We first conduct objective observations on the ESD dataset to validate the strong correlation between emotion and prosodic phrasing. Then the objective and subjective evaluations show that the EmoPP outperforms all baselines and achieves remarkable performance in terms of emotion expressiveness. The audio samples and the code are available at \url{https://github.com/AI-S2-Lab/EmoPP}.
</details>
<details>
<summary>摘要</summary>
“句子间的调音是 тек字至话（TTS）的自然和可理解性的关键。自然语言中存在语言和情感的调音。由于研究调音 phrasing 的动机主要是语言学的，因此对于表达情感的调音 phrasing 尚未受到充分研究。在这篇文章中，我们提出了一个情感认知的调音 phrasing 模型，称为 EmoPP，以精确地捕捉说话中的情感讯号和适当的分割点。我们首先通过对 ESD dataset 的 объектив观察， Validate 调音 phrasing 和情感之间的强相关。然后，对比性和主观评价显示，EmoPP 在情感表达方面具有很高的表现。另外，我们还提供了 Audio 示例和代码，可以在 GitHub 上找到。”Note that Simplified Chinese uses a different set of characters and grammar compared to Traditional Chinese, so the translation may differ slightly from the original text.
</details></li>
</ul>
<hr>
<h2 id="A-Dynamic-Domain-Adaptation-Deep-Learning-Network-for-EEG-based-Motor-Imagery-Classification"><a href="#A-Dynamic-Domain-Adaptation-Deep-Learning-Network-for-EEG-based-Motor-Imagery-Classification" class="headerlink" title="A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification"></a>A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11714">http://arxiv.org/abs/2309.11714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Jiao, Meiyan Xu, Qingqing Chen, Hefan Zhou, Wangliang Zhou</li>
<li>for: 提高 EEG 基于脑机器人接口的精度和效率，以及适应不同个体和Session 间的差异。</li>
<li>methods: 提议使用动态领域适应深度学习网络 (DADL-Net)，通过3D 卷积模块学习 EEG 数据的三维几何特征，然后使用空间通道注意力机制加强特征，并使用最大平均差分损失函数适应不同个体和Session 间的差异。</li>
<li>results: 在 BCI 竞赛 IV 2a 和 OpenBMI 数据集上验证了提议的方法，实现了70.42% 和73.91% 的准确率。<details>
<summary>Abstract</summary>
There is a correlation between adjacent channels of electroencephalogram (EEG), and how to represent this correlation is an issue that is currently being explored. In addition, due to inter-individual differences in EEG signals, this discrepancy results in new subjects need spend a amount of calibration time for EEG-based motor imagery brain-computer interface. In order to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net). First, the EEG data is mapped to the three-dimensional geometric space and its temporal-spatial features are learned through the 3D convolution module, and then the spatial-channel attention mechanism is used to strengthen the features, and the final convolution module can further learn the spatial-temporal information of the features. Finally, to account for inter-subject and cross-sessions differences, we employ a dynamic domain-adaptive strategy, the distance between features is reduced by introducing a Maximum Mean Discrepancy loss function, and the classification layer is fine-tuned by using part of the target domain data. We verify the performance of the proposed method on BCI competition IV 2a and OpenBMI datasets. Under the intra-subject experiment, the accuracy rates of 70.42% and 73.91% were achieved on the OpenBMI and BCIC IV 2a datasets.
</details>
<details>
<summary>摘要</summary>
“electroencephalogram（EEG）附近通道之间存在相关性，但如何表示这种相关性是目前正在探索的问题。此外，由于EEG信号间的差异，需要新的训练时间以便EEG基于脑神经接口。为解决上述问题，我们提出了动态领域适应基于深度学习网络（DADL-Net）。首先，EEG数据会被对三维几何空间中的映射，并通过3D梯度层学习三维空间中的特征，然后使用空间频道注意力机制来强化特征，最后通过最后一个梯度层学习特征的空间-时间信息。为了考虑对象和跨会议差异，我们使用动态领域适应策略，将特征之间的距离降低，并使用Maximum Mean Discrepancy损失函数微调分类层。我们证明提案的方法在BCI竞赛IV 2a和OpenBMI数据集上表现出色。在内部实验中，OpenBMI和BCIC IV 2a数据集的准确率分别为70.42%和73.91%。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.AI_2023_09_21/" data-id="clnsn0vdc004bgf88hb35ha2g" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/21/cs.CV_2023_09_21/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-09-21
        
      </div>
    </a>
  
  
    <a href="/2023/09/21/cs.CL_2023_09_21/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-09-21</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">78</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">35</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">78</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">22</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">150</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
