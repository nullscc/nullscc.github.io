
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-09-12 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Efficient Post-processing of Diffusion Tensor Cardiac Magnetic Imaging Using Texture-conserving Deformable Registration paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.06598 repo_url: None paper_authors: Fanwen">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-09-12">
<meta property="og:url" content="https://nullscc.github.io/2023/09/12/eess.IV_2023_09_12/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Efficient Post-processing of Diffusion Tensor Cardiac Magnetic Imaging Using Texture-conserving Deformable Registration paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.06598 repo_url: None paper_authors: Fanwen">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-09-12T09:00:00.000Z">
<meta property="article:modified_time" content="2023-09-14T20:38:20.162Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_09_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/12/eess.IV_2023_09_12/" class="article-date">
  <time datetime="2023-09-12T09:00:00.000Z" itemprop="datePublished">2023-09-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-09-12
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Post-processing-of-Diffusion-Tensor-Cardiac-Magnetic-Imaging-Using-Texture-conserving-Deformable-Registration"><a href="#Efficient-Post-processing-of-Diffusion-Tensor-Cardiac-Magnetic-Imaging-Using-Texture-conserving-Deformable-Registration" class="headerlink" title="Efficient Post-processing of Diffusion Tensor Cardiac Magnetic Imaging Using Texture-conserving Deformable Registration"></a>Efficient Post-processing of Diffusion Tensor Cardiac Magnetic Imaging Using Texture-conserving Deformable Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06598">http://arxiv.org/abs/2309.06598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanwen Wang, Pedro F. Ferreira, Yinzhe Wu, Andrew D. Scott, Camila Munoz, Ke Wen, Yaqing Luo, Jiahao Huang, Sonia Nielles-Vallespin, Dudley J. Pennell, Guang Yang</li>
<li>For: 提供非侵入式myocardial微结构测量方法* Methods: 使用深度学习基于B-spline网络进行抽象 registratin，利用低级特征减少杂变信息和扩散编码器-解码器来抑制扩散编码器所带来的噪声* Results: 提高了帧使用效率、手动剪辑和计算速度<details>
<summary>Abstract</summary>
Diffusion tensor based cardiac magnetic resonance (DT-CMR) is a method capable of providing non-invasive measurements of myocardial microstructure. Image registration is essential to correct image shifts due to intra and inter breath-hold motion. Registration is challenging in DT-CMR due to the low signal-to-noise and various contrasts induced by the diffusion encoding in the myocardial and surrounding organs. Traditional deformable registration destroys the texture information while rigid registration inefficiently discards frames with local deformation. In this study, we explored the possibility of deep learning-based deformable registration on DT- CMR. Based on the noise suppression using low-rank features and diffusion encoding suppression using variational auto encoder-decoder, a B-spline based registration network extracted the displacement fields and maintained the texture features of DT-CMR. In this way, our method improved the efficiency of frame utilization, manual cropping, and computational speed.
</details>
<details>
<summary>摘要</summary>
Diffusion tensor based cardiac magnetic resonance (DT-CMR) 是一种可提供非侵入性测量心肌微结构的方法。图像 регистрация是DT-CMR中必须的，因为图像偏移导致了呼吸和心跳停顿中的移动。但是，DT-CMR中的图像registratio是困难的，因为低信号噪声和diffusion编码器在心肌和周围器官中引起的多种对比。传统的可变形 регистраción会将文件中的纹理信息遗弃，而固定 registratio则不具有地方性的损失。在这项研究中，我们探索了基于深度学习的可变形 регистраción的可能性。通过噪声抑制使用低级别特征和diffusion编码器抑制使用自适应神经网络，我们提出了一种使用B-spline基本注意力网络提取displacement场和保留DT-CMR中的纹理特征。这种方法可以提高帧使用效率、手动剪辑和计算速度。
</details></li>
</ul>
<hr>
<h2 id="AGMDT-Virtual-Staining-of-Renal-Histology-Images-with-Adjacency-Guided-Multi-Domain-Transfer"><a href="#AGMDT-Virtual-Staining-of-Renal-Histology-Images-with-Adjacency-Guided-Multi-Domain-Transfer" class="headerlink" title="AGMDT: Virtual Staining of Renal Histology Images with Adjacency-Guided Multi-Domain Transfer"></a>AGMDT: Virtual Staining of Renal Histology Images with Adjacency-Guided Multi-Domain Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06421">http://arxiv.org/abs/2309.06421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Ma, Chao Zhang, Min Lu, Lin Luo</li>
<li>for:  This paper aims to propose a novel virtual staining framework to translate images into other domains, avoiding pixel-level alignment and utilizing correlations among adjacent tissue slices.</li>
<li>methods: The proposed framework AGMDT uses a high-quality multi-domain renal histological dataset, glomerulus detection, and bipartite graph matching to discover patch-level aligned pairs across serial slices of multi-domains, and utilizes such correlations to supervise the end-to-end model for multi-domain staining transformation.</li>
<li>results: The experimental results show that the proposed AGMDT achieves a good balance between precise pixel-level alignment and unpaired domain transfer by exploiting correlations across multi-domain serial pathological slices, and outperforms the state-of-the-art methods in both quantitative measure and morphological details.<details>
<summary>Abstract</summary>
Renal pathology, as the gold standard of kidney disease diagnosis, requires doctors to analyze a serial of tissue slices stained by H\&E staining and special staining like Masson, PASM, and PAS, respectively. These special staining methods are costly, time-consuming, and hard to standardize for wide use especially in primary hospitals. Advances of supervised learning methods can virtually convert H\&E images into special staining images, but the pixel-to-pixel alignment is hard to achieve for training. As contrast, unsupervised learning methods regarding different stains as different style transferring domains can use unpaired data, but they ignore the spatial inter-domain correlations and thus decrease the trustworthiness of structural details for diagnosis. In this paper, we propose a novel virtual staining framework AGMDT to translate images into other domains by avoiding pixel-level alignment and meanwhile utilizing the correlations among adjacent tissue slices. We first build a high-quality multi-domain renal histological dataset where each specimen case comprises a series of slices stained in various ways. Based on it, the proposed framework AGMDT discovers patch-level aligned pairs across the serial slices of multi-domains through glomerulus detection and bipartite graph matching, and utilizes such correlations to supervise the end-to-end model for multi-domain staining transformation. Experimental results show that the proposed AGMDT achieves a good balance between the precise pixel-level alignment and unpaired domain transfer by exploiting correlations across multi-domain serial pathological slices, and outperforms the state-of-the-art methods in both quantitative measure and morphological details.
</details>
<details>
<summary>摘要</summary>
肾脏病学，作为肾脏疾病诊断的标准方法，需要医生分析一系列染色的组织切片，包括H\&E染色和特殊染色如Masson、PASM和PAS等。这些特殊染色方法是成本高、时间耗费和标准化困难，特别是在初级医院中使用。随着超vised learning方法的进步，可以虚拟转换H\&E图像为特殊染色图像，但是像素级匹配困难以实现训练。相比之下，无监督学习方法，将不同染色视为不同的样式传输领域，可以使用无配对数据，但是忽略了组织间的空间相互关系，因此降低了诊断中结构细节的可靠性。在这篇论文中，我们提出了一种新的虚拟染色框架AGMDT，可以将图像转换到其他领域，而不需要像素级匹配。我们首先构建了高质量多频道肾脏 histological 数据集，每个案例包含一系列各种染色的组织切片。基于这个数据集，我们的框架AGMDT 在多频道串行切片中找到对应的patch级匹配，并利用这些相关性来监督终端模型进行多频道染色转换。实验结果表明，我们的AGMDT 能够在保持像素级匹配的同时，通过利用多频道串行切片之间的相关性，superior 于当前状态艺术方法，并且在量度 mesure 和结构细节方面都达到了更好的平衡。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-Capability-of-Deep-Learning-Based-Nuclei-Instance-Segmentation-by-Non-deterministic-Train-Time-and-Deterministic-Test-Time-Stain-Normalization"><a href="#Improving-Generalization-Capability-of-Deep-Learning-Based-Nuclei-Instance-Segmentation-by-Non-deterministic-Train-Time-and-Deterministic-Test-Time-Stain-Normalization" class="headerlink" title="Improving Generalization Capability of Deep Learning-Based Nuclei Instance Segmentation by Non-deterministic Train Time and Deterministic Test Time Stain Normalization"></a>Improving Generalization Capability of Deep Learning-Based Nuclei Instance Segmentation by Non-deterministic Train Time and Deterministic Test Time Stain Normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06143">http://arxiv.org/abs/2309.06143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirreza Mahbod, Georg Dorffner, Isabella Ellinger, Ramona Woitek, Sepideh Hatamikia</li>
<li>for:  This paper aims to improve the generalization capability of a deep learning-based automatic segmentation approach for nuclei instance segmentation in digital pathology.</li>
<li>methods:  The proposed method incorporates non-deterministic train time and deterministic test time stain normalization, and uses one single training set to evaluate the segmentation performance on seven test datasets.</li>
<li>results:  The proposed method provides up to 5.77%, 5.36%, and 5.27% better performance in segmenting nuclei based on Dice score, aggregated Jaccard index, and panoptic quality score, respectively, compared to the baseline segmentation model.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是提高深度学习基于自动分割模型的总化能力，用于核实体分割在数字病理学中。</li>
<li>methods: 该方法使用非束定训练时间和固定测试时间杯Normalization，使用单一训练集来评估分割性能在七个测试集上。</li>
<li>results: 该方法提供了基于Dice分数、积合Jacard指数和总质量分数的5.77%、5.36%和5.27%的提升，相比基准分割模型。<details>
<summary>Abstract</summary>
With the advent of digital pathology and microscopic systems that can scan and save whole slide histological images automatically, there is a growing trend to use computerized methods to analyze acquired images. Among different histopathological image analysis tasks, nuclei instance segmentation plays a fundamental role in a wide range of clinical and research applications. While many semi- and fully-automatic computerized methods have been proposed for nuclei instance segmentation, deep learning (DL)-based approaches have been shown to deliver the best performances. However, the performance of such approaches usually degrades when tested on unseen datasets.   In this work, we propose a novel approach to improve the generalization capability of a DL-based automatic segmentation approach. Besides utilizing one of the state-of-the-art DL-based models as a baseline, our method incorporates non-deterministic train time and deterministic test time stain normalization. We trained the model with one single training set and evaluated its segmentation performance on seven test datasets. Our results show that the proposed method provides up to 5.77%, 5.36%, and 5.27% better performance in segmenting nuclei based on Dice score, aggregated Jaccard index, and panoptic quality score, respectively, compared to the baseline segmentation model.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a novel approach to improve the generalization capability of a DL-based automatic segmentation approach. Our method incorporates non-deterministic train time and deterministic test time stain normalization. We trained the model with one single training set and evaluated its segmentation performance on seven test datasets. Our results show that the proposed method provides up to 5.77%, 5.36%, and 5.27% better performance in segmenting nuclei based on Dice score, aggregated Jaccard index, and panoptic quality score, respectively, compared to the baseline segmentation model.
</details></li>
</ul>
<hr>
<h2 id="Batch-Implicit-Neural-Representation-for-MRI-Parallel-Reconstruction"><a href="#Batch-Implicit-Neural-Representation-for-MRI-Parallel-Reconstruction" class="headerlink" title="Batch Implicit Neural Representation for MRI Parallel Reconstruction"></a>Batch Implicit Neural Representation for MRI Parallel Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06067">http://arxiv.org/abs/2309.06067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Li, Yusheng Zhou, Jianan Liu, Xiling Liu, Tao Huang, Zhihan Lv</li>
<li>for: 提高MRI扫描时间的问题</li>
<li>methods: 使用深度学习方法来重建MRI图像</li>
<li>results: 提出一种基于INR的新型MRI重建方法，可以在不同的抽样率下重建高质量图像，并且比其他重建方法有更好的性能<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) always suffered from the problem of long acquisition time. MRI reconstruction is one solution to reduce scan time by skipping certain phase-encoding lines and then restoring high-quality images from undersampled measurements. Recently, implicit neural representation (INR) has emerged as a new deep learning method that represents an object as a continuous function of spatial coordinates, and this function is normally parameterized by a multilayer perceptron (MLP). In this paper, we propose a novel MRI reconstruction method based on INR, which represents the fully-sampled images as the function of pixel coordinates and prior feature vectors of undersampled images for overcoming the generalization problem of INR. Specifically, we introduce a scale-embedded encoder to produce scale-independent pixel-specific features from MR images with different undersampled scales and then concatenate with coordinates vectors to recover fully-sampled MR images via an MLP, thus achieving arbitrary scale reconstruction. The performance of the proposed method was assessed by experimenting on publicly available MRI datasets and compared with other reconstruction methods. Our quantitative evaluation demonstrates the superiority of the proposed method over alternative reconstruction methods.
</details>
<details>
<summary>摘要</summary>
magnetic resonance imaging (MRI) 总是受到长期取样时间的困扰。MRI 重建是一种解决方案，可以降低扫描时间，通过略过certain phase-encoding lines并使用受损量测量来重建高质量图像。最近，implicit neural representation (INR)  emerged as a new deep learning method，可以将对象 Represented as a continuous function of spatial coordinates，通常通过多层感知器 (MLP) 进行参数化。在这篇论文中，我们提出了一种基于 INR 的新的 MRI 重建方法。specifically，我们引入了 scale-embedded encoder 来生成不同抽样缩放的 MR 图像中的scale-independent pixel-specific features，然后将坐标向量 concatenate 以重建完全扫描的 MR 图像，实现任意缩放重建。我们对公共可用的 MRI 数据集进行实验，与其他重建方法进行比较。我们的量化评估表明提出的方法在比较方法中表现出优异。
</details></li>
</ul>
<hr>
<h2 id="A-new-meteor-detection-application-robust-to-camera-movements"><a href="#A-new-meteor-detection-application-robust-to-camera-movements" class="headerlink" title="A new meteor detection application robust to camera movements"></a>A new meteor detection application robust to camera movements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06027">http://arxiv.org/abs/2309.06027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clara Ciocan, Mathuran Kandeepan, Adrien Cassagne, Jeremie Vaubaillon, Fabian Zander, Lionel Lacassagne</li>
<li>for: 本研究开发了一个新的自动探测流星工具箱 (FMDT)，用于检测天文学上的流星视域。</li>
<li>methods: FMDT使用了视觉摄影机里的当地摄影机或在飞机上的稳定镜头拍摄的影片进行分析，以探测流星视域。</li>
<li>results: FMDT可以实现高精度的流星探测，并且可以在实时运算25帧每秒的影片，且仅占用10瓦的电力。<details>
<summary>Abstract</summary>
This article presents a new tool for the automatic detection of meteors. Fast Meteor Detection Toolbox (FMDT) is able to detect meteor sightings by analyzing videos acquired by cameras onboard weather balloons or within airplane with stabilization. The challenge consists in designing a processing chain composed of simple algorithms, that are robust to the high fluctuation of the videos and that satisfy the constraints on power consumption (10 W) and real-time processing (25 frames per second).
</details>
<details>
<summary>摘要</summary>
本文介绍了一个新的自动探测陨石工具。快速陨石探测工具箱（FMDT）可以通过分析天气气球或飞机上的摄像头获取的视频来探测陨石见解。挑战在于设计一个简单的处理链，该链需要对视频高异常性具有鲁棒性，并满足功率消耗（10 W）和实时处理（25帧每秒）的限制。
</details></li>
</ul>
<hr>
<h2 id="RGB-Guided-Resolution-Enhancement-of-IR-Images"><a href="#RGB-Guided-Resolution-Enhancement-of-IR-Images" class="headerlink" title="RGB-Guided Resolution Enhancement of IR Images"></a>RGB-Guided Resolution Enhancement of IR Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05996">http://arxiv.org/abs/2309.05996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcel Trammer, Nils Genser, Jürgen Seiler</li>
<li>for: 提高低分辨率红外图像的空间分辨率</li>
<li>methods: 使用多摄像头和色彩摄像头的组合，以及RGB准则引导的分辨率提高技术</li>
<li>results: 对比现有方法，实现了1.2dB至1.8dB的PSNR提升，可见的提高分辨率<details>
<summary>Abstract</summary>
This paper introduces a novel method for RGB-Guided Resolution Enhancement of infrared (IR) images called Guided IR Resolution Enhancement (GIRRE). In the area of single image super resolution (SISR) there exists a wide variety of algorithms like interpolation methods or neural networks to improve the spatial resolution of images. In contrast to SISR, even more information can be gathered on the recorded scene when using multiple cameras. In our setup, we are dealing with multi image super resolution, especially with stereo super resolution. We consider a color camera and an IR camera. Current IR sensors have a very low resolution compared to color sensors so that recent color sensors take up 100 times more pixels than IR sensors. To this end, GIRRE increases the spatial resolution of the low-resolution IR image. After that, the upscaled image is filtered with the aid of the high-resolution color image. We show that our method achieves an average PSNR gain of 1.2 dB and at best up to 1.8 dB compared to state-of-the-art methods, which is visually noticeable.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Introducing-Shape-Prior-Module-in-Diffusion-Model-for-Medical-Image-Segmentation"><a href="#Introducing-Shape-Prior-Module-in-Diffusion-Model-for-Medical-Image-Segmentation" class="headerlink" title="Introducing Shape Prior Module in Diffusion Model for Medical Image Segmentation"></a>Introducing Shape Prior Module in Diffusion Model for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05929">http://arxiv.org/abs/2309.05929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqing Zhang, Guojia Fan, Tianyong Liu, Nan Li, Yuyang Liu, Ziyu Liu, Canwei Dong, Shoujun Zhou</li>
<li>for: 这个研究是为了提供高精度且多样化的骨科医照图像分类模板，以支持骨科医生在临床实践中。</li>
<li>methods: 我们提出了一个终端架构 called VerseDiff-UNet，它结合了去噪扩展probabilistic模型（DDPM）和标准的U型架构。在每个步骤中，我们结合了噪音添加的图像和标签mask来导引扩展方向精确地向目标区域。此外，我们还包括了一个形态先验模块，以提取医照图像中的结构semantic信息。</li>
<li>results: 我们在一个单一的骨科医照图像数据集上评估了我们的方法，结果显示VerseDiff-UNet在精度方面明显超过了其他现有的方法，同时保持了医照图像的自然特征和变化。<details>
<summary>Abstract</summary>
Medical image segmentation is critical for diagnosing and treating spinal disorders. However, the presence of high noise, ambiguity, and uncertainty makes this task highly challenging. Factors such as unclear anatomical boundaries, inter-class similarities, and irrational annotations contribute to this challenge. Achieving both accurate and diverse segmentation templates is essential to support radiologists in clinical practice. In recent years, denoising diffusion probabilistic modeling (DDPM) has emerged as a prominent research topic in computer vision. It has demonstrated effectiveness in various vision tasks, including image deblurring, super-resolution, anomaly detection, and even semantic representation generation at the pixel level. Despite the robustness of existing diffusion models in visual generation tasks, they still struggle with discrete masks and their various effects. To address the need for accurate and diverse spine medical image segmentation templates, we propose an end-to-end framework called VerseDiff-UNet, which leverages the denoising diffusion probabilistic model (DDPM). Our approach integrates the diffusion model into a standard U-shaped architecture. At each step, we combine the noise-added image with the labeled mask to guide the diffusion direction accurately towards the target region. Furthermore, to capture specific anatomical a priori information in medical images, we incorporate a shape a priori module. This module efficiently extracts structural semantic information from the input spine images. We evaluate our method on a single dataset of spine images acquired through X-ray imaging. Our results demonstrate that VerseDiff-UNet significantly outperforms other state-of-the-art methods in terms of accuracy while preserving the natural features and variations of anatomy.
</details>
<details>
<summary>摘要</summary>
医疗图像分割是诊断和治疗脊椎疾病的关键。然而，图像中的高噪音、不确定性和模糊性使得这个任务非常困难。这些因素包括不确定的解剖边界、类别之间的相似性和不合理的注释，均会增加图像分割的挑战。为了支持医生在临床实践中，获得准确和多样化的图像分割模板是非常重要。在最近几年，杂Diffusion probabilistic modeling（DDPM）在计算机视觉领域得到了广泛的研究。它在图像去噪、超分解、异常检测和甚至semantic representation生成等视觉任务中表现出色。然而，现有的杂Diffusion模型在精细mask和其各种效果下仍然存在困难。为了解决医疗图像分割模板的准确性和多样化问题，我们提出了一种综合框架 called VerseDiff-UNet。我们的方法将杂Diffusion模型 integrate into a standard U-shaped architecture。在每个步骤中，我们将噪音加到标注图像，以准确地导引杂Diffusion方向。此外，为了 Capture特定的解剖信息，我们添加了形态先验模块。这个模块能够高效地提取医疗图像中的结构semantic信息。我们对一个X-ray成像技术获得的脊椎图像集进行评估。我们的结果表明，VerseDiff-UNet在准确性方面与其他状态艺术法比较，同时保留了自然的特征和变化。
</details></li>
</ul>
<hr>
<h2 id="Deep-evidential-fusion-with-uncertainty-quantification-and-contextual-discounting-for-multimodal-medical-image-segmentation"><a href="#Deep-evidential-fusion-with-uncertainty-quantification-and-contextual-discounting-for-multimodal-medical-image-segmentation" class="headerlink" title="Deep evidential fusion with uncertainty quantification and contextual discounting for multimodal medical image segmentation"></a>Deep evidential fusion with uncertainty quantification and contextual discounting for multimodal medical image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05919">http://arxiv.org/abs/2309.05919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ling Huang, Su Ruan, Pierre Decazes, Thierry Denoeux</li>
<li>for: 这个论文是为了提高多模态医疗影像诊断的准确性和可靠性而写的。</li>
<li>methods: 该论文提出了基于深度学习和德мп斯特-沙法理论的多模态医疗影像分割框架。该框架会考虑每种单模态图像在 segmenting 不同对象时的可靠性，并使用上下文折扣操作来衡量每个模式的可靠性。最后，使用德мп斯特规则将每个模式的折扣副本相加以达到最终决定。</li>
<li>results: 实验结果表明，我们的方法在使用PET-CT数据集上的淋巴瘤和多个MRI数据集上的脑肿瘤上的准确性和可靠性都高于现有方法。<details>
<summary>Abstract</summary>
Single-modality medical images generally do not contain enough information to reach an accurate and reliable diagnosis. For this reason, physicians generally diagnose diseases based on multimodal medical images such as, e.g., PET/CT. The effective fusion of multimodal information is essential to reach a reliable decision and explain how the decision is made as well. In this paper, we propose a fusion framework for multimodal medical image segmentation based on deep learning and the Dempster-Shafer theory of evidence. In this framework, the reliability of each single modality image when segmenting different objects is taken into account by a contextual discounting operation. The discounted pieces of evidence from each modality are then combined by Dempster's rule to reach a final decision. Experimental results with a PET-CT dataset with lymphomas and a multi-MRI dataset with brain tumors show that our method outperforms the state-of-the-art methods in accuracy and reliability.
</details>
<details>
<summary>摘要</summary>
医学影像通常只有单一模式，而这不够以确定精确和可靠的诊断。因此，医生通常会基于多modal的医学影像，如PET/CT，进行诊断。有效地融合多modal信息是必要的，以确定可靠的决策并解释如何达成这个决策。在这篇论文中，我们提出了基于深度学习和Dempster-Shafer理论的多modal医学影像 segmentation框架。在这个框架中，每种单 modal 影像在 segmenting 不同的对象时的可靠性被考虑。然后，通过Dempster的规则将每种modal的折扣后的证据合并到一起，以达到最终的决策。实验结果表明，使用PET-CT数据集和多MRI数据集，我们的方法在精度和可靠性方面都高于当前的方法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/12/eess.IV_2023_09_12/" data-id="clmjn91r600ie0j88f4scg4he" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/12/cs.LG_2023_09_12/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-09-12
        
      </div>
    </a>
  
  
    <a href="/2023/09/11/cs.SD_2023_09_11/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-09-11</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">69</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">32</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
