
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-08-18 17:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Uncertainty-based quality assurance of carotid artery wall segmentation in black-blood MRI paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.09538 repo_url: https:&#x2F;&#x2F;github.com&#x2F;miagrouput&#x2F;carotid-segmentation paper">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-08-18 17:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/18/eess.IV_2023_08_18/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Uncertainty-based quality assurance of carotid artery wall segmentation in black-blood MRI paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.09538 repo_url: https:&#x2F;&#x2F;github.com&#x2F;miagrouput&#x2F;carotid-segmentation paper">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-17T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:33.081Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_08_18" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/18/eess.IV_2023_08_18/" class="article-date">
  <time datetime="2023-08-17T16:00:00.000Z" itemprop="datePublished">2023-08-18</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-08-18 17:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Uncertainty-based-quality-assurance-of-carotid-artery-wall-segmentation-in-black-blood-MRI"><a href="#Uncertainty-based-quality-assurance-of-carotid-artery-wall-segmentation-in-black-blood-MRI" class="headerlink" title="Uncertainty-based quality assurance of carotid artery wall segmentation in black-blood MRI"></a>Uncertainty-based quality assurance of carotid artery wall segmentation in black-blood MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09538">http://arxiv.org/abs/2308.09538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miagrouput/carotid-segmentation">https://github.com/miagrouput/carotid-segmentation</a></li>
<li>paper_authors: Elina Thibeau-Sutre, Dieuwertje Alblas, Sophie Buurman, Christoph Brune, Jelmer M. Wolterink</li>
<li>for: 这个研究旨在应用深度学习模型来自动确保大规模数据集的质量。</li>
<li>methods: 这种方法使用全自动的算法来 segmentation 黑血栓 MRI 中的血管壁。</li>
<li>results: 研究发现，包括不确定性测量不会下降 segmentation 的质量，不确定性指标可以作为质量指标，并且可以检测参与者级别的低质量 segmentation。<details>
<summary>Abstract</summary>
The application of deep learning models to large-scale data sets requires means for automatic quality assurance. We have previously developed a fully automatic algorithm for carotid artery wall segmentation in black-blood MRI that we aim to apply to large-scale data sets. This method identifies nested artery walls in 3D patches centered on the carotid artery. In this study, we investigate to what extent the uncertainty in the model predictions for the contour location can serve as a surrogate for error detection and, consequently, automatic quality assurance. We express the quality of automatic segmentations using the Dice similarity coefficient. The uncertainty in the model's prediction is estimated using either Monte Carlo dropout or test-time data augmentation. We found that (1) including uncertainty measurements did not degrade the quality of the segmentations, (2) uncertainty metrics provide a good proxy of the quality of our contours if the center found during the first step is enclosed in the lumen of the carotid artery and (3) they could be used to detect low-quality segmentations at the participant level. This automatic quality assurance tool might enable the application of our model in large-scale data sets.
</details>
<details>
<summary>摘要</summary>
深度学习模型在大规模数据集应用需要自动质量控制方法。我们之前已经开发了一种完全自动的护层动脉增强MRI图像分割算法，我们计划将其应用于大规模数据集。这种方法可以在3D补充中心于护层动脉的patch中标识嵌入的护层动脉增强。在这项研究中，我们研究了模型预测结果中的不确定性是否可以作为自动质量控制的代理。我们使用 dice相似度系数来衡量自动分割的质量。我们发现：（1）包括不确定性测量并不下降自动分割的质量，（2）不确定性指标可以作为护层动脉中心在护层动脉血栓中心的质量代理，（3）它们可以用来检测参与者级别的低质量分割。这种自动质量控制工具可能会使我们的模型在大规模数据集上应用。
</details></li>
</ul>
<hr>
<h2 id="INR-LDDMM-Fluid-based-Medical-Image-Registration-Integrating-Implicit-Neural-Representation-and-Large-Deformation-Diffeomorphic-Metric-Mapping"><a href="#INR-LDDMM-Fluid-based-Medical-Image-Registration-Integrating-Implicit-Neural-Representation-and-Large-Deformation-Diffeomorphic-Metric-Mapping" class="headerlink" title="INR-LDDMM: Fluid-based Medical Image Registration Integrating Implicit Neural Representation and Large Deformation Diffeomorphic Metric Mapping"></a>INR-LDDMM: Fluid-based Medical Image Registration Integrating Implicit Neural Representation and Large Deformation Diffeomorphic Metric Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09473">http://arxiv.org/abs/2308.09473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chulong Zhang, Xiaokun Liang</li>
<li>for: 这篇论文是用于医疗影像注册的流程基础架构，使用隐藏 нейрон表示法和大型可扭度Diffusion Metric Mapping（LDDMM）。</li>
<li>methods: 这篇论文使用了多层感知神经网络（MLP）来生成速度，同时估计速度和影像相似性。它还采用了从粗到细的方法来解决医疗影像注册方法中的严重扭转问题。</li>
<li>results: 这篇论文在一个包含50名病人的CT-CBCT资料集上验证了其方法，并使用转移过的标签作为评估指标。与现有方法相比，这篇论文的方法实现了现场状况的最佳性能。<details>
<summary>Abstract</summary>
We propose a flow-based registration framework of medical images based on implicit neural representation. By integrating implicit neural representation and Large Deformable Diffeomorphic Metric Mapping (LDDMM), we employ a Multilayer Perceptron (MLP) as a velocity generator while optimizing velocity and image similarity. Moreover, we adopt a coarse-to-fine approach to address the challenge of deformable-based registration methods dropping into local optimal solutions, thus aiding the management of significant deformations in medical image registration. Our algorithm has been validated on a paired CT-CBCT dataset of 50 patients,taking the dice coefficient of transferred annotations as an evaluation metric. Compared to existing methods, our approach achieves the state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
我们提出一种基于隐藏神经表示的医学图像注册框架。通过结合隐藏神经表示和大型可变截面度量mapping（LDDMM），我们使用多层感知器（MLP）作为速度生成器，同时优化速度和图像相似性。此外，我们采用宽泛到细节的方法来Addressing the challenge of deformable-based registration methods dropping into local optimal solutions，以避免医学图像注册中显著的形态变换问题。我们的算法在50名患者的CT-CBCT对照集上进行验证，并根据 transferred annotations的 dice coefficient 作为评价指标。与现有方法相比，我们的方法实现了状态的最佳性。
</details></li>
</ul>
<hr>
<h2 id="Quantitative-Susceptibility-Mapping-through-Model-based-Deep-Image-Prior-MoDIP"><a href="#Quantitative-Susceptibility-Mapping-through-Model-based-Deep-Image-Prior-MoDIP" class="headerlink" title="Quantitative Susceptibility Mapping through Model-based Deep Image Prior (MoDIP)"></a>Quantitative Susceptibility Mapping through Model-based Deep Image Prior (MoDIP)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09467">http://arxiv.org/abs/2308.09467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuang Xiong, Yang Gao, Yin Liu, Amir Fazlollahi, Peter Nestor, Feng Liu, Hongfu Sun</li>
<li>for: 提高Quantitative Susceptibility Mapping（QSM）中的批处理参数不同对象的普适性。</li>
<li>methods: 提出了一种新的无需训练的模型基于深度学习方法，称为MoDIP（模型基于深度图像先验）。MoDIP包括一个小型、未训练的网络和数据准确优化（DFO）模块。</li>
<li>results: MoDIP在不同扫描参数下的QSM普适性问题中表现出色，与深度学习和传统迭代方法相比，实现了32%的准确性提高，并且比传统DIP基于方法快33%，可以在4.5分钟内完成3D高分辨率图像重建。<details>
<summary>Abstract</summary>
The data-driven approach of supervised learning methods has limited applicability in solving dipole inversion in Quantitative Susceptibility Mapping (QSM) with varying scan parameters across different objects. To address this generalization issue in supervised QSM methods, we propose a novel training-free model-based unsupervised method called MoDIP (Model-based Deep Image Prior). MoDIP comprises a small, untrained network and a Data Fidelity Optimization (DFO) module. The network converges to an interim state, acting as an implicit prior for image regularization, while the optimization process enforces the physical model of QSM dipole inversion. Experimental results demonstrate MoDIP's excellent generalizability in solving QSM dipole inversion across different scan parameters. It exhibits robustness against pathological brain QSM, achieving over 32% accuracy improvement than supervised deep learning and traditional iterative methods. It is also 33% more computationally efficient and runs 4 times faster than conventional DIP-based approaches, enabling 3D high-resolution image reconstruction in under 4.5 minutes.
</details>
<details>
<summary>摘要</summary>
supervised学习方法的数据驱动方法在量子吸引mapping（QSM）中的不同对象扫描参数下有限的应用。为解决总化issue在超级vised QSM方法中，我们提出了一种新的无需训练的模型基于Unsupervised方法called MoDIP（模型基于深度图像先验）。MoDIP包括一个小型、未训练的网络和数据准确优化（DFO）模块。网络在某些扫描参数下 converges to an interim state，作为图像规范化的隐式先验，而优化过程检查QSM扫描器的物理模型。实验结果表明，MoDIP在不同扫描参数下的QSM扫描中具有出色的总化性能，与超级vised深度学习和传统迭代方法相比，具有32%的精度提高。此外，MoDIP还比折衔DIP基本方法更加快速，只需4.5分钟内可以完成3D高分辨率图像重建。
</details></li>
</ul>
<hr>
<h2 id="Causal-SAR-ATR-with-Limited-Data-via-Dual-Invariance"><a href="#Causal-SAR-ATR-with-Limited-Data-via-Dual-Invariance" class="headerlink" title="Causal SAR ATR with Limited Data via Dual Invariance"></a>Causal SAR ATR with Limited Data via Dual Invariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09412">http://arxiv.org/abs/2308.09412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cwwangsaratr/saratr_causal_dual_invariance">https://github.com/cwwangsaratr/saratr_causal_dual_invariance</a></li>
<li>paper_authors: Chenwei Wang, You Qin, Li Li, Siyi Luo, Yulin Huang, Jifang Pei, Yin Zhang, Jianyu Yang</li>
<li>for: 本文旨在提高受限制SAR数据的自动目标识别（SAR ATR）的迷你性。</li>
<li>methods: 本文提出了一个 causal ATR 模型，表明有限SAR数据中的噪声（N）会对特征X中的污染，导致SAR ATR的迷你性。为了解决这个问题，本文提出了一种双Inv隐含proxy和噪声不变损失。</li>
<li>results: 实验结果表明，提出的方法在三个标准数据集上达到了更高的性能。<details>
<summary>Abstract</summary>
Synthetic aperture radar automatic target recognition (SAR ATR) with limited data has recently been a hot research topic to enhance weak generalization. Despite many excellent methods being proposed, a fundamental theory is lacked to explain what problem the limited SAR data causes, leading to weak generalization of ATR. In this paper, we establish a causal ATR model demonstrating that noise $N$ that could be blocked with ample SAR data, becomes a confounder with limited data for recognition. As a result, it has a detrimental causal effect damaging the efficacy of feature $X$ extracted from SAR images, leading to weak generalization of SAR ATR with limited data. The effect of $N$ on feature can be estimated and eliminated by using backdoor adjustment to pursue the direct causality between $X$ and the predicted class $Y$. However, it is difficult for SAR images to precisely estimate and eliminated the effect of $N$ on $X$. The limited SAR data scarcely powers the majority of existing optimization losses based on empirical risk minimization (ERM), thus making it difficult to effectively eliminate $N$'s effect. To tackle with difficult estimation and elimination of $N$'s effect, we propose a dual invariance comprising the inner-class invariant proxy and the noise-invariance loss. Motivated by tackling change with invariance, the inner-class invariant proxy facilitates precise estimation of $N$'s effect on $X$ by obtaining accurate invariant features for each class with the limited data. The noise-invariance loss transitions the ERM's data quantity necessity into a need for noise environment annotations, effectively eliminating $N$'s effect on $X$ by cleverly applying the previous $N$'s estimation as the noise environment annotations. Experiments on three benchmark datasets indicate that the proposed method achieves superior performance.
</details>
<details>
<summary>摘要</summary>
射频干扰自动目标识别（SAR ATR）受限数据的研究在最近几年来非常热门，但是它们的基本理论仍然缺乏，这使得SAR ATR的训练受限数据的情况下存在强化问题。在这篇文章中，我们建立了一个导向性的ATR模型，证明了噪音N，可以阻据了充足的SAR数据，在有限数据情况下成为识别的干扰因子。这使得噪音N对特征X提出了负面的导向效应，导致SAR ATR的训练受限数据下存在弱化问题。但是，噪音N对特征X的影响可以通过后门调整来追求直接的 causality between X和预测的类别Y。即使SAR图像具有限制的数据能力，也可以通过内部的类别对称代理和噪音不对称损失来实现这一目的。实验结果显示，提案的方法在三个benchmark dataset上具有superior的表现。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Causalities-in-SAR-ATR-A-Causal-Interventional-Approach-for-Limited-Data"><a href="#Unveiling-Causalities-in-SAR-ATR-A-Causal-Interventional-Approach-for-Limited-Data" class="headerlink" title="Unveiling Causalities in SAR ATR: A Causal Interventional Approach for Limited Data"></a>Unveiling Causalities in SAR ATR: A Causal Interventional Approach for Limited Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09396">http://arxiv.org/abs/2308.09396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Xin Chen, You Qin, Siyi Luo, Yulin Huang, Jifang Pei, Jianyu Yang</li>
<li>For:	+ The paper aims to address the limited training data problem in synthetic aperture radar (SAR) automatic target recognition (ATR) by proposing a causal interventional ATR method (CIATR).* Methods:	+ The proposed CIATR method uses causal inference to understand the causal relationships among the key factors in ATR, and employs a structural causal model (SCM) to mitigate the spurious correlation introduced by limited SAR data.	+ The method includes data augmentation with spatial-frequency domain hybrid transformation and a feature discrimination approach with hybrid similarity measurement to measure and mitigate the impacts of varying imaging conditions on the extracted features from SAR images.* Results:	+ The proposed CIATR method has been experimented and compared on the moving and stationary target acquisition and recognition (MSTAR) and OpenSARship datasets, and has shown effective performance in pursuing the true causality between SAR images and the corresponding classes even with limited SAR data.<details>
<summary>Abstract</summary>
Synthetic aperture radar automatic target recognition (SAR ATR) methods fall short with limited training data. In this letter, we propose a causal interventional ATR method (CIATR) to formulate the problem of limited SAR data which helps us uncover the ever-elusive causalities among the key factors in ATR, and thus pursue the desired causal effect without changing the imaging conditions. A structural causal model (SCM) is comprised using causal inference to help understand how imaging conditions acts as a confounder introducing spurious correlation when SAR data is limited. This spurious correlation among SAR images and the predicted classes can be fundamentally tackled with the conventional backdoor adjustments. An effective implement of backdoor adjustments is proposed by firstly using data augmentation with spatial-frequency domain hybrid transformation to estimate the potential effect of varying imaging conditions on SAR images. Then, a feature discrimination approach with hybrid similarity measurement is introduced to measure and mitigate the structural and vector angle impacts of varying imaging conditions on the extracted features from SAR images. Thus, our CIATR can pursue the true causality between SAR images and the corresponding classes even with limited SAR data. Experiments and comparisons conducted on the moving and stationary target acquisition and recognition (MSTAR) and OpenSARship datasets have shown the effectiveness of our method with limited SAR data.
</details>
<details>
<summary>摘要</summary>
Synthetic aperture radar自动目标识别（SAR ATR）方法受有限训练数据的限制。在这封信中，我们提议一种 causal interventional ATR 方法（CIATR）来处理有限 SAR 数据的问题，并帮助我们探索 SAR 图像中隐藏的 causalities 以及它们如何影响 ATR 的性能。我们使用 causal inference 来理解如何限制 SAR 图像的捕捉条件引入了假 correlation，并且提出了一种基于 backdoor adjustments 的方法来解决这种假 correlation。我们首先使用数据扩充和空间频率域混合变换来估计限制 SAR 图像的可变 imaging 条件对 SAR 图像的影响。然后，我们引入了一种 hybrid similarity measurement 来衡量和减少限制 SAR 图像的结构和向量角度的影响。因此，我们的 CIATR 可以追求有限 SAR 数据中 true causality  между SAR 图像和对应的类别。我们在 MSTAR 和 OpenSARship 数据集上进行了实验和比较，并证明了我们的方法在有限 SAR 数据情况下的效果。
</details></li>
</ul>
<hr>
<h2 id="SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT"><a href="#SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT" class="headerlink" title="SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT"></a>SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09331">http://arxiv.org/abs/2308.09331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Botond Fazekas, José Morano, Dmitrii Lachinov, Guilherme Aresta, Hrvoje Bogunović</li>
<li>for: 这篇论文是为了评估Segment Anything Model（SAM）在Retinal OCT扫描影像分类中的可行性和优势。</li>
<li>methods: 这篇论文使用了SAM模型和其修改版本，并与现有的State-of-the-art retinal fluid segmentation方法进行比较。</li>
<li>results: 研究发现，这些修改版本的SAM模型在大量的Retinal OCT扫描影像 dataset上具有了优秀的分类能力，但在一些情况下仍落后于现有的方法。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) has gained significant attention in the field of image segmentation due to its impressive capabilities and prompt-based interface. While SAM has already been extensively evaluated in various domains, its adaptation to retinal OCT scans remains unexplored. To bridge this research gap, we conduct a comprehensive evaluation of SAM and its adaptations on a large-scale public dataset of OCTs from RETOUCH challenge. Our evaluation covers diverse retinal diseases, fluid compartments, and device vendors, comparing SAM against state-of-the-art retinal fluid segmentation methods. Through our analysis, we showcase adapted SAM's efficacy as a powerful segmentation model in retinal OCT scans, although still lagging behind established methods in some circumstances. The findings highlight SAM's adaptability and robustness, showcasing its utility as a valuable tool in retinal OCT image analysis and paving the way for further advancements in this domain.
</details>
<details>
<summary>摘要</summary>
Segment Anything Model (SAM) 已经在图像分割领域引起了广泛的关注，因为它的印象深刻和提示式接口。虽然 SAM 已经在不同领域进行了广泛的评估，但它在Retinal OCT扫描图像中的适用仍然未得到探索。为了填补这个研究差距，我们进行了大规模公共数据集的 RETOUCH 挑战中的 OCT 图像的全面评估。我们的评估覆盖了多种Retinal疾病、液体腔和设备制造商，与现有的Retinal液体分割方法进行比较。通过我们的分析，我们发现了适应 SAM 的可能性和强大性，尽管在某些情况下仍然落后于已知方法。这些发现表明 SAM 在Retinal OCT 图像分析中的可用性和稳定性，并且作为一个有价值的工具，可以在这个领域进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Intra-operative-Precision-Dynamic-Data-Driven-Non-Rigid-Registration-for-Enhanced-Brain-Tumor-Resection-in-Image-Guided-Neurosurgery"><a href="#Advancing-Intra-operative-Precision-Dynamic-Data-Driven-Non-Rigid-Registration-for-Enhanced-Brain-Tumor-Resection-in-Image-Guided-Neurosurgery" class="headerlink" title="Advancing Intra-operative Precision: Dynamic Data-Driven Non-Rigid Registration for Enhanced Brain Tumor Resection in Image-Guided Neurosurgery"></a>Advancing Intra-operative Precision: Dynamic Data-Driven Non-Rigid Registration for Enhanced Brain Tumor Resection in Image-Guided Neurosurgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10868">http://arxiv.org/abs/2308.10868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikos Chrisochoides, Andriy Fedorov, Fotis Drakopoulos, Andriy Kot, Yixun Liu, Panos Foteinos, Angelos Angelopoulos, Olivier Clatz, Nicholas Ayache, Peter M. Black, Alex J. Golby, Ron Kikinis</li>
<li>for: 用于 neurosurgery 中医学影像识别肿瘤和关键结构</li>
<li>methods: 使用 Dynamic Data-Driven Non-Rigid Registration (NRR) 方法对医学影像进行调整，以考虑 operation 中脑膜的变化</li>
<li>results: 实现 NRR 结果在临床时间限制内，并通过分布式计算和机器学习提高 registration 精度，同时描述了在操作室中使用 NRR 的挑战<details>
<summary>Abstract</summary>
During neurosurgery, medical images of the brain are used to locate tumors and critical structures, but brain tissue shifts make pre-operative images unreliable for accurate removal of tumors. Intra-operative imaging can track these deformations but is not a substitute for pre-operative data. To address this, we use Dynamic Data-Driven Non-Rigid Registration (NRR), a complex and time-consuming image processing operation that adjusts the pre-operative image data to account for intra-operative brain shift. Our review explores a specific NRR method for registering brain MRI during image-guided neurosurgery and examines various strategies for improving the accuracy and speed of the NRR method. We demonstrate that our implementation enables NRR results to be delivered within clinical time constraints while leveraging Distributed Computing and Machine Learning to enhance registration accuracy by identifying optimal parameters for the NRR method. Additionally, we highlight challenges associated with its use in the operating room.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: During 神经外科手术，医疗影像被用来确定肿瘤和重要结构，但是脑组织的运动使得先前的影像无法准确地识别肿瘤。 intra-operative imaging可以跟踪这些变形，但是不能代替先前的数据。为解决这个问题，我们使用动态数据驱动非固定注册（NRR）方法，将先前的影像数据调整以 compte for intra-operative brain shift。我们的文章检讨了一种特定的NRR方法，用于在图像引导神经外科手术中注册脑MRI。我们还检讨了不同的策略来提高NRR方法的准确性和速度。我们的实现可以在临床时间限制内提供NRR结果，并利用分布式计算和机器学习来提高注册精度。此外，我们还 highlighted some challenges associated with its use in the operating room.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="JPEG-Quantized-Coefficient-Recovery-via-DCT-Domain-Spatial-Frequential-Transformer"><a href="#JPEG-Quantized-Coefficient-Recovery-via-DCT-Domain-Spatial-Frequential-Transformer" class="headerlink" title="JPEG Quantized Coefficient Recovery via DCT Domain Spatial-Frequential Transformer"></a>JPEG Quantized Coefficient Recovery via DCT Domain Spatial-Frequential Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09110">http://arxiv.org/abs/2308.09110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingyu Ouyang, Zhenzhong Chen</li>
<li>for: 本研究旨在提出一种基于DCT频域的JPEG压缩图像恢复方法，以提高压缩图像的Restoration效果。</li>
<li>methods: 我们提出了一种名为DCTransformer的双支持结构，通过捕捉DCT快 Fourier Transform的空间-频域相关性来提高图像Restoration效果。此外，我们还采用量化矩阵嵌入和同色度组分对齐来扩展模型的应用范围。</li>
<li>results: 我们的DCTransformer模型在对压缩JPEG图像进行恢复时表现出色，在各种质量因素下都能够达到更高的Restoration效果。<details>
<summary>Abstract</summary>
JPEG compression adopts the quantization of Discrete Cosine Transform (DCT) coefficients for effective bit-rate reduction, whilst the quantization could lead to a significant loss of important image details. Recovering compressed JPEG images in the frequency domain has attracted more and more attention recently, in addition to numerous restoration approaches developed in the pixel domain. However, the current DCT domain methods typically suffer from limited effectiveness in handling a wide range of compression quality factors, or fall short in recovering sparse quantized coefficients and the components across different colorspace. To address these challenges, we propose a DCT domain spatial-frequential Transformer, named as DCTransformer. Specifically, a dual-branch architecture is designed to capture both spatial and frequential correlations within the collocated DCT coefficients. Moreover, we incorporate the operation of quantization matrix embedding, which effectively allows our single model to handle a wide range of quality factors, and a luminance-chrominance alignment head that produces a unified feature map to align different-sized luminance and chrominance components. Our proposed DCTransformer outperforms the current state-of-the-art JPEG artifact removal techniques, as demonstrated by our extensive experiments.
</details>
<details>
<summary>摘要</summary>
JPEG压缩采用了离散余弦变换（DCT）系数的归一化进行有效的比特率减少，而这可能会导致重要的图像细节产生损失。在频域中还原压缩的JPEG图像已经引起了越来越多的关注，而 besides numerous restoration approaches developed in the pixel domain. However, the current DCT domain methods typically suffer from limited effectiveness in handling a wide range of compression quality factors, or fall short in recovering sparse quantized coefficients and the components across different color spaces. To address these challenges, we propose a DCT domain spatial-frequential Transformer, named as DCTransformer. Specifically, a dual-branch architecture is designed to capture both spatial and frequential correlations within the collocated DCT coefficients. Moreover, we incorporate the operation of quantization matrix embedding, which effectively allows our single model to handle a wide range of quality factors, and a luminance-chrominance alignment head that produces a unified feature map to align different-sized luminance and chrominance components. Our proposed DCTransformer outperforms the current state-of-the-art JPEG artifact removal techniques, as demonstrated by our extensive experiments.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/18/eess.IV_2023_08_18/" data-id="clly4xtgc00fdvl884t87do3o" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/18/cs.SD_2023_08_18/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.SD - 2023-08-18 123:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/17/cs.LG_2023_08_17/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-08-17 18:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">108</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
