
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.SD - 2023-08-06 123:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="SoK: Acoustic Side Channels paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.03806 repo_url: None paper_authors: Ping Wang, Shishir Nagaraja, Aurélien Bourquard, Haichang Gao, Jeff Yan for: 本研究做出了一个 state-of-the-">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.SD - 2023-08-06 123:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/06/cs.SD_2023_08_06/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="SoK: Acoustic Side Channels paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.03806 repo_url: None paper_authors: Ping Wang, Shishir Nagaraja, Aurélien Bourquard, Haichang Gao, Jeff Yan for: 本研究做出了一个 state-of-the-">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-05T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-26T20:36:44.831Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.SD_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/cs.SD_2023_08_06/" class="article-date">
  <time datetime="2023-08-05T16:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.SD - 2023-08-06 123:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SoK-Acoustic-Side-Channels"><a href="#SoK-Acoustic-Side-Channels" class="headerlink" title="SoK: Acoustic Side Channels"></a>SoK: Acoustic Side Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03806">http://arxiv.org/abs/2308.03806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Wang, Shishir Nagaraja, Aurélien Bourquard, Haichang Gao, Jeff Yan</li>
<li>for: 本研究做出了一个 state-of-the-art 的分析，涵盖了全部重要的学术研究领域，讨论了安全性含义和对策，并寻找了未来研究的方向。</li>
<li>methods: 本研究使用了多种方法，包括对渠道的分析、对 inverse problems 的研究以及两者之间的连接。</li>
<li>results: 本研究得到了一些深刻的结论，包括渠道的安全性含义和未来研究的方向。<details>
<summary>Abstract</summary>
We provide a state-of-the-art analysis of acoustic side channels, cover all the significant academic research in the area, discuss their security implications and countermeasures, and identify areas for future research. We also make an attempt to bridge side channels and inverse problems, two fields that appear to be completely isolated from each other but have deep connections.
</details>
<details>
<summary>摘要</summary>
我们提供了当今最先进的声学侧途分析，涵盖了全部主要的学术研究领域，讨论了它们的安全意义和防范措施，并确定了未来研究的方向。我们还尝试将侧途和反问题两个领域联系起来，这两个领域之前被视为完全不相关的，但它们在深层次上有着深刻的联系。
</details></li>
</ul>
<hr>
<h2 id="Characterization-of-cough-sounds-using-statistical-analysis"><a href="#Characterization-of-cough-sounds-using-statistical-analysis" class="headerlink" title="Characterization of cough sounds using statistical analysis"></a>Characterization of cough sounds using statistical analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03019">http://arxiv.org/abs/2308.03019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naveenkumar Vodnala, Pratap Reddy Lankireddy, Padmasai Yarlagadda</li>
<li>For: 本研究旨在Characterize cough sounds with voiced content and cough sounds without voiced content，以便更好地诊断呼吸疾病。* Methods: 该研究使用spectral roll-off、spectral entropy、spectral flatness、spectral flux、zero crossing rate、spectral centroid和spectral bandwidth属性来描述呼吸 зву频谱特征。这些属性 subsequentially subjected to statistical analysis using measures of minimum, maximum, mean, median, and standard deviation。* Results: 实验结果表明，呼吸音频谱特征的mean和frequency distribution高于speech signals，spectral flatness水平在0.22左右，spectral flux在0.3-0.6之间，Zero Crossing Rate大约在0.05-0.4之间。这些属性具有重要的信息价值，可以帮助更好地Characterize cough sounds。<details>
<summary>Abstract</summary>
Cough is a primary symptom of most respiratory diseases, and changes in cough characteristics provide valuable information for diagnosing respiratory diseases. The characterization of cough sounds still lacks concrete evidence, which makes it difficult to accurately distinguish between different types of coughs and other sounds. The objective of this research work is to characterize cough sounds with voiced content and cough sounds without voiced content. Further, the cough sound characteristics are compared with the characteristics of speech. The proposed method to achieve this goal utilized spectral roll-off, spectral entropy, spectral flatness, spectral flux, zero crossing rate, spectral centroid, and spectral bandwidth attributes which describe the cough sounds related to the respiratory system, glottal information, and voice model. These attributes are then subjected to statistical analysis using the measures of minimum, maximum, mean, median, and standard deviation. The experimental results show that the mean and frequency distribution of spectral roll-off, spectral centroid, and spectral bandwidth are found to be higher for cough sounds than for speech signals. Spectral flatness levels in cough sounds will rise to 0.22, whereas spectral flux varies between 0.3 and 0.6. The Zero Crossing Rate (ZCR) of most frames of cough sounds is between 0.05 and 0.4. These attributes contribute significant information while characterizing cough sounds.
</details>
<details>
<summary>摘要</summary>
<SYS>将文本翻译成简化中文。</SYS>吐は多种呼吸疾病的主要症状之一，而吐的特征变化可以提供诊断呼吸疾病的有价值信息。然而，吐 зву的特征化仍然缺乏具体证据，这使得准确地分辨吐音和其他声音变得困难。本研究的目标是Characterize吐音与有声吐音。此外，吐音特征与语音特征进行比较。提出的方法是利用spectral roll-off、spectral entropy、spectral flatness、spectral flux、zero crossing rate、spectral centroid和spectral bandwidth属性来描述吐音，这些属性是基于呼吸系统、舌叶信息和语音模型。这些属性后来通过统计分析使用 minimum、maximum、mean、median和标准差度量进行评估。实验结果表明，吐音的mean和频谱分布的 spectral roll-off、spectral centroid和spectral bandwidth均高于语音信号。吐音中的spectral flatness水平上升到0.22，而spectral flux在0.3和0.6之间变化。zero crossing rate的大多数帧为0.05和0.4。这些属性对吐音 caracterization提供了重要信息。
</details></li>
</ul>
<hr>
<h2 id="DiffDance-Cascaded-Human-Motion-Diffusion-Model-for-Dance-Generation"><a href="#DiffDance-Cascaded-Human-Motion-Diffusion-Model-for-Dance-Generation" class="headerlink" title="DiffDance: Cascaded Human Motion Diffusion Model for Dance Generation"></a>DiffDance: Cascaded Human Motion Diffusion Model for Dance Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02915">http://arxiv.org/abs/2308.02915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiaosong Qi, Le Zhuo, Aixi Zhang, Yue Liao, Fei Fang, Si Liu, Shuicheng Yan</li>
<li>for: 本研究旨在生成高分辨率、长形舞蹈序列，以便与音乐进行 conditional generation。</li>
<li>methods: 我们提出了一种新的层次动态扩散模型，即 DiffDance，以解决传统autoregressive方法在采样中引入折衔错误和长期结构捕捉的限制。我们还采用了多种几何损失来限制模型输出的物理可能性，并在扩散过程中采用动态权重来促进样本多样性。</li>
<li>results: 我们通过对 AIST++ 数据集进行 comprehensive 试验，证明了 DiffDance 能够生成与输入音乐高效对齐的实际舞蹈序列，并与状态静态方法相当。<details>
<summary>Abstract</summary>
When hearing music, it is natural for people to dance to its rhythm. Automatic dance generation, however, is a challenging task due to the physical constraints of human motion and rhythmic alignment with target music. Conventional autoregressive methods introduce compounding errors during sampling and struggle to capture the long-term structure of dance sequences. To address these limitations, we present a novel cascaded motion diffusion model, DiffDance, designed for high-resolution, long-form dance generation. This model comprises a music-to-dance diffusion model and a sequence super-resolution diffusion model. To bridge the gap between music and motion for conditional generation, DiffDance employs a pretrained audio representation learning model to extract music embeddings and further align its embedding space to motion via contrastive loss. During training our cascaded diffusion model, we also incorporate multiple geometric losses to constrain the model outputs to be physically plausible and add a dynamic loss weight that adaptively changes over diffusion timesteps to facilitate sample diversity. Through comprehensive experiments performed on the benchmark dataset AIST++, we demonstrate that DiffDance is capable of generating realistic dance sequences that align effectively with the input music. These results are comparable to those achieved by state-of-the-art autoregressive methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Anonymizing-Speech-Evaluating-and-Designing-Speaker-Anonymization-Techniques"><a href="#Anonymizing-Speech-Evaluating-and-Designing-Speaker-Anonymization-Techniques" class="headerlink" title="Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques"></a>Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04455">http://arxiv.org/abs/2308.04455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deep-privacy/SA-toolkit">https://github.com/deep-privacy/SA-toolkit</a></li>
<li>paper_authors: Pierre Champion<br>for:  This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization to address the privacy issues arising from the collection and storage of personal speech data in voice-based digital assistants.methods: The thesis employs a combination of voice conversion-based anonymization systems and quantization-based transformation methods to reduce speaker PPI while maintaining utility.results: The thesis evaluates the degree of privacy protection provided by these methods and proposes a new attack method to invert anonymization, highlighting the limitations of current anonymization systems and identifying areas for improvement.<details>
<summary>Abstract</summary>
The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.   This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protocols need to consider to evaluate the degree of privacy protection properly. We clarify how anonymization systems must be configured for evaluation purposes and highlight that many practical deployment configurations do not permit privacy evaluation. Furthermore, we study and examine the most common voice conversion-based anonymization system and identify its weak points before suggesting new methods to overcome some limitations. We isolate all components of the anonymization system to evaluate the degree of speaker PPI associated with each of them. Then, we propose several transformation methods for each component to reduce as much as possible speaker PPI while maintaining utility. We promote anonymization algorithms based on quantization-based transformation as an alternative to the most-used and well-known noise-based approach. Finally, we endeavor a new attack method to invert anonymization.
</details>
<details>
<summary>摘要</summary>
声音用户界面的使用量在增长，导致了个人语音数据的收集和存储。而这些数据的收集可以为语音服务的开发提供高效的工具，但也会对用户的隐私造成严重的威胁，因为中央存储的私人语音数据容易受到网络攻击。随着智能语音助手 like Amazon Alexa、Google Home 和 Apple Siri 的使用的加密，以及个人语音数据的收集变得更加容易，黑客利用语音恶作剂和 speaker/性别/疾病等识别的风险也在增加。本论目标是提出一种隐藏个人语音数据的方法，以保护用户的隐私。在这个过程中，我们认为需要考虑以下几个挑战：1. 评估隐私保护程度：我们需要设计一种评估隐私保护程度的方法，以确保个人语音数据不可链接到用户身份。2. 配置评估系统：我们需要配置评估系统，以便在实际应用中进行评估。3. 避免攻击：我们需要研究和探讨常见的语音转换基于隐藏的攻击方法，并提出新的方法来解决一些限制。我们认为，以下几个方法可以用于隐藏个人语音数据：1. 量化变换：我们可以使用量化变换来减少说话人的个人特征，以保护用户的隐私。2. 隐藏语音特征：我们可以使用隐藏语音特征的技术来隐藏个人语音数据，以降低黑客的攻击风险。3. 多模型融合：我们可以使用多个模型来融合语音数据，以提高隐私保护的效果。最后，我们提出了一种新的攻击方法，可以尝试将隐藏后的语音数据恢复到原始形式。这种攻击方法可以帮助我们更好地理解隐私保护的限制，并提高隐私保护的效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/cs.SD_2023_08_06/" data-id="cllsj9wzd0054uv889rh1dz0n" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/06/cs.LG_2023_08_06/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-08-06 18:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/06/eess.IV_2023_08_06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.IV - 2023-08-06 17:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">43</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">42</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">44</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">53</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">114</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'', root:''}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
