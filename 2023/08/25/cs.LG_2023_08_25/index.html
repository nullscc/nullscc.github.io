
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-25 18:00:00 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12970 repo_url: None paper_authors: Navami Kairanda, Marc Habermann, Christian">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-25 18:00:00">
<meta property="og:url" content="http://example.com/2023/08/25/cs.LG_2023_08_25/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12970 repo_url: None paper_authors: Navami Kairanda, Marc Habermann, Christian">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-25T00:00:00.000Z">
<meta property="article:modified_time" content="2023-08-26T20:36:52.763Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/25/cs.LG_2023_08_25/" class="article-date">
  <time datetime="2023-08-25T00:00:00.000Z" itemprop="datePublished">2023-08-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-25 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NeuralClothSim-Neural-Deformation-Fields-Meet-the-Kirchhoff-Love-Thin-Shell-Theory"><a href="#NeuralClothSim-Neural-Deformation-Fields-Meet-the-Kirchhoff-Love-Thin-Shell-Theory" class="headerlink" title="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory"></a>NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12970">http://arxiv.org/abs/2308.12970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navami Kairanda, Marc Habermann, Christian Theobalt, Vladislav Golyanik</li>
<li>for: 这个论文的目的是提出一种新的软件 simulate cloth，使用软件 neural network 来模拟布料的形态变化。</li>
<li>methods: 这个论文使用的方法是基于 neural network 的 thin shell 模型， surface evolution 被编码在 neural network 的权重中。</li>
<li>results: 实验结果表明，这种新的软件可以具有高效的计算和可微的权重更新，同时可以保持 cloth 的物理合理性。<details>
<summary>Abstract</summary>
Cloth simulation is an extensively studied problem, with a plethora of solutions available in computer graphics literature. Existing cloth simulators produce realistic cloth deformations that obey different types of boundary conditions. Nevertheless, their operational principle remains limited in several ways: They operate on explicit surface representations with a fixed spatial resolution, perform a series of discretised updates (which bounds their temporal resolution), and require comparably large amounts of storage. Moreover, back-propagating gradients through the existing solvers is often not straightforward, which poses additional challenges when integrating them into modern neural architectures. In response to the limitations mentioned above, this paper takes a fundamentally different perspective on physically-plausible cloth simulation and re-thinks this long-standing problem: We propose NeuralClothSim, i.e., a new cloth simulation approach using thin shells, in which surface evolution is encoded in neural network weights. Our memory-efficient and differentiable solver operates on a new continuous coordinate-based representation of dynamic surfaces, i.e., neural deformation fields (NDFs); it supervises NDF evolution with the rules of the non-linear Kirchhoff-Love shell theory. NDFs are adaptive in the sense that they 1) allocate their capacity to the deformation details as the latter arise during the cloth evolution and 2) allow surface state queries at arbitrary spatial and temporal resolutions without retraining. We show how to train our NeuralClothSim solver while imposing hard boundary conditions and demonstrate multiple applications, such as material interpolation and simulation editing. The experimental results highlight the effectiveness of our formulation and its potential impact.
</details>
<details>
<summary>摘要</summary>
cloth simulation 是一个已经进行了广泛研究的问题， computer graphics 文献中有许多解决方案。现有的布料 simulator 可以生成真实的布料构型，但它们的运作原理有限制：它们在固定的空间分辨率上运算，执行一系列细化的更新（对其时间分辨率有限制），并需要相对较大的存储空间。此外，将梯度传递回 existing solver 是不直接的，这会增加当 integre 到 modern neural architecture 时的挑战。在上述限制的回应，这篇 paper 提出了一个新的布料 simulation 方法：我们提议使用薄板，将表面演化编码到 neural network 的权重中。我们的记忆效率高和可微分的解决方案在新的连续坐标基础上运作，即 neural deformation fields (NDFs)；它遵循非线性 Kirchhoff-Love 板理论的规则来监督 NDF 的演化。NDFs 是可靠的，它们 1) 在布料演化过程中获得演化细节的容量，2) 在布料表面状态查询中不需要再训练。我们示出了对 NeuralClothSim 解决方案的训练方法，并在实现应用中显示了材料插值和 simulate 编译等多个应用。实验结果显示了我们的形式化的构思和其潜在影响。
</details></li>
</ul>
<hr>
<h2 id="BridgeData-V2-A-Dataset-for-Robot-Learning-at-Scale"><a href="#BridgeData-V2-A-Dataset-for-Robot-Learning-at-Scale" class="headerlink" title="BridgeData V2: A Dataset for Robot Learning at Scale"></a>BridgeData V2: A Dataset for Robot Learning at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12952">http://arxiv.org/abs/2308.12952</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rail-berkeley/BridgeData-V2">https://github.com/rail-berkeley/BridgeData-V2</a></li>
<li>paper_authors: Homer Walke, Kevin Black, Abraham Lee, Moo Jin Kim, Max Du, Chongyi Zheng, Tony Zhao, Philippe Hansen-Estruch, Quan Vuong, Andre He, Vivek Myers, Kuan Fang, Chelsea Finn, Sergey Levine</li>
<li>for:  bridgedata v2 is a large and diverse dataset of robotic manipulation behaviors designed to facilitate research on scalable robot learning.</li>
<li>methods:  the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions.</li>
<li>results:  the dataset provides extensive task and environment variability, leading to skills that can generalize across environments, domains, and institutions, making it a useful resource for a broad range of researchers.<details>
<summary>Abstract</summary>
We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research on scalable robot learning. BridgeData V2 contains 60,096 trajectories collected across 24 environments on a publicly available low-cost robot. BridgeData V2 provides extensive task and environment variability, leading to skills that can generalize across environments, domains, and institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we train 6 state-of-the-art imitation learning and offline reinforcement learning methods on our dataset, and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models, and that training on a greater variety of skills leads to improved generalization. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods. Project page at https://rail-berkeley.github.io/bridgedata
</details>
<details>
<summary>摘要</summary>
我们介绍 BridgeData V2，一个大型和多样化的机器人操作行为数据集，旨在促进机器人学习的扩展研究。 BridgeData V2 包含 60,096 捷径，在 24 个环境中收集，这些环境为公共可用的低成本机器人。 BridgeData V2 提供了广泛的任务和环境多样性，导致技能可以泛化到环境、领域和机构，使 dataset 成为广泛的研究资源。此外，数据集compatible with 多种开放词汇、多任务学习方法，根据目标图像或自然语言指令。在我们的实验中，我们将 6 种现代抄情学习和离线强化学习方法训练在我们的数据集上，并发现这些方法在一系列需要不同量的泛化的任务中获得成功。我们还证明了这些方法的性能可以随着更多的数据和更高的容量模型而提高，并且训练更多的技能导致泛化性的提高。我们公开分享 BridgeData V2 和我们的预训模型，以促进机器人学习方法的扩展研究。相关页面请参考 <https://rail-berkeley.github.io/bridgedata>。
</details></li>
</ul>
<hr>
<h2 id="Learning-Only-On-Boundaries-a-Physics-Informed-Neural-operator-for-Solving-Parametric-Partial-Differential-Equations-in-Complex-Geometries"><a href="#Learning-Only-On-Boundaries-a-Physics-Informed-Neural-operator-for-Solving-Parametric-Partial-Differential-Equations-in-Complex-Geometries" class="headerlink" title="Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries"></a>Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12939">http://arxiv.org/abs/2308.12939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Fang, Sifan Wang, Paris Perdikaris</li>
<li>for: 解决Parametrized boundary value problems without labeled data.</li>
<li>methods: 使用Physics-informed neural operator方法，将PDEs转化为边界积分方程(BIEs)，然后通过训练操作网络来解决问题。</li>
<li>results: 可以快速训练和处理复杂的几何和无界问题。<details>
<summary>Abstract</summary>
Recently deep learning surrogates and neural operators have shown promise in solving partial differential equations (PDEs). However, they often require a large amount of training data and are limited to bounded domains. In this work, we present a novel physics-informed neural operator method to solve parametrized boundary value problems without labeled data. By reformulating the PDEs into boundary integral equations (BIEs), we can train the operator network solely on the boundary of the domain. This approach reduces the number of required sample points from $O(N^d)$ to $O(N^{d-1})$, where $d$ is the domain's dimension, leading to a significant acceleration of the training process. Additionally, our method can handle unbounded problems, which are unattainable for existing physics-informed neural networks (PINNs) and neural operators. Our numerical experiments show the effectiveness of parametrized complex geometries and unbounded problems.
</details>
<details>
<summary>摘要</summary>
近些年，深度学习替代方法和神经运算员已经在解决部分导数方程（PDEs）方面表现出了承诺。然而，它们经常需要大量的训练数据并且受到围栏领域的限制。在这项工作中，我们提出了一种新的物理学习神经运算员方法，用于解决没有标签数据的参数化边值问题。我们通过将PDEs转换为边Integral方程（BIEs），可以在边界上训练运算员网络，从而减少训练数据的数量从$O(N^d)$降低到$O(N^{d-1})$，其中$d$是域的维度，这导致训练过程的加速。此外，我们的方法可以处理无限制的问题，这些问题对现有的物理学习神经网络（PINNs）和神经运算员来说是不可达的。我们的数值实验表明， parametrized复杂的几何和无限制的问题都可以得到有效的解决。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Distributed-Multi-Agent-Reinforcement-Learning-for-EV-Charging-Network-Control"><a href="#An-Efficient-Distributed-Multi-Agent-Reinforcement-Learning-for-EV-Charging-Network-Control" class="headerlink" title="An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control"></a>An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12921">http://arxiv.org/abs/2308.12921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amin Shojaeighadikolaei, Morteza Hashemi</li>
<li>for: 这篇论文是为了开发一个具有隐私保证的电动车充电控制器，以减少分配网络成本和变压器负载。</li>
<li>methods: 本文使用多代理人强化学习（MARL）框架，实现隐私保证，并运用中央训练分散执行-深度决策精度梯度（CTDE-DDPG）计划，提供训练时期的有益信息，而保持执行时期的隐私。</li>
<li>results:  CTDE框架可以改善充电网络的性能，降低分配网络成本，并降低总需求的峰值变化比（PAR），从而降低变压器负载的风险。<details>
<summary>Abstract</summary>
The increasing trend in adopting electric vehicles (EVs) will significantly impact the residential electricity demand, which results in an increased risk of transformer overload in the distribution grid. To mitigate such risks, there are urgent needs to develop effective EV charging controllers. Currently, the majority of the EV charge controllers are based on a centralized approach for managing individual EVs or a group of EVs. In this paper, we introduce a decentralized Multi-agent Reinforcement Learning (MARL) charging framework that prioritizes the preservation of privacy for EV owners. We employ the Centralized Training Decentralized Execution-Deep Deterministic Policy Gradient (CTDE-DDPG) scheme, which provides valuable information to users during training while maintaining privacy during execution. Our results demonstrate that the CTDE framework improves the performance of the charging network by reducing the network costs. Moreover, we show that the Peak-to-Average Ratio (PAR) of the total demand is reduced, which, in turn, reduces the risk of transformer overload during the peak hours.
</details>
<details>
<summary>摘要</summary>
随着电动车（EV）的普及趋势，它将导致住宅电力需求增加，从而增加了分布网络中变压器负荷的风险。为了解决这些风险，需要开发有效的电动车充电控制器。现在，大多数电动车充电控制器采用中央化的方法来管理个别电动车或一群电动车。在这篇论文中，我们提出了分布式多智能体学习（MARL）充电框架，该框架优先保护电动车所有者隐私。我们采用了中央化训练、分布式执行-深度决定策 gradient（CTDE-DDPG）方案，该方案在训练时提供有价值信息，而执行时保持隐私。我们的结果表明，CTDE框架可以改善充电网络的性能，同时降低了总需求的峰值评价比（PAR），从而降低了变压器负荷的风险。
</details></li>
</ul>
<hr>
<h2 id="POLCA-Power-Oversubscription-in-LLM-Cloud-Providers"><a href="#POLCA-Power-Oversubscription-in-LLM-Cloud-Providers" class="headerlink" title="POLCA: Power Oversubscription in LLM Cloud Providers"></a>POLCA: Power Oversubscription in LLM Cloud Providers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12908">http://arxiv.org/abs/2308.12908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratyush Patel, Esha Choukse, Chaojie Zhang, Íñigo Goiri, Brijesh Warrier, Nithish Mahalingam, Ricardo Bianchini<br>for:这篇论文的目的是为了探讨大型自然语言模型（LLM）的创新，以及这些模型在数据中心中的应用场景带来的计算负担增长。methods:这篇论文使用了许多方法来研究数据中心中的能源使用情况，包括对多种LLM的能源消耗模式的Characterization，以及对这些模型的配置的分析。results:根据论文的分析，在数据中心中进行推理任务时，LLM集群的平均和峰值能源使用率不太高。此外， authors还提出了一个名为POLCA的可靠和可重复的能源扩展机制，可以在GPU集群中部署30%更多的服务器，并减少性能损失。<details>
<summary>Abstract</summary>
Recent innovation in large language models (LLMs), and their myriad use-cases have rapidly driven up the compute capacity demand for datacenter GPUs. Several cloud providers and other enterprises have made substantial plans of growth in their datacenters to support these new workloads. One of the key bottleneck resources in datacenters is power, and given the increasing model sizes of LLMs, they are becoming increasingly power intensive. In this paper, we show that there is a significant opportunity to oversubscribe power in LLM clusters. Power oversubscription improves the power efficiency of these datacenters, allowing more deployable servers per datacenter, and reduces the deployment time, since building new datacenters is slow.   We extensively characterize the power consumption patterns of a variety of LLMs and their configurations. We identify the differences between the inference and training power consumption patterns. Based on our analysis of these LLMs, we claim that the average and peak power utilization in LLM clusters for inference should not be very high. Our deductions align with the data from production LLM clusters, revealing that inference workloads offer substantial headroom for power oversubscription. However, the stringent set of telemetry and controls that GPUs offer in a virtualized environment, makes it challenging to have a reliable and robust power oversubscription mechanism.   We propose POLCA, our framework for power oversubscription that is robust, reliable, and readily deployable for GPU clusters. Using open-source models to replicate the power patterns observed in production, we simulate POLCA and demonstrate that we can deploy 30% more servers in the same GPU cluster for inference, with minimal performance loss
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的最新创新和多种应用场景在短时间内带来了数据中心GPU的计算能力需求的快速增长。许多云提供商和企业在数据中心扩展计划中投入了大量资源。在数据中心中，电力是最重要的瓶颈资源，而随着LLM的模型大小不断增长，它们变得越来越占用电力。在这篇论文中，我们显示出在LLM集群中可以进行电力扩展。电力扩展可以提高数据中心的能效性，允许更多的服务器部署在同一个数据中心中，并降低了部署时间，因为建立新的数据中心是慢的。我们对多种LLM的电力消耗模式进行了广泛的 caracterización。我们发现在推理和训练中，LLM的电力消耗模式存在差异。根据我们对LLM的分析，我们认为LLM集群中的推理工作负载的平均和峰值电力利用率不应该非常高。我们的结论与生产环境中LLM集群的数据相符，显示推理工作负载具有较大的留下空间，可以进行电力扩展。但是，GPU在虚拟化环境中提供的准确和可靠的电力扩展机制具有挑战。我们提出了POLCA，我们的可靠、可重复和Ready deployable的电力扩展框架。使用开源模型来复制生产环境中观测到的电力模式，我们在POLCA中进行了模拟，并证明可以在同一个GPU集群中部署30%更多的服务器，以Minimal performance loss。
</details></li>
</ul>
<hr>
<h2 id="Unified-Data-Management-and-Comprehensive-Performance-Evaluation-for-Urban-Spatial-Temporal-Prediction-Experiment-Analysis-Benchmark"><a href="#Unified-Data-Management-and-Comprehensive-Performance-Evaluation-for-Urban-Spatial-Temporal-Prediction-Experiment-Analysis-Benchmark" class="headerlink" title="Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]"></a>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12899">http://arxiv.org/abs/2308.12899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/libcity/bigscity-libcity">https://github.com/libcity/bigscity-libcity</a></li>
<li>paper_authors: Jiawei Jiang, Chengkai Han, Wayne Xin Zhao, Jingyuan Wang</li>
<li>for: 本研究旨在Addressing the challenges of accessing and utilizing diverse urban spatial-temporal datasets, and developing effective deep learning models for urban spatial-temporal prediction.</li>
<li>methods: 本研究使用了”atomic files” unified storage format和 comprehensive overview of technological advances in urban spatial-temporal prediction models, 并进行了广泛的实验使用多种模型和数据集，建立了性能排名和发现了有前途的研究方向。</li>
<li>results: 本研究提供了一个简单的数据管理方式，并提出了多种有前途的研究方向，可能对长期urban spatial-temporal数据管理和预测做出持续的贡献，最终导致城市生活水平的改善。<details>
<summary>Abstract</summary>
The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets. However, challenges persist in accessing and utilizing diverse urban spatial-temporal datasets from different sources and stored in different formats, as well as determining effective model structures and components with the proliferation of deep learning models. This work addresses these challenges and provides three significant contributions. Firstly, we introduce "atomic files", a unified storage format designed for urban spatial-temporal big data, and validate its effectiveness on 40 diverse datasets, simplifying data management. Secondly, we present a comprehensive overview of technological advances in urban spatial-temporal prediction models, guiding the development of robust models. Thirdly, we conduct extensive experiments using diverse models and datasets, establishing a performance leaderboard and identifying promising research directions. Overall, this work effectively manages urban spatial-temporal data, guides future efforts, and facilitates the development of accurate and efficient urban spatial-temporal prediction models. It can potentially make long-term contributions to urban spatial-temporal data management and prediction, ultimately leading to improved urban living standards.
</details>
<details>
<summary>摘要</summary>
随着深度学习技术的发展和城市空间时间数据的大规模化，城市空间时间预测领域快速发展，但是 still facing challenges in accessing and utilizing different types of urban spatial-temporal data from different sources and in different formats, as well as determining effective model structures and components with the proliferation of deep learning models. This work addresses these challenges and makes three significant contributions. First, we introduce "atomic files", a unified storage format designed for urban spatial-temporal big data, and validate its effectiveness on 40 diverse datasets, simplifying data management. Second, we provide a comprehensive overview of technological advances in urban spatial-temporal prediction models, guiding the development of robust models. Third, we conduct extensive experiments using diverse models and datasets, establishing a performance leaderboard and identifying promising research directions. Overall, this work effectively manages urban spatial-temporal data, guides future efforts, and facilitates the development of accurate and efficient urban spatial-temporal prediction models. It has the potential to make long-term contributions to urban spatial-temporal data management and prediction, ultimately leading to improved urban living standards.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/25/cs.LG_2023_08_25/" data-id="cllt9prw60032ol88h2hve409" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/25/cs.CV_2023_08_25/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-08-25
        
      </div>
    </a>
  
  
    <a href="/2023/08/24/cs.CL_2023_08_24/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-08-24</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">43</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">42</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">44</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">53</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">114</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
