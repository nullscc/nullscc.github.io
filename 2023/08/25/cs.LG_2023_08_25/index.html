
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-25 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12970 repo_url: None paper_authors: Navami Kairanda, Marc Habermann, Christian">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-25 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/25/cs.LG_2023_08_25/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12970 repo_url: None paper_authors: Navami Kairanda, Marc Habermann, Christian">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-24T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:37.557Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/25/cs.LG_2023_08_25/" class="article-date">
  <time datetime="2023-08-24T16:00:00.000Z" itemprop="datePublished">2023-08-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-25 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NeuralClothSim-Neural-Deformation-Fields-Meet-the-Kirchhoff-Love-Thin-Shell-Theory"><a href="#NeuralClothSim-Neural-Deformation-Fields-Meet-the-Kirchhoff-Love-Thin-Shell-Theory" class="headerlink" title="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory"></a>NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12970">http://arxiv.org/abs/2308.12970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navami Kairanda, Marc Habermann, Christian Theobalt, Vladislav Golyanik</li>
<li>For: 本研究旨在提出一种基于神经网络的精炼裤子模拟方法，以解决现有的精炼裤子模拟器具有限制的问题。* Methods: 该方法使用薄shell理论来编码表面演化，并使用神经网络来学习表面的演化规律。* Results: 实验结果表明，该方法可以准确地模拟精炼裤子的演化，并且具有高效的存储和计算能力。<details>
<summary>Abstract</summary>
Cloth simulation is an extensively studied problem, with a plethora of solutions available in computer graphics literature. Existing cloth simulators produce realistic cloth deformations that obey different types of boundary conditions. Nevertheless, their operational principle remains limited in several ways: They operate on explicit surface representations with a fixed spatial resolution, perform a series of discretised updates (which bounds their temporal resolution), and require comparably large amounts of storage. Moreover, back-propagating gradients through the existing solvers is often not straightforward, which poses additional challenges when integrating them into modern neural architectures. In response to the limitations mentioned above, this paper takes a fundamentally different perspective on physically-plausible cloth simulation and re-thinks this long-standing problem: We propose NeuralClothSim, i.e., a new cloth simulation approach using thin shells, in which surface evolution is encoded in neural network weights. Our memory-efficient and differentiable solver operates on a new continuous coordinate-based representation of dynamic surfaces, i.e., neural deformation fields (NDFs); it supervises NDF evolution with the rules of the non-linear Kirchhoff-Love shell theory. NDFs are adaptive in the sense that they 1) allocate their capacity to the deformation details as the latter arise during the cloth evolution and 2) allow surface state queries at arbitrary spatial and temporal resolutions without retraining. We show how to train our NeuralClothSim solver while imposing hard boundary conditions and demonstrate multiple applications, such as material interpolation and simulation editing. The experimental results highlight the effectiveness of our formulation and its potential impact.
</details>
<details>
<summary>摘要</summary>
cloth simulation是一个已经非常广泛研究的问题，计算机图形文献中有很多解决方案。现有的布料模拟器都可以生成真实的布料变形，但它们的运作原理受到一些限制：它们在固定的空间分辨率上操作，执行一系列精度化的更新（这限制了它们的时间分辨率），同时需要相对较大的存储空间。此外，在现有的解决方案中，将梯度反推到现代神经网络中是不直接的，这会增加集成的困难。为了解决这些限制，本文采用了一种完全不同的方法来实现物理可能的布料模拟：我们提出了一种基于薄层的新布料模拟方法，即NeuralClothSim。我们的方法使用辐射表示法来编码布料的表面演化，并且通过神经网络的权重来控制布料的演化。我们的方法是有内存效率和可微分的，可以在不需要大量存储空间和精度化更新的情况下进行模拟。我们还展示了如何在NeuralClothSim中训练模型，并在布料演化过程中遵循非线性的 Kirchhoff-Love 封闭理论来监督NDF的演化。NDF是可变的，它们可以根据布料演化的细节来分配其容量，同时允许在任何空间和时间分辨率下进行表面状态的查询无需重新训练。我们的实验结果表明，我们的方法可以具有高效性和可能的影响。
</details></li>
</ul>
<hr>
<h2 id="NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes"><a href="#NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes" class="headerlink" title="NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes"></a>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12967">http://arxiv.org/abs/2308.12967</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zubair-irshad/NeO-360">https://github.com/zubair-irshad/NeO-360</a></li>
<li>paper_authors: Muhammad Zubair Irshad, Sergey Zakharov, Katherine Liu, Vitor Guizilini, Thomas Kollar, Adrien Gaidon, Zsolt Kira, Rares Ambrus</li>
<li>for: 本研究旨在开发一种能够从单个或几个RGB图像中生成360度场景的神经网络方法，以解决现有方法需要费时优化多个视图的问题，从而限制其在实际世界无限范围内的应用。</li>
<li>methods: 我们提出了一种名为NeO 360的新方法，它使用神经场的方法来描述复杂的自然场景，并使用混合的图像条件三平面表示来从任何世界点进行查询。这种表示结合了精灵体的 voxel-based 表示和鸟瞰视图（BEV）表示的优点，并且在描述和推理中更有效和表达力。</li>
<li>results: 我们在提出的挑战性360度无限集成 dataset（NeRDS 360）上进行了实验，并证明了NeO 360在比较复杂的场景下能够具有更高的渲染质量和更好的普适性，而且还可以进行编辑和组合操作。<details>
<summary>Abstract</summary>
Recent implicit neural representations have shown great results for novel view synthesis. However, existing methods require expensive per-scene optimization from many views hence limiting their application to real-world unbounded urban settings where the objects of interest or backgrounds are observed from very few views. To mitigate this challenge, we introduce a new approach called NeO 360, Neural fields for sparse view synthesis of outdoor scenes. NeO 360 is a generalizable method that reconstructs 360{\deg} scenes from a single or a few posed RGB images. The essence of our approach is in capturing the distribution of complex real-world outdoor 3D scenes and using a hybrid image-conditional triplanar representation that can be queried from any world point. Our representation combines the best of both voxel-based and bird's-eye-view (BEV) representations and is more effective and expressive than each. NeO 360's representation allows us to learn from a large collection of unbounded 3D scenes while offering generalizability to new views and novel scenes from as few as a single image during inference. We demonstrate our approach on the proposed challenging 360{\deg} unbounded dataset, called NeRDS 360, and show that NeO 360 outperforms state-of-the-art generalizable methods for novel view synthesis while also offering editing and composition capabilities. Project page: https://zubair-irshad.github.io/projects/neo360.html
</details>
<details>
<summary>摘要</summary>
近期的隐式神经表示法已经实现了出色的新视图合成效果。然而，现有的方法需要每个场景进行贵重的多视图优化，因此在真实世界中无限无Bound的城市场景中应用起来有限。为解决这个挑战，我们介绍了一种新的方法called NeO 360，它是一种普适的方法，可以从单个或几个姿态的 RGB 图像中重construct 360度场景。我们的方法的核心思想是捕捉复杂的实际室外3D场景的分布，并使用一种混合图像条件的三平面表示，可以在任何世界点上进行查询。我们的表示结合了 voxel-based 和 bird's-eye-view（BEV）表示的优点，并且比每个表示更有效和表达力强。NeO 360 的表示允许我们从大量的无限室外3D场景中学习，并在新视图和新场景中进行推理，只需要从单个图像中提取信息。我们在 propose 的挑战性 360度无限数据集（NeRDS 360）上展示了 NeO 360 的效果，并证明它在比较最佳的通用方法之上。项目页面：https://zubair-irshad.github.io/projects/neo360.html
</details></li>
</ul>
<hr>
<h2 id="Scenimefy-Learning-to-Craft-Anime-Scene-via-Semi-Supervised-Image-to-Image-Translation"><a href="#Scenimefy-Learning-to-Craft-Anime-Scene-via-Semi-Supervised-Image-to-Image-Translation" class="headerlink" title="Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation"></a>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12968">http://arxiv.org/abs/2308.12968</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuxinn-j/scenimefy">https://github.com/yuxinn-j/scenimefy</a></li>
<li>paper_authors: Yuxin Jiang, Liming Jiang, Shuai Yang, Chen Change Loy</li>
<li>for: 高质量动漫场景自实际图像转换</li>
<li>methods: 结构一致的pseudo对数据驱动学习，采用semantic-constrained StyleGAN生成质量Model priors，并应用分割指导数据选择来获得高质量 pseudo 超级vision。</li>
<li>results: 比基eline性能和 perceived quality 都有显著提高，并且可以保持具有Semantic consistency、精细 Detail和 evident Stylization 的结果。<details>
<summary>Abstract</summary>
Automatic high-quality rendering of anime scenes from complex real-world images is of significant practical value. The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap. Despite promising attempts, previous efforts are still incompetent in achieving satisfactory results with consistent semantic preservation, evident stylization, and fine details. In this study, we propose Scenimefy, a novel semi-supervised image-to-image translation framework that addresses these challenges. Our approach guides the learning with structure-consistent pseudo paired data, simplifying the pure unsupervised setting. The pseudo data are derived uniquely from a semantic-constrained StyleGAN leveraging rich model priors like CLIP. We further apply segmentation-guided data selection to obtain high-quality pseudo supervision. A patch-wise contrastive style loss is introduced to improve stylization and fine details. Besides, we contribute a high-resolution anime scene dataset to facilitate future research. Our extensive experiments demonstrate the superiority of our method over state-of-the-art baselines in terms of both perceptual quality and quantitative performance.
</details>
<details>
<summary>摘要</summary>
自动高质量渲染动漫场景从复杂实际图像是有重要实用价值的。这个任务的挑战在于场景的复杂性、动漫风格的独特特征以及域之间的差距。虽然之前有一些有前途的尝试，但这些尝试仍然无法取得满意的结果，保持 semantics 的保持、明显的风格化和细节。在这个研究中，我们提出了 Scenimefy，一种新的 semi-supervised 图像-to-图像翻译框架。我们的方法利用具有结构含义的 pseudo 对数据进行引导学习，从而简化了纯无监督的设置。 pseudo 数据由具有 CLIP 的semantic-constrained StyleGAN 生成，并且通过 segmentation-guided 数据选择来获得高质量 pseudo 监督。此外，我们还引入了一种 patch-wise 对比性风格损失，以提高风格化和细节。除此之外，我们还为未来研究提供了一个高分辨率动漫场景数据集。我们的广泛的实验表明我们的方法在比较现有基线上的both perceptual quality 和量化性能方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="Dense-Text-to-Image-Generation-with-Attention-Modulation"><a href="#Dense-Text-to-Image-Generation-with-Attention-Modulation" class="headerlink" title="Dense Text-to-Image Generation with Attention Modulation"></a>Dense Text-to-Image Generation with Attention Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12964">http://arxiv.org/abs/2308.12964</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naver-ai/densediffusion">https://github.com/naver-ai/densediffusion</a></li>
<li>paper_authors: Yunji Kim, Jiyoung Lee, Jin-Hwa Kim, Jung-Woo Ha, Jun-Yan Zhu</li>
<li>for: 将 dense captions 转化为真实的图像</li>
<li>methods: 使用 pre-trained text-to-image 模型，并通过 analyze 图像的布局与模型的中间注意力映射关系，以及开发一种注意力调整方法，使对象在指定的区域出现。</li>
<li>results: 无需进一步的 fine-tuning 或数据集，对 dense captions 进行图像生成，自动评估和人工评估分数都得到了改进，并且与特定布局条件训练的模型达到了相似的视觉效果。<details>
<summary>Abstract</summary>
Existing text-to-image diffusion models struggle to synthesize realistic images given dense captions, where each text prompt provides a detailed description for a specific image region. To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout. We first analyze the relationship between generated images' layouts and the pre-trained model's intermediate attention maps. Next, we develop an attention modulation method that guides objects to appear in specific regions according to layout guidance. Without requiring additional fine-tuning or datasets, we improve image generation performance given dense captions regarding both automatic and human evaluation scores. In addition, we achieve similar-quality visual results with models specifically trained with layout conditions.
</details>
<details>
<summary>摘要</summary>
原文：现有的文本到图像扩散模型很难生成真实的图像，当每个文本提示给出了具体的图像区域的详细描述时。为解决这个问题，我们提出了DenseDiffusion，一种没有培训的方法，可以使用先前训练的文本到图像模型来处理这些紧凑的文本提示，同时提供场景布局的控制。我们首先分析生成的图像布局和先前训练模型的中间注意力地图之间的关系。然后，我们开发了一种注意力调节方法，可以根据场景布局指导物体出现在特定的区域中。无需进行额外的微调或数据集，我们在给出紧凑的文本提示时改进了图像生成性能， Both automatic and human evaluation scores. In addition, we achieve similar-quality visual results with models specifically trained with layout conditions.中文翻译：现有的文本到图像扩散模型在给出紧凑的文本提示时很难生成真实的图像，例如每个文本提示给出了具体的图像区域的详细描述。为解决这个问题，我们提出了DenseDiffusion，一种没有培训的方法，可以使用先前训练的文本到图像模型来处理这些紧凑的文本提示，同时提供场景布局的控制。我们首先分析生成的图像布局和先前训练模型的中间注意力地图之间的关系。然后，我们开发了一种注意力调节方法，可以根据场景布局指导物体出现在特定的区域中。无需进行额外的微调或数据集，我们在给出紧凑的文本提示时改进了图像生成性能， Both automatic and human evaluation scores. In addition, we achieve similar-quality visual results with models specifically trained with layout conditions.
</details></li>
</ul>
<hr>
<h2 id="DLIP-Distilling-Language-Image-Pre-training"><a href="#DLIP-Distilling-Language-Image-Pre-training" class="headerlink" title="DLIP: Distilling Language-Image Pre-training"></a>DLIP: Distilling Language-Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12956">http://arxiv.org/abs/2308.12956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Kuang, Jie Wu, Xiawu Zheng, Ming Li, Xuefeng Xiao, Rui Wang, Min Zheng, Rongrong Ji</li>
<li>For: The paper aims to explore how to distill a light Vision-Language Pre-training (VLP) model, specifically investigating the model distillation from multiple dimensions such as architecture characteristics and information transfer.* Methods: The proposed method, called DLIP, dissects the model distillation from multiple dimensions and conducts comprehensive experiments to provide insights on distilling a light but performant VLP model.* Results: The experimental results show that DLIP can achieve a state-of-the-art accuracy&#x2F;efficiency trade-off across diverse cross-modal tasks, with a 1.9x compression ratio compared to the teacher model, while retaining more than 95% of the performance and accelerating inference speed by 2.7x.Here’s the simplified Chinese version:* For: 这篇论文目标是探索如何压缩轻量级的视听预训练模型（VLP），具体来说是从多个维度进行模型压缩，包括模型结构特点和不同模式之间的信息传递。* Methods: 提出的方法是DLIP，它对模型压缩进行多维度的分析和实验，以提供适用于VLP的压缩模型。* Results: 实验结果显示，DLIP可以在多modal任务上实现状态之 искусственный智能&#x2F;效率的平衡，比如图文检索、图文描述和视觉问答等，并且可以压缩BLIP模型2.9亿个参数下来1.9倍，保持与教师模型相当或更好的性能。<details>
<summary>Abstract</summary>
Vision-Language Pre-training (VLP) shows remarkable progress with the assistance of extremely heavy parameters, which challenges deployment in real applications. Knowledge distillation is well recognized as the essential procedure in model compression. However, existing knowledge distillation techniques lack an in-depth investigation and analysis of VLP, and practical guidelines for VLP-oriented distillation are still not yet explored. In this paper, we present DLIP, a simple yet efficient Distilling Language-Image Pre-training framework, through which we investigate how to distill a light VLP model. Specifically, we dissect the model distillation from multiple dimensions, such as the architecture characteristics of different modules and the information transfer of different modalities. We conduct comprehensive experiments and provide insights on distilling a light but performant VLP model. Experimental results reveal that DLIP can achieve a state-of-the-art accuracy/efficiency trade-off across diverse cross-modal tasks, e.g., image-text retrieval, image captioning and visual question answering. For example, DLIP compresses BLIP by 1.9x, from 213M to 108M parameters, while achieving comparable or better performance. Furthermore, DLIP succeeds in retaining more than 95% of the performance with 22.4% parameters and 24.8% FLOPs compared to the teacher model and accelerates inference speed by 2.7x.
</details>
<details>
<summary>摘要</summary>
美化语言预训练（VLP）显示了惊人的进步，却因为极重的参数而困难应用于实际应用场景。知识填充是通用的程序压缩技术，但现有的知识填充技术尚未对VLP进行了深入的研究和分析，也没有提供VLP-指导的压缩指南。在这篇论文中，我们提出了DILP，一个简单又高效的语言图像预训练框架，通过该框架，我们进行了多维度模型填充的研究。具体来说，我们分析了不同模块的建筑特点和不同模式之间的信息传递。我们进行了广泛的实验，并提供了压缩轻量级VLP模型的惊人的成果。实验结果表明，DILP可以在多种跨模态任务中实现状态之最的精度/效率质量平衡，例如图像文本检索、图像captioning和视觉问答。例如，DILP可以将BLIP压缩至1.9倍，从213M Parameters下降至108M Parameters，同时保持与教师模型相同或更好的性能。此外，DILP成功地保留了95%以上的性能，使用22.4%的参数和24.8%的FLOPs，相比教师模型快速执行2.7倍。
</details></li>
</ul>
<hr>
<h2 id="BridgeData-V2-A-Dataset-for-Robot-Learning-at-Scale"><a href="#BridgeData-V2-A-Dataset-for-Robot-Learning-at-Scale" class="headerlink" title="BridgeData V2: A Dataset for Robot Learning at Scale"></a>BridgeData V2: A Dataset for Robot Learning at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12952">http://arxiv.org/abs/2308.12952</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rail-berkeley/BridgeData-V2">https://github.com/rail-berkeley/BridgeData-V2</a></li>
<li>paper_authors: Homer Walke, Kevin Black, Abraham Lee, Moo Jin Kim, Max Du, Chongyi Zheng, Tony Zhao, Philippe Hansen-Estruch, Quan Vuong, Andre He, Vivek Myers, Kuan Fang, Chelsea Finn, Sergey Levine</li>
<li>For: This paper introduces BridgeData V2, a large and diverse dataset of robotic manipulation behaviors for research on scalable robot learning.* Methods: The dataset contains 60,096 trajectories collected across 24 environments on a publicly available low-cost robot, and is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions.* Results: The authors train 6 state-of-the-art imitation learning and offline reinforcement learning methods on the dataset and demonstrate that they succeed on a suite of tasks requiring varying amounts of generalization. Additionally, they show that the performance of these methods improves with more data and higher capacity models, and that training on a greater variety of skills leads to improved generalization.<details>
<summary>Abstract</summary>
We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research on scalable robot learning. BridgeData V2 contains 60,096 trajectories collected across 24 environments on a publicly available low-cost robot. BridgeData V2 provides extensive task and environment variability, leading to skills that can generalize across environments, domains, and institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we train 6 state-of-the-art imitation learning and offline reinforcement learning methods on our dataset, and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models, and that training on a greater variety of skills leads to improved generalization. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods. Project page at https://rail-berkeley.github.io/bridgedata
</details>
<details>
<summary>摘要</summary>
我们介绍 BridgeData V2，一个大型和多样化的机器人 manipulate 行为数据集，用于促进可扩展的机器人学习研究。 BridgeData V2 包含 60,096 轨迹，在 24 个环境中采集，并且可以用于各种开放词汇、多任务学习方法，如图像目标或自然语言指令。在我们的实验中，我们训练了 6 种 state-of-the-art 仿制学习和离线奖励学习方法，并发现它们在一系列需要不同程度的泛化的任务上取得了成功。我们还证明了这些方法的性能随着更多的数据和更高的模型容量而提高，以及训练更多的技能会提高泛化性能。我们公共分享 BridgeData V2 和我们预训练的模型，以促进可扩展机器人学习方法的研究。项目页面位于 <https://rail-berkeley.github.io/bridgedata>
</details></li>
</ul>
<hr>
<h2 id="Label-Budget-Allocation-in-Multi-Task-Learning"><a href="#Label-Budget-Allocation-in-Multi-Task-Learning" class="headerlink" title="Label Budget Allocation in Multi-Task Learning"></a>Label Budget Allocation in Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12949">http://arxiv.org/abs/2308.12949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ximeng Sun, Kihyuk Sohn, Kate Saenko, Clayton Mellina, Xiao Bian</li>
<li>for: 提高机器学习系统的性能，解决标签成本问题</li>
<li>methods: 提出了标签预算分配问题，并提出了一种适应任务的预算分配算法</li>
<li>results: 经验表明，该算法可以在多任务学习中提高性能，并且比其他常用的标签策略更有效<details>
<summary>Abstract</summary>
The cost of labeling data often limits the performance of machine learning systems. In multi-task learning, related tasks provide information to each other and improve overall performance, but the label cost can vary among tasks. How should the label budget (i.e. the amount of money spent on labeling) be allocated among different tasks to achieve optimal multi-task performance? We are the first to propose and formally define the label budget allocation problem in multi-task learning and to empirically show that different budget allocation strategies make a big difference to its performance. We propose a Task-Adaptive Budget Allocation algorithm to robustly generate the optimal budget allocation adaptive to different multi-task learning settings. Specifically, we estimate and then maximize the extent of new information obtained from the allocated budget as a proxy for multi-task learning performance. Experiments on PASCAL VOC and Taskonomy demonstrate the efficacy of our approach over other widely used heuristic labeling strategies.
</details>
<details>
<summary>摘要</summary>
机器学习系统的标签成本常常限制其性能。在多任务学习中，相关任务之间共享信息，提高总体性能，但标签成本可能因任务而异。如何将标签预算（即用于标签的金钱）分配到不同任务以实现最佳多任务性能？我们是第一个提出和正式定义多任务学习标签预算分配问题，并通过实验证明不同预算分配策略对性能产生很大影响。我们提出了适应任务的预算分配算法，以适应不同的多任务学习设置。具体来说，我们估算并最大化分配的预算中新信息的总量，作为多任务学习性能的代理。 Pascal VOC和Taskonomy的实验表明，我们的方法在其他广泛使用的习惯标签策略的基础上具有较高的效果。
</details></li>
</ul>
<hr>
<h2 id="Learning-Only-On-Boundaries-a-Physics-Informed-Neural-operator-for-Solving-Parametric-Partial-Differential-Equations-in-Complex-Geometries"><a href="#Learning-Only-On-Boundaries-a-Physics-Informed-Neural-operator-for-Solving-Parametric-Partial-Differential-Equations-in-Complex-Geometries" class="headerlink" title="Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries"></a>Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12939">http://arxiv.org/abs/2308.12939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Fang, Sifan Wang, Paris Perdikaris</li>
<li>for: 解决 parametrized boundary value problems without labeled data</li>
<li>methods: 使用 physics-informed neural operator 方法，将 PDE 转化为 boundary integral equations (BIEs)，并通过训练网络来解决</li>
<li>results: 可以快速训练网络，并可以处理复杂的形状和无界问题，实验表明方法的效果<details>
<summary>Abstract</summary>
Recently deep learning surrogates and neural operators have shown promise in solving partial differential equations (PDEs). However, they often require a large amount of training data and are limited to bounded domains. In this work, we present a novel physics-informed neural operator method to solve parametrized boundary value problems without labeled data. By reformulating the PDEs into boundary integral equations (BIEs), we can train the operator network solely on the boundary of the domain. This approach reduces the number of required sample points from $O(N^d)$ to $O(N^{d-1})$, where $d$ is the domain's dimension, leading to a significant acceleration of the training process. Additionally, our method can handle unbounded problems, which are unattainable for existing physics-informed neural networks (PINNs) and neural operators. Our numerical experiments show the effectiveness of parametrized complex geometries and unbounded problems.
</details>
<details>
<summary>摘要</summary>
最近，深度学习代理和神经操作已经显示出解决部分 diferencial equations (PDEs) 的承诺。然而，它们经常需要大量的训练数据并且受到 bounded domains 的限制。在这种工作中，我们提出了一种新的物理学习神经操作方法，可以解决没有标注数据的参数化边值问题。我们通过将 PDEs 转换为边 интегра方程 (BIEs)，可以在边界上训练操作网络，从而减少了训练数据的数量从 $O(N^d)$ 降低到 $O(N^{d-1})$，其中 $d$ 是域的维度，这对训练过程带来了显著的加速。此外，我们的方法可以处理无限制的问题，这些问题是现有的物理学习神经网络 (PINNs) 和神经操作无法解决的。我们的数学实验表明，可以有效地处理参数化复杂的几何和无限制的问题。
</details></li>
</ul>
<hr>
<h2 id="Low-count-Time-Series-Anomaly-Detection"><a href="#Low-count-Time-Series-Anomaly-Detection" class="headerlink" title="Low-count Time Series Anomaly Detection"></a>Low-count Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12925">http://arxiv.org/abs/2308.12925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Renz, Kurt Cutajar, Niall Twomey, Gavin K. C. Cheung, Hanting Xie</li>
<li>for: 本研究旨在为低频时间序列预测和检测异常点提供新的方法和工具。</li>
<li>methods: 本研究使用了一种新的生成过程，可以创建含有异常段的低频时间序列的标准数据集。此外，我们还进行了 тео리тиче和实验分析，以解释一些常用算法在低频时间序列中的缺陷。</li>
<li>results: 我们的研究发现，使用异常分数平滑可以有效地提高检测异常点的性能。此外，我们还 Validated our analysis and recommendation on a real-world dataset containing sales data for retail stores, demonstrating its practical utility.<details>
<summary>Abstract</summary>
Low-count time series describe sparse or intermittent events, which are prevalent in large-scale online platforms that capture and monitor diverse data types. Several distinct challenges surface when modelling low-count time series, particularly low signal-to-noise ratios (when anomaly signatures are provably undetectable), and non-uniform performance (when average metrics are not representative of local behaviour). The time series anomaly detection community currently lacks explicit tooling and processes to model and reliably detect anomalies in these settings. We address this gap by introducing a novel generative procedure for creating benchmark datasets comprising of low-count time series with anomalous segments. Via a mixture of theoretical and empirical analysis, our work explains how widely-used algorithms struggle with the distribution overlap between normal and anomalous segments. In order to mitigate this shortcoming, we then leverage our findings to demonstrate how anomaly score smoothing consistently improves performance. The practical utility of our analysis and recommendation is validated on a real-world dataset containing sales data for retail stores.
</details>
<details>
<summary>摘要</summary>
低计数时序系列描述稀疏或间歇性事件，这些事件在大规模在线平台上采集和监测多种数据类型中很普遍。在模型低计数时序系列时，存在一些独特的挑战，包括低信号噪声比（畸变特征在确切检测时是不可识别的）和非均匀性（平均指标不是地方行为的代表）。现有的时序异常检测社区缺乏专门的工具和过程来模型和可靠地检测异常情况。我们填补这个空白，引入了一种新的生成过程，用于创建含有低计数时序系列异常段的 referential 数据集。通过理论和实验分析，我们解释了广泛使用的算法在正常和异常段之间的分布重叠问题。为了解决这个缺陷，我们then 利用我们的发现，示出了如何使用异常分数平滑来提高性能。我们的分析和建议在实际的零售业务数据中得到了验证。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Distributed-Multi-Agent-Reinforcement-Learning-for-EV-Charging-Network-Control"><a href="#An-Efficient-Distributed-Multi-Agent-Reinforcement-Learning-for-EV-Charging-Network-Control" class="headerlink" title="An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control"></a>An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12921">http://arxiv.org/abs/2308.12921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amin Shojaeighadikolaei, Morteza Hashemi</li>
<li>for: 这篇论文是为了开发一个具有隐私保护的电动车充电控制器。</li>
<li>methods: 这篇论文使用多智能体循环 reinforcement learning（MARL）的架构，并将训练和执行分离，以保持隐私。</li>
<li>results: 研究结果显示，CTDE框架可以提高充电网络的性能，并降低总需求的峰值变化率（PAR），从而降低发电transformer的风险。<details>
<summary>Abstract</summary>
The increasing trend in adopting electric vehicles (EVs) will significantly impact the residential electricity demand, which results in an increased risk of transformer overload in the distribution grid. To mitigate such risks, there are urgent needs to develop effective EV charging controllers. Currently, the majority of the EV charge controllers are based on a centralized approach for managing individual EVs or a group of EVs. In this paper, we introduce a decentralized Multi-agent Reinforcement Learning (MARL) charging framework that prioritizes the preservation of privacy for EV owners. We employ the Centralized Training Decentralized Execution-Deep Deterministic Policy Gradient (CTDE-DDPG) scheme, which provides valuable information to users during training while maintaining privacy during execution. Our results demonstrate that the CTDE framework improves the performance of the charging network by reducing the network costs. Moreover, we show that the Peak-to-Average Ratio (PAR) of the total demand is reduced, which, in turn, reduces the risk of transformer overload during the peak hours.
</details>
<details>
<summary>摘要</summary>
随着电动车（EV）的普及趋势，室内电力需求将增加，从而增加分布网络中变压器的负担风险。为了解决这一问题，需要开发有效的电动车充电控制器。目前，大多数电动车充电控制器采用中央化的方法来管理个体电动车或一群电动车。在这篇论文中，我们介绍了一种分布式多代理人学习（MARL）充电框架，这种框架强调避免电动车所有者的隐私泄露。我们采用了中央训练分布执行-深度决策优化（CTDE-DDPG）方案，该方案在训练时提供有价值的信息，而执行时保持隐私。我们的结果显示，CTDE框架可以提高充电网络的性能，同时降低峰值负荷的风险。此外，我们还发现，峰值至平均值比（PAR）的总需求下降，从而降低了变压器过载的风险。
</details></li>
</ul>
<hr>
<h2 id="Towards-Realistic-Unsupervised-Fine-tuning-with-CLIP"><a href="#Towards-Realistic-Unsupervised-Fine-tuning-with-CLIP" class="headerlink" title="Towards Realistic Unsupervised Fine-tuning with CLIP"></a>Towards Realistic Unsupervised Fine-tuning with CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12919">http://arxiv.org/abs/2308.12919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan</li>
<li>for: 这篇论文的目的是探讨CLIP模型的不监控下精确推导，并且考虑到测验数据可能包含未知的类别。</li>
<li>methods: 这篇论文提出了一个简单、高效、有效的精确推导方法，称为全局Entropy优化（UEO），它利用样本级别的信任度来最小化可信度的条件 entropy 和最大化不可信度的条件 entropy。</li>
<li>results: 这篇论文通过对15个领域和4种不同的内部知识进行广泛的实验，展示了 UEO 在精确推导和未知类别检测方面的表现都较好。<details>
<summary>Abstract</summary>
The emergence of vision-language models (VLMs), such as CLIP, has spurred a significant research effort towards their application for downstream supervised learning tasks. Although some previous studies have explored the unsupervised fine-tuning of CLIP, they often rely on prior knowledge in the form of class names associated with ground truth labels. In this paper, we delve into a realistic unsupervised fine-tuning scenario by assuming that the unlabeled data might contain out-of-distribution samples from unknown classes. Furthermore, we emphasize the importance of simultaneously enhancing out-of-distribution detection capabilities alongside the recognition of instances associated with predefined class labels.   To tackle this problem, we present a simple, efficient, and effective fine-tuning approach called Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances. Apart from optimizing the textual prompts, UEO also incorporates optimization of channel-wise affine transformations within the visual branch of CLIP. Through extensive experiments conducted across 15 domains and 4 different types of prior knowledge, we demonstrate that UEO surpasses baseline methods in terms of both generalization and out-of-distribution detection.
</details>
<details>
<summary>摘要</summary>
“随着感知语言模型（VLM）的出现，如CLIP，研究人员对其应用于下游指导学习任务进行了大量的研究努力。 although some previous studies have explored the unsupervised fine-tuning of CLIP, they often rely on prior knowledge in the form of class names associated with ground truth labels. 在这篇论文中，我们进行了一个实际的无超级 fine-tuningenario，assuming that the unlabeled data may contain out-of-distribution samples from unknown classes. 此外，我们强调了同时增强不同类别的检测能力和预先定义的类别标签相关的instance检测。  To tackle this problem, we present a simple, efficient, and effective fine-tuning approach called Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances. Apart from optimizing the textual prompts, UEO also incorporates optimization of channel-wise affine transformations within the visual branch of CLIP. Through extensive experiments conducted across 15 domains and 4 different types of prior knowledge, we demonstrate that UEO surpasses baseline methods in terms of both generalization and out-of-distribution detection.”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Vulnerabilities-in-ML-systems-in-terms-of-adversarial-attacks"><a href="#Evaluating-the-Vulnerabilities-in-ML-systems-in-terms-of-adversarial-attacks" class="headerlink" title="Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks"></a>Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12918">http://arxiv.org/abs/2308.12918</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Harshith, Mantej Singh Gill, Madhan Jothimani</li>
<li>for: 本研究探讨了现代深度学习系统中的攻击漏洞问题，尤其是新型的敏感攻击方法对现有防御系统的挑战。</li>
<li>methods: 作者采用了许多不同的方法来研究攻击漏洞，包括讲解攻击漏洞的起源、随机例子和敏感例子的区别，以及攻击漏洞的伦理问题。</li>
<li>results: 研究发现，攻击漏洞可能对现有防御系统 pose 挑战，并且需要采取适当的训练措施来准备AI系统进行更广泛的应用。<details>
<summary>Abstract</summary>
There have been recent adversarial attacks that are difficult to find. These new adversarial attacks methods may pose challenges to current deep learning cyber defense systems and could influence the future defense of cyberattacks. The authors focus on this domain in this research paper. They explore the consequences of vulnerabilities in AI systems. This includes discussing how they might arise, differences between randomized and adversarial examples and also potential ethical implications of vulnerabilities. Moreover, it is important to train the AI systems appropriately when they are in testing phase and getting them ready for broader use.
</details>
<details>
<summary>摘要</summary>
有些最新的敌对攻击方法已经变得很难找到。这些新的敌对攻击方法可能会对当前的深度学习网络防御系统 pose 挑战，并可能影响未来的网络攻击防御。作者在这篇研究报告中关注这个领域。他们探讨了人工智能系统披露漏洞的后果，包括披露漏洞如何产生，Randomized和敌对示例之间的差异，以及披露漏洞的伦理性。此外，在测试阶段，我们需要适当地训练人工智能系统，以便在更广泛的应用中使用。
</details></li>
</ul>
<hr>
<h2 id="POLCA-Power-Oversubscription-in-LLM-Cloud-Providers"><a href="#POLCA-Power-Oversubscription-in-LLM-Cloud-Providers" class="headerlink" title="POLCA: Power Oversubscription in LLM Cloud Providers"></a>POLCA: Power Oversubscription in LLM Cloud Providers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12908">http://arxiv.org/abs/2308.12908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratyush Patel, Esha Choukse, Chaojie Zhang, Íñigo Goiri, Brijesh Warrier, Nithish Mahalingam, Ricardo Bianchini</li>
<li>for:  This paper is written to address the issue of power oversubscription in large language model (LLM) clusters, and to propose a framework for power oversubscription that is robust, reliable, and readily deployable.</li>
<li>methods:  The paper uses extensive characterization of power consumption patterns of various LLMs and their configurations, as well as simulations using open-source models to replicate the power patterns observed in production.</li>
<li>results:  The paper shows that there is a significant opportunity to oversubscribe power in LLM clusters, and that the average and peak power utilization in LLM clusters for inference should not be very high. The proposed framework, POLCA, is demonstrated to be able to deploy 30% more servers in the same GPU cluster for inference with minimal performance loss.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了解决大语言模型（LLM）集群中的电力过载问题，并提出一个可靠、可靠、ready to deploy的电力过载框架。</li>
<li>methods: 这篇论文使用了大量的LLM的电力消耗特征和配置的描述，以及使用开源模型来复制生产环境中观察到的电力特征来进行模拟。</li>
<li>results: 论文显示了LLM集群中的电力过载潜在性，并证明了average和peak电力使用率在LLM集群中的推理任务应该不太高。提议的框架POLCA可以在同一个GPU集群中部署30%更多的服务器来进行推理，而无需 sacrify性能。<details>
<summary>Abstract</summary>
Recent innovation in large language models (LLMs), and their myriad use-cases have rapidly driven up the compute capacity demand for datacenter GPUs. Several cloud providers and other enterprises have made substantial plans of growth in their datacenters to support these new workloads. One of the key bottleneck resources in datacenters is power, and given the increasing model sizes of LLMs, they are becoming increasingly power intensive. In this paper, we show that there is a significant opportunity to oversubscribe power in LLM clusters. Power oversubscription improves the power efficiency of these datacenters, allowing more deployable servers per datacenter, and reduces the deployment time, since building new datacenters is slow.   We extensively characterize the power consumption patterns of a variety of LLMs and their configurations. We identify the differences between the inference and training power consumption patterns. Based on our analysis of these LLMs, we claim that the average and peak power utilization in LLM clusters for inference should not be very high. Our deductions align with the data from production LLM clusters, revealing that inference workloads offer substantial headroom for power oversubscription. However, the stringent set of telemetry and controls that GPUs offer in a virtualized environment, makes it challenging to have a reliable and robust power oversubscription mechanism.   We propose POLCA, our framework for power oversubscription that is robust, reliable, and readily deployable for GPU clusters. Using open-source models to replicate the power patterns observed in production, we simulate POLCA and demonstrate that we can deploy 30% more servers in the same GPU cluster for inference, with minimal performance loss
</details>
<details>
<summary>摘要</summary>
Recent innovations in large language models (LLMs) have led to a surge in demand for datacenter GPUs, driving up compute capacity needs. Several cloud providers and enterprises have made significant plans for growth in their datacenters to support these new workloads. However, power remains a key bottleneck resource in datacenters, and as LLMs continue to increase in size, they are becoming increasingly power-intensive. In this paper, we explore the opportunity to oversubscribe power in LLM clusters, which can improve power efficiency, allow for more deployable servers per datacenter, and reduce deployment time.We analyze the power consumption patterns of various LLMs and their configurations, identifying differences between inference and training power consumption patterns. Based on our findings, we claim that the average and peak power utilization in LLM clusters for inference should not be very high. Our conclusions align with data from production LLM clusters, indicating that inference workloads offer substantial headroom for power oversubscription.However, the strict telemetry and controls offered by GPUs in a virtualized environment make it challenging to implement a reliable and robust power oversubscription mechanism. To address this challenge, we propose POLCA, our framework for power oversubscription that is robust, reliable, and readily deployable for GPU clusters.Using open-source models to replicate the power patterns observed in production, we simulate POLCA and demonstrate that we can deploy 30% more servers in the same GPU cluster for inference with minimal performance loss.
</details></li>
</ul>
<hr>
<h2 id="CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement"><a href="#CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement" class="headerlink" title="CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement"></a>CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12902">http://arxiv.org/abs/2308.12902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Hassan Khotanlou</li>
<li>for: 提高低光照图像的品质和明暗分布，以便更好地进行图像分析和 интерпретация。</li>
<li>methods: 基于 autoencoder 架构，具有卷积和权重块，并且具有注意力机制和跳过连接。</li>
<li>results: 在低光照图像增强任务中表现出色，与现有技术相比显著提高了图像的品质和明暗分布，并且在多种低光照场景中表现稳定和可靠。<details>
<summary>Abstract</summary>
Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs remarkably on benchmark datasets, effectively mitigating under-exposure and proficiently restoring textures and colors in diverse low-light scenarios. This achievement underscores CDAN's potential for diverse computer vision tasks, notably enabling robust object detection and recognition in challenging low-light conditions.
</details>
<details>
<summary>摘要</summary>
低光照图像，受到不足照明的限制，会呈现出降低的清晰度、淡化的颜色和减少的细节。低光照图像增强是计算机视觉中的一项重要任务，旨在通过提高亮度、对比度和总体观察质量来促进准确的分析和解释。本文介绍了一种新的低光照图像增强方法——卷积神经网络加注意机制（CDAN）。CDAN结合了自适应网络架构、卷积块和稠密块，并且添加了注意机制和跳过连接。这种架构使得信息传递得到有效地进行，并且Feature学习得到了保障。此外，专门的后处理阶段可以进一步调整颜色均衡和对比度。我们的方法在低光照图像增强任务中表现出了明显的进步，在多种复杂的场景中都能够达到州前的结果。我们的模型在标准测试集上表现出了remarkable的表现，可以有效地抑制下 exposure 和修充细节和颜色在多种低光照场景中。这一成就表明CDAN在计算机视觉任务中具有广泛的潜力，特别是在挑战性的低光照条件下进行Robust对象检测和识别。
</details></li>
</ul>
<hr>
<h2 id="Unified-Data-Management-and-Comprehensive-Performance-Evaluation-for-Urban-Spatial-Temporal-Prediction-Experiment-Analysis-Benchmark"><a href="#Unified-Data-Management-and-Comprehensive-Performance-Evaluation-for-Urban-Spatial-Temporal-Prediction-Experiment-Analysis-Benchmark" class="headerlink" title="Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]"></a>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12899">http://arxiv.org/abs/2308.12899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/libcity/bigscity-libcity">https://github.com/libcity/bigscity-libcity</a></li>
<li>paper_authors: Jiawei Jiang, Chengkai Han, Wayne Xin Zhao, Jingyuan Wang</li>
<li>for: 这个论文的目的是提高城市空间时间预测的精度和效率，以及为城市规划和管理带来长期的贡献。</li>
<li>methods: 该论文使用了“原子文件”的统一存储格式，以及对城市空间时间预测模型的全面概述和实验研究，以解决城市空间时间数据的访问和利用问题。</li>
<li>results: 该论文的实验结果显示，使用“原子文件”可以简化城市空间时间数据的管理，而且对40个多样化的数据集进行验证，并提供了一个性能排名，以帮助未来的研究。<details>
<summary>Abstract</summary>
The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets. However, challenges persist in accessing and utilizing diverse urban spatial-temporal datasets from different sources and stored in different formats, as well as determining effective model structures and components with the proliferation of deep learning models. This work addresses these challenges and provides three significant contributions. Firstly, we introduce "atomic files", a unified storage format designed for urban spatial-temporal big data, and validate its effectiveness on 40 diverse datasets, simplifying data management. Secondly, we present a comprehensive overview of technological advances in urban spatial-temporal prediction models, guiding the development of robust models. Thirdly, we conduct extensive experiments using diverse models and datasets, establishing a performance leaderboard and identifying promising research directions. Overall, this work effectively manages urban spatial-temporal data, guides future efforts, and facilitates the development of accurate and efficient urban spatial-temporal prediction models. It can potentially make long-term contributions to urban spatial-temporal data management and prediction, ultimately leading to improved urban living standards.
</details>
<details>
<summary>摘要</summary>
随着深度学习技术的发展和大规模数据的可用性，城市空间时间预测领域在迅速进步。然而，获取和利用多种城市空间时间数据的挑战仍然存在，这些数据来源于不同的地方，格式也不同。此外，深度学习模型的迅速增加也使得确定有效的模型结构和组件变得更加复杂。本文解决这些挑战，并为城市空间时间预测领域提供三大贡献。首先，我们引入“原子文件”，一种适合城市空间时间大数据的统一存储格式，并在40个多样化数据集上验证其效果，从而简化数据管理。其次，我们提供城市空间时间预测模型技术的全面概述，指导未来的发展。最后，我们通过多种模型和数据集进行广泛的实验，建立了性能排名和有前途的研究方向。总之，本文有效地管理城市空间时间数据，引导未来的努力，并促进了城市空间时间预测模型的准确和高效。这可能在长期内对城市空间时间数据管理和预测产生深远的影响，从而提高城市生活标准。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Document-Page-Classification-Design-Datasets-and-Challenges"><a href="#Beyond-Document-Page-Classification-Design-Datasets-and-Challenges" class="headerlink" title="Beyond Document Page Classification: Design, Datasets, and Challenges"></a>Beyond Document Page Classification: Design, Datasets, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12896">http://arxiv.org/abs/2308.12896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordy Van Landeghem, Sanket Biswas, Matthew B. Blaschko, Marie-Francine Moens</li>
<li>for: 这篇论文提出了将文档分类评测更加接近实际应用的需求，包括数据的性质（多通道、多页、多产业）和分类任务的类型（多页文档、页流、文档包）。</li>
<li>methods: 论文指出了公共多页文档分类数据集缺乏，正式了不同应用场景中的分类任务，并强调了完整文档表示的重要性。</li>
<li>results: 实验研究表明，现有的分类指标已经成为了无关的，需要更新以评测实际中的完整文档。这也需要更加成熟的评价方法，涵盖calibration评估、计算复杂性（时间-内存）和多种实际分布变换（例如，生成vs扫描噪声、页码顺序变换）。<details>
<summary>Abstract</summary>
This paper highlights the need to bring document classification benchmarking closer to real-world applications, both in the nature of data tested ($X$: multi-channel, multi-paged, multi-industry; $Y$: class distributions and label set variety) and in classification tasks considered ($f$: multi-page document, page stream, and document bundle classification, ...). We identify the lack of public multi-page document classification datasets, formalize different classification tasks arising in application scenarios, and motivate the value of targeting efficient multi-page document representations. An experimental study on proposed multi-page document classification datasets demonstrates that current benchmarks have become irrelevant and need to be updated to evaluate complete documents, as they naturally occur in practice. This reality check also calls for more mature evaluation methodologies, covering calibration evaluation, inference complexity (time-memory), and a range of realistic distribution shifts (e.g., born-digital vs. scanning noise, shifting page order). Our study ends on a hopeful note by recommending concrete avenues for future improvements.}
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/25/cs.LG_2023_08_25/" data-id="clltaagof006fr888fbtaa354" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/25/cs.CV_2023_08_25/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-08-25 21:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/24/cs.AI_2023_08_24/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.AI - 2023-08-24 20:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">92</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
