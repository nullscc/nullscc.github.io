
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.AS - 2023-08-08 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Investigating Speaker Embedding Disentanglement on Natural Read Speech paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.04225 repo_url: None paper_authors: Michael Kuhlmann, Adrian Meise, Fritz Seebauer, Petra Wa">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.AS - 2023-08-08">
<meta property="og:url" content="https://nullscc.github.io/2023/08/08/eess.AS_2023_08_08/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Investigating Speaker Embedding Disentanglement on Natural Read Speech paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.04225 repo_url: None paper_authors: Michael Kuhlmann, Adrian Meise, Fritz Seebauer, Petra Wa">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-08T14:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T08:46:20.792Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.AS_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/eess.AS_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T14:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.AS - 2023-08-08
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech"><a href="#Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech" class="headerlink" title="Investigating Speaker Embedding Disentanglement on Natural Read Speech"></a>Investigating Speaker Embedding Disentanglement on Natural Read Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04225">http://arxiv.org/abs/2308.04225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kuhlmann, Adrian Meise, Fritz Seebauer, Petra Wagner, Reinhold Haeb-Umbach</li>
<li>for: 这个论文的目的是研究语音表示的分解，以提高数据驱动模型的普适性、解释性和公正性。</li>
<li>methods: 该论文使用了标准的分解目标函数来训练语音表示，并对比了这些表示的分解程度。</li>
<li>results: 研究发现，使用标准的分解目标函数可以限制语音表示的分解程度，但可以通过一定程度的改进来提高分解效果。<details>
<summary>Abstract</summary>
Disentanglement is the task of learning representations that identify and separate factors that explain the variation observed in data. Disentangled representations are useful to increase the generalizability, explainability, and fairness of data-driven models. Only little is known about how well such disentanglement works for speech representations. A major challenge when tackling disentanglement for speech representations are the unknown generative factors underlying the speech signal. In this work, we investigate to what degree speech representations encoding speaker identity can be disentangled. To quantify disentanglement, we identify acoustic features that are highly speaker-variant and can serve as proxies for the factors of variation underlying speech. We find that disentanglement of the speaker embedding is limited when trained with standard objectives promoting disentanglement but can be improved over vanilla representation learning to some extent.
</details>
<details>
<summary>摘要</summary>
<SYS><translation_language_model>分化是学习表示法，以分解数据中观察到的变化的因素为目的。分化的表示法有助于提高数据驱动模型的普遍性、解释性和公平性。对于speech表示法，尚不了解分化是否有效。在这种工作中，我们研究了speech表示法中的发音者标识可以被分化的程度。为量分化，我们确定了一些高度发音者特定的音频特征，可以作为变化的因素下的 фактор代表。我们发现，使用标准的分化目标可以有限地分化发音者表示，但可以通过一些程度上的表示学习来提高分化。</translation_language_model></SYS>Here's the translation in Traditional Chinese as well:<SYS><translation_language_model>分化是学习表示法，以分解数据中观察到的变化的因素为目的。分化的表示法有助于提高数据驱动模型的普遍性、解释性和公平性。对于speech表示法，还不了解分化是否有效。在这种工作中，我们研究了speech表示法中的发音者标识可以被分化的程度。为量分化，我们确定了一些高度发音者特定的音频特征，可以作为变化的因素下的 фактор代表。我们发现，使用标准的分化目标可以有限地分化发音者表示，但可以通过一些程度上的表示学习来提高分化。</translation_language_model></SYS>
</details></li>
</ul>
<hr>
<h2 id="EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation"><a href="#EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation" class="headerlink" title="EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation"></a>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04162">http://arxiv.org/abs/2308.04162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab206/epcformer">https://github.com/lab206/epcformer</a></li>
<li>paper_authors: Jiajun Chen, Jiacheng Lin, Zhiqiang Xiao, Haolong Fu, Ke Nai, Kailun Yang, Zhiyong Li</li>
<li>for: 这 paper 是为了解决 audio-guided video object segmentation (A-VOS) 和 referring video object segmentation (R-VOS) 等两个高度相关的任务。</li>
<li>methods: 这 paper 使用了一种 universal architecture called Expression Prompt Collaboration Transformer (EPCFormer)，并提出了一种 Expression Alignment (EA) 机制和一种 Expression-Visual Attention (EVA) 机制来解决模式表示问题。</li>
<li>results: 实验结果表明，EPCFormer 可以在 A-VOS 和 R-VOS 两个任务上达到州际级Result。此外，EPCFormer 可以快速转移知识 между两个任务，从而提高视频对象 segmentation 的精度。<details>
<summary>Abstract</summary>
Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly-related tasks, which both aim to segment specific objects from video sequences according to user-provided expression prompts. However, due to the challenges in modeling representations for different modalities, contemporary methods struggle to strike a balance between interaction flexibility and high-precision localization and segmentation. In this paper, we address this problem from two perspectives: the alignment representation of audio and text and the deep interaction among audio, text, and visual features. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text expressions. By introducing contrastive learning for audio and text expressions, the proposed EPCFormer realizes comprehension of the semantic equivalence between audio and text expressions denoting the same objects. Then, to facilitate deep interactions among audio, text, and video features, we introduce an Expression-Visual Attention (EVA) mechanism. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our universal EPCFormer attains state-of-the-art results on both tasks. The source code of EPCFormer will be made publicly available at https://github.com/lab206/EPCFormer.
</details>
<details>
<summary>摘要</summary>
audio-guided视频对象 segmentation (A-VOS) 和 referring视频对象 segmentation (R-VOS) 是两个非常相关的任务，它们都是根据用户提供的表达提示从视频序列中提取特定对象的。然而，由于不同媒体表示的模型化问题，当前方法很难协调用用户提供的表达提示和高精度的地方化分割。在这篇论文中，我们解决这个问题从两个方面：表达提示的对齐表示和听力和文本特征之间的深度交互。首先，我们提出了一种通用架构，即表达 prompt collaboration transformer（EPCFormer）。然后，我们提出了一种表达对齐（EA）机制，用于对听力和文本表达进行对齐。通过对听力和文本表达进行对比学习，我们的提出的EPCFormer实现了对听力和文本表达的semantic equivalence的认知。然后，为了促进听力、文本和视频特征之间的深度交互，我们引入了表达-视频注意力（EVA）机制。通过深入探索听力、文本和视频特征之间的相互补做，我们的EPCFormer可以很好地传递知识 между两个任务。实验结果表明，我们的通用EPCFormer在两个任务上达到了现有最佳结果。代码将在https://github.com/lab206/EPCFormer上公开。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/eess.AS_2023_08_08/" data-id="clopawnz2010cag885ub16gnk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/08/cs.SD_2023_08_08/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.SD - 2023-08-08
        
      </div>
    </a>
  
  
    <a href="/2023/08/08/cs.CV_2023_08_08/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CV - 2023-08-08</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">67</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
