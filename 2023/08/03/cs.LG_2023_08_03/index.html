
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-03 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="The Capability of Large Language Models to Measure Psychiatric Functioning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.01834 repo_url: None paper_authors: Isaac R. Galatzer-Levy, Daniel McDuff, Vivek Nataraj">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-03 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/03/cs.LG_2023_08_03/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="The Capability of Large Language Models to Measure Psychiatric Functioning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.01834 repo_url: None paper_authors: Isaac R. Galatzer-Levy, Daniel McDuff, Vivek Nataraj">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-02T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:24.732Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.LG_2023_08_03/" class="article-date">
  <time datetime="2023-08-02T16:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-03 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning"><a href="#The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning" class="headerlink" title="The Capability of Large Language Models to Measure Psychiatric Functioning"></a>The Capability of Large Language Models to Measure Psychiatric Functioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01834">http://arxiv.org/abs/2308.01834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isaac R. Galatzer-Levy, Daniel McDuff, Vivek Natarajan, Alan Karthikesalingam, Matteo Malgaroli</li>
<li>for:  investigate the capability of Large language models (LLMs) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so.</li>
<li>methods:  using prompts to extract estimated clinical scores and diagnoses based on standardized assessments.</li>
<li>results:  Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments, which were statistically indistinguishable from human clinical raters.<details>
<summary>Abstract</summary>
The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so. To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23. Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.
</details>
<details>
<summary>摘要</summary>
当前研究探讨了大语言模型（LLM）在大量医学知识训练（Med-PaLM 2）下预测患者诊断和精神功能水平，不需要专门训练。为了评估这一点，研究使用了145例带有抑郁症和115例带有PTSD的评估，以及46例临床案例，涵盖高发病率/高混合病率的疾病（抑郁、焦虑、精神病、压力和 стресс、依数病）。结果表明Med-PaLM 2可以评估各种心理疾病的精神功能水平，特别是预测抑郁评估结果（准确率范围=0.80-0.84），这些结果与人类临床评估员的结果 statistically indistinguishable（t(1,144) = 1.20; p = 0.23）。结果表明大规模临床语言模型可以通过自由描述功能来预测心理风险。
</details></li>
</ul>
<hr>
<h2 id="Distribution-Free-Inference-for-the-Regression-Function-of-Binary-Classification"><a href="#Distribution-Free-Inference-for-the-Regression-Function-of-Binary-Classification" class="headerlink" title="Distribution-Free Inference for the Regression Function of Binary Classification"></a>Distribution-Free Inference for the Regression Function of Binary Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01835">http://arxiv.org/abs/2308.01835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ambrus Tamás, Balázs Csanád Csáji</li>
<li>for: 本研究论文的目的是提出一种可靠、分布自由和非假想的预测函数信任区的构建方法，以便在任选的信任水平下确定真实的预测函数。</li>
<li>methods: 本文提出了一种抽样框架，用于构建可靠、分布自由和非假想的预测函数信任区。Specific algorithms are also suggested to demonstrate the framework.</li>
<li>results: 研究证明了构建的信任区是强有效的，即任何不正确的模型都将在长期内被排除，并且这种排除的可靠性被证明为一个可靠的 Probably Approximately Correct (PAC) 类型上下文。<details>
<summary>Abstract</summary>
One of the key objects of binary classification is the regression function, i.e., the conditional expectation of the class labels given the inputs. With the regression function not only a Bayes optimal classifier can be defined, but it also encodes the corresponding misclassification probabilities. The paper presents a resampling framework to construct exact, distribution-free and non-asymptotically guaranteed confidence regions for the true regression function for any user-chosen confidence level. Then, specific algorithms are suggested to demonstrate the framework. It is proved that the constructed confidence regions are strongly consistent, that is, any false model is excluded in the long run with probability one. The exclusion is quantified with probably approximately correct type bounds, as well. Finally, the algorithms are validated via numerical experiments, and the methods are compared to approximate asymptotic confidence ellipsoids.
</details>
<details>
<summary>摘要</summary>
一个重要的二分类问题中的关键对象是回归函数，即输入 conditional 类别标签的预期值。通过回归函数不仅可以定义 Bayes 优化的分类器，还可以表示相应的误分类概率。文章提出了一种抽样框架，可以构造 exact， distribution-free 和非假正极限保证的信任区域，以确定真实的回归函数。然后，文章提供了特定的算法，以示出框架。文章证明了构造的信任区域是strongly consistent，即任何 false model 都会在长期内被排除，并且这种排除的可能性可以通过 probably approximately correct 类型上限来衡量。最后，算法被数学实验 validate，并与approxymatic confidence ellipsoids 进行比较。
</details></li>
</ul>
<hr>
<h2 id="Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness"><a href="#Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness" class="headerlink" title="Hard Adversarial Example Mining for Improving Robust Fairness"></a>Hard Adversarial Example Mining for Improving Robust Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01823">http://arxiv.org/abs/2308.01823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhao Lin, Xiang Ji, Yulong Yang, Qian Li, Chao Shen, Run Wang, Liming Fang</li>
<li>for: 这篇论文的目的是提高深度神经网络的抗对抗性（Adversarial Training，AT），并解决这些模型对于对抗示例（Adversarial Examples，AE）的不公正性问题。</li>
<li>methods: 这篇论文提出了一个简单 yet effective的框架，即适应式强制对抗示例挖掘（HAM），并通过适应性地挖掘强制对抗示例，并将容易的对抗示例早期弃用，以提高AT的效率和公平性。</li>
<li>results: 实验结果显示，这篇论文的HAM方法可以在CIFAR-10、SVHN和Imagenette等三个数据集上实现重要的公平性提升，同时降低了computational cost，比较了state-of-the-art adversarial training方法的效果。<details>
<summary>Abstract</summary>
Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
“对抗训练”（AT）是深度神经网络（DNN）对异常示例（AE）的状态艺术技术。然而，最近的研究发现，对抗训练模型具有不公平问题，限制其应用。在这篇论文中，我们直观地发现这一问题可能归结于严重的对抗信任过拟合问题，即某些对抗示例具有过分信任。为了解决这个问题，我们提出了HAM，一种简单 yet有效的框架，通过适应式硬对抗示例挖掘来解决这个问题。HAM会在计算损失值时将硬对抗示例与易于攻击的示例进行分离，并在早期阶段使用早期释出机制来优化AT。实验结果表明，HAM在CIFAR-10、SVHN和Imagenette上实现了显著的公平性提升，同时降低了计算成本，相比于一些现状最佳的对抗训练方法。代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Tensor-Programs-IVb-Adaptive-Optimization-in-the-Infinite-Width-Limit"><a href="#Tensor-Programs-IVb-Adaptive-Optimization-in-the-Infinite-Width-Limit" class="headerlink" title="Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit"></a>Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01814">http://arxiv.org/abs/2308.01814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Greg Yang, Etai Littwin</li>
<li>for: 这篇论文探讨了在宽神经网络中使用自适应优化器 like Adam 以外的新现象，包括批处理矩阵和核函数行为。</li>
<li>methods: 该论文使用了一种新的张量编程语言 NEXORT，以及 bras-ket notation，以描述如何使用 adaptive optimizers 处理梯度并生成更新。</li>
<li>results: 论文显示了在宽神经网络中使用 Adam 优化器时，存在类似于梯度下降优化器的特征学习和核函数行为，并提供了对这些行为的分析和总结。<details>
<summary>Abstract</summary>
Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam? Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of "kernel." We derive the corresponding "neural tangent" and "maximal update" limits for any architecture. Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates. 2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs. This work summarizes and generalizes all previous results in the Tensor Programs series of papers.
</details>
<details>
<summary>摘要</summary>
SGD 以外，在宽神经网络中使用自适应优化器如 Adam 的训练中，新的现象出现了什么？我们表明：SGD 中的特征学习和核函数行为之 dichotomy 也存在于总的优化器中，包括 Adam，但是它们是非线性的。我们 derivates 对应的 "神经折射" 和 "最大更新" 限制，对于任何架构都成立。这两个基本进展是：1）一种新的tensor program语言，NEXORT，可以表示如何自适应优化器将梯度转化为更新。2）在tensor program中引入bra-ket表示法，以简化表达和计算。这些成果总结了以前在tensor program series中的所有结果。
</details></li>
</ul>
<hr>
<h2 id="Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach"><a href="#Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach" class="headerlink" title="Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach"></a>Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01797">http://arxiv.org/abs/2308.01797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawoz/JSP-DeepRL-Seq2Seq">https://github.com/dawoz/JSP-DeepRL-Seq2Seq</a></li>
<li>paper_authors: Giovanni Bonetta, Davide Zago, Rossella Cancelliere, Andrea Grosso</li>
<li>for: 本研究旨在提出一种基于深度学习的Job调度算法，可以自动学习调度规则。</li>
<li>methods: 本研究使用了自然语言编码器-解码器模型，并在Job Shop问题的benchmark实例上进行了测试。</li>
<li>results: 研究结果显示，我们的方法可以超过许多传统的优先级调度规则，并与当前最佳深度学习方法相当竞争。<details>
<summary>Abstract</summary>
Job scheduling is a well-known Combinatorial Optimization problem with endless applications. Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste. Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task. This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention. Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.
</details>
<details>
<summary>摘要</summary>
This paper presents an original end-to-end deep reinforcement learning approach to job scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method on some benchmark instances of the Job Shop Problem, but it is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention.The results demonstrate that we outperform many classical approaches that use priority dispatching rules and show competitive results with state-of-the-art deep reinforcement learning methods.
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Adaptative-Variational-Quantum-Algorithms-on-QUBO-Instances"><a href="#Benchmarking-Adaptative-Variational-Quantum-Algorithms-on-QUBO-Instances" class="headerlink" title="Benchmarking Adaptative Variational Quantum Algorithms on QUBO Instances"></a>Benchmarking Adaptative Variational Quantum Algorithms on QUBO Instances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01789">http://arxiv.org/abs/2308.01789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gloria Turati, Maurizio Ferrari Dacrema, Paolo Cremonesi</li>
<li>for: 这篇论文主要是为了研究可变量量量算法（Adaptative VQAs），以解决在量子计算机NISQ时代中的优化问题。</li>
<li>methods: 这篇论文比较了三种 Adaptative VQAs：EVQE、VAns 和 RA-VQE，以及传统的量子近似优化算法（QAOA）。这些算法都是基于不同的启发，如环境深度、共轭能力和硬件兼容性，来动态修改环境的电路结构和参数。</li>
<li>results: 论文通过应用这些算法解决 QUBO 问题，并研究了这些算法的性能，包括解决的问题质量和计算时间。此外，论文还检查了不同的超参数选择方法对算法的总性能的影响，提出了选择合适方法进行超参数调整的重要性。<details>
<summary>Abstract</summary>
In recent years, Variational Quantum Algorithms (VQAs) have emerged as a promising approach for solving optimization problems on quantum computers in the NISQ era. However, one limitation of VQAs is their reliance on fixed-structure circuits, which may not be taylored for specific problems or hardware configurations. A leading strategy to address this issue are Adaptative VQAs, which dynamically modify the circuit structure by adding and removing gates, and optimize their parameters during the training. Several Adaptative VQAs, based on heuristics such as circuit shallowness, entanglement capability and hardware compatibility, have already been proposed in the literature, but there is still lack of a systematic comparison between the different methods. In this paper, we aim to fill this gap by analyzing three Adaptative VQAs: Evolutionary Variational Quantum Eigensolver (EVQE), Variable Ansatz (VAns), already proposed in the literature, and Random Adapt-VQE (RA-VQE), a random approach we introduce as a baseline. In order to compare these algorithms to traditional VQAs, we also include the Quantum Approximate Optimization Algorithm (QAOA) in our analysis. We apply these algorithms to QUBO problems and study their performance by examining the quality of the solutions found and the computational times required. Additionally, we investigate how the choice of the hyperparameters can impact the overall performance of the algorithms, highlighting the importance of selecting an appropriate methodology for hyperparameter tuning. Our analysis sets benchmarks for Adaptative VQAs designed for near-term quantum devices and provides valuable insights to guide future research in this area.
</details>
<details>
<summary>摘要</summary>
近年来，变量量子算法（VQA）在量子计算机NISQ时代 emerged as a promising approach for solving optimization problems. However, one limitation of VQAs is their reliance on fixed-structure circuits, which may not be tailored for specific problems or hardware configurations. To address this issue, adaptive VQAs have been proposed, which dynamically modify the circuit structure and optimize parameters during training. Several adaptive VQAs have been proposed based on heuristics such as circuit shallowness, entanglement capability, and hardware compatibility. However, there is still a lack of a systematic comparison between the different methods.In this paper, we aim to fill this gap by analyzing three adaptive VQAs: Evolutionary Variational Quantum Eigensolver (EVQE), Variable Ansatz (VAns), and Random Adapt-VQE (RA-VQE), as well as the Quantum Approximate Optimization Algorithm (QAOA) for comparison. We apply these algorithms to QUBO problems and study their performance by examining the quality of the solutions found and the computational times required. Additionally, we investigate the impact of hyperparameter choice on the overall performance of the algorithms, highlighting the importance of selecting an appropriate methodology for hyperparameter tuning. Our analysis sets benchmarks for adaptive VQAs designed for near-term quantum devices and provides valuable insights to guide future research in this area.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment"><a href="#Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment" class="headerlink" title="Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment"></a>Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01771">http://arxiv.org/abs/2308.01771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasin Shokrollahi1, Pengfei Dong1, Xianqi Li, Linxia Gu<br>for: This study aimed to develop a surrogate model for finite element analysis to predict stress-strain fields within 2D cross sections of arterial walls, which could replace traditional FEM methods and be more effective and efficient.methods: The study used a U-Net based fully convolutional neural network (CNN) and a conditional generative adversarial network (cGAN) to predict the von Mises stress and strain distribution, and also proposed their ensemble approaches to further improve the prediction accuracy.results: The trained U-Net models and cGAN models demonstrated high accuracy in predicting von Mises stress and strain fields, with SSIM scores of 0.854 and 0.830, and mean squared errors of 0.017 and 0.018 for stress and strain, respectively. The ensemble and transfer learning techniques also showed high accuracy, with SSIM scores of 0.890 for stress and 0.803 for strain, and mean squared errors of 0.008 for stress and 0.017 for strain.<details>
<summary>Abstract</summary>
This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Bag-of-Policies-for-Distributional-Deep-Exploration"><a href="#Bag-of-Policies-for-Distributional-Deep-Exploration" class="headerlink" title="Bag of Policies for Distributional Deep Exploration"></a>Bag of Policies for Distributional Deep Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01759">http://arxiv.org/abs/2308.01759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asen Nachkov, Luchen Li, Giulia Luise, Filippo Valdettaro, Aldo Faisal</li>
<li>for: 提高复杂环境中RL的效率探索</li>
<li>methods: 使用Bag of Policies（BoP）方法，其包括多个独立更新的头部，每个头在每个话题中控制一集state-action对，并使用这些对来更新所有头部</li>
<li>results: 通过实验证明，BoP方法可以提高RL在ALE Atari游戏中的robustness和速度<details>
<summary>Abstract</summary>
Efficient exploration in complex environments remains a major challenge for reinforcement learning (RL). Compared to previous Thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL. We develop here a general purpose approach, Bag of Policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies. BoP consists of an ensemble of multiple heads that are updated independently. During training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behaviour. To test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a population of distributional actor-critics using Bayesian Distributional Policy Gradients (BDPG). The population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies. Another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration. As BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL. Overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games.
</details>
<details>
<summary>摘要</summary>
RL中的有效探索仍然是一个主要挑战。与前期的汤姆逊探索机制相比，我们在分布RL中强调深入探索。我们开发了一个通用的方法，即袋子策略（Bag of Policies，BoP），它可以基于任何返回分布估计器建立。BoP包括多个独立更新的头，每个头控制一个episode，并将收集的状态-动作对用于所有头上不同策略进行off-policy更新，从而生成多个不同的学习信号，使得学习和行为更加多样化。为了测试optimistic ensemble方法在分布RL中是否能够提高性能，我们实现了BoP方法，使用了一个分布 actor-critic 的人工 intel 拟合 Bayesian Distributional Policy Gradients（BDPG）。这个人工 intel Population Approximates posterior distribution of return distributions and posterior distribution of policies。此外，由于BDPG已经是一个optimistic方法，这种结合可以同时分析分布RL中的全局 posterior uncertainty和本地好奇购买奖励。实验结果表明，BoP在ALE Atari游戏中显示出更高的稳定性和速度。
</details></li>
</ul>
<hr>
<h2 id="Guided-Distillation-for-Semi-Supervised-Instance-Segmentation"><a href="#Guided-Distillation-for-Semi-Supervised-Instance-Segmentation" class="headerlink" title="Guided Distillation for Semi-Supervised Instance Segmentation"></a>Guided Distillation for Semi-Supervised Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02668">http://arxiv.org/abs/2308.02668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq Berrada, Camille Couprie, Karteek Alahari, Jakob Verbeek</li>
<li>for: 提高Instance Segmentation的表现，减少完全监督图像的需求</li>
<li>methods: 使用 semi-supervised 方法，利用无标注数据作为训练信号，限制过拟合到标注样本</li>
<li>results: 提高 teacher-student 抽象模型的表现，在 Cityscapes 和 COCO 数据集上提高 mask-AP 的数值，例如在 Cityscapes 数据集上提高 mask-AP 从 23.7 到 33.9，在 COCO 数据集上提高 mask-AP 从 18.3 到 34.1<details>
<summary>Abstract</summary>
Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully-annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel "guided burn-in" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on the Cityscapes dataset we improve mask-AP from 23.7 to 33.9 when using labels for 10\% of images, and on the COCO dataset we improve mask-AP from 18.3 to 34.1 when using labels for only 1\% of the training data.
</details>
<details>
<summary>摘要</summary>
尽管实例分割方法已经有了很大的进步，但主流方法仍然是基于完全标注的训练图像，这是获取标注数据的很 tedious 和耗时的过程。为了解决这个问题，并提高结果，半supervised方法利用无标注数据作为额外的训练信号，以避免过拟合标注样本。在这个上下文中，我们提出了新的设计选择，以提高教师学生热键扩展模型。具体来说，我们（i）改进了热键扩展approach，通过引入新的“导航燃烧”阶段，以及（ii）评估不同的实例分割架构、后备网络和预训练策略。与前一些工作一样，我们只使用supervised数据进行学生模型的热键期，但我们还使用教师模型的指导来利用无标注数据，从而在热键期内进行学习。我们改进的热键扩展方法导致了substantial提高，比如在Cityscapes数据集上，我们提高了mask-AP从23.7到33.9，并在COCO数据集上提高了mask-AP从18.3到34.1，只使用标注数据的1%。
</details></li>
</ul>
<hr>
<h2 id="Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants"><a href="#Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants" class="headerlink" title="Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants"></a>Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01746">http://arxiv.org/abs/2308.01746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuralcollapseapplications/unicil">https://github.com/neuralcollapseapplications/unicil</a></li>
<li>paper_authors: Yibo Yang, Haobo Yuan, Xiangtai Li, Jianlong Wu, Lefei Zhang, Zhouchen Lin, Philip Torr, Dacheng Tao, Bernard Ghanem<br>for: 这篇论文的目的是解决在新类incremental learning中保持老类能力的问题，包括长尾类增量学习和几架shot类增量学习，这些问题在实际应用中非常普遍，并且使得旧类能力衰退问题更加严重。methods: 这篇论文提出了一个统一的解决方案，即神经坍缩终点（Neural Collapse Terminus，NCT），这是一个固定的结构，具有整个标签空间中最大的等角对称分类分布。NCT  acted as a consistent target throughout the incremental training, 以避免在增量训练中分配特征空间。results: 实验结果显示，这篇论文的方法可以在多个数据集上进行实际应用，并且在增量训练中保持旧类能力，同时在新类 incremental learning 中获得良好的性能。实验结果还显示，这篇论文的方法可以应对实际应用中的数据不均匀和数据缺乏问题，并且可以在不知道总共有多少个类别和数据分布是否正常、长尾或几架shot的情况下进行通用化。<details>
<summary>Abstract</summary>
How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.
</details>
<details>
<summary>摘要</summary>
如何维护新类的学习能力而不损害老类的能力是泛cremental learning中的一个关键挑战。此外，我们还考虑了实际情况中的数据不均衡和数据罕见性，并提出了长尾类增量学习和少数shot类增量学习两种方法。现有的方法主要针对一个任务。在这篇论文中，我们提出了增量训练中的不一致问题的统一解决方案。具体来说，我们提出了一个固定结构的神经溃终点，该结构具有整个标签空间中最大的等角间距。它在增量训练中作为不变的目标，以避免在增量训练中分割特征空间。为CIL和LTCIL任务，我们进一步提出了一种prototype evolving scheme来顺略地将后ION抽象到我们的神经溃终点中。我们的方法也适用于FSCIL任务，只需要小量的修改。理论分析表明，我们的方法在增量训练中保持了神经溃优化的优化，不受数据不均衡或数据罕见性的影响。我们还设计了一种通用情况，在每个来来Session中不知道总共有多少类和每个数据分布是正常、长尾或少数shot，以测试我们的方法的通用性。我们进行了多个数据集的广泛实验，以证明我们的统一解决方案对所有三个任务和通用情况具有效果。
</details></li>
</ul>
<hr>
<h2 id="Multitask-Learning-with-No-Regret-from-Improved-Confidence-Bounds-to-Active-Learning"><a href="#Multitask-Learning-with-No-Regret-from-Improved-Confidence-Bounds-to-Active-Learning" class="headerlink" title="Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning"></a>Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01744">http://arxiv.org/abs/2308.01744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pier Giuseppe Sessa, Pierre Laforgue, Nicolò Cesa-Bianchi, Andreas Krause<br>for: 这个论文的目的是提供一种在不知道任务之间相似性的情况下，实现多任务学习的信任度范围，以及一种基于这些信任度范围的在线学习算法。methods: 该论文使用了多任务信任度范围的新研究，通过对多任务信息增量进行细化分析，提供了新的 regret保证，具有任务相似性参数的依赖性。results: 该论文提出了一种自动地适应任务相似性的在线学习算法，并在synthetic和实际世界数据上进行了实验验证，证明了其bounds和算法的有效性。<details>
<summary>Abstract</summary>
Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel multitask confidence intervals in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.
</details>
<details>
<summary>摘要</summary>
多任务学习是一个强大的框架，它允许一个模型同时学习多个相关的任务，并在这些任务之间共享信息。在许多下游应用中，量化任务估计中的不确定性是非常重要的，例如在线学习或活动学习中。在这项工作中，我们提供了新的多任务信任范围，它在无相似性信息和任务特征信息的情况下提供，并且可以直接应用于 bound 在线学习中的 regret。通过对多任务信息增量进行细化分析，我们获得了新的 regret 保证，它们可以在任务相似度参数的情况下显著改进于独立处理任务。此外，我们还提出了一种新的在线学习算法，它可以在不知道任务相似度参数的情况下实现改进的 regret。作为第二个关键应用，我们引入了一种多任务活动学习设置，在这个设置中，学习器需要同时优化多个任务，但只有一个任务可以在每次轮次中被学习器请求反馈。为解决这个问题，我们设计了一种无损算法，它使用我们的信任范围来决定哪个任务应该被请求反馈。 finally，我们employnull对我们的 bound 和算法进行了实验 validate 。
</details></li>
</ul>
<hr>
<h2 id="Finding-the-Optimum-Design-of-Large-Gas-Engines-Prechambers-Using-CFD-and-Bayesian-Optimization"><a href="#Finding-the-Optimum-Design-of-Large-Gas-Engines-Prechambers-Using-CFD-and-Bayesian-Optimization" class="headerlink" title="Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization"></a>Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01743">http://arxiv.org/abs/2308.01743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Posch, Clemens Gößnitzer, Franz Rohrhofer, Bernhard C. Geiger, Andreas Wimmer</li>
<li>for: 大功率液化燃料发动机中的紧急液喷启火概念，以实现在副气比较低的情况下稳定燃烧，从而提高效率并降低排放。</li>
<li>methods: 计算流体动力学（CFD）模拟，用于评估不同设计参数下的启火器设计。</li>
<li>results: 使用欧几里得法则精度的Reynolds均值 Navier-Stokes  simulations来确定选择启火器设计参数时的目标值。结果表明选择的策略是有效地找到符合目标值的启火器设计。<details>
<summary>Abstract</summary>
The turbulent jet ignition concept using prechambers is a promising solution to achieve stable combustion at lean conditions in large gas engines, leading to high efficiency at low emission levels. Due to the wide range of design and operating parameters for large gas engine prechambers, the preferred method for evaluating different designs is computational fluid dynamics (CFD), as testing in test bed measurement campaigns is time-consuming and expensive. However, the significant computational time required for detailed CFD simulations due to the complexity of solving the underlying physics also limits its applicability. In optimization settings similar to the present case, i.e., where the evaluation of the objective function(s) is computationally costly, Bayesian optimization has largely replaced classical design-of-experiment. Thus, the present study deals with the computationally efficient Bayesian optimization of large gas engine prechambers design using CFD simulation. Reynolds-averaged-Navier-Stokes simulations are used to determine the target values as a function of the selected prechamber design parameters. The results indicate that the chosen strategy is effective to find a prechamber design that achieves the desired target values.
</details>
<details>
<summary>摘要</summary>
大型气Engine预室设计使用液体喷射技术可能是实现稳定燃烧在质量低的情况下高效燃烧的有望解决方案。由于大型气Engine预室设计和运行参数的范围很广，因此计算流体力学（CFD）是评估不同设计的首选方法，因为测试床测量campaign是时间consuming和昂贵的。然而，由于解决下面的物理学问题的复杂度，详细的CFD simulations也有限制其应用。在优化设定中，例如现在的案例，i.e., where the evaluation of the objective function(s) is computationally costly, Bayesian optimization has largely replaced classical design-of-experiment。因此，本研究关注计算效率高的抽象归一化优化大型气Engine预室设计使用CFD simulations。Reynolds-averaged-Navier-Stokes simulations are used to determine the target values as a function of the selected prechamber design parameters. The results indicate that the chosen strategy is effective to find a prechamber design that achieves the desired target values.
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Multi-Label-Correlation-in-Label-Distribution-Learning"><a href="#Exploiting-Multi-Label-Correlation-in-Label-Distribution-Learning" class="headerlink" title="Exploiting Multi-Label Correlation in Label Distribution Learning"></a>Exploiting Multi-Label Correlation in Label Distribution Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01742">http://arxiv.org/abs/2308.01742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Kou jing wang yuheng jia xin geng</li>
<li>for: 本研究旨在提出一种新的机器学习模式即分布式标签学习（LDL），以便解决机器学习问题中的指标空间呈指数级别的问题。</li>
<li>methods: 本研究采用了一种新的方法，即通过在多个标签学习（MLL）中采用低级别标签相互关系来捕捉标签相互关系。</li>
<li>results: 经过对比分析，本研究发现了现有LDL方法的缺陷，并提出了一种新的方法，即通过在MLL中采用低级别标签相互关系来捕捉标签相互关系，从而提高LDL方法的性能。<details>
<summary>Abstract</summary>
Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance. Many LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation. However, recent studies disclosed that label distribution matrices are typically full-rank, posing challenges to those works exploiting low-rank label correlation. Note that multi-label is generally low-rank; low-rank label correlation is widely adopted in multi-label learning (MLL) literature. Inspired by that, we introduce an auxiliary MLL process in LDL and capture low-rank label correlation on that MLL rather than LDL. In such a way, low-rank label correlation is appropriately exploited in our LDL methods. We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods. Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL.
</details>
<details>
<summary>摘要</summary>
标签分布学习（LDL）是一种新的机器学习方案，它将标签分布分配给每个实例。许多LDL方法尝试利用标签关系来解决不同输出空间的问题，其中许多方法利用标签分布的低级结构来捕捉标签关系。然而，最近的研究发现，标签分布矩阵通常是全级结构的，这对于那些利用低级标签关系的方法带来了挑战。注意，多标签通常是低级的，低级标签关系广泛采用在多标签学习（MLL）文献中。针对这一点，我们引入了一个辅助的多标签学习过程（MLL），并在这个MLL上捕捉低级标签关系。这样做的优点是，我们可以正确地利用低级标签关系在LDL中。我们进行了广泛的实验，并证明了我们的方法比现有的LDL方法更高效。此外，缺省研究证明了在辅助MLL中利用低级标签关系的优势。
</details></li>
</ul>
<hr>
<h2 id="Bringing-Chemistry-to-Scale-Loss-Weight-Adjustment-for-Multivariate-Regression-in-Deep-Learning-of-Thermochemical-Processes"><a href="#Bringing-Chemistry-to-Scale-Loss-Weight-Adjustment-for-Multivariate-Regression-in-Deep-Learning-of-Thermochemical-Processes" class="headerlink" title="Bringing Chemistry to Scale: Loss Weight Adjustment for Multivariate Regression in Deep Learning of Thermochemical Processes"></a>Bringing Chemistry to Scale: Loss Weight Adjustment for Multivariate Regression in Deep Learning of Thermochemical Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01954">http://arxiv.org/abs/2308.01954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Franz M. Rohrhofer, Stefan Posch, Clemens Gößnitzer, José M. García-Oliver, Bernhard C. Geiger</li>
<li>for: 本研究旨在改进人工神经网络（ANN）在多变量回归任务中学习多种物质质量分布。</li>
<li>methods: 本研究使用了一种简单 yet effective的损失重量调整，以提高ANN在学习多种物质质量分布时的准确性。</li>
<li>results: 研究发现，这种损失重量调整可以使ANN更加准确地学习所有物质质量分布，包括次要物质的质量分布，而标准的平均方差优化则完全失败。此外，调整后的损失重量使得网络训练过程中的梯度更加均衡，这解释了其效果。<details>
<summary>Abstract</summary>
Flamelet models are widely used in computational fluid dynamics to simulate thermochemical processes in turbulent combustion. These models typically employ memory-expensive lookup tables that are predetermined and represent the combustion process to be simulated. Artificial neural networks (ANNs) offer a deep learning approach that can store this tabular data using a small number of network weights, potentially reducing the memory demands of complex simulations by orders of magnitude. However, ANNs with standard training losses often struggle with underrepresented targets in multivariate regression tasks, e.g., when learning minor species mass fractions as part of lookup tables. This paper seeks to improve the accuracy of an ANN when learning multiple species mass fractions of a hydrogen (\ce{H2}) combustion lookup table. We assess a simple, yet effective loss weight adjustment that outperforms the standard mean-squared error optimization and enables accurate learning of all species mass fractions, even of minor species where the standard optimization completely fails. Furthermore, we find that the loss weight adjustment leads to more balanced gradients in the network training, which explains its effectiveness.
</details>
<details>
<summary>摘要</summary>
法则模型广泛用于计算流体动力学来模拟热化学过程，以便在液体燃烧中预测燃烧过程。这些模型通常使用占用内存的lookup表，这些表示燃烧过程要模拟。人工神经网络（ANNs）提供了深度学习方法，可以将这些表格数据存储在小数量的网络参数中，从而可能减少复杂的计算模拟中的内存需求。然而，标准训练损失通常在多变量回归任务中struggle with underrepresented targets，例如在学习某些小分子质量 Fraction as part of lookup tables。本文旨在提高ANN在学习多种种质量 Fraction的氢（\ce{H2）}燃烧lookup表时的准确性。我们评估了一个简单，却有效的权重调整，该超过标准的平均方差优化，使得网络学习所有种质量 Fraction，包括次要种的质量 Fraction，其标准优化完全失败。此外，我们发现权重调整导致了网络训练中的更加平衡的梯度，这解释了其效果。
</details></li>
</ul>
<hr>
<h2 id="MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction"><a href="#MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction" class="headerlink" title="MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction"></a>MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01737">http://arxiv.org/abs/2308.01737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chiangel/map-code">https://github.com/chiangel/map-code</a></li>
<li>paper_authors: Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, Weinan Zhang</li>
<li>for: 这篇论文主要针对的是 clicked-through rate（CTR）预测，尤其是在大规模线上个人化服务中，为了提高CTR预测的精度和效率。</li>
<li>methods: 这篇论文提出了一个基于自动学习的预备架构（MAP），并提出了两种实用的算法：伪设对于每个实例中的特征进行隐藏和预测（Masked Feature Prediction，MFP），以及替换特征的检测（Replaced Feature Detection，RFD）。这些算法可以对大规模的用户点击logs进行自动学习，以提高CTR预测的精度和效率。</li>
<li>results: 根据该论文的实验结果，这两种算法可以在两个真实世界的大规模数据集（Avazu和Criteo）上达到新的州度测试表现，并在多个强大的后置模型（例如DCNv2和DeepFM）上显示出比较好的效果和效率。<details>
<summary>Abstract</summary>
With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data. Specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining.Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details></li>
</ul>
<hr>
<h2 id="Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling"><a href="#Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling" class="headerlink" title="Quantification of Predictive Uncertainty via Inference-Time Sampling"></a>Quantification of Predictive Uncertainty via Inference-Time Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01731">http://arxiv.org/abs/2308.01731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarína Tóthová, Ľubor Ladický, Daniel Thul, Marc Pollefeys, Ender Konukoglu</li>
<li>for: 这项研究旨在解决数据uncertainty导致预测不确定性的问题，提出了一种后期采样策略来估计预测不确定性。</li>
<li>methods: 该方法不需要特定的建筑Component或训练机制，可以应用于任何具有Feed-Forward Deterministic Network的模型，无需改变建筑或训练过程。</li>
<li>results: 实验结果表明，该方法可以生成多种可能性 distributions，与预测错误之间存在良好的相关性。<details>
<summary>Abstract</summary>
Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest. These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions. In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity. The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions. It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure. Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.
</details>
<details>
<summary>摘要</summary>
通常情况下，预测变化因数据 ambiguity 被通过建立专门的模型，这些模型具有内置的 probabilistic 能力，并通过训练来预测不确定性估计。这些方法可能需要特定的体系结构和训练机制，并且可能受限于假设和过于自信。在这项工作中，我们提出了一种后期抽样策略，用于估计预测不确定性，考虑到数据 ambiguity。这种方法可以生成不同的可能输出，并不假设预测分布的 parametic 形式。它是体系无关的，可以应用于任何批处网络，无需改变体系结构或训练过程。在重静态和非静态输入数据上的回归任务中，我们的方法能够生成多种多样的预测分布，并且预测不确定性与预测错误之间存在适当的相关性。
</details></li>
</ul>
<hr>
<h2 id="Telematics-Combined-Actuarial-Neural-Networks-for-Cross-Sectional-and-Longitudinal-Claim-Count-Data"><a href="#Telematics-Combined-Actuarial-Neural-Networks-for-Cross-Sectional-and-Longitudinal-Claim-Count-Data" class="headerlink" title="Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data"></a>Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01729">http://arxiv.org/abs/2308.01729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francis Duval, Jean-Philippe Boucher, Mathieu Pigeon</li>
<li>for: 这个论文的目的是提出一种基于CANN框架的车保险laim count模型，用于评估和预测驾驶行为对车保险的影响。</li>
<li>methods: 这个论文使用了一种combined actuarial neural network（CANN）模型，该模型结合了经典的概率模型和神经网络，以提高评估驾驶行为对车保险的精度和可靠性。</li>
<li>results: 研究结果表明，使用CANN模型可以比以经典的ilog-linear模型来评估驾驶行为对车保险的影响，并且可以更好地评估驾驶行为的复杂性和相互关系。<details>
<summary>Abstract</summary>
We present novel cross-sectional and longitudinal claim count models for vehicle insurance built upon the Combined Actuarial Neural Network (CANN) framework proposed by Mario W\"uthrich and Michael Merz. The CANN approach combines a classical actuarial model, such as a generalized linear model, with a neural network. This blending of models results in a two-component model comprising a classical regression model and a neural network part. The CANN model leverages the strengths of both components, providing a solid foundation and interpretability from the classical model while harnessing the flexibility and capacity to capture intricate relationships and interactions offered by the neural network. In our proposed models, we use well-known log-linear claim count regression models for the classical regression part and a multilayer perceptron (MLP) for the neural network part. The MLP part is used to process telematics car driving data given as a vector characterizing the driving behavior of each insured driver. In addition to the Poisson and negative binomial distributions for cross-sectional data, we propose a procedure for training our CANN model with a multivariate negative binomial (MVNB) specification. By doing so, we introduce a longitudinal model that accounts for the dependence between contracts from the same insured. Our results reveal that the CANN models exhibit superior performance compared to log-linear models that rely on manually engineered telematics features.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的跨部分和长期声明计数模型，用于汽车保险，基于Mario W\"uthrich和Michael Merz所提出的combined actuarial neural network（CANN）框架。CANN模型结合了一种经典的 actuarial模型，如一般线性模型，和一个神经网络。这种模型融合结果形成了一个两部分模型，包括一个经典回归模型和一个神经网络部分。CANN模型利用了经典模型的优点，提供了坚实的基础和解释，同时具有神经网络的灵活性和能力捕捉复杂的关系和交互。在我们的提议中，我们使用了常见的 log-linear 声明计数回归模型作为经典回归部分，并使用一个多层感知器（MLP）作为神经网络部分。MLP部分用于处理每名保险人的驾驶行为数据，即作为一个向量表示驾驶行为。此外，我们还提出了一种训练 CANN 模型的多变量负 binomial（MVNB）规范。通过这种方法，我们开发了一种长期模型，帮助考虑保险合同之间的依赖关系。我们的结果表明，CANN 模型在基于手动设计的驾驶特征的情况下显示出了更高的性能，与经典 log-linear 模型相比。
</details></li>
</ul>
<hr>
<h2 id="ADRNet-A-Generalized-Collaborative-Filtering-Framework-Combining-Clinical-and-Non-Clinical-Data-for-Adverse-Drug-Reaction-Prediction"><a href="#ADRNet-A-Generalized-Collaborative-Filtering-Framework-Combining-Clinical-and-Non-Clinical-Data-for-Adverse-Drug-Reaction-Prediction" class="headerlink" title="ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction"></a>ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02571">http://arxiv.org/abs/2308.02571</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoxuanli-pku/adrnet">https://github.com/haoxuanli-pku/adrnet</a></li>
<li>paper_authors: Haoxuan Li, Taojun Hu, Zetong Xiong, Chunyuan Zheng, Fuli Feng, Xiangnan He, Xiao-Hua Zhou</li>
<li>for: 预测药物副作用（ADR）的incidence rate，以提高医疗和药品发现中的安全性。</li>
<li>methods: 基于drugg-ADR的协同缓存问题进行预测，并利用非临床数据中的药物特征进行补充。</li>
<li>results: 通过对两个大规模的临床数据集进行广泛的比较，证明ADRNet可以准确地预测多个标签ADR。<details>
<summary>Abstract</summary>
Adverse drug reaction (ADR) prediction plays a crucial role in both health care and drug discovery for reducing patient mortality and enhancing drug safety. Recently, many studies have been devoted to effectively predict the drug-ADRs incidence rates. However, these methods either did not effectively utilize non-clinical data, i.e., physical, chemical, and biological information about the drug, or did little to establish a link between content-based and pure collaborative filtering during the training phase. In this paper, we first formulate the prediction of multi-label ADRs as a drug-ADR collaborative filtering problem, and to the best of our knowledge, this is the first work to provide extensive benchmark results of previous collaborative filtering methods on two large publicly available clinical datasets. Then, by exploiting the easy accessible drug characteristics from non-clinical data, we propose ADRNet, a generalized collaborative filtering framework combining clinical and non-clinical data for drug-ADR prediction. Specifically, ADRNet has a shallow collaborative filtering module and a deep drug representation module, which can exploit the high-dimensional drug descriptors to further guide the learning of low-dimensional ADR latent embeddings, which incorporates both the benefits of collaborative filtering and representation learning. Extensive experiments are conducted on two publicly available real-world drug-ADR clinical datasets and two non-clinical datasets to demonstrate the accuracy and efficiency of the proposed ADRNet. The code is available at https://github.com/haoxuanli-pku/ADRnet.
</details>
<details>
<summary>摘要</summary>
药物反应（ADR）预测对于医疗和药物发现具有重要作用，可以降低病人死亡率并提高药物安全性。在最近的研究中，许多研究者已经努力地预测药物-ADR的发生率。然而，这些方法大多未能有效地利用药物的非临床数据，例如物理、化学和生物学信息。此外，这些方法也未能够在训练阶段建立物理和纯粹的共同滤波技术之间的连接。在本文中，我们将药物多标签ADR预测定为药物-ADR共同滤波问题，并且，到我们所知，这是第一篇对两个大规模公共可用临床数据进行了广泛的比较分析的研究。然后，我们提出了ADRNet，一种通用的共同滤波框架，结合临床和非临床数据来预测药物-ADR。具体来说，ADRNet包括一个浅层共同滤波模块和一个深度药物表示模块，可以利用高维药物描述符进一步导航低维ADR秘密嵌入的学习，这里包括了共同滤波和表示学习的两大好处。我们对两个公共可用的真实世界药物-ADR临床数据集和两个非临床数据集进行了广泛的实验，以证明我们提出的ADRNet的准确和效率。代码可以在https://github.com/haoxuanli-pku/ADRnet上获取。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks"><a href="#Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks" class="headerlink" title="Evaluating Link Prediction Explanations for Graph Neural Networks"></a>Evaluating Link Prediction Explanations for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01682">http://arxiv.org/abs/2308.01682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cborile/eval_lp_xai">https://github.com/cborile/eval_lp_xai</a></li>
<li>paper_authors: Claudio Borile, Alan Perotti, André Panisson</li>
<li>for: 本研究旨在提供链接预测模型的解释评价指标，以便帮助推广Graph Machine Learning（GML）模型的应用。</li>
<li>methods: 本研究使用了现有的解释方法，如Graph Neural Networks（GNN），并评估了它们的解释质量。</li>
<li>results: 研究发现，选择距离 между节点表示的选择对链接预测解释质量有重要影响。此外，研究还发现了一些技术细节和假设对链接预测解释质量的影响。<details>
<summary>Abstract</summary>
Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.
</details>
<details>
<summary>摘要</summary>
机器学习（GML）在实际领域有广泛的应用，如节点/图分类和链接预测。提供可理解的GML模型解释是推广其使用的挑战，但链接预测模型的解释 Validating explanations has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.Here's the translation in Traditional Chinese:机器学习（GML）在实际领域有广泛的应用，如节点/图分类和链接预测。提供可理解的GML模型解释是推广其使用的挑战，但链接预测模型的解释 Validating explanations has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.
</details></li>
</ul>
<hr>
<h2 id="Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER"><a href="#Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER" class="headerlink" title="Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER"></a>Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02570">http://arxiv.org/abs/2308.02570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Chen, Jiajia Liu, Kaixiang Ji, Wang Ren, Jian Wang, Jingdong Wang</li>
<li>for: 本文提出了一种解决多modal named entity recognition（MNER）中的两个挑战的方法，即 bridging the semantic gap between text and image，以及匹配实体与其相关的对象在图像中。</li>
<li>methods: 本文提出了一种名为BGA-MNER的双向生成对应方法，该方法包括\texttt{image2text}和\texttt{text2image}两个生成阶段，以及对实体特征含义的生成对应。</li>
<li>results: 经过广泛的实验 validate，本文的方法在两个benchmark上达到了无需图像输入 durante la inferencia的状态之决性性能。<details>
<summary>Abstract</summary>
The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our method achieves state-of-the-art performance without image input during inference.
</details>
<details>
<summary>摘要</summary>
The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in the image. Existing methods fail to capture the implicit entity-object relations due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our method achieves state-of-the-art performance without image input during inference.Here's the translation in Traditional Chinese as well:The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in the image. Existing methods fail to capture the implicit entity-object relations due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our method achieves state-of-the-art performance without image input during inference.Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Efficiency-of-First-Order-Methods-for-Low-Rank-Tensor-Recovery-with-the-Tensor-Nuclear-Norm-Under-Strict-Complementarity"><a href="#Efficiency-of-First-Order-Methods-for-Low-Rank-Tensor-Recovery-with-the-Tensor-Nuclear-Norm-Under-Strict-Complementarity" class="headerlink" title="Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity"></a>Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01677">http://arxiv.org/abs/2308.01677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Garber, Atara Kaplan</li>
<li>for: 本文是关于使用凸relaxation来重建低维度张量的研究。</li>
<li>methods: 本文使用了凸relaxation方法，包括拟合线性map和拟合quadratic形函数。</li>
<li>results: 本文得到了以下三个结果：1. 当 objective 函数为形式 $f(\mX)&#x3D;g(\mA\mX)+\langle{\mC,\mX}\rangle$，其中 $g$ 是强制凸函数，且 $\mA$ 是线性映射， Then 有一个quadratic growth bound，implying linear convergence rates for standard projected gradient methods。 2. 对于一个平滑函数 objective，当初始化在一个满足 SC 的优解中，then standard projected gradient methods only require SVD computations (for projecting onto the tensor nuclear norm ball) of rank that matches the tubal rank of the optimal solution。 3. 对于一个非平滑函数 objective，we derive similar results for the well known extragradient method。 Additionally, the paper extends many basic results regarding tensors of arbitrary order, which were previously obtained only for third-order tensors.<details>
<summary>Abstract</summary>
We consider convex relaxations for recovering low-rank tensors based on constrained minimization over a ball induced by the tensor nuclear norm, recently introduced in \cite{tensor_tSVD}. We build on a recent line of results that considered convex relaxations for the recovery of low-rank matrices and established that under a strict complementarity condition (SC), both the convergence rate and per-iteration runtime of standard gradient methods may improve dramatically. We develop the appropriate strict complementarity condition for the tensor nuclear norm ball and obtain the following main results under this condition: 1. When the objective to minimize is of the form $f(\mX)=g(\mA\mX)+\langle{\mC,\mX}\rangle$ , where $g$ is strongly convex and $\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds, which implies linear convergence rates for standard projected gradient methods, despite the fact that $f$ need not be strongly convex. 2. For a smooth objective function, when initialized in certain proximity of an optimal solution which satisfies SC, standard projected gradient methods only require SVD computations (for projecting onto the tensor nuclear norm ball) of rank that matches the tubal rank of the optimal solution. In particular, when the tubal rank is constant, this implies nearly linear (in the size of the tensor) runtime per iteration, as opposed to super linear without further assumptions. 3. For a nonsmooth objective function which admits a popular smooth saddle-point formulation, we derive similar results to the latter for the well known extragradient method. An additional contribution which may be of independent interest, is the rigorous extension of many basic results regarding tensors of arbitrary order, which were previously obtained only for third-order tensors.
</details>
<details>
<summary>摘要</summary>
我们考虑使用凸关键函数来回复低维度tensor的方法，基于给定的凸关键函数球体上的受限最小化。我们在\cite{tensor_tSVD}中引入的tensor核心 нор的凸关键函数球体上建立了严格的完全相互矛盾（SC）的必要条件。我们获得以下主要结果：1. 当待解函数为$f(\mX)=g(\mA\mX)+\langle{\mC,\mX}\rangle$，其中$g$是强式凸函数且$\mA$是线性映射（例如最小二乘）， THEN 一个径度增长范围将成立，这意味着标准投影方法将在待解函数中展现出直线增长率，即使待解函数并不是强式凸函数。2. 当待解函数为几何函数且初值在具有SC的优解中， THEN 标准投影方法只需要在tensor核心 norm球体上进行SVD计算（用于对待解函数进行投影），其中SVD的维度与优解的管径维度相同。这意味着在无变量大小的tensor上，每次迭代的时间几乎是常量，而不是增长的。3. 当待解函数为非凸函数且具有流行的滑块形式则，我们 derive了类似的结果，对于通过extrapolation method来解决的问题。此外，我们还提供了一些独立有用的结果，例如在tensor的任意维度上，许多基本结果的扩展，这些结果在以前只有在第三维tensor上被证明。
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Reinforcement-Learning-of-Koopman-Models-for-Economic-Nonlinear-MPC"><a href="#End-to-End-Reinforcement-Learning-of-Koopman-Models-for-Economic-Nonlinear-MPC" class="headerlink" title="End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC"></a>End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01674">http://arxiv.org/abs/2308.01674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Mayfrank, Alexander Mitsos, Manuel Dahmen</li>
<li>for: 本研究旨在提出一种数据驱动的汽车模型，以便在实时控制中减少计算成本。</li>
<li>methods: 该方法使用端到端学习来学习动态模型，并通过对实际数据进行训练来提高预测性能。</li>
<li>results: 研究结果显示，使用该方法可以实时生成高性能的预测模型，并且可以在控制设置变化时快速适应。同时，该方法与传统的最大预测精度方法和模型自适应方法相比，能够减少计算成本。<details>
<summary>Abstract</summary>
(Economic) nonlinear model predictive control ((e)NMPC) requires dynamic system models that are sufficiently accurate in all relevant state-space regions. These models must also be computationally cheap enough to ensure real-time tractability. Data-driven surrogate models for mechanistic models can be used to reduce the computational burden of (e)NMPC; however, such models are typically trained by system identification for maximum average prediction accuracy on simulation samples and perform suboptimally as part of actual (e)NMPC. We present a method for end-to-end reinforcement learning of dynamic surrogate models for optimal performance in (e)NMPC applications, resulting in predictive controllers that strike a favorable balance between control performance and computational demand. We validate our method on two applications derived from an established nonlinear continuous stirred-tank reactor model. We compare the controller performance to that of MPCs utilizing models trained by the prevailing maximum prediction accuracy paradigm, and model-free neural network controllers trained using reinforcement learning. We show that our method matches the performance of the model-free neural network controllers while consistently outperforming models derived from system identification. Additionally, we show that the MPC policies can react to changes in the control setting without retraining.
</details>
<details>
<summary>摘要</summary>
经济非线性模型预测控制（(E)NMPC）需要具有 suficiently 精度的动态系统模型，以 guaranteee 在所有有用的状态空间Region中准确。这些模型还需要够快速计算，以确保实时可行性。使用数据驱动的替身模型来减少(E)NMPC中模型计算的复杂性可以使其更加快速，但这些模型通常通过系统标准化来训练，并且在实际(E)NMPC应用中表现不佳。我们提出了一种终端渐进学习的动态替身模型，以实现在(E)NMPC应用中的优化性能。我们验证了我们的方法，并与现有的最大预测精度 paradigm和模型自由神经网络控制器进行比较。我们发现，我们的方法与模型自由神经网络控制器的性能相同，而且一直占据了模型来自系统标准化的性能。此外，我们还发现MPC策略可以根据控制设置的变化而反应，而不需要重新训练。
</details></li>
</ul>
<hr>
<h2 id="UniG-Encoder-A-Universal-Feature-Encoder-for-Graph-and-Hypergraph-Node-Classification"><a href="#UniG-Encoder-A-Universal-Feature-Encoder-for-Graph-and-Hypergraph-Node-Classification" class="headerlink" title="UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification"></a>UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01650">http://arxiv.org/abs/2308.01650</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minhzou/unig-encoder">https://github.com/minhzou/unig-encoder</a></li>
<li>paper_authors: Minhao Zou, Zhongxue Gan, Yutong Wang, Junheng Zhang, Dongyan Sui, Chun Guan, Siyang Leng</li>
<li>for: 这篇论文的目的是为了提出一种 универсальный特征编码器，用于图和高级图表示学习。</li>
<li>methods: 该方法使用一个前向变换将图的 topological 关系转化为边或超边特征，然后将这些特征和原始节点特征 feed 入神经网络，最后使用反向变换，即投影矩阵的读取，获得编码后的节点嵌入。</li>
<li>results: 对于十二个 representativ 的高级图数据集和六个实际图数据集，该方法在对比state-of-the-art方法时显示出了更高的性能。<details>
<summary>Abstract</summary>
Graph and hypergraph representation learning has attracted increasing attention from various research fields. Despite the decent performance and fruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural Networks (HGNNs), and their well-designed variants, on some commonly used benchmark graphs and hypergraphs, they are outperformed by even a simple Multi-Layer Perceptron. This observation motivates a reexamination of the design paradigm of the current GNNs and HGNNs and poses challenges of extracting graph features effectively. In this work, a universal feature encoder for both graph and hypergraph representation learning is designed, called UniG-Encoder. The architecture starts with a forward transformation of the topological relationships of connected nodes into edge or hyperedge features via a normalized projection matrix. The resulting edge/hyperedge features, together with the original node features, are fed into a neural network. The encoded node embeddings are then derived from the reversed transformation, described by the transpose of the projection matrix, of the network's output, which can be further used for tasks such as node classification. The proposed architecture, in contrast to the traditional spectral-based and/or message passing approaches, simultaneously and comprehensively exploits the node features and graph/hypergraph topologies in an efficient and unified manner, covering both heterophilic and homophilic graphs. The designed projection matrix, encoding the graph features, is intuitive and interpretable. Extensive experiments are conducted and demonstrate the superior performance of the proposed framework on twelve representative hypergraph datasets and six real-world graph datasets, compared to the state-of-the-art methods. Our implementation is available online at https://github.com/MinhZou/UniG-Encoder.
</details>
<details>
<summary>摘要</summary>
GRaph和嵌入图 representation learning 已经引起了不同领域的研究者的关注。尽管图神经网络（GNNs）、嵌入图神经网络（HGNNs）以及其设计的许多变体在一些常用的图和嵌入图上达到了不错的性能，但它们在一些简单的多层感知器（MLP）上被超越。这种观察激发了现有GNNs和HGNNs的设计思路的重新评估，并提出了提取图特征的挑战。在这种工作中，我们设计了一种通用的特征编码器，称为UniG-Encoder。该架构开始于将图中连接节点的topological关系转化为Edge或嵌入Edge特征via一个正规投影矩阵。然后，这些特征，与原始节点特征一起，被 feed into一个神经网络。编码后的节点嵌入则是通过投影矩阵的背景矩阵反转，从神经网络的输出获得的。该架构，与传统的spectral-based和/或message passing方法不同，同时并且全面地利用节点特征和图/嵌入图结构，提供了一种高效的、统一的方法，可以处理异质的图和嵌入图。设计的投影矩阵是直观和可解释的。我们在十二个代表性的嵌入图 dataset和六个实际图 dataset上进行了广泛的实验，并证明了我们的框架在这些dataset上的超越性。我们的实现可以在https://github.com/MinhZou/UniG-Encoder上找到。
</details></li>
</ul>
<hr>
<h2 id="MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management"><a href="#MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management" class="headerlink" title="MARLIM: Multi-Agent Reinforcement Learning for Inventory Management"></a>MARLIM: Multi-Agent Reinforcement Learning for Inventory Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01649">http://arxiv.org/abs/2308.01649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rémi Leluc, Elie Kadoche, Antoine Bertoncello, Sébastien Gourvénec</li>
<li>for: 该论文旨在解决供应链中单一架构多种产品的存储管理问题，通过优化填充决策来保持供应和需求的平衡。</li>
<li>methods: 该论文提出了一种基于强化学习的新框架 named MARLIM，通过单或多个代理人在合作环境中开发控制器来解决存储管理问题。</li>
<li>results: 数值实验表明，基于强化学习方法比传统基线方法更有利于解决存储管理问题。<details>
<summary>Abstract</summary>
Maintaining a balance between the supply and demand of products by optimizing replenishment decisions is one of the most important challenges in the supply chain industry. This paper presents a novel reinforcement learning framework called MARLIM, to address the inventory management problem for a single-echelon multi-products supply chain with stochastic demands and lead-times. Within this context, controllers are developed through single or multiple agents in a cooperative setting. Numerical experiments on real data demonstrate the benefits of reinforcement learning methods over traditional baselines.
</details>
<details>
<summary>摘要</summary>
维护产品供应和需求的平衡是供应链业中最重要的挑战。本文提出了一个新的强化学习框架，名为MARLIM，以解决单一批制供应链中多产品的库存管理问题。在这个上下文中，控制器通过单一或多个代理人在合作环境下发展。实验结果显示，强化学习方法比传统基准方法更有利。Here's the breakdown of the translation:* 维护 (maintaining) = 维护 (maintaining)* 产品 (products) = 产品 (products)* 供应 (supply) = 供应 (supply)* 需求 (demand) = 需求 (demand)* 平衡 (balance) = 平衡 (balance)* 挑战 (challenge) = 挑战 (challenge)* 供应链 (supply chain) = 供应链 (supply chain)* 单一 (single) = 单一 (single)* 批制 (batch) = 批制 (batch)* 供应链 (supply chain) = 供应链 (supply chain)* 多产品 (multi-products) = 多产品 (multi-products)* 库存 (inventory) = 库存 (inventory)* 管理 (management) = 管理 (management)* 问题 (problem) = 问题 (problem)* 控制器 (controller) = 控制器 (controller)* 代理人 (agent) = 代理人 (agent)* 合作 (cooperative) = 合作 (cooperative)* 环境 (environment) = 环境 (environment)* 实验 (experiment) = 实验 (experiment)* 结果 (result) = 结果 (result)* 比 (than) = 比 (than)* 传统 (traditional) = 传统 (traditional)* 基准 (baseline) = 基准 (baseline)* 方法 (method) = 方法 (method)* 更 (more) = 更 (more)
</details></li>
</ul>
<hr>
<h2 id="Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers"><a href="#Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers" class="headerlink" title="Interleaving GANs with knowledge graphs to support design creativity for book covers"></a>Interleaving GANs with knowledge graphs to support design creativity for book covers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01626">http://arxiv.org/abs/2308.01626</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexmotogna/generatorapi">https://github.com/alexmotogna/generatorapi</a></li>
<li>paper_authors: Alexandru Motogna, Adrian Groza</li>
<li>for: 这篇论文是为了提高书籍封面的创作而写的。</li>
<li>methods: 这篇论文使用了生成对抗网络（GANs）来生成图像，并通过与知识图加以混合来改变输入标题，以生成多种可能性。</li>
<li>results: 这篇论文的方法比之前的尝试更好地生成了图像，并且知识图可以为书作者或编辑提供更多的选择。<details>
<summary>Abstract</summary>
An attractive book cover is important for the success of a book. In this paper, we apply Generative Adversarial Networks (GANs) to the book covers domain, using different methods for training in order to obtain better generated images. We interleave GANs with knowledge graphs to alter the input title to obtain multiple possible options for any given title, which are then used as an augmented input to the generator. Finally, we use the discriminator obtained during the training phase to select the best images generated with new titles. Our method performed better at generating book covers than previous attempts, and the knowledge graph gives better options to the book author or editor compared to using GANs alone.
</details>
<details>
<summary>摘要</summary>
一本有吸引力的书封面对书的成功很重要。在这篇论文中，我们使用生成对抗网络（GANs）来改进书封面领域中的生成图像。我们在训练中使用不同的方法，以获得更好的生成图像。我们将知识图库与GANs相互嵌入，以对输入书名进行修改，从而获得多个可能的选项。最后，我们使用训练阶段获得的推识器，选择最佳的生成图像。我们的方法在生成书封面方面比前一次尝试更好，而知识图库对书作者或编辑提供了更多的选择。
</details></li>
</ul>
<hr>
<h2 id="Weighted-Multi-Level-Feature-Factorization-for-App-ads-CTR-and-installation-prediction"><a href="#Weighted-Multi-Level-Feature-Factorization-for-App-ads-CTR-and-installation-prediction" class="headerlink" title="Weighted Multi-Level Feature Factorization for App ads CTR and installation prediction"></a>Weighted Multi-Level Feature Factorization for App ads CTR and installation prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02568">http://arxiv.org/abs/2308.02568</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knife982000/recsys2023challenge">https://github.com/knife982000/recsys2023challenge</a></li>
<li>paper_authors: Juan Manuel Rodriguez, Antonela Tommasel</li>
<li>for: 本文是针对ACM RecSys Challenge 2023进行报告，主要目标是预测用户点击和安装应用程序的概率，以优化深层渠道优化和尊重用户隐私。</li>
<li>methods: 该方法基于Weighted Multi-Level Feature Factorization，即在不同层次上结合任务特定和共享特征进行特征工程，以优化点击和安装两个相关 yet 不同的任务。</li>
<li>results: 本文在ACM RecSys Challenge 2023的学术赛道决赛中获得了11名和总分55的成绩，并在<a target="_blank" rel="noopener" href="https://github.com/knife982000/RecSys2023Challenge%E4%B8%8A%E5%85%AC%E5%BC%80%E4%BA%86%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/knife982000/RecSys2023Challenge上公开了代码。</a><details>
<summary>Abstract</summary>
This paper provides an overview of the approach we used as team ISISTANITOS for the ACM RecSys Challenge 2023. The competition was organized by ShareChat, and involved predicting the probability of a user clicking an app ad and/or installing an app, to improve deep funnel optimization and a special focus on user privacy. Our proposed method inferring the probabilities of clicking and installing as two different, but related tasks. Hence, the model engineers a specific set of features for each task and a set of shared features. Our model is called Weighted Multi-Level Feature Factorization because it considers the interaction of different order features, where the order is associated to the depth in a neural network. The prediction for a given task is generated by combining the task specific and shared features on the different levels. Our submission achieved the 11 rank and overall score of 55 in the competition academia-track final results. We release our source code at: https://github.com/knife982000/RecSys2023Challenge
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting"><a href="#Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting" class="headerlink" title="Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting"></a>Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02419">http://arxiv.org/abs/2308.02419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention">https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention</a></li>
<li>paper_authors: Ferdian Jovan, Catherine Morgan, Ryan McConville, Emma L. Tonkin, Ian Craddock, Alan Whone</li>
<li>for: 这个论文是为了提高现有的indoor localization方法的效果而写的。</li>
<li>methods: 这个论文使用了transformer模型，使用了双Modal的RSSI和加速度数据来提高indoor localization的准确率。</li>
<li>results: 论文的evaluation表明，该方法可以在real-world condition下提高indoor localization的准确率，并且可以准确地判断PD参与者是否正在服用levodopa药物。<details>
<summary>Abstract</summary>
Parkinson's disease (PD) is a slowly progressive, debilitating neurodegenerative disease which causes motor symptoms including gait dysfunction. Motor fluctuations are alterations between periods with a positive response to levodopa therapy ("on") and periods marked by re-emergency of PD symptoms ("off") as the response to medication wears off. These fluctuations often affect gait speed and they increase in their disabling impact as PD progresses. To improve the effectiveness of current indoor localisation methods, a transformer-based approach utilising dual modalities which provide complementary views of movement, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, is proposed. A sub-objective aims to evaluate whether indoor localisation, including its in-home gait speed features (i.e. the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withholding them. To properly evaluate our proposed method, we use a free-living dataset where the movements and mobility are greatly varied and unstructured as expected in real-world conditions. 24 participants lived in pairs (consisting of one person with PD, one control) for five days in a smart home with various sensors. Our evaluation on the resulting dataset demonstrates that our proposed network outperforms other methods for indoor localisation. The sub-objective evaluation shows that precise room-level localisation predictions, transformed into in-home gait speed features, produce accurate predictions on whether the PD participant is taking or withholding their medications.
</details>
<details>
<summary>摘要</summary>
帕金森病 (PD) 是一种慢速进行、抑酸性减退性神经病，引起运动征瘤包括跑步功能不优。运动波动是指在 леvodopa 治疗中有效期内和无效期间的变化，这些变化通常影响跑步速度，随着病情进展而加剧。为了改善当前indoor localization方法的效果，一种基于 transformer 的方法，使用 dual modalities 提供了补做的视角，包括Received Signal Strength Indicator (RSSI) 和加速器数据从 wearable 设备。一个副目标是评估whether indoor localization，包括室内跑步速度特征（即在房间之间行走的时间），可以用于评估PD参与者是否服用了levodopa 药物。为了准确评估我们的提议方法，我们使用了一个免费生活数据集，其中运动和 mobilty 具有很大的变化和不结构性，如预期的实际条件中。24名参与者（其中12名PD参与者和12名控制参与者）在 smart home 中生活了5天，并使用了各种感知器。我们对所获得的数据进行评估，并示出了我们的提议网络在indoor localization方面的出色表现。副目标评估显示，精准的房间层级本地化预测，经过转换为室内跑步速度特征，可以生成准确的PD参与者是否服用了levodopa 药物的预测。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry"><a href="#A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry" class="headerlink" title="A Novel Convolutional Neural Network Architecture with a Continuous Symmetry"></a>A Novel Convolutional Neural Network Architecture with a Continuous Symmetry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01621">http://arxiv.org/abs/2308.01621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuyao12/ConvNets-PDE-perspective">https://github.com/liuyao12/ConvNets-PDE-perspective</a></li>
<li>paper_authors: Yao Liu, Hang Shao, Bing Bai</li>
<li>for: 这种新的卷积神经网络架构是基于一种类型的偏微分方程（PDE），即 quasi-linear 超声速系统。</li>
<li>methods: 这种架构使得权重可以通过一个连续群的对称性进行修改，这与传统的模型不同，其架构和权重基本固定。</li>
<li>results: 与传统模型相比，这种架构在图像分类任务上具有相似的性能，同时具有内部对称性作为一个新的愿望属性。<details>
<summary>Abstract</summary>
This paper introduces a new Convolutional Neural Network (ConvNet) architecture inspired by a class of partial differential equations (PDEs) called quasi-linear hyperbolic systems. With comparable performance on the image classification task, it allows for the modification of the weights via a continuous group of symmetry. This is a significant shift from traditional models where the architecture and weights are essentially fixed. We wish to promote the (internal) symmetry as a new desirable property for a neural network, and to draw attention to the PDE perspective in analyzing and interpreting ConvNets in the broader Deep Learning community.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的卷积神经网络（ConvNet）架构， Drawing inspiration from a class ofpartial differential equations（PDEs）called quasi-linear hyperbolic systems. 与传统模型相比，这种架构允许权重的修改via continuous group of symmetry，这是一种重要的Shift from traditional models, where the architecture and weights are essentially fixed. 我们希望通过推广这种（内部）对称性作为神经网络的新有优点，并吸引Deep Learning社区更广泛关注PDE的视角来分析和解释ConvNets.Note: "quasi-linear hyperbolic systems" in the original text is translated as "quasi-linear hyperbolic systems" in Simplified Chinese, as there is no direct equivalent term in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals"><a href="#Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals" class="headerlink" title="Assessing Systematic Weaknesses of DNNs using Counterfactuals"></a>Assessing Systematic Weaknesses of DNNs using Counterfactuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01614">http://arxiv.org/abs/2308.01614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sujan Sai Gannamaneni, Michael Mock, Maram Akila</li>
<li>for: 这篇论文旨在检查和验证深度神经网络（DNN）在安全应用中的测试方法。</li>
<li>methods: 本文使用了一种基于对应假设的Semantic Attribution方法来验证DNN的性能差异。</li>
<li>results: 本文的结果显示，在自驾车领域中的一个例子中，使用高度标注的 simulated 数据，发现了一些特定的人工资产（asset）对于深度神经网络（DNN）的性能有差异，但是只有在某些情况下，资产类型本身是性能差异的原因。<details>
<summary>Abstract</summary>
With the advancement of DNNs into safety-critical applications, testing approaches for such models have gained more attention. A current direction is the search for and identification of systematic weaknesses that put safety assumptions based on average performance values at risk. Such weaknesses can take on the form of (semantically coherent) subsets or areas in the input space where a DNN performs systematically worse than its expected average. However, it is non-trivial to attribute the reason for such observed low performances to the specific semantic features that describe the subset. For instance, inhomogeneities within the data w.r.t. other (non-considered) attributes might distort results. However, taking into account all (available) attributes and their interaction is often computationally highly expensive. Inspired by counterfactual explanations, we propose an effective and computationally cheap algorithm to validate the semantic attribution of existing subsets, i.e., to check whether the identified attribute is likely to have caused the degraded performance. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data, where we show for a semantic segmentation model that (i) performance differences among the different pedestrian assets exist, but (ii) only in some cases is the asset type itself the reason for this reduction in the performance.
</details>
<details>
<summary>摘要</summary>
Inspired by counterfactual explanations, we propose an efficient and cost-effective algorithm to validate the semantic attribution of existing subsets. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data. Our results show that (i) performance differences exist among different pedestrian assets, but (ii) the asset type is not always the reason for the reduced performance.
</details></li>
</ul>
<hr>
<h2 id="Feature-Noise-Boosts-DNN-Generalization-under-Label-Noise"><a href="#Feature-Noise-Boosts-DNN-Generalization-under-Label-Noise" class="headerlink" title="Feature Noise Boosts DNN Generalization under Label Noise"></a>Feature Noise Boosts DNN Generalization under Label Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01609">http://arxiv.org/abs/2308.01609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zlzenglu/fn">https://github.com/zlzenglu/fn</a></li>
<li>paper_authors: Lu Zeng, Xuan Chen, Xiaoshuang Shi, Heng Tao Shen</li>
<li>for: 增强深度神经网络（DNNs）对标签噪声的泛化性能。</li>
<li>methods: 直接将噪声添加到训练数据中的特征上，以增强DNNs的泛化性能。</li>
<li>results: 经过理论分析，发现标签噪声会削弱DNNs的泛化性能，而特征噪声则可以增强DNNs的泛化性能，并且可以通过调整特征噪声的类型和水平来确定最佳的噪声类型和水平。经过实验 validate 的结果表明，这种特征噪声方法可以显著提高DNNs在标签噪声下的泛化性能。<details>
<summary>Abstract</summary>
The presence of label noise in the training data has a profound impact on the generalization of deep neural networks (DNNs). In this study, we introduce and theoretically demonstrate a simple feature noise method, which directly adds noise to the features of training data, can enhance the generalization of DNNs under label noise. Specifically, we conduct theoretical analyses to reveal that label noise leads to weakened DNN generalization by loosening the PAC-Bayes generalization bound, and feature noise results in better DNN generalization by imposing an upper bound on the mutual information between the model weights and the features, which constrains the PAC-Bayes generalization bound. Furthermore, to ensure effective generalization of DNNs in the presence of label noise, we conduct application analyses to identify the optimal types and levels of feature noise to add for obtaining desirable label noise generalization. Finally, extensive experimental results on several popular datasets demonstrate the feature noise method can significantly enhance the label noise generalization of the state-of-the-art label noise method.
</details>
<details>
<summary>摘要</summary>
deep neural networks (DNNs) 的泛化能力受到标签噪声的影响。在本研究中，我们提出了一种简单的特征噪声方法，可以直接将噪声添加到训练数据的特征中，以提高 DNN 的泛化能力。我们进行了理论分析，发现标签噪声会减弱 DNN 的泛化能力，而特征噪声则可以通过限制模型参数和特征之间的互信息，提高 PAC-Bayes 泛化 bound。此外，为确保 DNN 在标签噪声下的有效泛化，我们进行了应用分析，并identified optimal types and levels of feature noise to add for obtaining desirable label noise generalization。最后，我们在多个popular dataset上进行了广泛的实验，并证明了 feature noise method可以显著提高 state-of-the-art label noise method 的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model"><a href="#Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model" class="headerlink" title="Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model"></a>Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01947">http://arxiv.org/abs/2308.01947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whb605/gladst">https://github.com/whb605/gladst</a></li>
<li>paper_authors: Fu Lin, Xuexiong Luo, Jia Wu, Jian Yang, Shan Xue, Zitong Wang, Haonan Gong</li>
<li>for: 本研究的目标是找出图集中的异常图，并使用图表示来识别它们。由于现有的研究不够关于图级异常检测，因此我们需要更好地定义图级异常的描述。</li>
<li>methods: 我们首先定义图集中的异常图信息，包括节点和图像异常。然后，我们提出了一种可分辨性 Graph-level anomaly detection 框架，使用双学生-教师模型。教师模型使用准确的损失函数来让图表示更加分化。两个竞争学生模型通过正常和异常图来适应教师模型的图表示。最后，我们将两个学生模型的表示错误相加，以分别地识别异常图。</li>
<li>results: 我们在实验分析中发现，我们的方法可以有效地检测图集中的异常图。这表明我们的方法可以在实际世界中的图据集上进行异常检测。<details>
<summary>Abstract</summary>
Different from the current node-level anomaly detection task, the goal of graph-level anomaly detection is to find abnormal graphs that significantly differ from others in a graph set. Due to the scarcity of research on the work of graph-level anomaly detection, the detailed description of graph-level anomaly is insufficient. Furthermore, existing works focus on capturing anomalous graph information to learn better graph representations, but they ignore the importance of an effective anomaly score function for evaluating abnormal graphs. Thus, in this work, we first define anomalous graph information including node and graph property anomalies in a graph set and adopt node-level and graph-level information differences to identify them, respectively. Then, we introduce a discriminative graph-level anomaly detection framework with dual-students-teacher model, where the teacher model with a heuristic loss are trained to make graph representations more divergent. Then, two competing student models trained by normal and abnormal graphs respectively fit graph representations of the teacher model in terms of node-level and graph-level representation perspectives. Finally, we combine representation errors between two student models to discriminatively distinguish anomalous graphs. Extensive experiment analysis demonstrates that our method is effective for the graph-level anomaly detection task on graph datasets in the real world.
</details>
<details>
<summary>摘要</summary>
不同于现有的节点级异常检测任务，我们的目标是找到异常图的，这些图在图集中显著地不同于其他图。由于关于图级异常检测的研究缺乏，异常图的详细描述还不够。此外，现有的工作主要是捕捉异常图信息，以便学习更好的图表示，但它们忽略了评估异常图的有效 anomaly score 函数的重要性。因此，在这种工作中，我们首先定义图集中的异常图信息，包括节点和图性异常，并采用节点级和图级信息差异来识别它们。然后，我们提出了一种能够分类异常图的双学生-教师模型，其中教师模型通过规则损失来训练图表示更加分化。然后，两个竞争学生模型，一个通过正常图，另一个通过异常图进行训练，分别适应教师模型的节点级和图级表示视角。最后，我们将两个学生模型的表示错误相加，以分类异常图。我们的方法在实际世界的图据集上进行了广泛的实验分析，得到了有效的结果。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Multiplex-Graph-Learning-with-Complementary-and-Consistent-Information"><a href="#Unsupervised-Multiplex-Graph-Learning-with-Complementary-and-Consistent-Information" class="headerlink" title="Unsupervised Multiplex Graph Learning with Complementary and Consistent Information"></a>Unsupervised Multiplex Graph Learning with Complementary and Consistent Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01606">http://arxiv.org/abs/2308.01606</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/larryuestc/cocomg">https://github.com/larryuestc/cocomg</a></li>
<li>paper_authors: Liang Peng, Xin Wang, Xiaofeng Zhu</li>
<li>for: 本文提出了一种解决实际应用中issues的不监管多重图学习方法（UMGL），以提高不同下游任务的效果。</li>
<li>methods: 本方法使用多个多层感知网络（MLP）Encoder进行表示学习，并采用两个约束条件：保持节点之间的本地图structures，以处理异样问题，并 Maximize多个节点表示之间的相关性，以处理噪声问题。</li>
<li>results: 对比其他方法，本方法在实验中表现出了更高的效果和效率，并能够有效地解决异样和噪声问题。<details>
<summary>Abstract</summary>
Unsupervised multiplex graph learning (UMGL) has been shown to achieve significant effectiveness for different downstream tasks by exploring both complementary information and consistent information among multiple graphs. However, previous methods usually overlook the issues in practical applications, i.e., the out-of-sample issue and the noise issue. To address the above issues, in this paper, we propose an effective and efficient UMGL method to explore both complementary and consistent information. To do this, our method employs multiple MLP encoders rather than graph convolutional network (GCN) to conduct representation learning with two constraints, i.e., preserving the local graph structure among nodes to handle the out-of-sample issue, and maximizing the correlation of multiple node representations to handle the noise issue. Comprehensive experiments demonstrate that our proposed method achieves superior effectiveness and efficiency over the comparison methods and effectively tackles those two issues. Code is available at https://github.com/LarryUESTC/CoCoMG.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>Unsupervised多重图学习（UMGL）已经在不同的下游任务中显示出了 significanteffectiveness，通过探索多个图中的共同信息和差异信息。然而，之前的方法通常忽视了实际应用中的问题，即外样问题和噪声问题。为了解决这些问题，在这篇论文中，我们提出了一种有效和高效的 UMGL 方法，通过多个多层感知（MLP）编码器来进行表示学习，并遵循两个约束条件：保持节点之间的本地图结构，以处理外样问题，并 maximize 多个节点表示的相关性，以处理噪声问题。广泛的实验表明，我们提出的方法在比较方法中显示出了superior的有效性和高效性，并有效地解决了这两个问题。代码可以在 https://github.com/LarryUESTC/CoCoMG 上获取。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-surrogate-models-for-parametrized-PDEs-handling-geometric-variability-through-graph-neural-networks"><a href="#Deep-Learning-based-surrogate-models-for-parametrized-PDEs-handling-geometric-variability-through-graph-neural-networks" class="headerlink" title="Deep Learning-based surrogate models for parametrized PDEs: handling geometric variability through graph neural networks"></a>Deep Learning-based surrogate models for parametrized PDEs: handling geometric variability through graph neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01602">http://arxiv.org/abs/2308.01602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicola Rares Franco, Stefania Fresca, Filippo Tombari, Andrea Manzoni</li>
<li>for: 用于模拟复杂物理系统，需要解决参数化时间依赖非线性偏微分方程（PDEs）。</li>
<li>methods: 使用图ael neural networks（GNNs）来代替 computationally expensive solvers，以实现更高效的simulation。</li>
<li>results: GNNs可以提供一个有效的surrogate model，可以涵盖不同的几何和分解精度，并且可以在不同的参数下进行泛化。<details>
<summary>Abstract</summary>
Mesh-based simulations play a key role when modeling complex physical systems that, in many disciplines across science and engineering, require the solution of parametrized time-dependent nonlinear partial differential equations (PDEs). In this context, full order models (FOMs), such as those relying on the finite element method, can reach high levels of accuracy, however often yielding intensive simulations to run. For this reason, surrogate models are developed to replace computationally expensive solvers with more efficient ones, which can strike favorable trade-offs between accuracy and efficiency. This work explores the potential usage of graph neural networks (GNNs) for the simulation of time-dependent PDEs in the presence of geometrical variability. In particular, we propose a systematic strategy to build surrogate models based on a data-driven time-stepping scheme where a GNN architecture is used to efficiently evolve the system. With respect to the majority of surrogate models, the proposed approach stands out for its ability of tackling problems with parameter dependent spatial domains, while simultaneously generalizing to different geometries and mesh resolutions. We assess the effectiveness of the proposed approach through a series of numerical experiments, involving both two- and three-dimensional problems, showing that GNNs can provide a valid alternative to traditional surrogate models in terms of computational efficiency and generalization to new scenarios. We also assess, from a numerical standpoint, the importance of using GNNs, rather than classical dense deep neural networks, for the proposed framework.
</details>
<details>
<summary>摘要</summary>
mesh-based 模拟在许多科学和工程领域中扮演关键角色，特别是当模型复杂物理系统时，需要解决 Parametrized 时间依赖非线性偏微分方程 (PDEs)。在这种情况下，全序模型 (FOMs)，如基于 finite element 方法的模型，可以达到高级别的准确性，但通常需要昂贵的计算。为了解决这个问题，人们通常会开发供应商模型，以取代 computationally 昂贵的解决方案，从而实现可接受的妥协。这项工作探讨了使用图 neuron 网络 (GNNs) 来模拟时间依赖 PDEs 的可能性。具体来说，我们提出了一种系统性的策略，通过数据驱动的时间步骤来建立仿真模型。与大多数供应商模型不同的是，我们的方法可以处理具有参数依赖的空间领域的问题，同时能够泛化到不同的几何和分辨率。我们通过一系列数学实验，包括二维和三维问题，证明了 GNNs 可以提供一个有效的代替方案，而不需要经过复杂的拟合。此外，我们还评估了使用 GNNs 而不是传统的密集深度神经网络，对该框架的重要性。
</details></li>
</ul>
<hr>
<h2 id="Experimental-Results-regarding-multiple-Machine-Learning-via-Quaternions"><a href="#Experimental-Results-regarding-multiple-Machine-Learning-via-Quaternions" class="headerlink" title="Experimental Results regarding multiple Machine Learning via Quaternions"></a>Experimental Results regarding multiple Machine Learning via Quaternions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01946">http://arxiv.org/abs/2308.01946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianlei Zhu, Renzhe Zhu</li>
<li>for: 这项研究探讨了使用量子来实现机器学习算法的应用。</li>
<li>methods: 本研究使用随机生成的量子数据和对应的标签，将量子转换为旋转矩阵，并使其为输入特征。</li>
<li>results: 结果表明，使用量子和多种机器学习算法可以实现更高的准确率和显著改善在预测任务中。<details>
<summary>Abstract</summary>
This paper presents an experimental study on the application of quaternions in several machine learning algorithms. Quaternion is a mathematical representation of rotation in three-dimensional space, which can be used to represent complex data transformations. In this study, we explore the use of quaternions to represent and classify rotation data, using randomly generated quaternion data and corresponding labels, converting quaternions to rotation matrices, and using them as input features. Based on quaternions and multiple machine learning algorithms, it has shown higher accuracy and significantly improved performance in prediction tasks. Overall, this study provides an empirical basis for exploiting quaternions for machine learning tasks.
</details>
<details>
<summary>摘要</summary>
这个论文介绍了使用四元数在多种机器学习算法中的实验研究。四元数是三维空间中旋转的数学表示方式，可以用于表示复杂的数据变换。在这个研究中，我们研究了使用四元数来表示和分类旋转数据，使用随机生成的四元数数据和相应的标签，将四元数转换为旋转矩阵，并使其为输入特征。基于四元数和多种机器学习算法，研究结果显示了更高的准确率和明显改善的预测性能。总之，这个研究提供了使用四元数进行机器学习任务的实质基础。
</details></li>
</ul>
<hr>
<h2 id="SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning"><a href="#SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning" class="headerlink" title="SoK: Assessing the State of Applied Federated Machine Learning"></a>SoK: Assessing the State of Applied Federated Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02454">http://arxiv.org/abs/2308.02454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Müller, Maximilian Stäbler, Hugo Gascón, Frank Köster, Florian Matthes</li>
<li>for: 本研究旨在探讨 Federated Machine Learning（FedML）在实际应用中的现状和挑战。</li>
<li>methods: 本研究采用系统性的文献回顾方法，对74篇相关文章进行分析，描述 FedML 实现的特点和趋势，以及驱动其应用的动机和应用领域。</li>
<li>results: 本研究发现，FedML 在隐私敏感领域的应用具有许多优势，但在实际应用中还存在许多挑战，如数据质量问题、安全性和可信度问题等。<details>
<summary>Abstract</summary>
Machine Learning (ML) has shown significant potential in various applications; however, its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning (FedML), a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data, FedML offers enhanced privacy protections, making it suitable for privacy-critical environments. Despite its theoretical benefits, FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application domains. We also discuss the encountered challenges in integrating FedML into real-life settings. By shedding light on the existing landscape and potential obstacles, this research contributes to the further development and implementation of FedML in privacy-critical scenarios.
</details>
<details>
<summary>摘要</summary>
translate to Simplified Chinese:机器学习（ML）在不同的应用场景中表现出了很remarkable potential; however，its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning（FedML），a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data，FedML offers enhanced privacy protections，making it suitable for privacy-critical environments. Despite its theoretical benefits，FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review，we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations，as well as the motivational drivers and application domains. We also discuss the encountered challenges in integrating FedML into real-life settings. By shedding light on the existing landscape and potential obstacles，this research contributes to the further development and implementation of FedML in privacy-critical scenarios.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Representation-Learning-for-Time-Series-A-Review"><a href="#Unsupervised-Representation-Learning-for-Time-Series-A-Review" class="headerlink" title="Unsupervised Representation Learning for Time Series: A Review"></a>Unsupervised Representation Learning for Time Series: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01578">http://arxiv.org/abs/2308.01578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mqwfrog/ults">https://github.com/mqwfrog/ults</a></li>
<li>paper_authors: Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, Lizhen Cui</li>
<li>for: 本研究旨在探讨无监督表示学习方法的应用在时间序列数据上，以便学习不同特征表示而不需要每个样本的标注。</li>
<li>methods: 本研究使用了多种不监督表示学习技术，包括自适应表示学习、强化学习和对比学习等。</li>
<li>results: 经验证明，使用不监督表示学习方法可以在9种真实世界数据集上实现高度的特征表示能力，并且可以在不同的数据集上进行跨种类比较。<details>
<summary>Abstract</summary>
Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.
</details>
<details>
<summary>摘要</summary>
<<SYS>> transtableUnsupervised representation learning方法 aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Training-of-Denoising-Diffusion-Model-Using-Dual-Discriminators-for-High-Fidelity-Multi-Speaker-TTS"><a href="#Adversarial-Training-of-Denoising-Diffusion-Model-Using-Dual-Discriminators-for-High-Fidelity-Multi-Speaker-TTS" class="headerlink" title="Adversarial Training of Denoising Diffusion Model Using Dual Discriminators for High-Fidelity Multi-Speaker TTS"></a>Adversarial Training of Denoising Diffusion Model Using Dual Discriminators for High-Fidelity Multi-Speaker TTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01573">http://arxiv.org/abs/2308.01573</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/komyeongjin/specdiff-gan">https://github.com/komyeongjin/specdiff-gan</a></li>
<li>paper_authors: Myeongjin Ko, Yong-Hoon Choi</li>
<li>for: 本研究旨在提高 diffusion speech synthesis 模型的表现，通过添加两个识别器：扩散识别器和spectrogram识别器，以学习扩散过程的分布和生成数据的分布。</li>
<li>methods: 本研究使用了 diffusion 模型，并结合了 GAN 结构。具体来说，使用了一个扩散识别器和一个spectrogram识别器，以学习扩散过程的分布和生成数据的分布。</li>
<li>results: 对比 FastSpeech2 和 DiffGAN-TTS 等当前状态的艺术模型，本研究的模型在不同的 метриках中表现出优于其他模型，包括 SSIM、MCD、F0 RMSE、STOI、PESQ 等。<details>
<summary>Abstract</summary>
The diffusion model is capable of generating high-quality data through a probabilistic approach. However, it suffers from the drawback of slow generation speed due to the requirement of a large number of time steps. To address this limitation, recent models such as denoising diffusion implicit models (DDIM) focus on generating samples without directly modeling the probability distribution, while models like denoising diffusion generative adversarial networks (GAN) combine diffusion processes with GANs. In the field of speech synthesis, a recent diffusion speech synthesis model called DiffGAN-TTS, utilizing the structure of GANs, has been introduced and demonstrates superior performance in both speech quality and generation speed. In this paper, to further enhance the performance of DiffGAN-TTS, we propose a speech synthesis model with two discriminators: a diffusion discriminator for learning the distribution of the reverse process and a spectrogram discriminator for learning the distribution of the generated data. Objective metrics such as structural similarity index measure (SSIM), mel-cepstral distortion (MCD), F0 root mean squared error (F0 RMSE), short-time objective intelligibility (STOI), perceptual evaluation of speech quality (PESQ), as well as subjective metrics like mean opinion score (MOS), are used to evaluate the performance of the proposed model. The evaluation results show that the proposed model outperforms recent state-of-the-art models such as FastSpeech2 and DiffGAN-TTS in various metrics. Our implementation and audio samples are located on GitHub.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_parts:  - text: "The diffusion model"    translate: "扩散模型"  - text: "capable of generating high-quality data"    translate: "可以生成高质量数据"  - text: "through a probabilistic approach"    translate: "通过 probabilistic 方法"  - text: "However, it suffers from the drawback"    translate: "然而，它受到一个缺点"  - text: "of slow generation speed"    translate: "生成速度较慢"  - text: "due to the requirement of a large number of time steps"    translate: "因为需要较多的时间步骤"  - text: "To address this limitation"    translate: "以解决这些限制"  - text: "recent models such as denoising diffusion implicit models (DDIM)"    translate: "最近的模型，如杂谱扩散隐式模型（DDIM）"  - text: "focus on generating samples without directly modeling the probability distribution"    translate: "注重生成样本，不直接模型概率分布"  - text: "while models like denoising diffusion generative adversarial networks (GAN)"    translate: "如杂谱扩散生成敌方网络（GAN）"  - text: "combine diffusion processes with GANs"    translate: "将扩散过程与 GAN 结合"  - text: "In the field of speech synthesis"    translate: "在语音合成领域"  - text: "a recent diffusion speech synthesis model called DiffGAN-TTS"    translate: "一种最近的扩散语音合成模型，即 DiffGAN-TTS"  - text: "utilizing the structure of GANs"    translate: "利用 GAN 的结构"  - text: "has been introduced and demonstrates superior performance"    translate: "已经引入并示出了出色的表现"  - text: "in both speech quality and generation speed"    translate: "在语音质量和生成速度两个方面"  - text: "In this paper"    translate: "在这篇论文"  - text: "to further enhance the performance of DiffGAN-TTS"    translate: "以进一步提高 DiffGAN-TTS 的表现"  - text: "we propose a speech synthesis model with two discriminators"    translate: "我们提议一种语音合成模型，具有两个抑制器"  - text: "a diffusion discriminator for learning the distribution of the reverse process"    translate: "一个扩散抑制器，用于学习反向过程的分布"  - text: "and a spectrogram discriminator for learning the distribution of the generated data"    translate: "一个spectrogram抑制器，用于学习生成的数据的分布"  - text: "Objective metrics such as structural similarity index measure (SSIM)"    translate: "如结构相似度指标 (SSIM)"  - text: "mel-cepstral distortion (MCD)"    translate: "mel-cepstral 扭曲 (MCD)"  - text: "F0 root mean squared error (F0 RMSE)"    translate: "F0 根均方差 (F0 RMSE)"  - text: "short-time objective intelligibility (STOI)"    translate: "短时间目标可理解性 (STOI)"  - text: "perceptual evaluation of speech quality (PESQ)"    translate: "语音质量的主观评估 (PESQ)"  - text: "as well as subjective metrics like mean opinion score (MOS)"    translate: "以及主观指标如 mean opinion score (MOS)"  - text: "are used to evaluate the performance of the proposed model"    translate: "用于评估提议的模型表现"  - text: "The evaluation results show that the proposed model outperforms"    translate: "评估结果表明，提议的模型在"  - text: "recent state-of-the-art models such as FastSpeech2 and DiffGAN-TTS"    translate: "最近的状态艺术模型，如 FastSpeech2 和 DiffGAN-TTS"  - text: "in various metrics"    translate: "在多个指标中"Note: Some of the translated text may not be exact, as the meaning of the original text may not be perfectly conveyed in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Fast-Slate-Policy-Optimization-Going-Beyond-Plackett-Luce"><a href="#Fast-Slate-Policy-Optimization-Going-Beyond-Plackett-Luce" class="headerlink" title="Fast Slate Policy Optimization: Going Beyond Plackett-Luce"></a>Fast Slate Policy Optimization: Going Beyond Plackett-Luce</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01566">http://arxiv.org/abs/2308.01566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Otmane Sakhi, David Rohde, Nicolas Chopin</li>
<li>for: 这篇论文主要针对大规模机器学习系统中的返回板块问题，即在查询时返回一个有序列表的项目。这种技术在搜索、信息检索和推荐系统等领域都有广泛的应用。</li>
<li>methods: 该论文使用政策优化框架来优化大规模决策系统，并提出了一种新的政策类型，基于决策函数的新降低。这种方法简单而高效，可承载巨大的动作空间。</li>
<li>results: 论文对具有百万级动作空间的问题进行比较，并证明了其效果超过常见采用的普拉克特-劳伦谱策略。<details>
<summary>Abstract</summary>
An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.
</details>
<details>
<summary>摘要</summary>
“ Returns 的列表（slate）已成为大规模机器学习系统的关键组件。这些技术在搜索、信息检索和推荐系统中应用。当动作空间较大时，决策系统会受到特定结构的限制，以快速完成在线查询。本文通过policy优化框架优化大规模决策系统，并提出了一种新的策略类型，基于决策函数的新降级。这种简单 yet efficient的学习算法可扩展到巨大的动作空间。我们与常见的Plackett-Luce策略类比较，并在动作空间大约为百万的问题上证明了我们的方法的有效性。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Federated-Learning-in-Wireless-Networks-Pruning-Tackles-Bandwidth-Scarcity-and-System-Heterogeneity"><a href="#Hierarchical-Federated-Learning-in-Wireless-Networks-Pruning-Tackles-Bandwidth-Scarcity-and-System-Heterogeneity" class="headerlink" title="Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity"></a>Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01562">http://arxiv.org/abs/2308.01562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Ferdous Pervej, Richeng Jin, Huaiyu Dai</li>
<li>for: 这篇论文目的是提出一种基于层次联合学习的无线网络模型，以适应实际无线网络中的限制和硬件限制。</li>
<li>methods: 论文使用了模型剔除技术，并提出了一种层次联合学习（PHFL）算法，以满足各种硬件限制和延迟限制。</li>
<li>results: 通过大量的 simulate，论文证明了该算法可以提高测试精度、增加wall clock时间、减少能耗和带宽需求。<details>
<summary>Abstract</summary>
While a practical wireless network has many tiers where end users do not directly communicate with the central server, the users' devices have limited computation and battery powers, and the serving base station (BS) has a fixed bandwidth. Owing to these practical constraints and system models, this paper leverages model pruning and proposes a pruning-enabled hierarchical federated learning (PHFL) in heterogeneous networks (HetNets). We first derive an upper bound of the convergence rate that clearly demonstrates the impact of the model pruning and wireless communications between the clients and the associated BS. Then we jointly optimize the model pruning ratio, central processing unit (CPU) frequency and transmission power of the clients in order to minimize the controllable terms of the convergence bound under strict delay and energy constraints. However, since the original problem is not convex, we perform successive convex approximation (SCA) and jointly optimize the parameters for the relaxed convex problem. Through extensive simulation, we validate the effectiveness of our proposed PHFL algorithm in terms of test accuracy, wall clock time, energy consumption and bandwidth requirement.
</details>
<details>
<summary>摘要</summary>
而实际无线网络具有多层次结构，用户设备具有有限的计算和电池能力，服务基站（BS）具有固定带宽。由于这些实际约束和系统模型，这篇论文利用模型剔除和提出了剔除启用的层次联合学习（PHFL）在不同类型网络（HetNets）中。我们首先得出了模型剔除对 converge 速率的Upper bound，并明确地显示了无线通信和客户端与关联的BS之间的模型剔除和计算剔除的影响。然后，我们联合优化客户端的模型剔除比例、中央处理器频率和传输功率，以最小化控制性 bound 下的执行时间和能量消耗。然而，由于原始问题不是凸型问题，我们使用Successive Convex Approximation（SCA）进行凸化优化参数，并联合优化参数以获得 relaxed 凸型问题的解。通过广泛的Simulation，我们证明了我们提出的PHFL算法在测试准确率、墙 clock 时间、能源消耗和带宽要求方面的有效性。
</details></li>
</ul>
<hr>
<h2 id="Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models"><a href="#Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models" class="headerlink" title="Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models"></a>Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01557">http://arxiv.org/abs/2308.01557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joao Carvalho, An T. Le, Mark Baierl, Dorothea Koert, Jan Peters</li>
<li>for: 学习路径分布可以帮助加速机器人运动规划优化。已有成功的计划中，使用这些先前学习的路径生成模型作为新的规划问题的先验知识是非常有利的。</li>
<li>methods: 我们提议使用扩散模型来学习先验知识。通过扩散模型的逆噪处理，直接从任务目标条件下采样 posterior  trajectory 分布。此外，扩散模型在高维设定下能够有效地编码数据的多模性，这特别适合大型 trajectory 数据集。</li>
<li>results: 我们的实验表明，扩散模型是高维 trajectory 分布的强大先验知识。在 simulated 平面机器人和 7-odo 机器人臂 manipulate 环境中，我们的方法与基eline 进行比较，并在未看到过障碍物的环境中进行测试，以证明我们的方法的普适性。<details>
<summary>Abstract</summary>
Learning priors on trajectory distributions can help accelerate robot motion planning optimization. Given previously successful plans, learning trajectory generative models as priors for a new planning problem is highly desirable. Prior works propose several ways on utilizing this prior to bootstrapping the motion planning problem. Either sampling the prior for initializations or using the prior distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we propose learning diffusion models as priors. We then can sample directly from the posterior trajectory distribution conditioned on task goals, by leveraging the inverse denoising process of diffusion models. Furthermore, diffusion has been recently shown to effectively encode data multimodality in high-dimensional settings, which is particularly well-suited for large trajectory dataset. To demonstrate our method efficacy, we compare our proposed method - Motion Planning Diffusion - against several baselines in simulated planar robot and 7-dof robot arm manipulator environments. To assess the generalization capabilities of our method, we test it in environments with previously unseen obstacles. Our experiments show that diffusion models are strong priors to encode high-dimensional trajectory distributions of robot motions.
</details>
<details>
<summary>摘要</summary>
学习运动轨迹分布可以帮助加速机器人运动规划优化。已经成功的计划中，学习运动轨迹生成模型作为优先是非常有利的。先前的工作提出了多种利用这个优先来启动运动规划问题。可以从优先抽样或者在最大 posterior 形式中使用优先分布来优化运动规划。在这个工作中，我们提议学习扩散模型作为优先。我们可以通过扩散模型的逆减雑过程直接从后 posterior 轨迹分布中抽样，并且利用扩散模型可以有效地编码数据的多模性，尤其是在高维设定下。为了证明我们的方法效果，我们在 simulated 平面机器人和7-度 freedom 机器人 manipulate 环境中对我们的提议方法进行了比较。为了评估我们的方法泛化能力，我们在未看到的障碍物环境中进行了测试。我们的实验表明，扩散模型是高维轨迹分布的机器人运动优先。
</details></li>
</ul>
<hr>
<h2 id="InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent"><a href="#InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent" class="headerlink" title="InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent"></a>InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01552">http://arxiv.org/abs/2308.01552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Po-Lin Chen, Cheng-Shang Chang</li>
<li>for: 这个研究论文探讨了基于OpenAI的ChatGPT的embodied Agent系统的 интеграция，并评估了其对交互决策标准的影响。</li>
<li>methods: 我们引入了一种称为InterAct的方法，将ChatGPT fed with varied prompts，并将其分配为多个角色，如检查员和排序员，然后将其与原始语言模型结合。</li>
<li>results: 我们的研究显示，在AlfWorld中，包含6个任务的 simulate household environment中，ChatGPT的成功率达到98%，这表明ChatGPT在实际世界中完成复杂任务的能力强，从而预示了任务规划领域的进一步发展。<details>
<summary>Abstract</summary>
This research paper delves into the integration of OpenAI's ChatGPT into embodied agent systems, evaluating its influence on interactive decision-making benchmark. Drawing a parallel to the concept of people assuming roles according to their unique strengths, we introduce InterAct. In this approach, we feed ChatGPT with varied prompts, assigning it a numerous roles like a checker and a sorter, then integrating them with the original language model. Our research shows a remarkable success rate of 98% in AlfWorld, which consists of 6 different tasks in a simulated household environment, emphasizing the significance of proficient prompt engineering. The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.
</details>
<details>
<summary>摘要</summary>
这篇研究论文探讨了OpenAI的ChatGPT在具体体系中的整合，评估其对交互决策标准的影响。从人们按照自己特点任务的角度出发，我们提出了InterAct方法。在这种方法中，我们对ChatGPT提供了多种提示，将其分配为多个角色，如检查员和排序员，然后与原始语言模型结合。我们的研究显示在AlfWorld中，包括6种不同任务的 simulate 的家庭环境中，ChatGPT的成功率达到98%，这些结果表明ChatGPT在真实世界中执行复杂任务时的能力，这对任务规划带来了新的可能性。
</details></li>
</ul>
<hr>
<h2 id="MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies"><a href="#MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies" class="headerlink" title="MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies"></a>MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01546">http://arxiv.org/abs/2308.01546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Chen, Yusong Wu, Haohe Liu, Marianna Nezhurina, Taylor Berg-Kirkpatrick, Shlomo Dubnov</li>
<li>for: 这篇论文的目的是提出一种新的文本到音乐生成模型，以 Addressing the challenges of generating music with limited data and sensitivity to copyright and plagiarism.</li>
<li>methods: 该模型使用了Stable Diffusion和AudioLDM架构，并通过重新训练CLAP和Hifi-GAN vocoder来适应音乐领域。另外，该模型还使用了 beat tracking 模型和两种不同的mixup策略来进行数据扩展，以便生成更多样化的音乐。</li>
<li>results: 该模型可以生成更高质量和更多样化的音乐，同时仍然保持与输入文本的相关性。此外，该模型还可以提高CLAP score和新的评价指标，证明其在生成音乐的质量和创新性方面具有优势。<details>
<summary>Abstract</summary>
Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.
</details>
<details>
<summary>摘要</summary>
Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.
</details></li>
</ul>
<hr>
<h2 id="Lode-Enhancer-Level-Co-creation-Through-Scaling"><a href="#Lode-Enhancer-Level-Co-creation-Through-Scaling" class="headerlink" title="Lode Enhancer: Level Co-creation Through Scaling"></a>Lode Enhancer: Level Co-creation Through Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01543">http://arxiv.org/abs/2308.01543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Julian Togelius, Georgios N. Yannakakis, Ahmed Khalifa</li>
<li>for: 用AI技术帮助创建2D游戏关卡。</li>
<li>methods: 使用深度神经网络进行水平增强，以帮助用户在不同分辨率下创建和编辑关卡。</li>
<li>results: 通过训练神经网络，实现在不同分辨率下的同步编辑功能，并且通过提供高优先级块来增强水平的创建能力。<details>
<summary>Abstract</summary>
We explore AI-powered upscaling as a design assistance tool in the context of creating 2D game levels. Deep neural networks are used to upscale artificially downscaled patches of levels from the puzzle platformer game Lode Runner. The trained networks are incorporated into a web-based editor, where the user can create and edit levels at three different levels of resolution: 4x4, 8x8, and 16x16. An edit at any resolution instantly transfers to the other resolutions. As upscaling requires inventing features that might not be present at lower resolutions, we train neural networks to reproduce these features. We introduce a neural network architecture that is capable of not only learning upscaling but also giving higher priority to less frequent tiles. To investigate the potential of this tool and guide further development, we conduct a qualitative study with 3 designers to understand how they use it. Designers enjoyed co-designing with the tool, liked its underlying concept, and provided feedback for further improvement.
</details>
<details>
<summary>摘要</summary>
我们探索使用人工智能进行缩放作为游戏平台层级设计工具。我们使用深度神经网络缩放游戏《宝藏猎人》中的各个层级，并将训练好的网络集成到了基于网络的编辑器中。用户可以在3个不同的分辨率上创建和编辑层级：4x4、8x8和16x16。任何编辑操作都会同步到其他分辨率上。由于缩放需要创造不存在于较低分辨率上的特征，我们训练神经网络来重现这些特征。我们提出了一种神经网络架构，可以不仅学习缩放，还可以给较少出现的块优先级更高。为了了解这个工具的潜在可能性并提供进一步改进的建议，我们进行了3名设计师的质量研究，了解他们如何使用这个工具。设计师喜欢与这个工具合作，喜欢它的核心思想，并提供了进一步改进的反馈。
</details></li>
</ul>
<hr>
<h2 id="MFIM-Megapixel-Facial-Identity-Manipulation"><a href="#MFIM-Megapixel-Facial-Identity-Manipulation" class="headerlink" title="MFIM: Megapixel Facial Identity Manipulation"></a>MFIM: Megapixel Facial Identity Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01536">http://arxiv.org/abs/2308.01536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanghyeon Na</li>
<li>for: 本研究的目的是提出一种新的面孔交换框架，即高像素面孔标识修饰（MFIM）。</li>
<li>methods: 本模型使用预训练的StyleGAN进行GAN-倒转，以生成高像素图像。此外，本模型还使用3DMM来控制不同人脸特征的混合。</li>
<li>results: 经过广泛的实验，我们表明我们的模型可以达到状态对的性能，并且可以自由地调整新的人脸特征。此外，我们还提出了一种新的操作called ID mixing，可以通过semantic混合不同人脸特征来创建新的人脸标识。<details>
<summary>Abstract</summary>
Face swapping is a task that changes a facial identity of a given image to that of another person. In this work, we propose a novel face-swapping framework called Megapixel Facial Identity Manipulation (MFIM). The face-swapping model should achieve two goals. First, it should be able to generate a high-quality image. We argue that a model which is proficient in generating a megapixel image can achieve this goal. However, generating a megapixel image is generally difficult without careful model design. Therefore, our model exploits pretrained StyleGAN in the manner of GAN-inversion to effectively generate a megapixel image. Second, it should be able to effectively transform the identity of a given image. Specifically, it should be able to actively transform ID attributes (e.g., face shape and eyes) of a given image into those of another person, while preserving ID-irrelevant attributes (e.g., pose and expression). To achieve this goal, we exploit 3DMM that can capture various facial attributes. Specifically, we explicitly supervise our model to generate a face-swapped image with the desirable attributes using 3DMM. We show that our model achieves state-of-the-art performance through extensive experiments. Furthermore, we propose a new operation called ID mixing, which creates a new identity by semantically mixing the identities of several people. It allows the user to customize the new identity.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Face swapping is a task that changes a facial identity of a given image to that of another person. In this work, we propose a novel face-swapping framework called Megapixel Facial Identity Manipulation (MFIM). The face-swapping model should achieve two goals. First, it should be able to generate a high-quality image. We argue that a model which is proficient in generating a megapixel image can achieve this goal. However, generating a megapixel image is generally difficult without careful model design. Therefore, our model exploits pretrained StyleGAN in the manner of GAN-inversion to effectively generate a megapixel image. Second, it should be able to effectively transform the identity of a given image. Specifically, it should be able to actively transform ID attributes (e.g., face shape and eyes) of a given image into those of another person, while preserving ID-irrelevant attributes (e.g., pose and expression). To achieve this goal, we exploit 3DMM that can capture various facial attributes. Specifically, we explicitly supervise our model to generate a face-swapped image with the desirable attributes using 3DMM. We show that our model achieves state-of-the-art performance through extensive experiments. Furthermore, we propose a new operation called ID mixing, which creates a new identity by semantically mixing the identities of several people. It allows the user to customize the new identity."中文翻译：面部换位是一项任务，把给定图像中的面部标识换成另一个人的面部标识。在这项工作中，我们提出了一种新的面部换位框架，称为高像素面部标识修饰（MFIM）。这个模型应该实现两个目标。首先，它应该能够生成高质量图像。我们认为一个能够生成高像素图像的模型就可以实现这一目标。然而，生成高像素图像通常需要精心的模型设计。因此，我们利用预训练的StyleGAN，通过GAN-反向方式来有效地生成高像素图像。其次，它应该能够有效地将给定图像中的面部标识转换成另一个人的面部标识。具体来说，它应该能够活动地将ID特征（例如脸形和眼睛）转换成另一个人的ID特征，保留ID不相关的特征（例如姿势和表情）。为了实现这一目标，我们利用3DMM，可以捕捉各种面部特征。我们显式地监督我们的模型，使其生成符合愿望的面部换位图像，使用3DMM。我们示出了我们模型在各种实验中的状态级表现。此外，我们还提出了一种新的操作，称为ID混合，它可以创造一个新的标识，通过semantic地混合多个人的标识。这allow用户自定义新的标识。
</details></li>
</ul>
<hr>
<h2 id="Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data"><a href="#Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data" class="headerlink" title="Food Classification using Joint Representation of Visual and Textual Data"></a>Food Classification using Joint Representation of Visual and Textual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02562">http://arxiv.org/abs/2308.02562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Mittal, Puneet Goyal, Joohi Chauhan</li>
<li>for: 本研究旨在提出一种多模态分类框架，用于健康食品分类。</li>
<li>methods: 提议的网络使用修改版EfficientNet和Mish激活函数进行图像分类，而传统的BERT变换器网络用于文本分类。</li>
<li>results: 对于大规模开源数据集UPMC Food-101，提议的网络与其他状态时方法进行比较，实验结果显示，提议的网络在图像和文本分类任务中具有显著的优势，与第二最佳方法相比，图像分类精度提高11.57%，文本分类精度提高6.34%。<details>
<summary>Abstract</summary>
Food classification is an important task in health care. In this work, we propose a multimodal classification framework that uses the modified version of EfficientNet with the Mish activation function for image classification, and the traditional BERT transformer-based network is used for text classification. The proposed network and the other state-of-the-art methods are evaluated on a large open-source dataset, UPMC Food-101. The experimental results show that the proposed network outperforms the other methods, a significant difference of 11.57% and 6.34% in accuracy is observed for image and text classification, respectively, when compared with the second-best performing method. We also compared the performance in terms of accuracy, precision, and recall for text classification using both machine learning and deep learning-based models. The comparative analysis from the prediction results of both images and text demonstrated the efficiency and robustness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
食品分类是医疗领域中的重要任务。在这种工作中，我们提议了一种多modal分类框架，使用修改后的EfficientNet和Mish活动函数进行图像分类，而传统的BERT变换器网络用于文本分类。我们的提议网络和其他状态公共方法在大型开源数据集UPMC Food-101上进行评估。实验结果表明，我们的提议网络在图像和文本分类方面具有显著的优势，与第二好的方法相比，图像分类精度提高11.57%，文本分类精度提高6.34%。我们还对文本分类使用机器学习和深度学习模型进行比较分析，结果表明，我们的方法在预测结果中具有更高的准确率、精度和回归率。
</details></li>
</ul>
<hr>
<h2 id="Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models"><a href="#Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models" class="headerlink" title="Circumventing Concept Erasure Methods For Text-to-Image Generative Models"></a>Circumventing Concept Erasure Methods For Text-to-Image Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01508">http://arxiv.org/abs/2308.01508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyu-dice-lab/circumventing-concept-erasure">https://github.com/nyu-dice-lab/circumventing-concept-erasure</a></li>
<li>paper_authors: Minh Pham, Kelly O. Marshall, Chinmay Hegde</li>
<li>for: 本研究旨在检验五种最近提出的概念消除方法，以及这些方法是否能够彻底从文本到图像模型中除去目标概念。</li>
<li>methods: 本研究使用了五种最近提出的概念消除方法，包括隐藏概念、替换概念、排除概念、屏蔽概念和筛选概念等方法。</li>
<li>results: 研究发现，无论使用哪种方法，都无法彻底从文本到图像模型中除去目标概念。特别是，使用特殊学习的词嵌入可以很容易地从sanitized模型中恢复排除的概念，而无需对模型的权重进行任何修改。这些结果表明，后期概念消除方法不够可靠，并质疑它们在AI安全中的应用。<details>
<summary>Abstract</summary>
Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. On the flip side, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to "erase" sensitive concepts from text-to-image models. In this work, we examine five recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we leverage the existence of special learned word embeddings that can retrieve "erased" concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Local-Global-Temporal-Fusion-Network-with-an-Attention-Mechanism-for-Multiple-and-Multiclass-Arrhythmia-Classification"><a href="#Local-Global-Temporal-Fusion-Network-with-an-Attention-Mechanism-for-Multiple-and-Multiclass-Arrhythmia-Classification" class="headerlink" title="Local-Global Temporal Fusion Network with an Attention Mechanism for Multiple and Multiclass Arrhythmia Classification"></a>Local-Global Temporal Fusion Network with an Attention Mechanism for Multiple and Multiclass Arrhythmia Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02416">http://arxiv.org/abs/2308.02416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Kwan Kim, Minji Lee, Kunwook Jo, Hee Seok Song, Seong-Whan Lee</li>
<li>for: This paper aims to develop a clinical decision support system (CDSS) for arrhythmia classification, addressing the challenge of varying arrhythmia lengths.</li>
<li>methods: The proposed method combines local temporal information extraction, global pattern extraction, and local-global information fusion with attention to detect and classify arrhythmia with a constrained input length.</li>
<li>results: The proposed method achieved superior performance on the MIT-BIH arrhythmia database (MITDB) and MIT-BIH atrial fibrillation database (AFDB), outperforming comparison models. The method also demonstrated good generalization ability when tested on a different database.<details>
<summary>Abstract</summary>
Clinical decision support systems (CDSSs) have been widely utilized to support the decisions made by cardiologists when detecting and classifying arrhythmia from electrocardiograms (ECGs). However, forming a CDSS for the arrhythmia classification task is challenging due to the varying lengths of arrhythmias. Although the onset time of arrhythmia varies, previously developed methods have not considered such conditions. Thus, we propose a framework that consists of (i) local temporal information extraction, (ii) global pattern extraction, and (iii) local-global information fusion with attention to perform arrhythmia detection and classification with a constrained input length. The 10-class and 4-class performances of our approach were assessed by detecting the onset and offset of arrhythmia as an episode and the duration of arrhythmia based on the MIT-BIH arrhythmia database (MITDB) and MIT-BIH atrial fibrillation database (AFDB), respectively. The results were statistically superior to those achieved by the comparison models. To check the generalization ability of the proposed method, an AFDB-trained model was tested on the MITDB, and superior performance was attained compared with that of a state-of-the-art model. The proposed method can capture local-global information and dynamics without incurring information losses. Therefore, arrhythmias can be recognized more accurately, and their occurrence times can be calculated; thus, the clinical field can create more accurate treatment plans by using the proposed method.
</details>
<details>
<summary>摘要</summary>
临床决策支持系统（CDSS）已广泛应用于心电图（ECG）上的心Rate变化的诊断和分类。然而，为了建立一个CDSS来进行心Rate变化的诊断和分类，存在许多挑战。主要的问题在于心Rate变化的持续时间不同，导致过去的方法无法考虑这种情况。因此，我们提出了一种框架，包括（i）本地时间信息提取，（ii）全局模式提取，以及（iii）本地-全局信息融合 WITH attention来实现受限输入长度下的心Rate变化诊断和分类。我们使用MIT-BIH心Rate变化数据库（MITDB）和MIT-BIHatrioventricular flutter数据库（AFDB）进行10类和4类的评估，结果显著高于比较模型。为了证明提出的方法的通用能力，使用AFDB训练好的模型在MITDB上进行测试，并实现了与当前状态艺术模型的比较。这种方法可以捕捉本地-全局信息和动态，不会产生信息损失，因此可以更准确地识别心Rate变化，并计算其发生时间，从而为临床领域创造更加准确的治疗计划。
</details></li>
</ul>
<hr>
<h2 id="Online-Multi-Task-Learning-with-Recursive-Least-Squares-and-Recursive-Kernel-Methods"><a href="#Online-Multi-Task-Learning-with-Recursive-Least-Squares-and-Recursive-Kernel-Methods" class="headerlink" title="Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods"></a>Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01938">http://arxiv.org/abs/2308.01938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel R. Lencione, Fernando J. Von Zuben</li>
<li>for: 这paper是为了解决在线多任务学习（MTL）回归问题而提出的两种新方法。</li>
<li>methods: 这paper使用了高性能图 струкured MTL formulation，并基于Weighted Recursive Least Squares（WRLS）和Online Sparse Least Squares Support Vector Regression（OSLSSVR）的再归版本。</li>
<li>results: 通过采用任务堆叠变换，这paper实现了一个包含多个任务关系的矩阵，并将其 integrate到MT-WRLS和MT-OSLSSVR中。相比现有Literature，这paper实现了精确和近似归并，并在输入空间维度（MT-WRLS）或字典大小（MT-OSLSSVR）上实现了 quitropic per-instance cost。在一个实际世界的风速预测案例中，我们比较了这paper所提出的方法和其他竞争方法，并发现了 significan performance gain。<details>
<summary>Abstract</summary>
This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind speed forecasting case study, evidencing the significant gain in performance of both proposed approaches.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这篇论文介绍了两种新的在线多任务学习（MTL）回归问题的方法。我们使用高性能的图形基于的 MTL 形式，并开发了其循环版本，基于最小二乘回归（WRLS）和在线稀疏最小二乘支持向量回归（OSLSSVR）。通过任务堆叠变换，我们表明了一个单个矩阵可以捕捉多个任务之间的关系，并提供结构信息。这个矩阵在 MT-WRLS 方法的初始化过程中使用，以及 MT-OSLSSVR 方法的多任务核函数中使用。与现有文献，大多使用在线梯度下降（OGD）或立方不精确方法，我们实现了精确和近似循环的quadratic per-instance cost在输入空间维度（MT-WRLS）或实例词典大小（MT-OSLSSVR）。我们将这两种在线 MTL 方法与其他竞争者进行比较，在一个实际的风速预测案例中，证明了我们的两种方法具有显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Minimax-Optimal-Q-Learning-with-Nearest-Neighbors"><a href="#Minimax-Optimal-Q-Learning-with-Nearest-Neighbors" class="headerlink" title="Minimax Optimal $Q$ Learning with Nearest Neighbors"></a>Minimax Optimal $Q$ Learning with Nearest Neighbors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01490">http://arxiv.org/abs/2308.01490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Puning Zhao, Lifeng Lai<br>for: This paper focuses on modifying the original $Q$ learning method to make it suitable for continuous state spaces, and proposes two new $Q$ learning methods to improve the convergence rate.methods: The paper uses nearest neighbor approach to estimate $Q$ function, but with a direct nearest neighbor approach instead of the kernel nearest neighbor in discretized regions.results: The paper shows that both offline and online methods are minimax rate optimal, and the time complexity is significantly improved in high dimensional state spaces.<details>
<summary>Abstract</summary>
$Q$ learning is a popular model free reinforcement learning method. Most of existing works focus on analyzing $Q$ learning for finite state and action spaces. If the state space is continuous, then the original $Q$ learning method can not be directly used. A modification of the original $Q$ learning method was proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest neighbors. Such modification makes $Q$ learning suitable for continuous state space. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$ function is $\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower bound $\tilde{\Omega}(T^{-1/(d+2)})$, indicating that this method is not efficient. This paper proposes two new $Q$ learning methods to bridge the gap of convergence rates in (Shah and Xie, 2018), with one of them being offline, while the other is online. Despite that we still use nearest neighbor approach to estimate $Q$ function, the algorithms are crucially different from (Shah and Xie, 2018). In particular, we replace the kernel nearest neighbor in discretized region with a direct nearest neighbor approach. Consequently, our approach significantly improves the convergence rate. Moreover, the time complexity is also significantly improved in high dimensional state spaces. Our analysis shows that both offline and online methods are minimax rate optimal.
</details>
<details>
<summary>摘要</summary>
$Q$ 学习是一种流行的模型自由奖励学习方法。大多数现有工作都集中在finite state和动作空间上分析 $Q$ 学习。如果状态空间是连续的，那么原始 $Q$ 学习方法直接使用不可靠。(Shah and Xie, 2018) 提出了修改原始 $Q$ 学习方法的方法，该方法通过 nearest neighbors 来估计 $Q$ 值。这种修改使 $Q$ 学习适用于连续状态空间。(Shah and Xie, 2018) 显示了 estimated $Q$ 函数的减少率为 $\tilde{O}(T^{-1/(d+3)})$, 这 slower than minimax lower bound $\tilde{\Omega}(T^{-1/(d+2)})$, 这表明这种方法不够有效。这篇论文提出了两种新的 $Q$ 学习方法，其中一种是 offline，另一种是 online。尽管我们仍然使用 nearest neighbor 方法来估计 $Q$ 函数，但这些算法与 (Shah and Xie, 2018) 的方法有所不同。具体来说，我们将 kernel nearest neighbor 在离散区域中替换为直接 nearest neighbor 方法。因此，我们的方法可以 significatively 提高减少率。此外，在高维状态空间中，我们的时间复杂度也得到了显著改善。我们的分析表明，两种方法都是 minimax 率最优。
</details></li>
</ul>
<hr>
<h2 id="Efficient-neural-supersampling-on-a-novel-gaming-dataset"><a href="#Efficient-neural-supersampling-on-a-novel-gaming-dataset" class="headerlink" title="Efficient neural supersampling on a novel gaming dataset"></a>Efficient neural supersampling on a novel gaming dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01483">http://arxiv.org/abs/2308.01483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Mercier, Ruan Erasmus, Yashesh Savani, Manik Dhingra, Fatih Porikli, Guillaume Berger</li>
<li>for: 提高视频游戏的实时渲染效能，以满足更高的分辨率、帧率和 фото真实性要求。</li>
<li>methods: 使用神经网络算法进行精度较高的超采样渲染内容，比现有方法高效4倍。同时，我们提供了一个新的数据集，包括视频游戏中的运动 вектор和深度信息，这些信息可以用于测试和提高超解算法的性能。</li>
<li>results: 与现有方法相比，我们的方法可以提供4倍的效率，同时保持同等的准确性。此外，我们的数据集可以填补现有数据集的空白，并成为测试和提高超解技术的 valuable 资源。<details>
<summary>Abstract</summary>
Real-time rendering for video games has become increasingly challenging due to the need for higher resolutions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge. Our work introduces a novel neural algorithm for supersampling rendered content that is 4 times more efficient than existing methods while maintaining the same level of accuracy. Additionally, we introduce a new dataset which provides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Online-covariance-estimation-for-stochastic-gradient-descent-under-Markovian-sampling"><a href="#Online-covariance-estimation-for-stochastic-gradient-descent-under-Markovian-sampling" class="headerlink" title="Online covariance estimation for stochastic gradient descent under Markovian sampling"></a>Online covariance estimation for stochastic gradient descent under Markovian sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01481">http://arxiv.org/abs/2308.01481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Roy, Krishnakumar Balasubramanian</li>
<li>for: 这个论文主要针对 Stochastic Gradient Descent (SGD) 的在 Markovian 采样下的在线拟合方法 Covariance 估计。</li>
<li>methods: 论文使用了 batch-means 方法来估计 Covariance，并且对 Markovian 采样进行了分析。</li>
<li>results: 论文显示了在 Markovian 采样下，batch-means 方法的 convergence 率为 $O\big(\sqrt{d},n^{-1&#x2F;8}(\log n)^{1&#x2F;4}\big)$ 和 $O\big(\sqrt{d},n^{-1&#x2F;8}\big)$，与 $\iid$  случа子中最佳的 convergence 率相当，即Logarithmic 因子。此外，论文还研究了 SGD 动态中 $\ell_2$ 范数的错误的 converge 率，以及在 Markovian 采样下的 SGD 训练中的Linear 和 Logistic 回归模型的 numerics 示例。最后，论文应用了这些结论来解决了一个挑战性的攻击者可以在训练过程中随机修改特征来增加被分类到特定目标类的概率的问题。<details>
<summary>Abstract</summary>
We study the online overlapping batch-means covariance estimator for Stochastic Gradient Descent (SGD) under Markovian sampling. We show that the convergence rates of the covariance estimator are $O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$ and $O\big(\sqrt{d}\,n^{-1/8}\big)$ under state-dependent and state-independent Markovian sampling, respectively, with $d$ representing dimensionality and $n$ denoting the number of observations or SGD iterations. Remarkably, these rates match the best-known convergence rate previously established for the independent and identically distributed ($\iid$) case by \cite{zhu2021online}, up to logarithmic factors. Our analysis overcomes significant challenges that arise due to Markovian sampling, leading to the introduction of additional error terms and complex dependencies between the blocks of the batch-means covariance estimator. Moreover, we establish the convergence rate for the first four moments of the $\ell_2$ norm of the error of SGD dynamics under state-dependent Markovian data, which holds potential interest as an independent result. To validate our theoretical findings, we provide numerical illustrations to derive confidence intervals for SGD when training linear and logistic regression models under Markovian sampling. Additionally, we apply our approach to tackle the intriguing problem of strategic classification with logistic regression, where adversaries can adaptively modify features during the training process to increase their chances of being classified in a specific target class.
</details>
<details>
<summary>摘要</summary>
我们研究在采用Markovian sampling的线上遮盾Batch-means协方差估计器中的Stochastic Gradient Descent（SGD）。我们表明了协方差估计器的数据速度为$O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$和$O\big(\sqrt{d}\,n^{-1/8}\big)$，具体取决于Markovian sampling的状态。这些速度与以前在独立同分布（iid）情况下所得到的最佳速度相匹配，仅带有对数因子。我们的分析解决了由Markovian sampling引起的重要挑战，包括附加的错误项和几何上的复杂对话。此外，我们还证明了SGD动态中的第四个几何中的错误的$\ell_2$ нор的数据速度，这个结果可能具有独立的意义。在实验中，我们提供了几个数据示例，以建立SGD训练Linear和Logistic regression模型的信任区间。此外，我们还应用我们的方法解决了具有挑战性的分类问题，其中敌人可以在训练过程中随机修改特征，以增加他们被特定目标类别中分类的机会。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Machine-Learning-for-Discovery-Statistical-Challenges-Opportunities"><a href="#Interpretable-Machine-Learning-for-Discovery-Statistical-Challenges-Opportunities" class="headerlink" title="Interpretable Machine Learning for Discovery: Statistical Challenges &amp; Opportunities"></a>Interpretable Machine Learning for Discovery: Statistical Challenges &amp; Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01475">http://arxiv.org/abs/2308.01475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Genevera I. Allen, Luqin Gan, Lili Zheng</li>
<li>for: 本研究的目的是探讨可解释机器学习技术在大数据中进行发现和探索的应用。</li>
<li>methods: 本研究使用了多种可解释机器学习技术，包括可视化、预测和数据分析等方法，以便从大数据中提取有用的信息和发现新知识。</li>
<li>results: 本研究发现了一些在可解释机器学习技术应用中的挑战，包括数据采样和稳定性问题，以及验证发现的困难。同时，研究也提出了一些解决这些挑战的方法和技术。<details>
<summary>Abstract</summary>
New technologies have led to vast troves of large and complex datasets across many scientific domains and industries. People routinely use machine learning techniques to not only process, visualize, and make predictions from this big data, but also to make data-driven discoveries. These discoveries are often made using Interpretable Machine Learning, or machine learning models and techniques that yield human understandable insights. In this paper, we discuss and review the field of interpretable machine learning, focusing especially on the techniques as they are often employed to generate new knowledge or make discoveries from large data sets. We outline the types of discoveries that can be made using Interpretable Machine Learning in both supervised and unsupervised settings. Additionally, we focus on the grand challenge of how to validate these discoveries in a data-driven manner, which promotes trust in machine learning systems and reproducibility in science. We discuss validation from both a practical perspective, reviewing approaches based on data-splitting and stability, as well as from a theoretical perspective, reviewing statistical results on model selection consistency and uncertainty quantification via statistical inference. Finally, we conclude by highlighting open challenges in using interpretable machine learning techniques to make discoveries, including gaps between theory and practice for validating data-driven-discoveries.
</details>
<details>
<summary>摘要</summary>
新技术使得各科学领域和产业中的大量大数据备受欢迎。人们常常使用机器学习技术不仅处理、视觉和预测这些大数据，还可以通过机器学习模型和技术获得人类可理解的发现。在这篇论文中，我们讨论了机器学习可解释的场景，特别是在大数据集中使用机器学习模型和技术来获得新的发现。我们还详细介绍了在超级vised和无级vised情况下使用机器学习可解释的发现方法，以及如何验证这些发现的数据驱动方法。我们还讨论了验证这些发现的挑战，包括数据分割和稳定性问题，以及统计学的模型选择一致性和不确定性量化问题。最后，我们结束这篇文章，描述了使用机器学习可解释技术进行发现时存在的开放挑战。
</details></li>
</ul>
<hr>
<h2 id="Reverse-Stable-Diffusion-What-prompt-was-used-to-generate-this-image"><a href="#Reverse-Stable-Diffusion-What-prompt-was-used-to-generate-this-image" class="headerlink" title="Reverse Stable Diffusion: What prompt was used to generate this image?"></a>Reverse Stable Diffusion: What prompt was used to generate this image?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01472">http://arxiv.org/abs/2308.01472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah</li>
<li>for: 本研究的目的是提出一种新的文本描述生成模型，用于预测由生成扩散模型生成的图像所关联的文本描述。</li>
<li>methods: 我们采用了一种组合白盒和黑盒模型的方法，其中包括了聚合文本描述 regression 和多标签词汇分类目标函数。此外，我们还采用了一种师生学习程序和领域适应诊断器学习方法来提高方法的性能。</li>
<li>results: 我们在DiffusionDB数据集上进行了实验，并取得了优秀的结果。在白盒模型上，我们的新学习框架得到了最高的提升。此外，我们还发现了一个有趣的发现：通过直接将扩散模型用于文本-图像生成任务，可以使模型生成的图像与输入文本更加吻合。<details>
<summary>Abstract</summary>
Text-to-image diffusion models such as Stable Diffusion have recently attracted the interest of many researchers, and inverting the diffusion process can play an important role in better understanding the generative process and how to engineer prompts in order to obtain the desired images. To this end, we introduce the new task of predicting the text prompt given an image generated by a generative diffusion model. We combine a series of white-box and black-box models (with and without access to the weights of the diffusion network) to deal with the proposed task. We propose a novel learning framework comprising of a joint prompt regression and multi-label vocabulary classification objective that generates improved prompts. To further improve our method, we employ a curriculum learning procedure that promotes the learning of image-prompt pairs with lower labeling noise (i.e. that are better aligned), and an unsupervised domain-adaptive kernel learning method that uses the similarities between samples in the source and target domains as extra features. We conduct experiments on the DiffusionDB data set, predicting text prompts from images generated by Stable Diffusion. Our novel learning framework produces excellent results on the aforementioned task, yielding the highest gains when applied on the white-box model. In addition, we make an interesting discovery: training a diffusion model on the prompt generation task can make the model generate images that are much better aligned with the input prompts, when the model is directly reused for text-to-image generation.
</details>
<details>
<summary>摘要</summary>
文本至图像协托模型，如稳定协托，最近吸引了许多研究人员的关注，而协托过程的逆转也可以更好地理解生成过程和如何引入提示以获得所需的图像。为此，我们介绍了预测图像生成模型中的文本提示任务。我们组合了一系列的白盒和黑盒模型（具有或无Diffusion网络权重的访问）来处理该任务。我们提出了一种新的学习框架，包括文本提示回归和多标签词汇分类目标，可以生成改进的提示。为了进一步改进我们的方法，我们采用了课程学习程序，其中优先采用低噪音（即更好地对齐）的图像提示对象，以及一种不supervised领域适应kernel学习方法，该方法使用源和目标领域样本之间的相似性作为额外特征。我们在DiffusionDB数据集上进行了实验，预测由Stable Diffusion生成的图像中的文本提示。我们的新的学习框架在该任务上具有优秀的成绩，尤其是在白盒模型上。此外，我们发现了一项 interessante发现：通过直接将协托模型学习到提示生成任务上，可以使模型生成与输入提示更好地对齐的图像。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving"><a href="#Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving" class="headerlink" title="Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving"></a>Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01471">http://arxiv.org/abs/2308.01471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Agro, Quinlan Sykora, Sergio Casas, Raquel Urtasun</li>
<li>for: 这个论文旨在提出一种能够同时捕捉它周围环境和预测其他交通参与者未来行为的自动驾驶车辆（SDV）。</li>
<li>methods: 这个论文使用了一种混合了卷积神经网络和注意力机制的方法，能够同时预测它周围的占用和流动Grid，并且可以 directly queried by the motion planner at continuous spatio-temporal locations。</li>
<li>results: 经过广泛的实验证明，这个方法可以在城市和高速公路上的不同环境下表现出优于当前状态的论文。<details>
<summary>Abstract</summary>
A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traffic participants. Existing works either perform object detection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the number of detections needs to be kept low for efficiency reasons, sacrificing object recall. The latter is computationally expensive due to the high-dimensionality of the output grid, and suffers from the limited receptive field inherent to fully convolutional networks. Furthermore, both approaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to perception and future prediction that implicitly represents occupancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be directly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous explicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through extensive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the current state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito.
</details>
<details>
<summary>摘要</summary>
一个自动驾驶车（SDV）需要能够感知周围环境并预测其他交通参与者的未来行为。现有的工作都是在先检测对象，然后预测这些检测到的对象的轨迹，或者预测整个场景的厚度占用和流动Grid。前者会导致安全隐患，因为需要降低检测数量以实现效率，导致对象回溯问题。后者由于输出格式的高维度性而 computationally expensive，同时受到全 convolutional network 的局部感知限制。此外，两种方法都需要大量计算资源预测可能不会被询问的区域或对象。这种情况驱动我们提出了一种独立的感知和未来预测方法，该方法可以直接由运动规划器查询，避免不必要的计算。此外，我们还设计了一种高效但有效的全局注意机制，以解决前一些明确occupancy预测方法的局部感知限制。经过广泛的实验，我们表明我们的含义模型在城市和高速公路上都能够超越当前状态。更多信息请访问我们的项目网站：https://waabi.ai/research/implicito。
</details></li>
</ul>
<hr>
<h2 id="Training-Data-Protection-with-Compositional-Diffusion-Models"><a href="#Training-Data-Protection-with-Compositional-Diffusion-Models" class="headerlink" title="Training Data Protection with Compositional Diffusion Models"></a>Training Data Protection with Compositional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01937">http://arxiv.org/abs/2308.01937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Golatkar, Alessandro Achille, Ashwin Swaminathan, Stefano Soatto</li>
<li>for: 这篇论文是为了推动大规模扩散模型的各种应用场景，如选择性忘记和继续学习等。</li>
<li>methods: 这篇论文提出了一种叫做组 compartmentalized Diffusion Models（CDM）的方法，允许在推导时将不同的扩散模型（或提示）分别训练在不同的数据源上，并在推导时自由组合它们以实现与准确模型（训练在所有数据上）相当的性能。此外，每个模型只包含它在训练时接触到的数据subset的信息，因此可以实现数据训练保护和用户访问权限控制等功能。</li>
<li>results: 该研究表明，CDM可以实现选择性忘记和继续学习等功能，并且可以根据用户的访问权限来服务自定义的模型。此外，CDM还可以确定特定样本的数据subset的重要性。<details>
<summary>Abstract</summary>
We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
</details>
<details>
<summary>摘要</summary>
我们介绍 compartmentalized diffusion models (CDM)，一种方法可以在推导时分别训练不同的扩散模型（或启发），并在推导时随意组合。个别模型可以在隔离的时间、不同的分布和领域上进行训练，而且可以在推导时随意组合以实现与单一模型训练在所有数据上的性能相似。此外，每个模型只包含它在训练时所接触过的数据subset的信息，因此可以实现多种训练数据保护。例如，CDMs可以实现选择性的忘记和持续学习，以及根据用户的存取权提供自定义的模型。CDMs还允许决定特定数据subset的重要性在生成特定样本中。
</details></li>
</ul>
<hr>
<h2 id="Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI"><a href="#Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI" class="headerlink" title="Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI"></a>Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04448">http://arxiv.org/abs/2308.04448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avijit Ghosh, Dhanya Lakshmi<br>for:The paper focuses on the ethical and safety concerns surrounding the use of generative AI, particularly in the context of consumer-facing models, and proposes a framework called Dual Governance to address these issues.methods:The paper discusses the limitations of existing centralized regulations and decentralized safety mechanisms, and proposes a cooperative synergy between government regulations and community-developed safety mechanisms as a solution.results:The paper argues that the proposed Dual Governance framework can promote innovation and creativity while ensuring the safe and ethical deployment of generative AI.<details>
<summary>Abstract</summary>
Generative Artificial Intelligence (AI) has seen mainstream adoption lately, especially in the form of consumer-facing, open-ended, text and image generating models. However, the use of such systems raises significant ethical and safety concerns, including privacy violations, misinformation and intellectual property theft. The potential for generative AI to displace human creativity and livelihoods has also been under intense scrutiny. To mitigate these risks, there is an urgent need of policies and regulations responsible and ethical development in the field of generative AI. Existing and proposed centralized regulations by governments to rein in AI face criticisms such as not having sufficient clarity or uniformity, lack of interoperability across lines of jurisdictions, restricting innovation, and hindering free market competition. Decentralized protections via crowdsourced safety tools and mechanisms are a potential alternative. However, they have clear deficiencies in terms of lack of adequacy of oversight and difficulty of enforcement of ethical and safety standards, and are thus not enough by themselves as a regulation mechanism. We propose a marriage of these two strategies via a framework we call Dual Governance. This framework proposes a cooperative synergy between centralized government regulations in a U.S. specific context and safety mechanisms developed by the community to protect stakeholders from the harms of generative AI. By implementing the Dual Governance framework, we posit that innovation and creativity can be promoted while ensuring safe and ethical deployment of generative AI.
</details>
<details>
<summary>摘要</summary>
生成人工智能（AI）在最近几年内得到了普遍的批准，特别是在consumer-facing、开放结束的文本和图像生成模型的形式。然而，使用这些系统的使用带来了重大的伦理和安全问题，包括隐私侵犯、谎言和知识产权盗窃。生成AI可能会取代人类创造力和生活方式，也在严峻的检讨中。为了缓解这些风险，生成AI的负责任和伦理的开发是一个紧迫的需求。现有的中央政府的法规和 proposed regulations 面临批评，如不具有足够的明确性和一致性，跨司法管辖区域的不具有可靠性，限制创新，和妨碍自由市场竞争。 Decentralized protection mechanisms via crowdsourced safety tools and mechanisms are a potential alternative，但它们缺乏伦理和安全标准的充分监管和执行能力，因此不够作为唯一的规则机制。我们提议一种名为“双重管理”的框架，这种框架提议在美国特定的上下文中，中央政府的法规和社区开发的安全机制之间建立了合作的同步。通过实施“双重管理”框架，我们认为可以促进创新和创造力，同时确保生成AI的安全和伦理部署。
</details></li>
</ul>
<hr>
<h2 id="VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference"><a href="#VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference" class="headerlink" title="VertexSerum: Poisoning Graph Neural Networks for Link Inference"></a>VertexSerum: Poisoning Graph Neural Networks for Link Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01469">http://arxiv.org/abs/2308.01469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Ding, Shijin Duan, Xiaolin Xu, Yunsi Fei</li>
<li>for: 本研究旨在攻击图structured数据中的隐私泄露，特别是社交分析和诈骗探测等应用中使用的图生成网络（GNNs）。</li>
<li>methods: 我们提出了一种新的图毒液攻击方法——VertexSerum，它可以更好地利用图连接的敏感性和价值，从而提高图连接泄露的效果。我们还提出了一种注意力机制，可以嵌入到连接检测网络中，以提高连接检测的准确性。</li>
<li>results: 我们的实验结果表明，VertexSerum在四个真实世界数据集和三种不同的GNN结构下，与现有的链接探测攻击方法相比，平均提高了链接泄露的AUC分数 by 9.8%。此外，我们的实验还表明，VertexSerum在黑盒和在线学习Setting下都具有良好的实用性。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of $9.8\%$ across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
Graph Neural Networks (GNNs) 已经在不同的应用中提供了出色的表现，如社交分析和诈骗检测。图像链接，如社交关系和交易历史记录，是敏感和有价值的信息，这会使用 GNNs 引发隐私问题。为了利用这些漏洞，我们提议 VertexSerum，一种新的图像恶意攻击，可以增强图像链接窃取的效果。为更准确地推断节点相互关系，我们提议一种注意力机制，可以在链接检测网络中嵌入。我们的实验表明，VertexSerum significantly outperforms 当前链接推断攻击的最佳实践（SOTA），提高了平均混淆率（AUC）分数，分别在四个真实世界数据集和三种不同的 GNN 结构上提高了9.8%。此外，我们的实验还表明 VertexSerum 在黑盒和在线学习设置下都是有效的，进一步验证了它在实际场景中的适用性。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Small-Molecule-Properties-in-Drug-Discovery"><a href="#Machine-Learning-Small-Molecule-Properties-in-Drug-Discovery" class="headerlink" title="Machine Learning Small Molecule Properties in Drug Discovery"></a>Machine Learning Small Molecule Properties in Drug Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12354">http://arxiv.org/abs/2308.12354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikolai Schapin, Maciej Majewski, Alejandro Varela, Carlos Arroniz, Gianni De Fabritiis</li>
<li>for: 这篇论文主要是为了介绍近年来用于小分子性质预测的机器学习（ML）方法。</li>
<li>methods: 论文详细介绍了各种ML方法，包括绑定Affinity、溶解度、ABMET等多种属性的预测。还讨论了现有的流行数据集和分子特征，如化学指纹和图像神经网络。</li>
<li>results: 论文分析了小分子性质预测中存在的挑战，如同时预测和优化多个属性的问题，并 briefly介绍了可能的多目标优化技术来均衡多个属性。最后，论文评估了模型预测结果的可理解性，尤其是在药物发现过程中的关键决策中。总的来说，这篇论文提供了药物性质预测领域机器学习模型的全面回顾。<details>
<summary>Abstract</summary>
Machine learning (ML) is a promising approach for predicting small molecule properties in drug discovery. Here, we provide a comprehensive overview of various ML methods introduced for this purpose in recent years. We review a wide range of properties, including binding affinities, solubility, and ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity). We discuss existing popular datasets and molecular descriptors and embeddings, such as chemical fingerprints and graph-based neural networks. We highlight also challenges of predicting and optimizing multiple properties during hit-to-lead and lead optimization stages of drug discovery and explore briefly possible multi-objective optimization techniques that can be used to balance diverse properties while optimizing lead candidates. Finally, techniques to provide an understanding of model predictions, especially for critical decision-making in drug discovery are assessed. Overall, this review provides insights into the landscape of ML models for small molecule property predictions in drug discovery. So far, there are multiple diverse approaches, but their performances are often comparable. Neural networks, while more flexible, do not always outperform simpler models. This shows that the availability of high-quality training data remains crucial for training accurate models and there is a need for standardized benchmarks, additional performance metrics, and best practices to enable richer comparisons between the different techniques and models that can shed a better light on the differences between the many techniques.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）是药物搜索中预测小分子性质的有前途的方法。我们在这篇文章中提供了过去几年内对这些目的的多种机器学习方法的全面概述。我们评论了各种性质，包括绑定稳定性、溶解度和ADMET（吸收、分布、代谢、排泄和毒性）。我们讨论了现有的受欢迎数据集和分子特征，如化学指纹和图像基于神经网络。我们也提到了预测和优化多种性质的挑战，特别是在碰撞到领先和领先优化阶段。我们 briefly explored 可能的多目标优化技术，以填充多种性质的平衡。最后，我们评估了模型预测的方法，特别是在关键决策中的评估。总的来说，这篇文章提供了机器学习模型在小分子性质预测中的领域概况。目前有多种不同的方法，但它们的表现通常相似。神经网络，虽然更灵活，并不总是表现更好。这表明高质量的训练数据的可用性仍然是训练准确模型的关键，而且需要标准化的参考数据、额外的性能指标和最佳实践，以便更好地对不同的技术和模型进行比较，从而更好地了解它们之间的差异。
</details></li>
</ul>
<hr>
<h2 id="From-Discrete-Tokens-to-High-Fidelity-Audio-Using-Multi-Band-Diffusion"><a href="#From-Discrete-Tokens-to-High-Fidelity-Audio-Using-Multi-Band-Diffusion" class="headerlink" title="From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion"></a>From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02560">http://arxiv.org/abs/2308.02560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin San Roman, Yossi Adi, Antoine Deleforge, Romain Serizel, Gabriel Synnaeve, Alexandre Défossez</li>
<li>for: 这个论文的目的是提出一种高级别扩散模型，可以从低比特率的精度表示生成任何类型的音频模式（如语音、音乐、环境声）。</li>
<li>methods: 这个论文使用了扩散模型，但不同于之前的扩散模型，它可以生成任何类型的音频模式，并且可以在同等比特率下比其他生成技术具有更高的 perceived quality。</li>
<li>results: 根据论文的结果，这种扩散模型可以生成高质量的音频，并且可以在不同的音频类型和bit rate下进行调整。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Deep generative models can generate high-fidelity audio conditioned on various types of representations (e.g., mel-spectrograms, Mel-frequency Cepstral Coefficients (MFCC)). Recently, such models have been used to synthesize audio waveforms conditioned on highly compressed representations. Although such methods produce impressive results, they are prone to generate audible artifacts when the conditioning is flawed or imperfect. An alternative modeling approach is to use diffusion models. However, these have mainly been used as speech vocoders (i.e., conditioned on mel-spectrograms) or generating relatively low sampling rate signals. In this work, we propose a high-fidelity multi-band diffusion-based framework that generates any type of audio modality (e.g., speech, music, environmental sounds) from low-bitrate discrete representations. At equal bit rate, the proposed approach outperforms state-of-the-art generative techniques in terms of perceptual quality. Training and, evaluation code, along with audio samples, are available on the facebookresearch/audiocraft Github page.
</details>
<details>
<summary>摘要</summary>
深度生成模型可以生成高准确性音频，根据不同类型的表示（如mel-spectrograms、Mel-frequency Cepstral Coefficients (MFCC)）。最近，这些模型已经用于生成基于高度压缩表示的音频波形。虽然这些方法产生了很好的结果，但是它们容易产生噪音artefacts，当conditioning是错误或不完美时。另一种模型化方法是使用扩散模型。然而，这些模型主要用于speech vocoder（基于mel-spectrograms）或生成低频率的信号。在这项工作中，我们提议一种高准确度多带 diffusion-based框架，可以从低比特率精确表示中生成任何类型的音频模式（如语音、音乐、环境声）。在相同的比特率下，我们的提议方法与现状最佳生成技术相比，在人类可识别质量上表现出 excel。训练和评估代码，以及音频示例，可以在facebookresearch/audiocraft GitHub页面上找到。
</details></li>
</ul>
<hr>
<h2 id="A-digital-twin-framework-for-civil-engineering-structures"><a href="#A-digital-twin-framework-for-civil-engineering-structures" class="headerlink" title="A digital twin framework for civil engineering structures"></a>A digital twin framework for civil engineering structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01445">http://arxiv.org/abs/2308.01445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Torzoni, Marco Tezzele, Stefano Mariani, Andrea Manzoni, Karen E. Willcox</li>
<li>for: This paper proposes a predictive digital twin approach to health monitoring, maintenance, and management planning for civil engineering structures.</li>
<li>methods: The proposed approach uses a probabilistic graphical model, dynamic Bayesian network, and deep learning models to update the digital twin state in real-time and inform optimal maintenance and management actions.</li>
<li>results: The paper demonstrates the effectiveness of the proposed approach through two synthetic case studies, showing the ability of the digital twin to provide real-time structural health diagnostics and inform dynamic decision-making.<details>
<summary>Abstract</summary>
The digital twin concept represents an appealing opportunity to advance condition-based and predictive maintenance paradigms for civil engineering systems, thus allowing reduced lifecycle costs, increased system safety, and increased system availability. This work proposes a predictive digital twin approach to the health monitoring, maintenance, and management planning of civil engineering structures. The asset-twin coupled dynamical system is encoded employing a probabilistic graphical model, which allows all relevant sources of uncertainty to be taken into account. In particular, the time-repeating observations-to-decisions flow is modeled using a dynamic Bayesian network. Real-time structural health diagnostics are provided by assimilating sensed data with deep learning models. The digital twin state is continually updated in a sequential Bayesian inference fashion. This is then exploited to inform the optimal planning of maintenance and management actions within a dynamic decision-making framework. A preliminary offline phase involves the population of training datasets through a reduced-order numerical model and the computation of a health-dependent control policy. The strategy is assessed on two synthetic case studies, involving a cantilever beam and a railway bridge, demonstrating the dynamic decision-making capabilities of health-aware digital twins.
</details>
<details>
<summary>摘要</summary>
数字双生物概念在 цивиLENGINEERING 系统中表现出了吸引人的机会，以提高基于状况的维护和预测维护方法，从而降低生命周期成本、提高系统安全性和系统可用性。该工作提议一种预测性数字双生物方法来监测、维护和规划 цивиLENGINEERING 结构的健康状况。 asset-twin  Coupled 动力系统使用 probabilistic graphical model 编码，以涵盖所有相关的不确定性因素。特别是，时间重复的观测到决策流程使用动态 Bayesian network 模型。在实时 Structural health 诊断中，把感知数据 assimilate  WITH deep learning models。数字双生物状态在 sequential Bayesian inference 方式中不断更新。这后来被用来决策维护和管理行动的优化计划，在动态决策框架中。在 preliminary offline 阶段，通过减少的数值模型 Compute 健康依赖控制策略。该策略在 two  Synthetic case studies 中， involving 悬臂和铁路桥，表现出了健康意识数字双生物的动态决策能力。
</details></li>
</ul>
<hr>
<h2 id="DLSIA-Deep-Learning-for-Scientific-Image-Analysis"><a href="#DLSIA-Deep-Learning-for-Scientific-Image-Analysis" class="headerlink" title="DLSIA: Deep Learning for Scientific Image Analysis"></a>DLSIA: Deep Learning for Scientific Image Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02559">http://arxiv.org/abs/2308.02559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric J Roberts, Tanny Chavez, Alexander Hexemer, Petrus H. Zwart</li>
<li>for: 用于科学图像分析领域的深度学习库，为科学家和研究人员提供可自定义的卷积神经网络架构，用于许多图像分析任务，包括下游数据处理和实验循环计算场景。</li>
<li>methods: 使用易于使用的架构，如自动编码器、可调 U-Net 和精简 mixed-scale dense network (MSDNet)，以及 randomly generated sparse mixed-scale networks (SMSNets)。</li>
<li>results: 提供可访问的 CNN 构建和抽象，让科学家可以适应机器学习方法，加速发现，促进交叉领域合作，并进展科学图像分析研究。<details>
<summary>Abstract</summary>
We introduce DLSIA (Deep Learning for Scientific Image Analysis), a Python-based machine learning library that empowers scientists and researchers across diverse scientific domains with a range of customizable convolutional neural network (CNN) architectures for a wide variety of tasks in image analysis to be used in downstream data processing, or for experiment-in-the-loop computing scenarios. DLSIA features easy-to-use architectures such as autoencoders, tunable U-Nets, and parameter-lean mixed-scale dense networks (MSDNets). Additionally, we introduce sparse mixed-scale networks (SMSNets), generated using random graphs and sparse connections. As experimental data continues to grow in scale and complexity, DLSIA provides accessible CNN construction and abstracts CNN complexities, allowing scientists to tailor their machine learning approaches, accelerate discoveries, foster interdisciplinary collaboration, and advance research in scientific image analysis.
</details>
<details>
<summary>摘要</summary>
我们介绍DLSIA（深度学习 для科学影像分析），这是一个基于Python的机器学习库，它为科学家和研究人员在多种科学领域提供了一系列可自定义的卷积神经网络架构，用于处理各种影像分析任务，可以用于下游资料处理或实验运行 Computing enario。DLSIA 提供了易于使用的架构，例如自动encoder、可调 U-Net 和简洁的混合缩减网络（MSDNets）。此外，我们还引入了随机 graphs 和简Connection 的稀疏混合网络（SMSNets）。随着实验数据的数量和复杂度不断增加，DLSIA 提供了可访问的 CNN 建构和抽象 CNN 复杂度，让科学家能够适应自己的机器学习方法，加速发现，促进交叉领域合作，并进步科学影像分析研究。
</details></li>
</ul>
<hr>
<h2 id="Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations"><a href="#Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations" class="headerlink" title="Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations"></a>Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01438">http://arxiv.org/abs/2308.01438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Mohammadshirazi, Aida Nadafian, Amin Karimi Monsefi, Mohammad H. Rafiei, Rajiv Ramnath</li>
<li>for: 这个研究旨在提出六个新的物理学基础的机器学习模型，以精确地估计室内污染物浓度。</li>
<li>methods: 这个研究使用了 físic-based 的机器学习模型，包括State-space概念、Gated Recurrent Units和Decomposition技术。</li>
<li>results: 研究发现这些提案的模型比类似的现代变数组件模型更加简单、computationally更高效和更精确。<details>
<summary>Abstract</summary>
Cost-effective sensors are capable of real-time capturing a variety of air quality-related modalities from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models are capable of performing air-quality "ahead-of-time" approximations. Undoubtedly, accurate indoor air quality approximation significantly helps provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. However, it is crucial to design an ML architecture to capture the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models include an adroit combination of state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are shown to be less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their relatively light architecture (computational efficiency) and, more importantly, their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.
</details>
<details>
<summary>摘要</summary>
cost-effective sensors can real-time capture various indoor/outdoor air quality-related modalities, from different pollutant concentrations to humidity and temperature. machine learning (ml) models can perform air quality "ahead-of-time" approximations. accurately approximating indoor air quality can help provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. however, it is crucial to design an ml architecture to capture the domain knowledge, so-called problem physics. in this study, we propose six novel physics-based ml models for accurate indoor pollutant concentration approximations. the proposed models combine state-space concepts in physics, gated recurrent units, and decomposition techniques. the proposed models were illustrated using data collected from five offices in a commercial building in california. the proposed models are less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. the superiority of the proposed models is due to their relatively light architecture (computational efficiency) and their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.
</details></li>
</ul>
<hr>
<h2 id="Price-Aware-Deep-Learning-for-Electricity-Markets"><a href="#Price-Aware-Deep-Learning-for-Electricity-Markets" class="headerlink" title="Price-Aware Deep Learning for Electricity Markets"></a>Price-Aware Deep Learning for Electricity Markets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01436">http://arxiv.org/abs/2308.01436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vladimir Dvorkin, Ferdinando Fioretto</li>
<li>for: 该论文旨在探讨深度学习在运维规划中的应用，以及深度学习所带来的预测错误对电价价格的影响。</li>
<li>methods: 该论文使用了深度学习模型来预测电力供应和需求，并对预测错误进行分析。</li>
<li>results: 该论文发现了预测错误对电价价格的影响，并提出了一种基于深度学习的电力市场清算优化方法来增强公平性。该方法可以均衡预测错误和价格错误，从而提高系统的公平性和稳定性。<details>
<summary>Abstract</summary>
While deep learning gradually penetrates operational planning, its inherent prediction errors may significantly affect electricity prices. This letter examines how prediction errors propagate into electricity prices, revealing notable pricing errors and their spatial disparity in congested power systems. To improve fairness, we propose to embed electricity market-clearing optimization as a deep learning layer. Differentiating through this layer allows for balancing between prediction and pricing errors, as oppose to minimizing prediction errors alone. This layer implicitly optimizes fairness and controls the spatial distribution of price errors across the system. We showcase the price-aware deep learning in the nexus of wind power forecasting and short-term electricity market clearing.
</details>
<details>
<summary>摘要</summary>
而深度学习逐渐渗透到运维规划中，它的内生预测错误可能对电力价格产生重要影响。这封信件研究了预测错误如何传播到电力价格上，揭示了明显的价格错误和其空间差异在拥挤的电力系统中。为了提高公平性，我们提议将电力市场清算优化作为深度学习层的一部分。通过这层的微调，可以平衡预测错误和价格错误之间的平衡，而不是仅仅是减少预测错误。这层隐式地优化了公平性和价格错误的空间分布在系统中。我们在风力发电预测和短期电力市场清算之间展示了价格意识的深度学习。
</details></li>
</ul>
<hr>
<h2 id="COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography"><a href="#COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography" class="headerlink" title="COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography"></a>COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01433">http://arxiv.org/abs/2308.01433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noemi Maritza L. Romero, Ricco Vasconcellos, Mariana R. Mendoza, João L. D. Comba</li>
<li>for: 该论文目的是为了开发一种基于计算机断层成像（CT）图像的肺疾病分类方法，以提高肺疾病诊断的准确性和效率。</li>
<li>methods: 该方法使用了深度学习建模，将多个视角下的肺部CT图像转化为三维Volume Rendering图像，以提高肺疾病诊断的准确性和效率。</li>
<li>results: 对于私有数据和公共数据集的比较，该方法能够有效地识别肺疾病，并与切片方法相比，表现竞争力强。<details>
<summary>Abstract</summary>
The COVID-19 pandemic presented numerous challenges to healthcare systems worldwide. Given that lung infections are prevalent among COVID-19 patients, chest Computer Tomography (CT) scans have frequently been utilized as an alternative method for identifying COVID-19 conditions and various other types of pulmonary diseases. Deep learning architectures have emerged to automate the identification of pulmonary disease types by leveraging CT scan slices as inputs for classification models. This paper introduces COVID-VR, a novel approach for classifying pulmonary diseases based on volume rendering images of the lungs captured from multiple angles, thereby providing a comprehensive view of the entire lung in each image. To assess the effectiveness of our proposal, we compared it against competing strategies utilizing both private data obtained from partner hospitals and a publicly available dataset. The results demonstrate that our approach effectively identifies pulmonary lesions and performs competitively when compared to slice-based methods.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行对全球医疗系统带来了无数的挑战。由于 COVID-19 患者中肺部感染很普遍，因此胸部计算机扫描（CT）成为了一种代替方法来诊断 COVID-19 状况和其他多种肺病。深度学习架构在 CT 扫描片为分类模型提供输入，以自动识别肺病类型。本文介绍了 COVID-VR，一种基于肺部体积渲染图像的新方法，以捕捉多个角度捕捉肺部的全面视图。为评估我们的建议的有效性，我们与合作医院提供的私人数据进行比较，以及公开可用的数据集。结果显示，我们的方法可以有效地识别肺病涂抹，并与slice-based方法相比竞争性地表现。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training"><a href="#Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training" class="headerlink" title="Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training"></a>Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02427">http://arxiv.org/abs/2308.02427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanis Bahroun, Shagesh Sridharan, Atithi Acharya, Dmitri B. Chklovskii, Anirvan M. Sengupta</li>
<li>for: 这个研究旨在开发一种基于本地学习规则的替代算法，以增强backpropagation算法的有效性和生物可能性。</li>
<li>methods: 研究使用了一种主要是无监督的相似匹配（SM）框架，该框架与生物系统中观察到的机制相符，并且具有在线、本地化和生物可能性的算法。</li>
<li>results: 研究人员提出了一种使用PyTorch实现Convolutional Nonnegative SM的方法，并引入了一种本地化的supervised SM目标，以便堆叠SM层。此外，研究人员还使用PyTorch实现了预训练 architecture such as LeNet，并对BP-trained模型中的特征进行评估。这项研究结合了生物可能性的算法和计算效率，开辟了多个可能性的探索。<details>
<summary>Abstract</summary>
While effective, the backpropagation (BP) algorithm exhibits limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms. i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers. iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency opening multiple avenues for further explorations.
</details>
<details>
<summary>摘要</summary>
While effective, the backpropagation (BP) algorithm has limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms.i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch.ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers.iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency, opening multiple avenues for further explorations.Here's the translation in Traditional Chinese as well, for reference:While effective, the backpropagation (BP) algorithm has limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms.i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch.ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers.iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency, opening multiple avenues for further explorations.
</details></li>
</ul>
<hr>
<h2 id="Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction"><a href="#Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction" class="headerlink" title="Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction"></a>Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03782">http://arxiv.org/abs/2308.03782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Ling</li>
<li>for: 这个研究旨在开发一些可以分析病人的药物评价，并将其满意度精确地分类为正面、中性或负面的自然语言处理（NLP）模型。</li>
<li>methods: 这个研究使用了多种分类模型，包括BERT基础模型、Bio+Clinical BERT和简单的CNN。</li>
<li>results: 结果显示，医疗领域专门的Bio+Clinical BERT模型在表格2中表现出色，与通用领域基础BERT模型相比，macro f1和 recall 分数提高了11%。<details>
<summary>Abstract</summary>
The objective of this study is to develop natural language processing (NLP) models that can analyze patients' drug reviews and accurately classify their satisfaction levels as positive, neutral, or negative. Such models would reduce the workload of healthcare professionals and provide greater insight into patients' quality of life, which is a critical indicator of treatment effectiveness. To achieve this, we implemented and evaluated several classification models, including a BERT base model, Bio+Clinical BERT, and a simpler CNN. Results indicate that the medical domain-specific Bio+Clinical BERT model significantly outperformed the general domain base BERT model, achieving macro f1 and recall score improvement of 11%, as shown in Table 2. Future research could explore how to capitalize on the specific strengths of each model. Bio+Clinical BERT excels in overall performance, particularly with medical jargon, while the simpler CNN demonstrates the ability to identify crucial words and accurately classify sentiment in texts with conflicting sentiments.
</details>
<details>
<summary>摘要</summary>
本研究的目的是开发自然语言处理（NLP）模型，可以分析患者的药物评价并准确地分类为正面、中性或负面的满意度。这些模型会减轻医疗专业人员的工作负担，并为患者的生活质量提供更多的指导，这是治疗效果的重要指标。为达到这一目标，我们实施并评估了多种分类模型，包括BERT基础模型、Bio+клиничеBERT和简单的CNN。结果表明，专业领域域 especific的Bio+клиничеBERT模型在表格2中显著超越了通用领域基础BERT模型，实现了macro f1和回快分数的提高11%。未来的研究可以探讨如何利用每个模型的特点。Bio+клиничеBERT在总性性能方面表现出色，特别是对医疗专业术语的处理，而简单的CNN则能够准确地标识关键词并在文本中分类情感。
</details></li>
</ul>
<hr>
<h2 id="Sea-level-Projections-with-Machine-Learning-using-Altimetry-and-Climate-Model-ensembles"><a href="#Sea-level-Projections-with-Machine-Learning-using-Altimetry-and-Climate-Model-ensembles" class="headerlink" title="Sea level Projections with Machine Learning using Altimetry and Climate Model ensembles"></a>Sea level Projections with Machine Learning using Altimetry and Climate Model ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02460">http://arxiv.org/abs/2308.02460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saumya Sinha, John Fasullo, R. Steven Nerem, Claire Monteleoni</li>
<li>for: 本研究使用卫星测量数据自1993年起，检测全球海平面的升高趋势（3.4毫米&#x2F;年），并调查人类活动对这种升高的影响。</li>
<li>methods: 本研究使用机器学习（ML）技术，通过融合卫星观测数据和气候模型 simulations，预测未来海平面变化的趋势。</li>
<li>results: 研究发现，通过各种气候变化信号的评估，可以更好地预测未来海平面变化的趋势，并且可以通过各种方法提高预测的准确性。<details>
<summary>Abstract</summary>
Satellite altimeter observations retrieved since 1993 show that the global mean sea level is rising at an unprecedented rate (3.4mm/year). With almost three decades of observations, we can now investigate the contributions of anthropogenic climate-change signals such as greenhouse gases, aerosols, and biomass burning in this rising sea level. We use machine learning (ML) to investigate future patterns of sea level change. To understand the extent of contributions from the climate-change signals, and to help in forecasting sea level change in the future, we turn to climate model simulations. This work presents a machine learning framework that exploits both satellite observations and climate model simulations to generate sea level rise projections at a 2-degree resolution spatial grid, 30 years into the future. We train fully connected neural networks (FCNNs) to predict altimeter values through a non-linear fusion of the climate model hindcasts (for 1993-2019). The learned FCNNs are then applied to future climate model projections to predict future sea level patterns. We propose segmenting our spatial dataset into meaningful clusters and show that clustering helps to improve predictions of our ML model.
</details>
<details>
<summary>摘要</summary>
卫星测量数据自1993年起已经提供了全球海平面上升的无前例快速速率（3.4毫米/年）。在近三十年的观测记录下，我们现在可以进行人类活动气候变化的贡献分析，如绿色气体、喷气和生物燃烧等。我们使用机器学习（ML）技术来探索未来海平面变化的趋势。为了了解气候变化信号的贡献和未来海平面变化的预测，我们转向气候模型仿真。本研究提出了一种基于卫星观测和气候模型仿真的机器学习框架，用于预测未来30年的海平面变化趋势。我们使用全连接神经网络（FCNN）来预测测量值，通过非线性混合气候模型预测（1993-2019）来训练FCNN。然后，我们应用FCNN来预测未来气候模型预测中的海平面变化趋势。我们还提出了对空间数据进行有意义的分割，并证明分割可以提高我们的机器学习模型预测的准确性。
</details></li>
</ul>
<hr>
<h2 id="OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models"><a href="#OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models" class="headerlink" title="OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"></a>OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01390">http://arxiv.org/abs/2308.01390</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_flamingo">https://github.com/mlfoundations/open_flamingo</a></li>
<li>paper_authors: Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, Jenia Jitsev, Simon Kornblith, Pang Wei Koh, Gabriel Ilharco, Mitchell Wortsman, Ludwig Schmidt</li>
<li>for: 这篇论文是为了描述OpenFlamingo模型家族，该家族包括从3B到9B参数的束autoregressive视频语言模型，这是一个开源的Flamingo模型复制项目。</li>
<li>methods: 这篇论文使用了OpenFlamingo模型，training数据，超参数以及评估集合来训练这些模型。</li>
<li>results: 在七个视频语言数据集上，OpenFlamingo模型的平均表现为80-89%相对于对应的Flamingo模型表现。<details>
<summary>Abstract</summary>
We introduce OpenFlamingo, a family of autoregressive vision-language models ranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce an open-source replication of DeepMind's Flamingo models. On seven vision-language datasets, OpenFlamingo models average between 80 - 89% of corresponding Flamingo performance. This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at https://github.com/mlfoundations/open_flamingo.
</details>
<details>
<summary>摘要</summary>
我们介绍OpenFlamingo，一家以自适应推论为基础的视觉语言模型，它的参数量从3B至9B。OpenFlamingo是一个持续进行的开源复制项目，旨在实现深度联盟的Flamingo模型的开源版本。在七个视觉语言数据集上，OpenFlamingo模型的平均表现为80-89%相应的Flamingo表现。本技术报告描述了我们的模型、训练数据、几何 Parameters 和评估工具。我们在https://github.com/mlfoundations/open_flamingo 上分享我们的模型和代码。
</details></li>
</ul>
<hr>
<h2 id="Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning"><a href="#Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning" class="headerlink" title="Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning"></a>Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01389">http://arxiv.org/abs/2308.01389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jumman Hossain, Maliha Momtaz</li>
<li>for: 本研究的主要目标是建立一个自动驾驶系统，使其可以跟踪特定人（在我们项目中是士兵）在任何方向移动。</li>
<li>methods: 我们使用优化的单射多框检测（SSD）模型和再增强学习（RL）模型来实现这个目标。</li>
<li>results: 实验结果显示，使用 SSD Lite 模型可以提供更好的性能（比 SSD 和 NCS 更好），而且在执行速度方面也有显著提高（约2-3倍），而无需牺牲准确性。<details>
<summary>Abstract</summary>
Nowadays, autonomous cars are gaining traction due to their numerous potential applications on battlefields and in resolving a variety of other real-world challenges. The main goal of our project is to build an autonomous system using DeepRacer which will follow a specific person (for our project, a soldier) when they will be moving in any direction. Two main components to accomplish this project is an optimized Single-Shot Multibox Detection (SSD) object detection model and a Reinforcement Learning (RL) model. We accomplished the task using SSD Lite instead of SSD and at the end, compared the results among SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental results show that SSD Lite gives better performance among these three techniques and exhibits a considerable boost in inference speed (~2-3 times) without compromising accuracy.
</details>
<details>
<summary>摘要</summary>
现在，自动驾驶车在各种应用场景中得到了广泛的应用，尤其是在战场和解决各种现实世界问题方面。我们项目的主要目标是使用DeepRacer构建一个自动驾驶系统，该系统可以跟踪一个特定人（在我们项目中是一名士兵）在任何方向移动时。我们完成了这个项目，使用优化的Single-Shot Multibox Detection（SSD）物体检测模型和Reinforcement Learning（RL）模型。我们使用SSD Lite而不是SSD，并在结果中进行了比较。实验结果显示，SSD Lite在这三种技术中表现最佳，并且在执行速度方面表现出了明显的提升（大约2-3倍），而无需牺牲准确性。
</details></li>
</ul>
<hr>
<h2 id="DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales"><a href="#DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales" class="headerlink" title="DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales"></a>DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01320">http://arxiv.org/abs/2308.01320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepSpeed">https://github.com/microsoft/DeepSpeed</a></li>
<li>paper_authors: Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly Smith, Lev Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, Yuxiong He</li>
<li>for: This paper aims to provide an accessible, efficient, and cost-effective end-to-end RLHF training pipeline for ChatGPT-like models, particularly when training at the scale of billions of parameters.</li>
<li>methods: The paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. The system offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way.</li>
<li>results: The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是提供一个可accessible、高效、成本效果的RLHF训练管道，特别是在多亿个参数训练时。</li>
<li>methods: 论文引入了DeepSpeed-Chat系统，该系统提供了三个关键功能：对ChatGPT-like模型的易用训练和推理体验、DeepSpeed-RLHF管道，以及一个稳定的DeepSpeed-RLHF系统，该系统结合了多种优化来提高训练和推理的效率和扩展性。</li>
<li>results: 系统可以在记录时间内训练出多亿个参数的模型，并且在成本的一小部分。通过这一发展，DeepSpeed-Chat开创了更广泛的RLHF训练访问权，使得数据科学家们可以更容易地访问高级RLHF训练，从而推动AI领域的创新和发展。<details>
<summary>Abstract</summary>
ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI.
</details>
<details>
<summary>摘要</summary>
chatgpt-like模型已经革命化了人工智能中的多个应用，从概要和编程到翻译，与人类表现相当或甚至超越人类表现。然而，当前的景象缺乏可 accessible，高效，和cost-effective的RLHF（人工智能学习带反馈）训练管道，特别是在 billion parameter scale 的训练中。本文介绍了 DeepSpeed-Chat，一种新的系统，使得RLHF训练变得可 accessible。DeepSpeed-Chat具有三个关键能力：对 ChatGPT-like模型的易用训练和推理经验，基于 InstructGPT 的 DeepSpeed-RLHF 管道，以及一个可靠的 DeepSpeed-RLHF 系统，它将训练和推理过程合并到一起，提供了无 parallel 的效率和可扩展性。该系统可以在 record 时间内训练 billions of parameters 的模型，并且只需一小部分的成本。通过这一发展，DeepSpeed-Chat 为AI领域的进步和发展开辟了新的可能性，尤其是为那些具有限制的数据科学家，他们可以更容易地访问高级RLHF训练，从而推动AI领域的进步。
</details></li>
</ul>
<hr>
<h2 id="Computational-Long-Exposure-Mobile-Photography"><a href="#Computational-Long-Exposure-Mobile-Photography" class="headerlink" title="Computational Long Exposure Mobile Photography"></a>Computational Long Exposure Mobile Photography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01379">http://arxiv.org/abs/2308.01379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Tabellion, Nikhil Karnad, Noa Glaser, Ben Weiss, David E. Jacobs, Yael Pritch</li>
<li>for: 这篇论文旨在提供一种可以在手持式智能手机摄像头应用程序中实现长时间摄影的计算机 burst 摄影系统，以生成吸引人的满屏照片。</li>
<li>methods: 该系统首先检测和分割主题，然后跟踪场景运动多个帧，并对图像进行对齐，以保持所需的锐度和生成美观的运动梳子。系统还会捕捉不充足的短暂拍摄，并选择输入帧中能够生成控制长度的滑块，不管场景或摄像头运动速度。最后，系统预测间帧运动并synthesize运动滑块，以填充间隔 между输入帧。</li>
<li>results: 该系统可以自动生成高分辨率和高动态范围（HDR）照片，并使这种创作风格更加 accessible 于大多数临时摄影师。更多信息和补充材料可以在项目网页上找到：<a target="_blank" rel="noopener" href="https://motion-mode.github.io/">https://motion-mode.github.io/</a><details>
<summary>Abstract</summary>
Long exposure photography produces stunning imagery, representing moving elements in a scene with motion-blur. It is generally employed in two modalities, producing either a foreground or a background blur effect. Foreground blur images are traditionally captured on a tripod-mounted camera and portray blurred moving foreground elements, such as silky water or light trails, over a perfectly sharp background landscape. Background blur images, also called panning photography, are captured while the camera is tracking a moving subject, to produce an image of a sharp subject over a background blurred by relative motion. Both techniques are notoriously challenging and require additional equipment and advanced skills. In this paper, we describe a computational burst photography system that operates in a hand-held smartphone camera app, and achieves these effects fully automatically, at the tap of the shutter button. Our approach first detects and segments the salient subject. We track the scene motion over multiple frames and align the images in order to preserve desired sharpness and to produce aesthetically pleasing motion streaks. We capture an under-exposed burst and select the subset of input frames that will produce blur trails of controlled length, regardless of scene or camera motion velocity. We predict inter-frame motion and synthesize motion-blur to fill the temporal gaps between the input frames. Finally, we composite the blurred image with the sharp regular exposure to protect the sharpness of faces or areas of the scene that are barely moving, and produce a final high resolution and high dynamic range (HDR) photograph. Our system democratizes a capability previously reserved to professionals, and makes this creative style accessible to most casual photographers.   More information and supplementary material can be found on our project webpage: https://motion-mode.github.io/
</details>
<details>
<summary>摘要</summary>
长时间摄影可以生成吸目的图像，表现在Scene中的运动元素的混淆。它通常在两种方式下使用，生成 either 前景或背景混淆效果。前景混淆图像通常在静止摄像机上捕捉，显示混淆的移动前景元素，如柔软的水或光轨，与锐化的背景景象一起。背景混淆图像，也称为摄影满天飞行，通过跟踪移动主题，以生成一个锐化的主题图像，并且背景混淆由相对运动引起。这两种技术都非常具有挑战性，需要额外设备和高级技能。在这篇论文中，我们描述了一个基于智能手机摄像机应用程序的计算摄影系统，可以自动实现这些效果，只需要点击拍照按钮。我们的方法首先检测和分割出主题。我们跟踪场景运动，并将多帧图像相互对齐，以保持所需的锐化和生成美观的运动损块。我们捕捉充足的短暂拍照，并选择输入帧中生成混淆轨迹的子集，无论场景或摄像机运动速度如何。我们预测间帧运动，并使用Synthesize Motion-blur填充时间间隔。最后，我们将混淆图像与锐化图像合并，保护面部或场景中的细微运动部分，并生成一个高分辨率和高动态范围（HDR）照片。我们的系统将这种创作风格升级到普通用户，使得大多数休闲摄影爱好者可以轻松地获得这种创新风格。更多信息和补充材料可以在我们项目网站上找到：<https://motion-mode.github.io/>
</details></li>
</ul>
<hr>
<h2 id="AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping"><a href="#AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping" class="headerlink" title="AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping"></a>AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02664">http://arxiv.org/abs/2308.02664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddha Ganju, Amartya Hatua, Peter Jenniskens, Sahyadri Krishna, Chicheng Ren, Surya Ambardar</li>
<li>for: 该研究旨在自动化数据进行处理和获得洞察，以便提高 meteor 显示的发现率。</li>
<li>methods: 该研究使用了云端 AI 智能管道，以自动化数据进行处理和分析。</li>
<li>results: 该研究已经发现了超过 200 个新的 meteor 显示，并已经验证了多个先前报告的显示。<details>
<summary>Abstract</summary>
The Cameras for Allsky Meteor Surveillance (CAMS) project, funded by NASA starting in 2010, aims to map our meteor showers by triangulating meteor trajectories detected in low-light video cameras from multiple locations across 16 countries in both the northern and southern hemispheres. Its mission is to validate, discover, and predict the upcoming returns of meteor showers. Our research aimed to streamline the data processing by implementing an automated cloud-based AI-enabled pipeline and improve the data visualization to improve the rate of discoveries by involving the public in monitoring the meteor detections. This article describes the process of automating the data ingestion, processing, and insight generation using an interpretable Active Learning and AI pipeline. This work also describes the development of an interactive web portal (the NASA Meteor Shower portal) to facilitate the visualization of meteor radiant maps. To date, CAMS has discovered over 200 new meteor showers and has validated dozens of previously reported showers.
</details>
<details>
<summary>摘要</summary>
美国国家航空航天局（NASA）自2010年起投入了“全天 Meteor 探测”（CAMS）项目，旨在通过多个国家和多个地点的低光照视频摄像头检测 meteor 轨迹，并通过三角测量确定 meteor 的轨迹。项目的目标是验证、发现和预测未来的流星雨。我们的研究旨在减少数据处理的复杂度，通过实施云端基于人工智能的自动化数据管道，并改进数据可视化以提高发现率。这篇文章描述了自动化数据进口、处理和洞察的活动学习和人工智能管道的实现方式。此外，我们还开发了一个交互式网站（NASA 流星雨门户），以便为流星辐射地图的可视化提供便捷的方式。至今，CAMS 已经发现了超过 200 个新的流星雨，并验证了数十个先前报道的雨。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Deep-Learning-for-Tumor-Dynamic-Modeling-and-Overall-Survival-Prediction-using-Neural-ODE"><a href="#Explainable-Deep-Learning-for-Tumor-Dynamic-Modeling-and-Overall-Survival-Prediction-using-Neural-ODE" class="headerlink" title="Explainable Deep Learning for Tumor Dynamic Modeling and Overall Survival Prediction using Neural-ODE"></a>Explainable Deep Learning for Tumor Dynamic Modeling and Overall Survival Prediction using Neural-ODE</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01362">http://arxiv.org/abs/2308.01362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Laurie, James Lu</li>
<li>for: This paper aims to improve the predictivity of tumor dynamic modeling in oncology drug development by proposing a new pharmacology-informed neural network called TDNODE.</li>
<li>methods: The TDNODE model uses an encoder-decoder architecture to express an underlying dynamical law that is generalized homogeneous with respect to time, enabling the generation of kinetic rate metrics that can be used to predict patients’ overall survival with high accuracy.</li>
<li>results: The proposed modeling formalism provides a principled way to integrate multimodal dynamical datasets in oncology disease modeling, and the generated metrics can be used to predict patients’ overall survival with high accuracy.Here’s the simplified Chinese text:</li>
<li>for: 这篇论文目的是提高肿瘤动态模型在肿瘤药物开发中的预测性，提议一种新的药理学知识感知神经网络called TDNODE。</li>
<li>methods: TDNODE模型使用编码器-解码器架构表达一个基于时间的总体法则，使得生成的生物动力学指标可以用于预测患者的全身生存率高精度。</li>
<li>results: 提议的模型形式可以理性地将多模态动态数据集成在肿瘤疾病模型中，并生成的指标可以用于预测患者的全身生存率高精度。<details>
<summary>Abstract</summary>
While tumor dynamic modeling has been widely applied to support the development of oncology drugs, there remains a need to increase predictivity, enable personalized therapy, and improve decision-making. We propose the use of Tumor Dynamic Neural-ODE (TDNODE) as a pharmacology-informed neural network to enable model discovery from longitudinal tumor size data. We show that TDNODE overcomes a key limitation of existing models in its ability to make unbiased predictions from truncated data. The encoder-decoder architecture is designed to express an underlying dynamical law which possesses the fundamental property of generalized homogeneity with respect to time. Thus, the modeling formalism enables the encoder output to be interpreted as kinetic rate metrics, with inverse time as the physical unit. We show that the generated metrics can be used to predict patients' overall survival (OS) with high accuracy. The proposed modeling formalism provides a principled way to integrate multimodal dynamical datasets in oncology disease modeling.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:虾蟹肿瘤动态模型已广泛应用于肿瘤药物开发支持，但还有必要提高预测精度、实现个性化治疗和改善决策。我们提议使用肿瘤动态神经网络（TDNODE）作为药理学知识推导的神经网络，以从长期肿瘤大小数据中发现模型。我们表明，TDNODE可以超越现有模型的一个关键局限性，即从截断数据中做出不受偏见的预测。encoder-decoder架构是设计来表达下述动态法律：在时间上 generalized homogeneity 的基本性质。因此，模型 formalism 允许 encoder 输出被解释为动力学率度量，倒时间为物理单位。我们显示，生成的度量可以高精度地预测患者的总存活率（OS）。我们提出的模型 formalism 为肿瘤疾病模型集成多Modal dynamical dataset提供了原则性的方法。Here's a word-for-word translation of the text into Simplified Chinese:虾蟹肿瘤动态模型已广泛应用于肿瘤药物开发支持，但还有必要提高预测精度、实现个性化治疗和改善决策。我们提议使用肿瘤动态神经网络（TDNODE）作为药理学知识推导的神经网络，以从长期肿瘤大小数据中发现模型。我们表明，TDNODE可以超越现有模型的一个关键局限性，即从截断数据中做出不受偏见的预测。encoder-decoder架构是设计来表达下述动态法律：在时间上 generalized homogeneity 的基本性质。因此，模型 formalism 允许 encoder 输出被解释为动力学率度量，倒时间为物理单位。我们显示，生成的度量可以高精度地预测患者的总存活率（OS）。我们提出的模型 formalism 为肿瘤疾病模型集成多Modal dynamical dataset提供了原则性的方法。
</details></li>
</ul>
<hr>
<h2 id="Compressed-and-distributed-least-squares-regression-convergence-rates-with-applications-to-Federated-Learning"><a href="#Compressed-and-distributed-least-squares-regression-convergence-rates-with-applications-to-Federated-Learning" class="headerlink" title="Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning"></a>Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01358">http://arxiv.org/abs/2308.01358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Constantin Philippenko, Aymeric Dieuleveut</li>
<li>for: 这个论文研究了对机器学习的分布式和联合学习中使用整数压缩算法时的影响。</li>
<li>methods: 这篇论文使用了多种不同的压缩算法，并进行了对这些算法的分析。</li>
<li>results: 论文发现，即使使用不规则的随机场， covariance $\mathfrak{C}<em>{\mathrm{ania}}$ 的加法噪声仍然Scales with $\mathrm{Tr}(\mathfrak{C}</em>{\mathrm{ania}} H^{-1})&#x2F;K$，这generalizes the rate for the vanilla LSR case。此外，论文还分析了压缩策略的影响和联合学习框架中的应用。<details>
<summary>Abstract</summary>
In this paper, we investigate the impact of compression on stochastic gradient algorithms for machine learning, a technique widely used in distributed and federated learning. We underline differences in terms of convergence rates between several unbiased compression operators, that all satisfy the same condition on their variance, thus going beyond the classical worst-case analysis. To do so, we focus on the case of least-squares regression (LSR) and analyze a general stochastic approximation algorithm for minimizing quadratic functions relying on a random field. We consider weak assumptions on the random field, tailored to the analysis (specifically, expected H\"older regularity), and on the noise covariance, enabling the analysis of various randomizing mechanisms, including compression. We then extend our results to the case of federated learning.   More formally, we highlight the impact on the convergence of the covariance $\mathfrak{C}_{\mathrm{ania}}$ of the additive noise induced by the algorithm. We demonstrate despite the non-regularity of the stochastic field, that the limit variance term scales with $\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania}} H^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the number of iterations) generalizing the rate for the vanilla LSR case where it is $\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$ (Bach and Moulines, 2013). Then, we analyze the dependency of $\mathfrak{C}_{\mathrm{ania}}$ on the compression strategy and ultimately its impact on convergence, first in the centralized case, then in two heterogeneous FL frameworks.
</details>
<details>
<summary>摘要</summary>
本文 investigate 分布式学习和联合学习中的压缩对Stochastic Gradient Algorithm的影响。我们比较不同压缩算法的收敛率，其中所有算法都满足同样的假设条件，超出了经典最坏情况分析。为此，我们在Least Squares Regression (LSR) 中分析一种基于随机场的普通采样算法，并对随机场假设和噪声矩阵做出弱assumption。然后，我们扩展我们的结果到联合学习中。更 formally，我们关注 covariance $\mathfrak{C}_{\text{ania}}$ 的添加噪声对算法的收敛带来的影响。我们发现，即使随机场不规则，则限制变量 $\frac{\text{Tr}(\mathfrak{C}_{\text{ania}} H^{-1})}{K}$  scales，其中 $H$ 是优化问题的梯度矩阵，$K$ 是迭代次数。这与vanilla LSR 情况相同，其中 $\sigma^2 \text{Tr}(H H^{-1}) / K = \sigma^2 d / K$ (Bach 和 Moulines, 2013)。然后，我们分析压缩策略对 covariance $\mathfrak{C}_{\text{ania}}$ 的影响，并最终探讨其对收敛的影响，首先在中央化情况下，然后在两种不同的多元联合学习框架中。
</details></li>
</ul>
<hr>
<h2 id="More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes"><a href="#More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes" class="headerlink" title="More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes"></a>More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01313">http://arxiv.org/abs/2308.01313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/umd-huang-lab/perceptionclip">https://github.com/umd-huang-lab/perceptionclip</a></li>
<li>paper_authors: Bang An, Sicheng Zhu, Michael-Andrei Panaitescu-Liess, Chaithanya Kumar Mummadi, Furong Huang</li>
<li>for: 提高零shot图像分类的性能和可解释性</li>
<li>methods: 基于人类视觉过程的启发，提供图像上的 контекст特征，然后通过这些特征进行对象分类</li>
<li>results: 对比传统零shot分类方法，PerceptionCLIP可以更好地 generalized、group robustness和可解释性，例如在Waterbirds数据集上，PerceptionCLIP与ViT-L&#x2F;14组合可以提高最差组分精度 by 16.5%，并在CelebA数据集上提高组合精度 by 3.5%<details>
<summary>Abstract</summary>
CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</details>
<details>
<summary>摘要</summary>
CLIP，作为基础视语言模型，在零码图像分类中广泛应用，因其能够理解多种视觉概念和自然语言描述。然而，如何充分利用CLIP的人类样式理解能力以实现更好的零码分类仍是一个开放问题。这篇论文着眼于人类视觉过程：现代神经科学视野表明，在分类一个物体时，人们首先推理出该物体的类型独立特征（如背景和方向），然后根据这些信息进行决策。 inspirited by this，我们发现，为CLIP提供 contextual attributes 可以提高零码分类并减少偶极特征的依赖。我们还发现，CLIP本身可以有效地从图像中推理出这些特征。基于这些观察，我们提出了一种无需训练的、两步零码分类方法，名为PerceptionCLIP。给定一个图像，它首先推理出图像中的上下文特征（如背景），然后根据这些特征进行物体分类。我们的实验表明，PerceptionCLIP 可以 achieve better generalization, group robustness, and better interpretability。例如，PerceptionCLIP 与 ViT-L/14 在 Waterbirds 数据集上提高了最差群 accuracy 16.5%，并在 CelebA 数据集上提高了3.5%。
</details></li>
</ul>
<hr>
<h2 id="Lode-Encoder-AI-constrained-co-creativity"><a href="#Lode-Encoder-AI-constrained-co-creativity" class="headerlink" title="Lode Encoder: AI-constrained co-creativity"></a>Lode Encoder: AI-constrained co-creativity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01312">http://arxiv.org/abs/2308.01312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Ahmed Khalifa, Julian Togelius</li>
<li>for: 这篇论文是关于开发一种基于混合 iniciative 的平台游戏困难设计系统，用于 классиic 平台游戏困难游戏《寻找宝藏》。</li>
<li>methods: 该系统是基于多个自动编码器，每个自动编码器都是根据不同的困难设计训练而成。当用户提供设计时，每个自动编码器都会生成一个更加类似于它所训练的困难设计的版本。</li>
<li>results: 据报道，该系统可以帮助设计师探索新的设计可能性，而不是仅仅是通过传统的编辑工具。用户测试表明，该系统可以帮助设计师快速创建高质量的困难设计。<details>
<summary>Abstract</summary>
We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.
</details>
<details>
<summary>摘要</summary>
我们介绍Lode Encoder，一个基于混合 iniciativa 的游戏创作系统，专门为经典平台游戏Lode Runner创建各种各样的关卡。该系统建立在多个自动编码器之上，这些自动编码器在不同的Lode Runner关卡集上进行训练。当用户输入设计时，每个自动编码器都会生成一个更像原始关卡的版本。Lode Encoder 界面允许用户通过"油画"的方式从自动编码器提供的建议中创建和编辑关卡。重要的是，以便鼓励设计师探索新的可能性，该系统不包括传统的编辑工具。我们介绍了系统的设计和训练过程，以及用户测试。
</details></li>
</ul>
<hr>
<h2 id="Masked-and-Swapped-Sequence-Modeling-for-Next-Novel-Basket-Recommendation-in-Grocery-Shopping"><a href="#Masked-and-Swapped-Sequence-Modeling-for-Next-Novel-Basket-Recommendation-in-Grocery-Shopping" class="headerlink" title="Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping"></a>Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01308">http://arxiv.org/abs/2308.01308</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liming-7/mask-swap-nnbr">https://github.com/liming-7/mask-swap-nnbr</a></li>
<li>paper_authors: Ming Li, Mozhdeh Ariannezhad, Andrew Yates, Maarten de Rijke</li>
<li>for: 本研究的目的是提出一种新的下一个购物篮子推荐任务（NNBR），即推荐用户未前吃过的食品。</li>
<li>methods: 本研究提出了一种简单的双向变换器购物篮子推荐模型（BTBR），该模型直接模型食品之间的相关性，并使用了不同的屏蔽策略和训练目标来进行训练。</li>
<li>results: 实验结果表明，BTBR可以有效地解决NNBR任务，并且可以采用不同的屏蔽策略和训练目标来进一步提高性能。<details>
<summary>Abstract</summary>
Next basket recommendation (NBR) is the task of predicting the next set of items based on a sequence of already purchased baskets. It is a recommendation task that has been widely studied, especially in the context of grocery shopping. In next basket recommendation (NBR), it is useful to distinguish between repeat items, i.e., items that a user has consumed before, and explore items, i.e., items that a user has not consumed before. Most NBR work either ignores this distinction or focuses on repeat items. We formulate the next novel basket recommendation (NNBR) task, i.e., the task of recommending a basket that only consists of novel items, which is valuable for both real-world application and NBR evaluation. We evaluate how existing NBR methods perform on the NNBR task and find that, so far, limited progress has been made w.r.t. the NNBR task. To address the NNBR task, we propose a simple bi-directional transformer basket recommendation model (BTBR), which is focused on directly modeling item-to-item correlations within and across baskets instead of learning complex basket representations. To properly train BTBR, we propose and investigate several masking strategies and training objectives: (i) item-level random masking, (ii) item-level select masking, (iii) basket-level all masking, (iv) basket-level explore masking, and (v) joint masking. In addition, an item-basket swapping strategy is proposed to enrich the item interactions within the same baskets. We conduct extensive experiments on three open datasets with various characteristics. The results demonstrate the effectiveness of BTBR and our masking and swapping strategies for the NNBR task. BTBR with a properly selected masking and swapping strategy can substantially improve NNBR performance.
</details>
<details>
<summary>摘要</summary>
下一个篮筐推荐（NBR）任务是预测下一个篮筐中的项目，基于已经购买过的篮筐序列。这是一项推荐任务，尤其在超市购物中广泛研究。在NBR任务中，分 distinguish between repeat items，即用户已经消费过的项目，和 explore items，即用户没有消费过的项目。大多数NBR工作忽略这种分类或者专注于 repeat items。我们提出了下一个新篮筐推荐（NNBR）任务，即推荐一个仅由新项目组成的篮筐，这对于实际应用和NBR评估都具有价值。我们评估了现有NBR方法在NNBR任务中的性能，并发现，迄今为止，对NNBR任务的进展还很有限。为解决NNBR任务，我们提议了一个简单的双向转换器篮筐推荐模型（BTBR），该模型专门模型item-to-item相关性内 и外 basket中。为正确训练BTBR，我们提议并研究了多种masquerade策略和训练目标：（i）item-level随机masquerade，（ii）item-level选择masquerade，（iii）basket-level所有masquerade，（iv）basket-level探索masquerade，（v）联合masquerade。此外，我们还提议了一种item-篮筐交换策略，以便在同一个篮筐中增强item之间的交互。我们对三个开源数据集进行了广泛的实验，结果表明，BTBR和我们的masquerade策略和item-篮筐交换策略可以很好地提高NNBR性能。
</details></li>
</ul>
<hr>
<h2 id="Excitatory-Inhibitory-Balance-Emerges-as-a-Key-Factor-for-RBN-Performance-Overriding-Attractor-Dynamics"><a href="#Excitatory-Inhibitory-Balance-Emerges-as-a-Key-Factor-for-RBN-Performance-Overriding-Attractor-Dynamics" class="headerlink" title="Excitatory&#x2F;Inhibitory Balance Emerges as a Key Factor for RBN Performance, Overriding Attractor Dynamics"></a>Excitatory&#x2F;Inhibitory Balance Emerges as a Key Factor for RBN Performance, Overriding Attractor Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10831">http://arxiv.org/abs/2308.10831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emmanuel Calvet, Jean Rouat, Bertrand Reulet</li>
<li>for: 这个论文主要是为了研究储存和预测两个复杂任务中的表现。</li>
<li>methods: 作者使用了随机布尔网络（RBNs）来研究连接性、动力学和性能之间的关系。</li>
<li>results: 研究发现，在特定的分布参数下，随机布尔网络可以导致多样化的动力学行为，并且大多数储存器具有一个主要吸引器。此外，作者发现，储存和预测任务中的表现与储存器的内生动力学行为有很少关系。<details>
<summary>Abstract</summary>
Reservoir computing provides a time and cost-efficient alternative to traditional learning methods.Critical regimes, known as the "edge of chaos," have been found to optimize computational performance in binary neural networks. However, little attention has been devoted to studying reservoir-to-reservoir variability when investigating the link between connectivity, dynamics, and performance. As physical reservoir computers become more prevalent, developing a systematic approach to network design is crucial. In this article, we examine Random Boolean Networks (RBNs) and demonstrate that specific distribution parameters can lead to diverse dynamics near critical points. We identify distinct dynamical attractors and quantify their statistics, revealing that most reservoirs possess a dominant attractor. We then evaluate performance in two challenging tasks, memorization and prediction, and find that a positive excitatory balance produces a critical point with higher memory performance. In comparison, a negative inhibitory balance delivers another critical point with better prediction performance. Interestingly, we show that the intrinsic attractor dynamics have little influence on performance in either case.
</details>
<details>
<summary>摘要</summary>
储备计算提供了传统学习方法的时间和成本效益的代替方案。critical regime, known as the "edge of chaos", have been found to optimize computational performance in binary neural networks. However, little attention has been devoted to studying reservoir-to-reservoir variability when investigating the link between connectivity, dynamics, and performance. As physical reservoir computers become more prevalent, developing a systematic approach to network design is crucial. In this article, we examine Random Boolean Networks (RBNs) and demonstrate that specific distribution parameters can lead to diverse dynamics near critical points. We identify distinct dynamical attractors and quantify their statistics, revealing that most reservoirs possess a dominant attractor. We then evaluate performance in two challenging tasks, memorization and prediction, and find that a positive excitatory balance produces a critical point with higher memory performance. In comparison, a negative inhibitory balance delivers another critical point with better prediction performance. Interestingly, we show that the intrinsic attractor dynamics have little influence on performance in either case.Here's the translation in Traditional Chinese:储备计算提供了传统学习方法的时间和成本效益的代替方案。critical regime, known as the "edge of chaos", have been found to optimize computational performance in binary neural networks. However, little attention has been devoted to studying reservoir-to-reservoir variability when investigating the link between connectivity, dynamics, and performance. As physical reservoir computers become more prevalent, developing a systematic approach to network design is crucial. In this article, we examine Random Boolean Networks (RBNs) and demonstrate that specific distribution parameters can lead to diverse dynamics near critical points. We identify distinct dynamical attractors and quantify their statistics, revealing that most reservoirs possess a dominant attractor. We then evaluate performance in two challenging tasks, memorization and prediction, and find that a positive excitatory balance produces a critical point with higher memory performance. In comparison, a negative inhibitory balance delivers another critical point with better prediction performance. Interestingly, we show that the intrinsic attractor dynamics have little influence on performance in either case.
</details></li>
</ul>
<hr>
<h2 id="EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding"><a href="#EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding" class="headerlink" title="EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding"></a>EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01329">http://arxiv.org/abs/2308.01329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Zheng, Junpeng Wang, Chin-Chia Michael Yeh, Yujie Fan, Huiyuan Chen, Liang Wang, Wei Zhang</li>
<li>for: 这篇论文是为了探讨嵌入学习算法中feature的编码方式而写的。</li>
<li>methods: 该论文提出了一种嵌入探索算法，名为EmbeddingTree，可以结构化解释嵌入空间中feature的编码方式。</li>
<li>results: 通过使用EmbeddingTree和相关视觉化工具，可以帮助用户更好地了解高维嵌入的特征，进行嵌入训练中的特征杂谱除法和新数据集的嵌入生成。<details>
<summary>Abstract</summary>
Embedding learning transforms discrete data entities into continuous numerical representations, encoding features/properties of the entities. Despite the outstanding performance reported from different embedding learning algorithms, few efforts were devoted to structurally interpreting how features are encoded in the learned embedding space. This work proposes EmbeddingTree, a hierarchical embedding exploration algorithm that relates the semantics of entity features with the less-interpretable embedding vectors. An interactive visualization tool is also developed based on EmbeddingTree to explore high-dimensional embeddings. The tool helps users discover nuance features of data entities, perform feature denoising/injecting in embedding training, and generate embeddings for unseen entities. We demonstrate the efficacy of EmbeddingTree and our visualization tool through embeddings generated for industry-scale merchant data and the public 30Music listening/playlists dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNEmbedding learning 将粒度数据实体转换为连续数字表示，卷积特征/属性实体。尽管不同的嵌入学习算法报告了出色的性能，但有很少努力投入到嵌入空间中特征的结构性解释。这项工作提出了嵌入树（EmbeddingTree），一种嵌入探索算法，将实体特征 semantics 与卷积向量相关联。我们还开发了基于嵌入树的互动视觉化工具，帮助用户探索高维卷积中的细节特征，进行嵌入训练中的特征杂谔/插入、生成未看到的实体嵌入。我们通过使用industry-scale merchant数据和公共30Music listening/playlists数据集来证明嵌入树和我们的视觉化工具的有效性。
</details></li>
</ul>
<hr>
<h2 id="Investigation-on-Machine-Learning-Based-Approaches-for-Estimating-the-Critical-Temperature-of-Superconductors"><a href="#Investigation-on-Machine-Learning-Based-Approaches-for-Estimating-the-Critical-Temperature-of-Superconductors" class="headerlink" title="Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors"></a>Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01932">http://arxiv.org/abs/2308.01932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatin Abrar Shams, Rashed Hasan Ratul, Ahnaf Islam Naf, Syed Shaek Hossain Samir, Mirza Muntasir Nishat, Fahim Faisal, Md. Ashraful Hoque</li>
<li>for: 预测超导材料的 kritical 温度</li>
<li>methods: 使用堆叠机器学习方法对超导材料的复杂特征进行训练，以准确预测 kritical 温度</li>
<li>results: 与其他前一次可 accessible 研究相比，该模型显示了良好的性能，RMSE 为 9.68，R2 值为 0.922，这些发现可能为堆叠ensemble方法与超参数优化（HPO）提供新的视角。<details>
<summary>Abstract</summary>
Superconductors have been among the most fascinating substances, as the fundamental concept of superconductivity as well as the correlation of critical temperature and superconductive materials have been the focus of extensive investigation since their discovery. However, superconductors at normal temperatures have yet to be identified. Additionally, there are still many unknown factors and gaps of understanding regarding this unique phenomenon, particularly the connection between superconductivity and the fundamental criteria to estimate the critical temperature. To bridge the gap, numerous machine learning techniques have been established to estimate critical temperatures as it is extremely challenging to determine. Furthermore, the need for a sophisticated and feasible method for determining the temperature range that goes beyond the scope of the standard empirical formula appears to be strongly emphasized by various machine-learning approaches. This paper uses a stacking machine learning approach to train itself on the complex characteristics of superconductive materials in order to accurately predict critical temperatures. In comparison to other previous accessible research investigations, this model demonstrated a promising performance with an RMSE of 9.68 and an R2 score of 0.922. The findings presented here could be a viable technique to shed new insight on the efficient implementation of the stacking ensemble method with hyperparameter optimization (HPO).
</details>
<details>
<summary>摘要</summary>
超导材料已经是最吸引人的物质之一，因为超导性的基本概念以及相关的极点温度和超导材料的关系已经在发现之后得到了广泛的研究。然而，在常温下发现超导材料仍然没有被发现。此外，关于这一独特现象的多种未知因素和理解的缺陷仍然存在，特别是超导性和基本的评估极点温度的连接。为了填补这些缺陷，许多机器学习技术已经被建立来估算极点温度。此外，需要一种可靠和实用的方法来确定极点温度范围，这超出了标准的Empirical formula的范围。本文使用堆叠机器学习方法来训练自己，以准确预测超导材料的极点温度。与之前可 accessible 的研究相比，这个模型表现了非常出色的性能，RMSE 为 9.68 和 R2 分数为 0.922。本文所提出的结论可能是一种可靠的技术来释明堆叠ensemble method 的可行性和hyperparameter optimization（HPO）的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems"><a href="#BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems" class="headerlink" title="BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems"></a>BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01274">http://arxiv.org/abs/2308.01274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aralab-unr/brnes">https://github.com/aralab-unr/brnes</a></li>
<li>paper_authors: Md Tamjid Hossain, Hung Manh La, Shahriar Badsha, Anton Netchaev</li>
<li>for: 加速多智能体学习（MARL）的辅导者-被辅导者框架</li>
<li>methods: 使用启发式邻居区选择和权重经验聚合技术来降低滥览攻击的影响，并保护智能体的私有信息免受敌意推理攻击</li>
<li>results: 在拥有攻击者的情况下，提出了一个新的MARL框架（BRNES），可以快速地达到目标，并且在拥有隐私保护的情况下，对智能体的私有信息进行保护。 experiments show that our framework outperforms the state-of-the-art in terms of steps to goal, obtained reward, and time to goal metrics, and is 8.32x faster than non-private frameworks and 1.41x faster than private frameworks in an adversarial setting.<details>
<summary>Abstract</summary>
Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference. Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance. Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage. To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process. Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics. Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.
</details>
<details>
<summary>摘要</summary>
although experience sharing (ES) can accelerate multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have relied on trusted environments and ignored the possibility of adversarial manipulation and inference. however, in a real-world setting, some Byzantine attackers may provide false advice to the advisee and catastrophically degrade the overall learning performance. additionally, an inference attacker may conduct several queries to infer the advisors' private information, making the entire ES process questionable in terms of privacy leakage. to address these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage local differential privacy (LDP)-induced noise during the ES process. our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics. particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.
</details></li>
</ul>
<hr>
<h2 id="A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC"><a href="#A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC" class="headerlink" title="A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC"></a>A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01271">http://arxiv.org/abs/2308.01271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoumeh Javanbakhat, Christoph Lippert</li>
<li>for: 这个论文是为了提出一种实用的 bayesian自适应学习方法，使用循环随机梯度哈密顿 Monte Carlo（cSGHMC）。</li>
<li>methods: 这种方法使用 prior 来定义自适应学习模型的参数，并使用 cSGHMC 来近似高维和多模态的 posterior 分布。</li>
<li>results: 通过寻找高维和多模态的 posterior 分布， bayesian 自适应学习可以生成可读性和多样性的表示，并在多个下游分类任务上得到显著的性能提升、评估和对外部数据集的检测。<details>
<summary>Abstract</summary>
In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种实用的 bayesian自适应学习方法，即循环随机梯度汉堡 Monte Carlo（cSGHMC）。在这个框架中，我们将自适应学习模型的参数置于先验分布中，并使用cSGHMC来近似高维多模态的后验分布。通过探索表征空间的表示，bayesian自适应学习可以生成可读取和多样的表示。对这些表示进行聚合，可以得到大幅提高的性能、评估和异常检测性能。我们在多个分类任务上进行了多个数据集的实验，并证明了提posed方法的效果。此外，我们还用SVHN和CIFAR-10数据集来证明方法的异常检测能力。
</details></li>
</ul>
<hr>
<h2 id="Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites"><a href="#Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites" class="headerlink" title="Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites"></a>Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01246">http://arxiv.org/abs/2308.01246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/tirtha-public">https://github.com/smlab-niser/tirtha-public</a></li>
<li>paper_authors: Jyotirmaya Shivottam, Subhankar Mishra</li>
<li>for: 这篇论文的目的是为了推广和实现文化遗产（CH）区域的数位保存，并提供一个可靠、可读性高的平台 для将这些遗产转换为三维模型。</li>
<li>methods: 这篇论文使用了最新的构造从动（SfM）和多视野视力（MVS）技术，并提供了一个可调、可扩展的架构，以应对未来摄影学技术的进步。</li>
<li>results: 这篇论文的结果是一个名为Tirtha的网络平台，可以将拍摄到的CH区域转换为三维模型，并将这些模型提供给研究人员和公众进行检视、互动和下载。<details>
<summary>Abstract</summary>
Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.
</details>
<details>
<summary>摘要</summary>
digitization of cultural heritage (遗产) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible, and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.LG_2023_08_03/" data-id="clm0t8e0b006cv7882g8k9jkd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/04/eess.IV_2023_08_04/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-04 17:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/03/cs.SD_2023_08_03/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-03 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
