
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-08-23 17:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Comparing Autoencoder to Geometrical Features for Vascular Bifurcations Identification paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12314 repo_url: None paper_authors: Ibtissam Essadik, Anass Nouri, Raja Toua">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-08-23 17:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/23/eess.IV_2023_08_23/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Comparing Autoencoder to Geometrical Features for Vascular Bifurcations Identification paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12314 repo_url: None paper_authors: Ibtissam Essadik, Anass Nouri, Raja Toua">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-22T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-26T20:36:51.903Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_08_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/23/eess.IV_2023_08_23/" class="article-date">
  <time datetime="2023-08-22T16:00:00.000Z" itemprop="datePublished">2023-08-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-08-23 17:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Comparing-Autoencoder-to-Geometrical-Features-for-Vascular-Bifurcations-Identification"><a href="#Comparing-Autoencoder-to-Geometrical-Features-for-Vascular-Bifurcations-Identification" class="headerlink" title="Comparing Autoencoder to Geometrical Features for Vascular Bifurcations Identification"></a>Comparing Autoencoder to Geometrical Features for Vascular Bifurcations Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12314">http://arxiv.org/abs/2308.12314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibtissam Essadik, Anass Nouri, Raja Touahni, Florent Autrusseau</li>
<li>for: 预测脑血管树中分支点的精确位置，以便更好地理解脑内的各种疾病。</li>
<li>methods: 使用自适应神经网络和几何特征来分类脑血管树中的分支点。</li>
<li>results: 通过使用各种评价指标，如准确率、F1分数和混淆矩阵，证明了自适应神经网络和几何特征分类方法的效果和性能。<details>
<summary>Abstract</summary>
The cerebrovascular tree is a complex anatomical structure that plays a crucial role in the brain irrigation. A precise identification of the bifurcations in the vascular network is essential for understanding various cerebral pathologies. Traditional methods often require manual intervention and are sensitive to variations in data quality. In recent years, deep learning techniques, and particularly autoencoders, have shown promising performances for feature extraction and pattern recognition in a variety of domains. In this paper, we propose two novel approaches for vascular bifurcation identification based respectiveley on Autoencoder and geometrical features. The performance and effectiveness of each method in terms of classification of vascular bifurcations using medical imaging data is presented. The evaluation was performed on a sample database composed of 91 TOF-MRA, using various evaluation measures, including accuracy, F1 score and confusion matrix.
</details>
<details>
<summary>摘要</summary>
脑血管树是一个复杂的生物学结构，扮演着脑血液循环的重要角色。正确地识别血管网络中的分叉点非常重要，以便更好地理解脑内多种疾病。传统方法经常需要手动干预，而且敏感于数据质量的变化。在最近几年，深度学习技术和特别是自适应神经网络在各种领域中表现出了有前途的特点。本文提出了基于自适应神经网络和几何特征的两种新方法，用于识别血管分叉点。每种方法在使用医疗影像数据进行分类识别血管分叉点的性能和效果被评估，并通过精度、F1分数和混淆矩阵进行评估。
</details></li>
</ul>
<hr>
<h2 id="Studying-the-Impact-of-Augmentations-on-Medical-Confidence-Calibration"><a href="#Studying-the-Impact-of-Augmentations-on-Medical-Confidence-Calibration" class="headerlink" title="Studying the Impact of Augmentations on Medical Confidence Calibration"></a>Studying the Impact of Augmentations on Medical Confidence Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11902">http://arxiv.org/abs/2308.11902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrit Rao, Joon-Young Lee, Oliver Aalami</li>
<li>for: 本研究旨在评估Modern augmentation techniques的影响对Convolutional Neural Networks（CNN）的泛化和表现。</li>
<li>methods: 本研究使用了CutMix、MixUp和CutOut三种现代扩展技术，对CNN的泛化和表现进行评估。</li>
<li>results: CutMix最大化了泛化的改善，而CutOut通常会降低泛化水平。<details>
<summary>Abstract</summary>
The clinical explainability of convolutional neural networks (CNN) heavily relies on the joint interpretation of a model's predicted diagnostic label and associated confidence. A highly certain or uncertain model can significantly impact clinical decision-making. Thus, ensuring that confidence estimates reflect the true correctness likelihood for a prediction is essential. CNNs are often poorly calibrated and prone to overconfidence leading to improper measures of uncertainty. This creates the need for confidence calibration. However, accuracy and performance-based evaluations of CNNs are commonly used as the sole benchmark for medical tasks. Taking into consideration the risks associated with miscalibration is of high importance. In recent years, modern augmentation techniques, which cut, mix, and combine images, have been introduced. Such augmentations have benefited CNNs through regularization, robustness to adversarial samples, and calibration. Standard augmentations based on image scaling, rotating, and zooming, are widely leveraged in the medical domain to combat the scarcity of data. In this paper, we evaluate the effects of three modern augmentation techniques, CutMix, MixUp, and CutOut on the calibration and performance of CNNs for medical tasks. CutMix improved calibration the most while CutOut often lowered the level of calibration.
</details>
<details>
<summary>摘要</summary>
医学应用中的卷积神经网络（CNN）的临床解释性取决于模型预测的诊断标签和相关的信任度的共同解释。一个高度确定或不确定的模型可能会对临床决策产生重要影响。因此，确保模型的信任度反映实际正确性的可能性是非常重要的。然而，卷积神经网络经常具有质量不佳和过度自信，导致不正确的信任度评估。这创造了信任整理的需求。然而，在医学任务上，精度和性能基准通常只使用卷积神经网络的性能来评估。考虑到误差的风险是非常高的。在过去几年，modern augmentation技术，如剪切混合、混合和剪切，被引入。这些增强技术可以对卷积神经网络进行REGULARIZATION，使其更加稳定和对抗攻击样本。在医学领域，通过尺寸、旋转和缩放等标准增强，已经广泛采用了这些技术来解决数据稀缺的问题。在这篇论文中，我们评估了三种现代增强技术，即CutMix、MixUp和CutOut，对卷积神经网络的准确性和calibration的影响。CutMix最大化了准确性，而CutOut经常降低了准确性。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Residual-SwinV2-Transformer-for-Learned-Image-Compression"><a href="#Enhanced-Residual-SwinV2-Transformer-for-Learned-Image-Compression" class="headerlink" title="Enhanced Residual SwinV2 Transformer for Learned Image Compression"></a>Enhanced Residual SwinV2 Transformer for Learned Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11864">http://arxiv.org/abs/2308.11864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongqiang Wang, Feng Liang, Haisheng Fu, Jie Liang, Haipeng Qin, Junzhe Liang</li>
<li>for: 这paper aimed to propose an effective and efficient learned image compression framework.</li>
<li>methods: 方法使用了一种增强的 residual Swinv2 transformer，以及一个特性增强模块，以增强图像的非线性表示。</li>
<li>results: 实验结果显示，提议的方法可以与一些最近的学习型图像压缩方法相当，并且在Kodak和Tecnick数据集上超过一些传统编码器，包括VVC。特别是，我们的方法可以降低模型复杂度，相比于最近的方法降低56%。<details>
<summary>Abstract</summary>
Recently, the deep learning technology has been successfully applied in the field of image compression, leading to superior rate-distortion performance. However, a challenge of many learning-based approaches is that they often achieve better performance via sacrificing complexity, which making practical deployment difficult. To alleviate this issue, in this paper, we propose an effective and efficient learned image compression framework based on an enhanced residual Swinv2 transformer. To enhance the nonlinear representation of images in our framework, we use a feature enhancement module that consists of three consecutive convolutional layers. In the subsequent coding and hyper coding steps, we utilize a SwinV2 transformer-based attention mechanism to process the input image. The SwinV2 model can help to reduce model complexity while maintaining high performance. Experimental results show that the proposed method achieves comparable performance compared to some recent learned image compression methods on Kodak and Tecnick datasets, and outperforms some traditional codecs including VVC. In particular, our method achieves comparable results while reducing model complexity by 56% compared to these recent methods.
</details>
<details>
<summary>摘要</summary>
现在，深度学习技术在图像压缩领域得到了成功应用，导致了优于质量-缺失率性能。然而，许多学习基于的方法有时会通过牺牲复杂度来实现更好的性能，这使得实际部署变得困难。为了解决这个问题，在这篇论文中，我们提出了一个高效、高效的学习图像压缩框架，基于提升的SwinV2变换器。为了增强图像的非线性表示，我们使用了三个连续的卷积层组成的特征提升模块。在后续的编码和超编码步骤中，我们利用SwinV2变换器基于的注意力机制来处理输入图像。SwinV2模型可以减少模型复杂度，同时保持高性能。实验结果表明，我们的方法与一些最新的学习图像压缩方法在Kodak和Tecnick数据集上达到了相似的性能，并超过了一些传统编码器，包括VVC。尤其是，我们的方法在减少模型复杂度56%的情况下，与这些最新的方法达到了相似的结果。
</details></li>
</ul>
<hr>
<h2 id="Robust-RF-Data-Normalization-for-Deep-Learning"><a href="#Robust-RF-Data-Normalization-for-Deep-Learning" class="headerlink" title="Robust RF Data Normalization for Deep Learning"></a>Robust RF Data Normalization for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11833">http://arxiv.org/abs/2308.11833</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mostafa Sharifzadeh, Habib Benali, Hassan Rivaz</li>
<li>for: 用于训练深度神经网络，以利用ultrasound图像处理</li>
<li>methods: 使用个体标准化每个图像，以更有效地利用RF数据</li>
<li>results: 提高深度神经网络的性能，并且可以更好地普适化训练过程<details>
<summary>Abstract</summary>
Radio frequency (RF) data contain richer information compared to other data types, such as envelope or B-mode, and employing RF data for training deep neural networks has attracted growing interest in ultrasound image processing. However, RF data is highly fluctuating and additionally has a high dynamic range. Most previous studies in the literature have relied on conventional data normalization, which has been adopted within the computer vision community. We demonstrate the inadequacy of those techniques for normalizing RF data and propose that individual standardization of each image substantially enhances the performance of deep neural networks by utilizing the data more efficiently. We compare conventional and proposed normalizations in a phase aberration correction task and illustrate how the former enhances the generality of trained models.
</details>
<details>
<summary>摘要</summary>
Radio frequency (RF) 数据含有更多信息，比如封包或B模式数据，使用RF数据来训练深度神经网络已经吸引了各种各样的关注。然而，RF数据具有高度的波动和大Dynamic范围。大多数先前的学术研究中采用了传统的数据normalization技术。我们证明了这些技术不适合normalizing RF数据，而提议个性化标准化每个图像，可以更好地利用数据，提高深度神经网络的性能。我们在phas Aberration correction任务中比较了传统和我们提议的normalization，并示出了前者可以提高训练的模型的通用性。
</details></li>
</ul>
<hr>
<h2 id="Frequency-Space-Prediction-Filtering-for-Phase-Aberration-Correction-in-Plane-Wave-Ultrasound"><a href="#Frequency-Space-Prediction-Filtering-for-Phase-Aberration-Correction-in-Plane-Wave-Ultrasound" class="headerlink" title="Frequency-Space Prediction Filtering for Phase Aberration Correction in Plane-Wave Ultrasound"></a>Frequency-Space Prediction Filtering for Phase Aberration Correction in Plane-Wave Ultrasound</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11830">http://arxiv.org/abs/2308.11830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mostafa Sharifzadeh, Habib Benali, Hassan Rivaz<br>for:The paper aims to address the challenge of applying frequency-space prediction filtering (FXPF) to plane-wave imaging in ultrasound imaging, where the number of contributing signals varies with depth.methods:The paper proposes an adaptive AR model to improve the performance of FXPF in plane-wave imaging, and quantifies its effectiveness using contrast and generalized contrast-to-noise ratio metrics.results:The proposed adaptive AR model improves the performance of FXPF in plane-wave imaging, as demonstrated by the improved contrast and generalized contrast-to-noise ratio metrics.<details>
<summary>Abstract</summary>
Ultrasound imaging often suffers from image degradation stemming from phase aberration, which represents a significant contributing factor to the overall image degradation in ultrasound imaging. Frequency-space prediction filtering or FXPF is a technique that has been applied within focused ultrasound imaging to alleviate the phase aberration effect. It presupposes the existence of an autoregressive (AR) model across the signals received at the transducer elements and removes any components that do not conform to the established model. In this study, we illustrate the challenge of applying this technique to plane-wave imaging, where, at shallower depths, signals from more distant elements lose relevance, and a fewer number of elements contribute to image reconstruction. While the number of contributing signals varies, adopting a fixed-order AR model across all depths, results in suboptimal performance. To address this challenge, we propose an AR model with an adaptive order and quantify its effectiveness using contrast and generalized contrast-to-noise ratio metrics.
</details>
<details>
<summary>摘要</summary>
ultrasound imaging经常受到相位偏移的影响，这是ultrasound imaging中全面影响最大的一种因素。frequency-space prediction filtering（FXPF）是一种在专注于ultrasound imaging中应用的技术，以提高相位偏移的效果。它假设在探测器元素上接收的信号存在autoregressive（AR）模型，并从不符合模型的信号中除除。在本研究中，我们介绍了应用FXPF技术到平面波图像中的挑战。在浅层深度处，更远的探测器元素的信号失去了相关性，只有一些探测器元素参与到图像重建中。而元素数量的变化，使用固定的AR模型在所有深度上采用，会导致性能下降。为解决这个挑战，我们提议一种AR模型，其顺序随着深度的变化而变化，并通过对比和总比响应度来衡量其效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/23/eess.IV_2023_08_23/" data-id="cllsj9x0o009luv882aivhcge" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/23/eessp.SP_2023_08_23/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eessp.SP - 2023-08-23
        
      </div>
    </a>
  
  
    <a href="/2023/08/22/cs.CL_2023_08_22/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-08-22</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">43</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">42</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">44</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">53</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">114</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'', root:''}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
