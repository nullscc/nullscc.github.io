
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-12 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.06594 repo_url: None paper_authors: Jumman Hossa">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-12 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/12/cs.LG_2023_08_12/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.06594 repo_url: None paper_authors: Jumman Hossa">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-11T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:29.222Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.LG_2023_08_12/" class="article-date">
  <time datetime="2023-08-11T16:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-12 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CoverNav-Cover-Following-Navigation-Planning-in-Unstructured-Outdoor-Environment-with-Deep-Reinforcement-Learning"><a href="#CoverNav-Cover-Following-Navigation-Planning-in-Unstructured-Outdoor-Environment-with-Deep-Reinforcement-Learning" class="headerlink" title="CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning"></a>CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06594">http://arxiv.org/abs/2308.06594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jumman Hossain, Abu-Zaher Faridee, Nirmalya Roy, Anjan Basak, Derrik E. Asher</li>
<li>For: 本研究旨在提出一种基于深度强化学习（DRL）算法，帮助无人地面车辆在隐蔽的情况下安全地导航到预定的目的地。* Methods: 本研究使用了DRL算法，计算了地方成本图，帮助机器人选择低高度的路径，并在检测到观察者时，使用自然障碍物（如岩石、房屋、瘫痪车辆、树木等）作为隐蔽物。* Results: 研究表明，CoverNav可以在 Unity 模拟环境中保证动态可行性，并在不同高度场景下实现最大目标距离和成功率。与当前最佳方法相比，CoverNav 没有妥协精度。<details>
<summary>Abstract</summary>
Autonomous navigation in offroad environments has been extensively studied in the robotics field. However, navigation in covert situations where an autonomous vehicle needs to remain hidden from outside observers remains an underexplored area. In this paper, we propose a novel Deep Reinforcement Learning (DRL) based algorithm, called CoverNav, for identifying covert and navigable trajectories with minimal cost in offroad terrains and jungle environments in the presence of observers. CoverNav focuses on unmanned ground vehicles seeking shelters and taking covers while safely navigating to a predefined destination. Our proposed DRL method computes a local cost map that helps distinguish which path will grant the maximal covertness while maintaining a low cost trajectory using an elevation map generated from 3D point cloud data, the robot's pose, and directed goal information. CoverNav helps robot agents to learn the low elevation terrain using a reward function while penalizing it proportionately when it experiences high elevation. If an observer is spotted, CoverNav enables the robot to select natural obstacles (e.g., rocks, houses, disabled vehicles, trees, etc.) and use them as shelters to hide behind. We evaluate CoverNav using the Unity simulation environment and show that it guarantees dynamically feasible velocities in the terrain when fed with an elevation map generated by another DRL based navigation algorithm. Additionally, we evaluate CoverNav's effectiveness in achieving a maximum goal distance of 12 meters and its success rate in different elevation scenarios with and without cover objects. We observe competitive performance comparable to state of the art (SOTA) methods without compromising accuracy.
</details>
<details>
<summary>摘要</summary>
自主导航在非路面环境中已经得到了机器人学Field的广泛研究。然而，在情报人员发现自动驾驶车辆的情况下，自主导航仍然是一个未得到充分研究的领域。在这篇论文中，我们提出了一种基于深度优化学习（DRL）算法，称为CoverNav，用于在非路面环境中寻找最佳隐蔽和可行的轨迹，并且尽量降低成本。CoverNav关注于无人地面车辆在安全地 navigate到预定目的地点时，找到遮盾和避险的方法。我们提出的DRL方法计算了当地的成本地图，以帮助选择最佳隐蔽的路径，同时维护低成本轨迹。如果检测到了观察者，CoverNav允许机器人使用自然障碍物（如岩石、房屋、瘫痪车辆、树木等）作为遮盾，隐藏自己。我们使用Unity simulate环境评估CoverNav，并证明它在地形图生成自 another DRL基 Navigation algorithm时能够保证动态可行速度。此外，我们在不同高度场景下评估CoverNav的效果，并发现其与SOTA方法相比，没有妥协精度。
</details></li>
</ul>
<hr>
<h2 id="Value-Distributional-Model-Based-Reinforcement-Learning"><a href="#Value-Distributional-Model-Based-Reinforcement-Learning" class="headerlink" title="Value-Distributional Model-Based Reinforcement Learning"></a>Value-Distributional Model-Based Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06590">http://arxiv.org/abs/2308.06590</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters</li>
<li>for: 这个论文目的是为了解决sequential decision-making任务中的uncertainty quantification问题。</li>
<li>methods: 这个论文使用了model-based Bayesian reinforcement learning的方法，其中的目标是学习Markov决策过程中参数不确定性induced的 posterior distribution over value functions。</li>
<li>results: 论文的实验表明，EQR算法可以在 continuous-control tasks 中比Established model-based和model-free算法表现出性能优势。<details>
<summary>Abstract</summary>
Quantifying uncertainty about a policy's long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. Evaluation across several continuous-control tasks shows performance benefits with respect to established model-based and model-free algorithms.
</details>
<details>
<summary>摘要</summary>
<<SYS>>量化政策长期表现的不确定性是解决sequential decision-making任务的重要问题。我们从model-based Bayesian reinforcement learning的视角 изуча这个问题，目标是学习Markov决策过程中参数（эпистемиче）不确定性引起的 posterior distribution over value functions。先前的工作只考虑了这些分布的一些瞬间或假设了特定的分布形式，例如 Gaussian。 inspirited by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function。 Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. 评估在多个连续控制任务上表现出与已有的model-based和model-free算法相比的性能优势。Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Approximate-Answering-of-Graph-Queries"><a href="#Approximate-Answering-of-Graph-Queries" class="headerlink" title="Approximate Answering of Graph Queries"></a>Approximate Answering of Graph Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06585">http://arxiv.org/abs/2308.06585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Cochez, Dimitrios Alivanistos, Erik Arakelyan, Max Berrendorf, Daniel Daza, Mikhail Galkin, Pasquale Minervini, Mathias Niepert, Hongyu Ren</li>
<li>for: 本文旨在介绍几种方法，以帮助回答含有不完整信息的知识图（KG）中的查询。</li>
<li>methods: 本文提出了多种方法，包括基于预测、基于潜在相似性、基于证据等方法，以满足不同类型的查询需求。</li>
<li>results: 这些方法可以帮助解决各种查询问题，如答案推断、 Entity Disambiguation、 Relation extraction 等。但是，这些方法受到图数据不完整和不准确的限制。<details>
<summary>Abstract</summary>
Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities.
</details>
<details>
<summary>摘要</summary>
知识图（KG）自然而然地是不完整的，因为世界知识的不完整和输入KG中的偏见。此外，世界知识不断扩展和发展，使现有的事实过时或引入新的事实。然而，我们仍然希望能够回答问题，作为如果图完整一样。在这章中，我们将给出不同类型的查询支持的方法的概述，以及通常用于评估的数据集，以及这些方法的局限性。然后，我们将对不同的方法进行描述，包括表达力、支持的图类型和推理能力。
</details></li>
</ul>
<hr>
<h2 id="A-new-solution-and-concrete-implementation-steps-for-Artificial-General-Intelligence"><a href="#A-new-solution-and-concrete-implementation-steps-for-Artificial-General-Intelligence" class="headerlink" title="A new solution and concrete implementation steps for Artificial General Intelligence"></a>A new solution and concrete implementation steps for Artificial General Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09721">http://arxiv.org/abs/2308.09721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongcong Chen, Ting Zeng, Jun Zhang</li>
<li>for: 本文旨在探讨大型模型技术路径的局限性，并提出解决这些局限性的方案，以实现true AGI。</li>
<li>methods: 本文使用了现有技术和方法，包括注意机制、深度学习和补偿学习，并提出了一种新的解决方案。</li>
<li>results: 本文提出的解决方案可以解决大型模型技术路径中的缺陷，并实现true AGI。<details>
<summary>Abstract</summary>
At present, the mainstream artificial intelligence generally adopts the technical path of "attention mechanism + deep learning" + "reinforcement learning". It has made great progress in the field of AIGC (Artificial Intelligence Generated Content), setting off the technical wave of big models[ 2][13 ]. But in areas that need to interact with the actual environment, such as elderly care, home nanny, agricultural production, and vehicle driving, trial and error are expensive and a reinforcement learning process that requires much trial and error is difficult to achieve. Therefore, in order to achieve Artificial General Intelligence(AGI) that can be applied to any field, we need to use both existing technologies and solve the defects of existing technologies, so as to further develop the technological wave of artificial intelligence. In this paper, we analyze the limitations of the technical route of large models, and by addressing these limitations, we propose solutions, thus solving the inherent defects of large models. In this paper, we will reveal how to achieve true AGI step by step.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现在，主流人工智能通常采用“注意机制+深度学习”+“奖励学习”的技术路径。这种方法在AIGC（人工智能生成内容）领域已经取得了 significanthistorical achievements[ 2][13 ], triggering a technological wave of big models. However, in areas that require interaction with the actual environment, such as elderly care, home nanny, agricultural production, and vehicle driving, trial and error are costly and a reinforcement learning process that requires much trial and error is difficult to achieve. Therefore, to achieve Artificial General Intelligence (AGI) that can be applied to any field, we need to leverage both existing technologies and address the limitations of existing technologies, thereby further developing the technological wave of artificial intelligence. In this paper, we analyze the limitations of the technical route of large models, and by addressing these limitations, we propose solutions, thus solving the inherent defects of large models. Through this paper, we will reveal how to achieve true AGI step by step.
</details></li>
</ul>
<hr>
<h2 id="EquiDiff-A-Conditional-Equivariant-Diffusion-Model-For-Trajectory-Prediction"><a href="#EquiDiff-A-Conditional-Equivariant-Diffusion-Model-For-Trajectory-Prediction" class="headerlink" title="EquiDiff: A Conditional Equivariant Diffusion Model For Trajectory Prediction"></a>EquiDiff: A Conditional Equivariant Diffusion Model For Trajectory Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06564">http://arxiv.org/abs/2308.06564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kehua Chen, Xianda Chen, Zihan Yu, Meixin Zhu, Hai Yang</li>
<li>for: 预测自动驾驶车辆的未来轨迹是关键的，以确保安全和效率地运行。</li>
<li>methods: 我们提出了一种基于深度生成模型的轨迹预测方法，即EquiDiff。EquiDiff基于 Conditional Diffusion 模型，通过历史信息和随机抽样 Gaussian 噪声来生成未来轨迹。</li>
<li>results: 我们在 NGSIM 数据集上进行了广泛的实验，并证明了 EquiDiff 在短期预测方面的性能较高，但在长期预测方面有些较高的错误率。此外，我们还进行了一个ablation study，以调查各组件对预测精度的贡献。<details>
<summary>Abstract</summary>
Accurate trajectory prediction is crucial for the safe and efficient operation of autonomous vehicles. The growing popularity of deep learning has led to the development of numerous methods for trajectory prediction. While deterministic deep learning models have been widely used, deep generative models have gained popularity as they learn data distributions from training data and account for trajectory uncertainties. In this study, we propose EquiDiff, a deep generative model for predicting future vehicle trajectories. EquiDiff is based on the conditional diffusion model, which generates future trajectories by incorporating historical information and random Gaussian noise. The backbone model of EquiDiff is an SO(2)-equivariant transformer that fully utilizes the geometric properties of location coordinates. In addition, we employ Recurrent Neural Networks and Graph Attention Networks to extract social interactions from historical trajectories. To evaluate the performance of EquiDiff, we conduct extensive experiments on the NGSIM dataset. Our results demonstrate that EquiDiff outperforms other baseline models in short-term prediction, but has slightly higher errors for long-term prediction. Furthermore, we conduct an ablation study to investigate the contribution of each component of EquiDiff to the prediction accuracy. Additionally, we present a visualization of the generation process of our diffusion model, providing insights into the uncertainty of the prediction.
</details>
<details>
<summary>摘要</summary>
准确预测车辆轨迹是自动驾驶车辆运行的安全和效率的关键。随着深度学习的普及，许多方法 для轨迹预测得到了开发。而深度生成模型在训练数据中学习数据分布，并考虑轨迹不确定性，因此在这种情况下变得更加受欢迎。在这项研究中，我们提出了EquiDiff，一种基于 conditional diffusion 模型的深度生成模型，用于预测未来车辆轨迹。EquiDiff 使用 SO(2)-equivariant transformer 作为底层模型，并使用循环神经网络和 Graph Attention Networks 提取历史轨迹中的社会交互。为了评估EquiDiff的性能，我们在 NGSIM 数据集上进行了广泛的实验。我们的结果表明，EquiDiff 在短期预测方面表现出色，但是在长期预测方面有些微的错误。此外，我们进行了ablation study，以investigate EquiDiff 中每个组件对预测精度的贡献。此外，我们还提供了生成过程中 diffusion 模型的视觉化，为预测不确定性提供了更多的信息。
</details></li>
</ul>
<hr>
<h2 id="Human-Behavior-based-Personalized-Meal-Recommendation-and-Menu-Planning-Social-System"><a href="#Human-Behavior-based-Personalized-Meal-Recommendation-and-Menu-Planning-Social-System" class="headerlink" title="Human Behavior-based Personalized Meal Recommendation and Menu Planning Social System"></a>Human Behavior-based Personalized Meal Recommendation and Menu Planning Social System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06549">http://arxiv.org/abs/2308.06549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanvir Islam, Anika Rahman Joyita, Md. Golam Rabiul Alam, Mohammad Mehedi Hassan, Md. Rafiul Hassan, Raffaele Gravina</li>
<li>for: 这个研究的目的是为了提供一种基于情感计算的餐Menu建议系统，以满足用户的情感需求和营养需求。</li>
<li>methods: 这个系统使用了问卷调查和偏好认知来获取用户的餐食偏好，并使用EEG信号检测用户对不同餐食的情感反应。然后，使用一种层次ensemble方法预测餐食的情感反应，并使用TOPSIS算法生成一个基于预测结果的餐Menu。</li>
<li>results: 实验结果表明，提出的情感计算、餐Menu建议和自动菜单规划算法都能够在不同评价参数下表现良好。<details>
<summary>Abstract</summary>
The traditional dietary recommendation systems are basically nutrition or health-aware where the human feelings on food are ignored. Human affects vary when it comes to food cravings, and not all foods are appealing in all moods. A questionnaire-based and preference-aware meal recommendation system can be a solution. However, automated recognition of social affects on different foods and planning the menu considering nutritional demand and social-affect has some significant benefits of the questionnaire-based and preference-aware meal recommendations. A patient with severe illness, a person in a coma, or patients with locked-in syndrome and amyotrophic lateral sclerosis (ALS) cannot express their meal preferences. Therefore, the proposed framework includes a social-affective computing module to recognize the affects of different meals where the person's affect is detected using electroencephalography signals. EEG allows to capture the brain signals and analyze them to anticipate affective toward a food. In this study, we have used a 14-channel wireless Emotive Epoc+ to measure affectivity for different food items. A hierarchical ensemble method is applied to predict affectivity upon multiple feature extraction methods and TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) is used to generate a food list based on the predicted affectivity. In addition to the meal recommendation, an automated menu planning approach is also proposed considering a person's energy intake requirement, affectivity, and nutritional values of the different menus. The bin-packing algorithm is used for the personalized menu planning of breakfast, lunch, dinner, and snacks. The experimental findings reveal that the suggested affective computing, meal recommendation, and menu planning algorithms perform well across a variety of assessment parameters.
</details>
<details>
<summary>摘要</summary>
传统的饮食建议系统基本上是nutrition或健康意识的，忽略了人类的情感 toward food。人类的食欲情绪 varying degree，不同的情感状态下不同的食物都不能吸引人。问卷式和偏好意识的饭单推荐系统可以是一种解决方案。然而，通过自动认知不同食物的社会情感影响和根据饮食需求和社会情感规划饭单，有一些显著的优点。例如，患有严重疾病、昏迷状态或 locked-in syndrome 和 amyotrophic lateral sclerosis (ALS) 的患者无法表达他们的饭单首选。因此，我们的框架包括一个社交情感计算模块，用于识别不同饭物中的情感。我们使用了14核心无线Emotive Epoc+来测量不同食物的情感。我们使用了一种层次ensemble方法来预测情感，并使用TOPSIS (技术 дляOrder of Preference by Similarity to Ideal Solution)来生成基于预测情感的食品列表。此外，我们还提出了一种自动饭单规划方法，考虑人类的能量摄入需求、情感和不同饭单的营养价值。使用了bin-packing算法进行个性化饭单规划的早餐、午餐、晚餐和快餐。实验结果表明，我们提出的情感计算、饭单推荐和饭单规划算法在多种评估参数下表现良好。
</details></li>
</ul>
<hr>
<h2 id="Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters"><a href="#Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters" class="headerlink" title="Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters"></a>Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06545">http://arxiv.org/abs/2308.06545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chukwuma Okolie, Jon Mills, Adedayo Adeleke, Julian Smit</li>
<li>For: The paper aims to enhance the accuracy of medium-resolution digital elevation models (DEMs) in urban areas, specifically in Cape Town, South Africa, for hydrological and environmental modelling.* Methods: The authors use the extreme gradient boosting (XGBoost) ensemble algorithm to correct the DEMs, with eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, and more.* Results: The corrected DEMs achieved significant accuracy gains, with a root mean square error (RMSE) improvement of 46-53% for Copernicus DEM and 72-73% for AW3D DEM, compared to other proposed methods. These results demonstrate the potential of gradient boosted trees for enhancing DEM quality and improving hydrological modelling in urban catchments.Here is the same information in Simplified Chinese text, as requested:* For: 这个论文的目的是提高城市区域中的数字高程模型（DEM）的准确性，以便于水文和环境模型。* Methods: 作者使用极限Gradient Boosting（XGBoost）ensemble算法来修正DEM，使用的predictor变量包括高程、城市脚印、坡度、方向、表面荒凉、地形位置指数、地形荒凉指数、地形表面 текстура等 eleven个变量。* Results: 修正后的DEM实现了显著的准确性提高，比如 Copernicus DEM的RMSE提高46-53%，AW3D DEM的RMSE提高72-73%，与其他提议的方法相比。这些结果表明极限Gradient Boosting树可以提高DEM的质量，并且为城市catchments中的水文模型提供改善。<details>
<summary>Abstract</summary>
The accuracy of digital elevation models (DEMs) in urban areas is influenced by numerous factors including land cover and terrain irregularities. Moreover, building artifacts in global DEMs cause artificial blocking of surface flow pathways. This compromises their quality and adequacy for hydrological and environmental modelling in urban landscapes where precise and accurate terrain information is needed. In this study, the extreme gradient boosting (XGBoost) ensemble algorithm is adopted for enhancing the accuracy of two medium-resolution 30m DEMs over Cape Town, South Africa: Copernicus GLO-30 and ALOS World 3D (AW3D). XGBoost is a scalable, portable and versatile gradient boosting library that can solve many environmental modelling problems. The training datasets are comprised of eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, topographic position index, terrain ruggedness index, terrain surface texture, vector roughness measure, forest cover and bare ground cover. The target variable (elevation error) was calculated with respect to highly accurate airborne LiDAR. After training and testing, the model was applied for correcting the DEMs at two implementation sites. The correction achieved significant accuracy gains which are competitive with other proposed methods. The root mean square error (RMSE) of Copernicus DEM improved by 46 to 53% while the RMSE of AW3D DEM improved by 72 to 73%. These results showcase the potential of gradient boosted trees for enhancing the quality of DEMs, and for improved hydrological modelling in urban catchments.
</details>
<details>
<summary>摘要</summary>
地数模型（DEM）在城市地区的准确性受到多种因素的影响，包括地表覆盖物和地形 irregularities。此外，全球 DEM 中的建筑物略导致表面流道路径的人工堵塞，从而降低其质量和适用性 для水文环境模型在城市景观中，需要精准和准确的地形信息。在这种研究中，我们采用了极限拟合搅拌（XGBoost）ensemble算法来提高两个中等分辨率 30 m DEM 的准确性，即 Copernicus GLO-30 和 ALOS World 3D（AW3D）。XGBoost 是一种可扩展、可移植和多样的拟合搅拌库，可以解决许多环境模型问题。训练数据集包括 eleven 个预测变量，包括高程、城市脚印、坡度、方向、表面粗糙度、地形坡度指数、地形表面文化、向量粗糙度度量、森林覆盖率和裸地覆盖率。target variable （高程误差）与高精度飞行 LiDAR 进行计算。之后，模型被应用于修正 DEM 的两个实施场景。修正后，DEM 的Root Mean Square Error（RMSE）提高了46%到53%，AW3D DEM 的 RMSE 提高了72%到73%。这些结果显示了拟合搅拌树的潜在可能性，以及对城市流域水文模型的改进。
</details></li>
</ul>
<hr>
<h2 id="Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models"><a href="#Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models" class="headerlink" title="Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models"></a>Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06534">http://arxiv.org/abs/2308.06534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wolfda95/ssl-medicalimagining-cl-mae">https://github.com/wolfda95/ssl-medicalimagining-cl-mae</a></li>
<li>paper_authors: Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Timo Ropinski, Michael Götz</li>
<li>for: 这篇论文旨在探讨deep learning在医疗影像领域中的应用，以减少诊断错误、轻量化医生工作负担，并加快诊断。</li>
<li>methods: 这篇论文使用了自动标注学习方法，包括对大量无标注影像进行自动标注。</li>
<li>results: 研究发现，使用SparK预训方法可以更好地适应小型标注数据，并且在诊断任务中表现更好。<details>
<summary>Abstract</summary>
Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task. The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares state-of-the-art contrastive learning methods with the recently introduced masked autoencoder approach "SparK" for convolutional neural networks (CNNs) on medical images. Therefore we pre-train on a large unannotated CT image dataset and fine-tune on several CT classification tasks. Due to the challenge of obtaining sufficient annotated training data in medical imaging, it is of particular interest to evaluate how the self-supervised pre-training methods perform when fine-tuning on small datasets. By experimenting with gradually reducing the training dataset size for fine-tuning, we find that the reduction has different effects depending on the type of pre-training chosen. The SparK pre-training method is more robust to the training dataset size than the contrastive methods. Based on our results, we propose the SparK pre-training for medical imaging tasks with only small annotated datasets.
</details>
<details>
<summary>摘要</summary>
深度学习在医疗影像领域可能减少诊断错误风险，减轻放射学家的工作负担，并加速诊断。深度学习模型的训练需要大量和准确的数据集，并将所有训练样本标注。然而，在医疗影像领域，特定任务的标注数据集经常很小，这可能由标注的复杂性、访问限制或疾病的罕见性引起。为解决这个挑战，可以使用自动标注学习的方法进行深度学习模型的预训练。在预训练后，只需要小量的标注数据集来精度地调整模型 для特定任务。医疗影像领域最受欢迎的自动标注预训练方法是对比学习。然而，最近的自然图像处理研究表明，遮盲 autoencoder 方法有很强的潜在性。我们的工作比较了当前状态的对比学习方法和新引入的遮盲 autoencoder 方法 "SparK" 在医疗影像中的 convolutional neural networks (CNNs) 上。因此，我们预训练在大量无注释 CT 图像数据集上，并在多个 CT 分类任务上进行精度调整。由于医疗影像领域获得足够的注释训练数据是困难的，因此特别关心自动标注预训练方法在小型注释数据集上的性能。通过逐渐减少 fine-tuning 数据集大小的实验，我们发现降低的效果与预训练方法的类型有很大的差异。SparK 预训练方法在训练数据集尺寸减少后表现更加稳定。根据我们的结果，我们建议使用 SparK 预训练方法进行医疗影像任务，只需要小量的注释训练数据。
</details></li>
</ul>
<hr>
<h2 id="Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices"><a href="#Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices" class="headerlink" title="Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices"></a>Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06528">http://arxiv.org/abs/2308.06528</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jakubkwiatkowski/abstract_compositional_transformer">https://github.com/jakubkwiatkowski/abstract_compositional_transformer</a></li>
<li>paper_authors: Jakub Kwiatkowski, Krzysztof Krawiec</li>
<li>for: 本研究旨在提高 Ravens 进步矩阵（RPM）问题的抽象逻辑能力，通过预测图像中对象的视觉特征和排序来选择答案。</li>
<li>methods: 本研究使用了一种基于 transformer 框架的深度学习模型，通过预测图像中对象的视觉特征和排序来选择答案。研究还考虑了不同的图像分割方法和自我指导学习策略。</li>
<li>results: 实验结果表明，本研究的模型不仅超越了当前最佳方法，还提供了有趣的思路和部分解释，以帮助理解问题的含义。此外，模型的设计还使其具有免疫一些已知 RPM  bencmarks 中的偏见的能力。<details>
<summary>Abstract</summary>
One of the challenges in learning to perform abstract reasoning is that problems are often posed as monolithic tasks, with no intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint which, rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.
</details>
<details>
<summary>摘要</summary>
一个挑战在抽象逻辑学习中是，问题经常是单一任务，没有中间目标。在萨瑟进步矩阵（RPM）中，任务是根据Context选择可用的答案，Context和答案都是复杂的图像，包含多个物体在不同的空间排列。由于高级目标是唯一的指导，学习是困难的，而大多数当代解决方案都是透明的。在这种研究中，我们提出了基于变换器蓝图的深度学习架构，而不是直接选择上述高级目标，而是预测图像中物体的视觉属性和排列。 obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.Here's the translation in Traditional Chinese:一个挑战在抽象逻辑学习中是，问题经常是单一任务，没有中间目标。在萨瑟进步矩阵（RPM）中，任务是根据Context选择可用的答案，Context和答案都是复杂的图像，包含多个物体在不同的空间排列。由于高级目标是唯一的指导，学习是困难的，而大多数当代解决方案都是透明的。在这种研究中，我们提出了基于变数器蓝图的深度学习架构，而不是直接选择上述高级目标，而是预测图像中物体的视觉属性和排列。 obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.
</details></li>
</ul>
<hr>
<h2 id="SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models"><a href="#SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models" class="headerlink" title="SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models"></a>SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06522">http://arxiv.org/abs/2308.06522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Qingfeng Liu, Kee-Bong Song, Mostafa El-Khamy, Salman Avestimehr</li>
<li>for: 这个论文主要针对的是如何使用 parameter efficient fine-tuning (PEFT) 方法在 Federated Learning (FL) 中进行语言任务的训练。</li>
<li>methods: 本文使用了 FL 技术和 PEFT 方法，并进行了实验研究以探讨在不同的数据场景下的可行性和挑战。</li>
<li>results: 实验结果表明，当用户数据变得更加多样化时，PEFT 方法与全量精度训练的性能差距逐渐增大。为了bridge这个性能差距，本文提出了一种名为 SLoRA 的方法，通过一种新的数据驱动初始化技术来超越 LoRA 在高多样数据场景下的限制。SLoRA 方法可以实现与全量精度训练相当的性能，并且可以减少训练时间，并且可以减少稀疏更新的数量。<details>
<summary>Abstract</summary>
Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data scenarios through a novel data-driven initialization technique. Our experimental results demonstrate that SLoRA achieves performance comparable to full fine-tuning, with significant sparse updates with approximately $\sim 1\%$ density while reducing training time by up to $90\%$.
</details>
<details>
<summary>摘要</summary>
通过精细调整已经训练过的变换器模型，通过中央化数据的缺失， Federated Learning (FL) 可以利用分布式和私有的 Edge 客户端数据进行 fine-tuning。然而，由于 Edge 设备的通信、计算和存储能力的限制，以及各种变换器模型的巨大大小，高效的 fine-tuning 是在 federated 训练中实现可行的。这种工作探讨了在语言任务中应用 parameter efficient fine-tuning (PEFT) 方法的机会和挑战。具体来说，我们的调查发现，当用户数据变得更加多样化时，具有完全 fine-tuning 模型和使用 PEFT 方法之间的性能差距变得更加明显。为了补做这个性能差距，我们提出了一种名为 SLoRA 的方法，通过一种新的数据驱动初始化技术，超越 LoRA 在高多样化数据场景中的关键限制。我们的实验结果表明，SLoRA 可以与完全 fine-tuning 性能相似，使用约 $\sim 1\%$ 的稀疏更新，同时降低训练时间达到 $90\%$。
</details></li>
</ul>
<hr>
<h2 id="One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training"><a href="#One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training" class="headerlink" title="One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training"></a>One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07934">http://arxiv.org/abs/2308.07934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jianshuod/tba">https://github.com/jianshuod/tba</a></li>
<li>paper_authors: Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia</li>
<li>for: 保持深度神经网络（DNNs）的安全性，因为它们在实际设备上广泛部署。</li>
<li>methods: 使用记忆FAULT INJECT技术，如行ammer，对量化模型进行攻击。只需要一些位置的变化，目标模型可以变成一个随机估计或者恶意功能模型。</li>
<li>results: 在基准数据集上，攻击者可以轻松地通过flipping一个关键位的变化，将高风险模型转换为恶意模型。此外，我们的攻击还能够绕过一些防御机制。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/jianshuod/TBA%7D">https://github.com/jianshuod/TBA}</a> 上复制。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are widely deployed on real-world devices. Concerns regarding their security have gained great attention from researchers. Recently, a new weight modification attack called bit flip attack (BFA) was proposed, which exploits memory fault inject techniques such as row hammer to attack quantized models in the deployment stage. With only a few bit flips, the target model can be rendered useless as a random guesser or even be implanted with malicious functionalities. In this work, we seek to further reduce the number of bit flips. We propose a training-assisted bit flip attack, in which the adversary is involved in the training stage to build a high-risk model to release. This high-risk model, obtained coupled with a corresponding malicious model, behaves normally and can escape various detection methods. The results on benchmark datasets show that an adversary can easily convert this high-risk but normal model to a malicious one on victim's side by \textbf{flipping only one critical bit} on average in the deployment stage. Moreover, our attack still poses a significant threat even when defenses are employed. The codes for reproducing main experiments are available at \url{https://github.com/jianshuod/TBA}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Performance-Analysis-for-Resource-Constrained-Decentralized-Federated-Learning-Over-Wireless-Networks"><a href="#Performance-Analysis-for-Resource-Constrained-Decentralized-Federated-Learning-Over-Wireless-Networks" class="headerlink" title="Performance Analysis for Resource Constrained Decentralized Federated Learning Over Wireless Networks"></a>Performance Analysis for Resource Constrained Decentralized Federated Learning Over Wireless Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06496">http://arxiv.org/abs/2308.06496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhigang Yan, Dong Li</li>
<li>for: 这个研究旨在测试和优化内存和通信参数以提高 Federated Learning（FL）的可靠性和效率。</li>
<li>methods: 这个研究使用了分布式 Federated Learning（DFL）框架，并使用了不同的通信方案（数位和分数）来分析它们的通信效率。</li>
<li>results: 研究发现，在不同的通信方案下，这个框架可以提供内存和通信参数的优化，以提高模型的训练效率和可靠性。<details>
<summary>Abstract</summary>
Federated learning (FL) can lead to significant communication overhead and reliance on a central server. To address these challenges, decentralized federated learning (DFL) has been proposed as a more resilient framework. DFL involves parameter exchange between devices through a wireless network. This study analyzes the performance of resource-constrained DFL using different communication schemes (digital and analog) over wireless networks to optimize communication efficiency. Specifically, we provide convergence bounds for both digital and analog transmission approaches, enabling analysis of the model performance trained on DFL. Furthermore, for digital transmission, we investigate and analyze resource allocation between computation and communication and convergence rates, obtaining its communication complexity and the minimum probability of correction communication required for convergence guarantee. For analog transmission, we discuss the impact of channel fading and noise on the model performance and the maximum errors accumulation with convergence guarantee over fading channels. Finally, we conduct numerical simulations to evaluate the performance and convergence rate of convolutional neural networks (CNNs) and Vision Transformer (ViT) trained in the DFL framework on fashion-MNIST and CIFAR-10 datasets. Our simulation results validate our analysis and discussion, revealing how to improve performance by optimizing system parameters under different communication conditions.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 可能会带来重要的通信负担和依赖中央服务器。为了解决这些挑战，分散式 federated learning (DFL) 已经被提议作为一个更可靠的框架。DFL 中各个设备之间的参数交换通过无线网络。本研究分析了受限制的 DFL 在无线网络上的执行效率，使用不同的通信方案（数位和分散）。特别是，我们提供了两种通信方案的整合边界值，以便分析模型在 DFL 中的表现。此外，我们还调查了在数位传输中的资源分配和计算和通信的复杂度，以及它们对模型表现的影响。另外，我们还分析了随机传输中频道折射和噪音对模型表现的影响，以及在折射频道上累累的最大错误累累。最后，我们对 fashion-MNIST 和 CIFAR-10 数据集上的 CNNs 和 ViT 在 DFL 框架中进行了数值模拟，以评估其表现和融合率。我们的模拟结果证实了我们的分析和讨论，显示了如何通过优化系统参数来改善表现，不同的通信条件下。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Keyword-Spotting-based-on-Homogeneous-Audio-Text-Embedding"><a href="#Flexible-Keyword-Spotting-based-on-Homogeneous-Audio-Text-Embedding" class="headerlink" title="Flexible Keyword Spotting based on Homogeneous Audio-Text Embedding"></a>Flexible Keyword Spotting based on Homogeneous Audio-Text Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06472">http://arxiv.org/abs/2308.06472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumari Nishu, Minsik Cho, Paul Dixon, Devang Naik</li>
<li>for: 这个论文的目的是提出一种高效的关键词检测方法，以便在 audio-text  embedding 空间中快速检测任意关键词。</li>
<li>methods: 该方法使用一个 audio-compliant 文本编码器，将文本转换为phonemes使用 G2P 模型，然后将phonemes转换为嵌入使用表示性强的音频编码器生成的phoneme вектор。此外，该方法还使用杂音词生成来提高audio-text embedding验证器的强度。</li>
<li>results: 实验结果表明，该方法在 Libriphrase 难 dataset 上超过了州�类-国度的Result（AUC：84.21% → 92.7%，EER：23.36% → 14.4%）， indicating that our scheme can efficiently detect arbitrary keywords in audio-text embedding space with high accuracy.<details>
<summary>Abstract</summary>
Spotting user-defined/flexible keywords represented in text frequently uses an expensive text encoder for joint analysis with an audio encoder in an embedding space, which can suffer from heterogeneous modality representation (i.e., large mismatch) and increased complexity. In this work, we propose a novel architecture to efficiently detect arbitrary keywords based on an audio-compliant text encoder which inherently has homogeneous representation with audio embedding, and it is also much smaller than a compatible text encoder. Our text encoder converts the text to phonemes using a grapheme-to-phoneme (G2P) model, and then to an embedding using representative phoneme vectors, extracted from the paired audio encoder on rich speech datasets. We further augment our method with confusable keyword generation to develop an audio-text embedding verifier with strong discriminative power. Experimental results show that our scheme outperforms the state-of-the-art results on Libriphrase hard dataset, increasing Area Under the ROC Curve (AUC) metric from 84.21% to 92.7% and reducing Equal-Error-Rate (EER) metric from 23.36% to 14.4%.
</details>
<details>
<summary>摘要</summary>
通常，用户定义/灵活关键词在文本中的检测使用昂贵的文本编码器进行联合分析与音频编码器在嵌入空间，这可能会导致不同类型的表达媒体表示（大匹配度差）和增加复杂性。在这种工作中，我们提出一种新的架构，可以有效地检测任意关键词基于兼容音频编码器的文本编码器，该编码器自然具有同 Audio embedding的同一个表示形式，而且比兼容的文本编码器更小。我们的文本编码器将文本转换为音频的phoneme使用图eme-to-phoneme（G2P）模型，然后将其转换为嵌入使用表示音频编码器中的可表示性phoneme вектор。我们进一步增强我们的方法，通过可混淆关键词生成来开发一个具有强 дискриминатив力的音频-文本嵌入验证器。实验结果表明，我们的方案在Libriphrase hard数据集上的Result outperform了状态的aru的结果，从84.21%提高到92.7%，并从23.36%降低到14.4%。
</details></li>
</ul>
<hr>
<h2 id="Volterra-Accentuated-Non-Linear-Dynamical-Admittance-VANYA-to-model-Deforestation-An-Exemplification-from-the-Amazon-Rainforest"><a href="#Volterra-Accentuated-Non-Linear-Dynamical-Admittance-VANYA-to-model-Deforestation-An-Exemplification-from-the-Amazon-Rainforest" class="headerlink" title="Volterra Accentuated Non-Linear Dynamical Admittance (VANYA) to model Deforestation: An Exemplification from the Amazon Rainforest"></a>Volterra Accentuated Non-Linear Dynamical Admittance (VANYA) to model Deforestation: An Exemplification from the Amazon Rainforest</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06471">http://arxiv.org/abs/2308.06471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karthik R., Ramamoorthy A.</li>
<li>for: 这篇论文是为了研究森林覆盖率的预测，特别是通过VANYA模型，包括预测动物食肉动力学。</li>
<li>methods: 该论文使用了时间序列数据和人工智能技术，包括神经网络和推论算法。</li>
<li>results: 论文通过对亚马逊雨林数据进行预测，显示了VANYA模型的可靠性和准确性，并与其他预测器如LSTM、N-BEATS、RCN进行比较。<details>
<summary>Abstract</summary>
Intelligent automation supports us against cyclones, droughts, and seismic events with recent technology advancements. Algorithmic learning has advanced fields like neuroscience, genetics, and human-computer interaction. Time-series data boosts progress. Challenges persist in adopting these approaches in traditional fields. Neural networks face comprehension and bias issues. AI's expansion across scientific areas is due to adaptable descriptors and combinatorial argumentation. This article focuses on modeling Forest loss using the VANYA Model, incorporating Prey Predator Dynamics. VANYA predicts forest cover, demonstrated on Amazon Rainforest data against other forecasters like Long Short-Term Memory, N-BEATS, RCN.
</details>
<details>
<summary>摘要</summary>
智能自动化支持我们面对风暴、旱情和地震等自然灾害，由于最新的技术进步。算法学习在 neuroscience、遗传学和人机交互等领域得到了进步，时间序列数据也促进了进步。然而，在传统领域采用这些方法还存在挑战。神经网络具有理解和偏见问题。AI在科学领域的扩张归功于可变描述符和组合说服。本文通过使用VANYA模型，包括猎Predator Dinamics，预测森林覆盖率，并与Long Short-Term Memory、N-BEATS、RCN等预测器进行比较。
</details></li>
</ul>
<hr>
<h2 id="Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization"><a href="#Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization" class="headerlink" title="Tiny and Efficient Model for the Edge Detection Generalization"></a>Tiny and Efficient Model for the Edge Detection Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06468">http://arxiv.org/abs/2308.06468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xavysp/teed">https://github.com/xavysp/teed</a></li>
<li>paper_authors: Xavier Soria, Yachuan Li, Mohammad Rouhani, Angel D. Sappa</li>
<li>for: 本研究旨在提高图像Edge detection的简洁性、效率和通用性，对现有的State-of-the-art（SOTA）Edge detection模型进行改进。</li>
<li>methods: 本文提出了一种名为Tiny and Efficient Edge Detector（TEED）的轻量级卷积神经网络，只有58K个参数，比SOTA模型少了99.8%。该模型训练在BIPED dataset上只需30分钟左右，每个epoch只需5分钟左右。</li>
<li>results: 本文的提出的模型具有训练容易、快速收敛的特点，并且预测的边映射质量高。此外，本文还提出了一个新的边检测测试集，包括图像Edge detection和图像分割中常用的样本。代码可以在<a target="_blank" rel="noopener" href="https://github.com/xavysp/TEED%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/xavysp/TEED上下载。</a><details>
<summary>Abstract</summary>
Most high-level computer vision tasks rely on low-level image operations as their initial processes. Operations such as edge detection, image enhancement, and super-resolution, provide the foundations for higher level image analysis. In this work we address the edge detection considering three main objectives: simplicity, efficiency, and generalization since current state-of-the-art (SOTA) edge detection models are increased in complexity for better accuracy. To achieve this, we present Tiny and Efficient Edge Detector (TEED), a light convolutional neural network with only $58K$ parameters, less than $0.2$% of the state-of-the-art models. Training on the BIPED dataset takes $less than 30 minutes$, with each epoch requiring $less than 5 minutes$. Our proposed model is easy to train and it quickly converges within very first few epochs, while the predicted edge-maps are crisp and of high quality. Additionally, we propose a new dataset to test the generalization of edge detection, which comprises samples from popular images used in edge detection and image segmentation. The source code is available in https://github.com/xavysp/TEED.
</details>
<details>
<summary>摘要</summary>
大多数高级计算机视觉任务都基于低级图像操作作为初始过程。操作如边检测、图像提高和超分解，为更高级图像分析提供基础。在这项工作中，我们考虑了三个主要目标：简单、高效和通用，因为当前状态之arte（SOTA）边检测模型在精度方面增加了复杂度。为 достичь这一目标，我们提出了小型和高效的边检测器（TEED），这是一个具有58000个参数的小 convolutional neural network，相对于状态之arte模型的0.2%。在BIPE dataset上训练TEED只需几分钟时间，每个epoch仅需5分钟或更少。我们的提议的模型容易训练，快速 converges于第一些epoch，而预测的边映射具有高质量。此外，我们还提出了一个新的边检测检验集，该集包括来自popular图像的边检测和图像分割领域的样本。代码可以在https://github.com/xavysp/TEED中下载。
</details></li>
</ul>
<hr>
<h2 id="Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks"><a href="#Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks" class="headerlink" title="Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks"></a>Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06467">http://arxiv.org/abs/2308.06467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roman Garaev, Bader Rasheed, Adil Khan</li>
<li>for: 挑战当代防御机制对于攻击性质变化的测试</li>
<li>methods: 使用 adversarial attacks  manipulate input data 以测试 DNN 的强项和普遍性</li>
<li>results: 发现 DNN 对于 $L_2$ 和 $L_{\infty}$ 攻击性质的差异，并通过对 DNN 表现的分析和可视化获得更深入的理解。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have gained prominence in various applications, such as classification, recognition, and prediction, prompting increased scrutiny of their properties. A fundamental attribute of traditional DNNs is their vulnerability to modifications in input data, which has resulted in the investigation of adversarial attacks. These attacks manipulate the data in order to mislead a DNN. This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks. Specifically, we explore the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. This hypothesis suggests that training a DNN on a dataset consisting solely of robust features should produce a model resistant to adversarial attacks. However, our experiments demonstrate that this is not universally true. To gain further insights into our findings, we analyze the impact of adversarial attack norms on DNN representations, focusing on samples subjected to $L_2$ and $L_{\infty}$ norm attacks. Further, we employ canonical correlation analysis, visualize the representations, and calculate the mean distance between these representations and various DNN decision boundaries. Our results reveal a significant difference between $L_2$ and $L_{\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\infty}$ norm attacks, previously underestimated by the research community.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-One-dimensional-HEVC-video-steganalysis-method-using-the-Optimality-of-Predicted-Motion-Vectors"><a href="#A-One-dimensional-HEVC-video-steganalysis-method-using-the-Optimality-of-Predicted-Motion-Vectors" class="headerlink" title="A One-dimensional HEVC video steganalysis method using the Optimality of Predicted Motion Vectors"></a>A One-dimensional HEVC video steganalysis method using the Optimality of Predicted Motion Vectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06464">http://arxiv.org/abs/2308.06464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Li, Minqing Zhang, Ke Niu, Yingnan Zhang, Xiaoyuan Yang</li>
<li>for: 本研究旨在提高掩埋检测性能，对高效视频编码标准（HEVC）中的动态vector域基于视频掩埋进行检测。</li>
<li>methods: 该研究提出了基于优化的动态vectorprediction（AMVP）技术的一种掩埋特征，即HEVC视频中的信息投射可能会破坏当地优化的动态vectorprediction（MVP）。然后，定义HEVC视频中的MVP优化率作为掩埋检测特征。</li>
<li>results: 通过在两个通用数据集上进行检测，研究发现，对于所有的覆盖视频，MVP优化率都为100%，而对于所有的掩埋视频，MVP优化率小于100%。因此，该掩埋方法可以准确地分辨覆盖视频和掩埋视频，并且在实际应用中具有无模型训练和低计算复杂度。<details>
<summary>Abstract</summary>
Among steganalysis techniques, detection against motion vector (MV) domain-based video steganography in High Efficiency Video Coding (HEVC) standard remains a hot and challenging issue. For the purpose of improving the detection performance, this paper proposes a steganalysis feature based on the optimality of predicted MVs with a dimension of one. Firstly, we point out that the motion vector prediction (MVP) of the prediction unit (PU) encoded using the Advanced Motion Vector Prediction (AMVP) technique satisfies the local optimality in the cover video. Secondly, we analyze that in HEVC video, message embedding either using MVP index or motion vector differences (MVD) may destroy the above optimality of MVP. And then, we define the optimal rate of MVP in HEVC video as a steganalysis feature. Finally, we conduct steganalysis detection experiments on two general datasets for three popular steganography methods and compare the performance with four state-of-the-art steganalysis methods. The experimental results show that the proposed optimal rate of MVP for all cover videos is 100\%, while the optimal rate of MVP for all stego videos is less than 100\%. Therefore, the proposed steganography scheme can accurately distinguish between cover videos and stego videos, and it is efficiently applied to practical scenarios with no model training and low computational complexity.
</details>
<details>
<summary>摘要</summary>
在隐藏分析技术中，对高效视频编码标准（HEVC）中的动态 vector domain-based 视频隐藏技术进行检测仍然是一个热点和挑战。为了提高检测性能，本文提出了基于预测动态 vector（MVP）的隐藏特征。首先，我们指出了HEVC视频中的预测单元（PU）使用高级动态 vector prediction（AMVP）技术预测的动态 vector prediction（MVP）满足了本地优化性。其次，我们分析了在HEVC视频中，使用MVP index或动态 vector differences（MVD）进行消息嵌入可能会破坏MVP的优化性。然后，我们定义HEVC视频中的MVP优化率作为隐藏特征。最后，我们对两个通用数据集上三种流行的隐藏方法进行了隐藏检测实验，并与四种现状顶尖隐藏检测方法进行比较。实验结果显示，提议的MVP优化率对所有封装视频是100%，而对所有隐藏视频是less than 100%。因此，提议的隐藏方法可以准确地分辨封装视频和隐藏视频，并且可以应用于实际场景中无模型训练和低计算复杂度。
</details></li>
</ul>
<hr>
<h2 id="Multi-Label-Knowledge-Distillation"><a href="#Multi-Label-Knowledge-Distillation" class="headerlink" title="Multi-Label Knowledge Distillation"></a>Multi-Label Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06453">http://arxiv.org/abs/2308.06453</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/penghui-yang/l2d">https://github.com/penghui-yang/l2d</a></li>
<li>paper_authors: Penghui Yang, Ming-Kun Xie, Chen-Chen Zong, Lei Feng, Gang Niu, Masashi Sugiyama, Sheng-Jun Huang</li>
<li>for: 该 paper 是关于多标签学习的知识储存方法的研究，它针对现有的知识储存方法在多标签学习场景中的局限性，并提出了一种新的多标签知识储存方法。</li>
<li>methods: 该 paper 使用了分类预测器和学生网络，并将知识储存于 label-wise embeddings 中。它还利用了分类预测器的准确率来提高学生网络的分类性能。</li>
<li>results: 实验结果表明，该 paper 的方法可以避免知识冲突现象，并在多个 benchmark 数据集上达到了superior的性能。<details>
<summary>Abstract</summary>
Existing knowledge distillation methods typically work by imparting the knowledge of output logits or intermediate feature maps from the teacher network to the student network, which is very successful in multi-class single-label learning. However, these methods can hardly be extended to the multi-label learning scenario, where each instance is associated with multiple semantic labels, because the prediction probabilities do not sum to one and feature maps of the whole example may ignore minor classes in such a scenario. In this paper, we propose a novel multi-label knowledge distillation method. On one hand, it exploits the informative semantic knowledge from the logits by dividing the multi-label learning problem into a set of binary classification problems; on the other hand, it enhances the distinctiveness of the learned feature representations by leveraging the structural information of label-wise embeddings. Experimental results on multiple benchmark datasets validate that the proposed method can avoid knowledge counteraction among labels, thus achieving superior performance against diverse comparing methods. Our code is available at: https://github.com/penghui-yang/L2D
</details>
<details>
<summary>摘要</summary>
传统的知识填充方法通常是通过将教师网络的输出LOGIT或中间特征图传递给学生网络，这在多类单标学习中非常成功。然而，这些方法几乎无法扩展到多标学习场景，因为预测概率不同类别之间不相加，特征图中涉及到小类时可能被忽略。在这篇论文中，我们提出了一种新的多标知识填充方法。一方面，它利用多标学习问题的分类器的semantic知识，将问题分解成一系列的binary分类问题。另一方面，它利用标签wise嵌入结构来增强学习的特征表示的分化性。我们的实验结果表明，提案的方法可以避免标签之间的知识冲突，从而在多种 comparing方法的比较中达到更高的性能。我们的代码可以在：https://github.com/penghui-yang/L2D 查看。
</details></li>
</ul>
<hr>
<h2 id="Latent-Random-Steps-as-Relaxations-of-Max-Cut-Min-Cut-and-More"><a href="#Latent-Random-Steps-as-Relaxations-of-Max-Cut-Min-Cut-and-More" class="headerlink" title="Latent Random Steps as Relaxations of Max-Cut, Min-Cut, and More"></a>Latent Random Steps as Relaxations of Max-Cut, Min-Cut, and More</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06448">http://arxiv.org/abs/2308.06448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudhanshu Chanpuriya, Cameron Musco</li>
<li>for: 本 paper 是为了探讨图像 clustering 中的缺省结构，并提出了一种基于非正式矩阵分解的 probabilistic 模型，用于统一 clustering 和简化图像。</li>
<li>methods: 本 paper 使用的方法是基于非正式矩阵分解的一种 probabilistic 模型，用于模型图像的结构。该模型通过 Random Walk 过程的 фактор化来实现 clustering 和简化图像的同时进行。</li>
<li>results: 本 paper 的结果表明，使用该方法可以很好地处理具有缺省结构的图像，并且可以很好地处理一些涉及多类别的不约分类任务。<details>
<summary>Abstract</summary>
Algorithms for node clustering typically focus on finding homophilous structure in graphs. That is, they find sets of similar nodes with many edges within, rather than across, the clusters. However, graphs often also exhibit heterophilous structure, as exemplified by (nearly) bipartite and tripartite graphs, where most edges occur across the clusters. Grappling with such structure is typically left to the task of graph simplification. We present a probabilistic model based on non-negative matrix factorization which unifies clustering and simplification, and provides a framework for modeling arbitrary graph structure. Our model is based on factorizing the process of taking a random walk on the graph. It permits an unconstrained parametrization, allowing for optimization via simple gradient descent. By relaxing the hard clustering to a soft clustering, our algorithm relaxes potentially hard clustering problems to a tractable ones. We illustrate our algorithm's capabilities on a synthetic graph, as well as simple unsupervised learning tasks involving bipartite and tripartite clustering of orthographic and phonological data.
</details>
<details>
<summary>摘要</summary>
algorithm для clustering 通常是找到同类结点的结构。即它们在集群内部找到多个边，而不是跨集群。但是图 oftentimes 也具有异类结构，如（几乎）二分图和三分图，其中大多数边在集群之间。对这种结构的处理通常被归入图简化任务。我们提出了一种基于非负矩阵因子化的概率模型，该模型结合了 clustering 和简化，并提供了对任意图结构的模型化框架。我们的模型基于对图进行随机游走的过程的分解。它允许不受限制的参数化，通过简单的梯度下降优化。通过宽松化硬 clustering 到软 clustering，我们的算法将硬 clustering 问题转化为可解决的问题。我们在一个 sintetic 图上以及一些无监督学习任务中应用了我们的算法，包括orthographic 和 phonological 数据的二分和三分 clustering。
</details></li>
</ul>
<hr>
<h2 id="A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing"><a href="#A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing" class="headerlink" title="A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing"></a>A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06447">http://arxiv.org/abs/2308.06447</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miladramzy/sequentialmetatransferpinns">https://github.com/miladramzy/sequentialmetatransferpinns</a></li>
<li>paper_authors: Milad Ramezankhani, Abbas S. Milani</li>
<li>for: 解决非线性偏微分方程（PDE）问题，即使在长时间域内。</li>
<li>methods: 使用 физи学 informed neural networks（PINNs）和sequential meta-transfer（SMT）学习框架。</li>
<li>results: 比传统PINNs更高效地解决复杂系统问题，并且具有更好的适应性。<details>
<summary>Abstract</summary>
Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework decomposes PDE's time domain into smaller time segments to create "easier" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.Through a composites autoclave processing case study, it is shown that SMT is clearly able to enhance the adaptability of PINNs while significantly reducing computational cost, by a factor of 100.
</details>
<details>
<summary>摘要</summary>
physics-informed neural networks (PINNs) 已经在解决非线性偏微分方程 (PDEs) 中获得了广泛应用，通过将物理法则 integrate 到 neural networks 的训练中，使其在科学和工程应用中脱颖而出。然而，传统 PINNs 仍然缺乏对复杂系统的准确描述能力，特别是在长时间领域中。此外，由于 PINNs 是设计来描述特定的 PDE 系统实现，因此缺乏能够快速适应新系统配置的一般化能力。这会导致 computationally expensive re-training from scratch 的问题。为了解决这些不足，这个研究提出了一个新的sequential meta-transfer (SMT) 学习框架，可以提供快速训练和高效适应 PINNs 的解决方案。具体来说，这个框架将 PDE 的时间领域 decomposed 为 smaller time segments，则将每个时间段赋予一个 meta-learner 进行训练，以实现快速适应一系列相关任务的能力。然后，通过将 transfer learning 原则应用到时间intervals，进一步降低 computional cost。通过一个 composite autoclave processing 案例研究，显示了 SMT 能够优化 PINNs 的适应能力，同时大幅降低 computional cost，比例为 100。
</details></li>
</ul>
<hr>
<h2 id="Neural-Latent-Aligner-Cross-trial-Alignment-for-Learning-Representations-of-Complex-Naturalistic-Neural-Data"><a href="#Neural-Latent-Aligner-Cross-trial-Alignment-for-Learning-Representations-of-Complex-Naturalistic-Neural-Data" class="headerlink" title="Neural Latent Aligner: Cross-trial Alignment for Learning Representations of Complex, Naturalistic Neural Data"></a>Neural Latent Aligner: Cross-trial Alignment for Learning Representations of Complex, Naturalistic Neural Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06443">http://arxiv.org/abs/2308.06443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheol Jun Cho, Edward F. Chang, Gopala K. Anumanchipalli</li>
<li>for: 本研究旨在解决神经科学中复杂行为的神经实现问题，即找到真实表示神经数据的方法。</li>
<li>methods: 我们提出了一种新的无监督学习框架，神经幽默对应器（NLA），来找到有效、行为相关的神经表示。该方法通过对重复尝试的表示进行对应来学习交叉尝试中的共同信息。此外，我们还提出了一种完全可导时间扭曲模型（TWM）来解决尝试的时间不同问题。</li>
<li>results: 当应用于自然说话的内部电rocorticography（ECoG）数据时，我们的模型可以更好地表示行为，特别是在更低的维度空间中。TWM被验证了通过测量行为协调性 между对应的尝试。我们的框架比基线模型更好地学习了交叉尝试中的共同表示，并且当Visualized时，替换 manifold 显示了在尝试中共享的神经轨迹。<details>
<summary>Abstract</summary>
Understanding the neural implementation of complex human behaviors is one of the major goals in neuroscience. To this end, it is crucial to find a true representation of the neural data, which is challenging due to the high complexity of behaviors and the low signal-to-ratio (SNR) of the signals. Here, we propose a novel unsupervised learning framework, Neural Latent Aligner (NLA), to find well-constrained, behaviorally relevant neural representations of complex behaviors. The key idea is to align representations across repeated trials to learn cross-trial consistent information. Furthermore, we propose a novel, fully differentiable time warping model (TWM) to resolve the temporal misalignment of trials. When applied to intracranial electrocorticography (ECoG) of natural speaking, our model learns better representations for decoding behaviors than the baseline models, especially in lower dimensional space. The TWM is empirically validated by measuring behavioral coherence between aligned trials. The proposed framework learns more cross-trial consistent representations than the baselines, and when visualized, the manifold reveals shared neural trajectories across trials.
</details>
<details>
<summary>摘要</summary>
The key idea of NLA is to align representations across repeated trials to learn cross-trial consistent information. To achieve this, we propose a novel, fully differentiable time warping model (TWM) to resolve the temporal misalignment of trials. When applied to intracranial electrocorticography (ECoG) of natural speaking, our model learns better representations for decoding behaviors than the baseline models, especially in lower dimensional space.The TWM is empirically validated by measuring behavioral coherence between aligned trials. The proposed framework learns more cross-trial consistent representations than the baselines, and when visualized, the manifold reveals shared neural trajectories across trials.Here is the translation in Simplified Chinese:理解人类复杂行为的神经实现是神经科学的一个主要目标。为了实现这一目标，寻找真实的神经数据表示是非常困难的，因为行为的复杂性和神经信号的噪声比（SNR）都很低。在这里，我们提出了一种新的无监督学习框架——神经潜在适应器（NLA），以找到行为相关的神经表示。NLA的关键思想是将重复尝试的表示进行对齐，以学习跨试验可靠信息。为了实现这一点，我们提出了一种全部可导的时间折叠模型（TWM），以解决试验的时间不同问题。当应用于自然语言说话的电rocorticalography（ECoG）时，我们的模型可以比基eline模型更好地学习行为的表示，特别是在lower dimensional space中。TWM的实验验证了我们的模型可以更好地处理行为听起来的听起来的听起来，并且当Visualize的时候，曾经的折叠 manifold  revelas shared neural trajectories across trials。
</details></li>
</ul>
<hr>
<h2 id="A-Domain-adaptive-Physics-informed-Neural-Network-for-Inverse-Problems-of-Maxwell’s-Equations-in-Heterogeneous-Media"><a href="#A-Domain-adaptive-Physics-informed-Neural-Network-for-Inverse-Problems-of-Maxwell’s-Equations-in-Heterogeneous-Media" class="headerlink" title="A Domain-adaptive Physics-informed Neural Network for Inverse Problems of Maxwell’s Equations in Heterogeneous Media"></a>A Domain-adaptive Physics-informed Neural Network for Inverse Problems of Maxwell’s Equations in Heterogeneous Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06436">http://arxiv.org/abs/2308.06436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyuan Piao, Hong Gu, Aina Wang, Pan Qin</li>
<li>for: 解决Maxwell方程在不同媒质中的逆问题</li>
<li>methods: 使用Physics-informed neural networks (PINNs)和适应域训练策略</li>
<li>results: 在两个案例研究中证明了domain-adaptive PINN的有效性<details>
<summary>Abstract</summary>
Maxwell's equations are a collection of coupled partial differential equations (PDEs) that, together with the Lorentz force law, constitute the basis of classical electromagnetism and electric circuits. Effectively solving Maxwell's equations is crucial in various fields, like electromagnetic scattering and antenna design optimization. Physics-informed neural networks (PINNs) have shown powerful ability in solving PDEs. However, PINNs still struggle to solve Maxwell's equations in heterogeneous media. To this end, we propose a domain-adaptive PINN (da-PINN) to solve inverse problems of Maxwell's equations in heterogeneous media. First, we propose a location parameter of media interface to decompose the whole domain into several sub-domains. Furthermore, the electromagnetic interface conditions are incorporated into a loss function to improve the prediction performance near the interface. Then, we propose a domain-adaptive training strategy for da-PINN. Finally, the effectiveness of da-PINN is verified with two case studies.
</details>
<details>
<summary>摘要</summary>
马克斯威尔方程是一系列联动部分偏微分方程（PDEs），与 Лорен茨力学定律共同组成经典电磁学和电路Circuit。有效解决马克斯威尔方程是许多领域的关键，如电磁散射和天线设计优化。physics-informed neural networks（PINNs）已经表现出解决PDEs的强大能力。然而，PINNs仍然在不同媒体中解决马克斯威尔方程困难。为此，我们提出了域 adaptive PINN（da-PINN）解决Maxwell方程的 inverse problem在不同媒体中。首先，我们提出了媒体界面位置参数，将整个领域分解成多个子领域。然后，我们在损失函数中包含了电磁界面条件，以提高预测性能 near the interface。最后，我们提出了适应域训练策略 для da-PINN。Finally, da-PINN的效果被两个案例验证。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format instead.
</details></li>
</ul>
<hr>
<h2 id="Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration"><a href="#Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration" class="headerlink" title="Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration"></a>Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06432">http://arxiv.org/abs/2308.06432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Zhang, Kun Huang, Mingchao Li, Songtao Yuan, Qiang Chen</li>
<li>for: 这 paper 的目的是预测 age-related macular degeneration (nAMD) 的发展。</li>
<li>methods: 这 paper 使用的方法包括 feature encoder、graph evolution module 和 feature decoder。具体来说，feature encoder 将输入 SD-OCT 图像转换为深度特征，然后 graph evolution module 预测了疾病发展过程在高维 latent space 中，并输出了预测的深度特征。最后，feature decoder 将预测的深度特征转换回 SD-OCT 图像。</li>
<li>results: 这 paper 的结果表明，SHENet 可以生成高质量的预测 SD-OCT 图像，同时保持疾病结构和内容的准确性。 qualitative 评估也表明，SHENet 的生成的 SD-OCT 图像比其他方法更有Visual effect。<details>
<summary>Abstract</summary>
Most of the existing disease prediction methods in the field of medical image processing fall into two classes, namely image-to-category predictions and image-to-parameter predictions. Few works have focused on image-to-image predictions. Different from multi-horizon predictions in other fields, ophthalmologists prefer to show more confidence in single-horizon predictions due to the low tolerance of predictive risk. We propose a single-horizon disease evolution network (SHENet) to predictively generate post-therapeutic SD-OCT images by inputting pre-therapeutic SD-OCT images with neovascular age-related macular degeneration (nAMD). In SHENet, a feature encoder converts the input SD-OCT images to deep features, then a graph evolution module predicts the process of disease evolution in high-dimensional latent space and outputs the predicted deep features, and lastly, feature decoder recovers the predicted deep features to SD-OCT images. We further propose an evolution reinforcement module to ensure the effectiveness of disease evolution learning and obtain realistic SD-OCT images by adversarial training. SHENet is validated on 383 SD-OCT cubes of 22 nAMD patients based on three well-designed schemes based on the quantitative and qualitative evaluations. Compared with other generative methods, the generative SD-OCT images of SHENet have the highest image quality. Besides, SHENet achieves the best structure protection and content prediction. Qualitative evaluations also demonstrate that SHENet has a better visual effect than other methods. SHENet can generate post-therapeutic SD-OCT images with both high prediction performance and good image quality, which has great potential to help ophthalmologists forecast the therapeutic effect of nAMD.
</details>
<details>
<summary>摘要</summary>
大多数现有的疾病预测方法在医学图像处理领域都属于两类，即图像到类别预测和图像到参数预测。只有少数作品强调图像到图像预测。与其他多个 horizons 预测不同，眼科医生更偏向于在单个 horizons 上展示更高的预测信任度，这是因为眼科疾病风险预测的偏好。我们提出了单个 horizon 疾病进化网络（SHENet），用于预测基于前治疗 SD-OCT 图像的后治疗 SD-OCT 图像。在 SHENet 中，一个特征编码器将输入 SD-OCT 图像转换为深度特征，然后一个图像进化模块预测疾病进化的过程在高维latent空间中，并输出预测的深度特征。最后，特征解码器将预测的深度特征恢复为 SD-OCT 图像。我们还提出了进化权威模块，以确保疾病进化学习的效果和获得实际的 SD-OCT 图像。SHENet 在 383 个 SD-OCT 立方体上基于三种良好的方案进行验证，并通过量化和质量评价来评估其效果。与其他生成方法相比，SHENet 生成的 SD-OCT 图像的生成质量最高。此外，SHENet 还实现了最好的结构保护和内容预测。质量评价还表明，SHENet 的视觉效果比其他方法更好。SHENet 可以生成具有高预测性和好的图像质量的后治疗 SD-OCT 图像，这有很大的潜在价值，可以帮助眼科医生预测 nAMD 的治疗效果。
</details></li>
</ul>
<hr>
<h2 id="Genetic-heterogeneity-analysis-using-genetic-algorithm-and-network-science"><a href="#Genetic-heterogeneity-analysis-using-genetic-algorithm-and-network-science" class="headerlink" title="Genetic heterogeneity analysis using genetic algorithm and network science"></a>Genetic heterogeneity analysis using genetic algorithm and network science</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06429">http://arxiv.org/abs/2308.06429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhendong Sha, Yuanzhu Chen, Ting Hu</li>
<li>For: This paper is written to address the challenges of identifying disease susceptible genetic variables using genome-wide association studies (GWAS) due to genetic heterogeneity and feature interactions.* Methods: The paper introduces a novel feature selection mechanism for GWAS called Feature Co-selection Network (FCSNet), which extracts heterogeneous subsets of genetic variables from a network constructed from multiple independent feature selection runs based on a genetic algorithm (GA) and a non-linear machine learning algorithm to detect feature interactions.* Results: The paper shows the effectiveness of the utilized GA-based feature selection method in identifying feature interactions through synthetic data analysis, and applies the novel approach to a case-control colorectal cancer GWAS dataset, resulting in synthetic features that explain the genetic heterogeneity in an additional case-only GWAS dataset.Here’s the simplified Chinese version of the three key points:* For: 这篇论文是为了解决基因组宽协调研究（GWAS）中疾病抵触性基因变量的难题，因为基因多样性和特征交互。* Methods: 论文提出了一种新的特征选择机制，即特征共选网络（FCSNet），它从多个独立的特征选择跑程中提取了多种不同的基因变量，并使用一种进化学习算法（GA）和一种非线性机器学习算法来检测特征交互。* Results: 论文通过synthetic数据分析表明了GA基于的特征选择方法的效果，并应用了这种新方法到一个case-control大肠癌GWAS数据集中，得到了解释基因多样性的Synthetic特征。<details>
<summary>Abstract</summary>
Through genome-wide association studies (GWAS), disease susceptible genetic variables can be identified by comparing the genetic data of individuals with and without a specific disease. However, the discovery of these associations poses a significant challenge due to genetic heterogeneity and feature interactions. Genetic variables intertwined with these effects often exhibit lower effect-size, and thus can be difficult to be detected using machine learning feature selection methods. To address these challenges, this paper introduces a novel feature selection mechanism for GWAS, named Feature Co-selection Network (FCSNet). FCS-Net is designed to extract heterogeneous subsets of genetic variables from a network constructed from multiple independent feature selection runs based on a genetic algorithm (GA), an evolutionary learning algorithm. We employ a non-linear machine learning algorithm to detect feature interaction. We introduce the Community Risk Score (CRS), a synthetic feature designed to quantify the collective disease association of each variable subset. Our experiment showcases the effectiveness of the utilized GA-based feature selection method in identifying feature interactions through synthetic data analysis. Furthermore, we apply our novel approach to a case-control colorectal cancer GWAS dataset. The resulting synthetic features are then used to explain the genetic heterogeneity in an additional case-only GWAS dataset.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:通过全 genomic协同asso ciation研究 (GWAS)，可以通过比较患病者和无病者的基因数据来确定疾病抵触性的基因变量。然而，发现这些相互作用具有一定的挑战，因为基因多样性和特征互动。基因变量与这些效应相互作用的情况经常表现出较低的效果大小，因此可能会难以通过机器学习特征选择方法探测。为解决这些挑战，本文提出了一种新的特征选择机制，名为特征合选网络 (FCSNet)。FCS-Net 是基于多个独立的特征选择跑目的基因算法 (GA) 构建的网络，并使用一种非线性机器学习算法探测特征互动。我们还引入了一个社区风险分数 (CRS)，用于量化每个变量subset 的疾病相关度。我们的实验表明，使用我们提出的 GA 基因选择方法可以通过 sintetic 数据分析来识别特征互动。此外，我们还应用了我们的新方法到一个 case-control 大陆癌 GWAS 数据集。得到的 sintetic 特征后来用于解释一个额外的 case-only GWAS 数据集中的基因多样性。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Learnability-Does-Not-Imply-Sample-Compression"><a href="#Multiclass-Learnability-Does-Not-Imply-Sample-Compression" class="headerlink" title="Multiclass Learnability Does Not Imply Sample Compression"></a>Multiclass Learnability Does Not Imply Sample Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06424">http://arxiv.org/abs/2308.06424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chirag Pabbaraju</li>
<li>for: 本研究证明了一个假设集合可以 admit 一种样本压缩 schemes，即对于每个样本被标注为来自该假设集合中的某个假设，只需保留一小样本，可以推断出整个样本的标签。</li>
<li>methods: 本研究使用了learnable binary hypothesis class 和 multiclass hypothesis class，以及其们的VC dimension 和 DS dimension。</li>
<li>results: 本研究发现，learnable binary hypothesis class 总是可以 admit 一种样本压缩 schemes，但是 learnable multiclass hypothesis class 则不一定可以 admit 样本压缩 schemes，即不一定可以通过保留一小样本来推断出整个样本的标签。<details>
<summary>Abstract</summary>
A hypothesis class admits a sample compression scheme, if for every sample labeled by a hypothesis from the class, it is possible to retain only a small subsample, using which the labels on the entire sample can be inferred. The size of the compression scheme is an upper bound on the size of the subsample produced. Every learnable binary hypothesis class (which must necessarily have finite VC dimension) admits a sample compression scheme of size only a finite function of its VC dimension, independent of the sample size. For multiclass hypothesis classes, the analog of VC dimension is the DS dimension. We show that the analogous statement pertaining to sample compression is not true for multiclass hypothesis classes: every learnable multiclass hypothesis class, which must necessarily have finite DS dimension, does not admit a sample compression scheme of size only a finite function of its DS dimension.
</details>
<details>
<summary>摘要</summary>
一个假设集合满足样本压缩方案，如果每个样本被标注为从集合中的假设，那么只需保留一小样本，使得整个样本上的标签可以被推断出。压缩方案的大小是样本上的子样本的上界。每个可学习的二进制假设集合（必然具有有限VC维度）总是具有一个只具有有限函数与样本大小无关的压缩方案。对多类假设集合，相应的VC维度的概念是DS维度。我们显示了，相应的假设集合不是真的：每个可学习的多类假设集合，必然具有有限DS维度，但并不总是具有只具有有限函数与DS维度无关的压缩方案。
</details></li>
</ul>
<hr>
<h2 id="Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation"><a href="#Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation" class="headerlink" title="Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation"></a>Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06422">http://arxiv.org/abs/2308.06422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedarmin Azizi, Mahdi Nazemi, Arash Fayyazi, Massoud Pedram</li>
<li>for: 这个研究旨在提高深度学习模型的设计优化，以提高模型的效率。</li>
<li>methods: 本研究使用了一种新的搜寻机制，可以自动选择个别神经网络层的最佳位元和层宽。这些搜寻机制利用了希腊数-基于的删除，以确保删除不必要的参数。然后，我们使用了一种基于对应的树结构的Parzen估计器，以建立优化的对应模型。</li>
<li>results: 我们的方法在知名的数据集上进行了严谨的测试，与现有的方法相比， recording an impressive 20% decrease in model size without compromising accuracy. In addition, our method boasts a 12x reduction in search time relative to the best search-focused strategies currently available.<details>
<summary>Abstract</summary>
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 20% decrease in model size without compromising accuracy. Additionally, our method boasts a 12x reduction in search time relative to the best search-focused strategies currently available. As a result, our proposed method represents a leap forward in neural network design optimization, paving the way for quick model design and implementation in settings with limited resources, thereby propelling the potential of scalable deep learning solutions.
</details>
<details>
<summary>摘要</summary>
深度学习模型的复杂性和计算需求逐渐增长，因此选择最佳的神经网络层宽和批处理层宽成为了至关重要的一环。这项工作提出了一种新的搜索机制，可以自动选择具有最佳性能的神经网络层宽和批处理层宽。通过利用层次结构的Parzen估计器来构建封闭的搜索空间，我们可以快速地探索不同的建筑方案，并快速地找到最佳的设计。我们通过对知名数据集进行严格的测试，证明了我们的方法与现有方法相比，可以减少模型大小20%，同时保持准确性。此外，我们的方法可以减少搜索时间12倍，相比于目前最佳的搜索焦点策略。因此，我们的提议方法 represents a significant advance in neural network design optimization, paving the way for rapid model design and implementation in resource-constrained settings, and thereby accelerating the potential of scalable deep learning solutions.
</details></li>
</ul>
<hr>
<h2 id="Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review"><a href="#Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review" class="headerlink" title="Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review"></a>Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06419">http://arxiv.org/abs/2308.06419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: 本研究旨在提供一种实用的行人轨迹预测算法，用于自动驾驶车辆（AV）在与行人共同使用的空间中规划路径。</li>
<li>methods: 本文系统性地查询了在文献中提出的不同方法，用于模拟行人轨迹预测在交通工具存在下。文中还详细讨论了与交通工具交互对行人未来动向的影响，以及不同变量如预测不确定性和行为差异如何在先前提出的预测模型中被考虑。</li>
<li>results: 文中提出了1260个唯一的同行评审文章，从ACM数字图书馆、IEEE Xplore和Scopus数据库中搜索到。64篇文章符合包含和排除条件，因此被包含在最终审查中。文中还提供了各种轨迹数据集的概述，包括行人和交通工具的轨迹数据。文中还讨论了未来研究中的潜在漏洞和方向，如更有效的交互代理在深度学习方法中定义，以及更多的混合交通环境中的数据采集。<details>
<summary>Abstract</summary>
Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments are discussed.
</details>
<details>
<summary>摘要</summary>
планирование пути автономного транспортного средства (АВ) в пространстве, где присутствуют пешеходы, требует рассмотрения предполагаемых траекторий пешеходов в будущем. практический алгоритм предсказания траекторий пешеходов для использования АВов в неструктурированных средах должен учитывать влияние взаимодействия автомобиля с пешеходами на будущие движения пешеходов. в этом смысле, эта статья систематически обзорывает разные методы, предложенные в литературе для моделирования предсказания траекторий пешеходов в присутствии автомобилей, которые могут быть применены в неструктурированных средах. эта статья также рассматривает конкретные аспекты взаимодействия пешехода-автомобиль (в сравнении с взаимодействием пешеходов-пешеходов) и обсуждает, как различные переменные, такие как неопределенности предсказаний и различия в поведении, учитываются в предыдущих моделях предсказания. following PRISMA guidelines, articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. a total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. an overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments, are discussed.
</details></li>
</ul>
<hr>
<h2 id="Learning-Bayesian-Networks-with-Heterogeneous-Agronomic-Data-Sets-via-Mixed-Effect-Models-and-Hierarchical-Clustering"><a href="#Learning-Bayesian-Networks-with-Heterogeneous-Agronomic-Data-Sets-via-Mixed-Effect-Models-and-Hierarchical-Clustering" class="headerlink" title="Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering"></a>Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06399">http://arxiv.org/abs/2308.06399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Vallegi, Marco Scutari, Federico Mattia Stefanini</li>
<li>for:  agronomic studies, handling hierarchical data with complex networks of causal relationships</li>
<li>methods:  Bayesian networks (BNs) with integrated random effects, based on linear mixed-effects models</li>
<li>results:  enhanced structural learning, discovery of new connections, improved model specification, reduction in prediction errors from 28% to 17%<details>
<summary>Abstract</summary>
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.   Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery of new connections and the improvement of improved model specification. Furthermore, we observe a reduction in prediction errors from 28\% to 17\%. By extending the applicability of BNs to complex data set structures, this approach contributes to the effective utilisation of BNs for hierarchical agronomic data. This, in turn, enhances their value as decision-support tools in the field.
</details>
<details>
<summary>摘要</summary>
研究涉及多元相关数据集，其中covariates和结果变量之间存在关系的现象，在各个领域，如农学研究，非常普遍。在这些情况下，层次模型，也称为多级模型，经常被使用，以融合不同数据集的信息，同时适应它们的特点。然而，这些结构超出了简单的不同性，因为变量经常形成复杂的 causal 关系网络。� Bayesian networks（BNs）提供了一个强大的模型化这些关系的框架，使用导向的无环图来示出变量之间的连接。本研究提出了一种新的方法，将随机效应 integrate into BN 学习。基于线性混合效应模型，这种方法特别适用于处理层次数据。实际 agronomic 试验结果表明，通过使用这种方法，可以提高结构学习，发现新的连接，并提高模型规定的精度。此外，我们发现预测错误率从28%降至17%。通过扩展 BNs 的应用范围，使其能够更好地处理复杂数据集结构，这种方法增加了 BNs 作为决策支持工具的价值。
</details></li>
</ul>
<hr>
<h2 id="Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models"><a href="#Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models" class="headerlink" title="Detecting and Preventing Hallucinations in Large Vision Language Models"></a>Detecting and Preventing Hallucinations in Large Vision Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06394">http://arxiv.org/abs/2308.06394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anisha Gunjal, Jihan Yin, Erhan Bas<br>for:The paper aims to address the issue of hallucinations in instruction-tuned large vision language models (LVLMs) for visual question answering (VQA).methods:The authors introduce a new dataset called M-HalDetect, which is a multi-modal hallucination detection dataset for detailed image descriptions. They also propose a novel optimization method called Fine-grained Direct Preference Optimization (FDPO) to reduce hallucinations in LVLMs.results:The authors evaluate the effectiveness of M-HalDetect and FDPO on several state-of-the-art LVLMs, including InstructBLIP, LLaVA, and mPLUG-OWL. They find that M-HalDetect can reduce hallucination rates in InstructBLIP by 41%, and FDPO can reduce hallucination rates by 55%. Additionally, they find that their reward model generalizes well to other multi-modal models and has a strong correlation with human evaluated accuracy scores.<details>
<summary>Abstract</summary>
Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a (M)ultimodal (Hal)lucination (Detect)ion Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling. We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores.
</details>
<details>
<summary>摘要</summary>
现代化的启示抽象语言模型（LVLM）在多模态任务上进行总结的能力已经得到了显著提高，尤其是在视觉问答（VQA）领域。然而，使模型生成具有详细Visualgrounding的回答仍然是一个挑战。我们发现，even the current state-of-the-art LVLMs（InstructBLIP）仍然包含了30%的虚假文本，包括不存在的物体、不准确的描述和关系。为解决这个问题，我们介绍了M-HalDetect，一个多模态虚假检测 dataset，可以用于训练和测试模型，以避免虚假检测。M-HalDetect包含16k细致的VQA例子，使其成为了首个多模态虚假检测 dataset。与前一代研究只考虑对象虚假，我们还注释了不准确的实体描述和关系。为证明M-HalDetect的潜在性，我们通过我们的新的精细直接偏好优化（FDPO）来优化InstructBLIP。我们还通过多模态 reward models来训练精细的多模态奖励模型，并通过best-of-n拒绝采样来评估其效果。我们对FDPO和拒绝采样进行了人工评估，并发现它们可以降低InstructBLIP中的虚假率 by 41%和55%。此外，我们发现我们的奖励模型可以泛化到其他多模态模型，降低LLaVA和mPLUG-OWL中的虚假率 by 15%和57%，并与人类评估准确率有强相关性。
</details></li>
</ul>
<hr>
<h2 id="Phoneme-Hallucinator-One-shot-Voice-Conversion-via-Set-Expansion"><a href="#Phoneme-Hallucinator-One-shot-Voice-Conversion-via-Set-Expansion" class="headerlink" title="Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion"></a>Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06382">http://arxiv.org/abs/2308.06382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PhonemeHallucinator/Phoneme_Hallucinator">https://github.com/PhonemeHallucinator/Phoneme_Hallucinator</a></li>
<li>paper_authors: Siyuan Shan, Yang Li, Amartya Banerjee, Junier B. Oliva</li>
<li>for: 这篇论文的目的是提出一种新的语音变换技术，以提高语音变换的Intelligibility和Speaker Similarity。</li>
<li>methods: 这篇论文使用了一种新的模型，即“Phoneme Hallucinator”，可以基于短时间内的目标说话人声音（例如3秒）生成多样化和高质量的目标说话人音频。</li>
<li>results: 对比于现有的语音变换方法，“Phoneme Hallucinator”在Intelligibility和Speaker Similarity两个指标上均表现出色，并且不需要文本标注和支持任意转换。<details>
<summary>Abstract</summary>
Voice conversion (VC) aims at altering a person's voice to make it sound similar to the voice of another person while preserving linguistic content. Existing methods suffer from a dilemma between content intelligibility and speaker similarity; i.e., methods with higher intelligibility usually have a lower speaker similarity, while methods with higher speaker similarity usually require plenty of target speaker voice data to achieve high intelligibility. In this work, we propose a novel method \textit{Phoneme Hallucinator} that achieves the best of both worlds. Phoneme Hallucinator is a one-shot VC model; it adopts a novel model to hallucinate diversified and high-fidelity target speaker phonemes based just on a short target speaker voice (e.g. 3 seconds). The hallucinated phonemes are then exploited to perform neighbor-based voice conversion. Our model is a text-free, any-to-any VC model that requires no text annotations and supports conversion to any unseen speaker. Objective and subjective evaluations show that \textit{Phoneme Hallucinator} outperforms existing VC methods for both intelligibility and speaker similarity.
</details>
<details>
<summary>摘要</summary>
声音转换（VC）目标是使一个人的声音与另一个人的声音相似，同时保持语言内容的正确性。现有的方法受到一种权衡问题：即具有更高的智能可读性通常具有较低的说话人类似性，而具有更高的说话人类似性通常需要大量的目标说话人声音数据来实现高度的智能可读性。在这项工作中，我们提出了一种新的方法——《phoneme hallucinator》。这是一个一枚VC模型，它采用了一种新的模型来幻化具有多样性和高精度的目标说话人声音，基于短时间内的目标说话人声音（例如3秒）。这些幻化的声音然后被利用来进行邻居基于的声音转换。我们的模型是文本 libre，任何到任何的VC模型，不需要文本注释，并且支持转换到任何未看过的说话人。对象和主观评估表明，《phoneme hallucinator》比既有VC方法更高的智能可读性和说话人类似性。
</details></li>
</ul>
<hr>
<h2 id="DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System"><a href="#DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System" class="headerlink" title="DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System"></a>DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06378">http://arxiv.org/abs/2308.06378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojtaba Yeganejou, Kimia Honari, Ryan Kluzinski, Scott Dick, Michael Lipsett, James Miller</li>
<li>for: 提高可解释人工智能中的透明度和准确性之间的负面选择。</li>
<li>methods: 使用深度神经网络和规则引擎结合深度学习模型，设计了一种新的深度征函数逻辑决策系统（DCNFIS），并证明DCNFIS可以与现有的卷积神经网络相比，在四个常见的数据集上达到相同的准确性。</li>
<li>results: DCNFIS可以在Fashion-MNIST数据集上生成saliency map，并且对这些解释进行了进一步的研究。<details>
<summary>Abstract</summary>
A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在可解释人工智能中是论文知名的质量和可读性之间的贸易。我们报告了一种新的深度网络的设计，该网络可以提高可读性而不 sacrificing 精度。我们设计了一种深度卷积神经推理系统（DCNFIS），通过将神经网络和推理逻辑模型相结合，并证明 DCNFIS 与三种现有的卷积神经网络在四个常见数据集上的性能相同。此外，我们还证明 DCNFIS 在深度推理系统中表现更好。然后，我们利用推理逻辑的可读性，从 DCNFIS 中提取出解释，以干扰 maps 的形式。我们对 Fashion-MNIST 数据集进行更深入的调查，以explore 这些解释的性质。
</details></li>
</ul>
<hr>
<h2 id="UAMM-UBET-Automated-Market-Maker"><a href="#UAMM-UBET-Automated-Market-Maker" class="headerlink" title="UAMM: UBET Automated Market Maker"></a>UAMM: UBET Automated Market Maker</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06375">http://arxiv.org/abs/2308.06375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Jiwoong Im, Alexander Kondratskiy, Vincent Harvey, Hsuan-Wei Fu</li>
<li>for: 这篇论文是为了解决传统自适应市场制定价机制（AMM）的局限性，提出了一种新的价格计算方法——UBET AMM（UAMM）。</li>
<li>methods: UAMM使用外部市场价格和流动性池的不稳定损失来计算价格，并保持愿意产品曲线的定量性。关键元素是根据目标均衡来确定合适的滑动量，以避免流动性池的不稳定损失。</li>
<li>results: 我们的方法可以在有效的外部市场价格下消除投资机会。<details>
<summary>Abstract</summary>
Automated market makers (AMMs) are pricing mechanisms utilized by decentralized exchanges (DEX). Traditional AMM approaches are constrained by pricing solely based on their own liquidity pool, without consideration of external markets or risk management for liquidity providers. In this paper, we propose a new approach known as UBET AMM (UAMM), which calculates prices by considering external market prices and the impermanent loss of the liquidity pool. Despite relying on external market prices, our method maintains the desired properties of a constant product curve when computing slippages. The key element of UAMM is determining the appropriate slippage amount based on the desired target balance, which encourages the liquidity pool to minimize impermanent loss. We demonstrate that our approach eliminates arbitrage opportunities when external market prices are efficient.
</details>
<details>
<summary>摘要</summary>
自动化市场制造机制（AMM）是分布式交易所（DEX）中使用的价格计算机制。传统的 AMM 方法受限于基于自己的流动性池价格计算，不考虑外部市场或流动性提供者风险管理。在这篇论文中，我们提出了一种新的方法，称为 UBET AMM（UAMM），它根据外部市场价格和流动性池的不稳定损失计算价格。尽管依赖于外部市场价格，我们的方法保持了恒定的产品曲线的属性，当计算滑块时。UBET AMM 的关键元素是确定合适的滑块量，以达到目标均衡。这种办法鼓励流动性池减少不稳定损失。我们示出，当外部市场价格高效时，我们的方法可以消除投资机会。
</details></li>
</ul>
<hr>
<h2 id="Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems"><a href="#Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems" class="headerlink" title="Topic-Level Bayesian Surprise and Serendipity for Recommender Systems"></a>Topic-Level Bayesian Surprise and Serendipity for Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06368">http://arxiv.org/abs/2308.06368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ton-moy/surprise-and-serendipity">https://github.com/ton-moy/surprise-and-serendipity</a></li>
<li>paper_authors: Tonmoy Hasan, Razvan Bunescu<br>for: This paper aims to mitigate the filter bubble problem in recommender systems by incorporating serendipity into the recommendation process.methods: The paper proposes a content-based formulation of serendipity that is rooted in Bayesian surprise, and uses this formulation to measure the serendipity of items after they are consumed and rated by the user. The paper also introduces a collaborative-filtering component that identifies similar users.results: The experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.<details>
<summary>Abstract</summary>
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 books read by 4 users in terms of their time-dependent, topic-level surprise. Experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.
</details>
<details>
<summary>摘要</summary>
一个推荐系统可以将推荐项目单独根据用户的项目点击历史进行最佳化，从而创建一个范本径（filter bubble），使用户不会获得来自新、未见类别的项目。为了解决这个问题，我们可以推荐项目具有高度的意外性，即让用户惊喜的项目，这些项目很可能会获得高度的评价。在这篇论文中，我们提出了一个基于 bayesian 的内容基式，用于衡量项目的意外性，并且与协同推荐 ком成组件相结合，从而为用户提供意外性高的项目推荐。为了促进项目级模型的surprise和serendipity的评估，我们创建了一个基于goodreads的阅读历史数据集，包含26,000名用户和1,300,000本书，并 manually annotate 449本书，其中4名用户在不同的时间点阅读这些书籍。实验结果显示，使用 bayesian  surprise 可以与距离基于的规律更好地与手动标注的题目级surprise相对较好，并且也可以获得更好的意外性项目推荐性能。
</details></li>
</ul>
<hr>
<h2 id="Learning-Distributions-via-Monte-Carlo-Marginalization"><a href="#Learning-Distributions-via-Monte-Carlo-Marginalization" class="headerlink" title="Learning Distributions via Monte-Carlo Marginalization"></a>Learning Distributions via Monte-Carlo Marginalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06352">http://arxiv.org/abs/2308.06352</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenqiu Zhao, Guanfang Dong, Anup Basu</li>
<li>for: 学习难以求解的分布。</li>
<li>methods: 使用参数化分布模型（如混合型分布）来 aproximate 难以求解的分布，并使用 Monte-Carlo Marginalization 和 Kernel Density Estimation 解决计算复杂性和优化过程不可导的问题。</li>
<li>results: 提出了一种可以学习复杂分布的方法，该方法可以替代变量推理（VAE），并在标准数据集和 sintetic 数据上进行了实验，证明了该方法的效果。<details>
<summary>Abstract</summary>
We propose a novel method to learn intractable distributions from their samples. The main idea is to use a parametric distribution model, such as a Gaussian Mixture Model (GMM), to approximate intractable distributions by minimizing the KL-divergence. Based on this idea, there are two challenges that need to be addressed. First, the computational complexity of KL-divergence is unacceptable when the dimensions of distributions increases. The Monte-Carlo Marginalization (MCMarg) is proposed to address this issue. The second challenge is the differentiability of the optimization process, since the target distribution is intractable. We handle this problem by using Kernel Density Estimation (KDE). The proposed approach is a powerful tool to learn complex distributions and the entire process is differentiable. Thus, it can be a better substitute of the variational inference in variational auto-encoders (VAE). One strong evidence of the benefit of our method is that the distributions learned by the proposed approach can generate better images even based on a pre-trained VAE's decoder. Based on this point, we devise a distribution learning auto-encoder which is better than VAE under the same network architecture. Experiments on standard dataset and synthetic data demonstrate the efficiency of the proposed approach.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于从样本中学习不可解 Distribution。主要想法是使用参数化分布模型，如 Gaussian Mixture Model（GMM），来近似不可解 Distribution，并且通过最小化KL-分布来实现。然而，存在两个挑战：首先，在分布维度增加时，KL-分布的计算复杂度过高；其次，目标分布是不可导的，因此Optimization过程中的导数不存在。我们解决了这两个问题，使用Monte-Carlo Marginalization（MCMarg）和Kernel Density Estimation（KDE）。我们的方法可以学习复杂的分布，整个过程都是导数可导的，因此可以作为VAE中的更好的替补。我们的方法可以在标准数据集和synthetic数据上实现，并且在具有相同网络架构下，我们设计了一个更好的分布学习自动编码器，比VAE更好。Note: Please note that the translation is in Simplified Chinese, and some words or phrases may have been translated differently in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Mirror-Diffusion-Models"><a href="#Mirror-Diffusion-Models" class="headerlink" title="Mirror Diffusion Models"></a>Mirror Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06342">http://arxiv.org/abs/2308.06342</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cran/DIMORA">https://github.com/cran/DIMORA</a></li>
<li>paper_authors: Jaesung Tae</li>
<li>for: 本研究旨在应用扩散模型到分类数据领域，并提出了一种基于镜像Langevin算法的受限采样问题的理论框架。</li>
<li>methods: 本文提出了一种基于镜像扩散模型的受限采样算法，并在简单的顺序扩散问题上进行了实验 validate。</li>
<li>results: 研究表明，镜像扩散模型在受限采样问题上具有良好的性能，并且可以在各种流行的领域，如图像和文本生成等，进行自然的扩展。<details>
<summary>Abstract</summary>
Diffusion models have successfully been applied to generative tasks in various continuous domains. However, applying diffusion to discrete categorical data remains a non-trivial task. Moreover, generation in continuous domains often requires clipping in practice, which motivates the need for a theoretical framework for adapting diffusion to constrained domains. Inspired by the mirror Langevin algorithm for the constrained sampling problem, in this theoretical report we propose Mirror Diffusion Models (MDMs). We demonstrate MDMs in the context of simplex diffusion and propose natural extensions to popular domains such as image and text generation.
</details>
<details>
<summary>摘要</summary>
Diffusion models have successfully been applied to generative tasks in various continuous domains. However, applying diffusion to discrete categorical data remains a non-trivial task. Moreover, generation in continuous domains often requires clipping in practice, which motivates the need for a theoretical framework for adapting diffusion to constrained domains. Inspired by the mirror Langevin algorithm for the constrained sampling problem, in this theoretical report we propose Mirror Diffusion Models (MDMs). We demonstrate MDMs in the context of simplex diffusion and propose natural extensions to popular domains such as image and text generation.Here's the translation in Simplified Chinese:diffusion模型在各种连续领域中已经成功应用于生成任务。然而，将diffusion应用于分类数据仍然是一个非常困难的任务。此外，在连续领域中的生成通常需要剪辑在实践中，这引发了需要适应受限的领域的理论框架。以mirror langevin算法为 inspirations，在这份理论报告中我们提出了镜像扩散模型（MDM）。我们在简单领域中示例了MDM，并提出了自然的扩展到流行的领域，如图像和文本生成。
</details></li>
</ul>
<hr>
<h2 id="Size-Lowerbounds-for-Deep-Operator-Networks"><a href="#Size-Lowerbounds-for-Deep-Operator-Networks" class="headerlink" title="Size Lowerbounds for Deep Operator Networks"></a>Size Lowerbounds for Deep Operator Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06338">http://arxiv.org/abs/2308.06338</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anirbit Mukherjee, Amartya Roy</li>
<li>for: 本研究目的是为了确定深度运算网络（DeepONet）解决杂项问题所需的数据大小下限。</li>
<li>methods: 本研究使用了数据依赖的下界来证明深度运算网络需要一定的数据大小来实现低训练错误。特别是，我们证明在$n$个数据点上获得低训练错误需要通过增加分支网络和主干网络的公共输出维度的扩展。</li>
<li>results: 我们通过实验示例，表明在固定模型大小下，通过增加公共输出维度，可以实现 monotonic 下降的训练错误。此外，我们还发现，随着数据大小的增加，训练错误会 quadratic 下降。<details>
<summary>Abstract</summary>
Deep Operator Networks are an increasingly popular paradigm for solving regression in infinite dimensions and hence solve families of PDEs in one shot. In this work, we aim to establish a first-of-its-kind data-dependent lowerbound on the size of DeepONets required for them to be able to reduce empirical error on noisy data. In particular, we show that for low training errors to be obtained on $n$ data points it is necessary that the common output dimension of the branch and the trunk net be scaling as $\Omega \left ( {\sqrt{n}} \right )$. This inspires our experiments with DeepONets solving the advection-diffusion-reaction PDE, where we demonstrate the possibility that at a fixed model size, to leverage increase in this common output dimension and get monotonic lowering of training error, the size of the training data might necessarily need to scale quadratically with it.
</details>
<details>
<summary>摘要</summary>
深度运算网络（DeepONet）是一种越来越受欢迎的方法，用于解决无穷维度上的回归问题，并且可以一步解决多个偏微分方程（PDE）。在这项工作中，我们想要建立一个数据依赖的下界，以确定深度运算网络的大小是否足够减少噪声数据上的实际错误。我们显示，为了在 $n$ 个数据点上获得低训练错误， THENET 的通用输出维度和树网络的输出维度必须Scaling as $\Omega \left ( \sqrt{n} \right )$.这种情况 inspirits我们对 DeepONet 解决扩散吸引反应PDE的实验，我们示出，随着模型大小不变，通过增加common output维度，在fixed模型大小下，可以实现 monotonic 下降的训练错误。这意味着，在训练数据规模增加时，可能需要随着common output维度的增加，来降低训练错误。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector"><a href="#Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector" class="headerlink" title="Foundation Model is Efficient Multimodal Multitask Model Selector"></a>Foundation Model is Efficient Multimodal Multitask Model Selector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06262">http://arxiv.org/abs/2308.06262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/multitask-model-selector">https://github.com/opengvlab/multitask-model-selector</a></li>
<li>paper_authors: Fanqing Meng, Wenqi Shao, Zhanglin Peng, Chonghe Jiang, Kaipeng Zhang, Yu Qiao, Ping Luo<br>for:This paper addresses an under-explored problem in the field of multi-modal multi-task learning: predicting the performance of pre-trained neural networks on various tasks without fine-tuning them.methods:The proposed method, called EMMS (Efficient Multi-task Model Selector), employs large-scale foundation models to transform diverse label formats into a unified noisy label embedding, and uses a simple weighted linear regression to estimate a model’s transferability.results:EMMS achieves significant performance gains (9.0%, 26.3%, 20.1%, 54.8%, 12.2%) and speedup (5.13x, 6.29x, 3.59x, 6.19x, 5.66x) compared to the state-of-the-art method LogME, while being fast and effective for assessing the transferability of pre-trained models in a multi-task scenario.<details>
<summary>Abstract</summary>
This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering. A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability,they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee. Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models, making it the first model selection method in the multi-task scenario. For instance, compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves 9.0\%, 26.3\%, 20.1\%, 54.8\%, 12.2\% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, while bringing 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose an efficient multi-task model selector (EMMS), which uses large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS estimates a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee.Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models. Compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves a 9.0%, 26.3%, 20.1%, 54.8%, and 12.2% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, respectively, while bringing a 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Resilience-with-Neural-Networks"><a href="#Predicting-Resilience-with-Neural-Networks" class="headerlink" title="Predicting Resilience with Neural Networks"></a>Predicting Resilience with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06309">http://arxiv.org/abs/2308.06309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karen da Mata, Priscila Silva, Lance Fiondella</li>
<li>for: 这个论文探讨了系统能够抵抗破坏性事件的能力，并应用于多个领域。</li>
<li>methods: 该论文提出了三种人工神经网络（ANN）方法，包括 искусственный神经网络（ANN）、循环神经网络（RNN）和长短期记忆神经网络（LSTM），用于模拟和预测系统性能，包括负因素和正因素对系统抵抗力的影响。</li>
<li>results: 研究结果显示，人工神经网络模型在所有评价指标上都超过了传统模型，特别是LSTM模型的可变R平方和预测误差分别下降了34倍和60%以上。这些结果表明，人工神经网络模型可能在许多重要领域中找到实际应用。<details>
<summary>Abstract</summary>
Resilience engineering studies the ability of a system to survive and recover from disruptive events, which finds applications in several domains. Most studies emphasize resilience metrics to quantify system performance, whereas recent studies propose statistical modeling approaches to project system recovery time after degradation. Moreover, past studies are either performed on data after recovering or limited to idealized trends. Therefore, this paper proposes three alternative neural network (NN) approaches including (i) Artificial Neural Networks, (ii) Recurrent Neural Networks, and (iii) Long-Short Term Memory (LSTM) to model and predict system performance, including negative and positive factors driving resilience to quantify the impact of disruptive events and restorative activities. Goodness-of-fit measures are computed to evaluate the models and compared with a classical statistical model, including mean squared error and adjusted R squared. Our results indicate that NN models outperformed the traditional model on all goodness-of-fit measures. More specifically, LSTMs achieved an over 60\% higher adjusted R squared, and decreased predictive error by 34-fold compared to the traditional method. These results suggest that NN models to predict resilience are both feasible and accurate and may find practical use in many important domains.
</details>
<details>
<summary>摘要</summary>
这篇研究探讨了系统的恢复能力，包括系统在干扰事件后的恢复和回复。这些研究通常强调系统的恢复指标数量，而最近的研究则提出了使用统计模型估计系统的复原时间。然而，以往的研究通常是在资料复原后进行，或仅仅是对理想化趋势进行研究。因此，这篇研究提出了三种人工神经网络（ANN）方法，包括人工神经网络（ANN）、回传神经网络（RNN）和长短期内存（LSTM），以模拟和预测系统的性能，包括负面和正面因素的影响，以量化干扰事件的影响和恢复活动。我们使用了一个传统的统计模型，包括平均方差和调整乘根，来评估模型的适合度。我们的结果显示，ANN模型在所有适合度检查中表现较好，特别是LSTM模型在调整乘根上高于60%，且预测误差下降34倍。这些结果表明，ANN模型可以实际地和精确地预测系统的恢复能力，并在许多重要领域中找到实际应用。
</details></li>
</ul>
<hr>
<h2 id="FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods"><a href="#FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods" class="headerlink" title="FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods"></a>FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06248">http://arxiv.org/abs/2308.06248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/visinf/funnybirds">https://github.com/visinf/funnybirds</a></li>
<li>paper_authors: Robin Hesse, Simone Schaub-Meyer, Stefan Roth</li>
<li>for: The paper is written for the field of explainable artificial intelligence (XAI), specifically to address the challenge of evaluating the effectiveness of XAI methods in a fully automatic and systematic manner.</li>
<li>methods: The paper proposes a novel synthetic vision dataset called FunnyBirds and accompanying automatic evaluation protocols to evaluate XAI methods. The dataset allows for semantically meaningful image interventions, such as removing individual object parts, which enables analyzing explanations on a part level and estimating ground-truth part importances.</li>
<li>results: The paper reports results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner. The results show that the proposed evaluation protocols are effective in identifying the strengths and weaknesses of different XAI methods.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇论文是为了解释人工智能（XAI）领域的一个挑战，具体来说是如何在完全自动和系统atic的方式下评估XAI方法的有效性。</li>
<li>methods: 论文提出了一个新的 sintetic vision dataset名为FunnyBirds，以及一系列的自动评估协议，用于评估XAI方法。该dataset允许进行semantic meaningful的图像干扰，例如 removing各个物体部分，这使得可以分析解释在每个部分上的含义。</li>
<li>results: 论文报告了24种不同的神经网络模型和XAI方法的结果，这些结果表明了评估方法的优劣。<details>
<summary>Abstract</summary>
The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.
</details>
<details>
<summary>摘要</summary>
领域的解释人工智能（XAI）目标是探索复杂的深度神经网络模型的内部工作原理。虽然在安全关键领域非常重要，但XAI自然lacks ground-truth explanations，making its automatic evaluation an unsolved problem。我们解决这个挑战 by proposing a novel synthetic vision dataset named FunnyBirds， accompanied by automatic evaluation protocols。我们的数据集允许进行semantically meaningful image interventions，例如移除个体物体部分，这有三个重要的后果。首先，它允许分析解释在部件层次上进行分析，这更加接近人类理解的水平than existing methods that evaluate on a pixel level。其次，通过比较模型输出对具有移除部件的输入的比较，我们可以估算ground-truth part importances，这些importances应该被反映在解释中。最后，将各种解释映射到一个共同的部件importances空间，我们可以分析多种不同的解释类型在一个共同框架中。使用我们的工具，我们报告了24种不同的神经网络模型和XAI方法的结果，这些结果 Demonstrate the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.
</details></li>
</ul>
<hr>
<h2 id="Private-Distribution-Learning-with-Public-Data-The-View-from-Sample-Compression"><a href="#Private-Distribution-Learning-with-Public-Data-The-View-from-Sample-Compression" class="headerlink" title="Private Distribution Learning with Public Data: The View from Sample Compression"></a>Private Distribution Learning with Public Data: The View from Sample Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06239">http://arxiv.org/abs/2308.06239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shai Ben-David, Alex Bie, Clément L. Canonne, Gautam Kamath, Vikrant Singhal</li>
<li>for: 本文研究了在公共数据上进行隐私学习的问题，即公共私有学习。learner 是 Given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.</li>
<li>methods: 本文使用了 sample compression scheme for $\mathcal Q$ 和 list learning 来研究公共私有学习的可行性。</li>
<li>results: 本文的结果包括：(1) 回归 previous results on Gaussians over $\mathbb R^d$ ；(2) 适用于任意 $k$-mixtures of Gaussians over $\mathbb R^d$ 的新结果，包括学习复杂性上下文和分布转移抗性学习者的结果，以及 closure properties for public-private learnability under taking mixtures and products of distributions。此外，通过连接到 list learning，本文还证明了对 Gaussian 在 $\mathbb R^d$ 中，至少需要 $d$ 个公共样本来保证私有学习可行性，这与知道的Upper bound of $d+1$ 公共样本很接近。<details>
<summary>Abstract</summary>
We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.   We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability under taking mixtures and products of distributions. Finally, via the connection to list learning, we show that for Gaussians in $\mathbb R^d$, at least $d$ public samples are necessary for private learnability, which is close to the known upper bound of $d+1$ public samples.
</details>
<details>
<summary>摘要</summary>
我们研究了公共-私人学习问题，在这种设置下，学习者被公共和私人样本所访问，目标是输出一个未知分布$p$的估计，同时遵循隐私限制（这里是纯度ifferential privacy）只与私人样本相关。我们证明了公共-私人学习可能性与样本压缩 schemes for $\mathcal Q$ 以及 list learning 的存在有关，并且利用这种关系：1. 约束 previous results on Gaussians over $\mathbb R^d$ 的 approximately recovery;2. 导致新的结论，包括 $k$-mixtures of Gaussians over $\mathbb R^d$ 的 sample complexity upper bounds, agnostic 和 distribution-shift resistant learners,以及 distribution under taking mixtures and products of distributions. finally, via the connection to list learning, we show that for Gaussians in $\mathbb R^d$, at least $d$ public samples are necessary for private learnability, which is close to the known upper bound of $d+1$ public samples.
</details></li>
</ul>
<hr>
<h2 id="MaxFloodCast-Ensemble-Machine-Learning-Model-for-Predicting-Peak-Inundation-Depth-And-Decoding-Influencing-Features"><a href="#MaxFloodCast-Ensemble-Machine-Learning-Model-for-Predicting-Peak-Inundation-Depth-And-Decoding-Influencing-Features" class="headerlink" title="MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features"></a>MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06228">http://arxiv.org/abs/2308.06228</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-Chun Lee, Lipai Huang, Federico Antolini, Matthew Garcia, Andrew Juanb, Samuel D. Brody, Ali Mostafavi</li>
<li>for: 提供快速、准确和可靠的洪水信息，以支持洪水事件中的决策者、紧急管理人员和基础设施运营人员。</li>
<li>methods: 使用机器学习模型MaxFloodCast，基于物理基础的水动力学模拟，在哈里斯县进行训练，以实现高效和可解释的洪水涵顶深度预测。</li>
<li>results: MaxFloodCast模型在未见数据上达到了0.949的平均R-squared值和0.61 ft的Root Mean Square Error，表明其可靠地预测洪水涵顶深度。验证了飓风哈维和飓风伊梅拉达，MaxFloodCast模型显示出在近实时洪水管理和紧急应急管理中的潜在作用。<details>
<summary>Abstract</summary>
Timely, accurate, and reliable information is essential for decision-makers, emergency managers, and infrastructure operators during flood events. This study demonstrates a proposed machine learning model, MaxFloodCast, trained on physics-based hydrodynamic simulations in Harris County, offers efficient and interpretable flood inundation depth predictions. Achieving an average R-squared of 0.949 and a Root Mean Square Error of 0.61 ft on unseen data, it proves reliable in forecasting peak flood inundation depths. Validated against Hurricane Harvey and Storm Imelda, MaxFloodCast shows the potential in supporting near-time floodplain management and emergency operations. The model's interpretability aids decision-makers in offering critical information to inform flood mitigation strategies, to prioritize areas with critical facilities and to examine how rainfall in other watersheds influences flood exposure in one area. The MaxFloodCast model enables accurate and interpretable inundation depth predictions while significantly reducing computational time, thereby supporting emergency response efforts and flood risk management more effectively.
</details>
<details>
<summary>摘要</summary>
时尚、准确、可靠的信息是决策者、紧急管理者和基础设施操作者在洪水事件中的基本需求。这个研究显示了一个提议的机器学习模型MaxFloodCast，在哈里斯县基于物理学 hydrodynamic 模拟中训练，可以提供高效和可解释的洪水淹没深度预测。在未见数据上，它实现了0.949的平均R-squared和0.61 ft的Root Mean Square Error，证明它在预测洪水淹没深度方面具有可靠性。验证了飓风哈维和飓风Imelda，MaxFloodCast显示了在近实时洪水平原管理和紧急作业中的潜在应用 potential。模型的可解释性帮助决策者对洪水缓和策略提供重要信息，优先级有critical facilities的区域，并考虑在一个区域中的降雨影响洪水暴露。MaxFloodCast模型可以提供高效和可解释的洪水淹没深度预测，同时大幅降低计算时间，以更好地支持紧急 Response efforts和洪水风险管理。
</details></li>
</ul>
<hr>
<h2 id="Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms"><a href="#Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms" class="headerlink" title="Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms"></a>Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06221">http://arxiv.org/abs/2308.06221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kanishka Tyagi, Chinmay Rane, Michael Manry</li>
<li>for: 该论文旨在提出一种多步训练方法，用于设计通用线性分类器。</li>
<li>methods: 该方法包括初始化多类线性分类器，然后通过权重裁剪来降低验证错误，同时通过类似于霍-卡希普规则来改进期望输出。接着，输出推导器被拟合成为一个通用的多层感知器中的抑制器。</li>
<li>results: 该paper通过对多层感知器的搜索、验证错误的最小化和权重裁剪来提高总性能。此外，paper还提出了一种批处理算法，用于优化隐藏层大小和训练轮数。最终，paper通过对多层感知器进行权重裁剪和增长来提高其性能。<details>
<summary>Abstract</summary>
We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for deep autoencoders. We investigate several problems in deep autoencoders networks including training issues, the theoretical, mathematical and experimental justification that the networks are linear, optimizing the number of hidden units in each layer and determining the depth of the deep learning model. A direct implication of the current work is the ability to construct fast deep learning models using desktop level computational resources. This, in our opinion, promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi layer perceptron and deep learners reported in the literature.
</details>
<details>
<summary>摘要</summary>
我们提出了一种多步训练方法用于设计通用线性分类器。首先，通过回归获得初始多类线性分类器。然后，通过剔除不必要的输入，降低验证错误。同时，通过类似于霍-卡希普规则进行改进。接着，输出推定器被映射到通用线性分类器中的sigmoid输出单元中的核函数。我们然后开发了一种批处理训练算法，以优化隐藏层大小和训练轮次数。接着，我们结合剔除和增长策略。最后，输入单元被映射到sigmoid输出单元中的核函数，然后被输入到多层感知器中。我们提出了改进每个深度学习块的方法，从而提高整体深度学习模型的性能。我们讨论了深度学习算法的学习原理和形式化表述，并 investigate了深度学习网络中的许多问题，包括训练问题、理论、数学和实验上的正当性。我们的研究表明，通过使用桌面级计算机资源，可以快速构建高性能的深度学习模型。这与我们的设计哲学相吻合，即建立小而强大的算法。我们的实验表明，使用常用的数据集，最终网络的十倍测试错误比其他线性、通用线性分类器、多层感知器和深度学习者报道的较低。
</details></li>
</ul>
<hr>
<h2 id="Change-Point-Detection-With-Conceptors"><a href="#Change-Point-Detection-With-Conceptors" class="headerlink" title="Change Point Detection With Conceptors"></a>Change Point Detection With Conceptors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06213">http://arxiv.org/abs/2308.06213</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/noahgade/changepointdetectionwithconceptors">https://github.com/noahgade/changepointdetectionwithconceptors</a></li>
<li>paper_authors: Noah D. Gade, Jordan Rodu</li>
<li>for:  Identifying changes in the data generating process in time series with increasing dimension and temporal dependence.</li>
<li>methods:  Using a conceptor matrix to learn the characteristic dynamics of a specified training window, and a random recurrent neural network to featurize the data.</li>
<li>results:  A method that provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on simulations from several classes of processes and applied to publicly available neural data from rats experiencing bouts of non-REM sleep prior to exploration of a radial maze.<details>
<summary>Abstract</summary>
Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on simulations from several classes of processes, and we evaluate performance with clustering metrics, graphical methods, and observed Type 1 error control. We apply our method to publicly available neural data from rats experiencing bouts of non-REM sleep prior to exploration of a radial maze.
</details>
<details>
<summary>摘要</summary>
非线性变换点检测目的是检测时序序列中数据生成过程中的变化点。这个问题在独立Identical Distribution（i.i.d）数据上得到了广泛的研究，但是随着维度和时间相关性的增加，问题变得更加复杂。为了检测最多一个变换点，我们提议使用特征动力矩阵来学习指定的训练窗口中数据的特征动力。相关的随机回归神经网络作为数据的特征化器，变换点通过单variate量化的距离来确定与一个表征动力矩阵所生成的空间之间的距离。这种模型无关的方法可以提供有价值的可能性点，供进一步研究。我们证明，在某些假设下，该方法可以提供一个一致的变换点估计，并通过移动块bootstrap来生成quantile估计。我们在一些类型的过程的 simulations中测试了该方法，并根据集成度、图形方法和观察到的类型一错控制来评估性能。我们将该方法应用于公共可用的非 REM睡眠前的大鼠脑电信号。
</details></li>
</ul>
<hr>
<h2 id="Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey"><a href="#Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey" class="headerlink" title="Safety in Traffic Management Systems: A Comprehensive Survey"></a>Safety in Traffic Management Systems: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06204">http://arxiv.org/abs/2308.06204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlu Du, Ankan Dash, Jing Li, Hua Wei, Guiling Wang</li>
<li>for: 本研究提供了交通管理系统安全性的全面审查，包括交通管理系统中的安全问题、现有研究的当前状况以及提高交通管理系统安全性的技术和方法。</li>
<li>methods: 本研究审视了交通管理系统中的各种安全问题，包括技术问题、人因问题和管理问题，并评估了现有研究的当前状况和发展趋势。</li>
<li>results: 本研究结果表明，确保交通管理系统安全性是一个复杂的问题，需要考虑技术、人因和管理因素。现有的研究主要集中在技术方面，未来研究应该更加着重于人因和管理方面。<details>
<summary>Abstract</summary>
Traffic management systems play a vital role in ensuring safe and efficient transportation on roads. However, the use of advanced technologies in traffic management systems has introduced new safety challenges. Therefore, it is important to ensure the safety of these systems to prevent accidents and minimize their impact on road users. In this survey, we provide a comprehensive review of the literature on safety in traffic management systems. Specifically, we discuss the different safety issues that arise in traffic management systems, the current state of research on safety in these systems, and the techniques and methods proposed to ensure the safety of these systems. We also identify the limitations of the existing research and suggest future research directions.
</details>
<details>
<summary>摘要</summary>
交通管理系统在公路交通中扮演至关重要的角色，但是使用先进科技在交通管理系统中带来了新的安全挑战。因此，确保交通管理系统的安全性是非常重要的，以预防事故和最小化对交通路用者的影响。在本调查中，我们提供了交通管理系统安全的全面文献评审。具体来说，我们讨论了交通管理系统中不同的安全问题，现有的研究状况，以及确保交通管理系统安全的技术和方法。我们还识别了现有研究的限制，并建议未来研究的方向。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.LG_2023_08_12/" data-id="clly3dvzi006c0988ea4ndom6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/13/eess.IV_2023_08_13/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-13 17:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/12/cs.SD_2023_08_12/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-12 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">104</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
