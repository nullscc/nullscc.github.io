
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-08-05 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Flashlight Search Medial Axis: A Pixel-Free Pore-Network Extraction Algorithm paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.10990 repo_url: None paper_authors: Jie Liu, Tao Zhang, Shuyu Sun for: 这个论文的目的是提出一种基于">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-08-05">
<meta property="og:url" content="https://nullscc.github.io/2023/08/05/eess.IV_2023_08_05/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Flashlight Search Medial Axis: A Pixel-Free Pore-Network Extraction Algorithm paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.10990 repo_url: None paper_authors: Jie Liu, Tao Zhang, Shuyu Sun for: 这个论文的目的是提出一种基于">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-05T09:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T08:44:51.536Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_08_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/05/eess.IV_2023_08_05/" class="article-date">
  <time datetime="2023-08-05T09:00:00.000Z" itemprop="datePublished">2023-08-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-08-05
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Flashlight-Search-Medial-Axis-A-Pixel-Free-Pore-Network-Extraction-Algorithm"><a href="#Flashlight-Search-Medial-Axis-A-Pixel-Free-Pore-Network-Extraction-Algorithm" class="headerlink" title="Flashlight Search Medial Axis: A Pixel-Free Pore-Network Extraction Algorithm"></a>Flashlight Search Medial Axis: A Pixel-Free Pore-Network Extraction Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10990">http://arxiv.org/abs/2308.10990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Liu, Tao Zhang, Shuyu Sun</li>
<li>for: 这个论文的目的是提出一种基于扫描线的方法，用于精准地提取porous media中的孔网。</li>
<li>methods: 这个方法使用了flashlight search medial axis（FSMA）算法，该算法在维度减少的思想下，通过只需要在搜索区域中选择一些点来确定孔网的中心点，从而大大降低了计算复杂性，使得大规模的孔网提取变得可能。</li>
<li>results: 根据两维和三维porous media的实验结果表明，FSMA算法在不同的 topological structure和孔和耳中心点的位置下都表现良好，并且可以处理闭合和开放边界的情况。此外，该算法还可以搜索死绕孔，这在多相流动在porous media中的研究中具有重要意义。<details>
<summary>Abstract</summary>
Pore-network models (PNMs) have become an important tool in the study of fluid flow in porous media over the last few decades, and the accuracy of their results highly depends on the extraction of pore networks. Traditional methods of pore-network extraction are based on pixels and require images with high quality. Here, a pixel-free method called the flashlight search medial axis (FSMA) algorithm is proposed for pore-network extraction in a continuous space. The search domain in a two-dimensional space is a line, whereas a surface domain is searched in a three-dimensional scenario. Thus, the FSMA algorithm follows the dimensionality reduction idea; the medial axis can be identified using only a few points instead of calculating every point in the void space. In this way, computational complexity of this method is greatly reduced compared to that of traditional pixel-based extraction methods, thus enabling large-scale pore-network extraction. Based on cases featuring two- and three-dimensional porous media, the FSMA algorithm performs well regardless of the topological structure of the pore network or the positions of the pore and throat centers. This algorithm can also be used to examine both closed- and open-boundary cases. Finally, the FSMA algorithm can search dead-end pores, which is of great significance in the study of multiphase flow in porous media.
</details>
<details>
<summary>摘要</summary>
PORE-NETWORK MODELS (PNMs) 在过去几十年中变得了流体流动在孔隙媒体的研究中非常重要的工具，并且其结果的准确性很大程度上取决于破孔网络的提取。传统的破孔网络提取方法基于像素，需要高质量的图像。在这里，一种没有像素的方法，即flashlight搜索中点（FSMA）算法，被提出用于破孔网络提取在连续空间中。搜索空间为二维或三维空间中的一条线，而搜索surface空间则是在三维场景中。因此，FSMA算法采用维度减少的想法，通过只需要在缺空空间中标定一些点来确定中点，而不需要计算所有点。这样，与传统基于像素的提取方法相比，FSMA算法的计算复杂度得到了很大的减少，可以实现大规模的破孔网络提取。无论破孔网络的topological结构是多样的，FSMA算法都能够perform well。此外，这种算法还可以用于研究开放和闭合边界的情况。最后，FSMA算法还可以搜索死绕的破孔，这对多相流动在孔隙媒体中的研究具有重要性。
</details></li>
</ul>
<hr>
<h2 id="Landmark-Detection-using-Transformer-Toward-Robot-assisted-Nasal-Airway-Intubation"><a href="#Landmark-Detection-using-Transformer-Toward-Robot-assisted-Nasal-Airway-Intubation" class="headerlink" title="Landmark Detection using Transformer Toward Robot-assisted Nasal Airway Intubation"></a>Landmark Detection using Transformer Toward Robot-assisted Nasal Airway Intubation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02845">http://arxiv.org/abs/2308.02845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/conorlth/airway_intubation_landmarks_detection">https://github.com/conorlth/airway_intubation_landmarks_detection</a></li>
<li>paper_authors: Tianhang Liu, Hechen Li, Long Bai, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren</li>
<li>for: 该研究旨在提出一种基于变形转换器的医疗器具辅助气管镜插入应用程序，以提高气管镜插入过程中的准确性。</li>
<li>methods: 该研究使用了自适应转换器和含义对齐模块，以实现气管镜插入过程中的精度察看和量化评估。</li>
<li>results: 实验结果表明，该解决方案在气管镜插入应用程序中达到了竞争性的检测精度。<details>
<summary>Abstract</summary>
Robot-assisted airway intubation application needs high accuracy in locating targets and organs. Two vital landmarks, nostrils and glottis, can be detected during the intubation to accommodate the stages of nasal intubation. Automated landmark detection can provide accurate localization and quantitative evaluation. The Detection Transformer (DeTR) leads object detectors to a new paradigm with long-range dependence. However, current DeTR requires long iterations to converge, and does not perform well in detecting small objects. This paper proposes a transformer-based landmark detection solution with deformable DeTR and the semantic-aligned-matching module for detecting landmarks in robot-assisted intubation. The semantics aligner can effectively align the semantics of object queries and image features in the same embedding space using the most discriminative features. To evaluate the performance of our solution, we utilize a publicly accessible glottis dataset and automatically annotate a nostril detection dataset. The experimental results demonstrate our competitive performance in detection accuracy. Our code is publicly accessible.
</details>
<details>
<summary>摘要</summary>
robot-assisted 空气道插管应用需要高精度在目标和器官的位置检测。在插管过程中，两个重要的地标，鼻孔和肺部，可以被检测出来，以便适应插管的不同阶段。自动地标检测可以提供准确的地标位置和质量评价。但现有的DeTR需要长时间融合，并不能够准确地检测小 objet。本文提出了基于 transformer 的地标检测解决方案，包括可变 DeTR 和 semantics-aligned-matching 模块。semantics aligner 可以有效地将对象查询和图像特征在同一 embedding 空间中进行Semantic alignment，使用最 дискriminative 特征。为评估我们的解决方案的性能，我们利用公共 accessible glottis 数据集和自动生成 nostril 检测数据集。实验结果表明我们的竞争性表现在检测精度方面。我们的代码公开 accessible。
</details></li>
</ul>
<hr>
<h2 id="Non-line-of-sight-reconstruction-via-structure-sparsity-regularization"><a href="#Non-line-of-sight-reconstruction-via-structure-sparsity-regularization" class="headerlink" title="Non-line-of-sight reconstruction via structure sparsity regularization"></a>Non-line-of-sight reconstruction via structure sparsity regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02782">http://arxiv.org/abs/2308.02782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duolan Huang, Quan Chen, Zhun Wei, Rui Chen</li>
<li>For: The paper is written for the purpose of improving the quality of non-line-of-sight (NLOS) imaging, specifically in the context of denoising and reconstruction of occluded objects.* Methods: The paper proposes a regularization method called structure sparsity (SS) regularization, which incorporates nuclear norm penalization into the cost function of the directional light-cone transform (DLCT) model for NLOS imaging systems. The method utilizes prior knowledge of structure sparseness to facilitate denoising and improve reconstruction quality.* Results: The proposed approach is demonstrated to yield high-quality reconstructions, surpassing state-of-the-art reconstruction algorithms, especially in scenarios involving short exposure and low signal-noise-ratio (SNR) measurements. The approach is effective in denoising and reconstructing occluded objects, and is shown to be robust in various scenarios.<details>
<summary>Abstract</summary>
Non-line-of-sight (NLOS) imaging allows for the imaging of objects around a corner, which enables potential applications in various fields such as autonomous driving, robotic vision, medical imaging, security monitoring, etc. However, the quality of reconstruction is challenged by low signal-noise-ratio (SNR) measurements. In this study, we present a regularization method, referred to as structure sparsity (SS) regularization, for denoising in NLOS reconstruction. By exploiting the prior knowledge of structure sparseness, we incorporate nuclear norm penalization into the cost function of directional light-cone transform (DLCT) model for NLOS imaging system. This incorporation effectively integrates the neighborhood information associated with the directional albedo, thereby facilitating the denoising process. Subsequently, the reconstruction is achieved by optimizing a directional albedo model with SS regularization using fast iterative shrinkage-thresholding algorithm. Notably, the robust reconstruction of occluded objects is observed. Through comprehensive evaluations conducted on both synthetic and experimental datasets, we demonstrate that the proposed approach yields high-quality reconstructions, surpassing the state-of-the-art reconstruction algorithms, especially in scenarios involving short exposure and low SNR measurements.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Dual-Degradation-Inspired-Deep-Unfolding-Network-for-Low-Light-Image-Enhancement"><a href="#Dual-Degradation-Inspired-Deep-Unfolding-Network-for-Low-Light-Image-Enhancement" class="headerlink" title="Dual Degradation-Inspired Deep Unfolding Network for Low-Light Image Enhancement"></a>Dual Degradation-Inspired Deep Unfolding Network for Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02776">http://arxiv.org/abs/2308.02776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huake Wang, Xingsong Hou, Xiaoyang Yan</li>
<li>for: 提高低光照图像的增强性能，探讨低光照图像减退机理的物理意义。</li>
<li>methods: 提出了一种基于双层减退模型的深度 unfolding 网络（DASUNet），通过两种不同的图像假设来学习低光照图像的特征。</li>
<li>results: 对多个流行的低光照图像数据集进行了广泛的实验，并证明了 DASUNet 比传统的低光照图像增强方法更有效。<details>
<summary>Abstract</summary>
Although low-light image enhancement has achieved great stride based on deep enhancement models, most of them mainly stress on enhancement performance via an elaborated black-box network and rarely explore the physical significance of enhancement models. Towards this issue, we propose a Dual degrAdation-inSpired deep Unfolding network, termed DASUNet, for low-light image enhancement. Specifically, we construct a dual degradation model (DDM) to explicitly simulate the deterioration mechanism of low-light images. It learns two distinct image priors via considering degradation specificity between luminance and chrominance spaces. To make the proposed scheme tractable, we design an alternating optimization solution to solve the proposed DDM. Further, the designed solution is unfolded into a specified deep network, imitating the iteration updating rules, to form DASUNet. Local and long-range information are obtained by prior modeling module (PMM), inheriting the advantages of convolution and Transformer, to enhance the representation capability of dual degradation priors. Additionally, a space aggregation module (SAM) is presented to boost the interaction of two degradation models. Extensive experiments on multiple popular low-light image datasets validate the effectiveness of DASUNet compared to canonical state-of-the-art low-light image enhancement methods. Our source code and pretrained model will be publicly available.
</details>
<details>
<summary>摘要</summary>
尽管深度改进模型在低光照图像增强方面已经取得了很大的进步，但大多数模型很少探究增强模型的物理意义。为解决这个问题，我们提出了一种基于双层退化的深度 unfolding 网络（DASUNet），用于低光照图像增强。具体来说，我们构建了双层退化模型（DDM），以特别模拟低光照图像的衰变机制。它学习了两个不同的图像假设，通过考虑颜色和灰度空间中的退化特点进行分别学习。为使我们的方案可行，我们设计了一种 alternate 优化解决方案，以解决我们的 DDM。此外，我们设计了一个特定的深度网络，以模仿我们的迭代更新规则，以形成 DASUNet。本网络具有优化了表征能力的双层退化假设模块（PMM）和空间聚合模块（SAM）。通过PMM，我们继承了 convolution 和 Transformer 的优点，以提高表征能力。SAM 则用于提高两个退化模型之间的交互。我们对多个流行的低光照图像 dataset 进行了广泛的实验，并证明了 DASUNet 比 canonical state-of-the-art 低光照图像增强方法更有效。我们将源代码和预训练模型公开发布。
</details></li>
</ul>
<hr>
<h2 id="Incorporation-of-Eye-Tracking-and-Gaze-Feedback-to-Characterize-and-Improve-Radiologist-Search-Patterns-of-Chest-X-rays-A-Randomized-Controlled-Clinical-Trial"><a href="#Incorporation-of-Eye-Tracking-and-Gaze-Feedback-to-Characterize-and-Improve-Radiologist-Search-Patterns-of-Chest-X-rays-A-Randomized-Controlled-Clinical-Trial" class="headerlink" title="Incorporation of Eye-Tracking and Gaze Feedback to Characterize and Improve Radiologist Search Patterns of Chest X-rays: A Randomized Controlled Clinical Trial"></a>Incorporation of Eye-Tracking and Gaze Feedback to Characterize and Improve Radiologist Search Patterns of Chest X-rays: A Randomized Controlled Clinical Trial</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06280">http://arxiv.org/abs/2308.06280</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carolina Ramirez-Tamayo, Syed Hasib Akhter Faruqui, Stanford Martinez, Angel Brisco, Nicholas Czarnek, Adel Alaeddini, Jeffrey R. Mock, Edward J. Golob, Kal L. Clark</li>
<li>for: 本研究旨在使用眼动追踪技术分析验表诊断医生的搜寻模式，评估验表诊断医生的性能，并评估一种自动反馈驱动的教育框架对悬虚癌细胞检测的影响。</li>
<li>methods: 本研究使用了眼动追踪技术分析验表诊断医生的搜寻模式，并使用已知的指标评估验表诊断医生的性能。另外，研究还使用了自动反馈驱动的教育框架，以提高验表诊断医生的搜寻模式和悬虚癌检测精度。</li>
<li>results: 研究结果表明，在接受了自动反馈驱动的教育框架的情况下，验表诊断医生的悬虚癌检测精度得到了38.89%的绝对提高，比控制组的提高（5.56%，p值&#x3D;0.006）要高得多。此外，在四次培训会议中，改进速度也得到了 statistically significant 的改进（p值&#x3D;0.0001）。然而，其他指标，如速度、搜寻模式多样性、干扰和覆盖率，未显示出 statistically significant 的变化。<details>
<summary>Abstract</summary>
Diagnostic errors in radiology often occur due to incomplete visual assessments by radiologists, despite their knowledge of predicting disease classes. This insufficiency is possibly linked to the absence of required training in search patterns. Additionally, radiologists lack consistent feedback on their visual search patterns, relying on ad-hoc strategies and peer input to minimize errors and enhance efficiency, leading to suboptimal patterns and potential false negatives. This study aimed to use eye-tracking technology to analyze radiologist search patterns, quantify performance using established metrics, and assess the impact of an automated feedback-driven educational framework on detection accuracy. Ten residents participated in a controlled trial focused on detecting suspicious pulmonary nodules. They were divided into an intervention group (received automated feedback) and a control group. Results showed that the intervention group exhibited a 38.89% absolute improvement in detecting suspicious-for-cancer nodules, surpassing the control group's improvement (5.56%, p-value=0.006). Improvement was more rapid over the four training sessions (p-value=0.0001). However, other metrics such as speed, search pattern heterogeneity, distractions, and coverage did not show significant changes. In conclusion, implementing an automated feedback-driven educational framework improved radiologist accuracy in detecting suspicious nodules. The study underscores the potential of such systems in enhancing diagnostic performance and reducing errors. Further research and broader implementation are needed to consolidate these promising results and develop effective training strategies for radiologists, ultimately benefiting patient outcomes.
</details>
<details>
<summary>摘要</summary>
诊断错误在医学影像领域经常发生，主要是因为医师未能完整评估影像，即使他们具备疾病类型预测的知识。这可能是因为缺乏必要的训练，导致医师缺乏具体的搜寻模式训练。此外，医师也缺乏一致的反馈，他们通常靠协商策略和对手提供反馈，以减少错误和提高效率，从而导致可能的错误诊断。这项研究采用了眼动追踪技术来分析医师的搜寻模式，量化表现使用已知的 метрик，并评估自动化反馈驱动的教育框架对于癌症检测的影响。本研究中，有10名住院医生参与了一个控制性试验，检测肺部潜在癌瘤。他们被分为干预件组（接受自动化反馈）和控制件组。结果显示，干预件组与控制件组之间的差异为38.89%，高于控制件组的改善（5.56%，p值=0.006）。改善的速度在四次训练Session中明显（p值=0.0001）。但是，其他的 метри克，如速度、搜寻模式多样性、干扰和覆盖，未经过 significatif 的变化。总结来说，实施自动化反馈驱动的教育框架可以改善医师检测潜在癌瘤的精度。这项研究强调了这种系统对于诊断性能的提高和错误的减少的潜在。进一步的研究和更广泛的实施是需要实现这些有前途的结果，以 ultimately 改善病人结果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/05/eess.IV_2023_08_05/" data-id="cloq1wldt014m7o8865my06l1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/05/cs.LG_2023_08_05/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-08-05
        
      </div>
    </a>
  
  
    <a href="/2023/08/04/cs.SD_2023_08_04/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-04</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
