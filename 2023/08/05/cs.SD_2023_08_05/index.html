
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.SD - 2023-08-05 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.02870 repo_url: None paper">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.SD - 2023-08-05">
<meta property="og:url" content="https://nullscc.github.io/2023/08/05/cs.SD_2023_08_05/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.02870 repo_url: None paper">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-05T15:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T08:44:46.567Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.SD_2023_08_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/05/cs.SD_2023_08_05/" class="article-date">
  <time datetime="2023-08-05T15:00:00.000Z" itemprop="datePublished">2023-08-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.SD - 2023-08-05
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ApproBiVT-Lead-ASR-Models-to-Generalize-Better-Using-Approximated-Bias-Variance-Tradeoff-Guided-Early-Stopping-and-Checkpoint-Averaging"><a href="#ApproBiVT-Lead-ASR-Models-to-Generalize-Better-Using-Approximated-Bias-Variance-Tradeoff-Guided-Early-Stopping-and-Checkpoint-Averaging" class="headerlink" title="ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging"></a>ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02870">http://arxiv.org/abs/2308.02870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fangyuan Wang, Ming Hao, Yuhai Shi, Bo Xu</li>
<li>for: This paper aims to improve the conventional recipe for Automatic Speech Recognition (ASR) models by rethinking and updating the early stopping and checkpoint averaging methods from the perspective of the bias-variance tradeoff.</li>
<li>methods: The proposed method, called Approximated Bias-Variance Tradeoff (ApproBiVT), uses the training loss and validation loss as proxies of bias and variance to guide the early stopping and checkpoint averaging.</li>
<li>results: When evaluated on the AISHELL-1 and AISHELL-2 datasets, the proposed recipe provided a CER reduction of 2.5%-3.7% and 3.1%-4.6%, respectively, compared to the conventional recipe.<details>
<summary>Abstract</summary>
The conventional recipe for Automatic Speech Recognition (ASR) models is to 1) train multiple checkpoints on a training set while relying on a validation set to prevent overfitting using early stopping and 2) average several last checkpoints or that of the lowest validation losses to obtain the final model. In this paper, we rethink and update the early stopping and checkpoint averaging from the perspective of the bias-variance tradeoff. Theoretically, the bias and variance represent the fitness and variability of a model and the tradeoff of them determines the overall generalization error. But, it's impractical to evaluate them precisely. As an alternative, we take the training loss and validation loss as proxies of bias and variance and guide the early stopping and checkpoint averaging using their tradeoff, namely an Approximated Bias-Variance Tradeoff (ApproBiVT). When evaluating with advanced ASR models, our recipe provides 2.5%-3.7% and 3.1%-4.6% CER reduction on the AISHELL-1 and AISHELL-2, respectively.
</details>
<details>
<summary>摘要</summary>
传统的自动语音识别（ASR）模型制作流程是：1）在训练集上训练多个Checkpoint，并且使用验证集来防止过拟合，使用早期停止和Checkpoint平均来获得最终模型。在这篇论文中，我们重新思考和更新了早期停止和Checkpoint平均的方法，从偏差-变差质量的角度来考虑。在理论上，偏差和变差代表模型的适应度和多样性，它们之间的质量评价是模型的总泛化误差的关键因素。但是，很难准确地评价它们。因此，我们使用训练损失和验证损失作为偏差和变差的代理，并使用它们之间的质量评价来引导早期停止和Checkpoint平均，即 Approximated Bias-Variance Tradeoff（ApproBiVT）。在使用高级ASR模型进行评估时，我们的制作流程可以提供2.5%-3.7%和3.1%-4.6%的CER减少在AISHELL-1和AISHELL-2上。
</details></li>
</ul>
<hr>
<h2 id="A-Systematic-Exploration-of-Joint-training-for-Singing-Voice-Synthesis"><a href="#A-Systematic-Exploration-of-Joint-training-for-Singing-Voice-Synthesis" class="headerlink" title="A Systematic Exploration of Joint-training for Singing Voice Synthesis"></a>A Systematic Exploration of Joint-training for Singing Voice Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02867">http://arxiv.org/abs/2308.02867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuning Wu, Yifeng Yu, Jiatong Shi, Tao Qian, Qin Jin</li>
<li>for: 提高Singing Voice Synthesis（SVS）系统的 JOINT-TRAINING 性能</li>
<li>methods: 采用joint-training策略，协同训练Acoustic Model和Vocoder</li>
<li>results: 对多个数据集进行了广泛的实验，并达到了比基eline更稳定的性能，同时提高了整个框架的可解释性。<details>
<summary>Abstract</summary>
There has been a growing interest in using end-to-end acoustic models for singing voice synthesis (SVS). Typically, these models require an additional vocoder to transform the generated acoustic features into the final waveform. However, since the acoustic model and the vocoder are not jointly optimized, a gap can exist between the two models, leading to suboptimal performance. Although a similar problem has been addressed in the TTS systems by joint-training or by replacing acoustic features with a latent representation, adopting corresponding approaches to SVS is not an easy task. How to improve the joint-training of SVS systems has not been well explored. In this paper, we conduct a systematic investigation of how to better perform a joint-training of an acoustic model and a vocoder for SVS. We carry out extensive experiments and demonstrate that our joint-training strategy outperforms baselines, achieving more stable performance across different datasets while also increasing the interpretability of the entire framework.
</details>
<details>
<summary>摘要</summary>
Recently, there has been growing interest in using end-to-end acoustic models for singing voice synthesis (SVS). Typically, these models require an additional vocoder to transform the generated acoustic features into the final waveform. However, since the acoustic model and the vocoder are not jointly optimized, a gap can exist between the two models, leading to suboptimal performance. Although a similar problem has been addressed in TTS systems by joint-training or by replacing acoustic features with a latent representation, adopting corresponding approaches to SVS is not an easy task. How to improve the joint-training of SVS systems has not been well explored. In this paper, we conduct a systematic investigation of how to better perform a joint-training of an acoustic model and a vocoder for SVS. We carry out extensive experiments and demonstrate that our joint-training strategy outperforms baselines, achieving more stable performance across different datasets while also increasing the interpretability of the entire framework.
</details></li>
</ul>
<hr>
<h2 id="Bootstrapping-Contrastive-Learning-Enhanced-Music-Cold-Start-Matching"><a href="#Bootstrapping-Contrastive-Learning-Enhanced-Music-Cold-Start-Matching" class="headerlink" title="Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching"></a>Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02844">http://arxiv.org/abs/2308.02844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinping Zhao, Ying Zhang, Qiang Xiao, Yuming Ren, Yingchun Yang</li>
<li>for: 这篇论文是为了解决音乐冷启始匹配问题，即在没有相关数据的情况下，根据歌曲内容特征来找到与之相似的歌曲和听众。</li>
<li>methods: 作者们使用了一种名为Bootstrapping Contrastive Learning（BCL）的新的对比学习方法，以增强学习的歌曲表示质量。此外，他们还提出了一种名为Clustering-based Audience Targeting（CAT）的听众定向策略，用于在在线服务中更准确地定位目标听众。</li>
<li>results: 作者们通过对离线数据集和在线系统进行广泛的实验，证明了他们的方法的有效性和高效性。此外，他们还在NetEase Cloud Music上部署了这种方法，影响了数百万用户。<details>
<summary>Abstract</summary>
We study a particular matching task we call Music Cold-Start Matching. In short, given a cold-start song request, we expect to retrieve songs with similar audiences and then fastly push the cold-start song to the audiences of the retrieved songs to warm up it. However, there are hardly any studies done on this task. Therefore, in this paper, we will formalize the problem of Music Cold-Start Matching detailedly and give a scheme. During the offline training, we attempt to learn high-quality song representations based on song content features. But, we find supervision signals typically follow power-law distribution causing skewed representation learning. To address this issue, we propose a novel contrastive learning paradigm named Bootstrapping Contrastive Learning (BCL) to enhance the quality of learned representations by exerting contrastive regularization. During the online serving, to locate the target audiences more accurately, we propose Clustering-based Audience Targeting (CAT) that clusters audience representations to acquire a few cluster centroids and then locate the target audiences by measuring the relevance between the audience representations and the cluster centroids. Extensive experiments on the offline dataset and online system demonstrate the effectiveness and efficiency of our method. Currently, we have deployed it on NetEase Cloud Music, affecting millions of users. Code will be released in the future.
</details>
<details>
<summary>摘要</summary>
我们研究了一个特定的匹配任务，称之为音乐冷启始匹配（Music Cold-Start Matching）。简而言之，给定一个冷启始歌曲请求，我们期望检索到与其相似的听众，然后快速推广冷启始歌曲到检索到的听众中，以便让其热身。然而，现有的研究对此任务的研究非常有限。因此，在这篇论文中，我们将Music Cold-Start Matching问题进行详细化，并提出一种方案。在线上训练时，我们尝试学习高质量的歌曲表示，基于歌曲内容特征。然而，我们发现监督信号通常遵循力量分布，导致表示学习受到扭曲的影响。为解决这个问题，我们提出了一种新的对比学习方法，称之为启动对比学习（Bootstrapping Contrastive Learning，BCL），以提高学习的质量。在线上服务时，我们提出了分组听众定向（Clustering-based Audience Targeting，CAT），将听众表示分组为一些集中点，然后通过测量听众表示和集中点之间的相似度来确定目标听众。我们对历史数据集和在线系统进行了广泛的实验，证明了我们的方法的有效性和效率。目前，我们已经将其部署到NetEase Cloud Music上，影响了数百万名用户。代码将在未来发布。
</details></li>
</ul>
<hr>
<h2 id="Self-Distillation-Network-with-Ensemble-Prototypes-Learning-Robust-Speaker-Representations-without-Supervision"><a href="#Self-Distillation-Network-with-Ensemble-Prototypes-Learning-Robust-Speaker-Representations-without-Supervision" class="headerlink" title="Self-Distillation Network with Ensemble Prototypes: Learning Robust Speaker Representations without Supervision"></a>Self-Distillation Network with Ensemble Prototypes: Learning Robust Speaker Representations without Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02774">http://arxiv.org/abs/2308.02774</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alibaba-damo-academy/3D-Speaker">https://github.com/alibaba-damo-academy/3D-Speaker</a></li>
<li>paper_authors: Yafeng Chen, Siqi Zheng, Qian Chen</li>
<li>for: 提高无标签 speaker verification 系统的可靠性和稳定性。</li>
<li>methods: 提出了一种自动学习 speaker representation 的 Self-Distillation network with Ensemble Prototypes (SDEP) 框架，无需使用标签数据。</li>
<li>results: 在 VoxCeleb 数据集上进行了详细的实验，并达到了新的 SOTA 水平（ i.e., 等Error rate 1.94%、1.99% 和 3.77%），不使用任何标签数据进行训练。<details>
<summary>Abstract</summary>
Training speaker-discriminative and robust speaker verification systems without speaker labels is still challenging and worthwhile to explore. Previous studies have noted a substantial performance disparity between self-supervised and fully supervised approaches. In this paper, we propose an effective Self-Distillation network with Ensemble Prototypes (SDEP) to facilitate self-supervised speaker representation learning. A range of experiments conducted on the VoxCeleb datasets demonstrate the superiority of the SDEP framework in speaker verification. SDEP achieves a new SOTA on Voxceleb1 speaker verification evaluation benchmark ( i.e., equal error rate 1.94\%, 1.99\%, and 3.77\% for trial Vox1-O, Vox1-E and Vox1-H , respectively), discarding any speaker labels in the training phase. Code will be publicly available at https://github.com/alibaba-damo-academy/3D-Speaker.
</details>
<details>
<summary>摘要</summary>
<SYS>使用无标签的语音训练说话人识别系统仍然是一项挑战，但也是值得探索的。过去的研究表明自我超vised和完全超vised方法之间存在很大的性能差异。在这篇论文中，我们提出了一种有效的自我蒸馏网络与集成观察者（SDEP），以便无标签语音表征学习。对于VoxCeleb数据集进行了一系列实验， demonstarted SDEP框架在说话人识别中的优越性。SDEP在Voxceleb1说话人识别评价标准（即错误率1.94%、1.99%和3.77%）上达到了新的最佳性能，不使用任何说话人标签在训练阶段。代码将在https://github.com/alibaba-damo-academy/3D-Speaker上公开。</SYS>Note that Simplified Chinese is used in the translation, as it is the more widely used standard in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/05/cs.SD_2023_08_05/" data-id="clot2mhgw00uvx78821n8bng8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/06/eess.IV_2023_08_06/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-06
        
      </div>
    </a>
  
  
    <a href="/2023/08/05/cs.CV_2023_08_05/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CV - 2023-08-05</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">130</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">130</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">130</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">130</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">61</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">70</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">65</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
