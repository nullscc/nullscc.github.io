
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-22 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="A free from local minima algorithm for training regressive MLP neural networks paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.11532 repo_url: None paper_authors: Augusto Montisci for: 这篇论文旨在提出一种不受地方最小值的多层感知网络训练">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-22 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/22/cs.LG_2023_08_22/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="A free from local minima algorithm for training regressive MLP neural networks paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.11532 repo_url: None paper_authors: Augusto Montisci for: 这篇论文旨在提出一种不受地方最小值的多层感知网络训练">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-21T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:35.420Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.LG_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-22 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-free-from-local-minima-algorithm-for-training-regressive-MLP-neural-networks"><a href="#A-free-from-local-minima-algorithm-for-training-regressive-MLP-neural-networks" class="headerlink" title="A free from local minima algorithm for training regressive MLP neural networks"></a>A free from local minima algorithm for training regressive MLP neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11532">http://arxiv.org/abs/2308.11532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Augusto Montisci</li>
<li>for: 这篇论文旨在提出一种不受地方最小值的多层感知网络训练方法。</li>
<li>methods: 该方法基于训练集分布的特性，通过内部图像来避免地方最小值问题。</li>
<li>results: 研究表明，该方法可以减少地方最小值问题，并且在知名的测试集上达到了良好的性能。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
In this article an innovative method for training regressive MLP networks is presented, which is not subject to local minima. The Error-Back-Propagation algorithm, proposed by William-Hinton-Rummelhart, has had the merit of favouring the development of machine learning techniques, which has permeated every branch of research and technology since the mid-1980s. This extraordinary success is largely due to the black-box approach, but this same factor was also seen as a limitation, as soon more challenging problems were approached. One of the most critical aspects of the training algorithms was that of local minima of the loss function, typically the mean squared error of the output on the training set. In fact, as the most popular training algorithms are driven by the derivatives of the loss function, there is no possibility to evaluate if a reached minimum is local or global. The algorithm presented in this paper avoids the problem of local minima, as the training is based on the properties of the distribution of the training set, or better on its image internal to the neural network. The performance of the algorithm is shown for a well-known benchmark.
</details>
<details>
<summary>摘要</summary>
在本文中，一种创新的多层感知网络训练方法被介绍，不受局部最小点的限制。欧文-希金特-吕姆哈特提出的错误反传播算法，在1980年代中期以来，对机器学习技术的发展做出了重要贡献，这种成功是由黑盒方法引起的，但同时也被认为是局限性的因素。当面临更复杂的问题时，最 kritical的训练算法问题是搜索函数的局部最小点，通常是训练集的平均方差。因为现有最popular的训练算法都是根据损失函数的导数进行驱动，因此无法确定是否到达了局部最小点或全局最小点。本文中提出的算法解决了局部最小点问题，基于训练集的分布性质或更好地说是其内部图像。文章中展示了一个知名的标准 bencmark 的性能。
</details></li>
</ul>
<hr>
<h2 id="ReLiCADA-–-Reservoir-Computing-using-Linear-Cellular-Automata-Design-Algorithm"><a href="#ReLiCADA-–-Reservoir-Computing-using-Linear-Cellular-Automata-Design-Algorithm" class="headerlink" title="ReLiCADA – Reservoir Computing using Linear Cellular Automata Design Algorithm"></a>ReLiCADA – Reservoir Computing using Linear Cellular Automata Design Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11522">http://arxiv.org/abs/2308.11522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Kantic, Fabian C. Legl, Walter Stechele, Jakob Hermann</li>
<li>for: 这个论文目的是提出一种基于细胞自动机模型的泵Computing优化算法，用于处理时间序列应用。</li>
<li>methods: 该算法不仅选择模型的超参数，而且解决了线性细胞自动机规则选择的开放问题。选择方法可以从无限增长的规则空间中预选出一些有潜力的规则。</li>
<li>results: 应用于相关的参考数据集时，选择的规则可以实现低的错误率，其中最佳规则位于总规则空间的前5%。该算法基于细胞自动机属性的数学分析，通过约一百万个实验，计算时间约为一年。与其他现状最佳时间序列模型比较，提出的泵Computing使用细胞自动机模型具有较低的计算复杂度，同时实现较低的错误率。因此，我们的方法可以减少训练和超参数优化所需的时间，达到数量级减少。<details>
<summary>Abstract</summary>
In this paper, we present a novel algorithm to optimize the design of Reservoir Computing using Cellular Automata models for time series applications. Besides selecting the models' hyperparameters, the proposed algorithm particularly solves the open problem of linear Cellular Automaton rule selection. The selection method pre-selects only a few promising candidate rules out of an exponentially growing rule space. When applied to relevant benchmark datasets, the selected rules achieve low errors, with the best rules being among the top 5% of the overall rule space. The algorithm was developed based on mathematical analysis of linear Cellular Automaton properties and is backed by almost one million experiments, adding up to a computational runtime of nearly one year. Comparisons to other state-of-the-art time series models show that the proposed Reservoir Computing using Cellular Automata models have lower computational complexity, at the same time, achieve lower errors. Hence, our approach reduces the time needed for training and hyperparameter optimization by up to several orders of magnitude.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的算法优化储池计算机using Cellular Automata模型 для时间序列应用。除了选择模型的超参数之外，提出的算法特别解决了开放问题，即选择线性Cellular Automaton规则。选择方法先选择了一些有前途的候选规则，从急增的规则空间中选择出来。当应用到相关的标准数据集时，选择的规则都达到了低错误率，最好的规则在总规则空间中排名前5%。算法基于Cellular Automata模型的数学分析和大约一百万个实验，计算时间约为一年。与其他当前最佳时间序列模型进行比较，我们的方法具有较低的计算复杂度，同时实现了较低的错误率。因此，我们的方法可以减少训练和超参数优化所需的时间，可能是数量级减少。
</details></li>
</ul>
<hr>
<h2 id="EM-for-Mixture-of-Linear-Regression-with-Clustered-Data"><a href="#EM-for-Mixture-of-Linear-Regression-with-Clustered-Data" class="headerlink" title="EM for Mixture of Linear Regression with Clustered Data"></a>EM for Mixture of Linear Regression with Clustered Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11518">http://arxiv.org/abs/2308.11518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Reisizadeh, Khashayar Gatmiry, Asuman Ozdaglar</li>
<li>for: 这篇论文是为了提高分布式学习中数据不同性的问题。</li>
<li>methods: 这篇论文使用了Expectation-Maximization（EM）方法来估计两组线性回归问题的最佳参数。</li>
<li>results: 论文显示，如果初始化得当，EM在结构化数据上只需要O(1)迭代iterations来达到同样的统计精度，provided that m grows as e^(o(n))。<details>
<summary>Abstract</summary>
Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from $m$ batches of dependent samples each containing $n$ measurements. Discarding the clustered structure in the mixture model, EM is known to require $O(\log(mn/d))$ iterations to reach the statistical accuracy of $O(\sqrt{d/(mn)})$. In contrast, we show that if initialized properly, EM on the structured data requires only $O(1)$ iterations to reach the same statistical accuracy, as long as $m$ grows up as $e^{o(n)}$. Our analysis establishes and combines novel asymptotic optimization and generalization guarantees for population and empirical EM with dependent samples, which may be of independent interest.
</details>
<details>
<summary>摘要</summary>
现代数据驱动和分布式学习框架面临着各种各样的大量数据，由客户端分布在不同环境中生成。实际上，数据异ogeneity是规模化多个分布式学习模式的主要瓶颈。然而，在许多应用程序中，客户端生成的数据可能会组成带有共同结构的分布，如联邦学习中，所有样本的共同隐变量控制所有样本的分布。因此，可以问到如何利用分布式数据中的下层结构来改进学习方案。在这篇论文中，我们解决这个问题，在特定的两个分布线性回归问题中。我们使用已知的期望-最大化（EM）方法来估算最大有可能性参数，从$m$个批处理中获取$n$个测量结果。不考虑分布式数据中的带有共同结构的混合模型，EM在$O(\log(mn/d))$迭代中可以达到同等的统计准确性，其中$d$是维度，$m$是节点数，$n$是测量结果数。然而，我们证明，如果初始化得当，EM在结构化数据上只需要$O(1)$迭代来达到同等的统计准确性，只要$m$在$e^{o(n)}$中增长。我们的分析提出和组合了新的极限优化和通用验证保证，可能是独立有价值的。
</details></li>
</ul>
<hr>
<h2 id="TrackFlow-Multi-Object-Tracking-with-Normalizing-Flows"><a href="#TrackFlow-Multi-Object-Tracking-with-Normalizing-Flows" class="headerlink" title="TrackFlow: Multi-Object Tracking with Normalizing Flows"></a>TrackFlow: Multi-Object Tracking with Normalizing Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11513">http://arxiv.org/abs/2308.11513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gianluca Mancusi, Aniello Panariello, Angelo Porrello, Matteo Fabbri, Simone Calderara, Rita Cucchiara</li>
<li>for: 提高多对目标跟踪的性能，特别是在多模态场景下。</li>
<li>methods: 基于深度概率分布模型，计算候选关联的成本为负极log值，以提高跟踪检测算法的性能。</li>
<li>results: 对多种跟踪检测算法进行实验，显示我们的方法可以一致提高其性能。<details>
<summary>Abstract</summary>
The field of multi-object tracking has recently seen a renewed interest in the good old schema of tracking-by-detection, as its simplicity and strong priors spare it from the complex design and painful babysitting of tracking-by-attention approaches. In view of this, we aim at extending tracking-by-detection to multi-modal settings, where a comprehensive cost has to be computed from heterogeneous information e.g., 2D motion cues, visual appearance, and pose estimates. More precisely, we follow a case study where a rough estimate of 3D information is also available and must be merged with other traditional metrics (e.g., the IoU). To achieve that, recent approaches resort to either simple rules or complex heuristics to balance the contribution of each cost. However, i) they require careful tuning of tailored hyperparameters on a hold-out set, and ii) they imply these costs to be independent, which does not hold in reality. We address these issues by building upon an elegant probabilistic formulation, which considers the cost of a candidate association as the negative log-likelihood yielded by a deep density estimator, trained to model the conditional joint probability distribution of correct associations. Our experiments, conducted on both simulated and real benchmarks, show that our approach consistently enhances the performance of several tracking-by-detection algorithms.
</details>
<details>
<summary>摘要</summary>
“multi-object tracking领域最近又重新启发了使用检测方法的古老schema，因为它的简单性和强有力的假设，使其不需要复杂的设计和痛苦的照顾，相比之下，tracking-by-attention方法更加复杂。在视野内，我们想扩展tracking-by-detection到多modal设置，在其中需要从多种不同的信息（例如2D运动cue、视觉外观和姿态估计）计算全面的成本。更准确地说，我们采用了一个实际案例，其中有一个粗略的3D信息估计也可以与传统的metric（例如IoU）一起使用。为了实现这一点，现有的方法通常采用简单的规则或复杂的规则来均衡每个成本的贡献。然而，这些方法有以下两个问题：一是需要精心调整特定的超参数，二是它们假设成本是独立的，这并不符合实际情况。我们解决这些问题 by 建立在一种简洁的概率形式上，即使用深度概率分布来模型correct association的 conditional joint probability distribution。我们的实验在模拟和实际 benchmark上展示了我们的方法可以不断提高多个tracking-by-detection算法的性能。”
</details></li>
</ul>
<hr>
<h2 id="Mode-Combinability-Exploring-Convex-Combinations-of-Permutation-Aligned-Models"><a href="#Mode-Combinability-Exploring-Convex-Combinations-of-Permutation-Aligned-Models" class="headerlink" title="Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models"></a>Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11511">http://arxiv.org/abs/2308.11511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrián Csiszárik, Melinda F. Kiss, Péter Kőrösi-Szabó, Márton Muntag, Gergely Papp, Dániel Varga</li>
<li>for: 本文研究了两个嵌入型神经网络参数 вектора $\Theta_A$ 和 $\Theta_B$ 的元素wise convex combination，以探索这些模型组合的可行性和特性。</li>
<li>methods: 作者采用了大量的实验，对不同的模型组合 parametrized by $[0,1]^d$ 的元素进行了探索，发现了广泛的超平面存在低损值，这表明了线性模式连接的概念扩展到一般情况，称为模式可 conjugacy。</li>
<li>results: 作者发现了一些新的线性模式连接和模型重新定位的观察结果，包括模型重新定位的转移性和稳定性，以及模型组合的功能和权重相似性。<details>
<summary>Abstract</summary>
We explore element-wise convex combinations of two permutation-aligned neural network parameter vectors $\Theta_A$ and $\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are non-vacuous in the sense that there are significant functional differences between the resulting models.
</details>
<details>
<summary>摘要</summary>
我们探索两个 permutation-aligned 神经网络参数 вектор $\Theta_A$ 和 $\Theta_B$ 的元素层次 convex 组合。我们进行了广泛的实验，检查了不同的模型组合参数化的元素随机分布在 $[0,1]^d$ 和其邻近区域，我们的发现表明，广泛的区域在卷积体中形成低损值表面，这表明了线性模式连接的概念扩展到一般现象，我们称之为模式可组合性。我们还做了一些新的观察，包括线性模式连接和模型重定向。我们证明了两个模型重定向到共同的第三模型时，也是线性模式连接的，并且在神经元匹配的干扰下，得到的组合仍然可以形成一个工作模型。此外，我们分析了模型组合的功能和权重相似性，并证明了这些组合不是空的，即存在 significativ functional differences  между得到的模型。
</details></li>
</ul>
<hr>
<h2 id="Can-Authorship-Representation-Learning-Capture-Stylistic-Features"><a href="#Can-Authorship-Representation-Learning-Capture-Stylistic-Features" class="headerlink" title="Can Authorship Representation Learning Capture Stylistic Features?"></a>Can Authorship Representation Learning Capture Stylistic Features?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11490">http://arxiv.org/abs/2308.11490</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llnl/luar">https://github.com/llnl/luar</a></li>
<li>paper_authors: Andrew Wang, Cristina Aggazzotti, Rebecca Kotula, Rafael Rivera Soto, Marcus Bishop, Nicholas Andrews</li>
<li>for: 这篇论文主要是为了研究如何自动分离作者的风格和内容。</li>
<li>methods: 这篇论文使用了数据驱动的方法来学习作者表示，并通过一系列定制的实验来评估这些表示是否能够捕捉作者的风格。</li>
<li>results: 研究发现，这些表示确实受到作者的风格影响，并且可能对于某些类型的数据变换（如时间上的话题变化）具有一定的Robustness。这些结果可能对于应用于风格转换等下渠应用有所帮助。<details>
<summary>Abstract</summary>
Automatically disentangling an author's style from the content of their writing is a longstanding and possibly insurmountable problem in computational linguistics. At the same time, the availability of large text corpora furnished with author labels has recently enabled learning authorship representations in a purely data-driven manner for authorship attribution, a task that ostensibly depends to a greater extent on encoding writing style than encoding content. However, success on this surrogate task does not ensure that such representations capture writing style since authorship could also be correlated with other latent variables, such as topic. In an effort to better understand the nature of the information these representations convey, and specifically to validate the hypothesis that they chiefly encode writing style, we systematically probe these representations through a series of targeted experiments. The results of these experiments suggest that representations learned for the surrogate authorship prediction task are indeed sensitive to writing style. As a consequence, authorship representations may be expected to be robust to certain kinds of data shift, such as topic drift over time. Additionally, our findings may open the door to downstream applications that require stylistic representations, such as style transfer.
</details>
<details>
<summary>摘要</summary>
自动分离作者的风格从他们的写作内容是计算语言学领域的长期问题。同时，Recently有大量的文本 corpus 提供了作者标签，使得可以通过数据驱动方式学习作者表示。然而，这种表示是否真的捕捉了作者的风格呢？我们通过系统的实验来彻底检验这些表示是否具有风格特征。结果表明，这些表示对作者预测任务有高度敏感性，表明它们主要捕捉了作者的风格。这意味着作者表示可能对某些类型的数据变换具有较高的Robustness，例如在时间上的话题变化。此外，我们的发现可能开启了在下游应用中使用风格表示的可能性，如样式转移。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Sensitivity-to-The-Order-of-Options-in-Multiple-Choice-Questions"><a href="#Large-Language-Models-Sensitivity-to-The-Order-of-Options-in-Multiple-Choice-Questions" class="headerlink" title="Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions"></a>Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11483">http://arxiv.org/abs/2308.11483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pouya Pezeshkpour, Estevam Hruschka</li>
<li>for:  investigate the sensitivity of large language models (LLMs) towards the order of options in multiple-choice questions, and to understand the underlying reasons for this sensitivity.</li>
<li>methods:  the authors use various benchmarks and experiments to study the performance of LLMs on multiple-choice questions, and they adopt two approaches to calibrate the models’ predictions.</li>
<li>results:  the authors find a significant performance gap of approximately 13% to 75% in LLMs on different benchmarks when answer options are reordered, and they identify patterns in top-2 choices that amplify or mitigate the model’s bias toward option placement. Additionally, they show that calibrating the models’ predictions can improve their performance by up to 8 percentage points across different models and benchmarks.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions -- commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specific options placements may favor certain prediction between those top choices depending on the question caused by positional bias. We also identify patterns in top-2 choices that amplify or mitigate the model's bias toward option placement. We found that for amplifying bias, the optimal strategy involves positioning the top two choices as the first and last options. Conversely, to mitigate bias, we recommend placing these choices among the adjacent options. To validate our conjecture, we conduct various experiments and adopt two approaches to calibrate LLMs' predictions, leading to up to 8 percentage points improvement across different models and benchmarks.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在不同的自然语言处理任务中表现出了很好的能力。然而，之前的研究表明这些模型对示例语言和示例的顺序有敏感性，这会带来评估这些模型的困难。随着这些模型的力量的提高，我们需要更好地理解和解决这些局限性。在这篇论文中，我们关注LLM在多选题上的Robustness——一个常用的任务来评估这些模型的理解和知识检索能力。我们发现，当选项的顺序变化时，LLM的表现会受到较大的影响，在不同的benchmark上，表现差距可达13%到75%，即使使用几个示例。通过详细分析，我们推断这种敏感性是由于LLM在前两选项之间的uncertainty，specific option placement可能会对certain prediction between those top choices产生影响，这是因为位置偏好。我们还发现了在top-2选项之间的抗抑补偏好和增强偏好的模式。对于增强偏好，我们发现可以将top two选项放在第一和最后的位置。相反，为了减轻偏好，我们建议将这些选项放在相邻的位置。为了证明我们的推断，我们进行了多种实验和采用了两种方法来调整LLM的预测，导致在不同的模型和benchmark上的改进率达到8%。
</details></li>
</ul>
<hr>
<h2 id="Expecting-The-Unexpected-Towards-Broad-Out-Of-Distribution-Detection"><a href="#Expecting-The-Unexpected-Towards-Broad-Out-Of-Distribution-Detection" class="headerlink" title="Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection"></a>Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11480">http://arxiv.org/abs/2308.11480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/servicenow/broad-openood">https://github.com/servicenow/broad-openood</a></li>
<li>paper_authors: Charles Guille-Escuret, Pierre-André Noël, Ioannis Mitliagkas, David Vazquez, Joao Monteiro</li>
<li>for: 本研究旨在提高部署在机器学习系统上的可靠性，通过开发检测异常输入（Out-of-distribution，OOD）方法。</li>
<li>methods: 我们分类了五种不同类型的分布偏移，并评估了最新的OOD检测方法在每种分布偏移下的表现。</li>
<li>results: 我们发现，现有方法可以很好地检测未知类别的异常输入，但它们在其他类型的分布偏移下表现不一致。即，它们只可以可靠地检测它们已经特定地设计来预期的异常输入。我们通过学习现有检测分数的生成模型，提出了一种ensemble方法，可以为广泛的OOD检测提供一种更加一致和全面的解决方案，并证明其性能比现有方法更高。<details>
<summary>Abstract</summary>
Improving the reliability of deployed machine learning systems often involves developing methods to detect out-of-distribution (OOD) inputs. However, existing research often narrowly focuses on samples from classes that are absent from the training set, neglecting other types of plausible distribution shifts. This limitation reduces the applicability of these methods in real-world scenarios, where systems encounter a wide variety of anomalous inputs. In this study, we categorize five distinct types of distribution shifts and critically evaluate the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expect. As a first step toward broad OOD detection, we learn a generative model of existing detection scores with a Gaussian mixture. By doing so, we present an ensemble approach that offers a more consistent and comprehensive solution for broad OOD detection, demonstrating superior performance compared to existing methods. Our code to download BROAD and reproduce our experiments is publicly available.
</details>
<details>
<summary>摘要</summary>
增强已部署的机器学习系统的可靠性通常需要开发检测异常输入（OOD）的方法。然而，现有研究通常只关注未在训练集中出现的样本，忽略其他类型的可能的分布Shift。这种限制使得这些方法在实际应用中的可用性受到限制，因为系统会遇到各种异常输入。在本研究中，我们将五种不同类型的分布Shift分类，并且严格评估最近的OOD检测方法在每一类中的性能。我们将这些数据集公开发布，名为BROAD（Benchmarking Resilience Over Anomaly Diversity）。我们的发现表明，虽然这些方法可以很好地检测未知的类别，但是它们在其他类型的分布Shift下的性能不一致。即它们只能可靠地检测它们已经特定地设计来预期的异常输入。作为广泛OOD检测的第一步，我们学习了现有检测分数的生成模型，使用高斯混合模型。通过这种ensemble方法，我们提供了一种更加一致和全面的广泛OOD检测解决方案，并且在与现有方法进行比较时表现出了superior的性能。我们在下载BROAD和复现我们的实验的代码是公开可用的。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-column-generation-based-matheuristic-for-learning-classification-trees"><a href="#Revisiting-column-generation-based-matheuristic-for-learning-classification-trees" class="headerlink" title="Revisiting column-generation-based matheuristic for learning classification trees"></a>Revisiting column-generation-based matheuristic for learning classification trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11477">http://arxiv.org/abs/2308.11477</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krooonal/col_gen_estimator">https://github.com/krooonal/col_gen_estimator</a></li>
<li>paper_authors: Krunal Kishor Patel, Guy Desaulniers, Andrea Lodi</li>
<li>for: 提高分类问题中decision trees的准确性和可扩展性</li>
<li>methods: 使用列生成方法优化decision trees的训练</li>
<li>results: 提高了分类问题中decision trees的准确性和可扩展性，并且可以处理大型数据集<details>
<summary>Abstract</summary>
Decision trees are highly interpretable models for solving classification problems in machine learning (ML). The standard ML algorithms for training decision trees are fast but generate suboptimal trees in terms of accuracy. Other discrete optimization models in the literature address the optimality problem but only work well on relatively small datasets. \cite{firat2020column} proposed a column-generation-based heuristic approach for learning decision trees. This approach improves scalability and can work with large datasets. In this paper, we describe improvements to this column generation approach. First, we modify the subproblem model to significantly reduce the number of subproblems in multiclass classification instances. Next, we show that the data-dependent constraints in the master problem are implied, and use them as cutting planes. Furthermore, we describe a separation model to generate data points for which the linear programming relaxation solution violates their corresponding constraints. We conclude by presenting computational results that show that these modifications result in better scalability.
</details>
<details>
<summary>摘要</summary>
决策树是机器学习中高度可解释的模型，用于解决分类问题。标准的机器学习算法可以快速训练决策树，但是会生成准确性不高的树。文献中的其他离散优化模型可以解决优化问题，但只能在较小的数据集上工作。 \cite{firat2020column} 提出了一种基于列生成的规则方法来学习决策树。这种方法可以扩展到大型数据集。在这篇论文中，我们介绍了对这种列生成方法的改进。首先，我们修改了多类分类实例中的子问题模型，以Significantly reduce the number of subproblems。然后，我们显示了数据依赖的约束在主问题中被含有，并使用它们作为裁剪平面。此外，我们描述了一种分离模型，用于生成具有Linear programming relaxation solution违反其相应约束的数据点。我们 conclude by presenting computational results that show that these modifications result in better scalability。
</details></li>
</ul>
<hr>
<h2 id="Internal-Cross-layer-Gradients-for-Extending-Homogeneity-to-Heterogeneity-in-Federated-Learning"><a href="#Internal-Cross-layer-Gradients-for-Extending-Homogeneity-to-Heterogeneity-in-Federated-Learning" class="headerlink" title="Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"></a>Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11464">http://arxiv.org/abs/2308.11464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun-Hin Chan, Rui Zhou, Running Zhao, Zhihan Jiang, Edith C. -H. Ngai</li>
<li>for: 提高实际场景中 Federated Learning（FL）系统的兼容性和灵活性。</li>
<li>methods: 提出一种基于内部相似层次梯度的聚合方法，可以增强深层模型之间的相似性，无需更多的客户端之间的交流。</li>
<li>results: 经验证明，该方法可以提高FL系统的性能，并且可以跨种模型进行扩展。<details>
<summary>Abstract</summary>
Federated learning (FL) inevitably confronts the challenge of system heterogeneity in practical scenarios. To enhance the capabilities of most model-homogeneous FL methods in handling system heterogeneity, we propose a training scheme that can extend their capabilities to cope with this challenge. In this paper, we commence our study with a detailed exploration of homogeneous and heterogeneous FL settings and discover three key observations: (1) a positive correlation between client performance and layer similarities, (2) higher similarities in the shallow layers in contrast to the deep layers, and (3) the smoother gradients distributions indicate the higher layer similarities. Building upon these observations, we propose InCo Aggregation that leverags internal cross-layer gradients, a mixture of gradients from shallow and deep layers within a server model, to augment the similarity in the deep layers without requiring additional communication between clients. Furthermore, our methods can be tailored to accommodate model-homogeneous FL methods such as FedAvg, FedProx, FedNova, Scaffold, and MOON, to expand their capabilities to handle the system heterogeneity. Copious experimental results validate the effectiveness of InCo Aggregation, spotlighting internal cross-layer gradients as a promising avenue to enhance the performance in heterogenous FL.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）在实际应用中会面临系统不同性的挑战。为了增强大多数模型同质FL方法的处理能力，我们提出了一个训练方案，可以将其扩展到处理这个挑战。在这篇论文中，我们开始我们的研究，进行了详细的探索同质和不同质FL环境，发现了三个关键观察结果：（1）客户端性能与层 Similarity 之间存在正相关，（2）在浅层比深层更高的 Similarity，（3）更平滑的梯度分布显示了更高的层 Similarity。基于这些观察结果，我们提出了内部混合层梯度（InCo Aggregation），利用服务器模型内部的混合梯度，以增强深层层 Similarity 而无需更多的客户端通信。此外，我们的方法可以与模型同质FL方法，如FedAvg、FedProx、FedNova、Scaffold和MOON，整合，扩展其处理能力，处理不同系统的挑战。丰富的实验结果证明了InCo Aggregation 的效果，显示了内部混合层梯度作为提高hetrogenous FL性能的有前途之路。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning"><a href="#An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning" class="headerlink" title="An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning"></a>An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11677">http://arxiv.org/abs/2308.11677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grégoire Petit, Michael Soumm, Eva Feillet, Adrian Popescu, Bertrand Delezoide, David Picard, Céline Hudelot</li>
<li>for: 本研究的目的是研究分类模型在数据流中建立和维护的问题，具体来说是在不能保留过去类的情况下，通过累积学习来逐步增加新类。</li>
<li>methods: 本研究使用了累积学习的增量学习策略，并对不同的策略、神经网络架构、目标任务、类别分布和数据量进行了广泛的实验研究。</li>
<li>results: 研究发现，初始训练策略是增量性能的主要影响因素，但是选择适合的增量学习算法更重要地防止忘记。基于这些分析结果，提出了实践中增量学习的实用建议。<details>
<summary>Abstract</summary>
Class-Incremental Learning (CIL) aims to build classification models from data streams. At each step of the CIL process, new classes must be integrated into the model. Due to catastrophic forgetting, CIL is particularly challenging when examples from past classes cannot be stored, the case on which we focus here. To date, most approaches are based exclusively on the target dataset of the CIL process. However, the use of models pre-trained in a self-supervised way on large amounts of data has recently gained momentum. The initial model of the CIL process may only use the first batch of the target dataset, or also use pre-trained weights obtained on an auxiliary dataset. The choice between these two initial learning strategies can significantly influence the performance of the incremental learning model, but has not yet been studied in depth. Performance is also influenced by the choice of the CIL algorithm, the neural architecture, the nature of the target task, the distribution of classes in the stream and the number of examples available for learning. We conduct a comprehensive experimental study to assess the roles of these factors. We present a statistical analysis framework that quantifies the relative contribution of each factor to incremental performance. Our main finding is that the initial training strategy is the dominant factor influencing the average incremental accuracy, but that the choice of CIL algorithm is more important in preventing forgetting. Based on this analysis, we propose practical recommendations for choosing the right initial training strategy for a given incremental learning use case. These recommendations are intended to facilitate the practical deployment of incremental learning.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:类cremental Learning (CIL) 目标是从数据流中建立分类模型。在每个步骤中，新的类需要被添加到模型中。由于悬崖式忘记，CIL 特别在不能存储过去类例时是挑战。到目前为止，大多数方法都是专注于目标数据集。然而，使用基于大量数据的自动学习模型的预训练方法在最近几年中得到了迅速发展。CIL 过程的初始模型可以使用目标数据集的第一个批处或者使用 auxiliary 数据集上预训练的模型。这两种初始学习策略的选择会对增量性表现产生重要的影响，但是这个问题还没有得到深入的研究。增量表现的性能也受到 CIL 算法、神经网络架构、任务性质、类别分布和学习例数的影响。我们进行了全面的实验研究，以评估这些因素对增量性表现的影响。我们提供了一个统计分析框架，以量化每个因素对增量性表现的贡献。我们的主要发现是，初始训练策略是增量性表现的主导因素，但是选择 CIL 算法更重要地防止忘记。基于这种分析，我们提供了实用的初始训练策略选择指南，这些指南旨在促进实际部署增量学习。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Self-Supervised-Representation-Learning"><a href="#A-Survey-on-Self-Supervised-Representation-Learning" class="headerlink" title="A Survey on Self-Supervised Representation Learning"></a>A Survey on Self-Supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11455">http://arxiv.org/abs/2308.11455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/esvit">https://github.com/microsoft/esvit</a></li>
<li>paper_authors: Tobias Uelwer, Jan Robine, Stefan Sylvius Wagner, Marc Höftmann, Eric Upschulte, Sebastian Konietzny, Maike Behrendt, Stefan Harmeling</li>
<li>for: 本文提供了一个抽象的审视，概述了一些不需要监督学习的图像表示学习方法。</li>
<li>methods: 本文使用了一些不需要监督学习的图像表示学习方法，包括自适应 Representation Learning 方法和卷积神经网络方法。</li>
<li>results: 本文对图像表示学习方法进行了一个系统的审视，并对相关的实验结果进行了一个综合的Meta-study。<details>
<summary>Abstract</summary>
Learning meaningful representations is at the heart of many tasks in the field of modern machine learning. Recently, a lot of methods were introduced that allow learning of image representations without supervision. These representations can then be used in downstream tasks like classification or object detection. The quality of these representations is close to supervised learning, while no labeled images are needed. This survey paper provides a comprehensive review of these methods in a unified notation, points out similarities and differences of these methods, and proposes a taxonomy which sets these methods in relation to each other. Furthermore, our survey summarizes the most-recent experimental results reported in the literature in form of a meta-study. Our survey is intended as a starting point for researchers and practitioners who want to dive into the field of representation learning.
</details>
<details>
<summary>摘要</summary>
学习有意义的表示是现代机器学习领域中的核心任务之一。最近，许多没有监督的方法被引入，可以学习图像表示。这些表示可以在下游任务中使用，如分类或物体检测。这些表示质量与监督学习几乎相同，但无需标注图像。本文提供了这些方法的统一notation，指出了这些方法之间的相似性和差异，并提出了这些方法的分类方法。此外，我们的survey还summarized literaturereported最新的实验结果，以meta-study的形式。本文作为研究者和实践者入门点，准备了涉及表示学习领域的所有信息。
</details></li>
</ul>
<hr>
<h2 id="Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding"><a href="#Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding" class="headerlink" title="Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding"></a>Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11448">http://arxiv.org/abs/2308.11448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiantao Wu, Shentong Mo, Muhammad Awais, Sara Atito, Zhenhua Feng, Josef Kittler</li>
<li>for: 本研究旨在评估无监督学习（SSL）技术在计算机视觉任务中的效果，以便模拟人类对未看过的对象的总结和识别。</li>
<li>methods: 本研究使用了一种基于提示 patch的评估协议来进行零shot segmentation，以及一种内部和外部相似性评估来评估 SSL ViTs 的准确性。</li>
<li>results: 研究发现，通过提取本地特征的相似性和全局特征的准确性，可以提高 SSL ViTs 的准确性和总结能力。此外，提出了一种简单的 SSL 方法，称为 MMC，可以减少内部和外部相似性的重叠，从而实现图像中的有效对象 segmentation。<details>
<summary>Abstract</summary>
Self-supervised pretraining (SSP) has emerged as a popular technique in machine learning, enabling the extraction of meaningful feature representations without labelled data. In the realm of computer vision, pretrained vision transformers (ViTs) have played a pivotal role in advancing transfer learning. Nonetheless, the escalating cost of finetuning these large models has posed a challenge due to the explosion of model size. This study endeavours to evaluate the effectiveness of pure self-supervised learning (SSL) techniques in computer vision tasks, obviating the need for finetuning, with the intention of emulating human-like capabilities in generalisation and recognition of unseen objects. To this end, we propose an evaluation protocol for zero-shot segmentation based on a prompting patch. Given a point on the target object as a prompt, the algorithm calculates the similarity map between the selected patch and other patches, upon that, a simple thresholding is applied to segment the target. Another evaluation is intra-object and inter-object similarity to gauge discriminatory ability of SSP ViTs. Insights from zero-shot segmentation from prompting and discriminatory abilities of SSP led to the design of a simple SSP approach, termed MMC. This approaches combines Masked image modelling for encouraging similarity of local features, Momentum based self-distillation for transferring semantics from global to local features, and global Contrast for promoting semantics of global features, to enhance discriminative representations of SSP ViTs. Consequently, our proposed method significantly reduces the overlap of intra-object and inter-object similarities, thereby facilitating effective object segmentation within an image. Our experiments reveal that MMC delivers top-tier results in zero-shot semantic segmentation across various datasets.
</details>
<details>
<summary>摘要</summary>
自适应预训练（SSP）已经成为机器学习中受欢迎的技术之一，允许无需标注数据抽取有意义的特征表示。在计算机视觉领域，预训练视transformer（ViT）已经发挥了重要的作用，促进了转移学习。然而，模型的规模快速增长，使得训练这些大型模型的成本急剧增加。本研究旨在评估无标注自适应学习（SSL）技术在计算机视觉任务中的效果，不需要训练，以模仿人类的一般化和未看过物体的识别能力。为此，我们提出了一种零shot分割评估方法，基于提示 patch。给定目标对象的一点为提示，算法计算选定 patch 和其他 patches 之间的相似度图，然后应用简单的阈值分割目标。此外，我们还进行了内部和外部相似性评估，以评估 SSL ViTs 的抽象能力。基于零shot分割和抽象能力的发现，我们设计了一种简单的 SSP 方法，称为 MMC。这种方法结合了压缩图像模型，自动填充自适应特征，以及全局对比，以提高 SSL ViTs 的抽象表示能力。因此，我们的提案可以减少内部和外部相似性的重叠，从而实现图像中效果的对象分割。我们的实验表明，MMC 在多个数据集上达到了顶尖的 zero-shot semantic segmentation结果。
</details></li>
</ul>
<hr>
<h2 id="Exploration-of-Rashomon-Set-Assists-Explanations-for-Medical-Data"><a href="#Exploration-of-Rashomon-Set-Assists-Explanations-for-Medical-Data" class="headerlink" title="Exploration of Rashomon Set Assists Explanations for Medical Data"></a>Exploration of Rashomon Set Assists Explanations for Medical Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11446">http://arxiv.org/abs/2308.11446</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarzyna Kobylińska, Mateusz Krzyziński, Rafał Machowicz, Mariusz Adamek, Przemysław Biecek<br>for:This paper aims to address the problem of selecting a single model that maximizes a performance metric in machine learning modeling, particularly in medical and healthcare studies where the objective is to generate valuable insights beyond predictions.methods:The proposed approach uses a novel process to explore the Rashomon set of models, which includes identifying the most different models within the set using the $\texttt{Rashomon_DETECT}$ algorithm and comparing profiles illustrating prediction dependencies on variable values generated by XAI techniques. The Profile Disparity Index (PDI) is introduced to quantify differences in variable effects among models.results:The approach is applied to predict survival among hemophagocytic lymphohistiocytosis (HLH) patients and is shown to be effective in identifying the most informative models. The approach is also benchmarked on other medical data sets, demonstrating its versatility and utility in various contexts.<details>
<summary>Abstract</summary>
The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorithm. This algorithm compares profiles illustrating prediction dependencies on variable values generated by eXplainable Artificial Intelligence (XAI) techniques. To quantify differences in variable effects among models, we introduce the Profile Disparity Index (PDI) based on measures from functional data analysis. To illustrate the effectiveness of our approach, we showcase its application in predicting survival among hemophagocytic lymphohistiocytosis (HLH) patients - a foundational case study. Additionally, we benchmark our approach on other medical data sets, demonstrating its versatility and utility in various contexts.
</details>
<details>
<summary>摘要</summary>
传统的机器学习模型选择过程是选择最大化一个选择性指标的模型。然而，这种方法会忽略一些较差的模型，尤其在医疗和健康研究中， где目标不仅是预测，还是获得有价值的发现。在一个称为“Rashomon set”的集合中，包含一些性能几乎与最佳一样的模型时，这种问题变得非常棘手。这篇论文提出了一种新的方法，以探索Rashomon set模型，从传统模型选择方法的基础上扩展。我们的核心思想是通过引入的 $\texttt{Rashomon_DETECT}$ 算法，确定Rashomon set中最为不同的模型。我们还引入了 Profile Disparity Index（PDI），以量化不同模型中变量效果的差异。我们通过使用扩展ible Artificial Intelligence（XAI）技术生成的变量值预测 Profiling，来评估模型之间的差异。我们在针对 Hemophagocytic lymphohistiocytosis（HLH）患者的存活预测中进行了应用示例，并在其他医疗数据集上进行了多种场景的比较。
</details></li>
</ul>
<hr>
<h2 id="Inferring-gender-from-name-a-large-scale-performance-evaluation-study"><a href="#Inferring-gender-from-name-a-large-scale-performance-evaluation-study" class="headerlink" title="Inferring gender from name: a large scale performance evaluation study"></a>Inferring gender from name: a large scale performance evaluation study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12381">http://arxiv.org/abs/2308.12381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kriste Krstovski, Yao Lu, Ye Xu</li>
<li>for: 本研究旨在评估现有名字到性别推断的方法的性能，以及提出新的混合方法以提高性别推断的准确性。</li>
<li>methods: 本研究使用了多个现有的名字推断算法和软件产品，并对其进行大规模的性能评估。同时，我们还提出了两种新的混合方法，以提高性别推断的准确性。</li>
<li>results: 研究结果显示，现有的名字推断方法在不同的数据集上的性能差异较大。此外，我们还发现了一些新的混合方法，可以提高性别推断的准确性。<details>
<summary>Abstract</summary>
A person's gender is a crucial piece of information when performing research across a wide range of scientific disciplines, such as medicine, sociology, political science, and economics, to name a few. However, in increasing instances, especially given the proliferation of big data, gender information is not readily available. In such cases researchers need to infer gender from readily available information, primarily from persons' names. While inferring gender from name may raise some ethical questions, the lack of viable alternatives means that researchers have to resort to such approaches when the goal justifies the means - in the majority of such studies the goal is to examine patterns and determinants of gender disparities. The necessity of name-to-gender inference has generated an ever-growing domain of algorithmic approaches and software products. These approaches have been used throughout the world in academia, industry, governmental and non-governmental organizations. Nevertheless, the existing approaches have yet to be systematically evaluated and compared, making it challenging to determine the optimal approach for future research. In this work, we conducted a large scale performance evaluation of existing approaches for name-to-gender inference. Analysis are performed using a variety of large annotated datasets of names. We further propose two new hybrid approaches that achieve better performance than any single existing approach.
</details>
<details>
<summary>摘要</summary>
人的性别信息是科学研究的重要参数，广泛应用于医学、社会学、政治科学和经济等多个领域。然而，随着大数据的普及， gender信息越来越难以获得。在这些情况下，研究人员需要从可用的信息中推断性别，主要来自人名。虽然这可能会提出一些伦理问题，但由于没有可靠的替代方案，研究人员需要采用这种方法，以达到研究目标。由于这种方法在全球各地的学术机构、产业、政府和非政府组织中都有广泛应用，因此需要系统地评估和比较现有的方法，以确定未来研究中最佳的方法。在这项工作中，我们进行了大规模性能评估现有的名称到性别推断方法。我们使用了多个大型注释的名称集来进行分析，并提出了两种新的混合方法，其性能比任何单独的现有方法更高。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-the-Impact-of-Non-confounding-Covariates-on-the-Inferential-Performance-of-Methods-based-on-the-Potential-Outcome-Framework"><a href="#A-Study-on-the-Impact-of-Non-confounding-Covariates-on-the-Inferential-Performance-of-Methods-based-on-the-Potential-Outcome-Framework" class="headerlink" title="A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework"></a>A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11676">http://arxiv.org/abs/2308.11676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghe Zhao, Shuai Fu, Huiyan Sun</li>
<li>for: 这个论文的主要目标是解释 causal inference 中 confounding 问题的几种方法，以及这些方法如何处理高维 covariates。</li>
<li>methods: 这个论文使用了 Potential Outcome Framework (POF) 和 causal inference models based on POF (CIMs-B-POF)，并对这些模型的应用进行了系统性的分析。</li>
<li>results: 研究发现，在减少偏见时，最佳情况是 covariates 仅包含 confounders；在推断 counterfactual outcomes 时，调整变量对准确预测做出了贡献。此外，对 synthetic datasets 进行了广泛的实验，并经过了 теоретиче分析。<details>
<summary>Abstract</summary>
The Potential Outcome Framework (POF) plays a prominent role in the field of causal inference. Most causal inference models based on the POF (CIMs-B-POF) are designed for eliminating confounding bias and default to an underlying assumption of Confounding Covariates. This assumption posits that the covariates consist solely of confounders. However, the assumption of Confounding Covariates is challenging to maintain in practice, particularly when dealing with high-dimensional covariates. While certain methods have been proposed to differentiate the distinct components of covariates prior to conducting causal inference, the consequences of treating non-confounding covariates as confounders remain unclear. This ambiguity poses a potential risk when applying the CIMs-B-POF in practical scenarios. In this paper, we present a unified graphical framework for the CIMs-B-POF, which greatly enhances the comprehension of these models' underlying principles. Using this graphical framework, we quantitatively analyze the extent to which the inference performance of CIMs-B-POF is influenced when incorporating various types of non-confounding covariates, such as instrumental variables, mediators, colliders, and adjustment variables. The key findings are: in the task of eliminating confounding bias, the optimal scenario is for the covariates to exclusively encompass confounders; in the subsequent task of inferring counterfactual outcomes, the adjustment variables contribute to more accurate inferences. Furthermore, extensive experiments conducted on synthetic datasets consistently validate these theoretical conclusions.
</details>
<details>
<summary>摘要</summary>
《潜在结果框架（POF）在 causal inference 领域发挥突出作用。大多数基于 POF 的 causal inference 模型（CIMs-B-POF）是设计用于消除干扰偏见的，默认假设是 Confounding Covariates 假设。这个假设认为covariates 仅仅包含干扰因素。然而，在实践中保持 Confounding Covariates 假设是困难的，特别是面临高维 covariates 时。虽然一些方法已经提出来分解 covariates 的不同组成部分以前进行 causal inference，但对于不是干扰因素的 covariates 的处理仍然存在uncertainty。这种不确定性可能会在实践中应用 CIMs-B-POF 时产生风险。在这篇论文中，我们提出了一个统一的图形框架 для CIMs-B-POF，这有助于更好地理解这些模型的内在原理。使用这个图形框架，我们量化分析了 CIMs-B-POF 在不同类型的非干扰 covariates （如工具变量、中介变量、冲击变量和调整变量）的 incorporation 影响了 causal inference 的性能。我们发现，在消除干扰偏见的任务中，covariates 应该仅仅包含干扰因素；在接下来的计算Counterfactual 结果任务中，调整变量对更加准确的推断做出了贡献。此外，我们在 synthetic 数据上进行了广泛的实验，并 consistently 验证了这些理论结论。
</details></li>
</ul>
<hr>
<h2 id="TurboViT-Generating-Fast-Vision-Transformers-via-Generative-Architecture-Search"><a href="#TurboViT-Generating-Fast-Vision-Transformers-via-Generative-Architecture-Search" class="headerlink" title="TurboViT: Generating Fast Vision Transformers via Generative Architecture Search"></a>TurboViT: Generating Fast Vision Transformers via Generative Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11421">http://arxiv.org/abs/2308.11421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Wong, Saad Abbasi, Saeejith Nair</li>
<li>for: 本研究旨在设计高效的视觉 трансформер架构，以满足高速、低内存的应用需求。</li>
<li>methods: 本研究使用生成架构搜索（GAS）技术，通过搜索和优化mask单元注意力和Q-pooling设计模式，生成高效的层次结构视觉 трансформер架构设计。</li>
<li>results: 对于ImageNet-1K数据集，TurboViT架构设计在同等准确性下，与10个状态的有效视觉 трансформер网络架构设计相比，具有较低的建筑计算复杂度（&gt;2.47倍小于FasterViT-0）和计算复杂度（&gt;3.4倍少于MobileViT2-2.0），同时在低延迟和批处理场景中也表现出了优秀的执行速度和吞吐量（&gt;3.21倍低于FasterViT-0的延迟和&gt;3.18倍高于MobileViT2-2.0）。<details>
<summary>Abstract</summary>
Vision transformers have shown unprecedented levels of performance in tackling various visual perception tasks in recent years. However, the architectural and computational complexity of such network architectures have made them challenging to deploy in real-world applications with high-throughput, low-memory requirements. As such, there has been significant research recently on the design of efficient vision transformer architectures. In this study, we explore the generation of fast vision transformer architecture designs via generative architecture search (GAS) to achieve a strong balance between accuracy and architectural and computational efficiency. Through this generative architecture search process, we create TurboViT, a highly efficient hierarchical vision transformer architecture design that is generated around mask unit attention and Q-pooling design patterns. The resulting TurboViT architecture design achieves significantly lower architectural computational complexity (>2.47$\times$ smaller than FasterViT-0 while achieving same accuracy) and computational complexity (>3.4$\times$ fewer FLOPs and 0.9% higher accuracy than MobileViT2-2.0) when compared to 10 other state-of-the-art efficient vision transformer network architecture designs within a similar range of accuracy on the ImageNet-1K dataset. Furthermore, TurboViT demonstrated strong inference latency and throughput in both low-latency and batch processing scenarios (>3.21$\times$ lower latency and >3.18$\times$ higher throughput compared to FasterViT-0 for low-latency scenario). These promising results demonstrate the efficacy of leveraging generative architecture search for generating efficient transformer architecture designs for high-throughput scenarios.
</details>
<details>
<summary>摘要</summary>
视transformer在近年来的视觉任务中表现出了无 precedent的水平。然而，这些网络架构的建筑和计算复杂性使其在实际应用中高throughput低内存要求下部署成为了挑战。因此，有一些研究最近关于效率视transformer架构设计。在这项研究中，我们通过生成架构搜索（GAS）生成高效的视transformer架构设计，以达到精准和建筑计算效率的平衡。通过这种生成架构搜索过程，我们创造了TurboViT，一种高效的层次结构视transformer架构设计，围绕着面积单元注意力和Q-pooling设计模式。得到的TurboViT架构设计在与其他10种状态当前高效视transformer网络架构设计相比，在ImageNet-1K dataset上实现了明显的建筑计算复杂性下降（>2.47倍小于FasterViT-0，同等精准）和计算复杂性下降（>3.4倍少于MobileViT2-2.0，同等精准）。此外，TurboViT在低延迟和批处理场景中显示出了强大的执行速度和吞吐量（>3.21倍低于FasterViT-0的延迟和>3.18倍高于MobileViT2-2.0）。这些出色的结果证明了利用生成架构搜索生成高效的transformer架构设计的可行性。
</details></li>
</ul>
<hr>
<h2 id="Designing-an-attack-defense-game-how-to-increase-robustness-of-financial-transaction-models-via-a-competition"><a href="#Designing-an-attack-defense-game-how-to-increase-robustness-of-financial-transaction-models-via-a-competition" class="headerlink" title="Designing an attack-defense game: how to increase robustness of financial transaction models via a competition"></a>Designing an attack-defense game: how to increase robustness of financial transaction models via a competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11406">http://arxiv.org/abs/2308.11406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexey Zaytsev, Alex Natekin, Evgeni Vorsin, Valerii Smirnov, Georgii Smirnov, Oleg Sidorshin, Alexander Senin, Alexander Dudin, Dmitry Berestnev</li>
<li>for: 这种研究旨在 Investigating the current state and dynamics of adversarial attacks and defenses for neural network models that use sequential financial data as the input.</li>
<li>methods: 作者们使用了一场竞赛来进行实际和详细的研究问题，并对现代金融交易数据进行了实际应用。</li>
<li>results: 研究发现了一些新的攻击和防御策略，并证明了这些策略在现实生活中的可行性和有效性。<details>
<summary>Abstract</summary>
Given the escalating risks of malicious attacks in the finance sector and the consequential severe damage, a thorough understanding of adversarial strategies and robust defense mechanisms for machine learning models is critical. The threat becomes even more severe with the increased adoption in banks more accurate, but potentially fragile neural networks. We aim to investigate the current state and dynamics of adversarial attacks and defenses for neural network models that use sequential financial data as the input.   To achieve this goal, we have designed a competition that allows realistic and detailed investigation of problems in modern financial transaction data. The participants compete directly against each other, so possible attacks and defenses are examined in close-to-real-life conditions. Our main contributions are the analysis of the competition dynamics that answers the questions on how important it is to conceal a model from malicious users, how long does it take to break it, and what techniques one should use to make it more robust, and introduction additional way to attack models or increase their robustness.   Our analysis continues with a meta-study on the used approaches with their power, numerical experiments, and accompanied ablations studies. We show that the developed attacks and defenses outperform existing alternatives from the literature while being practical in terms of execution, proving the validity of the competition as a tool for uncovering vulnerabilities of machine learning models and mitigating them in various domains.
</details>
<details>
<summary>摘要</summary>
随着金融业的风险增加，机器学习模型的攻击和防御技术成为了紧迫的问题。随着银行更广泛地应用更加准确但可能脆弱的神经网络，这种威胁变得更加严重。我们希望通过研究现有的敌对攻击和防御策略来深入理解这些机器学习模型在使用时的漏洞和攻击方法。为了实现这一目标，我们设计了一项竞赛，允许参与者在真实的金融交易数据上进行实际的攻击和防御研究。参与者在直接对抗的环境中竞争，这使得可能的攻击和防御策略得到了充分的检验。我们的主要贡献包括对竞赛的竞争动态进行分析，回答如何隐藏模型于恶意用户，模型如何快速被破坏，以及如何使模型更加坚强的问题。我们的分析继续进行meta研究，对使用的方法进行评估，并通过数学实验和附加的ablation研究来证明我们的攻击和防御策略的有效性。我们的结果显示，我们提出的攻击和防御策略在实施上具有优势，并在不同领域中能够实现有效的抵御。因此，我们的竞赛和分析证明了竞赛是一种有效的工具，用于探索机器学习模型的漏洞并实现其在不同领域的防御。
</details></li>
</ul>
<hr>
<h2 id="Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer"><a href="#Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer" class="headerlink" title="Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer"></a>Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11389">http://arxiv.org/abs/2308.11389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebeca Vétil, Clément Abi-Nader, Alexandre Bône, Marie-Pierre Vullierme, Marc-Michel Rohé, Pietro Gori, Isabelle Bloch</li>
<li>for: 这篇论文旨在解决深度学习医学影像特征（DLR）和手工设计医学影像特征（HCR）之间的重叠问题。</li>
<li>methods: 作者使用VAE实现DLR特征EXTRACTING，并通过最小化这两种特征之间的相互信息来保持其独立性。</li>
<li>results: 研究结果显示，结合非重叠DLR和HCR特征可以提高预测早期肝癌标志物的精度，相比基eline方法不 Addressing redundancy or solely relying on HCR features。<details>
<summary>Abstract</summary>
We address the problem of learning Deep Learning Radiomics (DLR) that are not redundant with Hand-Crafted Radiomics (HCR). To do so, we extract DLR features using a VAE while enforcing their independence with HCR features by minimizing their mutual information. The resulting DLR features can be combined with hand-crafted ones and leveraged by a classifier to predict early markers of cancer. We illustrate our method on four early markers of pancreatic cancer and validate it on a large independent test set. Our results highlight the value of combining non-redundant DLR and HCR features, as evidenced by an improvement in the Area Under the Curve compared to baseline methods that do not address redundancy or solely rely on HCR features.
</details>
<details>
<summary>摘要</summary>
我们对深度学习医学图像学习（DLR）进行非重复的应用，以避免与手工医学图像学习（HCR）的重复。我们使用VAE对DLR特征进行提取，并在HCR特征和DLR特征之间强制独立性，以避免它们之间的相互信息。得到的DLR特征可以与手工医学图像学习特征结合，并由分类器使用以预测肝癌的早期标志。我们在四种肝癌早期标志上运算我们的方法，并在一个大的独立测试集上验证。我们的结果表明，结合非重复的DLR和HCR特征可以提高预测性能，比基eline方法不 Addressing redundancy or solely relying on HCR features。
</details></li>
</ul>
<hr>
<h2 id="Targeted-Data-Augmentation-for-bias-mitigation"><a href="#Targeted-Data-Augmentation-for-bias-mitigation" class="headerlink" title="Targeted Data Augmentation for bias mitigation"></a>Targeted Data Augmentation for bias mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11386">http://arxiv.org/abs/2308.11386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Maria Ferlin, Michał Grochowski</li>
<li>For: The paper aims to address the issue of bias in AI systems by introducing a novel approach called Targeted Data Augmentation (TDA).* Methods: The paper uses classical data augmentation techniques to insert biases into the training data, which helps to mitigate biases in the models.* Results: The paper shows that the proposed TDA approach can significantly decrease bias measures while maintaining a negligible increase in the error rate, using two diverse datasets of clinical skin lesions and male and female faces.Here are the three key points in Simplified Chinese text:* For: 这篇论文目标是解决人工智能系统中的偏见问题，提出了一种新的方法called Targeted Data Augmentation (TDA)。* Methods: 这篇论文使用了经典的数据扩展技术，插入了偏见到训练数据中，以减少模型中的偏见。* Results: 论文表明，提出的TDA方法可以在两个多样化的数据集上（皮肤病和♂♀脸）获得了显著减少偏见的效果，而且保持了误差率的增加在一定范围内。<details>
<summary>Abstract</summary>
The development of fair and ethical AI systems requires careful consideration of bias mitigation, an area often overlooked or ignored. In this study, we introduce a novel and efficient approach for addressing biases called Targeted Data Augmentation (TDA), which leverages classical data augmentation techniques to tackle the pressing issue of bias in data and models. Unlike the laborious task of removing biases, our method proposes to insert biases instead, resulting in improved performance. To identify biases, we annotated two diverse datasets: a dataset of clinical skin lesions and a dataset of male and female faces. These bias annotations are published for the first time in this study, providing a valuable resource for future research. Through Counterfactual Bias Insertion, we discovered that biases associated with the frame, ruler, and glasses had a significant impact on models. By randomly introducing biases during training, we mitigated these biases and achieved a substantial decrease in bias measures, ranging from two-fold to more than 50-fold, while maintaining a negligible increase in the error rate.
</details>
<details>
<summary>摘要</summary>
发展公平和伦理AI系统需要仔细考虑偏见缓解，这一领域经常被排在第二队列。在这项研究中，我们介绍了一种新的和高效的方法，称为目标数据扩充（TDA），该方法利用经典数据扩充技术来解决数据和模型中的偏见问题。不同于努力地去除偏见，我们的方法提议插入偏见，从而提高性能。为了识别偏见，我们对两个多样化的数据集进行了标注：一个是皮肤病变数据集，另一个是♂♂♀♀脸部数据集。这些偏见标注在本研究中首次公布，为未来研究提供了一个价值的资源。通过对比事实插入偏见，我们发现了框架、尺度和镜片等偏见对模型产生了重要影响。通过在训练过程中随机插入偏见，我们成功缓解了这些偏见，并实现了偏见度量的显著减少，从2倍到更多于50倍，同时保持了错误率的微不足百分之一增加。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Distribution-Invariant-Fairness-Measures-for-Continuous-Scores"><a href="#Interpretable-Distribution-Invariant-Fairness-Measures-for-Continuous-Scores" class="headerlink" title="Interpretable Distribution-Invariant Fairness Measures for Continuous Scores"></a>Interpretable Distribution-Invariant Fairness Measures for Continuous Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11375">http://arxiv.org/abs/2308.11375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ann-Kristin Becker, Oana Dumitrasc, Klaus Broelemann</li>
<li>for: 这篇论文的目的是扩展 binary 决策中的算法公平度量到连续分数上。</li>
<li>methods: 这篇论文提出了一种基于 Wasserstein 距离的分布不变的公平度量方法，这种方法可以快速计算并对不同的模型、数据集、时间点进行比较。</li>
<li>results: 这篇论文通过实验表明，提出的公平度量方法可以更好地捕捉和评估不同群体之间的差异，并且可以比较不同的模型和数据集之间的偏见。<details>
<summary>Abstract</summary>
Measures of algorithmic fairness are usually discussed in the context of binary decisions. We extend the approach to continuous scores. So far, ROC-based measures have mainly been suggested for this purpose. Other existing methods depend heavily on the distribution of scores, are unsuitable for ranking tasks, or their effect sizes are not interpretable. Here, we propose a distributionally invariant version of fairness measures for continuous scores with a reasonable interpretation based on the Wasserstein distance. Our measures are easily computable and well suited for quantifying and interpreting the strength of group disparities as well as for comparing biases across different models, datasets, or time points. We derive a link between the different families of existing fairness measures for scores and show that the proposed distributionally invariant fairness measures outperform ROC-based fairness measures because they are more explicit and can quantify significant biases that ROC-based fairness measures miss. Finally, we demonstrate their effectiveness through experiments on the most commonly used fairness benchmark datasets.
</details>
<details>
<summary>摘要</summary>
通常情况下，算法公平性的度量是在二进制决策中讨论的。我们将这种方法扩展到连续分数上。目前，ROC基本的度量是为此目的提出的。其他现有的方法对于分数的分布取决于，不适用于排名任务，或者其效果大小不容易理解。我们提议一种对连续分数的公平度量，基于 Wasserstein 距离，具有合理的解释，可以量化和解释群体偏见的强度以及不同模型、数据集、时间点之间的偏见。我们还 derivates了不同家族的现有公平度量的连接，并证明了我们的分布不变的公平度量在ROC基本的公平度量之上表现更好，因为它们更加显着，可以捕捉ROC基本的公平度量所miss的重要偏见。最后，我们通过使用最常用的公平性标准数据集进行实验，证明了它们的效果。
</details></li>
</ul>
<hr>
<h2 id="How-Much-Temporal-Long-Term-Context-is-Needed-for-Action-Segmentation"><a href="#How-Much-Temporal-Long-Term-Context-is-Needed-for-Action-Segmentation" class="headerlink" title="How Much Temporal Long-Term Context is Needed for Action Segmentation?"></a>How Much Temporal Long-Term Context is Needed for Action Segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11358">http://arxiv.org/abs/2308.11358</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ltcontext/ltcontext">https://github.com/ltcontext/ltcontext</a></li>
<li>paper_authors: Emad Bahrami, Gianpiero Francesca, Juergen Gall</li>
<li>for: 本研究的目的是回答 temporal action segmentation 中需要多少长期 temporal context 以达到最佳性能。</li>
<li>methods: 我们提出了一种基于 transformer 的模型，使用 sparse attention  capture 全视频的 context。</li>
<li>results: 我们的实验表明，模型全视频的 context 是 temporal action segmentation 中获得最佳性能的必要条件。<details>
<summary>Abstract</summary>
Modeling long-term context in videos is crucial for many fine-grained tasks including temporal action segmentation. An interesting question that is still open is how much long-term temporal context is needed for optimal performance. While transformers can model the long-term context of a video, this becomes computationally prohibitive for long videos. Recent works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window. While these approaches show good results, their performance is limited by their inability to capture the full context of a video. In this work, we try to answer how much long-term temporal context is required for temporal action segmentation by introducing a transformer-based model that leverages sparse attention to capture the full context of a video. We compare our model with the current state of the art on three datasets for temporal action segmentation, namely 50Salads, Breakfast, and Assembly101. Our experiments show that modeling the full context of a video is necessary to obtain the best performance for temporal action segmentation.
</details>
<details>
<summary>摘要</summary>
模型长期视频上下文是多种细化任务中的关键，包括时间动作分割。一个有趣的问题是如何确定最佳长期时间上下文的范围。虽然转换器可以模型视频的长期上下文，但这在长视频时会变得计算拒绝。 current works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window。although these approaches show good results, their performance is limited by their inability to capture the full context of a video。在这项工作中，我们试图回答 temporal action segmentation 需要多少长期时间上下文来达到最佳性能的问题。我们提出了一种基于转换器的模型，通过采用缺省注意力来捕捉整个视频的上下文。我们与当前领先的三个数据集（50Salads、Breakfast和Assembly101）进行比较，实验结果表明，模型整个视频的上下文是 temporal action segmentation 获得最佳性能的必要条件。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-assisted-exploration-for-affine-Deligne-Lusztig-varieties"><a href="#Machine-learning-assisted-exploration-for-affine-Deligne-Lusztig-varieties" class="headerlink" title="Machine learning assisted exploration for affine Deligne-Lusztig varieties"></a>Machine learning assisted exploration for affine Deligne-Lusztig varieties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11355">http://arxiv.org/abs/2308.11355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinpf314/ml4adlv">https://github.com/jinpf314/ml4adlv</a></li>
<li>paper_authors: Bin Dong, Xuhua He, Pengfei Jin, Felix Schremmer, Qingchao Yu</li>
<li>for: 这 paper 的 primary objective 是 investigate the nonemptiness pattern, dimension 和 enumeration of irreducible components of affine Deligne-Lusztig varieties (ADLV).</li>
<li>methods: 这 paper 使用了 Machine Learning (ML) 协助的 framework 来探索 ADLV 的几何结构。 The proposed framework 包括 data generation, model training, pattern analysis, 和 human examination, which presents an intricate interplay between ML 和 pure mathematical research.</li>
<li>results: 这 paper 提出了一种新的, interdisciplinary 的方法，可以帮助加速 pure mathematical research, 并且可以找到新的 conjectures 和 promising research directions。 The paper 还 rediscovered the virtual dimension formula 和 provided a full mathematical proof of a newly identified problem concerning a certain lower bound of dimension.<details>
<summary>Abstract</summary>
This paper presents a novel, interdisciplinary study that leverages a Machine Learning (ML) assisted framework to explore the geometry of affine Deligne-Lusztig varieties (ADLV). The primary objective is to investigate the nonemptiness pattern, dimension and enumeration of irreducible components of ADLV. Our proposed framework demonstrates a recursive pipeline of data generation, model training, pattern analysis, and human examination, presenting an intricate interplay between ML and pure mathematical research. Notably, our data-generation process is nuanced, emphasizing the selection of meaningful subsets and appropriate feature sets. We demonstrate that this framework has a potential to accelerate pure mathematical research, leading to the discovery of new conjectures and promising research directions that could otherwise take significant time to uncover. We rediscover the virtual dimension formula and provide a full mathematical proof of a newly identified problem concerning a certain lower bound of dimension. Furthermore, we extend an open invitation to the readers by providing the source code for computing ADLV and the ML models, promoting further explorations. This paper concludes by sharing valuable experiences and highlighting lessons learned from this collaboration.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了一项新的、混合数学和机器学习（ML）的研究方法，用于探索非线性Deligne-Lusztig多样体（ADLV）的几何学。研究的主要目标是研究ADLV中的非空性模式、维度和总数，以及其不同组成部分的分析。我们提出的框架包括数据生成、模型训练、模式分析和人类检查，这些步骤之间存在着细腻的交互。特别是，我们的数据生成过程强调选择有意义的子集和适当的特征集。我们示出了这种框架的潜在可能性，可以加速纯数学研究，导致新的推测和潜在的研究方向的发现。此外，我们还重新发现了虚方尺式和一个新的问题的证明，即某些维度下的下界问题。此外，我们还向读者开放了源代码，以便进一步探索ADLV和ML模型。这篇论文结束于分享有价值的经验和学习到的教训。
</details></li>
</ul>
<hr>
<h2 id="WEARS-Wearable-Emotion-AI-with-Real-time-Sensor-data"><a href="#WEARS-Wearable-Emotion-AI-with-Real-time-Sensor-data" class="headerlink" title="WEARS: Wearable Emotion AI with Real-time Sensor data"></a>WEARS: Wearable Emotion AI with Real-time Sensor data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11673">http://arxiv.org/abs/2308.11673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhruv Limbani, Daketi Yatin, Nitish Chaturvedi, Vaishnavi Moorthy, Pushpalatha M, Harichandana BSS, Sumit Kumar</li>
<li>For: The paper aims to predict user emotion using smartwatch sensors, with a focus on developing a practical and user-friendly system for everyday use.* Methods: The authors propose a framework that collects ground truth data in real-time using a combination of English and regional language-based videos to evoke emotions in participants. They use a binary classification approach due to limited dataset size and experiment with multiple machine-learning models, including Multi-Layer Perceptron, which achieves a maximum accuracy of 93.75% for pleasant-unpleasant moods.* Results: The paper reports an accuracy of 93.75% for predicting pleasant-unpleasant moods using Multi-Layer Perceptron, indicating the effectiveness of using smartwatch sensors for emotion recognition.Here’s the simplified Chinese text for the three key points:* For: 这篇论文旨在使用智能手表传感器预测用户情绪，旨在开发一个实用、日常使用的系统。* Methods: 作者提出了一种基于英文和地方语言基于视频诱发情感的实验框架，并使用多种机器学习模型进行实验，其中多层感知器达到了93.75%的最高准确率。* Results: 论文报告了使用多层感知器预测愉悦-不愉悦情绪的准确率为93.75%，表明智能手表传感器可以有效地进行情绪识别。<details>
<summary>Abstract</summary>
Emotion prediction is the field of study to understand human emotions. Existing methods focus on modalities like text, audio, facial expressions, etc., which could be private to the user. Emotion can be derived from the subject's psychological data as well. Various approaches that employ combinations of physiological sensors for emotion recognition have been proposed. Yet, not all sensors are simple to use and handy for individuals in their daily lives. Thus, we propose a system to predict user emotion using smartwatch sensors. We design a framework to collect ground truth in real-time utilizing a mix of English and regional language-based videos to invoke emotions in participants and collect the data. Further, we modeled the problem as binary classification due to the limited dataset size and experimented with multiple machine-learning models. We also did an ablation study to understand the impact of features including Heart Rate, Accelerometer, and Gyroscope sensor data on mood. From the experimental results, Multi-Layer Perceptron has shown a maximum accuracy of 93.75 percent for pleasant-unpleasant (high/low valence classification) moods.
</details>
<details>
<summary>摘要</summary>
预测人类情感是一个研究领域，旨在理解人们的情感。现有方法主要集中在文本、音频、脸部表现等Modalities上，这些modalities可能是用户私有的。情感还可以从主题的心理数据中 derivation。许多方法使用多种生物学传感器进行情感识别，但不是所有传感器都是用户日常生活中容易使用。因此，我们提出了一个基于智能手表传感器的情感预测系统。我们设计了一个框架，以实时收集真实数据，使用英文和地区语言基于视频释放情感并收集数据。此外，我们将问题定型为二分类问题，因为数据集的小型限制了我们的实验。我们还进行了减少研究，以了解特征包括心率、加速度和陀螺仪传感器数据对情感的影响。从实验结果来看，多层感知器在高/低积极情感（愉悦-不愉悦）类别上达到最高的准确率为93.75%。
</details></li>
</ul>
<hr>
<h2 id="Careful-at-Estimation-and-Bold-at-Exploration"><a href="#Careful-at-Estimation-and-Bold-at-Exploration" class="headerlink" title="Careful at Estimation and Bold at Exploration"></a>Careful at Estimation and Bold at Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11348">http://arxiv.org/abs/2308.11348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xing Chen, Yijun Liu, Zhaogeng Liu, Hechang Chen, Hengshuai Yao, Yi Chang</li>
<li>for: 本研究旨在解决 kontinuous action space 中的尝试策略问题，即因为无限多个动作而导致的规则性尝试策略不能得出总体结论。</li>
<li>methods: 我们基于 double-Q 函数框架，提出了一种新的尝试策略，以解决issues 1和2。我们首先提出了 Q 值更新的greedy Q softmax schema，然后 derivated expected Q value 的公式，并将其与 Q 值更新相结合。</li>
<li>results: 我们在 Mujoco  benchmark 上评估了我们的方法，并与之前的 state-of-the-art 方法进行比较。结果显示，我们的方法在不同环境中表现出色，特别是在最复杂的 Humanoid 环境中。<details>
<summary>Abstract</summary>
Exploration strategies in continuous action space are often heuristic due to the infinite actions, and these kinds of methods cannot derive a general conclusion. In prior work, it has been shown that policy-based exploration is beneficial for continuous action space in deterministic policy reinforcement learning(DPRL). However, policy-based exploration in DPRL has two prominent issues: aimless exploration and policy divergence, and the policy gradient for exploration is only sometimes helpful due to inaccurate estimation. Based on the double-Q function framework, we introduce a novel exploration strategy to mitigate these issues, separate from the policy gradient. We first propose the greedy Q softmax update schema for Q value update. The expected Q value is derived by weighted summing the conservative Q value over actions, and the weight is the corresponding greedy Q value. Greedy Q takes the maximum value of the two Q functions, and conservative Q takes the minimum value of the two different Q functions. For practicality, this theoretical basis is then extended to allow us to combine action exploration with the Q value update, except for the premise that we have a surrogate policy that behaves like this exploration policy. In practice, we construct such an exploration policy with a few sampled actions, and to meet the premise, we learn such a surrogate policy by minimizing the KL divergence between the target policy and the exploration policy constructed by the conservative Q. We evaluate our method on the Mujoco benchmark and demonstrate superior performance compared to previous state-of-the-art methods across various environments, particularly in the most complex Humanoid environment.
</details>
<details>
<summary>摘要</summary>
在连续动作空间中，探索策略经常是规则性的，因为动作的数量是无限的。在先前的工作中，已经证明了在决定性政策学习（DPRL）中，政策基于的探索是有利的。然而，DPRL中的政策基于探索有两个明显的问题：无目的探索和政策分化，并且政策梯度对探索是不一定有帮助的，因为估计不准确。基于双Q函数框架，我们介绍了一种新的探索策略，以解决这些问题。我们首先提出了Q值更新的软MAX schema，其中预期Q值是通过对动作的权重 sums来计算的。在这个过程中，权重是根据动作的greedy Q值进行调整。greedy Q值是两个Q函数中的最大值，而conservative Q值是两个Q函数中的最小值。为了实用，我们将这种理论基础扩展到允许我们将探索策略与Q值更新结合，只要我们有一个伪函数，这个伪函数在探索策略下被学习。在实践中，我们构建了一个这种探索策略，并通过最小化KL抽象度来学习这个伪函数。我们在Mujoco benchmark上评估了我们的方法，并在不同的环境中达到了先前的状态艺术方法的超越性表现，特别是在最复杂的人型环境中。
</details></li>
</ul>
<hr>
<h2 id="ProAgent-Building-Proactive-Cooperative-AI-with-Large-Language-Models"><a href="#ProAgent-Building-Proactive-Cooperative-AI-with-Large-Language-Models" class="headerlink" title="ProAgent: Building Proactive Cooperative AI with Large Language Models"></a>ProAgent: Building Proactive Cooperative AI with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11339">http://arxiv.org/abs/2308.11339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PKU-Alignment/ProAgent">https://github.com/PKU-Alignment/ProAgent</a></li>
<li>paper_authors: Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge Zhang, Feng Yin, Yitao Liang, Yaodong Yang<br>for:This paper aims to develop a novel framework called ProAgent that enables AI agents to cooperate with other agents and humans in a more effective and adaptive manner.methods:ProAgent leverages large language models (LLMs) to anticipate teammates’ decisions and formulate better plans, and it has a high degree of modularity and interpretability, making it easy to integrate with different coordination scenarios.results:Experimental evaluations show that ProAgent outperforms five comparison methods in cooperation with AI agents, and it also performs better than the current state-of-the-art, COLE, when cooperating with human proxy models, with an average improvement of over 10%. These results demonstrate the effectiveness of ProAgent in facilitating human-AI collaboration.Here’s the simplified Chinese version:for:这篇论文目标是开发一种名为ProAgent的新框架，使AI代理能够更有效地和其他代理和人类合作。methods:ProAgent利用大型自然语言模型（LLMs）预测同事的决策并提出更好的计划，它具有高度的可模块化和可解释性，方便与不同的协调方案集成。results:实验评估表明，ProAgent比五种参考方法在与AI代理合作中表现更出色，并且与当前状态艺术的COLE相比，在与人类代理模型合作时的表现也有超过10%的提升。这些结果证明ProAgent在人AI合作方面的作用是有效的。<details>
<summary>Abstract</summary>
Building AIs with adaptive behaviors in human-AI cooperation stands as a pivotal focus in AGI research. Current methods for developing cooperative agents predominantly rely on learning-based methods, where policy generalization heavily hinges on past interactions with specific teammates. These approaches constrain the agent's capacity to recalibrate its strategy when confronted with novel teammates. We propose \textbf{ProAgent}, a novel framework that harnesses large language models (LLMs) to fashion a \textit{pro}active \textit{agent} empowered with the ability to anticipate teammates' forthcoming decisions and formulate enhanced plans for itself. ProAgent excels at cooperative reasoning with the capacity to dynamically adapt its behavior to enhance collaborative efforts with teammates. Moreover, the ProAgent framework exhibits a high degree of modularity and interpretability, facilitating seamless integration to address a wide array of coordination scenarios. Experimental evaluations conducted within the framework of \textit{Overcook-AI} unveil the remarkable performance superiority of ProAgent, outperforming five methods based on self-play and population-based training in cooperation with AI agents. Further, when cooperating with human proxy models, its performance exhibits an average improvement exceeding 10\% compared to the current state-of-the-art, COLE. The advancement was consistently observed across diverse scenarios involving interactions with both AI agents of varying characteristics and human counterparts. These findings inspire future research for human-robot collaborations. For a hands-on demonstration, please visit \url{https://pku-proagent.github.io}.
</details>
<details>
<summary>摘要</summary>
building 人工智能（AI） WITH adaptive behaviors in human-AI cooperation 是AGI研究中的重点ocus。 current methods for developing cooperative agents mainly rely on learning-based methods, where policy generalization heavily relies on past interactions with specific teammates. these approaches limit the agent's ability to adjust its strategy when faced with new teammates. we propose \textbf{ProAgent}, a novel framework that leverages large language models (LLMs) to create a proactive agent that can anticipate teammates' upcoming decisions and formulate improved plans for itself. ProAgent excels at cooperative reasoning and can dynamically adapt its behavior to enhance collaborative efforts with teammates. furthermore, the ProAgent framework has a high degree of modularity and interpretability, making it easy to integrate into various coordination scenarios. experimental evaluations conducted within the Overcook-AI framework show that ProAgent outperforms five self-play and population-based training methods in cooperation with AI agents, with an average improvement of over 10% compared to the current state-of-the-art, COLE. this improvement was consistently observed across diverse scenarios involving interactions with both AI agents of varying characteristics and human counterparts. these findings pave the way for future research on human-robot collaborations. for a hands-on demonstration, please visit \url{https://pku-proagent.github.io}.
</details></li>
</ul>
<hr>
<h2 id="Generalising-sequence-models-for-epigenome-predictions-with-tissue-and-assay-embeddings"><a href="#Generalising-sequence-models-for-epigenome-predictions-with-tissue-and-assay-embeddings" class="headerlink" title="Generalising sequence models for epigenome predictions with tissue and assay embeddings"></a>Generalising sequence models for epigenome predictions with tissue and assay embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11671">http://arxiv.org/abs/2308.11671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacob Deasy, Ron Schwessinger, Ferran Gonzalez, Stephen Young, Kim Branson</li>
<li>for: 本研究旨在提高epigenetic profile预测方法的精度和可靠性，通过integrating tissue和assay embeddings into a Contextualised Genomic Network (CGN)来增强long-range sequence embeddings的准确性。</li>
<li>methods: 本研究使用了Contextualised Genomic Network (CGN)，其中integrates tissue和assay embeddings into a single network，以增强long-range sequence embeddings的准确性。</li>
<li>results: 研究表明，使用CGN可以在各种实验条件下实现强相关性，而且超过了现有方法的表现。此外，研究还提供了关于基因变化对epigenetic sequence模型训练的首个发现。<details>
<summary>Abstract</summary>
Sequence modelling approaches for epigenetic profile prediction have recently expanded in terms of sequence length, model size, and profile diversity. However, current models cannot infer on many experimentally feasible tissue and assay pairs due to poor usage of contextual information, limiting $\textit{in silico}$ understanding of regulatory genomics. We demonstrate that strong correlation can be achieved across a large range of experimental conditions by integrating tissue and assay embeddings into a Contextualised Genomic Network (CGN). In contrast to previous approaches, we enhance long-range sequence embeddings with contextual information in the input space, rather than expanding the output space. We exhibit the efficacy of our approach across a broad set of epigenetic profiles and provide the first insights into the effect of genetic variants on epigenetic sequence model training. Our general approach to context integration exceeds state of the art in multiple settings while employing a more rigorous validation procedure.
</details>
<details>
<summary>摘要</summary>
Sequence模型方法 для脱氧核型谱预测最近几年得到了较长的序列长度、更大的模型大小和更多的谱型多样性。然而，当前的模型无法对许多实验可行的组织和检测对照进行预测，因为忽略了Contextual信息的使用，这限制了$\textit{in silico}$的规则生物学理解。我们示示了在各种实验条件下强相关性的 achievement，通过将组织和检测嵌入到Contextualised Genomic Network（CGN）中，而不是扩展输出空间。我们在输入空间中增强长距离序列嵌入中的Contextual信息，而不是扩展输出空间。我们在多种脱氧核型谱中展示了我们的方法的效果，并提供了脱氧核型序列模型训练中基因变化的首次研究。我们的通用方法进行Context集成超过了当前状态的多个设置，而且采用更严格的验证过程。
</details></li>
</ul>
<hr>
<h2 id="Protect-Federated-Learning-Against-Backdoor-Attacks-via-Data-Free-Trigger-Generation"><a href="#Protect-Federated-Learning-Against-Backdoor-Attacks-via-Data-Free-Trigger-Generation" class="headerlink" title="Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation"></a>Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11333">http://arxiv.org/abs/2308.11333</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen</li>
<li>for: 防止 Federated Learning (FL) 中的毒蛋攻击 (backdoor attacks)</li>
<li>methods: 基于毒蛋攻击的两个特点（ triggers 更快学习，触发图像分类更大）的数据free trigger-generation-based 防御方法</li>
<li>results: 对多种现有毒蛋攻击和七种现有防御方法进行了广泛的实验，结果表明我们的方法可以成功防止毒蛋攻击，并在 IID 和非 IID 场景下出perform 所有七种防御方法。特别是，我们的方法可以在 80% 的客户端被恶意攻击时仍然成功防止毒蛋攻击。<details>
<summary>Abstract</summary>
As a distributed machine learning paradigm, Federated Learning (FL) enables large-scale clients to collaboratively train a model without sharing their raw data. However, due to the lack of data auditing for untrusted clients, FL is vulnerable to poisoning attacks, especially backdoor attacks. By using poisoned data for local training or directly changing the model parameters, attackers can easily inject backdoors into the model, which can trigger the model to make misclassification of targeted patterns in images. To address these issues, we propose a novel data-free trigger-generation-based defense approach based on the two characteristics of backdoor attacks: i) triggers are learned faster than normal knowledge, and ii) trigger patterns have a greater effect on image classification than normal class patterns. Our approach generates the images with newly learned knowledge by identifying the differences between the old and new global models, and filters trigger images by evaluating the effect of these generated images. By using these trigger images, our approach eliminates poisoned models to ensure the updated global model is benign. Comprehensive experiments demonstrate that our approach can defend against almost all the existing types of backdoor attacks and outperform all the seven state-of-the-art defense methods with both IID and non-IID scenarios. Especially, our approach can successfully defend against the backdoor attack even when 80\% of the clients are malicious.
</details>
<details>
<summary>摘要</summary>
作为分布式机器学习模式，联邦学习（FL）允许大规模客户端共同训练模型，而无需分享原始数据。然而，由于客户端数据审核不足，FL容易受到毒素攻击，尤其是后门攻击。攻击者可以使用毒素数据进行本地训练或直接改变模型参数，从而轻松地植入后门到模型中，使模型在目标图像中产生误分类。为解决这些问题，我们提出了一种基于两个后门攻击特征的新防御方法：一是触发更快速学习than正常知识，二是触发模式在图像分类中比正常类型更大的影响。我们的方法生成图像新学习的知识，并将触发图像过滤通过评估这些生成的图像的效果。通过使用这些触发图像，我们的方法可以消除毒素模型，确保更新的全局模型是无辜的。我们的实验表明，我们的方法可以对现有的所有类型后门攻击进行防御，并在IID和非IID场景中高效超越七种现状防御方法。特别是，我们的方法可以成功防御80%的客户端恶意攻击。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-based-Positioning-using-Multivariate-Time-Series-Classification-for-Factory-Environments"><a href="#Machine-Learning-based-Positioning-using-Multivariate-Time-Series-Classification-for-Factory-Environments" class="headerlink" title="Machine Learning-based Positioning using Multivariate Time Series Classification for Factory Environments"></a>Machine Learning-based Positioning using Multivariate Time Series Classification for Factory Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11670">http://arxiv.org/abs/2308.11670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nisal Hemadasa Manikku Badu, Marcus Venzke, Volker Turau, Yanqiu Huang</li>
<li>for: 这个论文是为了解决在私隐要求高的Factory环境中实现indoor位置系统（IPS），而不需要外部基础设施和数据。</li>
<li>methods: 该论文使用机器学习（ML）技术，利用运动和室内传感器来定位移动物体。它将问题定义为多变量时间序列分类（MTSC）问题，并对不同的机器学习模型进行比较分析，以选择最佳适用于IoT设备的模型。</li>
<li>results: 研究人员通过使用一个新的时间序列数据集来评估和比较不同的机器学习模型，发现所有评估模型的准确率都超过80%。CNN-1D表现最佳，其次是MLP。DT模型具有最低的内存占用量和计算延迟，因此有可能在实际应用中使用。<details>
<summary>Abstract</summary>
Indoor Positioning Systems (IPS) gained importance in many industrial applications. State-of-the-art solutions heavily rely on external infrastructures and are subject to potential privacy compromises, external information requirements, and assumptions, that make it unfavorable for environments demanding privacy and prolonged functionality. In certain environments deploying supplementary infrastructures for indoor positioning could be infeasible and expensive. Recent developments in machine learning (ML) offer solutions to address these limitations relying only on the data from onboard sensors of IoT devices. However, it is unclear which model fits best considering the resource constraints of IoT devices. This paper presents a machine learning-based indoor positioning system, using motion and ambient sensors, to localize a moving entity in privacy concerned factory environments. The problem is formulated as a multivariate time series classification (MTSC) and a comparative analysis of different machine learning models is conducted in order to address it. We introduce a novel time series dataset emulating the assembly lines of a factory. This dataset is utilized to assess and compare the selected models in terms of accuracy, memory footprint and inference speed. The results illustrate that all evaluated models can achieve accuracies above 80 %. CNN-1D shows the most balanced performance, followed by MLP. DT was found to have the lowest memory footprint and inference latency, indicating its potential for a deployment in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
内部定位系统（IPS）在多个业务应用中升级了其重要性。现代解决方案强依赖于外部基础设施，受到隐私侵犯、外部信息需求和假设的限制，使其不适合需要隐私和持续性的环境。在某些环境中，为实现内部定位而部署补充基础设施可能是不可能的和昂贵的。现代机器学习（ML）技术提供了解决这些限制的方案，不需要外部基础设施，只需基于 IoT 设备上的固件传感器数据。然而，选择最佳模型是有困难的，因为 IoT 设备的资源限制是一个重要的考虑因素。本文描述了一种基于机器学习的内部定位系统，使用运动和室内传感器来确定在隐私问题中的工厂环境中移动的实体。问题被формализова为多变量时间序列分类（MTSC），并对不同的机器学习模型进行比较分析，以解决它。我们引入了一个新的时间序列数据集，该数据集模拟了制造工程厂的生产线。这个数据集用于评估和比较选择的模型，以确定它们的准确率、内存占用量和推理速度。结果显示所有评估模型均可达到上百分之八的准确率。CNN-1D表现最佳，其次是 MLP。DT 具有最低的内存占用量和推理延迟，因此它在实际应用中具有潜在的优势。
</details></li>
</ul>
<hr>
<h2 id="Class-Label-aware-Graph-Anomaly-Detection"><a href="#Class-Label-aware-Graph-Anomaly-Detection" class="headerlink" title="Class Label-aware Graph Anomaly Detection"></a>Class Label-aware Graph Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11669">http://arxiv.org/abs/2308.11669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jhkim611/clad">https://github.com/jhkim611/clad</a></li>
<li>paper_authors: Junghoon Kim, Yeonjun In, Kanghoon Yoon, Junmo Lee, Chanyoung Park</li>
<li>for: 本研究旨在提高无监督图像检测方法的性能，特别是在缺乏类别标签信息的情况下。</li>
<li>methods: 本研究提出了一种基于类别标签的图像检测方法，即类别标签感知图像检测方法（CLAD）。该方法利用有限数量的标签节点来增强无监督图像检测的性能。</li>
<li>results: 对于十个数据集，CLAD方法在无监督情况下表现出了比较出色的性能，甚至超过了现有的无监督图像检测方法。<details>
<summary>Abstract</summary>
Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese:Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}.Translate the text into Simplified Chinese:<</SYS>>Here's the translation:Unsupervised GAD方法假设缺乏异常标签，即节点是否异常。我们从前一些无监督方法中发现，不仅假设缺乏这些异常标签，还假设缺乏类别标签（用于普通的节点分类任务中）。在这个工作中，我们研究了类别标签是否增强了无监督GAD的检测性。为此，我们提出了一个具有限量标签的Class Label-aware Graph Anomaly Detection框架（CLAD），可以将有限量的标签用于增强无监督GAD的性能。我们在十个数据集上进行了广泛的实验，结果显示CLAD在与现有的无监督GAD方法比较时表现更好，甚至在没有真实的类别标签信息时仍能取得更高的性能。CLAD的源代码可以在\url{https://github.com/jhkim611/CLAD}中找到。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-of-Transformers’-Predictions-via-Topological-Analysis-of-the-Attention-Matrices"><a href="#Uncertainty-Estimation-of-Transformers’-Predictions-via-Topological-Analysis-of-the-Attention-Matrices" class="headerlink" title="Uncertainty Estimation of Transformers’ Predictions via Topological Analysis of the Attention Matrices"></a>Uncertainty Estimation of Transformers’ Predictions via Topological Analysis of the Attention Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11295">http://arxiv.org/abs/2308.11295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Kostenok, Daniil Cherniavskii, Alexey Zaytsev</li>
<li>for: This paper aims to address the open problem of determining the degree of confidence of deep learning models in their predictions, specifically for text classification models using the Transformer architecture.</li>
<li>methods: The proposed method for uncertainty estimation is based on Topological Data Analysis (TDA) and utilizes the attention mechanism to form relationships between internal representations.</li>
<li>results: The proposed method outperforms classical methods in quality and opens up a new area of application for the attention mechanism, but requires the selection of topological features.<details>
<summary>Abstract</summary>
Determining the degree of confidence of deep learning model in its prediction is an open problem in the field of natural language processing. Most of the classical methods for uncertainty estimation are quite weak for text classification models. We set the task of obtaining an uncertainty estimate for neural networks based on the Transformer architecture. A key feature of such mo-dels is the attention mechanism, which supports the information flow between the hidden representations of tokens in the neural network. We explore the formed relationships between internal representations using Topological Data Analysis methods and utilize them to predict model's confidence. In this paper, we propose a method for uncertainty estimation based on the topological properties of the attention mechanism and compare it with classical methods. As a result, the proposed algorithm surpasses the existing methods in quality and opens up a new area of application of the attention mechanism, but requires the selection of topological features.
</details>
<details>
<summary>摘要</summary>
决定深度学习模型预测结果的信任度是自然语言处理领域的一个开问题。大多数经典方法的不确定性估计对文本分类模型来说是很弱的。我们设定了基于Transformer架构的神经网络中的不确定性估计任务。Transformer模型的一个重要特征是对应机制，它支持内部表示之间的信息流动。我们使用Topological Data Analysis方法来探索内部表示之间的关系，并将其用于预测模型的信任度。在这篇论文中，我们提出了基于对应机制的不确定性估计方法，并与经典方法进行比较。结果显示，提案的算法在质量上超过了现有的方法，并开启了一个新的对应机制的应用领域，但是需要选择几个类型的特征。
</details></li>
</ul>
<hr>
<h2 id="Network-Momentum-across-Asset-Classes"><a href="#Network-Momentum-across-Asset-Classes" class="headerlink" title="Network Momentum across Asset Classes"></a>Network Momentum across Asset Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11294">http://arxiv.org/abs/2308.11294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyue Pu, Stephen Roberts, Xiaowen Dong, Stefan Zohren</li>
<li>for: 这篇论文探讨了网络势力的概念，即基于资产之间的势力扩散的新交易信号。</li>
<li>methods: 该论文使用了一种可读性高的图学学习模型，以探索不同资产类型之间的势力扩散网络。</li>
<li>results: 该论文提出了一种基于网络势力的多资产投资策略，并通过实证分析表明其具有1.5的沙勃级效果和22%的年化收益。<details>
<summary>Abstract</summary>
We investigate the concept of network momentum, a novel trading signal derived from momentum spillover across assets. Initially observed within the confines of pairwise economic and fundamental ties, such as the stock-bond connection of the same company and stocks linked through supply-demand chains, momentum spillover implies a propagation of momentum risk premium from one asset to another. The similarity of momentum risk premium, exemplified by co-movement patterns, has been spotted across multiple asset classes including commodities, equities, bonds and currencies. However, studying the network effect of momentum spillover across these classes has been challenging due to a lack of readily available common characteristics or economic ties beyond the company level. In this paper, we explore the interconnections of momentum features across a diverse range of 64 continuous future contracts spanning these four classes. We utilise a linear and interpretable graph learning model with minimal assumptions to reveal the intricacies of the momentum spillover network. By leveraging the learned networks, we construct a network momentum strategy that exhibits a Sharpe ratio of 1.5 and an annual return of 22%, after volatility scaling, from 2000 to 2022. This paper pioneers the examination of momentum spillover across multiple asset classes using only pricing data, presents a multi-asset investment strategy based on network momentum, and underscores the effectiveness of this strategy through robust empirical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Knot-Prediction-in-Wood-Logs-with-Longitudinal-Feature-Propagation"><a href="#Improving-Knot-Prediction-in-Wood-Logs-with-Longitudinal-Feature-Propagation" class="headerlink" title="Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation"></a>Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11291">http://arxiv.org/abs/2308.11291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeremyfix/icvs2023">https://github.com/jeremyfix/icvs2023</a></li>
<li>paper_authors: Salim Khazem, Jeremy Fix, Cédric Pradalier</li>
<li>for: 本研究旨在预测木材中内部缺陷的位置，以提高木材质量评估的准确性和效率。</li>
<li>methods: 本研究使用了卷积回归神经网络来解决木材外形特征与内部缺陷之间的关系。</li>
<li>results: 研究结果表明，通过使用卷积回归神经网络进行预测，可以准确地预测木材内部缺陷的位置，并且可以通过便宜的外形测量设备进行实时检测。<details>
<summary>Abstract</summary>
The quality of a wood log in the wood industry depends heavily on the presence of both outer and inner defects, including inner knots that are a result of the growth of tree branches. Today, locating the inner knots require the use of expensive equipment such as X-ray scanners. In this paper, we address the task of predicting the location of inner defects from the outer shape of the logs. The dataset is built by extracting both the contours and the knots with X-ray measurements. We propose to solve this binary segmentation task by leveraging convolutional recurrent neural networks. Once the neural network is trained, inference can be performed from the outer shape measured with cheap devices such as laser profilers. We demonstrate the effectiveness of our approach on fir and spruce tree species and perform ablation on the recurrence to demonstrate its importance.
</details>
<details>
<summary>摘要</summary>
木材行业中木材质量受到内部和外部缺陷的影响，其中包括由树木支 Branches 生长而成的内部缺陷。当前，发现内部缺陷需要使用昂贵的设备如X射验器。在这篇论文中，我们Addressing the task of predicting the location of inner defects from the outer shape of the logs. Our dataset is built by extracting both the contours and the knots with X-ray measurements. We propose to solve this binary segmentation task by leveraging convolutional recurrent neural networks. Once the neural network is trained, inference can be performed from the outer shape measured with cheap devices such as laser profilers. We demonstrate the effectiveness of our approach on fir and spruce tree species and perform ablation on the recurrence to demonstrate its importance.Here's the breakdown of the translation:* 木材 (mù cǎi) - wood* 行业 (xíng yè) - industry* 质量 (zhì yù) - quality* 受到 (shòu dào) - influenced by* 内部 (nèi bù) - inner* 缺陷 (jiǔ jī) - defects* 包括 (bāo gè) - including* 内部缺陷 (nèi bù jī jī) - inner defects* 由 (yù) - caused by* 树木 (shù mù) - trees* 支 (zhī) - branches* 生长 (shēng cháng) - growth* 成 (chéng) - formed* 内部缺陷 (nèi bù jī jī) - inner defects* 需要 (xū yào) - need* 使用 (shǐ yòng) - use* 昂贵 (áng jí) - expensive* 设备 (tiě bì) - equipment* X射验器 (X chū zhì qi) - X-ray scanner* Addressing (dào zhèng) - addressing* task (dao) - task* predicting (jì dì) - predicting* location (dì yì) - location* of (de) - of* inner defects (nèi bù jī jī) - inner defects* from (from) - from* the outer shape (wài xíng) - the outer shape* of the logs (de logs) - of the logs* Our dataset (wǒ de dataset) - our dataset* is built (is built) - is built* by extracting (by extracting) - by extracting* both (both) - both* the contours (the contours) - the contours* and the knots (and the knots) - and the knots* with X-ray measurements (with X-ray measurements) - with X-ray measurements* We propose (wǒ yù) - we propose* to solve (to solve) - to solve* this binary segmentation task (this binary segmentation task) - this binary segmentation task* by leveraging (by leveraging) - by leveraging* convolutional recurrent neural networks (convolutional recurrent neural networks) - convolutional recurrent neural networks* Once (once) - once* the neural network (the neural network) - the neural network* is trained (is trained) - is trained* inference can be performed (inference can be performed) - inference can be performed* from the outer shape (from the outer shape) - from the outer shape* measured with cheap devices (measured with cheap devices) - measured with cheap devices* such as laser profilers (such as laser profilers) - such as laser profilers* We demonstrate (wǒ yù) - we demonstrate* the effectiveness (the effectiveness) - the effectiveness* of our approach (of our approach) - of our approach* on fir (on fir) - on fir* and spruce (and spruce) - and spruce* tree species (tree species) - tree species* and perform ablation (and perform ablation) - and perform ablation* on the recurrence (on the recurrence) - on the recurrence* to demonstrate (to demonstrate) - to demonstrate* its importance (its importance) - its importance
</details></li>
</ul>
<hr>
<h2 id="ShadowNet-for-Data-Centric-Quantum-System-Learning"><a href="#ShadowNet-for-Data-Centric-Quantum-System-Learning" class="headerlink" title="ShadowNet for Data-Centric Quantum System Learning"></a>ShadowNet for Data-Centric Quantum System Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11290">http://arxiv.org/abs/2308.11290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxuan Du, Yibo Yang, Tongliang Liu, Zhouchen Lin, Bernard Ghanem, Dacheng Tao<br>for: 这篇论文的目的是提出一种数据驱动学习方法，帮助解决大量量子系统的研究困难，尤其是量子状态实物探测和精确性评估等任务。methods: 这篇论文使用了神经网络协议和古典影子的方法，但这两种方法都有限制：前者受到预测不确定性的影响，后者则缺乏扩展能力。这篇论文提出了一个融合这两种方法的数据驱动学习模式，通过将古典影子与其他量子系统的轻松可取信息融合，创建训练数据集，然后让神经网络学习这个数据集中的对应规律。results: 这篇论文的结果显示，这个数据驱动学习模式可以在没有量子系统的资料时，通过训练神经网络，实现预测未见过的量子系统。此外，这个模式还具有快速适应和储存效率的特点，可以实现在大量量子系统中的应用。<details>
<summary>Abstract</summary>
Understanding the dynamics of large quantum systems is hindered by the curse of dimensionality. Statistical learning offers new possibilities in this regime by neural-network protocols and classical shadows, while both methods have limitations: the former is plagued by the predictive uncertainty and the latter lacks the generalization ability. Here we propose a data-centric learning paradigm combining the strength of these two approaches to facilitate diverse quantum system learning (QSL) tasks. Particularly, our paradigm utilizes classical shadows along with other easily obtainable information of quantum systems to create the training dataset, which is then learnt by neural networks to unveil the underlying mapping rule of the explored QSL problem. Capitalizing on the generalization power of neural networks, this paradigm can be trained offline and excel at predicting previously unseen systems at the inference stage, even with few state copies. Besides, it inherits the characteristic of classical shadows, enabling memory-efficient storage and faithful prediction. These features underscore the immense potential of the proposed data-centric approach in discovering novel and large-scale quantum systems. For concreteness, we present the instantiation of our paradigm in quantum state tomography and direct fidelity estimation tasks and conduct numerical analysis up to 60 qubits. Our work showcases the profound prospects of data-centric artificial intelligence to advance QSL in a faithful and generalizable manner.
</details>
<details>
<summary>摘要</summary>
大量量子系统的dinamics受到维度祸害。统计学学习提供了新的可能性，通过神经网络协议和类型暂影，然而这两种方法均有局限性：前者受到预测不确定性的困扰，后者缺乏泛化能力。我们提议一种数据驱动学习思维方式，结合这两种方法，以便推动多种量子学习任务（QSL）。特别是，我们的思维方式利用类型暂影和其他可见的量子系统信息，创建训练集，然后由神经网络学习探索QSL问题的下面规则。通过神经网络的泛化能力，这种思维方式可以在训练前线上进行offline训练，在推断阶段可以准确预测未经见过的系统，即使只有几个状态复制。此外，它继承了类型暂影的特点，具有储存效率和准确预测的特点。这些特点说明了我们提议的数据驱动方法在发现新的大规模量子系统方面的极大潜力。为了具体展示我们的思维方式，我们在量子状态探测和直接准确度估计任务中实现了这种思维方式，并进行了数值分析至60个量子比特。我们的工作展示了数据驱动人工智能在 faithful和泛化的方式下，进一步推动量子学习的前iers。
</details></li>
</ul>
<hr>
<h2 id="Test-Time-Embedding-Normalization-for-Popularity-Bias-Mitigation"><a href="#Test-Time-Embedding-Normalization-for-Popularity-Bias-Mitigation" class="headerlink" title="Test Time Embedding Normalization for Popularity Bias Mitigation"></a>Test Time Embedding Normalization for Popularity Bias Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11288">http://arxiv.org/abs/2308.11288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ml-postech/tten">https://github.com/ml-postech/tten</a></li>
<li>paper_authors: Dain Kim, Jinhyeok Park, Dongwoo Kim</li>
<li>for: 本研究旨在解决推荐系统中的人気偏袋问题，即推荐结果受到item popularity的影响。</li>
<li>methods: 本研究提出了’Test Time Embedding Normalization’方法，它是一种简单 yet effective的方法，可以有效地减少人気偏袋的影响。该方法在推荐阶段使用 норmalized item embedding来控制 embedding magnitude的影响，其与item popularity高度相关。</li>
<li>results: 通过广泛的实验，本研究证明了我们的方法可以与之前的偏袋缓解方法相比，提高了推荐结果的准确性。此外，我们还发现了用户和项目 embedding之间的关系，angular similarity between embeddings可以分辨 preferable 和 non-preferable 的项目，不abhängigkeit von их popularity。这些分析解释了我们的方法如何成功地减少人気偏袋的影响。<details>
<summary>Abstract</summary>
Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approach in eliminating the impact of popularity bias. Our code is available at https://github.com/ml-postech/TTEN.
</details>
<details>
<summary>摘要</summary>
受欢迎偏见是推荐系统领域中的一个广泛存在的问题，它导致受欢迎的项目在推荐结果中占据着主导地位。在这个工作中，我们提出了“测试时嵌入 normalization”作为一种简单 yet有效的策略来 Mitigate 受欢迎偏见，该策略在previous mitigation Approaches的性能上超过了很大的差。我们的方法利用了normalized item embedding During the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity。经过了广泛的实验，我们表明了我们的方法与sampled softmax loss combination 能够有效地减少受欢迎偏见，比之前的缓解方法更高效。我们进一步investigated the relationship between user and item embeddings and found that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity。这种分析解释了我们的方法在消除受欢迎偏见的机制。我们的代码可以在https://github.com/ml-postech/TTEN中找到。
</details></li>
</ul>
<hr>
<h2 id="CNN-based-Cuneiform-Sign-Detection-Learned-from-Annotated-3D-Renderings-and-Mapped-Photographs-with-Illumination-Augmentation"><a href="#CNN-based-Cuneiform-Sign-Detection-Learned-from-Annotated-3D-Renderings-and-Mapped-Photographs-with-Illumination-Augmentation" class="headerlink" title="CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation"></a>CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11277">http://arxiv.org/abs/2308.11277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernst Stötzner, Timo Homburg, Hubert Mara</li>
<li>for: 这篇论文是为了提供一种用于处理古代中东文明的数字工具，尤其是用于处理码iform文字，这种文字在陶 TABLETS上印刷了三千年以上，并且包含了许多不同的语言。</li>
<li>methods: 这篇论文使用了一种novel OCR-like方法来处理混合图像数据，包括将3D Rendering和摄影照片的标签转换到对应的3D模型上。它还使用了一个RepPoints探测器来预测文字的位置，并使用了GigaMesh的MSII基于曲线的呈现、Phong-shaded 3D模型和摄影照片，以及照明增强。</li>
<li>results: 根据结果，使用 Rendering 3D图像进行文字探测比使用摄影照片更好，而且这种方法在混合数据集上也表现良好。此外，使用Phong renderings和特别是MSII renderings可以提高摄影照片上的结果，这是全球规模最大的数据集。<details>
<summary>Abstract</summary>
Motivated by the challenges of the Digital Ancient Near Eastern Studies (DANES) community, we develop digital tools for processing cuneiform script being a 3D script imprinted into clay tablets used for more than three millennia and at least eight major languages. It consists of thousands of characters that have changed over time and space. Photographs are the most common representations usable for machine learning, while ink drawings are prone to interpretation. Best suited 3D datasets that are becoming available. We created and used the HeiCuBeDa and MaiCuBeDa datasets, which consist of around 500 annotated tablets. For our novel OCR-like approach to mixed image data, we provide an additional mapping tool for transferring annotations between 3D renderings and photographs. Our sign localization uses a RepPoints detector to predict the locations of characters as bounding boxes. We use image data from GigaMesh's MSII (curvature, see https://gigamesh.eu) based rendering, Phong-shaded 3D models, and photographs as well as illumination augmentation. The results show that using rendered 3D images for sign detection performs better than other work on photographs. In addition, our approach gives reasonably good results for photographs only, while it is best used for mixed datasets. More importantly, the Phong renderings, and especially the MSII renderings, improve the results on photographs, which is the largest dataset on a global scale.
</details>
<details>
<summary>摘要</summary>
受到古近东学界的挑战启发，我们开发了用于处理古代 кли牒文字的数字工具。这种3D文字印刷在泥 TABLETS上用于 более三千年和至少八种主要语言，它包含了数以千计的字符，其中一些在时间和空间上发生了变化。相比之下，图片是最常用于机器学习的表示方式，而墨渍绘制则容易被解释。我们使用的最佳3D数据集在可用。我们创建了HeiCuBeDa和MaiCuBeDa数据集，它们包含约500个注释的板。为了我们的新的OCR-like方法，我们提供了一个将3D渲染与图片之间的映射工具。我们使用的签名地址使用RepPoints探测器预测字符的位置。我们使用GigaMesh的MSII（曲率，请参考https://gigamesh.eu）基于的渲染、Phong灯光渲染和图片以及照明增强。结果表明，使用渲染的3D图像进行字符检测比其他工作更好。此外，我们的方法在图片只的情况下也能达到相对良好的结果，而且在混合数据集情况下表现最佳。特别是MSII渲染和Phong渲染在图片上提高了结果，这是全球规模最大的图片数据集。
</details></li>
</ul>
<hr>
<h2 id="FoX-Formation-aware-exploration-in-multi-agent-reinforcement-learning"><a href="#FoX-Formation-aware-exploration-in-multi-agent-reinforcement-learning" class="headerlink" title="FoX: Formation-aware exploration in multi-agent reinforcement learning"></a>FoX: Formation-aware exploration in multi-agent reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11272">http://arxiv.org/abs/2308.11272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghyeon Jo, Sunwoo Lee, Junghyuk Yum, Seungyul Han</li>
<li>for: 这篇论文的目的是解决多智能代理人学习（MARL）中的探索问题，因为代理人的partial observability和探索空间的增长会导致探索问题增加。</li>
<li>methods: 本文使用了一个formation-based equivalence relation来缩小探索空间，并提出了一个novel的formation-aware探索（FoX）框架，帮助部分可观代理人探索到不同的formation中的状态。</li>
<li>results: numerical results显示，提出的FoX框架在Google Research Football（GRF）和Sparse Starcraft II multi-agent challenge（SMAC）任务上明显超过了现有的MARL算法。<details>
<summary>Abstract</summary>
Recently, deep multi-agent reinforcement learning (MARL) has gained significant popularity due to its success in various cooperative multi-agent tasks. However, exploration still remains a challenging problem in MARL due to the partial observability of the agents and the exploration space that can grow exponentially as the number of agents increases. Firstly, in order to address the scalability issue of the exploration space, we define a formation-based equivalence relation on the exploration space and aim to reduce the search space by exploring only meaningful states in different formations. Then, we propose a novel formation-aware exploration (FoX) framework that encourages partially observable agents to visit the states in diverse formations by guiding them to be well aware of their current formation solely based on their own observations. Numerical results show that the proposed FoX framework significantly outperforms the state-of-the-art MARL algorithms on Google Research Football (GRF) and sparse Starcraft II multi-agent challenge (SMAC) tasks.
</details>
<details>
<summary>摘要</summary>
近些年来，深度多代理人学习（MARL）已经受到了各种合作多代理人任务中的成功，但是探索仍然是MARL中的挑战。这是因为代理人的部分可见性和代理人探索空间的快速增长，尤其是在代理人数量增加时。为解决探索空间的扩展性问题，我们定义了基于形态的相似关系在探索空间上，并尝试将搜索空间减少到有意义的状态。然后，我们提出了一种新的形态意识探索（FoX）框架，该框架鼓励部分可见的代理人访问不同形态中的状态，通过根据自己的观察来让代理人更加了解当前形态。 numerically results show that the proposed FoX framework significantly outperforms the state-of-the-art MARL algorithms on Google Research Football (GRF) and sparse Starcraft II multi-agent challenge (SMAC) tasks.
</details></li>
</ul>
<hr>
<h2 id="Quantum-Inspired-Machine-Learning-a-Survey"><a href="#Quantum-Inspired-Machine-Learning-a-Survey" class="headerlink" title="Quantum-Inspired Machine Learning: a Survey"></a>Quantum-Inspired Machine Learning: a Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11269">http://arxiv.org/abs/2308.11269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Larry Huynh, Jin Hong, Ajmal Mian, Hajime Suzuki, Yanqiu Wu, Seyit Camtepe</li>
<li>for: This survey provides an integrated and comprehensive examination of Quantum-inspired Machine Learning (QiML), exploring its diverse research domains and recent advancements, as well as showcasing practical applications and potential future research avenues.</li>
<li>methods: The survey covers a range of methods in QiML, including tensor network simulations and dequantized algorithms.</li>
<li>results: The survey provides a comprehensive overview of the current landscape of QiML, including recent advancements and potential future directions for research in this field.Here is the information in Simplified Chinese text:</li>
<li>for: 这份报告提供了量子概念Machine Learning（QiML）的全面和综合性评估，探讨其多样化的研究领域，包括维度网络仿真和量子化算法等，以及展示实际应用和未来研究方向。</li>
<li>methods: 报告覆盖了QiML中的多种方法，包括维度网络仿真和量子化算法等。</li>
<li>results: 报告提供了量子概念Machine Learning（QiML）当前的景观，包括最新的进展和未来研究方向。<details>
<summary>Abstract</summary>
Quantum-inspired Machine Learning (QiML) is a burgeoning field, receiving global attention from researchers for its potential to leverage principles of quantum mechanics within classical computational frameworks. However, current review literature often presents a superficial exploration of QiML, focusing instead on the broader Quantum Machine Learning (QML) field. In response to this gap, this survey provides an integrated and comprehensive examination of QiML, exploring QiML's diverse research domains including tensor network simulations, dequantized algorithms, and others, showcasing recent advancements, practical applications, and illuminating potential future research avenues. Further, a concrete definition of QiML is established by analyzing various prior interpretations of the term and their inherent ambiguities. As QiML continues to evolve, we anticipate a wealth of future developments drawing from quantum mechanics, quantum computing, and classical machine learning, enriching the field further. This survey serves as a guide for researchers and practitioners alike, providing a holistic understanding of QiML's current landscape and future directions.
</details>
<details>
<summary>摘要</summary>
量子机器学习（QiML）是一个快速发展的领域，在全球的研究者中受到广泛关注，因为它可以利用量子力学的原理在类别计算框架中进行应用。然而，当前的文献综述往往停留在更广泛的量子机器学习（QML）领域上，而不是深入探讨QiML。为了填补这一空白，本调查提供了一个整合和完整的量子机器学习的调查，探讨了QiML的多个研究领域，包括张量网络 simulations、dequantized算法和其他，展示了最新的进展、实践应用和未来研究方向。此外，本文还提供了一个具体的QiML定义，通过分析各种先前解释的term和其内在的歧义来确定。随着QiML的进一步发展，我们预计将有更多的未来发展，借鉴量子力学、量子计算和类别机器学习，使QiML更加丰富。本调查作为研究者和实践者的指南，提供了量子机器学习当前领域的整体认识和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Robust-Lagrangian-and-Adversarial-Policy-Gradient-for-Robust-Constrained-Markov-Decision-Processes"><a href="#Robust-Lagrangian-and-Adversarial-Policy-Gradient-for-Robust-Constrained-Markov-Decision-Processes" class="headerlink" title="Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes"></a>Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11267">http://arxiv.org/abs/2308.11267</a></li>
<li>repo_url: None</li>
<li>paper_authors: David M. Bossens</li>
<li>for: 本 paper 目的是提出两种基于 RCMDP 的算法，以提高 reinforcement learning 中的 robustness 和可靠性。</li>
<li>methods: 本 paper 使用了两种方法：RCPG with Robust Lagrangian 和 Adversarial RCPG。RCPG with Robust Lagrangian 是修改了 traditional RCPG 的方法，通过使用 Lagrangian 来计算 worst-case dynamics。Adversarial RCPG 则是通过 directly 和 incrementally 学习 adversarial policy 来提高 robustness。</li>
<li>results: 实验结果表明，本 paper 提出的两种算法在 inventory management 和 safe navigation 任务中具有竞争性的性能，并且比 traditional RCPG  variants 和非 robust 的 ablation 更高。尤其是 Adversarial RCPG，在所有测试中排名第二。<details>
<summary>Abstract</summary>
The robust constrained Markov decision process (RCMDP) is a recent task-modelling framework for reinforcement learning that incorporates behavioural constraints and that provides robustness to errors in the transition dynamics model through the use of an uncertainty set. Simulating RCMDPs requires computing the worst-case dynamics based on value estimates for each state, an approach which has previously been used in the Robust Constrained Policy Gradient (RCPG). Highlighting potential downsides of RCPG such as not robustifying the full constrained objective and the lack of incremental learning, this paper introduces two algorithms, called RCPG with Robust Lagrangian and Adversarial RCPG. RCPG with Robust Lagrangian modifies RCPG by taking the worst-case dynamics based on the Lagrangian rather than either the value or the constraint. Adversarial RCPG also formulates the worst-case dynamics based on the Lagrangian but learns this directly and incrementally as an adversarial policy through gradient descent rather than indirectly and abruptly through constrained optimisation on a sorted value list. A theoretical analysis first derives the Lagrangian policy gradient for the policy optimisation of both proposed algorithms and then the adversarial policy gradient to learn the adversary for Adversarial RCPG. Empirical experiments injecting perturbations in inventory management and safe navigation tasks demonstrate the competitive performance of both algorithms compared to traditional RCPG variants as well as non-robust and non-constrained ablations. In particular, Adversarial RCPG ranks among the top two performing algorithms on all tests.
</details>
<details>
<summary>摘要</summary>
RCMDP（Robust Constrained Markov Decision Process）是一种最近的任务建模框架，用于学习奖励学习，它包含行为约束和对过程动态模型的不确定性集。在计算 RCMDP 的 worst-case 动态时，需要根据每个状态的值估计来进行计算，这种方法曾经在 Robust Constrained Policy Gradient (RCPG) 中使用。然而，RCPG 存在一些缺点，如不能对完整的约束目标进行强化，以及不具备逐步学习的能力。这篇论文提出了两种算法，即 RCPG with Robust Lagrangian 和 Adversarial RCPG。RCPG with Robust Lagrangian 修改了 RCPG，通过使用 Lagrangian 而不是值或约束来计算 worst-case 动态。Adversarial RCPG 则通过直接和逐步地使用各元的敌对策略来学习 Lagrangian，而不是通过受限优化来 indirectly 和突然地修改 value 列表。这篇论文首先 derive Lagrangian 政策偏移量，然后是对 Adversarial RCPG 的敌对策略学习。实验表明，两种算法在具有扰动的 inventory management 和 safe navigation 任务中表现竞争性。特别是，Adversarial RCPG 在所有测试中排名第二。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Last-iterate-Convergence-Algorithms-in-Solving-Games"><a href="#Efficient-Last-iterate-Convergence-Algorithms-in-Solving-Games" class="headerlink" title="Efficient Last-iterate Convergence Algorithms in Solving Games"></a>Efficient Last-iterate Convergence Algorithms in Solving Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11256">http://arxiv.org/abs/2308.11256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linjian Meng, Zhenxing Ge, Wenbin Li, Bo An, Yang Gao</li>
<li>for: 学习二人 zero-sum 正规形游戏（NFG）和广泛形游戏（EFG）中的 Nash 平衡（NE）。</li>
<li>methods: 使用 last-iterate convergence no-regret 算法，包括 Optimistic Gradient Descent Ascent（OGDA）和 Optimistic Multiplicative Weight Update（OMWU）。</li>
<li>results: 提出了一种 Reward Transformation（RT）框架，可以减少 OGDA 的每次迭代复杂性，并在不假设 NE 唯一的情况下保证 converge。但是，RT 基于的算法在同样的迭代次数下表现较差，而且其 convergence  garantuee 基于 continuous-time feedback 假设，不符合实际场景。通过对 RT 框架进行更深入的分析，我们发现 RT 框架可以将学习 NE 问题转化为一系列 strongly convex-concave 优化问题（SCCPs）。我们还设计了一种新的转换方法，使得 SCCPs 可以通过 Regret Matching+（RM+）算法解决，并且使得算法在离散时间反馈设定下 converge。实验结果表明，我们的算法在 existing last-iterate convergence 算法和 RM+（CFR+）上表现出色。<details>
<summary>Abstract</summary>
No-regret algorithms are popular for learning Nash equilibrium (NE) in two-player zero-sum normal-form games (NFGs) and extensive-form games (EFGs). Many recent works consider the last-iterate convergence no-regret algorithms. Among them, the two most famous algorithms are Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weight Update (OMWU). However, OGDA has high per-iteration complexity. OMWU exhibits a lower per-iteration complexity but poorer empirical performance, and its convergence holds only when NE is unique. Recent works propose a Reward Transformation (RT) framework for MWU, which removes the uniqueness condition and achieves competitive performance with OMWU. Unfortunately, RT-based algorithms perform worse than OGDA under the same number of iterations, and their convergence guarantee is based on the continuous-time feedback assumption, which does not hold in most scenarios. To address these issues, we provide a closer analysis of the RT framework, which holds for both continuous and discrete-time feedback. We demonstrate that the essence of the RT framework is to transform the problem of learning NE in the original game into a series of strongly convex-concave optimization problems (SCCPs). We show that the bottleneck of RT-based algorithms is the speed of solving SCCPs. To improve the their empirical performance, we design a novel transformation method to enable the SCCPs can be solved by Regret Matching+ (RM+), a no-regret algorithm with better empirical performance, resulting in Reward Transformation RM+ (RTRM+). RTRM+ enjoys last-iterate convergence under the discrete-time feedback setting. Using the counterfactual regret decomposition framework, we propose Reward Transformation CFR+ (RTCFR+) to extend RTRM+ to EFGs. Experimental results show that our algorithms significantly outperform existing last-iterate convergence algorithms and RM+ (CFR+).
</details>
<details>
<summary>摘要</summary>
“调整算法”在二 player零差游戏（NFG）和延展游戏（EFG）中学习 Nash 均衡（NE）很受欢迎。多些最近的研究专注于最后迭代具有调整性的算法。其中最具名望的两个算法是Optimistic Gradient Descent Ascent（OGDA）和Optimistic Multiplicative Weight Update（OMWU）。但OGDA的每迭代复杂度高，OMWU具有较低的每迭代复杂度，但实际性较差，且它的均衡性只适用于当 NE 独特的情况。现有的工作提出了一个 Reward Transformation（RT）框架，用于MWU，可以将 NE 独特性的假设移除，并实现与 OMWU 的竞争性表现。但RT-based algorithms 在同一数量的迭代下表现较差，且其均衡保证基于紧急时间反馈假设，这不是大多数情况下的假设。为了解决这些问题，我们进行了更深入的 RT 框架分析，这个框架在紧急时间反馈下和离散时间反馈下都适用。我们证明了 RT 框架的核心是将原始游戏中学习 NE 的问题转换为一系列强弱点减游戏（SCCPs）。我们显示了 SCCPs 的瓶颈在 RT-based algorithms 中，以及如何使用 Regret Matching+（RM+）这个 no-regret 算法来解决这个问题。我们给出了一个新的变换方法，使得 SCCPs 可以使用 RM+ 来解决，从而获得 Reward Transformation RM+（RTRM+）。RTRM+ 在离散时间反馈下具有最后迭代均衡性。使用 counterfactual regret decomposition 框架，我们提出了 Reward Transformation CFR+（RTCFR+）来扩展 RTRM+ 到 EFGs。实验结果显示我们的算法在与现有的最后迭代均衡算法和 RM+（CFR+）进行比较时，具有更好的实际表现。”
</details></li>
</ul>
<hr>
<h2 id="A-survey-on-bias-in-machine-learning-research"><a href="#A-survey-on-bias-in-machine-learning-research" class="headerlink" title="A survey on bias in machine learning research"></a>A survey on bias in machine learning research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11254">http://arxiv.org/abs/2308.11254</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aastha2104/Parkinson-Disease-Prediction">https://github.com/Aastha2104/Parkinson-Disease-Prediction</a></li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Michał Grochowski</li>
<li>for: 本研究旨在强调机器学习中的偏见问题，而不仅仅是公平性。</li>
<li>methods: 本文提供了机器学习管道中偏见的多种可能来源和错误的数据和模型阶段的分类。</li>
<li>results: 本研究通过对四十多个机器学习管道中偏见的分析，提供了具体的示例，以便更好地理解和掌握机器学习中的偏见问题，并开发更公平、更透明、更准确的机器学习模型。<details>
<summary>Abstract</summary>
Current research on bias in machine learning often focuses on fairness, while overlooking the roots or causes of bias. However, bias was originally defined as a "systematic error," often caused by humans at different stages of the research process. This article aims to bridge the gap between past literature on bias in research by providing taxonomy for potential sources of bias and errors in data and models. The paper focus on bias in machine learning pipelines. Survey analyses over forty potential sources of bias in the machine learning (ML) pipeline, providing clear examples for each. By understanding the sources and consequences of bias in machine learning, better methods can be developed for its detecting and mitigating, leading to fairer, more transparent, and more accurate ML models.
</details>
<details>
<summary>摘要</summary>
当前的研究对机器学习中的偏见通常集中于公平性，而忽视了偏见的根源或原因。然而，偏见最初是定义为一种"系统性错误"，经常由人类在不同阶段的研究过程中引入。这篇文章试图 bridge 过去的Literature on bias在研究中的偏见，提供机器学习管道中可能的偏见和错误的分类。文章专注于机器学习管道中的偏见。survey分析了超过四十个机器学习管道中的偏见来源，并提供了明确的示例。通过理解机器学习中的偏见源头和后果，可以开发出更好的检测和缓解偏见方法，导致更公平、更透明和更准确的机器学习模型。
</details></li>
</ul>
<hr>
<h2 id="Multi-Source-Domain-Adaptation-for-Cross-Domain-Fault-Diagnosis-of-Chemical-Processes"><a href="#Multi-Source-Domain-Adaptation-for-Cross-Domain-Fault-Diagnosis-of-Chemical-Processes" class="headerlink" title="Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes"></a>Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11247">http://arxiv.org/abs/2308.11247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Fernandes Montesuma, Michela Mulas, Fred Ngolè Mboula, Francesco Corona, Antoine Souloumiac</li>
<li>for: 本研究旨在对过程监测中的故障诊断进行自动化，并使用机器学习来预测故障类型基于传感器读ings。</li>
<li>methods: 本研究使用单源隐式预测（SSDA）和多源隐式预测（MSDA）算法进行过程监测中的故障诊断，并在田东曼过程中进行了广泛的比较。</li>
<li>results: 研究结果表明，在多个源数据中训练时，使用多源隐式预测算法可以提高故障类型的预测精度，相比单源隐式预测算法，多源隐式预测算法在无适应情况下提高了平均23%的分类精度。此外，在多源数据中训练时，无适应情况下，多源隐式预测算法可以提高故障类型的预测精度8.4%的平均提升。<details>
<summary>Abstract</summary>
Fault diagnosis is an essential component in process supervision. Indeed, it determines which kind of fault has occurred, given that it has been previously detected, allowing for appropriate intervention. Automatic fault diagnosis systems use machine learning for predicting the fault type from sensor readings. Nonetheless, these models are sensible to changes in the data distributions, which may be caused by changes in the monitored process, such as changes in the mode of operation. This scenario is known as Cross-Domain Fault Diagnosis (CDFD). We provide an extensive comparison of single and multi-source unsupervised domain adaptation (SSDA and MSDA respectively) algorithms for CDFD. We study these methods in the context of the Tennessee-Eastmann Process, a widely used benchmark in the chemical industry. We show that using multiple domains during training has a positive effect, even when no adaptation is employed. As such, the MSDA baseline improves over the SSDA baseline classification accuracy by 23% on average. In addition, under the multiple-sources scenario, we improve classification accuracy of the no adaptation setting by 8.4% on average.
</details>
<details>
<summary>摘要</summary>
检测 fault 是 proces supervision 中的一个重要组件。它可以确定已经检测到的 fault 类型，并且允许适当的 intervención。自动 fault 检测系统 使用机器学习来预测 fault 类型从 sensor 读数中。然而，这些模型对数据分布的变化敏感，这可能是由监测过程中的变化引起的，例如操作模式的变化。这种情况被称为 Cross-Domain Fault Diagnosis (CDFD)。我们提供了单和多源无监督领域适应 (SSDA 和 MSDA 分别) 算法的广泛比较，用于 CDFD。我们在 Tennessee-Eastmann 过程中进行研究，这是化学工业中 widely 使用的标准测试集。我们发现，在训练时使用多个领域可以提高分类精度，即使没有适应。因此，MSDA 基线比 SSDA 基线分类精度高出 23% 的平均值。此外，在多源enario 下，我们可以提高无适应设置的分类精度的平均值8.4%。
</details></li>
</ul>
<hr>
<h2 id="An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification"><a href="#An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification" class="headerlink" title="An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification"></a>An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11241">http://arxiv.org/abs/2308.11241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harunorikawano/speaker-identification-with-tgp">https://github.com/harunorikawano/speaker-identification-with-tgp</a></li>
<li>paper_authors: Harunori Kawano, Sota Shimizu</li>
<li>for: 这 paper 的目的是提出一种基于 Transformer 架构和自我超vised 学习的高效 speaker identification 模型。</li>
<li>methods: 该 paper 使用了 Transformer-based contextual model，并进行了参数与性能之间的关系研究，以探索一个有效的模型结构。此外， paper 还提出了 Temporal Gate Pooling（TGP）方法，可以增强 speaker identification 的学习能力。</li>
<li>results: 通过使用 Conformer 编码器和 BEST-RQ 预训练， authors 实现了一个准确率为 85.9%，参数量为 28.5M 的 speaker identification 模型，与 wav2vec2 的 317.7M 参数量相当。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/HarunoriKawano/speaker-identification-with-tgp">https://github.com/HarunoriKawano/speaker-identification-with-tgp</a> 上获取。<details>
<summary>Abstract</summary>
Wav2vec2 has achieved success in applying Transformer architecture and self-supervised learning to speech recognition. Recently, these have come to be used not only for speech recognition but also for the entire speech processing. This paper introduces an effective end-to-end speaker identification model applied Transformer-based contextual model. We explored the relationship between the parameters and the performance in order to discern the structure of an effective model. Furthermore, we propose a pooling method, Temporal Gate Pooling, with powerful learning ability for speaker identification. We applied Conformer as encoder and BEST-RQ for pre-training and conducted an evaluation utilizing the speaker identification of VoxCeleb1. The proposed method has achieved an accuracy of 85.9% with 28.5M parameters, demonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is available at https://github.com/HarunoriKawano/speaker-identification-with-tgp.
</details>
<details>
<summary>摘要</summary>
噪声2vec2在应用transformer架构和自动学习方法上取得了成功，现在不仅用于语音识别，还用于整个语音处理。这篇论文介绍了一种高效的端到端Speaker Identification模型，该模型基于Transformer-based contextual模型。我们研究了参数和性能之间的关系，以便理解有效模型的结构。此外，我们提出了一种强大学习能力的pooling方法：Temporal Gate Pooling。我们使用Conformer作Encoder，并在BEST-RQ上进行预训练，对VoxCeleb1中的Speaker Identification进行评估。我们的方法实现了85.9%的准确率， Parameters为28.5M，与wav2vec2的317.7M Parameters相比，表现相对较高。代码可以在https://github.com/HarunoriKawano/speaker-identification-with-tgp中找到。
</details></li>
</ul>
<hr>
<h2 id="Minwise-Independent-Permutations-with-Insertion-and-Deletion-of-Features"><a href="#Minwise-Independent-Permutations-with-Insertion-and-Deletion-of-Features" class="headerlink" title="Minwise-Independent Permutations with Insertion and Deletion of Features"></a>Minwise-Independent Permutations with Insertion and Deletion of Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11240">http://arxiv.org/abs/2308.11240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rameshwar Pratap, Raghav Kulkarni</li>
<li>for: 本研究的目的是研究在动态插入和删除特征的情况下，$\mathrm{minHash}$ 算法是否可以提供高效和精准的笛卡尔相似性计算。</li>
<li>methods: 本研究使用了动态插入和删除特征的 $\mathrm{minHash}$ 算法，并提出了一种基于随机排序的算法来使$\mathrm{minHash}$ 笛卡尔相似性计算更加高效和精准。</li>
<li>results: 本研究通过了一系列的实验和理论分析，证明了该算法在动态插入和删除特征的情况下可以具有显著的时间效益和相似性表现。<details>
<summary>Abstract</summary>
In their seminal work, Broder \textit{et. al.}~\citep{BroderCFM98} introduces the $\mathrm{minHash}$ algorithm that computes a low-dimensional sketch of high-dimensional binary data that closely approximates pairwise Jaccard similarity. Since its invention, $\mathrm{minHash}$ has been commonly used by practitioners in various big data applications. Further, the data is dynamic in many real-life scenarios, and their feature sets evolve over time. We consider the case when features are dynamically inserted and deleted in the dataset. We note that a naive solution to this problem is to repeatedly recompute $\mathrm{minHash}$ with respect to the updated dimension. However, this is an expensive task as it requires generating fresh random permutations. To the best of our knowledge, no systematic study of $\mathrm{minHash}$ is recorded in the context of dynamic insertion and deletion of features. In this work, we initiate this study and suggest algorithms that make the $\mathrm{minHash}$ sketches adaptable to the dynamic insertion and deletion of features. We show a rigorous theoretical analysis of our algorithms and complement it with extensive experiments on several real-world datasets. Empirically we observe a significant speed-up in the running time while simultaneously offering comparable performance with respect to running $\mathrm{minHash}$ from scratch. Our proposal is efficient, accurate, and easy to implement in practice.
</details>
<details>
<summary>摘要</summary>
它们的著名论文《CFM98》中，布罗德等人（Broder et al.)提出了一种低维度的$\mathrm{minHash}$算法，用于计算高维度二分类数据的紧密相似性。自其发明以来，$\mathrm{minHash}$在各种大数据应用中广泛使用。然而，在许多实际场景中，数据的特征集合会随着时间的推移而变化。我们考虑在数据集中动态插入和删除特征的情况。一个简单的解决方案是在更新后重新计算$\mathrm{minHash}$。然而，这是一项昂贵的任务，需要生成新的随机排序。到目前为止，我们未发现任何关于动态插入和删除特征的$\mathrm{minHash}$系统性研究。在这个研究中，我们开始了这个研究，并提出了一些使$\mathrm{minHash}$签名适应动态插入和删除特征的算法。我们进行了严格的理论分析，并通过多个实际数据集的实验观察，证明了我们的方法可以快速、精准地计算$\mathrm{minHash}$签名，同时保持与从scratch计算$\mathrm{minHash}$的性能相似。我们的提议是高效、准确、易于实现的。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-on-Patient-Data-for-Privacy-Protecting-Polycystic-Ovary-Syndrome-Treatment"><a href="#Federated-Learning-on-Patient-Data-for-Privacy-Protecting-Polycystic-Ovary-Syndrome-Treatment" class="headerlink" title="Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment"></a>Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11220">http://arxiv.org/abs/2308.11220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toriqiu/fl-pcos">https://github.com/toriqiu/fl-pcos</a></li>
<li>paper_authors: Lucia Morris, Tori Qiu, Nikhil Raghuraman</li>
<li>for: 这个研究旨在应用 Federated Learning (FL) 技术来预测女性患有多囊淋巴综合症 (PCOS) 的最佳药物。</li>
<li>methods: 本研究使用了多种 Federated Learning 方法，包括 Federated Averaging (FedAvg)、Proximal Federated Learning (PFL) 和 Federated Transfer Learning (FTL)，并证明这些方法在人工生成的 PCOS 患者数据集上得到了成功。</li>
<li>results: 研究发现，这些 Federated Learning 方法可以在 accessed massive quantities of diverse data 中提供最佳的治疗选择，并为 PCOS 患者提供隐私保证。<details>
<summary>Abstract</summary>
The field of women's endocrinology has trailed behind data-driven medical solutions, largely due to concerns over the privacy of patient data. Valuable datapoints about hormone levels or menstrual cycling could expose patients who suffer from comorbidities or terminate a pregnancy, violating their privacy. We explore the application of Federated Learning (FL) to predict the optimal drug for patients with polycystic ovary syndrome (PCOS). PCOS is a serious hormonal disorder impacting millions of women worldwide, yet it's poorly understood and its research is stunted by a lack of patient data. We demonstrate that a variety of FL approaches succeed on a synthetic PCOS patient dataset. Our proposed FL models are a tool to access massive quantities of diverse data and identify the most effective treatment option while providing PCOS patients with privacy guarantees.
</details>
<details>
<summary>摘要</summary>
女性内分泌学领域落后于数据驱动医疗解决方案，主要是因为担心病人数据隐私问题。病人患有混合症或终止怀孕的情况可能会透露出有价值的内分泌水平或月经周期数据，违反病人隐私。我们研究了 Federated Learning（FL）的应用，以预测患有多囊卵巢综合症（PCOS）的女性患者需要哪种药物。PCOS 是全球数百万女性患有的严重内分泌疾病，但它的研究受到缺乏病人数据的限制。我们展示了多种 FL 方法在 sintetic PCOS 患者数据集上取得成功。我们提议的 FL 模型可以访问庞大的多样数据，并在保证病人隐私的情况下，为患有 PCOS 的女性患者预测最有效的治疗方案。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-in-Big-Model-Era-Domain-Specific-Multimodal-Large-Models"><a href="#Federated-Learning-in-Big-Model-Era-Domain-Specific-Multimodal-Large-Models" class="headerlink" title="Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models"></a>Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11217">http://arxiv.org/abs/2308.11217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zengxiang Li, Zhaoxiang Hou, Hui Liu, Ying Wang, Tongzhi Li, Longfei Xie, Chao Shi, Chengyi Yang, Weishan Zhang, Zelei Liu, Liang Xu</li>
<li>for: 提出一种多模态联合学习框架，以帮助多家企业通过私有领域数据来共同训练大型模型，实现各种场景下的智能服务。</li>
<li>methods: 提出了多模态联合学习框架，包括智能基础和目标的战略转变，以及新的多样数据、模型聚合、性能和成本负担、数据隐私和奖励机制等挑战。</li>
<li>results: 通过实施多模态联合学习框架，企业可以增强和积累智能能力，共同创造智能城市模型，提供高质量智能服务，包括能源基础设施安全、住宅社区安全和城市运营管理。<details>
<summary>Abstract</summary>
Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. This paper proposes a multimodal federated learning framework that enables multiple enterprises to utilize private domain data to collaboratively train large models for vertical domains, achieving intelligent services across scenarios. The authors discuss in-depth the strategic transformation of federated learning in terms of intelligence foundation and objectives in the era of big model, as well as the new challenges faced in heterogeneous data, model aggregation, performance and cost trade-off, data privacy, and incentive mechanism. The paper elaborates a case study of leading enterprises contributing multimodal data and expert knowledge to city safety operation management , including distributed deployment and efficient coordination of the federated learning platform, technical innovations on data quality improvement based on large model capabilities and efficient joint fine-tuning approaches. Preliminary experiments show that enterprises can enhance and accumulate intelligent capabilities through multimodal model federated learning, thereby jointly creating an smart city model that provides high-quality intelligent services covering energy infrastructure safety, residential community security, and urban operation management. The established federated learning cooperation ecosystem is expected to further aggregate industry, academia, and research resources, realize large models in multiple vertical domains, and promote the large-scale industrial application of artificial intelligence and cutting-edge research on multimodal federated learning.
</details>
<details>
<summary>摘要</summary>
多modal数据，可以全面感受和认可物理世界，已成为通往通用人工智能的重要路径。然而，多modal大型模型在公共数据集上训练时经常下perform。这篇论文提出了一个多modal联合学习框架，允许多家企业使用私有领域数据共同训练大型模型，实现多场景智能服务。作者们详细讲解联合学习在智能基础和目标方面的战略转型，以及在不同数据和模型聚合、性能和成本权衡、数据隐私和奖励机制方面新出现的挑战。论文还介绍了一个城市安全运营管理案例研究，包括分布式部署和有效协调联合学习平台，以及基于大型模型能力的数据质量改进技术和有效联合精度调整方法。初步实验表明，企业可以通过多modal模型联合学习增强和积累智能能力，共同创建一个智能城市模型，提供高质量智能服务，涵盖能源基础设施安全、居民社区安全和城市运营管理。建立的联合学习合作生态系统预计会进一步吸引产业、学术和研究资源，实现多个垂直领域的大型模型，并推动人工智能的大规模工业应用和多modal联合学习的前沿研究。
</details></li>
</ul>
<hr>
<h2 id="Hamiltonian-GAN"><a href="#Hamiltonian-GAN" class="headerlink" title="Hamiltonian GAN"></a>Hamiltonian GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11216">http://arxiv.org/abs/2308.11216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/koritsky/hamiltonian_learning">https://github.com/koritsky/hamiltonian_learning</a></li>
<li>paper_authors: Christine Allen-Blanchette</li>
<li>for: 这个论文旨在使用 Hamiltonian  formalism 作为一种 физи学上有效的视频生成方法的 inductive bias。</li>
<li>methods: 该方法使用了一种叫做 Hamiltonian neural network 的 Motion Model，通过学习配置空间地图和 Hamiltonian 来学习一个可以表示配置空间的表示。</li>
<li>results: 该方法在使用 physics-inspired cyclic-coordinate loss function 进行训练后，能够在 Hamiltonian Dynamics Suite Toy Physics 数据集上实现更高的效果和可 interpretability。<details>
<summary>Abstract</summary>
A growing body of work leverages the Hamiltonian formalism as an inductive bias for physically plausible neural network based video generation. The structure of the Hamiltonian ensures conservation of a learned quantity (e.g., energy) and imposes a phase-space interpretation on the low-dimensional manifold underlying the input video. While this interpretation has the potential to facilitate the integration of learned representations in downstream tasks, existing methods are limited in their applicability as they require a structural prior for the configuration space at design time. In this work, we present a GAN-based video generation pipeline with a learned configuration space map and Hamiltonian neural network motion model, to learn a representation of the configuration space from data. We train our model with a physics-inspired cyclic-coordinate loss function which encourages a minimal representation of the configuration space and improves interpretability. We demonstrate the efficacy and advantages of our approach on the Hamiltonian Dynamics Suite Toy Physics dataset.
</details>
<details>
<summary>摘要</summary>
“一个增长中的研究利用哈密顿ormalism作为神经网络基于视频生成的假设逻辑。哈密顿结构保证学习的量（例如能量）的保守和要求输入视频的低维度抽象空间具有相位空间的解释，这有助于在下游任务中集成学习的表示。然而现有的方法有限于其应用，因为它们在设计时需要一个结构的假设 для配置空间。在这项工作中，我们提出了一个基于GAN的视频生成管线，使用学习的配置空间地图和哈密顿神经网络动力学模型来学习配置空间的表示。我们使用一种受物理灵感的循环坐标损失函数来驱动学习，这种损失函数鼓励最小化配置空间的表示，并提高可读性。我们在哈密顿动力学集 Toy Physics 数据集上证明了我们的方法的有效性和优势。”Note: Simplified Chinese is used in this translation, which is a more casual and widely-used version of Chinese. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Framework-for-Multi-mode-Spatial-Temporal-Data-Modeling"><a href="#A-Simple-Framework-for-Multi-mode-Spatial-Temporal-Data-Modeling" class="headerlink" title="A Simple Framework for Multi-mode Spatial-Temporal Data Modeling"></a>A Simple Framework for Multi-mode Spatial-Temporal Data Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11204">http://arxiv.org/abs/2308.11204</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lzhmarkk/simmst">https://github.com/lzhmarkk/simmst</a></li>
<li>paper_authors: Zihang Liu, Le Yu, Tongyu Zhu, Leiei Sun</li>
<li>for: 本文旨在提出一种简单的多模式空间时间数据模型方法，以提高效率和效果的权衡。</li>
<li>methods: 本文提出了一种通用的对角模式空间关系学习组件，可以适应多种模式之间的连接和信息传递。此外，文章还使用多层感知器来捕捉时间相关性和通道相关性，技术上和概念上都非常简洁。</li>
<li>results: 实验结果表明，我们的模型可以在三个实际数据集上经常超越基线，并且具有较低的空间和时间复杂度。此外，通用的对角模式空间关系学习模块的一致性也得到了验证。<details>
<summary>Abstract</summary>
Spatial-temporal data modeling aims to mine the underlying spatial relationships and temporal dependencies of objects in a system. However, most existing methods focus on the modeling of spatial-temporal data in a single mode, lacking the understanding of multiple modes. Though very few methods have been presented to learn the multi-mode relationships recently, they are built on complicated components with higher model complexities. In this paper, we propose a simple framework for multi-mode spatial-temporal data modeling to bring both effectiveness and efficiency together. Specifically, we design a general cross-mode spatial relationships learning component to adaptively establish connections between multiple modes and propagate information along the learned connections. Moreover, we employ multi-layer perceptrons to capture the temporal dependencies and channel correlations, which are conceptually and technically succinct. Experiments on three real-world datasets show that our model can consistently outperform the baselines with lower space and time complexity, opening up a promising direction for modeling spatial-temporal data. The generalizability of the cross-mode spatial relationships learning module is also validated.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SegRNN-Segment-Recurrent-Neural-Network-for-Long-Term-Time-Series-Forecasting"><a href="#SegRNN-Segment-Recurrent-Neural-Network-for-Long-Term-Time-Series-Forecasting" class="headerlink" title="SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting"></a>SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11200">http://arxiv.org/abs/2308.11200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengsheng Lin, Weiwei Lin, Wentai Wu, Feiyu Zhao, Ruichao Mo, Haotong Zhang</li>
<li>for: 这 paper 是为了解决 RNN 在长期时间序列预测（LTSF）领域中遇到的挑战，特别是面临非常长的寻回窗口和预测范围。</li>
<li>methods: 这 paper 提出了两种新的策略来减少 RNN 在 LTSF 任务中的迭代次数：Segment-wise Iterations 和 Parallel Multi-step Forecasting（PMF）。这两种策略可以减少 RNN 的迭代次数，从而提高预测精度和执行速度。</li>
<li>results: 对比 SOTA Transformer-based 模型，SegRNN 能够显著提高预测精度和执行速度，同时减少了 runtime 和内存使用量，减少了超过 78%。这些成果证明 RNN 仍然在 LTSF 任务中具有优势，并促使更多的 RNN-based 方法在这个领域进行进一步的探索。<details>
<summary>Abstract</summary>
RNN-based methods have faced challenges in the Long-term Time Series Forecasting (LTSF) domain when dealing with excessively long look-back windows and forecast horizons. Consequently, the dominance in this domain has shifted towards Transformer, MLP, and CNN approaches. The substantial number of recurrent iterations are the fundamental reasons behind the limitations of RNNs in LTSF. To address these issues, we propose two novel strategies to reduce the number of iterations in RNNs for LTSF tasks: Segment-wise Iterations and Parallel Multi-step Forecasting (PMF). RNNs that combine these strategies, namely SegRNN, significantly reduce the required recurrent iterations for LTSF, resulting in notable improvements in forecast accuracy and inference speed. Extensive experiments demonstrate that SegRNN not only outperforms SOTA Transformer-based models but also reduces runtime and memory usage by more than 78%. These achievements provide strong evidence that RNNs continue to excel in LTSF tasks and encourage further exploration of this domain with more RNN-based approaches. The source code is coming soon.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ConcatPlexer-Additional-Dim1-Batching-for-Faster-ViTs"><a href="#ConcatPlexer-Additional-Dim1-Batching-for-Faster-ViTs" class="headerlink" title="ConcatPlexer: Additional Dim1 Batching for Faster ViTs"></a>ConcatPlexer: Additional Dim1 Batching for Faster ViTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11199">http://arxiv.org/abs/2308.11199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donghoon Han, Seunghyeon Seo, Donghyeon Jeon, Jiho Jang, Chaerin Kong, Nojun Kwak</li>
<li>for: 降低计算成本，提高图像识别效率</li>
<li>methods: 使用额外维度批处理（ concatenation）和改进的图像多路径（Image Multiplexer），提高通过put和精度之间的平衡</li>
<li>results: 在ImageNet1K和CIFAR100 dataset上训练ConcatPlexer，相比ViT-B&#x2F;16，减少了23.5%的GFLOPs，并在验证集上达到69.5%和83.4%的验证精度I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Transformers have demonstrated tremendous success not only in the natural language processing (NLP) domain but also the field of computer vision, igniting various creative approaches and applications. Yet, the superior performance and modeling flexibility of transformers came with a severe increase in computation costs, and hence several works have proposed methods to reduce this burden. Inspired by a cost-cutting method originally proposed for language models, Data Multiplexing (DataMUX), we propose a novel approach for efficient visual recognition that employs additional dim1 batching (i.e., concatenation) that greatly improves the throughput with little compromise in the accuracy. We first introduce a naive adaptation of DataMux for vision models, Image Multiplexer, and devise novel components to overcome its weaknesses, rendering our final model, ConcatPlexer, at the sweet spot between inference speed and accuracy. The ConcatPlexer was trained on ImageNet1K and CIFAR100 dataset and it achieved 23.5% less GFLOPs than ViT-B/16 with 69.5% and 83.4% validation accuracy, respectively.
</details>
<details>
<summary>摘要</summary>
启发于语言模型的成本减少方法，我们提出了一种新的方法 для快速识别图像，即 concatenation 方法。我们首先介绍了图像多元化（Image Multiplexer），然后开发了新的组件以解决其缺陷，最终得到了 ConcatPlexer 模型。ConcatPlexer 模型在 ImageNet1K 和 CIFAR100 数据集上训练，并实现了与 ViT-B/16 相比的 23.5%  menos GFLOPs，同时保持了69.5% 和 83.4% 的验证精度。
</details></li>
</ul>
<hr>
<h2 id="Toward-Generalizable-Machine-Learning-Models-in-Speech-Language-and-Hearing-Sciences-Power-Analysis-and-Sample-Size-Estimation"><a href="#Toward-Generalizable-Machine-Learning-Models-in-Speech-Language-and-Hearing-Sciences-Power-Analysis-and-Sample-Size-Estimation" class="headerlink" title="Toward Generalizable Machine Learning Models in Speech, Language, and Hearing Sciences: Power Analysis and Sample Size Estimation"></a>Toward Generalizable Machine Learning Models in Speech, Language, and Hearing Sciences: Power Analysis and Sample Size Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11197">http://arxiv.org/abs/2308.11197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamzeh Ghasemzadeh, Robert E. Hillman, Daryush D. Mehta</li>
<li>for: 提供量化证据，鼓励研究人员使用更加稳健的嵌套十字验证法。</li>
<li>methods: 使用 Monte Carlo 仿真和 Matlab 代码进行 ML 分析的力度分析，比较不同的十字验证方法（单个割裂、10-fold、训练-验证-测试和嵌套10-fold）的统计能力和统计信任度。</li>
<li>results: 结果显示，使用嵌套十字验证法可以获得最高的统计信任度和统计能力，并提供了不偏的准确率估计。相比之下，使用单个割裂法可能会过估准确率，需要50%更多的样本来达到同等的统计能力。<details>
<summary>Abstract</summary>
This study's first purpose is to provide quantitative evidence that would incentivize researchers to instead use the more robust method of nested cross-validation. The second purpose is to present methods and MATLAB codes for doing power analysis for ML-based analysis during the design of a study. Monte Carlo simulations were used to quantify the interactions between the employed cross-validation method, the discriminative power of features, the dimensionality of the feature space, and the dimensionality of the model. Four different cross-validations (single holdout, 10-fold, train-validation-test, and nested 10-fold) were compared based on the statistical power and statistical confidence of the ML models. Distributions of the null and alternative hypotheses were used to determine the minimum required sample size for obtaining a statistically significant outcome ({\alpha}=0.05, 1-\b{eta}=0.8). Statistical confidence of the model was defined as the probability of correct features being selected and hence being included in the final model. Our analysis showed that the model generated based on the single holdout method had very low statistical power and statistical confidence and that it significantly overestimated the accuracy. Conversely, the nested 10-fold cross-validation resulted in the highest statistical confidence and the highest statistical power, while providing an unbiased estimate of the accuracy. The required sample size with a single holdout could be 50% higher than what would be needed if nested cross-validation were used. Confidence in the model based on nested cross-validation was as much as four times higher than the confidence in the single holdout-based model. A computational model, MATLAB codes, and lookup tables are provided to assist researchers with estimating the sample size during the design of their future studies.
</details>
<details>
<summary>摘要</summary>
In simplified Chinese, the text might be translated as:这个研究的第一个目的是提供量化证据，以便激励研究人员使用更加稳定的嵌套十分之分验方法。第二个目的是向研究人员提供方法和MATLAB代码，以便在设计研究时进行能量分析。 Monte Carlo仿真被用来评估各种十分之分验方法的交互作用，包括单个停留、10个折衣、训练验证测试、嵌套10个折衣。研究发现，使用嵌套10个折衣方法可以获得最高的统计信任度和统计能力，而且可以提供不偏的准确率估计。单个停留方法的模型具有很低的统计信任度和统计能力，并且很大程度上过估了准确率。相比之下，使用嵌套10个折衣方法可以避免这些问题。这个研究提供了一个计算模型、MATLAB代码和查找表，以帮助研究人员在设计未来研究时估计样本大小。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Task-Parallelization-of-Dataflow-Graphs-in-ML-DL-models"><a href="#Automatic-Task-Parallelization-of-Dataflow-Graphs-in-ML-DL-models" class="headerlink" title="Automatic Task Parallelization of Dataflow Graphs in ML&#x2F;DL models"></a>Automatic Task Parallelization of Dataflow Graphs in ML&#x2F;DL models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11192">http://arxiv.org/abs/2308.11192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srinjoy Das, Lawrence Rauchwerger</li>
<li>for: 加速 Machine Learning(ML) 和 Deep-Learning(DL) 模型的训练和执行，以提高性能和效率。</li>
<li>methods: 使用 Critical-Path-based Linear Clustering 方法，利用 ML 数据流图中的自然平行路径进行并行处理，并通过clone和常量传递来优化图结构。此外，我们还使用一个新建的工具 called {\bf Ramiel}，将 ML 模型转换成可读写并可执行的 Pytorch+Python 代码，以便利用其他下游加速技术。</li>
<li>results: 我们的实验结果表明，使用我们的方法可以在多个 ML 图中获得至多 1.9 倍的速度提升，并在 compile 和 runtime 中超越一些当前的机制。此外，我们的方法具有轻量级和快速的特点，适用于资源和电源受限的设备，同时仍能启用下游优化。<details>
<summary>Abstract</summary>
Several methods exist today to accelerate Machine Learning(ML) or Deep-Learning(DL) model performance for training and inference. However, modern techniques that rely on various graph and operator parallelism methodologies rely on search space optimizations which are costly in terms of power and hardware usage. Especially in the case of inference, when the batch size is 1 and execution is on CPUs or for power-constrained edge devices, current techniques can become costly, complicated or inapplicable. To ameliorate this, we present a Critical-Path-based Linear Clustering approach to exploit inherent parallel paths in ML dataflow graphs. Our task parallelization approach further optimizes the structure of graphs via cloning and prunes them via constant propagation and dead-code elimination. Contrary to other work, we generate readable and executable parallel Pytorch+Python code from input ML models in ONNX format via a new tool that we have built called {\bf Ramiel}. This allows us to benefit from other downstream acceleration techniques like intra-op parallelism and potentially pipeline parallelism. Our preliminary results on several ML graphs demonstrate up to 1.9$\times$ speedup over serial execution and outperform some of the current mechanisms in both compile and runtimes. Lastly, our methods are lightweight and fast enough so that they can be used effectively for power and resource-constrained devices, while still enabling downstream optimizations.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, but please note that the translation may not be perfect and may require some adjustments to accurately convey the intended meaning.)
</details></li>
</ul>
<hr>
<h2 id="Diversity-Measures-Domain-Independent-Proxies-for-Failure-in-Language-Model-Queries"><a href="#Diversity-Measures-Domain-Independent-Proxies-for-Failure-in-Language-Model-Queries" class="headerlink" title="Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries"></a>Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11189">http://arxiv.org/abs/2308.11189</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab-v2/diversity_measures">https://github.com/lab-v2/diversity_measures</a></li>
<li>paper_authors: Noel Ngu, Nathaniel Lee, Paulo Shakarian</li>
<li>for: 这篇论文是针对大型语言模型中的错误预测进行研究，特别是基于领域专门知识。</li>
<li>methods: 本文提出了基于对答几何的多元性来衡量错误的三种方法：基于熵、基于金尼逊级别和基于中心距离。</li>
<li>results: 本文通过多个数据集和温度设定的实验显示，这三种方法强相关于错误的可能性。此外，本文还提供了实践结果，说明了这些方法可以应用于几何问题、链式思维和错误检测。<details>
<summary>Abstract</summary>
Error prediction in large language models often relies on domain-specific information. In this paper, we present measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt - hence independent of the underlying application. We describe how three such measures - based on entropy, Gini impurity, and centroid distance - can be employed. We perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. Additionally, we present empirical results demonstrating how these measures can be applied to few-shot prompting, chain-of-thought reasoning, and error detection.
</details>
<details>
<summary>摘要</summary>
大型语言模型中的错误预测通常需要对特定领域的信息。在这篇文章中，我们提出了基于响应问题的多样性的评估方法，以独立于下游应用。我们详细描述了三种评估方法，包括基于熵、基于吉尼不纯度和中心距离。我们在多个数据集和温度设定下进行了一系列实验，以示这些评估方法与错误的机会强相关。此外，我们还提供了实践结果，详细介绍了如何将这些评估方法应用到几个问题、推理和错误检测。
</details></li>
</ul>
<hr>
<h2 id="A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology"><a href="#A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology" class="headerlink" title="A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology"></a>A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11179">http://arxiv.org/abs/2308.11179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibtihaj Ahmad, Syed Muhammad Israr, Zain Ul Islam</li>
<li>for: 这篇论文主要关注于电子显微镜中的细胞构成物分类和分 segmentation的问题，以协助电脑助癌诊断。</li>
<li>methods: 这篇论文使用了多个增强型深度学习模型，包括多个核心decoder head和独立的复杂损失函数，以解决电子显微镜中的挑战。</li>
<li>results: 这篇论文获得了高品质的分类和分 segmentation结果，包括0.841 dice score、0.713 bPQ score和0.633 mPQ score等。此外，这个框架可以在19种不同的组织中进行通用化。<details>
<summary>Abstract</summary>
Simultaneous segmentation and classification of nuclei in digital histology play an essential role in computer-assisted cancer diagnosis; however, it remains challenging. The highest achieved binary and multi-class Panoptic Quality (PQ) remains as low as 0.68 bPQ and 0.49 mPQ, respectively. It is due to the higher staining variability, variability across the tissue, rough clinical conditions, overlapping nuclei, and nuclear class imbalance. The generic deep-learning methods usually rely on end-to-end models, which fail to address these problems associated explicitly with digital histology. In our previous work, DAN-NucNet, we resolved these issues for semantic segmentation with an end-to-end model. This work extends our previous model to simultaneous instance segmentation and classification. We introduce additional decoder heads with independent weighted losses, which produce semantic segmentation, edge proposals, and classification maps. We use the outputs from the three-head model to apply post-processing to produce the final segmentation and classification. Our multi-stage approach utilizes edge proposals and semantic segmentations compared to direct segmentation and classification strategies followed by most state-of-the-art methods. Due to this, we demonstrate a significant performance improvement in producing high-quality instance segmentation and nuclei classification. We have achieved a 0.841 Dice score for semantic segmentation, 0.713 bPQ scores for instance segmentation, and 0.633 mPQ for nuclei classification. Our proposed framework is generalized across 19 types of tissues. Furthermore, the framework is less complex compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
计算机助enciaría的数字 histology 中的同时分割和分类问题具有重要的作用，但是它还是一个挑战。最高的二进制和多类 Panoptic Quality (PQ) 仍然为 0.68 bPQ 和 0.49 mPQ，分别。这是因为数字 histology 中的染色变化、组织内部的变化、临床条件不稳定、核体重叠和核类异质性等问题。通常的深度学习方法通常采用端到端模型，而这些模型无法直接解决数字 histology 中的这些问题。在我们之前的工作中，我们已经解决了这些问题，并在 DAN-NucNet 中提出了一种终端模型。这个工作是基于这个模型，并增加了一些额外的解码头，以生成 semantic segmentation、edge proposal 和分类图像。我们使用这些头的输出来进行后处理，以生成最终的分割和分类结果。我们的多阶段方法比较多样化，比如直接分割和分类策略，并且我们展示了一个显著的性能提高。我们在 19 种组织中实现了 0.841 Dice 分割率、0.713 bPQ 分割率和 0.633 mPQ 分类率。我们的提案的框架通过对 19 种组织进行扩展，并且比 state-of-the-art 更加简单。
</details></li>
</ul>
<hr>
<h2 id="A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks"><a href="#A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks" class="headerlink" title="A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks"></a>A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11162">http://arxiv.org/abs/2308.11162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abubakr Shafique, Ricardo Gonzalez, Liron Pantanowitz, Puay Hoon Tan, Alberto Machado, Ian A Cree, Hamid R. Tizhoosh</li>
<li>for: 这种研究旨在使用深度学习技术，对世界卫生组织乳腺癌分类（TCGA数据集）进行分类和检索。</li>
<li>methods: 研究人员使用了一种state-of-the-art的深度学习模型，通过对数百万个诊断 histopathology 图像进行预训练，提取了深度特征来visualize所有 sorts of tumor。</li>
<li>results: 研究人员发现，使用深度学习模型可以准确地检索和匹配罕见的乳腺癌种类，并且可以 investigating complex relationships among common and rare breast lesions。patch similarity search 的准确率达到了88%以上，并且使用 top-n tumor types 的验证率高达91%。<details>
<summary>Abstract</summary>
Breast cancer is one of the most common cancers affecting women worldwide. They include a group of malignant neoplasms with a variety of biological, clinical, and histopathological characteristics. There are more than 35 different histological forms of breast lesions that can be classified and diagnosed histologically according to cell morphology, growth, and architecture patterns. Recently, deep learning, in the field of artificial intelligence, has drawn a lot of attention for the computerized representation of medical images. Searchable digital atlases can provide pathologists with patch matching tools allowing them to search among evidently diagnosed and treated archival cases, a technology that may be regarded as computational second opinion. In this study, we indexed and analyzed the WHO breast taxonomy (Classification of Tumours 5th Ed.) spanning 35 tumour types. We visualized all tumour types using deep features extracted from a state-of-the-art deep learning model, pre-trained on millions of diagnostic histopathology images from the TCGA repository. Furthermore, we test the concept of a digital "atlas" as a reference for search and matching with rare test cases. The patch similarity search within the WHO breast taxonomy data reached over 88% accuracy when validating through "majority vote" and more than 91% accuracy when validating using top-n tumour types. These results show for the first time that complex relationships among common and rare breast lesions can be investigated using an indexed digital archive.
</details>
<details>
<summary>摘要</summary>
乳癌是全球女性中最常见的一种恶性肿瘤，其包括多种生物学、临床和 Histopathological 特征。存在超过35种乳腺病变型，可以根据细胞 morfology、生长和建筑模式进行分类和诊断。最近，人工智能领域的深度学习技术在医学图像计算方面吸引了很多关注，并在计算机化第二次诊断方面发挥了重要作用。在本研究中，我们对WHO乳腺分类（第五版）进行了索引和分析，覆盖了35种肿瘤类型。使用深度学习模型，我们将所有肿瘤类型视觉化，并使用从TCGA数据库中获得的数百万个诊断 histopathology 图像进行预处理。此外，我们测试了一种数字“图鉴”的概念，作为搜索和匹配罕见检测例的参考。在WHO乳腺分类数据集中进行质心 Similarity 搜索可达88%的准确率，并在“主要投票”验证方法下达到91%的准确率。这些结果表明，使用索引数字档案可以Investigate  Complex 乳腺病变之间的关系。
</details></li>
</ul>
<hr>
<h2 id="xxMD-Benchmarking-Neural-Force-Fields-Using-Extended-Dynamics-beyond-Equilibrium"><a href="#xxMD-Benchmarking-Neural-Force-Fields-Using-Extended-Dynamics-beyond-Equilibrium" class="headerlink" title="xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium"></a>xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11155">http://arxiv.org/abs/2308.11155</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zpengmei/xxmd">https://github.com/zpengmei/xxmd</a></li>
<li>paper_authors: Zihan Pengmei, Junyu Liu, Yinan Shu</li>
<li>for: 这个论文旨在探讨神经力场（NFFs）在计算化学中作为参数模型，取代量子化学计算在初始态分子动力学中的地位。</li>
<li>methods: 该论文使用了非对易动力学方法，以获得更加精准的分子动力学数据。</li>
<li>results: 论文发现了MD17数据集的约束分布不足，导致其不适用于描述化学反应中的分子变形。该论文还引入了xxMD数据集，该数据集包括基于多参考波函数理论和density functional theory的能量和力学数据，并且更加 authentically depicts chemical reactions。<details>
<summary>Abstract</summary>
Neural force fields (NFFs) have gained prominence in computational chemistry as surrogate models, superseding quantum-chemistry calculations in ab initio molecular dynamics. The prevalent benchmark for NFFs has been the MD17 dataset and its subsequent extension. These datasets predominantly comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampling from direct adiabatic dynamics. However, many chemical reactions entail significant molecular deformations, notably bond breaking. We demonstrate the constrained distribution of internal coordinates and energies in the MD17 datasets, underscoring their inadequacy for representing systems undergoing chemical reactions. Addressing this sampling limitation, we introduce the xxMD (Extended Excited-state Molecular Dynamics) dataset, derived from non-adiabatic dynamics. This dataset encompasses energies and forces ascertained from both multireference wave function theory and density functional theory. Furthermore, its nuclear configuration spaces authentically depict chemical reactions, making xxMD a more chemically relevant dataset. Our re-assessment of equivariant models on the xxMD datasets reveals notably higher mean absolute errors than those reported for MD17 and its variants. This observation underscores the challenges faced in crafting a generalizable NFF model with extrapolation capability. Our proposed xxMD-CASSCF and xxMD-DFT datasets are available at \url{https://github.com/zpengmei/xxMD}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Mobility-Aware-Computation-Offloading-for-Swarm-Robotics-using-Deep-Reinforcement-Learning"><a href="#Mobility-Aware-Computation-Offloading-for-Swarm-Robotics-using-Deep-Reinforcement-Learning" class="headerlink" title="Mobility-Aware Computation Offloading for Swarm Robotics using Deep Reinforcement Learning"></a>Mobility-Aware Computation Offloading for Swarm Robotics using Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11154">http://arxiv.org/abs/2308.11154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiucheng Wang, Hongzhi Guo</li>
<li>for:  automatize dirty, dangerous, and dull tasks with limited robot resources</li>
<li>methods:  mobile edge computing, mobility-aware deep reinforcement learning model for computing scheduling and resource allocation</li>
<li>results:  meet delay requirements, guarantee computation precision with minimum robot energy<details>
<summary>Abstract</summary>
Swarm robotics is envisioned to automate a large number of dirty, dangerous, and dull tasks. Robots have limited energy, computation capability, and communication resources. Therefore, current swarm robotics have a small number of robots, which can only provide limited spatio-temporal information. In this paper, we propose to leverage the mobile edge computing to alleviate the computation burden. We develop an effective solution based on a mobility-aware deep reinforcement learning model at the edge server side for computing scheduling and resource. Our results show that the proposed approach can meet delay requirements and guarantee computation precision by using minimum robot energy.
</details>
<details>
<summary>摘要</summary>
《群体机器人自动化技术》是旨在自动执行大量污 dirty、危险、无聊任务的。机器人具有有限的能量、计算能力和通信资源，因此当前的群体机器人只有少量机器人，可以提供有限的空间时间信息。在本文中，我们提议利用移动边缘计算来减轻计算负担。我们开发了基于移动性感知深度学习模型的Edge服务器端解决方案，以实现计算调度和资源分配。我们的结果显示，我们的方法可以遵循延迟要求，保证计算精度，并使用最小的机器人能量。
</details></li>
</ul>
<hr>
<h2 id="Energy-Efficient-On-Board-Radio-Resource-Management-for-Satellite-Communications-via-Neuromorphic-Computing"><a href="#Energy-Efficient-On-Board-Radio-Resource-Management-for-Satellite-Communications-via-Neuromorphic-Computing" class="headerlink" title="Energy-Efficient On-Board Radio Resource Management for Satellite Communications via Neuromorphic Computing"></a>Energy-Efficient On-Board Radio Resource Management for Satellite Communications via Neuromorphic Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11152">http://arxiv.org/abs/2308.11152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Flor Ortiz, Nicolas Skatchkovsky, Eva Lagunas, Wallace A. Martins, Geoffrey Eappen, Saed Daoud, Osvaldo Simeone, Bipin Rajendran, Symeon Chatzinotas</li>
<li>for: 本研究旨在应用能效的脑意传播模型来进行卫星通信（SatCom）系统中的无线资源管理。</li>
<li>methods: 本研究使用了复视预测（CNN）和脊搏神经网络（SNN）等机器学习（ML）技术，并进行了软件模拟和实验实践。</li>
<li>results: 比较 Convention CNN 和 SNN 的实验结果显示，在相关的工作负载下，SNN 在 Loihi 2 芯片上实现了更高的准确性，同时降低了电力消耗量超过 100 倍。这些结果显示了脑意 computing 和 SNN 在未来 SatCom 系统中的潜在潜力，并点出了这些技术在支持无线资源管理方面的应用前景。<details>
<summary>Abstract</summary>
The latest satellite communication (SatCom) missions are characterized by a fully reconfigurable on-board software-defined payload, capable of adapting radio resources to the temporal and spatial variations of the system traffic. As pure optimization-based solutions have shown to be computationally tedious and to lack flexibility, machine learning (ML)-based methods have emerged as promising alternatives. We investigate the application of energy-efficient brain-inspired ML models for on-board radio resource management. Apart from software simulation, we report extensive experimental results leveraging the recently released Intel Loihi 2 chip. To benchmark the performance of the proposed model, we implement conventional convolutional neural networks (CNN) on a Xilinx Versal VCK5000, and provide a detailed comparison of accuracy, precision, recall, and energy efficiency for different traffic demands. Most notably, for relevant workloads, spiking neural networks (SNNs) implemented on Loihi 2 yield higher accuracy, while reducing power consumption by more than 100$\times$ as compared to the CNN-based reference platform. Our findings point to the significant potential of neuromorphic computing and SNNs in supporting on-board SatCom operations, paving the way for enhanced efficiency and sustainability in future SatCom systems.
</details>
<details>
<summary>摘要</summary>
最新的卫星通信（SatCom）任务 caracterized by a fully reconfigurable on-board software-defined payload, capable of adapting radio resources to the temporal and spatial variations of the system traffic. As pure optimization-based solutions have shown to be computationally tedious and to lack flexibility, machine learning（ML）based methods have emerged as promising alternatives. We investigate the application of energy-efficient brain-inspired ML models for on-board radio resource management. Apart from software simulation, we report extensive experimental results leveraging the recently released Intel Loihi 2 chip. To benchmark the performance of the proposed model, we implement conventional convolutional neural networks（CNN）on a Xilinx Versal VCK5000, and provide a detailed comparison of accuracy, precision, recall, and energy efficiency for different traffic demands. Most notably, for relevant workloads, spiking neural networks（SNNs）implemented on Loihi 2 yield higher accuracy, while reducing power consumption by more than 100 times as compared to the CNN-based reference platform. Our findings point to the significant potential of neuromorphic computing and SNNs in supporting on-board SatCom operations, paving the way for enhanced efficiency and sustainability in future SatCom systems.
</details></li>
</ul>
<hr>
<h2 id="LLaMA-Reviewer-Advancing-Code-Review-Automation-with-Large-Language-Models-through-Parameter-Efficient-Fine-Tuning-Practical-Experience-Report"><a href="#LLaMA-Reviewer-Advancing-Code-Review-Automation-with-Large-Language-Models-through-Parameter-Efficient-Fine-Tuning-Practical-Experience-Report" class="headerlink" title="LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning (Practical Experience Report)"></a>LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning (Practical Experience Report)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11148">http://arxiv.org/abs/2308.11148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Lu, Lei Yu, Xiaojia Li, Li Yang, Chun Zuo</li>
<li>for:  automatización de tareas de revisión de código</li>
<li>methods:  utilización de modelos de lenguaje grande y técnicas de fine-tuning eficiente de parámetros</li>
<li>results:  iguala el rendimiento de modelos existentes de código de revisión con una base de datos pequeña y limitada cantidad de epochas de entrenamiento<details>
<summary>Abstract</summary>
The automation of code review activities, a long-standing pursuit in software engineering, has been primarily addressed by numerous domain-specific pre-trained models. Despite their success, these models frequently demand extensive resources for pre-training from scratch. In contrast, Large Language Models (LLMs) provide an intriguing alternative, given their remarkable capabilities when supplemented with domain-specific knowledge. However, their potential for automating code review tasks remains largely unexplored.   In response to this research gap, we present LLaMA-Reviewer, an innovative framework that leverages the capabilities of LLaMA, a popular LLM, in the realm of code review. Mindful of resource constraints, this framework employs parameter-efficient fine-tuning (PEFT) methods, delivering high performance while using less than 1% of trainable parameters.   An extensive evaluation of LLaMA-Reviewer is conducted on two diverse, publicly available datasets. Notably, even with the smallest LLaMA base model consisting of 6.7B parameters and a limited number of tuning epochs, LLaMA-Reviewer equals the performance of existing code-review-focused models.   The ablation experiments provide insights into the influence of various fine-tuning process components, including input representation, instruction tuning, and different PEFT methods. To foster continuous progress in this field, the code and all PEFT-weight plugins have been made open-source.
</details>
<details>
<summary>摘要</summary>
自动化代码审查活动，软件工程中长期追求的问题，主要通过许多域специфи的预训模型解决。尽管它们获得了成功，但它们经常需要大量的资源进行预训。相比之下，大型语言模型（LLM）提供了一个吸引人的代替方案，因为它们在域специфи知识的支持下表现出了惊人的能力。然而，它们在代码审查任务上的潜在作用仍然未得到了充分的探索。为了解决这个研究空白，我们介绍了 LLama Reviewer，一个创新的框架，利用 LLama 语言模型在代码审查中的能力。注意资源限制，这个框架使用了 parameter-efficient fine-tuning（PEFT）方法，以提高性能，同时使用的可调参数少于 1%。我们对 LLama Reviewer 进行了广泛的评估，使用了两个公开available的数据集。结果显示，即使使用 LLama 基础模型的最小版本（6.7B参数）和有限制的调教 epoch，LLama Reviewer 与现有的代码审查专注模型表现相同。我们还进行了一系列的减少实验，以了解不同的精细调教过程组件的影响，包括输入表示、指令调教和不同的 PEFT 方法。为了促进这个领域的不断发展，我们将代码和所有 PEFT-weight 插件公开发布。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Unsupervised-Cell-Recognition-with-Prior-Self-activation-Maps"><a href="#Exploring-Unsupervised-Cell-Recognition-with-Prior-Self-activation-Maps" class="headerlink" title="Exploring Unsupervised Cell Recognition with Prior Self-activation Maps"></a>Exploring Unsupervised Cell Recognition with Prior Self-activation Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11144">http://arxiv.org/abs/2308.11144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cpystan/psm">https://github.com/cpystan/psm</a></li>
<li>paper_authors: Pingyi Chen, Chenglu Zhu, Zhongyi Shui, Jiatong Cai, Sunyi Zheng, Shichuan Zhang, Lin Yang</li>
<li>for: 提高cell recognition任务中supervised deep learning模型的成功率，减少标注成本。</li>
<li>methods: 使用自我活化图（PSM）生成 Pseudo 面积标注，通过自动学习训练 activation network 生成 PSM，然后通过semantic clustering模块将 PSM 转换为像素级别的semantic pseudo mask。</li>
<li>results: 在两个 histological 数据集（MoNuSeg 和 BCData）上评估了我们的方法，与其他完全超vised 和弱supervised 方法相比，我们的方法可以实现竞争性的性能，而无需任何手动标注。我们的简单 yet effective 框架还可以实现多类细胞检测，其他无supervised 方法无法完成这一点。结果表明 PSM 的潜在价值，可能会激励其他研究人员在医疗领域尝试解决标注的问题。<details>
<summary>Abstract</summary>
The success of supervised deep learning models on cell recognition tasks relies on detailed annotations. Many previous works have managed to reduce the dependency on labels. However, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. To this end, we explored label-free methods for cell recognition. Prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. To be specific, an activation network is trained with self-supervised learning. The gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. Afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. We evaluated our method on two histological datasets: MoNuSeg (cell segmentation) and BCData (multi-class cell detection). Compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. Our simple but effective framework can also achieve multi-class cell detection which can not be done by existing unsupervised methods. The results show the potential of PSMs that might inspire other research to deal with the hunger for labels in medical area.
</details>
<details>
<summary>摘要</summary>
success of supervised deep learning models on cell recognition tasks rely on detailed annotations. many previous works have managed to reduce the dependency on labels. however, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. to this end, we explored label-free methods for cell recognition. prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. to be specific, an activation network is trained with self-supervised learning. the gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. we evaluated our method on two histological datasets: monunseg (cell segmentation) and bcdata (multi-class cell detection). compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. our simple but effective framework can also achieve multi-class cell detection which can not be done by existing unsupervised methods. the results show the potential of PSMs that might inspire other research to deal with the hunger for labels in medical area.Note that Simplified Chinese is used here, as it is the more commonly used standard for Chinese translation. Traditional Chinese is also an option, but it may be less widely understood by some readers. Let me know if you would like me to translate the text into Traditional Chinese instead.
</details></li>
</ul>
<hr>
<h2 id="Graph-Encoding-and-Neural-Network-Approaches-for-Volleyball-Analytics-From-Game-Outcome-to-Individual-Play-Predictions"><a href="#Graph-Encoding-and-Neural-Network-Approaches-for-Volleyball-Analytics-From-Game-Outcome-to-Individual-Play-Predictions" class="headerlink" title="Graph Encoding and Neural Network Approaches for Volleyball Analytics: From Game Outcome to Individual Play Predictions"></a>Graph Encoding and Neural Network Approaches for Volleyball Analytics: From Game Outcome to Individual Play Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11142">http://arxiv.org/abs/2308.11142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rhys Tracy, Haotian Xia, Alex Rasla, Yuan-Fang Wang, Ambuj Singh</li>
<li>for: 本研究旨在提高复杂排球预测精度，为教练和运动员提供更加有意义的洞察。</li>
<li>methods: 我们引入专门的图编码技术，为已有的排球数据添加了额外的接触接触排球上下文。我们使用图神经网络（GNNs）进行三个不同的排球预测任务：落点预测、场地预测和击球类型预测。</li>
<li>results: 我们的图基模型比基线模型表现更出色，在落点预测、场地预测和击球类型预测等三个任务上显著提高了预测结果。此外，我们还发现了一些简单的调整，如移除封锁的击球，可以显著提高预测结果。最后，我们展示了选择合适的模型结构对于某个任务的预测结果具有重要的作用。总的来说，我们的研究表明使用图编码在运动数据分析中具有极大的潜力，并希望未来的机器学习策略在运动和应用中使用图基编码。<details>
<summary>Abstract</summary>
This research aims to improve the accuracy of complex volleyball predictions and provide more meaningful insights to coaches and players. We introduce a specialized graph encoding technique to add additional contact-by-contact volleyball context to an already available volleyball dataset without any additional data gathering. We demonstrate the potential benefits of using graph neural networks (GNNs) on this enriched dataset for three different volleyball prediction tasks: rally outcome prediction, set location prediction, and hit type prediction. We compare the performance of our graph-based models to baseline models and analyze the results to better understand the underlying relationships in a volleyball rally. Our results show that the use of GNNs with our graph encoding yields a much more advanced analysis of the data, which noticeably improves prediction results overall. We also show that these baseline tasks can be significantly improved with simple adjustments, such as removing blocked hits. Lastly, we demonstrate the importance of choosing a model architecture that will better extract the important information for a certain task. Overall, our study showcases the potential strengths and weaknesses of using graph encodings in sports data analytics and hopefully will inspire future improvements in machine learning strategies across sports and applications by using graphbased encodings.
</details>
<details>
<summary>摘要</summary>
（简化中文）这项研究的目标是提高复杂的排球预测精度并为教练和运动员提供更深刻的意义。我们引入特殊的图编码技术，以添加更多的接触点排球上下文到现有的排球数据集中，而无需收集更多数据。我们示出了使用图神经网络（GNNs）在这种增强的数据集上进行三种不同的排球预测任务：落点预测、场地预测和击打类型预测。我们与基线模型进行比较，分析结果以更好地理解排球落点中的下面关系。我们的结果表明，使用GNNs与我们的图编码可以提供更高级的数据分析，显著提高预测结果总体。我们还示出了可以通过简单的调整，如移除封锁的击球，提高基线任务的性能。最后，我们表明了选择合适的模型结构，可以更好地提取关键信息，以便更好地完成特定任务。总之，我们的研究展示了使用图编码在体育数据分析中的潜在优势和不足，希望能启发未来的机器学习策略的改进，以及在体育和应用程序中使用图基于编码。
</details></li>
</ul>
<hr>
<h2 id="Towards-Validating-Long-Term-User-Feedbacks-in-Interactive-Recommendation-Systems"><a href="#Towards-Validating-Long-Term-User-Feedbacks-in-Interactive-Recommendation-Systems" class="headerlink" title="Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems"></a>Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11137">http://arxiv.org/abs/2308.11137</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Hojoon Lee, Dongyoon Hwang, Kyushik Min, Jaegul Choo</li>
<li>for: 这个论文的目的是为了评估基于奖励学习（RL）的推荐系统在互动过程中的性能。</li>
<li>methods: 论文使用了公共可用的评价数据集来比较和评估不同的算法。</li>
<li>results: 研究发现，简单的资产奖励模型在长期效果方面一直表现出优异，而RL基本模型在评价数据集上表现较差。此外，研究还发现，在评价数据集上，用户的反馈具有较少的长期效果。<details>
<summary>Abstract</summary>
Interactive Recommender Systems (IRSs) have attracted a lot of attention, due to their ability to model interactive processes between users and recommender systems. Numerous approaches have adopted Reinforcement Learning (RL) algorithms, as these can directly maximize users' cumulative rewards. In IRS, researchers commonly utilize publicly available review datasets to compare and evaluate algorithms. However, user feedback provided in public datasets merely includes instant responses (e.g., a rating), with no inclusion of delayed responses (e.g., the dwell time and the lifetime value). Thus, the question remains whether these review datasets are an appropriate choice to evaluate the long-term effects of the IRS. In this work, we revisited experiments on IRS with review datasets and compared RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Following extensive analysis, we can reveal three main findings: First, a simple greedy reward model consistently outperforms RL-based models in maximizing cumulative rewards. Second, applying higher weighting to long-term rewards leads to a degradation of recommendation performance. Third, user feedbacks have mere long-term effects on the benchmark datasets. Based on our findings, we conclude that a dataset has to be carefully verified and that a simple greedy baseline should be included for a proper evaluation of RL-based IRS approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>一个简单的奖励模型在累绩奖励方面一直表现出色，常常高于 RL-based 模型。2. 将更高的权重传递到长期奖励导致推荐性能下降。3. 在评价数据上，用户的反馈仅具有微不足道的长期影响。根据我们的发现，我们结论是，一个数据集需要仔细验证，而且一个简单的奖励基准应该包括在评估 RL-based IRS 方法的评估中。</details></li>
</ol>
<hr>
<h2 id="Transformers-for-Capturing-Multi-level-Graph-Structure-using-Hierarchical-Distances"><a href="#Transformers-for-Capturing-Multi-level-Graph-Structure-using-Hierarchical-Distances" class="headerlink" title="Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances"></a>Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11129">http://arxiv.org/abs/2308.11129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuankai Luo</li>
<li>for: 本研究旨在提高现有图Transformer的表现，通过设计一种基于层次距离的结构编码方法（HDSE），以适应不同类型的图像处理任务。</li>
<li>methods: 本研究使用的方法包括HDSE方法和现有的位置表示方法的综合应用，以捕捉图像中的多层次、层次结构。</li>
<li>results: 经过广泛的实验 validate，HDSE方法能够在12种实际 dataset上提高多种基eline transformer的表现，达到了10个benchmark dataset的状态时表现。<details>
<summary>Abstract</summary>
Graph transformers need strong inductive biases to derive meaningful attention scores. Yet, current proposals rarely address methods capturing longer ranges, hierarchical structures, or community structures, as they appear in various graphs such as molecules, social networks, and citation networks. In this paper, we propose a hierarchy-distance structural encoding (HDSE), which models a hierarchical distance between the nodes in a graph focusing on its multi-level, hierarchical nature. In particular, this yields a framework which can be flexibly integrated with existing graph transformers, allowing for simultaneous application with other positional representations. Through extensive experiments on 12 real-world datasets, we demonstrate that our HDSE method successfully enhances various types of baseline transformers, achieving state-of-the-art empirical performances on 10 benchmark datasets.
</details>
<details>
<summary>摘要</summary>
图形转换器需要强大的推导性偏好，以获得有意义的注意分数。然而，当前的建议通常不会考虑 capture longer ranges, hierarchical structures 或 community structures, 这些结构在分子、社交网络和引用网络等图形中都存在。在这篇论文中，我们提出了一种层次距离结构编码（HDSE），它模型了图形中节点之间的层次距离，特别是这些距离的多层、层次结构。因此，我们的 HDSE 方法可以与现有的图形转换器集成，以同时应用其他位置表示。通过对 12 个真实世界数据集进行了广泛的实验，我们示出了 HDSE 方法可以成功地提高多种基eline transformers，在 10 个标准测试集上达到了最佳的实验性能。
</details></li>
</ul>
<hr>
<h2 id="How-Expressive-are-Graph-Neural-Networks-in-Recommendation"><a href="#How-Expressive-are-Graph-Neural-Networks-in-Recommendation" class="headerlink" title="How Expressive are Graph Neural Networks in Recommendation?"></a>How Expressive are Graph Neural Networks in Recommendation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11127">http://arxiv.org/abs/2308.11127</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkuds/gte">https://github.com/hkuds/gte</a></li>
<li>paper_authors: Xuheng Cai, Lianghao Xia, Xubin Ren, Chao Huang</li>
<li>for: 这篇论文主要针对推荐问题的Graph Neural Networks（GNNs）表现能力进行了系统的理论分析，以强化GNNs在推荐 task中的表现。</li>
<li>methods: 该论文使用了三种表达能力指标：图同构（graph-level）、节点自同构（node-level）和结构靠近性（link-level），其中结构靠近性指标是专门为推荐任务设计的，能够评估GNNs在推荐任务中表现的准确性。</li>
<li>results: 该论文通过对多种现有GNN模型进行比较，证明了结构靠近性指标在评估GNNs在推荐任务中表现的效果。此外，该论文还提出了一种学习无关的GNN算法，可以在结构靠近性指标下达到优化的表现。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have demonstrated superior performance on various graph learning tasks, including recommendation, where they leverage user-item collaborative filtering signals in graphs. However, theoretical formulations of their capability are scarce, despite their empirical effectiveness in state-of-the-art recommender models. Recently, research has explored the expressiveness of GNNs in general, demonstrating that message passing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that GNNs combined with random node initialization are universal. Nevertheless, the concept of "expressiveness" for GNNs remains vaguely defined. Most existing works adopt the graph isomorphism test as the metric of expressiveness, but this graph-level task may not effectively assess a model's ability in recommendation, where the objective is to distinguish nodes of different closeness. In this paper, we provide a comprehensive theoretical analysis of the expressiveness of GNNs in recommendation, considering three levels of expressiveness metrics: graph isomorphism (graph-level), node automorphism (node-level), and topological closeness (link-level). We propose the topological closeness metric to evaluate GNNs' ability to capture the structural distance between nodes, which aligns closely with the objective of recommendation. To validate the effectiveness of this new metric in evaluating recommendation performance, we introduce a learning-less GNN algorithm that is optimal on the new metric and can be optimal on the node-level metric with suitable modification. We conduct extensive experiments comparing the proposed algorithm against various types of state-of-the-art GNN models to explore the explainability of the new metric in the recommendation task. For reproducibility, implementation codes are available at https://github.com/HKUDS/GTE.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 已经在不同的图学任务上展现出优秀的性能，包括推荐，其中利用用户Item的协同过滤信号在图中。然而，GNNs的理论表述还很缺乏，尽管它们在现有的推荐模型中的实际效果很高。最近，研究人员开始探索GNNs的表达能力，并证明了消息传递GNNs在最多情况下与维氏-莱曼测试相当强大，并且GNNs与随机节点初始化结合起来是 universally expressive。然而，GNNs的“表达能力”概念仍然很模糊。大多数现有的工作采用图 isomorphism test作为表达能力的度量，但这可能不能有效地评估一个模型在推荐任务中的能力，因为推荐任务的目标是将节点分类为不同的靠近程度。在这篇论文中，我们提供了对GNNs在推荐任务中表达能力的全面性分析，包括图 isomorphism（图级），节点自身omorphism（节点级）和 topological closeness（链级）三种表达能力度量。我们提出了 topological closeness 度量，以评估 GNNs 在不同节点之间的结构距离，这与推荐任务的目标很 closely align。为验证这个新的度量在推荐任务中的效用，我们引入了一种不含学习的 GNN 算法，该算法在新的度量上是优化的，并且可以通过修改来在节点级度量上达到优化。我们对多种现有的 state-of-the-art GNN 模型进行了广泛的比较，以探索这个新的度量在推荐任务中的解释性。为保持可重现性，我们在 GitHub 上提供了实现代码，可以在 https://github.com/HKUDS/GTE 中找到。
</details></li>
</ul>
<hr>
<h2 id="Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection"><a href="#Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection" class="headerlink" title="Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection"></a>Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11119">http://arxiv.org/abs/2308.11119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Tamura</li>
<li>for: 这个研究是为了开发一个基于 CLIP 的零数据Point Anomaly Detection 方法。</li>
<li>methods: 这个方法使用 CLIP 的显示语言模型来生成图像中的文本嵌入，并使用这些嵌入进行类别。</li>
<li>results: 实验结果显示，这个方法可以在零数据情况下 дости持state-of-the-art表现，并且不需要传入任何训练图像。<details>
<summary>Abstract</summary>
This paper presents a novel method that leverages a visual-language model, CLIP, as a data source for zero-shot anomaly detection. Tremendous efforts have been put towards developing anomaly detectors due to their potential industrial applications. Considering the difficulty in acquiring various anomalous samples for training, most existing methods train models with only normal samples and measure discrepancies from the distribution of normal samples during inference, which requires training a model for each object category. The problem of this inefficient training requirement has been tackled by designing a CLIP-based anomaly detector that applies prompt-guided classification to each part of an image in a sliding window manner. However, the method still suffers from the labor of careful prompt ensembling with known object categories. To overcome the issues above, we propose leveraging CLIP as a data source for training. Our method generates text embeddings with the text encoder in CLIP with typical prompts that include words of normal and anomaly. In addition to these words, we insert several randomly generated words into prompts, which enables the encoder to generate a diverse set of normal and anomalous samples. Using the generated embeddings as training data, a feed-forward neural network learns to extract features of normal and anomaly from CLIP's embeddings, and as a result, a category-agnostic anomaly detector can be obtained without any training images. Experimental results demonstrate that our method achieves state-of-the-art performance without laborious prompt ensembling in zero-shot setups.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文提出了一种新的方法，利用视觉语言模型CLIP作为数据源，实现零例异常检测。因为异常样本很难获得，现有的方法通常只使用正常样本进行训练，并在推理时对正常样本的分布进行评估，这需要对每个物体类型进行训练。这种不fficient的训练方式被解决了，通过使用CLIP中的提示引导分类来对每个图像中的每个部分进行滑动窗口 manner进行异常检测。然而，这种方法仍然受到提示的精心组合的压力。为了解决以上问题，我们提议利用CLIP作为训练数据源。我们的方法生成了文本嵌入，使用CLIP中的文本编码器，并使用典型的提示，包括正常和异常的词语。此外，我们还在提示中插入了一些随机生成的词语，使编码器生成的嵌入集是多样的正常和异常样本。使用生成的嵌入作为训练数据，一个卷积神经网络学习提取CLIP的嵌入中的正常和异常特征，从而实现了没有任何训练图像的类型无关异常检测器。实验结果表明，我们的方法在零例设置下达到了状态的艺术性表现，无需劳累的提示组合。
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models"><a href="#Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models" class="headerlink" title="Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models"></a>Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11112">http://arxiv.org/abs/2308.11112</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hajimesuzuki999/qpf">https://github.com/hajimesuzuki999/qpf</a></li>
<li>paper_authors: Farina Riaz, Shahab Abdulla, Hajime Suzuki, Srinjoy Ganguly, Ravinesh C. Deo, Susan Hopkins</li>
<li>for: 提高图像分类模型的准确率</li>
<li>methods: 使用量子预处理筛选器（QPF），应用于图像分类模型中</li>
<li>results: 对于MNIST和EMNIST dataset，使用QPF提高了图像分类精度，从92.5%提高到95.4%和从68.9%提高到75.9%，而不需要额外的模型参数或优化。但是在GTSRB dataset上，使用QPF显示了一个较大的下降。<details>
<summary>Abstract</summary>
This paper proposes a novel quantum pre-processing filter (QPF) to improve the image classification accuracy of neural network (NN) models. A simple four qubit quantum circuit that uses Y rotation gates for encoding and two controlled NOT gates for creating correlation among the qubits is applied as a feature extraction filter prior to passing data into the fully connected NN architecture. By applying the QPF approach, the results show that the image classification accuracy based on the MNIST (handwritten 10 digits) and the EMNIST (handwritten 47 class digits and letters) datasets can be improved, from 92.5% to 95.4% and from 68.9% to 75.9%, respectively. These improvements were obtained without introducing extra model parameters or optimizations in the machine learning process. However, tests performed on the developed QPF approach against a relatively complex GTSRB dataset with 43 distinct class real-life traffic sign images showed a degradation in the classification accuracy. Considering this result, further research into the understanding and the design of a more suitable quantum circuit approach for image classification neural networks could be explored utilizing the baseline method proposed in this paper.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CAME-Contrastive-Automated-Model-Evaluation"><a href="#CAME-Contrastive-Automated-Model-Evaluation" class="headerlink" title="CAME: Contrastive Automated Model Evaluation"></a>CAME: Contrastive Automated Model Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11111">http://arxiv.org/abs/2308.11111</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pengr/contrastive_autoeval">https://github.com/pengr/contrastive_autoeval</a></li>
<li>paper_authors: Ru Peng, Qiuyang Duan, Haobo Wang, Jiachen Ma, Yanbo Jiang, Yongjun Tu, Xiu Jiang, Junbo Zhao</li>
<li>for: 评估已经训练的机器学习模型的性能，无需使用标注的测试集。</li>
<li>methods: 提出了一种新的自动评估框架，即对比自动评估（CAME），不再需要使用训练集。基于理论分析和广泛的实验验证，CAME可以在无标注测试集的情况下建立模型性能和对比损失之间的可预测关系。</li>
<li>results: CAME在自动评估领域的新标准时间（SOTA）Result，舒过先前的工作。<details>
<summary>Abstract</summary>
The Automated Model Evaluation (AutoEval) framework entertains the possibility of evaluating a trained machine learning model without resorting to a labeled testing set. Despite the promise and some decent results, the existing AutoEval methods heavily rely on computing distribution shifts between the unlabelled testing set and the training set. We believe this reliance on the training set becomes another obstacle in shipping this technology to real-world ML development. In this work, we propose Contrastive Automatic Model Evaluation (CAME), a novel AutoEval framework that is rid of involving training set in the loop. The core idea of CAME bases on a theoretical analysis which bonds the model performance with a contrastive loss. Further, with extensive empirical validation, we manage to set up a predictable relationship between the two, simply by deducing on the unlabeled/unseen testing set. The resulting framework CAME establishes a new SOTA results for AutoEval by surpassing prior work significantly.
</details>
<details>
<summary>摘要</summary>
自动模型评估（AutoEval）框架考虑不使用标注测试集来评估训练完成的机器学习模型。尽管存在承诺和一些不错的结果，现有的AutoEval方法仍然很重要地依赖于计算测试集和训练集之间的分布差异。我们认为，这种依赖于训练集会成为实际机器学习开发中这种技术的又一个障碍。在这种工作中，我们提出了对比自动模型评估（CAME）框架，它不再依赖于训练集。CAME框架的核心思想是基于一种理论分析，它将模型性能与对比损失相关联。然后，通过广泛的实验验证，我们成功地建立了测试集中未经标注的模型性能和对比损失之间的可预测关系。这种关系的建立使得CAME框架可以超越现有的AutoEval方法，并设置新的最高纪录（SOTA）。
</details></li>
</ul>
<hr>
<h2 id="Anonymity-at-Risk-Assessing-Re-Identification-Capabilities-of-Large-Language-Models"><a href="#Anonymity-at-Risk-Assessing-Re-Identification-Capabilities-of-Large-Language-Models" class="headerlink" title="Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models"></a>Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11103">http://arxiv.org/abs/2308.11103</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models">https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models</a></li>
<li>paper_authors: Alex Nyffenegger, Matthias Stürmer, Joel Niklaus</li>
<li>for:  This paper aims to explore the potential of large language models (LLMs) to re-identify individuals in court rulings, with a focus on the Federal Supreme Court of Switzerland.</li>
<li>methods:  The authors constructed a proof-of-concept using actual legal data from the Swiss federal supreme court and an anonymized Wikipedia dataset to investigate the feasibility of re-identifying individuals using LLMs. They introduced new metrics to measure performance and systematically analyzed the factors that influence successful re-identifications.</li>
<li>results:  Despite high re-identification rates on Wikipedia, the authors found that even the best LLMs struggled with court decisions, attributed to the lack of test datasets, the necessity for substantial training resources, and data sparsity in the information used for re-identification. The study demonstrates that re-identification using LLMs may not be feasible for now, but it might become possible in the future.<details>
<summary>Abstract</summary>
Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland. With the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland, we explore the potential of LLMs to re-identify individuals in court rulings by constructing a proof-of-concept using actual legal data from the Swiss federal supreme court. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. With the introduction and application of the new task of re-identifying people in texts, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on Wikipedia, even the best LLMs struggled with court decisions. The complexity is attributed to the lack of test datasets, the necessity for substantial training resources, and data sparsity in the information used for re-identification. In conclusion, this study demonstrates that re-identification using LLMs may not be feasible for now, but as the proof-of-concept on Wikipedia showed, it might become possible in the future. We hope that our system can help enhance the confidence in the security of anonymized decisions, thus leading to the courts being more confident to publish decisions.
</details>
<details>
<summary>摘要</summary>
欧盟和瑞士的法院判决中的自然人和法人匿名性是隐私保护的关键方面。随着LLM的出现，大规模重新标识匿名人士的问题减少。根据瑞士联邦最高法院的规定，我们在实际的法院判决数据上进行了证明。然后，我们使用了一个更加严格的Wikipedia数据集进行进一步的研究。我们将重新标识文本中的人员为新任务，并引入了新的评价指标。我们系统地分析了重要因素的影响，包括模型大小、输入长度和调整指南。尽管在Wikipedia上达到了高重新标识率，但是even the best LLMs在法院判决上遇到了困难。这种复杂性归结于缺乏测试集，需要巨量的训练资源以及重要的数据稀缺。因此，本研究表明，使用LLM重新标识可能不可能现在，但是在未来可能变得可能。我们希望通过我们的系统，增强对匿名判决的信任，使法院更自信地发布判决。
</details></li>
</ul>
<hr>
<h2 id="Explicability-and-Inexplicability-in-the-Interpretation-of-Quantum-Neural-Networks"><a href="#Explicability-and-Inexplicability-in-the-Interpretation-of-Quantum-Neural-Networks" class="headerlink" title="Explicability and Inexplicability in the Interpretation of Quantum Neural Networks"></a>Explicability and Inexplicability in the Interpretation of Quantum Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11098">http://arxiv.org/abs/2308.11098</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lirandepira/interpret-qnn">https://github.com/lirandepira/interpret-qnn</a></li>
<li>paper_authors: Lirandë Pira, Chris Ferrie</li>
<li>for: 本研究旨在探讨量子神经网络的解释性，以帮助建立可信任的量子AI系统。</li>
<li>methods: 本研究使用了本地模型无关解释性度量来研究量子和类传统神经网络的解释性。它还 introduce了带宽不可解释区（band of inexplicability），表示无法解释的数据样本。</li>
<li>results: 研究发现，量子神经网络的解释性与其数据采样方式有关，并且存在一个带宽不可解释区，表示无法解释的数据样本。这些结果为建立负责任和可负责的量子AI模型提供了一个重要的基础。<details>
<summary>Abstract</summary>
Interpretability of artificial intelligence (AI) methods, particularly deep neural networks, is of great interest due to the widespread use of AI-backed systems, which often have unexplainable behavior. The interpretability of such models is a crucial component of building trusted systems. Many methods exist to approach this problem, but they do not obviously generalize to the quantum setting. Here we explore the interpretability of quantum neural networks using local model-agnostic interpretability measures of quantum and classical neural networks. We introduce the concept of the band of inexplicability, representing the interpretable region in which data samples have no explanation, likely victims of inherently random quantum measurements. We see this as a step toward understanding how to build responsible and accountable quantum AI models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对人工智能（AI）技术的可解释性（Interpretability）是非常关键的，因为AI支持的系统在使用中经常表现出不可解释的行为。这种可解释性是建立可信系统的重要组成部分。虽然有很多方法可以解决这个问题，但它们不显而易懂地推广到量子设置下。在这里，我们研究了量子神经网络的可解释性，使用本地模型无关的解释度量来评估量子和经典神经网络的可解释性。我们称之为“不可解释的带”（band of inexplicability），表示无法解释的数据样本的解释不可能， probable victims of inherently random quantum measurements。我们认为这是一步向于理解如何构建负责任和可负责的量子AI模型。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Video-OWL-ViT-Temporally-consistent-open-world-localization-in-video"><a href="#Video-OWL-ViT-Temporally-consistent-open-world-localization-in-video" class="headerlink" title="Video OWL-ViT: Temporally-consistent open-world localization in video"></a>Video OWL-ViT: Temporally-consistent open-world localization in video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11093">http://arxiv.org/abs/2308.11093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Heigold, Matthias Minderer, Alexey Gritsenko, Alex Bewley, Daniel Keysers, Mario Lučić, Fisher Yu, Thomas Kipf</li>
<li>for: 本文采用预训练的开放世界图像模型进行视频地标定。</li>
<li>methods: 本文使用了对大量图像文本数据进行对比预训练，然后将该模型应用到视频地标定任务上，并添加了一个变换器解码器来在视频帧中传播物体表示。</li>
<li>results: 本文在TAO-OW标准测试集上展示了对开放世界地标定任务的成功转移，而且与基于检测的跟踪基eline相比，本文的模型具有更好的时间一致性。<details>
<summary>Abstract</summary>
We present an architecture and a training recipe that adapts pre-trained open-world image models to localization in videos. Understanding the open visual world (without being constrained by fixed label spaces) is crucial for many real-world vision tasks. Contrastive pre-training on large image-text datasets has recently led to significant improvements for image-level tasks. For more structured tasks involving object localization applying pre-trained models is more challenging. This is particularly true for video tasks, where task-specific data is limited. We show successful transfer of open-world models by building on the OWL-ViT open-vocabulary detection model and adapting it to video by adding a transformer decoder. The decoder propagates object representations recurrently through time by using the output tokens for one frame as the object queries for the next. Our model is end-to-end trainable on video data and enjoys improved temporal consistency compared to tracking-by-detection baselines, while retaining the open-world capabilities of the backbone detector. We evaluate our model on the challenging TAO-OW benchmark and demonstrate that open-world capabilities, learned from large-scale image-text pre-training, can be transferred successfully to open-world localization across diverse videos.
</details>
<details>
<summary>摘要</summary>
我们提出了一种体系和训练方法，可以将预训练的开放世界图像模型适应到视频本地化。理解开放视觉世界（不受固定标签空间的限制）对实际视觉任务非常重要。最近，对大量图像文本数据进行对比预训练已经导致了图像级任务的显著改进。但是，对于结构化任务，如对象本地化，使用预训练模型更加具有挑战性。特别是在视频任务中，任务特有的数据受限。我们构建了基于 OWL-ViT 开放 vocabulary 检测模型，并将其适应到视频中。将输出 токен用于下一帧的对象查询。我们的模型是可以综合训练在视频数据上，并且具有更好的时间一致性，与racking-by-detection 基elines相比，保留了预训练模型的开放世界能力。我们在 TAO-OW 测试准则上评估了我们的模型，并证明了预训练的开放世界能力可以成功地传递到多种视频中的开放本地化。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport"><a href="#Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport" class="headerlink" title="Addressing Fairness and Explainability in Image Classification Using Optimal Transport"></a>Addressing Fairness and Explainability in Image Classification Using Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11090">http://arxiv.org/abs/2308.11090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Ratz, François Hu, Arthur Charpentier</li>
<li>for: 本研究旨在提高人工智能系统的可靠性和负责任性，通过推导对不公平结果的解释来建立信任和负责任。</li>
<li>methods: 本研究提出了一种完整的方法，利用最优运输理论来探索图像中偏见的原因和影响，这种方法可以轻松扩展到表格数据上。</li>
<li>results: 研究发现，通过使用沃氏矩阵中心来获得不受敏感变量影响的分数，同时保持分数的排序结果，可以帮助找出偏见的主要来源和影响。这些发现有助于构建可靠、公平和透明的人工智能系统，在医疗和巡捕等领域中应用。<details>
<summary>Abstract</summary>
Algorithmic Fairness and the explainability of potentially unfair outcomes are crucial for establishing trust and accountability of Artificial Intelligence systems in domains such as healthcare and policing. Though significant advances have been made in each of the fields separately, achieving explainability in fairness applications remains challenging, particularly so in domains where deep neural networks are used. At the same time, ethical data-mining has become ever more relevant, as it has been shown countless times that fairness-unaware algorithms result in biased outcomes. Current approaches focus on mitigating biases in the outcomes of the model, but few attempts have been made to try to explain \emph{why} a model is biased. To bridge this gap, we propose a comprehensive approach that leverages optimal transport theory to uncover the causes and implications of biased regions in images, which easily extends to tabular data as well. Through the use of Wasserstein barycenters, we obtain scores that are independent of a sensitive variable but keep their marginal orderings. This step ensures predictive accuracy but also helps us to recover the regions most associated with the generation of the biases. Our findings hold significant implications for the development of trustworthy and unbiased AI systems, fostering transparency, accountability, and fairness in critical decision-making scenarios across diverse domains.
</details>
<details>
<summary>摘要</summary>
算法公正和可解释性是在医疗和警察等领域建立人工智能系统的信任和负责任的关键因素。虽然在每个领域 separately 有所进步，但在公正性应用中保持可解释性仍然是挑战，特别是在使用深度神经网络时。同时，伦理数据挖掘已经变得更加重要，因为不公正的算法结果常常导致偏见。现有的方法主要是为了减轻模型的偏见结果，但很少人尝试解释为何模型偏见。为了bridging这个差距，我们提出了一种全面的方法，利用最优运输理论来揭示偏见区域在图像中的原因和后果，这种方法也可以轻松扩展到表格数据。通过使用沃asserstein矩阵，我们可以获得不同敏感变量之间的相对排名，这步确保预测精度，同时帮助我们回溯偏见的生成原因。我们的发现对于开发可靠、不偏见的人工智能系统产生了重要的影响，推动了透明度、负责任和公正在多个领域中的决策过程中的发展。
</details></li>
</ul>
<hr>
<h2 id="Stress-representations-for-tensor-basis-neural-networks-alternative-formulations-to-Finger-Rivlin-Ericksen"><a href="#Stress-representations-for-tensor-basis-neural-networks-alternative-formulations-to-Finger-Rivlin-Ericksen" class="headerlink" title="Stress representations for tensor basis neural networks: alternative formulations to Finger-Rivlin-Ericksen"></a>Stress representations for tensor basis neural networks: alternative formulations to Finger-Rivlin-Ericksen</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11080">http://arxiv.org/abs/2308.11080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan N. Fuhg, Nikolaos Bouklas, Reese E. Jones</li>
<li>For: This paper focuses on developing and comparing different neural network models for modeling hyperelastic materials in a finite deformation context.* Methods: The paper uses a variety of tensor basis neural network models, including some unexplored formulations, and compares their performance against noisy and noiseless datasets for three different materials. The paper also examines the effectiveness of potential-based and coefficient-based approaches, as well as different calibration techniques.* Results: The paper provides theoretical and practical insights into the performance of each formulation, and compares the results of the nine variants tested.<details>
<summary>Abstract</summary>
Data-driven constitutive modeling frameworks based on neural networks and classical representation theorems have recently gained considerable attention due to their ability to easily incorporate constitutive constraints and their excellent generalization performance. In these models, the stress prediction follows from a linear combination of invariant-dependent coefficient functions and known tensor basis generators. However, thus far the formulations have been limited to stress representations based on the classical Rivlin and Ericksen form, while the performance of alternative representations has yet to be investigated. In this work, we survey a variety of tensor basis neural network models for modeling hyperelastic materials in a finite deformation context, including a number of so far unexplored formulations which use theoretically equivalent invariants and generators to Finger-Rivlin-Ericksen. Furthermore, we compare potential-based and coefficient-based approaches, as well as different calibration techniques. Nine variants are tested against both noisy and noiseless datasets for three different materials. Theoretical and practical insights into the performance of each formulation are given.
</details>
<details>
<summary>摘要</summary>
“数据驱动的构成模型框架，基于神经网络和经典表述定理，在最近受到了广泛关注，因为它们可以轻松地包含构成约束和优秀的泛化性能。在这些模型中，压力预测来自于线性组合的不变 coefficient 函数和已知的张量基 generator。然而，至今为止，这些形ulation 仅限于压力表示基于经典的 Rivlin 和 Eriksson 形式，尚未探讨其他表示形式的性能。在这种工作中，我们检验了一种多种张量基神经网络模型，用于模型弹性材料在有限减形上，包括一些尚未探讨的形式，它们使用了同等的 invariants 和生成器来 Finger-Rivlin-Eriksson。此外，我们比较了 potential-based 和 coefficient-based 方法，以及不同的 calibration 技术。 nine 个变体被测试在三种不同材料上，对于噪声和噪声无的数据集。我们提供了理论和实践的深入分析每种形式的性能。”Note: Simplified Chinese is used in this translation, which is a simplified version of Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors"><a href="#Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors" class="headerlink" title="Long-Term Prediction of Natural Video Sequences with Robust Video Predictors"></a>Long-Term Prediction of Natural Video Sequences with Robust Video Predictors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11079">http://arxiv.org/abs/2308.11079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 预测高维度视频序列是一个具有挑战性的问题，由于未知性的增加，预测范围越长，难度也越大。本文提出了一些改进方案来创建Robust Video Predictors（RoViPs），以提高短期预测质量。</li>
<li>methods: 本文使用深度Perceptual和不确定性基于的重建损失，以及注意力机制 skip 连接，以提高输入特征的长距离空间移动性。</li>
<li>results: 本文表明，通过使用这些改进方案，可以创建高质量的短期预测，并且可以通过迭代单步预测任务，生成非常长的自然视频序列。<details>
<summary>Abstract</summary>
Predicting high dimensional video sequences is a curiously difficult problem. The number of possible futures for a given video sequence grows exponentially over time due to uncertainty. This is especially evident when trying to predict complicated natural video scenes from a limited snapshot of the world. The inherent uncertainty accumulates the further into the future you predict making long-term prediction very difficult. In this work we introduce a number of improvements to existing work that aid in creating Robust Video Predictors (RoViPs). We show that with a combination of deep Perceptual and uncertainty-based reconstruction losses we are able to create high quality short-term predictions. Attention-based skip connections are utilised to allow for long range spatial movement of input features to further improve performance. Finally, we show that by simply making the predictor robust to its own prediction errors, it is possible to produce very long, realistic natural video sequences using an iterated single-step prediction task.
</details>
<details>
<summary>摘要</summary>
“预测高维视频序列是一个奇怪地困难的问题。视频序列中可能的未来数量因时间不确定性而呈指数增长。特别是当试图从有限的世界快照中预测自然的视频场景时，这种不确定性会更加突出。在这种情况下，我们介绍了一些改进现有工作的方法，以创建robust Video Predictors（RoViPs）。我们表明，通过深度感知和不确定性基于的重建损失，可以创造高质量短期预测。增强功能skip连接使得输入特征可以在较长距离上进行空间运动，进一步改善性能。最后，我们表明，只需要让预测器具有自己预测错误的抗性，就可以使用迭代单步预测任务生成非常长、自然的视频序列。”Note that Simplified Chinese is a standardized form of Chinese that is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and other parts of the world. The translation may vary slightly depending on the specific dialect or variation of Chinese that is used.
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Dive-into-the-Connections-Between-the-Renormalization-Group-and-Deep-Learning-in-the-Ising-Model"><a href="#A-Deep-Dive-into-the-Connections-Between-the-Renormalization-Group-and-Deep-Learning-in-the-Ising-Model" class="headerlink" title="A Deep Dive into the Connections Between the Renormalization Group and Deep Learning in the Ising Model"></a>A Deep Dive into the Connections Between the Renormalization Group and Deep Learning in the Ising Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11075">http://arxiv.org/abs/2308.11075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kelsie Taylor</li>
<li>for: 这个论文是关于物理理论和量子场论中的粒子规范群（RG）技术，以及深度学习（Deep Learning）的相互关系。</li>
<li>methods: 作者使用了Restricted Boltzmann Machines（RBMs）来实现深度学习，并对2D最近邻Iseng模型进行了Kadanoff块 renormalization。作者还开发了1D和2D Ising模型的扩展renormalization技术作为比较基准。</li>
<li>results: 作者成功地使用了Adam优化器和相关长度损失函数来学习群流，并对1D Ising模型获得了与分析模型相符的结果。作者还使用了Wolff算法生成了Iseng模型样本，并使用了 quasi-deterministic方法进行了群流。最后，作者发现了RBM学习层次结构与RG块化结构之间的相似性。<details>
<summary>Abstract</summary>
The renormalization group (RG) is an essential technique in statistical physics and quantum field theory, which considers scale-invariant properties of physical theories and how these theories' parameters change with scaling. Deep learning is a powerful computational technique that uses multi-layered neural networks to solve a myriad of complicated problems. Previous research suggests the possibility that unsupervised deep learning may be a form of RG flow, by being a layer-by-layer coarse graining of the original data. We examined this connection on a more rigorous basis for the simple example of Kadanoff block renormalization of the 2D nearest-neighbor Ising model, with our deep learning accomplished via Restricted Boltzmann Machines (RBMs). We developed extensive renormalization techniques for the 1D and 2D Ising model to provide a baseline for comparison. For the 1D Ising model, we successfully used Adam optimization on a correlation length loss function to learn the group flow, yielding results consistent with the analytical model for infinite N. For the 2D Ising model, we successfully generated Ising model samples using the Wolff algorithm, and performed the group flow using a quasi-deterministic method, validating these results by calculating the critical exponent \nu. We then examined RBM learning of the Ising model layer by layer, finding a blocking structure in the learning that is qualitatively similar to RG. Lastly, we directly compared the weights of each layer from the learning to Ising spin renormalization, but found quantitative inconsistencies for the simple case of nearest-neighbor Ising models.
</details>
<details>
<summary>摘要</summary>
“ renormalization group（RG）是物理学和量子场论中的一种重要技术，它考虑物理理论中尺度不变性的性质和尺度下降参数的变化。深度学习是一种强大的计算技术，使用多层神经网络解决各种复杂问题。以前的研究表明，无监督深度学习可能是一种RG流，通过层次归约原始数据来实现。我们在2D nearest-neighbor Ising模型中进行了更加严谨的研究，我们使用Restricted Boltzmann Machines（RBMs）来实现深度学习。我们为1D和2D Ising模型开发了广泛的renoormalization技术，以提供比较基eline。对1D Ising模型，我们使用Adam优化器和尺度长度损失函数来学习群流，得到了与分析模型的一致 результа。对2D Ising模型，我们使用Wolff算法生成样本，并使用一种 quasi-deterministic 方法来实现群流，并计算了扩散率 \nu。然后，我们对 Ising 模型层次进行了 RBM 学习，发现了一种块结构，与RG有趋同性。最后，我们直接比较了各层 weights 的学习结果和 Ising 磁力 renormalization，发现了简单 nearest-neighbor Ising 模型中的量化不一致。”
</details></li>
</ul>
<hr>
<h2 id="Neural-Amortized-Inference-for-Nested-Multi-agent-Reasoning"><a href="#Neural-Amortized-Inference-for-Nested-Multi-agent-Reasoning" class="headerlink" title="Neural Amortized Inference for Nested Multi-agent Reasoning"></a>Neural Amortized Inference for Nested Multi-agent Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11071">http://arxiv.org/abs/2308.11071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunal Jha, Tuan Anh Le, Chuanyang Jin, Yen-Ling Kuo, Joshua B. Tenenbaum, Tianmin Shu</li>
<li>for: 本研究旨在提高多代理交互中的社会推理能力，以便更好地模拟人类的社会听说和推理能力。</li>
<li>methods: 本研究使用神经网络来快速化高阶社会推理，以便在多代理交互中提高推理效率。</li>
<li>results: 实验结果显示，使用神经网络可以减少计算复杂性，同时保持准确性。<details>
<summary>Abstract</summary>
Multi-agent interactions, such as communication, teaching, and bluffing, often rely on higher-order social inference, i.e., understanding how others infer oneself. Such intricate reasoning can be effectively modeled through nested multi-agent reasoning. Nonetheless, the computational complexity escalates exponentially with each level of reasoning, posing a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy.
</details>
<details>
<summary>摘要</summary>
多智能机器人之间的交互，如 коммуника、教学和谎言，frequently rely on高级社会推理，即理解他们如何推理自己。这种复杂的推理可以通过嵌入式多智能推理模型来有效地模拟。然而，计算复杂性随着每级别推理的层次层次增加， pose a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Topological-Graph-Signal-Compression"><a href="#Topological-Graph-Signal-Compression" class="headerlink" title="Topological Graph Signal Compression"></a>Topological Graph Signal Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11068">http://arxiv.org/abs/2308.11068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, Lev Telyatnikov, Eduard Alarcón, Albert Cabellos-Aparicio, Pere Barlet-Ros, Pietro Liò</li>
<li>for: 提出了一种基于Topological Deep Learning（TDL）方法的信号压缩方法，用于处理图structured数据。</li>
<li>methods: 方法包括两个主要步骤：首先，基于原始信号，使用 clustering 将 $N$ 个数据点分为 $K\ll N$ 个多元素集合；然后，使用 topological-inspired message passing 获取这些多元素集合中的压缩表示。</li>
<li>results: 我们的框架可以在两个实际Internet Service Provider Networks的数据集上提高标准GNN和Feed-Forward架构的压缩率，从 $30%$ 提高到 $90%$，表明它更好地捕捉和利用图structured网络结构中的空间和时间相关性。<details>
<summary>Abstract</summary>
Recently emerged Topological Deep Learning (TDL) methods aim to extend current Graph Neural Networks (GNN) by naturally processing higher-order interactions, going beyond the pairwise relations and local neighborhoods defined by graph representations. In this paper we propose a novel TDL-based method for compressing signals over graphs, consisting in two main steps: first, disjoint sets of higher-order structures are inferred based on the original signal --by clustering $N$ datapoints into $K\ll N$ collections; then, a topological-inspired message passing gets a compressed representation of the signal within those multi-element sets. Our results show that our framework improves both standard GNN and feed-forward architectures in compressing temporal link-based signals from two real-word Internet Service Provider Networks' datasets --from $30\%$ up to $90\%$ better reconstruction errors across all evaluation scenarios--, suggesting that it better captures and exploits spatial and temporal correlations over the whole graph-based network structure.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Disjoint sets of higher-order structures are inferred based on the original signal by clustering $N$ datapoints into $K\ll N$ collections.2. A topological-inspired message passing gets a compressed representation of the signal within those multi-element sets.Our results show that our framework improves both standard GNN and feed-forward architectures in compressing temporal link-based signals from two real-world Internet Service Provider Networks’ datasets - from $30%$ up to $90%$ better reconstruction errors across all evaluation scenarios - suggesting that it better captures and exploits spatial and temporal correlations over the whole graph-based network structure.Translated into Simplified Chinese:最近提出的 topological deep learning (TDL) 方法目的是扩展当前的图神经网络 (GNN)，以自然处理更高级别的交互，超越对图表示的对称关系和本地邻域。在这篇论文中，我们提出了一种基于 TDL 的图信号压缩方法，包括两个主要步骤：1. 根据原始信号，使用 clustering 将 $N$ 个数据点分为 $K\ll N$ 个集合。2. 使用图启发的消息传递机制，在多个元素集中获得压缩表示。我们的结果表明，我们的框架可以提高标准 GNN 和Feed-Forward 架构在图信号压缩方面的性能，从两个实际的互联网服务提供商网络数据集中，提高压缩率，从 $30%$ 到 $90%$，表明它更好地捕捉和利用图structured 网络的空间和时间相关性。</details></li>
</ol>
<hr>
<h2 id="UnLoc-A-Unified-Framework-for-Video-Localization-Tasks"><a href="#UnLoc-A-Unified-Framework-for-Video-Localization-Tasks" class="headerlink" title="UnLoc: A Unified Framework for Video Localization Tasks"></a>UnLoc: A Unified Framework for Video Localization Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11062">http://arxiv.org/abs/2308.11062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/scenic">https://github.com/google-research/scenic</a></li>
<li>paper_authors: Shen Yan, Xuehan Xiong, Arsha Nagrani, Anurag Arnab, Zhonghao Wang, Weina Ge, David Ross, Cordelia Schmid</li>
<li>for: 这篇论文是为了解决无法裁剪视频的视频地址Localization问题而设计的。</li>
<li>methods: 该论文使用预训练的图像和文本楼层，并将其传递给视频-文本融合模型。输出的融合模块 then用于构建一个特征峰，每个级别与一个头相连，以预测每帧的相关性分数和开始&#x2F;结束时间偏移。</li>
<li>results: 该方法可以实现Moment Retrieval、Temporal Localization和Action Segmentation三个任务，而无需动作提案、运动基于预训练特征或 Representation masking。与专门的模型不同，我们在三个不同的地址Localization任务上达到了状态 искусственный智能的最佳result。<details>
<summary>Abstract</summary>
While large-scale image-text pretrained models such as CLIP have been used for multiple video-level tasks on trimmed videos, their use for temporal localization in untrimmed videos is still a relatively unexplored task. We design a new approach for this called UnLoc, which uses pretrained image and text towers, and feeds tokens to a video-text fusion model. The output of the fusion module are then used to construct a feature pyramid in which each level connects to a head to predict a per-frame relevancy score and start/end time displacements. Unlike previous works, our architecture enables Moment Retrieval, Temporal Localization, and Action Segmentation with a single stage model, without the need for action proposals, motion based pretrained features or representation masking. Unlike specialized models, we achieve state of the art results on all three different localization tasks with a unified approach. Code will be available at: \url{https://github.com/google-research/scenic}.
</details>
<details>
<summary>摘要</summary>
大规模图像文本预训练模型，如CLIP，已经用于多个视频级任务，但它们在未处理的视频中进行时间地理化仍然是一个相对未探索的任务。我们设计了一种新的方法，即UnLoc，它使用预训练的图像和文本楼层，并将Token传递给视频文本融合模型。模型的输出被用construct一个特征 pyramid，其中每个层与一个头连接，以预测每帧相关性分数和开始/结束时间偏移。与先前的工作不同，我们的架构允许每帧 Localization、Temporal Localization 和 Action Segmentation 通过单一的阶段模型进行，不需要动作提案、运动基于预训练特征或表示掩码。与专门的模型不同，我们在三个不同的地理化任务上达到了状态机器的最佳result，代码将在： \url{https://github.com/google-research/scenic} 中提供。
</details></li>
</ul>
<hr>
<h2 id="FedDAT-An-Approach-for-Foundation-Model-Finetuning-in-Multi-Modal-Heterogeneous-Federated-Learning"><a href="#FedDAT-An-Approach-for-Foundation-Model-Finetuning-in-Multi-Modal-Heterogeneous-Federated-Learning" class="headerlink" title="FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning"></a>FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12305">http://arxiv.org/abs/2308.12305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Yao Zhang, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 这个研究是为了提高基础模型在多modal学习中的表现，并且解决训练需要大量数据的问题。</li>
<li>methods: 这个研究使用了联合学习（Federated Learning）和内部知识传播（Mutual Knowledge Distillation）等方法，以及一个叫做DAT的双适束教师，来处理客户端资料不同性。</li>
<li>results: 这个研究的结果显示，使用FedDAT可以将基础模型进行高效的分布式调整，并且在不同类型的多modal任务上表现出色，比较现有的中央PEFT方法更高效。<details>
<summary>Abstract</summary>
Recently, foundation models have exhibited remarkable advancements in multi-modal learning. These models, equipped with millions (or billions) of parameters, typically require a substantial amount of data for finetuning. However, collecting and centralizing training data from diverse sectors becomes challenging due to distinct privacy regulations. Federated Learning (FL) emerges as a promising solution, enabling multiple clients to collaboratively train neural networks without centralizing their local data. To alleviate client computation burdens and communication overheads, previous works have adapted Parameter-efficient Finetuning (PEFT) methods for FL. Hereby, only a small fraction of the model parameters are optimized and communicated during federated communications. Nevertheless, most previous works have focused on a single modality and neglected one common phenomenon, i.e., the presence of data heterogeneity across the clients. Therefore, in this work, we propose a finetuning framework tailored to heterogeneous multi-modal FL, called Federated Dual-Aadapter Teacher (FedDAT). Specifically, our approach leverages a Dual-Adapter Teacher (DAT) to address data heterogeneity by regularizing the client local updates and applying Mutual Knowledge Distillation (MKD) for an efficient knowledge transfer. FedDAT is the first approach that enables an efficient distributed finetuning of foundation models for a variety of heterogeneous Vision-Language tasks. To demonstrate its effectiveness, we conduct extensive experiments on four multi-modality FL benchmarks with different types of data heterogeneity, where FedDAT substantially outperforms the existing centralized PEFT methods adapted for FL.
</details>
<details>
<summary>摘要</summary>
近些时候，基金会模型在多Modal学习方面做出了很大的进步。这些模型通常需要大量数据进行微调，但由于不同领域的隐私规定，收集和中央化训练数据变得困难。为了解决这问题，联邦学习（FL）出现了，允许多个客户共同训练神经网络，无需中央化地方数据。为了减轻客户计算负担和通信开销，先前的工作已经采用了精度高的微调方法（PEFT）。然而，大多数先前的工作都是单modal的，忽略了客户数据的不同性。因此，在这项工作中，我们提出了适用于多样性多Modal FL的微调框架，即联邦双Adapter教师（FedDAT）。我们的方法利用了双Adapter教师（DAT）来 Address客户本地更新的数据不同性，并通过互助知识传播（MKD）来进行高效的知识传递。FedDAT 是首个可以有效地分布式微调基础模型的多Modal Vision-Language 联邦FL 方法。为证明其有效性，我们在四个多Modal FL 标准准的不同类型的数据不同性上进行了广泛的实验，并证明FedDAT 在这些标准上大幅超越了已有的中央化 PEFT 方法。
</details></li>
</ul>
<hr>
<h2 id="Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression"><a href="#Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression" class="headerlink" title="Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression"></a>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11053">http://arxiv.org/abs/2308.11053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hangting Chen, Jianwei Yu, Yi Luo, Rongzhi Gu, Weihua Li, Zhuocheng Lu, Chao Weng</li>
<li>for: 实现全动频通信的杂音抑制和调变减少，但大多数现有的神经网络具有高计算成本和不可靠的模型复杂度调整。</li>
<li>methods: 我们提出了时间-频率二重路径压缩，以实现广泛的压缩比率选择。特别是在频率压缩方面，使用可训练的范子网络来进行维度减少。在时间压缩方面，仅使用几帧预测会导致巨大的性能下降，可以通过全序模型来缓和这一下。</li>
<li>results: 我们发现，将时间和频率两种方法组合在一起，可以实现更好的性能改进，覆盖压缩比率的选择范围从4x至32x，而且这些提案的模型具有与快速FullSubNet和DeepFilterNet相似的竞争性能。<details>
<summary>Abstract</summary>
Echo cancellation and noise reduction are essential for full-duplex communication, yet most existing neural networks have high computational costs and are inflexible in tuning model complexity. In this paper, we introduce time-frequency dual-path compression to achieve a wide range of compression ratios on computational cost. Specifically, for frequency compression, trainable filters are used to replace manually designed filters for dimension reduction. For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io/ultra_dual_path_compression.github.io/.
</details>
<details>
<summary>摘要</summary>
echo 抑制和噪声减少是全双工通信的必备条件，然而大多数现有的神经网络具有高计算成本和不 flexible 的模型复杂度调整。在这篇论文中，我们引入时频双路压缩来实现广泛的压缩比例。 Specifically， для频率压缩，使用可训练的滤波器来替代手动设计的滤波器进行维度减少。 For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io/ultra_dual_path_compression.github.io/.Note that the text has been translated using Simplified Chinese characters and grammar. If you prefer Traditional Chinese, please let me know and I can provide the translation using Traditional Chinese characters and grammar.
</details></li>
</ul>
<hr>
<h2 id="Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI"><a href="#Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI" class="headerlink" title="Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI"></a>Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11047">http://arxiv.org/abs/2308.11047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhijeet Parida, Zhifan Jiang, Syed Muhammad Anwar, Nicholas Foreman, Nicholas Stence, Michael J. Fisher, Roger J. Packer, Robert A. Avery, Marius George Linguraru</li>
<li>for: 这篇论文旨在应用深度学习技术来进行少见疾病，如儿童脑肿瘤的诊断和预测。</li>
<li>methods: 本论文使用生成对抗网络（GANs）进行深度学习预测，并提出了一个一击学习方法，将单一的诊断影像转换为医疗影像集合中的一个标准化影像。</li>
<li>results: 实验结果显示，本方法可以优化医疗影像的尺度，同时保持病人解剖结构的稳定性。<details>
<summary>Abstract</summary>
For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as "hallucination". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.
</details>
<details>
<summary>摘要</summary>
For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as "hallucination". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Spurious-Correlations-and-Where-to-Find-Them"><a href="#Spurious-Correlations-and-Where-to-Find-Them" class="headerlink" title="Spurious Correlations and Where to Find Them"></a>Spurious Correlations and Where to Find Them</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11043">http://arxiv.org/abs/2308.11043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gautam Sreekumar, Vishnu Naresh Boddeti</li>
<li>for: 本研究旨在探讨数据驱动学习中的假 correlate 问题，并提出一种基于 causal graph 的方法来解决这个问题。</li>
<li>methods: 本研究使用了一些常见的假 correlate 假设，并通过对标准 ERM 基elines 进行比较，检验这些假设对模型性能的影响。</li>
<li>results: 研究发现，在不同的假 correlate 假设下，模型的性能会受到不同程度的影响，并且可以通过对模型设计 Parameters 进行调整来改善模型性能。<details>
<summary>Abstract</summary>
Spurious correlations occur when a model learns unreliable features from the data and are a well-known drawback of data-driven learning. Although there are several algorithms proposed to mitigate it, we are yet to jointly derive the indicators of spurious correlations. As a result, the solutions built upon standalone hypotheses fail to beat simple ERM baselines. We collect some of the commonly studied hypotheses behind the occurrence of spurious correlations and investigate their influence on standard ERM baselines using synthetic datasets generated from causal graphs. Subsequently, we observe patterns connecting these hypotheses and model design choices.
</details>
<details>
<summary>摘要</summary>
伪 correlate 发生在模型从数据中学习不可靠特征时，这是数据驱动学习的一个知名缺陷。虽然有多种算法提出来 mitigate 其影响，但我们还没有共同 derivation 这些伪 correlate 的指标。因此，基于单独的假设建立的解决方案不能超过简单的 ERM 基elines。我们收集了一些常study 的假设下伪 correlate 的发生，并 investigate 这些假设对标准 ERM 基elines 的影响使用 synthetic 数据集。然后，我们发现了这些假设和模型设计选择之间的 Patterns。
</details></li>
</ul>
<hr>
<h2 id="Split-Learning-for-Distributed-Collaborative-Training-of-Deep-Learning-Models-in-Health-Informatics"><a href="#Split-Learning-for-Distributed-Collaborative-Training-of-Deep-Learning-Models-in-Health-Informatics" class="headerlink" title="Split Learning for Distributed Collaborative Training of Deep Learning Models in Health Informatics"></a>Split Learning for Distributed Collaborative Training of Deep Learning Models in Health Informatics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11027">http://arxiv.org/abs/2308.11027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuohang Li, Chao Yan, Xinmeng Zhang, Gharib Gharibi, Zhijun Yin, Xiaoqian Jiang, Bradley A. Malin</li>
<li>for: 本研究旨在Addressing the challenge of training deep learning models across healthcare organizations with privacy requirements.</li>
<li>methods: 该研究提出了一种新的隐私保护分布式学习框架，可以在私有保持原始数据和模型参数的情况下进行分布式学习。</li>
<li>results: 研究表明，通过使用分布式学习，可以实现高度相似的性能与中央化和联合学习，同时提高计算效率和降低隐私风险。<details>
<summary>Abstract</summary>
Deep learning continues to rapidly evolve and is now demonstrating remarkable potential for numerous medical prediction tasks. However, realizing deep learning models that generalize across healthcare organizations is challenging. This is due, in part, to the inherent siloed nature of these organizations and patient privacy requirements. To address this problem, we illustrate how split learning can enable collaborative training of deep learning models across disparate and privately maintained health datasets, while keeping the original records and model parameters private. We introduce a new privacy-preserving distributed learning framework that offers a higher level of privacy compared to conventional federated learning. We use several biomedical imaging and electronic health record (EHR) datasets to show that deep learning models trained via split learning can achieve highly similar performance to their centralized and federated counterparts while greatly improving computational efficiency and reducing privacy risks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Extreme-Multilabel-Classification-for-Specialist-Doctor-Recommendation-with-Implicit-Feedback-and-Limited-Patient-Metadata"><a href="#Extreme-Multilabel-Classification-for-Specialist-Doctor-Recommendation-with-Implicit-Feedback-and-Limited-Patient-Metadata" class="headerlink" title="Extreme Multilabel Classification for Specialist Doctor Recommendation with Implicit Feedback and Limited Patient Metadata"></a>Extreme Multilabel Classification for Specialist Doctor Recommendation with Implicit Feedback and Limited Patient Metadata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11022">http://arxiv.org/abs/2308.11022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filipa Valdeira, Stevo Racković, Valeria Danalachi, Qiwei Han, Cláudia Soares</li>
<li>for: 预测医生 Referral 建议，包括新患者和已有咨询历史</li>
<li>methods: 使用 Extreme Multilabel Classification (XML) 编码可用特征，并 explore 不同的场景</li>
<li>results: 比对标准推荐 metric ，our approach 在有咨询历史的患者群体中提高推荐精度大约 $10%$，并在新患者群体中提高 recall 纪录In English, this means:</li>
<li>for: Predicting doctor referrals, including new patients and those with a consultation history</li>
<li>methods: Using Extreme Multilabel Classification (XML) to encode available features and explore different scenarios</li>
<li>results: Comparing standard recommendation metrics, our approach consistently improves recommendation accuracy by approximately $10%$ for patients with a previous consultation history, and outperforms the benchmark in favorable scenarios for new patients, with a focus on recall metrics.<details>
<summary>Abstract</summary>
Recommendation Systems (RS) are often used to address the issue of medical doctor referrals. However, these systems require access to patient feedback and medical records, which may not always be available in real-world scenarios. Our research focuses on medical referrals and aims to predict recommendations in different specialties of physicians for both new patients and those with a consultation history. We use Extreme Multilabel Classification (XML), commonly employed in text-based classification tasks, to encode available features and explore different scenarios. While its potential for recommendation tasks has often been suggested, this has not been thoroughly explored in the literature. Motivated by the doctor referral case, we show how to recast a traditional recommender setting into a multilabel classification problem that current XML methods can solve. Further, we propose a unified model leveraging patient history across different specialties. Compared to state-of-the-art RS using the same features, our approach consistently improves standard recommendation metrics up to approximately $10\%$ for patients with a previous consultation history. For new patients, XML proves better at exploiting available features, outperforming the benchmark in favorable scenarios, with particular emphasis on recall metrics. Thus, our approach brings us one step closer to creating more effective and personalized doctor referral systems. Additionally, it highlights XML as a promising alternative to current hybrid or content-based RS, while identifying key aspects to take into account when using XML for recommendation tasks.
</details>
<details>
<summary>摘要</summary>
医疗专家推荐系统（RS）经常用于解决医疗专家推荐问题。然而，这些系统可能需要患者反馈和医疗记录，这些资料在实际场景中可能不常可用。我们的研究关注医疗推荐，并且想要预测不同专业医生的推荐建议，包括新患者和已经有咨询历史的患者。我们使用极端多类标签分类（XML），通常用于文本分类任务，来编码可用的特征并explore不同的场景。虽然XML在推荐任务中的潜力尚未得到了足够的研究，但我们在医疗推荐中提出了一种新的方法。我们的方法可以将传统的推荐设定转换成多类标签分类问题，使得现有的XML方法可以解决。此外，我们提议一种综合模型，利用患者历史跨专业。相比于使用同样的特征的状态体系，我们的方法在患者历史存在时可以保持标准推荐指标的提高，达到约10%。在新患者情况下，XML较好地利用可用的特征，超越了标准。特别是，我们的方法在反报率指标方面具有明显的优势。因此，我们的方法可以为创建更有效和个性化的医疗专家推荐系统做出一步进展。此外，它也证明了XML作为推荐任务的一种有前途的alternative，而且标识了在使用XML时需要注意的关键方面。
</details></li>
</ul>
<hr>
<h2 id="Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations"><a href="#Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations" class="headerlink" title="Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations"></a>Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11021">http://arxiv.org/abs/2308.11021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mihai Pirvu, Alina Marcu, Alexandra Dobrescu, Nabil Belbachir, Marius Leordeanu</li>
<li>for: 这个论文的目的是为了解决EARTH OBSERVATION问题，这个问题是多任务的并且常常缺少地面真实数据。</li>
<li>methods: 这篇论文提出了一种多任务希пер图模型，其中每个节点是一个任务，不同的路径通过希пер图达到某个任务都成为了无监督教师，这些教师 ensemble 学习生成可靠的假标签 для该任务。每个希PERedge 是一个任务的教师和学生，它也是一个自动матичеSK hypergraph 系统的学生。</li>
<li>results: 通过对NASA NEO Dataset进行广泛的实验，证明了我们的多任务半监督方法的价值， consistently 超过了强基eline和最新的工作。此外，我们还证明了希PERgraph 可以适应无监督数据分布变化，并可靠地恢复多个观测层的缺失数据，超过了7年。<details>
<summary>Abstract</summary>
There are many ways of interpreting the world and they are highly interdependent. We exploit such complex dependencies and introduce a powerful multi-task hypergraph, in which every node is a task and different paths through the hypergraph reaching a given task become unsupervised teachers, by forming ensembles that learn to generate reliable pseudolabels for that task. Each hyperedge is part of an ensemble teacher for a given task and it is also a student of the self-supervised hypergraph system. We apply our model to one of the most important problems of our times, that of Earth Observation, which is highly multi-task and it often suffers from missing ground-truth data. By performing extensive experiments on the NASA NEO Dataset, spanning a period of 22 years, we demonstrate the value of our multi-task semi-supervised approach, by consistent improvements over strong baselines and recent work. We also show that the hypergraph can adapt unsupervised to gradual data distribution shifts and reliably recover, through its multi-task self-supervision process, the missing data for several observational layers for up to seven years.
</details>
<details>
<summary>摘要</summary>
世界的解释有多种方法，它们之间具有高度的互相依赖关系。我们利用这些复杂的依赖关系，引入一个强大的多任务跨граф，其中每个节点是一个任务，不同的路径通过跨граф到达给定任务都变成了无监督教师。每个跨边都是一个任务的ensemble教师，同时也是自动编程跨 graf系统的学生。我们应用我们的模型到现代时代最重要的问题之一——地球观测，这是一个高度多任务的问题， часто会 missing ground-truth data。通过对 NASA NEO 数据集进行了22年的广泛实验，我们展示了我们的多任务半监督方法的价值，通过不断超过强大的基准和最新的研究成果。我们还表明了跨 graf 可以适应无监督的数据分布变化，并可靠地恢复多个观测层的缺失数据，达7年之久。
</details></li>
</ul>
<hr>
<h2 id="Instance-based-Learning-with-Prototype-Reduction-for-Real-Time-Proportional-Myocontrol-A-Randomized-User-Study-Demonstrating-Accuracy-preserving-Data-Reduction-for-Prosthetic-Embedded-Systems"><a href="#Instance-based-Learning-with-Prototype-Reduction-for-Real-Time-Proportional-Myocontrol-A-Randomized-User-Study-Demonstrating-Accuracy-preserving-Data-Reduction-for-Prosthetic-Embedded-Systems" class="headerlink" title="Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems"></a>Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11019">http://arxiv.org/abs/2308.11019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Sziburis, Markus Nowak, Davide Brunelli</li>
<li>for: 这篇论文探讨了基于kNN的手势识别方法，用于辅助控制 prosthesis。</li>
<li>methods: 方法包括实现kNN scheme，并评估不同的实现方式和参数化方法，以提高运算效率和可靠性。</li>
<li>results: 结果显示，使用kNN scheme和Decision Surface Mapping（DSM）可以实现高精度的手势识别，并且在实时运算中保持高速度和可靠性。<details>
<summary>Abstract</summary>
This work presents the design, implementation and validation of learning techniques based on the kNN scheme for gesture detection in prosthetic control. To cope with high computational demands in instance-based prediction, methods of dataset reduction are evaluated considering real-time determinism to allow for the reliable integration into battery-powered portable devices. The influence of parameterization and varying proportionality schemes is analyzed, utilizing an eight-channel-sEMG armband. Besides offline cross-validation accuracy, success rates in real-time pilot experiments (online target achievement tests) are determined. Based on the assessment of specific dataset reduction techniques' adequacy for embedded control applications regarding accuracy and timing behaviour, Decision Surface Mapping (DSM) proves itself promising when applying kNN on the reduced set. A randomized, double-blind user study was conducted to evaluate the respective methods (kNN and kNN with DSM-reduction) against Ridge Regression (RR) and RR with Random Fourier Features (RR-RFF). The kNN-based methods performed significantly better (p<0.0005) than the regression techniques. Between DSM-kNN and kNN, there was no statistically significant difference (significance level 0.05). This is remarkable in consideration of only one sample per class in the reduced set, thus yielding a reduction rate of over 99% while preserving success rate. The same behaviour could be confirmed in an extended user study. With k=1, which turned out to be an excellent choice, the runtime complexity of both kNN (in every prediction step) as well as DSM-kNN (in the training phase) becomes linear concerning the number of original samples, favouring dependable wearable prosthesis applications.
</details>
<details>
<summary>摘要</summary>
这个工作介绍了基于kNN算法的手势检测技术的设计、实现和验证。为了应对实例基本预测的高计算需求，dataset减少方法被评估，包括实时决定性以便可靠地 интеGRATE到电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池
</details></li>
</ul>
<hr>
<h2 id="Personalized-Event-Prediction-for-Electronic-Health-Records"><a href="#Personalized-Event-Prediction-for-Electronic-Health-Records" class="headerlink" title="Personalized Event Prediction for Electronic Health Records"></a>Personalized Event Prediction for Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11013">http://arxiv.org/abs/2308.11013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeong Min Lee, Milos Hauskrecht</li>
<li>for: 这篇论文的目的是为了开发一些准确的预测模型，以支持不同的医疗执行和病例分析，并且提高病人照顾质量。</li>
<li>methods: 这篇论文使用了多种新的事件序列预测模型和方法，包括人群内部模型修饰、自适应和元件水平模型转换，以更好地适应个别病人和其特定情况。</li>
<li>results: 这篇论文的结果显示，这些新的预测模型和方法可以对医疗纪录中的事件序列进行更准确的预测，并且可以适应不同的病人和其特定情况。<details>
<summary>Abstract</summary>
Clinical event sequences consist of hundreds of clinical events that represent records of patient care in time. Developing accurate predictive models of such sequences is of a great importance for supporting a variety of models for interpreting/classifying the current patient condition, or predicting adverse clinical events and outcomes, all aimed to improve patient care. One important challenge of learning predictive models of clinical sequences is their patient-specific variability. Based on underlying clinical conditions, each patient's sequence may consist of different sets of clinical events (observations, lab results, medications, procedures). Hence, simple population-wide models learned from event sequences for many different patients may not accurately predict patient-specific dynamics of event sequences and their differences. To address the problem, we propose and investigate multiple new event sequence prediction models and methods that let us better adjust the prediction for individual patients and their specific conditions. The methods developed in this work pursue refinement of population-wide models to subpopulations, self-adaptation, and a meta-level model switching that is able to adaptively select the model with the best chance to support the immediate prediction. We analyze and test the performance of these models on clinical event sequences of patients in MIMIC-III database.
</details>
<details>
<summary>摘要</summary>
临床事件序列包含数百个临床事件记录，表示患者的时间序列记录。开发准确预测临床序列模型是非常重要的，以支持评估当前患者状况、分类临床事件类型和预测不良临床结果等，以提高患者治疗。一个重要的预测临床序列模型挑战是每个患者的序列可能具有不同的临床事件集（观察结果、实验室测试结果、药物和处理），因此通用于许多患者的人口级别模型可能无法准确预测每个患者的特定状况和差异。为解决这个问题，我们提出并研究了多种新的临床序列预测模型和方法，使得我们可以更好地适应每个患者和其特定状况。我们在MIMIC-III数据库中分析和测试了这些模型的性能。
</details></li>
</ul>
<hr>
<h2 id="Using-language-models-in-the-implicit-automated-assessment-of-mathematical-short-answer-items"><a href="#Using-language-models-in-the-implicit-automated-assessment-of-mathematical-short-answer-items" class="headerlink" title="Using language models in the implicit automated assessment of mathematical short answer items"></a>Using language models in the implicit automated assessment of mathematical short answer items</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11006">http://arxiv.org/abs/2308.11006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Ormerod</li>
<li>for: 这个论文旨在提出一种新的短 constructed response 评估方法，用于评估学生在数学题目上的答案。</li>
<li>methods: 该方法使用一个管道来标识学生的答案中关键的值。该管道包括两个精心定制的自然语言模型，第一个模型判断答案中是否含有关键值，第二个模型则确定答案中关键值的位置。</li>
<li>results: 相比传统的分页式评估方法，该管道可以更准确地评估短 constructed response，并且可以提供更有arget的反馈给学生和教师，帮助学生提高数学理解。<details>
<summary>Abstract</summary>
We propose a new way to assess certain short constructed responses to mathematics items. Our approach uses a pipeline that identifies the key values specified by the student in their response. This allows us to determine the correctness of the response, as well as identify any misconceptions. The information from the value identification pipeline can then be used to provide feedback to the teacher and student. The value identification pipeline consists of two fine-tuned language models. The first model determines if a value is implicit in the student response. The second model identifies where in the response the key value is specified. We consider both a generic model that can be used for any prompt and value, as well as models that are specific to each prompt and value. The value identification pipeline is a more accurate and informative way to assess short constructed responses than traditional rubric-based scoring. It can be used to provide more targeted feedback to students, which can help them improve their understanding of mathematics.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来评估某些短 constructed responses 的数学项目。我们的方法使用一个管道，从student response中提取关键值。这使得我们可以确定答案是否正确，以及学生是否存在误会。管道中的信息可以用于给教师和学生提供反馈。我们的值标识管道包括两个精度调整的自然语言模型。第一个模型判断学生答案中是否存在某个值。第二个模型则确定答案中关键值的位置。我们考虑了一个通用的模型，可以用于任何提问和值，以及每个提问和值的特定模型。值标识管道比传统基于满分表格的评分方法更准确和有用，可以为学生提供更加精准的反馈，从而帮助学生提高数学理解。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning"><a href="#Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning" class="headerlink" title="Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning"></a>Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11003">http://arxiv.org/abs/2308.11003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bertrand Rouet-Leduc, Thomas Kerdreux, Alexandre Tuel, Claudia Hulbert</li>
<li>For: The paper aims to develop a method for automatically detecting methane leaks in satellite multispectral data using deep learning techniques.* Methods: The paper uses Sentinel-2 satellite multispectral data and leverages the image recognition capabilities of deep learning methods to detect methane leaks.* Results: The paper shows that the proposed approach can dramatically reduce false positive rates compared to state-of-the-art multispectral methane data products and can automatically detect methane leaks without the need for a priori knowledge of potential leak sites.Here’s the same information in Simplified Chinese:* For: 该文章目的是开发一种自动检测卫星多spectral数据中的甲烷泄漏的方法，使用深度学习技术。* Methods: 文章使用Sentinel-2卫星多spectral数据，利用深度学习方法对图像进行识别，检测甲烷泄漏。* Results: 文章显示，提议的方法可以减少false positive率，比state-of-the-art多spectral甲烷数据产品更加精准，无需先知道泄漏点的位置。<details>
<summary>Abstract</summary>
Methane is one of the most potent greenhouse gases, and its short atmospheric half-life makes it a prime target to rapidly curb global warming. However, current methane emission monitoring techniques primarily rely on approximate emission factors or self-reporting, which have been shown to often dramatically underestimate emissions. Although initially designed to monitor surface properties, satellite multispectral data has recently emerged as a powerful method to analyze atmospheric content. However, the spectral resolution of multispectral instruments is poor, and methane measurements are typically very noisy. Methane data products are also sensitive to absorption by the surface and other atmospheric gases (water vapor in particular) and therefore provide noisy maps of potential methane plumes, that typically require extensive human analysis. Here, we show that the image recognition capabilities of deep learning methods can be leveraged to automatize the detection of methane leaks in Sentinel-2 satellite multispectral data, with dramatically reduced false positive rates compared with state-of-the-art multispectral methane data products, and without the need for a priori knowledge of potential leak sites. Our proposed approach paves the way for the automated, high-definition and high-frequency monitoring of point-source methane emissions across the world.
</details>
<details>
<summary>摘要</summary>
孕气是最强烈的绿色气体之一，它的大气半衰期短，使其成为缓解全球变暖的 prime target。然而，现有的甲烷排放监测技术主要基于估算的排放因子或自我报告，这些估算通常会很大幅度地下估排放。虽然初始设计用于监测地面属性，但卫星多spectral数据最近在气象Content的分析方面 emerged as a powerful tool。然而，多spectral instrument的 spectral resolution poor, and methane measurements are typically very noisy. methane data products are also sensitive to absorption by the surface and other atmospheric gases (water vapor in particular) and therefore provide noisy maps of potential methane plumes, that typically require extensive human analysis。在这里，我们展示了深度学习方法的图像识别能力可以用来自动检测Sentinel-2卫星多spectral数据中的甲烷泄漏，与现有的多spectral甲烷数据产品相比， false positive rate 下降了多少，而无需对潜在泄漏点的 prior knowledge。我们的提议方法开 up the possibility of automated, high-definition and high-frequency monitoring of point-source methane emissions across the world。
</details></li>
</ul>
<hr>
<h2 id="SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance"><a href="#SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance" class="headerlink" title="SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance"></a>SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10973">http://arxiv.org/abs/2308.10973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jarrod Haas</li>
<li>for: 本研究旨在提出一种非常简单的方法来检测数据集外的异常（Out-of-Distribution，OoD）样本。</li>
<li>methods: 本研究使用了Supervised Contrastive Learning（SCL）方法将ResNet18模型训练，并使用欧几丁度评分函数来评估OoD样本。</li>
<li>results: 研究发现，使用SCL方法训练ResNet18模型，可以直接使用Euclidean distance评分函数来检测OoD样本，并且可以达到或超过许多现有的州态艺法和大型模型的效果。<details>
<summary>Abstract</summary>
Out-of-Distribution (OoD) detection has developed substantially in the past few years, with available methods approaching, and in a few cases achieving, perfect data separation on standard benchmarks. These results generally involve large or complex models, pretraining, exposure to OoD examples or extra hyperparameter tuning. Remarkably, it is possible to achieve results that can exceed many of these state-of-the-art methods with a very simple method. We demonstrate that ResNet18 trained with Supervised Contrastive Learning (SCL) produces state-of-the-art results out-of-the-box on near and far OoD detection benchmarks using only Euclidean distance as a scoring rule. This may obviate the need in some cases for more sophisticated methods or larger models, and at the very least provides a very strong, easy to use baseline for further experimentation and analysis.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION（OOD）检测在最近几年内发展了很大，现有的方法已经几乎完美地分离了标准 benchmark 上的数据。这些结果通常需要使用大型或复杂的模型，预训练，对 OOD 示例进行暴露或额外的 гиперпараметр调整。很 Remarkably，我们发现可以使用非常简单的方法来超越许多state-of-the-art方法。我们示出，使用 Supervised Contrastive Learning（SCL）训练的 ResNet18 在靠近和远 OOD 检测 benchmark 上达到了 state-of-the-art 结果，只使用 euclidian distance 作为分数规则。这可能将一些情况下取代更复杂的方法或更大的模型，而且最少提供了一个非常强大、易于使用的基准， для 进一步的实验和分析。
</details></li>
</ul>
<hr>
<h2 id="Fat-Shattering-Joint-Measurability-and-PAC-Learnability-of-POVM-Hypothesis-Classes"><a href="#Fat-Shattering-Joint-Measurability-and-PAC-Learnability-of-POVM-Hypothesis-Classes" class="headerlink" title="Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes"></a>Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12304">http://arxiv.org/abs/2308.12304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abram Magner, Arun Padakandla</li>
<li>for: 本文研究了量子测量类的学习可能性，并提出了匹配的必要和 suficient conditions，以及相应的样本复杂度下界。</li>
<li>methods: 本文使用了Empirical Risk Minimization（ERM）和denoised ERM来学习量子测量类，并提出了新的学习规则——denoised ERM，以及其uniform convergence的condition。</li>
<li>results: 本文证明了POVM和概率观测类是PAC可学习的，并给出了量子测量类的样本复杂度下界。此外，本文还证明了所有在finite-dimensional Hilbert space上定义的测量类都是PAC可学习的。<details>
<summary>Abstract</summary>
We characterize learnability for quantum measurement classes by establishing matching necessary and sufficient conditions for their PAC learnability, along with corresponding sample complexity bounds, in the setting where the learner is given access only to prepared quantum states. We first probe the results from previous works on this setting. We show that the empirical risk defined in previous works and matching the definition in the classical theory fails to satisfy the uniform convergence property enjoyed in the classical setting for some learnable classes. Moreover, we show that VC dimension generalization upper bounds in previous work are frequently infinite, even for finite-dimensional POVM classes. To surmount the failure of the standard ERM to satisfy uniform convergence, we define a new learning rule -- denoised ERM. We show this to be a universal learning rule for POVM and probabilistically observed concept classes, and the condition for it to satisfy uniform convergence is finite fat shattering dimension of the class. We give quantitative sample complexity upper and lower bounds for learnability in terms of finite fat-shattering dimension and a notion of approximate finite partitionability into approximately jointly measurable subsets, which allow for sample reuse. We then show that finite fat shattering dimension implies finite coverability by approximately jointly measurable subsets, leading to our matching conditions. We also show that every measurement class defined on a finite-dimensional Hilbert space is PAC learnable. We illustrate our results on several example POVM classes.
</details>
<details>
<summary>摘要</summary>
我们 caracteriza 学习可能性 для量子测量类型 by 确定匹配的必需和充分条件，以及相应的样本复杂性 bound，在learner 被给定只有准备好的量子状态的设置下。我们首先探究 previous works 中的结果。我们显示了empirical risk 定义在 previous works 中并不满足 classical setting 中的各种learnable classes 上的 uniform convergence property。此外，我们还显示了 previous work 中的VC dimension 泛化Upper bound  часто是无限大，即使是 finite-dimensional POVM 类型。为了缺乏标准 ERM 满足 uniform convergence，我们定义了一种新的学习规则 -- denoised ERM。我们显示这是一种universal learning rule  для POVM 和 probabilistically observed concept classes，并且 condition  для它满足 uniform convergence 是类型的 finite fat shattering dimension。我们给出了量化样本复杂性 upper 和 lower bound ，用于描述learnability 的conditions。我们然后显示了 finite fat shattering dimension implies finite coverability by approximately jointly measurable subsets，导致我们的matching conditions。最后，我们还显示了 every measurement class defined on a finite-dimensional Hilbert space 是 PAC learnable。我们在 several example POVM classes 中应用我们的结果。
</details></li>
</ul>
<hr>
<h2 id="MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer"><a href="#MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer" class="headerlink" title="MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer"></a>MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10968">http://arxiv.org/abs/2308.10968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoyao Shen, Yancheng Zhu, Hernan Jara, Sean B. Andersson, Chad W. Farris, Stephan Anderson, Xin Zhang</li>
<li>for: 这 paper 的目的是提出一种基于深度学习的 MRI 重建方法，以提高 MRI 的图像质量。</li>
<li>methods: 这 paper 使用了 regularization by denoising (RED) 和 regularization by neural style transfer (RNST) 两种方法，将它们组合使用以实现高质量的 MRI 重建。</li>
<li>results: 研究发现，使用 RNST 方法可以在不同的图像风格和有限数据情况下，从噪声低质量图像中重建出高质量图像。这些结果表明 RNST 框架在 MRI 重建中具有广泛的应用前景和可能性。<details>
<summary>Abstract</summary>
Recent works have demonstrated success in MRI reconstruction using deep learning-based models. However, most reported approaches require training on a task-specific, large-scale dataset. Regularization by denoising (RED) is a general pipeline which embeds a denoiser as a prior for image reconstruction. The potential of RED has been demonstrated for multiple image-related tasks such as denoising, deblurring and super-resolution. In this work, we propose a regularization by neural style transfer (RNST) method to further leverage the priors from the neural transfer and denoising engine. This enables RNST to reconstruct a high-quality image from a noisy low-quality image with different image styles and limited data. We validate RNST with clinical MRI scans from 1.5T and 3T and show that RNST can significantly boost image quality. Our results highlight the capability of the RNST framework for MRI reconstruction and the potential for reconstruction tasks with limited data.
</details>
<details>
<summary>摘要</summary>
近期研究表明，使用深度学习模型进行MRI重建有成功经验。然而，大多数报道的方法需要对特定任务的大规模数据进行训练。抑制权（RED）是一个通用管道，它嵌入了一个抑制器作为图像重建的先验。抑制权的潜力已经在多种图像相关任务中展现出来，如降噪、去锈和超解等。在这种工作中，我们提议一种基于神经传输和抑制器的常规化（RNST）方法，以利用神经传输和抑制器的先验来重建高质量图像。我们验证了RNST方法使用临床MRI扫描数据，并显示RNST可以在噪声低质量图像中重建高质量图像，并且可以在有限数据情况下进行重建。我们的结果显示RNST框架在MRI重建中具有优秀的能力，并且有潜力应用于有限数据的重建任务。
</details></li>
</ul>
<hr>
<h2 id="Structured-World-Models-from-Human-Videos"><a href="#Structured-World-Models-from-Human-Videos" class="headerlink" title="Structured World Models from Human Videos"></a>Structured World Models from Human Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10901">http://arxiv.org/abs/2308.10901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Russell Mendonca, Shikhar Bahl, Deepak Pathak</li>
<li>for: 本研究旨在训练机器人通过互联网大规模人类视频数据来快速学习复杂的 manipulate 技能。</li>
<li>methods: 本研究使用了人类视频数据来构建一个结构化的人类行为空间，并在这个空间中学习视觉可行性。然后，通过人类视频数据进行世界模型训练，并在小量机器人互动数据上进行细化调整。</li>
<li>results: 研究发现，通过这种方法，不同的机器人可以在复杂的设置下快速学习 manipulate 技能，仅需在30分钟内进行互动。视频可以在<a target="_blank" rel="noopener" href="https://human-world-model.github.io找到./">https://human-world-model.github.io找到。</a><details>
<summary>Abstract</summary>
We tackle the problem of learning complex, general behaviors directly in the real world. We propose an approach for robots to efficiently learn manipulation skills using only a handful of real-world interaction trajectories from many different settings. Inspired by the success of learning from large-scale datasets in the fields of computer vision and natural language, our belief is that in order to efficiently learn, a robot must be able to leverage internet-scale, human video data. Humans interact with the world in many interesting ways, which can allow a robot to not only build an understanding of useful actions and affordances but also how these actions affect the world for manipulation. Our approach builds a structured, human-centric action space grounded in visual affordances learned from human videos. Further, we train a world model on human videos and fine-tune on a small amount of robot interaction data without any task supervision. We show that this approach of affordance-space world models enables different robots to learn various manipulation skills in complex settings, in under 30 minutes of interaction. Videos can be found at https://human-world-model.github.io
</details>
<details>
<summary>摘要</summary>
我们面对现实世界中学习复杂、通用行为的问题。我们提议一种方法，让机器人通过几个不同设定下的实际互动路径学习摄取技能。我们受到电视频道和自然语言领域中大规模数据集的成功所激发，我们信服机器人可以通过互联网规模的人类视频数据来快速学习。人类在世界中进行许多有趣的互动，这可以让机器人不仅建立用Actions和可用性的理解，也可以了解如何这些Actions影响世界来进行摄取。我们的方法建立了基于视觉可用性的结构化人类行为空间，然后将人类视频中的世界模型训练，并在小量机器人互动数据上精致调整。我们显示这种价值空间世界模型可以让不同的机器人在复杂的设定下学习不同的摄取技能，仅需30分钟的互动。视频可以在https://human-world-model.github.io获取。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification"><a href="#Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification" class="headerlink" title="Unlocking Accuracy and Fairness in Differentially Private Image Classification"></a>Unlocking Accuracy and Fairness in Differentially Private Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10888">http://arxiv.org/abs/2308.10888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonard Berrada, Soham De, Judy Hanwen Shen, Jamie Hayes, Robert Stanforth, David Stutz, Pushmeet Kohli, Samuel L. Smith, Borja Balle</li>
<li>for:  trains models on private data without leaking sensitive information</li>
<li>methods:  uses differential privacy (DP) framework, fine-tunes pre-trained foundation models with DP</li>
<li>results: achieves similar accuracy to non-private classifiers, with private accuracies within a few percent of the non-private state of the art, and without larger performance disparities across demographic groups.<details>
<summary>Abstract</summary>
Privacy-preserving machine learning aims to train models on private data without leaking sensitive information. Differential privacy (DP) is considered the gold standard framework for privacy-preserving training, as it provides formal privacy guarantees. However, compared to their non-private counterparts, models trained with DP often have significantly reduced accuracy. Private classifiers are also believed to exhibit larger performance disparities across subpopulations, raising fairness concerns. The poor performance of classifiers trained with DP has prevented the widespread adoption of privacy preserving machine learning in industry. Here we show that pre-trained foundation models fine-tuned with DP can achieve similar accuracy to non-private classifiers, even in the presence of significant distribution shifts between pre-training data and downstream tasks. We achieve private accuracies within a few percent of the non-private state of the art across four datasets, including two medical imaging benchmarks. Furthermore, our private medical classifiers do not exhibit larger performance disparities across demographic groups than non-private models. This milestone to make DP training a practical and reliable technology has the potential to widely enable machine learning practitioners to train safely on sensitive datasets while protecting individuals' privacy.
</details>
<details>
<summary>摘要</summary>
“隐私保护机器学习” aim to 训练模型在私人数据上无泄露敏感信息。“数据隐私”（DP）被视为机器学习隐私保护的金标准框架，但与非私人模型相比，DP 训练的模型通常会有很大的准确性下降。私人分类器也被认为会在不同的人口集中Displaying 更大的性差，引起公平性的关注。DP 训练的模型表现不佳的问题阻碍了机器学习领域广泛采用隐私保护技术。我们在这篇文章中显示，将预训练的基础模型 fine-tune  avec DP 可以 дости到与非私人模型相似的准确性，甚至在数据分布差异很大的情况下。我们在四个数据集上 achieve private accuracy 与非私人模型相似，包括两个医疗影像标准 benchmark。此外，我们的私人医疗分类器不会在不同的民族群体中表现出更大的性差，与非私人模型相比。这个突破可以让机器学习实践者在敏感数据上安全地训练模型，保护个人隐私。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Transformer-Dynamics-as-Movement-through-Embedding-Space"><a href="#Analyzing-Transformer-Dynamics-as-Movement-through-Embedding-Space" class="headerlink" title="Analyzing Transformer Dynamics as Movement through Embedding Space"></a>Analyzing Transformer Dynamics as Movement through Embedding Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10874">http://arxiv.org/abs/2308.10874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumeet S. Singh</li>
<li>for: 本研究探讨了 transformer 语言模型的基本机制如何导致智能行为的出现。</li>
<li>methods: 我们采用系统方法分析 transformer 的具体机制，并开发了一个数学框架来解释它们的动态。这种新的视角提供了一个原则性的方法来思考问题，并且显示出了智能行为的出现的重要意义。</li>
<li>results: 研究发现，transformer 的核心是一个嵌入空间漫步者，将智能行为映射到嵌入空间中的路径上。每步漫步都会将上下文组合成一个单一的 composite vector，该 vector 的位置定义下一步的路径。无需学习，decode 只是一种嵌入空间中的漫步。知识、智能和技能都是嵌入空间中 vectors 的组织方式，而不是特定神经元或层。关注的贡献是对 vector 的组合Association-bias，但需要更多的研究来证明其重要性。transformer 的整体结构由两种基本操作组成：数据独立的滤波和数据依赖的聚合。这种一致性将 transformer 与其他序列模型和模式联系起来。<details>
<summary>Abstract</summary>
Transformer language models exhibit intelligent behaviors such as understanding natural language, recognizing patterns, acquiring knowledge, reasoning, planning, reflecting and using tools. This paper explores how their underlying mechanics give rise to intelligent behaviors. We adopt a systems approach to analyze Transformers in detail and develop a mathematical framework that frames their dynamics as movement through embedding space. This novel perspective provides a principled way of thinking about the problem and reveals important insights related to the emergence of intelligence:   1. At its core the Transformer is a Embedding Space walker, mapping intelligent behavior to trajectories in this vector space.   2. At each step of the walk, it composes context into a single composite vector whose location in Embedding Space defines the next step.   3. No learning actually occurs during decoding; in-context learning and generalization are simply the result of different contexts composing into different vectors.   4. Ultimately the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in Embedding Space rather than in specific neurons or layers. These abilities are properties of this organization.   5. Attention's contribution boils down to the association-bias it lends to vector composition and which influences the aforementioned organization. However, more investigation is needed to ascertain its significance.   6. The entire model is composed from two principal operations: data independent filtering and data dependent aggregation. This generalization unifies Transformers with other sequence models and across modalities.   Building upon this foundation we formalize and test a semantic space theory which posits that embedding vectors represent semantic concepts and find some evidence of its validity.
</details>
<details>
<summary>摘要</summary>
transformer 语言模型会示出智能行为，如理解自然语言、识别模式、获取知识、理解、规划和使用工具。这篇研究探索了 transformer 底下的机制如何导致智能行为。我们采用系统方法来分析 transformer 的细节，开发了一个数学框架，将 transformer 的动态视为嵌入空间中的运动。这个新的观点提供了一个原理式的思考方式，并显示出智能行为的出现有重要的意义：1. transformer 的核心是嵌入空间漫步者，将智能行为映射到嵌入空间中的路径上。2. 在每次漫步过程中，它会将上下文转换为单一的合成vector，其位于嵌入空间中的位置定义下一步的方向。3. 在解oding过程中，不会有真正的学习 occuring; 内在学习和泛化都是由不同的上下文对vector的聚合所带来的。4.  ultimately, the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in embedding space rather than in specific neurons or layers. these abilities are properties of this organization.5. attention 的贡献可以理解为对 vector 的聚合中带来的协议偏好，这影响了 embedding space 中 vectors 的组织。但是，需要进一步的研究，以了解它的重要性。6. transformer 的整个模型由两个主要操作组成：data independent filtering和data dependent aggregation。这个一致性使 transformer 与其他序列模型以及不同的模式之间建立了联系。基于这个基础，我们正式化了一个 semantic space 理论，提出 embedding vectors 代表 semantics concepts，并发现了一些证据支持这个理论的正确性。
</details></li>
</ul>
<hr>
<h2 id="Majorana-Demonstrator-Data-Release-for-AI-ML-Applications"><a href="#Majorana-Demonstrator-Data-Release-for-AI-ML-Applications" class="headerlink" title="Majorana Demonstrator Data Release for AI&#x2F;ML Applications"></a>Majorana Demonstrator Data Release for AI&#x2F;ML Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10856">http://arxiv.org/abs/2308.10856</a></li>
<li>repo_url: None</li>
<li>paper_authors: I. J. Arnquist, F. T. Avignone III, A. S. Barabash, C. J. Barton, K. H. Bhimani, E. Blalock, B. Bos, M. Busch, M. Buuck, T. S. Caldwell, Y. -D. Chan, C. D. Christofferson, P. -H. Chu, M. L. Clark, C. Cuesta, J. A. Detwiler, Yu. Efremenko, H. Ejiri, S. R. Elliott, N. Fuad, G. K. Giovanetti, M. P. Green, J. Gruszko, I. S. Guinn, V. E. Guiseppe, C. R. Haufe, R. Henning, D. Hervas Aguilar, E. W. Hoppe, A. Hostiuc, M. F. Kidd, I. Kim, R. T. Kouzes, T. E. Lannen V, A. Li, J. M. Lopez-Castano, R. D. Martin, R. Massarczyk, S. J. Meijer, S. Mertens, T. K. Oli, L. S. Paudel, W. Pettus, A. W. P. Poon, B. Quenallata, D. C. Radford, A. L. Reine, K. Rielage, N. W. Ruof, D. C. Schaper, S. J. Schleich, D. Tedeschi, R. L. Varner, S. Vasilyev, S. L. Watkins, J. F. Wilkerson, C. Wiseman, W. Xu, C. -H. Yu, B. X. Zhu</li>
<li>for: 本研究的目的是为了提供一个 Majorana 实验中的数据集，用于训练和测试人工智能和机器学习算法。</li>
<li>methods: 本研究使用了 Majorana 实验中的数据，包括 raw Germanium 探测器波形、激光形态分割cuts 和加工后的能量，共同存储在 HDF5 文件格式中，并附带相关的元数据。</li>
<li>results: 本研究提供了一个特定的数据集，用于支持人工智能和机器学习算法的训练和测试。<details>
<summary>Abstract</summary>
The enclosed data release consists of a subset of the calibration data from the Majorana Demonstrator experiment. Each Majorana event is accompanied by raw Germanium detector waveforms, pulse shape discrimination cuts, and calibrated final energies, all shared in an HDF5 file format along with relevant metadata. This release is specifically designed to support the training and testing of Artificial Intelligence (AI) and Machine Learning (ML) algorithms upon our data. This document is structured as follows. Section I provides an overview of the dataset's content and format; Section II outlines the location of this dataset and the method for accessing it; Section III presents the NPML Machine Learning Challenge associated with this dataset; Section IV contains a disclaimer from the Majorana collaboration regarding the use of this dataset; Appendix A contains technical details of this data release. Please direct questions about the material provided within this release to liaobo77@ucsd.edu (A. Li).
</details>
<details>
<summary>摘要</summary>
<<SYS>>将附件的数据发布包括 Majorana实验中的一个子集调整数据。每个 Majorana 事件都由 raw 氙元器波形、激发形分割 cuts 和调整后的能量， alles 共享在 HDF5 文件格式中，并附带相关的元数据。这个发布是为支持人工智能（AI）和机器学习（ML）算法的训练和测试而设计的。本文分为以下四部分：I. 数据集的内容和格式的概述II. 数据集的位置和访问方法III. NPML 机器学习挑战与这个数据集相关IV. Majorana 团队的免责声明 appendix A. 数据发布的技术详细信息请对这个发布中的内容向 liaobo77@ucsd.edu (A. Li) 提出问题。>>Note: "Majorana" in the text should be translated as "抗随机扰动器" (anti-random noise device) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-quantum-generative-models-via-imbalanced-data-classification-benchmarks"><a href="#Evaluating-quantum-generative-models-via-imbalanced-data-classification-benchmarks" class="headerlink" title="Evaluating quantum generative models via imbalanced data classification benchmarks"></a>Evaluating quantum generative models via imbalanced data classification benchmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10847">http://arxiv.org/abs/2308.10847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Graham R. Enos, Matthew J. Reagor, Eric Hulburd</li>
<li>for: 这个论文是为了研究量子机器学习模型的不同行为是否与传统模型不同，并在实际数据集上进行系统性的分析。</li>
<li>methods: 这个论文使用可解释人工智能技术来分析从混合量子-классификаル нейрон网络中生成的数据，并对这些数据进行比较与当前的 Mitigating 方法。</li>
<li>results: 研究发现，不同的数据集 exhibits varying degrees of complexity and class imbalance，并且可以使用 hybrid 量子-классификаル生成模型来分析这些数据。这些结果可以帮助我们理解哪些问题是可以使用 hybrid 模型解决，哪些问题则需要更多的研究。<details>
<summary>Abstract</summary>
A limited set of tools exist for assessing whether the behavior of quantum machine learning models diverges from conventional models, outside of abstract or theoretical settings. We present a systematic application of explainable artificial intelligence techniques to analyze synthetic data generated from a hybrid quantum-classical neural network adapted from twenty different real-world data sets, including solar flares, cardiac arrhythmia, and speech data. Each of these data sets exhibits varying degrees of complexity and class imbalance. We benchmark the quantum-generated data relative to state-of-the-art methods for mitigating class imbalance for associated classification tasks. We leverage this approach to elucidate the qualities of a problem that make it more or less likely to be amenable to a hybrid quantum-classical generative model.
</details>
<details>
<summary>摘要</summary>
有限的工具存在，用于判断量子机器学习模型与传统模型之间的行为异同，除了抽象或理论上的设置。我们将可追踪的人工智能技术系统化应用于生成从混合量子-классификаLL大 neural network中的 synthetic数据，该数据来自20个真实世界数据集，包括太阳风暴、心脏 arrhythmia 和语音数据。每个数据集都具有不同的复杂度和类别偏好。我们将量子生成的数据与当前的状态艺术方法进行比较，以mitigate class imbalance相关的分类任务。我们利用这种方法，以便描述一个问题的特点，使其更或 menos适合混合量子-классификаLL生成模型。
</details></li>
</ul>
<hr>
<h2 id="Real-World-Time-Series-Benchmark-Datasets-with-Distribution-Shifts-Global-Crude-Oil-Price-and-Volatility"><a href="#Real-World-Time-Series-Benchmark-Datasets-with-Distribution-Shifts-Global-Crude-Oil-Price-and-Volatility" class="headerlink" title="Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility"></a>Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10846">http://arxiv.org/abs/2308.10846</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oilpricebenchmarks/COB">https://github.com/oilpricebenchmarks/COB</a></li>
<li>paper_authors: Pranay Pasula</li>
<li>for: 这个论文旨在提供一个适用于金融领域的时间序列benchmark，以促进持续学习的进步。</li>
<li>methods: 该论文使用了asset price数据的转换方法，并使用了期望最大化（EM）方法来适应模型。</li>
<li>results: 论文通过生成相关的任务标签，以及对四种持续学习算法的比较，证明了这些benchmark的有效性。<details>
<summary>Abstract</summary>
The scarcity of task-labeled time-series benchmarks in the financial domain hinders progress in continual learning. Addressing this deficit would foster innovation in this area. Therefore, we present COB, Crude Oil Benchmark datasets. COB includes 30 years of asset prices that exhibit significant distribution shifts and optimally generates corresponding task (i.e., regime) labels based on these distribution shifts for the three most important crude oils in the world. Our contributions include creating real-world benchmark datasets by transforming asset price data into volatility proxies, fitting models using expectation-maximization (EM), generating contextual task labels that align with real-world events, and providing these labels as well as the general algorithm to the public. We show that the inclusion of these task labels universally improves performance on four continual learning algorithms, some state-of-the-art, over multiple forecasting horizons. We hope these benchmarks accelerate research in handling distribution shifts in real-world data, especially due to the global importance of the assets considered. We've made the (1) raw price data, (2) task labels generated by our approach, (3) and code for our algorithm available at https://oilpricebenchmarks.github.io.
</details>
<details>
<summary>摘要</summary>
“财经领域内的任务标签时间序列库 scarcity 阻碍了无终学习的进步。解决这个不足，将促进这个领域的创新。因此，我们提出了 COB，即原油价格库存数据。COB 包含了30年的资产价格，其中具有明显的分布迁移，并且根据这些分布迁移生成对应的任务（即频率）标签。我们的贡献包括将资产价格数据转换为可用性干扰量表现，使用期望最大化（EM）运算进行模型适应，生成基于实际世界事件的任务标签，并且将这些标签以及通用的算法公开给社区。我们显示，将这些任务标签包含在内，可以在多个预测时间点上 universally 提高四种不断学习算法的性能，其中一些是现有的State-of-the-art。我们希望这些库可以促进实际数据中的分布迁移处理研究，尤其是由于考虑到资产考虑的全球重要性。我们将（1）原始价格数据、（2）生成的任务标签、以及（3）实现这种算法的代码公开在https://oilpricebenchmarks.github.io。”
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-Optimizations-Against-Concept-and-Data-Drift-in-Malware-Detection"><a href="#Neural-Networks-Optimizations-Against-Concept-and-Data-Drift-in-Malware-Detection" class="headerlink" title="Neural Networks Optimizations Against Concept and Data Drift in Malware Detection"></a>Neural Networks Optimizations Against Concept and Data Drift in Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10821">http://arxiv.org/abs/2308.10821</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Maillet, Benjamin Marais</li>
<li>for: 提高基eline神经网络对抗演化漏斗问题</li>
<li>methods: 提出了一种模型无关协议，包括特征减少和使用最新验证集训练，并提出了一种适应退化损失函数 named Drift-Resilient Binary Cross-Entropy</li>
<li>results: 对EMBER数据集（2018）进行训练，对2020-2023年间的恶意文件进行评估，提高了15.2%的恶意软件检测率<details>
<summary>Abstract</summary>
Despite the promising results of machine learning models in malware detection, they face the problem of concept drift due to malware constant evolution. This leads to a decline in performance over time, as the data distribution of the new files differs from the training one, requiring regular model update. In this work, we propose a model-agnostic protocol to improve a baseline neural network to handle with the drift problem. We show the importance of feature reduction and training with the most recent validation set possible, and propose a loss function named Drift-Resilient Binary Cross-Entropy, an improvement to the classical Binary Cross-Entropy more effective against drift. We train our model on the EMBER dataset (2018) and evaluate it on a dataset of recent malicious files, collected between 2020 and 2023. Our improved model shows promising results, detecting 15.2% more malware than a baseline model.
</details>
<details>
<summary>摘要</summary>
尽管机器学习模型在恶意软件检测方面表现良好，但它们面临着概念漂移问题，即恶意软件不断演化导致模型性能逐渐下降。这是因为新的文件数据分布与训练数据分布不同，需要定期更新模型。在这种情况下，我们提出了一种模型无关协议，用于改进基eline neural network，以适应概念漂移问题。我们表明了特征减少和使用最新的验证集进行训练的重要性，并提出了一种名为漂移抗耐 binary cross-entropy 的损失函数，它在对漂移问题更有效。我们使用 EMBER 数据集（2018）进行训练，并对2020-2023年间收集的恶意文件进行评估。我们改进后的模型表现出色，可以检测到基eline模型无法检测到的15.2%更多的恶意软件。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/cs.LG_2023_08_22/" data-id="clm0t8e0k007ev788c971608s" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/22/cs.CV_2023_08_22/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-08-22 21:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/22/cs.SD_2023_08_22/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-22 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
