
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-24 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Easy attention: A simple self-attention mechanism for Transformers paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12874 repo_url: None paper_authors: Marcial Sanchis-Agudo, Yuning Wang, Karthik Duraisamy, Ricar">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-24">
<meta property="og:url" content="http://nullscc.github.io/2023/08/24/cs.LG_2023_08_24/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Easy attention: A simple self-attention mechanism for Transformers paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12874 repo_url: None paper_authors: Marcial Sanchis-Agudo, Yuning Wang, Karthik Duraisamy, Ricar">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-23T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-25T19:46:18.400Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Fun Paper" type="application/atom+xml">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
      <a class="main-nav-link st-search-show-outputs">Search</a>
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.LG_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-24
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Easy-attention-A-simple-self-attention-mechanism-for-Transformers"><a href="#Easy-attention-A-simple-self-attention-mechanism-for-Transformers" class="headerlink" title="Easy attention: A simple self-attention mechanism for Transformers"></a>Easy attention: A simple self-attention mechanism for Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12874">http://arxiv.org/abs/2308.12874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcial Sanchis-Agudo, Yuning Wang, Karthik Duraisamy, Ricardo Vinuesa</li>
<li>for: 预测混沌系统的时间动态特性</li>
<li>methods: 提议一种名为“易注意”的注意机制，通过对软MAX的特征值分解来更好地捕捉长期相关性</li>
<li>results: 与自注意和LSTM网络相比，该方法具有更高的稳定性和较低的复杂性，并且在重建和预测混沌系统的时间动态特性方面获得了优秀的结果<details>
<summary>Abstract</summary>
To improve the robustness of transformer neural networks used for temporal-dynamics prediction of chaotic systems, we propose a novel attention mechanism called easy attention. Due to the fact that self attention only makes usage of the inner product of queries and keys, it is demonstrated that the keys, queries and softmax are not necessary for obtaining the attention score required to capture long-term dependencies in temporal sequences. Through implementing singular-value decomposition (SVD) on the softmax attention score, we further observe that the self attention compresses contribution from both queries and keys in the spanned space of the attention score. Therefore, our proposed easy-attention method directly treats the attention scores as learnable parameters. This approach produces excellent results when reconstructing and predicting the temporal dynamics of chaotic systems exhibiting more robustness and less complexity than the self attention or the widely-used long short-term memory (LSTM) network. Our results show great potential for applications in more complex high-dimensional dynamical systems.
</details>
<details>
<summary>摘要</summary>
要提高转换器神经网络在时间动力学预测混沌系统的稳定性，我们提议一种新的注意力机制called「容易注意」。由于自注意只使用内积Query和Key，所以我们发现键、Query和软MAX不是必需的来获取注意力分数，以 capture长期依赖关系在时间序列中。通过对软MAX注意力分数进行特征值分解（SVD），我们还发现自注意力压缩从Query和Key在注意力分数的核心空间中的贡献。因此，我们的提议的「容易注意」方法直接将注意力分数作为学习参数。这种方法在重建和预测混沌系统的时间动力学中表现出色，比自注意或广泛使用的长期短期记忆（LSTM）网络更加稳定和简洁。我们的结果表明这种方法在更复杂的高维动力系统中具有潜在的应用前景。
</details></li>
</ul>
<hr>
<h2 id="IPA-Inference-Pipeline-Adaptation-to-Achieve-High-Accuracy-and-Cost-Efficiency"><a href="#IPA-Inference-Pipeline-Adaptation-to-Achieve-High-Accuracy-and-Cost-Efficiency" class="headerlink" title="IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency"></a>IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12871">http://arxiv.org/abs/2308.12871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeid Ghafouri, Kamran Razavi, Mehran Salmani, Alireza Sanaee, Tania Lorido-Botran, Lin Wang, Joseph Doyle, Pooyan Jamshidi</li>
<li>for: 提高深度学习推理系统的快速、准确和Cost-effective推理</li>
<li>methods: 使用Integer Programming动态配置批处理大小、复制和模型变体，以优化准确率、降低成本并满足用户定义的响应时间SLAs</li>
<li>results: 在Kubernetes实现上，对五个实际推理管道进行了广泛的实验，发现IPA可以提高normalized准确率达35%，而成本增加仅为5%以下。<details>
<summary>Abstract</summary>
Efficiently optimizing multi-model inference pipelines for fast, accurate, and cost-effective inference is a crucial challenge in ML production systems, given their tight end-to-end latency requirements. To simplify the exploration of the vast and intricate trade-off space of accuracy and cost in inference pipelines, providers frequently opt to consider one of them. However, the challenge lies in reconciling accuracy and cost trade-offs. To address this challenge and propose a solution to efficiently manage model variants in inference pipelines, we present IPA, an online deep-learning Inference Pipeline Adaptation system that efficiently leverages model variants for each deep learning task. Model variants are different versions of pre-trained models for the same deep learning task with variations in resource requirements, latency, and accuracy. IPA dynamically configures batch size, replication, and model variants to optimize accuracy, minimize costs, and meet user-defined latency SLAs using Integer Programming. It supports multi-objective settings for achieving different trade-offs between accuracy and cost objectives while remaining adaptable to varying workloads and dynamic traffic patterns. Extensive experiments on a Kubernetes implementation with five real-world inference pipelines demonstrate that IPA improves normalized accuracy by up to 35% with a minimal cost increase of less than 5%.
</details>
<details>
<summary>摘要</summary>
efficiently 优化多模型推理管道是 ML 生产系统中关键的挑战，以实现快速、准确、cost-effective 的推理。为了简化推理管道中精度和成本费用之间的质量和成本费用的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用之间的质量和成本费用
</details></li>
</ul>
<hr>
<h2 id="Auto-weighted-Bayesian-Physics-Informed-Neural-Networks-and-robust-estimations-for-multitask-inverse-problems-in-pore-scale-imaging-of-dissolution"><a href="#Auto-weighted-Bayesian-Physics-Informed-Neural-Networks-and-robust-estimations-for-multitask-inverse-problems-in-pore-scale-imaging-of-dissolution" class="headerlink" title="Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution"></a>Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12864">http://arxiv.org/abs/2308.12864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarah Perez, Philippe Poncet<br>for:这种新的数据融合策略可以帮助解决涉及不确定性评估的反应 inverse 问题，并提供可靠的减噪计算方法。methods:这种方法基于多任务形式的反应 inverse 问题，结合数据驱动和物理驱动技术，以评估气体扩散和氯化物溶解的反应过程。results:这种方法可以提供可靠的 uncertainty 评估和反应参数范围的估计，并在1D+时和2D+时calcite dissolution中进行成功的 bayesian 推理。<details>
<summary>Abstract</summary>
In this article, we present a novel data assimilation strategy in pore-scale imaging and demonstrate that this makes it possible to robustly address reactive inverse problems incorporating Uncertainty Quantification (UQ). Pore-scale modeling of reactive flow offers a valuable opportunity to investigate the evolution of macro-scale properties subject to dynamic processes. Yet, they suffer from imaging limitations arising from the associated X-ray microtomography (X-ray microCT) process, which induces discrepancies in the properties estimates. Assessment of the kinetic parameters also raises challenges, as reactive coefficients are critical parameters that can cover a wide range of values. We account for these two issues and ensure reliable calibration of pore-scale modeling, based on dynamical microCT images, by integrating uncertainty quantification in the workflow.   The present method is based on a multitasking formulation of reactive inverse problems combining data-driven and physics-informed techniques in calcite dissolution. This allows quantifying morphological uncertainties on the porosity field and estimating reactive parameter ranges through prescribed PDE models with a latent concentration field and dynamical microCT. The data assimilation strategy relies on sequential reinforcement incorporating successively additional PDE constraints. We guarantee robust and unbiased uncertainty quantification by straightforward adaptive weighting of Bayesian Physics-Informed Neural Networks (BPINNs), ensuring reliable micro-porosity changes during geochemical transformations. We demonstrate successful Bayesian Inference in 1D+Time and 2D+Time calcite dissolution based on synthetic microCT images with meaningful posterior distribution on the reactive parameters and dimensionless numbers.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们介绍了一种新的数据融合策略在粒度图像中，并证明这使得可以坚定地解决包含不确定性评估（UQ）的反应反问题。粒度图像模拟的反应流动提供了可观察的大规模特性的演化，但受到X射微 Tomatoes图像过程的限制，导致属性估计存在偏差。评估反应参数也存在挑战，因为反应系数可以覆盖广泛的值范围。我们考虑了这两个问题，并确保了粒度图像模拟的可靠校准，基于动态微 Tomatoes图像。我们的方法基于反应反问题的多任务形式，结合数据驱动和物理驱动技术，在氯酸硅酸盐解析中实现。这允许评估 morphological uncertainty 在porosity field 上，并估算反应参数范围通过隐藏 концентрация场和动态微 Tomatoes图像。数据融合策略基于顺序强制，并在每个循环中添加更多的PDE约束。我们 garantía robust 和无偏评估，通过简单的适应权重 Bayesian Physics-Informed Neural Networks (BPINNs)，确保微软� Porosity 变化在地化学转化过程中可靠。我们在1D+Time和2D+Time氯酸硅酸盐解析中成功完成 bayesian inference，并得到了 meaningful posterior distribution 上的反应参数和约束数。
</details></li>
</ul>
<hr>
<h2 id="Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture"><a href="#Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture" class="headerlink" title="Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture"></a>Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12859">http://arxiv.org/abs/2308.12859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuheng Wang, Juan Ye, David L. Borchers</li>
<li>for: 监测野生动物人口，特别是难以视见的动物。</li>
<li>methods: 使用机器学习方法进行 vocals 识别，并将各个发声的特征纳入捕捉识别。</li>
<li>results: 比 tradicional 方法更准确地捕捉野生动物人口，并且可以考虑发声特征的不确定性。<details>
<summary>Abstract</summary>
Passive acoustic monitoring can be an effective way of monitoring wildlife populations that are acoustically active but difficult to survey visually. Digital recorders allow surveyors to gather large volumes of data at low cost, but identifying target species vocalisations in these data is non-trivial. Machine learning (ML) methods are often used to do the identification. They can process large volumes of data quickly, but they do not detect all vocalisations and they do generate some false positives (vocalisations that are not from the target species). Existing wildlife abundance survey methods have been designed specifically to deal with the first of these mistakes, but current methods of dealing with false positives are not well-developed. They do not take account of features of individual vocalisations, some of which are more likely to be false positives than others. We propose three methods for acoustic spatial capture-recapture inference that integrate individual-level measures of confidence from ML vocalisation identification into the likelihood and hence integrate ML uncertainty into inference. The methods include a mixture model in which species identity is a latent variable. We test the methods by simulation and find that in a scenario based on acoustic data from Hainan gibbons, in which ignoring false positives results in 17% positive bias, our methods give negligible bias and coverage probabilities that are close to the nominal 95% level.
</details>
<details>
<summary>摘要</summary>
Passive acoustic monitoring可以是有效的监测野生动物人口，因为这些动物可能是视觉上难以观察的。数字录音器allsow surveyors to gather大量数据at low cost，但是寻找目标种 vocalizations在这些数据中是非常困难的。机器学习（ML）方法经常用于进行识别。它们可以快速处理大量数据，但是它们不会检测所有的 vocalizations，而且会出现一些假阳性（不是目标种的 vocalizations）。现有的野生生物资源量评估方法已经特意设计来处理第一种错误，但是现有的方法并不是很好地处理假阳性。它们没有考虑个体 vocalizations 的特征，一些这些特征更可能是假阳性的。我们提议三种静音空间捕捉-重复检测方法，这些方法会将机器学习确定性测试结果 integrate 到概率中，因此可以 integrate 机器学习的不确定性到推断中。这些方法包括一种混合模型，在这种模型中，种类标识是隐藏变量。我们通过模拟测试了这些方法，在基于海南 Gibbon 的声音数据场景中，如果忽略假阳性，则有17%的正确率偏差，而我们的方法则没有偏差，并且涵 coverage probabilities 接近 Nominal 95% 水平。
</details></li>
</ul>
<hr>
<h2 id="Fast-Adversarial-Training-with-Smooth-Convergence"><a href="#Fast-Adversarial-Training-with-Smooth-Convergence" class="headerlink" title="Fast Adversarial Training with Smooth Convergence"></a>Fast Adversarial Training with Smooth Convergence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12857">http://arxiv.org/abs/2308.12857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fat-cs/convergesmooth">https://github.com/fat-cs/convergesmooth</a></li>
<li>paper_authors: Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin</li>
<li>for: 提高神经网络的攻击强度 robustness</li>
<li>methods: 提出了一种新的振荡约束（ConvergeSmooth），以保证训练过程的稳定和平滑，从而避免极端过拟合问题。</li>
<li>results: 经过EXTENSIVE EXPERIMENTS ON POPULAR DATASETS的测试，提出的方法能够高效地避免极端过拟合问题，并且超过所有之前的FAT方法的性能。<details>
<summary>Abstract</summary>
Fast adversarial training (FAT) is beneficial for improving the adversarial robustness of neural networks. However, previous FAT work has encountered a significant issue known as catastrophic overfitting when dealing with large perturbation budgets, \ie the adversarial robustness of models declines to near zero during training.   To address this, we analyze the training process of prior FAT work and observe that catastrophic overfitting is accompanied by the appearance of loss convergence outliers.   Therefore, we argue a moderately smooth loss convergence process will be a stable FAT process that solves catastrophic overfitting.   To obtain a smooth loss convergence process, we propose a novel oscillatory constraint (dubbed ConvergeSmooth) to limit the loss difference between adjacent epochs. The convergence stride of ConvergeSmooth is introduced to balance convergence and smoothing. Likewise, we design weight centralization without introducing additional hyperparameters other than the loss balance coefficient.   Our proposed methods are attack-agnostic and thus can improve the training stability of various FAT techniques.   Extensive experiments on popular datasets show that the proposed methods efficiently avoid catastrophic overfitting and outperform all previous FAT methods. Code is available at \url{https://github.com/FAT-CS/ConvergeSmooth}.
</details>
<details>
<summary>摘要</summary>
快速对抗训练（FAT）可以提高神经网络的对抗性。然而，先前的FAT工作遇到了一个重要的问题，即灾难性过拟合，即在训练过程中模型的对抗性下降到接近零。  为了解决这个问题，我们分析了过去的FAT工作训练过程，发现灾难性过拟合与搅拌值异常强相关。因此，我们认为一个 moderadamente suave proceso de convergencia de pérdida（dubbed ConvergeSmooth）可以使FAT过程更加稳定，并解决灾难性过拟合。  为了获得一个 suave proceso de convergencia de pérdida，我们提出了一种新的振荡约束（dubbed ConvergeSmooth），用于限制连续两个步骤之间的搅拌值差。抽象层中的权重归一化也是在搅拌值差的平衡下实现的。  我们提出的方法是对抗性的，可以改善各种FAT技术的训练稳定性。  我们进行了广泛的实验，发现我们的方法可以有效避免灾难性过拟合，并在各种 популяр的数据集上超越所有之前的FAT方法。代码可以在 \url{https://github.com/FAT-CS/ConvergeSmooth} 上找到。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-load-forecasting-with-Reservoir-Computing"><a href="#Probabilistic-load-forecasting-with-Reservoir-Computing" class="headerlink" title="Probabilistic load forecasting with Reservoir Computing"></a>Probabilistic load forecasting with Reservoir Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12844">http://arxiv.org/abs/2308.12844</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MicheleUIT/Probabilistic-load-forecasting-with-Reservoir-Computing">https://github.com/MicheleUIT/Probabilistic-load-forecasting-with-Reservoir-Computing</a></li>
<li>paper_authors: Michele Guerra, Simone Scardapane, Filippo Maria Bianchi</li>
<li>for: 预测电力负荷的准确性和不确定性评估</li>
<li>methods: 使用批量计算机efficiently forecasting time series, 并evaluate uncertainty quantification methods的compatibility and performance</li>
<li>results: 对电力负荷预测的点预测和不确定性评估, 比较不同方法的预测准确性、计算资源效率和不确定性评估结果<details>
<summary>Abstract</summary>
Some applications of deep learning require not only to provide accurate results but also to quantify the amount of confidence in their prediction. The management of an electric power grid is one of these cases: to avoid risky scenarios, decision-makers need both precise and reliable forecasts of, for example, power loads. For this reason, point forecasts are not enough hence it is necessary to adopt methods that provide an uncertainty quantification.   This work focuses on reservoir computing as the core time series forecasting method, due to its computational efficiency and effectiveness in predicting time series. While the RC literature mostly focused on point forecasting, this work explores the compatibility of some popular uncertainty quantification methods with the reservoir setting. Both Bayesian and deterministic approaches to uncertainty assessment are evaluated and compared in terms of their prediction accuracy, computational resource efficiency and reliability of the estimated uncertainty, based on a set of carefully chosen performance metrics.
</details>
<details>
<summary>摘要</summary>
某些深度学习应用需要不仅提供准确的结果，还需要衡量预测结果的置信度。电力系统管理是其中一个案例：为了避免危险情况，决策者需要准确且可靠地预测电力负荷。因此，点预测不 enough，需要采用能够衡量置信度的方法。这项工作将 rezolver computing 作为时间序列预测方法，因为它的计算效率高和预测时间序列的能力强。而 RC 文献中大多数关注点预测，这项工作将考虑rezolver setting中的一些流行的置信度评估方法的 compatibilty。两种bayesian和deterministic approaches to uncertainty assessment 都会被评估和比较，以确定它们在预测精度、计算资源效率和置信度估计的可靠性方面的表现，根据一组仔细选择的性能指标。
</details></li>
</ul>
<hr>
<h2 id="Actuator-Trajectory-Planning-for-UAVs-with-Overhead-Manipulator-using-Reinforcement-Learning"><a href="#Actuator-Trajectory-Planning-for-UAVs-with-Overhead-Manipulator-using-Reinforcement-Learning" class="headerlink" title="Actuator Trajectory Planning for UAVs with Overhead Manipulator using Reinforcement Learning"></a>Actuator Trajectory Planning for UAVs with Overhead Manipulator using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12843">http://arxiv.org/abs/2308.12843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hazim Alzorgan, Abolfazl Razi, Ata Jahangir Moshayedi</li>
<li>For: The paper is written for the purpose of developing a control mechanism for an aerial manipulator system, specifically a UAV with a controllable arm, to perform actuation tasks in hard-to-reach and risky environments.* Methods: The paper employs a Q-learning method to control the trajectory of the tip of the arm (end-effector), and develops a motion planning model based on Time To Collision (TTC) to navigate around obstacles while ensuring the manipulator’s reachability. Additionally, the paper utilizes a model-based Q-learning model to independently track and control the desired trajectory of the manipulator’s end-effector.* Results: The paper achieves 92% accuracy in terms of average displacement error (i.e. the mean distance between the target and obtained trajectory points) using Q-learning with 15,000 episodes.Here are the three key information points in Simplified Chinese text:* For: 本文是为了开发一种用于空中抓取系统（即无人飞行器（UAV）配备可控的机械臂）来执行困难环境中的 actuation 任务而写的。* Methods: 本文使用 Q-学习方法控制机械臂的投影（end-effector）的轨迹，并开发基于 Time To Collision (TTC) 的动态规划模型以避免障碍物并确保抓取系统的可访问性。此外，本文还利用基于模型的 Q-学习模型独立地跟踪和控制抓取系统的结束效果的欲要轨迹。* Results: 本文使用 Q-学习方法，在15,000集 Episodes 中实现了92%的均方差误差（即目标轨迹点与实际轨迹点之间的平均距离）。<details>
<summary>Abstract</summary>
In this paper, we investigate the operation of an aerial manipulator system, namely an Unmanned Aerial Vehicle (UAV) equipped with a controllable arm with two degrees of freedom to carry out actuation tasks on the fly. Our solution is based on employing a Q-learning method to control the trajectory of the tip of the arm, also called \textit{end-effector}. More specifically, we develop a motion planning model based on Time To Collision (TTC), which enables a quadrotor UAV to navigate around obstacles while ensuring the manipulator's reachability. Additionally, we utilize a model-based Q-learning model to independently track and control the desired trajectory of the manipulator's end-effector, given an arbitrary baseline trajectory for the UAV platform. Such a combination enables a variety of actuation tasks such as high-altitude welding, structural monitoring and repair, battery replacement, gutter cleaning, sky scrapper cleaning, and power line maintenance in hard-to-reach and risky environments while retaining compatibility with flight control firmware. Our RL-based control mechanism results in a robust control strategy that can handle uncertainties in the motion of the UAV, offering promising performance. Specifically, our method achieves 92\% accuracy in terms of average displacement error (i.e. the mean distance between the target and obtained trajectory points) using Q-learning with 15,000 episodes
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了一种天空 manipulate系统，即一架有控制可能的无人飞行器（UAV） equipped with a controllable arm with two degrees of freedom，用于实施 actuation 任务在飞行过程中。我们的解决方案基于采用 Q-学习方法控制 manipulate 系统的末端效应器（end-effector）的 trajectory。更 specifically，我们开发了一种基于 Time To Collision（TTC）的动态规划模型，使得一架quadrotor UAV可以在避免碰撞的情况下环绕障碍物进行航行。此外，我们利用一种基于模型的 Q-学习模型独立地跟踪和控制 manipulate 系统的末端效应器的 Desired Trajectory，对于 UAV 平台的任意基线轨迹。这种组合允许实现高空焊接、结构监测和维护、电池更换、射雾扫描、高层建筑清扫和电缆维护等 actuation 任务，而且保留与飞行控制软件的兼容性。我们的 RL-based 控制机制实现了一种稳定的控制策略，可以处理 UAV 的运动不确定性，提供了有前途的表现。具体来说，我们的方法实现了 92% 的平均偏移误差（即target和实际轨迹点之间的平均距离），使用 Q-学习的 15000 集 episode。
</details></li>
</ul>
<hr>
<h2 id="Prediction-without-Preclusion-Recourse-Verification-with-Reachable-Sets"><a href="#Prediction-without-Preclusion-Recourse-Verification-with-Reachable-Sets" class="headerlink" title="Prediction without Preclusion: Recourse Verification with Reachable Sets"></a>Prediction without Preclusion: Recourse Verification with Reachable Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12820">http://arxiv.org/abs/2308.12820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avni Kothari, Bogdan Kulynych, Tsui-Wei Weng, Berk Ustun</li>
<li>for: 这个论文目的是提出一种官方测试程序，用于检查机器学习模型是否具有修复功能，以确保模型的预测结果不会永久锁定用户。</li>
<li>methods: 这个论文使用了一种新的测试方法，可以确定模型是否具有修复功能，并且可以在用户指定的行动可能性范围内确定模型的修复能力。</li>
<li>results: 研究人员使用了这种测试方法，对实际数据集进行了测试，并发现了一些现实世界中的借款模型可能会永久锁定用户的问题。这些结果表明，在开发机器学习模型时，需要考虑行动可能性，以确保模型的预测结果不会永久锁定用户。<details>
<summary>Abstract</summary>
Machine learning models are often used to decide who will receive a loan, a job interview, or a public benefit. Standard techniques to build these models use features about people but overlook their actionability. In turn, models can assign predictions that are fixed, meaning that consumers who are denied loans, interviews, or benefits may be permanently locked out from access to credit, employment, or assistance. In this work, we introduce a formal testing procedure to flag models that assign fixed predictions that we call recourse verification. We develop machinery to reliably determine if a given model can provide recourse to its decision subjects from a set of user-specified actionability constraints. We demonstrate how our tools can ensure recourse and adversarial robustness in real-world datasets and use them to study the infeasibility of recourse in real-world lending datasets. Our results highlight how models can inadvertently assign fixed predictions that permanently bar access, and we provide tools to design algorithms that account for actionability when developing models.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "actionability" is translated as "可行性" (kěxíngxìng) in Simplified Chinese, which means "feasibility" or "ability to take action".* "recourse" is translated as "征求" (chèngqǐ) in Simplified Chinese, which means "to seek" or "to request".* "adversarial robustness" is translated as "对抗强度" (duìkòng qiángdé) in Simplified Chinese, which means "robustness against adversarial attacks".
</details></li>
</ul>
<hr>
<h2 id="Single-shot-Bayesian-approximation-for-neural-networks"><a href="#Single-shot-Bayesian-approximation-for-neural-networks" class="headerlink" title="Single-shot Bayesian approximation for neural networks"></a>Single-shot Bayesian approximation for neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12785">http://arxiv.org/abs/2308.12785</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kaibrach/Moment-Propagation">https://github.com/kaibrach/Moment-Propagation</a></li>
<li>paper_authors: Kai Brach, Beate Sick, Oliver Dürr</li>
<li>for: 这种论文主要针对的是深度神经网络（NN）的预测性能和不确定性问题。</li>
<li>methods: 这种论文使用了蒙те Carlo（MC）掉dropout方法来提供不确定性度量，同时提高预测性能。但MC掉dropout方法的缺点是在测试时需要更长的计算时间。这种论文提出了一种单射MC掉dropout近似方法，可以快速地提供BNNs的预测性能和不确定性度量。</li>
<li>results: 该论文在不同的 benchmark 数据集和一个 simulate 的例子中进行了分类和回归任务的评估。结果表明，该单射MC掉dropout近似方法可以快速地提供BNNs的预测性能和不确定性度量，并且与MC掉dropout方法的点估值和不确定性度量相似。此外，使用部分积累的时间和深度ensemble技术可以进一步改善不确定性度量。<details>
<summary>Abstract</summary>
Deep neural networks (NNs) are known for their high-prediction performances. However, NNs are prone to yield unreliable predictions when encountering completely new situations without indicating their uncertainty. Bayesian variants of NNs (BNNs), such as Monte Carlo (MC) dropout BNNs, do provide uncertainty measures and simultaneously increase the prediction performance. The only disadvantage of BNNs is their higher computation time during test time because they rely on a sampling approach. Here we present a single-shot MC dropout approximation that preserves the advantages of BNNs while being as fast as NNs. Our approach is based on moment propagation (MP) and allows to analytically approximate the expected value and the variance of the MC dropout signal for commonly used layers in NNs, i.e. convolution, max pooling, dense, softmax, and dropout layers. The MP approach can convert an NN into a BNN without re-training given the NN has been trained with standard dropout. We evaluate our approach on different benchmark datasets and a simulated toy example in a classification and regression setting. We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs. We show that using part of the saved time to combine our MP approach with deep ensemble techniques does further improve the uncertainty measures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Intentionally-underestimated-Value-Function-at-Terminal-State-for-Temporal-difference-Learning-with-Mis-designed-Reward"><a href="#Intentionally-underestimated-Value-Function-at-Terminal-State-for-Temporal-difference-Learning-with-Mis-designed-Reward" class="headerlink" title="Intentionally-underestimated Value Function at Terminal State for Temporal-difference Learning with Mis-designed Reward"></a>Intentionally-underestimated Value Function at Terminal State for Temporal-difference Learning with Mis-designed Reward</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12772">http://arxiv.org/abs/2308.12772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taisuke Kobayashi</li>
<li>for:  solves the problem of unintentional overestimation in TD learning when an episode is terminated due to task failure.</li>
<li>methods:  proposes a method to intentionally underestimate the value after termination, adjusting the degree of underestimation based on the degree of stationarity at termination.</li>
<li>results:  the proposed method can stably obtain the optimal policies for various tasks and reward designs through simulations and real robot experiments.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究强调解决了TD学习在 episoden 结束时出现的不Intentional overestimation 问题，即在 terminate 时强制设置值为零，导致不Intentional 的下降或上涨，具体取决于奖励设计。</li>
<li>methods: 本研究提出了一种意外下降的方法，根据 terminate 时的 stationarity 度进行调整。</li>
<li>results: 通过实验和真实机器人实验，提出的方法可以稳定地获得不同任务和奖励设计的优化策略。<details>
<summary>Abstract</summary>
Robot control using reinforcement learning has become popular, but its learning process generally terminates halfway through an episode for safety and time-saving reasons. This study addresses the problem of the most popular exception handling that temporal-difference (TD) learning performs at such termination. That is, by forcibly assuming zero value after termination, unintentionally implicit underestimation or overestimation occurs, depending on the reward design in the normal states. When the episode is terminated due to task failure, the failure may be highly valued with the unintentional overestimation, and the wrong policy may be acquired. Although this problem can be avoided by paying attention to the reward design, it is essential in practical use of TD learning to review the exception handling at termination. This paper therefore proposes a method to intentionally underestimate the value after termination to avoid learning failures due to the unintentional overestimation. In addition, the degree of underestimation is adjusted according to the degree of stationarity at termination, thereby preventing excessive exploration due to the intentional underestimation. Simulations and real robot experiments showed that the proposed method can stably obtain the optimal policies for various tasks and reward designs. https://youtu.be/AxXr8uFOe7M
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Consistency-of-Average-Embeddings-for-Item-Recommendation"><a href="#On-the-Consistency-of-Average-Embeddings-for-Item-Recommendation" class="headerlink" title="On the Consistency of Average Embeddings for Item Recommendation"></a>On the Consistency of Average Embeddings for Item Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12767">http://arxiv.org/abs/2308.12767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deezer/consistency">https://github.com/deezer/consistency</a></li>
<li>paper_authors: Walid Bendada, Guillaume Salha-Galvan, Romain Hennequin, Thomas Bouabça, Tristan Cazenave</li>
<li>for: 这篇论文 investigate了推荐系统中常见的做法，即将项目嵌入平均到用户或更高层概念的嵌入空间中。</li>
<li>methods: 作者提出了一个预期准确度分数，用于评估这种嵌入平均的一致性，并在具体的假设下进行了理论分析，以及对实际数据进行了实验研究。</li>
<li>results: 结果表明，实际中的嵌入平均不太一致，这为将来的研究提供了一个改进实际嵌入的方向。<details>
<summary>Abstract</summary>
A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
</details>
<details>
<summary>摘要</summary>
一种常见的 recommender systems 实践是将 item embeddings 平均为用户或更高级概念的嵌入空间表示。这篇论文探讨这种做法的正确性。为此，我们提出了一个预期精度分数，用于衡量average embedding 与构建它的ITEM的一致程度。我们然后对这个分数在具体的理论设定下的数学表达进行分析，以及其实际行为在真实世界数据上。我们的结果表明，真实世界的平均嵌入更不一致，这为未来研究更好地将实际嵌入与理论设定进行对应提供了道路。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Out-of-the-Box-Thinking-Improving-Customer-Lifetime-Value-Modelling-via-Expert-Routing-and-Game-Whale-Detection"><a href="#Out-of-the-Box-Thinking-Improving-Customer-Lifetime-Value-Modelling-via-Expert-Routing-and-Game-Whale-Detection" class="headerlink" title="Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection"></a>Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12729">http://arxiv.org/abs/2308.12729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Zhang, Xin Yan, Xuejiao Yang, Binfeng Jia, Shuangyang Wang</li>
<li>for: 這個研究旨在提高手機遊戲出版商的用戶生命週期預測（LTV）和遊戲巨型用戶（game whale）探測，以便更好地优化宣傳投資。</li>
<li>methods: 這個研究使用了一個多任務框架（ExpLTV），具有LTV預測和遊戲巨型用戶探測兩個任務。 ExpLTV使用了深度神經網絡設計的遊戲巨型探測器，可以不僅推測遊戲費用的階層，而且精確地識別高支付者（遊戲巨型）和低支付者。</li>
<li>results: 在三個industrial dataset上進行了廣泛的實驗，顯示了ExpLTV的超越性。<details>
<summary>Abstract</summary>
Customer lifetime value (LTV) prediction is essential for mobile game publishers trying to optimize the advertising investment for each user acquisition based on the estimated worth. In mobile games, deploying microtransactions is a simple yet effective monetization strategy, which attracts a tiny group of game whales who splurge on in-game purchases. The presence of such game whales may impede the practicality of existing LTV prediction models, since game whales' purchase behaviours always exhibit varied distribution from general users. Consequently, identifying game whales can open up new opportunities to improve the accuracy of LTV prediction models. However, little attention has been paid to applying game whale detection in LTV prediction, and existing works are mainly specialized for the long-term LTV prediction with the assumption that the high-quality user features are available, which is not applicable in the UA stage. In this paper, we propose ExpLTV, a novel multi-task framework to perform LTV prediction and game whale detection in a unified way. In ExpLTV, we first innovatively design a deep neural network-based game whale detector that can not only infer the intrinsic order in accordance with monetary value, but also precisely identify high spenders (i.e., game whales) and low spenders. Then, by treating the game whale detector as a gating network to decide the different mixture patterns of LTV experts assembling, we can thoroughly leverage the shared information and scenario-specific information (i.e., game whales modelling and low spenders modelling). Finally, instead of separately designing a purchase rate estimator for two tasks, we design a shared estimator that can preserve the inner task relationships. The superiority of ExpLTV is further validated via extensive experiments on three industrial datasets.
</details>
<details>
<summary>摘要</summary>
顾客生命周期值（LTV）预测是移动游戏发布者需要优化每个用户获取的广告投资基于预计值。在移动游戏中，实施微交易是一种简单又有效的营收化策略，吸引了一些游戏巨型用户，这些用户在游戏中购买各种内容。存在这些游戏巨型用户可能会妨碍现有的 LTV 预测模型的实用性，因为这些用户的购买行为通常与普通用户的购买行为存在差异。因此，识别游戏巨型用户可以开启新的机会来改善 LTV 预测模型的准确性。然而，现有的工作很少关注在 LTV 预测中应用游戏巨型用户检测，现有的工作主要是专注于长期 LTV 预测，假设高质量的用户特征可以获得，这并不适用于 UA 阶段。本文提出了 ExpLTV，一种新的多任务框架，用于同时进行 LTV 预测和游戏巨型用户检测。在 ExpLTV 中，我们首先创新地设计了一种深度神经网络基于的游戏巨型用户检测器，可以不仅掌握游戏内购买金额的内在顺序，还可以精准地标识高支付者（即游戏巨型用户）和低支付者。然后，我们将游戏巨型用户检测器作为权重网络来决定不同类型的 LTV 专家组合的各种混合模式。通过这种方式，我们可以全面利用共享信息和场景特定信息（即游戏巨型用户模型和低支付者模型）。最后，相比 separately 设计两个任务的购买率估计器，我们设计了一个共享估计器，可以保留内部任务关系。ExpLTV 的优势得到了三个 industrialdataset 的广泛验证。
</details></li>
</ul>
<hr>
<h2 id="Solving-Forward-and-Inverse-Problems-of-Contact-Mechanics-using-Physics-Informed-Neural-Networks"><a href="#Solving-Forward-and-Inverse-Problems-of-Contact-Mechanics-using-Physics-Informed-Neural-Networks" class="headerlink" title="Solving Forward and Inverse Problems of Contact Mechanics using Physics-Informed Neural Networks"></a>Solving Forward and Inverse Problems of Contact Mechanics using Physics-Informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12716">http://arxiv.org/abs/2308.12716</a></li>
<li>repo_url: None</li>
<li>paper_authors: T. Sahin, M. von Danwitz, A. Popp</li>
<li>for: 这 paper 探讨了基于物理学习的神经网络 (PINNs) 在粘性塑形力学中的应用，包括前向和反向问题。</li>
<li>methods: 本 paper 使用了混合变量的 PINNs 和输出变换来实现粘性塑形力学中的 Dirichlet 和 Neumann 边界条件，并通过优化器来满足 KKT 类型的不等约束。</li>
<li>results: 本 paper 表明了 PINNs 可以作为纯 PDE 解决方案、数据增强的前向模型、参数标定的 inverse 解决方案以及快速评估的减少模型。<details>
<summary>Abstract</summary>
This paper explores the ability of physics-informed neural networks (PINNs) to solve forward and inverse problems of contact mechanics for small deformation elasticity. We deploy PINNs in a mixed-variable formulation enhanced by output transformation to enforce Dirichlet and Neumann boundary conditions as hard constraints. Inequality constraints of contact problems, namely Karush-Kuhn-Tucker (KKT) type conditions, are enforced as soft constraints by incorporating them into the loss function during network training. To formulate the loss function contribution of KKT constraints, existing approaches applied to elastoplasticity problems are investigated and we explore a nonlinear complementarity problem (NCP) function, namely Fischer-Burmeister, which possesses advantageous characteristics in terms of optimization. Based on the Hertzian contact problem, we show that PINNs can serve as pure partial differential equation (PDE) solver, as data-enhanced forward model, as inverse solver for parameter identification, and as fast-to-evaluate surrogate model. Furthermore, we demonstrate the importance of choosing proper hyperparameters, e.g. loss weights, and a combination of Adam and L-BFGS-B optimizers aiming for better results in terms of accuracy and training time.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:这篇论文探讨了物理学 Informed Neural Networks (PINNs) 能够解决contact mechanics 的前向和反向问题，特别是小塑性粘合性。我们在混合变量形式中使用 PINNs，并通过输出变换来强制满足 Dirichlet 和 Neumann 边界条件。 contacts 问题中的不等式约束，例如 Karush-Kuhn-Tucker 类型的约束，通过在网络训练时添加到损失函数中来强制满足。为了形式化损失函数中的 KKT 约束贡献，我们调查了已有的 elastoplasticity 问题解决方案，并 explore Fischer-Burmeister 非线性共振问题，它具有优化的特点。基于 Hertzian contact problem，我们表明 PINNs 可以作为纯 partial differential equation (PDE) 解决方案，数据增强的前向模型，参数标识的 inverse solver，以及快速评估的 surrogate model。此外，我们还证明了选择合适的 hyperparameter，例如损失权重，以及 Adam 和 L-BFGS-B 优化器的组合，可以为准确率和训练时间带来更好的效果。
</details></li>
</ul>
<hr>
<h2 id="Disentanglement-Learning-via-Topology"><a href="#Disentanglement-Learning-via-Topology" class="headerlink" title="Disentanglement Learning via Topology"></a>Disentanglement Learning via Topology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12696">http://arxiv.org/abs/2308.12696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Balabin, Daria Voronkova, Ilya Trofimov, Evgeny Burnaev, Serguei Barannikov</li>
<li>for: 本研究提出了一种基于多尺度拓扑学loss函数的TopDis方法，用于在无监督的情况下学习分离的表示。</li>
<li>methods: 本研究使用了一种新的拓扑学loss函数，该loss函数可以计算数据拓扑结构的相似性，从而实现分离表示。</li>
<li>results: 实验表明，使用提出的拓扑学loss函数可以提高分离度指标（MIG、FactorVAE score、SAP score和DCI分离度指标），相比之下现有的状态艺术方法。此外，本研究还实现了在已经训练的GAN中找到分离的方向。<details>
<summary>Abstract</summary>
We propose TopDis (Topological Disentanglement), a method for learning disentangled representations via adding multi-scale topological loss term. Disentanglement is a crucial property of data representations substantial for the explainability and robustness of deep learning models and a step towards high-level cognition. The state-of-the-art method based on VAE minimizes the total correlation of the joint distribution of latent variables. We take a different perspective on disentanglement by analyzing topological properties of data manifolds. In particular, we optimize the topological similarity for data manifolds traversals. To the best of our knowledge, our paper is the first one to propose a differentiable topological loss for disentanglement. Our experiments have shown that the proposed topological loss improves disentanglement scores such as MIG, FactorVAE score, SAP score and DCI disentanglement score with respect to state-of-the-art results. Our method works in an unsupervised manner, permitting to apply it for problems without labeled factors of variation. Additionally, we show how to use the proposed topological loss to find disentangled directions in a trained GAN.
</details>
<details>
<summary>摘要</summary>
我们提出了TopDis（Topological Disentanglement）方法，通过添加多尺度 topological 损失项来学习分解表示。分解是深度学习模型的解释性和鲁棒性的重要属性，也是向高级认知的一步。现状的方法是基于VAE的总corrrelation减小joint分布的Latent variable的方法。我们从数据集的拓扑属性的角度来分析数据集的拓扑结构，并且通过对数据集的拓扑探索进行优化。我们认为这是首次提出了可导的拓扑损失 для分解。我们的实验表明，我们的方法可以在无标注因素的情况下提高分解分数，包括MIG、FactorVAE分数、SAP分数和DCI分解分数，与现状的结果相比。我们的方法是无监督的，可以应用于没有标注因素的问题。此外，我们还展示了如何使用我们的拓扑损失来找出在训练过的GAN中的分解方向。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Data-Analysis-Method-for-Big-Data-using-Multiple-Model-Linear-Regression"><a href="#An-Efficient-Data-Analysis-Method-for-Big-Data-using-Multiple-Model-Linear-Regression" class="headerlink" title="An Efficient Data Analysis Method for Big Data using Multiple-Model Linear Regression"></a>An Efficient Data Analysis Method for Big Data using Multiple-Model Linear Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12691">http://arxiv.org/abs/2308.12691</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Bohan Lyu, Jianzhong Li</li>
<li>for: 这篇论文提出了一种新的大数据分析方法，使用一种新的多模型线性回归模型（MMLR），可以将输入数据集分解成多个子集，并在每个子集上构建本地线性回归模型。</li>
<li>methods: 该论文提出了一种近似算法来构建MMLR模型，基于($\epsilon$, $\delta$)-估计器，并提供了数学证明MMLR算法的正确性和效率。</li>
<li>results: 该论文通过synthetic和实际数据集的实验，表明MMLR算法可以与现有的回归方法相比，在许多情况下具有相似的性能，而且具有较短的计时间，可以提供高预测精度。<details>
<summary>Abstract</summary>
This paper introduces a new data analysis method for big data using a newly defined regression model named multiple model linear regression(MMLR), which separates input datasets into subsets and construct local linear regression models of them. The proposed data analysis method is shown to be more efficient and flexible than other regression based methods. This paper also proposes an approximate algorithm to construct MMLR models based on $(\epsilon,\delta)$-estimator, and gives mathematical proofs of the correctness and efficiency of MMLR algorithm, of which the time complexity is linear with respect to the size of input datasets. This paper also empirically implements the method on both synthetic and real-world datasets, the algorithm shows to have comparable performance to existing regression methods in many cases, while it takes almost the shortest time to provide a high prediction accuracy.
</details>
<details>
<summary>摘要</summary>
The paper also proposes an approximate algorithm to construct MMLR models based on the $(\epsilon,\delta)$-estimator, and provides mathematical proofs of the correctness and efficiency of the MMLR algorithm, with a time complexity linear with respect to the size of the input datasets. The algorithm is empirically implemented on both synthetic and real-world datasets, and is shown to have comparable performance to existing regression methods in many cases, while taking almost the shortest time to provide high prediction accuracy.Here is the translation in Simplified Chinese:这篇论文介绍了一种基于多模型线性回归（MMLR）的新数据分析方法，该方法将输入数据集分解成多个子集，并在每个子集上构建本地线性回归模型。提出的数据分析方法比其他回归基于方法更加高效和灵活。论文还提出了一种近似算法来构建MMLR模型，基于($\epsilon$, $\delta$)-估计器，并提供了数学证明，证明MMLR算法的正确性和高效性，时间复杂度与输入数据集的大小成线性关系。此外，论文还实验了该方法在 sintetic 和实际数据集上，结果显示，该方法在许多情况下与现有的回归方法相当，而且时间复杂度几乎最短。
</details></li>
</ul>
<hr>
<h2 id="Match-And-Deform-Time-Series-Domain-Adaptation-through-Optimal-Transport-and-Temporal-Alignment"><a href="#Match-And-Deform-Time-Series-Domain-Adaptation-through-Optimal-Transport-and-Temporal-Alignment" class="headerlink" title="Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment"></a>Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12686">http://arxiv.org/abs/2308.12686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rtavenar/MatchAndDeform">https://github.com/rtavenar/MatchAndDeform</a></li>
<li>paper_authors: François Painblanc, Laetitia Chapel, Nicolas Courty, Chloé Friguet, Charlotte Pelletier, Romain Tavenard</li>
<li>for: 這篇論文旨在解決缺乏標籤的大量數據中，將來自不同來源的時間序列轉換為新的標籤。</li>
<li>methods: 這篇論文提出了一個名為匹配並變形（MAD）的方法，它可以在時間序列上找到對應點，並同時對時間排序進行匯流。</li>
<li>results: 實驗結果顯示，MAD 可以實現有意義的標籤對照和時間偏移估計，並在深度神經網絡中學習新的時間序列表示，以推導預測性的表現。<details>
<summary>Abstract</summary>
While large volumes of unlabeled data are usually available, associated labels are often scarce. The unsupervised domain adaptation problem aims at exploiting labels from a source domain to classify data from a related, yet different, target domain. When time series are at stake, new difficulties arise as temporal shifts may appear in addition to the standard feature distribution shift. In this paper, we introduce the Match-And-Deform (MAD) approach that aims at finding correspondences between the source and target time series while allowing temporal distortions. The associated optimization problem simultaneously aligns the series thanks to an optimal transport loss and the time stamps through dynamic time warping. When embedded into a deep neural network, MAD helps learning new representations of time series that both align the domains and maximize the discriminative power of the network. Empirical studies on benchmark datasets and remote sensing data demonstrate that MAD makes meaningful sample-to-sample pairing and time shift estimation, reaching similar or better classification performance than state-of-the-art deep time series domain adaptation strategies.
</details>
<details>
<summary>摘要</summary>
大量的无标签数据通常可以获得，但相关的标签却罕见。不supervised领域适应问题 aimsto exploit source domain中的标签来类别target domain中的数据。在时间序列的情况下，新的difficulties arise，因为存在时间偏移，同时标准的特征分布shift。在这篇论文中，我们引入Match-And-Deform（MAD）方法，该方法通过找到源和目标时间序列之间的匹配，并允许时间偏移。与此同时，相关的优化问题使用最优运输损失和时间戳进行同步。当嵌入到深度神经网络中时，MAD帮助建立新的时间序列表示，同时对域和神经网络的泛化能力做出贡献。实验表明，MAD可以实现有意义的样本对对答和时间偏移估计，并达到或更好的深度时间序列领域适应策略的分类性能。
</details></li>
</ul>
<hr>
<h2 id="Master-slave-Deep-Architecture-for-Top-K-Multi-armed-Bandits-with-Non-linear-Bandit-Feedback-and-Diversity-Constraints"><a href="#Master-slave-Deep-Architecture-for-Top-K-Multi-armed-Bandits-with-Non-linear-Bandit-Feedback-and-Diversity-Constraints" class="headerlink" title="Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints"></a>Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12680">http://arxiv.org/abs/2308.12680</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huanghanchi/master-slave-algorithm-for-top-k-bandits">https://github.com/huanghanchi/master-slave-algorithm-for-top-k-bandits</a></li>
<li>paper_authors: Hanchi Huang, Li Shen, Deheng Ye, Wei Liu</li>
<li>for:  solves the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints.</li>
<li>methods:  introduces six slave models with distinguished merits to generate diversified samples well balancing rewards and constraints as well as efficiency, and proposes teacher learning based optimization and the policy co-training technique to boost the performance of the multiple slave models.</li>
<li>results:  significantly surpasses existing state-of-the-art algorithms in both synthetic and real datasets for recommendation tasks.Here’s the simplified Chinese text:</li>
<li>for: 解决 combinatorial multi-armed bandits problem 中的 top-$K$ 问题，包括非线性带回应和多样性约束。</li>
<li>methods: 采用 six slave models 来生成多样化的样本，并提出 teacher learning 基本化优化和策略协同训练技术来提高多个 slave models 的性能。</li>
<li>results: 在 synthetic 和实际数据集上，与现有状态的算法相比，显著提高了推荐任务的性能。<details>
<summary>Abstract</summary>
We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback. Specifically, to efficiently explore the combinatorial and constrained action space, we introduce six slave models with distinguished merits to generate diversified samples well balancing rewards and constraints as well as efficiency. Moreover, we propose teacher learning based optimization and the policy co-training technique to boost the performance of the multiple slave models. The master model then collects the elite samples provided by the slave models and selects the best sample estimated by a neural contextual UCB-based network to make a decision with a trade-off between exploration and exploitation. Thanks to the elaborate design of slave models, the co-training mechanism among slave models, and the novel interactions between the master and slave models, our approach significantly surpasses existing state-of-the-art algorithms in both synthetic and real datasets for recommendation tasks. The code is available at: \url{https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits}.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的主奴 Architecture来解决top-$K$ combinatorial多臂bandits问题，这是我们知道的首个 combinatorial bandits设置中考虑了多样性约束。Specifically,我们引入了六个奴隶模型，每个模型具有独特的优势，以生成均衡奖励和约束的多样化样本。此外，我们提出了教师学习基于优化和策略共训技术，以提高多个奴隶模型的性能。主模型然后收集奴隶模型提供的Elite样本，并通过神经Contextual UCB-based网络选择最佳样本，以实现exploration和exploitation之间的衡量。由于奴隶模型的精心设计、奴隶模型之间的共训机制以及主模型和奴隶模型之间的新型互动，我们的方法在 synthetic和实际数据集上 для推荐任务上显著超越了现有的状态态Algorithm。代码可以在以下链接中找到：\url{https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits}.
</details></li>
</ul>
<hr>
<h2 id="Optimal-data-pooling-for-shared-learning-in-maintenance-operations"><a href="#Optimal-data-pooling-for-shared-learning-in-maintenance-operations" class="headerlink" title="Optimal data pooling for shared learning in maintenance operations"></a>Optimal data pooling for shared learning in maintenance operations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12670">http://arxiv.org/abs/2308.12670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Collin Drent, Melvin Drent, Geert-Jan van Houtum</li>
<li>for: 本文研究 Shared Learning 在维护操作中的利点。</li>
<li>methods: 作者使用了一种叫做 Decomposition 的技术，将高维 Markov Decision Processes (MDPs) 转化为二维 MDPs，以便进行结构分析和计算。</li>
<li>results: 研究发现，通过数据池化，可以实现比不pooling的成本减少。<details>
<summary>Abstract</summary>
This paper addresses the benefits of pooling data for shared learning in maintenance operations. We consider a set of systems subject to Poisson degradation that are coupled through an a-priori unknown rate. Decision problems involving these systems are high-dimensional Markov decision processes (MDPs). We present a decomposition result that reduces such an MDP to two-dimensional MDPs, enabling structural analyses and computations. We leverage this decomposition to demonstrate that pooling data can lead to significant cost reductions compared to not pooling.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文研究了保养操作中数据共享学习的好处。我们考虑了受 pozuelos 衰减的系统集合，这些系统之间由未知的速率相互连接。决策问题相关的这些系统是高维 Markov 决策过程（MDPs）。我们提出了一个分解结果，使得如此一个 MDP 分解成两个维度的 MDPs，以便进行结构分析和计算。通过利用这种分解，我们示出了pooling数据可以比不pooling leads to significant cost reductions。
</details></li>
</ul>
<hr>
<h2 id="Geodesic-Mode-Connectivity"><a href="#Geodesic-Mode-Connectivity" class="headerlink" title="Geodesic Mode Connectivity"></a>Geodesic Mode Connectivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12666">http://arxiv.org/abs/2308.12666</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/char-tan/geodesic-mode-connectivity">https://github.com/char-tan/geodesic-mode-connectivity</a></li>
<li>paper_authors: Charlie Tan, Theodore Long, Sarah Zhao, Rudolf Laine</li>
<li>for: 这篇论文是研究模式连接性的（mode connectivity），即训练过的模型之间可以通过低损失的路径连接。</li>
<li>methods: 这篇论文使用信息几何来研究神经网络，即神经网络可以视为参数化分布的空间，其中的几何结构具有弯曲性。作者提出了一种算法来近似地odesics，并证明了这些地odesics可以实现模式连接性。</li>
<li>results: 作者通过实验表明，使用这种算法可以准确地找到模式连接性，并且这些连接性可以在不同的损失函数下保持稳定。<details>
<summary>Abstract</summary>
Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces, known as geodesics, correspond to mode-connecting paths in the loss landscape. We propose an algorithm to approximate geodesics and demonstrate that they achieve mode connectivity.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将模型连接到低损 paths的现象称为模式连接性。我们将这种现象重新框架为信息 геометрии中的神经网络，即参数化分布空间的拟合曲线。我们假设拟合曲线上的最短路（即地odesics）与损失 landscape 中的模式连接路径相对应。我们提出了一种算法来 aproximate geodesics，并证明它们实现模式连接性。Note: "模式连接性" (mode connectivity) is a term used in the context of neural networks to describe the ability of a model to connect different modes or solutions in the loss landscape. In this text, the authors are using the term to refer to the idea that shortest paths in the parameter space of a neural network correspond to mode-connecting paths in the loss landscape.
</details></li>
</ul>
<hr>
<h2 id="The-GENEA-Challenge-2023-A-large-scale-evaluation-of-gesture-generation-models-in-monadic-and-dyadic-settings"><a href="#The-GENEA-Challenge-2023-A-large-scale-evaluation-of-gesture-generation-models-in-monadic-and-dyadic-settings" class="headerlink" title="The GENEA Challenge 2023: A large scale evaluation of gesture generation models in monadic and dyadic settings"></a>The GENEA Challenge 2023: A large scale evaluation of gesture generation models in monadic and dyadic settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12646">http://arxiv.org/abs/2308.12646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taras Kucherenko, Rajmund Nagy, Youngwoo Yoon, Jieyeon Woo, Teodor Nikolov, Mihail Tsakov, Gustav Eje Henter</li>
<li>for: 这个论文报告了2023年的GENEA挑战，参与的团队使用了同一个语音和动作数据集，然后进行了共同评估。</li>
<li>methods: 参与的团队使用了语音和动作数据来生成语音驱动的手势生成系统。</li>
<li>results: 评估结果表明，参与的团队的系统在人工智能化的动作方面存在很大的差异，只有一些系统被评估为与人类动作相似。另外，大多数系统在适应性方面表现不佳，只有在agent自己的语音上表现 slightely above chance。<details>
<summary>Abstract</summary>
This paper reports on the GENEA Challenge 2023, in which participating teams built speech-driven gesture-generation systems using the same speech and motion dataset, followed by a joint evaluation. This year's challenge provided data on both sides of a dyadic interaction, allowing teams to generate full-body motion for an agent given its speech (text and audio) and the speech and motion of the interlocutor. We evaluated 12 submissions and 2 baselines together with held-out motion-capture data in several large-scale user studies. The studies focused on three aspects: 1) the human-likeness of the motion, 2) the appropriateness of the motion for the agent's own speech whilst controlling for the human-likeness of the motion, and 3) the appropriateness of the motion for the behaviour of the interlocutor in the interaction, using a setup that controls for both the human-likeness of the motion and the agent's own speech. We found a large span in human-likeness between challenge submissions, with a few systems rated close to human mocap. Appropriateness seems far from being solved, with most submissions performing in a narrow range slightly above chance, far behind natural motion. The effect of the interlocutor is even more subtle, with submitted systems at best performing barely above chance. Interestingly, a dyadic system being highly appropriate for agent speech does not necessarily imply high appropriateness for the interlocutor. Additional material is available via the project website at https://svito-zar.github.io/GENEAchallenge2023/ .
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Human-likeness of the motion2. Appropriateness of the motion for the agent’s own speech, while controlling for the human-likeness of the motion3. Appropriateness of the motion for the behavior of the interlocutor in the interaction, while controlling for both the human-likeness of the motion and the agent’s own speechWe found a significant range in human-likeness among the challenge submissions, with a few systems rated close to human motion capture. However, appropriateness was not well-solved, with most submissions performing in a narrow range slightly above chance, far behind natural motion. The effect of the interlocutor was even more subtle, with submitted systems at best performing barely above chance. Interestingly, a dyadic system being highly appropriate for agent speech does not necessarily imply high appropriateness for the interlocutor. Additional information can be found on the project website at <a target="_blank" rel="noopener" href="https://svito-zar.github.io/GENEAchallenge2023/">https://svito-zar.github.io/GENEAchallenge2023/</a>.</details></li>
</ol>
<hr>
<h2 id="Uncertainty-and-Explainable-Analysis-of-Machine-Learning-Model-for-Reconstruction-of-Sonic-Slowness-Logs"><a href="#Uncertainty-and-Explainable-Analysis-of-Machine-Learning-Model-for-Reconstruction-of-Sonic-Slowness-Logs" class="headerlink" title="Uncertainty and Explainable Analysis of Machine Learning Model for Reconstruction of Sonic Slowness Logs"></a>Uncertainty and Explainable Analysis of Machine Learning Model for Reconstruction of Sonic Slowness Logs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12625">http://arxiv.org/abs/2308.12625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hua Wang, Yuqiong Wu, Yushun Zhang, Fuqiang Lai, Zhou Feng, Bing Xie, Ailin Zhao<br>for:This paper aims to predict missing compressional wave slowness and shear wave slowness logs in horizontal or old wells using other logs in the same borehole.methods:The authors use the NGBoost algorithm to construct an Ensemble Learning model and the SHAP method to investigate the interpretability of the machine learning model.results:The NGBoost model performs well in the testing set and provides a probability distribution for the prediction results. The variance of the probability distribution can be used to justify the quality of the constructed log. The machine learning model captures the influence of the changing borehole caliper on slowness, which is consistent with the physical principle of borehole acoustics.Here is the simplified Chinese version:for:这篇论文目的是使用同一个孔隧中的其他记录预测潜在压缩波慢速和剪切波慢速记录的缺失。methods:作者使用NGBoost算法构建一个集成学习模型，并使用SHAP方法进行可解释性分析。results:NGBoost模型在测试集中表现良好，并提供了预测结果的可能性分布。预测结果的变化可以用来评估构建的记录质量。机器学习模型捕捉了孔隧尺寸的变化对慢速的影响，这与物理原理相符。<details>
<summary>Abstract</summary>
Logs are valuable information for oil and gas fields as they help to determine the lithology of the formations surrounding the borehole and the location and reserves of subsurface oil and gas reservoirs. However, important logs are often missing in horizontal or old wells, which poses a challenge in field applications. In this paper, we utilize data from the 2020 machine learning competition of the SPWLA, which aims to predict the missing compressional wave slowness and shear wave slowness logs using other logs in the same borehole. We employ the NGBoost algorithm to construct an Ensemble Learning model that can predicate the results as well as their uncertainty. Furthermore, we combine the SHAP method to investigate the interpretability of the machine learning model. We compare the performance of the NGBosst model with four other commonly used Ensemble Learning methods, including Random Forest, GBDT, XGBoost, LightGBM. The results show that the NGBoost model performs well in the testing set and can provide a probability distribution for the prediction results. In addition, the variance of the probability distribution of the predicted log can be used to justify the quality of the constructed log. Using the SHAP explainable machine learning model, we calculate the importance of each input log to the predicted results as well as the coupling relationship among input logs. Our findings reveal that the NGBoost model tends to provide greater slowness prediction results when the neutron porosity and gamma ray are large, which is consistent with the cognition of petrophysical models. Furthermore, the machine learning model can capture the influence of the changing borehole caliper on slowness, where the influence of borehole caliper on slowness is complex and not easy to establish a direct relationship. These findings are in line with the physical principle of borehole acoustics.
</details>
<details>
<summary>摘要</summary>
logs 是油气田中非常重要的信息，它们可以帮助确定附近钻井的岩石类型和油气储量。然而，在探钻过的油气井中，有时logs会缺失，这会对预测和勘探带来挑战。在这篇论文中，我们利用2020年机器学习竞赛的SPWLA数据，以预测缺失的压缩波慢速度和剪切波慢速度logs。我们使用NGBoost算法构建一个Ensemble Learning模型，可以预测结果以及其不确定性。此外，我们使用SHAP方法来检验机器学习模型的可解释性。我们对NGBoost模型与四种常用的Ensemble Learning方法进行比较，包括Random Forest、GBDT、XGBoost和LightGBM。结果表明，NGBoost模型在测试集中表现良好，并可以提供预测结果的概率分布。此外，预测结果的变差可以用来评估模型的质量。通过SHAP可解释机器学习模型，我们可以计算输入logs的重要性和预测结果之间的相互关系。我们发现，NGBoost模型在大于钻井中的中子滤波和γ射线强度大时，具有更高的慢速度预测结果，这与岩石物理模型的认知一致。此外，机器学习模型可以捕捉钻井径的变化对慢速度的影响，这种影响是复杂的，不易建立直接关系。这与物理原理相一致。
</details></li>
</ul>
<hr>
<h2 id="Try-with-Simpler-–-An-Evaluation-of-Improved-Principal-Component-Analysis-in-Log-based-Anomaly-Detection"><a href="#Try-with-Simpler-–-An-Evaluation-of-Improved-Principal-Component-Analysis-in-Log-based-Anomaly-Detection" class="headerlink" title="Try with Simpler – An Evaluation of Improved Principal Component Analysis in Log-based Anomaly Detection"></a>Try with Simpler – An Evaluation of Improved Principal Component Analysis in Log-based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12612">http://arxiv.org/abs/2308.12612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Yang, Junjie Chen, Zhihao Gong, Shutao Gao, Hongyu Zhang, Yue Kang, Huaan Li</li>
<li>for: 本研究旨在提高 traditional machine learning 和数据挖掘技术，使其与深度学习方法匹配效果。</li>
<li>methods: 本研究使用了优化后的无监督 PCA，具有轻量级 semantic-based 日志表示，以解决训练数据中未见的日志事件问题。</li>
<li>results: 研究结果显示，优化后的无监督 PCA 技术与高级supervised&#x2F;semi-supervised DL 方法效果相似，但更稳定、数据和资源更具有效率。<details>
<summary>Abstract</summary>
The rapid growth of deep learning (DL) has spurred interest in enhancing log-based anomaly detection. This approach aims to extract meaning from log events (log message templates) and develop advanced DL models for anomaly detection. However, these DL methods face challenges like heavy reliance on training data, labels, and computational resources due to model complexity. In contrast, traditional machine learning and data mining techniques are less data-dependent and more efficient but less effective than DL. To make log-based anomaly detection more practical, the goal is to enhance traditional techniques to match DL's effectiveness. Previous research in a different domain (linking questions on Stack Overflow) suggests that optimized traditional techniques can rival state-of-the-art DL methods. Drawing inspiration from this concept, we conducted an empirical study. We optimized the unsupervised PCA (Principal Component Analysis), a traditional technique, by incorporating lightweight semantic-based log representation. This addresses the issue of unseen log events in training data, enhancing log representation. Our study compared seven log-based anomaly detection methods, including four DL-based, two traditional, and the optimized PCA technique, using public and industrial datasets. Results indicate that the optimized unsupervised PCA technique achieves similar effectiveness to advanced supervised/semi-supervised DL methods while being more stable with limited training data and resource-efficient. This demonstrates the adaptability and strength of traditional techniques through small yet impactful adaptations.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）的快速发展促使了对日志Event（日志消息模板）的异常检测的提升。这种方法的目标是从日志事件中提取意义并开发高级DL模型进行异常检测。然而，这些DL方法面临着大量训练数据、标签和计算资源的需求，因为模型的复杂性。与此相反，传统的机器学习和数据挖掘技术更加不需要大量数据，但是效果较差。为了使日志异常检测更加实用，目标是通过提高传统技术来匹配DL的效果。前一个研究（在Stack Overflow上的问题链接）表明，优化传统技术可以与当前DL方法相当有效。以此为 inspirited，我们进行了一个实验研究。我们优化了无监督的PCA（主成分分析），一种传统技术，通过 integrate lightweight语义基于的日志表示。这种方法可以解决训练数据中未看到的日志事件问题，改进日志表示。我们对公共和工业数据集进行比较，包括四种DL基于的方法、两种传统方法和优化PCA技术。结果表明，优化的无监督PCA技术与高级监督/半监督DL方法相当有效，同时更加稳定、资源效率。这说明传统技术通过小 yet 有力的改进可以具备相同的效果。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement"><a href="#Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement" class="headerlink" title="Exploiting Time-Frequency Conformers for Music Audio Enhancement"></a>Exploiting Time-Frequency Conformers for Music Audio Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12599">http://arxiv.org/abs/2308.12599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunkee Chae, Junghyun Koo, Sungho Lee, Kyogu Lee</li>
<li>for: 提高网络视频平台上音乐表演录音质量</li>
<li>methods: 使用Conformer架构和注意机制进行音乐提升</li>
<li>results: 实现单音轨音乐提升和多轨合唱音乐提升，并达到现有最佳性能水平<details>
<summary>Abstract</summary>
With the proliferation of video platforms on the internet, recording musical performances by mobile devices has become commonplace. However, these recordings often suffer from degradation such as noise and reverberation, which negatively impact the listening experience. Consequently, the necessity for music audio enhancement (referred to as music enhancement from this point onward), involving the transformation of degraded audio recordings into pristine high-quality music, has surged to augment the auditory experience. To address this issue, we propose a music enhancement system based on the Conformer architecture that has demonstrated outstanding performance in speech enhancement tasks. Our approach explores the attention mechanisms of the Conformer and examines their performance to discover the best approach for the music enhancement task. Our experimental results show that our proposed model achieves state-of-the-art performance on single-stem music enhancement. Furthermore, our system can perform general music enhancement with multi-track mixtures, which has not been examined in previous work.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a music enhancement system based on the Conformer architecture, which has shown outstanding performance in speech enhancement tasks. Our approach leverages the attention mechanisms of the Conformer and explores their performance to determine the best approach for the music enhancement task.Our experimental results show that our proposed model achieves state-of-the-art performance on single-stem music enhancement. Moreover, our system can perform general music enhancement with multi-track mixtures, which has not been examined in previous work.
</details></li>
</ul>
<hr>
<h2 id="Persistent-learning-signals-and-working-memory-without-continuous-attractors"><a href="#Persistent-learning-signals-and-working-memory-without-continuous-attractors" class="headerlink" title="Persistent learning signals and working memory without continuous attractors"></a>Persistent learning signals and working memory without continuous attractors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12585">http://arxiv.org/abs/2308.12585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Il Memming Park, Ábel Ságodi, Piotr Aleksander Sokół</li>
<li>for: 这个论文探讨了神经动力系统中稳定吸引结构，如点吸引器和连续吸引器，如何支持有用的时间行为，而不需要工作 память。</li>
<li>methods: 论文提出了一种新的初始化方案，以及一种可靠的循环记忆机制，用于学习和维护头方向。</li>
<li>results: 研究发现，Periodic和 quasi-periodic吸引器可以支持学习无限长时间关系，而不受细节问题的干扰。这些吸引器也可以用于开发人工学习系统，并且预测了生物神经动力系统中可以支持时间依赖学习和工作 память的 observable 特征。<details>
<summary>Abstract</summary>
Neural dynamical systems with stable attractor structures, such as point attractors and continuous attractors, are hypothesized to underlie meaningful temporal behavior that requires working memory. However, working memory may not support useful learning signals necessary to adapt to changes in the temporal structure of the environment. We show that in addition to the continuous attractors that are widely implicated, periodic and quasi-periodic attractors can also support learning arbitrarily long temporal relationships. Unlike the continuous attractors that suffer from the fine-tuning problem, the less explored quasi-periodic attractors are uniquely qualified for learning to produce temporally structured behavior. Our theory has broad implications for the design of artificial learning systems and makes predictions about observable signatures of biological neural dynamics that can support temporal dependence learning and working memory. Based on our theory, we developed a new initialization scheme for artificial recurrent neural networks that outperforms standard methods for tasks that require learning temporal dynamics. Moreover, we propose a robust recurrent memory mechanism for integrating and maintaining head direction without a ring attractor.
</details>
<details>
<summary>摘要</summary>
神经动力系统 WITH stable attractor structure, such as point attractors and continuous attractors, are hypothesized to underlie meaningful temporal behavior that requires working memory. However, working memory may not support useful learning signals necessary to adapt to changes in the temporal structure of the environment. We show that in addition to the continuous attractors that are widely implicated, periodic and quasi-periodic attractors can also support learning arbitrarily long temporal relationships. Unlike the continuous attractors that suffer from the fine-tuning problem, the less explored quasi-periodic attractors are uniquely qualified for learning to produce temporally structured behavior. Our theory has broad implications for the design of artificial learning systems and makes predictions about observable signatures of biological neural dynamics that can support temporal dependence learning and working memory. Based on our theory, we developed a new initialization scheme for artificial recurrent neural networks that outperforms standard methods for tasks that require learning temporal dynamics. Moreover, we propose a robust recurrent memory mechanism for integrating and maintaining head direction without a ring attractor.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Hypergraph-Convolutional-Networks-for-Fine-grained-ICU-Patient-Similarity-Analysis-and-Risk-Prediction"><a href="#Hypergraph-Convolutional-Networks-for-Fine-grained-ICU-Patient-Similarity-Analysis-and-Risk-Prediction" class="headerlink" title="Hypergraph Convolutional Networks for Fine-grained ICU Patient Similarity Analysis and Risk Prediction"></a>Hypergraph Convolutional Networks for Fine-grained ICU Patient Similarity Analysis and Risk Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12575">http://arxiv.org/abs/2308.12575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Liu, Zhenhao Zhang, Shaowen Qin, Flora D. Salim, Antonio Jimeno Yepes, Jun Shen</li>
<li>for: 预测 critically ill 病人的死亡风险，帮助医疗专业人员在临床决策中更加有效。</li>
<li>methods: 提出了一种新的跨体系数据的 Hypergraph Convolutional Network，可以捕捉非对称关系，例如诊断代码之间的高阶关系，以计算细腻的病人相似性。</li>
<li>results: 使用公共可用的 eICU Collaborative Research Database进行评估，该方法在死亡风险预测方面超过了现有模型的性能。此外，案例研究还表明，构建图网络可以提供良好的透明度和可靠性。<details>
<summary>Abstract</summary>
The Intensive Care Unit (ICU) is one of the most important parts of a hospital, which admits critically ill patients and provides continuous monitoring and treatment. Various patient outcome prediction methods have been attempted to assist healthcare professionals in clinical decision-making. Existing methods focus on measuring the similarity between patients using deep neural networks to capture the hidden feature structures. However, the higher-order relationships are ignored, such as patient characteristics (e.g., diagnosis codes) and their causal effects on downstream clinical predictions.   In this paper, we propose a novel Hypergraph Convolutional Network that allows the representation of non-pairwise relationships among diagnosis codes in a hypergraph to capture the hidden feature structures so that fine-grained patient similarity can be calculated for personalized mortality risk prediction. Evaluation using a publicly available eICU Collaborative Research Database indicates that our method achieves superior performance over the state-of-the-art models on mortality risk prediction. Moreover, the results of several case studies demonstrated the effectiveness of constructing graph networks in providing good transparency and robustness in decision-making.
</details>
<details>
<summary>摘要</summary>
医疗机构（ICU）是医院中最重要的部分，患者进入ICU后会接受无间断的监测和治疗。各种患者结果预测方法已经被尝试以帮助医疗专业人员做出决策。现有方法主要是使用深度神经网络捕捉患者特征结构中的隐藏关系，但是忽略了患者特征（例如诊断代码）以及它们对下游临床预测产生的 causal 效应。在这篇论文中，我们提出了一种新的超graph convolutional neural network，允许在超graph 中表示诊断代码之间的非对称关系，以捕捉隐藏特征结构，从而计算出细化的患者相似性，用于个性化致死风险预测。经评估公共可用的 eICU 合作研究数据库，我们的方法在致死风险预测中超过了当前最佳模型的性能。此外，案例研究结果表明，构建图网络可以提供良好的透明度和可靠性，以便决策。
</details></li>
</ul>
<hr>
<h2 id="Multivariate-Time-Series-Anomaly-Detection-with-Contaminated-Data-Application-to-Physiological-Signals"><a href="#Multivariate-Time-Series-Anomaly-Detection-with-Contaminated-Data-Application-to-Physiological-Signals" class="headerlink" title="Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals"></a>Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12563">http://arxiv.org/abs/2308.12563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thi Kieu Khanh Ho, Narges Armanfard</li>
<li>for: 本研究旨在提高实际 anomaly detection 中的宽泛无监督方法的表现，Addressing the challenge of 训练数据中噪声的问题，这个问题在实际应用中很普遍。</li>
<li>methods: 该研究提出了一种新的、实用的端到端无监督时间序列异常检测（TSAD）方法，无需训练阶段获取异常标签。该方法包括三个模块：一个 Rectifier 模块用于修正训练数据中的异常（即噪声），一个 Variable Dependency Modeling 模块用于捕捉训练数据中的长期内部和外部变量关系，以及一个异常检测模块用于检测异常。</li>
<li>results: 研究人员通过在三个广泛使用的生物 physiological 数据集进行了广泛的实验，证明了我们的方法可以超越现有的方法，从而在该领域建立了新的状态方法。<details>
<summary>Abstract</summary>
Mainstream unsupervised anomaly detection algorithms often excel in academic datasets, yet their real-world performance is restricted due to the controlled experimental conditions involving clean training data. Addressing the challenge of training with noise, a prevalent issue in practical anomaly detection, is frequently overlooked. In a pioneering endeavor, this study delves into the realm of label-level noise within sensory time-series anomaly detection (TSAD). This paper presents a novel and practical end-to-end unsupervised TSAD when the training data are contaminated with anomalies. The introduced approach, called TSAD-C, is devoid of access to abnormality labels during the training phase. TSAD-C encompasses three modules: a Decontaminator to rectify the abnormalities (aka noise) present in the training data, a Variable Dependency Modeling module to capture both long-term intra- and inter-variable dependencies within the decontaminated data that can be considered as a surrogate of the pure normal data, and an Anomaly Scoring module to detect anomalies. Our extensive experiments conducted on three widely used physiological datasets conclusively demonstrate that our approach surpasses existing methodologies, thus establishing a new state-of-the-art performance in the field.
</details>
<details>
<summary>摘要</summary>
主流无监督异常检测算法在学术数据集中 frequently excel，但它们在实际应用中的性能受到干扰因素的限制。干扰因素包括训练数据中含有异常的问题，这是实际异常检测中的一大挑战。本研究在感知时序异常检测（TSAD）领域进行了先锋性的尝试，推出了一种实用的无监督TSAD方法。该方法，称为TSAD-C，在训练阶段不会有对异常标签的访问。TSAD-C包括三个模块：一个归正器来修正训练数据中的异常（即噪声），一个变量依赖模型来捕捉训练数据中的长期内部和间部变量关系，以及一个异常分数模块来检测异常。我们在三个广泛使用的生理数据集上进行了广泛的实验，结果显示，我们的方法超过了现有的方法，从而在TSAD领域设置了新的状态纪录。
</details></li>
</ul>
<hr>
<h2 id="Variational-Information-Pursuit-with-Large-Language-and-Multimodal-Models-for-Interpretable-Predictions"><a href="#Variational-Information-Pursuit-with-Large-Language-and-Multimodal-Models-for-Interpretable-Predictions" class="headerlink" title="Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions"></a>Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12562">http://arxiv.org/abs/2308.12562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kwan Ho Ryan Chan, Aditya Chattopadhyay, Benjamin David Haeffele, Rene Vidal</li>
<li>for:  This paper is written for extending the Variational Information Pursuit (V-IP) framework to address the limitation of requiring dense concept-labeling by domain experts.</li>
<li>methods: The paper uses Large Language Models (LLMs) to generate a candidate set of task-relevant interpretable concepts, and Large Multimodal Models to annotate each data sample by semantic similarity with each concept in the generated concept set.</li>
<li>results: The paper shows that the proposed Framework (FM+V-IP) can achieve better test performance than V-IP with human annotated concepts, and can achieve competitive test performance using fewer number of concepts&#x2F;queries compared to other interpretable-by-design frameworks such as Concept Bottleneck Models (CBMs).<details>
<summary>Abstract</summary>
Variational Information Pursuit (V-IP) is a framework for making interpretable predictions by design by sequentially selecting a short chain of task-relevant, user-defined and interpretable queries about the data that are most informative for the task. While this allows for built-in interpretability in predictive models, applying V-IP to any task requires data samples with dense concept-labeling by domain experts, limiting the application of V-IP to small-scale tasks where manual data annotation is feasible. In this work, we extend the V-IP framework with Foundational Models (FMs) to address this limitation. More specifically, we use a two-step process, by first leveraging Large Language Models (LLMs) to generate a sufficiently large candidate set of task-relevant interpretable concepts, then using Large Multimodal Models to annotate each data sample by semantic similarity with each concept in the generated concept set. While other interpretable-by-design frameworks such as Concept Bottleneck Models (CBMs) require an additional step of removing repetitive and non-discriminative concepts to have good interpretability and test performance, we mathematically and empirically justify that, with a sufficiently informative and task-relevant query (concept) set, the proposed FM+V-IP method does not require any type of concept filtering. In addition, we show that FM+V-IP with LLM generated concepts can achieve better test performance than V-IP with human annotated concepts, demonstrating the effectiveness of LLMs at generating efficient query sets. Finally, when compared to other interpretable-by-design frameworks such as CBMs, FM+V-IP can achieve competitive test performance using fewer number of concepts/queries in both cases with filtered or unfiltered concept sets.
</details>
<details>
<summary>摘要</summary>
「Variational Information Pursuit（V-IP）是一個框架，用於將預測模型變得更加解釋性。它可以逐步選擇一組短的任務相關、用戶定義且可解釋的問題，以提高預測模型的解釋性。然而，實際應用V-IP時需要具備充分的數據樣本，並且需要由領域專家 manually annotate 數據，這限制了V-IP的應用範圍只能是小規模任務。在這個工作中，我們將V-IP框架與基礎模型（FM）相結合，以解決這個問題。我們使用了兩步過程，首先使用大型語言模型（LLM）生成一個足夠大的候選集，然後使用大型多媒體模型來對每個數據樣本進行Semantic similarity annotation。相比其他可解釋性的設計框架，如概念瓶頸模型（CBM），我們無需進行額外的排除非解釋性和重複的概念，因為我們可以使用LLM生成的候選集來確保解釋性。實際和理論上，我們證明了，只要有足夠有用和任務相關的問題（概念）集，則FM+V-IP方法不需要進行任何類型的概念排除。此外，我們顯示了FM+V-IP將LLM生成的概念集和人工標注的概念集相比，可以在兩者都有好的表現。最後，我們與其他可解釋性的設計框架，如CBM，進行比較，FM+V-IP可以使用更少的概念/問題來達到相同或更好的表現。」
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-driven-Cross-Community-Energy-Interaction-Optimal-Scheduling"><a href="#Deep-Reinforcement-Learning-driven-Cross-Community-Energy-Interaction-Optimal-Scheduling" class="headerlink" title="Deep Reinforcement Learning-driven Cross-Community Energy Interaction Optimal Scheduling"></a>Deep Reinforcement Learning-driven Cross-Community Energy Interaction Optimal Scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12554">http://arxiv.org/abs/2308.12554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Fanjin Bu, Zhen Yang, Bin Wang, Meng Han</li>
<li>for: 這篇論文目的是為了協調不同社區之間的能源互動，並處理多種能源互聯系統中的不確定性，以達到總體优化和調度綜合能源系統。</li>
<li>methods: 本論文提出了一個涉及多元智能 Agent 深度強化學習算法的綜合調度模型，以學習不同社區的負載特性，並根據這個知識進行決策。在這個模型中，綜合能源系統的調度問題被轉換為Markov問題，並使用數據驅動的深度強化學習算法解決。</li>
<li>results:  simulations 結果顯示，提出的方法能夠有效地捕捉不同社區的負載特性，並將其融合為一個合理的能源互動策略。這 leads to 风力 Curtailment 率由16.3%降至0%，並降低總運行成本5445.6 Yuan，表現出了significant economic和環境 benefits。<details>
<summary>Abstract</summary>
In order to coordinate energy interactions among various communities and energy conversions among multi-energy subsystems within the multi-community integrated energy system under uncertain conditions, and achieve overall optimization and scheduling of the comprehensive energy system, this paper proposes a comprehensive scheduling model that utilizes a multi-agent deep reinforcement learning algorithm to learn load characteristics of different communities and make decisions based on this knowledge. In this model, the scheduling problem of the integrated energy system is transformed into a Markov decision process and solved using a data-driven deep reinforcement learning algorithm, which avoids the need for modeling complex energy coupling relationships between multi-communities and multi-energy subsystems. The simulation results show that the proposed method effectively captures the load characteristics of different communities and utilizes their complementary features to coordinate reasonable energy interactions among them. This leads to a reduction in wind curtailment rate from 16.3% to 0% and lowers the overall operating cost by 5445.6 Yuan, demonstrating significant economic and environmental benefits.
</details>
<details>
<summary>摘要</summary>
为了协调不同社区之间的能源互动和多种能源互动系统内部的多个能源互动系统之间的不确定条件下，以实现总体优化和规划多元能源系统，这篇论文提出了一种全面的调度模型。该模型利用多智能深度学习算法来学习不同社区的负荷特点，并基于这些知识来做出决策。在该模型中，集成能源系统的调度问题被转化为了马尔可夫决策过程，并使用数据驱动的深度学习算法解决，从而避免了模拟复杂的能源协同关系 между多个社区和多种能源互动系统的需要。 simulation结果表明，提出的方法能够有效捕捉不同社区的负荷特点，并利用它们的互补特点来协调合理的能源互动。这Result in a reduction in wind curtailment rate from 16.3% to 0% and lowers the overall operating cost by 5445.6 Yuan, demonstrating significant economic and environmental benefits.
</details></li>
</ul>
<hr>
<h2 id="Don’t-blame-Dataset-Shift-Shortcut-Learning-due-to-Gradients-and-Cross-Entropy"><a href="#Don’t-blame-Dataset-Shift-Shortcut-Learning-due-to-Gradients-and-Cross-Entropy" class="headerlink" title="Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy"></a>Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12553">http://arxiv.org/abs/2308.12553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aahlad Puli, Lily Zhang, Yoav Wald, Rajesh Ranganath</li>
<li>for: 这 paper 是关于短cutting learning的研究，它们发现了 default-ERM 在 percection 任务中的偏好，并提出了一种新的权重规则来mitigate 短cutting learning。</li>
<li>methods: 这 paper 使用了 linear perception 任务来研究 default-ERM 的偏好，并开发了一种新的权重规则 called margin control (MARG-CTRL) 来mitigate 短cutting learning。</li>
<li>results: 这 paper 通过实验示出了 MARG-CTRL 可以在多种视觉和语言任务中mitigate 短cutting learning，并且表明了 better inductive biases 可以消除二次的 shortcut-mitigating 方法。<details>
<summary>Abstract</summary>
Common explanations for shortcut learning assume that the shortcut improves prediction under the training distribution but not in the test distribution. Thus, models trained via the typical gradient-based optimization of cross-entropy, which we call default-ERM, utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM still exhibits shortcut learning. Why are such solutions preferred when the loss for default-ERM can be driven to zero using the stable feature alone? By studying a linear perception task, we show that default-ERM's preference for maximizing the margin leads to models that depend more on the shortcut than the stable feature, even without overparameterization. This insight suggests that default-ERM's implicit inductive bias towards max-margin is unsuitable for perception tasks. Instead, we develop an inductive bias toward uniform margins and show that this bias guarantees dependence only on the perfect stable feature in the linear perception task. We develop loss functions that encourage uniform-margin solutions, called margin control (MARG-CTRL). MARG-CTRL mitigates shortcut learning on a variety of vision and language tasks, showing that better inductive biases can remove the need for expensive two-stage shortcut-mitigating methods in perception tasks.
</details>
<details>
<summary>摘要</summary>
通常的解释是，快捷学习方法可以在训练分布下提高预测性能，但在测试分布下不提供任何更多的信息。因此，通过 Typical 的梯度下降法和cross-entropy 优化，我们称之为 default-ERM，这些模型会使用快捷方法。然而，即使稳定的特征可以决定标签在训练分布下，并且快捷方法不提供任何额外信息，如感知任务中， default-ERM 仍然会 exhibits 快捷学习。这种解释是为何 default-ERM 会偏向使用快捷方法，而不是稳定的特征？我们通过一个 linear 的感知任务来研究 default-ERM 的偏好。我们发现，default-ERM 在寻找最大margin 的情况下会偏向使用快捷方法，而不是稳定的特征。这种发现表明 default-ERM 的隐式偏好向 max-margin 是不适合感知任务的。相反，我们开发了一种偏好 uniform margin，并证明这种偏好会导致依赖于稳定的特征，而不是快捷方法。我们开发的损失函数，called MARG-CTRL，可以鼓励 uniform-margin 解决方案，并在多种视觉和语言任务上mitigate 快捷学习。这些成果表明，更好的偏好可以消除两阶段的快捷方法 mitigation 方法的需要，从而提高感知任务的性能。
</details></li>
</ul>
<hr>
<h2 id="UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023"></a>UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12526">http://arxiv.org/abs/2308.12526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Zheng, Yajun Zhang, Chuanying Niu, Yibin Zhan, Yanhua Long, Dongxing Xu</li>
<li>for: 本文是为了参加2023年度VOXCELEB Speaker Recognition Challenge（VoxSRC 2023）的评测提交。</li>
<li>methods: 我们使用了VoxCeleb2-dev进行训练，并开发了大规模ResNet和RepVGG架构。我们还提出了一种准确性感知因子（CMF）来改进相似性分数的稳定性。</li>
<li>results: 我们的最终系统是六个模型的拟合体，在VoxSRC 2023的Track 1和Track 2中获得了第一名和第二名。我们的最终提交的minDCF为0.0855，EER为1.5880%。<details>
<summary>Abstract</summary>
This report describes the UNISOUND submission for Track1 and Track2 of VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same system on Track 1 and Track 2, which is trained with only VoxCeleb2-dev. Large-scale ResNet and RepVGG architectures are developed for the challenge. We propose a consistency-aware score calibration method, which leverages the stability of audio voiceprints in similarity score by a Consistency Measure Factor (CMF). CMF brings a huge performance boost in this challenge. Our final system is a fusion of six models and achieves the first place in Track 1 and second place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855 and the EER is 1.5880%.
</details>
<details>
<summary>摘要</summary>
这份报告描述我们在2023年 voxceleb speaker recognition challenge（VoxSRC 2023）中的UNISOUND提交，我们在Track 1和Track 2上提交了同一个系统，该系统基于voxceleb2-dev进行训练。我们开发了大规模ResNet和RepVGG架构，并提出了一种相对性意识分数调整方法（CMF），该方法利用了音频voiceprint的稳定性来提高相对性分数的稳定性。我们的最终系统是六个模型的拟合体，在Track 1中达到了第一名，在Track 2中达到了第二名，minDCF为0.0855，EER为1.5880%。
</details></li>
</ul>
<hr>
<h2 id="False-Information-Bots-and-Malicious-Campaigns-Demystifying-Elements-of-Social-Media-Manipulations"><a href="#False-Information-Bots-and-Malicious-Campaigns-Demystifying-Elements-of-Social-Media-Manipulations" class="headerlink" title="False Information, Bots and Malicious Campaigns: Demystifying Elements of Social Media Manipulations"></a>False Information, Bots and Malicious Campaigns: Demystifying Elements of Social Media Manipulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12497">http://arxiv.org/abs/2308.12497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Majid Akhtar, Rahat Masood, Muhammad Ikram, Salil S. Kanhere</li>
<li>for:  This paper aims to provide a comprehensive analysis of the manipulation landscape on online social networks (OSNs), addressing the research gap in user psychology, bot tactics, and false information detection.</li>
<li>methods:  The paper synthesizes insights from various disciplines, integrating primary elements of social media manipulation (SMM) such as false information, bots, and malicious campaigns. It conducts a systematic investigation of prior research to identify commonalities, gaps, and valuable insights.</li>
<li>results:  The paper highlights the urgent need for interdisciplinary research to combat social media manipulations and provides a systematization of the field to guide future research efforts and assist OSN providers in ensuring the safety and integrity of their platforms.<details>
<summary>Abstract</summary>
The rapid spread of false information and persistent manipulation attacks on online social networks (OSNs), often for political, ideological, or financial gain, has affected the openness of OSNs. While researchers from various disciplines have investigated different manipulation-triggering elements of OSNs (such as understanding information diffusion on OSNs or detecting automated behavior of accounts), these works have not been consolidated to present a comprehensive overview of the interconnections among these elements. Notably, user psychology, the prevalence of bots, and their tactics in relation to false information detection have been overlooked in previous research. To address this research gap, this paper synthesizes insights from various disciplines to provide a comprehensive analysis of the manipulation landscape. By integrating the primary elements of social media manipulation (SMM), including false information, bots, and malicious campaigns, we extensively examine each SMM element. Through a systematic investigation of prior research, we identify commonalities, highlight existing gaps, and extract valuable insights in the field. Our findings underscore the urgent need for interdisciplinary research to effectively combat social media manipulations, and our systematization can guide future research efforts and assist OSN providers in ensuring the safety and integrity of their platforms.
</details>
<details>
<summary>摘要</summary>
在社交媒体网络（OSN）上，快速传播false信息和持续的操纵攻击， oft для政治、 ideological或Financial gain，已经影响了OSN的开放性。 而研究人员从不同领域 investigatedifferent manipulation- triggering elements of OSNs (such as understanding information diffusion on OSNs or detecting automated behavior of accounts), but these works have not been consolidated to present a comprehensive overview of the interconnections among these elements. Notably, user psychology, the prevalence of bots, and their tactics in relation to false information detection have been overlooked in previous research. To address this research gap, this paper synthesizes insights from various disciplines to provide a comprehensive analysis of the manipulation landscape. By integrating the primary elements of social media manipulation (SMM), including false information, bots, and malicious campaigns, we extensively examine each SMM element. Through a systematic investigation of prior research, we identify commonalities, highlight existing gaps, and extract valuable insights in the field. Our findings underscore the urgent need for interdisciplinary research to effectively combat social media manipulations, and our systematization can guide future research efforts and assist OSN providers in ensuring the safety and integrity of their platforms.
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Neural-Network-Scale-for-ECG-Classification"><a href="#Optimizing-Neural-Network-Scale-for-ECG-Classification" class="headerlink" title="Optimizing Neural Network Scale for ECG Classification"></a>Optimizing Neural Network Scale for ECG Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12492">http://arxiv.org/abs/2308.12492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byeong Tak Lee, Yong-Yeon Jo, Joon-Myoung Kwon</li>
<li>for: 这个论文targets Residual neural networks (ResNet) for analyzing electrocardiograms (ECGs), with the goal of improving the accuracy and efficiency of ECG classification.</li>
<li>methods: The authors explore and demonstrate an efficient approach to scaling ResNet for ECG classification, by examining the effects of crucial parameters such as layer depth, the number of channels, and the convolution kernel size.</li>
<li>results: Through extensive experiments, the authors found that a shallower network, a larger number of channels, and smaller kernel sizes result in better performance for ECG classifications. They also demonstrate that a narrower search space based on their findings leads to higher performance in practice.<details>
<summary>Abstract</summary>
We study scaling convolutional neural networks (CNNs), specifically targeting Residual neural networks (ResNet), for analyzing electrocardiograms (ECGs). Although ECG signals are time-series data, CNN-based models have been shown to outperform other neural networks with different architectures in ECG analysis. However, most previous studies in ECG analysis have overlooked the importance of network scaling optimization, which significantly improves performance. We explored and demonstrated an efficient approach to scale ResNet by examining the effects of crucial parameters, including layer depth, the number of channels, and the convolution kernel size. Through extensive experiments, we found that a shallower network, a larger number of channels, and smaller kernel sizes result in better performance for ECG classifications. The optimal network scale might differ depending on the target task, but our findings provide insight into obtaining more efficient and accurate models with fewer computing resources or less time. In practice, we demonstrate that a narrower search space based on our findings leads to higher performance.
</details>
<details>
<summary>摘要</summary>
我们研究了扩展卷积神经网络（CNN），特指差异神经网络（ResNet），用于分析电 electrocardiogram（ECG）信号。虽然ECG信号是时间序列数据，但是CNN模型已经被证明可以在ECG分析中表现出色，而其他不同结构神经网络则被忽略了。然而，大多数前一代ECG分析研究忽略了网络缩放优化的重要性，这会提高性能。我们探索了和证明了一种有效的方法来缩放ResNet，包括层数、通道数和核形状等关键参数的影响。通过广泛的实验，我们发现，更浅的网络、更多的通道和更小的核形状会对ECG分类提供更好的表现。但是，优化的网络Scale可能因目标任务而异，但我们的发现可以帮助我们在更少的计算资源和更少的时间内获得更高效和准确的模型。在实践中，我们示例了一种基于我们发现的更窄的搜索空间可以提高性能。
</details></li>
</ul>
<hr>
<h2 id="Fall-Detection-using-Knowledge-Distillation-Based-Long-short-term-memory-for-Offline-Embedded-and-Low-Power-Devices"><a href="#Fall-Detection-using-Knowledge-Distillation-Based-Long-short-term-memory-for-Offline-Embedded-and-Low-Power-Devices" class="headerlink" title="Fall Detection using Knowledge Distillation Based Long short-term memory for Offline Embedded and Low Power Devices"></a>Fall Detection using Knowledge Distillation Based Long short-term memory for Offline Embedded and Low Power Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12481">http://arxiv.org/abs/2308.12481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hannah Zhou, Allison Chen, Celine Buer, Emily Chen, Kayleen Tang, Lauryn Gong, Zhiqi Liu, Jianbin Tang</li>
<li>for: 這篇論文旨在提出一種可靠且低功耗的跌倒探測方法，以提高準確率。</li>
<li>methods: 本論文使用知識傳授-基於LSTM（長期記憶體）模型，並藉由該模型進行時間序列數據的分析，以獲得實時探測結果。</li>
<li>results: 本論文的實驗結果顯示，這種方法可以實現高準確率的跌倒探測，並且可以降低功耗consumption。<details>
<summary>Abstract</summary>
This paper presents a cost-effective, low-power approach to unintentional fall detection using knowledge distillation-based LSTM (Long Short-Term Memory) models to significantly improve accuracy. With a primary focus on analyzing time-series data collected from various sensors, the solution offers real-time detection capabilities, ensuring prompt and reliable identification of falls. The authors investigate fall detection models that are based on different sensors, comparing their accuracy rates and performance. Furthermore, they employ the technique of knowledge distillation to enhance the models' precision, resulting in refined accurate configurations that consume lower power. As a result, this proposed solution presents a compelling avenue for the development of energy-efficient fall detection systems for future advancements in this critical domain.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "unintentional fall detection" is translated as "意外落下检测" (yì wài luò xià jiàn dòu)* "knowledge distillation-based LSTM models" is translated as "基于知识填充的LSTM模型" (jī yú zhī xí fán zhī de LSTM mó delì)* "time-series data" is translated as "时间序列数据" (shí jiān xiàng zhì shuō yì)* "real-time detection capabilities" is translated as "实时检测能力" (shí jì jiàn dòu néng lì)* "prompt and reliable identification of falls" is translated as "快速可靠地识别落下" (kuài sù kě huì de shí bèi luò xià)* "energy-efficient fall detection systems" is translated as "能效的落下检测系统" (néng yì de luò xià jiàn dòu xì tuān)
</details></li>
</ul>
<hr>
<h2 id="Zero-delay-Consistent-Signal-Reconstruction-from-Streamed-Multivariate-Time-Series"><a href="#Zero-delay-Consistent-Signal-Reconstruction-from-Streamed-Multivariate-Time-Series" class="headerlink" title="Zero-delay Consistent Signal Reconstruction from Streamed Multivariate Time Series"></a>Zero-delay Consistent Signal Reconstruction from Streamed Multivariate Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12459">http://arxiv.org/abs/2308.12459</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emilio Ruiz-Moreno, Luis Miguel López-Ramos, Baltasar Beferull-Lozano</li>
<li>for: 本文为了实现流动数据流中的稳定信号重建。</li>
<li>methods: 本文使用了回归神经网络学习流动数据流中的空间时间相关性，以提高信号重建精度。</li>
<li>results: 对于流动数据流中的多变量时间序列，本文提出了一种稳定的信号重建方法，可以在零延迟响应下实现高精度的信号重建。<details>
<summary>Abstract</summary>
Digitalizing real-world analog signals typically involves sampling in time and discretizing in amplitude. Subsequent signal reconstructions inevitably incur an error that depends on the amplitude resolution and the temporal density of the acquired samples. From an implementation viewpoint, consistent signal reconstruction methods have proven a profitable error-rate decay as the sampling rate increases. Despite that, these results are obtained under offline settings. Therefore, a research gap exists regarding methods for consistent signal reconstruction from data streams. This paper presents a method that consistently reconstructs streamed multivariate time series of quantization intervals under a zero-delay response requirement. On the other hand, previous work has shown that the temporal dependencies within univariate time series can be exploited to reduce the roughness of zero-delay signal reconstructions. This work shows that the spatiotemporal dependencies within multivariate time series can also be exploited to achieve improved results. Specifically, the spatiotemporal dependencies of the multivariate time series are learned, with the assistance of a recurrent neural network, to reduce the roughness of the signal reconstruction on average while ensuring consistency. Our experiments show that our proposed method achieves a favorable error-rate decay with the sampling rate compared to a similar but non-consistent reconstruction.
</details>
<details>
<summary>摘要</summary>
digitizing real-world analog signals typically involves sampling in time and discretizing in amplitude. Subsequent signal reconstructions inevitably incur an error that depends on the amplitude resolution and the temporal density of the acquired samples. From an implementation viewpoint, consistent signal reconstruction methods have proven a profitable error-rate decay as the sampling rate increases. Despite that, these results are obtained under offline settings. Therefore, a research gap exists regarding methods for consistent signal reconstruction from data streams. This paper presents a method that consistently reconstructs streamed multivariate time series of quantization intervals under a zero-delay response requirement. On the other hand, previous work has shown that the temporal dependencies within univariate time series can be exploited to reduce the roughness of zero-delay signal reconstructions. This work shows that the spatiotemporal dependencies within multivariate time series can also be exploited to achieve improved results. Specifically, the spatiotemporal dependencies of the multivariate time series are learned, with the assistance of a recurrent neural network, to reduce the roughness of the signal reconstruction on average while ensuring consistency. Our experiments show that our proposed method achieves a favorable error-rate decay with the sampling rate compared to a similar but non-consistent reconstruction.Here's the translation in Traditional Chinese: digitizing real-world analog signals typically involves sampling in time and discretizing in amplitude. Subsequent signal reconstructions inevitably incur an error that depends on the amplitude resolution and the temporal density of the acquired samples. From an implementation viewpoint, consistent signal reconstruction methods have proven a profitable error-rate decay as the sampling rate increases. Despite that, these results are obtained under offline settings. Therefore, a research gap exists regarding methods for consistent signal reconstruction from data streams. This paper presents a method that consistently reconstructs streamed multivariate time series of quantization intervals under a zero-delay response requirement. On the other hand, previous work has shown that the temporal dependencies within univariate time series can be exploited to reduce the roughness of zero-delay signal reconstructions. This work shows that the spatiotemporal dependencies within multivariate time series can also be exploited to achieve improved results. Specifically, the spatiotemporal dependencies of the multivariate time series are learned, with the assistance of a recurrent neural network, to reduce the roughness of the signal reconstruction on average while ensuring consistency. Our experiments show that our proposed method achieves a favorable error-rate decay with the sampling rate compared to a similar but non-consistent reconstruction.
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-in-parameter-estimation-of-nonlinear-systems"><a href="#Machine-learning-in-parameter-estimation-of-nonlinear-systems" class="headerlink" title="Machine learning in parameter estimation of nonlinear systems"></a>Machine learning in parameter estimation of nonlinear systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12393">http://arxiv.org/abs/2308.12393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaushal Kumar</li>
<li>for: 這篇論文的目的是提出一種基於神經網絡的參數估計方法，並使用哈伯損失函數來優化參數估計。</li>
<li>methods: 這篇論文使用神經網絡學習架構，並運用哈伯損失函數來優化參數估計。</li>
<li>results: 這篇論文的實驗結果顯示，使用神經網絡和哈伯損失函數可以實現高精度的參數估計，並且可以應對不確定和雜質。<details>
<summary>Abstract</summary>
Accurately estimating parameters in complex nonlinear systems is crucial across scientific and engineering fields. We present a novel approach for parameter estimation using a neural network with the Huber loss function. This method taps into deep learning's abilities to uncover parameters governing intricate behaviors in nonlinear equations. We validate our approach using synthetic data and predefined functions that model system dynamics. By training the neural network with noisy time series data, it fine-tunes the Huber loss function to converge to accurate parameters. We apply our method to damped oscillators, Van der Pol oscillators, Lotka-Volterra systems, and Lorenz systems under multiplicative noise. The trained neural network accurately estimates parameters, evident from closely matching latent dynamics. Comparing true and estimated trajectories visually reinforces our method's precision and robustness. Our study underscores the Huber loss-guided neural network as a versatile tool for parameter estimation, effectively uncovering complex relationships in nonlinear systems. The method navigates noise and uncertainty adeptly, showcasing its adaptability to real-world challenges.
</details>
<details>
<summary>摘要</summary>
估算复杂非线性系统中参数的精度是科学和工程领域中的关键。我们提出了一种使用神经网络和惩整函数Huber来进行参数估算的新方法。这种方法利用深度学习的能力揭示非线性方程中的参数。我们使用 synthetic 数据和预定的函数来验证我们的方法。通过训练神经网络，它可以根据噪声时间序列数据来细化Huber惩整函数，以达到准确的参数。我们将方法应用于抑制振荡器、Van der Pol振荡器、Lotka-Volterra系统和lorenz系统中的多重噪声下。训练神经网络后，可以准确地估算参数，可以从相似的潜在动力学证明我们的方法的精度和稳定性。我们的研究证明了Huber惩整函数领导的神经网络为非线性系统参数估算的可靠工具，能够有效地揭示复杂的关系。该方法在噪声和不确定性中 navigates 得olis，证明其适应实际挑战。
</details></li>
</ul>
<hr>
<h2 id="FOSA-Full-Information-Maximum-Likelihood-FIML-Optimized-Self-Attention-Imputation-for-Missing-Data"><a href="#FOSA-Full-Information-Maximum-Likelihood-FIML-Optimized-Self-Attention-Imputation-for-Missing-Data" class="headerlink" title="FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data"></a>FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12388">http://arxiv.org/abs/2308.12388</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oudeng/fosa">https://github.com/oudeng/fosa</a></li>
<li>paper_authors: Ou Deng, Qun Jin</li>
<li>for: 填充缺失数据的有效Addressing missing values is crucial, especially in complex datasets.</li>
<li>methods:  combine FIML estimation with self-attention neural networks to refine initial estimates of missing values.</li>
<li>results: 1) superior accuracy and efficiency compared to traditional FIML techniques; 2) adaptability to diverse data structures; 3) robustness in the presence of up to 40% random missingness.<details>
<summary>Abstract</summary>
In data imputation, effectively addressing missing values is pivotal, especially in intricate datasets. This paper delves into the FIML Optimized Self-attention (FOSA) framework, an innovative approach that amalgamates the strengths of Full Information Maximum Likelihood (FIML) estimation with the capabilities of self-attention neural networks. Our methodology commences with an initial estimation of missing values via FIML, subsequently refining these estimates by leveraging the self-attention mechanism. Our comprehensive experiments on both simulated and real-world datasets underscore FOSA's pronounced advantages over traditional FIML techniques, encapsulating facets of accuracy, computational efficiency, and adaptability to diverse data structures. Intriguingly, even in scenarios where the Structural Equation Model (SEM) might be mis-specified, leading to suboptimal FIML estimates, the robust architecture of FOSA's self-attention component adeptly rectifies and optimizes the imputation outcomes. Our empirical tests reveal that FOSA consistently delivers commendable predictions, even in the face of up to 40% random missingness, highlighting its robustness and potential for wide-scale applications in data imputation.
</details>
<details>
<summary>摘要</summary>
在数据补充中，有效地处理缺失值是关键，特别是在复杂的数据集中。这篇论文探讨了FIML优化自注意（FOSA）框架，这是一种结合FIML估计的优点和自注意神经网络的创新方法。我们的方法开始于 initial 缺失值估计 via FIML，然后通过自注意机制来进一步改进这些估计。我们的完整的实验表明，FOSA在真实世界数据集和模拟数据集上表现出了明显的优势，包括精度、计算效率和适应不同数据结构。尤其是在SEM可能是错误的情况下，FOSA的自注意机制能够有效地修复和优化投入结果。我们的实验表明，FOSA可靠地提供了优秀的预测结果，即使缺失率高达40%，这 highlights its 可靠性和广泛的应用前景在数据补充领域。
</details></li>
</ul>
<hr>
<h2 id="Renormalizing-Diffusion-Models"><a href="#Renormalizing-Diffusion-Models" class="headerlink" title="Renormalizing Diffusion Models"></a>Renormalizing Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12355">http://arxiv.org/abs/2308.12355</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan Cotler, Semon Rezchikov</li>
<li>for: 学习 inverse renormalization group flows of statistical and quantum field theories</li>
<li>methods: 使用 diffusion models 学习 inverse process</li>
<li>results: 提出了一种基于机器学习的方法来研究场theory，并应用到了interacting statistical field theories 中的 RG flows  numericallyHere’s a more detailed explanation of each point:1. for: The paper is written for studying the inverse renormalization group flows of statistical and quantum field theories using machine learning methods, specifically diffusion models.2. methods: The paper uses diffusion models to learn the inverse process of nonperturbative renormalization group schemes, which are naturally written as diffusion processes in the space of fields. The authors combine these observations in a concrete framework for building machine learning-based models for studying field theories. They also detail how these models define a class of adaptive bridge (or parallel tempering) samplers for lattice field theory.3. results: The authors apply their methods to numerically find RG flows of interacting statistical field theories and provide explicit prescriptions for comparing results derived from models associated with different renormalization group schemes of interest. They also explain how to use diffusion models in a variational method to find ground states of quantum systems. The work provides an interpretation of multiscale diffusion models and gives physically-inspired suggestions for diffusion models with novel properties.<details>
<summary>Abstract</summary>
We explain how to use diffusion models to learn inverse renormalization group flows of statistical and quantum field theories. Diffusion models are a class of machine learning models which have been used to generate samples from complex distributions, such as the distribution of natural images, by learning the inverse process to a diffusion process which adds noise to the data until the distribution of the data is pure noise. Nonperturbative renormalization group schemes can naturally be written as diffusion processes in the space of fields. We combine these observations in a concrete framework for building ML-based models for studying field theories, in which the models learn the inverse process to an explicitly-specified renormalization group scheme. We detail how these models define a class of adaptive bridge (or parallel tempering) samplers for lattice field theory. Because renormalization group schemes have a physical meaning, we provide explicit prescriptions for how to compare results derived from models associated to several different renormalization group schemes of interest. We also explain how to use diffusion models in a variational method to find ground states of quantum systems. We apply some of our methods to numerically find RG flows of interacting statistical field theories. From the perspective of machine learning, our work provides an interpretation of multiscale diffusion models, and gives physically-inspired suggestions for diffusion models which should have novel properties.
</details>
<details>
<summary>摘要</summary>
我們介紹如何使用傳播模型來學習逆蘊立group流程的統計和量子場論。傳播模型是一種機器學習模型，可以生成複雜分布中的樣本，例如自然圖像分布，通過學習逆 процесс，將數據中的噪音給降低，直到數據的分布只有噪音。非修改性renormalization group scheme可以自然地寫作傳播過程，我們結合這些觀察，建立一個實際應用的框架，用於建立基於機器學習的場論研究模型。這些模型可以定義一種適應橋（或平行溫度）抽樣器，用於確定零點粒子場論。因為renormalization group scheme有物理意義，我們提供明確的指南，用於比較來自不同renormalization group scheme的結果。我們還解釋如何使用傳播模型來找到量子系統的基底 states。我們將一些方法應用到計算互動量子場論中的RG流程。從機器學習的角度來看，我們的工作提供了傳播模型的解釋，並給出了物理启发的傳播模型，這些模型應有新的性質。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generative-Model-based-Unfolding-with-Schrodinger-Bridges"><a href="#Improving-Generative-Model-based-Unfolding-with-Schrodinger-Bridges" class="headerlink" title="Improving Generative Model-based Unfolding with Schrödinger Bridges"></a>Improving Generative Model-based Unfolding with Schrödinger Bridges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12351">http://arxiv.org/abs/2308.12351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sascha Diefenbacher, Guan-Horng Liu, Vinicius Mikuni, Benjamin Nachman, Weili Nie</li>
<li>for: 用于高维ensional差分扩散测量</li>
<li>methods: 使用Schroedinger Bridges和扩散模型</li>
<li>results: 实现了对比今的性能Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written for the purpose of developing a new method for unfolding, which is a technique used to correct for detector effects in high-dimensional differential cross section measurements.</li>
<li>methods: The paper proposes the use of Schroedinger Bridges and diffusion models to create SBUnfold, a new unfolding approach that combines the strengths of both discriminative and generative models.</li>
<li>results: The paper shows that SBUnfold achieves excellent performance compared to state-of-the-art methods on a synthetic Z+jets dataset.<details>
<summary>Abstract</summary>
Machine learning-based unfolding has enabled unbinned and high-dimensional differential cross section measurements. Two main approaches have emerged in this research area: one based on discriminative models and one based on generative models. The main advantage of discriminative models is that they learn a small correction to a starting simulation while generative models scale better to regions of phase space with little data. We propose to use Schroedinger Bridges and diffusion models to create SBUnfold, an unfolding approach that combines the strengths of both discriminative and generative models. The key feature of SBUnfold is that its generative model maps one set of events into another without having to go through a known probability density as is the case for normalizing flows and standard diffusion models. We show that SBUnfold achieves excellent performance compared to state of the art methods on a synthetic Z+jets dataset.
</details>
<details>
<summary>摘要</summary>
Translate the given text into Simplified Chinese.<</SYS>>机器学习基于的 unfolding 技术已经实现了无桶和高维差异扩散测量。这两种主要方法是基于推论模型和基于生成模型。推论模型的主要优点是它可以学习一个小的修正来对 Starting simulation 进行修正，而生成模型则在数据 scarcity 地区更好地缩放。我们提议使用 Schroedinger Bridges 和扩散模型创建 SBUnfold，这是一种 combining 两种模型的 unfolding 方法。SBUnfold 的关键特点是其生成模型可以将一个事件集转换成另一个事件集，无需通过一个知道的概率密度。我们示出 SBUnfold 可以与现有技术相比，在一个 synthetic Z+jets 数据集上实现出色的性能。
</details></li>
</ul>
<hr>
<h2 id="Extended-Linear-Regression-A-Kalman-Filter-Approach-for-Minimizing-Loss-via-Area-Under-the-Curve"><a href="#Extended-Linear-Regression-A-Kalman-Filter-Approach-for-Minimizing-Loss-via-Area-Under-the-Curve" class="headerlink" title="Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss via Area Under the Curve"></a>Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss via Area Under the Curve</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12280">http://arxiv.org/abs/2308.12280</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gokulprasath R</li>
<li>for: 提高线性回归模型的精度，使其更适用于实际应用。</li>
<li>methods:  integrate Kalman filter into linear regression model，使用梯度下降法更新参数，并分析曲线面积以最小化损失。</li>
<li>results: 提出一种可靠的线性回归方程，避免了不断更新参数的缺点，并且可以处理部分数据集，不同于需要完整数据集的方法。<details>
<summary>Abstract</summary>
This research enhances linear regression models by integrating a Kalman filter and analysing curve areas to minimize loss. The goal is to develop an optimal linear regression equation using stochastic gradient descent (SGD) for weight updating. Our approach involves a stepwise process, starting with user-defined parameters. The linear regression model is trained using SGD, tracking weights and loss separately and zipping them finally. A Kalman filter is then trained based on weight and loss arrays to predict the next consolidated weights. Predictions result from multiplying input averages with weights, evaluated for loss to form a weight-versus-loss curve. The curve's equation is derived using the two-point formula, and area under the curve is calculated via integration. The linear regression equation with minimum area becomes the optimal curve for prediction. Benefits include avoiding constant weight updates via gradient descent and working with partial datasets, unlike methods needing the entire set. However, computational complexity should be considered. The Kalman filter's accuracy might diminish beyond a certain prediction range.
</details>
<details>
<summary>摘要</summary>
这项研究升级了线性回归模型，通过结合卡尔曼滤波器和分析曲线面积来减少损失。目标是通过随机梯度下降（SGD）更新加权来开发最优的线性回归方程。我们的方法包括一个步骤性的过程，从用户定义的参数开始，然后通过SGD训练线性回归模型，并跟踪加权和损失分别。接着，我们使用卡尔曼滤波器根据加权和损失数组预测下一个总结合 weights。这些预测结果来自输入平均值与加权的乘积，并且评估损失来形成一个加权对损失曲线。曲线的方程由两点方程 derive，而曲线面积则通过积分来计算。最优的曲线方程是 minimize 损失的加权对损失曲线方程。 benefits 包括避免了不断更新加权 via 随机梯度下降，以及与部分数据集工作，不同于需要整个集合。然而，计算复杂性应该被考虑。卡尔曼滤波器的准确性可能在预测范围内减退。
</details></li>
</ul>
<hr>
<h2 id="On-Manifold-Projected-Gradient-Descent"><a href="#On-Manifold-Projected-Gradient-Descent" class="headerlink" title="On-Manifold Projected Gradient Descent"></a>On-Manifold Projected Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12279">http://arxiv.org/abs/2308.12279</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JonasGrabbe/GradientDecentOnManifolds">https://github.com/JonasGrabbe/GradientDecentOnManifolds</a></li>
<li>paper_authors: Aaron Mahler, Tyrus Berry, Tom Stephens, Harbir Antil, Michael Merritt, Jeanie Schreiber, Ioannis Kevrekidis</li>
<li>For:	+ The paper aims to provide a computable, direct, and mathematically rigorous approximation to the differential geometry of class manifolds for high-dimensional data.	+ The authors aim to improve the robustness of neural network image classifiers to adversarial attacks by generating novel, on-manifold data samples and implementing a projected gradient descent algorithm for on-manifold adversarial training.* Methods:	+ The authors use conformally invariant diffusion maps (CIDM) to approximate class manifolds in diffusion coordinates, and develop the Nystr&quot;{o}m projection to project novel points onto class manifolds in this setting.	+ They employ the spectral exterior calculus (SEC) to determine geometric quantities such as tangent vectors of the manifold.	+ They use these tools to obtain adversarial examples that reside on a class manifold, yet fool a classifier.* Results:	+ The authors obtain adversarial examples that reside on a class manifold, yet fool a classifier.	+ They demonstrate the effectiveness of their approach by showing that these misclassifications can be explained in terms of human-understandable manipulations within the data, by expressing the on-manifold adversary in the semantic basis on the manifold.<details>
<summary>Abstract</summary>
This work provides a computable, direct, and mathematically rigorous approximation to the differential geometry of class manifolds for high-dimensional data, along with nonlinear projections from input space onto these class manifolds. The tools are applied to the setting of neural network image classifiers, where we generate novel, on-manifold data samples, and implement a projected gradient descent algorithm for on-manifold adversarial training. The susceptibility of neural networks (NNs) to adversarial attack highlights the brittle nature of NN decision boundaries in input space. Introducing adversarial examples during training has been shown to reduce the susceptibility of NNs to adversarial attack; however, it has also been shown to reduce the accuracy of the classifier if the examples are not valid examples for that class. Realistic "on-manifold" examples have been previously generated from class manifolds in the latent of an autoencoder. Our work explores these phenomena in a geometric and computational setting that is much closer to the raw, high-dimensional input space than can be provided by VAE or other black box dimensionality reductions. We employ conformally invariant diffusion maps (CIDM) to approximate class manifolds in diffusion coordinates, and develop the Nystr\"{o}m projection to project novel points onto class manifolds in this setting. On top of the manifold approximation, we leverage the spectral exterior calculus (SEC) to determine geometric quantities such as tangent vectors of the manifold. We use these tools to obtain adversarial examples that reside on a class manifold, yet fool a classifier. These misclassifications then become explainable in terms of human-understandable manipulations within the data, by expressing the on-manifold adversary in the semantic basis on the manifold.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这个工作提出了一种新的方法来生成高维数据上的隐藏攻击例子，使其能够让抽象分类器错误分类。该方法使用了一种可计算、直接、数学上正确的抽象几何方法来 aproximate高维数据上的类抽象 manifold。该方法还使用了一种不变射影映射（CIDM）来 aproximate类抽象 manifold 在扩散坐标系中，并使用了 Nystr\"{o}m 投影将新的点投影到类抽象 manifold 上。此外，该方法还使用了 spectral exterior calculus（SEC）来确定类抽象 manifold 上的几何量，如 Tangent vector。得到的隐藏攻击例子都是在类抽象 manifold 上，且可以用来解释分类器的错误分类。
</details></li>
</ul>
<hr>
<h2 id="LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition"><a href="#LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition" class="headerlink" title="LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition"></a>LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12882">http://arxiv.org/abs/2308.12882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti</li>
<li>for:  Audio classification, particularly in recognizing speech commands or sound events, despite perturbations and adversarial attacks.</li>
<li>methods:  Neuro-inspired convolutional neural networks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA) in multiple layers (LCANets++), combining supervised and unsupervised learning to reduce dependency on labeled samples.</li>
<li>results:  LCANets++ are more robust than standard CNNs and LCANets against perturbations and various types of attacks, such as background noise and black-box and white-box attacks like evasion and fast gradient sign (FGSM) attacks.<details>
<summary>Abstract</summary>
Audio classification aims at recognizing audio signals, including speech commands or sound events. However, current audio classifiers are susceptible to perturbations and adversarial attacks. In addition, real-world audio classification tasks often suffer from limited labeled data. To help bridge these gaps, previous work developed neuro-inspired convolutional neural networks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA) in the first layer (i.e., LCANets) for computer vision. LCANets learn in a combination of supervised and unsupervised learning, reducing dependency on labeled samples. Motivated by the fact that auditory cortex is also sparse, we extend LCANets to audio recognition tasks and introduce LCANets++, which are CNNs that perform sparse coding in multiple layers via LCA. We demonstrate that LCANets++ are more robust than standard CNNs and LCANets against perturbations, e.g., background noise, as well as black-box and white-box attacks, e.g., evasion and fast gradient sign (FGSM) attacks.
</details>
<details>
<summary>摘要</summary>
audio分类目标是识别音频信号，包括语音命令或声音事件。然而，当前的音频分类器受到干扰和敌意攻击的影响。此外，实际世界中的音频分类任务经常受到有限的标注数据的限制。为了bridge这些差距，前一些工作已经开发了基于神经元的启发式 convolutional neural networks (CNNs) 的 sparse coding via the Locally Competitive Algorithm (LCA) 的首层 (i.e., LCANets)  для计算机视觉。LCANets 通过精心设计的损失函数和训练策略来学习，从而减少了对标注样本的依赖。受到auditory cortex 的启发，我们扩展了 LCANets 到音频识别任务，并 introduce LCANets++，它们是 CNNs 在多层 via LCA 进行 sparse coding 的。我们示示了 LCANets++ 对于干扰、黑盒和白盒攻击（如误导和快速梯度签名攻击）都更加Robust。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Negative-User-Feedback-and-Measuring-Responsiveness-for-Sequential-Recommenders"><a href="#Learning-from-Negative-User-Feedback-and-Measuring-Responsiveness-for-Sequential-Recommenders" class="headerlink" title="Learning from Negative User Feedback and Measuring Responsiveness for Sequential Recommenders"></a>Learning from Negative User Feedback and Measuring Responsiveness for Sequential Recommenders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12256">http://arxiv.org/abs/2308.12256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yueqi Wang, Yoni Halpern, Shuo Chang, Jingchen Feng, Elaine Ya Le, Longfei Li, Xujian Liang, Min-Cheng Huang, Shane Li, Alex Beutel, Yaping Zhang, Shuchao Bi</li>
<li>for: 本研究旨在强化sequential retrieval模型中对负反馈的学习，以提高推荐系统的响应性和精度。</li>
<li>methods: 研究人员采用了一种“不推荐”损失函数，将负反馈纳入模型训练对象中，以提高模型对负反馈的响应性。</li>
<li>results: 实验结果表明，在大规模实际推荐系统中，该方法可以提高推荐系统的响应性和精度，并且可以准确地捕捉用户的负反馈信号。<details>
<summary>Abstract</summary>
Sequential recommenders have been widely used in industry due to their strength in modeling user preferences. While these models excel at learning a user's positive interests, less attention has been paid to learning from negative user feedback. Negative user feedback is an important lever of user control, and comes with an expectation that recommenders should respond quickly and reduce similar recommendations to the user. However, negative feedback signals are often ignored in the training objective of sequential retrieval models, which primarily aim at predicting positive user interactions. In this work, we incorporate explicit and implicit negative user feedback into the training objective of sequential recommenders in the retrieval stage using a "not-to-recommend" loss function that optimizes for the log-likelihood of not recommending items with negative feedback. We demonstrate the effectiveness of this approach using live experiments on a large-scale industrial recommender system. Furthermore, we address a challenge in measuring recommender responsiveness to negative feedback by developing a counterfactual simulation framework to compare recommender responses between different user actions, showing improved responsiveness from the modeling change.
</details>
<details>
<summary>摘要</summary>
幾何推薦器在業界中廣泛使用，因為它們能夠很好地模型用戶的喜好。然而，這些模型對於学習用戶的負面反饋來說，Received less attention。負面用戶反饋是用戶控制的重要來源，而且預期推薦器會快速地對用戶的負面反饋進行回應，以減少類似的推薦。然而，在sequential retrieval模型的訓練目標中，通常忽略負面用戶反饋的信號。在這個工作中，我們將explicit和implicit的負面用戶反饋包含在sequential retrieval模型的訓練目標中，使用“不推薦”損失函數，以便提高log-likelihood不推薦項目。我們透過實際實驗，證明這種方法的效果。此外，我們解決了推薦器對負面反饋的回應的評估挑戰，通過開發counterfactual simulation框架，比較不同用戶動作的推薦回應，顯示改進的回應性。
</details></li>
</ul>
<hr>
<h2 id="How-Safe-Am-I-Given-What-I-See-Calibrated-Prediction-of-Safety-Chances-for-Image-Controlled-Autonomy"><a href="#How-Safe-Am-I-Given-What-I-See-Calibrated-Prediction-of-Safety-Chances-for-Image-Controlled-Autonomy" class="headerlink" title="How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy"></a>How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12252">http://arxiv.org/abs/2308.12252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maozj6/hsai-predictor">https://github.com/maozj6/hsai-predictor</a></li>
<li>paper_authors: Zhenjiang Mao, Carson Sobolewski, Ivan Ruchkin</li>
<li>for: 本研究旨在开发一种可靠的 END-TO-END 学习系统，以满足自动化系统的性能和安全性需求。</li>
<li>methods: 本研究使用生成型世界模型，不需要低维度的解释状态，以解决在线安全预测问题。研究者还使用了适配性的学习管道，以满足不同的安全需求。</li>
<li>results: 研究者通过实验证明，提出的学习管道可以在图像控制系统中提供高度的安全预测，并且具有统计calibration保证。<details>
<summary>Abstract</summary>
End-to-end learning has emerged as a major paradigm for developing autonomous systems. Unfortunately, with its performance and convenience comes an even greater challenge of safety assurance. A key factor of this challenge is the absence of the notion of a low-dimensional and interpretable dynamical state, around which traditional assurance methods revolve. Focusing on the online safety prediction problem, this paper proposes a configurable family of learning pipelines based on generative world models, which do not require low-dimensional states. To implement these pipelines, we overcome the challenges of learning safety-informed latent representations and missing safety labels under prediction-induced distribution shift. These pipelines come with statistical calibration guarantees on their safety chance predictions based on conformal prediction. We perform an extensive evaluation of the proposed learning pipelines on two case studies of image-controlled systems: a racing car and a cartpole.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.LG_2023_08_24/" data-id="cllr07v2v001ljtr857wf9ubj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/24/eess.IV_2023_08_24/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-24
        
      </div>
    </a>
  
  
    <a href="/2023/08/23/cs.CL_2023_08_23/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-08-23</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">26</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/physics-optics/">physics.optics</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/q-bio-NC/">q-bio.NC</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/quant-ph/">quant-ph</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
  <a href="#search" class="mobile-nav-link st-search-show-outputs">Search</a>
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


</div>
</body>
</html>
