
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-08-24 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12840 repo_url: None paper_authors: Mohamed R.">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-08-24">
<meta property="og:url" content="http://nullscc.github.io/2023/08/24/cs.AI_2023_08_24/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.12840 repo_url: None paper_authors: Mohamed R.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-23T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-25T05:54:50.846Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Fun Paper" type="application/atom+xml">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
      <a class="main-nav-link st-search-show-outputs">Search</a>
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.AI_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-08-24
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="FaceTouch-Detecting-hand-to-face-touch-with-supervised-contrastive-learning-to-assist-in-tracing-infectious-disease"><a href="#FaceTouch-Detecting-hand-to-face-touch-with-supervised-contrastive-learning-to-assist-in-tracing-infectious-disease" class="headerlink" title="FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease"></a>FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12840">http://arxiv.org/abs/2308.12840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed R. Ibrahim, Terry Lyons</li>
</ul>
<p>Abstract:<br>Through our respiratory system, many viruses and diseases frequently spread and pass from one person to another. Covid-19 served as an example of how crucial it is to track down and cut back on contacts to stop its spread. There is a clear gap in finding automatic methods that can detect hand-to-face contact in complex urban scenes or indoors. In this paper, we introduce a computer vision framework, called FaceTouch, based on deep learning. It comprises deep sub-models to detect humans and analyse their actions. FaceTouch seeks to detect hand-to-face touches in the wild, such as through video chats, bus footage, or CCTV feeds. Despite partial occlusion of faces, the introduced system learns to detect face touches from the RGB representation of a given scene by utilising the representation of the body gestures such as arm movement. This has been demonstrated to be useful in complex urban scenarios beyond simply identifying hand movement and its closeness to faces. Relying on Supervised Contrastive Learning, the introduced model is trained on our collected dataset, given the absence of other benchmark datasets. The framework shows a strong validation in unseen datasets which opens the door for potential deployment.</p>
<hr>
<h2 id="Short-Run-Transit-Route-Planning-Decision-Support-System-Using-a-Deep-Learning-Based-Weighted-Graph"><a href="#Short-Run-Transit-Route-Planning-Decision-Support-System-Using-a-Deep-Learning-Based-Weighted-Graph" class="headerlink" title="Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph"></a>Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12828">http://arxiv.org/abs/2308.12828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nadav Shalit, Michael Fire, Dima Kagan, Eran Ben-Elia</li>
</ul>
<p>Abstract:<br>Public transport routing plays a crucial role in transit network design, ensuring a satisfactory level of service for passengers. However, current routing solutions rely on traditional operational research heuristics, which can be time-consuming to implement and lack the ability to provide quick solutions. Here, we propose a novel deep learning-based methodology for a decision support system that enables public transport (PT) planners to identify short-term route improvements rapidly. By seamlessly adjusting specific sections of routes between two stops during specific times of the day, our method effectively reduces times and enhances PT services. Leveraging diverse data sources such as GTFS and smart card data, we extract features and model the transportation network as a directed graph. Using self-supervision, we train a deep learning model for predicting lateness values for road segments.   These lateness values are then utilized as edge weights in the transportation graph, enabling efficient path searching. Through evaluating the method on Tel Aviv, we are able to reduce times on more than 9% of the routes. The improved routes included both intraurban and suburban routes showcasing a fact highlighting the model’s versatility. The findings emphasize the potential of our data-driven decision support system to enhance public transport and city logistics, promoting greater efficiency and reliability in PT services.</p>
<hr>
<h2 id="Job-Shop-Scheduling-Benchmark-Environments-and-Instances-for-Learning-and-Non-learning-Methods"><a href="#Job-Shop-Scheduling-Benchmark-Environments-and-Instances-for-Learning-and-Non-learning-Methods" class="headerlink" title="Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods"></a>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12794">http://arxiv.org/abs/2308.12794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-for-decision-making-tue/job_shop_scheduling_benchmark">https://github.com/ai-for-decision-making-tue/job_shop_scheduling_benchmark</a></li>
<li>paper_authors: Robbert Reijnen, Kjell van Straaten, Zaharah Bukhsh, Yingqian Zhang</li>
</ul>
<p>Abstract:<br>We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals). Our primary goal is to provide a centralized hub for researchers, practitioners, and enthusiasts interested in tackling machine scheduling challenges.</p>
<hr>
<h2 id="Acquiring-Qualitative-Explainable-Graphs-for-Automated-Driving-Scene-Interpretation"><a href="#Acquiring-Qualitative-Explainable-Graphs-for-Automated-Driving-Scene-Interpretation" class="headerlink" title="Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation"></a>Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12755">http://arxiv.org/abs/2308.12755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nassim Belmecheri, Arnaud Gotlieb, Nadjib Lazaar, Helge Spieker</li>
</ul>
<p>Abstract:<br>The future of automated driving (AD) is rooted in the development of robust, fair and explainable artificial intelligence methods. Upon request, automated vehicles must be able to explain their decisions to the driver and the car passengers, to the pedestrians and other vulnerable road users and potentially to external auditors in case of accidents. However, nowadays, most explainable methods still rely on quantitative analysis of the AD scene representations captured by multiple sensors. This paper proposes a novel representation of AD scenes, called Qualitative eXplainable Graph (QXG), dedicated to qualitative spatiotemporal reasoning of long-term scenes. The construction of this graph exploits the recent Qualitative Constraint Acquisition paradigm. Our experimental results on NuScenes, an open real-world multi-modal dataset, show that the qualitative eXplainable graph of an AD scene composed of 40 frames can be computed in real-time and light in space storage which makes it a potentially interesting tool for improved and more trustworthy perception and control processes in AD.</p>
<hr>
<h2 id="Motion-In-Betweening-with-Phase-Manifolds"><a href="#Motion-In-Betweening-with-Phase-Manifolds" class="headerlink" title="Motion In-Betweening with Phase Manifolds"></a>Motion In-Betweening with Phase Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12751">http://arxiv.org/abs/2308.12751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pauzii/phasebetweener">https://github.com/pauzii/phasebetweener</a></li>
<li>paper_authors: Paul Starke, Sebastian Starke, Taku Komura, Frank Steinicke</li>
</ul>
<p>Abstract:<br>This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder. Our approach utilizes a mixture-of-experts neural network model, in which the phases cluster movements in both space and time with different expert weights. Each generated set of weights then produces a sequence of poses in an autoregressive manner between the current and target state of the character. In addition, to satisfy poses which are manually modified by the animators or where certain end effectors serve as constraints to be reached by the animation, a learned bi-directional control scheme is implemented to satisfy such constraints. The results demonstrate that using phases for motion in-betweening tasks sharpen the interpolated movements, and furthermore stabilizes the learning process. Moreover, using phases for motion in-betweening tasks can also synthesize more challenging movements beyond locomotion behaviors. Additionally, style control is enabled between given target keyframes. Our proposed framework can compete with popular state-of-the-art methods for motion in-betweening in terms of motion quality and generalization, especially in the existence of long transition durations. Our framework contributes to faster prototyping workflows for creating animated character sequences, which is of enormous interest for the game and film industry.</p>
<hr>
<h2 id="Separating-the-Human-Touch-from-AI-Generated-Text-using-Higher-Criticism-An-Information-Theoretic-Approach"><a href="#Separating-the-Human-Touch-from-AI-Generated-Text-using-Higher-Criticism-An-Information-Theoretic-Approach" class="headerlink" title="Separating the Human Touch from AI-Generated Text using Higher Criticism: An Information-Theoretic Approach"></a>Separating the Human Touch from AI-Generated Text using Higher Criticism: An Information-Theoretic Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12747">http://arxiv.org/abs/2308.12747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alon Kipnis</li>
</ul>
<p>Abstract:<br>We propose a method to determine whether a given article was entirely written by a generative language model versus an alternative situation in which the article includes some significant edits by a different author, possibly a human. Our process involves many perplexity tests for the origin of individual sentences or other text atoms, combining these multiple tests using Higher Criticism (HC). As a by-product, the method identifies parts suspected to be edited. The method is motivated by the convergence of the log-perplexity to the cross-entropy rate and by a statistical model for edited text saying that sentences are mostly generated by the language model, except perhaps for a few sentences that might have originated via a different mechanism. We demonstrate the effectiveness of our method using real data and analyze the factors affecting its success. This analysis raises several interesting open challenges whose resolution may improve the method’s effectiveness.</p>
<hr>
<h2 id="Human-Comprehensible-Active-Learning-of-Genome-Scale-Metabolic-Networks"><a href="#Human-Comprehensible-Active-Learning-of-Genome-Scale-Metabolic-Networks" class="headerlink" title="Human Comprehensible Active Learning of Genome-Scale Metabolic Networks"></a>Human Comprehensible Active Learning of Genome-Scale Metabolic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12740">http://arxiv.org/abs/2308.12740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lun Ai, Shi-Shun Liang, Wang-Zhou Dai, Liam Hallett, Stephen H. Muggleton, Geoff S. Baldwin</li>
</ul>
<p>Abstract:<br>An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach that efficiently explores the hypothesis space and guides experimental design is urgently needed for the Design-Build-Test-Learn (DBTL) cycle of the host cell system. We introduce a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. In contrast to numerical models, ILP-iML1515 is built on comprehensible logical representations of a genome-scale metabolic model and can update the model by learning new logical structures from auxotrophic mutant trials. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that reduce the experimental cost of learning gene functions in comparison to randomly selected experiments.</p>
<hr>
<h2 id="Asymmetric-Co-Training-with-Explainable-Cell-Graph-Ensembling-for-Histopathological-Image-Classification"><a href="#Asymmetric-Co-Training-with-Explainable-Cell-Graph-Ensembling-for-Histopathological-Image-Classification" class="headerlink" title="Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification"></a>Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12737">http://arxiv.org/abs/2308.12737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Yang, Zhongyu Li, Chen Liu, Xiangde Luo, Xingguang Wang, Dou Xu, Chaoqun Li, Xiaoying Qin, Meng Yang, Long Jin</li>
</ul>
<p>Abstract:<br>Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, GCNs underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integrate the two asymmetric branches. Notably, we collect a private clinically acquired dataset termed LUAD7C, including seven subtypes of lung adenocarcinoma, which is rare and more challenging. We evaluated our approach on the private LUAD7C and public colorectal cancer datasets, showcasing its superior performance, explainability, and generalizability in multi-class histopathological image classification.</p>
<hr>
<h2 id="DeepLOC-Deep-Learning-based-Bone-Pathology-Localization-and-Classification-in-Wrist-X-ray-Images"><a href="#DeepLOC-Deep-Learning-based-Bone-Pathology-Localization-and-Classification-in-Wrist-X-ray-Images" class="headerlink" title="DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images"></a>DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12727">http://arxiv.org/abs/2308.12727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Razan Dibo, Andrey Galichin, Pavel Astashev, Dmitry V. Dylov, Oleg Y. Rogov</li>
</ul>
<p>Abstract:<br>In recent years, computer-aided diagnosis systems have shown great potential in assisting radiologists with accurate and efficient medical image analysis. This paper presents a novel approach for bone pathology localization and classification in wrist X-ray images using a combination of YOLO (You Only Look Once) and the Shifted Window Transformer (Swin) with a newly proposed block. The proposed methodology addresses two critical challenges in wrist X-ray analysis: accurate localization of bone pathologies and precise classification of abnormalities. The YOLO framework is employed to detect and localize bone pathologies, leveraging its real-time object detection capabilities. Additionally, the Swin, a transformer-based module, is utilized to extract contextual information from the localized regions of interest (ROIs) for accurate classification.</p>
<hr>
<h2 id="Continuous-Reinforcement-Learning-based-Dynamic-Difficulty-Adjustment-in-a-Visual-Working-Memory-Game"><a href="#Continuous-Reinforcement-Learning-based-Dynamic-Difficulty-Adjustment-in-a-Visual-Working-Memory-Game" class="headerlink" title="Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game"></a>Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12726">http://arxiv.org/abs/2308.12726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoud Rahimi, Hadi Moradi, Abdol-hossein Vahabie, Hamed Kebriaei</li>
</ul>
<p>Abstract:<br>Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a player’s experience in video games. Recently, Reinforcement Learning (RL) methods have been employed for DDA in non-competitive games; nevertheless, they rely solely on discrete state-action space with a small search space. In this paper, we propose a continuous RL-based DDA methodology for a visual working memory (VWM) game to handle the complex search space for the difficulty of memorization. The proposed RL-based DDA tailors game difficulty based on the player’s score and game difficulty in the last trial. We defined a continuous metric for the difficulty of memorization. Then, we consider the task difficulty and the vector of difficulty-score as the RL’s action and state, respectively. We evaluated the proposed method through a within-subject experiment involving 52 subjects. The proposed approach was compared with two rule-based difficulty adjustment methods in terms of player’s score and game experience measured by a questionnaire. The proposed RL-based approach resulted in a significantly better game experience in terms of competence, tension, and negative and positive affect. Players also achieved higher scores and win rates. Furthermore, the proposed RL-based DDA led to a significantly less decline in the score in a 20-trial session.</p>
<hr>
<h2 id="VIGC-Visual-Instruction-Generation-and-Correction"><a href="#VIGC-Visual-Instruction-Generation-and-Correction" class="headerlink" title="VIGC: Visual Instruction Generation and Correction"></a>VIGC: Visual Instruction Generation and Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12714">http://arxiv.org/abs/2308.12714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Wang, Fan Wu, Xiao Han, Jiahui Peng, Huaping Zhong, Pan Zhang, Xiaoyi Dong, Weijia Li, Wei Li, Jiaqi Wang, Conghui He</li>
</ul>
<p>Abstract:<br>The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However, the scarcity of high-quality instruction-tuning data for vision-language tasks remains a challenge. The current leading paradigm, such as LLaVA, relies on language-only GPT-4 to generate data, which requires pre-annotated image captions and detection bounding boxes, suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models (MLLMs) to generate instruction data for vision-language tasks. However, it’s worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue, this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to generate instruction-tuning data and progressively enhance its quality on-the-fly. Specifically, Visual Instruction Generation (VIG) guides the vision-language model to generate diverse instruction-tuning data. To ensure generation quality, Visual Instruction Correction (VIC) adopts an iterative update mechanism to correct any inaccuracies in data produced by VIG, effectively reducing the risk of hallucination. Leveraging the diverse, high-quality data generated by VIGC, we finetune mainstream models and validate data quality based on various evaluations. Experimental results demonstrate that VIGC not only compensates for the shortcomings of language-only data generation methods, but also effectively enhances the benchmark performance. The models, datasets, and code will be made publicly available.</p>
<hr>
<h2 id="SayCanPay-Heuristic-Planning-with-Large-Language-Models-using-Learnable-Domain-Knowledge"><a href="#SayCanPay-Heuristic-Planning-with-Large-Language-Models-using-Learnable-Domain-Knowledge" class="headerlink" title="SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge"></a>SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12682">http://arxiv.org/abs/2308.12682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishi Hazra, Pedro Zuidberg Dos Martires, Luc De Raedt</li>
</ul>
<p>Abstract:<br>Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast “world knowledge”. Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions’ feasibility (Can) and long-term reward&#x2F;payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective elements into the generated plans, and (3) using heuristic search over actions. Our extensive evaluations show that our model surpasses other LLM planning approaches.</p>
<hr>
<h2 id="LR-XFL-Logical-Reasoning-based-Explainable-Federated-Learning"><a href="#LR-XFL-Logical-Reasoning-based-Explainable-Federated-Learning" class="headerlink" title="LR-XFL: Logical Reasoning-based Explainable Federated Learning"></a>LR-XFL: Logical Reasoning-based Explainable Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12681">http://arxiv.org/abs/2308.12681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanci Zhang, Han Yu</li>
</ul>
<p>Abstract:<br>Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients’ local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in terms of classification accuracy, rule accuracy and rule fidelity, respectively. The explicit rule evaluation and expression under LR-XFL enable human experts to validate and correct the rules on the server side, hence improving the global FL model’s robustness to errors. It has the potential to enhance the transparency of FL models for areas like healthcare and finance where both data privacy and explainability are important.</p>
<hr>
<h2 id="Improving-Translation-Faithfulness-of-Large-Language-Models-via-Augmenting-Instructions"><a href="#Improving-Translation-Faithfulness-of-Large-Language-Models-via-Augmenting-Instructions" class="headerlink" title="Improving Translation Faithfulness of Large Language Models via Augmenting Instructions"></a>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12674">http://arxiv.org/abs/2308.12674</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pppa2019/swie_overmiss_llm4mt">https://github.com/pppa2019/swie_overmiss_llm4mt</a></li>
<li>paper_authors: Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou</li>
</ul>
<p>Abstract:<br>Large Language Models (LLMs) present strong general capabilities, and a current compelling challenge is stimulating their specialized capabilities, such as machine translation, through low-cost instruction tuning. The standard instruction-following data is sequentially organized as the concatenation of an instruction, an input, and a response. As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding. To alleviate the above issues, We propose SWIE (Segment-Weighted Instruction Embedding) and an instruction-following dataset OVERMISS. SWIE improves the model instruction understanding by adding a global instruction representation on the following input and response representations. OVERMISS improves model faithfulness by comparing over-translation and miss-translation results with the correct translation. We apply our methods to two main-stream open-source LLMs, BLOOM and LLaMA. The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk. Additionally, OVERMISS outperforms the baseline in translation performance (e.g. an increase in BLEU scores from 0.69 to 3.12 and an average improvement of 0.48 percentage comet scores for LLaMA-7b) with further enhancements seen in models combining OVERMISS and SWIE (e.g. the BLUE scores increase up to 0.56 from English to German across three different backbones), and both exhibit improvements in the faithfulness metric based on word alignment.</p>
<hr>
<h2 id="Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers"><a href="#Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers" class="headerlink" title="Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers"></a>Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12661">http://arxiv.org/abs/2308.12661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
</ul>
<p>Abstract:<br>Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards. However, designing effective out-of-distribution tests that encompass all possible scenarios while preserving accurate label information is a challenging task. Existing methodologies often entail a compromise between variety and constraint levels for attacks and sometimes even both. In a first step towards a more holistic robustness evaluation of image classification models, we introduce an attack method based on image solarization that is conceptually straightforward yet avoids jeopardizing the global structure of natural images independent of the intensity. Through comprehensive evaluations of multiple ImageNet models, we demonstrate the attack’s capacity to degrade accuracy significantly, provided it is not integrated into the training augmentations. Interestingly, even then, no full immunity to accuracy deterioration is achieved. In other settings, the attack can often be simplified into a black-box attack with model-independent parameters. Defenses against other corruptions do not consistently extend to be effective against our specific attack.   Project website: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></p>
<hr>
<h2 id="kTrans-Knowledge-Aware-Transformer-for-Binary-Code-Embedding"><a href="#kTrans-Knowledge-Aware-Transformer-for-Binary-Code-Embedding" class="headerlink" title="kTrans: Knowledge-Aware Transformer for Binary Code Embedding"></a>kTrans: Knowledge-Aware Transformer for Binary Code Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12659">http://arxiv.org/abs/2308.12659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/learner0x5a/ktrans-release">https://github.com/learner0x5a/ktrans-release</a></li>
<li>paper_authors: Wenyu Zhu, Hao Wang, Yuchen Zhou, Jiaming Wang, Zihan Sha, Zeyu Gao, Chao Zhang</li>
</ul>
<p>Abstract:<br>Binary Code Embedding (BCE) has important applications in various reverse engineering tasks such as binary code similarity detection, type recovery, control-flow recovery and data-flow analysis. Recent studies have shown that the Transformer model can comprehend the semantics of binary code to support downstream tasks. However, existing models overlooked the prior knowledge of assembly language. In this paper, we propose a novel Transformer-based approach, namely kTrans, to generate knowledge-aware binary code embedding. By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework. We inspect the generated embeddings with outlier detection and visualization, and also apply kTrans to 3 downstream tasks: Binary Code Similarity Detection (BCSD), Function Type Recovery (FTR) and Indirect Call Recognition (ICR). Evaluation results show that kTrans can generate high-quality binary code embeddings, and outperforms state-of-the-art (SOTA) approaches on downstream tasks by 5.2%, 6.8%, and 12.6% respectively. kTrans is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Learner0x5a/kTrans-release">https://github.com/Learner0x5a/kTrans-release</a></p>
<hr>
<h2 id="APART-Diverse-Skill-Discovery-using-All-Pairs-with-Ascending-Reward-and-DropouT"><a href="#APART-Diverse-Skill-Discovery-using-All-Pairs-with-Ascending-Reward-and-DropouT" class="headerlink" title="APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT"></a>APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12649">http://arxiv.org/abs/2308.12649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadar Schreiber Galler, Tom Zahavy, Guillaume Desjardins, Alon Cohen</li>
</ul>
<p>Abstract:<br>We study diverse skill discovery in reward-free environments, aiming to discover all possible skills in simple grid-world environments where prior methods have struggled to succeed. This problem is formulated as mutual training of skills using an intrinsic reward and a discriminator trained to predict a skill given its trajectory. Our initial solution replaces the standard one-vs-all (softmax) discriminator with a one-vs-one (all pairs) discriminator and combines it with a novel intrinsic reward function and a dropout regularization technique. The combined approach is named APART: Diverse Skill Discovery using All Pairs with Ascending Reward and Dropout. We demonstrate that APART discovers all the possible skills in grid worlds with remarkably fewer samples than previous works. Motivated by the empirical success of APART, we further investigate an even simpler algorithm that achieves maximum skills by altering VIC, rescaling its intrinsic reward, and tuning the temperature of its softmax discriminator. We believe our findings shed light on the crucial factors underlying success of skill discovery algorithms in reinforcement learning.</p>
<hr>
<h2 id="Advancing-Hungarian-Text-Processing-with-HuSpaCy-Efficient-and-Accurate-NLP-Pipelines"><a href="#Advancing-Hungarian-Text-Processing-with-HuSpaCy-Efficient-and-Accurate-NLP-Pipelines" class="headerlink" title="Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines"></a>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12635">http://arxiv.org/abs/2308.12635</a></li>
<li>repo_url: None</li>
<li>paper_authors: György Orosz, Gergő Szabó, Péter Berkecz, Zsolt Szántó, Richárd Farkas</li>
</ul>
<p>Abstract:<br>This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.</p>
<hr>
<h2 id="Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning"><a href="#Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning" class="headerlink" title="Towards Hierarchical Regional Transformer-based Multiple Instance Learning"></a>Towards Hierarchical Regional Transformer-based Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12634">http://arxiv.org/abs/2308.12634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Cersovsky, Sadegh Mohammadi, Dagmar Kainmueller, Johannes Hoehne</li>
</ul>
<p>Abstract:<br>The classification of gigapixel histopathology images with deep multiple instance learning models has become a critical task in digital pathology and precision medicine. In this work, we propose a Transformer-based multiple instance learning approach that replaces the traditional learned attention mechanism with a regional, Vision Transformer inspired self-attention mechanism. We present a method that fuses regional patch information to derive slide-level predictions and show how this regional aggregation can be stacked to hierarchically process features on different distance levels. To increase predictive accuracy, especially for datasets with small, local morphological features, we introduce a method to focus the image processing on high attention regions during inference. Our approach is able to significantly improve performance over the baseline on two histopathology datasets and points towards promising directions for further research.</p>
<hr>
<h2 id="A-Greedy-Approach-for-Offering-to-Telecom-Subscribers"><a href="#A-Greedy-Approach-for-Offering-to-Telecom-Subscribers" class="headerlink" title="A Greedy Approach for Offering to Telecom Subscribers"></a>A Greedy Approach for Offering to Telecom Subscribers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12606">http://arxiv.org/abs/2308.12606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyush Kanti Bhunre, Tanmay Sen, Arijit Sarkar</li>
</ul>
<p>Abstract:<br>Customer retention or churn prevention is a challenging task of a telecom operator. One of the effective approaches is to offer some attractive incentive or additional services or money to the subscribers for keeping them engaged and make sure they stay in the operator’s network for longer time. Often, operators allocate certain amount of monetary budget to carry out the offer campaign. The difficult part of this campaign is the selection of a set of customers from a large subscriber-base and deciding the amount that should be offered to an individual so that operator’s objective is achieved. There may be multiple objectives (e.g., maximizing revenue, minimizing number of churns) for selection of subscriber and selection of an offer to the selected subscriber. Apart from monetary benefit, offers may include additional data, SMS, hots-spot tethering, and many more. This problem is known as offer optimization. In this paper, we propose a novel combinatorial algorithm for solving offer optimization under heterogeneous offers by maximizing expected revenue under the scenario of subscriber churn, which is, in general, seen in telecom domain. The proposed algorithm is efficient and accurate even for a very large subscriber-base.</p>
<hr>
<h2 id="APLA-Additional-Perturbation-for-Latent-Noise-with-Adversarial-Training-Enables-Consistency"><a href="#APLA-Additional-Perturbation-for-Latent-Noise-with-Adversarial-Training-Enables-Consistency" class="headerlink" title="APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency"></a>APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12605">http://arxiv.org/abs/2308.12605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yupu Yao, Shangqi Deng, Zihan Cao, Harry Zhang, Liang-Jian Deng</li>
</ul>
<p>Abstract:<br>Diffusion models have exhibited promising progress in video generation. However, they often struggle to retain consistent details within local regions across frames. One underlying cause is that traditional diffusion models approximate Gaussian noise distribution by utilizing predictive noise, without fully accounting for the impact of inherent information within the input itself. Additionally, these models emphasize the distinction between predictions and references, neglecting information intrinsic to the videos. To address this limitation, inspired by the self-attention mechanism, we propose a novel text-to-video (T2V) generation network structure based on diffusion models, dubbed Additional Perturbation for Latent noise with Adversarial training (APLA). Our approach only necessitates a single video as input and builds upon pre-trained stable diffusion networks. Notably, we introduce an additional compact network, known as the Video Generation Transformer (VGT). This auxiliary component is designed to extract perturbations from the inherent information contained within the input, thereby refining inconsistent pixels during temporal predictions. We leverage a hybrid architecture of transformers and convolutions to compensate for temporal intricacies, enhancing consistency between different frames within the video. Experiments demonstrate a noticeable improvement in the consistency of the generated videos both qualitatively and quantitatively.</p>
<hr>
<h2 id="SICNN-Soft-Interference-Cancellation-Inspired-Neural-Network-Equalizers"><a href="#SICNN-Soft-Interference-Cancellation-Inspired-Neural-Network-Equalizers" class="headerlink" title="SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers"></a>SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12591">http://arxiv.org/abs/2308.12591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Baumgartner, Oliver Lang, Mario Huemer</li>
</ul>
<p>Abstract:<br>Equalization is an important task at the receiver side of a digital wireless communication system, which is traditionally conducted with model-based estimation methods. Among the numerous options for model-based equalization, iterative soft interference cancellation (SIC) is a well-performing approach since error propagation caused by hard decision data symbol estimation during the iterative estimation procedure is avoided. However, the model-based method suffers from high computational complexity and performance degradation due to required approximations. In this work, we propose a novel neural network (NN-)based equalization approach, referred to as SICNN, which is designed by deep unfolding of a model-based iterative SIC method, eliminating the main disadvantages of its model-based counterpart. We present different variants of SICNN. SICNNv1 is very similar to the model-based method, and is specifically tailored for single carrier frequency domain equalization systems, which is the communication system we regard in this work. The second variant, SICNNv2, is more universal, and is applicable as an equalizer in any communication system with a block-based data transmission scheme. We highlight the pros and cons of both variants. Moreover, for both SICNNv1 and SICNNv2 we present a version with a highly reduced number of learnable parameters. We compare the achieved bit error ratio performance of the proposed NN-based equalizers with state-of-the-art model-based and NN-based approaches, highlighting the superiority of SICNNv1 over all other methods. Also, we present a thorough complexity analysis of the proposed NN-based equalization approaches, and we investigate the influence of the training set size on the performance of NN-based equalizers.</p>
<hr>
<h2 id="A-Huber-Loss-Minimization-Approach-to-Byzantine-Robust-Federated-Learning"><a href="#A-Huber-Loss-Minimization-Approach-to-Byzantine-Robust-Federated-Learning" class="headerlink" title="A Huber Loss Minimization Approach to Byzantine Robust Federated Learning"></a>A Huber Loss Minimization Approach to Byzantine Robust Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12581">http://arxiv.org/abs/2308.12581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Puning Zhao, Fei Yu, Zhiguo Wan</li>
</ul>
<p>Abstract:<br>Federated learning systems are susceptible to adversarial attacks. To combat this, we introduce a novel aggregator based on Huber loss minimization, and provide a comprehensive theoretical analysis. Under independent and identically distributed (i.i.d) assumption, our approach has several advantages compared to existing methods. Firstly, it has optimal dependence on $\epsilon$, which stands for the ratio of attacked clients. Secondly, our approach does not need precise knowledge of $\epsilon$. Thirdly, it allows different clients to have unequal data sizes. We then broaden our analysis to include non-i.i.d data, such that clients have slightly different distributions.</p>
<hr>
<h2 id="Mind-vs-Mouth-On-Measuring-Re-judge-Inconsistency-of-Social-Bias-in-Large-Language-Models"><a href="#Mind-vs-Mouth-On-Measuring-Re-judge-Inconsistency-of-Social-Bias-in-Large-Language-Models" class="headerlink" title="Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models"></a>Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12578">http://arxiv.org/abs/2308.12578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yachao Zhao, Bo Wang, Dongming Zhao, Kun Huang, Yan Wang, Ruifang He, Yuexian Hou</li>
</ul>
<p>Abstract:<br>Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals’ explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as “re-judge inconsistency” in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human’s unaware implicit social bias and their aware explicit social bias. Experimental investigations on ChatGPT and GPT-4 concerning common gender biases examined in psychology corroborate the highly stable nature of the re-judge inconsistency. This finding may suggest that diverse cognitive constructs emerge as LLMs’ capabilities strengthen. Consequently, leveraging psychological theories can provide enhanced insights into the underlying mechanisms governing the expressions of explicit and implicit constructs in LLMs.</p>
<hr>
<h2 id="REB-Reducing-Biases-in-Representation-for-Industrial-Anomaly-Detection"><a href="#REB-Reducing-Biases-in-Representation-for-Industrial-Anomaly-Detection" class="headerlink" title="REB: Reducing Biases in Representation for Industrial Anomaly Detection"></a>REB: Reducing Biases in Representation for Industrial Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12577">http://arxiv.org/abs/2308.12577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Lyu, Dongmei Mo, Waikeung Wong</li>
</ul>
<p>Abstract:<br>Existing K-nearest neighbor (KNN) retrieval-based methods usually conduct industrial anomaly detection in two stages: obtain feature representations with a pre-trained CNN model and perform distance measures for defect detection. However, the features are not fully exploited as they ignore domain bias and the difference of local density in feature space, which limits the detection performance. In this paper, we propose Reducing Biases (REB) in representation by considering the domain bias of the pre-trained model and building a self-supervised learning task for better domain adaption with a defect generation strategy (DefectMaker) imitating the natural defects. Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection. We achieve a promising result of 99.5% AUROC on the widely used MVTec AD benchmark. We also achieve 88.0% AUROC on the challenging MVTec LOCO AD dataset and bring an improvement of 4.7% AUROC to the state-of-the-art result. All results are obtained with smaller backbone networks such as Vgg11 and Resnet18, which indicates the effectiveness and efficiency of REB for practical industrial applications.</p>
<hr>
<h2 id="Exploring-the-Integration-Strategies-of-Retriever-and-Large-Language-Models"><a href="#Exploring-the-Integration-Strategies-of-Retriever-and-Large-Language-Models" class="headerlink" title="Exploring the Integration Strategies of Retriever and Large Language Models"></a>Exploring the Integration Strategies of Retriever and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12574">http://arxiv.org/abs/2308.12574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Liu, Semih Yavuz, Rui Meng, Meghana Moorthy, Shafiq Joty, Caiming Xiong, Yingbo Zhou</li>
</ul>
<p>Abstract:<br>The integration of retrieved passages and large language models (LLMs), such as ChatGPTs, has significantly contributed to improving open-domain question answering. However, there is still a lack of exploration regarding the optimal approach for incorporating retrieved passages into the answer generation process. This paper aims to fill this gap by investigating different methods of combining retrieved passages with LLMs to enhance answer generation. We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating “unknown” outputs, even when the correct document is among the top-k retrieved passages. To address this issue, we explore four alternative strategies for integrating the retrieved passages with the LLMs. These strategies include two single-round methods that utilize chain-of-thought reasoning and two multi-round strategies that incorporate feedback loops. Through comprehensive analyses and experiments, we provide insightful observations on how to effectively leverage retrieved passages to enhance the answer generation capability of LLMs.</p>
<hr>
<h2 id="Conditional-Kernel-Imitation-Learning-for-Continuous-State-Environments"><a href="#Conditional-Kernel-Imitation-Learning-for-Continuous-State-Environments" class="headerlink" title="Conditional Kernel Imitation Learning for Continuous State Environments"></a>Conditional Kernel Imitation Learning for Continuous State Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12573">http://arxiv.org/abs/2308.12573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Agrawal, Nathan Dahlin, Rahul Jain, Ashutosh Nayyar</li>
</ul>
<p>Abstract:<br>Imitation Learning (IL) is an important paradigm within the broader reinforcement learning (RL) methodology. Unlike most of RL, it does not assume availability of reward-feedback. Reward inference and shaping are known to be difficult and error-prone methods particularly when the demonstration data comes from human experts. Classical methods such as behavioral cloning and inverse reinforcement learning are highly sensitive to estimation errors, a problem that is particularly acute in continuous state space problems. Meanwhile, state-of-the-art IL algorithms convert behavioral policy learning problems into distribution-matching problems which often require additional online interaction data to be effective. In this paper, we consider the problem of imitation learning in continuous state space environments based solely on observed behavior, without access to transition dynamics information, reward structure, or, most importantly, any additional interactions with the environment. Our approach is based on the Markov balance equation and introduces a novel conditional kernel density estimation-based imitation learning framework. It involves estimating the environment’s transition dynamics using conditional kernel density estimators and seeks to satisfy the probabilistic balance equations for the environment. We establish that our estimators satisfy basic asymptotic consistency requirements. Through a series of numerical experiments on continuous state benchmark environments, we show consistently superior empirical performance over many state-of-the-art IL algorithms.</p>
<hr>
<h2 id="A-Co-training-Approach-for-Noisy-Time-Series-Learning"><a href="#A-Co-training-Approach-for-Noisy-Time-Series-Learning" class="headerlink" title="A Co-training Approach for Noisy Time Series Learning"></a>A Co-training Approach for Noisy Time Series Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12551">http://arxiv.org/abs/2308.12551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiqi Zhang, Jianfeng Zhang, Jia Li, Fugee Tsung</li>
</ul>
<p>Abstract:<br>In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.</p>
<hr>
<h2 id="Synchronize-Feature-Extracting-and-Matching-A-Single-Branch-Framework-for-3D-Object-Tracking"><a href="#Synchronize-Feature-Extracting-and-Matching-A-Single-Branch-Framework-for-3D-Object-Tracking" class="headerlink" title="Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking"></a>Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12549">http://arxiv.org/abs/2308.12549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu</li>
</ul>
<p>Abstract:<br>Siamese network has been a de facto benchmark framework for 3D LiDAR object tracking with a shared-parametric encoder extracting features from template and search region, respectively. This paradigm relies heavily on an additional matching network to model the cross-correlation&#x2F;similarity of the template and search region. In this paper, we forsake the conventional Siamese paradigm and propose a novel single-branch framework, SyncTrack, synchronizing the feature extracting and matching to avoid forwarding encoder twice for template and search region as well as introducing extra parameters of matching network. The synchronization mechanism is based on the dynamic affinity of the Transformer, and an in-depth analysis of the relevance is provided theoretically. Moreover, based on the synchronization, we introduce a novel Attentive Points-Sampling strategy into the Transformer layers (APST), replacing the random&#x2F;Farthest Points Sampling (FPS) method with sampling under the supervision of attentive relations between the template and search region. It implies connecting point-wise sampling with the feature learning, beneficial to aggregating more distinctive and geometric features for tracking with sparse points. Extensive experiments on two benchmark datasets (KITTI and NuScenes) show that SyncTrack achieves state-of-the-art performance in real-time tracking.</p>
<hr>
<h2 id="CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias"><a href="#CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias" class="headerlink" title="CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias"></a>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/calm">https://github.com/vipulgupta1011/calm</a></li>
<li>paper_authors: Vipul Gupta, Pranav Narayanan Venkit, Hugo Laurençon, Shomir Wilson, Rebecca J. Passonneau</li>
</ul>
<p>Abstract:<br>As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language models including six prominent families of LMs such as Llama-2. In two LM series, OPT and Bloom, we found that larger parameter models are more biased than lower parameter models. We found the T0 series of models to be the least biased. Furthermore, we noticed a tradeoff between gender and racial bias with increasing model size in some model series. The code is available at <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/CALM">https://github.com/vipulgupta1011/CALM</a>.</p>
<hr>
<h2 id="FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning"><a href="#FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning" class="headerlink" title="FedSoL: Bridging Global Alignment and Local Generality in Federated Learning"></a>FedSoL: Bridging Global Alignment and Local Generality in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12532">http://arxiv.org/abs/2308.12532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gihun Lee, Minchan Jeong, Sangmook Kim, Jaehoon Oh, Se-Young Yun</li>
</ul>
<p>Abstract:<br>Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (FedSoL), which combines both the concepts of global alignment and local generality. In FedSoL, the local learning seeks a parameter region robust against proximal perturbations. This strategy introduces an implicit proximal restriction effect in local learning while maintaining the original local objective for parameter update. Our experiments show that FedSoL consistently achieves state-of-the-art performance on various setups.</p>
<hr>
<h2 id="Not-Only-Rewards-But-Also-Constraints-Applications-on-Legged-Robot-Locomotion"><a href="#Not-Only-Rewards-But-Also-Constraints-Applications-on-Legged-Robot-Locomotion" class="headerlink" title="Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion"></a>Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12517">http://arxiv.org/abs/2308.12517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunho Kim, Hyunsik Oh, Jeonghyun Lee, Jinhyeok Choi, Gwanghyeon Ji, Moonkyu Jung, Donghoon Youm, Jemin Hwangbo</li>
</ul>
<p>Abstract:<br>Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this work, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints. To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attributes to traverse challenging terrains. Extensive simulation and real-world experiments demonstrate that performant controllers can be trained with significantly less reward engineering, by tuning only a single reward coefficient. Furthermore, a more straightforward and intuitive engineering process can be utilized, thanks to the interpretability and generalizability of constraints. The summary video is available at <a target="_blank" rel="noopener" href="https://youtu.be/KAlm3yskhvM">https://youtu.be/KAlm3yskhvM</a>.</p>
<hr>
<h2 id="I3DOD-Towards-Incremental-3D-Object-Detection-via-Prompting"><a href="#I3DOD-Towards-Incremental-3D-Object-Detection-via-Prompting" class="headerlink" title="I3DOD: Towards Incremental 3D Object Detection via Prompting"></a>I3DOD: Towards Incremental 3D Object Detection via Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12512">http://arxiv.org/abs/2308.12512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqi Liang, Gan Sun, Chenxi Liu, Jiahua Dong, Kangru Wang</li>
</ul>
<p>Abstract:<br>3D object detection has achieved significant performance in many fields, e.g., robotics system, autonomous driving, and augmented reality. However, most existing methods could cause catastrophic forgetting of old classes when performing on the class-incremental scenarios. Meanwhile, the current class-incremental 3D object detection methods neglect the relationships between the object localization information and category semantic information and assume all the knowledge of old model is reliable. To address the above challenge, we present a novel Incremental 3D Object Detection framework with the guidance of prompting, i.e., I3DOD. Specifically, we propose a task-shared prompts mechanism to learn the matching relationships between the object localization information and category semantic information. After training on the current task, these prompts will be stored in our prompt pool, and perform the relationship of old classes in the next task. Moreover, we design a reliable distillation strategy to transfer knowledge from two aspects: a reliable dynamic distillation is developed to filter out the negative knowledge and transfer the reliable 3D knowledge to new detection model; the relation feature is proposed to capture the responses relation in feature space and protect plasticity of the model when learning novel 3D classes. To the end, we conduct comprehensive experiments on two benchmark datasets and our method outperforms the state-of-the-art object detection methods by 0.6% - 2.7% in terms of <a href="mailto:&#109;&#x41;&#80;&#x40;&#48;&#x2e;&#50;&#x35;">&#109;&#x41;&#80;&#x40;&#48;&#x2e;&#50;&#x35;</a>.</p>
<hr>
<h2 id="Masked-Autoencoders-are-Efficient-Class-Incremental-Learners"><a href="#Masked-Autoencoders-are-Efficient-Class-Incremental-Learners" class="headerlink" title="Masked Autoencoders are Efficient Class Incremental Learners"></a>Masked Autoencoders are Efficient Class Incremental Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12510">http://arxiv.org/abs/2308.12510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scok30/mae-cil">https://github.com/scok30/mae-cil</a></li>
<li>paper_authors: Jiang-Tian Zhai, Xialei Liu, Andrew D. Bagdanov, Ke Li, Ming-Ming Cheng</li>
</ul>
<p>Abstract:<br>Class Incremental Learning (CIL) aims to sequentially learn new classes while avoiding catastrophic forgetting of previous knowledge. We propose to use Masked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally designed to learn useful representations through reconstructive unsupervised learning, and they can be easily integrated with a supervised loss for classification. Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL. We also propose a bilateral MAE framework to learn from image-level and embedding-level fusion, which produces better-quality reconstructed images and more stable representations. Our experiments confirm that our approach performs better than the state-of-the-art on CIFAR-100, ImageNet-Subset, and ImageNet-Full. The code is available at <a target="_blank" rel="noopener" href="https://github.com/scok30/MAE-CIL">https://github.com/scok30/MAE-CIL</a> .</p>
<hr>
<h2 id="CGMI-Configurable-General-Multi-Agent-Interaction-Framework"><a href="#CGMI-Configurable-General-Multi-Agent-Interaction-Framework" class="headerlink" title="CGMI: Configurable General Multi-Agent Interaction Framework"></a>CGMI: Configurable General Multi-Agent Interaction Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12503">http://arxiv.org/abs/2308.12503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shi Jinxin, Zhao Jiabao, Wang Yilei, Wu Xingjiao, Li Jiawen, He Liang</li>
</ul>
<p>Abstract:<br>Benefiting from the powerful capabilities of large language models (LLMs), agents based on LLMs have shown the potential to address domain-specific tasks and emulate human behaviors. However, the content generated by these agents remains somewhat superficial, owing to their limited domain expertise and the absence of an effective cognitive architecture. To address this, we present the Configurable General Multi-Agent Interaction (CGMI) framework, designed to replicate human interactions in real-world scenarios. Specifically, we propose a tree-structured methodology for the assignment, detection, and maintenance of agent personality. Additionally, we designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules. We have also integrated general agents to augment the virtual environment’s realism. Using the CGMI framework, we simulated numerous classroom interactions between teacher and students. The experiments indicate that aspects such as the teaching methodology, curriculum, and student performance closely mirror real classroom settings. We will open source our work.</p>
<hr>
<h2 id="Source-Free-Collaborative-Domain-Adaptation-via-Multi-Perspective-Feature-Enrichment-for-Functional-MRI-Analysis"><a href="#Source-Free-Collaborative-Domain-Adaptation-via-Multi-Perspective-Feature-Enrichment-for-Functional-MRI-Analysis" class="headerlink" title="Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis"></a>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12495">http://arxiv.org/abs/2308.12495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yqfang9199/scda">https://github.com/yqfang9199/scda</a></li>
<li>paper_authors: Yuqi Fang, Jinjian Wu, Qianqian Wang, Shijun Qiu, Andrea Bozoki, Huaicheng Yan, Mingxia Liu</li>
</ul>
<p>Abstract:<br>Resting-state functional MRI (rs-fMRI) is increasingly employed in multi-site research to aid neurological disorder analysis. Existing studies usually suffer from significant cross-site&#x2F;domain data heterogeneity caused by site effects such as differences in scanners&#x2F;protocols. Many methods have been proposed to reduce fMRI heterogeneity between source and target domains, heavily relying on the availability of source data. But acquiring source data is challenging due to privacy concerns and&#x2F;or data storage burdens in multi-site studies. To this end, we design a source-free collaborative domain adaptation (SCDA) framework for fMRI analysis, where only a pretrained source model and unlabeled target data are accessible. Specifically, a multi-perspective feature enrichment method (MFE) is developed for target fMRI analysis, consisting of multiple collaborative branches to dynamically capture fMRI features of unlabeled target data from multiple views. Each branch has a data-feeding module, a spatiotemporal feature encoder, and a class predictor. A mutual-consistency constraint is designed to encourage pair-wise consistency of latent features of the same input generated from these branches for robust representation learning. To facilitate efficient cross-domain knowledge transfer without source data, we initialize MFE using parameters of a pretrained source model. We also introduce an unsupervised pretraining strategy using 3,806 unlabeled fMRIs from three large-scale auxiliary databases, aiming to obtain a general feature encoder. Experimental results on three public datasets and one private dataset demonstrate the efficacy of our method in cross-scanner and cross-study prediction tasks. The model pretrained on large-scale rs-fMRI data has been released to the public.</p>
<hr>
<h2 id="GPTEval-A-Survey-on-Assessments-of-ChatGPT-and-GPT-4"><a href="#GPTEval-A-Survey-on-Assessments-of-ChatGPT-and-GPT-4" class="headerlink" title="GPTEval: A Survey on Assessments of ChatGPT and GPT-4"></a>GPTEval: A Survey on Assessments of ChatGPT and GPT-4</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12488">http://arxiv.org/abs/2308.12488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Mao, Guanyi Chen, Xulang Zhang, Frank Guerin, Erik Cambria</li>
</ul>
<p>Abstract:<br>The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.</p>
<hr>
<h2 id="A-Model-of-Sequential-Learning-based-on-Non-Axiomatic-Logic"><a href="#A-Model-of-Sequential-Learning-based-on-Non-Axiomatic-Logic" class="headerlink" title="A Model of Sequential Learning based on Non-Axiomatic Logic"></a>A Model of Sequential Learning based on Non-Axiomatic Logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12486">http://arxiv.org/abs/2308.12486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Xu</li>
</ul>
<p>Abstract:<br>Sequential learning is a fundamental function of an intelligent agent. This technical report introduces a model of sequential learning, which is interpretable through Non-Axiomatic Logic. The learning procedure includes three steps, hypothesizing, revising, and recycling, and can work under the Assumption of Insufficient Knowledge and Resources. Although there are limitations for the current design, the model has been proven effective in some simple cases.</p>
<hr>
<h2 id="Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection"><a href="#Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection" class="headerlink" title="Attention-Based Acoustic Feature Fusion Network for Depression Detection"></a>Attention-Based Acoustic Feature Fusion Network for Depression Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12478">http://arxiv.org/abs/2308.12478</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuxiaoooo/abafnet">https://github.com/xuxiaoooo/abafnet</a></li>
<li>paper_authors: Xiao Xu, Yang Wang, Xinru Wei, Fei Wang, Xizhe Zhang</li>
</ul>
<p>Abstract:<br>Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech characteristics. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep learning model, thereby effectively integrating and blending multi-tiered features. We present a novel weight adjustment module for late fusion that boosts performance by efficaciously synthesizing these features. The effectiveness of our approach is confirmed via extensive validation on two clinical speech databases, CNRAC and CS-NRAC, thereby outperforming previous methods in depression detection and subtype classification. Further in-depth analysis confirms the key role of each feature and highlights the importance of MFCCrelated features in speech-based depression detection.</p>
<hr>
<h2 id="Are-ChatGPT-and-GPT-4-Good-Poker-Players-–-A-Pre-Flop-Analysis"><a href="#Are-ChatGPT-and-GPT-4-Good-Poker-Players-–-A-Pre-Flop-Analysis" class="headerlink" title="Are ChatGPT and GPT-4 Good Poker Players? – A Pre-Flop Analysis"></a>Are ChatGPT and GPT-4 Good Poker Players? – A Pre-Flop Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12466">http://arxiv.org/abs/2308.12466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshat Gupta</li>
</ul>
<p>Abstract:<br>Since the introduction of ChatGPT and GPT-4, these models have been tested across a large number of tasks. Their adeptness across domains is evident, but their aptitude in playing games and specifically their aptitude in the realm of poker has remained unexplored. Poker is a game that requires decision making under uncertainty and incomplete information. In this paper, we put ChatGPT and GPT-4 through the poker test and evaluate their poker skills. Our findings reveal that while both models display an advanced understanding of poker, encompassing concepts like the valuation of starting hands, playing positions and other intricacies of game theory optimal (GTO) poker, both ChatGPT and GPT-4 are NOT game theory optimal poker players.   Through a series of experiments, we first discover the characteristics of optimal prompts and model parameters for playing poker with these models. Our observations then unveil the distinct playing personas of the two models. We first conclude that GPT-4 is a more advanced poker player than ChatGPT. This exploration then sheds light on the divergent poker tactics of the two models: ChatGPT’s conservativeness juxtaposed against GPT-4’s aggression. In poker vernacular, when tasked to play GTO poker, ChatGPT plays like a Nit, which means that it has a propensity to only engage with premium hands and folds a majority of hands. When subjected to the same directive, GPT-4 plays like a maniac, showcasing a loose and aggressive style of play. Both strategies, although relatively advanced, are not game theory optimal.</p>
<hr>
<h2 id="PFL-GAN-When-Client-Heterogeneity-Meets-Generative-Models-in-Personalized-Federated-Learning"><a href="#PFL-GAN-When-Client-Heterogeneity-Meets-Generative-Models-in-Personalized-Federated-Learning" class="headerlink" title="PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning"></a>PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12454">http://arxiv.org/abs/2308.12454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Achintha Wijesinghe, Songyang Zhang, Zhi Ding</li>
</ul>
<p>Abstract:<br>Recent advances of generative learning models are accompanied by the growing interest in federated learning (FL) based on generative adversarial network (GAN) models. In the context of FL, GAN can capture the underlying client data structure, and regenerate samples resembling the original data distribution without compromising the private raw data. Although most existing GAN-based FL works focus on training a global model, Personalized FL (PFL) sometimes can be more effective in view of client data heterogeneity in terms of distinct data sample distributions, feature spaces, and labels. To cope with client heterogeneity in GAN-based FL, we propose a novel GAN sharing and aggregation strategy for PFL. The proposed PFL-GAN addresses the client heterogeneity in different scenarios. More specially, we first learn the similarity among clients and then develop an weighted collaborative data aggregation. The empirical results through the rigorous experimentation on several well-known datasets demonstrate the effectiveness of PFL-GAN.</p>
<hr>
<h2 id="Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models"><a href="#Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models" class="headerlink" title="Augmenting medical image classifiers with synthetic data from latent diffusion models"></a>Augmenting medical image classifiers with synthetic data from latent diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12453">http://arxiv.org/abs/2308.12453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke W. Sagers, James A. Diao, Luke Melas-Kyriazi, Matthew Groh, Pranav Rajpurkar, Adewole S. Adamson, Veronica Rotemberg, Roxana Daneshjou, Arjun K. Manrai</li>
</ul>
<p>Abstract:<br>While hundreds of artificial intelligence (AI) algorithms are now approved or cleared by the US Food and Drugs Administration (FDA), many studies have shown inconsistent generalization or latent bias, particularly for underrepresented populations. Some have proposed that generative AI could reduce the need for real data, but its utility in model development remains unclear. Skin disease serves as a useful case study in synthetic image generation due to the diversity of disease appearance, particularly across the protected attribute of skin tone. Here we show that latent diffusion models can scalably generate images of skin disease and that augmenting model training with these data improves performance in data-limited settings. These performance gains saturate at synthetic-to-real image ratios above 10:1 and are substantially smaller than the gains obtained from adding real images. As part of our analysis, we generate and analyze a new dataset of 458,920 synthetic images produced using several generation strategies. Our results suggest that synthetic data could serve as a force-multiplier for model development, but the collection of diverse real-world data remains the most important step to improve medical AI algorithms.</p>
<hr>
<h2 id="An-Intentional-Forgetting-Driven-Self-Healing-Method-For-Deep-Reinforcement-Learning-Systems"><a href="#An-Intentional-Forgetting-Driven-Self-Healing-Method-For-Deep-Reinforcement-Learning-Systems" class="headerlink" title="An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems"></a>An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12445">http://arxiv.org/abs/2308.12445</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahmedhajyahmed/drdrl">https://github.com/ahmedhajyahmed/drdrl</a></li>
<li>paper_authors: Ahmed Haj Yahmed, Rached Bouchoucha, Houssem Ben Braiek, Foutse Khomh</li>
</ul>
<p>Abstract:<br>Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment’s conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases the DRL system’s minor behaviors to systematically prioritize the adaptation of the key problem-solving skills. Using well-established DRL algorithms, Dr. DRL is compared with vanilla CL on various drifted environments. Dr. DRL is able to reduce, on average, the healing time and fine-tuning episodes by, respectively, 18.74% and 17.72%. Dr. DRL successfully helps agents to adapt to 19.63% of drifted environments left unsolved by vanilla CL while maintaining and even enhancing by up to 45% the obtained rewards for drifted environments that are resolved by both approaches.</p>
<hr>
<h2 id="BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection"><a href="#BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection" class="headerlink" title="BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection"></a>BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12439">http://arxiv.org/abs/2308.12439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal</li>
</ul>
<p>Abstract:<br>We present a novel defense, against backdoor attacks on Deep Neural Networks (DNNs), wherein adversaries covertly implant malicious behaviors (backdoors) into DNNs. Our defense falls within the category of post-development defenses that operate independently of how the model was generated. The proposed defense is built upon a novel reverse engineering approach that can directly extract backdoor functionality of a given backdoored model to a backdoor expert model. The approach is straightforward – finetuning the backdoored model over a small set of intentionally mislabeled clean samples, such that it unlearns the normal functionality while still preserving the backdoor functionality, and thus resulting in a model (dubbed a backdoor expert model) that can only recognize backdoor inputs. Based on the extracted backdoor expert model, we show the feasibility of devising highly accurate backdoor input detectors that filter out the backdoor inputs during model inference. Further augmented by an ensemble strategy with a finetuned auxiliary model, our defense, BaDExpert (Backdoor Input Detection with Backdoor Expert), effectively mitigates 16 SOTA backdoor attacks while minimally impacting clean utility. The effectiveness of BaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet) across various model architectures (ResNet, VGG, MobileNetV2 and Vision Transformer).</p>
<hr>
<h2 id="Deploying-Deep-Reinforcement-Learning-Systems-A-Taxonomy-of-Challenges"><a href="#Deploying-Deep-Reinforcement-Learning-Systems-A-Taxonomy-of-Challenges" class="headerlink" title="Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges"></a>Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12438">http://arxiv.org/abs/2308.12438</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/drldeploymentchallenges-icsme2023/replicationpackage">https://github.com/drldeploymentchallenges-icsme2023/replicationpackage</a></li>
<li>paper_authors: Ahmed Haj Yahmed, Altaf Allah Abbassi, Amin Nikanjam, Heng Li, Foutse Khomh</li>
</ul>
<p>Abstract:<br>Deep reinforcement learning (DRL), leveraging Deep Learning (DL) in reinforcement learning, has shown significant potential in achieving human-level autonomy in a wide range of domains, including robotics, computer vision, and computer games. This potential justifies the enthusiasm and growing interest in DRL in both academia and industry. However, the community currently focuses mostly on the development phase of DRL systems, with little attention devoted to DRL deployment. In this paper, we propose an empirical study on Stack Overflow (SO), the most popular Q&amp;A forum for developers, to uncover and understand the challenges practitioners faced when deploying DRL systems. Specifically, we categorized relevant SO posts by deployment platforms: server&#x2F;cloud, mobile&#x2F;embedded system, browser, and game engine. After filtering and manual analysis, we examined 357 SO posts about DRL deployment, investigated the current state, and identified the challenges related to deploying DRL systems. Then, we investigate the prevalence and difficulty of these challenges. Results show that the general interest in DRL deployment is growing, confirming the study’s relevance and importance. Results also show that DRL deployment is more difficult than other DRL issues. Additionally, we built a taxonomy of 31 unique challenges in deploying DRL to different platforms. On all platforms, RL environment-related challenges are the most popular, and communication-related challenges are the most difficult among practitioners. We hope our study inspires future research and helps the community overcome the most common and difficult challenges practitioners face when deploying DRL systems.</p>
<hr>
<h2 id="Reframing-the-Brain-Age-Prediction-Problem-to-a-More-Interpretable-and-Quantitative-Approach"><a href="#Reframing-the-Brain-Age-Prediction-Problem-to-a-More-Interpretable-and-Quantitative-Approach" class="headerlink" title="Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach"></a>Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12416">http://arxiv.org/abs/2308.12416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha Gianchandani, Mahsa Dibaji, Mariana Bento, Ethan MacDonald, Roberto Souza</li>
</ul>
<p>Abstract:<br>Deep learning models have achieved state-of-the-art results in estimating brain age, which is an important brain health biomarker, from magnetic resonance (MR) images. However, most of these models only provide a global age prediction, and rely on techniques, such as saliency maps to interpret their results. These saliency maps highlight regions in the input image that were significant for the model’s predictions, but they are hard to be interpreted, and saliency map values are not directly comparable across different samples. In this work, we reframe the age prediction problem from MR images to an image-to-image regression problem where we estimate the brain age for each brain voxel in MR images. We compare voxel-wise age prediction models against global age prediction models and their corresponding saliency maps. The results indicate that voxel-wise age prediction models are more interpretable, since they provide spatial information about the brain aging process, and they benefit from being quantitative.</p>
<hr>
<h2 id="Benchmarking-Causal-Study-to-Interpret-Large-Language-Models-for-Source-Code"><a href="#Benchmarking-Causal-Study-to-Interpret-Large-Language-Models-for-Source-Code" class="headerlink" title="Benchmarking Causal Study to Interpret Large Language Models for Source Code"></a>Benchmarking Causal Study to Interpret Large Language Models for Source Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12415">http://arxiv.org/abs/2308.12415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Rodriguez-Cardenas, David N. Palacio, Dipin Khati, Henry Burke, Denys Poshyvanyk</li>
</ul>
<p>Abstract:<br>One of the most common solutions adopted by software researchers to address code generation is by training Large Language Models (LLMs) on massive amounts of source code. Although a number of studies have shown that LLMs have been effectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu), previous research has largely overlooked the role of Causal Inference as a fundamental component of the interpretability of LLMs’ performance. Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, prompt size) that equally influence the accuracy metrics. The fact remains that, when dealing with generative software tasks by LLMs, no benchmark is available to tell researchers how to quantify neither the causal effect of SE-based treatments nor the correlation of confounders to the model’s performance. In an effort to bring statistical rigor to the evaluation of LLMs, this paper introduces a benchmarking strategy named Galeras comprised of curated testbeds for three SE tasks (i.e., code completion, code summarization, and commit generation) to help aid the interpretation of LLMs’ performance. We illustrate the insights of our benchmarking strategy by conducting a case study on the performance of ChatGPT under distinct prompt engineering methods. The results of the case study demonstrate the positive causal influence of prompt semantics on ChatGPT’s generative performance by an average treatment effect of $\approx 3%$. Moreover, it was found that confounders such as prompt size are highly correlated with accuracy metrics ($\approx 0.412%$). The end result of our case study is to showcase causal inference evaluations, in practice, to reduce confounding bias. By reducing the bias, we offer an interpretable solution for the accuracy metric under analysis.</p>
<hr>
<h2 id="A-Theory-of-Intelligences-Concepts-Models-Implications"><a href="#A-Theory-of-Intelligences-Concepts-Models-Implications" class="headerlink" title="A Theory of Intelligences: Concepts, Models, Implications"></a>A Theory of Intelligences: Concepts, Models, Implications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12411">http://arxiv.org/abs/2308.12411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael E. Hochberg</li>
</ul>
<p>Abstract:<br>Intelligence is a human construct to represent the ability to achieve goals. Given this wide berth, intelligence has been defined countless times, studied in a variety of ways and quantified using numerous measures. Understanding intelligence ultimately requires theory and quantification, both of which are elusive. My main objectives are to identify some of the central elements in and surrounding intelligence, discuss some of its challenges and propose a theory based on first principles. I focus on intelligence as defined by and for humans, frequently in comparison to machines, with the intention of setting the stage for more general characterizations in life, collectives, human designs such as AI and in non-designed physical and chemical systems. I discuss key features of intelligence, including path efficiency and goal accuracy, intelligence as a Black Box, environmental influences, flexibility to deal with surprisal, the regress of intelligence, the relativistic nature of intelligence and difficulty, and temporal changes in intelligence including its evolution. I present a framework for a first principles Theory of IntelligenceS (TIS), based on the quantifiable macro-scale system features of difficulty, surprisal and goal resolution accuracy. The proposed partitioning of uncertainty&#x2F;solving and accuracy&#x2F;understanding is particularly novel since it predicts that paths to a goal not only function to accurately achieve goals, but as experimentations leading to higher probabilities for future attainable goals and increased breadth to enter new goal spaces. TIS can therefore explain endeavors that do not necessarily affect Darwinian fitness, such as leisure, politics, games and art. I conclude with several conceptual advances of TIS including a compact mathematical form of surprisal and difficulty, the theoretical basis of TIS, and open questions.</p>
<hr>
<h2 id="Self-Supervised-Learning-for-Endoscopic-Video-Analysis"><a href="#Self-Supervised-Learning-for-Endoscopic-Video-Analysis" class="headerlink" title="Self-Supervised Learning for Endoscopic Video Analysis"></a>Self-Supervised Learning for Endoscopic Video Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12394">http://arxiv.org/abs/2308.12394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/royhirsch/endossl">https://github.com/royhirsch/endossl</a></li>
<li>paper_authors: Roy Hirsch, Mathilde Caron, Regev Cohen, Amir Livne, Ron Shapiro, Tomer Golany, Roman Goldenberg, Daniel Freedman, Ehud Rivlin</li>
</ul>
<p>Abstract:<br>Self-supervised learning (SSL) has led to important breakthroughs in computer vision by allowing learning from large amounts of unlabeled data. As such, it might have a pivotal role to play in biomedicine where annotating data requires a highly specialized expertise. Yet, there are many healthcare domains for which SSL has not been extensively explored. One such domain is endoscopy, minimally invasive procedures which are commonly used to detect and treat infections, chronic inflammatory diseases or cancer. In this work, we study the use of a leading SSL framework, namely Masked Siamese Networks (MSNs), for endoscopic video analysis such as colonoscopy and laparoscopy. To fully exploit the power of SSL, we create sizable unlabeled endoscopic video datasets for training MSNs. These strong image representations serve as a foundation for secondary training with limited annotated datasets, resulting in state-of-the-art performance in endoscopic benchmarks like surgical phase recognition during laparoscopy and colonoscopic polyp characterization. Additionally, we achieve a 50% reduction in annotated data size without sacrificing performance. Thus, our work provides evidence that SSL can dramatically reduce the need of annotated data in endoscopy.</p>
<hr>
<h2 id="With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning"><a href="#With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning" class="headerlink" title="With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning"></a>With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12383">http://arxiv.org/abs/2308.12383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/pma-net">https://github.com/aimagelab/pma-net</a></li>
<li>paper_authors: Manuele Barraco, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara</li>
</ul>
<p>Abstract:<br>Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components. We demonstrate that our proposal can increase the performance of an encoder-decoder Transformer by 3.7 CIDEr points both when training in cross-entropy only and when fine-tuning with self-critical sequence training. Source code and trained models are available at: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/PMA-Net">https://github.com/aimagelab/PMA-Net</a>.</p>
<hr>
<h2 id="Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation"><a href="#Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation" class="headerlink" title="Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation"></a>Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12371">http://arxiv.org/abs/2308.12371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Henrique Vareto, Manuel Günther, William Robson Schwartz</li>
</ul>
<p>Abstract:<br>Open-set face recognition refers to a scenario in which biometric systems have incomplete knowledge of all existing subjects. Therefore, they are expected to prevent face samples of unregistered subjects from being identified as previously enrolled identities. This watchlist context adds an arduous requirement that calls for the dismissal of irrelevant faces by focusing mainly on subjects of interest. As a response, this work introduces a novel method that associates an ensemble of compact neural networks with a margin-based cost function that explores additional samples. Supplementary negative samples can be obtained from external databases or synthetically built at the representation level in training time with a new mix-up feature augmentation approach. Deep neural networks pre-trained on large face datasets serve as the preliminary feature extraction module. We carry out experiments on well-known LFW and IJB-C datasets where results show that the approach is able to boost closed and open-set identification rates.</p>
<hr>
<h2 id="SafeAR-Towards-Safer-Algorithmic-Recourse-by-Risk-Aware-Policies"><a href="#SafeAR-Towards-Safer-Algorithmic-Recourse-by-Risk-Aware-Policies" class="headerlink" title="SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies"></a>SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12367">http://arxiv.org/abs/2308.12367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochen Wu, Shubham Sharma, Sunandita Patra, Sriram Gopalakrishnan</li>
</ul>
<p>Abstract:<br>With the growing use of machine learning (ML) models in critical domains such as finance and healthcare, the need to offer recourse for those adversely affected by the decisions of ML models has become more important; individuals ought to be provided with recommendations on actions to take for improving their situation and thus receive a favorable decision. Prior work on sequential algorithmic recourse – which recommends a series of changes – focuses on action feasibility and uses the proximity of feature changes to determine action costs. However, the uncertainties of feature changes and the risk of higher than average costs in recourse have not been considered. It is undesirable if a recourse could (with some probability) result in a worse situation from which recovery requires an extremely high cost. It is essential to incorporate risks when computing and evaluating recourse. We call the recourse computed with such risk considerations as Safer Algorithmic Recourse (SafeAR). The objective is to empower people to choose a recourse based on their risk tolerance. In this work, we discuss and show how existing recourse desiderata can fail to capture the risk of higher costs. We present a method to compute recourse policies that consider variability in cost and connect algorithmic recourse literature with risk-sensitive reinforcement learning. We also adopt measures <code>Value at Risk&#39;&#39; and </code>Conditional Value at Risk’’ from the financial literature to summarize risk concisely. We apply our method to two real-world datasets and compare policies with different levels of risk-aversion using risk measures and recourse desiderata (sparsity and proximity).</p>
<hr>
<h2 id="CHORUS-Learning-Canonicalized-3D-Human-Object-Spatial-Relations-from-Unbounded-Synthesized-Images"><a href="#CHORUS-Learning-Canonicalized-3D-Human-Object-Spatial-Relations-from-Unbounded-Synthesized-Images" class="headerlink" title="CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images"></a>CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12288">http://arxiv.org/abs/2308.12288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sookwan Han, Hanbyul Joo</li>
</ul>
<p>Abstract:<br>We present a method for teaching machines to understand and model the underlying spatial common sense of diverse human-object interactions in 3D in a self-supervised way. This is a challenging task, as there exist specific manifolds of the interactions that can be considered human-like and natural, but the human pose and the geometry of objects can vary even for similar interactions. Such diversity makes the annotating task of 3D interactions difficult and hard to scale, which limits the potential to reason about that in a supervised way. One way of learning the 3D spatial relationship between humans and objects during interaction is by showing multiple 2D images captured from different viewpoints when humans interact with the same type of objects. The core idea of our method is to leverage a generative model that produces high-quality 2D images from an arbitrary text prompt input as an “unbounded” data generator with effective controllability and view diversity. Despite its imperfection of the image quality over real images, we demonstrate that the synthesized images are sufficient to learn the 3D human-object spatial relations. We present multiple strategies to leverage the synthesized images, including (1) the first method to leverage a generative image model for 3D human-object spatial relation learning; (2) a framework to reason about the 3D spatial relations from inconsistent 2D cues in a self-supervised manner via 3D occupancy reasoning with pose canonicalization; (3) semantic clustering to disambiguate different types of interactions with the same object types; and (4) a novel metric to assess the quality of 3D spatial learning of interaction. Project Page: <a target="_blank" rel="noopener" href="https://jellyheadandrew.github.io/projects/chorus">https://jellyheadandrew.github.io/projects/chorus</a></p>
<hr>
<h2 id="D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification"><a href="#D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification" class="headerlink" title="D4: Improving LLM Pretraining via Document De-Duplication and Diversification"></a>D4: Improving LLM Pretraining via Document De-Duplication and Diversification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12284">http://arxiv.org/abs/2308.12284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari S. Morcos</li>
</ul>
<p>Abstract:<br>Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.</p>
<hr>
<h2 id="Simple-is-Better-and-Large-is-Not-Enough-Towards-Ensembling-of-Foundational-Language-Models"><a href="#Simple-is-Better-and-Large-is-Not-Enough-Towards-Ensembling-of-Foundational-Language-Models" class="headerlink" title="Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models"></a>Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12272">http://arxiv.org/abs/2308.12272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nancy Tyagi, Aidin Shiri, Surjodeep Sarkar, Abhishek Kumar Umrawal, Manas Gaur</li>
</ul>
<p>Abstract:<br>Foundational Language Models (FLMs) have advanced natural language processing (NLP) research. Current researchers are developing larger FLMs (e.g., XLNet, T5) to enable contextualized language representation, classification, and generation. While developing larger FLMs has been of significant advantage, it is also a liability concerning hallucination and predictive uncertainty. Fundamentally, larger FLMs are built on the same foundations as smaller FLMs (e.g., BERT); hence, one must recognize the potential of smaller FLMs which can be realized through an ensemble. In the current research, we perform a reality check on FLMs and their ensemble on benchmark and real-world datasets. We hypothesize that the ensembling of FLMs can influence the individualistic attention of FLMs and unravel the strength of coordination and cooperation of different FLMs. We utilize BERT and define three other ensemble techniques: {Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a knowledge-guided reinforcement learning approach. We discovered that the suggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by a factor of many times using datasets that show the usefulness of NLP in sensitive fields, such as mental health.</p>
<hr>
<h2 id="Language-Reward-Modulation-for-Pretraining-Reinforcement-Learning"><a href="#Language-Reward-Modulation-for-Pretraining-Reinforcement-Learning" class="headerlink" title="Language Reward Modulation for Pretraining Reinforcement Learning"></a>Language Reward Modulation for Pretraining Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12270">http://arxiv.org/abs/2308.12270</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ademiadeniji/lamp">https://github.com/ademiadeniji/lamp</a></li>
<li>paper_authors: Ademi Adeniji, Amber Xie, Carmelo Sferrazza, Younggyo Seo, Stephen James, Pieter Abbeel</li>
</ul>
<p>Abstract:<br>Using learned reward functions (LRFs) as a means to solve sparse-reward reinforcement learning (RL) tasks has yielded some steady progress in task-complexity through the years. In this work, we question whether today’s LRFs are best-suited as a direct replacement for task rewards. Instead, we propose leveraging the capabilities of LRFs as a pretraining signal for RL. Concretely, we propose $\textbf{LA}$nguage Reward $\textbf{M}$odulated $\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities of Vision-Language Models (VLMs) as a $\textit{pretraining}$ utility for RL as opposed to a downstream task reward. LAMP uses a frozen, pretrained VLM to scalably generate noisy, albeit shaped exploration rewards by computing the contrastive alignment between a highly diverse collection of language instructions and the image observations of an agent in its pretraining environment. LAMP optimizes these rewards in conjunction with standard novelty-seeking exploration rewards with reinforcement learning to acquire a language-conditioned, pretrained policy. Our VLM pretraining approach, which is a departure from previous attempts to use LRFs, can warmstart sample-efficient learning on robot manipulation tasks in RLBench.</p>
<hr>
<h2 id="FECoM-A-Step-towards-Fine-Grained-Energy-Measurement-for-Deep-Learning"><a href="#FECoM-A-Step-towards-Fine-Grained-Energy-Measurement-for-Deep-Learning" class="headerlink" title="FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning"></a>FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12264">http://arxiv.org/abs/2308.12264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurabhsingh Rajput, Tim Widmayer, Ziyuan Shang, Maria Kechagia, Federica Sarro, Tushar Sharma</li>
</ul>
<p>Abstract:<br>With the increasing usage, scale, and complexity of Deep Learning (DL) models, their rapidly growing energy consumption has become a critical concern. Promoting green development and energy awareness at different granularities is the need of the hour to limit carbon emissions of DL systems. However, the lack of standard and repeatable tools to accurately measure and optimize energy consumption at a fine granularity (e.g., at method level) hinders progress in this area. In this paper, we introduce FECoM (Fine-grained Energy Consumption Meter), a framework for fine-grained DL energy consumption measurement. Specifically, FECoM provides researchers and developers a mechanism to profile DL APIs. FECoM addresses the challenges of measuring energy consumption at fine-grained level by using static instrumentation and considering various factors, including computational load and temperature stability. We assess FECoM’s capability to measure fine-grained energy consumption for one of the most popular open-source DL frameworks, namely TensorFlow. Using FECoM, we also investigate the impact of parameter size and execution time on energy consumption, enriching our understanding of TensorFlow APIs’ energy profiles. Furthermore, we elaborate on the considerations, issues, and challenges that one needs to consider while designing and implementing a fine-grained energy consumption measurement tool. We hope this work will facilitate further advances in DL energy measurement and the development of energy-aware practices for DL systems.</p>
<hr>
<h2 id="Multi-Objective-Optimization-for-Sparse-Deep-Neural-Network-Training"><a href="#Multi-Objective-Optimization-for-Sparse-Deep-Neural-Network-Training" class="headerlink" title="Multi-Objective Optimization for Sparse Deep Neural Network Training"></a>Multi-Objective Optimization for Sparse Deep Neural Network Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12243">http://arxiv.org/abs/2308.12243</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/salomonhotegni/mdmtn">https://github.com/salomonhotegni/mdmtn</a></li>
<li>paper_authors: S. S. Hotegni, S. Peitz, M. Berkemeier</li>
</ul>
<p>Abstract:<br>Different conflicting optimization criteria arise naturally in various Deep Learning scenarios. These can address different main tasks (i.e., in the setting of Multi-Task Learning), but also main and secondary tasks such as loss minimization versus sparsity. The usual approach is a simple weighting of the criteria, which formally only works in the convex setting. In this paper, we present a Multi-Objective Optimization algorithm using a modified Weighted Chebyshev scalarization for training Deep Neural Networks (DNNs) with respect to several tasks. By employing this scalarization technique, the algorithm can identify all optimal solutions of the original problem while reducing its complexity to a sequence of single-objective problems. The simplified problems are then solved using an Augmented Lagrangian method, enabling the use of popular optimization techniques such as Adam and Stochastic Gradient Descent, while efficaciously handling constraints. Our work aims to address the (economical and also ecological) sustainability issue of DNN models, with a particular focus on Deep Multi-Task models, which are typically designed with a very large number of weights to perform equally well on multiple tasks. Through experiments conducted on two Machine Learning datasets, we demonstrate the possibility of adaptively sparsifying the model during training without significantly impacting its performance, if we are willing to apply task-specific adaptations to the network weights. Code is available at <a target="_blank" rel="noopener" href="https://github.com/salomonhotegni/MDMTN">https://github.com/salomonhotegni/MDMTN</a>.</p>
<hr>
<h2 id="LLMRec-Benchmarking-Large-Language-Models-on-Recommendation-Task"><a href="#LLMRec-Benchmarking-Large-Language-Models-on-Recommendation-Task" class="headerlink" title="LLMRec: Benchmarking Large Language Models on Recommendation Task"></a>LLMRec: Benchmarking Large Language Models on Recommendation Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12241">http://arxiv.org/abs/2308.12241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/williamliujl/llmrec">https://github.com/williamliujl/llmrec</a></li>
<li>paper_authors: Junling Liu, Chao Liu, Peilin Zhou, Qichen Ye, Dading Chong, Kang Zhou, Yueqi Xie, Yuwei Cao, Shoujin Wang, Chenyu You, Philip S. Yu</li>
</ul>
<p>Abstract:<br>Recently, the fast development of Large Language Models (LLMs) such as ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. However, the application of LLMs in the recommendation domain has not been thoroughly investigated. To bridge this gap, we propose LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks. Specifically, we benchmark several popular off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. Furthermore, we investigate the effectiveness of supervised finetuning to improve LLMs’ instruction compliance ability. The benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation. However, they demonstrated comparable performance to state-of-the-art methods in explainability-based tasks. We also conduct qualitative evaluations to further evaluate the quality of contents generated by different models, and the results show that LLMs can truly understand the provided information and generate clearer and more reasonable results. We aspire that this benchmark will serve as an inspiration for researchers to delve deeper into the potential of LLMs in enhancing recommendation performance. Our codes, processed data and benchmark results are available at <a target="_blank" rel="noopener" href="https://github.com/williamliujl/LLMRec">https://github.com/williamliujl/LLMRec</a>.</p>
<hr>
<h2 id="Enhancing-cardiovascular-risk-prediction-through-AI-enabled-calcium-omics"><a href="#Enhancing-cardiovascular-risk-prediction-through-AI-enabled-calcium-omics" class="headerlink" title="Enhancing cardiovascular risk prediction through AI-enabled calcium-omics"></a>Enhancing cardiovascular risk prediction through AI-enabled calcium-omics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12224">http://arxiv.org/abs/2308.12224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar Hoori, Sadeer Al-Kindi, Tao Hu, Yingnan Song, Hao Wu, Juhwan Lee, Nour Tashtish, Pingfu Fu, Robert Gilkeson, Sanjay Rajagopalan, David L. Wilson</li>
</ul>
<p>Abstract:<br>Background. Coronary artery calcium (CAC) is a powerful predictor of major adverse cardiovascular events (MACE). Traditional Agatston score simply sums the calcium, albeit in a non-linear way, leaving room for improved calcification assessments that will more fully capture the extent of disease.   Objective. To determine if AI methods using detailed calcification features (i.e., calcium-omics) can improve MACE prediction.   Methods. We investigated additional features of calcification including assessment of mass, volume, density, spatial distribution, territory, etc. We used a Cox model with elastic-net regularization on 2457 CT calcium score (CTCS) enriched for MACE events obtained from a large no-cost CLARIFY program (ClinicalTri-als.gov Identifier: NCT04075162). We employed sampling techniques to enhance model training. We also investigated Cox models with selected features to identify explainable high-risk characteristics.   Results. Our proposed calcium-omics model with modified synthetic down sampling and up sampling gave C-index (80.5%&#x2F;71.6%) and two-year AUC (82.4%&#x2F;74.8%) for (80:20, training&#x2F;testing), respectively (sampling was applied to the training set only). Results compared favorably to Agatston which gave C-index (71.3%&#x2F;70.3%) and AUC (71.8%&#x2F;68.8%), respectively. Among calcium-omics features, numbers of calcifications, LAD mass, and diffusivity (a measure of spatial distribution) were important determinants of increased risk, with dense calcification (&gt;1000HU) associated with lower risk. The calcium-omics model reclassified 63% of MACE patients to the high risk group in a held-out test. The categorical net-reclassification index was NRI&#x3D;0.153.   Conclusions. AI analysis of coronary calcification can lead to improved results as compared to Agatston scoring. Our findings suggest the utility of calcium-omics in improved prediction of risk.</p>
<hr>
<h2 id="Critical-Learning-Periods-Emerge-Even-in-Deep-Linear-Networks"><a href="#Critical-Learning-Periods-Emerge-Even-in-Deep-Linear-Networks" class="headerlink" title="Critical Learning Periods Emerge Even in Deep Linear Networks"></a>Critical Learning Periods Emerge Even in Deep Linear Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12221">http://arxiv.org/abs/2308.12221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kleinman, Alessandro Achille, Stefano Soatto</li>
</ul>
<p>Abstract:<br>Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show analytically and in simulations that the learning of features is tied to competition between sources. Finally, we extend our analysis to multi-task learning to show that pre-training on certain tasks can damage the transfer performance on new tasks, and show how this depends on the relationship between tasks and the duration of the pre-training stage. To the best of our knowledge, our work provides the first analytically tractable model that sheds light into why critical learning periods emerge in biological and artificial networks.</p>
<hr>
<h2 id="Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning"><a href="#Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning" class="headerlink" title="Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning"></a>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12219">http://arxiv.org/abs/2308.12219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yegcjs/diffusionllm">https://github.com/yegcjs/diffusionllm</a></li>
<li>paper_authors: Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu</li>
</ul>
<p>Abstract:<br>The recent surge of generative AI has been fueled by the generative power of diffusion probabilistic models and the scalable capabilities of large language models. Despite their potential, it remains elusive whether diffusion language models can solve general language tasks comparable to their autoregressive counterparts. This paper demonstrates that scaling diffusion models w.r.t. data, sizes, and tasks can effectively make them strong language learners. We build competent diffusion language models at scale by first acquiring knowledge from massive data via masked language modeling pretraining thanks to their intrinsic connections. We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks. Experiments show that scaling diffusion language models consistently improves performance across downstream language tasks. We further discover that instruction finetuning can elicit zero-shot and few-shot in-context learning abilities that help tackle many unseen tasks by following natural language instructions, and show promise in advanced and challenging abilities such as reasoning</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.AI_2023_08_24/" data-id="cllq6n4ao0004yo883lag8mr8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/25/cs.LG_2023_08_25/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-08-25
        
      </div>
    </a>
  
  
    <a href="/2023/08/24/cs.CL_2023_08_24/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-08-24</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">26</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
  <a href="#search" class="mobile-nav-link st-search-show-outputs">Search</a>
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


</div>
</body>
</html>
