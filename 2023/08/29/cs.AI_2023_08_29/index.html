
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-08-29 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="AI Deception: A Survey of Examples, Risks, and Potential Solutions paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.14752 repo_url: None paper_authors: Peter S. Park, Simon Goldstein, Aidan O’Gara, Michael Chen,">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-08-29">
<meta property="og:url" content="https://nullscc.github.io/2023/08/29/cs.AI_2023_08_29/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="AI Deception: A Survey of Examples, Risks, and Potential Solutions paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.14752 repo_url: None paper_authors: Peter S. Park, Simon Goldstein, Aidan O’Gara, Michael Chen,">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-29T12:00:00.000Z">
<meta property="article:modified_time" content="2023-08-30T18:43:23.913Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_08_29" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/29/cs.AI_2023_08_29/" class="article-date">
  <time datetime="2023-08-29T12:00:00.000Z" itemprop="datePublished">2023-08-29</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-08-29
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AI-Deception-A-Survey-of-Examples-Risks-and-Potential-Solutions"><a href="#AI-Deception-A-Survey-of-Examples-Risks-and-Potential-Solutions" class="headerlink" title="AI Deception: A Survey of Examples, Risks, and Potential Solutions"></a>AI Deception: A Survey of Examples, Risks, and Potential Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14752">http://arxiv.org/abs/2308.14752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter S. Park, Simon Goldstein, Aidan O’Gara, Michael Chen, Dan Hendrycks</li>
<li>For: 这篇论文主要探讨了现代人工智能系统是如何骗取人类信任的现象。* Methods: 论文首先是通过对现有的AI骗局例子进行概述，然后讨论了特定的AI系统（如Meta的CICERO）和通用AI系统（如大语言模型）如何骗取人类信任。* Results: 论文指出了AI骗局可能导致的一些风险，如诈骗、选举干预和AI系统控制失败等问题，并提出了一些解决这些问题的可能性，如实施robust风险评估要求、实施“机器人或者人”法律和重视相关研究，包括检测AI骗局和使AI系统更加不骗取人类信任的工具。<details>
<summary>Abstract</summary>
This paper argues that a range of current AI systems have learned how to deceive humans. We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth. We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta's CICERO) built for specific competitive situations, and general-purpose AI systems (such as large language models). Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI systems. Finally, we outline several potential solutions to the problems posed by AI deception: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive. Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Regulatory frameworks should subject AI systems capable of deception to rigorous risk assessments.2. Policymakers should implement “bot-or-not” laws to distinguish between human and AI-generated content.3. Policymakers should prioritize funding for research on AI deception detection and making AI systems less deceptive.We urge policymakers, researchers, and the public to work together to prevent AI deception from undermining the foundations of our society.</details></li>
</ol>
<hr>
<h2 id="Flexible-Techniques-for-Differentiable-Rendering-with-3D-Gaussians"><a href="#Flexible-Techniques-for-Differentiable-Rendering-with-3D-Gaussians" class="headerlink" title="Flexible Techniques for Differentiable Rendering with 3D Gaussians"></a>Flexible Techniques for Differentiable Rendering with 3D Gaussians</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14737">http://arxiv.org/abs/2308.14737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonid Keselman, Martial Hebert</li>
<li>for: 快速、可靠的形状重建是计算机视觉应用中的关键组成部分。神经辐射场示示了高品质新视图合成可能性，但是受到实际场景和物体快速重建的性能要求受限。</li>
<li>methods: 本文提出了基于 altenative 形状表示的新方法，包括使用可导流动、导出水密网格和按照光栅方向渲染每个光栅。此外，我们还证明了两种最近的方法之间的互操作性。</li>
<li>results: 我们的扩展方法可以快速、稳定地进行形状重建，并且可以在GPU或CPU上进行执行。codes和视觉示例可以在<a target="_blank" rel="noopener" href="https://leonidk.github.io/fmb-plus%E6%89%BE%E5%88%B0%E3%80%82">https://leonidk.github.io/fmb-plus找到。</a><details>
<summary>Abstract</summary>
Fast, reliable shape reconstruction is an essential ingredient in many computer vision applications. Neural Radiance Fields demonstrated that photorealistic novel view synthesis is within reach, but was gated by performance requirements for fast reconstruction of real scenes and objects. Several recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see https://leonidk.github.io/fmb-plus
</details>
<details>
<summary>摘要</summary>
快速可靠的形状重建是许多计算机视觉应用程序的关键组成部分。神经辐射场示示了高真实度新视图合成可能性，但是它受到快速重建真实场景和物体的性能要求限制。数据recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes, and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see <https://leonidk.github.io/fmb-plus>Here's the breakdown of the translation:* 快速可靠的形状重建 (fast and reliable shape reconstruction)* 是许多计算机视觉应用程序的关键组成部分 (is an essential ingredient in many computer vision applications)* 神经辐射场示示了高真实度新视图合成可能性 (Neural Radiance Fields demonstrated the possibility of high-fidelity novel view synthesis)* 但是它受到快速重建真实场景和物体的性能要求限制 (but was gated by performance requirements for fast reconstruction of real scenes and objects)* 数据recent approaches have built on alternative shape representations, in particular, 3D Gaussians (recent methods have focused on alternative shape representations, such as 3D Gaussians)* We develop extensions to these renderers (we develop extensions to these methods)* such as integrating differentiable optical flow (including differentiable optical flow)* exporting watertight meshes (exporting watertight meshes)* and rendering per-ray normals (and rendering per-ray normals)* Additionally, we show how two of the recent methods are interoperable with each other (additionally, we show how two of the recent methods can be combined)* These reconstructions are quick, robust, and easily performed on GPU or CPU (these reconstructions are fast, robust, and can be performed easily on GPU or CPU)* For code and visual examples, see <https://leonidk.github.io/fmb-plus> (for code and visual examples, see <https://leonidk.github.io/fmb-plus>)
</details></li>
</ul>
<hr>
<h2 id="Bayesian-artificial-brain-with-ChatGPT"><a href="#Bayesian-artificial-brain-with-ChatGPT" class="headerlink" title="Bayesian artificial brain with ChatGPT"></a>Bayesian artificial brain with ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14732">http://arxiv.org/abs/2308.14732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renato A. Krohling</li>
<li>for: 这个论文是为了研究 chatGPT 在概率理解方面的数学问题解决能力。</li>
<li>methods: 这个研究使用了 Zhu &amp; Gigerenzer 在 2006 年的研究，对 10 个概率理解问题进行了测试。</li>
<li>results: 结果显示，ChatGPT 能够 correctly 解决所有 10 个问题。<details>
<summary>Abstract</summary>
This paper aims to investigate the mathematical problem-solving capabilities of Chat Generative Pre-Trained Transformer (ChatGPT) in case of Bayesian reasoning. The study draws inspiration from Zhu & Gigerenzer's research in 2006, which posed the question: Can children reason the Bayesian way? In the pursuit of answering this question, a set of 10 Bayesian reasoning problems were presented. The results of their work revealed that children's ability to reason effectively using Bayesian principles is contingent upon a well-structured information representation. In this paper, we present the same set of 10 Bayesian reasoning problems to ChatGPT. Remarkably, the results demonstrate that ChatGPT provides the right solutions to all problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Distilled-GPT-for-Source-Code-Summarization"><a href="#Distilled-GPT-for-Source-Code-Summarization" class="headerlink" title="Distilled GPT for Source Code Summarization"></a>Distilled GPT for Source Code Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14731">http://arxiv.org/abs/2308.14731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apcl-research/jam-cgpt">https://github.com/apcl-research/jam-cgpt</a></li>
<li>paper_authors: Chia-Yi Su, Collin McMillan</li>
<li>for: 这个论文的目的是提出一种可以在单个16GHz GPU上运行的开源模型，以便自动生成代码摘要，而不需要将代码发送到不受信任的第三方服务器上。</li>
<li>methods: 该论文使用了一种基于大语言模型的方法，通过知识储存的过程来训练一个小型的开源模型，以便模拟GPT-3.5的功能。</li>
<li>results: 论文的评估结果表明，该模型可以准确地生成代码摘要，并且可以在单个16GHz GPU上运行。<details>
<summary>Abstract</summary>
A code summary is a brief natural language description of source code. Summaries are usually only a single sentence long, and yet form the backbone of developer documentation. A short descriptions such as "changes all visible polygons to the color blue" can give a programmer a high-level idea of what code does without the effort of reading the code itself. Recently, products based on Large Language Models such as ChatGPT have demonstrated a strong ability to write these descriptions automatically. However, to use these tools, programmers must send their code to untrusted third parties for processing (e.g., via an API call). This loss of custody is not acceptable to many organizations. In this paper, we present an alternative: we train an open source model using sample output generated by GPT-3.5 in a process related to knowledge distillation. Our model is small enough (350m parameters) to be run on a single 16gb GPU, yet we show in our evaluation that it is large enough to mimic GPT-3.5 on this task.
</details>
<details>
<summary>摘要</summary>
code summary 是一个简短的自然语言描述，描述源代码的功能。这些描述通常只是一句话长，但是它们成为开发者文档的基础。例如，"改变所有可见的多边形为蓝色" 可以给程序员提供高级别的理解，不需要阅读代码本身。现在，基于大语言模型的产品，如 ChatGPT，已经显示出自动生成这些描述的能力。然而，使用这些工具，程序员必须将代码传递给不可靠的第三方进行处理（例如，通过 API 调用）。这种失去控制不acceptable  для多个组织。在这篇论文中，我们提出一种代替方案：我们使用一个开源模型，使用 GPT-3.5 生成的样本输出进行训练。我们的模型具有 350 万参数，可以在单个 16 GB GPU 上运行，而我们的评估表明，它可以模拟 GPT-3.5 在这个任务上。
</details></li>
</ul>
<hr>
<h2 id="PanoSwin-a-Pano-style-Swin-Transformer-for-Panorama-Understanding"><a href="#PanoSwin-a-Pano-style-Swin-Transformer-for-Panorama-Understanding" class="headerlink" title="PanoSwin: a Pano-style Swin Transformer for Panorama Understanding"></a>PanoSwin: a Pano-style Swin Transformer for Panorama Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14726">http://arxiv.org/abs/2308.14726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhixin Ling, Zhen Xing, Xiangdong Zhou, Manliang Cao, Guichun Zhou</li>
<li>for: 提高panorama理解能力</li>
<li>methods: 使用狭窄窗口卷积和投影注意力来解决equirectangular projection中的边界缺失和空间扭曲问题，同时采用绝对位坐标嵌入和相对位坐标偏移来增强panoramic geometry信息。</li>
<li>results: 在多种panoramic任务上（包括panoramic object detection、panoramic classification和panoramic layout estimation）实现了比领先方法更高的性能。<details>
<summary>Abstract</summary>
In panorama understanding, the widely used equirectangular projection (ERP) entails boundary discontinuity and spatial distortion. It severely deteriorates the conventional CNNs and vision Transformers on panoramas. In this paper, we propose a simple yet effective architecture named PanoSwin to learn panorama representations with ERP. To deal with the challenges brought by equirectangular projection, we explore a pano-style shift windowing scheme and novel pitch attention to address the boundary discontinuity and the spatial distortion, respectively. Besides, based on spherical distance and Cartesian coordinates, we adapt absolute positional embeddings and relative positional biases for panoramas to enhance panoramic geometry information. Realizing that planar image understanding might share some common knowledge with panorama understanding, we devise a novel two-stage learning framework to facilitate knowledge transfer from the planar images to panoramas. We conduct experiments against the state-of-the-art on various panoramic tasks, i.e., panoramic object detection, panoramic classification, and panoramic layout estimation. The experimental results demonstrate the effectiveness of PanoSwin in panorama understanding.
</details>
<details>
<summary>摘要</summary>
在панोра姆理解方面，广泛使用的Equirectangular Projection（ERP）会导致边界缺continuity和空间扭曲。这会严重损害传统的CNN和vision Transformers在пан姆上的性能。在这篇论文中，我们提出了一种简单又有效的架构名为PanoSwin，用于学习pan姆表示。为了处理ERP所带来的挑战，我们研究了一种pano-style shift windowing scheme和novel pitch attention来解决边界缺continuity和空间扭曲问题。此外，基于球面距离和Cartesian坐标，我们采用绝对位域嵌入和相对位域偏好来增强pan姆的几何信息。由于平面图像理解可能与pan姆理解共享一些共同知识，我们设计了一种新的两Stage学习框架，以便从平面图像中传输知识到pan姆。我们对各种pan姆任务进行了实验，包括pan姆 объек检测、pan姆分类和pan姆布局估计。实验结果表明PanoSwin在pan姆理解方面的效果。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Time-Series-Forecasting-with-Bayesian-Modeling"><a href="#Hierarchical-Time-Series-Forecasting-with-Bayesian-Modeling" class="headerlink" title="Hierarchical Time Series Forecasting with Bayesian Modeling"></a>Hierarchical Time Series Forecasting with Bayesian Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14719">http://arxiv.org/abs/2308.14719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gal Elgavish</li>
<li>for: 这个论文主要针对时间序列分析中的预测任务，即在不约束的情况下做出有用的决策。</li>
<li>methods: 该论文提出了一种分布式预测方法，即在不同层次结构中训练独立的预测模型，并将这些模型传递给一种重新调整算法以改进预测结果。</li>
<li>results: 该论文通过synthetic和实际数据集的实验表明，分布式预测方法可以提高预测的准确性，并且可以与其他相关的研究作品进行比较。<details>
<summary>Abstract</summary>
We encounter time series data in many domains such as finance, physics, business, and weather. One of the main tasks of time series analysis, one that helps to take informed decisions under uncertainty, is forecasting. Time series are often hierarchically structured, e.g., a company sales might be broken down into different regions, and each region into different stores. In some cases the number of series in the hierarchy is too big to fit in a single model to produce forecasts in relevant time, and a decentralized approach is beneficial.   One way to do this is to train independent forecasting models for each series and for some summary statistics series implied by the hierarchy (e.g. the sum of all series) and to pass those models to a reconciliation algorithm to improve those forecasts by sharing information between the series.   In this work we focus on the reconciliation step, and propose a method to do so from a Bayesian perspective - Bayesian forecast reconciliation. We also define the common case of linear Gaussian reconciliation, where the forecasts are Gaussian and the hierarchy has linear structure, and show that we can compute reconciliation in closed form. We evaluate these methods on synthetic and real data sets, and compare them to other work in this field.
</details>
<details>
<summary>摘要</summary>
我们在各个领域，如金融、物理、商业和天气中都可以找到时间序列数据。时间序列分析的一个主要任务是预测，帮助在不确定的情况下做出了解的决策。时间序列经常具有层次结构，例如一家公司的销售可能分解为不同的区域和每个区域的不同的店铺。在某些情况下，序列的数量太多，不能准确地预测，这时一种分布式方法是有利的。我们在这种情况下提出了一种方法，即训练独立的预测模型 для每个序列和某些层次统计量（例如所有序列的总和），然后将这些模型传递给一个协调算法以提高预测。在这篇文章中，我们关注协调步骤，并从泛函视角出发提出了一种bayesian预测协调方法。我们还定义了常见的线性 Gaussian 协调情况，其中预测是 Gaussian 分布，序列层次结构是线性的，并且可以在关闭式形式内计算协调。我们在 sintetic 和实际数据集上评估了这些方法，并与其他相关研究进行比较。
</details></li>
</ul>
<hr>
<h2 id="Fast-Feedforward-Networks"><a href="#Fast-Feedforward-Networks" class="headerlink" title="Fast Feedforward Networks"></a>Fast Feedforward Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14711">http://arxiv.org/abs/2308.14711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pbelcak/fastfeedforward">https://github.com/pbelcak/fastfeedforward</a></li>
<li>paper_authors: Peter Belcak, Roger Wattenhofer</li>
<li>for: 提高层SIZE与计算成本之间的非线性关系，并提供一种快速的替代方案。</li>
<li>methods: 引入快速推导（FFF）架构，其运行时间与 feedforward 网络相似，但计算成本呈尖峰式增长。</li>
<li>results: 比较 feedforward 网络和混合专家网络，FFF 在计算成本下降了5.8%的性能，并且可以轻松地替换 transformers。<details>
<summary>Abstract</summary>
We break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a logarithmic-time alternative to feedforward networks.   We show that FFFs give comparable performance to feedforward networks at an exponential fraction of their inference cost, are quicker to deliver performance compared to mixture-of-expert networks, and can readily take the place of either in transformers.   Pushing FFFs to the absolute limit, we train a vision transformer to perform single-neuron inferences at the cost of only 5.8% performance decrease against the full-width variant.   Our implementation is available as a Python package; just use "pip install fastfeedforward".
</details>
<details>
<summary>摘要</summary>
我们打破层Size和推论成本之间的直线关系，通过引入快速feedforward（FFF）架构，实现了对数时间的替代方案。我们显示，FFFs可以与传统 feedforward 网络比较，具有相似的性能，并且在推论过程中更快速地获得结果，而且可以轻松地取代混合专家网络。我们在推展FFFs的最大限度下，将视觉 трансформа获得单 neuron 推论的成本，与全宽版本相对只需要5.8%的性能损失。我们的实现可以通过 pip 安装 fastfeedforward  packages。
</details></li>
</ul>
<hr>
<h2 id="VideoCutLER-Surprisingly-Simple-Unsupervised-Video-Instance-Segmentation"><a href="#VideoCutLER-Surprisingly-Simple-Unsupervised-Video-Instance-Segmentation" class="headerlink" title="VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation"></a>VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14710">http://arxiv.org/abs/2308.14710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/cutler">https://github.com/facebookresearch/cutler</a></li>
<li>paper_authors: Xudong Wang, Ishan Misra, Ziyun Zeng, Rohit Girdhar, Trevor Darrell</li>
<li>For: The paper is written for unsupervised video instance segmentation, which is a challenging task that requires identifying and tracking multiple objects in a video sequence without any labeled data.* Methods: The paper proposes a simple method called VideoCutLER, which uses high-quality pseudo masks and a simple video synthesis method to train a video model that can effectively segment and track multiple instances across video frames.* Results: The paper achieves competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, surpassing the previous state-of-the-art by a large margin. Specifically, the paper achieves 50.7% APvideo^50 and exceeds DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.Here’s the information in Simplified Chinese text:</li>
<li>for: 该 paper 是为了解决无监督视频实例分割问题，这是一个非常困难的任务，需要在视频序列中识别和跟踪多个对象，而无需任何标注数据。</li>
<li>methods: 该 paper 提出了一种简单的方法，即 VideoCutLER，它使用高质量的 Pseudo 面Mask 和简单的视频合成方法来训练一个视频模型，能够有效地 segment 和跟踪多个实例 Across 视频帧。</li>
<li>results: 该 paper 在 YouTubeVIS-2019 benchmark 上 achieve 竞争性的无监督学习结果，大幅超过之前的状态泰施，具体来说是 50.7% APvideo^50 和 exceeds DINO 在 YouTubeVIS-2019 上的 APvideo 指标上。<details>
<summary>Abstract</summary>
Existing approaches to unsupervised video instance segmentation typically rely on motion estimates and experience difficulties tracking small or divergent motions. We present VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos. Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames. We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50 , surpassing the previous state-of-the-art by a large margin. VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.
</details>
<details>
<summary>摘要</summary>
Traditional unsupervised video instance segmentation methods usually rely on motion estimates and have difficulty tracking small or divergent motions. We propose VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos. Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames. We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50, surpassing the previous state-of-the-art by a large margin. VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.Here's the word-for-word translation:传统的无监督视频实例分割方法通常基于运动估计，并且在跟踪小或弯曲运动时存在困难。我们提出了VideoCutLER，一种简单的无监督多实例视频分割方法，不使用运动基于学习信号如光流或者在自然视频上进行训练。我们的关键发现是，使用高质量的 Pseudo 面积和简单的视频合成方法来训练视频模型，奇怪地 sufficient 使得模型可以有效地在视频帧中分割和跟踪多个实例。我们在 YouTubeVIS-2019 benchmark 上 achieve 50.7% APvideo^50，大幅超越过去的状态泰然。VideoCutLER 还可以作为supervised video instance segmentation任务的强大预训练模型，在 YouTubeVIS-2019 上过去 DINO 的 APvideo 值 by 15.9%。
</details></li>
</ul>
<hr>
<h2 id="TRIVEA-Transparent-Ranking-Interpretation-using-Visual-Explanation-of-Black-Box-Algorithmic-Rankers"><a href="#TRIVEA-Transparent-Ranking-Interpretation-using-Visual-Explanation-of-Black-Box-Algorithmic-Rankers" class="headerlink" title="TRIVEA: Transparent Ranking Interpretation using Visual Explanation of Black-Box Algorithmic Rankers"></a>TRIVEA: Transparent Ranking Interpretation using Visual Explanation of Black-Box Algorithmic Rankers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14622">http://arxiv.org/abs/2308.14622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yuan, Kaustav Bhattacharjee, Akm Zahirul Islam, Aritra Dasgupta</li>
<li>for: 这篇论文的目的是提高排名的透明度，使得不同领域的决策者可以更加了解排名的内在逻辑。</li>
<li>methods: 本论文使用算法学习排名模型，并使用可解释Machine Learning（XAI）技术来帮助人类理解排名模型中的各个参数对排名的影响。</li>
<li>results: 通过TRIVEA视觉分析系统，研究人员可以轻松地探索和理解复杂多属性排名数据，无需打开黑盒排名模型。<details>
<summary>Abstract</summary>
Ranking schemes drive many real-world decisions, like, where to study, whom to hire, what to buy, etc. Many of these decisions often come with high consequences. For example, a university can be deemed less prestigious if not featured in a top-k list, and consumers might not even explore products that do not get recommended to buyers. At the heart of most of these decisions are opaque ranking schemes, which dictate the ordering of data entities, but their internal logic is inaccessible or proprietary. Drawing inferences about the ranking differences is like a guessing game to the stakeholders, like, the rankees (i.e., the entities who are ranked, like product companies) and the decision-makers (i.e., who use the rankings, like buyers). In this paper, we aim to enable transparency in ranking interpretation by using algorithmic rankers that learn from available data and by enabling human reasoning about the learned ranking differences using explainable AI (XAI) methods. To realize this aim, we leverage the exploration-explanation paradigm of human-data interaction to let human stakeholders explore subsets and groupings of complex multi-attribute ranking data using visual explanations of model fit and attribute influence on rankings. We realize this explanation paradigm for transparent ranking interpretation in TRIVEA, a visual analytic system that is fueled by: i) visualizations of model fit derived from algorithmic rankers that learn the associations between attributes and rankings from available data and ii) visual explanations derived from XAI methods that help abstract important patterns, like, the relative influence of attributes in different ranking ranges. Using TRIVEA, end users not trained in data science have the agency to transparently reason about the global and local behavior of the rankings without the need to open black-box ranking models and develop confidence in the resulting attribute-based inferences. We demonstrate the efficacy of TRIVEA using multiple usage scenarios and subjective feedback from researchers with diverse domain expertise. Keywords: Visual Analytics, Learning-to-Rank, Explainable ML, Ranking
</details>
<details>
<summary>摘要</summary>
排名方案在现实生活中影响很大，例如选择学习的地方、聘请的人员、购买的产品等。这些决策通常带有严重的后果。例如，如果一所大学不被列入某些排名列表中，那么该大学可能会被评估为 less prestigious。顾客可能不会考虑没有获得推荐的产品。排名方案的内部逻辑通常是不可见或 propriety 的，因此决策者（如产品公司）和排名对象（如顾客）无法了解排名差异的解释。在这篇论文中，我们想要使排名解释变得 transparent ，使用算法学习排名方法，并使用可解释AI（XAI）方法来帮助人类理解学习到的排名差异。为实现这一目标，我们利用人类数据互动的探索-解释模式，让人类决策者在可视化的方式下探索复杂多属性排名数据的子集和分组。我们在 TRIVEA 中实现了这一解释模式，TRIVEA 是一个基于可视化的数据分析系统，它使用以下两种方法来提供可视化和解释：1. 基于算法学习的排名模型，从可用数据中学习排名和属性之间的关系，并生成可视化的模型适配。2. XAI 方法，帮助抽象出重要的 Pattern，如排名范围内的属性影响。使用 TRIVEA，无需数据科学背景的结束用户可以自主地透明地理解排名的全球和本地行为，并对Attribute-based的推理产生信任。我们通过多个使用场景和域专家的主观反馈，证明了 TRIVEA 的可行性和有用性。关键字：可视化分析、学习排名、可解释Machine Learning、排名
</details></li>
</ul>
<hr>
<h2 id="Assessing-Trust-in-Construction-AI-Powered-Collaborative-Robots-using-Structural-Equation-Modeling"><a href="#Assessing-Trust-in-Construction-AI-Powered-Collaborative-Robots-using-Structural-Equation-Modeling" class="headerlink" title="Assessing Trust in Construction AI-Powered Collaborative Robots using Structural Equation Modeling"></a>Assessing Trust in Construction AI-Powered Collaborative Robots using Structural Equation Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14697">http://arxiv.org/abs/2308.14697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Newsha Emaminejad, Lisa Kath, Reza Akhavian</li>
<li>for: This study aimed to investigate the key technical and psychological factors that impact the architecture, engineering, and construction (AEC) professionals’ trust in collaborative robots (cobots) powered by artificial intelligence (AI).</li>
<li>methods: The study employed a nationwide survey of 600 AEC industry practitioners to gather in-depth responses and valuable insights into the future opportunities for promoting the adoption, cultivation, and training of a skilled workforce to leverage this technology effectively. A Structural Equation Modeling (SEM) analysis was used to reveal the significant factors for the adoption of AI-powered cobots in construction.</li>
<li>results: The study found that safety and reliability are significant factors for the adoption of AI-powered cobots in construction, and fear of being replaced resulting from the use of cobots can have a substantial effect on the mental health of the affected workers. Additionally, the study found that a lower error rate in jobs involving cobots, safety measurements, and security of data collected by cobots from jobsites significantly impact reliability, while the transparency of cobots’ inner workings can benefit accuracy, robustness, security, privacy, and communication, and results in higher levels of automation. The study’s findings provide critical insights into the perceptions and experiences of AEC professionals towards adoption of cobots in construction and help project teams determine the adoption approach that aligns with the company’s goals and workers’ welfare.<details>
<summary>Abstract</summary>
This study aimed to investigate the key technical and psychological factors that impact the architecture, engineering, and construction (AEC) professionals' trust in collaborative robots (cobots) powered by artificial intelligence (AI). The study employed a nationwide survey of 600 AEC industry practitioners to gather in-depth responses and valuable insights into the future opportunities for promoting the adoption, cultivation, and training of a skilled workforce to leverage this technology effectively. A Structural Equation Modeling (SEM) analysis revealed that safety and reliability are significant factors for the adoption of AI-powered cobots in construction. Fear of being replaced resulting from the use of cobots can have a substantial effect on the mental health of the affected workers. A lower error rate in jobs involving cobots, safety measurements, and security of data collected by cobots from jobsites significantly impact reliability, while the transparency of cobots' inner workings can benefit accuracy, robustness, security, privacy, and communication, and results in higher levels of automation, all of which demonstrated as contributors to trust. The study's findings provide critical insights into the perceptions and experiences of AEC professionals towards adoption of cobots in construction and help project teams determine the adoption approach that aligns with the company's goals workers' welfare.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这项研究的目标是调查建筑、工程和建筑（AEC）专业人员对人工智能（AI）驱动的协作机器人（cobots）的信任度。研究使用了600名AEC行业专业人员参与全国范围内的调查，以获取深入的反应和有价值的洞察。结构方程分析发现，在建筑中采用AI驱动的cobots的安全性和可靠性是采用的关键因素。使用cobots可能会导致工人被取代，并且可能会对工人的心理健康产生很大的影响。在cobots参与的任务中，误差率的下降和工地安全测量对可靠性产生了重要影响，而cobots内部的透明度可以提高准确性、Robustness、安全性、隐私和通信，并导致更高水平的自动化，这些都是信任的重要因素。这项研究的发现对AEC专业人员对cobots在建筑领域的采用提供了关键的洞察和经验，帮助项目团队确定采用策略，以实现公司的目标和工人的福祉。
</details></li>
</ul>
<hr>
<h2 id="MELT-Mining-Effective-Lightweight-Transformations-from-Pull-Requests"><a href="#MELT-Mining-Effective-Lightweight-Transformations-from-Pull-Requests" class="headerlink" title="MELT: Mining Effective Lightweight Transformations from Pull Requests"></a>MELT: Mining Effective Lightweight Transformations from Pull Requests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14687">http://arxiv.org/abs/2308.14687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/squareslab/melt">https://github.com/squareslab/melt</a></li>
<li>paper_authors: Daniel Ramos, Hailie Mitchell, Inês Lynce, Vasco Manquinho, Ruben Martins, Claire Le Goues</li>
<li>for: 提高API更新效率，帮助软件开发人员更快速地更新API。</li>
<li>methods: 使用机器学习技术 mines API更新规则 directly from pull requests in popular library repositories，并提出了一种通用化过程来提高规则的可重用性。</li>
<li>results: 在四个流行的库中 mines 461个更新规则，并通过应用这些规则到客户端项目中，成功减少了警告数量并解决了一些测试案例。<details>
<summary>Abstract</summary>
Software developers often struggle to update APIs, leading to manual, time-consuming, and error-prone processes. We introduce MELT, a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from the library source and automatically generated code examples based on the pull requests, we infer transformation rules in \comby, a language for structural code search and replace. Since inferred rules from single code examples may be too specific, we propose a generalization procedure to make the rules more applicable to client projects. MELT rules are syntax-driven, interpretable, and easily adaptable. Moreover, unlike previous work, our approach enables rule inference to seamlessly integrate into the library workflow, removing the need to wait for client code migrations. We evaluated MELT on pull requests from four popular libraries, successfully mining 461 migration rules from code examples in pull requests and 114 rules from auto-generated code examples. Our generalization procedure increases the number of matches for mined rules by 9x. We applied these rules to client projects and ran their tests, which led to an overall decrease in the number of warnings and fixing some test cases demonstrating MELT's effectiveness in real-world scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fine-Tuning-Llama-2-Large-Language-Models-for-Detecting-Online-Sexual-Predatory-Chats-and-Abusive-Texts"><a href="#Fine-Tuning-Llama-2-Large-Language-Models-for-Detecting-Online-Sexual-Predatory-Chats-and-Abusive-Texts" class="headerlink" title="Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts"></a>Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14683">http://arxiv.org/abs/2308.14683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanh Thi Nguyen, Campbell Wilson, Janis Dalins</li>
<li>for: 这个研究的目的是为了探索在社交媒体平台上探索性的偏见和不当语言，以及发展一个可靠的检测系统，以维护网络上的安全，特别是对于弱化人群，如儿童和青少年。</li>
<li>methods: 本研究使用了Meta GenAI公司最近发布的免费预训Llama 2 7B-parameter模型，进行了精致的调整和测试，以检测在线上的性骚扰和不当语言。</li>
<li>results: 本研究的结果显示，提出的方法在三个不同的数据集上具有优秀的表现，能够自动和自适应地检测性骚扰和不当语言，并且可以应用于各种文本分类问题，如情感分析、骇客和诈欺检测、法律文件排序、假新闻检测、语言识别、用户意愿识别、文本基于产品分类、医疗记录分析和维护产品检测。<details>
<summary>Abstract</summary>
Detecting online sexual predatory behaviours and abusive language on social media platforms has become a critical area of research due to the growing concerns about online safety, especially for vulnerable populations such as children and adolescents. Researchers have been exploring various techniques and approaches to develop effective detection systems that can identify and mitigate these risks. Recent development of large language models (LLMs) has opened a new opportunity to address this problem more effectively. This paper proposes an approach to detection of online sexual predatory chats and abusive language using the open-source pretrained Llama 2 7B-parameter model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu). Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods in this domain. Experimental results show a strong performance of the proposed approach, which performs proficiently and consistently across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities. Furthermore, it can be employed for solving text classification problems with other potential applications such as sentiment analysis, spam and phishing detection, sorting legal documents, fake news detection, language identification, user intent recognition, text-based product categorization, medical record analysis, and resume screening.
</details>
<details>
<summary>摘要</summary>
在社交媒体平台上探测在线性侵和辱骂语言的行为已成为研究的关键领域，特别是对于容易受到侵害的人群，如儿童和青少年。研究人员已经在各种技术和方法上进行了探索，以开发有效的检测系统，以避免这些风险。最近，大型语言模型（LLMs）的发展对于解决这个问题提供了新的机会。本文提出了一种在线性侵辱聊天和辱骂语言检测的方法，使用Meta GenAI最近发布的开源预训练Llama 2 7B参数模型。我们在不同的数据集、不同程度的偏好和不同语言（英语、旁语和乌都）上进行了精细调整。基于LLMs的强大能力，我们的方法是自动化的，无需手动搜索特征提取和分类器设计步骤，与传统方法不同。实验结果表明，我们的方法在三个不同的数据集上表现出色，并在五组实验中表现了稳定和可靠的性。这些结果表明，我们的方法可以在实际应用中使用，即 Flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities.此外，它还可以用于解决文本分类问题，包括情感分析、垃圾邮件和恶意软件检测、法律文档排序、假新闻检测、语言识别、用户意图识别、文本基于产品分类、医疗记录分析和简历屏选择。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/29/cs.AI_2023_08_29/" data-id="clly3602k0012dd88fh44btj0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/29/cs.CV_2023_08_29/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-08-29
        
      </div>
    </a>
  
  
    <a href="/2023/08/29/cs.LG_2023_08_29/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-08-29</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">104</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
