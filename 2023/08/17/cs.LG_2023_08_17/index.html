
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-17 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Enhancing API Documentation through BERTopic Modeling and Summarization paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.09070 repo_url: https:&#x2F;&#x2F;github.com&#x2F;scam2023-bert&#x2F;bertopic paper_authors: AmirHossein Naghsh">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-17 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/17/cs.LG_2023_08_17/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Enhancing API Documentation through BERTopic Modeling and Summarization paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.09070 repo_url: https:&#x2F;&#x2F;github.com&#x2F;scam2023-bert&#x2F;bertopic paper_authors: AmirHossein Naghsh">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-16T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:32.167Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.LG_2023_08_17/" class="article-date">
  <time datetime="2023-08-16T16:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-17 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization"><a href="#Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization" class="headerlink" title="Enhancing API Documentation through BERTopic Modeling and Summarization"></a>Enhancing API Documentation through BERTopic Modeling and Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09070">http://arxiv.org/abs/2308.09070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scam2023-bert/bertopic">https://github.com/scam2023-bert/bertopic</a></li>
<li>paper_authors: AmirHossein Naghshzan, Sylvie Ratte</li>
<li>for: 本研究旨在提高API文档的可读性和效率，以便开发者更方便地从官方文档中提取有用信息。</li>
<li>methods: 本研究使用BERTopic进行主题分析，并采用自然语言处理（NLP）技术生成API文档的摘要。</li>
<li>results: 研究发现了各种常见主题和问题，并生成了可能的解决方案，从而提高了开发者对复杂API的理解和 Navigation 效率。<details>
<summary>Abstract</summary>
As the amount of textual data in various fields, including software development, continues to grow, there is a pressing demand for efficient and effective extraction and presentation of meaningful insights. This paper presents a unique approach to address this need, focusing on the complexities of interpreting Application Programming Interface (API) documentation. While official API documentation serves as a primary source of information for developers, it can often be extensive and lacks user-friendliness. In light of this, developers frequently resort to unofficial sources like Stack Overflow and GitHub. Our novel approach employs the strengths of BERTopic for topic modeling and Natural Language Processing (NLP) to automatically generate summaries of API documentation, thereby creating a more efficient method for developers to extract the information they need. The produced summaries and topics are evaluated based on their performance, coherence, and interoperability.   The findings of this research contribute to the field of API documentation analysis by providing insights into recurring topics, identifying common issues, and generating potential solutions. By improving the accessibility and efficiency of API documentation comprehension, our work aims to enhance the software development process and empower developers with practical tools for navigating complex APIs.
</details>
<details>
<summary>摘要</summary>
随着不同领域的文本数据量不断增加，包括软件开发，有效和高效地提取和展示有用的洞察结论成为了一项急需。这篇论文提出了一种独特的方法，专注于API文档解释的复杂性。尽管官方API文档作为开发者的主要信息来源，但它们可能是广泛的和不易于使用的。为此，开发者经常查阅Stack Overflow和GitHub等非官方来源。我们的新方法利用BERTopic的话题模型和自然语言处理（NLP）技术，自动生成API文档摘要，从而为开发者提供更高效的信息提取方式。生成的摘要和话题被评估基于其性能、一致性和可操作性。我们的研究成果对API文档分析领域进行了贡献，提供了循环话题、常见问题的指导和解决方案。我们的工作目标是通过改善API文档理解的可 accessed性和效率，推动软件开发过程和开发者在复杂API中导航的实用工具。
</details></li>
</ul>
<hr>
<h2 id="Uplift-Modeling-from-Causal-Inference-to-Personalization"><a href="#Uplift-Modeling-from-Causal-Inference-to-Personalization" class="headerlink" title="Uplift Modeling: from Causal Inference to Personalization"></a>Uplift Modeling: from Causal Inference to Personalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09066">http://arxiv.org/abs/2308.09066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felipe Moraes, Hugo Manuel Proença, Anastasiia Kornilova, Javier Albert, Dmitri Goldenberg</li>
<li>For: The paper is written for individuals who want to learn about uplift modeling and its applications in personalized promotional campaigns.* Methods: The paper introduces state-of-the-art techniques in uplift modeling, including the advantages and limitations of different approaches. It also covers the unique setup of constrained uplift modeling.* Results: The paper presents real-life applications of uplift modeling and discusses challenges in implementing these models in production.Here’s the same information in Simplified Chinese text:* For: 论文主要是为了探讨个性化促销活动中的营销效果估计和个性化推荐。* Methods: 论文介绍了当前最新的营销效果估计技术，包括不同方法的优点和缺点，以及受限制的营销效果估计。* Results: 论文介绍了实际应用的营销效果估计案例，以及实现这些模型的挑战。<details>
<summary>Abstract</summary>
Uplift modeling is a collection of machine learning techniques for estimating causal effects of a treatment at the individual or subgroup levels. Over the last years, causality and uplift modeling have become key trends in personalization at online e-commerce platforms, enabling the selection of the best treatment for each user in order to maximize the target business metric. Uplift modeling can be particularly useful for personalized promotional campaigns, where the potential benefit caused by a promotion needs to be weighed against the potential costs. In this tutorial we will cover basic concepts of causality and introduce the audience to state-of-the-art techniques in uplift modeling. We will discuss the advantages and the limitations of different approaches and dive into the unique setup of constrained uplift modeling. Finally, we will present real-life applications and discuss challenges in implementing these models in production.
</details>
<details>
<summary>摘要</summary>
“ upplift 模型是一种集成机器学习技术，用于估计干预效应的个体或 subgroup 水平。过去几年， causality 和 upplift 模型在在线电商平台上Personalization中变得越来越普遍，以便为每个用户选择最佳治疗，以最大化目标业务指标。upplift 模型在个性化促销活动中 particualrly 有用，因为促销的潜在利益需要与潜在成本进行平衡。在这个教程中，我们将覆盖 causality 的基本概念，并介绍现代 uplift 模型的技术。我们将讨论不同方法的优势和局限性，并深入探讨受限 uplift 模型的特殊设置。最后，我们将介绍实际应用和在生产中实施这些模型的挑战。”
</details></li>
</ul>
<hr>
<h2 id="Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression"><a href="#Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression" class="headerlink" title="Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression"></a>Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09065">http://arxiv.org/abs/2308.09065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanlong Yu, Gianni Franchi, Jindong Gu, Emanuel Aldea</li>
<li>for: 这个论文主要是为了提供更加 Robust uncertainty quantification 方法，以便在实际应用中部署深度神经网络 (DNNs)。</li>
<li>methods: 这个方法使用了一个称为 Auxiliary Uncertainty Estimator (AuxUE) 的方法，并且考虑了不同的分布假设来估计随机误差，最终选择了 Laplace 分布估计预测误差。此外，这个方法还提出了一个名为 Discretization-Induced Dirichlet pOsterior (DIDO) 的新解决方案，用于模型预测误差的 Dirichlet  posterior。</li>
<li>results: 实验结果显示，这个方法可以在噪音输入下提供更加Robust的 uncertainty estimates，并且可以扩展到 both image-level 和 pixel-wise 任务上。<details>
<summary>Abstract</summary>
Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks."中文翻译：uncertainty quantification是深度神经网络（DNN）在实际应用中的关键。auxiliary uncertainty estimator（AuxUE）是修改主任务模型的最有效的方法来估计主任务预测结果的uncertainty。为了被视为可靠，AuxUE必须能够保持其性能并在面对Out-of-Distribution（OOD）输入时触发更高的uncertainty。然而，目前的AuxUE设计主要用于aleatoric uncertainty estimate，而AuxUE的Robustness尚未被探索。在这项工作中，我们提出了一种通用的AuxUE方案，用于更加Robust的uncertainty量化。 Specifically，为了实现更加Robust的aleatoric uncertainty estimate，我们考虑了不同的分布假设，并最终选择了Laplace分布来近似预测错误。 For epistemic uncertainty，我们提出了一种新的解决方案，名为Discretization-Induced Dirichlet Posterior（DIDO），它模型了预测错误的Discretized posterior。经验表明，我们的提议方法可以在噪声输入下提供Robust的uncertainty估计，并且可以扩展到像素级和图像级任务。>>
</details></li>
</ul>
<hr>
<h2 id="Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods"><a href="#Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods" class="headerlink" title="Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods"></a>Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09051">http://arxiv.org/abs/2308.09051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paavo Alku, Sudarsana Reddy Kadiri, Dhananjaya Gowda</li>
<li>for: 这个研究是 investigate 形式追踪的，使用现有的数据驱动追踪器DeepFormants的形式被改进，使用LP-based方法来估算形式。</li>
<li>methods: 这个研究使用了LP-COV和QCP-FB两种LP-based方法来估算形式，并将这些估算结果与数据驱动DeepFormants tracker的预测结果进行比较。</li>
<li>results: 研究结果表明，使用QCP-FB方法来改进DeepFormants tracker的表现最佳，并且这种改进的追踪器在受到雑音损害的情况下表现更好。<details>
<summary>Abstract</summary>
In this study, formant tracking is investigated by refining the formants tracked by an existing data-driven tracker, DeepFormants, using the formants estimated in a model-driven manner by linear prediction (LP)-based methods. As LP-based formant estimation methods, conventional covariance analysis (LP-COV) and the recently proposed quasi-closed phase forward-backward (QCP-FB) analysis are used. In the proposed refinement approach, the contours of the three lowest formants are first predicted by the data-driven DeepFormants tracker, and the predicted formants are replaced frame-wise with local spectral peaks shown by the model-driven LP-based methods. The refinement procedure can be plugged into the DeepFormants tracker with no need for any new data learning. Two refined DeepFormants trackers were compared with the original DeepFormants and with five known traditional trackers using the popular vocal tract resonance (VTR) corpus. The results indicated that the data-driven DeepFormants trackers outperformed the conventional trackers and that the best performance was obtained by refining the formants predicted by DeepFormants using QCP-FB analysis. In addition, by tracking formants using VTR speech that was corrupted by additive noise, the study showed that the refined DeepFormants trackers were more resilient to noise than the reference trackers. In general, these results suggest that LP-based model-driven approaches, which have traditionally been used in formant estimation, can be combined with a modern data-driven tracker easily with no further training to improve the tracker's performance.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了形式追踪的可行性，通过改进现有的数据驱动追踪器DeepFormants的形式追踪结果，使用模型驱动的方法来估算形式。作为模型驱动的形式估算方法，我们使用了传统的covariance分析(LP-COV)和最近提出的 quasi-closed phase forward-backward(QCP-FB)分析。在我们提议的改进方法中，首先使用DeepFormants tracker来预测三个最低的形式，然后将预测的形式替换为每帧的本地 спектраль峰点，这些峰点是由模型驱动的LP-based方法估算出来的。这个改进过程可以轻松地插入到DeepFormants tracker中，无需进行任何新的数据学习。我们 compare了两个改进后的DeepFormants tracker与原始DeepFormants tracker和五个已知的传统追踪器，结果表明，数据驱动的DeepFormants tracker比传统追踪器高效，而使用QCP-FB分析进行改进后的追踪器表现最佳。此外，通过使用受损的VTR语音追踪，研究发现，改进后的DeepFormants tracker对噪声抗性更高于参照追踪器。总的来说，这些结果表明，LP-based模型驱动的方法可以轻松地与现有的数据驱动追踪器结合使用，无需进行任何新的数据学习，以提高追踪器的性能。
</details></li>
</ul>
<hr>
<h2 id="Kernel-Based-Tests-for-Likelihood-Free-Hypothesis-Testing"><a href="#Kernel-Based-Tests-for-Likelihood-Free-Hypothesis-Testing" class="headerlink" title="Kernel-Based Tests for Likelihood-Free Hypothesis Testing"></a>Kernel-Based Tests for Likelihood-Free Hypothesis Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09043">http://arxiv.org/abs/2308.09043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrik Róbert Gerber, Tianze Jiang, Yury Polyanskiy, Rui Sun</li>
<li>For: The paper is focused on the problem of labeling additional inputs when only a portion of the data is labeled, specifically in the context of likelihood-free inference.* Methods: The paper introduces a generalization of the problem where unlabeled samples come from a mixture of the two classes, and studies the minimax sample complexity for non-parametric classes of densities under maximum mean discrepancy (MMD) separation.* Results: The paper investigates the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images, and confirms the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.Here’s the Chinese translation of the three points:* For: 这篇论文关注的是只有部分数据标注的情况下，进行likelihood-free推断的标注问题。* Methods: 论文引入了一种扩展，即未标注样本来自两个类的混合，并研究非 Parametric 类型的density下的最小最大值复杂性。* Results: 论文 investigate了使用神经网络参数化的kernel在两个任务上的实际性能：探测希格斯粒子和探测DDPM生成的图像 amidst CIFAR-10图像，并证实了理论上预测的 $m$ vs $n$ 负面trade-off。<details>
<summary>Abstract</summary>
Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax sample complexity for non-parametric classes of densities under \textit{maximum mean discrepancy} (MMD) separation; and (c) investigate the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images. For both problems we confirm the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.
</details>
<details>
<summary>摘要</summary>
In this work, we:(a) Introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice.(b) Study the minimax sample complexity for non-parametric classes of densities under maximum mean discrepancy (MMD) separation.(c) Investigate the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images. For both problems, we confirm the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.
</details></li>
</ul>
<hr>
<h2 id="LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation"><a href="#LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation" class="headerlink" title="LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation"></a>LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09026">http://arxiv.org/abs/2308.09026</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dogabasaran/lesionmix">https://github.com/dogabasaran/lesionmix</a></li>
<li>paper_authors: Berke Doga Basaran, Weitong Zhang, Mengyun Qiao, Bernhard Kainz, Paul M. Matthews, Wenjia Bai</li>
<li>for: 提高深度学习基于医学影像分割方法的精度和稳定性，通过对医学影像进行数据增强。</li>
<li>methods: LesionMix是一种新的、简单的疾病意识数据增强方法，通过在肿瘤水平进行数据增强，提高了肿瘤形态、位置、强度和负荷分布的多样性，同时允许肿瘤填充和缺失。</li>
<li>results: 在不同的Modalities和不同的肿瘤数据集上，LesionMix实现了优秀的肿瘤图像分割性能，比较新的 Mix-based 数据增强方法更好。代码将于<a target="_blank" rel="noopener" href="https://github.com/dogabasaran/lesionmix">https://github.com/dogabasaran/lesionmix</a> 发布。<details>
<summary>Abstract</summary>
Data augmentation has become a de facto component of deep learning-based medical image segmentation methods. Most data augmentation techniques used in medical imaging focus on spatial and intensity transformations to improve the diversity of training images. They are often designed at the image level, augmenting the full image, and do not pay attention to specific abnormalities within the image. Here, we present LesionMix, a novel and simple lesion-aware data augmentation method. It performs augmentation at the lesion level, increasing the diversity of lesion shape, location, intensity and load distribution, and allowing both lesion populating and inpainting. Experiments on different modalities and different lesion datasets, including four brain MR lesion datasets and one liver CT lesion dataset, demonstrate that LesionMix achieves promising performance in lesion image segmentation, outperforming several recent Mix-based data augmentation methods. The code will be released at https://github.com/dogabasaran/lesionmix.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>深度学习基于医学影像分割方法中的数据扩充已成为一种标准组成部分。大多数医学影像扩充技术都是在空间和强度水平进行变换，以提高训练图像的多样性。它们通常是在图像层次上进行设计，对全图像进行扩充，而不是关注特定的病变内部。在这里，我们介绍了LesionMix，一种新的和简单的病变意识数据扩充方法。它在病变层次上进行扩充，提高病变形状、位置、强度和负荷分布，并允许病变填充和抹除。在不同的modalities和不同的病变数据集上，包括四个脑MR病变数据集和一个肝CT病变数据集，LesionMix在病变图像分割中实现了可观的表现，比较出色于一些最近的混合数据扩充方法。代码将在https://github.com/dogabasaran/lesionmix上发布。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming"><a href="#Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming" class="headerlink" title="Reinforcement Learning for Battery Management in Dairy Farming"></a>Reinforcement Learning for Battery Management in Dairy Farming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09023">http://arxiv.org/abs/2308.09023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nawazish Ali, Abdul Wahid, Rachael shaw, Karl Mason</li>
<li>for: 这项研究是为了应对牛奶农业中的能源消耗异常高的问题，通过人工智能技术来优化电池充放和充电管理策略，以提高牛奶农业中的能源效率和可持续性。</li>
<li>methods: 该研究使用Q学习算法来学习一个有效的电池充放和充电策略，并对比与现有的基线算法进行比较。</li>
<li>results: 研究结果表明，使用Q学习算法可以Significantly reduce electricity costs compared to the baseline algorithm，这些发现 highlights the effectiveness of reinforcement learning for battery management within the dairy farming sector。<details>
<summary>Abstract</summary>
Dairy farming is a particularly energy-intensive part of the agriculture sector. Effective battery management is essential for renewable integration within the agriculture sector. However, controlling battery charging/discharging is a difficult task due to electricity demand variability, stochasticity of renewable generation, and energy price fluctuations. Despite the potential benefits of applying Artificial Intelligence (AI) to renewable energy in the context of dairy farming, there has been limited research in this area. This research is a priority for Ireland as it strives to meet its governmental goals in energy and sustainability. This research paper utilizes Q-learning to learn an effective policy for charging and discharging a battery within a dairy farm setting. The results demonstrate that the developed policy significantly reduces electricity costs compared to the established baseline algorithm. These findings highlight the effectiveness of reinforcement learning for battery management within the dairy farming sector.
</details>
<details>
<summary>摘要</summary>
奶业是农业部门中特别能耗能源的一部分。有效的电池管理是重要的，以便在农业部门中 integrating 可再生能源。然而，控制电池充放电是一个困难的任务，因为能源需求的变化、可再生能源的随机性和能源价格的波动。尽管应用人工智能（AI）到奶业中可能有很多的优点，但是这个领域的研究却有限。这项研究是爱尔兰政府的一个优先事项，以实现能源和可持续发展的目标。这篇研究论文使用Q学习算法学习一个有效的电池充放电策略，结果表明，发展的策略可以较基准算法减少电力成本。这些发现表明，强化学习可以在奶业部门中有效地管理电池。
</details></li>
</ul>
<hr>
<h2 id="Multi-field-Visualisation-via-Trait-induced-Merge-Trees"><a href="#Multi-field-Visualisation-via-Trait-induced-Merge-Trees" class="headerlink" title="Multi-field Visualisation via Trait-induced Merge Trees"></a>Multi-field Visualisation via Trait-induced Merge Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09015">http://arxiv.org/abs/2308.09015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jochen Jankowai, Talha Bin Masood, Ingrid Hotz</li>
<li>for: 这paper是为了探讨tensor场或多变量数据的分析，提出 trait-based merge trees，一种特性基于merge trees的总结。</li>
<li>methods: 这paper使用了特性空间中的特性定义，以及Attribute Space中的特性空间定义，将distance field转化为属性空间中的一个整数场，用于 topological data analysis。</li>
<li>results: 这paper提出了一种基于特性的merge tree Hierarchy，可以用于查询最相似和持续存在的特性，并提供了不同的查询方法以便高亮不同的特性方面。三个 caso study在不同的领域中应用了该方法，以证明其跨领域可用性。<details>
<summary>Abstract</summary>
In this work, we propose trait-based merge trees a generalization of merge trees to feature level sets, targeting the analysis of tensor field or general multi-variate data. For this, we employ the notion of traits defined in attribute space as introduced in the feature level sets framework. The resulting distance field in attribute space induces a scalar field in the spatial domain that serves as input for topological data analysis. The leaves in the merge tree represent those areas in the input data that are closest to the defined trait and thus most closely resemble the defined feature. Hence, the merge tree yields a hierarchy of features that allows for querying the most relevant and persistent features. The presented method includes different query methods for the tree which enable the highlighting of different aspects. We demonstrate the cross-application capabilities of this approach with three case studies from different domains.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了 trait-based merge trees，这是 merge trees 的一种普遍化，targeting tensor field 或一般多变量数据的分析。为此，我们利用 attribute space 中定义的特质（trait）。在这个框架中，输入数据的特征空间距离场所引入了一个拓扑数据分析的输入场。merge tree 的叶子节点表示输入数据中最接近定义特质的区域，因此最接近定义的特征。因此，merge tree 提供了一个特征层次结构，可以对输入数据进行特征 queries。我们还提供了不同的查询方法，可以根据不同的需求高亮不同的特征。我们通过三个不同领域的案例，证明了这种方法的跨应用性。
</details></li>
</ul>
<hr>
<h2 id="Deep-seeded-Clustering-for-Unsupervised-Valence-Arousal-Emotion-Recognition-from-Physiological-Signals"><a href="#Deep-seeded-Clustering-for-Unsupervised-Valence-Arousal-Emotion-Recognition-from-Physiological-Signals" class="headerlink" title="Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals"></a>Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09013">http://arxiv.org/abs/2308.09013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Dubois, Carlos Lima Azevedo, Sonja Haustein, Bruno Miranda</li>
<li>for: 这篇论文主要是关于情感认知的研究，旨在提出一种基于物理和心理数据的无监督深度划分方法来实现情感认知。</li>
<li>methods: 该方法使用了深度划分算法，包括深度k-means和深度c-means，并在测试数据集WESAD上实现了87%的总准确率。</li>
<li>results: 该研究表明，通过使用物理和心理数据，并使用无监督深度划分方法，可以实现高度准确的情感认知，并且可以避免需要大量的标签数据。<details>
<summary>Abstract</summary>
Emotions play a significant role in the cognitive processes of the human brain, such as decision making, learning and perception. The use of physiological signals has shown to lead to more objective, reliable and accurate emotion recognition combined with raising machine learning methods. Supervised learning methods have dominated the attention of the research community, but the challenge in collecting needed labels makes emotion recognition difficult in large-scale semi- or uncontrolled experiments. Unsupervised methods are increasingly being explored, however sub-optimal signal feature selection and label identification challenges unsupervised methods' accuracy and applicability. This article proposes an unsupervised deep cluster framework for emotion recognition from physiological and psychological data. Tests on the open benchmark data set WESAD show that deep k-means and deep c-means distinguish the four quadrants of Russell's circumplex model of affect with an overall accuracy of 87%. Seeding the clusters with the subject's subjective assessments helps to circumvent the need for labels.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:情感对人类大脑的认知过程具有重要作用，如决策、学习和感知。通过使用生物学信号，可以实现更加客观、可靠和准确的情感识别，并且与机器学习方法相结合。但是，在大规模的半控制或无控制实验中收集标签是困难的，因此许多研究者对supervised learning方法进行了探索。然而，不同信号特征选择和标签标识问题限制了无监督方法的准确性和可应用性。这篇文章提出了一种无监督深度团 clustering框架，用于从生物学和心理学数据中进行情感识别。在WESAD开放数据集上进行测试，深度k-means和深度c-means能够分解Russell的情感圆框模型中的四个 quadrant，总准确率达87%。通过使用参与者的主观评估来填充团中的标签，可以避免标签收集的困难。
</details></li>
</ul>
<hr>
<h2 id="Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability"><a href="#Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability" class="headerlink" title="Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability"></a>Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09004">http://arxiv.org/abs/2308.09004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renan Souza, Tyler J. Skluzacek, Sean R. Wilkinson, Maxim Ziatdinov, Rafael Ferreira da Silva</li>
<li>for: 科学发现的大规模合作和数据分析</li>
<li>methods: 基于数据可见性、适配器系统设计和证据的轻量级运行多工程数据分析方法</li>
<li>results: 实现了灵活的多工程数据分析，可以在多种并行环境中运行，并且在 Summit 超级计算机上实现了near-zero overhead，可以处理大量任务。<details>
<summary>Abstract</summary>
Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.
</details>
<details>
<summary>摘要</summary>
现代大规模科学发现需要跨学科合作和多种计算机facility的支持，包括高性能计算机（HPC）机器和Edge-to-Cloud kontinuum。集成数据分析在科学发现中扮演着关键的角色，特别是在当前人工智能时代，通过帮助开发负责任AI，FAIR，可重现和用户指导。然而，科学的多元性带来了多种支持工具、跨设施环境和高效HPC执行的挑战。基于数据可见性，适配器系统设计和证明，我们提出MIDA：一种轻量级运行时多工流Integrated Data Analysis的方法。MIDA定义了数据可见性策略和适配方法，用于不同的并行系统和机器学习工具。通过可见性，它在背景中 intercepts 数据流 ohne requiring  инструментирование，并将domain、证明和电信数据在运行时集成到一个统一的数据库中，准备就绪 для用户指导查询。我们进行实验，将多工流分析集成到了材料科学中的分布式深度学习应用程序中，运行在多种环境上，包括最多276个GPU并行。我们显示了near-zero overhead，在1,680个CPU核心上运行Up to 100,000个任务。
</details></li>
</ul>
<hr>
<h2 id="DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering"><a href="#DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering" class="headerlink" title="DealMVC: Dual Contrastive Calibration for Multi-view Clustering"></a>DealMVC: Dual Contrastive Calibration for Multi-view Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09000">http://arxiv.org/abs/2308.09000</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/dealmvc">https://github.com/xihongyang1999/dealmvc</a></li>
<li>paper_authors: Xihong Yang, Jiaqi Jin, Siwei Wang, Ke Liang, Yue Liu, Yi Wen, Suyuan Liu, Sihang Zhou, Xinwang Liu, En Zhu</li>
<li>for: 解决多视图 clustering 中同样 pero different samples 的问题，提高 clustering 性能。</li>
<li>methods: 提出了一种 dual contrastive calibration network (DealMVC)，包括 global contrastive calibration loss 和 local contrastive calibration loss，以及 feature structure 的 regularization。</li>
<li>results: 与其他 state-of-the-art 方法进行比较，实验结果表明 DealMVC 的效果和优势较高，可以提高 clustering 性能。<details>
<summary>Abstract</summary>
Benefiting from the strong view-consistent information mining capacity, multi-view contrastive clustering has attracted plenty of attention in recent years. However, we observe the following drawback, which limits the clustering performance from further improvement. The existing multi-view models mainly focus on the consistency of the same samples in different views while ignoring the circumstance of similar but different samples in cross-view scenarios. To solve this problem, we propose a novel Dual contrastive calibration network for Multi-View Clustering (DealMVC). Specifically, we first design a fusion mechanism to obtain a global cross-view feature. Then, a global contrastive calibration loss is proposed by aligning the view feature similarity graph and the high-confidence pseudo-label graph. Moreover, to utilize the diversity of multi-view information, we propose a local contrastive calibration loss to constrain the consistency of pair-wise view features. The feature structure is regularized by reliable class information, thus guaranteeing similar samples have similar features in different views. During the training procedure, the interacted cross-view feature is jointly optimized at both local and global levels. In comparison with other state-of-the-art approaches, the comprehensive experimental results obtained from eight benchmark datasets provide substantial validation of the effectiveness and superiority of our algorithm. We release the code of DealMVC at https://github.com/xihongyang1999/DealMVC on GitHub.
</details>
<details>
<summary>摘要</summary>
利用强大的视图一致信息挖掘能力，多视图对比 clustering 在最近几年内吸引了大量的注意力。然而，我们发现现有的多视图模型主要关注不同视图中的同样样本之间的一致性，而忽略了不同视图中的相似 yet 不同样本之间的关系。为解决这个问题，我们提出了一种新的 dual contrastive calibration network for Multi-View Clustering（DealMVC）。具体来说，我们首先设计了一种 fusions 机制，以获得全局跨视图特征。然后，我们提出了一种全局对比准备损失，通过对视图特征相似图和高置信度假标签图进行对比，使得相似的样本在不同视图中具有相似的特征。此外，为了利用多视图信息的多样性，我们提出了一种本地对比准备损失，以强制不同视图中的对应样本之间的一致性。特征结构被可靠的类信息规范化，以保证不同视图中的相似样本具有相似的特征。在训练过程中，交互的跨视图特征被在本地和全局两级进行优化。与其他状态 искус法比较，我们从八个标准 benchmark 数据集获得了广泛的实验结果，这些结果证明了我们的算法的有效性和优越性。我们在 GitHub 上发布了 DealMVC 的代码，请参考 <https://github.com/xihongyang1999/DealMVC>。
</details></li>
</ul>
<hr>
<h2 id="Reinforced-Self-Training-ReST-for-Language-Modeling"><a href="#Reinforced-Self-Training-ReST-for-Language-Modeling" class="headerlink" title="Reinforced Self-Training (ReST) for Language Modeling"></a>Reinforced Self-Training (ReST) for Language Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08998">http://arxiv.org/abs/2308.08998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas</li>
<li>for: 提高大语言模型的输出质量（machine translation）</li>
<li>methods: 使用激励自学习（Reinforced Self-Training，ReST）算法，通过在初始语言模型策略基础上生成样本，然后使用离线激励学习算法进行改进</li>
<li>results: substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.
</details>
<details>
<summary>摘要</summary>
人工反馈学习（RLHF）可以提高大语言模型（LLM）的输出质量，通过将其与人类喜好进行对齐。我们提出了一种简单的算法，即增强自我训练（ReST），以提高 LLM 政策。给定初始 LLM 策略，ReST 会生成一个样本集，然后使用在线 RL 算法来改善 LLM 策略。相比于 typical online RLHF 方法，ReST 更加高效，因为它可以在线下进行训练，从而实现数据重用。虽然 ReST 是一种通用的措施，但我们在机器翻译中进行了应用。我们的结果显示，ReST 可以在计算和样本效率下提高翻译质量，并且通过人类评估得到证明。
</details></li>
</ul>
<hr>
<h2 id="Learning-representations-by-forward-propagating-errors"><a href="#Learning-representations-by-forward-propagating-errors" class="headerlink" title="Learning representations by forward-propagating errors"></a>Learning representations by forward-propagating errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09728">http://arxiv.org/abs/2308.09728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryoungwoo Jang</li>
<li>for: 这个论文目的是提出一种轻量级、快速的学习算法，用于在中央处理单元（CPU）上优化神经网络。</li>
<li>methods: 这种算法基于前向传播方法，使用了代数几何中的双数概念。</li>
<li>results: 该算法比 tradicional back-propagation（BP）算法更快速，可以在CPU上进行神经网络优化。<details>
<summary>Abstract</summary>
Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry." into Simplified Chinese.翻译文本为Simplified Chinese：Back-propagation（BP）是广泛使用的神经网络优化算法。然而，BP需要巨大的计算成本，并且在中央处理单元（CPU）中训练太慢。因此，当前的神经网络优化通常在图形处理单元（GPU）上使用compute unified device architecture（CUDA）编程进行。在这篇论文中，我们提出了一种轻量级、快速的学习算法，在CPU上实现，与GPU上CUDA加速相同快速。这种算法基于前向传播方法，利用了代数几何中的双数概念。
</details></li>
</ul>
<hr>
<h2 id="Neural-oscillators-for-generalization-of-physics-informed-machine-learning"><a href="#Neural-oscillators-for-generalization-of-physics-informed-machine-learning" class="headerlink" title="Neural oscillators for generalization of physics-informed machine learning"></a>Neural oscillators for generalization of physics-informed machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08989">http://arxiv.org/abs/2308.08989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Kapoor, Abhishek Chandra, Daniel M. Tartakovsky, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet</li>
<li>for: 提高物理学 Informed 机器学习（PIML）的泛化能力，特别是在面临复杂物理问题时。</li>
<li>methods: 利用 PDE 解的内在 causality 和时间序列特征，将 PIML 模型与回归神经网络结合，基于系数 ordinary differential equations 的神经抗 oscilators。</li>
<li>results: 通过有效地捕捉长时间依赖和缓解扩散和消失Gradient问题，神经抗 oscilators 提高 PIML 模型的泛化能力，在时间依赖非线性 PDE 和 biharmonic beam 方程上进行了广泛的实验，并证明了该方法的有效性。<details>
<summary>Abstract</summary>
A primary challenge of physics-informed machine learning (PIML) is its generalization beyond the training domain, especially when dealing with complex physical problems represented by partial differential equations (PDEs). This paper aims to enhance the generalization capabilities of PIML, facilitating practical, real-world applications where accurate predictions in unexplored regions are crucial. We leverage the inherent causality and temporal sequential characteristics of PDE solutions to fuse PIML models with recurrent neural architectures based on systems of ordinary differential equations, referred to as neural oscillators. Through effectively capturing long-time dependencies and mitigating the exploding and vanishing gradient problem, neural oscillators foster improved generalization in PIML tasks. Extensive experimentation involving time-dependent nonlinear PDEs and biharmonic beam equations demonstrates the efficacy of the proposed approach. Incorporating neural oscillators outperforms existing state-of-the-art methods on benchmark problems across various metrics. Consequently, the proposed method improves the generalization capabilities of PIML, providing accurate solutions for extrapolation and prediction beyond the training data.
</details>
<details>
<summary>摘要</summary>
physics-informed machine learning (PIML) 的主要挑战之一是其泛化性，特别是在处理复杂的物理问题时。这篇论文的目的是增强 PIML 的泛化能力，以便在实际应用中做出准确的预测，特别是在训练数据外的未探索区域。我们利用 PDE 解的内在 causality 和时间序列特征来融合 PIML 模型和回归神经网络，称为神经振荡器。通过有效地捕捉长期依赖关系和 Mitigate 爆炸和消失梯度问题，神经振荡器 提高了 PIML 任务中的泛化能力。经过大量的实验，我们发现在时间不断改变的非线性 PDE 和二次杠杆方程中，包含神经振荡器 的方法可以更高效地解决问题，并且在不同的 метриках上都超过了现有的状态ünstler 方法。因此，我们的方法可以提高 PIML 的泛化能力，为 extrapolation 和预测 beyond 训练数据提供准确的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-the-biomimicry-gap-in-biohybrid-systems"><a href="#Quantifying-the-biomimicry-gap-in-biohybrid-systems" class="headerlink" title="Quantifying the biomimicry gap in biohybrid systems"></a>Quantifying the biomimicry gap in biohybrid systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08978">http://arxiv.org/abs/2308.08978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vaios Papaspyros, Guy Theraulaz, Clément Sire, Francesco Mondada<br>for: 这个论文的目的是用生物hybrid系统来探索和识别动物群体行为的机制。methods: 这篇论文使用了生物寄生的鱼类模型和神经网络模型来生成生物寄生的社交互动。results: 这篇论文通过实验和模拟来证明，使用生物寄生的鱼类模型和神经网络模型可以生成高精度的社交互动，与真实的鱼类群体行为高度相似。<details>
<summary>Abstract</summary>
Biohybrid systems in which robotic lures interact with animals have become compelling tools for probing and identifying the mechanisms underlying collective animal behavior. One key challenge lies in the transfer of social interaction models from simulations to reality, using robotics to validate the modeling hypotheses. This challenge arises in bridging what we term the "biomimicry gap", which is caused by imperfect robotic replicas, communication cues and physics constrains not incorporated in the simulations that may elicit unrealistic behavioral responses in animals. In this work, we used a biomimetic lure of a rummy-nose tetra fish (Hemigrammus rhodostomus) and a neural network (NN) model for generating biomimetic social interactions. Through experiments with a biohybrid pair comprising a fish and the robotic lure, a pair of real fish, and simulations of pairs of fish, we demonstrate that our biohybrid system generates high-fidelity social interactions mirroring those of genuine fish pairs. Our analyses highlight that: 1) the lure and NN maintain minimal deviation in real-world interactions compared to simulations and fish-only experiments, 2) our NN controls the robot efficiently in real-time, and 3) a comprehensive validation is crucial to bridge the biomimicry gap, ensuring realistic biohybrid systems.
</details>
<details>
<summary>摘要</summary>
生物融合系统，在其中机器人饵料与动物互动，已成为诱导和识别集体动物行为的有力工具。一个关键挑战在于将社交互动模型从 simulations 转移到实际情况，使用机器人来验证模型假设。这个挑战 arise 由我们称为 "生物模仿差距"，这是因为机器人的复制不准确、通信提示和物理约束不包括在 simulations 中，可能会诱导动物的不实际行为响应。在这项工作中，我们使用了一个生物模仿的鲤鱼鱼饵（Hemigrammus rhodostomus）和一个神经网络（NN）模型来生成生物模仿社交互动。通过实验中的生物融合对，一个鱼和机器人饵料对，一对真正的鱼对和 simulations 中的鱼对，我们示出了我们的生物融合系统可以生成高准确性的社交互动，与真正的鱼对相似。我们的分析表明：1）饵料和 NN 在实际情况中具有最小偏差，与 simulations 和鱼只实验相比; 2）我们的 NN 在实时控制机器人; 3）全面验证是必要的，以bridging "生物模仿差距"，确保生物融合系统的真实性。
</details></li>
</ul>
<hr>
<h2 id="Hitting-the-High-Dimensional-Notes-An-ODE-for-SGD-learning-dynamics-on-GLMs-and-multi-index-models"><a href="#Hitting-the-High-Dimensional-Notes-An-ODE-for-SGD-learning-dynamics-on-GLMs-and-multi-index-models" class="headerlink" title="Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models"></a>Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08977">http://arxiv.org/abs/2308.08977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizabeth Collins-Woodfin, Courtney Paquette, Elliot Paquette, Inbar Seroussi</li>
<li>for: 这 paper 是研究 streaming stochastic gradient descent (SGD) 在高维限制下的动态特性，具体来说是在通用线性模型和多指量模型（例如Logistic regression、phase retrieval）中应用 SGD，并研究其在大数据量下的性能。</li>
<li>methods: 这 paper 使用了一种系统Ordinary differential equations来描述 SGD 的动态行为，这种方法可以涵盖许多统计量，如风险和优化度量。此外，paper 还引入了一种简化的卷积 coefficient的 SDE（homogenized SGD），以便分析 SGD 迭代器的动态行为。</li>
<li>results: 这 paper 的结果表明，当模型参数个数与数据量成正比时，SGD 可以被视为一种确定性的方法，其可以提供风险和优化度量的确定性 guarantees。此外，paper 还提供了一些标准示例的数据分析，并与理论结果相符。<details>
<summary>Abstract</summary>
We analyze the dynamics of streaming stochastic gradient descent (SGD) in the high-dimensional limit when applied to generalized linear models and multi-index models (e.g. logistic regression, phase retrieval) with general data-covariance. In particular, we demonstrate a deterministic equivalent of SGD in the form of a system of ordinary differential equations that describes a wide class of statistics, such as the risk and other measures of sub-optimality. This equivalence holds with overwhelming probability when the model parameter count grows proportionally to the number of data. This framework allows us to obtain learning rate thresholds for stability of SGD as well as convergence guarantees. In addition to the deterministic equivalent, we introduce an SDE with a simplified diffusion coefficient (homogenized SGD) which allows us to analyze the dynamics of general statistics of SGD iterates. Finally, we illustrate this theory on some standard examples and show numerical simulations which give an excellent match to the theory.
</details>
<details>
<summary>摘要</summary>
我们分析流动式随机Gradient Descent（SGD）在高维限制下的动态行为，尤其是在泛化线性模型和多指标模型（例如逻辑回归、相位恢复）中。我们展示了一个确定的SGD等价项，它描述了一个广泛的统计量，例如风险和其他不足之数据。这个等价项在资料数量增加时，对数据的尺度成长时，具有极高的概率。这个框架允许我们获得SGD的学习率阈值以及稳定性的保证。此外，我们引入了一个简化的扩散系数（殷合SGD），它允许我们分析SGD迭代的一般统计。最后，我们在一些标准的例子中详细介绍了这个理论，并提供了一些实际的实验结果，与理论内容匹配得极佳。
</details></li>
</ul>
<hr>
<h2 id="Cross-city-Few-Shot-Traffic-Forecasting-via-Traffic-Pattern-Bank"><a href="#Cross-city-Few-Shot-Traffic-Forecasting-via-Traffic-Pattern-Bank" class="headerlink" title="Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank"></a>Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09727">http://arxiv.org/abs/2308.09727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhyliu00/tpb">https://github.com/zhyliu00/tpb</a></li>
<li>paper_authors: Zhanyu Liu, Guanjie Zheng, Yanwei Yu</li>
<li>for: 提高智能交通系统中的交通预测精度，尤其是在数据穷市场地区。</li>
<li>methods: 利用交通模式银行（TPB），通过预训练的交通补充编码器将数据丰富城市的交通数据 proyect到高维空间，然后根据协调分区生成交通模式银行。</li>
<li>results: 在实际交通数据集上进行实验，表明TPB在cross-city几个shot交通预测中表现出色，超越现有方法，证明我们的方法在数据穷市场地区的交通预测中具有效果。<details>
<summary>Abstract</summary>
Traffic forecasting is a critical service in Intelligent Transportation Systems (ITS). Utilizing deep models to tackle this task relies heavily on data from traffic sensors or vehicle devices, while some cities might lack device support and thus have few available data. So, it is necessary to learn from data-rich cities and transfer the knowledge to data-scarce cities in order to improve the performance of traffic forecasting. To address this problem, we propose a cross-city few-shot traffic forecasting framework via Traffic Pattern Bank (TPB) due to that the traffic patterns are similar across cities. TPB utilizes a pre-trained traffic patch encoder to project raw traffic data from data-rich cities into high-dimensional space, from which a traffic pattern bank is generated through clustering. Then, the traffic data of the data-scarce city could query the traffic pattern bank and explicit relations between them are constructed. The metaknowledge is aggregated based on these relations and an adjacency matrix is constructed to guide a downstream spatial-temporal model in forecasting future traffic. The frequently used meta-training framework Reptile is adapted to find a better initial parameter for the learnable modules. Experiments on real-world traffic datasets show that TPB outperforms existing methods and demonstrates the effectiveness of our approach in cross-city few-shot traffic forecasting.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统（ITS）中的关键服务。使用深度模型来解决这个任务需要依赖于交通感知器或车辆设备上的数据，而一些城市可能缺乏设备支持，因此有限的数据。因此，我们需要从数据丰富的城市学习并传递知识到数据缺乏的城市，以改善交通预测性能。为解决这个问题，我们提出了跨城市几拟交通预测框架via Traffic Pattern Bank（TPB）。TPB利用预训练的交通补充器来将数据丰富城市的 raw 交通数据 proyect到高维空间中，从而生成交通模式银行。然后，数据缺乏城市的交通数据可以在交通模式银行中查询，并构建了明确的交通模式之间的关系。这些关系的总体知识被聚合，并构建了一个导航下游空间时间模型的优化矩阵。我们采用了现有的meta-training框架Reptile来找到更好的初始参数。实验表明，TPB比现有方法更高效，并证明了我们的方法在跨城市几拟交通预测中的效果。
</details></li>
</ul>
<hr>
<h2 id="CONVERT-Contrastive-Graph-Clustering-with-Reliable-Augmentation"><a href="#CONVERT-Contrastive-Graph-Clustering-with-Reliable-Augmentation" class="headerlink" title="CONVERT:Contrastive Graph Clustering with Reliable Augmentation"></a>CONVERT:Contrastive Graph Clustering with Reliable Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08963">http://arxiv.org/abs/2308.08963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/convert">https://github.com/xihongyang1999/convert</a></li>
<li>paper_authors: Xihong Yang, Cheng Tan, Yue Liu, Ke Liang, Siwei Wang, Sihang Zhou, Jun Xia, Stan Z. Li, Xinwang Liu, En Zhu</li>
<li>for: 提高不监督图像学习中的图像自动生成技术的可靠性和效果。</li>
<li>methods: 提出了一种名为COVERT的新网络模型，该模型通过一种叫做征识扰动恢复网络的方式，对数据生成器进行了可靠性提高和semantic信息捕捉。此外，还提出了一种新的semantic损失函数，用于约束网络的学习。</li>
<li>results: 经过广泛的实验研究，该方法在七个数据集上得到了极高的效果，超过了现有的方法。code和补充文件也在github上公开发布。<details>
<summary>Abstract</summary>
Contrastive graph node clustering via learnable data augmentation is a hot research spot in the field of unsupervised graph learning. The existing methods learn the sampling distribution of a pre-defined augmentation to generate data-driven augmentations automatically. Although promising clustering performance has been achieved, we observe that these strategies still rely on pre-defined augmentations, the semantics of the augmented graph can easily drift. The reliability of the augmented view semantics for contrastive learning can not be guaranteed, thus limiting the model performance. To address these problems, we propose a novel CONtrastiVe Graph ClustEring network with Reliable AugmenTation (COVERT). Specifically, in our method, the data augmentations are processed by the proposed reversible perturb-recover network. It distills reliable semantic information by recovering the perturbed latent embeddings. Moreover, to further guarantee the reliability of semantics, a novel semantic loss is presented to constrain the network via quantifying the perturbation and recovery. Lastly, a label-matching mechanism is designed to guide the model by clustering information through aligning the semantic labels and the selected high-confidence clustering pseudo labels. Extensive experimental results on seven datasets demonstrate the effectiveness of the proposed method. We release the code and appendix of CONVERT at https://github.com/xihongyang1999/CONVERT on GitHub.
</details>
<details>
<summary>摘要</summary>
“对照性图节点聚合via学习数据增强是现场无监督图学中的热点研究领域。现有方法通过自动生成数据驱动增强来学习增强分布。虽然这些策略已经实现了有前途的聚合性能，但我们发现这些策略仍然依赖于预定的增强，即使在增强后，图的 semantics 容易偏移。因此，我们提出了一种名为 CONtrastiVe Graph ClustEring network with Reliable AugmenTation（COVERT）的新方法。具体来说，我们的方法通过我们提出的可逆压抽网络进行数据增强。这个网络可以通过压抽并重建原始 embedding 来提取可靠的semantic信息。此外，为了进一步保证 semantics 的可靠性，我们提出了一种新的semantic损失函数，该函数通过量化压抽和重建来约束网络。最后，我们设计了一种标签匹配机制，通过对semantic标签和选择高置信聚合 Pseudolabels 进行对应，以导引模型。我们的实验结果表明，我们的方法能够有效地进行图聚合。我们在 GitHub 上发布了代码和补充材料，详细的实验结果和方法详细介绍可以参考我们的 GitHub 上的文章。”
</details></li>
</ul>
<hr>
<h2 id="Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health"><a href="#Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health" class="headerlink" title="Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health"></a>Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09726">http://arxiv.org/abs/2308.09726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/socialgood">https://github.com/google-research/socialgood</a></li>
<li>paper_authors: Jackson A. Killian, Manish Jain, Yugang Jia, Jonathan Amar, Erich Huang, Milind Tambe</li>
<li>for: 这篇论文旨在研究多重臂摆（RMAB）的公平目标（ERMAB），以提高决策的公平性和健康等级。</li>
<li>methods: 这篇论文使用了两种公平目标，即最小最大奖励和最大奈雪威夷。它们分别使用了一种灌水算法和一种理论上 inspirited 的落叶算法来实现。</li>
<li>results: 研究在三个模拟领域中，包括一个新的数字医疗模型，发现了其方法可以比现有技术多少 times 更公平，而无需损害效用。这些结果认可了这种研究的urgency，因为RMAB在人类和野生动物的结果中广泛应用。<details>
<summary>Abstract</summary>
Restless multi-armed bandits (RMABs) are a popular framework for algorithmic decision making in sequential settings with limited resources. RMABs are increasingly being used for sensitive decisions such as in public health, treatment scheduling, anti-poaching, and -- the motivation for this work -- digital health. For such high stakes settings, decisions must both improve outcomes and prevent disparities between groups (e.g., ensure health equity). We study equitable objectives for RMABs (ERMABs) for the first time. We consider two equity-aligned objectives from the fairness literature, minimax reward and max Nash welfare. We develop efficient algorithms for solving each -- a water filling algorithm for the former, and a greedy algorithm with theoretically motivated nuance to balance disparate group sizes for the latter. Finally, we demonstrate across three simulation domains, including a new digital health model, that our approaches can be multiple times more equitable than the current state of the art without drastic sacrifices to utility. Our findings underscore our work's urgency as RMABs permeate into systems that impact human and wildlife outcomes. Code is available at https://github.com/google-research/socialgood/tree/equitable-rmab
</details>
<details>
<summary>摘要</summary>
众臂猎手（RMAB）是一种流行的算法决策框架，广泛应用于顺序设置中的有限资源管理。众臂猎手在公共卫生、治疗安排、反贪杀和数字医疗等高规模场景中得到应用，决策必须同时提高结果和避免群体之间的差距（如保障健康公平）。我们研究了众臂猎手的公平目标（ERMAB），并考虑了两种与公平相关的目标，即最小最大奖励和最大 NASH 利益。我们开发了高效的算法来解决每一个目标，包括水填算法和基于理论的柔和策略来平衡不同群体大小的算法。最后，我们在三个 simulations 频道中，包括一个新的数字医疗模型，证明了我们的方法可以在无损Utility 的情况下多达多少倍提高公平性。我们的发现强调了我们的工作的急迫性，因为众臂猎手在影响人类和野生动物的系统中普遍应用。代码可以在 <https://github.com/google-research/socialgood/tree/equitable-rmab> 中获取。
</details></li>
</ul>
<hr>
<h2 id="A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods"><a href="#A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods" class="headerlink" title="A Dual-Perspective Approach to Evaluating Feature Attribution Methods"></a>A Dual-Perspective Approach to Evaluating Feature Attribution Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08949">http://arxiv.org/abs/2308.08949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yawei Li, Yang Zhang, Kenji Kawaguchi, Ashkan Khakzar, Bernd Bischl, Mina Rezaei</li>
<li>for: 本研究旨在提供一个新的评估feature attribution方法的框架，以及两种新的评估视角，即实用性（soundness）和完整性（completeness）。</li>
<li>methods: 本研究使用了现有的feature attribution方法，并提出了两种新的评估方法，即实用性评估和完整性评估。这两种方法都基于固定的数学基础，并可以通过高效的算法来计算。</li>
<li>results: 本研究通过应用这两种新的评估方法，对主流的feature attribution方法进行了评估。结果表明，这两种方法可以提供一个新的视角来分析和比较feature attribution方法的效果。<details>
<summary>Abstract</summary>
Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods."into Simplified Chinese.Feature 归属方法 attempt to explain neural network 预测结果 by identifying relevant features. However, establishing a cohesive framework for assessing feature 归属 remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level"><a href="#Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level" class="headerlink" title="Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level"></a>Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08948">http://arxiv.org/abs/2308.08948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Pathak, Miro Miranda, Francisco Mena, Cristhian Sanchez, Patrick Helber, Benjamin Bischke, Peter Habelitz, Hiba Najjar, Jayanth Siddamsetty, Diego Arenas, Michaela Vollmer, Marcela Charfuelan, Marlon Nuske, Andreas Dengel</li>
<li>for: 这个论文是为了预测农业产量而写的。</li>
<li>methods: 这个论文使用了一种简单 yet effective的早期融合方法，该方法可以处理多种输入模式，并且可以在不同的时间和空间分辨率下工作。</li>
<li>results: 这个论文使用了高分辨率农业产量地图作为真实数据来训练农作物和机器学习模型，并且使用了全球覆盖的卫星图像作为主要输入数据，以及其他补充的模式，如天气、土壤和地形数据。<details>
<summary>Abstract</summary>
We introduce a simple yet effective early fusion method for crop yield prediction that handles multiple input modalities with different temporal and spatial resolutions. We use high-resolution crop yield maps as ground truth data to train crop and machine learning model agnostic methods at the sub-field level. We use Sentinel-2 satellite imagery as the primary modality for input data with other complementary modalities, including weather, soil, and DEM data. The proposed method uses input modalities available with global coverage, making the framework globally scalable. We explicitly highlight the importance of input modalities for crop yield prediction and emphasize that the best-performing combination of input modalities depends on region, crop, and chosen model.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种简单 yet 有效的早期融合方法 для农作物收成预测，该方法可以处理多种输入模式，每种模式具有不同的时空分解能力。我们使用高分辨率农作物收成地图作为真实数据来训练农作物和机器学习模型无关的方法。我们使用卫星影像作为主要输入数据，其他补充数据包括天气、土壤和地形数据。我们的方法使用全球覆盖的输入数据，因此该框架可以在全球范围内扩展。我们显式强调输入数据对农作物收成预测的重要性，并且指出在不同的区域、作物和选择的模型中，最佳的输入数据组合会有所不同。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Graph-Neural-Networks-for-Tabular-Data"><a href="#Interpretable-Graph-Neural-Networks-for-Tabular-Data" class="headerlink" title="Interpretable Graph Neural Networks for Tabular Data"></a>Interpretable Graph Neural Networks for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08945">http://arxiv.org/abs/2308.08945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amr Alkhatib, Sofiane Ennadir, Henrik Boström, Michalis Vazirgiannis</li>
<li>for: 这种论文是为了处理实际应用中频繁出现的表格数据而设计的，使用图 neural network 扩展来捕捉特征间的交互。</li>
<li>methods: 这种方法使用了一种名为 IGNNet 的解释性图 neural network，它通过限制学习算法来生成可解释的模型，从原始输入特征直接计算出预测结果的确切计算方式。</li>
<li>results: 实验表明，IGNNet 与现状的机器学习算法相比，能够在处理表格数据方面达到相同的性能水平，同时可以提供可解释的模型，其预测结果与特征 SHAPley 值相对aligned，而无需额外的计算开销。<details>
<summary>Abstract</summary>
Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true Shapley values of the features without incurring any additional computational overhead.
</details>
<details>
<summary>摘要</summary>
<SYS>将数据表示为表格 Format 是实际应用中的常见现象。Graph Neural Networks (GNNs) 最近已经扩展到可以有效处理这类数据，以捕捉特征之间的交互。然而，这些方法基本上生成黑盒模型，即深度神经网络，使用户无法跟踪模型预测的逻辑。我们提出了一种方法，called IGNNet (Interpretable Graph Neural Network for tabular data), 它强制学习算法生成可解释性模型，其中模型可以从原始输入特征直接计算预测。我们对大规模的实验进行了报告，显示IGNNet 与目标 tabular 数据的状态机器学习算法，包括 XGBoost、Random Forests 和 TabNet 相比，表现准确。同时，结果表明IGNNet 获得的解释与特征的真正 Shapley 值相对应，而无需增加计算开销。</SYS>Note: "Shapley value" refers to a concept in cooperative game theory that assigns a value to each player in a cooperative game, based on their contribution to the grand coalition. In the context of the text, it refers to the contribution of each feature to the prediction made by the model.
</details></li>
</ul>
<hr>
<h2 id="Causal-Adversarial-Perturbations-for-Individual-Fairness-and-Robustness-in-Heterogeneous-Data-Spaces"><a href="#Causal-Adversarial-Perturbations-for-Individual-Fairness-and-Robustness-in-Heterogeneous-Data-Spaces" class="headerlink" title="Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces"></a>Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08938">http://arxiv.org/abs/2308.08938</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Ehyaei/CAPIFY">https://github.com/Ehyaei/CAPIFY</a></li>
<li>paper_authors: Ahmad-Reza Ehyaei, Kiarash Mohammadi, Amir-Hossein Karimi, Samira Samadi, Golnoosh Farnadi</li>
<li>for: 本研究旨在探讨个人公平、鲁棒性和结构 causal 模型在不同数据空间中同时探索和 интегразиOINT 这些性能。</li>
<li>methods: 我们提出了一种新的方法，通过使用 causal 结构模型和敏感特征来创建一个公平度量，并应用它来度量个体之间的 semantic 相似性。我们还引入了一种新的 causal  adversarial 干扰和 adversarial 训练，以创建一个新的 regularizer，这个 regularizer 同时包含了个体公平、鲁棒性和 causal 意识。</li>
<li>results: 我们在实际世界和 sintetic 数据集上评估了我们的方法，并证明了它可以构建一个准确的分类器，同时满足个体公平、鲁棒性和 causal 意识的要求。<details>
<summary>Abstract</summary>
As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness.
</details>
<details>
<summary>摘要</summary>
As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness.Here's the translation in Traditional Chinese:随着责任AI在机器学习算法中的重要性增加，属于不同类型的特性，如公平、敏感性、因果关系等，在最近的几年中已经获得了很大的关注。然而，这些个别的特性之间仍然存在着重要的欠缺，即同时探索和结合这些特性的方法。在这篇文章中，我们提出了一个新的方法，它探索了个人公平、敏感性和结构因果模型在不同数据空间中的关系，特别是在处理数据中的数据敏感特征时。我们使用因果结构模型和数据敏感特征来建立公平度量，并将其应用到测量个体之间的semantic相似性。通过引入新的因果敌对推差和敌对训练，我们创建了一个新的正规化器，它结合个人公平、因果和敏感性在分类器中的作用。我们的方法在真实世界和 sintetic数据集上进行评估，展示了它在精准分类器同时具备公平、敏感性和因果意识的能力。
</details></li>
</ul>
<hr>
<h2 id="Estimating-fire-Duration-using-regression-methods"><a href="#Estimating-fire-Duration-using-regression-methods" class="headerlink" title="Estimating fire Duration using regression methods"></a>Estimating fire Duration using regression methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08936">http://arxiv.org/abs/2308.08936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hansong Xiao</li>
<li>for: 这篇论文的目的是提出一种基于机器学习的野火预测方法，以解决传统的网格式数学模型所带来的计算成本和时间消耗问题。</li>
<li>methods: 该论文使用了Random Forest、KNN和XGBoost回归模型，以及图像基于的CNN和Encoder模型，来预测已知的野火燃烧时间。模型的输入是通过卫星提供的地形特征地图和相应的历史火灾数据。模型在被训练后，通过处理输入数据以获得最佳结果，能够快速和相对准确地预测未来的野火图像。</li>
<li>results: 论文的实验结果表明，机器学习基于的野火预测方法可以快速和准确地预测野火燃烧时间，并且可以减少计算成本和时间消耗。<details>
<summary>Abstract</summary>
Wildfire forecasting problems usually rely on complex grid-based mathematical models, mostly involving Computational fluid dynamics(CFD) and Celluar Automata, but these methods have always been computationally expensive and difficult to deliver a fast decision pattern. In this paper, we provide machine learning based approaches that solve the problem of high computational effort and time consumption. This paper predicts the burning duration of a known wildfire by RF(random forest), KNN, and XGBoost regression models and also image-based, like CNN and Encoder. Model inputs are based on the map of landscape features provided by satellites and the corresponding historical fire data in this area. This model is trained by happened fire data and landform feature maps and tested with the most recent real value in the same area. By processing the input differently to obtain the optimal outcome, the system is able to make fast and relatively accurate future predictions based on landscape images of known fires.
</details>
<details>
<summary>摘要</summary>
通常情况下，野火预测问题都会采用复杂的网格式数学模型，主要包括计算流体动力学(CFD)和细胞自动机，但这些方法总是 computationally expensive 并且困难呈现快速决策模式。在这篇论文中，我们提供了基于机器学习的方法来解决高计算成本和时间消耗的问题。本文预测已知野火燃烧的时间长度，使用Random Forest、KNN和XGBoost回归模型，以及图像基于的方法，如CNN和Encoder。模型输入基于通过卫星提供的地形特征图和相应的历史火灾数据。这个模型通过已发生火灾数据和地形特征图进行训练，并在同一地区测试最新的实际值。通过不同的处理方式来获得最佳结果，系统可以根据地形图像来快速和相对准确地预测未来的野火。
</details></li>
</ul>
<hr>
<h2 id="On-Data-Imbalance-in-Molecular-Property-Prediction-with-Pre-training"><a href="#On-Data-Imbalance-in-Molecular-Property-Prediction-with-Pre-training" class="headerlink" title="On Data Imbalance in Molecular Property Prediction with Pre-training"></a>On Data Imbalance in Molecular Property Prediction with Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08934">http://arxiv.org/abs/2308.08934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Limin Wang, Masatoshi Hanai, Toyotaro Suzumura, Shun Takashige, Kenjiro Taura</li>
<li>for: 本研究旨在提高分子性质预测模型的准确性，通过修改现有的代表性预训练方法（node masking）的损失函数，以补偿输入数据的不均衡。</li>
<li>methods: 本研究使用了一种组合方法，包括理论计算和机器学习，其中理论计算用于确定分子性质，而机器学习用于构建一个可以应用于剩下的材料的模型。此外，本研究还使用了预训练技术，包括node masking，以提高机器学习模型的准确性。</li>
<li>results: 本研究通过实验和评估使用了benchmark模型，发现修改损失函数可以提高预测结果的准确性，并且可以补偿输入数据的不均衡。<details>
<summary>Abstract</summary>
Revealing and analyzing the various properties of materials is an essential and critical issue in the development of materials, including batteries, semiconductors, catalysts, and pharmaceuticals. Traditionally, these properties have been determined through theoretical calculations and simulations. However, it is not practical to perform such calculations on every single candidate material. Recently, a combination method of the theoretical calculation and machine learning has emerged, that involves training machine learning models on a subset of theoretical calculation results to construct a surrogate model that can be applied to the remaining materials. On the other hand, a technique called pre-training is used to improve the accuracy of machine learning models. Pre-training involves training the model on pretext task, which is different from the target task, before training the model on the target task. This process aims to extract the input data features, stabilizing the learning process and improving its accuracy. However, in the case of molecular property prediction, there is a strong imbalance in the distribution of input data and features, which may lead to biased learning towards frequently occurring data during pre-training. In this study, we propose an effective pre-training method that addresses the imbalance in input data. We aim to improve the final accuracy by modifying the loss function of the existing representative pre-training method, node masking, to compensate the imbalance. We have investigated and assessed the impact of our proposed imbalance compensation on pre-training and the final prediction accuracy through experiments and evaluations using benchmark of molecular property prediction models.
</details>
<details>
<summary>摘要</summary>
描述和分析材料的不同性质是物料发展中的关键和重要问题，包括电池、半导体、催化剂和药物。在过去，这些性质通常通过理论计算和模拟来确定。但是，对每种候选材料进行这些计算是不实际的。最近，一种结合理论计算和机器学习的方法得到了应用，即通过训练机器学习模型在一个子集理论计算结果上构建一个代理模型，以应用于剩下的材料。而在机器学习模型训练中，一种称为预训练的技术得到了应用，即在预测任务上训练模型，然后在目标任务上训练模型。这个过程的目的是提取输入数据特征，稳定学习过程，提高准确性。但在分子性质预测中，输入数据和特征之间存在强烈的不均衡，这可能导致在预训练过程中偏向频繁出现的数据进行偏激学习。在本研究中，我们提出了一种有效地弥合输入数据不均衡的预训练方法。我们希望通过修改现有代表预训练方法的损失函数，以补偿不均衡。我们通过实验和评估使用分子性质预测模型的标准套件进行了研究和评估。
</details></li>
</ul>
<hr>
<h2 id="IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making"><a href="#IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making" class="headerlink" title="IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making"></a>IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08918">http://arxiv.org/abs/2308.08918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Niu, Siyuan Li, Jiahao Zheng, Zhouchi Lin, Jian Li, Jian Guo, Bo An</li>
<li>For: 这篇论文旨在提出一种基于强化学习的多价格水平市场制作者（Imitative Market Maker，IMM）方法，以提高市场流动性和订单处理效率。* Methods: 该方法基于一种新的状态和动作表示方法，可以快速和高效地学习多价格水平市场制作者的策略。它还 integrate了一种表示学习单元，可以捕捉市场趋势的短期和长期变化，从而降低风险。* Results: 实验结果表明，IMM方法在四个实际市场数据集上比现有的RL基于市场制作者策略具有较高的财务效益和处理效率。减少策略的风险也得到了证明。<details>
<summary>Abstract</summary>
Market making (MM) has attracted significant attention in financial trading owing to its essential function in ensuring market liquidity. With strong capabilities in sequential decision-making, Reinforcement Learning (RL) technology has achieved remarkable success in quantitative trading. Nonetheless, most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. Strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level strategies involves a comprehensive trading action space, the challenge of effectively training profitable RL agents for MM persists. Inspired by the efficient workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework start with introducing effective state and action representations adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.
</details>
<details>
<summary>摘要</summary>
市场制作（MM）在金融交易中吸引了广泛的注意力，因为它对市场流动性的稳定性具有关键作用。RL技术在数学交易中取得了显著的成功，但大多数现有RL基于MM方法都是优化单价级别策略，这会导致频繁的订单取消和排队优先权失去。使用多个价格级别的策略更好地适应实际交易场景。然而，由于多个价格级别的策略的复杂性，训练可财富RL代理人是一项挑战。 Drawing inspiration from professional human market makers' efficient workflow, we propose Imitative Market Maker (IMM), a novel RL framework that leverages both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework starts by introducing effective state and action representations that are adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.
</details></li>
</ul>
<hr>
<h2 id="Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection"><a href="#Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection" class="headerlink" title="Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection"></a>Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08915">http://arxiv.org/abs/2308.08915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawnvince/mts_cad">https://github.com/dawnvince/mts_cad</a></li>
<li>paper_authors: Haotian Si, Changhua Pei, Zhihan Li, Yadong Zhao, Jingjing Li, Haiming Zhang, Zulong Diao, Jianhui Li, Gaogang Xie, Dan Pei</li>
<li>for: 本研究旨在提出一种基于多任务学习的多变量时间序列异常检测（MTS AD）算法，以确保软件应用和服务系统的可靠性。</li>
<li>methods: 本研究使用了自适应MTS AD方法，通过优化总体目标&#x2F;损失来捕捉所有指标的回归目标&#x2F;损失。然而，我们的实验发现，这些指标的回归目标之间存在冲突，导致MTS模型面临不同的损失。为解决这问题，我们提出了一种具有冲突 Mitigation的多变量KPI异常检测算法（CAD）。</li>
<li>results: 我们的实验表明，CAD算法在三个公共数据集上的平均F1分数为0.943，明显超过现有方法。此外，我们还发现了MTS形式ulation的输入-输出不一致和扩展任务的问题，并提出了一种简单 yet有效的任务导向指标选择和个性化分配机制，以解决这些挑战。<details>
<summary>Abstract</summary>
Massive key performance indicators (KPIs) are monitored as multivariate time series data (MTS) to ensure the reliability of the software applications and service system. Accurately detecting the abnormality of MTS is very critical for subsequent fault elimination. The scarcity of anomalies and manual labeling has led to the development of various self-supervised MTS anomaly detection (AD) methods, which optimize an overall objective/loss encompassing all metrics' regression objectives/losses. However, our empirical study uncovers the prevalence of conflicts among metrics' regression objectives, causing MTS models to grapple with different losses. This critical aspect significantly impacts detection performance but has been overlooked in existing approaches. To address this problem, by mimicking the design of multi-gate mixture-of-experts (MMoE), we introduce CAD, a Conflict-aware multivariate KPI Anomaly Detection algorithm. CAD offers an exclusive structure for each metric to mitigate potential conflicts while fostering inter-metric promotions. Upon thorough investigation, we find that the poor performance of vanilla MMoE mainly comes from the input-output misalignment settings of MTS formulation and convergence issues arising from expansive tasks. To address these challenges, we propose a straightforward yet effective task-oriented metric selection and p&s (personalized and shared) gating mechanism, which establishes CAD as the first practicable multi-task learning (MTL) based MTS AD model. Evaluations on multiple public datasets reveal that CAD obtains an average F1-score of 0.943 across three public datasets, notably outperforming state-of-the-art methods. Our code is accessible at https://github.com/dawnvince/MTS_CAD.
</details>
<details>
<summary>摘要</summary>
巨大的关键性能指标 (KPI) 被监测为多变量时间序列数据 (MTS)，以确保软件应用程序和服务系统的可靠性。正确地探测 MTS 中的异常是非常关键的，以便后续的故障排除。由于罕见的异常和手动标注的缺乏，已经导致了多种无监督 MTS 异常检测 (AD) 方法的发展，这些方法通过优化总体的目标/损失函数来优化所有指标的回归目标/损失函数。然而，我们的实验发现，在不同指标之间存在冲突的问题，导致 MTS 模型在不同的损失函数之间挣扎。这种问题在现有方法中受到了忽略。为解决这个问题，我们通过模仿多门混合专家 (MMoE) 的设计，引入 CAD，即冲突意识多变量 KPI 异常检测算法。CAD 提供了每个指标 exclusive 结构，以mitigate 可能的冲突，同时推动指标之间的促进。经过全面的调查，我们发现，简单的 MMoE 的 Poor 性能主要来自 MTS 表示形式的输入-输出不一致和扩展任务的准确性问题。为解决这些挑战，我们提议一种简单 yet 有效的任务意向指标选择和人性化分配机制，使 CAD 成为首个实用多任务学习 (MTL) 基于 MTS AD 模型。多个公共数据集的评估显示，CAD 在三个公共数据集上的平均 F1-score 为 0.943，显著超过当前state-of-the-art方法。我们的代码可以在 GitHub 上找到：https://github.com/dawnvince/MTS_CAD。
</details></li>
</ul>
<hr>
<h2 id="MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling"><a href="#MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling" class="headerlink" title="MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling"></a>MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09725">http://arxiv.org/abs/2308.09725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziwei Yang, Zheng Chen, Yasuko Matsubara, Yasushi Sakurai</li>
<li>for: 这个论文目的是使用多Omics数据来改进肿瘤分型结果，以便更好地了解肿瘤的发展机理。</li>
<li>methods: 该论文使用了一种名为MoCLIM的表示学习框架，通过独立提取不同Omics模式下的有用特征，并使用这些特征进行归一化，以便更好地分类肿瘤。</li>
<li>results: 实验结果表明，使用MoCLIM方法可以提高肿瘤分型结果的数据适应度和分类性能，并且可以在 fewer 高维度肿瘤实例中提供更高的解释性。<details>
<summary>Abstract</summary>
Precision medicine fundamentally aims to establish causality between dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer subtyping has emerged as a revolutionary approach, as different level of omics records the biochemical products of multistep processes in cancers. This paper focuses on fully exploiting the potential of multi-omics data to improve cancer subtyping outcomes, and hence developed MoCLIM, a representation learning framework. MoCLIM independently extracts the informative features from distinct omics modalities. Using a unified representation informed by contrastive learning of different omics modalities, we can well-cluster the subtypes, given cancer, into a lower latent space. This contrast can be interpreted as a projection of inter-omics inference observed in biological networks. Experimental results on six cancer datasets demonstrate that our approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer instances. Moreover, our framework incorporates various medical evaluations as the final component, providing high interpretability in medical analysis.
</details>
<details>
<summary>摘要</summary>
基于精准医学的研究旨在确立肿瘤Subtype与生物化学过程的缺陷关系。ómics技术在肿瘤分类方面发挥了革命性的作用，不同的ómics数据记录了肿瘤的生物化学产物。本文将关注在完全利用多个ómics数据来提高肿瘤分类效果，并因此开发了MoCLIM表示学框架。MoCLIM独立提取不同ómics模式中的有用特征。通过对不同ómics模式的对比学习，我们可以将肿瘤分类到一个较低的 latent space。这种对比可以被解释为生物网络中跨modalities的推理。实验结果表明，我们的方法可以在六个肿瘤数据集中显著提高数据适应度和肿瘤分类性能，并且我们的框架可以 incorporate多种医学评估作为最后一个组件，提供高度可解释的医学分析。
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain"><a href="#Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain" class="headerlink" title="Development of a Knowledge Graph Embeddings Model for Pain"></a>Development of a Knowledge Graph Embeddings Model for Pain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08904">http://arxiv.org/abs/2308.08904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaya Chaturvedi, Tao Wang, Sumithra Velupillai, Robert Stewart, Angus Roberts</li>
<li>for: 本研究的目的是构建一个知识图谱模型，用于理解抑郁症患者的痛苦经验。</li>
<li>methods: 本研究使用了知识图谱embedding技术，将痛苦相关的概念与关系从外部医学知识库中提取，并与电子医疗记录中的痛苦实例进行结合。</li>
<li>results: 研究结果显示，使用知识图谱embedding模型可以提高预测痛苦相关的Subject-Object链接任务的性能，比基eline模型更高。<details>
<summary>Abstract</summary>
Pain is a complex concept that can interconnect with other concepts such as a disorder that might cause pain, a medication that might relieve pain, and so on. To fully understand the context of pain experienced by either an individual or across a population, we may need to examine all concepts related to pain and the relationships between them. This is especially useful when modeling pain that has been recorded in electronic health records. Knowledge graphs represent concepts and their relations by an interlinked network, enabling semantic and context-based reasoning in a computationally tractable form. These graphs can, however, be too large for efficient computation. Knowledge graph embeddings help to resolve this by representing the graphs in a low-dimensional vector space. These embeddings can then be used in various downstream tasks such as classification and link prediction. The various relations associated with pain which are required to construct such a knowledge graph can be obtained from external medical knowledge bases such as SNOMED CT, a hierarchical systematic nomenclature of medical terms. A knowledge graph built in this way could be further enriched with real-world examples of pain and its relations extracted from electronic health records. This paper describes the construction of such knowledge graph embedding models of pain concepts, extracted from the unstructured text of mental health electronic health records, combined with external knowledge created from relations described in SNOMED CT, and their evaluation on a subject-object link prediction task. The performance of the models was compared with other baseline models.
</details>
<details>
<summary>摘要</summary>
痛苦是一个复杂的概念，可以与其他概念相互连接，如疾病、药物等，以全面理解个人或人口群体的痛苦经验。为了实现这一目标，我们需要检视所有与痛苦相关的概念和他们之间的关系。这非常有用，特别是在模拟基于电子医疗记录的痛苦记录时。知识图表示概念和其关系为相互连接的网络，允许semantic和上下文基本的推理。但这些图可能太大，不可靠性Compute。知识图嵌入帮助解决这一问题，将知识图 Represented in一个低维度的向量空间。这些嵌入可以在多种下游任务中使用，如分类和链接预测。关于痛苦的各种关系，可以从外部的医疗知识库，如SNOMED CT，获取。SNOMED CT是一个层次的系统性词汇表，用于医学术语。通过将这些知识库与电子医疗记录中的实际痛苦例子相结合，可以构建更加完整的知识图。这篇论文描述了基于痛苦概念的知识图嵌入模型的建构，从精神医疗电子记录中提取的概念和SNOMED CT中的外部知识进行组合，以及这些模型在主题-对象链接预测任务上的评估。与其他基eline模型相比，这些模型的性能如何呢？
</details></li>
</ul>
<hr>
<h2 id="Optimal-Resource-Allocation-for-U-Shaped-Parallel-Split-Learning"><a href="#Optimal-Resource-Allocation-for-U-Shaped-Parallel-Split-Learning" class="headerlink" title="Optimal Resource Allocation for U-Shaped Parallel Split Learning"></a>Optimal Resource Allocation for U-Shaped Parallel Split Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08896">http://arxiv.org/abs/2308.08896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Lyu, Zheng Lin, Guanqiao Qu, Xianhao Chen, Xiaoxia Huang, Pan Li<br>for: 这paper是为了解决 tradicional的 Split Learning（SL）方法会泄露标签隐私的问题，提出了U-shaped网络的使用来保护标签隐私。methods: 该paper使用了U-shaped网络和Parallel Split Learning（PSL）技术，并提出了一种名为LSCRA的资源分配算法来优化边缘网络的性能。results: 该paper的实验结果表明，LSCRA算法可以有效地分配资源和Split层，并且U-shaped PSL可以与其他SL基线方法具有相似的性能而又保护标签隐私。<details>
<summary>Abstract</summary>
Split learning (SL) has emerged as a promising approach for model training without revealing the raw data samples from the data owners. However, traditional SL inevitably leaks label privacy as the tail model (with the last layers) should be placed on the server. To overcome this limitation, one promising solution is to utilize U-shaped architecture to leave both early layers and last layers on the user side. In this paper, we develop a novel parallel U-shaped split learning and devise the optimal resource optimization scheme to improve the performance of edge networks. In the proposed framework, multiple users communicate with an edge server for SL. We analyze the end-to-end delay of each client during the training process and design an efficient resource allocation algorithm, called LSCRA, which finds the optimal computing resource allocation and split layers. Our experimental results show the effectiveness of LSCRA and that U-shaped PSL can achieve a similar performance with other SL baselines while preserving label privacy. Index Terms: U-shaped network, split learning, label privacy, resource allocation, 5G/6G edge networks.
</details>
<details>
<summary>摘要</summary>
Split learning (SL) 已经出现为训练模型无需披露原始数据样本的有效方法。然而，传统的 SL 必然泄露标签隐私，因为tail模型（最后层）必须放置在服务器上。为解决这个限制，一种有前途的解决方案是使用 U 型架构，留下 Early layers 和 Last layers 在用户端。在本文中，我们开发了一种新的平行 U 型 Split Learning 框架，并设计了最佳资源优化策略，以提高边缘网络的性能。在我们的提案中，多个用户与边缘服务器进行 SL 通信。我们分析每个客户端在训练过程中的末端延迟，并设计了一个高效的资源分配算法，称为 LSCRA，以找到最佳计算资源分配和分割层。我们的实验结果表明 LSCRA 的效果和 U 型 PSL 可以在保持标签隐私的情况下实现相似的性能。关键字： U 型网络、Split learning、标签隐私、资源分配、5G/6G 边缘网络。
</details></li>
</ul>
<hr>
<h2 id="Dual-Gauss-Newton-Directions-for-Deep-Learning"><a href="#Dual-Gauss-Newton-Directions-for-Deep-Learning" class="headerlink" title="Dual Gauss-Newton Directions for Deep Learning"></a>Dual Gauss-Newton Directions for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08886">http://arxiv.org/abs/2308.08886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincent Roulet, Mathieu Blondel</li>
<li>for: 提高深度学习优化算法的精度和效率</li>
<li>methods: 基于半线性化的对象结构，使用对数损失函数和非线性网络的复合，计算更好的方向指标，而不是渐进随机梯度</li>
<li>results: 实验表明，使用对数损失函数和非线性网络的复合，可以获得更好的下降方向指标，并且可以用现有的优化算法中的梯度更新Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to improve the accuracy and efficiency of deep learning optimization algorithms by leveraging the structure of deep learning objectives.</li>
<li>methods: The authors propose to compute better direction oracles using the dual formulation of the objective function, which leads to both computational benefits and new insights.</li>
<li>results: The experimental results show that using the dual formulation of the objective function, combined with the composition of a convex loss function and a nonlinear network, can lead to better descent directions that can be used as a drop-in replacement for stochastic gradients in existing optimization algorithms.<details>
<summary>Abstract</summary>
Inspired by Gauss-Newton-like methods, we study the benefit of leveraging the structure of deep learning objectives, namely, the composition of a convex loss function and of a nonlinear network, in order to derive better direction oracles than stochastic gradients, based on the idea of partial linearization. In a departure from previous works, we propose to compute such direction oracles via their dual formulation, leading to both computational benefits and new insights. We demonstrate that the resulting oracles define descent directions that can be used as a drop-in replacement for stochastic gradients, in existing optimization algorithms. We empirically study the advantage of using the dual formulation as well as the computational trade-offs involved in the computation of such oracles.
</details>
<details>
<summary>摘要</summary>
受加ус-牛顿方法启发，我们研究利用深度学习目标结构的优点，即几何函数和抽象网络的复合，以 derive better direction oracles than stochastic gradients，基于partial linearization的想法。在之前的工作中，我们提议通过对 dual 形式来计算这些方向指南，从而实现计算上的收益和新的理解。我们证明这些方向指南可以作为现有优化算法中的替补，以及计算这些方向指南的计算成本和计算质量的负担。我们进行了实验研究，证明使用 dual 形式的计算具有优势，并且计算成本和计算质量的负担存在trade-off关系。
</details></li>
</ul>
<hr>
<h2 id="Feature-Enforcing-PINN-FE-PINN-A-Framework-to-Learn-the-Underlying-Physics-Features-Before-Target-Task"><a href="#Feature-Enforcing-PINN-FE-PINN-A-Framework-to-Learn-the-Underlying-Physics-Features-Before-Target-Task" class="headerlink" title="Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task"></a>Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08873">http://arxiv.org/abs/2308.08873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Jahaninasab, Mohamad Ali Bijarchi</li>
<li>for:  This paper is written for solving partial differential equations (PDEs) with a new data-free framework called Feature Enforcing Physics Informed Neural Network (FE-PINN).</li>
<li>methods:  The FE-PINN framework uses a sequence of sub-tasks to learn useful features about the underlying physics and then refine the calculations for the target task.</li>
<li>results:  The FE-PINN framework achieves 15x, 2x, and 5x speed up for three benchmarks (flow over a cylinder, 2D heat conduction, and an inverse problem of calculating inlet velocity) compared to vanilla PINN, and can reach a loss value near 1e-5, which is challenging for vanilla PINN.Here is the simplified Chinese text for the three key information points:</li>
<li>for: 这篇论文是为解决部分 diferencial 方程（PDEs）而编写的，使用一种新的数据自由框架called Feature Enforcing Physics Informed Neural Network (FE-PINN)。</li>
<li>methods:  FE-PINN 框架使用一个序列的子任务来学习有用的物理特征，然后为目标任务进行精细的计算。</li>
<li>results: FE-PINN 框架在三个 benchmark（流过cylinder，2D heat conduction，和反向问题计算入口速度）中实现了15倍，2倍，和5倍的速度提升，并可以达到1e-5的损失值，这是vanilla PINN 困难的。<details>
<summary>Abstract</summary>
In this work, a new data-free framework called Feature Enforcing Physics Informed Neural Network (FE-PINN) is introduced. This framework is capable of learning the underlying pattern of any problem with low computational cost before the main training loop. The loss function of vanilla PINN due to the existence of two terms of partial differential residuals and boundary condition mean squared error is imbalanced. FE-PINN solves this challenge with just one minute of training instead of time-consuming hyperparameter tuning for loss function that can take hours. The FE-PINN accomplishes this process by performing a sequence of sub-tasks. The first sub-task learns useful features about the underlying physics. Then, the model trains on the target task to refine the calculations. FE-PINN is applied to three benchmarks, flow over a cylinder, 2D heat conduction, and an inverse problem of calculating inlet velocity. FE-PINN can solve each case with, 15x, 2x, and 5x speed up accordingly. Another advantage of FE-PINN is that reaching lower order of value for loss function is systematically possible. In this study, it was possible to reach a loss value near 1e-5 which is challenging for vanilla PINN. FE-PINN also has a smooth convergence process which allows for utilizing higher learning rates in comparison to vanilla PINN. This framework can be used as a fast, accurate tool for solving a wide range of Partial Differential Equations (PDEs) across various fields.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了一种新的数据自由框架，即特征强制物理学 Informed Neural Network（FE-PINN）。这个框架可以在低计算成本下学习问题的下面 patrern。这个框架通过一系列子任务来实现。首先，它学习问题的下面特征。然后，模型在目标任务上进行反射计算。FE-PINN应用于三个标准测试函数，即流过圆柱、2D热传导和反向问题计算入口速度。FE-PINN可以在每个情况下提高计算速度15倍、2倍和5倍。此外，FE-PINN可以系统地降低损失函数的值。在这项研究中，我们可以达到一个损失值附近1e-5，这是vanilla PINN很困难的。FE-PINN也有平滑的收敛过程，因此可以在vanilla PINN的比例上使用更高的学习率。这个框架可以作为解决各种 partial Differential Equations（PDEs）的快速、准确的工具。
</details></li>
</ul>
<hr>
<h2 id="Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels"><a href="#Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels" class="headerlink" title="Towards Semi-supervised Learning with Non-random Missing Labels"></a>Towards Semi-supervised Learning with Non-random Missing Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08872">http://arxiv.org/abs/2308.08872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njuyued/prg4ssl-mnar">https://github.com/njuyued/prg4ssl-mnar</a></li>
<li>paper_authors: Yue Duan, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi</li>
<li>for: 本文 targets the problem of label missing not at random (MNAR) in semi-supervised learning (SSL), and proposes a class transition tracking based Pseudo-Rectifying Guidance (PRG) method to improve the performance of SSL models in MNAR scenarios.</li>
<li>methods: 本文使用的方法包括Markov随机游走模型和动态创建的类追踪矩阵，以及基于这些信息的PRG方法，来维护模型的偏好性和类分布的历史信息，从而提高SSL模型在MNAR场景中的性能。</li>
<li>results: 本文的实验结果表明，PRG方法可以在多种MNAR场景中显著超过latest SSL方法组合偏移解决方案的性能，并且在各种极端场景下都能够保持良好的性能。<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) tackles the label missing problem by enabling the effective usage of unlabeled data. While existing SSL methods focus on the traditional setting, a practical and challenging scenario called label Missing Not At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled data fall into different class distributions resulting in biased label imputation, which deteriorates the performance of SSL models. In this work, class transition tracking based Pseudo-Rectifying Guidance (PRG) is devised for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details>
<details>
<summary>摘要</summary>
semi-supervised learning (SSL)  solves the problem of missing labels by using unlabeled data effectively. However, existing SSL methods mostly focus on the traditional setting and ignore the practical and challenging scenario of label Missing Not At Random (MNAR). In MNAR, the labeled and unlabeled data are in different class distributions, leading to biased label imputation and degrading the performance of SSL models. In this work, we propose class transition tracking based Pseudo-Rectifying Guidance (PRG) for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details></li>
</ul>
<hr>
<h2 id="Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games"><a href="#Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games" class="headerlink" title="Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games"></a>Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08858">http://arxiv.org/abs/2308.08858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songtao Feng, Ming Yin, Yu-Xiang Wang, Jing Yang, Yingbin Liang</li>
<li>for: 这个论文主要研究的是在多智能RL中的两参与 Zero-Sum Markov Game 问题，具体来说是在有限时间循环 Markov Decision Processes 中。</li>
<li>methods: 该论文提出了一种基于Stage-based Q-学习算法的模型自由方法，并证明了该算法可以达到最佳的 $\epsilon $-优 Nash Equilibrium 的样本复杂度为 $O(H^3SAB&#x2F;\epsilon^2) $，这是在 $H $ 和 $S $ 上依赖的最佳。</li>
<li>results: 该论文展示了该算法可以达到模型基于算法的最佳性，并且在 $H $ 上依赖的部分提高了模型自由算法的样本复杂度。此外，该论文还提出了一种新的 referential advantage decomposition 技术，以提高样本效率。<details>
<summary>Abstract</summary>
The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by leveraging the popular variance reduction technique based on the reference-advantage decomposition previously used only for single-agent RL. However, such a technique relies on a critical monotonicity property of the value function, which does not hold in Markov games due to the update of the policy via the coarse correlated equilibrium (CCE) oracle. Thus, to extend such a technique to Markov games, our algorithm features a key novel design of updating the reference value functions as the pair of optimistic and pessimistic value functions whose value difference is the smallest in the history in order to achieve the desired improvement in the sample efficiency.
</details>
<details>
<summary>摘要</summary>
“两个玩家零游戏马克夫游戏（Markov game）的问题在多智能抽象学习（multi-agent reinforcement learning，RL）中得到了越来越多的关注。特别是在有限时间剪辑Markov决策过程（MDP）中，已经证明了使用模型基本算法可以在$\epsilon$-优 NashEquilibrium（NE）中找到$O(H^3SAB/\epsilon^2)$的样本复杂度，这是在$H$和$S$上依赖的最优性。然而，现有的模型自由算法无法达到这种优化。在这个工作中，我们提出了一种模型自由阶段Q学习算法，并证明它可以 дости到最优的$H$依赖性。这个主要的改进来自于使用单个智能RL中广泛使用的参考优势分解技术，但这种技术需要Markov游戏中值函数的幂等性，这并不是真实存在的。因此，我们的算法具有一个关键的新特点，即在历史中更新参考值函数为最小值差的对，以实现所需的样本效率提高。”
</details></li>
</ul>
<hr>
<h2 id="Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays"><a href="#Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays" class="headerlink" title="Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays"></a>Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08853">http://arxiv.org/abs/2308.08853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Hong, Tianjie Dai, Jiangchao Yao, Ya Zhang, Yanfeng Wang</li>
<li>for: 这个研究旨在提高胸部X射镜（CXR）诊断的准确性，探讨了许多进步设计，如数据增强、特征提取、分类器设计、损失函数重新配置、外部数据补充等。</li>
<li>methods: 这个研究使用了多种进步设计，包括数据增强、特征提取、分类器设计、损失函数重新配置、外部数据补充等。</li>
<li>results: 这个研究获得了0.349 mAP的成绩，位居评比测试集的前五名。<details>
<summary>Abstract</summary>
Clinical classification of chest radiography is particularly challenging for standard machine learning algorithms due to its inherent long-tailed and multi-label nature. However, few attempts take into account the coupled challenges posed by both the class imbalance and label co-occurrence, which hinders their value to boost the diagnosis on chest X-rays (CXRs) in the real-world scenarios. Besides, with the prevalence of pretraining techniques, how to incorporate these new paradigms into the current framework lacks of the systematical study. This technical report presents a brief description of our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness for CXR diagnosis with the integration of several advanced designs about data augmentation, feature extractor, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improve the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details>
<details>
<summary>摘要</summary>
严重疾病分类在胸部X射影图（CXR）中是特别挑战，主要因为它具有自然长尾和多标签性。然而，少数尝试不足以考虑这两个挑战的结合，从而限制其在实际场景中的价值。此外，随着预训练技术的普及，如何在当前框架中 integrate these new paradigms lacks systematic study.本技术报告 briefly describes our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness of CXR diagnosis with the integration of several advanced designs, including data augmentation, feature extraction, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improved the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details></li>
</ul>
<hr>
<h2 id="Learning-the-hub-graphical-Lasso-model-with-the-structured-sparsity-via-an-efficient-algorithm"><a href="#Learning-the-hub-graphical-Lasso-model-with-the-structured-sparsity-via-an-efficient-algorithm" class="headerlink" title="Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm"></a>Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08852">http://arxiv.org/abs/2308.08852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjing Wang, Peipei Tang, Wenling He, Meixia Lin</li>
<li>for:  efficiently estimate graphical models with hub nodes in large datasets</li>
<li>methods:  dual alternating direction method of multipliers (ADMM) and semismooth Newton (SSN) based augmented Lagrangian method (ALM)</li>
<li>results:  significantly outperforms existing state-of-the-art algorithms in terms of execution time and estimation accuracy, with savings of up to 70% in some high-dimensional tasks.<details>
<summary>Abstract</summary>
Graphical models have exhibited their performance in numerous tasks ranging from biological analysis to recommender systems. However, graphical models with hub nodes are computationally difficult to fit, particularly when the dimension of the data is large. To efficiently estimate the hub graphical models, we introduce a two-phase algorithm. The proposed algorithm first generates a good initial point via a dual alternating direction method of multipliers (ADMM), and then warm starts a semismooth Newton (SSN) based augmented Lagrangian method (ALM) to compute a solution that is accurate enough for practical tasks. The sparsity structure of the generalized Jacobian ensures that the algorithm can obtain a nice solution very efficiently. Comprehensive experiments on both synthetic data and real data show that it obviously outperforms the existing state-of-the-art algorithms. In particular, in some high dimensional tasks, it can save more than 70\% of the execution time, meanwhile still achieves a high-quality estimation.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：</SYS>图形模型在各种任务中表现出色，从生物分析到推荐系统。然而，含有中心节点的图形模型在大量数据时 computationally 难以适应。为了高效地估算中心图形模型，我们提出了两阶段算法。我们的算法首先使用对偶替代方法（ADMM）生成一个良好的初始点，然后使用增强的均值法（SSN）基于扩展拉格朗日方法（ALM）计算一个精度足够高的解决方案。通过各个稀疏结构的总导数，我们的算法可以很快地获得一个高质量的解决方案。实验表明，我们的算法在各种高维任务中可以 saves more than 70% 的执行时间，同时仍然达到高质量的估算。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Assisted-Discovery-of-Novel-Reactor-Designs-via-CFD-Coupled-Multi-fidelity-Bayesian-Optimisation"><a href="#Machine-Learning-Assisted-Discovery-of-Novel-Reactor-Designs-via-CFD-Coupled-Multi-fidelity-Bayesian-Optimisation" class="headerlink" title="Machine Learning-Assisted Discovery of Novel Reactor Designs via CFD-Coupled Multi-fidelity Bayesian Optimisation"></a>Machine Learning-Assisted Discovery of Novel Reactor Designs via CFD-Coupled Multi-fidelity Bayesian Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08841">http://arxiv.org/abs/2308.08841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Savage, Nausheen Basha, Jonathan McDonough, Omar K Matar, Ehecatl Antonio del Rio Chanona</li>
<li>for: 这 paper 的目的是设计、优化和制造以下一代化学反应器。</li>
<li>methods: 这 paper 使用了多级 Bayesian 优化法，以优化各种不同的尺度和曲线路径，从而实现高维度、复杂的优化问题。</li>
<li>results: 这 paper 通过 maximizing 填充流性能，提出了两种新的卷积管 geometries，并通过 3D 打印和实验验证了它们的可靠性和性能。<details>
<summary>Abstract</summary>
Additive manufacturing has enabled the production of more advanced reactor geometries, resulting in the potential for significantly larger and more complex design spaces. Identifying and optimising promising configurations within broader design spaces presents a significant challenge for existing human-centric design approaches. As such, existing parameterisations of coiled-tube reactor geometries are low-dimensional with expensive optimisation limiting more complex solutions. Given algorithmic improvements and the onset of additive manufacturing, we propose two novel coiled-tube parameterisations enabling the variation of cross-section and coil path, resulting in a series of high dimensional, complex optimisation problems. To ensure tractable, non-local optimisation where gradients are not available, we apply multi-fidelity Bayesian optimisation. Our approach characterises multiple continuous fidelities and is coupled with parameterised meshing and simulation, enabling lower quality, but faster simulations to be exploited throughout optimisation. Through maximising the plug-flow performance, we identify key characteristics of optimal reactor designs, and extrapolate these to produce two novel geometries that we 3D print and experimentally validate. By demonstrating the design, optimisation, and manufacture of highly parameterised reactors, we seek to establish a framework for the next-generation of reactors, demonstrating that intelligent design coupled with new manufacturing processes can significantly improve the performance and sustainability of future chemical processes.
</details>
<details>
<summary>摘要</summary>
“三维打印技术的出现已经使得反应室的设计空间得以扩大，并且可以实现更复杂的设计。但是，对于现有的人类中心设计方法来说，identifying和优化promising配置在更广泛的设计空间中是一项具有挑战性的任务。因此，现有的环形管径参数化方法都是低维的，并且优化成本较高，不能实现更复杂的解决方案。为了解决这个问题，我们提出了两种新的环形管径参数化方法，允许环形管径的跨section和径路变化，从而导致一系列高维度、复杂的优化问题。为了确保可行的、非本地优化，我们采用多质量抽象 Bayesian 优化方法。我们的方法通过连接多个连续质量的 Bayesian 优化和参数化的笆化和模拟，以便在优化过程中使用较低质量但快速的 simulations。通过最大化插入性性能，我们确定了优化反应室的关键特征，并将其推广到生产两个新的geometry。我们通过3D打印和实验验证这两个geometry，以证明我们的设计、优化和制造方法可以带来未来化学过程的性能和可持续性。”
</details></li>
</ul>
<hr>
<h2 id="ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space"><a href="#ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space" class="headerlink" title="ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space"></a>ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08830">http://arxiv.org/abs/2308.08830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veronika Spieker, Wenqi Huang, Hannah Eichhorn, Jonathan Stelter, Kilian Weiss, Veronika A. Zimmer, Rickmer F. Braren, Dimitrios C. Karampinos, Kerstin Hammernik, Julia A. Schnabel</li>
<li>for: 这份研究旨在提出一种能够生成不受运动噪声影响的高精度腹部MRI重建方法。</li>
<li>methods: 本研究使用神经阶层学习（NIK）来直接在k空间中学习无残差的运动解析，并引入了一个受资料支持的几何调整层（ICo）以正常化NIK的预测。</li>
<li>results: 该方法比标准的运动解析方法表现更好，并且可以获得高精度的腹部MRI重建结果。<details>
<summary>Abstract</summary>
Motion-resolved reconstruction for abdominal magnetic resonance imaging (MRI) remains a challenge due to the trade-off between residual motion blurring caused by discretized motion states and undersampling artefacts. In this work, we propose to generate blurring-free motion-resolved abdominal reconstructions by learning a neural implicit representation directly in k-space (NIK). Using measured sampling points and a data-derived respiratory navigator signal, we train a network to generate continuous signal values. To aid the regularization of sparsely sampled regions, we introduce an additional informed correction layer (ICo), which leverages information from neighboring regions to correct NIK's prediction. Our proposed generative reconstruction methods, NIK and ICoNIK, outperform standard motion-resolved reconstruction techniques and provide a promising solution to address motion artefacts in abdominal MRI.
</details>
<details>
<summary>摘要</summary>
对于腹部磁共振成像（MRI）中的运动解构，仍然是一个挑战，这是因为运动状态的精细化会导致剩下的运动扩散噪声和抽取 artefacts。在这项工作中，我们提议通过直接在 k-空间学习神经网络表示（NIK）来生成无拟合噪声的运动解构。使用测量的抽取点和数据驱动的呼吸导航信号，我们将网络训练出continuous的信号值。为了帮助稀疏抽取区域的正则化，我们引入了一个更正层（ICo），该层利用邻近区域的信息来正则化 NIK 的预测。我们的提出的生成重建方法，NIK 和 ICoNIK，超过了标准的运动解构技术，并提供了Addressing motion artefacts in abdominal MRI 中的一个有前途的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Controlling-Federated-Learning-for-Covertness"><a href="#Controlling-Federated-Learning-for-Covertness" class="headerlink" title="Controlling Federated Learning for Covertness"></a>Controlling Federated Learning for Covertness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08825">http://arxiv.org/abs/2308.08825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adit Jain, Vikram Krishnamurthy</li>
<li>for: 这篇论文目的是探讨一个叫做“covert”或“learner-private”的优化问题，learner要在发生噪音的情况下，通过对应用数据的随机性来隐藏目标函数的最佳值。</li>
<li>methods: 本文使用了Markov decision process来模型问题，并证明了运算的超模统性，这使得找到优化策略的问题可以使用政策条件运算。同时，一个 computationally efficient policy gradient algorithm 是提出来解决问题。</li>
<li>results: 在实际应用中，本文将方法应用在一个联邦学习中的 hate speech 分类任务上，并证明了在使用优化策略时，一个 eavesdropper 只能在没有信息的情况下取得52%的验证率，对比之下，在有10%阳性数据的情况下，eavesdropper 只能取得69%的验证率，而且这些结果较好于使用单纯的 greedy 策略。<details>
<summary>Abstract</summary>
A learner aims to minimize a function $f$ by repeatedly querying a distributed oracle that provides noisy gradient evaluations. At the same time, the learner seeks to hide $\arg\min f$ from a malicious eavesdropper that observes the learner's queries. This paper considers the problem of \textit{covert} or \textit{learner-private} optimization, where the learner has to dynamically choose between learning and obfuscation by exploiting the stochasticity. The problem of controlling the stochastic gradient algorithm for covert optimization is modeled as a Markov decision process, and we show that the dynamic programming operator has a supermodular structure implying that the optimal policy has a monotone threshold structure. A computationally efficient policy gradient algorithm is proposed to search for the optimal querying policy without knowledge of the transition probabilities. As a practical application, our methods are demonstrated on a hate speech classification task in a federated setting where an eavesdropper can use the optimal weights to generate toxic content, which is more easily misclassified. Numerical results show that when the learner uses the optimal policy, an eavesdropper can only achieve a validation accuracy of $52\%$ with no information and $69\%$ when it has a public dataset with 10\% positive samples compared to $83\%$ when the learner employs a greedy policy.
</details>
<details>
<summary>摘要</summary>
学生希望减少函数 $f$ 的值，通过 repeatedly 请求分布式 oracle 提供噪声梯度评估。同时，学生尝试隐藏 $\arg\min f$ 于一个恶意窃听者，该窃听者可以观察学生的查询。这篇论文考虑了“隐蔽”或“学习者私有”优化问题，学生需要在执行权重学习和隐蔽之间 dynamically 选择。在模型中，我们使用 Markov 决策过程来控制权重学习的执行，并证明了优化算法的动态程序拥有超模ular结构，表示优化策略的最优策略具有垂直阈值结构。我们提出了一种 Computational 效率的策略梯度算法，可以无需知情转移概率进行搜索优化策略。在实际应用中，我们将方法应用于一个联合 Setting 中的 hate speech 分类任务，恶意窃听者可以使用最优策略生成毒品，这些毒品更容易被误分类。实际结果表明，当学生使用优化策略时，恶意窃听者只能在没有信息的情况下达到52%的验证精度，并且在拥有10%正样本的情况下达到69%的验证精度，与学生使用响应策略相比，恶意窃听者的验证精度提高了21个百分点。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Semantic-Confusion-from-Hostile-Neighborhood-for-Graph-Active-Learning"><a href="#Mitigating-Semantic-Confusion-from-Hostile-Neighborhood-for-Graph-Active-Learning" class="headerlink" title="Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning"></a>Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08823">http://arxiv.org/abs/2308.08823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianmeng Yang, Min Zhou, Yujing Wang, Zhengjie Lin, Lujia Pan, Bin Cui, Yunhai Tong<br>for: 本文targets to improve the performance of Graph Neural Networks (GNNs) by addressing the challenge of semantic confusion in graph active learning (GAL).methods: 本文提出了一个Semantic-aware Active learning framework for Graphs (SAG)，包括引入节点相似度和不相似度，jointly evaluate node influence，并设计了一种新的原型基于 criterion和查询策略来保持节点选择的多样性和分类均衡。results: 对于公共 benchmark graphs 和一个实际世界金融数据集，SAGsignificantly improves node classification performance，并常常超过先前的方法。此外，广泛的分析和剥离研究也证明了提案的效果。<details>
<summary>Abstract</summary>
Graph Active Learning (GAL), which aims to find the most informative nodes in graphs for annotation to maximize the Graph Neural Networks (GNNs) performance, has attracted many research efforts but remains non-trivial challenges. One major challenge is that existing GAL strategies may introduce semantic confusion to the selected training set, particularly when graphs are noisy. Specifically, most existing methods assume all aggregating features to be helpful, ignoring the semantically negative effect between inter-class edges under the message-passing mechanism. In this work, we present Semantic-aware Active learning framework for Graphs (SAG) to mitigate the semantic confusion problem. Pairwise similarities and dissimilarities of nodes with semantic features are introduced to jointly evaluate the node influence. A new prototype-based criterion and query policy are also designed to maintain diversity and class balance of the selected nodes, respectively. Extensive experiments on the public benchmark graphs and a real-world financial dataset demonstrate that SAG significantly improves node classification performances and consistently outperforms previous methods. Moreover, comprehensive analysis and ablation study also verify the effectiveness of the proposed framework.
</details>
<details>
<summary>摘要</summary>
格Active学习（GAL），旨在找到图中最有信息的节点进行标注，以最大化图神经网络（GNNs）性能，已经吸引了许多研究努力，但仍存在许多挑战。一个主要挑战是现有的GAL策略可能会在选择训练集时引入semantic confusion，特别是当图像具有噪音时。在这种情况下，大多数现有方法假设所有聚合特征都是有用的，忽略了间类边缘下的semantic负面效果。在这个工作中，我们提出了Semantic-aware Active learning framework for Graphs（SAG），以 Mitigate semantic confusion problem。节点之间的对比性和不同性以及semantic特征被引入，以共同评估节点的影响力。一个新的原型基本 критерион和查询策略也被设计，以保持节点的多样性和分类均衡。经过对公共的benchmark图和一个真实世界的金融 dataset的广泛实验，我们发现SAG可以明显提高节点的分类性能，并常常超过先前的方法。此外，广泛的分析和减少研究也证明了提案的效果。
</details></li>
</ul>
<hr>
<h2 id="A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction"><a href="#A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction" class="headerlink" title="A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction"></a>A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08812">http://arxiv.org/abs/2308.08812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchar Palit, Sandika Biswas</li>
<li>for: 这个论文的目的是提出一种基于 kontinual learning的单图三维重建方法，以便在新类的训练中仍能reasonably重建之前见类。</li>
<li>methods: 该方法使用Variational Priors来表示抽象形态，并使用saliency map来保留物体特征，从而降低存储训练数据的资源成本。</li>
<li>results: 经过进行了严格的实验，该方法与已知方法相比，具有竞争的Result， both quantitatively and qualitatively。<details>
<summary>Abstract</summary>
Single-image 3D reconstruction is a research challenge focused on predicting 3D object shapes from single-view images. This task requires significant data acquisition to predict both visible and occluded portions of the shape. Furthermore, learning-based methods face the difficulty of creating a comprehensive training dataset for all possible classes. To this end, we propose a continual learning-based 3D reconstruction method where our goal is to design a model using Variational Priors that can still reconstruct the previously seen classes reasonably even after training on new classes. Variational Priors represent abstract shapes and combat forgetting, whereas saliency maps preserve object attributes with less memory usage. This is vital due to resource constraints in storing extensive training data. Additionally, we introduce saliency map-based experience replay to capture global and distinct object features. Thorough experiments show competitive results compared to established methods, both quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
单图3D重建是一个研究挑战，旨在根据单个图像预测3D物体形状。这项任务需要大量数据收集，以预测可见和遮盖的部分。学习基本方法面临的挑战是创建所有可能的类型的完整训练集。为此，我们提出了一种基于不断学习的3D重建方法，其目标是使用可变假设来设计一个可以在训练新类后仍然理解先前看到的类的模型。可变假设表示抽象形状，并避免忘记，而精灵图保留物体特征，减少存储训练数据的内存占用。此外，我们引入精灵图经验回放，以捕捉全局和特定的物体特征。经验表明，我们的方法与已知方法相比，具有竞争力的result。
</details></li>
</ul>
<hr>
<h2 id="Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts"><a href="#Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts" class="headerlink" title="Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts"></a>Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08810">http://arxiv.org/abs/2308.08810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sunghyun Park, Seunghan Yang, Jaegul Choo, Sungrack Yun</li>
<li>for: 这个论文的目的是要在推断过程中进行测试时适应（Test-time adaptation，TTA），并且能够处理类别分布的不均匀。</li>
<li>methods: 这个论文使用了一种新的类别shift adapter，可以与现有的TTA方法结合，以便在推断过程中处理类别分布的不均匀。</li>
<li>results: 这个论文的实验结果显示， integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner during inference. While label distributions often exhibit imbalances in real-world scenarios, most previous TTA approaches typically assume that both source and target domain datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natural that the label distribution shifts as the domain changes. However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and label shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA approaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for the target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be easily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation"><a href="#Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation" class="headerlink" title="Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation"></a>Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08799">http://arxiv.org/abs/2308.08799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jingxiaoyi/pare">https://github.com/jingxiaoyi/pare</a></li>
<li>paper_authors: Jiazheng Jing, Yinan Zhang, Xin Zhou, Zhiqi Shen</li>
<li>for: The paper aims to address the issue of item popularity in recommendation systems and proposes a novel approach called Popularity-Aware Recommender (PARE) to make non-personalized recommendations.</li>
<li>methods: PARE consists of four modules: popularity history, temporal impact, periodic impact, and side information, which are combined using an attention layer. The approach explicitly models item popularity and does not rely on personalized user preferences.</li>
<li>results: The paper reports that PARE performs on par or even better than state-of-the-art recommendation methods in extensive experiments. Additionally, integrating PARE with existing recommendation methods significantly improves performance, demonstrating its potential as a complementary component.Here’s the Simplified Chinese text version of the three key points:</li>
<li>for: 这篇论文目标是解决推荐系统中的item Popularity问题，并提出了一种新的方法 Popularity-Aware Recommender (PARE)，以非个人化的方式为用户提供推荐。</li>
<li>methods: PARE包括四个模块： popularity history、temporal impact、 periodic impact 和 side information，这些模块通过注意层结合。该方法Explicitly models item popularity，不依赖个人化用户偏好。</li>
<li>results: 论文Reported that PARE在广泛的实验中表现了与当前领先的推荐方法相当或更好的表现。此外，将PARE与现有的推荐方法集成显著提高了性能， демонстрируя其作为补充组件的潜在价值。<details>
<summary>Abstract</summary>
Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.
</details>
<details>
<summary>摘要</summary>
“推荐系统在过去几年中得到了不断的研究注意力。现有大多数推荐方法强调用户个人化偏好，可能会侵犯用户隐私。此外，这些方法经常忽略 Item 的时间影响和周期性，这可能会影响用户的决策。为了填补这个 gap，我们提出了 Popularity-Aware Recommender（PARE），这是一个不个人化的推荐方法，可以预测将在未来具有最高 популярность的 Item。PARE 包括四个模块，每个模块都集中在不同的方面：偏好历史、时间影响、周期影响和副资料。最后，我们使用了注意力层来融合四个模块的出力。我们知道这是第一个明确地模型 Item 的受欢迎程度的推荐系统。我们的实验结果显示，PARE 与现有的先进推荐方法相比，在大多数情况下表现相当或甚至更好。由于 PARE 将受欢迎程度放在用户个人化偏好之前，因此它可以增强现有的推荐方法，成为补充性的一部分。我们的实验显示，将 PARE 与现有的推荐方法结合，可以大幅提高推荐效果，强调 PARE 的潜在价值。此外，PARE 的简单性使其在工业应用中具有实际的实用性，并且成为未来研究的良好基础。”
</details></li>
</ul>
<hr>
<h2 id="Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data"><a href="#Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data" class="headerlink" title="Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data"></a>Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11646">http://arxiv.org/abs/2308.11646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Liao, Chaochao Chen, Weiming Liu, Pengyang Zhou, Huabin Zhu, Shuheng Shen, Weiqiang Wang, Mengling Hu, Yanchao Tan, Xiaolin Zheng</li>
<li>for: 提高 Federated Learning 在非独立 Identical Distribution （non-IID）数据上的效果。</li>
<li>methods: 提出了两个主要模块：本地关系增强（LRA）和全局纳什平衡（GNE），解决了内部和间接客户端不一致的问题。在每个客户端上，LRA 挖掘出不同数据样本之间的相似关系，并通过帮助函数通信来增强少数据样本的表示。在服务器端，GNE 达成了客户端到服务器端的不一致和不同模型偏差的协调，使全局模型在不破坏客户端优化向本地优化的情况下更新。</li>
<li>results: 通过在四个benchmark数据集上进行了广泛的实验，证明了 FedRANE 在非独立 Identical Distribution 数据上提高 Federated Learning 的性能。<details>
<summary>Abstract</summary>
Federated learning (FL) is a distributed machine learning paradigm that needs collaboration between a server and a series of clients with decentralized data. To make FL effective in real-world applications, existing work devotes to improving the modeling of decentralized data with non-independent and identical distributions (non-IID). In non-IID settings, there are intra-client inconsistency that comes from the imbalanced data modeling, and inter-client inconsistency among heterogeneous client distributions, which not only hinders sufficient representation of the minority data, but also brings discrepant model deviations. However, previous work overlooks to tackle the above two coupling inconsistencies together. In this work, we propose FedRANE, which consists of two main modules, i.e., local relational augmentation (LRA) and global Nash equilibrium (GNE), to resolve intra- and inter-client inconsistency simultaneously. Specifically, in each client, LRA mines the similarity relations among different data samples and enhances the minority sample representations with their neighbors using attentive message passing. In server, GNE reaches an agreement among inconsistent and discrepant model deviations from clients to server, which encourages the global model to update in the direction of global optimum without breaking down the clients optimization toward their local optimums. We conduct extensive experiments on four benchmark datasets to show the superiority of FedRANE in enhancing the performance of FL with non-IID data.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种分布式机器学习 paradigma，需要服务器和多个客户端之间的合作，以进行分布式数据的机器学习。为了在实际应用中使 FL 更加有效，现有的工作是针对非独立和非同分布 (non-IID) 的数据进行模型化。在 non-IID  Setting 中，存在客户端内的不均匀数据模型，以及客户端间的不一致性，这不仅会阻碍缺乏表征少数据的充分表示，而且会导致模型偏差的不一致。然而，先前的工作忽视了对上述两种结合不一致的解决。在这种工作中，我们提出了 FedRANE，它包括两个主要模块：本地关系增强 (LRA) 和全局纳什均衡 (GNE)。具体来说，在每个客户端中，LRA 挖掘不同数据样本之间的相似关系，并通过帮助式消息传递增强少数据表示。在服务器端，GNE 达成客户端间的不一致和不一致的模型偏差协议，使全局模型更新方向全局优点，而不是让客户端的优化方向各自的局部优点。我们在四个 benchmark 数据集上进行了广泛的实验，以示 FedRANE 在非独立和非同分布数据上的突出表现。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations"><a href="#Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations" class="headerlink" title="Bayesian polynomial neural networks and polynomial neural ordinary differential equations"></a>Bayesian polynomial neural networks and polynomial neural ordinary differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10892">http://arxiv.org/abs/2308.10892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Colby Fronk, Jaewoong Yun, Prashant Singh, Linda Petzold</li>
<li>for: 这 paper 是为了解决科学和工程问题中的方程回归问题。</li>
<li>methods: 这 paper 使用了 polynomial neural networks 和 polynomial neural ODEs 两种现代和强大的方法来回归方程。</li>
<li>results: 这 paper 通过开发和验证 Bayesian 推理方法（包括 Laplace  aproximation、MCMC 采样方法和 variational inference）来解决 noisy 数据问题。<details>
<summary>Abstract</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.
</details>
<details>
<summary>摘要</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) 是两种最近的和有力的方法，用于解决许多科学和工程问题中的方程回归问题。然而，这些方法只能提供点估计模型参数，并且不能处理噪声数据。我们解决这个挑战，通过开发和验证以下抽象推理方法：拉普拉斯近似法、Markov链 Monte Carlo（MCMC）抽样方法和变分推理法。我们发现，拉普拉斯近似法是这类问题中最佳的方法。我们的工作可以轻松扩展到更广泛的符号神经网络中，其中包括 polynomial neural network。
</details></li>
</ul>
<hr>
<h2 id="Tipping-Point-Forecasting-in-Non-Stationary-Dynamics-on-Function-Spaces"><a href="#Tipping-Point-Forecasting-in-Non-Stationary-Dynamics-on-Function-Spaces" class="headerlink" title="Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces"></a>Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08794">http://arxiv.org/abs/2308.08794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Liu-Schiaffini, Clare E. Singer, Nikola Kovachki, Tapio Schneider, Kamyar Azizzadenesheli, Anima Anandkumar</li>
<li>for: 本研究旨在预测非站立异常变化的演化，例如气候变化导致云覆盖减少的 climatological tipping point。</li>
<li>methods: 本研究使用一种新的循环神经网络算法（RNO）来学习函数空间的映射。通过训练 RNO 只使用前段动力学的数据，然后使用不确定性基于预测法来检测未来的至点。</li>
<li>results: 我们在非站立 ordinary 和 partial differential equations 上测试了我们的提议方法，并在气候至点预测中应用了我们的方法。我们的实验结果表明，即使只使用部分或 approximate physics constraints，仍可以准确预测未来的至点。<details>
<summary>Abstract</summary>
Tipping points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.
</details>
<details>
<summary>摘要</summary>
“衰点”是指不断、悬崖式、常常不可逆转变的非站点动力系统的演化。例如，增加绿house气体浓度可能导致低云覆盖率减少，这被称为气候学衰点。在这篇论文中，我们使用一种新的循环神经操作（RNO）来学习函数空间之间的映射。我们在只有前期衰点动力学的训练下使用RNO来检测未来衰点。特别是，我们提出了一种准确预测衰点的极限预测框架，通过监测物理约束（如保守量和部分偏微分方程）的偏差来预测这些急剧变化。我们在非站点常微分方程和部分偏微分方程中应用我们的方法，并在气候衰点中预测云层覆盖率的变化。在我们的实验中，我们表明了只需要部分或 aproximate的物理约束可以准确预测未来衰点。
</details></li>
</ul>
<hr>
<h2 id="Federated-Reinforcement-Learning-for-Electric-Vehicles-Charging-Control-on-Distribution-Networks"><a href="#Federated-Reinforcement-Learning-for-Electric-Vehicles-Charging-Control-on-Distribution-Networks" class="headerlink" title="Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks"></a>Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08792">http://arxiv.org/abs/2308.08792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junkai Qian, Yuning Jiang, Xin Liu, Qing Wang, Ting Wang, Yuanming Shi, Wei Chen<br>for: This paper aims to address the challenges of power grid stability and driver privacy in electric vehicle (EV) charging control by proposing a novel approach that combines multi-EV charging&#x2F;discharging with a radial distribution network (RDN) operating under optimal power flow (OPF).methods: The proposed approach uses a mathematical model to describe the RDN load and formulates the EV charging control problem as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. A federated deep reinforcement learning algorithm named FedSAC is further proposed to effectively learn the optimal EV charging control strategy.results: The comprehensive simulation results demonstrate the effectiveness and superiority of the proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.<details>
<summary>Abstract</summary>
With the growing popularity of electric vehicles (EVs), maintaining power grid stability has become a significant challenge. To address this issue, EV charging control strategies have been developed to manage the switch between vehicle-to-grid (V2G) and grid-to-vehicle (G2V) modes for EVs. In this context, multi-agent deep reinforcement learning (MADRL) has proven its effectiveness in EV charging control. However, existing MADRL-based approaches fail to consider the natural power flow of EV charging/discharging in the distribution network and ignore driver privacy. To deal with these problems, this paper proposes a novel approach that combines multi-EV charging/discharging with a radial distribution network (RDN) operating under optimal power flow (OPF) to distribute power flow in real time. A mathematical model is developed to describe the RDN load. The EV charging control problem is formulated as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. To effectively learn the optimal EV charging control strategy, a federated deep reinforcement learning algorithm named FedSAC is further proposed. Comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.
</details>
<details>
<summary>摘要</summary>
随着电动汽车（EV）的普及，维护电力网络稳定性已成为一个主要挑战。为解决这个问题，EV充电控制策略已被开发来管理电动汽车的充电和充电模式之间的转换。在这个上下文中，多代理深度学习（MADRL）已经证明其在EV充电控制中的效iveness。然而，现有的MADRL基本方法忽略了电动汽车充电/充电的自然流向和驾驶员隐私。为解决这些问题，本文提出了一种新的方法，即将多个电动汽车充电/充电与径向分布网络（RDN）在优化电力流动（OPF）下进行分布式充电控制。一个数学模型被开发来描述RDN负荷。EV充电控制问题被转化为Markov决策过程（MDP），以找到一个优化充电控制策略，折衔V2G利润、RDN负荷和驾驶员焦虑。为有效地学习优化EV充电控制策略，一种名为FedSAC的联邦深度学习算法被进一步提出。 comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.
</details></li>
</ul>
<hr>
<h2 id="APPFLx-Providing-Privacy-Preserving-Cross-Silo-Federated-Learning-as-a-Service"><a href="#APPFLx-Providing-Privacy-Preserving-Cross-Silo-Federated-Learning-as-a-Service" class="headerlink" title="APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service"></a>APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08786">http://arxiv.org/abs/2308.08786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilinghan Li, Shilan He, Pranshu Chaturvedi, Trung-Hieu Hoang, Minseok Ryu, E. A. Huerta, Volodymyr Kindratenko, Jordan Fuhrman, Maryellen Giger, Ryan Chard, Kibaek Kim, Ravi Madduri</li>
<li>for: 本研究旨在提供一个 Privacy-Preserving Federated Learning (PPFL) 平台，帮助无需分享敏感数据就可以协同训练 Robust 和 Generalized Machine Learning (ML) 模型。</li>
<li>methods: 本研究使用 Globus 身份验证技术，让用户轻松地邀请可靠的合作者参与 PPFL，并实现了一些同步和异步 Federated Learning (FL) 算法，简化了 FL 实验启动过程，并允许域专家和 ML 实践者轻松地协调和评估 cross-silo FL。</li>
<li>results: 本研究提供了一个名为 APPFLx 的ready-to-use 平台，可以帮助域专家和 ML 实践者轻松地使用 PPFL 技术进行数据 Privacy 保护和模型训练。APPFLx 在线可以在 <a target="_blank" rel="noopener" href="https://appflx.link/">https://appflx.link</a> 上查看。<details>
<summary>Abstract</summary>
Cross-silo privacy-preserving federated learning (PPFL) is a powerful tool to collaboratively train robust and generalized machine learning (ML) models without sharing sensitive (e.g., healthcare of financial) local data. To ease and accelerate the adoption of PPFL, we introduce APPFLx, a ready-to-use platform that provides privacy-preserving cross-silo federated learning as a service. APPFLx employs Globus authentication to allow users to easily and securely invite trustworthy collaborators for PPFL, implements several synchronous and asynchronous FL algorithms, streamlines the FL experiment launch process, and enables tracking and visualizing the life cycle of FL experiments, allowing domain experts and ML practitioners to easily orchestrate and evaluate cross-silo FL under one platform. APPFLx is available online at https://appflx.link
</details>
<details>
<summary>摘要</summary>
cross-silo隐私保护联合学习（PPFL）是一种强大的工具，可以无需分享敏感数据（如医疗或金融）来训练robust和通用机器学习（ML）模型。为了使PPFL更加容易采用，我们引入了APPFLx，一个快速启用的平台，提供隐私保护跨存储 Federated Learning（FL）服务。APPFLx使用Globus身份验证，让用户轻松地邀请可靠的合作者参与PPFL，实现了同步和异步FL算法，简化了FL实验启动过程，并允许域专家和机器学习实践者轻松地进行跨存储FL的导航和评估。APPFLx在线可以在https://appflx.link上访问。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer"><a href="#Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer" class="headerlink" title="Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer"></a>Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09724">http://arxiv.org/abs/2308.09724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyue Chen, Linian Wang, Jinyu Xu, Shuai Chen, Weiqiang Wang, Wenbiao Zhao, Qiyu Li, Leye Wang</li>
<li>for: 这篇论文是为了提出一个新的专门领域适应方法，以便在不同领域之间进行精确的预测。</li>
<li>methods: 这篇论文使用了一个名为“知识驱动的子领域适应”（KISA）的新方法，它可以在不同领域之间进行精确的预测。</li>
<li>results: 实验结果显示，KISA在骗案探测和交通需求预测等任务上取得了很好的结果。<details>
<summary>Abstract</summary>
Most state-of-the-art deep domain adaptation techniques align source and target samples in a global fashion. That is, after alignment, each source sample is expected to become similar to any target sample. However, global alignment may not always be optimal or necessary in practice. For example, consider cross-domain fraud detection, where there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may yield better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable such fine-grained domain adaption, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We provide the theoretical insight that KISA minimizes the shared expected loss which is the premise for the success of domain adaptation methods. (2) We propose the knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) We design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments demonstrate that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.
</details>
<details>
<summary>摘要</summary>
Current state-of-the-art deep domain adaptation methods align source and target samples globally, meaning that each source sample should become similar to any target sample after alignment. However, this global alignment may not always be optimal or necessary in practice. For example, in cross-domain fraud detection, there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may lead to better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable fine-grained domain adaptation, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. Specifically, (1) we provide theoretical insight that KISA minimizes the shared expected loss, which is the premise of domain adaptation methods. (2) we propose a knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) we design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments show that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.
</details></li>
</ul>
<hr>
<h2 id="Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning"><a href="#Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning" class="headerlink" title="Environment Diversification with Multi-head Neural Network for Invariant Learning"></a>Environment Diversification with Multi-head Neural Network for Invariant Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08778">http://arxiv.org/abs/2308.08778</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joe0123/EDNIL">https://github.com/joe0123/EDNIL</a></li>
<li>paper_authors: Bo-Wei Huang, Keng-Te Liao, Chang-Sheng Kao, Shou-De Lin</li>
<li>for: 提高模型对不同分布的鲁棒性</li>
<li>methods: 提出了一种基于多头神经网络吸收数据偏见的不变学习框架（EDNIL）</li>
<li>results: 实验表明，使用EDNIL框架可以提高模型对不同分布的鲁棒性，而无需先知环境或强ASSUMEptions about预训练模型。<details>
<summary>Abstract</summary>
Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.
</details>
<details>
<summary>摘要</summary>
神经网络经常使用隐式风险最小化进行训练;然而，已经证明了在训练和测试分布之间的偏移会导致性能下降。为解决这一问题，一种研究方向——抗变异学习——已经被提出，以抽取不受分布变化影响的特征。本研究提出了EDNIL框架，包括多头神经网络来吸收数据偏见。我们表明，这种框架不需要先知环境或强制假设先训练模型。我们还揭示了该算法与最近的研究中关于变异和不变特征的性质有许多理论连接。最后，我们实证表明使用EDNIL训练的模型在分布偏移下的表现更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models"><a href="#Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models" class="headerlink" title="Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models"></a>Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08774">http://arxiv.org/abs/2308.08774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phillip Rust, Anders Søgaard</li>
<li>for: 这些研究目的是为了实现多语言通用性和压缩，以便将模型转移到大量（可能未经见）语言中。</li>
<li>methods: 这些模型使用了 differential privacy，以保证隐私。</li>
<li>results: 研究发现，多语言压缩和语言公正性可以同时满足，但是对于训练数据的影响稀缺性和隐私保证之间存在矛盾。<details>
<summary>Abstract</summary>
Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual generalization or compression to facilitate transfer to a large number of (potentially unseen) languages. However, these models should ideally also be private, linguistically fair, and transparent, by relating their predictions to training data. Can these requirements be simultaneously satisfied? We show that multilingual compression and linguistic fairness are compatible with differential privacy, but that differential privacy is at odds with training data influence sparsity, an objective for transparency. We further present a series of experiments on two common NLP tasks and evaluate multilingual compression and training data influence sparsity under different privacy guarantees, exploring these trade-offs in more detail. Our results suggest that we need to develop ways to jointly optimize for these objectives in order to find practical trade-offs.
</details>
<details>
<summary>摘要</summary>
语模型如mBERT、XLM-R和BLOOM目的是实现多语言通用或压缩，以便转移至大量（可能未看过）语言。但这些模型应该也是私人、语言公平和透明的，通过与训练数据的关联来预测。可以这些需求同时满足吗？我们表明，多语言压缩和语言公平是与数据隐私相容的，但数据隐私与训练数据影响简洁矛盾。我们进一步对两个常见的NLP任务进行了试验，评估多语言压缩和训练数据影响简洁在不同的隐私保证下，进一步探索这些贸易的细节。我们的结果表明，我们需要开发方法来同时优化这些目标，以寻找实际的贸易。
</details></li>
</ul>
<hr>
<h2 id="Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving"><a href="#Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving" class="headerlink" title="Sensor Fusion by Spatial Encoding for Autonomous Driving"></a>Sensor Fusion by Spatial Encoding for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10707">http://arxiv.org/abs/2308.10707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quoc-Vinh Lai-Dang, Jihui Lee, Bumgeun Park, Dongsoo Har</li>
<li>for: 本研究旨在提出一种用于摄像头和激光雷达数据融合的方法，以提高自动驾驶和机器人感知系统的性能。</li>
<li>methods: 该方法使用Transformer模块在多个分辨率进行融合，以确保地面和高空的上下文关系的有效组合。</li>
<li>results: 对于两个难度最高的 benchmark，提出的方法在训练后显示出了明显的改善，与之前的方法相比，在驾驶和违法分数上分别提高8%和19%。<details>
<summary>Abstract</summary>
Sensor fusion is critical to perception systems for task domains such as autonomous driving and robotics. Recently, the Transformer integrated with CNN has demonstrated high performance in sensor fusion for various perception tasks. In this work, we introduce a method for fusing data from camera and LiDAR. By employing Transformer modules at multiple resolutions, proposed method effectively combines local and global contextual relationships. The performance of the proposed method is validated by extensive experiments with two adversarial benchmarks with lengthy routes and high-density traffics. The proposed method outperforms previous approaches with the most challenging benchmarks, achieving significantly higher driving and infraction scores. Compared with TransFuser, it achieves 8% and 19% improvement in driving scores for the Longest6 and Town05 Long benchmarks, respectively.
</details>
<details>
<summary>摘要</summary>
感知系统中的感知融合是自动驾驶和机器人等任务领域的关键技术。最近，由Transformer搭配CNN的方法在不同的感知任务中表现出了高水平的性能。在这篇文章中，我们介绍了一种将摄像头和LiDAR数据进行融合的方法。通过在多个分辨率下使用Transformer模块，我们的方法可以有效地组合本地和全局的contextual关系。我们的方法的性能被证明了通过对两个挑战性 benchmarks进行了广泛的实验。与之前的方法相比，我们的方法在 longest6和town05 Long benchmarks上的驾驶和违法分数都表现出了显著的提高，相比TransFuser，我们的方法在Longest6 benchmark上提高了8%和19%的驾驶分数。
</details></li>
</ul>
<hr>
<h2 id="Neurological-Prognostication-of-Post-Cardiac-Arrest-Coma-Patients-Using-EEG-Data-A-Dynamic-Survival-Analysis-Framework-with-Competing-Risks"><a href="#Neurological-Prognostication-of-Post-Cardiac-Arrest-Coma-Patients-Using-EEG-Data-A-Dynamic-Survival-Analysis-Framework-with-Competing-Risks" class="headerlink" title="Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks"></a>Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11645">http://arxiv.org/abs/2308.11645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobin Shen, Jonathan Elmer, George H. Chen<br>for: 这个研究旨在预测响心止痛后昏迷 patients的神经LOGICAL OUTCOMES，帮助医疗决策。methods: 该研究提出了基于EEG数据的神经LOGICAL PROGNOSIS的动态框架，可以随着更多的EEG数据得到更加准确的预测。该框架使用任何支持竞争风险的动态存存分析模型，并且可以针对不同的训练病人的可用EEG时间序列进行不同的预测。results: 研究发现，使用static特征和最新一小时的EEG数据的Fine和Gray模型在准确度上与使用大量EEG数据的Dynamic-DeepHit模型相当竞争，而且在减少模型简化后，三种竞争风险模型中的模型可以learn更多信息而且准确性至少相当。<details>
<summary>Abstract</summary>
Patients resuscitated from cardiac arrest who enter a coma are at high risk of death. Forecasting neurological outcomes of these patients (the task of neurological prognostication) could help with treatment decisions. In this paper, we propose, to the best of our knowledge, the first dynamic framework for neurological prognostication of post-cardiac-arrest comatose patients using EEG data: our framework makes predictions for a patient over time as more EEG data become available, and different training patients' available EEG time series could vary in length. Predictions are phrased in terms of either time-to-event outcomes (time-to-awakening or time-to-death) or as the patient's probability of awakening or of dying across multiple time horizons. Our framework uses any dynamic survival analysis model that supports competing risks in the form of estimating patient-level cumulative incidence functions. We consider three competing risks as to what happens first to a patient: awakening, being withdrawn from life-sustaining therapies (and thus deterministically dying), or dying (by other causes). We demonstrate our framework by benchmarking three existing dynamic survival analysis models that support competing risks on a real dataset of 922 patients. Our main experimental findings are that: (1) the classical Fine and Gray model which only uses a patient's static features and summary statistics from the patient's latest hour's worth of EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model that uses substantially more of the patient's EEG data; and (2) in an ablation study, we show that our choice of modeling three competing risks results in a model that is at least as accurate while learning more information than simpler models (using two competing risks or a standard survival analysis setup with no competing risks).
</details>
<details>
<summary>摘要</summary>
患者从心肺停止急救后入 coma 的风险很高，预测神经学结果可以帮助医疗决策。在这篇论文中，我们提出了，到目前为止最先进的动态推测框架，使用 EEG 数据预测患者后期神经学结果：我们的框架可以随着更多的 EEG 数据提供预测，不同的训练患者可以有不同的 EEG 时间序列长度。预测是基于时间到事件结果（时间到唤醒或时间到死亡）或患者在多个时间水平上的唤醒或死亡概率。我们的框架使用任何支持竞争风险的动态存生分析模型， estimate 患者级别累积发生函数。我们考虑了三种竞争风险：患者会于何时醒来，被撤销生命维持治疗（然后确定性死亡），或者死亡（由其他原因）。我们在实际数据集上进行了比较三种现有的动态存生分析模型，我们的主要实验结果是：（1）经典的 Fine 和 Gray 模型，只使用患者的静态特征和最近一小时的 EEG 数据，能够与最近开发的 Dynamic-DeepHit 模型匹配精度，而且（2）在剖析研究中，我们发现，我们选择了三种竞争风险的模型，可以提供至少相当精度的预测，同时学习更多的信息。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-for-tool-wear-prediction-in-turning"><a href="#Explainable-AI-for-tool-wear-prediction-in-turning" class="headerlink" title="Explainable AI for tool wear prediction in turning"></a>Explainable AI for tool wear prediction in turning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08765">http://arxiv.org/abs/2308.08765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saleh Valizadeh Sotubadi, Rui Liu, Vinh Neguyen<br>for: 这份研究旨在发展一个可解释人工智能（XAI）框架，以便为切割过程中工具损坏预测提供人类理解的解决方案。methods: 本研究使用了一个随机森林算法作为监督式机器学习（ML）分类器，并使用加速度、声学、温度和螺旋速度等参数进行训练和二分类 classification。results: 经过训练后，使用了Shapley准则来解释训练好的ML分类器预测的结果，并确定工具温度是决定切割工具可用或失效的最重要的输入参数。因此，本研究显示了XAI可以提供磨削操作员诊断和理解复杂的ML分类器预测工具损坏的能力。<details>
<summary>Abstract</summary>
This research aims develop an Explainable Artificial Intelligence (XAI) framework to facilitate human-understandable solutions for tool wear prediction during turning. A random forest algorithm was used as the supervised Machine Learning (ML) classifier for training and binary classification using acceleration, acoustics, temperature, and spindle speed during the orthogonal tube turning process as input features. The ML classifier was used to predict the condition of the tool after the cutting process, which was determined in a binary class form indicating if the cutting tool was available or failed. After the training process, the Shapley criterion was used to explain the predictions of the trained ML classifier. Specifically, the significance of each input feature in the decision-making and classification was identified to explain the reasoning of the ML classifier predictions. After implementing the Shapley criterion on all testing datasets, the tool temperature was identified as the most significant feature in determining the classification of available versus failed cutting tools. Hence, this research demonstrates capability of XAI to provide machining operators the ability to diagnose and understand complex ML classifiers in prediction of tool wear.
</details>
<details>
<summary>摘要</summary>
After training the ML classifier, the Shapley criterion was used to explain the predictions. Specifically, the significance of each input feature in the decision-making and classification was identified to explain the reasoning behind the ML classifier's predictions. The results showed that tool temperature was the most significant feature in determining the classification of available versus failed cutting tools.This research demonstrates the capability of XAI to provide machining operators with the ability to diagnose and understand complex ML classifiers in predicting tool wear. By using the Shapley criterion to explain the predictions, the research provides a human-understandable explanation of the decision-making process, allowing operators to better understand and trust the ML classifier's predictions.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Commercial-Bank-Customer-Credit-Risk-Assessment-Based-on-LightGBM-and-Feature-Engineering"><a href="#Efficient-Commercial-Bank-Customer-Credit-Risk-Assessment-Based-on-LightGBM-and-Feature-Engineering" class="headerlink" title="Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering"></a>Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08762">http://arxiv.org/abs/2308.08762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanjie Sun, Zhike Gong, Quan Shi, Lin Chen</li>
<li>for: 本研究主要是为了帮助商业银行控制债务风险，通过使用LightGBM算法建立分类器，判断客户是否有可能 Default on 债务。</li>
<li>methods: 本研究使用了LightGBM算法，并进行了特征工程，如处理缺失值、编码、不均衡样本等，以提高机器学习效果。</li>
<li>results: 本研究构建了新的特征属性，使得分类器的准确率达到0.734，AUC达到0.772，超过了基于同一数据集的许多分类器。这些结果可以为商业银行的债务授予提供参考，也可以为其他相似研究提供特征处理的想法。<details>
<summary>Abstract</summary>
Effective control of credit risk is a key link in the steady operation of commercial banks. This paper is mainly based on the customer information dataset of a foreign commercial bank in Kaggle, and we use LightGBM algorithm to build a classifier to classify customers, to help the bank judge the possibility of customer credit default. This paper mainly deals with characteristic engineering, such as missing value processing, coding, imbalanced samples, etc., which greatly improves the machine learning effect. The main innovation of this paper is to construct new feature attributes on the basis of the original dataset so that the accuracy of the classifier reaches 0.734, and the AUC reaches 0.772, which is more than many classifiers based on the same dataset. The model can provide some reference for commercial banks' credit granting, and also provide some feature processing ideas for other similar studies.
</details>
<details>
<summary>摘要</summary>
效果控制信贷风险是商业银行稳定运营的关键链接。本文主要基于一家外国商业银行的客户信息数据集在Kaggle上，使用LightGBM算法建立分类器，以帮助银行判断客户债务 default 的可能性。本文主要关注特征工程，如排除 missing value、编码、不均衡样本等，这些改进了机器学习效果。本文的主要创新在于在原始数据集基础上构建新的特征属性，使分类器的准确率达0.734，AUC达0.772，超过了同基据集上的许多分类器。该模型可以为商业银行债务赐与提供参考，同时也可以为其他相似研究提供特征处理的想法。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="PMET-Precise-Model-Editing-in-a-Transformer"><a href="#PMET-Precise-Model-Editing-in-a-Transformer" class="headerlink" title="PMET: Precise Model Editing in a Transformer"></a>PMET: Precise Model Editing in a Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08742">http://arxiv.org/abs/2308.08742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xpq-tech/pmet">https://github.com/xpq-tech/pmet</a></li>
<li>paper_authors: Xiaopeng Li, Shasha Li, Shezheng Song, Jing Yang, Jun Ma, Jie Yu</li>
<li>for: 提高模型编辑技术的性能，减少模型更新的成本。</li>
<li>methods: 分析隐藏状态的多头自注意力（MHSA）和循环神经网络（FFN），并同时优化它们的隐藏状态，以便准确地更新FFN的参数。</li>
<li>results: 在COUNTERFACT和zsRE dataset上达到了state-of-the-art的性能。<details>
<summary>Abstract</summary>
Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we introduce PMET, which simultaneously optimizes Transformer Component (TC, namely MHSA and FFN) hidden states, while only using the optimized TC hidden states of FFN to precisely update FFN weights. Our experiments demonstrate that PMET exhibits state-of-the-art performance on both the COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the effectiveness of our enhancements, further reinforcing the finding that the MHSA encodes certain general knowledge extraction patterns and indicating its storage of a small amount of factual knowledge. Our code is available at https://github.com/xpq-tech/PMET.git.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的修改技术可以轻松地修改一小部分知识，并且已经获得了可观的成功。现有的方法假设transformer层（TL）的隐藏状态是Feed-Forward Network（FFN）中的钥匙值内存。它们通常将TL隐藏状态优化为记忆target知识，并使用这些TL隐藏状态来更新FFN的重量。但是，TL隐藏状态的信息来源来自三个部分：多头自我对话（MHSA）、FFN和复合连接。现有的方法忽略了TL隐藏状态中包含的信息不是FFN特定所需的。因此，模型修改的性能受到影响。为了更精确地进行模型修改，我们进行了隐藏状态分析，发现MHSA对于某些一般知识提取模式具有编码功能。这意味着MHSA的重量不需要更新当新知识引入。基于以上发现，我们提出了PMET，它同时优化transformer ком ponent（TC，即MHSA和FFN）的隐藏状态，仅使用优化TC隐藏状态的FFN来精确地更新FFN的重量。我们的实验显示PMET在COUNTERFACT和zsRE datasets上展示了顶尖的表现。我们的剥离实验证明了我们的改进的有效性，进一步证明MHSA对于一些一般知识提取模式具有编码功能，并且它储存了一小部分的事实知识。我们的代码可以在https://github.com/xpq-tech/PMET.git中找到。
</details></li>
</ul>
<hr>
<h2 id="ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents"><a href="#ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents" class="headerlink" title="ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents"></a>ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08737">http://arxiv.org/abs/2308.08737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tejaswini Manjunath, Mozhgan Navardi, Prakhar Dixit, Bharat Prakash, Tinoosh Mohsenin</li>
<li>for: 本研究旨在提出一种能够在实际世界中进行多目标导航的彩虹RL算法，以提高现有RL算法在实际环境中的适用性。</li>
<li>methods: 该方法利用了彩虹RL算法，并在训练过程中使用了对象检测器作为预处理步骤，以学习多目标导航并在实际世界中传递。</li>
<li>results: 实验结果显示，提出的Ready for Production Hierarchical RL（ReProHRL）方法在模拟环境和真实世界环境中都有较好的性能，比基eline方法提高18%和5%。<details>
<summary>Abstract</summary>
Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigation, in a more complex environment and multi-goal setting, the proposed method outperforms the baseline by 18% and 5%, respectively. For the real-world implementation and proof of concept demonstration, we deploy the proposed method on a nano-drone named Crazyflie with a front camera to perform multi-goal navigation experiments.
</details>
<details>
<summary>摘要</summary>
роботы已经成功地完成了高精度任务。在实际环境中，受限回报和多个目标是学习的主要挑战，并且使用强化学习（RL）算法学习良好策略仍然是一个挑战。训练在模拟环境中并在实际环境中细化是一个常见的方法。然而，适应实际环境的挑战仍然存在。在这篇论文中，我们提出了一种名为Ready for Production Hierarchical RL（ReProHRL）的方法，该方法将任务分解为层次多目标导航，并使用强化学习来导航。我们还使用对象检测器作为预处理步骤，以学习多目标导航并将其转移到实际世界。我们的实验结果表明，提议的ReProHRL方法在模拟环境和实际世界环境中都能够超越基准值。虽然两个方法在简单环境中完成单目标导航时都达到100%的成功率，但在更复杂的环境和多目标设定下，提议的方法在基准值的18%和5%之上。为了证明实际应用和概念示范，我们在一架名为Crazyflie的奈米飞行器上部署了提议的方法，并使用前置摄像头完成多目标导航实验。
</details></li>
</ul>
<hr>
<h2 id="On-the-Effectiveness-of-Log-Representation-for-Log-based-Anomaly-Detection"><a href="#On-the-Effectiveness-of-Log-Representation-for-Log-based-Anomaly-Detection" class="headerlink" title="On the Effectiveness of Log Representation for Log-based Anomaly Detection"></a>On the Effectiveness of Log Representation for Log-based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08736">http://arxiv.org/abs/2308.08736</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mooselab/suppmaterial-logrepforanomalydetection">https://github.com/mooselab/suppmaterial-logrepforanomalydetection</a></li>
<li>paper_authors: Xingfang Wu, Heng Li, Foutse Khomh</li>
<li>for: 本研究旨在比较常用的日志表示技术，以便选择最适合自动日志分析过程中的日志表示技术。</li>
<li>methods: 本研究使用了六种日志表示技术，并与七种机器学习模型和四个公共日志集（HDFS、BGL、Spirit和Thunderbird）进行了比较。</li>
<li>results: 实验结果显示，不同的日志表示技术对下游模型的性能产生了不同的影响，并提供了一些启示式指南 для未来的研究人员和开发者。<details>
<summary>Abstract</summary>
Logs are an essential source of information for people to understand the running status of a software system. Due to the evolving modern software architecture and maintenance methods, more research efforts have been devoted to automated log analysis. In particular, machine learning (ML) has been widely used in log analysis tasks. In ML-based log analysis tasks, converting textual log data into numerical feature vectors is a critical and indispensable step. However, the impact of using different log representation techniques on the performance of the downstream models is not clear, which limits researchers and practitioners' opportunities of choosing the optimal log representation techniques in their automated log analysis workflows. Therefore, this work investigates and compares the commonly adopted log representation techniques from previous log analysis research. Particularly, we select six log representation techniques and evaluate them with seven ML models and four public log datasets (i.e., HDFS, BGL, Spirit and Thunderbird) in the context of log-based anomaly detection. We also examine the impacts of the log parsing process and the different feature aggregation approaches when they are employed with log representation techniques. From the experiments, we provide some heuristic guidelines for future researchers and developers to follow when designing an automated log analysis workflow. We believe our comprehensive comparison of log representation techniques can help researchers and practitioners better understand the characteristics of different log representation techniques and provide them with guidance for selecting the most suitable ones for their ML-based log analysis workflow.
</details>
<details>
<summary>摘要</summary>
ilog文件是软件系统运行状况的重要来源信息。由于现代软件架构和维护方法不断演化，更多的研究努力被投入到自动化log分析领域。特别是机器学习（ML）在log分析任务中得到了广泛的应用。在ML基于log分析任务中，将文本log数据转化为数字特征向量是一项关键和不可或缺的步骤。然而，使用不同的log表示技术对下游模型的性能的影响并不清晰，这限制了研究人员和实践者在自动化log分析 workflow中选择最佳log表示技术的机会。因此，本工作调查和比较了过去的log分析研究中广泛采用的log表示技术。特别是我们选择了六种log表示技术，并与七种ML模型和四个公共log数据集（即HDFS、BGL、Spirit和Thunderbird）进行了在log基于异常检测中的评估。我们还考虑了在log解析过程和不同的特征聚合方法被采用时的影响。从实验结果来看，我们提供了一些启示性的指南，以帮助未来的研究人员和开发者在设计自动化log分析 workflow时采取更好的决策。我们认为我们的全面的log表示技术比较可以帮助研究人员和实践者更好地了解不同log表示技术的特点，并为他们选择最适合的一种。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing"><a href="#A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing" class="headerlink" title="A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing"></a>A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10869">http://arxiv.org/abs/2308.10869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nibraas Khan, Mahrukh Tauseef, Ritam Ghosh, Nilanjan Sarkar</li>
<li>For: The paper aims to improve the accuracy of emotion detection using deep learning techniques and physiological data.* Methods: The proposed cost function employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data and reduce the impact of subject-dependent noise.* Results: The proposed cost function outperforms a state-of-the-art loss function (Mean Squared Error) across four commonly used datasets, with an average increase of 14.75% and 17.75% in minimum and centroid euclidean distance, respectively.<details>
<summary>Abstract</summary>
Emotions are an essential part of human behavior that can impact thinking, decision-making, and communication skills. Thus, the ability to accurately monitor and identify emotions can be useful in many human-centered applications such as behavioral training, tracking emotional well-being, and development of human-computer interfaces. The correlation between patterns in physiological data and affective states has allowed for the utilization of deep learning techniques which can accurately detect the affective states of a person. However, the generalisability of existing models is often limited by the subject-dependent noise in the physiological data due to variations in a subject's reactions to stimuli. Hence, we propose a novel cost function that employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise. The performance of the proposed cost function is demonstrated through an autoencoder with a multi-class classifier attached to the latent space and trained simultaneously to detect different affective states. An autoencoder with a state-of-the-art loss function i.e., Mean Squared Error, is used as a baseline for comparison with our model across four different commonly used datasets. Centroid and minimum distance between different classes are used as a metrics to indicate the separation between different classes in the latent space. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum and centroid euclidean distance respectively over all datasets.
</details>
<details>
<summary>摘要</summary>
人类行为中的情感是一个重要的部分，可以影响思维、决策和communication技能。因此，能够准确识别和评估情感的能力可以在许多人类中心应用中发挥作用，如行为训练、情感健康评估和人机界面开发。通过physiological数据中的模式和情感状态之间的相关性，使用深度学习技术可以准确检测人类情感状态。然而，现有模型的泛化能力 oft limited by subject-dependent noise in physiological data due to variations in a subject's reactions to stimuli。因此，我们提出了一个新的成本函数，利用Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise。我们的模型在四个常用的数据集上进行了评估，并与使用 Mean Squared Error 的基eline模型进行比较。中心和最小距离between different classes在latent space中用来衡量不同类别之间的分离度。在所有数据集上，我们发现了平均增加14.75%和17.75%（从基eline到我们的损失函数）的 minimum和centroid Euclidean distance。
</details></li>
</ul>
<hr>
<h2 id="Synergistic-Signal-Denoising-for-Multimodal-Time-Series-of-Structure-Vibration"><a href="#Synergistic-Signal-Denoising-for-Multimodal-Time-Series-of-Structure-Vibration" class="headerlink" title="Synergistic Signal Denoising for Multimodal Time Series of Structure Vibration"></a>Synergistic Signal Denoising for Multimodal Time Series of Structure Vibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11644">http://arxiv.org/abs/2308.11644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Yu, Han Chen</li>
<li>for: 这篇论文的目的是提出一种基于深度学习的Structural Health Monitoring（SHM）方法，以实现基础设施的longevity和安全性。</li>
<li>methods: 这篇论文使用了一种混合了卷积和回归架构的深度学习算法，以捕捉多 modal vibration signals 中的 Complexity。另外，这篇论文还使用了注意力机制，以优化模型的准确性和适应能力。</li>
<li>results: 这篇论文的结果显示了这种方法在多个 SHM enario 中的预测精度和早期损坏探测得到了明显提高，同时也提供了更加透明和可解释的 AI-driven SHM 解决方案。<details>
<summary>Abstract</summary>
Structural Health Monitoring (SHM) plays an indispensable role in ensuring the longevity and safety of infrastructure. With the rapid growth of sensor technology, the volume of data generated from various structures has seen an unprecedented surge, bringing forth challenges in efficient analysis and interpretation. This paper introduces a novel deep learning algorithm tailored for the complexities inherent in multimodal vibration signals prevalent in SHM. By amalgamating convolutional and recurrent architectures, the algorithm adeptly captures both localized and prolonged structural behaviors. The pivotal integration of attention mechanisms further enhances the model's capability, allowing it to discern and prioritize salient structural responses from extraneous noise. Our results showcase significant improvements in predictive accuracy, early damage detection, and adaptability across multiple SHM scenarios. In light of the critical nature of SHM, the proposed approach not only offers a robust analytical tool but also paves the way for more transparent and interpretable AI-driven SHM solutions. Future prospects include real-time processing, integration with external environmental factors, and a deeper emphasis on model interpretability.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)structural health monitoring (SHM) 在保证基础设施的寿命和安全方面发挥不可或缺的作用。随着感知技术的快速发展，来自不同结构的感知数据量有历史上前所未有的增长，这带来了分析和解释数据的挑战。本文介绍了一种适应 multimodal 振荡信号的深度学习算法。通过将卷积和回归架构融合起来，该算法可以fficiently 捕捉结构的本地和持续行为。另外，通过集成注意机制，该算法可以更好地异化和优化结构的响应。我们的结果表明，该算法可以在多个 SHM 场景中提供显著提高的预测精度、早期损害检测和适应性。鉴于 SHM 的重要性，我们的方法不仅提供了一种可靠的分析工具，还开创了更加透明和可解释的 AI-驱动 SHM 解决方案。未来的发展方向包括实时处理、与外部环境因素集成以及更深入的模型解释性。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Neural-Network-is-All-You-Need-Understanding-the-Robustness-of-Dynamic-Mechanisms-in-Neural-Networks"><a href="#Dynamic-Neural-Network-is-All-You-Need-Understanding-the-Robustness-of-Dynamic-Mechanisms-in-Neural-Networks" class="headerlink" title="Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks"></a>Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08709">http://arxiv.org/abs/2308.08709</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous2015258/Early_Attack">https://github.com/anonymous2015258/Early_Attack</a></li>
<li>paper_authors: Mirazul Haque, Wei Yang</li>
<li>for: 本研究旨在 investigate 动态神经网络（DyNNs）中动态机制的稳定性影响和如何通过设计选择来提高 DyNNs 的稳定性。</li>
<li>methods: 本研究使用三个模型和两个数据集来评估动态机制在 DyNNs 中的影响。我们采用了多种攻击方法来评估动态机制的影响，包括转移攻击和生成攻击。</li>
<li>results: 我们发现，从 DyNNs 到 SDNNs 的攻击传递率高于从 SDNNs 到 DyNNs 的攻击传递率。此外，我们发现 DyNNs 可以更有效地生成攻击样本than SDNNs。最后，我们通过研究来提供设计选择来提高 DyNNs 对攻击的抵抗力。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) have been used to solve different day-to-day problems. Recently, DNNs have been deployed in real-time systems, and lowering the energy consumption and response time has become the need of the hour. To address this scenario, researchers have proposed incorporating dynamic mechanism to static DNNs (SDNN) to create Dynamic Neural Networks (DyNNs) performing dynamic amounts of computation based on the input complexity. Although incorporating dynamic mechanism into SDNNs would be preferable in real-time systems, it also becomes important to evaluate how the introduction of dynamic mechanism impacts the robustness of the models. However, there has not been a significant number of works focusing on the robustness trade-off between SDNNs and DyNNs. To address this issue, we propose to investigate the robustness of dynamic mechanism in DyNNs and how dynamic mechanism design impacts the robustness of DyNNs. For that purpose, we evaluate three research questions. These evaluations are performed on three models and two datasets. Through the studies, we find that attack transferability from DyNNs to SDNNs is higher than attack transferability from SDNNs to DyNNs. Also, we find that DyNNs can be used to generate adversarial samples more efficiently than SDNNs. Then, through research studies, we provide insight into the design choices that can increase robustness of DyNNs against the attack generated using static model. Finally, we propose a novel attack to understand the additional attack surface introduced by the dynamic mechanism and provide design choices to improve robustness against the attack.
</details>
<details>
<summary>摘要</summary>
深度神经网络 (DNNs) 已经用于解决不同的日常问题。近些年，DNNs 已经在实时系统中部署，降低能耗和响应时间已成为当务之急。为了解决这种情况，研究人员已经提议将静态神经网络 (SDNNs) 转换成动态神经网络 (DyNNs)，以进行动态量的计算基于输入复杂性。虽然将动态机制添加到 SDNNs 可以在实时系统中提高性能，但也需要评估这种变化对模型的稳定性的影响。然而，有很少的研究集中注意到 SDNNs 和 DyNNs 之间的稳定性质量。为了解决这个问题，我们提出了三个研究问题，并对三种模型和两个数据集进行评估。我们发现，从 DyNNs 到 SDNNs 的攻击传播率高于从 SDNNs 到 DyNNs 的攻击传播率。此外，我们发现 DyNNs 可以更有效地生成黑客样本。然后，通过研究，我们提供了一些设计选择，可以增强 DyNNs 对攻击的抵御力。最后，我们提出了一种新的攻击方法，以评估动态机制引入的额外攻击表面，并提供了一些设计选择，可以提高 DyNNs 对攻击的抵御力。
</details></li>
</ul>
<hr>
<h2 id="Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness"><a href="#Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness" class="headerlink" title="Consciousness in Artificial Intelligence: Insights from the Science of Consciousness"></a>Consciousness in Artificial Intelligence: Insights from the Science of Consciousness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08708">http://arxiv.org/abs/2308.08708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Butlin, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, Stephen M. Fleming, Chris Frith, Xu Ji, Ryota Kanai, Colin Klein, Grace Lindsay, Matthias Michel, Liad Mudrik, Megan A. K. Peters, Eric Schwitzgebel, Jonathan Simon, Rufin VanRullen</li>
<li>for: 本文提出了一种rigorous和empirically grounded的方法来评估现代AI系统是否具备意识，并根据我们最好支持的神经科学理论来评估AI系统的意识性。</li>
<li>methods: 本文首先介绍了一些主流的科学理论，包括回卷处理理论、全局工作空间理论、更高级理论、预测处理理论和注意schema理论，然后从这些理论中提取了”指标属性”，这些属性可以用计算机科学的语言来评估AI系统是否满足这些指标。</li>
<li>results: 本文对一些最新的AI系统进行了评估，并发现现在的AI系统没有意识性，但也没有显而出技术障碍建立意识AI系统。<details>
<summary>Abstract</summary>
Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive "indicator properties" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.
</details>
<details>
<summary>摘要</summary>
当前或近期的人工智能系统是科学兴趣和公众关注的话题。本报告强调和证明了一种严谨和基于实验的AI意识方法：通过评估现有AI系统，以及我们最好支持的神经科学理论来评估AI意识。我们对多种知名的科学理论进行了survey，包括回propagation理论、全球工作区理论、更高级理论、预测处理理论和注意schema理论。从这些理论中，我们得出了"指标性质"的 consciousness，并将其转化为计算机科学中的形式，以评估AI系统是否满足这些指标。我们对多个最新的AI系统进行了评估，并讨论了未来系统如何实现这些指标。我们的分析结果表明，目前没有任何AI系统具备意识，但也没有明显的技术障碍建立具备这些指标的AI系统。
</details></li>
</ul>
<hr>
<h2 id="FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs"><a href="#FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs" class="headerlink" title="FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs"></a>FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09723">http://arxiv.org/abs/2308.09723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Jin Kim, Rawn Henry, Raffy Fahim, Hany Hassan Awadalla<br>for: 这个研究是为了提高大型语言模型（LLMs）的实际部署，因为它们需要很大的内存。methods: 我们提出了一种高效的量化方法，可以降低内存consumption和加速LLMs的测试过程。我们还提出了一个简单且有效的规律，可以在无需调整的情况下保持模型质量。results: 我们的方法可以在大规模的开源模型，如 OPT-175B 和内部MoE模型上，实现最小的精度损失，同时获得最多3.65倍的通过率。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto-regressive decoding process. To address these issues, we propose an efficient weight-only quantization method that reduces memory consumption and accelerates inference for LLMs. To ensure minimal quality degradation, we introduce a simple and effective heuristic approach that utilizes only the model weights of a pre-trained model. This approach is applicable to both Mixture-of-Experts (MoE) and dense models without requiring additional fine-tuning. To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of quantization, effectively addressing these problems. Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly matrix multiplication and dequantization, supporting the multiplication of fp16 or bf16 activations with int8 or int4 weights. We evaluate our approach on large-scale open source models such as OPT-175B and internal MoE models, showcasing minimal accuracy loss while achieving up to 3.65 times higher throughput on the same number of GPUs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经在不同的语言任务上达到了现场的表现水准，但是它们在实际应用中受到了内存需求的挑战。另外，最新的生成模型受到了自动预测过程中的内存带宽瓶须的高处理成本的影响。为了解决这些问题，我们提出了一种高效的量化方法，可以降低内存消耗和加速 LLM 的测试。我们还提出了一个简单而有效的规则，可以在不需要进一步微调的情况下，将模型精度降至最低。这个方法适用于内部的 Mixture-of-Experts（MoE）和稠密模型。我们还实现了高效的 GPU GEMM，可以在线进行矩阵乘法和量化，支持对 fp16 或 bf16 的激活值进行 int8 或 int4 的重量量化。我们将这个方法应用于 OPT-175B 和内部的 MoE 模型，展示了最小的准确度损失，同时可以在相同的 GPU 上 Achieve 3.65 倍的运算速度。
</details></li>
</ul>
<hr>
<h2 id="Partially-Observable-Multi-agent-RL-with-Quasi-Efficiency-The-Blessing-of-Information-Sharing"><a href="#Partially-Observable-Multi-agent-RL-with-Quasi-Efficiency-The-Blessing-of-Information-Sharing" class="headerlink" title="Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing"></a>Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08705">http://arxiv.org/abs/2308.08705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Liu, Kaiqing Zhang</li>
<li>for: This paper focuses on developing a sample- and computation-efficient partially observable multi-agent reinforcement learning (MARL) algorithm in the general framework of partially observable stochastic games (POSGs).</li>
<li>methods: The authors propose leveraging information-sharing among agents and approximating the shared common information to construct an approximate model of the POSG, which enables quasi-efficient planning and solving of the original POSG.</li>
<li>results: The proposed algorithm is both statistically and computationally quasi-efficient, and the authors hope that their study may open up possibilities for leveraging and designing different information structures for developing sample- and computation-efficient partially observable MARL.<details>
<summary>Abstract</summary>
We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study may open up the possibilities of leveraging and even designing different \emph{information structures}, for developing both sample- and computation-efficient partially observable MARL.
</details>
<details>
<summary>摘要</summary>
我们研究可证明多智能 reinforcement learning（MARL）的通用框架中的部分可见随机游戏（POSG）。为了绕过已知的困难性和使用计算量卷积的执行器，我们建议利用智能之间的信息共享，这是现实中的多智能控制系统通信的标准模型。我们首先确立了一些计算复杂性结论，以 justify 信息共享的必要性，以及在部分观察下的可见性假设，这使得单机RL可以有效地解决POSG。然后，我们提议使用approximate shared common information来构建一个approximate模型，在该模型中，计划一个近似平衡（在原POSG中解决）可以在可证明的时间内完成，即 quasi-polynomial-time。此外，我们开发了一种部分可见MARL算法，该算法同时具备了统计学和计算学的 quasi-有效性。我们希望我们的研究可以开拓出不同的信息结构，以开发更高效的部分可见MARL算法。
</details></li>
</ul>
<hr>
<h2 id="Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces"><a href="#Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces" class="headerlink" title="Planning in the imagination: High-level planning on learned abstract search spaces"></a>Planning in the imagination: High-level planning on learned abstract search spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08693">http://arxiv.org/abs/2308.08693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Martin, Tuomas Sandholm</li>
<li>for: 该论文旨在提供一种新的规划方法，叫做PiZero，可以让代理人在自己创造的抽象搜索空间中进行规划，完全与实际环境解耦。</li>
<li>methods: 该方法不同于先前的方法，可以在任意时间尺度和基础级微动作数量的情况下进行高级规划，并且可以处理连续动作空间和部分可见性的情况。</li>
<li>results: 在多个领域中进行实验，该方法与相似的先前方法进行比较，达到更高的性能，而不需要访问环境模拟器。<details>
<summary>Abstract</summary>
We propose a new method, called PiZero, that gives an agent the ability to plan in an abstract search space of its own creation that is completely decoupled from the real environment. Unlike prior approaches, this enables the agent to perform high-level planning at arbitrary timescales and reason in terms of compound or temporally-extended actions, which can be useful in environments where large numbers of base-level micro-actions are needed to perform relevant macro-actions. In addition, our method is more general than comparable prior methods because it handles settings with continuous action spaces and partial observability. We evaluate our method on multiple domains, including navigation tasks and Sokoban. Experimentally, it outperforms comparable prior methods without assuming access to an environment simulator.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新方法，叫做PiZero，它让代理人能够在自己创建的抽象搜索空间中进行规划，完全与真实环境分离。与先前的方法不同，这使得代理人可以在任意时间尺度上进行高级规划，并在基础级微动作的批量进行复杂或时间扩展的动作，这可以在环境中需要大量基础级微动作来完成重要的macro动作时是有用的。此外，我们的方法更加通用于先前的方法，因为它处理了连续动作空间和部分可见性的设置。我们在多个领域进行了实验，包括导航任务和Sokoban，并证明了我们的方法在相对先前方法无需访问环境模拟器的情况下表现出色。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Overfitting-Introducing-the-Overfitting-Index"><a href="#Quantifying-Overfitting-Introducing-the-Overfitting-Index" class="headerlink" title="Quantifying Overfitting: Introducing the Overfitting Index"></a>Quantifying Overfitting: Introducing the Overfitting Index</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08682">http://arxiv.org/abs/2308.08682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass</li>
<li>for: 本研究旨在提供一个量化评估模型过拟合情况的度量，以便提高机器学习模型在实际应用中的可靠性。</li>
<li>methods: 本研究使用了一个新的度量方法—Overfitting Index（OI），通过实验显示了OI的有用性和显著性。</li>
<li>results: 研究结果显示，不同架构在不同数据集上的过拟合情况有很大差异，而资料增强对小型特殊数据集的影响特别明显。此外，ViT-32在MNIST数据集上的表现也显示了某些模型和数据集之间的具体关系。<details>
<summary>Abstract</summary>
In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising avenue to advance model optimization and ensure real-world efficacy.
</details>
<details>
<summary>摘要</summary>
在机器学习领域中，确保模型通用性是一项核心挑战。过拟合，其中模型在训练数据上表现出色但在未见数据上表现不佳，是一个常见问题。这篇论文介绍了一种新的度量方法——过拟合指数（OI），用于评估模型过拟合的倾向。通过对Breast Ultrasound Images Dataset（BUS）和MNIST dataset上的多种架构（如MobileNet、U-Net、ResNet、Darknet和ViT-32）进行了广泛的实验，我们示出了OI的实用性和分辨率。我们的结果表明不同的架构之间存在变化的过拟合行为，并且数据扩展尤其是在小型特定数据集上具有缓解作用。ViT-32在MNIST上的表现更加强调了某些模型的稳定性和数据集的全面性。通过提供一个对过拟合进行对象评估的途径，OI提供了一个有前途的方法，以确保模型在实际应用中的有效性。
</details></li>
</ul>
<hr>
<h2 id="SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification"><a href="#SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification" class="headerlink" title="SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification"></a>SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08669">http://arxiv.org/abs/2308.08669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Longman-Stan/SkinDistilVit">https://github.com/Longman-Stan/SkinDistilVit</a></li>
<li>paper_authors: Vlad-Constantin Lungu-Stan, Dumitru-Clementin Cercel, Florin Pop</li>
<li>for: 这个研究旨在提供一个基于 transformer 的 skin cancer 分类方案，可以匹配人工智能的 melanoma 识别精度。</li>
<li>methods: 研究人员使用 knowledge distillation 技术来训练一个基于 transformer 的模型，并在模型中添加多个分类头来提高分类精度。</li>
<li>results: 模型可以匹配教师模型的精度（98.33%），并且在时间和内存方面具有较好的性能（69.25%  faster on GPU、97.96% faster on CPU）。<details>
<summary>Abstract</summary>
Skin cancer is a treatable disease if discovered early. We provide a production-specific solution to the skin cancer classification problem that matches human performance in melanoma identification by training a vision transformer on melanoma medical images annotated by experts. Since inference cost, both time and memory wise is important in practice, we employ knowledge distillation to obtain a model that retains 98.33% of the teacher's balanced multi-class accuracy, at a fraction of the cost. Memory-wise, our model is 49.60% smaller than the teacher. Time-wise, our solution is 69.25% faster on GPU and 97.96% faster on CPU. By adding classification heads at each level of the transformer and employing a cascading distillation process, we improve the balanced multi-class accuracy of the base model by 2.1%, while creating a range of models of various sizes but comparable performance. We provide the code at https://github.com/Longman-Stan/SkinDistilVit.
</details>
<details>
<summary>摘要</summary>
皮肤癌是一种可治疗的疾病，如果早期发现。我们提供了一种特定于生产的解决方案，用于皮肤癌类型分类问题，与专家标注的医疗图像进行匹配。由于实际应用中的推理成本（时间和内存）非常重要，我们使用知识储存技术来获得一个保留98.33%的教师平衡多类准确率的模型，而且内存占用量为49.60%，时间占用量为69.25%和97.96%。通过在转换器中添加分类头和使用层次分类处理，我们提高了基本模型的平衡多类准确率2.1%，同时创造了不同大小的模型，但具有相同性能。我们提供了代码，可以在 GitHub上找到：https://github.com/Longman-Stan/SkinDistilVit。
</details></li>
</ul>
<hr>
<h2 id="BREATHE-Second-Order-Gradients-and-Heteroscedastic-Emulation-based-Design-Space-Exploration"><a href="#BREATHE-Second-Order-Gradients-and-Heteroscedastic-Emulation-based-Design-Space-Exploration" class="headerlink" title="BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration"></a>BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08666">http://arxiv.org/abs/2308.08666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikhar Tuli, Niraj K. Jha</li>
<li>for: 这个研究的目的是提出一个受限制的多目标优化（MOO）框架，以便在各种科学研究和物理实验中更好地探索和观察新的设计样本。</li>
<li>methods: 这个框架使用了第二项Gradient和异escaled对应模型来实现样本有效的优化。</li>
<li>results: 在单一目标vector优化应用中，BREATHE比下一个基elineRandom Forest Regression高效性64.1%；在图形基数搜索中，BREATHE比下一个基elineGaussian-process-based Bayesian optimization高效性64.9%；在多目标优化任务中，BREATHE可以达到21.9倍的超过MOBOpt的内在量。<details>
<summary>Abstract</summary>
Researchers constantly strive to explore larger and more complex search spaces in various scientific studies and physical experiments. However, such investigations often involve sophisticated simulators or time-consuming experiments that make exploring and observing new design samples challenging. Previous works that target such applications are typically sample-inefficient and restricted to vector search spaces. To address these limitations, this work proposes a constrained multi-objective optimization (MOO) framework, called BREATHE, that searches not only traditional vector-based design spaces but also graph-based design spaces to obtain best-performing graphs. It leverages second-order gradients and actively trains a heteroscedastic surrogate model for sample-efficient optimization. In a single-objective vector optimization application, it leads to 64.1% higher performance than the next-best baseline, random forest regression. In graph-based search, BREATHE outperforms the next-best baseline, i.e., a graphical version of Gaussian-process-based Bayesian optimization, with up to 64.9% higher performance. In a MOO task, it achieves up to 21.9$\times$ higher hypervolume than the state-of-the-art method, multi-objective Bayesian optimization (MOBOpt). BREATHE also outperforms the baseline methods on most standard MOO benchmark applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data"><a href="#Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data" class="headerlink" title="Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data"></a>Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08656">http://arxiv.org/abs/2308.08656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keziah Naggita, Julienne LaChance, Alice Xiang</li>
<li>for:  investigate the limitations of standard Internet data collection methods in low- and middle-income countries</li>
<li>methods: analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa</li>
<li>results: findings for an &#96;&#96;othering’’ phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers, and the need for further work to capture image data representative of African people and their environments to improve the applicability of computer vision models in a global context.Here’s the full text in Simplified Chinese:</li>
<li>for: 这个研究的目的是调查低收入国家和中等收入国家的标准互联网数据采集方法的局限性。</li>
<li>methods: 该研究使用非常大规模的地标批处Flickr图片，对每个非洲国家进行分析，以获取有关人类中心的图像宽泛分布。</li>
<li>results: 研究发现，非洲的图像数据中存在一种“其他化”现象，即非洲的图像由非本地摄影师拍摄的情况很多。这些结果表明，需要进一步的工作，以捕捉更加符合非洲人和他们环境的图像数据，以提高计算机视觉模型在全球上的适用性。<details>
<summary>Abstract</summary>
Biases in large-scale image datasets are known to influence the performance of computer vision models as a function of geographic context. To investigate the limitations of standard Internet data collection methods in low- and middle-income countries, we analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa. We report the quantity and content of available data with comparisons to population-matched nations in Europe as well as the distribution of data according to fine-grained intra-national wealth estimates. Temporal analyses are performed at two-year intervals to expose emerging data trends. Furthermore, we present findings for an ``othering'' phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers. The results of our study suggest that further work is required to capture image data representative of African people and their environments and, ultimately, to improve the applicability of computer vision models in a global context.
</details>
<details>
<summary>摘要</summary>
大规模图像数据集中的偏见会影响计算机视觉模型的表现，具体来说是根据地理背景。为了调查互联网数据采集方法在LOW-和中等收入国家的限制，我们使用Geotagged Flickr图像与每个非洲国家进行大规模人类中心图像地域多样性分析。我们对可用数据量和内容进行比较，并根据细化的内国财富估计进行分布分析。我们还在两年间进行时间分析，以暴露出emerging数据趋势。此外，我们还发现了一种“他者”现象，即非本地摄影师拍摄的非洲图像的巨大数量。我们的研究结果表明，需要进一步的工作，以捕捉非洲人和其环境的图像数据，并最终提高计算机视觉模型在全球上的应用性。
</details></li>
</ul>
<hr>
<h2 id="Physics-Informed-Recurrent-Neural-Networks-for-Seismic-Response-Evaluation-of-Nonlinear-Systems"><a href="#Physics-Informed-Recurrent-Neural-Networks-for-Seismic-Response-Evaluation-of-Nonlinear-Systems" class="headerlink" title="Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems"></a>Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08655">http://arxiv.org/abs/2308.08655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faisal Nissar Malik, James Ricles, Masoud Yari, Malik Arsala Nissar</li>
<li>for: 这个论文旨在测试多度自由系统（MDOF）的类型动态回应，尤其是在地震（earthquake）载荷下的非线性结构性能。</li>
<li>methods: 这个论文使用了物理知识数据驱动的遗传 ней网（Physics-Informed Recurrent Neural Network，PIRNN）来评估多度自由系统的类型动态回应。</li>
<li>results: 该论文预测的回应将与现有方法（如金属元件分析，FEA）进行比较，以评估PIRNN模型的有效性。<details>
<summary>Abstract</summary>
Dynamic response evaluation in structural engineering is the process of determining the response of a structure, such as member forces, node displacements, etc when subjected to dynamic loads such as earthquakes, wind, or impact. This is an important aspect of structural analysis, as it enables engineers to assess structural performance under extreme loading conditions and make informed decisions about the design and safety of the structure. Conventional methods for dynamic response evaluation involve numerical simulations using finite element analysis (FEA), where the structure is modeled using finite elements, and the equations of motion are solved numerically. Although effective, this approach can be computationally intensive and may not be suitable for real-time applications. To address these limitations, recent advancements in machine learning, specifically artificial neural networks, have been applied to dynamic response evaluation in structural engineering. These techniques leverage large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs, making them ideal for such problems. In this paper, a novel approach is proposed for evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks. The focus of this paper is to evaluate the seismic (earthquake) response of nonlinear structures. The predicted response will be compared to state-of-the-art methods such as FEA to assess the efficacy of the physics-informed RNN model.
</details>
<details>
<summary>摘要</summary>
dynamically respond evaluation in structural engineering 是指评估结构受到动力荷载（如风、地震、冲击等）时的响应，例如成员力、节点偏移等。这是结构分析中非常重要的一环，因为它可以让工程师在极端荷载情况下评估结构性能，并根据这些结果做出有知识的设计和安全决策。传统的方法 для dynamically respond evaluation 包括数学模拟（FEA），其中结构被模型为finite element，并通过数学方法解决方程。虽然有效，但这种方法可能是计算昂贵的，并且可能不适用于实时应用。为了解决这些限制，最近在机器学习领域，特别是人工神经网络（RNN）中，对 dynamically respond evaluation 进行了应用。这些技术可以利用大量数据集和复杂的算法来学习输入和输出之间的复杂关系，使其成为这种问题的理想解决方案。在本文中，一种新的方法被提出来评估多度关系（MDOF）系统的动力响应。本文的焦点是评估震动（地震）响应。预测的响应将与现有方法（如FEA）进行比较，以评估物理学信息RNN模型的有效性。
</details></li>
</ul>
<hr>
<h2 id="Reproducing-Kernel-Hilbert-Space-Pruning-for-Sparse-Hyperspectral-Abundance-Prediction"><a href="#Reproducing-Kernel-Hilbert-Space-Pruning-for-Sparse-Hyperspectral-Abundance-Prediction" class="headerlink" title="Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction"></a>Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08653">http://arxiv.org/abs/2308.08653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael G. Rawson, Timothy Doster, Tegan Emerson</li>
<li>for: 本研究旨在开发一种基于希尔伯特空间的减少维度方法，以提高光谱分析的效率和精度。</li>
<li>methods: 该方法使用非负最小二乘估算来构建稀疏表示，并使用最大可能性压缩向量来减少信息损失。</li>
<li>results: 对实验和 sintética数据进行评估，发现希尔伯特空间减少方法可以减少错误率，并且可以与标准减少和最小二乘方法相比，提高压缩率和精度。<details>
<summary>Abstract</summary>
Hyperspectral measurements from long range sensors can give a detailed picture of the items, materials, and chemicals in a scene but analysis can be difficult, slow, and expensive due to high spatial and spectral resolutions of state-of-the-art sensors. As such, sparsity is important to enable the future of spectral compression and analytics. It has been observed that environmental and atmospheric effects, including scattering, can produce nonlinear effects posing challenges for existing source separation and compression methods. We present a novel transformation into Hilbert spaces for pruning and constructing sparse representations via non-negative least squares minimization. Then we introduce max likelihood compression vectors to decrease information loss. Our approach is benchmarked against standard pruning and least squares as well as deep learning methods. Our methods are evaluated in terms of overall spectral reconstruction error and compression rate using real and synthetic data. We find that pruning least squares methods converge quickly unlike matching pursuit methods. We find that Hilbert space pruning can reduce error by as much as 40% of the error of standard pruning and also outperform neural network autoencoders.
</details>
<details>
<summary>摘要</summary>
高spectral度测量从长距离感知器可以提供场景中物品、材料和化学物质的详细图像，但是分析可能困难、慢和昂贵，这主要是因为现有的感知器具有高空间和spectral分辨率。因此，稀疏性具有重要作用，以便未来的spectral压缩和分析。已经观察到环境和大气效应，包括散射，可以导致非线性效应，这会对现有的源分离和压缩方法 pose challenges。我们提出了一种将测量转换到希尔伯特空间的新方法，以便减少稀疏表示的最小二乘问题。然后，我们引入最大可能性压缩向量，以降低信息损失。我们的方法与标准减少和最小二乘以及深度学习方法进行比较。我们的方法在实际和 sintetic数据上进行评估，并发现减少最小二乘方法可以快速 converges，而不同于匹配追求方法。此外，希尔伯特空间减少可以将错误降低到40%以上，并超越神经网络自适应编码器。
</details></li>
</ul>
<hr>
<h2 id="Towards-Personalized-Federated-Learning-via-Heterogeneous-Model-Reassembly"><a href="#Towards-Personalized-Federated-Learning-via-Heterogeneous-Model-Reassembly" class="headerlink" title="Towards Personalized Federated Learning via Heterogeneous Model Reassembly"></a>Towards Personalized Federated Learning via Heterogeneous Model Reassembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08643">http://arxiv.org/abs/2308.08643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wang, Xingyi Yang, Suhan Cui, Liwei Che, Lingjuan Lyu, Dongkuan Xu, Fenglong Ma</li>
<li>for: addressing the practical problem of model heterogeneity in federated learning, where clients possess models with different network structures.</li>
<li>methods: leverages heterogeneous model reassembly to achieve personalized federated learning, approaches the problem of heterogeneous model personalization as a model-matching optimization task on the server side, and automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention.</li>
<li>results: outperforms baselines on three datasets under both IID and Non-IID settings, effectively reduces the adverse impact of using different public data, and dynamically generates diverse personalized models in an automated manner.Here’s the full translation in Simplified Chinese:</li>
<li>for: 这篇论文是解决联邦学习中的实际问题， Client 拥有不同网络结构的模型。</li>
<li>methods: 利用多元模型重组来实现个性化联邦学习，在服务器端以模型匹配优化任务方式解决各种模型个性化问题，并自动生成有用且多样化的个性化候选人。</li>
<li>results: 在三个数据集上比基eline 表现出色，在 IID 和 Non-IID 设定下都有出色的表现，可以干扰使用不同的公共数据对模型的影响，同时自动生成多样化的个性化模型。<details>
<summary>Abstract</summary>
This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Non-monotone-Sequential-Submodular-Maximization"><a href="#Non-monotone-Sequential-Submodular-Maximization" class="headerlink" title="Non-monotone Sequential Submodular Maximization"></a>Non-monotone Sequential Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08641">http://arxiv.org/abs/2308.08641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaojie Tang, Jing Yuan</li>
<li>for: 本研究targets a fundamental problem in submodular optimization, specifically sequential submodular maximization, which is to select and rank a group of $k$ items from a ground set $V$ such that the weighted summation of $k$ (possibly non-monotone) submodular functions $f_1, \cdots ,f_k$ is maximized.</li>
<li>methods: 该研究提出了一些有效的解决方案，包括针对 flexible 和 fixed 长度约束的方法，以及一个特殊情况下的同Utility函数方法。</li>
<li>results: 实验证明了我们提出的算法在视频推荐领域的有效性。这些结果在推荐系统和搜索优化等领域有着广泛的应用，因为选择项的顺序对总值有着重要的影响。<details>
<summary>Abstract</summary>
In this paper, we study a fundamental problem in submodular optimization, which is called sequential submodular maximization. Specifically, we aim to select and rank a group of $k$ items from a ground set $V$ such that the weighted summation of $k$ (possibly non-monotone) submodular functions $f_1, \cdots ,f_k: 2^V \rightarrow \mathbb{R}^+$ is maximized, here each function $f_j$ takes the first $j$ items from this sequence as input. The existing research on sequential submodular maximization has predominantly concentrated on the monotone setting, assuming that the submodular functions are non-decreasing. However, in various real-world scenarios, like diversity-aware recommendation systems, adding items to an existing set might negatively impact the overall utility. In response, this paper pioneers the examination of the aforementioned problem with non-monotone submodular functions and offers effective solutions for both flexible and fixed length constraints, as well as a special case with identical utility functions. The empirical evaluations further validate the effectiveness of our proposed algorithms in the domain of video recommendations. The results of this research have implications in various fields, including recommendation systems and assortment optimization, where the ordering of items significantly impacts the overall value obtained.
</details>
<details>
<summary>摘要</summary>
在本文中，我们研究了一个基本问题在 subsequential 优化中，即Sequential Submodular Maximization。特别是，我们想选择和排序一组 $k$ 个元素从基aset $V$，使得权重总和 $k$ (可能非增长) 的可模协变函数 $f_1, \cdots ,f_k: 2^V \rightarrow \mathbb{R}^+$ 的最大化，其中每个函数 $f_j$ 取第 $j$ 个元素序列为输入。现有的研究sequential submodular maximization 偏向偏向非增长Setting,假设优化函数是非递减的。然而，在现实生活中的多个enario中，如多样化推荐系统，添加元素到现有的集合可能会下降总用户体验。为此，本文开拓了非增长优化函数的问题，并提供了有效的解决方案，包括灵活和固定长度约束，以及特殊情况下的同用户函数。实验证明了我们提出的算法在视频推荐领域的有效性。本研究的结果在多个领域有着启示性，包括推荐系统和排序优化，其中元素的顺序具有重要的影响。
</details></li>
</ul>
<hr>
<h2 id="Fair-GANs-through-model-rebalancing-with-synthetic-data"><a href="#Fair-GANs-through-model-rebalancing-with-synthetic-data" class="headerlink" title="Fair GANs through model rebalancing with synthetic data"></a>Fair GANs through model rebalancing with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08638">http://arxiv.org/abs/2308.08638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anubhav Jain, Nasir Memon, Julian Togelius</li>
<li>for: 本研究旨在 mitigate 生成模型中的偏见，以提高模型的公平性。</li>
<li>methods: 本研究使用了 latent space exploration 技术，通过生成 balance 的数据来重新训练一个公平的生成模型。同时，提出了一种偏见纠正损失函数，可以在不平衡数据集上进行训练，并且可以提高公平度标度。</li>
<li>results: 在使用 FFHQ 数据集进行隔离性质测试时，提出的方法可以提高公平度标度，与传统的 Frechet inception distance (FID) 不同，可以更好地评估模型的公平性。此外，在 Cifar-10 数据集上进行了验证，并证明了方法的可行性。<details>
<summary>Abstract</summary>
Deep generative models require large amounts of training data. This often poses a problem as the collection of datasets can be expensive and difficult, in particular datasets that are representative of the appropriate underlying distribution (e.g. demographic). This introduces biases in datasets which are further propagated in the models. We present an approach to mitigate biases in an existing generative adversarial network by rebalancing the model distribution. We do so by generating balanced data from an existing unbalanced deep generative model using latent space exploration and using this data to train a balanced generative model. Further, we propose a bias mitigation loss function that shows improvements in the fairness metric even when trained with unbalanced datasets. We show results for the Stylegan2 models while training on the FFHQ dataset for racial fairness and see that the proposed approach improves on the fairness metric by almost 5 times, whilst maintaining image quality. We further validate our approach by applying it to an imbalanced Cifar-10 dataset. Lastly, we argue that the traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.
</details>
<details>
<summary>摘要</summary>
深度生成模型需要大量的训练数据。这经常会导致问题，因为收集数据集可能是昂贵的和困难的，特别是数据集是合适的下面分布（例如人口）。这会导致数据集中的偏见，并将它们传递给模型。我们提出了一种方法来减少模型中的偏见，通过使用潜在空间探索生成均衡数据，并使用这些数据来训练均衡的生成模型。此外，我们提出了一种偏见缓解损失函数，该函数能够在不均衡的数据集上提高公平度指标，并且可以保持图像质量。我们在使用FFHQ数据集进行遥感匈灵抑制问题中证明了我们的方法的有效性，并且在不均衡的Cifar-10数据集上验证了我们的方法。最后，我们 argue That traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.
</details></li>
</ul>
<hr>
<h2 id="FedPop-Federated-Population-based-Hyperparameter-Tuning"><a href="#FedPop-Federated-Population-based-Hyperparameter-Tuning" class="headerlink" title="FedPop: Federated Population-based Hyperparameter Tuning"></a>FedPop: Federated Population-based Hyperparameter Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08634">http://arxiv.org/abs/2308.08634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 该论文旨在提出一种新的分布式机器学习（Federated Learning，FL）中的参数优化算法，以提高FL的性能。</li>
<li>methods: 该论文提出了一种基于种群进化算法的参数优化算法，称为Federated Population-based Hyperparameter Tuning（FedPop），以优化FL中的参数。</li>
<li>results: 实验结果表明，FedPop比PRIOR的HP优化方法更高效，在常见的FL benchmark和实际世界FL数据集上显著提高了FL的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning (ML) paradigm, in which multiple clients collaboratively train ML models without centralizing their local data. Similar to conventional ML pipelines, the client local optimization and server aggregation procedure in FL are sensitive to the hyperparameter (HP) selection. Despite extensive research on tuning HPs for centralized ML, these methods yield suboptimal results when employed in FL. This is mainly because their "training-after-tuning" framework is unsuitable for FL with limited client computation power. While some approaches have been proposed for HP-Tuning in FL, they are limited to the HPs for client local updates. In this work, we propose a novel HP-tuning algorithm, called Federated Population-based Hyperparameter Tuning (FedPop), to address this vital yet challenging problem. FedPop employs population-based evolutionary algorithms to optimize the HPs, which accommodates various HP types at both client and server sides. Compared with prior tuning methods, FedPop employs an online "tuning-while-training" framework, offering computational efficiency and enabling the exploration of a broader HP search space. Our empirical validation on the common FL benchmarks and complex real-world FL datasets demonstrates the effectiveness of the proposed method, which substantially outperforms the concurrent state-of-the-art HP tuning methods for FL.
</details>
<details>
<summary>摘要</summary>
Federated Learning (FL) 是一种分布式机器学习 (ML) 模式，在多个客户端协同训练 ML 模型时，不需要集中客户端的本地数据。与传统的 ML 管道类似，在 FL 中客户端本地优化和服务器聚合过程中的超参数 (HP) 选择也是敏感的。尽管有大量关于中心化 ML 中HP的优化研究，这些方法在 FL 中具有较差的效果，主要因为它们的 "训练后优化" 框架不适合 FL 中限制的客户端计算能力。一些对 FL 中HP的优化方法已经被提出，但它们只适用于客户端本地更新中的HP。在这项工作中，我们提出了一种新的HP优化算法，called Federated Population-based Hyperparameter Tuning (FedPop)，以解决这一重要但具有挑战性的问题。FedPop 使用人口生物学算法优化 HP，可以满足多种 HP 类型在客户端和服务器端。相比之前的优化方法，FedPop 采用在线 "优化while training" 框架，可以提高计算效率，并允许探索更广泛的 HP 搜索空间。我们对常见 FL benchmark 和复杂的实际 FL 数据进行了实验 validate，结果表明我们提出的方法效果明显超过了当前状态的HP优化方法 для FL。
</details></li>
</ul>
<hr>
<h2 id="LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data"><a href="#LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data" class="headerlink" title="LSTM-Based Forecasting Model for GRACE Accelerometer Data"></a>LSTM-Based Forecasting Model for GRACE Accelerometer Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08621">http://arxiv.org/abs/2308.08621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers">https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers</a></li>
<li>paper_authors: Neda Darbeheshti, Elahe Moradi</li>
<li>for: This paper is written for monitoring variations in Earth’s gravity field and filling data gaps in the GRACE satellite mission.</li>
<li>methods: The paper uses Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.</li>
<li>results: The model demonstrates effectiveness in filling gaps and forecasting GRACE accelerometer data, with accurate predictions for the three axes.<details>
<summary>Abstract</summary>
The Gravity Recovery and Climate Experiment (GRACE) satellite mission, spanning from 2002 to 2017, has provided a valuable dataset for monitoring variations in Earth's gravity field, enabling diverse applications in geophysics and hydrology. The mission was followed by GRACE Follow-On in 2018, continuing data collection efforts. The monthly Earth gravity field, derived from the integration different instruments onboard satellites, has shown inconsistencies due to various factors, including gaps in observations for certain instruments since the beginning of the GRACE mission.   With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.   In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.
</details>
<details>
<summary>摘要</summary>
格拉vity Recovery和气候实验(GRACE)卫星任务，从2002年至2017年，提供了对地球重力场变化的珍贵数据集，用于气象和地球物理多种应用。这个任务被GRACE Follow-On在2018年继承，继续数据采集。月度地球重力场，由卫星上不同仪器的集成，具有各种因素引起的不一致，包括GRACE任务开始时的某些仪器观测 gap。  With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.   In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.
</details></li>
</ul>
<hr>
<h2 id="Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought"><a href="#Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought" class="headerlink" title="Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought"></a>Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08614">http://arxiv.org/abs/2308.08614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lei, pei-Hung Lin, Chunhua Liao, Caiwen Ding</li>
<li>for: 提高大规模模型对复杂问题的逻辑推理能力</li>
<li>methods: 提出了一种新的引导技术 called Graph of Thoughts (GoT)</li>
<li>results: 在三个增加的挑战任务中，与 GPT-4 和 Tree of Thought (ToT) 相比，我们的方法实现了 $89.7%$, $86%$, $56%$ 的准确率提高，并且与 SOTA 方法的平均准确率提高 $23%$, $24%$, $15%$。<details>
<summary>Abstract</summary>
Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\%$, $86\%$, and $56\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\%$, $24\%$, and $15\%$.
</details>
<details>
<summary>摘要</summary>
最近的大规模模型，如GPT-4，已经表现出了解决标准问题的很好的能力。然而，当面临复杂的问题需要多步逻辑推理时，其准确率会减少很多。现有研究在\textit{提示工程}（prompting engineering）领域进行了研究，以增强这些模型的推理能力。我们的论文揭示了一种新的提示技术，名为\textit{思维图（GoT）}。在三个逐渐增加的挑战任务中：24点游戏、高度波动方程的解决和递归序列的公式 derivation 中，我们的方法比GPT-4高效，实现了准确率提高的89.7%、86%和56%。此外，与现有最佳实践（SOTA）提示方法，\textit{树思维（ToT）}，相比，我们的方法在平均上registered一个23%、24%和15%的准确率提高。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach"><a href="#Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach" class="headerlink" title="Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach"></a>Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08611">http://arxiv.org/abs/2308.08611</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Wahid, I faiud, K. Mason</li>
<li>for: 这个研究用于优化农业领域 photovoltaic (PV) 系统的决策。</li>
<li>methods: 这个研究使用深度Q学习网络（DQN）来帮助农业投资者做出有数据支持的决策，包括考虑安装预算、政府激励、能源需求、系统成本以及长期效益。</li>
<li>results: 这个研究提供了一个全面的理解，如何使用DQN来支持农业投资者做出PV安装的决策，以及该技术在农业领域的应用可能性。这些研究结果对推广可持续可靠的农业实践，提高能源效益，降低环境影响，提高利润等方面具有重要意义。<details>
<summary>Abstract</summary>
This article investigates the use of Deep Q-Networks (DQNs) to optimize decision-making for photovoltaic (PV) systems installations in the agriculture sector. The study develops a DQN framework to assist agricultural investors in making informed decisions considering factors such as installation budget, government incentives, energy requirements, system cost, and long-term benefits. By implementing a reward mechanism, the DQN learns to make data-driven decisions on PV integration. The analysis provides a comprehensive understanding of how DQNs can support investors in making decisions about PV installations in agriculture. This research has significant implications for promoting sustainable and efficient farming practices while also paving the way for future advancements in this field. By leveraging DQNs, agricultural investors can make optimized decisions that improve energy efficiency, reduce environmental impact, and enhance profitability. This study contributes to the advancement of PV integration in agriculture and encourages further innovation in this promising area.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Atom-by-atom-protein-generation-and-beyond-with-language-models"><a href="#Atom-by-atom-protein-generation-and-beyond-with-language-models" class="headerlink" title="Atom-by-atom protein generation and beyond with language models"></a>Atom-by-atom protein generation and beyond with language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09482">http://arxiv.org/abs/2308.09482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Flam-Shepherd, Kevin Zhu, Alán Aspuru-Guzik</li>
<li>for: 这paper是为了探索使用语言模型来生成蛋白质的可能性。</li>
<li>methods: 这paper使用了化学语言模型来学习蛋白质的原子层次表示，并可以生成不受标准遗传码限制的蛋白质。</li>
<li>results: 这paper的结果表明，语言模型可以学习蛋白质的多层次结构，从原始序列到次结构和三维结构，并可以生成不受标准遗传码限制的蛋白质，还可以同时探索蛋白质和化学空间，并生成新的蛋白质-药物 conjugate。<details>
<summary>Abstract</summary>
Protein language models learn powerful representations directly from sequences of amino acids. However, they are constrained to generate proteins with only the set of amino acids represented in their vocabulary. In contrast, chemical language models learn atom-level representations of smaller molecules that include every atom, bond, and ring. In this work, we show that chemical language models can learn atom-level representations of proteins enabling protein generation unconstrained to the standard genetic code and far beyond it. In doing so, we show that language models can generate entire proteins atom by atom -- effectively learning the multiple hierarchical layers of molecular information that define proteins from their primary sequence to their secondary, and tertiary structure. We demonstrate language models are able to explore beyond protein space -- generating proteins with modified sidechains that form unnatural amino acids. Even further, we find that language models can explore chemical space and protein space simultaneously and generate novel examples of protein-drug conjugates. The results demonstrate the potential for biomolecular design at the atom level using language models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Proprioceptive-Learning-with-Soft-Polyhedral-Networks"><a href="#Proprioceptive-Learning-with-Soft-Polyhedral-Networks" class="headerlink" title="Proprioceptive Learning with Soft Polyhedral Networks"></a>Proprioceptive Learning with Soft Polyhedral Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08538">http://arxiv.org/abs/2308.08538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobo Liu, Xudong Han, Wei Hong, Fang Wan, Chaoyang Song</li>
<li>for: 这篇论文旨在开发一种能够实现自适应肢体位姿感知的软体网络，以提高现代机器人的敏捷、适应性和感知能力。</li>
<li>methods: 该论文使用了软体网络和内置的视觉系统，通过学习动态力学特征来实现适应性和感知。</li>
<li>results: 实验结果显示，软体网络可以在实时感知6个自由度力和扭矩的同时，精度为0.25&#x2F;0.24&#x2F;0.35 N和0.025&#x2F;0.034&#x2F;0.006 Nm，并在静态适应中包含滑动和塑性修正以提高预测结果。<details>
<summary>Abstract</summary>
Proprioception is the "sixth sense" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed soft network combines simplicity in design, omni-adaptation, and proprioceptive sensing with high accuracy, making it a versatile solution for robotics at a low cost with more than 1 million use cycles for tasks such as sensitive and competitive grasping, and touch-based geometry reconstruction. This study offers new insights into vision-based proprioception for soft robots in adaptive grasping, soft manipulation, and human-robot interaction.
</details>
<details>
<summary>摘要</summary>
Proprioception 是Robotics中的"六感"，它通过motor neurons探测 LIMB 姿势。它需要自然的 musculoskeletal 系统和感官器件之间的集成，这是现代Robotics中的挑战，因为它们需要轻量、适应性和敏捷的设计，同时需要低成本。在这篇文章中，我们提出了Soft Polyhedral Network，它具有嵌入式的视觉系统，能够进行适应的运动和弹簧 proprioception，通过学习运动特征来进行预测。这个设计允许机器人在无方向互动中进行自适应，并且可以通过高速动态追踪系统进行 proprioceptive 学习。实验结果显示，软网络可以在实时进行6D 力和扭矩的测量，精度为0.25/0.24/0.35 N 和 0.025/0.034/0.006 Nm。我们还将viscoelasticity 加入 proprioception 中，以更好地精确地预测结果。我们的软网络结合了简单的设计、适应性和 proprioceptive 感知，并且具有高精度和低成本，适合Robotics 中的多种任务，如敏捷和竞争性的抓取、触碰基本重建等。这篇文章将带来新的见解到视基 proprioception 领域，对于软机器人在适应抓取、软操作和人机交互等方面的应用有很大的潜力。
</details></li>
</ul>
<hr>
<h2 id="Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems"><a href="#Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems" class="headerlink" title="Can Transformers Learn Optimal Filtering for Unknown Systems?"></a>Can Transformers Learn Optimal Filtering for Unknown Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08536">http://arxiv.org/abs/2308.08536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haldun Balim, Zhe Du, Samet Oymak, Necmiye Ozay</li>
<li>for: 这个论文的目的是用 transformers 来解决 dynamical systems 中的优化输出估计问题。</li>
<li>methods: 这个论文使用 transformers 来生成输出预测，使用所有过去的输出来生成当前输出预测。论文通过在不同系统上进行训练，以实现在新的系统上快速适应和预测。</li>
<li>results: 这个论文的结果表明，使用 transformers 可以具有很高的预测性能，并且可以在具有非同异idi 噪声、时间变化动力学和非线性动力学等挑战的场景中表现良好。论文还提供了对 MOP 的统计保证和测试时间内的过程中所需的训练量。<details>
<summary>Abstract</summary>
Transformers have demonstrated remarkable success in natural language processing; however, their potential remains mostly unexplored for problems arising in dynamical systems. In this work, we investigate the optimal output estimation problem using transformers, which generate output predictions using all the past ones. We train the transformer using various systems drawn from a prior distribution and then evaluate its performance on previously unseen systems from the same distribution. As a result, the obtained transformer acts like a prediction algorithm that learns in-context and quickly adapts to and predicts well for different systems - thus we call it meta-output-predictor (MOP). MOP matches the performance of the optimal output estimator, based on Kalman filter, for most linear dynamical systems even though it does not have access to a model. We observe via extensive numerical experiments that MOP also performs well in challenging scenarios with non-i.i.d. noise, time-varying dynamics, and nonlinear dynamics like a quadrotor system with unknown parameters. To further support this observation, in the second part of the paper, we provide statistical guarantees on the performance of MOP and quantify the required amount of training to achieve a desired excess risk during test-time. Finally, we point out some limitations of MOP by identifying two classes of problems MOP fails to perform well, highlighting the need for caution when using transformers for control and estimation.
</details>
<details>
<summary>摘要</summary>
transformers 已经展示出了惊人的成功在自然语言处理领域;然而，它们的潜力还未得到了充分的探索，尤其是在动力系统中。在这项工作中，我们使用 transformers 来解决输出预测问题，它们使用所有过去的输出来生成输出预测。我们使用不同的系统从先验分布中随机选择训练数据，然后评估其性能在未经见过的系统上。因此，我们得到的 transformer 被称为元输出预测器 (MOP)。MOP与优化的输出估计器（基于 kalman 滤波器）的性能相当，即使它没有访问模型。我们通过广泛的数值实验发现，MOP 在非相关噪声、时间变化动力学和不确定参数的 quadrotor 系统中也表现良好。在第二部分的论文中，我们提供了对 MOP 性能的统计保证，并估计在测试时需要多少训练时间来达到所需的过量风险。最后，我们指出了 MOP 在某些情况下的限制，并标识了使用 transformers 进行控制和估计时需要小心的两类问题。
</details></li>
</ul>
<hr>
<h2 id="Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches"><a href="#Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches" class="headerlink" title="Painter: Teaching Auto-regressive Language Models to Draw Sketches"></a>Painter: Teaching Auto-regressive Language Models to Draw Sketches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08520">http://arxiv.org/abs/2308.08520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Pourreza, Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Pulkit Madan, Roland Memisevic</li>
<li>for: 这个论文主要针对大语言模型（LLMs）在自然语言理解方面的进步，以及在其他领域如计算机视觉、机器人学习等领域的应用。</li>
<li>methods: 本文使用LLMs直接生成虚拟的毫线笔触来绘制图像。我们提出了Painter，一个基于市场上可购买的LLM，通过对新任务进行细化而不失去语言理解能力来构建Painter。</li>
<li>results: Painter可以从文本描述转换为绘制图像，从图像中移除对象，并检测和分类图像中的对象。虽然这是一项前所未有的使用LLMs进行自动进程图像生成的研究，但结果很鼓励人。<details>
<summary>Abstract</summary>
Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc. In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image. We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way. We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities. We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks. Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches. Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）已经取得了巨大的进步，并在其他领域如计算机视觉、机器人学、奖励学习等领域中得到成功应用。在这项工作中，我们将LLM应用到图像生成任务中，直接生成虚拟的毫幅笔触来绘制图像。我们提出了“艺术家”（Painter），一种可以根据用户提示转化为笔触的LLM。我们基于市场上可获得的LLM，通过精度调整和保留语言理解能力来构建Painter。我们创建了包含多种物体绘制和任务的多样化笔触集合，并将Painter应用于这些笔触集合中。Painter可以根据文本提示生成笔触，从笔触中移除物体，并探测和分类笔触中的物体。虽然这是使用LLM进行自然语言到自动生成图像的前所未有的做法，但结果非常鼓动人心。
</details></li>
</ul>
<hr>
<h2 id="Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems"><a href="#Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems" class="headerlink" title="Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems"></a>Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08511">http://arxiv.org/abs/2308.08511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zirong Li, Yanyang Wang, Jianjia Zhang, Weiwen Wu, Hengyong Yu</li>
<li>for: 提高CT和MRI图像重建的精度和效率，解决不同的 inverse problem。</li>
<li>methods: 基于Score-based模型，通过在2D空间学习数据分布，然后在3D空间更新数据分布来实现更精度的重建。</li>
<li>results: 在大规模的稀缺视图CT和快速MRI数据集上进行了广泛的实验，比较了现有的方法，并达到了目前最佳的解决3D稀缺 inverse problem 的效果。<details>
<summary>Abstract</summary>
Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are crucial technologies in the field of medical imaging. Score-based models have proven to be effective in addressing different inverse problems encountered in CT and MRI, such as sparse-view CT and fast MRI reconstruction. However, these models face challenges in achieving accurate three dimensional (3D) volumetric reconstruction. The existing score-based models primarily focus on reconstructing two dimensional (2D) data distribution, leading to inconsistencies between adjacent slices in the reconstructed 3D volumetric images. To overcome this limitation, we propose a novel two-and-a-half order score-based model (TOSM). During the training phase, our TOSM learns data distributions in 2D space, which reduces the complexity of training compared to directly working on 3D volumes. However, in the reconstruction phase, the TOSM updates the data distribution in 3D space, utilizing complementary scores along three directions (sagittal, coronal, and transaxial) to achieve a more precise reconstruction. The development of TOSM is built on robust theoretical principles, ensuring its reliability and efficacy. Through extensive experimentation on large-scale sparse-view CT and fast MRI datasets, our method demonstrates remarkable advancements and attains state-of-the-art results in solving 3D ill-posed inverse problems. Notably, the proposed TOSM effectively addresses the inter-slice inconsistency issue, resulting in high-quality 3D volumetric reconstruction.
</details>
<details>
<summary>摘要</summary>
computed tomography (CT) 和 magnetism resonance imaging (MRI) 是医学影像领域的关键技术。分数模型已经证明可以有效地解决 CT 和 MRI 中的不同的反问题，如稀疏视图 CT 和快速 MRI 重建。然而，这些模型在实现准确的三维（3D）卷积重建方面遇到了挑战。现有的分数模型主要是对二维（2D）数据分布进行重建，从而导致扫描图像中的邻域匹配不准确。为解决这个限制，我们提出了一种新的二阶半分数模型（TOSM）。在训练阶段，我们的 TOSM 学习了数据分布在二维空间，从而降低了训练的复杂性。然而，在重建阶段，TOSM 将数据分布更新到三维空间，利用三个方向（极轴、极圆、和扫描）的补做分数来实现更加精确的重建。TOSM 的开发基于Robust的理论原则，确保其可靠性和效果。通过对大规模稀疏视图 CT 和快速 MRI 数据进行广泛的实验，我们的方法在解决 3D 负定问题中具有显著的进步和达到了当前最佳结果。特别是，我们的 TOSM 能够有效地解决邻域不一致问题，从而实现高质量的 3D 卷积重建。
</details></li>
</ul>
<hr>
<h2 id="Autoencoding-a-Soft-Touch-to-Learn-Grasping-from-On-land-to-Underwater"><a href="#Autoencoding-a-Soft-Touch-to-Learn-Grasping-from-On-land-to-Underwater" class="headerlink" title="Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater"></a>Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08510">http://arxiv.org/abs/2308.08510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bionicdl-sustech/amphibioussoftfinger">https://github.com/bionicdl-sustech/amphibioussoftfinger</a></li>
<li>paper_authors: Ning Guo, Xudong Han, Xiaobo Liu, Shuqiao Zhong, Zhiyuan Zhou, Jian Lin, Jiansheng Dai, Fang Wan, Chaoyang Song</li>
<li>for: 该研究旨在提高水下机器人的物体抓取稳定性和可靠性，以支持生态环境和海洋研究的基础科学发现。</li>
<li>methods: 该研究使用了视觉基于的软体机器人手指，通过监督VARAE学习6D力和扭矩（FT）。高速摄像机记录了软机器人手指与物体之间的整体塑变，以获得更好的学习效果。</li>
<li>results: 研究结果显示，SVAE模型学习到了从陆地到水中的软机械学的各种秘密代表，在改变环境中具有Superior的适应能力，与商业FT传感器相比，提供了更加稳定和可靠的抓取。这种感觉智能抓取技术将为水下机器人带来更好的可靠性和可重复性，为生态环境和海洋研究带来更多的支持。<details>
<summary>Abstract</summary>
Robots play a critical role as the physical agent of human operators in exploring the ocean. However, it remains challenging to grasp objects reliably while fully submerging under a highly pressurized aquatic environment with little visible light, mainly due to the fluidic interference on the tactile mechanics between the finger and object surfaces. This study investigates the transferability of grasping knowledge from on-land to underwater via a vision-based soft robotic finger that learns 6D forces and torques (FT) using a Supervised Variational Autoencoder (SVAE). A high-framerate camera captures the whole-body deformations while a soft robotic finger interacts with physical objects on-land and underwater. Results show that the trained SVAE model learned a series of latent representations of the soft mechanics transferrable from land to water, presenting a superior adaptation to the changing environments against commercial FT sensors. Soft, delicate, and reactive grasping enabled by tactile intelligence enhances the gripper's underwater interaction with improved reliability and robustness at a much-reduced cost, paving the path for learning-based intelligent grasping to support fundamental scientific discoveries in environmental and ocean research.
</details>
<details>
<summary>摘要</summary>
роботы играют критическую роль как физические агенты человеческих операторов в исследовании океана. Однако, было трудно удерживать объекты надежно, когда полностью погружались в высокопрессURIZрованную акватическую среду с ограниченным видимым светом, главным образом из-за динамической интерференции между поверхностями пальца и объекта. Этот исследование изучает передачу знаний о захвате с наземных в подводные условия с помощью визуальной базированной мягкой роботической пальца, которая обучается 6D силам и моментам (FT) с помощью надсмотренного верификатора автоенкодера (SVAE). Высококачественный камеруCaptures Whole-Body Deformations While Interacting with Physical Objects On-Land and Underwater. Results Show That the Trained SVAE Model Learned a Series of Latent Representations of Soft Mechanics Transferable from Land to Water, Presenting a Superior Adaptation to Changing Environments Against Commercial FT Sensors. Soft, Delicate, and Reactive Grasping Enabled by Tactile Intelligence Enhances the Gripper's Underwater Interaction with Improved Reliability and Robustness at a Much-Reduced Cost, Paving the Path for Learning-Based Intelligent Grasping to Support Fundamental Scientific Discoveries in Environmental and Ocean Research.
</details></li>
</ul>
<hr>
<h2 id="ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures"><a href="#ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures" class="headerlink" title="ResBuilder: Automated Learning of Depth with Residual Structures"></a>ResBuilder: Automated Learning of Depth with Residual Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08504">http://arxiv.org/abs/2308.08504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julian Burghoff, Matthias Rottmann, Jill von Conta, Sebastian Schoenen, Andreas Witte, Hanno Gottschalk</li>
<li>for: 本文开发了一种基于神经网络搜索算法，即Resbuilder，可以从头开始构建高精度低计算成本的ResNet架构。它还可以修改现有架构，并且可以移除和插入ResNet块，从而在ResNet架构空间进行搜索。</li>
<li>methods: 本文使用了一种基于隐藏状态抽象的搜索算法，并且使用了一种新的强化策略来优化搜索结果。在不同的图像分类任务上进行了实验，Resbuilder能够几乎与状态地标的性能匹配，同时减少了计算成本。</li>
<li>results: 本文在不同的图像分类任务上的实验结果表明，Resbuilder能够减少计算成本，同时保持高精度。此外，通过对一个Proprietary fraud detection dataset进行应用，表明了该方法在实际应用中的一致性。<details>
<summary>Abstract</summary>
In this work, we develop a neural architecture search algorithm, termed Resbuilder, that develops ResNet architectures from scratch that achieve high accuracy at moderate computational cost. It can also be used to modify existing architectures and has the capability to remove and insert ResNet blocks, in this way searching for suitable architectures in the space of ResNet architectures. In our experiments on different image classification datasets, Resbuilder achieves close to state-of-the-art performance while saving computational cost compared to off-the-shelf ResNets. Noteworthy, we once tune the parameters on CIFAR10 which yields a suitable default choice for all other datasets. We demonstrate that this property generalizes even to industrial applications by applying our method with default parameters on a proprietary fraud detection dataset.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们开发了一种神经网络搜索算法，即Resbuilder，它可以从头开始开发高精度低计算成本的ResNet架构。它还可以修改现有架构，并且具有将ResNet块添加或删除的能力，从而在ResNet架构空间进行搜索。在我们对不同的图像分类 dataset 进行实验中，Resbuilder 可以达到 state-of-the-art 性能，而且与 commercially 可用的 ResNet 相比，计算成本更低。值得一提的是，我们在 CIFAR10 上调参得到了一个适合所有其他 dataset 的默认选择，并且我们证明这种性能可以普遍应用于工业应用程序，例如在一个 proprietary 销售欺诈数据集上使用 default 参数。
</details></li>
</ul>
<hr>
<h2 id="Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models"><a href="#Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models" class="headerlink" title="Time Travel in LLMs: Tracing Data Contamination in Large Language Models"></a>Time Travel in LLMs: Tracing Data Contamination in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08493">http://arxiv.org/abs/2308.08493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahriar Golchin, Mihai Surdeanu</li>
<li>for: 本研究旨在检测大语言模型（LLM）训练数据中是否存在测试数据污染问题。</li>
<li>methods: 本研究提出了一种简单 yet有效的方法来识别LLM中的数据污染。该方法包括对个别实例进行识别污染，然后判断整个数据分区是否受到污染。</li>
<li>results: 研究发现，使用“导向指令”（一个包含数据集名称、分区类型和参考实例的提示）来评估实例是否受到污染，可以准确地检测LLM中的数据污染。此外，研究还发现GPT-4中存在数据污染问题，特别是AG News、WNLI和XSum数据集。<details>
<summary>Abstract</summary>
Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated. To estimate contamination of individual instances, we employ "guided instruction:" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE or BLEURT) is statistically significantly better with the guided instruction vs. a general instruction that does not include the dataset and partition name. The second idea marks a dataset as contaminated if a classifier based on GPT-4 with in-context learning prompting marks multiple instances as contaminated. Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human expert. Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.
</details>
<details>
<summary>摘要</summary>
大数据污染，即大语言模型（LLM）训练数据中下游任务的测试数据存在的问题，是 LLM 效果理解的 potential 主要问题。我们提出了一种简单 yet 有效的方法来在 LLM 中 Identify 数据污染。我们的方法的核心是在小样本中随机选择的实例上 Identify 数据污染。使用这些信息，我们的方法然后判断整个数据分区是否污染。为了估计实例上的污染，我们采用 "导向指令"：一个包含数据集名、分区类型和参考实例的开头的提示，请 LLM 完成它。如果 LLM 的输出与参考实例的后半部分匹配，则标记该实例为污染。为了理解整个分区是否污染，我们提出了两个想法。第一个想法是如果使用 ROUGE 或 BLEURT  measure 参考实例与指令之间的 overlap 得分为 statistically  significiantly 高于不包含数据集和分区名的通用指令，那么将标记该分区为污染。第二个想法是如果一个基于 GPT-4 的类ifier 通过受Context learning 提示标记多个实例为污染，那么将标记该数据集为污染。我们的最佳方法在七个数据集（包括训练和测试/验证分区）上达到了92% 到 100% 的准确率，与人工评估 compare 。此外，我们发现 GPT-4 污染 AG News、WNLI 和 XSum 数据集。
</details></li>
</ul>
<hr>
<h2 id="Label-Propagation-Techniques-for-Artifact-Detection-in-Imbalanced-Classes-using-Photoplethysmogram-Signals"><a href="#Label-Propagation-Techniques-for-Artifact-Detection-in-Imbalanced-Classes-using-Photoplethysmogram-Signals" class="headerlink" title="Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals"></a>Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08480">http://arxiv.org/abs/2308.08480</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clara Macabiau, Thanh-Dung Le, Kevin Albert, Philippe Jouvet, Rita Noumeir</li>
<li>for: 这个研究探讨了在受到运动干扰的情况下如何使用标签卷传递技术来标注医疗数据集，特别是在不平衡的类型场景下，清洁的PPG样本被干扰样本所显著多出。</li>
<li>methods: 这种研究使用了标签卷传递技术来传递标签到PPG样本中，并与支持学习模型（包括传统类ifiers和神经网络）进行比较。</li>
<li>results: 研究结果表明，使用标签卷传递技术可以准确地标注PPG样本，尤其是在清洁样本罕见时。与支持学习模型相比，标签卷传递算法在检测干扰物时表现更好。这些结果表明，标签卷传递算法在PPG信号中的干扰物检测中具有潜在的优势。<details>
<summary>Abstract</summary>
Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring vital signs, but they are susceptible to motion artifacts that can lead to inaccurate interpretations. In this study, the use of label propagation techniques to propagate labels among PPG samples is explored, particularly in imbalanced class scenarios where clean PPG samples are significantly outnumbered by artifact-contaminated samples. With a precision of 91%, a recall of 90% and an F1 score of 90% for the class without artifacts, the results demonstrate its effectiveness in labeling a medical dataset, even when clean samples are rare. For the classification of artifacts our study compares supervised classifiers such as conventional classifiers and neural networks (MLP, Transformers, FCN) with the semi-supervised label propagation algorithm. With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN supervised model gives good results, but the semi-supervised algorithm performs better in detecting artifacts. The findings suggest that the semi-supervised algorithm label propagation hold promise for artifact detection in PPG signals, which can enhance the reliability of PPG-based health monitoring systems in real-world applications.
</details>
<details>
<summary>摘要</summary>
对于artifact的分类，我们比较了传统的supervised类ifiers（例如conventional classifiers和神经网络）与 semi-supervised label propagation algorithm。与89%的精度、95%的回归率和92%的F1 Score相比，KNN 超vised模型给出了不错的结果，但semi-supervised algorithm在检测artifacts方面表现更好。研究结果表明，semi-supervised algorithm label propagation在 PPG 信号中检测artifacts 有前途，可以提高 PPG 基于健康监测系统的可靠性在实际应用中。
</details></li>
</ul>
<hr>
<h2 id="LLM4TS-Two-Stage-Fine-Tuning-for-Time-Series-Forecasting-with-Pre-Trained-LLMs"><a href="#LLM4TS-Two-Stage-Fine-Tuning-for-Time-Series-Forecasting-with-Pre-Trained-LLMs" class="headerlink" title="LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs"></a>LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08469">http://arxiv.org/abs/2308.08469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ching Chang, Wen-Chih Peng, Tien-Fu Chen</li>
<li>for: 提高长期时间序列预测精度</li>
<li>methods: 利用预训练的大语言模型（LLM）进行时间序列预测，并采用时间补充和时间编码等技术增强LLM对时间序列数据的处理能力。</li>
<li>results: 通过两stage精度调整和多 Parameter-Efficient Fine-Tuning（PEFT）技术，实现了长期预测的状态艺能，并且能够快速适应新的时间序列数据。<details>
<summary>Abstract</summary>
In this work, we leverage pre-trained Large Language Models (LLMs) to enhance time-series forecasting. Mirroring the growing interest in unifying models for Natural Language Processing and Computer Vision, we envision creating an analogous model for long-term time-series forecasting. Due to limited large-scale time-series data for building robust foundation models, our approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By combining time-series patching with temporal encoding, we have enhanced the capability of LLMs to handle time-series data effectively. Inspired by the supervised fine-tuning in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art results in long-term forecasting. Our model has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们利用预训练的大语言模型（LLM）来提高时间序列预测。随着自然语言处理和计算机视觉模型的统一的兴趣增长，我们意识到创建相应的模型。由于有限的大规模时间序列数据建立坚实的基础模型，我们的方法LLM4TS将注重利用预训练LLM的优势。通过将时间序列补丁与时间编码结合，我们已经提高了LLM对时间序列数据的处理能力。 Drawing on the supervised fine-tuning experience in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques. Our model has yielded state-of-the-art results in long-term forecasting, and has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM.
</details></li>
</ul>
<hr>
<h2 id="An-Expert’s-Guide-to-Training-Physics-informed-Neural-Networks"><a href="#An-Expert’s-Guide-to-Training-Physics-informed-Neural-Networks" class="headerlink" title="An Expert’s Guide to Training Physics-informed Neural Networks"></a>An Expert’s Guide to Training Physics-informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08468">http://arxiv.org/abs/2308.08468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/predictiveintelligencelab/jaxpi">https://github.com/predictiveintelligencelab/jaxpi</a></li>
<li>paper_authors: Sifan Wang, Shyam Sankaran, Hanwen Wang, Paris Perdikaris</li>
<li>for: 本研究旨在提高physics-informed neural networks（PINNs）的训练效率和总体准确性，并提供一系列最佳实践和挑战性 benchmark 问题，以便未来研究者可以使用这些方法和指导原则进行比较。</li>
<li>methods: 本研究使用了一系列最佳实践和architecture choices，包括使用 JAX 库进行高效的训练和推理，以及进行了完整的ablation study，以确定不同的训练策略和architecture的影响。</li>
<li>results: 本研究的结果表明，采用本研究提出的方法和指导原则，可以获得state-of-the-art的结果，并提供了strong baselines，可以用于 future studies 的比较。此外，本研究还发布了一个高度优化的 JAX 库，可以用于重现所有结果，以及为新用例场景进行扩展和适应。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints. Their practical effectiveness however can be hampered by training pathologies, but also oftentimes by poor choices made by users who lack deep learning expertise. In this paper we present a series of best practices that can significantly improve the training efficiency and overall accuracy of PINNs. We also put forth a series of challenging benchmark problems that highlight some of the most prominent difficulties in training PINNs, and present comprehensive and fully reproducible ablation studies that demonstrate how different architecture choices and training strategies affect the test accuracy of the resulting models. We show that the methods and guiding principles put forth in this study lead to state-of-the-art results and provide strong baselines that future studies should use for comparison purposes. To this end, we also release a highly optimized library in JAX that can be used to reproduce all results reported in this paper, enable future research studies, as well as facilitate easy adaptation to new use-case scenarios.
</details>
<details>
<summary>摘要</summary>
物理学 informed neural networks (PINNs) 已经广泛应用于深度学习框架，可以快速生成观察数据和部分偏微分方程 (PDE) 约束的模型。然而，它们的实际效果可能受到训练问题和用户缺乏深度学习知识所妨碍。在这篇论文中，我们提出了一系列最佳实践，可以大幅提高 PINNs 的训练效率和总准确率。我们还提出了一系列挑战性的 benchmark 问题，描述了 PINNs 训练中的一些最 prominent difficulties，并进行了完整和可重现的剥离研究，以示不同架构选择和训练策略对模型测试准确率的影响。我们显示了我们在这篇论文中提出的方法和指导原则可以获得 estado-of-the-art 结果，并提供了强大的基准值，以便 future studies 可以用于比较。为此，我们还发布了高度优化的库在 JAX 上，可以重现所有报告在这篇论文中的结果，促进未来研究，以及方便将新的应用场景适应到现有的模型。
</details></li>
</ul>
<hr>
<h2 id="On-Neural-Quantum-Support-Vector-Machines"><a href="#On-Neural-Quantum-Support-Vector-Machines" class="headerlink" title="On Neural Quantum Support Vector Machines"></a>On Neural Quantum Support Vector Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08467">http://arxiv.org/abs/2308.08467</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GhadaAbdulsalam/Explainable_Heart_Disease_Prediction_Using_Ensemble-Quantum_ML">https://github.com/GhadaAbdulsalam/Explainable_Heart_Disease_Prediction_Using_Ensemble-Quantum_ML</a></li>
<li>paper_authors: Lars Simon, Manuel Radons</li>
<li>for: 本研究旨在探讨神经量子支持向量机（NSVM）的训练方法。</li>
<li>methods: 本文使用四种算法来训练神经支持向量机（NSVM），并证明其可行性。</li>
<li>results: 本文延伸了前一文中的结果，提出神经量子支持向量机（NSVM）和量子核函数的概念，并对其进行扩展。<details>
<summary>Abstract</summary>
In \cite{simon2023algorithms} we introduced four algorithms for the training of neural support vector machines (NSVMs) and demonstrated their feasibility. In this note we introduce neural quantum support vector machines, that is, NSVMs with a quantum kernel, and extend our results to this setting.
</details>
<details>
<summary>摘要</summary>
在《《Algorithms for Training Neural Support Vector Machines》》中（[simon2023algorithms）我们介绍了四种算法用于神经支持向量机（NSVM）的训练，并证明其可行性。在这份note中，我们介绍了神经量子支持向量机（NSVM），即具有量子核函数的NSVM，并扩展我们的结果到这种设定下。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks"><a href="#Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks" class="headerlink" title="Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks"></a>Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08465">http://arxiv.org/abs/2308.08465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Bai, Wenjia Bai</li>
<li>for: 这个论文的目的是建立一个可靠的医学图像分割模型，以及计算模型预测结果的不确定性。</li>
<li>methods: 这个论文使用了一种简单 yet effective的方法，利用 hierarchical image representation 和 skip-connection module 来估计模型预测结果的不确定性。</li>
<li>results: 这个论文的实验结果表明，通过将这种 hierarchical uncertainty estimation module 加入到深度学习图像分割网络中，可以实现高效的图像分割，同时提供了有意义的不确定性地图，可以用于out-of-distribution排除。<details>
<summary>Abstract</summary>
Learning a medical image segmentation model is an inherently ambiguous task, as uncertainties exist in both images (noise) and manual annotations (human errors and bias) used for model training. To build a trustworthy image segmentation model, it is important to not just evaluate its performance but also estimate the uncertainty of the model prediction. Most state-of-the-art image segmentation networks adopt a hierarchical encoder architecture, extracting image features at multiple resolution levels from fine to coarse. In this work, we leverage this hierarchical image representation and propose a simple yet effective method for estimating uncertainties at multiple levels. The multi-level uncertainties are modelled via the skip-connection module and then sampled to generate an uncertainty map for the predicted image segmentation. We demonstrate that a deep learning segmentation network such as U-net, when implemented with such hierarchical uncertainty estimation module, can achieve a high segmentation performance, while at the same time provide meaningful uncertainty maps that can be used for out-of-distribution detection.
</details>
<details>
<summary>摘要</summary>
学习医学图像分割模型是一个自然存在各种不确定性的任务，图像中的噪声和人工标注（人类错误和偏见）在模型训练中都存在不确定性。为建立可靠的图像分割模型，不仅需要评估其性能，还需要估计模型预测结果的不确定性。现有大多数状态的艺术图像分割网络采用层次编码结构，从细致到粗略提取图像特征。在这种工作中，我们利用这种层次图像表示，并提议一种简单 yet effective的方法来估计多个水平的不确定性。这些多个不确定性被模拟为跳过连接模块，然后采样以生成预测图像分割结果的不确定性地图。我们示示了一个深度学习分割网络如U-Net，当其与多个水平不确定性估计模块相结合时，可以实现高级别的分割性能，同时也可以提供有意义的不确定性地图，用于非标准分布检测。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.LG_2023_08_17/" data-id="clmjn91mk00730j88htf25fzt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/18/eess.IV_2023_08_18/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-18 17:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/17/cs.SD_2023_08_17/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-17 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">69</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">32</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
