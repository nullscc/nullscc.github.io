
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-08-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="SoilNet: An Attention-based Spatio-temporal Deep Learning Framework for Soil Organic Carbon Prediction with Digital Soil Mapping in Europe paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.03586 repo_url: None pap">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-08-07">
<meta property="og:url" content="https://nullscc.github.io/2023/08/07/eess.IV_2023_08_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="SoilNet: An Attention-based Spatio-temporal Deep Learning Framework for Soil Organic Carbon Prediction with Digital Soil Mapping in Europe paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.03586 repo_url: None pap">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-07T09:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T08:45:47.819Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_08_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/07/eess.IV_2023_08_07/" class="article-date">
  <time datetime="2023-08-07T09:00:00.000Z" itemprop="datePublished">2023-08-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-08-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SoilNet-An-Attention-based-Spatio-temporal-Deep-Learning-Framework-for-Soil-Organic-Carbon-Prediction-with-Digital-Soil-Mapping-in-Europe"><a href="#SoilNet-An-Attention-based-Spatio-temporal-Deep-Learning-Framework-for-Soil-Organic-Carbon-Prediction-with-Digital-Soil-Mapping-in-Europe" class="headerlink" title="SoilNet: An Attention-based Spatio-temporal Deep Learning Framework for Soil Organic Carbon Prediction with Digital Soil Mapping in Europe"></a>SoilNet: An Attention-based Spatio-temporal Deep Learning Framework for Soil Organic Carbon Prediction with Digital Soil Mapping in Europe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03586">http://arxiv.org/abs/2308.03586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nafiseh Kakhani, Moien Rangzan, Ali Jamali, Sara Attarchi, Seyed Kazem Alavipanah, Thomas Scholten</li>
<li>for: 这个研究旨在精确地描述土壤属性的空间分布，并且运用深度学习技术来预测土壤碳数量。</li>
<li>methods: 本研究提出了一个新的架构， combining 类神经网络（CNN）模型和时间缓冲机制，以及一个长期记忆（LSTM）网络，用于预测欧洲各地的土壤碳数量。</li>
<li>results: 研究结果显示，提案的架构比普遍使用的机器学习方法（如随机森林）精度高，具有较低的根平方差误差（RMSE）。这个模型可以作为预测土壤碳数量的robust工具，并且可以应用到其他土壤特性的预测中。<details>
<summary>Abstract</summary>
Digital soil mapping (DSM) is an advanced approach that integrates statistical modeling and cutting-edge technologies, including machine learning (ML) methods, to accurately depict soil properties and their spatial distribution. Soil organic carbon (SOC) is a crucial soil attribute providing valuable insights into soil health, nutrient cycling, greenhouse gas emissions, and overall ecosystem productivity. This study highlights the significance of spatial-temporal deep learning (DL) techniques within the DSM framework. A novel architecture is proposed, incorporating spatial information using a base convolutional neural network (CNN) model and spatial attention mechanism, along with climate temporal information using a long short-term memory (LSTM) network, for SOC prediction across Europe. The model utilizes a comprehensive set of environmental features, including Landsat-8 images, topography, remote sensing indices, and climate time series, as input features. Results demonstrate that the proposed framework outperforms conventional ML approaches like random forest commonly used in DSM, yielding lower root mean square error (RMSE). This model is a robust tool for predicting SOC and could be applied to other soil properties, thereby contributing to the advancement of DSM techniques and facilitating land management and decision-making processes based on accurate information.
</details>
<details>
<summary>摘要</summary>
《数字化土壤地图（DSM）是一种高级方法，通过统计模型和先进技术，包括机器学习（ML）方法，准确描述土壤属性和其空间分布。土壤有机碳（SOC）是一项重要的土壤特征，提供了有价值的信息关于土壤健康、营养循环、温室气体排放和生态系统产生力。本研究强调了在 DSM 框架中使用深度学习（DL）技术的重要性。本文提出了一种新的架构，其包括使用基本的卷积神经网络（CNN）模型和空间注意机制，以及使用长期短 памяouss术（LSTM）网络，为欧洲地区的 SOC 预测。该模型使用了包括 Landsat-8 图像、地形、遥感指数和气候时间序列等环境特征作为输入特征。结果表明，提议的框架在比Random Forest 常用于 DSM 的 ML 方法下，得到了更低的根平均方差误差（RMSE）。这种模型是一种可靠的 SOC 预测工具，可以应用于其他土壤属性预测，从而为土地管理和决策过程提供准确信息的支持。
</details></li>
</ul>
<hr>
<h2 id="Quantitative-MR-Image-Reconstruction-using-Parameter-Specific-Dictionary-Learning-with-Adaptive-Dictionary-Size-and-Sparsity-Level-Choice"><a href="#Quantitative-MR-Image-Reconstruction-using-Parameter-Specific-Dictionary-Learning-with-Adaptive-Dictionary-Size-and-Sparsity-Level-Choice" class="headerlink" title="Quantitative MR Image Reconstruction using Parameter-Specific Dictionary Learning with Adaptive Dictionary-Size and Sparsity-Level Choice"></a>Quantitative MR Image Reconstruction using Parameter-Specific Dictionary Learning with Adaptive Dictionary-Size and Sparsity-Level Choice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03460">http://arxiv.org/abs/2308.03460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Kofler, Kirsten Miriam Kerkering, Laura Göschel, Ariane Fillmer, Cristoph Kolbitsch</li>
<li>for: 提出一种方法用于量化磁共振成像（QMRI）中的参数地图重建。</li>
<li>methods: 使用字典学习（DL）和稀疏编码（SC）算法自动计算参数地图的最佳字典大小和稀疏程度，并对每个参数地图进行自适应调整。</li>
<li>results: 相比MAP方法和其他基于稀疏性的方法（TV、Wl、Sh），提出的方法在PSNR和RMSE上表现更好，同时能够加速重建过程约七倍。Here’s the full text in Simplified Chinese:</li>
<li>for: 本文提出了一种方法，用于量化磁共振成像（QMRI）中的参数地图重建。</li>
<li>methods: 该方法使用字典学习（DL）和稀疏编码（SC）算法自动计算参数地图的最佳字典大小和稀疏程度，并对每个参数地图进行自适应调整。</li>
<li>results: 相比MAP方法和其他基于稀疏性的方法（TV、Wl、Sh），提出的方法在PSNR和RMSE上表现更好，同时能够加速重建过程约七倍。I hope that helps!<details>
<summary>Abstract</summary>
Objective: We propose a method for the reconstruction of parameter-maps in Quantitative Magnetic Resonance Imaging (QMRI).   Methods: Because different quantitative parameter-maps differ from each other in terms of local features, we propose a method where the employed dictionary learning (DL) and sparse coding (SC) algorithms automatically estimate the optimal dictionary-size and sparsity level separately for each parameter-map. We evaluated the method on a $T_1$-mapping QMRI problem in the brain using the BrainWeb data as well as in-vivo brain images acquired on an ultra-high field 7T scanner. We compared it to a model-based acceleration for parameter mapping (MAP) approach, other sparsity-based methods using total variation (TV), Wavelets (Wl) and Shearlets (Sh), and to a method which uses DL and SC to reconstruct qualitative images, followed by a non-linear (DL+Fit).   Results: Our algorithm surpasses MAP, TV, Wl and Sh in terms of RMSE and PSNR. It yields better or comparable results to DL+Fit by additionally significantly accelerating the reconstruction by a factor of approximately seven.   Conclusion: The proposed method outperforms the reported methods of comparison and yields accurate $T_1$-maps. Although presented for $T_1$-mapping in the brain, our method's structure is general and thus most probably also applicable for the the reconstruction of other quantitative parameters in other organs.   Significance: From a clinical perspective, the obtained $T_1$-maps could be utilized to differentiate between healthy subjects and patients with Alzheimer's disease. From a technical perspective, the proposed unsupervised method could be employed to obtain ground-truth data for the development of data-driven methods based on supervised learning.+
</details>
<details>
<summary>摘要</summary>
Methods: 因为不同的量化参数地图之间的本地特征不同，我们提议使用自适应词库学习（DL）和稀疏编码（SC）算法自动计算参数地图的优化词库大小和稀疏性水平。我们对BrainWeb数据集和7T磁共振成像机上实验取得的生物体内部图像进行评估。我们与参数映射（MAP）方法、总变量（TV）、波лет（Wl）和扭变（Sh）等其他稀疏方法进行比较，以及使用DL和SC重建质量图像，然后使用非线性（DL+Fit）方法。Results: 我们的算法在RMSE和PSNR方面都高于MAP、TV、Wl和Sh，并且与DL+Fit相比，同时提供了约七倍的加速。Conclusion: 我们提出的方法在$T_1$-mapping问题上表现出色，并且可以在脑部其他参数的重建中使用。尽管我们只对脑部的$T_1$-mapping进行了评估，但我们的方法结构是通用的，因此可能适用于其他器官的量化参数重建。Significance: 从临床角度来看，获得的$T_1$-地图可能用于识别健康人群和患有阿尔茨海默病的患者。从技术角度来看，我们提出的无监督方法可以用于获得数据驱动学习方法的基准数据。
</details></li>
</ul>
<hr>
<h2 id="Lighting-Every-Darkness-in-Two-Pairs-A-Calibration-Free-Pipeline-for-RAW-Denoising"><a href="#Lighting-Every-Darkness-in-Two-Pairs-A-Calibration-Free-Pipeline-for-RAW-Denoising" class="headerlink" title="Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising"></a>Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03448">http://arxiv.org/abs/2308.03448</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/srameo/led">https://github.com/srameo/led</a></li>
<li>paper_authors: Xin Jin, Jia-Wen Xiao, Ling-Hao Han, Chunle Guo, Ruixun Zhang, Xialei Liu, Chongyi Li</li>
<li>for: 提高低光环境下 RAW 图像减噪性能，不需要干扰式减噪方法。</li>
<li>methods: 基于减噪策略，对目标摄像机进行几次匹配数据和微调，以适应不同摄像机和数字增量。同时，通过特殊的结构修改，解决synthetic noise和实际噪声之间的域距离问题。</li>
<li>results: 与其他干扰式减噪方法相比，本方法在6对增量数据和0.5%迭代后，在低光环境下达到了更高的性能。<details>
<summary>Abstract</summary>
Calibration-based methods have dominated RAW image denoising under extremely low-light environments. However, these methods suffer from several main deficiencies: 1) the calibration procedure is laborious and time-consuming, 2) denoisers for different cameras are difficult to transfer, and 3) the discrepancy between synthetic noise and real noise is enlarged by high digital gain. To overcome the above shortcomings, we propose a calibration-free pipeline for Lighting Every Drakness (LED), regardless of the digital gain or camera sensor. Instead of calibrating the noise parameters and training repeatedly, our method could adapt to a target camera only with few-shot paired data and fine-tuning. In addition, well-designed structural modification during both stages alleviates the domain gap between synthetic and real noise without any extra computational cost. With 2 pairs for each additional digital gain (in total 6 pairs) and 0.5% iterations, our method achieves superior performance over other calibration-based methods. Our code is available at https://github.com/Srameo/LED .
</details>
<details>
<summary>摘要</summary>
准确性基于方法在极低照度环境中对RAW图像净化得到了广泛应用。然而，这些方法受到以下主要缺点的影响：1）准备和实施准化过程是时间consuming和劳动密集的；2）描述器对不同的相机难以传递；3）高度数字增强会使 synthetic 噪声与实际噪声之间的差距变大。为了缓解以上缺点，我们提出了不需要准化的激光照明每个点（LED）管道，无论相机感知器或数字增强。而不是在每次训练中重复准化噪声参数，我们的方法可以适应目标相机只需要几个数据对和微调。此外，我们在两个阶段中设计了结构修改，以避免噪声生成器和实际噪声之间的领域差距，无需额外计算成本。使用2对每个附加的数字增强（总共6对）和0.5%迭代，我们的方法可以在其他准化基于方法上达到更高的性能。我们的代码可以在https://github.com/Srameo/LED 上找到。
</details></li>
</ul>
<hr>
<h2 id="Energy-Guided-Diffusion-Model-for-CBCT-to-CT-Synthesis"><a href="#Energy-Guided-Diffusion-Model-for-CBCT-to-CT-Synthesis" class="headerlink" title="Energy-Guided Diffusion Model for CBCT-to-CT Synthesis"></a>Energy-Guided Diffusion Model for CBCT-to-CT Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03354">http://arxiv.org/abs/2308.03354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linjie Fu, Xia Li, Xiuding Cai, Dong Miao, Yu Yao, Yali Shen</li>
<li>for: 提高CBCT图像质量和Hounsfield单位精度，以便更好地用于放射治疗</li>
<li>methods: 基于能量导向扩散模型(EGDiff)，从CBCT图像生成synthetic CT(sCT)</li>
<li>results: 对胸腔肿瘤数据集进行实验，得到了具有较高精度和视觉质量的sCT图像，并且超过了现有无监督合成方法的性能。<details>
<summary>Abstract</summary>
Cone Beam CT (CBCT) plays a crucial role in Adaptive Radiation Therapy (ART) by accurately providing radiation treatment when organ anatomy changes occur. However, CBCT images suffer from scatter noise and artifacts, making relying solely on CBCT for precise dose calculation and accurate tissue localization challenging. Therefore, there is a need to improve CBCT image quality and Hounsfield Unit (HU) accuracy while preserving anatomical structures. To enhance the role and application value of CBCT in ART, we propose an energy-guided diffusion model (EGDiff) and conduct experiments on a chest tumor dataset to generate synthetic CT (sCT) from CBCT. The experimental results demonstrate impressive performance with an average absolute error of 26.87$\pm$6.14 HU, a structural similarity index measurement of 0.850$\pm$0.03, a peak signal-to-noise ratio of the sCT of 19.83$\pm$1.39 dB, and a normalized cross-correlation of the sCT of 0.874$\pm$0.04. These results indicate that our method outperforms state-of-the-art unsupervised synthesis methods in accuracy and visual quality, producing superior sCT images.
</details>
<details>
<summary>摘要</summary>
cone beam CT (CBCT) 在适应性辐射疗法 (ART) 中发挥关键作用，准确地提供辐射治疗当器官 анатомиче变化时。然而， CBCT 图像受到扰干噪和artefacts的影响，使凭借 CBCT  alone 准确地计算辐射剂量和精确地地标定组织结构困难。因此，需要改进 CBCT 图像质量和温迪尔单位 (HU) 准确性，同时保持器官结构。为了提高 CBCT 在 ART 中的应用价值，我们提议一种能量导向扩散模型 (EGDiff) ，并在胸腔肿瘤数据集上进行实验，将 CBCT 转换成Synthetic CT (sCT)。实验结果表明，我们的方法可以准确地生成高质量的 sCT 图像，其中平均绝对错误为 26.87$\pm$6.14 HU，结构相似度指数为 0.850$\pm$0.03，峰值响应信号强度为 19.83$\pm$1.39 dB，和正常化交叉相似度为 0.874$\pm$0.04。这些结果表明，我们的方法在精度和视觉质量方面都有出色的表现，生成的 sCT 图像较为优秀。
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-CNN-Transformer-Architecture-with-Frequency-Domain-Contrastive-Learning-for-Image-Deraining"><a href="#A-Hybrid-CNN-Transformer-Architecture-with-Frequency-Domain-Contrastive-Learning-for-Image-Deraining" class="headerlink" title="A Hybrid CNN-Transformer Architecture with Frequency Domain Contrastive Learning for Image Deraining"></a>A Hybrid CNN-Transformer Architecture with Frequency Domain Contrastive Learning for Image Deraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03340">http://arxiv.org/abs/2308.03340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Wang, Wei Li</li>
<li>for: 图像恢复（image restoration），即修复受损图像中的雨线 Streaks 的问题。</li>
<li>methods: 该论文使用了 Deep Learning 技术，特别是 Convolutional Neural Networks (CNNs) 和 Generative Adversarial Networks (GANs)，以实现图像恢复。</li>
<li>results: 该论文实现了高效的图像恢复，可以减少或完全消除雨线 Streaks，并保持图像的原始细节和颜色彩虹。<details>
<summary>Abstract</summary>
Image deraining is a challenging task that involves restoring degraded images affected by rain streaks.
</details>
<details>
<summary>摘要</summary>
图像推Clearing是一项具有挑战性的任务，旨在修复受到雨批 streaks 的图像。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/07/eess.IV_2023_08_07/" data-id="clpxp6cah018tee88hcy1eb3x" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/07/cs.LG_2023_08_07/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-08-07
        
      </div>
    </a>
  
  
    <a href="/2023/08/06/cs.SD_2023_08_06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-06</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
