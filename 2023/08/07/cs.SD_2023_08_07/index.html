
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.SD - 2023-08-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Active Noise Control based on the Momentum Multichannel Normalized Filtered-x Least Mean Square Algorithm paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.03684 repo_url: None paper_authors: Dongyuan Shi, Woon-Se">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.SD - 2023-08-07">
<meta property="og:url" content="https://nullscc.github.io/2023/08/07/cs.SD_2023_08_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Active Noise Control based on the Momentum Multichannel Normalized Filtered-x Least Mean Square Algorithm paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.03684 repo_url: None paper_authors: Dongyuan Shi, Woon-Se">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-07T15:00:00.000Z">
<meta property="article:modified_time" content="2023-09-23T08:45:42.661Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.SD_2023_08_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/07/cs.SD_2023_08_07/" class="article-date">
  <time datetime="2023-08-07T15:00:00.000Z" itemprop="datePublished">2023-08-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.SD - 2023-08-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Active-Noise-Control-based-on-the-Momentum-Multichannel-Normalized-Filtered-x-Least-Mean-Square-Algorithm"><a href="#Active-Noise-Control-based-on-the-Momentum-Multichannel-Normalized-Filtered-x-Least-Mean-Square-Algorithm" class="headerlink" title="Active Noise Control based on the Momentum Multichannel Normalized Filtered-x Least Mean Square Algorithm"></a>Active Noise Control based on the Momentum Multichannel Normalized Filtered-x Least Mean Square Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03684">http://arxiv.org/abs/2308.03684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyuan Shi, Woon-Seng Gan, Bhan Lam, Shulin Wen, Xiaoyi Shen</li>
<li>for: 实现多 канал活动噪声控制 (MCANC) 中的广泛噪声处理区域。</li>
<li>methods: 使用 filter-x least mean square (FxLMS) 算法，但它的快速减退速度使得在面对快速变化的噪声时，表现不佳。此外，噪声功率的变化也会损害算法的稳定性。</li>
<li>results: 通过与征算法结合了惯性方法，使得算法更加快速地趋向稳定点，并且更好地避免了主要噪声功率的干扰。<details>
<summary>Abstract</summary>
Multichannel active noise control (MCANC) is widely utilized to achieve significant noise cancellation area in the complicated acoustic field. Meanwhile, the filter-x least mean square (FxLMS) algorithm gradually becomes the benchmark solution for the implementation of MCANC due to its low computational complexity. However, its slow convergence speed more or less undermines the performance of dealing with quickly varying disturbances, such as piling noise. Furthermore, the noise power variation also deteriorates the robustness of the algorithm when it adopts the fixed step size. To solve these issues, we integrated the normalized multichannel FxLMS with the momentum method, which hence, effectively avoids the interference of the primary noise power and accelerates the convergence of the algorithm. To validate its effectiveness, we deployed this algorithm in a multichannel noise control window to control the real machine noise.
</details>
<details>
<summary>摘要</summary>
多通道活动噪声控制（MCANC）广泛应用于复杂的噪声场中实现显著的噪声抑制面积。同时，Filter-x最小二乘（FxLMS）算法逐渐成为MCANC实现的标准解决方案，因为它的计算复杂性较低。然而，它的慢速收敛速度在面对快变化的干扰时，很大程度地降低了性能。此外，噪声功率变化也降低了算法的稳定性，特别是当采用固定步长时。为解决这些问题，我们将normalized multichannel FxLMS与势量方法结合，从而有效地避免了主要噪声功率的干扰和加速了算法的收敛。为验证其效果，我们在多通道噪声控制窗口中应用了这种算法来控制实际机器噪声。
</details></li>
</ul>
<hr>
<h2 id="AudioVMAF-Audio-Quality-Prediction-with-VMAF"><a href="#AudioVMAF-Audio-Quality-Prediction-with-VMAF" class="headerlink" title="AudioVMAF: Audio Quality Prediction with VMAF"></a>AudioVMAF: Audio Quality Prediction with VMAF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03437">http://arxiv.org/abs/2308.03437</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Biswas, Harald Mundt</li>
<li>for: 提高编码音频质量评估的精度</li>
<li>methods: 基于现有VMAF的听觉前端创建参考视频和编码spectrogram，并扩展VMAF来评估编码音频质量</li>
<li>results: 提出的AudioVMAF系统在带宽限制场景下表现出更高的预测精度，并在比较已有视觉质量特征与专门的音频质量指标（ViSQOL-v3）中显示出7.8%和2.0%的显著提高。<details>
<summary>Abstract</summary>
Video Multimethod Assessment Fusion (VMAF) [1], [2], [3] is a popular tool in the industry for measuring coded video quality. In this study, we propose an auditory-inspired frontend in existing VMAF for creating videos of reference and coded spectrograms, and extended VMAF for measuring coded audio quality. We name our system AudioVMAF. We demonstrate that image replication is capable of further enhancing prediction accuracy, especially when band-limited anchors are present. The proposed method significantly outperforms all existing visual quality features repurposed for audio, and even demonstrates a significant overall improvement of 7.8% and 2.0% of Pearson and Spearman rank correlation coefficient, respectively, over a dedicated audio quality metric (ViSQOL-v3 [4]) also inspired from the image domain.
</details>
<details>
<summary>摘要</summary>
视频多方法评估融合（VMAF）是行业中广泛使用的视频质量评估工具。在本研究中，我们提出一种听力 inspirited 的前端，用于创建参考视频和编码спектрограм，并扩展了VMAF以测量编码音频质量。我们称之为AudioVMAF。我们示出，图像复制能够进一步提高预测精度，特别是在存在带限 anchors 时。我们的方法在所有现有的视觉质量特征的抽象下表现出色，并在ViSQOL-v3 （4）中显示了 significan 7.8% 和 2.0% 的潘森和斯宾塞排名相关系数，分别。
</details></li>
</ul>
<hr>
<h2 id="Improving-Deep-Attractor-Network-by-BGRU-and-GMM-for-Speech-Separation"><a href="#Improving-Deep-Attractor-Network-by-BGRU-and-GMM-for-Speech-Separation" class="headerlink" title="Improving Deep Attractor Network by BGRU and GMM for Speech Separation"></a>Improving Deep Attractor Network by BGRU and GMM for Speech Separation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03332">http://arxiv.org/abs/2308.03332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rawad Melhem, Assef Jafar, Riad Hamadeh</li>
<li>for: 这个论文是为了提出一种简化了DANet模型，使其更加强大和简单的 speech separation 模型。</li>
<li>methods: 该模型使用了bidirectional gated neural network (BGRU) 代替了 bidirectional long short-term memory (BLSTM)，并使用 Gaussian Mixture Model (GMM) 作为聚类算法来降低复杂性和提高学习速度和准确性。</li>
<li>results: 在使用 TIMIT 语音数据集进行评估时，提出的模型可以达到12.3 dB和2.94的 SDR 和 PESQ 分数，比原始 DANet 模型更好。此外，该模型还减少了20.7%和17.9%的参数数量和训练时间。最后，该模型在混合阿拉伯语音信号上进行评估，得到了更好的结果。<details>
<summary>Abstract</summary>
Deep Attractor Network (DANet) is the state-of-the-art technique in speech separation field, which uses Bidirectional Long Short-Term Memory (BLSTM), but the complexity of the DANet model is very high. In this paper, a simplified and powerful DANet model is proposed using Bidirectional Gated neural network (BGRU) instead of BLSTM. The Gaussian Mixture Model (GMM) other than the k-means was applied in DANet as a clustering algorithm to reduce the complexity and increase the learning speed and accuracy. The metrics used in this paper are Signal to Distortion Ratio (SDR), Signal to Interference Ratio (SIR), Signal to Artifact Ratio (SAR), and Perceptual Evaluation Speech Quality (PESQ) score. Two speaker mixture datasets from TIMIT corpus were prepared to evaluate the proposed model, and the system achieved 12.3 dB and 2.94 for SDR and PESQ scores respectively, which were better than the original DANet model. Other improvements were 20.7% and 17.9% in the number of parameters and time training, respectively. The model was applied on mixed Arabic speech signals and the results were better than that in English.
</details>
<details>
<summary>摘要</summary>
深度吸引网络（DANet）是现代语音分离领域的状态元技术，使用了双向长短期记忆（BLSTM），但DANet模型的复杂性很高。在本文中，一种简化了DANet模型，使用了双向闭合神经网络（BGRU）而不是BLSTM。 Gaussian Mixture Model（GMM）在DANet中作为聚类算法来降低复杂性和提高学习速度和准确性。本文使用的度量包括信号质量至噪声比（SDR）、信号质量至干扰比（SIR）、信号质量至噪声比（SAR）和语音质量评价分数（PESQ）。使用TIMIT corpus中的两个说话者混合数据集进行评估，提出的模型在SDR和PESQ分数上分别达到12.3 dB和2.94，比原始DANet模型更好。此外，模型的参数数量和训练时间都有20.7%和17.9%的下降。该模型在混合阿拉伯语音信号上得到了更好的结果，比英语更好。
</details></li>
</ul>
<hr>
<h2 id="SeACo-Paraformer-A-Non-Autoregressive-ASR-System-with-Flexible-and-Effective-Hotword-Customization-Ability"><a href="#SeACo-Paraformer-A-Non-Autoregressive-ASR-System-with-Flexible-and-Effective-Hotword-Customization-Ability" class="headerlink" title="SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability"></a>SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03266">http://arxiv.org/abs/2308.03266</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/r1ckshi/seaco-paraformer">https://github.com/r1ckshi/seaco-paraformer</a></li>
<li>paper_authors: Xian Shi, Yexin Yang, Zerui Li, Shiliang Zhang</li>
<li>for: 提高 ASR 系统中热词定制的灵活性和效果性。</li>
<li>methods: 提出 Semantic-augmented Contextual-Paraformer (SeACo-Paraformer) 模型，结合 AED 模型的精度、NAR 模型的效率和Contextualization 能力，实现热词定制的灵活性和效果性。</li>
<li>results: 在50,000小时工业大数据实验中，提出的模型比强基eline在定制和总 ASR 任务中表现出色，同时提出了一种高效的大规模热词筛选方法。 industrial models 和两个热词测试集都已经公开。<details>
<summary>Abstract</summary>
Hotword customization is one of the important issues remained in ASR field - it is of value to enable users of ASR systems to customize names of entities, persons and other phrases. The past few years have seen both implicit and explicit modeling strategies for ASR contextualization developed. While these approaches have performed adequately, they still exhibit certain shortcomings such as instability in effectiveness. In this paper we propose Semantic-augmented Contextual-Paraformer (SeACo-Paraformer) a novel NAR based ASR system with flexible and effective hotword customization ability. It combines the accuracy of the AED-based model, the efficiency of the NAR model, and the excellent performance in contextualization. In 50,000 hours industrial big data experiments, our proposed model outperforms strong baselines in customization and general ASR tasks. Besides, we explore an efficient way to filter large scale incoming hotwords for further improvement. The source codes and industrial models proposed and compared are all opened as well as two hotword test sets.
</details>
<details>
<summary>摘要</summary>
“热词自定义是ASR领域中一个重要的 issuesthat is of great value to enable users of ASR systems to customize names of entities, persons, and other phrases. Recently, both implicit and explicit modeling strategies for ASR contextualization have been developed, but they still have some shortcomings such as instability in effectiveness. In this paper, we propose a novel NAR-based ASR system with flexible and effective hotword customization ability, called Semantic-augmented Contextual-Paraformer (SeACo-Paraformer). It combines the accuracy of the AED-based model, the efficiency of the NAR model, and the excellent performance in contextualization. In 50,000 hours of industrial big data experiments, our proposed model outperforms strong baselines in customization and general ASR tasks. Furthermore, we explore an efficient way to filter large-scale incoming hotwords for further improvement. The source codes and industrial models proposed and compared are all open, as well as two hotword test sets.”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Investigation-of-Self-supervised-Pre-trained-Models-for-Classification-of-Voice-Quality-from-Speech-and-Neck-Surface-Accelerometer-Signals"><a href="#Investigation-of-Self-supervised-Pre-trained-Models-for-Classification-of-Voice-Quality-from-Speech-and-Neck-Surface-Accelerometer-Signals" class="headerlink" title="Investigation of Self-supervised Pre-trained Models for Classification of Voice Quality from Speech and Neck Surface Accelerometer Signals"></a>Investigation of Self-supervised Pre-trained Models for Classification of Voice Quality from Speech and Neck Surface Accelerometer Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03226">http://arxiv.org/abs/2308.03226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudarsana Reddy Kadiri, Farhad Javanmardi, Paavo Alku</li>
<li>for: 这个研究的目的是研究自动分类声音质量的方法，特别是使用同时记录的语音和脊梁压力仪（NSA）信号作为输入，并提取MFCCs和颚部源特征。</li>
<li>methods: 这个研究使用了三个自助学习模型（wav2vec2-BASE、wav2vec2-LARGE和HuBERT）生成的特征，以及支持向量机（SVM）和卷积神经网络（CNN）作为分类器。此外，研究还对颚部源波形和原始信号波形进行了两种信号处理方法（ quasi-closed phase（QCP）颚部逆滤波和零频 filtering（ZFF））来生成颚部源波形。</li>
<li>results: 研究发现，使用 NSA 输入可以比语音输入更好地进行分类，而且使用预训练模型生成的特征可以提高分类精度，特别是对于语音和 NSA 输入。此外，研究还发现 HuBERT 特征在分类任务中表现更好于 wav2vec2-BASE 和 wav2vec2-LARGE 特征。<details>
<summary>Abstract</summary>
Prior studies in the automatic classification of voice quality have mainly studied the use of the acoustic speech signal as input. Recently, a few studies have been carried out by jointly using both speech and neck surface accelerometer (NSA) signals as inputs, and by extracting MFCCs and glottal source features. This study examines simultaneously-recorded speech and NSA signals in the classification of voice quality (breathy, modal, and pressed) using features derived from three self-supervised pre-trained models (wav2vec2-BASE, wav2vec2-LARGE, and HuBERT) and using a SVM as well as CNNs as classifiers. Furthermore, the effectiveness of the pre-trained models is compared in feature extraction between glottal source waveforms and raw signal waveforms for both speech and NSA inputs. Using two signal processing methods (quasi-closed phase (QCP) glottal inverse filtering and zero frequency filtering (ZFF)), glottal source waveforms are estimated from both speech and NSA signals. The study has three main goals: (1) to study whether features derived from pre-trained models improve classification accuracy compared to conventional features (spectrogram, mel-spectrogram, MFCCs, i-vector, and x-vector), (2) to investigate which of the two modalities (speech vs. NSA) is more effective in the classification task with pre-trained model-based features, and (3) to evaluate whether the deep learning-based CNN classifier can enhance the classification accuracy in comparison to the SVM classifier. The results revealed that the use of the NSA input showed better classification performance compared to the speech signal. Between the features, the pre-trained model-based features showed better classification accuracies, both for speech and NSA inputs compared to the conventional features. It was also found that the HuBERT features performed better than the wav2vec2-BASE and wav2vec2-LARGE features.
</details>
<details>
<summary>摘要</summary>
先前的研究主要是使用语音信号来自动分类voice quality，现在有一些研究使用语音和颈部表面加速器（NSA）信号同时录制，并提取MFCCs和颈部源特征。本研究通过使用三种自动学习模型（wav2vec2-BASE、wav2vec2-LARGE和HuBERT）提取特征，使用SVM和CNN作为分类器，研究语音和NSA信号同时录制的voice quality分类效果。此外，还比较了三种模型在特征提取中的效果，以及使用不同的信号处理方法（ quasi-closed phase颈部逆推和zero frequency filtering）来提取颈部源波形。研究的主要目标是：1. 研究使用预训练模型提取的特征是否能够提高分类精度，比较传统特征（spectrogram、mel-spectrogram、MFCCs、i-vector和x-vector）的效果。2. 研究语音和NSA信号中哪一种Modalities更有效iveness在分类任务中，并使用预训练模型基于特征进行分类。3. 研究使用深度学习基于CNN的分类器是否能够提高分类精度，相比SVM分类器。结果表明，使用NSA输入信号可以实现更好的分类性能，而且使用预训练模型基于特征可以提高分类精度，无论是语音还是NSA输入信号。此外，HuBERT特征也表现出了更高的分类精度。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/07/cs.SD_2023_08_07/" data-id="clombedwk00tds088cywd1a8w" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/08/eess.IV_2023_08_08/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-08
        
      </div>
    </a>
  
  
    <a href="/2023/08/07/cs.CV_2023_08_07/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CV - 2023-08-07</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">113</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">63</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
