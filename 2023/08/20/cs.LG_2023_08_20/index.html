
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-20 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.10302 repo_url: None paper_authors: Junhao Zhang, Qianqian W">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-20 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/20/cs.LG_2023_08_20/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.10302 repo_url: None paper_authors: Junhao Zhang, Qianqian W">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-19T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:34.118Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.LG_2023_08_20/" class="article-date">
  <time datetime="2023-08-19T16:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-20 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Preserving-Specificity-in-Federated-Graph-Learning-for-fMRI-based-Neurological-Disorder-Identification"><a href="#Preserving-Specificity-in-Federated-Graph-Learning-for-fMRI-based-Neurological-Disorder-Identification" class="headerlink" title="Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification"></a>Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10302">http://arxiv.org/abs/2308.10302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhao Zhang, Qianqian Wang, Xiaochuan Wang, Lishan Qiao, Mingxia Liu</li>
<li>for: 这个研究旨在应用Resting-state functional magnetic resonance imaging (rs-fMRI)和 Federated Learning (FL)技术来探索脑疾病的不均衡连接性，并且考虑到体域特点如年龄、性别和教育水准。</li>
<li>methods: 本研究使用了Graph Neural Network (GNN)和 Federated Learning (FL)技术，并且提出了特定性敏感 Federated Graph Learning (SFGL)框架，以探索不同体域特点下的脑疾病特征。</li>
<li>results: 实验结果显示，SFGL方法在两个rs-fMRI数据集上的调整后，较前方的方法提高了10%至20%的准确率。<details>
<summary>Abstract</summary>
Resting-state functional magnetic resonance imaging (rs-fMRI) offers a non-invasive approach to examining abnormal brain connectivity associated with brain disorders. Graph neural network (GNN) gains popularity in fMRI representation learning and brain disorder analysis with powerful graph representation capabilities. Training a general GNN often necessitates a large-scale dataset from multiple imaging centers/sites, but centralizing multi-site data generally faces inherent challenges related to data privacy, security, and storage burden. Federated Learning (FL) enables collaborative model training without centralized multi-site fMRI data. Unfortunately, previous FL approaches for fMRI analysis often ignore site-specificity, including demographic factors such as age, gender, and education level. To this end, we propose a specificity-aware federated graph learning (SFGL) framework for rs-fMRI analysis and automated brain disorder identification, with a server and multiple clients/sites for federated model aggregation and prediction. At each client, our model consists of a shared and a personalized branch, where parameters of the shared branch are sent to the server while those of the personalized branch remain local. This can facilitate knowledge sharing among sites and also helps preserve site specificity. In the shared branch, we employ a spatio-temporal attention graph isomorphism network to learn dynamic fMRI representations. In the personalized branch, we integrate vectorized demographic information (i.e., age, gender, and education years) and functional connectivity networks to preserve site-specific characteristics. Representations generated by the two branches are then fused for classification. Experimental results on two fMRI datasets with a total of 1,218 subjects suggest that SFGL outperforms several state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
RESTING-STATE ФУНКЦИОНАЛНО МАГНЕТНО РЕЗОНАНСНА ИМАЖИНГ (RS-fMRI) ПРОВОДИ ГНИЛОСТИВЫЙ ПОДХОД К ИЗУЧЕНИЮ АБНОРМАЛЬНОЙ БРАИНОВОЙ СОЕДИНЕНИЯ ПРОВОДЗЕМ СО БРАИНОВЫМИ РАЗЛИЧИЯМИ. ГРАФОВАЯ НЕРВНАЯ СИСТЕМА (GNN) ЗНАЧАЕТСЯ В ФМРИ ЗАПИСИВАНИЕ И БРАИНОВОЙ РАЗЛИЧИЕВАНИИ СО ВСЕМОГОВОРТНОЙ ГРАФОЙОЙ РЕПРЕСЕНТАЦИЕЙ. ОБУЧЕНИЕ ГЕНЕРАЛЬНОЙ GNN НОВОЕ РЕЗУЛЬТАТО ВОЗМОЖНО СОВЕРШИТЬ БЕЗ ЦЕНТРАЛИЗОВАННОГО МНОГОСИТЕЙНОГО ДАННЫХ, НО ОБЫЧЕСКИЕ ПРОТОКОЛЫ ФЛЕARNING (FL) ДЛЯ ФМРИАНАЛИЗА СНИЖАЮТ ОБЪЕМ ДАННЫХ ПО КОРАБОРАТИВНОМУ ОБЪЕМУ. НО В ПРЕДЫДСТВИИ ТОГО, ПРОПОЛОЖЕННЫЕ ФЛЕARNING (SFGL) ПРОВОДИТ К КОМБИНИРОВАНИЮ МЕСТООБРАЗНЫХ КАРАКТЕРИСТИК ИЗУЧЕНИЯ БРАИНОВОГО РАЗЛИЧИЕВАНИА. В НАШЕМ ФРАМВОРКЕ, МАТЕРИАЛЫ СЕРВЕРА И МУЛЬТИПЛОВЫЕ КЛИЕНТЫ/СИТИ ИСКАЗЫВАТЬСЯ В ФЕДЕРАТИВНОМ ОБЪЕМЕ, ГДЕ ВСЕ КЛИЕНТЫ ПРОВОДЗЕМ ИЗ СЕРВЕРА СОБСТВЕННЫЕ И ПЕРСОНАЛИЗОВАННЫЕ БРАНЧИ. В СОБСТВЕННОМ БРАНЧЕ МЫ ЗЕМЛЯЕМ СПАЦИО-ВРЕМЕННЫЙ ВАТЕРНЫЙ ГРАФОВЫЙ ИЗОМОРФИЗМ КАК РЕПРЕСЕНТАЦИЮ ФМРИ. В ПЕРСОНАЛИЗОВАННЫМ БРАНЧЕ МЫ СОБИРАЕММ ВЕКТОРИЗИРОВАННЫЕ ДЕМОГРАФИЧЕСКИЕ ИЗМЕРЕНИЯ (НАПРИМЕР, ВОСРОД СТОРОК, И УЧЕТ ОБУЧЕНИЯ) И ФУНКЦИОНАЛЬНУЮ СОЕДИНЕННУЮ СИТЬ, ЧТОБЫ ПРЕЗЕРВИТЬ МЕСТООБРАЗНЫЕ КАРАКТЕРИСТИКИ. ЗАПИСИВАННЫЕ В ДВУХ БРАНЧАХ ЗАТОМ СОБИРАЕТСЯ ДЛЯ КЛАССИРОВКИ. ЭКСПЕРИМЕНТАЛЬНЫЕ РЕЗУЛЬТАТЫ ПРОВОДИТЫ КТОРЫМУ, ЧТО SFGL ПРОВОДИТ К БЫСТРОМ И ГОРОДОМ ПОКОВКЕ, ПРОТИВОЗАПИСАНИЮ ИЗУЧЕНИЯ БРАИНОВОГО РАЗЛИЧИЕВАНИА.
</details></li>
</ul>
<hr>
<h2 id="An-interpretable-deep-learning-method-for-bearing-fault-diagnosis"><a href="#An-interpretable-deep-learning-method-for-bearing-fault-diagnosis" class="headerlink" title="An interpretable deep learning method for bearing fault diagnosis"></a>An interpretable deep learning method for bearing fault diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10292">http://arxiv.org/abs/2308.10292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Lu, Austin M. Bray, Chao Hu, Andrew T. Zimmerman, Hongyi Xu</li>
<li>for: 这个研究旨在解决深度学习模型中的黑盒问题，以提高人工维护人员对模型的信任度。</li>
<li>methods: 本研究使用了卷积神经网组合Gradient-weighted Class Activation Mapping（Grad-CAM）来实现深度学习模型的解释和可读性。</li>
<li>results: 研究结果显示，使用Grad-CAM可以从training sample中找到重要的特征对照，并将其annotate为健康库（health library）中的一部分。在评估过程中，提出的方法可以从健康库中选择相似的预测基础样本，以提高模型的可信度。<details>
<summary>Abstract</summary>
Deep learning (DL) has gained popularity in recent years as an effective tool for classifying the current health and predicting the future of industrial equipment. However, most DL models have black-box components with an underlying structure that is too complex to be interpreted and explained to human users. This presents significant challenges when deploying these models for safety-critical maintenance tasks, where non-technical personnel often need to have complete trust in the recommendations these models give. To address these challenges, we utilize a convolutional neural network (CNN) with Gradient-weighted Class Activation Mapping (Grad-CAM) activation map visualizations to form an interpretable DL method for classifying bearing faults. After the model training process, we apply Grad-CAM to identify a training sample's feature importance and to form a library of diagnosis knowledge (or health library) containing training samples with annotated feature maps. During the model evaluation process, the proposed approach retrieves prediction basis samples from the health library according to the similarity of the feature importance. The proposed method can be easily applied to any CNN model without modifying the model architecture, and our experimental results show that this method can select prediction basis samples that are intuitively and physically meaningful, improving the model's trustworthiness for human users.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）在最近几年内得到了广泛应用，用于现代工业设备的类型和未来预测。然而，大多数DL模型具有黑盒子组件，其下面结构太复杂，无法被人类用户理解和解释。这些问题在安全维护任务中具有重要性，因为非技术人员经常需要对这些模型的建议产生完全的信任。为解决这些问题，我们使用卷积神经网络（CNN）和梯度权重分类图像（Grad-CAM）活动图像可视化来形成可解释的DL方法，用于分类承载问题。在模型训练过程中，我们使用Grad-CAM来标识训练样本的特征重要性，并将其作为健康图书馆（health library）中的训练样本，并将其标注为特征图像。在评估模型过程中，我们的方法可以从健康图书馆中检索预测基础样本，根据特征重要性的相似性。我们的方法可以轻松地应用于任何CNN模型，无需修改模型结构，我们的实验结果表明，这种方法可以选择Physically meaningful和直观的预测基础样本，提高模型的人类用户的信任度。
</details></li>
</ul>
<hr>
<h2 id="Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi"><a href="#Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi" class="headerlink" title="Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi"></a>Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10284">http://arxiv.org/abs/2308.10284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Nekoei, Xutong Zhao, Janarthanan Rajendran, Miao Liu, Sarath Chandar</li>
<li>for: 这个论文的目的是研究 Cooperative Multi-agent Reinforcement Learning（MARL）算法中的零批合作（ZSC）能力，以及如何提高这种能力以适应复杂的任务和变化的环境。</li>
<li>methods: 该论文使用了一种基于 Hanabi 游戏的实验框架，并定义了一个新的 metric called adaptation regret，用于衡量 MARL 算法的适应能力。</li>
<li>results: 实验结果显示，当将 ZSC 算法与不同的学习方法训练的 Agent 结合时，state-of-the-art ZSC 算法的性能很差，并且需要 millions of interaction samples 来适应这些新的合作伙伴。此外，研究发现，通过调整不同的 hyper-parameter 和设计选择，可以提高 Hanabi 算法的适应能力。<details>
<summary>Abstract</summary>
Cooperative Multi-agent Reinforcement Learning (MARL) algorithms with Zero-Shot Coordination (ZSC) have gained significant attention in recent years. ZSC refers to the ability of agents to coordinate zero-shot (without additional interaction experience) with independently trained agents. While ZSC is crucial for cooperative MARL agents, it might not be possible for complex tasks and changing environments. Agents also need to adapt and improve their performance with minimal interaction with other agents. In this work, we show empirically that state-of-the-art ZSC algorithms have poor performance when paired with agents trained with different learning methods, and they require millions of interaction samples to adapt to these new partners. To investigate this issue, we formally defined a framework based on a popular cooperative multi-agent game called Hanabi to evaluate the adaptability of MARL methods. In particular, we created a diverse set of pre-trained agents and defined a new metric called adaptation regret that measures the agent's ability to efficiently adapt and improve its coordination performance when paired with some held-out pool of partners on top of its ZSC performance. After evaluating several SOTA algorithms using our framework, our experiments reveal that naive Independent Q-Learning (IQL) agents in most cases adapt as quickly as the SOTA ZSC algorithm Off-Belief Learning (OBL). This finding raises an interesting research question: How to design MARL algorithms with high ZSC performance and capability of fast adaptation to unseen partners. As a first step, we studied the role of different hyper-parameters and design choices on the adaptability of current MARL algorithms. Our experiments show that two categories of hyper-parameters controlling the training data diversity and optimization process have a significant impact on the adaptability of Hanabi agents.
</details>
<details>
<summary>摘要</summary>
合作多智能 reinforcement learning（MARL）算法 WITH Zero-Shot Coordination（ZSC）在 recent 年份中受到了关注。 ZSC 指的是无需额外交互经验的 AGENTS 之间的协调。 虽然 ZSC 对协作 MARL 代理人来说非常重要，但在复杂任务和变化环境下可能无法实现。 AGENTS 也需要通过最小化交互amples 来改进其性能。 在这项工作中，我们通过实验表明，当将最新的 ZSC 算法与另外的学习方法训练的 AGENTS 结合时，其性能很差。 为了解释这个问题，我们形式地定义了一个基于流行的合作多智能游戏 Hanabi 的框架，用于评估 MARL 方法的适应性。 具体来说，我们创建了一组多样化的预训练 AGENTS，并定义了一个新的指标called adaptation regret，用于衡量 AGENTS 在与其他另外的合作伙伴交互时的快速适应和改进协调性能。 经过我们的实验，我们发现，在 Hanabi 游戏中，简单的独立 Q-学习（IQL） AGENTS 在大多数情况下可以与 SOTA ZSC 算法 Off-Belief Learning（OBL）相当快地适应。 这一发现提出了一个有趣的研究问题：如何设计 MARL 算法，具有高度的 ZSC 性能和适应不visible 合作伙伴的能力。 作为一个第一步，我们研究了现有 MARL 算法中的不同超参数和设计选择对 Hanabi 代理人的适应性有多大的影响。 我们的实验表明，控制训练数据多样性和优化过程的两类超参数具有重要的影响。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Uncertainty-Guided-Model-Selection-for-Data-Driven-PDE-Discovery"><a href="#Adaptive-Uncertainty-Guided-Model-Selection-for-Data-Driven-PDE-Discovery" class="headerlink" title="Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery"></a>Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10283">http://arxiv.org/abs/2308.10283</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pongpisit-thanasutives/ubic">https://github.com/pongpisit-thanasutives/ubic</a></li>
<li>paper_authors: Pongpisit Thanasutives, Takashi Morita, Masayuki Numao, Ken-ichi Fukui</li>
<li>For: 本研究提出了一种新的参数 adaptive uncertainty-penalized Bayesian information criterion (UBIC), 用于优先选择含有噪声的空间-时间观察数据的简洁参数化 differential equation (PDE)。* Methods: 本研究使用了一种physics-informed neural network learning的数据驱动方法来验证选择的 PDE 是否具有足够的准确性。* Results: 实验结果表明，UBIC 可以成功地选择真实的管理 PDE，并且发现了对噪声数据的适当处理可以提高模型选择的trade-off。Here’s the same information in English:* For: This study proposes a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms.* Methods: The study uses a physics-informed neural network learning approach to validate the selected PDE flexibly against the other discovered PDE.* Results: Experimental results show that UBIC can successfully select the true governing PDE, and reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity.<details>
<summary>Abstract</summary>
We propose a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms. Since the naive use of the BIC for model selection has been known to yield an undesirable overfitted PDE, the UBIC penalizes the found PDE not only by its complexity but also the quantified uncertainty, derived from the model supports' coefficient of variation in a probabilistic view. We also introduce physics-informed neural network learning as a simulation-based approach to further validate the selected PDE flexibly against the other discovered PDE. Numerical results affirm the successful application of the UBIC in identifying the true governing PDE. Additionally, we reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity. Code is available at https://github.com/Pongpisit-Thanasutives/UBIC.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的参数适应不确定性加权 bayesian信息条件（UBIC），用于优先选择含有噪声的空间-时间观测数据中的简洁partial differential equation（PDE）。由于直接使用BIC来进行模型选择可能会导致不想要的过拟合PDE，因此UBIC不仅对发现的PDE进行复杂度惩罚，还对其进行量化的不确定性惩罚，从概率视角来看。我们还引入了物理学习神经网络，作为一种基于实验的方法，以验证选择的PDE的可行性。numerical results表明，UBIC成功地实现了选择真实的导导PDE。此外，我们发现了对观测数据进行降噪有助于改善模型复杂度和BIC分数之间的交互效应。代码可以在https://github.com/Pongpisit-Thanasutives/UBIC上获取。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis"><a href="#Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis" class="headerlink" title="Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis"></a>Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10282">http://arxiv.org/abs/2308.10282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suminhan/traffic-uagcrntf">https://github.com/suminhan/traffic-uagcrntf</a></li>
<li>paper_authors: Sumin Han, Youngjun Park, Minji Lee, Jisun An, Dongman Lee</li>
<li>for: 提高城市交通预测精度，帮助确保公民的安全和便利。</li>
<li>methods: 基于图 convolution deep learning 算法，利用人员活动频率数据从国家家庭旅行调查来增强推理 causal 关系 между活动和交通模式。</li>
<li>results: 对比传统的深度学习模型，该方法实现了状态之 искусственный智能模型，无需增加计算负担。<details>
<summary>Abstract</summary>
Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.
</details>
<details>
<summary>摘要</summary>
traffic prediction 是一个关键的元素，以确保公民的安全和便利。现有的交通预测模型主要采用深度学习架构，以捕捉空间和时间相关性。它们经常忽略交通的本质。具体来说，交通数据集中的感知网络不准确地表示实际行驶的道路网络，失去了对交通模式的探索。为了解决这些限制，我们提出了基于图конvolution深度学习算法的改进交通预测方法。我们利用国家家庭旅行调查中的人类活动频率数据，以提高 causal 关系 между活动和交通模式的推理能力。虽然我们对传统的图 convolutional recurrent networks 和图 convolutional transformer 架构进行了最小的修改，但我们的方法可以在计算开销不增加的情况下达到状态的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023"><a href="#The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023" class="headerlink" title="The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023"></a>The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10281">http://arxiv.org/abs/2308.10281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexin Cai, Weiqing Wang, Yikang Wang, Ming Li</li>
<li>for: 本文描述了我们在 Audio Deepfake Detection Challenge (ADD 2023) 中的 Track 2 系统，它的目的是识别受修改的音频段。</li>
<li>methods: 我们的方法包括使用多个检测系统来确定受修改的区域和确定其真实性。我们训练并结合了两个帧级系统：一个用于边界检测，另一个用于深伪检测。此外，我们还使用了专门使用真实数据训练的 VAE 模型来确定音频剪辑的真实性。</li>
<li>results: 通过将这三个系统融合，我们的topperforming解决方案在 ADD 挑战中取得了82.23% 的句子准确率和60.66%的 F1 分数，最终的 ADD 分数为0.6713，在 Track 2 中获得了第一名。<details>
<summary>Abstract</summary>
This paper introduces our system designed for Track 2, which focuses on locating manipulated regions, in the second Audio Deepfake Detection Challenge (ADD 2023). Our approach involves the utilization of multiple detection systems to identify splicing regions and determine their authenticity. Specifically, we train and integrate two frame-level systems: one for boundary detection and the other for deepfake detection. Additionally, we employ a third VAE model trained exclusively on genuine data to determine the authenticity of a given audio clip. Through the fusion of these three systems, our top-performing solution for the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1 score of 60.66%. This results in a final ADD score of 0.6713, securing the first rank in Track 2 of ADD 2023.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了我们为Track 2设计的系统，专注于寻找操作区域（splicing regions），在第二届音频深圳检测比赛（ADD 2023）中获得第一名。我们的方法包括多个检测系统的结合，以确定声音片断的真实性。具体来说，我们训练并集成了两个帧级别系统：一个用于边界检测，另一个用于深圳检测。此外，我们还使用专门用于真实数据训练的VAE模型，以确定声音片断的真实性。通过这三种系统的融合，我们在ADD挑战中获得了82.23%的句子准确率和60.66%的F1分数，最终得分为0.6713，在Track 2中排名第一。
</details></li>
</ul>
<hr>
<h2 id="GPFL-Simultaneously-Learning-Global-and-Personalized-Feature-Information-for-Personalized-Federated-Learning"><a href="#GPFL-Simultaneously-Learning-Global-and-Personalized-Feature-Information-for-Personalized-Federated-Learning" class="headerlink" title="GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning"></a>GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10279">http://arxiv.org/abs/2308.10279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao, Haibing Guan</li>
<li>for: 这个论文主要是为了解决 Federated Learning (FL) 中的个人化特征提取问题，提出了一种新的个人化 Federated Learning (pFL) 方法，以实现在多客户端上同时学习全局和个人特征信息。</li>
<li>methods: 该方法使用了一种新的特征提取技术，可以同时学习全局和个人特征信息，并在多客户端上进行协同学习。</li>
<li>results: 在六个数据集上进行了三种统计上不同的实验，证明了 GPFL 在效果、可扩展性、公平性、稳定性和隐私方面比十种现有方法更优。此外，GPFL 还可以避免过拟合并超过基eline的提升。<details>
<summary>Abstract</summary>
Federated Learning (FL) is popular for its privacy-preserving and collaborative learning capabilities. Recently, personalized FL (pFL) has received attention for its ability to address statistical heterogeneity and achieve personalization in FL. However, from the perspective of feature extraction, most existing pFL methods only focus on extracting global or personalized feature information during local training, which fails to meet the collaborative learning and personalization goals of pFL. To address this, we propose a new pFL method, named GPFL, to simultaneously learn global and personalized feature information on each client. We conduct extensive experiments on six datasets in three statistically heterogeneous settings and show the superiority of GPFL over ten state-of-the-art methods regarding effectiveness, scalability, fairness, stability, and privacy. Besides, GPFL mitigates overfitting and outperforms the baselines by up to 8.99% in accuracy.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是由于其隐私保护和合作学习能力而受欢迎的。最近，个性化 federated learning (pFL) 已经受到关注，因为它可以 Address statistical heterogeneity 和实现个性化。然而，从特征提取的角度来看，大多数现有的 pFL 方法只是在本地训练中提取全局或个性化特征信息，这不符合 pFL 的协作学习和个性化目标。为解决这个问题，我们提出了一种新的 pFL 方法，名为 GPFL，它可以在每个客户端同时学习全局和个性化特征信息。我们在六个数据集上进行了三种 statistically heterogeneous 的实验，并证明 GPFL 在效果、可扩展性、公平性、稳定性和隐私方面超过了十个现有方法。此外，GPFL 可以 Mitigate overfitting 并超过基eline 的性能。
</details></li>
</ul>
<hr>
<h2 id="Minimalist-Traffic-Prediction-Linear-Layer-Is-All-You-Need"><a href="#Minimalist-Traffic-Prediction-Linear-Layer-Is-All-You-Need" class="headerlink" title="Minimalist Traffic Prediction: Linear Layer Is All You Need"></a>Minimalist Traffic Prediction: Linear Layer Is All You Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10276">http://arxiv.org/abs/2308.10276</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenyingduan/STLinear">https://github.com/wenyingduan/STLinear</a></li>
<li>paper_authors: Wenying Duan, Hong Rao, Wei Huang, Xiaoxi He</li>
<li>for: 这篇论文是为了解决智能交通系统（ITS）和智能城市的发展中的交通预测问题而写的。</li>
<li>methods: 本论文提出了三个解决方案：节点嵌入方法、时间序列分解和周期学习。它还介绍了一种名为 STLinear 的简单化模型架构，它在计算复杂性和计算负担方面具有明显的优势。</li>
<li>results: 实验表明，STLinear 能够与其他领先的 STGNN 模型匹配或超越其精度，但具有明显的计算复杂性和计算负担减少（相比于2023年的状态艺术 STGNN 基eline，MACs每个epoch减少了超过95%）。<details>
<summary>Abstract</summary>
Traffic prediction is essential for the progression of Intelligent Transportation Systems (ITS) and the vision of smart cities. While Spatial-Temporal Graph Neural Networks (STGNNs) have shown promise in this domain by leveraging Graph Neural Networks (GNNs) integrated with either RNNs or Transformers, they present challenges such as computational complexity, gradient issues, and resource-intensiveness. This paper addresses these challenges, advocating for three main solutions: a node-embedding approach, time series decomposition, and periodicity learning. We introduce STLinear, a minimalist model architecture designed for optimized efficiency and performance. Unlike traditional STGNNs, STlinear operates fully locally, avoiding inter-node data exchanges, and relies exclusively on linear layers, drastically cutting computational demands. Our empirical studies on real-world datasets confirm STLinear's prowess, matching or exceeding the accuracy of leading STGNNs, but with significantly reduced complexity and computation overhead (more than 95% reduction in MACs per epoch compared to state-of-the-art STGNN baseline published in 2023). In summary, STLinear emerges as a potent, efficient alternative to conventional STGNNs, with profound implications for the future of ITS and smart city initiatives.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统（ITS）的核心和智能城市的视野。而 spatial-temporal graph neural networks（STGNNs）在这个领域表现了承诺，通过结合图神经网络（GNNs）和 either RNNs 或 Transformers 来预测交通流。然而，STGNNs 还存在一些挑战，如计算复杂性、梯度问题和资源占用性。这篇文章解决了这些挑战，提出三个主要解决方案：节点嵌入方法、时间序列分解和周期学习。我们介绍了 STLinear，一种最佳化的模型建立，与传统的 STGNNs 不同，STLinear 完全地地方处理，不需要 между节点数据交换，并且仅仅使用线性层，减少了计算需求。我们对实际数据集进行了实验，确认 STLinear 的强大性，与状态之前的 STGNNs 准确性相当或超过，但计算负担减少了超过 95%。总之，STLinear  emerges 为智能交通系统和智能城市initiatives的强大、高效的代替方案。
</details></li>
</ul>
<hr>
<h2 id="SBSM-Pro-Support-Bio-sequence-Machine-for-Proteins"><a href="#SBSM-Pro-Support-Bio-sequence-Machine-for-Proteins" class="headerlink" title="SBSM-Pro: Support Bio-sequence Machine for Proteins"></a>SBSM-Pro: Support Bio-sequence Machine for Proteins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10275">http://arxiv.org/abs/2308.10275</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wyzbio/support-bio-sequence-machine">https://github.com/wyzbio/support-bio-sequence-machine</a></li>
<li>paper_authors: Yizheng Wang, Yixiao Zhai, Yijie Ding, Quan Zou</li>
<li>for: 本研究旨在提出一种特制 для生物序列分类的支持机器学习模型（SBSM-Pro），帮助指导生物实验和应用。</li>
<li>methods: 该模型从原始序列开始，根据蛋白质物理化学性质进行氨基酸分组，并使用序列对 alignment 测量蛋白质之间的相似性。它采用了一种新的 MKL 方法，将不同类型的信息集成，使用支持向量机器学习进行分类预测。</li>
<li>results: 研究结果表明，SBSM-Pro 在 10 个数据集中表现出色，在蛋白质功能预测和后转录修饰方面进行了正确的识别。这项研究不仅代表了生物序列分类领域的国际前沿，还开创了新的方向，为生物序列分类平台的开发做出了重要贡献。<details>
<summary>Abstract</summary>
Proteins play a pivotal role in biological systems. The use of machine learning algorithms for protein classification can assist and even guide biological experiments, offering crucial insights for biotechnological applications. We propose a support bio-sequence machine for proteins, a model specifically designed for biological sequence classification. This model starts with raw sequences and groups amino acids based on their physicochemical properties. It incorporates sequence alignment to measure the similarities between proteins and uses a novel MKL approach to integrate various types of information, utilizing support vector machines for classification prediction. The results indicate that our model demonstrates commendable performance across 10 datasets in terms of the identification of protein function and posttranslational modification. This research not only showcases state-of-the-art work in protein classification but also paves the way for new directions in this domain, representing a beneficial endeavour in the development of platforms tailored for biological sequence classification. SBSM-Pro is available for access at http://lab.malab.cn/soft/SBSM-Pro/.
</details>
<details>
<summary>摘要</summary>
生物系统中，蛋白质扮演着关键角色。使用机器学习算法进行蛋白质分类可以帮助和指导生物实验，提供生物技术应用中关键的发现。我们提出了一种专门为蛋白质分类设计的生物序列机器学习模型（SBSM-Pro）。这个模型从原始序列开始，根据蛋白质物理化学性质分组氨基酸。它利用序列对alignment测量蛋白质之间的相似性，并采用一种新的MKL方法集成不同类型的信息，使用支持向量机进行分类预测。结果表明，我们的模型在10个数据集中表现出色地预测蛋白质功能和后转化 modify。这项研究不仅代表了蛋白质分类领域的 estado-of-the-art，还开拓了新的发展方向，代表了一项有利的生物序列分类平台开发的努力。SBSM-Pro可以在http://lab.malab.cn/soft/SBSM-Pro/上下载。
</details></li>
</ul>
<hr>
<h2 id="An-alternative-to-SVM-Method-for-Data-Classification"><a href="#An-alternative-to-SVM-Method-for-Data-Classification" class="headerlink" title="An alternative to SVM Method for Data Classification"></a>An alternative to SVM Method for Data Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11579">http://arxiv.org/abs/2308.11579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning">https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning</a></li>
<li>paper_authors: Lakhdar Remaki</li>
<li>for: 这篇论文是为了提出一种新的分类方法，以解决支持向量机（SVM）的一些缺点。</li>
<li>methods: 该方法使用最小距离到优化的子空间，以确定分类结果。</li>
<li>results: 研究发现，新方法与支持向量机（SVM）的性能相似，但具有轻量级的优势，如减少计算时间、避免优化过程失败、扩展到多类分类、处理不均衡类型和动态分类等问题。<details>
<summary>Abstract</summary>
Support vector machine (SVM), is a popular kernel method for data classification that demonstrated its efficiency for a large range of practical applications. The method suffers, however, from some weaknesses including; time processing, risk of failure of the optimization process for high dimension cases, generalization to multi-classes, unbalanced classes, and dynamic classification. In this paper an alternative method is proposed having a similar performance, with a sensitive improvement of the aforementioned shortcomings. The new method is based on a minimum distance to optimal subspaces containing the mapped original classes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks"><a href="#Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks" class="headerlink" title="Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks"></a>Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10273">http://arxiv.org/abs/2308.10273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Ding, Yongwei Wang, Zuheng Xu<br>for: 这个论文旨在提高Continuous Conditional Generative Adversarial Networks（CcGANs）中的生成模型，使其能够基于连续数值变量（称为回归标签）进行生成。methods: 这个论文提出了一种新的Negative Data Augmentation（NDA）方法，称为Dual-NDA，以解决CcGANs中的问题，即生成低质量的假图像。Dual-NDA使用了两种类型的负样本：来自预训练CcGAN的视觉不真实图像和 manipulate 真实图像的标签。results: 实验表明，Dual-NDA可以提高CcGANs中生成图像的视觉准确性和标签一致性，而且可以超越当前的状态艺术Conditional GANs和扩散模型，达到新的高水平性能。<details>
<summary>Abstract</summary>
Continuous Conditional Generative Adversarial Networks (CcGANs) enable generative modeling conditional on continuous scalar variables (termed regression labels). However, they can produce subpar fake images due to limited training data. Although Negative Data Augmentation (NDA) effectively enhances unconditional and class-conditional GANs by introducing anomalies into real training images, guiding the GANs away from low-quality outputs, its impact on CcGANs is limited, as it fails to replicate negative samples that may occur during the CcGAN sampling. We present a novel NDA approach called Dual-NDA specifically tailored for CcGANs to address this problem. Dual-NDA employs two types of negative samples: visually unrealistic images generated from a pre-trained CcGAN and label-inconsistent images created by manipulating real images' labels. Leveraging these negative samples, we introduce a novel discriminator objective alongside a modified CcGAN training algorithm. Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA consistently enhances the visual fidelity and label consistency of fake images generated by CcGANs, exhibiting a substantial performance gain over the vanilla NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable advancement beyond the capabilities of state-of-the-art conditional GANs and diffusion models, establishing a new pinnacle of performance.
</details>
<details>
<summary>摘要</summary>
Dual-NDA 使用了两种负样本：由预训练 CcGAN 生成的视觉不可能的图像，以及 manipulate 真实图像的标签以创造的 label-inconsistent 图像。我们利用这些负样本，引入了一种新的识别器目标 alongside 修改后 CcGAN 训练算法。我们的实验表明，使用 Dual-NDA，CcGANs 能够在 UTKFace 和 Steering Angle 上提高假图像的视觉准确性和标签一致性，并且表现出了明显的性能提升。此外，通过应用 Dual-NDA，CcGANs 能够超越现有的 conditional GANs 和扩散模型，达到新的高点性能。
</details></li>
</ul>
<hr>
<h2 id="Large-Transformers-are-Better-EEG-Learners"><a href="#Large-Transformers-are-Better-EEG-Learners" class="headerlink" title="Large Transformers are Better EEG Learners"></a>Large Transformers are Better EEG Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11654">http://arxiv.org/abs/2308.11654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingxin Wang, Xiaowen Fu, Yuan Lan, Luchan Zhang, Yang Xiang</li>
<li>for: 这个论文主要针对的是如何将类型变数的电enzephalogram（EEG）资料转换为图像或文本格式，以便使用预训Transformer模型进行预测。</li>
<li>methods: 作者提出了一个名为AdaCE的专案，用于将EEG资料转换为图像或文本格式，并将这些格式与预训Transformer模型进行混合，以便进行预测。</li>
<li>results: 作者的实验结果显示，使用AdaCE模组可以将预训Transformer模型直接 fine-tune 为EEG预测任务，并 achieve state-of-the-art 性能在多种EEG预测任务上。例如，AdaCE在预训Swin-Transformer上 achieve 99.6%，即相对提高9.2%的精度。此外，作者还证明了，将更大的预训模型通过AdaCE进行 fine-tune 可以在EEG预测任务上 achieve better performance。<details>
<summary>Abstract</summary>
Pre-trained large transformer models have achieved remarkable performance in the fields of natural language processing and computer vision. Since the magnitude of available labeled electroencephalogram (EEG) data is much lower than that of text and image data, it is difficult for transformer models pre-trained from EEG to be developed as large as GPT-4 100T to fully unleash the potential of this architecture. In this paper, we show that transformers pre-trained from images as well as text can be directly fine-tuned for EEG-based prediction tasks. We design AdaCE, plug-and-play Adapters for Converting EEG data into image as well as text forms, to fine-tune pre-trained vision and language transformers. The proposed AdaCE module is highly effective for fine-tuning pre-trained transformers while achieving state-of-the-art performance on diverse EEG-based prediction tasks. For example, AdaCE on the pre-trained Swin-Transformer achieves 99.6%, an absolute improvement of 9.2%, on the EEG-decoding task of human activity recognition (UCI HAR). Furthermore, we empirically show that applying the proposed AdaCE to fine-tune larger pre-trained models can achieve better performance on EEG-based predicting tasks, indicating the potential of our adapters for even larger transformers. The plug-and-play AdaCE module can be applied to fine-tuning most of the popular pre-trained transformers on many other time-series data with multiple channels, not limited to EEG data and the models we use. Our code will be available at https://github.com/wangbxj1234/AdaCE.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>大型预训练变换器模型在自然语言处理和计算机视觉领域已经实现了很好的表现。由于电生成ogram（EEG）数据的数量相对较少，预训练后的变换器模型难以达到GPT-4 100T的规模，以全面发挥变换器模型的潜力。在这篇论文中，我们表明了从图像和文本预训练的变换器模型可以直接进行EEG数据适应。我们设计了AdaCE模块，它是一种用于将EEG数据转换为图像和文本形式的插件，以便适应预训练的视觉和语言变换器。我们的AdaCE模块非常有效地进行适应预训练后的变换器模型，并在多种EEG预测任务中达到了状态元的表现。例如，AdaCE在预训练Swin-Transformer上的EEG解码任务上达到了99.6%，相对于基线方法的9.2%提升。此外，我们还证明了在应用我们的AdaCE插件后，可以进行更大的预训练模型的精度调整，这表明了我们的插件在更大的变换器模型上的潜力。插件可以应用于大多数流行的预训练变换器模型上，并不限于EEG数据和我们所用的模型。我们的代码将在https://github.com/wangbxj1234/AdaCE上提供。
</details></li>
</ul>
<hr>
<h2 id="Towards-Synthesizing-Datasets-for-IEEE-802-1-Time-sensitive-Networking"><a href="#Towards-Synthesizing-Datasets-for-IEEE-802-1-Time-sensitive-Networking" class="headerlink" title="Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking"></a>Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10255">http://arxiv.org/abs/2308.10255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doğanalp Ergenç, Nurefşan Sertbaş Bülbül, Lisa Maile, Anna Arestova, Mathias Fischer</li>
<li>for: 本文旨在探讨IEEE 802.1时间敏感网络协议在不同的传统系统中的应用，以及使用人工智能和机器学习模型来开发高级配置和维护方法。</li>
<li>methods: 本文提出了一种使用人工智能和机器学习模型来开发高级配置和维护方法的方法，并分析了该方法的主要需求和可行设计。</li>
<li>results: 本文指出，为了推进IEEE 802.1时间敏感网络协议的研究，需要开发一些可靠的TSN数据集，以便训练人工智能和机器学习模型。<details>
<summary>Abstract</summary>
IEEE 802.1 Time-sensitive Networking (TSN) protocols have recently been proposed to replace legacy networking technologies across different mission-critical systems (MCSs). Design, configuration, and maintenance of TSN within MCSs require advanced methods to tackle the highly complex and interconnected nature of those systems. Accordingly, artificial intelligence (AI) and machine learning (ML) models are the most prominent enablers to develop such methods. However, they usually require a significant amount of data for model training, which is not easily accessible. This short paper aims to recapitulate the need for TSN datasets to flourish research on AI/ML-based techniques for TSN systems. Moreover, it analyzes the main requirements and alternative designs to build a TSN platform to synthesize realistic datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data"><a href="#StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data" class="headerlink" title="StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data"></a>StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10253">http://arxiv.org/abs/2308.10253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/icoz69/stablellava">https://github.com/icoz69/stablellava</a></li>
<li>paper_authors: Yanda Li, Chi Zhang, Gang Yu, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, Yunchao Wei</li>
<li>for: 这些论文的主要研究目标是开发一种能够有效地对应文本和视觉模式的大型自然语言模型（LLM），以便理解人类的指令。</li>
<li>methods: 我们提议一种新的数据收集方法，即同步生成图像和对话，以便对视觉指令进行调整。这种方法利用了生成模型的能力，将文本生成模型和对话生成模型结合起来，以生成多样化和可控的数据集。</li>
<li>results: 我们的研究包括对多个数据集进行了广泛的实验，使用开源的 LLAVA 模型作为我们提议的管道进行测试。我们的结果表明，我们的方法可以明显提高 LLM 的多种常见能力，包括图像生成、对话生成、问题回答、文本生成等。<details>
<summary>Abstract</summary>
The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human instructions. Current methodologies often rely on annotations derived from benchmark datasets to construct image-dialogue datasets for training purposes, akin to instruction tuning in LLMs. However, these datasets often exhibit domain bias, potentially constraining the generative capabilities of the models. In an effort to mitigate these limitations, we propose a novel data collection methodology that synchronously synthesizes images and dialogues for visual instruction tuning. This approach harnesses the power of generative models, marrying the abilities of ChatGPT and text-to-image generative models to yield a diverse and controllable dataset with varied image content. This not only provides greater flexibility compared to existing methodologies but also significantly enhances several model capabilities. Our research includes comprehensive experiments conducted on various datasets using the open-source LLAVA model as a testbed for our proposed pipeline. Our results underscore marked enhancements across more than ten commonly assessed capabilities,
</details>
<details>
<summary>摘要</summary>
“OpenAI的GPT-4的多模式能力引起了很大的关注，推动了多模式大语言模型（LLM）的研发。这些模型的主要研究目标是在理解人类 instrucion 时，有效地对文本和视觉模式进行对应。现有的方法ologies  oft en rely on来自标准 benchmark dataset 的注释来构建图像对话集 для训练purpose，类似于 instruction tuning 在 LLM 中。然而，这些数据集经常受到领域偏见的影响，可能限制模型的生成能力。为了缓解这些限制，我们提出了一种新的数据采集方法，同时生成图像和对话，以便对视觉 instrucion 进行调整。这种方法利用了生成模型的能力，将文本生成模型和图像生成模型结合起来，生成了多样化和可控的数据集。这不仅提供了现有方法所不具备的灵活性，还显著提高了多种模型能力。我们的研究包括对多个数据集进行了全面的实验，使用开源的 LLAVA 模型作为我们提议的管道测试环境。我们的结果表明，我们的方法在多达十个常评价指标上具有明显的提升。”
</details></li>
</ul>
<hr>
<h2 id="Activation-Addition-Steering-Language-Models-Without-Optimization"><a href="#Activation-Addition-Steering-Language-Models-Without-Optimization" class="headerlink" title="Activation Addition: Steering Language Models Without Optimization"></a>Activation Addition: Steering Language Models Without Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10248">http://arxiv.org/abs/2308.10248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini, Monte MacDiarmid</li>
<li>for: 这个论文旨在提出一种可靠地控制大型自然语言模型（LLM）的行为的方法。</li>
<li>methods: 论文使用激活工程（Activation Addition，ActAdd）方法，在推理时添加一个“导航向量”，通过自然语言来隐式地定义。</li>
<li>results: 论文在GPT-2上进行了OpenWebText和ConceptNet的测试，表明ActAdd方法可以在推理时控制输出的高级性质，并且不会影响模型的目标性能。此外，ActAdd方法比超visionfinetuning和人类反馈学习（RLHF）更加快速，需要更少的计算资源和实现努力，同时允许用户提供自然语言指令。<details>
<summary>Abstract</summary>
Reliably controlling the behavior of large language models (LLMs) is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback (RLHF), prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference time to predictably alter model behavior. In particular, we bias the forward pass with an added 'steering vector' implicitly specified through natural language.   Unlike past work which learned these steering vectors (Subramani, Suresh, and Peters 2022; Hernandez, Li, and Andreas 2023), our Activation Addition (ActAdd) method computes them by taking the activation differences that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet. Our inference-time approach yields control over high-level properties of output and preserves off-target model performance. It involves far less compute and implementation effort compared to finetuning or RLHF, allows users to provide natural language specifications, and its overhead scales naturally with model size.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的可靠控制问题仍是一个开放的问题。现有的方法包括监督微调、人工反馈学习（RLHF）、提示工程和导航解码。我们则是活动工程：在推理时修改激活来预测性地改变模型行为。具体来说，我们在前进通过添加“导航向量”来隐式地指定自然语言中的批处理。与过去的工作不同（Subramani et al. 2022；Hernandez et al. 2023），我们的激活添加（ActAdd）方法不是学习这些导航向量，而是通过对提示对的激活差异来计算它们。我们在GPT-2上使用OpenWebText和ConceptNet进行了实验，并证明了ActAdd可以在推理时控制输出的高级性质，并且保持目标模型性能。这种在推理时进行的方法比微调或RLHF需要更少的计算和实现努力，允许用户提供自然语言规范，并且其开销随模型大小呈指数增长。
</details></li>
</ul>
<hr>
<h2 id="From-Global-to-Local-Multi-scale-Out-of-distribution-Detection"><a href="#From-Global-to-Local-Multi-scale-Out-of-distribution-Detection" class="headerlink" title="From Global to Local: Multi-scale Out-of-distribution Detection"></a>From Global to Local: Multi-scale Out-of-distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10239">http://arxiv.org/abs/2308.10239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jimzai/mode-ood">https://github.com/jimzai/mode-ood</a></li>
<li>paper_authors: Ji Zhang, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Hengtao Shen</li>
<li>for: 这个研究的目的是提高OD detection的精度，尤其是在遇到未知数据时。</li>
<li>methods: 这个方法使用了多个缩寸的方法，包括global visual information和local region details，以提高OD detection的精度。</li>
<li>results: 这个方法在多个benchmark上的表现比前一代方法好，具体的表现提高了19.24%在False Positive Rate和2.77%在AUC上。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection aims to detect "unknown" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION (OOD) 检测的目标是检测“未知”数据，其标签在ID 训练过程中没有出现过。随着表征学学习的进步，距离基于 OOD 检测已经得到了广泛应用。然而，过去的方法通常基于全局图像表征，忽略了图像内部的细节信息，这可能会导致同一个ID类型的图像在给定的表征空间中被分化。在这种情况下，我们提出了一个新的框架，即多scale OOD 检测（MODE），它利用全局视觉信息和图像内部的局部区域特征来最大化 OOD 检测的效果。Specifically, we find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
</details></li>
</ul>
<hr>
<h2 id="Thompson-Sampling-for-Real-Valued-Combinatorial-Pure-Exploration-of-Multi-Armed-Bandit"><a href="#Thompson-Sampling-for-Real-Valued-Combinatorial-Pure-Exploration-of-Multi-Armed-Bandit" class="headerlink" title="Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit"></a>Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10238">http://arxiv.org/abs/2308.10238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shintaro Nakamura, Masashi Sugiyama</li>
<li>for:  solve the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem, which is to find the optimal action from a finite-sized real-valued action set with as few arm pulls as possible.</li>
<li>methods:  the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in d.</li>
<li>results:  a novel problem-dependent sample complexity lower bound of the R-CPE-MAB problem, and show that the GenTS-Explore algorithm achieves the optimal sample complexity up to a problem-dependent constant factor.Here are the three information in a more concise format, using bullet points:</li>
<li>for:  solve the R-CPE-MAB problem with a large action set.</li>
<li>methods:  GenTS-Explore algorithm.</li>
<li>results:  a novel problem-dependent sample complexity lower bound, and the GenTS-Explore algorithm achieves the optimal sample complexity up to a constant factor.<details>
<summary>Abstract</summary>
We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown distribution with mean $\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity lower bound of the R-CPE-MAB problem, and show that the GenTS-Explore algorithm achieves the optimal sample complexity up to a problem-dependent constant factor.
</details>
<details>
<summary>摘要</summary>
我们研究了实数值的可整合探索多臂枪手问题（R-CPE-MAB）。在R-CPE-MAB中，一个玩家被分配了$d$个随机臂，每个臂$s\in\{1, \ldots, d\}$的奖励follows一个未知分布的mean $\mu_s$。在每个时间步骤中，一个玩家抓一个臂并观察其奖励。玩家的目标是从一个封闭的实数值动作集$\mathcal{A}\subset \mathbb{R}^{d}$中选择最佳的动作 $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$，以最少的臂抓次数为目标。先前的R-CPE-MAB方法假设动作集$\mathcal{A}$的大小是对数函数的$d$。我们介绍了一个名为Generalized Thompson Sampling Explore（GenTS-Explore）算法，这是第一个可以在动作集$\mathcal{A}$的大小是指数增长的$d$时工作的算法。我们还介绍了一个问题内部依赖的样本缩减下限，并证明GenTS-Explore算法实现了问题内部依赖的样本缩减下限。
</details></li>
</ul>
<hr>
<h2 id="FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection"><a href="#FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection" class="headerlink" title="FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection"></a>FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10236">http://arxiv.org/abs/2308.10236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naiftt/fedsis">https://github.com/naiftt/fedsis</a></li>
<li>paper_authors: Naif Alkhunaizi, Koushik Srivatsan, Faris Almalik, Ibrahim Almakky, Karthik Nandakumar</li>
<li>for: 本研究旨在提高面部攻击检测算法（FacePAD）的通用性，解决现有算法的 Achilles heel 问题。</li>
<li>methods: 本研究提出了一种新的框架called Federated Split learning with Intermediate representation Sampling（FedSIS），combines federated learning（FL）和split learning，以保持隐私而实现预测通用性。</li>
<li>results: 研究表明，FedSIS 可以在不需要数据共享的情况下，达到面部攻击检测算法的状态之最游标性表现，并在未见过的频道上实现良好的泛化性。<details>
<summary>Abstract</summary>
Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS
</details>
<details>
<summary>摘要</summary>
缺乏泛化到未经见的领域/攻击是现有的面孔展示攻击检测（FacePAD）算法的 Achilles heel。现有的增强FacePAD解决方案假设有多个源领域的数据可以在单一实体上进行中央式训练。然而，在实践中，来自不同的源领域的数据可能是由不同的实体收集的，这些实体经常因为法律和隐私限制无法共享自己的数据。而合作学习 paradigm such as federated learning（FL）可以解决这个问题，但标准的FL方法在适应新的领域时存在两大挑战：处理非标一Client数据分布在训练中和在推断中适应未经见的领域。在这种情况下，一种名为 Federated Split learning with Intermediate representation Sampling（FedSIS）的新框架被引入，用于保护隐私的领域泛化。在 FedSIS 中，使用一种混合的 Vision Transformer（ViT）架构，通过 combining FL 和 split learning 来实现对Client数据分布的统计异质性的Robustness，而不需要 Client 数据的共享。为了进一步提高适应未经见的领域，一种名为 intermediate representation sampling 的新的特征增强策略被使用，并通过一个共享的 adapter 网络来浓缩出权威信息。FedSIS 方法在两个常用的 cross-domain FacePAD  benchmark 上进行了评估，并证明了可以在没有数据共享情况下实现状态码的泛化性能。代码：https://github.com/Naiftt/FedSIS
</details></li>
</ul>
<hr>
<h2 id="Karma-Adaptive-Video-Streaming-via-Causal-Sequence-Modeling"><a href="#Karma-Adaptive-Video-Streaming-via-Causal-Sequence-Modeling" class="headerlink" title="Karma: Adaptive Video Streaming via Causal Sequence Modeling"></a>Karma: Adaptive Video Streaming via Causal Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10230">http://arxiv.org/abs/2308.10230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fcbw2012/Karma">https://github.com/fcbw2012/Karma</a></li>
<li>paper_authors: Bowei Xu, Hao Chen, Zhan Ma</li>
<li>For: This paper aims to improve the adaptive bitrate (ABR) decision-making process by utilizing causal sequence modeling to comprehend the interrelated causality among past observations, returns, and actions, and timely refining actions when deviations occur.* Methods: The proposed Karma algorithm uses a decision transformer to determine the next action based on a multi-dimensional time series of observations, returns, and actions, with the maximum cumulative future quality of experience (QoE) as an extended return signal.* Results: The paper demonstrates superior performance compared to existing state-of-the-art ABR algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across diverse network conditions, and strong generalization capabilities under unseen networks in both simulations and real-world tests.Here is the text in Simplified Chinese:* For: 这篇论文目标是通过利用 causal sequence modeling 改善 adaptive bitrate (ABR) 决策过程，以便更好地理解过去观察、返回和行为之间的相互关系，并在偏差发生时及时更新行动。* Methods: 提议的 Karma 算法使用决策转换器来确定下一步行动，基于多维时间序列观察、返回和行动中的观察、返回和行动。* Results: 论文表明，相比现有的状态艺术 ABR 算法，Karma 算法在多种网络条件下表现出较高的平均Quality of Experience（QoE）提升，从10.8% 到18.7%。此外，Karma 算法在未见网络上也显示出了强大的泛化能力。<details>
<summary>Abstract</summary>
Optimal adaptive bitrate (ABR) decision depends on a comprehensive characterization of state transitions that involve interrelated modalities over time including environmental observations, returns, and actions. However, state-of-the-art learning-based ABR algorithms solely rely on past observations to decide the next action. This paradigm tends to cause a chain of deviations from optimal action when encountering unfamiliar observations, which consequently undermines the model generalization. This paper presents Karma, an ABR algorithm that utilizes causal sequence modeling to improve generalization by comprehending the interrelated causality among past observations, returns, and actions and timely refining action when deviation occurs. Unlike direct observation-to-action mapping, Karma recurrently maintains a multi-dimensional time series of observations, returns, and actions as input and employs causal sequence modeling via a decision transformer to determine the next action. In the input sequence, Karma uses the maximum cumulative future quality of experience (QoE) (a.k.a, QoE-to-go) as an extended return signal, which is periodically estimated based on current network conditions and playback status. We evaluate Karma through trace-driven simulations and real-world field tests, demonstrating superior performance compared to existing state-of-the-art ABR algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across diverse network conditions. Furthermore, Karma exhibits strong generalization capabilities, showing leading performance under unseen networks in both simulations and real-world tests.
</details>
<details>
<summary>摘要</summary>
优化的适应比率（ABR）决策需要对状态转移进行全面的特征化，包括时间上的相关Modalities。然而，现有的学习基于ABR算法只是基于过去的观察来决定下一个动作。这种做法会导致对于不熟悉的观察而引起链式偏差，从而下降模型泛化。这篇论文提出了Karma算法，它利用 causal sequence modeling来提高泛化性，通过理解过去观察、返回和动作之间的相关 causality，并在偏差发生时进行时间 opportune 的修正。与直接观察到动作映射不同，Karma 使用循环维护一个多维时间序列，并使用决策变换器来确定下一个动作。在输入序列中，Karma 使用最大累积未来体验质量（QoE）作为延长返回信号，这些信号 periodically 根据当前网络conditions和播放状态来 estimating。我们通过跟踪驱动的 simulations 和实际场景测试评估了Karma，并证明它在不同的网络条件下表现出优于现有状态艺术ABR算法，QoE 提升平均值在10.8%到18.7%之间。此外，Karma 表现出了强大的泛化能力，在未看到的网络上仍然保持领先的表现。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-powered-Combinatorial-Clock-Auction"><a href="#Machine-Learning-powered-Combinatorial-Clock-Auction" class="headerlink" title="Machine Learning-powered Combinatorial Clock Auction"></a>Machine Learning-powered Combinatorial Clock Auction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10226">http://arxiv.org/abs/2308.10226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marketdesignresearch/ml-cca">https://github.com/marketdesignresearch/ml-cca</a></li>
<li>paper_authors: Ermis Soumalias, Jakob Weissteiner, Jakob Heiss, Sven Seuken</li>
<li>for: 这篇论文关注了迭代 combinatorial 拍卖（ICA）的设计。ICA 中的主要挑战在于bundle空间随着物品数量的增加而 exponentiates。</li>
<li>methods: 这篇论文提出了一种基于机器学习（ML）的偏好拟合算法，以便从投标者那里获取最重要的信息。</li>
<li>results: 这篇论文的实验结果表明，相比 combinatorial clock auction（CCA），我们的 ML-based demand query mechanism在各个频谱拍卖领域中表现出了显著的高效性。它在一个较小的数量的拍卖轮次中达到了更高的效率，并且使用线性价格时可以达到了巨大的清算潜力。因此，这篇论文 bridge了研究和实践之间的差距，并提出了首个实用的 ML-powered ICA。<details>
<summary>Abstract</summary>
We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders. However, from a practical point of view, the main shortcoming of this prior work is that those designs elicit bidders' preferences via value queries (i.e., ``What is your value for the bundle $\{A,B\}$?''). In most real-world ICA domains, value queries are considered impractical, since they impose an unrealistically high cognitive burden on bidders, which is why they are not used in practice. In this paper, we address this shortcoming by designing an ML-powered combinatorial clock auction that elicits information from the bidders only via demand queries (i.e., ``At prices $p$, what is your most preferred bundle of items?''). We make two key technical contributions: First, we present a novel method for training an ML model on demand queries. Second, based on those trained ML models, we introduce an efficient method for determining the demand query with the highest clearing potential, for which we also provide a theoretical foundation. We experimentally evaluate our ML-based demand query mechanism in several spectrum auction domains and compare it against the most established real-world ICA: the combinatorial clock auction (CCA). Our mechanism significantly outperforms the CCA in terms of efficiency in all domains, it achieves higher efficiency in a significantly reduced number of rounds, and, using linear prices, it exhibits vastly higher clearing potential. Thus, with this paper we bridge the gap between research and practice and propose the first practical ML-powered ICA.
</details>
<details>
<summary>摘要</summary>
我们研究Iterative Combinatorial Auctions（ICA）的设计。ICA的主要挑战在于bundle空间随着物品数量的增加而增加 exponentially。为了解决这个问题，一些最近的论文已经提出了基于机器学习（ML）的偏好探索算法，以探索供应商对不同套件的偏好。然而，从实践的角度来看，这些设计都是通过值询问（i.e.,“What is your value for the bundle $\{A,B\}$?”）来探索供应商的偏好，这种方法在实际应用中被视为不实际。在这篇论文中，我们解决这个问题，通过设计一个基于ML的套件时钟拍卖，通过需求询问（i.e.,“At prices $p$, what is your most preferred bundle of items?”）来探索供应商的偏好。我们的研究做出了两个关键技术贡献：首先，我们提出了一种新的需求询问训练ML模型的方法；其次，基于这些训练的ML模型，我们引入了一种高效的需求询问找到最高清算潜力的方法，并提供了理论基础。我们在几个频谱拍卖领域进行了实验评估，与现有最具実际应用的ICA：套件时钟拍卖（CCA）进行比较。我们的机制在所有领域中都有着明显的高效性，在许多领域中，它在许多更少的轮数中达到了更高的高效性，并且使用线性价格，它的清算潜力是极大的。因此，这篇论文通过实践和理论的研究，提出了第一个实际应用的ML-Powered ICA。
</details></li>
</ul>
<hr>
<h2 id="Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL"><a href="#Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL" class="headerlink" title="Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL"></a>Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10203">http://arxiv.org/abs/2308.10203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yechen Zhang, Jian Sun, Gang Wang, Zhuo Li, Wei Chen</li>
<li>for: 解决连续控制问题中的维度爆炸问题</li>
<li>methods: combines soft RL和actor-critic技术，独立地对每个动作维度进行柔化，使用共享批处理网络来最大化柔化$Q$-函数</li>
<li>results: 在多种连续控制任务中，比如Mujoco的人工智能和Box2d的两脚行走器，实验结果表明我们提出的方法可以超越现有的连续RL算法表现。<details>
<summary>Abstract</summary>
Discrete reinforcement learning (RL) algorithms have demonstrated exceptional performance in solving sequential decision tasks with discrete action spaces, such as Atari games. However, their effectiveness is hindered when applied to continuous control problems due to the challenge of dimensional explosion. In this paper, we present the Soft Decomposed Policy-Critic (SDPC) architecture, which combines soft RL and actor-critic techniques with discrete RL methods to overcome this limitation. SDPC discretizes each action dimension independently and employs a shared critic network to maximize the soft $Q$-function. This novel approach enables SDPC to support two types of policies: decomposed actors that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed $Q$-networks that generate Boltzmann soft exploration policies, resulting in the Soft Decomposed-Critic Q (SDCQ) algorithm. Through extensive experiments, we demonstrate that our proposed approach outperforms state-of-the-art continuous RL algorithms in a variety of continuous control tasks, including Mujoco's Humanoid and Box2d's BipedalWalker. These empirical results validate the effectiveness of the SDPC architecture in addressing the challenges associated with continuous control.
</details>
<details>
<summary>摘要</summary>
离散强化学习（RL）算法在解决顺序决策任务中的离散动作空间方面表现出色，如Atari游戏。然而，当应用于连续控制问题时，它们的效iveness受到维度爆炸的挑战。在这篇论文中，我们提出了软分解策略-批评（SDPC）架构，它将离散RL和演员-批评技术与离散RL方法相结合，以解决这一问题。SDPC独立地对每个动作维度进行分解，并使用共享批评网络来最大化软Q函数。这种新的方法使得SDPC支持两种策略：分解演员，导致Soft Decomposed Actor-Critic（SDAC）算法，以及分解Q网络，生成Boltzmann软探索策略，导致Soft Decomposed-Critic Q（SDCQ）算法。我们通过广泛的实验表明，我们提出的方法在多种连续控制任务中比州前的连续RL算法表现出色，包括Mujoco的人iform和Box2d的BipedalWalker。这些实验结果证明了SDPC架构在连续控制问题中的有效性。
</details></li>
</ul>
<hr>
<h2 id="Hiding-Backdoors-within-Event-Sequence-Data-via-Poisoning-Attacks"><a href="#Hiding-Backdoors-within-Event-Sequence-Data-via-Poisoning-Attacks" class="headerlink" title="Hiding Backdoors within Event Sequence Data via Poisoning Attacks"></a>Hiding Backdoors within Event Sequence Data via Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10201">http://arxiv.org/abs/2308.10201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev</li>
<li>for: 这个论文旨在描述如何在金融业中使用深度学习模型，同时解决这些模型受到恶意攻击的问题。</li>
<li>methods: 这个论文使用了一种名为“潜藏后门”的方法，通过在训练过程中插入一个隐藏的攻击点来引入攻击性质的模型。</li>
<li>results:  experiments 表明，这种方法可以在不同的 dataset、架构和模型组件上实现攻击，并且可以让模型在检测攻击时保持正常的功能。<details>
<summary>Abstract</summary>
The financial industry relies on deep learning models for making important decisions. This adoption brings new danger, as deep black-box models are known to be vulnerable to adversarial attacks. In computer vision, one can shape the output during inference by performing an adversarial attack called poisoning via introducing a backdoor into the model during training. For sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems.
</details>
<details>
<summary>摘要</summary>
Financial industry 使用深度学习模型作重要决策，这种采用带来新的危险，深度黑盒模型容易受到抗击攻击。在计算机视觉中，可以在推理过程中Shape the outputby performing an adversarial attack called poisoning via introducing a backdoor into the model during training. However, for sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan, Hong Kong, and other regions.
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management"><a href="#Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management" class="headerlink" title="Deep Reinforcement Learning for Artificial Upwelling Energy Management"></a>Deep Reinforcement Learning for Artificial Upwelling Energy Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10199">http://arxiv.org/abs/2308.10199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyuan Zhang, Wei Fan</li>
<li>for: 这篇论文旨在探讨人工上升（Artificial Upwelling，AU）技术是否能够提高海洋抑 carbon 储存，以及AU 系统如何 efficiently 运行。</li>
<li>methods: 该论文提出了一种使用深度强化学习（Deep Reinforcement Learning，DRL）算法来开发高效的 AU 系统操作策略。</li>
<li>results: 通过大量的 simulations，该论文表明了 DRL 算法比传统的规则型approaches和其他 DRL 算法更有效率地减少能源浪费，同时确保 AU 系统的稳定和高效操作。<details>
<summary>Abstract</summary>
The potential of artificial upwelling (AU) as a means of lifting nutrient-rich bottom water to the surface, stimulating seaweed growth, and consequently enhancing ocean carbon sequestration, has been gaining increasing attention in recent years. This has led to the development of the first solar-powered and air-lifted AU system (AUS) in China. However, efficient scheduling of air injection systems remains a crucial challenge in operating AUS, as it holds the potential to significantly improve system efficiency. Conventional approaches based on rules or models are often impractical due to the complex and heterogeneous nature of the marine environment and its associated disturbances. To address this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.
</details>
<details>
<summary>摘要</summary>
人工升浮（AU）的潜在作用是将有营养物质的底水升到表层，促进海藻生长，从而提高海洋碳储存量。在最近几年中，AU在中国已经开始研发首个太阳能驱动、空气升降系统（AUS）。然而，AU系统的有效调度仍然是一个主要挑战，因为它们的 marine 环境复杂且多样化，以及其关联的干扰。为 Addressing this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.
</details></li>
</ul>
<hr>
<h2 id="ProSpire-Proactive-Spatial-Prediction-of-Radio-Environment-Using-Deep-Learning"><a href="#ProSpire-Proactive-Spatial-Prediction-of-Radio-Environment-Using-Deep-Learning" class="headerlink" title="ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep Learning"></a>ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10193">http://arxiv.org/abs/2308.10193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Sarkar, Dongning Guo, Danijela Cabric</li>
<li>for: 这个研究旨在帮助无线网络中的输送器预测电磁环境，以提高无线网络的多样性和可靠性。</li>
<li>methods: 这个研究使用了一个新的、受到监督学习的框架，即ProSpire，以实现对输送器的探测。ProSpire 利用了一个叫做 RSSu-net 的深度学习方法，实现了对输送器的预测。</li>
<li>results: 这个研究获得了reasonable的实验结果，其中预测误差为5 dB的平均绝对误差，与其他相关方法相当。此外，ProSpire 可以实现对输送器的探测，使其可以在97%的机会下不会导致干扰。相比之下，RSSu-net 的性能比其他相似方法更好，增加了19%的可能性。<details>
<summary>Abstract</summary>
Spatial prediction of the radio propagation environment of a transmitter can assist and improve various aspects of wireless networks. The majority of research in this domain can be categorized as 'reactive' spatial prediction, where the predictions are made based on a small set of measurements from an active transmitter whose radio environment is to be predicted. Emerging spectrum-sharing paradigms would benefit from 'proactive' spatial prediction of the radio environment, where the spatial predictions must be done for a transmitter for which no measurement has been collected.   This paper proposes a novel, supervised deep learning-based framework, ProSpire, that enables spectrum sharing by leveraging the idea of proactive spatial prediction. We carefully address several challenges in ProSpire, such as designing a framework that conveniently collects training data for learning, performing the predictions in a fast manner, enabling operations without an area map, and ensuring that the predictions do not lead to undesired interference. ProSpire relies on the crowdsourcing of transmitters and receivers during their normal operations to address some of the aforementioned challenges. The core component of ProSpire is a deep learning-based image-to-image translation method, which we call RSSu-net. We generate several diverse datasets using ray tracing software and numerically evaluate ProSpire. Our evaluations show that RSSu-net performs reasonably well in terms of signal strength prediction, 5 dB mean absolute error, which is comparable to the average error of other relevant methods. Importantly, due to the merits of RSSu-net, ProSpire creates proactive boundaries around transmitters such that they can be activated with 97% probability of not causing interference. In this regard, the performance of RSSu-net is 19% better than that of other comparable methods.
</details>
<details>
<summary>摘要</summary>
通过预测广播环境，可以提高无线网络的多种方面。大多数研究在这个领域是“反应式”的预测，基于活动发送器的 радио环境进行预测。然而，新兴的spectrum-sharing paradigms需要“积极”的预测，预测发送器没有收集过数据。这篇论文提出了一种新的、深度学习基于的框架，名为ProSpire，它利用了积极预测的想法。我们仔细解决了一些挑战，例如如何便捷地收集训练数据，在快速方式进行预测，不需要地图，以及预测不导致不必要的干扰。ProSpire通过在正常运行时 solicit 发送器和接收器来解决一些上述挑战。核心组件是一种基于图像至图像翻译的深度学习方法，我们称之为RSSu-net。我们使用 ray tracing 软件生成了多种多样的数据集，并 numerically 评估了ProSpire。我们的评估结果表明，RSSu-net在信号强度预测方面表现reasonably well，相比其他相关方法的平均误差为5 dB。这意味着ProSpire可以创建积极的边界，使 transmitter 有97%的概率不会导致干扰。这种性能比其他相似方法高出19%。
</details></li>
</ul>
<hr>
<h2 id="Mimicking-To-Dominate-Imitation-Learning-Strategies-for-Success-in-Multiagent-Competitive-Games"><a href="#Mimicking-To-Dominate-Imitation-Learning-Strategies-for-Success-in-Multiagent-Competitive-Games" class="headerlink" title="Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games"></a>Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10188">http://arxiv.org/abs/2308.10188</a></li>
<li>repo_url: None</li>
<li>paper_authors: The Viet Bui, Tien Mai, Thanh Hong Nguyen</li>
<li>for: 本研究旨在Addressing the challenges of training agents in multi-agent competitive games, particularly in mitigating uncertainties in game dynamics.</li>
<li>methods: 我们提出了一种新的多体学习模型，可以预测对手的下一步行动，基于隐藏的对手行动和本地观察。此外，我们还提出了一种新的多体强化学习算法，可以结合我们的模型和策略训练进行一起训练。</li>
<li>results: 我们在三个复杂的游戏环境中进行了广泛的实验，包括SMACv2。实验结果表明，我们的方法可以比现有的多体RL算法 achieve superior performance.<details>
<summary>Abstract</summary>
Training agents in multi-agent competitive games presents significant challenges due to their intricate nature. These challenges are exacerbated by dynamics influenced not only by the environment but also by opponents' strategies. Existing methods often struggle with slow convergence and instability. To address this, we harness the potential of imitation learning to comprehend and anticipate opponents' behavior, aiming to mitigate uncertainties with respect to the game dynamics. Our key contributions include: (i) a new multi-agent imitation learning model for predicting next moves of the opponents -- our model works with hidden opponents' actions and local observations; (ii) a new multi-agent reinforcement learning algorithm that combines our imitation learning model and policy training into one single training process; and (iii) extensive experiments in three challenging game environments, including an advanced version of the Star-Craft multi-agent challenge (i.e., SMACv2). Experimental results show that our approach achieves superior performance compared to existing state-of-the-art multi-agent RL algorithms.
</details>
<details>
<summary>摘要</summary>
training 多个代理人在多代理人竞争游戏中存在巨大的挑战，这些挑战受到环境以及对手策略的影响。现有方法经常受到慢性和不稳定性的影响。为了解决这些问题，我们利用仿制学来理解和预测对手的行为，以降低与游戏动力学有关的不确定性。我们的关键贡献包括：(i) 一种新的多个代理人仿制学模型，用于预测对手的下一步行动，该模型可以处理隐藏的对手行动和地方观察。(ii) 一种新的多个代理人 reinforcement learning 算法，将我们的仿制学模型和策略训练集成在一起，以实现单一的训练过程。(iii) 在三个复杂的游戏环境中进行了广泛的实验，包括 Star-Craft 多代理人挑战（SMACv2）的高级版本。实验结果表明，我们的方法可以与现有的多代理人 RL 算法相比，实现更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Quantization-based-Optimization-with-Perspective-of-Quantum-Mechanics"><a href="#Quantization-based-Optimization-with-Perspective-of-Quantum-Mechanics" class="headerlink" title="Quantization-based Optimization with Perspective of Quantum Mechanics"></a>Quantization-based Optimization with Perspective of Quantum Mechanics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11594">http://arxiv.org/abs/2308.11594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinwuk Seok, Changsik Cho</li>
<li>for: 本研究旨在探讨量子逻辑如何应用于全球优化问题中，提供一种新的研究框架。</li>
<li>methods: 本文使用量子谱分法对全球优化问题进行分析，揭示了量子力学中允许全球优化的特性。</li>
<li>results: 实验结果表明，量子谱分法中的 Tunneling 效应可以使得找到局部最优点的问题逃脱局部最优点，并且这种效应与量子力学基础的全球优化问题相同。<details>
<summary>Abstract</summary>
Statistical and stochastic analysis based on thermodynamics has been the main analysis framework for stochastic global optimization. Recently, appearing quantum annealing or quantum tunneling algorithm for global optimization, we require a new researching framework for global optimization algorithms. In this paper, we provide the analysis for quantization-based optimization based on the Schr\"odinger equation to reveal what property in quantum mechanics enables global optimization. We present that the tunneling effect derived by the Schr\"odinger equation in quantization-based optimization enables to escape of a local minimum. Additionally, we confirm that this tunneling effect is the same property included in quantum mechanics-based global optimization. Experiments with standard multi-modal benchmark functions represent that the proposed analysis is valid.
</details>
<details>
<summary>摘要</summary>
基于热力学的统计学和随机分析已经是全球优化的主要分析框架。在最近，量子气体或量子隧道算法在全球优化中出现，我们需要一个新的研究框架来探讨全球优化算法。在这篇论文中，我们提供了量子化基于Schrödinger方程的优化分析，以探索量子力学中允许全球优化的属性。我们发现，通过Schrödinger方程中的隧道效应，可以在量子化基于优化中突破本地最小值。此外，我们证明这种隧道效应与量子力学基于全球优化中的同一性。通过对标准多模式函数的实验，我们证明了我们的分析的有效性。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective"><a href="#Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective" class="headerlink" title="Rethinking Client Drift in Federated Learning: A Logit Perspective"></a>Rethinking Client Drift in Federated Learning: A Logit Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10162">http://arxiv.org/abs/2308.10162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlu Yan, Chun-Mei Feng, Mang Ye, Wangmeng Zuo, Ping Li, Rick Siow Mong Goh, Lei Zhu, C. L. Philip Chen</li>
<li>for: 这个研究是为了解决 Federated Learning (FL) 中 Client Drift 问题，并提高 FL 的性能。</li>
<li>methods: 本研究使用了一个新的 Class prototype Similarity Distillation (FedCSD) 算法，将本地和全球模型进行对预。 FedCSD 不仅将全球知识转移到本地客户端，因为一个未熟悉的全球模型无法提供可靠的知识，即类别相似性信息。而是将本地征推与全球原型之间的相似性用于对预。</li>
<li>results: 实验结果显示，FedCSD 在不同的多 клиєн端数据设定下表现更好，并且可以避免 Catastrophic Forgetting 问题。<details>
<summary>Abstract</summary>
Federated Learning (FL) enables multiple clients to collaboratively learn in a distributed way, allowing for privacy protection. However, the real-world non-IID data will lead to client drift which degrades the performance of FL. Interestingly, we find that the difference in logits between the local and global models increases as the model is continuously updated, thus seriously deteriorating FL performance. This is mainly due to catastrophic forgetting caused by data heterogeneity between clients. To alleviate this problem, we propose a new algorithm, named FedCSD, a Class prototype Similarity Distillation in a federated framework to align the local and global models. FedCSD does not simply transfer global knowledge to local clients, as an undertrained global model cannot provide reliable knowledge, i.e., class similarity information, and its wrong soft labels will mislead the optimization of local models. Concretely, FedCSD introduces a class prototype similarity distillation to align the local logits with the refined global logits that are weighted by the similarity between local logits and the global prototype. To enhance the quality of global logits, FedCSD adopts an adaptive mask to filter out the terrible soft labels of the global models, thereby preventing them to mislead local optimization. Extensive experiments demonstrate the superiority of our method over the state-of-the-art federated learning approaches in various heterogeneous settings. The source code will be released.
</details>
<details>
<summary>摘要</summary>
受欢迎的 Federated Learning (FL) 技术允许多个客户端共同学习，以保护隐私。然而，在实际世界中，客户端数据不够一致，导致客户端漂移，从而下降 FL 性能。我们发现，在不断更新模型时，本地和全球模型之间的差异在逐渐增加，从而严重降低 FL 性能。这主要是由于客户端数据不同性导致的慢速忘记。为解决这问题，我们提出了一种新的算法，即 FedCSD，它是一种基于联合类prototype similarity distillation的联邦框架，用于对本地和全球模型进行对齐。FedCSD不仅将全球知识传递给本地客户端，因为一个受训练不充分的全球模型无法提供可靠的类 similarity 信息，而且其错误的软标签会mislead本地优化。具体来说，FedCSD 引入一种类 prototype similarity distillation，用于对本地征标与全球 проtotypes 之间的类 similarity进行对齐。为提高全球征标的质量，FedCSD 采用了一种适应性掩模，以过滤全球模型的差异化软标签，从而避免它们对本地优化产生负面影响。我们的实验表明，FedCSD 在不同的异质设置下表现出优于当前 state-of-the-art 联邦学习方法。我们将源代码发布。
</details></li>
</ul>
<hr>
<h2 id="Resource-Adaptive-Newton’s-Method-for-Distributed-Learning"><a href="#Resource-Adaptive-Newton’s-Method-for-Distributed-Learning" class="headerlink" title="Resource-Adaptive Newton’s Method for Distributed Learning"></a>Resource-Adaptive Newton’s Method for Distributed Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10154">http://arxiv.org/abs/2308.10154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuzhen Chen, Yuan Yuan, Youming Tao, Zhipeng Cai, Dongxiao Yu</li>
<li>for: 这篇论文是用于探讨分布式随机优化方法，特别是以新顿方法为基础，以提高性能。</li>
<li>methods: 这篇论文使用了一种名为RANL的新型和有效的算法，它利用了简单的希腊矩来初始化，并通过自适应训练区域的分配来解决新顿方法的问题。</li>
<li>results: 这篇论文的结果显示了RANL算法在数据不均匀和训练资料组件复杂的情况下仍然能够实现线性的快速减退。此外，RANL算法还能够自动适应可用资源，以确保高效率。<details>
<summary>Abstract</summary>
Distributed stochastic optimization methods based on Newton's method offer significant advantages over first-order methods by leveraging curvature information for improved performance. However, the practical applicability of Newton's method is hindered in large-scale and heterogeneous learning environments due to challenges such as high computation and communication costs associated with the Hessian matrix, sub-model diversity, staleness in training, and data heterogeneity. To address these challenges, this paper introduces a novel and efficient algorithm called RANL, which overcomes the limitations of Newton's method by employing a simple Hessian initialization and adaptive assignments of training regions. The algorithm demonstrates impressive convergence properties, which are rigorously analyzed under standard assumptions in stochastic optimization. The theoretical analysis establishes that RANL achieves a linear convergence rate while effectively adapting to available resources and maintaining high efficiency. Unlike traditional first-order methods, RANL exhibits remarkable independence from the condition number of the problem and eliminates the need for complex parameter tuning. These advantages make RANL a promising approach for distributed stochastic optimization in practical scenarios.
</details>
<details>
<summary>摘要</summary>
新类的分布式数据估计方法，基于牛顿法，可以实现更好的性能，但是它实际应用在大规模和多标的学习环境中受到一些挑战，例如牛顿矩阵的计算和通信成本高昂，模型多标的问题，训练过程中的偏预设问题，数据多标性。为了解决这些挑战，本文提出了一个新的和高效的算法，叫做RANL，它可以超越牛顿法的限制，通过简单的牛顿矩阵初始化和自适应的训练区域分配。这个算法在标准假设下进行了严谨的分析，证明了RANL可以在线性几何中实现快速的渐近稳定。不同于传统的首项方法，RANL不受问题的条件数值影响，并且不需要复杂的参数调整。这些优点使RANL成为实际应用中的分布式数据估计方法。
</details></li>
</ul>
<hr>
<h2 id="Global-Warming-In-Ghana’s-Major-Cities-Based-on-Statistical-Analysis-of-NASA’s-POWER-Over-3-Decades"><a href="#Global-Warming-In-Ghana’s-Major-Cities-Based-on-Statistical-Analysis-of-NASA’s-POWER-Over-3-Decades" class="headerlink" title="Global Warming In Ghana’s Major Cities Based on Statistical Analysis of NASA’s POWER Over 3-Decades"></a>Global Warming In Ghana’s Major Cities Based on Statistical Analysis of NASA’s POWER Over 3-Decades</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10909">http://arxiv.org/abs/2308.10909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Attih</li>
<li>for: 这项研究旨在 investigate Ghana 四大城市的长期温度趋势，以了解地方气候变化的影响和政策制定的依据。</li>
<li>methods: 该研究使用 NASA 的 Prediction of Worldwide Energy Resource (POWER) 数据，并使用统计分析和 XGBoost 机器学习算法来预测温度变化。 地表温度 profiling 图表从 RSLab 平台生成，以提高准确性。</li>
<li>results: 研究发现各城市都有本地气候变化趋势，特别是工业化的 Accra 显示明显的升高趋势。 涉及人口因素不显著。 XGBoost 模型的低 Root Mean Square Error (RMSE) 分数表明其能够准确地捕捉温度模式。 Wa  unexpectedly 的平均温度最高。 预计2023 中期 Accra 的平均温度为 27.86℃，Kumasi 为 27.15℃， Kete-Krachi 为 29.39℃， Wa 为 30.76℃。这些结果可以帮助气候变化策略的制定和实施。<details>
<summary>Abstract</summary>
Global warming's impact on high temperatures in various parts of the world has raised concerns. This study investigates long-term temperature trends in four major Ghanaian cities representing distinct climatic zones. Using NASA's Prediction of Worldwide Energy Resource (POWER) data, statistical analyses assess local climate warming and its implications. Linear regression trend analysis and eXtreme Gradient Boosting (XGBoost) machine learning predict temperature variations. Land Surface Temperature (LST) profile maps generated from the RSLab platform enhance accuracy. Results reveal local warming trends, particularly in industrialized Accra. Demographic factors aren't significant. XGBoost model's low Root Mean Square Error (RMSE) scores demonstrate effectiveness in capturing temperature patterns. Wa unexpectedly has the highest mean temperature. Estimated mean temperatures for mid-2023 are: Accra 27.86{\deg}C, Kumasi 27.15{\deg}C, Kete-Krachi 29.39{\deg}C, and Wa 30.76{\deg}C. These findings improve understanding of local climate warming for policymakers and communities, aiding climate change strategies.
</details>
<details>
<summary>摘要</summary>
全球气候变化对各地高温的影响已引发了关注。这项研究对四个加纳城市进行了长期气温趋势分析，这些城市代表了不同的气候区。使用NASA的Prediction of Worldwide Energy Resource（POWER）数据，统计分析评估了地方气候变暖的影响。线性回归方法和极限梯度提升（XGBoost）机器学习方法预测温度变化。RSLab平台生成的土地表面温度（LST）profile图表提高了准确性。结果显示了地方气候变暖趋势，特别是工业化的阿克拉。人口因素没有显著影响。XGBoost模型的低根据平方误差（RMSE）得分表明其能够准确捕捉温度模式。意外地，华有最高的平均温度。预计2023年中的温度为：阿克拉27.86℃，库马西27.15℃，别克拉29.39℃，和华30.76℃。这些发现可以帮助气候变化策略的制定和社区的决策。
</details></li>
</ul>
<hr>
<h2 id="OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision"><a href="#OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision" class="headerlink" title="OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision"></a>OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10146">http://arxiv.org/abs/2308.10146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shujie Zhang, Tianyue Zheng, Zhe Chen, Jingzhi Hu, Abdelwahed Khamis, Jiajun Liu, Jun Luo<br>for: occluded hand pose estimationmethods: RF-vision and adversarial learningresults: comparable accuracy to CM-HPE under normal conditions, maintains accuracy in occluded scenarios, generalizable to new domains.Here’s the simplified Chinese text:for:  occluded手势识别methods: RF-vision和对抗学习results: 与CM-HPE在正常情况下具有相同的准确率，在遮盖情况下保持准确率，并能在新领域中普适应用.<details>
<summary>Abstract</summary>
Hand Pose Estimation (HPE) is crucial to many applications, but conventional cameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as cameras cannot capture occluded objects. In this paper, we propose to exploit Radio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose estimation capability. OCHID-Fi employs wideband RF sensors widely available on smart devices (e.g., iPhones) to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the challenge in labeling RF imaging given its human incomprehensible nature, OCHID-Fi employs a cross-modality and cross-domain training process. It uses a pre-trained CM-HPE network and a synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE network under LoS conditions. It further transfers knowledge learned from labeled LoS domain to unlabeled occluded domain via adversarial learning, enabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental results demonstrate the superiority of OCHID-Fi: it achieves comparable accuracy to CM-HPE under normal conditions while maintaining such accuracy even in occluded scenarios, with empirical evidence for its generalizability to new domains.
</details>
<details>
<summary>摘要</summary>
手势识别（HPE）是许多应用程序的关键，但传统的相机基于CM-HPE方法是完全依赖于直线视野（LoS），因为相机无法捕捉遮盖物体。在这篇论文中，我们提议利用Radio-Frequency-Vision（RF-vision）来绕过障碍物实现遮盖物体HPE，并介绍了OCHID-Fi作为首个RF-HPE方法，具有3D手势 pose estimation能力。OCHID-Fi利用了广泛可用的智能设备（如iPhone）上的宽频RF传感器来探测3D人手势 pose和其骨架，并在障碍物下实现了高精度的手势识别。为了解决RF图像标注的挑战，OCHID-Fi采用了交叉模式和交叉领域训练过程。它使用了预训练的CM-HPE网络和同步CM/RF数据集，以导引其复杂的RF-HPE网络在LoS条件下进行训练。它还通过对LoS频谱频谱中的标注进行反向传播学习，使OCHID-Fi能够在未看到障碍物的情况下泛化到新领域。实验结果表明，OCHID-Fi具有较高的精度和泛化能力，可以在正常情况下与CM-HPE具有相同的精度，而在障碍物下仍然保持高精度，并且在新领域中进行泛化。
</details></li>
</ul>
<hr>
<h2 id="Wasserstein-Geodesic-Generator-for-Conditional-Distributions"><a href="#Wasserstein-Geodesic-Generator-for-Conditional-Distributions" class="headerlink" title="Wasserstein Geodesic Generator for Conditional Distributions"></a>Wasserstein Geodesic Generator for Conditional Distributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10145">http://arxiv.org/abs/2308.10145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyg0910/wasserstein-geodesic-generator-for-conditional-distributions">https://github.com/kyg0910/wasserstein-geodesic-generator-for-conditional-distributions</a></li>
<li>paper_authors: Young-geun Kim, Kyungbok Lee, Youngwon Choi, Joong-Ho Won, Myunghee Cho Paik</li>
<li>for: 这篇论文是用于研究如何获得高品质的条件生成。</li>
<li>methods: 论文使用估计条件分布的方法，包括 derive 一个可诠释的上界 bound 来定义条件分布，并使用 optimal transport 理论来设计一个名为 Wasserstein geodesic generator 的新型条件生成器。</li>
<li>results: 实验结果显示，提案的方法可以高效地学习条件分布，并可以生成高品质的条件生成。<details>
<summary>Abstract</summary>
Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the Wasserstein geodesic generator, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
</details>
<details>
<summary>摘要</summary>
<<SYS>计算样本 Given Specific标签需要估算conditional Distributions。我们得出了可观察 Wasserstein distance的Upper bound，以准备 theoretically learn conditional Distributions。 Based on this result, we propose a novel conditional generation algorithm, where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the Wasserstein geodesic generator, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method. tranlation notes:* "conditional distributions" translated as "条件分布"* "Wasserstein distance" translated as "沃斯坦距离"* "metric space" translated as "度量空间"* "optimal transport theory" translated as "最优运输理论"* "Wasserstein geodesic" translated as "沃斯坦曲线"* "conditional generator" translated as "条件生成器"* "observed domains" translated as "观察Domain"* "unobserved intermediate domains" translated as "未观察中间Domain"* "light conditions" translated as "照明条件"Please note that the translation is in Simplified Chinese, and the word order may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="ExpeL-LLM-Agents-Are-Experiential-Learners"><a href="#ExpeL-LLM-Agents-Are-Experiential-Learners" class="headerlink" title="ExpeL: LLM Agents Are Experiential Learners"></a>ExpeL: LLM Agents Are Experiential Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10144">http://arxiv.org/abs/2308.10144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Andrewzh112/ExpeL">https://github.com/Andrewzh112/ExpeL</a></li>
<li>paper_authors: Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, Gao Huang</li>
<li>for: 这篇论文的目的是提出一种新的语言模型学习方法，以便在做决策任务时不需要进行参数更新。</li>
<li>methods: 该方法使用自然语言从训练任务中收集经验，并通过自动提取知识来做出 Informed 决策。</li>
<li>results: 该方法在实验中表现出了Robust 的学习效果，表明随着经验的积累，模型的性能会不断提高。<details>
<summary>Abstract</summary>
The recent surge in research interest in applying large language models (LLMs) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in LLMs. While there is a growing demand to tailor LLMs for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the ExpeL agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results show that the ExpeL agent exhibits robust learning efficacy, with its performance consistently improving as it accumulates experiences. We also explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details></li>
</ul>
<hr>
<h2 id="A-Review-on-Objective-Driven-Artificial-Intelligence"><a href="#A-Review-on-Objective-Driven-Artificial-Intelligence" class="headerlink" title="A Review on Objective-Driven Artificial Intelligence"></a>A Review on Objective-Driven Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10135">http://arxiv.org/abs/2308.10135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Apoorv Singh</li>
<li>for: 本文旨在探讨人工智能（AI）技术目前的缺陷，以及如何通过层次规划和能量基、隐变量方法等方法来减少人机智能差距。</li>
<li>methods: 本文主要使用层次规划、能量基、隐变量方法等方法来探讨人工智能技术的发展和应用。</li>
<li>results: 本文指出，现有的AI技术尚未能够准确地理解人类的语言和情感表达，而层次规划和能量基、隐变量方法等方法可以帮助人工智能技术更好地理解人类的语言和情感表达。<details>
<summary>Abstract</summary>
While advancing rapidly, Artificial Intelligence still falls short of human intelligence in several key aspects due to inherent limitations in current AI technologies and our understanding of cognition. Humans have an innate ability to understand context, nuances, and subtle cues in communication, which allows us to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret such contextual information accurately. Humans possess a vast repository of common-sense knowledge that helps us make logical inferences and predictions about the world. Machines lack this innate understanding and often struggle with making sense of situations that humans find trivial. In this article, we review the prospective Machine Intelligence candidates, a review from Prof. Yann LeCun, and other work that can help close this gap between human and machine intelligence. Specifically, we talk about what's lacking with the current AI techniques such as supervised learning, reinforcement learning, self-supervised learning, etc. Then we show how Hierarchical planning-based approaches can help us close that gap and deep-dive into energy-based, latent-variable methods and Joint embedding predictive architecture methods.
</details>
<details>
<summary>摘要</summary>
artifical intelligence 在快速发展中，但仍然缺乏人类智能的一些关键方面，这主要归结于当前的 AI 技术和我们认知神经科学的限制。人类有内置的理解上下文、涵义和微妙提示的能力，使得我们能够理解讽刺、讽刺和 метаFOR。机器则很难准确地理解这些上下文信息。人类拥有庞大的通用智能知识，帮助我们做出逻辑推理和世界上的预测。机器缺乏这种内置的理解，经常陷入人类轻视的情况。在这篇文章中，我们评论了当前的机器智能候选人，包括Prof. Yann LeCun的评论以及其他工作，以帮助关闭人类和机器智能之间的差距。我们讨论了当前 AI 技术的缺陷，如监督学习、奖励学习、自监学习等。然后，我们介绍了层次规划基础的方法，可以帮助我们关闭这个差距。我们还深入探讨了能量基础、隐变量方法和联合嵌入预测架构。
</details></li>
</ul>
<hr>
<h2 id="AutoReP-Automatic-ReLU-Replacement-for-Fast-Private-Network-Inference"><a href="#AutoReP-Automatic-ReLU-Replacement-for-Fast-Private-Network-Inference" class="headerlink" title="AutoReP: Automatic ReLU Replacement for Fast Private Network Inference"></a>AutoReP: Automatic ReLU Replacement for Fast Private Network Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10134">http://arxiv.org/abs/2308.10134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harveyp123/autorep">https://github.com/harveyp123/autorep</a></li>
<li>paper_authors: Hongwu Peng, Shaoyi Huang, Tong Zhou, Yukui Luo, Chenghong Wang, Zigeng Wang, Jiahui Zhao, Xi Xie, Ang Li, Tony Geng, Kaleel Mahmood, Wujie Wen, Xiaolin Xu, Caiwen Ding<br>for: This paper aims to address the data privacy and security issues in Machine-Learning-As-A-Service (MLaaS) market by proposing a gradient-based approach called AutoReP, which reduces the number of non-linear operators and maintains model expressivity.methods: The proposed AutoReP method uses gradient-based approach to select appropriate ReLU and polynomial functions for private inference, and introduces distribution-aware polynomial approximation (DaPa) to accurately approximate ReLUs.results: The experimental results on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets show significant accuracy improvements over current state-of-the-art methods, e.g., SNL. Specifically, the accuracy improvements are 6.12%, 8.39%, and 9.45%, respectively. Additionally, AutoReP is applied to EfficientNet-B2 on ImageNet dataset, achieving 75.55% accuracy with 176.1 times ReLU budget reduction.<details>
<summary>Abstract</summary>
The growth of the Machine-Learning-As-A-Service (MLaaS) market has highlighted clients' data privacy and security issues. Private inference (PI) techniques using cryptographic primitives offer a solution but often have high computation and communication costs, particularly with non-linear operators like ReLU. Many attempts to reduce ReLU operations exist, but they may need heuristic threshold selection or cause substantial accuracy loss. This work introduces AutoReP, a gradient-based approach to lessen non-linear operators and alleviate these issues. It automates the selection of ReLU and polynomial functions to speed up PI applications and introduces distribution-aware polynomial approximation (DaPa) to maintain model expressivity while accurately approximating ReLUs. Our experimental results demonstrate significant accuracy improvements of 6.12% (94.31%, 12.9K ReLU budget, CIFAR-10), 8.39% (74.92%, 12.9K ReLU budget, CIFAR-100), and 9.45% (63.69%, 55K ReLU budget, Tiny-ImageNet) over current state-of-the-art methods, e.g., SNL. Morever, AutoReP is applied to EfficientNet-B2 on ImageNet dataset, and achieved 75.55% accuracy with 176.1 times ReLU budget reduction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Intelligent-Communication-Planning-for-Constrained-Environmental-IoT-Sensing-with-Reinforcement-Learning"><a href="#Intelligent-Communication-Planning-for-Constrained-Environmental-IoT-Sensing-with-Reinforcement-Learning" class="headerlink" title="Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning"></a>Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10124">http://arxiv.org/abs/2308.10124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Hu, Jinhang Zuo, Bob Iannucci, Carlee Joe-Wong</li>
<li>for: 这篇论文旨在提高环境监测和风险警告，通过部署一个网络的物联网设备（IoT）。</li>
<li>methods: 该论文使用多代理学习（MARL）方法来优化物联网设备的通信策略，以最大化环境数据跟踪准确性，同时满足功率和带宽限制。</li>
<li>results: 实验表明，使用MARL方法可以学习和利用环境数据的空间时间相关性，以减少物联网设备的重复报告。<details>
<summary>Abstract</summary>
Internet of Things (IoT) technologies have enabled numerous data-driven mobile applications and have the potential to significantly improve environmental monitoring and hazard warnings through the deployment of a network of IoT sensors. However, these IoT devices are often power-constrained and utilize wireless communication schemes with limited bandwidth. Such power constraints limit the amount of information each device can share across the network, while bandwidth limitations hinder sensors' coordination of their transmissions. In this work, we formulate the communication planning problem of IoT sensors that track the state of the environment. We seek to optimize sensors' decisions in collecting environmental data under stringent resource constraints. We propose a multi-agent reinforcement learning (MARL) method to find the optimal communication policies for each sensor that maximize the tracking accuracy subject to the power and bandwidth limitations. MARL learns and exploits the spatial-temporal correlation of the environmental data at each sensor's location to reduce the redundant reports from the sensors. Experiments on wildfire spread with LoRA wireless network simulators show that our MARL method can learn to balance the need to collect enough data to predict wildfire spread with unknown bandwidth limitations.
</details>
<details>
<summary>摘要</summary>
互联网物件技术（IoT）已经启用了许多数据驱动的移动应用程序，并有潜力增强环境监控和险情警告通过网络设置 IoT 感知器。然而，这些 IoT 设备通常受限于能源和无线通信协议的限制，这限制每个设备可以在网络上分享的资讯量，而且对于感知器的传输协议的协调也受到限制。在这个工作中，我们将环境监控 IoT 感知器的通信规划问题形式化为一个最佳化问题，以最大化感知器对环境状态的追踪精度，同时遵循能源和传输协议的限制。我们提出了一种基于多代理问题学习（MARL）方法，以便每个感知器可以在网络上传输环境数据，并且可以适当地调整传输策略，以最大化追踪精度。实验结果显示，我们的 MARL 方法可以在不知道传输协议的情况下，对野火传播进行精确的预测。
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Modeling-based-Data-Augmentation-with-Demonstration-using-the-BFBT-Benchmark-Void-Fraction-Datasets"><a href="#Deep-Generative-Modeling-based-Data-Augmentation-with-Demonstration-using-the-BFBT-Benchmark-Void-Fraction-Datasets" class="headerlink" title="Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets"></a>Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10120">http://arxiv.org/abs/2308.10120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farah Alsafadi, Xu Wu</li>
<li>for: 这个论文的目的是用深度学习（DL）技术来扩展科学数据，以便更好地训练深度学习模型。</li>
<li>methods: 这个论文使用了深度生成模型（DGM），包括生成敌对网络（GAN）、标准化流（NF）、变换自动编码器（VAE）和条件VAE（CVAE）等，来学习训练数据集的下面分布。</li>
<li>results: 研究发现，使用DGM生成的 sintetic数据可以覆盖现有训练数据的限制，并且可以减少训练数据的缺失值。CVAEs的生成性能最佳，其生成的数据具有最小的错误。这些结果表明，DGM可以有效地扩展科学数据，并且可以帮助深度学习模型更加准确地训练。<details>
<summary>Abstract</summary>
Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of ``big data''. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）在许多领域取得了很大成功，如计算机视觉和自然语言处理，这主要归功于大量数据的可用性。然而，在核工程问题中，由于数据的有限性，特别是高成本实验室中的数据，因此复制这种成功是不容易的。为解决这个数据缺乏问题，本文探讨了在科学数据增强方面使用深度生成模型（DGM）的应用。DGM包括生成对抗网络（GAN）、Normalizing Flows（NF）、Variational Autoencoders（VAE）和 Conditional VAEs（CVAE）等，可以在训练数据集的下采用学习下面的概率分布。一旦训练完成，它们可以生成与训练数据相似的 sintetic 数据，并大大增加数据集的大小。本研究通过使用 DGM 增强 TRACE 仿真数据，基于 NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test（BFBT）标准底本，展示了 VAE、CVAE 和 GAN 在生成数据时的相似性，CVAE 的错误最小。这些发现表明 DGM 在核工程领域有很大的潜力，可以增强数据增强模型的准确性，从而提高核工程领域的研究效果。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Random-Networks-with-Heterogeneous-Reciprocity"><a href="#Modeling-Random-Networks-with-Heterogeneous-Reciprocity" class="headerlink" title="Modeling Random Networks with Heterogeneous Reciprocity"></a>Modeling Random Networks with Heterogeneous Reciprocity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10113">http://arxiv.org/abs/2308.10113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Cirkovic, Tiandong Wang</li>
<li>For: 本研究旨在模型社交网络中不同水平的反馈行为。* Methods: 本文提出了一种偏好附加模型，用于模拟用户吸引受欢迎用户的行为，以及不同水平的反馈行为。文章还比较了 bayesian 和 frequentist 模型适应技术，以及计算效率高的变量方案。* Results: 对 Facebook 墙上的墙文网络进行分析，发现用户的反馈行为呈差异性分布，并使用模型预测用户之间的连接关系。模型能够捕捉 Facebook 数据中的重概率分布，并分别确定了多个用户群体的反馈行为特征。<details>
<summary>Abstract</summary>
Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities are known and unknown are both considered. We apply the presented methods to the analysis of a Facebook wallpost network where users have non-uniform reciprocal behavior patterns. The fitted model captures the heavy-tailed nature of the empirical degree distributions in the Facebook data and identifies multiple groups of users that differ in their tendency to reply to and receive responses to wallposts.
</details>
<details>
<summary>摘要</summary>
“循环性”或“模仿行为”是社交网络中信息交换的关键指标。社交网络中的用户通常在不同的水平上进行反馈行为。不同的反馈行为可能表示社交网络中存在不同的社群，这些社群在链接reciprocate的速率上有所不同。在这篇论文中，我们开发了模型社交网络中多样化反馈行为的方法ологи。特别是，我们提出了具有异质反馈的偏好附着模型，该模型模拟用户循环行为的吸引力和不同的反馈方式。我们比较了 bayesian 和频率主义模型适应技术，以及计算效率高的变量替代方法。我们还考虑了知道和不知道社群数量的两种情况。我们应用这些方法分析Facebook墙上的墙posts网络，发现用户的反馈行为具有不均匀的特点，并确定了不同的用户群体。Note: "循环性" (reciprocity) in the text refers to the tendency of individuals to mirror behavior in a social network.
</details></li>
</ul>
<hr>
<h2 id="Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks"><a href="#Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks" class="headerlink" title="Robust Mixture-of-Expert Training for Convolutional Neural Networks"></a>Robust Mixture-of-Expert Training for Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10110">http://arxiv.org/abs/2308.10110</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/optml-group/robust-moe-cnn">https://github.com/optml-group/robust-moe-cnn</a></li>
<li>paper_authors: Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu</li>
<li>for: 本研究旨在探讨如何使用 sparse-gated Mixture of Expert (MoE) 模型提高 convolutional neural networks (CNNs) 的鲁棒性。</li>
<li>methods: 本研究提出了一种新的 router-expert alternating Adversarial training 框架，以提高 MoE-CNN 模型的鲁棒性。</li>
<li>results: 实验结果表明，相比 dense CNN，AdvMoE 可以提高 adversarial robustness 1% ~ 4%，同时具有较高的计算效率，减少了 более半个 inference cost。<details>
<summary>Abstract</summary>
Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details>
<details>
<summary>摘要</summary>
这是一篇研究档案，探讨了一种新的深度学习模型架构，即零价对抗性混合专家（MoE）。这种模型架构已经展示了高精度和高效率的推断能力。 despite its growing popularity, little work has been done to investigate its potential to improve convolutional neural networks (CNNs)， especially in the area of adversarial robustness. therefore, we ask: how to adversarially robustify a CNN-based MoE model? can we train it like an ordinary CNN model? our preliminary study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) is no longer effective to robustify an MoE-CNN. to better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: the robustness of routers (i.e., gating functions to select data-specific experts) and the robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). our analyses show that routers and experts are difficult to adapt to each other in the vanilla AT. therefore, we propose a new router-expert alternating adversarial training framework for MoE, termed AdvMoE. the effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. we find that AdvMoE achieves 1% to 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details></li>
</ul>
<hr>
<h2 id="An-Online-Multiple-Kernel-Parallelizable-Learning-Scheme"><a href="#An-Online-Multiple-Kernel-Parallelizable-Learning-Scheme" class="headerlink" title="An Online Multiple Kernel Parallelizable Learning Scheme"></a>An Online Multiple Kernel Parallelizable Learning Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10101">http://arxiv.org/abs/2308.10101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emilio Ruiz-Moreno, Baltasar Beferull-Lozano</li>
<li>for: 提高单kernel方法的选择灵活性和计算效率，使其能够更好地适应数据丰富任务中的解决空间。</li>
<li>methods: 基于多kernel学习形式，可以将单kernel解决空间扩展到更广泛的解决空间，从而提高解决空间内的性能。同时，该学习形式可以并行化，以便分配计算负担到不同的计算单元。</li>
<li>results: 在实验中，提出的学习方案比单个单kernel方法相比，在累积较少的最小二乘loss metric上表现出更高的性能。<details>
<summary>Abstract</summary>
The performance of reproducing kernel Hilbert space-based methods is known to be sensitive to the choice of the reproducing kernel. Choosing an adequate reproducing kernel can be challenging and computationally demanding, especially in data-rich tasks without prior information about the solution domain. In this paper, we propose a learning scheme that scalably combines several single kernel-based online methods to reduce the kernel-selection bias. The proposed learning scheme applies to any task formulated as a regularized empirical risk minimization convex problem. More specifically, our learning scheme is based on a multi-kernel learning formulation that can be applied to widen any single-kernel solution space, thus increasing the possibility of finding higher-performance solutions. In addition, it is parallelizable, allowing for the distribution of the computational load across different computing units. We show experimentally that the proposed learning scheme outperforms the combined single-kernel online methods separately in terms of the cumulative regularized least squares cost metric.
</details>
<details>
<summary>摘要</summary>
“kernel Hilbert space-based方法的性能受选择kernel的影响很大。选择合适的kernel可以是一个问题，特别是在没有对解题域的内部信息的情况下。本文提出了一个学习方案，可以可扩展性地结合多个单kernel-based在线方法，以减少kernel-选择偏见。这个学习方案适用于任何形式化为单倍阶调整项目的问题。更 Specifically, our learning scheme is based on a multi-kernel learning formulation that can be applied to widen any single-kernel solution space, thus increasing the possibility of finding higher-performance solutions. In addition, it is parallelizable, allowing for the distribution of the computational load across different computing units. We show experimentally that the proposed learning scheme outperforms the combined single-kernel online methods separately in terms of the cumulative regularized least squares cost metric.”Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Geometric-instability-of-graph-neural-networks-on-large-graphs"><a href="#Geometric-instability-of-graph-neural-networks-on-large-graphs" class="headerlink" title="Geometric instability of graph neural networks on large graphs"></a>Geometric instability of graph neural networks on large graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10099">http://arxiv.org/abs/2308.10099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/brs96/geometric-instability-gnn-large-graphs">https://github.com/brs96/geometric-instability-gnn-large-graphs</a></li>
<li>paper_authors: Emily Morris, Haotian Shen, Weiling Du, Muhammad Hamza Sajjad, Borun Shi</li>
<li>for: 研究图 Néural Networks（GNNs）中的几何不稳定性。</li>
<li>methods: 提出了一种简单、高效的图native Graph Gram Index（GGI）来测量这种不稳定性，该指标具有卷积、旋转、平移和评估顺序不敏感的特点。</li>
<li>results: 通过研究大图上GNN embedding的不稳定性，发现 embeddings的不稳定性随图的大小而变化，并且在node classification和链接预测 tasks上有不同的不稳定性行为。<details>
<summary>Abstract</summary>
We analyse the geometric instability of embeddings produced by graph neural networks (GNNs). Existing methods are only applicable for small graphs and lack context in the graph domain. We propose a simple, efficient and graph-native Graph Gram Index (GGI) to measure such instability which is invariant to permutation, orthogonal transformation, translation and order of evaluation. This allows us to study the varying instability behaviour of GNN embeddings on large graphs for both node classification and link prediction.
</details>
<details>
<summary>摘要</summary>
我们分析图 neural network (GNN) 生成的嵌入的几何不稳定性。现有方法只适用于小图，缺乏图域上的上下文。我们提议一种简单、高效、图原生的图agram Gram Index (GGI) 来衡量这种不稳定性，该指标是对Permutation、旋转、平移和评估顺序进行 invariant。这使得我们可以研究 GNN 嵌入在大图上的不同不稳定行为，包括节点分类和链接预测。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Bilevel-Learning-with-Inexact-Line-Search"><a href="#Dynamic-Bilevel-Learning-with-Inexact-Line-Search" class="headerlink" title="Dynamic Bilevel Learning with Inexact Line Search"></a>Dynamic Bilevel Learning with Inexact Line Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10098">http://arxiv.org/abs/2308.10098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</li>
<li>for: 这篇论文的目的是解决在各种图像和数据科学领域中，特别是使用变分regularization方法时，手动配置正则化参数的问题。</li>
<li>methods: 这篇论文使用了积分学习来学习适当的正则化参数。</li>
<li>results: 这篇论文的实验结果表明，该方法可以有效地解决手动配置正则化参数的问题，并且可以根据实际需求动态地确定需要的精度。<details>
<summary>Abstract</summary>
In various domains within imaging and data science, particularly when addressing tasks modeled utilizing the variational regularization approach, manually configuring regularization parameters presents a formidable challenge. The difficulty intensifies when employing regularizers involving a large number of hyperparameters. To overcome this challenge, bilevel learning is employed to learn suitable hyperparameters. However, due to the use of numerical solvers, the exact gradient with respect to the hyperparameters is unattainable, necessitating the use of methods relying on approximate gradients. State-of-the-art inexact methods a priori select a decreasing summable sequence of the required accuracy and only assure convergence given a sufficiently small fixed step size. Despite this, challenges persist in determining the Lipschitz constant of the hypergradient and identifying an appropriate fixed step size. Conversely, computing exact function values is not feasible, impeding the use of line search. In this work, we introduce a provably convergent inexact backtracking line search involving inexact function evaluations and hypergradients. We show convergence to a stationary point of the loss with respect to hyperparameters. Additionally, we propose an algorithm to determine the required accuracy dynamically. Our numerical experiments demonstrate the efficiency and feasibility of our approach for hyperparameter estimation in variational regularization problems, alongside its robustness in terms of the initial accuracy and step size choices.
</details>
<details>
<summary>摘要</summary>
在各种图像和数据科学领域中，特别是使用变分regularization方法解决问题时，手动配置正则化参数是一项具有挑战性的任务。这种挑战会加剧，当使用含有大量hyperparameter的正则izers时。为了解决这个问题，我们使用笛卡尔学习来学习适当的hyperparameter。然而，由于使用数值解析器，不能获取正则izers的精确梯度，因此需要使用 Approximate Gradients 的方法。现有的 state-of-the-art 不精确方法会选择一个递减和可加性的精度要求，并且只有在 sufficiently small fixed step size 下才能确保收敛。然而，在确定 Lipschitz 常数和选择合适的fixed step size 方面，仍然存在挑战。另外，计算精确函数值是不可能的，从而阻碍了使用线搜索。在这种情况下，我们提出了一种可证明收敛的不精确返回搜索，该搜索利用不精确函数评估和正则izers的梯度。我们证明了该方法可以收敛到正则izers中的一个站点点。此外，我们还提出了一种动态确定所需的精度的算法。我们的数值实验表明，我们的方法可以有效地进行正则izers的优化，并且具有较好的Robustness 性。
</details></li>
</ul>
<hr>
<h2 id="MLOps-A-Review"><a href="#MLOps-A-Review" class="headerlink" title="MLOps: A Review"></a>MLOps: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10908">http://arxiv.org/abs/2308.10908</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jenningst/ecommerce-ops">https://github.com/jenningst/ecommerce-ops</a></li>
<li>paper_authors: Samar Wazir, Gautam Siddharth Kashyap, Parag Saxena</li>
<li>for: The paper aims to explore the significance of Machine Learning Operations (MLOps) methods and assess their features and operability to help create software that is simple to use.</li>
<li>methods: The authors evaluate 22 papers that attempted to apply the MLOps idea and assess the features and operability of various MLOps methods.</li>
<li>results: The authors conclude that there is a scarcity of fully effective MLOps methods that can self-regulate by limiting human engagement.Here’s the same information in Simplified Chinese text:</li>
<li>for: 该论文旨在探讨机器学习运维（MLOps）方法的重要性和评估各种MLOps方法的特性和操作性，以帮助创建简单易用的软件。</li>
<li>methods: 作者评估了22篇应用了MLOps想法的论文，并评估各种MLOps方法的特性和操作性。</li>
<li>results: 作者认为，目前 még 缺乏完全有效的MLOps方法，可以通过限制人类参与来自动化进程。<details>
<summary>Abstract</summary>
Recently, Machine Learning (ML) has become a widely accepted method for significant progress that is rapidly evolving. Since it employs computational methods to teach machines and produce acceptable answers. The significance of the Machine Learning Operations (MLOps) methods, which can provide acceptable answers for such problems, is examined in this study. To assist in the creation of software that is simple to use, the authors research MLOps methods. To choose the best tool structure for certain projects, the authors also assess the features and operability of various MLOps methods. A total of 22 papers were assessed that attempted to apply the MLOps idea. Finally, the authors admit the scarcity of fully effective MLOps methods based on which advancements can self-regulate by limiting human engagement.
</details>
<details>
<summary>摘要</summary>
最近，机器学习（ML）已成为广泛接受的方法，迅速发展。由于它利用计算方法教育机器并生成可接受的答案。本研究研究机器学习操作（MLOps）方法，以便为解决这些问题提供可靠的答案。为便于创建简单易用的软件，作者研究了不同的MLOps方法。为选择特定项目适用的最佳工具结构，作者还评估了各种MLOps方法的特性和操作性。本研究总共评估了22篇尝试应用MLOps想法的论文。最后，作者承认MLOps方法的完全可效性尚未得到保证，尤其是限制人类参与的情况下。
</details></li>
</ul>
<hr>
<h2 id="Securing-Pathways-with-Orthogonal-Robots"><a href="#Securing-Pathways-with-Orthogonal-Robots" class="headerlink" title="Securing Pathways with Orthogonal Robots"></a>Securing Pathways with Orthogonal Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10093">http://arxiv.org/abs/2308.10093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamid Hoorfar, Faraneh Fathi, Sara Moshtaghi Largani, Alireza Bagheri</li>
<li>for: 本研究旨在提供一种新型的路径保护方法，使用正交机器人来保护路径。</li>
<li>methods: 本研究使用了正交机器人来 efficiently guard orthogonal areas with the minimum number of orthogonal robots.</li>
<li>results: 研究表明可以在线时确定最小数量的正交机器人，以保护路径。<details>
<summary>Abstract</summary>
The protection of pathways holds immense significance across various domains, including urban planning, transportation, surveillance, and security. This article introduces a groundbreaking approach to safeguarding pathways by employing orthogonal robots. The study specifically addresses the challenge of efficiently guarding orthogonal areas with the minimum number of orthogonal robots. The primary focus is on orthogonal pathways, characterized by a path-like dual graph of vertical decomposition. It is demonstrated that determining the minimum number of orthogonal robots for pathways can be achieved in linear time. However, it is essential to note that the general problem of finding the minimum number of robots for simple polygons with general visibility, even in the orthogonal case, is known to be NP-hard. Emphasis is placed on the flexibility of placing robots anywhere within the polygon, whether on the boundary or in the interior.
</details>
<details>
<summary>摘要</summary>
保护路径在多个领域，如城市规划、交通、监视和安全方面，具有极高的重要性。本文介绍了一种创新的路径保护方法，利用正交机器人。研究特点在于有效地使用最少的正交机器人来保护正交区域。研究主要关注正交路径，即笛卡尔分解中的路径 dual graph。实验表明，可以在线性时间内确定最少正交机器人数量。然而，需要注意的是，对于简单多边形的通用可见情况，即使是正交情况，找到最少机器人数量的问题是NP困难的。研究强调了机器人的位置可以在多边形边界上或者在内部。
</details></li>
</ul>
<hr>
<h2 id="Minimizing-Turns-in-Watchman-Robot-Navigation-Strategies-and-Solutions"><a href="#Minimizing-Turns-in-Watchman-Robot-Navigation-Strategies-and-Solutions" class="headerlink" title="Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions"></a>Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10090">http://arxiv.org/abs/2308.10090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamid Hoorfar, Sara Moshtaghi Largani, Reza Rahimi, Alireza Bagheri</li>
<li>For: 这篇论文的目的是解决监视人员路径问题（OWRP），即在多边形环境中找到最短路径，使机器人可以在一次连续扫描整个环境。* Methods: 本研究使用了有效的线性时间算法，解决OWRP问题，假设环境是单调的。* Results: 研究发现，这种算法可以减少机器人转弯的数量，从而提高机器人在观察和监视方面的效率，并且可以应用于各种实际应用中。<details>
<summary>Abstract</summary>
The Orthogonal Watchman Route Problem (OWRP) entails the search for the shortest path, known as the watchman route, that a robot must follow within a polygonal environment. The primary objective is to ensure that every point in the environment remains visible from at least one point on the route, allowing the robot to survey the entire area in a single, continuous sweep. This research places particular emphasis on reducing the number of turns in the route, as it is crucial for optimizing navigation in watchman routes within the field of robotics. The cost associated with changing direction is of significant importance, especially for specific types of robots. This paper introduces an efficient linear-time algorithm for solving the OWRP under the assumption that the environment is monotone. The findings of this study contribute to the progress of robotic systems by enabling the design of more streamlined patrol robots. These robots are capable of efficiently navigating complex environments while minimizing the number of turns. This advancement enhances their coverage and surveillance capabilities, making them highly effective in various real-world applications.
</details>
<details>
<summary>摘要</summary>
orthogonal 看守路径问题 (OWRP) 是关于找到最短路径，也称为看守路径，Robot在多边形环境中移动的问题。主要目标是确保环境中每个点都可以在一个点上看到，使Robot在一次连续扫描中涵盖整个区域。这种研究强调减少路径转弯数量，因为这对于某些类型的Robot来说非常重要。这篇论文介绍了一种高效的直线时间算法，用于解决 OWRP，假设环境是均匀的。这些发现对于 robotic 系统的进步做出了贡献，可以设计更加流畅的执勤Robot，这些Robot可以在复杂环境中高效巡捕，最小化转弯数量，提高覆盖和监测能力，使其在实际应用中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views"><a href="#Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views" class="headerlink" title="Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views"></a>Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10077">http://arxiv.org/abs/2308.10077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asif Khan, Amos Storkey</li>
<li>for: 学习不同类型图的节点水平表示，用于识别骗子和蛋白质功能预测等应用。</li>
<li>methods: 提出了一种基于多视图对比学习的新方法，该方法通过在图上执行扩散缓动来捕捉高级别图 структуры，从而提高节点表示的准确性。</li>
<li>results: 在synthetic和实际结构数据上比较baseline，该方法的表现较佳，胜过best baseline by 16.06% on Cornell, 3.27% on Texas, and 8.04% on Wisconsin。此外，它在邻近任务上也表现出优异，这表明它有效地捕捉了结构信息，并且可以提高下游应用的性能。<details>
<summary>Abstract</summary>
Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\%$ on Cornell, $3.27\%$ on Texas, and $8.04\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications.
</details>
<details>
<summary>摘要</summary>
学习不同类型图的节点级别表示是关键的，包括诈器检测和蛋白质功能预测。在这些图中，节点具有同类结构，可以通过节点之间的连接相似性来隐式地编码在图中。对比方法是选择学习节点在图中的表示方法，但现有的对比方法很难捕捉更高级别的图结构。为解决这些限制，我们提出了一种新的多视图对比学习方法，该方法在图中integration多个视图作为增强。通过这种方法，我们可以捕捉到不同类型图中节点之间的结构相似性，从而找到隐藏的关系和相似性，不同于传统节点表示。我们的方法在 sintetic和实际结构数据上比基eline表现出色，胜过最佳基eline的$16.06\%$在 Cornell，$3.27\%$在 Texas，和$8.04\%$在 Wisconsin。此外，我们的方法在邻近任务上持续表现出色，证明它的有效性在揭示结构信息和提高下游应用中。
</details></li>
</ul>
<hr>
<h2 id="ILCAS-Imitation-Learning-Based-Configuration-Adaptive-Streaming-for-Live-Video-Analytics-with-Cross-Camera-Collaboration"><a href="#ILCAS-Imitation-Learning-Based-Configuration-Adaptive-Streaming-for-Live-Video-Analytics-with-Cross-Camera-Collaboration" class="headerlink" title="ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration"></a>ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10068">http://arxiv.org/abs/2308.10068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duo Wu, Dayou Zhang, Miao Zhang, Ruoyu Zhang, Fangxin Wang, Shuguang Cui</li>
<li>for: 这个论文目的是为了提出一个基于模仿学习的配置适应式视频分析系统（ILCAS），以减少对网络带宽的需求和处理时间，并且能够适应不同的视频内容变化。</li>
<li>methods: ILCAS使用了视频动态特征地图和镜头间协力机制，以捕捉视频内容变化并选择适当的配置。它还使用了专家示范的对策来训练代理人，通过动态计划来解决配置适应问题。</li>
<li>results: 实验结果显示，ILCAS比之前的方案有2-20.9%的增加精度和19.9-85.3%的减少块上传延迟。<details>
<summary>Abstract</summary>
The high-accuracy and resource-intensive deep neural networks (DNNs) have been widely adopted by live video analytics (VA), where camera videos are streamed over the network to resource-rich edge/cloud servers for DNN inference. Common video encoding configurations (e.g., resolution and frame rate) have been identified with significant impacts on striking the balance between bandwidth consumption and inference accuracy and therefore their adaption scheme has been a focus of optimization. However, previous profiling-based solutions suffer from high profiling cost, while existing deep reinforcement learning (DRL) based solutions may achieve poor performance due to the usage of fixed reward function for training the agent, which fails to craft the application goals in various scenarios. In this paper, we propose ILCAS, the first imitation learning (IL) based configuration-adaptive VA streaming system. Unlike DRL-based solutions, ILCAS trains the agent with demonstrations collected from the expert which is designed as an offline optimal policy that solves the configuration adaption problem through dynamic programming. To tackle the challenge of video content dynamics, ILCAS derives motion feature maps based on motion vectors which allow ILCAS to visually ``perceive'' video content changes. Moreover, ILCAS incorporates a cross-camera collaboration scheme to exploit the spatio-temporal correlations of cameras for more proper configuration selection. Extensive experiments confirm the superiority of ILCAS compared with state-of-the-art solutions, with 2-20.9% improvement of mean accuracy and 19.9-85.3% reduction of chunk upload lag.
</details>
<details>
<summary>摘要</summary>
高精度和资源占用深度神经网络（DNN）在实时视频分析（VA）中广泛应用，其中摄像头视频流经网络传输至 Edge/云服务器进行DNN推理。常见的视频编码配置（例如分辨率和帧率）有显著影响于占用带宽和推理精度的平衡，因此其适应方案成为优化的焦点。然而，先前的 Profiling-based 解决方案具有高 Profiling 成本，而现有的深度强化学习（DRL）基于解决方案可能因为使用固定的奖励函数进行训练代理人，导致在不同enario中拟合应用目标的问题。在本文中，我们提出了 ILCAS，第一个仿学学习（IL）基于配置适应VA流动系统。与 DRL-based 解决方案不同，ILCAS 通过收集专家设计的示例来训练代理人，通过动态计划解决配置适应问题。为了解决视频内容变化的挑战，ILCAS  derivates 基于运动 вектор的动作特征图， Allow ILCAS 在视觉上“感受”视频内容变化。此外，ILCAS 还实现了相机间协作机制，以便更好地选择适配。经验证明，ILCAS 相比现有的解决方案具有2-20.9%的提升精度和19.9-85.3%的减少块上传延迟。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.LG_2023_08_20/" data-id="clly3604h006rdd887x7o2rcr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/21/eess.IV_2023_08_21/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-21 17:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/20/cs.SD_2023_08_20/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-20 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">104</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
