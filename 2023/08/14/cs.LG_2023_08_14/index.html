
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-14 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Distance Matters For Improving Performance Estimation Under Covariate Shift paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.07223 repo_url: https:&#x2F;&#x2F;github.com&#x2F;melanibe&#x2F;distance_matters_performance_estimation pap">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-14 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/14/cs.LG_2023_08_14/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Distance Matters For Improving Performance Estimation Under Covariate Shift paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.07223 repo_url: https:&#x2F;&#x2F;github.com&#x2F;melanibe&#x2F;distance_matters_performance_estimation pap">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-13T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:30.319Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/14/cs.LG_2023_08_14/" class="article-date">
  <time datetime="2023-08-13T16:00:00.000Z" itemprop="datePublished">2023-08-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-14 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distance-Matters-For-Improving-Performance-Estimation-Under-Covariate-Shift"><a href="#Distance-Matters-For-Improving-Performance-Estimation-Under-Covariate-Shift" class="headerlink" title="Distance Matters For Improving Performance Estimation Under Covariate Shift"></a>Distance Matters For Improving Performance Estimation Under Covariate Shift</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07223">http://arxiv.org/abs/2308.07223</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/melanibe/distance_matters_performance_estimation">https://github.com/melanibe/distance_matters_performance_estimation</a></li>
<li>paper_authors: Mélanie Roschewitz, Ben Glocker</li>
<li>for: 本研究旨在提高 covariate shift 下的性能估算，尤其是在敏感应用场景下。</li>
<li>methods: 该研究提出了一种基于 distance 的方法，通过检查测试样本与预期的训练分布之间的距离，以避免基于不可靠的模型输出来估算性能。</li>
<li>results: 研究在 13 个图像分类任务上进行了实验，并在各种自然和 sintetic 分布shift 下达到了 median 相对 MAE 改进率为 27%，并在 10 个任务中达到了最佳基eline。<details>
<summary>Abstract</summary>
Performance estimation under covariate shift is a crucial component of safe AI model deployment, especially for sensitive use-cases. Recently, several solutions were proposed to tackle this problem, most leveraging model predictions or softmax confidence to derive accuracy estimates. However, under dataset shifts, confidence scores may become ill-calibrated if samples are too far from the training distribution. In this work, we show that taking into account distances of test samples to their expected training distribution can significantly improve performance estimation under covariate shift. Precisely, we introduce a "distance-check" to flag samples that lie too far from the expected distribution, to avoid relying on their untrustworthy model outputs in the accuracy estimation step. We demonstrate the effectiveness of this method on 13 image classification tasks, across a wide-range of natural and synthetic distribution shifts and hundreds of models, with a median relative MAE improvement of 27% over the best baseline across all tasks, and SOTA performance on 10 out of 13 tasks. Our code is publicly available at https://github.com/melanibe/distance_matters_performance_estimation.
</details>
<details>
<summary>摘要</summary>
性能估计下 covariate shift 是安全 AI 模型部署中的一个关键组件，尤其是在敏感应用场景下。最近，一些解决方案被提出来解决这个问题，大多数都是基于模型预测或软max信任来 derive 准确性估计。然而，在数据集 shift 下，信任度分数可能会变得不准确，如果样本太far away from the training distribution。在这种情况下，我们表明可以通过考虑测试样本与预期的训练分布之间的距离来进行性能估计。我们引入了一种"距离检查"来检测测试样本是否位于预期的训练分布中，以避免基于不可靠的模型输出来进行准确性估计。我们在 13 个图像分类任务上进行了实验，包括自然和合成分布 shift，以及多达百个模型， median 相对误差改进率为 27%，并在所有任务上达到最佳基eline的表现。我们的代码可以在 <https://github.com/melanibe/distance_matters_performance_estimation> 上获取。
</details></li>
</ul>
<hr>
<h2 id="AudioFormer-Audio-Transformer-learns-audio-feature-representations-from-discrete-acoustic-codes"><a href="#AudioFormer-Audio-Transformer-learns-audio-feature-representations-from-discrete-acoustic-codes" class="headerlink" title="AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes"></a>AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07221">http://arxiv.org/abs/2308.07221</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LZH-0225/AudioFormer">https://github.com/LZH-0225/AudioFormer</a></li>
<li>paper_authors: Zhaohui Li, Haitao Wang, Xinghua Jiang</li>
<li>for: 这篇论文是为了学习音频特征表示，通过自然语言理解（NLU）的新角度，并使用神经网络音码器模型生成抽象的音频代码，然后使用这些代码训练马斯克隐藏语言模型（MLM）来获得高质量的音频表示。</li>
<li>methods: 这篇论文使用了一种新的多 positivesample Contrastive（MPC）学习方法，它可以学习多个抽象的音频代码之间的共同表示，从而提高音频表示质量。具体来说，首先使用一个神经网络音码器模型生成抽象的音频代码，然后使用这些代码训练一个马斯克隐藏语言模型（MLM），最后使用MPC学习方法来学习多个抽象的音频代码之间的共同表示。</li>
<li>results: 根据实验结果，AudioFormer在多个数据集上达到了显著提高的性能，甚至超过了一些音视频多模态分类模型。具体来说，AudioFormer在AudioSet（2M,20K）、FSD50K等数据集上的性能分别为53.9、45.1和65.6。<details>
<summary>Abstract</summary>
We propose a method named AudioFormer,which learns audio feature representations through the acquisition of discrete acoustic codes and subsequently fine-tunes them for audio classification tasks. Initially,we introduce a novel perspective by considering the audio classification task as a form of natural language understanding (NLU). Leveraging an existing neural audio codec model,we generate discrete acoustic codes and utilize them to train a masked language model (MLM),thereby obtaining audio feature representations. Furthermore,we pioneer the integration of a Multi-Positive sample Contrastive (MPC) learning approach. This method enables the learning of joint representations among multiple discrete acoustic codes within the same audio input. In our experiments,we treat discrete acoustic codes as textual data and train a masked language model using a cloze-like methodology,ultimately deriving high-quality audio representations. Notably,the MPC learning technique effectively captures collaborative representations among distinct positive samples. Our research outcomes demonstrate that AudioFormer attains significantly improved performance compared to prevailing monomodal audio classification models across multiple datasets,and even outperforms audio-visual multimodal classification models on select datasets. Specifically,our approach achieves remarkable results on datasets including AudioSet (2M,20K),and FSD50K,with performance scores of 53.9,45.1,and 65.6,respectively. We have openly shared both the code and models: https://github.com/LZH-0225/AudioFormer.git.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法 named AudioFormer，它通过获取逻辑音频编码并进一步练习其为音频分类任务进行学习。我们首先提出了一种新的视角，即视音频分类任务为自然语言理解（NLU）的一种形式。利用现有的神经网络音频编码器模型，我们生成了逻辑音频编码，并使用其训练一个封面语言模型（MLM），从而获得了高质量的音频特征表示。此外，我们还开拓了多个正样本对比（MPC）学习方法的应用。这种方法可以在同一个音频输入中学习多个独立的逻辑音频编码之间的共同表示。在我们的实验中，我们将逻辑音频编码视为文本数据，并使用cloze-like方法训练一个封面语言模型，最终获得了高质量的音频表示。尤其是，MPC学习技术可以有效捕捉多个正样本之间的协作表示。我们的研究结果显示，AudioFormer在多个数据集上达到了 significatively提高的性能，甚至超过了多模态音视频分类模型在一些数据集上。具体来说，我们的方法在AudioSet（2M,20K）、FSD50K等数据集上获得了53.9、45.1和65.6的性能分数。我们已经在 GitHub 上公开了代码和模型：https://github.com/LZH-0225/AudioFormer.git。
</details></li>
</ul>
<hr>
<h2 id="Generating-Individual-Trajectories-Using-GPT-2-Trained-from-Scratch-on-Encoded-Spatiotemporal-Data"><a href="#Generating-Individual-Trajectories-Using-GPT-2-Trained-from-Scratch-on-Encoded-Spatiotemporal-Data" class="headerlink" title="Generating Individual Trajectories Using GPT-2 Trained from Scratch on Encoded Spatiotemporal Data"></a>Generating Individual Trajectories Using GPT-2 Trained from Scratch on Encoded Spatiotemporal Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07940">http://arxiv.org/abs/2308.07940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taizo Horikomi, Shouji Fujimoto, Atushi Ishikawa, Takayuki Mizuno</li>
<li>for: 本研究用于构建一个基于GPT-2语言模型的深度学习模型，用于生成受环境因素和个人特征 influencing的日常行走路径。</li>
<li>methods: 研究使用了地理坐标转换为特定的位置符号，并将每天的行走路径表示为一个序列符号。通过训练GPT-2架构，实现了从零开始训练一个深度学习模型，用于生成受环境因素和个人特征 influencing的日常行走路径。</li>
<li>results: 研究得出了一个基于GPT-2语言模型的深度学习模型，可以生成受环境因素和个人特征 influencing的日常行走路径。这种模型可以帮助我们更好地理解人们的日常活动行为，并且可以用于评估不同环境和个人特征对行走路径的影响。<details>
<summary>Abstract</summary>
Following Mizuno, Fujimoto, and Ishikawa's research (Front. Phys. 2022), we transpose geographical coordinates expressed in latitude and longitude into distinctive location tokens that embody positions across varied spatial scales. We encapsulate an individual daily trajectory as a sequence of tokens by adding unique time interval tokens to the location tokens. Using the architecture of an autoregressive language model, GPT-2, this sequence of tokens is trained from scratch, allowing us to construct a deep learning model that sequentially generates an individual daily trajectory. Environmental factors such as meteorological conditions and individual attributes such as gender and age are symbolized by unique special tokens, and by training these tokens and trajectories on the GPT-2 architecture, we can generate trajectories that are influenced by both environmental factors and individual attributes.
</details>
<details>
<summary>摘要</summary>
据米榊、藤本、石川等人的研究（Front. Phys. 2022），我们将地理坐标表示为纬度和经度转化为不同的空间尺度下的特征位置符号。我们将每个日常路径作为一个序列符号，通过将唯一的时间间隔符号添加到位置符号中来嵌入它。使用GPT-2架构的自然语言模型，我们从零开始训练这个序列符号，以构建一个可以逐步生成个人日常路径的深度学习模型。environmental factor such as weather conditions和个人属性such as gender and age通过特殊符号表示，我们通过在GPT-2架构上训练这些符号和路径，可以生成受环境因素和个人属性 influencing的 trajectory。
</details></li>
</ul>
<hr>
<h2 id="Automated-Ensemble-Based-Segmentation-of-Pediatric-Brain-Tumors-A-Novel-Approach-Using-the-CBTN-CONNECT-ASNR-MICCAI-BraTS-PEDs-2023-Challenge-Data"><a href="#Automated-Ensemble-Based-Segmentation-of-Pediatric-Brain-Tumors-A-Novel-Approach-Using-the-CBTN-CONNECT-ASNR-MICCAI-BraTS-PEDs-2023-Challenge-Data" class="headerlink" title="Automated Ensemble-Based Segmentation of Pediatric Brain Tumors: A Novel Approach Using the CBTN-CONNECT-ASNR-MICCAI BraTS-PEDs 2023 Challenge Data"></a>Automated Ensemble-Based Segmentation of Pediatric Brain Tumors: A Novel Approach Using the CBTN-CONNECT-ASNR-MICCAI BraTS-PEDs 2023 Challenge Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07212">http://arxiv.org/abs/2308.07212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashidhar Reddy Javaji, Sovesh Mohapatra, Advait Gosai, Gottfried Schlaug</li>
<li>for: 这个研究的目的是为了发展用于脑膜癌的诊断技术和治疗方法。</li>
<li>methods: 这个研究使用了深度学习技术，使用了Magnetic Resonance Imaging（MRI）模式，并导入了一种新的组合方法，包括ONet和修改过的UNet，以及新的损失函数。</li>
<li>results: 这个研究获得了2023年BraTS-PEDs挑战赛的精确分类模型。使用扩展资料，包括单独和composite变数，以确保模型的稳定性和准确性。组合策略，结合ONet和UNet模型，展现了更高的效率和精确性。 lesion_wise dice scores为0.52、0.72和0.78，证明了这种组合方法的优势。<details>
<summary>Abstract</summary>
Brain tumors remain a critical global health challenge, necessitating advancements in diagnostic techniques and treatment methodologies. In response to the growing need for age-specific segmentation models, particularly for pediatric patients, this study explores the deployment of deep learning techniques using magnetic resonance imaging (MRI) modalities. By introducing a novel ensemble approach using ONet and modified versions of UNet, coupled with innovative loss functions, this study achieves a precise segmentation model for the BraTS-PEDs 2023 Challenge. Data augmentation, including both single and composite transformations, ensures model robustness and accuracy across different scanning protocols. The ensemble strategy, integrating the ONet and UNet models, shows greater effectiveness in capturing specific features and modeling diverse aspects of the MRI images which result in lesion_wise dice scores of 0.52, 0.72 and 0.78 for enhancing tumor, tumor core and whole tumor labels respectively. Visual comparisons further confirm the superiority of the ensemble method in accurate tumor region coverage. The results indicate that this advanced ensemble approach, building upon the unique strengths of individual models, offers promising prospects for enhanced diagnostic accuracy and effective treatment planning for brain tumors in pediatric brains.
</details>
<details>
<summary>摘要</summary>
脑肿仍然是全球医疗挑战，需要进一步的技术创新和治疗方法。为了应对儿童患者的年龄特定分 segmentation模型的增长需求，本研究利用深度学习技术和Magnetic Resonance Imaging（MRI）模式，探讨一种新的集成方法。通过引入ONet和修改版本的UNet模型，以及创新的损失函数，本研究实现了高精度的分割模型，为BraTS-PEDs 2023 Challenge提供了精准的分割结果。数据扩展，包括单个和复合变换，使模型具有不同扫描协议下的Robustness和准确性。集成策略，将ONet和UNet模型集成在一起，表现出更高的特征捕捉和多样化图像模型化能力，最终得到了lesion_wise dice分割率为0.52、0.72和0.78，用于涉及肿块、肿块核心和整个肿块等标签。视觉比较还证明了集成方法在精准肿块覆盖方面的优势。结果表明，这种高级集成方法，基于各个模型的特点优势，对儿童脑肿的诊断精度和有效的治疗规划具有替代性。
</details></li>
</ul>
<hr>
<h2 id="Unified-Data-Free-Compression-Pruning-and-Quantization-without-Fine-Tuning"><a href="#Unified-Data-Free-Compression-Pruning-and-Quantization-without-Fine-Tuning" class="headerlink" title="Unified Data-Free Compression: Pruning and Quantization without Fine-Tuning"></a>Unified Data-Free Compression: Pruning and Quantization without Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07209">http://arxiv.org/abs/2308.07209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shipeng Bai, Jun Chen, Xintian Shen, Yixuan Qian, Yong Liu</li>
<li>for: 降低神经网络的执行时间和内存占用</li>
<li>methods: 同时施行减少和量化，不需要原始训练数据集</li>
<li>results: 在大规模图像分类任务上实现了显著的改善，比如在ImageNet dataset上与 State-of-the-Art 方法相比，使用30% 减少率和6位量化，ResNet-34 网络上获得20.54%的准确率提升。<details>
<summary>Abstract</summary>
Structured pruning and quantization are promising approaches for reducing the inference time and memory footprint of neural networks. However, most existing methods require the original training dataset to fine-tune the model. This not only brings heavy resource consumption but also is not possible for applications with sensitive or proprietary data due to privacy and security concerns. Therefore, a few data-free methods are proposed to address this problem, but they perform data-free pruning and quantization separately, which does not explore the complementarity of pruning and quantization. In this paper, we propose a novel framework named Unified Data-Free Compression(UDFC), which performs pruning and quantization simultaneously without any data and fine-tuning process. Specifically, UDFC starts with the assumption that the partial information of a damaged(e.g., pruned or quantized) channel can be preserved by a linear combination of other channels, and then derives the reconstruction form from the assumption to restore the information loss due to compression. Finally, we formulate the reconstruction error between the original network and its compressed network, and theoretically deduce the closed-form solution. We evaluate the UDFC on the large-scale image classification task and obtain significant improvements over various network architectures and compression methods. For example, we achieve a 20.54% accuracy improvement on ImageNet dataset compared to SOTA method with 30% pruning ratio and 6-bit quantization on ResNet-34.
</details>
<details>
<summary>摘要</summary>
《结构化截割和量化是神经网络减少推理时间和内存占用的有力方法。然而，大多数现有方法需要原始训练数据来细化模型，这不仅带来了重量级的资源占用，而且对于敏感或商业机密数据来说，由于隐私和安全问题，无法进行训练。因此，一些无数据方法被提出，但它们只是分别进行无数据截割和量化，没有利用截割和量化的衔接。在本文中，我们提出了一种名为统一无数据压缩（UDFC）的新框架，它在无数据情况下同时进行截割和量化。具体来说，UDFC从假设损坏（例如截割或量化）通道的部分信息可以通过其他通道的线性组合来保留，然后从假设中 derive 重建形式来恢复因压缩而产生的信息损失。最后，我们将重建错误 между 原始网络和压缩后的网络，并理论上解出closed-form解决方案。我们对大规模图像分类任务进行评估，并在不同的网络架构和压缩方法下获得了显著的改进。例如，我们在ImageNet数据集上达到了30%截割率和6位量化的SOTA方法比20.54%的精度提升。》
</details></li>
</ul>
<hr>
<h2 id="Algorithms-for-the-Training-of-Neural-Support-Vector-Machines"><a href="#Algorithms-for-the-Training-of-Neural-Support-Vector-Machines" class="headerlink" title="Algorithms for the Training of Neural Support Vector Machines"></a>Algorithms for the Training of Neural Support Vector Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07204">http://arxiv.org/abs/2308.07204</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sayantann11/all-classification-templetes-for-ML">https://github.com/sayantann11/all-classification-templetes-for-ML</a></li>
<li>paper_authors: Lars Simon, Manuel Radons</li>
<li>for: 本研究使用神经支持向量机（NSVM）结构，以汲取领域知识在模型设计中。</li>
<li>methods: 本文提出了一组基于 Pegasos 算法的 NSVM 训练算法，并通过解决一系列标准机器学习任务来证明其效果。</li>
<li>results: 本研究通过实验和分析，证明了 NSVM 在一些标准机器学习任务中的表现，并验证了领域知识的Integration在模型设计中的重要性。<details>
<summary>Abstract</summary>
Neural support vector machines (NSVMs) allow for the incorporation of domain knowledge in the design of the model architecture. In this article we introduce a set of training algorithms for NSVMs that leverage the Pegasos algorithm and provide a proof of concept by solving a set of standard machine learning tasks.
</details>
<details>
<summary>摘要</summary>
神经支持向量机器 (NSVM) 允许在模型建立的架构中包含领域知识。在这篇文章中，我们介绍了一组用 Pegasos 算法进行训练的 NSVM 训练算法，并通过解决一组标准机器学习任务来提供证明。Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Neural-Categorical-Priors-for-Physics-Based-Character-Control"><a href="#Neural-Categorical-Priors-for-Physics-Based-Character-Control" class="headerlink" title="Neural Categorical Priors for Physics-Based Character Control"></a>Neural Categorical Priors for Physics-Based Character Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07200">http://arxiv.org/abs/2308.07200</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Tencent-RoboticsX/NCP">https://github.com/Tencent-RoboticsX/NCP</a></li>
<li>paper_authors: Qingxu Zhu, He Zhang, Mengting Lan, Lei Han</li>
<li>for: 这paper aimed to propose a new learning framework for controlling physics-based characters with naturalistic behaviors.</li>
<li>methods: The proposed method uses reinforcement learning (RL) to initially track and imitate life-like movements from unstructured motion clips, and then uses a discrete information bottleneck and prior shifting to generate high-quality life-like behaviors.</li>
<li>results: The proposed framework is capable of controlling the character to perform considerably high-quality movements in terms of behavioral strategies, diversity, and realism, as demonstrated through comprehensive experiments using humanoid characters on two challenging downstream tasks.Here’s the Chinese version of the three key points:</li>
<li>for: 这paper的目标是提出一种新的学习框架，用于控制基于物理的角色表现出自然的行为。</li>
<li>methods: 提议的方法使用了反馈学习（RL）来跟踪和模仿生活中的自然运动，然后使用一种简化信息瓶颈和征识偏移来生成高质量的自然行为。</li>
<li>results: 提议的框架可以控制角色表现出较高质量的行为策略、多样性和真实性，这得到通过对人工智能角色进行了两个复杂的下游任务的实验证明。<details>
<summary>Abstract</summary>
Recent advances in learning reusable motion priors have demonstrated their effectiveness in generating naturalistic behaviors. In this paper, we propose a new learning framework in this paradigm for controlling physics-based characters with significantly improved motion quality and diversity over existing state-of-the-art methods. The proposed method uses reinforcement learning (RL) to initially track and imitate life-like movements from unstructured motion clips using the discrete information bottleneck, as adopted in the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure compresses the most relevant information from the motion clips into a compact yet informative latent space, i.e., a discrete space over vector quantized codes. By sampling codes in the space from a trained categorical prior distribution, high-quality life-like behaviors can be generated, similar to the usage of VQ-VAE in computer vision. Although this prior distribution can be trained with the supervision of the encoder's output, it follows the original motion clip distribution in the dataset and could lead to imbalanced behaviors in our setting. To address the issue, we further propose a technique named prior shifting to adjust the prior distribution using curiosity-driven RL. The outcome distribution is demonstrated to offer sufficient behavioral diversity and significantly facilitates upper-level policy learning for downstream tasks. We conduct comprehensive experiments using humanoid characters on two challenging downstream tasks, sword-shield striking and two-player boxing game. Our results demonstrate that the proposed framework is capable of controlling the character to perform considerably high-quality movements in terms of behavioral strategies, diversity, and realism. Videos, codes, and data are available at https://tencent-roboticsx.github.io/NCP/.
</details>
<details>
<summary>摘要</summary>
最近的研究发展强化 reuse motion prior 技术已经证明其能够生成自然的行为。在这篇论文中，我们提出一种新的学习框架，用于控制基于物理的人物，并且能够提高 Motion 质量和多样性，至今为止的现有方法。我们使用 reinforcement learning（RL）来初始化和模仿生命like 运动从未结构化运动clip 中提取有用信息，并使用 discrete information bottleneck，与 Vector Quantized Variational AutoEncoder（VQ-VAE）相同。这种结构压缩运动clip 中最重要的信息，并将其压缩成一个紧凑的、有用的幂论空间中。通过在训练过的 categorical prior distribution 中采样代码，可以生成高质量的生命like 行为。尽管这个 prior distribution 可以通过encoder的输出进行训练，但它遵循原始运动clip 的分布，这可能会导致行为偏斜。为了解决这个问题，我们提出了一种名为 prior shifting 的技术，通过 Curiosity-driven RL 来调整 prior distribution。结果显示，我们的方法可以提供足够的行为多样性，并且能够帮助上层策略学习以下渠道任务。我们在人iform 角色上进行了全面的实验，并使用剑盾战斗和两个玩家简易拳击游戏。我们的结果表明，我们的框架能够控制人iform 角色进行较高质量的运动，包括行为策略、多样性和真实性。视频、代码和数据可以在https://tencent-roboticsx.github.io/NCP/ 获取。
</details></li>
</ul>
<hr>
<h2 id="Explaining-Black-Box-Models-through-Counterfactuals"><a href="#Explaining-Black-Box-Models-through-Counterfactuals" class="headerlink" title="Explaining Black-Box Models through Counterfactuals"></a>Explaining Black-Box Models through Counterfactuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07198">http://arxiv.org/abs/2308.07198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juliatrustworthyai/counterfactualexplanations.jl">https://github.com/juliatrustworthyai/counterfactualexplanations.jl</a></li>
<li>paper_authors: Patrick Altmeyer, Arie van Deursen, Cynthia C. S. Liem</li>
<li>for: 用于解释人工智能模型的输出</li>
<li>methods: 使用Counterfactual Explanations（CE）和Algorithmic Recourse（AR）生成解释和修复方法</li>
<li>results: 可以提供实用和现实的修复方法，帮助改善模型的输出结果<details>
<summary>Abstract</summary>
We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.
</details>
<details>
<summary>摘要</summary>
我们介绍CounterfactualExplanations.jl：一个用于生成反对方案解释（CE）和算法补救（AR）的 julia 套件。CE 解释了模型对于特定预测所需的输入更改，这些解释可以提供AR：一组可行和有效的改善结果的建议。在这篇文章中，我们讨论了CE 在可解释人工智能中的用途，并详细介绍套件的功能。套件易于使用，设计为可自定义和扩展。我们将它作为 julia 中解释任何预测模型的首选之地。
</details></li>
</ul>
<hr>
<h2 id="gSASRec-Reducing-Overconfidence-in-Sequential-Recommendation-Trained-with-Negative-Sampling"><a href="#gSASRec-Reducing-Overconfidence-in-Sequential-Recommendation-Trained-with-Negative-Sampling" class="headerlink" title="gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling"></a>gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07192">http://arxiv.org/abs/2308.07192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asash/gsasrec">https://github.com/asash/gsasrec</a></li>
<li>paper_authors: Aleksandr Petrov, Craig Macdonald</li>
<li>for: This paper aims to address the issue of overconfidence in recommendation models, specifically in the popular SASRec model, and to propose a novel loss function and improved model that can mitigate overconfidence and improve performance.</li>
<li>methods: The paper proposes a novel Generalised Binary Cross-Entropy Loss function (gBCE) and a modified version of SASRec called gSASRec, which deploys an increased number of negatives and the gBCE loss to mitigate overconfidence.</li>
<li>results: The paper shows through detailed experiments on three datasets that gSASRec does not exhibit the overconfidence problem, and can outperform BERT4Rec in terms of NDCG score (e.g. +9.47% on the MovieLens-1M dataset) while requiring less training time (e.g. -73% training time on MovieLens-1M). Additionally, gSASRec is suitable for large datasets with more than 1 million items, unlike BERT4Rec.<details>
<summary>Abstract</summary>
A large catalogue size is one of the central challenges in training recommendation models: a large number of items makes them memory and computationally inefficient to compute scores for all items during training, forcing these models to deploy negative sampling. However, negative sampling increases the proportion of positive interactions in the training data, and therefore models trained with negative sampling tend to overestimate the probabilities of positive interactions a phenomenon we call overconfidence. While the absolute values of the predicted scores or probabilities are not important for the ranking of retrieved recommendations, overconfident models may fail to estimate nuanced differences in the top-ranked items, resulting in degraded performance. In this paper, we show that overconfidence explains why the popular SASRec model underperforms when compared to BERT4Rec. This is contrary to the BERT4Rec authors explanation that the difference in performance is due to the bi-directional attention mechanism. To mitigate overconfidence, we propose a novel Generalised Binary Cross-Entropy Loss function (gBCE) and theoretically prove that it can mitigate overconfidence. We further propose the gSASRec model, an improvement over SASRec that deploys an increased number of negatives and the gBCE loss. We show through detailed experiments on three datasets that gSASRec does not exhibit the overconfidence problem. As a result, gSASRec can outperform BERT4Rec (e.g. +9.47% NDCG on the MovieLens-1M dataset), while requiring less training time (e.g. -73% training time on MovieLens-1M). Moreover, in contrast to BERT4Rec, gSASRec is suitable for large datasets that contain more than 1 million items.
</details>
<details>
<summary>摘要</summary>
庞大的目录大小是训练推荐模型的中心挑战之一：大量的项目使得计算分数的计算成本高昂，使得这些模型不能在训练过程中计算所有项目的分数，因此需要使用负样本。然而，使用负样本增加了正交互动的比例在训练数据中，因此模型受负样本训练后会过度估计正交互动，这种现象我们称为过自信。这会导致模型估计排名顺序中的差异不准确，从而导致性能下降。在这篇论文中，我们表明了SASRec模型在比较BERT4Rec时的下降性能是由于过自信而不是BI-directional attention机制的解释。为了 Mitigate overconfidence，我们提出了一种通用二进制十字积分损失函数（gBCE），并证明了它可以 Mitigate overconfidence。此外，我们还提出了一种改进SASRec模型的gSASRec模型，该模型通过增加负样本数和gBCE损失函数来减少过自信。我们通过对三个数据集进行详细的实验，证明了gSASRec模型不受过自信问题。因此，gSASRec可以在MovieLens-1M数据集上超过BERT4Rec（+9.47% NDCG），同时具有较少的训练时间(-73% 训练时间）。此外，gSASRec模型适用于大于100万个项目的大数据集。
</details></li>
</ul>
<hr>
<h2 id="Improving-ICD-based-semantic-similarity-by-accounting-for-varying-degrees-of-comorbidity"><a href="#Improving-ICD-based-semantic-similarity-by-accounting-for-varying-degrees-of-comorbidity" class="headerlink" title="Improving ICD-based semantic similarity by accounting for varying degrees of comorbidity"></a>Improving ICD-based semantic similarity by accounting for varying degrees of comorbidity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07359">http://arxiv.org/abs/2308.07359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Janosch Schneider, Marius Adler, Christoph Ammer-Herrmenau, Alexander Otto König, Ulrich Sax, Jonas Hügel</li>
<li>for: 这篇论文的目的是为了找到类似的病人，以便评估治疗结果和临床决策支持。</li>
<li>methods: 这篇论文使用了世界各地医疗病理分类（ICD）代码，将病人的病理特征转换为数据集，然后使用Semantic Similarity算法进行相似性计算。</li>
<li>results: 这篇论文的结果显示，使用了我们提出的标准化运算符 Lateral Epicritical Density 和 Bipartite Graph Matching 的 комbination，可以实现最高的相似性分析效果，与专家评价的真实相似性相符。<details>
<summary>Abstract</summary>
Finding similar patients is a common objective in precision medicine, facilitating treatment outcome assessment and clinical decision support. Choosing widely-available patient features and appropriate mathematical methods for similarity calculations is crucial. International Statistical Classification of Diseases and Related Health Problems (ICD) codes are used worldwide to encode diseases and are available for nearly all patients. Aggregated as sets consisting of primary and secondary diagnoses they can display a degree of comorbidity and reveal comorbidity patterns. It is possible to compute the similarity of patients based on their ICD codes by using semantic similarity algorithms. These algorithms have been traditionally evaluated using a single-term expert rated data set.   However, real-word patient data often display varying degrees of documented comorbidities that might impair algorithm performance. To account for this, we present a scale term that considers documented comorbidity-variance. In this work, we compared the performance of 80 combinations of established algorithms in terms of semantic similarity based on ICD-code sets. The sets have been extracted from patients with a C25.X (pancreatic cancer) primary diagnosis and provide a variety of different combinations of ICD-codes. Using our scale term we yielded the best results with a combination of level-based information content, Leacock & Chodorow concept similarity and bipartite graph matching for the set similarities reaching a correlation of 0.75 with our expert's ground truth. Our results highlight the importance of accounting for comorbidity variance while demonstrating how well current semantic similarity algorithms perform.
</details>
<details>
<summary>摘要</summary>
在精度医学中，找到类似的患者是一项常见的目标，以便评估治疗结果和临床决策支持。选择广泛可用的患者特征和适当的数学方法进行相似计算是关键。国际疾病分类法（ICD）代码在全球使用，可以为大多数患者提供代码。将这些代码聚合成集合，包括主要和次要诊断，可以显示患者的诊断程度和诊断模式。可以使用语义相似算法计算患者之间的相似性。这些算法通常通过专家评分的数据集来评估。但在实际患者数据中，患者通常有不同程度的记录的相关疾病，这可能会影响算法性能。为解决这个问题，我们提出了一个权重因素，该因素考虑了记录的相关疾病变化。在这种情况下，我们比较了80种已知算法的语义相似性，基于ICD代码集。这些代码集来自患有C25.X（肝癌）主诊断的患者，并提供了不同的ICD代码组合。使用我们的权重因素，我们得到了最佳的结果，与专家的真实ground truth相匹配，相似度为0.75。我们的结果表明了考虑相关疾病变化的重要性，同时也展示了当前语义相似算法的性能。
</details></li>
</ul>
<hr>
<h2 id="Conformal-Predictions-Enhanced-Expert-guided-Meshing-with-Graph-Neural-Networks"><a href="#Conformal-Predictions-Enhanced-Expert-guided-Meshing-with-Graph-Neural-Networks" class="headerlink" title="Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural Networks"></a>Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07358">http://arxiv.org/abs/2308.07358</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahnobari/autosurf">https://github.com/ahnobari/autosurf</a></li>
<li>paper_authors: Amin Heyrani Nobari, Justin Rey, Suhas Kodali, Matthew Jones, Faez Ahmed</li>
<li>for: 这个论文的目的是自动生成CFD模型的网格，以提高计算流体力学的精度和效率。</li>
<li>methods: 这个论文使用图解树神经网络（GNN）和专家指导来自动生成CFD模型的网格。它还提出了一种新的3D分割算法，以及一种将预测从3D分割模型项目到CAD表面的方法。</li>
<li>results: 论文通过一个实际案例研究表明，自动生成的网格与专家生成的网格相比较，具有相似的质量，并且使得计算机程序能够正确地计算结果。此外，论文还比较了自动生成网格和适应重新分割的方法，发现自动生成网格比适应重新分割更快。代码和数据可以在<a target="_blank" rel="noopener" href="https://github.com/ahnobari/AutoSurf%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ahnobari/AutoSurf上获取。</a><details>
<summary>Abstract</summary>
Computational Fluid Dynamics (CFD) is widely used in different engineering fields, but accurate simulations are dependent upon proper meshing of the simulation domain. While highly refined meshes may ensure precision, they come with high computational costs. Similarly, adaptive remeshing techniques require multiple simulations and come at a great computational cost. This means that the meshing process is reliant upon expert knowledge and years of experience. Automating mesh generation can save significant time and effort and lead to a faster and more efficient design process. This paper presents a machine learning-based scheme that utilizes Graph Neural Networks (GNN) and expert guidance to automatically generate CFD meshes for aircraft models. In this work, we introduce a new 3D segmentation algorithm that outperforms two state-of-the-art models, PointNet++ and PointMLP, for surface classification. We also present a novel approach to project predictions from 3D mesh segmentation models to CAD surfaces using the conformal predictions method, which provides marginal statistical guarantees and robust uncertainty quantification and handling. We demonstrate that the addition of conformal predictions effectively enables the model to avoid under-refinement, hence failure, in CFD meshing even for weak and less accurate models. Finally, we demonstrate the efficacy of our approach through a real-world case study that demonstrates that our automatically generated mesh is comparable in quality to expert-generated meshes and enables the solver to converge and produce accurate results. Furthermore, we compare our approach to the alternative of adaptive remeshing in the same case study and find that our method is 5 times faster in the overall process of simulation. The code and data for this project are made publicly available at https://github.com/ahnobari/AutoSurf.
</details>
<details>
<summary>摘要</summary>
计算流体动力学（CFD）在不同的工程领域都广泛应用，但是准确的计算受到域的适当精细化的约束。高精度的精细化可能确保准确性，但是来自高计算成本。同时，适应精细化技术需要多次 simulations和高计算成本。这意味着精细化过程取决于专家知识和年代经验。自动生成精细化可以节省很多时间和努力，并且可以加速设计过程。本文提出了基于机器学习的方案，利用图像神经网络（GNN）和专家指导来自动生成飞机模型的CFD精细化。在这个工作中，我们提出了一种新的3D分割算法，其在surface classification方面比PointNet++和PointMLP两种状态态模型更高效。我们还提出了一种将预测从3D分割模型 projet到CAD surface的方法，使用确ensional predictions方法，该方法提供了边缘统计保证和稳定的不确定性评估和处理。我们发现，通过添加确ensional predictions，我们的方法可以避免精细化失败，即下REFINE。最后，我们通过一个实际的案例研究证明了我们的自动生成精细化与专家生成精细化相比质量相同，并且使得计算器能够 converges和生成准确结果。此外，我们与适应精细化的相同案例进行比较，发现我们的方法比适应精细化5倍快。我们将项目的代码和数据公开发布在https://github.com/ahnobari/AutoSurf上。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Learning-of-Quantum-States-Prepared-With-Few-Non-Clifford-Gates-II-Single-Copy-Measurements"><a href="#Efficient-Learning-of-Quantum-States-Prepared-With-Few-Non-Clifford-Gates-II-Single-Copy-Measurements" class="headerlink" title="Efficient Learning of Quantum States Prepared With Few Non-Clifford Gates II: Single-Copy Measurements"></a>Efficient Learning of Quantum States Prepared With Few Non-Clifford Gates II: Single-Copy Measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07175">http://arxiv.org/abs/2308.07175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</li>
<li>for: 学习 $n$-qubit 量子状态，输出由具有最多 $t$ 单位逻辑门的电路。</li>
<li>methods: 使用单Copy测量来学习这类状态，而不需要双Copy测量。</li>
<li>results: 可以在 $\mathsf{poly}(n,2^t,1&#x2F;\epsilon)$ 时间和样本数量内学习这类状态，与之前所有的算法相同。<details>
<summary>Abstract</summary>
Recent work has shown that $n$-qubit quantum states output by circuits with at most $t$ single-qubit non-Clifford gates can be learned to trace distance $\epsilon$ using $\mathsf{poly}(n,2^t,1/\epsilon)$ time and samples. All prior algorithms achieving this runtime use entangled measurements across two copies of the input state. In this work, we give a similarly efficient algorithm that learns the same class of states using only single-copy measurements.
</details>
<details>
<summary>摘要</summary>
最近的工作表明，$n$-粒子量子状态由具有最多$t$个单元素非束地 gates生成的电路可以使用$\mathsf{poly}(n,2^t,1/\epsilon)$时间和样本来跟踪距离$\epsilon$。所有先前的算法达到这个 runtime 都使用了两份输入状态的排合测试。在这种工作中，我们给出了同样的效率的算法，可以使用单份输入状态来学习同一类型的状态。Note:* " $n$-qubit quantum states" is translated as " $n$-粒子量子状态" (n-qubit quantum states)* "circuits with at most $t$ single-qubit non-Clifford gates" is translated as "具有最多$t$个单元素非束地 gates的电路" (circuits with at most t single-qubit non-Clifford gates)* "can be learned to trace distance $\epsilon$ using $\mathsf{poly}(n,2^t,1/\epsilon)$ time and samples" is translated as "可以使用$\mathsf{poly}(n,2^t,1/\epsilon)$时间和样本来跟踪距离$\epsilon$" (can be learned to trace distance ε using polynomial time and samples)* "All prior algorithms achieving this runtime use entangled measurements across two copies of the input state" is translated as "所有先前的算法达到这个 runtime 都使用了两份输入状态的排合测试" (all previous algorithms achieving this runtime use entangled measurements across two copies of the input state)* "In this work, we give a similarly efficient algorithm that learns the same class of states using only single-copy measurements" is translated as "在这种工作中，我们给出了同样的效率的算法，可以使用单份输入状态来学习同一类型的状态" (in this work, we give a similarly efficient algorithm that learns the same class of states using only single-copy measurements)
</details></li>
</ul>
<hr>
<h2 id="PitchNet-A-Fully-Convolutional-Neural-Network-for-Pitch-Estimation"><a href="#PitchNet-A-Fully-Convolutional-Neural-Network-for-Pitch-Estimation" class="headerlink" title="PitchNet: A Fully Convolutional Neural Network for Pitch Estimation"></a>PitchNet: A Fully Convolutional Neural Network for Pitch Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07170">http://arxiv.org/abs/2308.07170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeremy Cochoy</li>
<li>for: 这项研究旨在提高人声中的抑 pitch 检测精度，以便在音乐和语音处理领域中进行更加精准的抑 pitch EXTraction。</li>
<li>methods: 该研究提出了一种基于卷积神经网络的 “PitchNet”，用于从人声中提取抑 pitch。该网络结合自相关函数和深度学习技术，以便优化抑 pitch 检测的精度。</li>
<li>results: 对于 synthetic sounds、opera recordings 和 time-stretched vowels 等数据集的评估表明，PitchNet 能够准确地检测人声中的抑 pitch。这项研究为音乐和语音处理领域中的抑 pitch EXTraction 开创了新的可能性。<details>
<summary>Abstract</summary>
In the domain of music and sound processing, pitch extraction plays a pivotal role. This research introduces "PitchNet", a convolutional neural network tailored for pitch extraction from the human singing voice, including acapella performances. Integrating autocorrelation with deep learning techniques, PitchNet aims to optimize the accuracy of pitch detection. Evaluation across datasets comprising synthetic sounds, opera recordings, and time-stretched vowels demonstrates its efficacy. This work paves the way for enhanced pitch extraction in both music and voice settings.
</details>
<details>
<summary>摘要</summary>
在音乐和声音处理领域中，抽取高度扮演着关键性的角色。本研究介绍“PitchNet”，一种适用于人声歌唱中的声调抽取 convolutional neural network（CNN）。通过对深度学习技术与自相关函数的组合，PitchNet目标是提高声调检测精度。对于 synthetic sounds、opera recording 和时间压缩词汇等数据集进行评估，PitchNet 的效果得到证明。这项工作将为音乐和声音设置中的声调抽取带来进一步的改进。Note: "Simplified Chinese" refers to the standardized form of Chinese used in mainland China, which is different from Traditional Chinese used in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="SPEGTI-Structured-Prediction-for-Efficient-Generative-Text-to-Image-Models"><a href="#SPEGTI-Structured-Prediction-for-Efficient-Generative-Text-to-Image-Models" class="headerlink" title="SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models"></a>SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10997">http://arxiv.org/abs/2308.10997</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadeep Jayasumana, Daniel Glasner, Srikumar Ramalingam, Andreas Veit, Ayan Chakrabarti, Sanjiv Kumar</li>
<li>for: 提高文本生成图像模型的计算效率，使其能够更快地生成高质量的图像。</li>
<li>methods: 使用Markov Random Field（MRF）模型来加速 Muse 模型的推理过程，从而提高图像生成的计算效率。</li>
<li>results: 通过使用 MRF 模型，可以significantly reduce the required number of Muse prediction steps，并且在各个空间位置上编码图像元素之间的兼容性，以提高图像质量和计算效率。<details>
<summary>Abstract</summary>
Modern text-to-image generation models produce high-quality images that are both photorealistic and faithful to the text prompts. However, this quality comes at significant computational cost: nearly all of these models are iterative and require running inference multiple times with large models. This iterative process is needed to ensure that different regions of the image are not only aligned with the text prompt, but also compatible with each other. In this work, we propose a light-weight approach to achieving this compatibility between different regions of an image, using a Markov Random Field (MRF) model. This method is shown to work in conjunction with the recently proposed Muse model. The MRF encodes the compatibility among image tokens at different spatial locations and enables us to significantly reduce the required number of Muse prediction steps. Inference with the MRF is significantly cheaper, and its parameters can be quickly learned through back-propagation by modeling MRF inference as a differentiable neural-network layer. Our full model, SPEGTI, uses this proposed MRF model to speed up Muse by 1.5X with no loss in output image quality.
</details>
<details>
<summary>摘要</summary>
现代文本到图像生成模型可以生成高质量的图像，这些图像不仅具有摄影真实性，还能够准确地反映文本提示。然而，这种质量来自于费时的计算成本：大多数这些模型都是迭代的，需要多次运行推理，以确保不同区域的图像与文本提示保持一致。在这种情况下，我们提出了一种轻量级的方法，使用Markov随机场（MRF）模型来实现不同区域图像的兼容性。这种方法与最近提出的Muse模型结合使用，并且可以减少Muse预测步骤的数量，从而大幅降低计算成本。我们的全模型SPEGTI使用这种MRF模型，可以帮助Muse快速推理1.5倍，而无需 sacrifi额外的图像质量。
</details></li>
</ul>
<hr>
<h2 id="Pairing-interacting-protein-sequences-using-masked-language-modeling"><a href="#Pairing-interacting-protein-sequences-using-masked-language-modeling" class="headerlink" title="Pairing interacting protein sequences using masked language modeling"></a>Pairing interacting protein sequences using masked language modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07136">http://arxiv.org/abs/2308.07136</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bitbol-lab/diffpalm">https://github.com/bitbol-lab/diffpalm</a></li>
<li>paper_authors: Umberto Lupo, Damiano Sgarbossa, Anne-Florence Bitbol</li>
<li>For: The paper aims to predict which proteins interact together from their amino acid sequences.* Methods: The paper uses protein language models trained on multiple sequence alignments, specifically MSA Transformer and the EvoFormer module of AlphaFold, to pair interacting protein sequences.* Results: The proposed method, DiffPALM, outperforms existing coevolution-based pairing methods on difficult benchmarks of shallow multiple sequence alignments and improves the structure prediction of some eukaryotic protein complexes by AlphaFold-Multimer.Here’s the same information in Simplified Chinese:* For: 文章目标是从蛋白质序列中预测哪些蛋白质进行互作。* Methods: 文章使用多个序列对 alignment 训练的蛋白质语言模型，特别是 MSA Transformer 和 AlphaFold 的 EvoFormer 模块，来对互作蛋白质序列进行对应。* Results: 提案的方法 DiffPALM 在难度较高的多个序列对上表现出优于现有的共演化基本方法，并在一些细胞蛋白质复合物的结构预测中达到竞争性表现。<details>
<summary>Abstract</summary>
Predicting which proteins interact together from amino-acid sequences is an important task. We develop a method to pair interacting protein sequences which leverages the power of protein language models trained on multiple sequence alignments, such as MSA Transformer and the EvoFormer module of AlphaFold. We formulate the problem of pairing interacting partners among the paralogs of two protein families in a differentiable way. We introduce a method called DiffPALM that solves it by exploiting the ability of MSA Transformer to fill in masked amino acids in multiple sequence alignments using the surrounding context. MSA Transformer encodes coevolution between functionally or structurally coupled amino acids. We show that it captures inter-chain coevolution, while it was trained on single-chain data, which means that it can be used out-of-distribution. Relying on MSA Transformer without fine-tuning, DiffPALM outperforms existing coevolution-based pairing methods on difficult benchmarks of shallow multiple sequence alignments extracted from ubiquitous prokaryotic protein datasets. It also outperforms an alternative method based on a state-of-the-art protein language model trained on single sequences. Paired alignments of interacting protein sequences are a crucial ingredient of supervised deep learning methods to predict the three-dimensional structure of protein complexes. DiffPALM substantially improves the structure prediction of some eukaryotic protein complexes by AlphaFold-Multimer, without significantly deteriorating any of those we tested. It also achieves competitive performance with using orthology-based pairing.
</details>
<details>
<summary>摘要</summary>
预测 protein sequences 中的互作对是一项重要任务。我们开发了一种方法，可以将 protein sequence 中的互作对级联起来，这种方法利用了多个序列对 alignment（如 MSA Transformer 和 EvoFormer 模块）训练的 protein language model。我们将这个问题转化为一个可导的问题，并提出了一种名为 DiffPALM 的方法来解决它。DiffPALM 利用了 MSA Transformer 可以填充遮盖的氨基酸，通过周围的上下文来填充它们。MSA Transformer 编码了功能或结构上的氨基酸之间的共演化，我们表明它可以在单链数据上训练，并在不需要微调的情况下在多链数据上进行预测。与现有的共演化基本方法相比，DiffPALM 在困难的多链对 alignments 上表现出色，同时也在不需要微调的情况下进行预测。此外，DiffPALM 还可以和一种基于 state-of-the-art 蛋白质语言模型进行比较，并且在一些欧化蛋白质复合物的结构预测中表现出色。Paired alignments of interacting protein sequences 是深度学习方法预测蛋白质复合物的重要组成部分。DiffPALM 在这些复合物的结构预测中提供了重要的改进。
</details></li>
</ul>
<hr>
<h2 id="Natural-Language-is-All-a-Graph-Needs"><a href="#Natural-Language-is-All-a-Graph-Needs" class="headerlink" title="Natural Language is All a Graph Needs"></a>Natural Language is All a Graph Needs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07134">http://arxiv.org/abs/2308.07134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, Yongfeng Zhang</li>
<li>for: 本研究旨在探讨 Whether large language models (LLMs) can replace graph neural networks (GNNs) as the foundation model for graphs.</li>
<li>methods: 我们提出了 InstructGLM (Instruction-finetuned Graph Language Model)，使用自然语言指令设计了高度可扩展的 prompt，并使用自然语言描述图像的几何结构和节点特征。</li>
<li>results: 我们的方法在 ogbn-arxiv、Cora 和 PubMed 数据集上超过了所有竞争 GNN 基elines，这说明了我们的方法的有效性，并且推照generative大型语言模型为图机器学习的基础模型。<details>
<summary>Abstract</summary>
The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scalable prompts based on natural language instructions, and use natural language to describe the geometric structure and node features of the graph for instruction tuning an LLM to perform learning and inference on graphs in a generative manner. Our method exceeds all competitive GNN baselines on ogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of our method and sheds light on generative large language models as the foundation model for graph machine learning.
</details>
<details>
<summary>摘要</summary>
“大规模预训练语言模型，如ChatGPT，对人工智能多种研究领域产生了革命性的影响。基于Transformers的大语言模型（LLM）逐渐取代了CNNs和RNNs，统一了计算机视觉和自然语言处理领域。与独立存在的数据，如图像、视频或文本，相比，图表是一种包含丰富结构和关系信息的数据类型。同时，自然语言作为最表达力强的媒介，能够描述复杂结构。然而，将图学学习问题 integrate into the generative language modeling framework的现有工作很有限。随着大语言模型的重要性不断增长，我们需要探索 Whether LLMs可以取代GNNs作为图学基础模型。本文提出InstructGLM（基于natural language instruction的图语言模型），系统地设计了可扩展的提示，使用自然语言描述图表的结构和节点特征，并使用LLM进行图学学习和推理。我们的方法在ogbn-arxiv、Cora和PubMed数据集上都超过了所有的竞争GNN基elines，这 demonstates了我们的方法的有效性，并照亮了大语言模型作为图学基础模型的可能性。”
</details></li>
</ul>
<hr>
<h2 id="Implementation-of-The-Future-of-Drug-Discovery-QuantumBased-Machine-Learning-Simulation-QMLS"><a href="#Implementation-of-The-Future-of-Drug-Discovery-QuantumBased-Machine-Learning-Simulation-QMLS" class="headerlink" title="Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS)"></a>Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08561">http://arxiv.org/abs/2308.08561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yew Kee Wong, Yifan Zhou, Yan Shing Liang, Haichuan Qiu, Yu Xi Wu, Bin He</li>
<li>for: 这份研究目的是为了缩短药物开发过程的时间和成本，以及创新一种能够在三到六个月内完成整个R&amp;D过程，并且只需五十到八十千美元的成本。</li>
<li>methods: 这篇研究使用的方法包括机器学习分子生成（MLMG）和量子模拟（QS），两者共同实现了精确地预测药物的结构和功能。MLMG根据目标蛋白质的分子结构来生成可能的击中者，而QS则对这些分子进行筛选，以确定它们对目标蛋白质的反应和紧缩效果。</li>
<li>results: 这篇研究的结果显示，使用机器学习和量子模拟的融合方法可以快速生成高效的药物材料，并且可以实现对药物的评估和筛选。这些材料可以在几个月内完成整个R&amp;D过程，并且可以降低成本至五十到八十千美元。<details>
<summary>Abstract</summary>
The Research & Development (R&D) phase of drug development is a lengthy and costly process. To revolutionize this process, we introduce our new concept QMLS to shorten the whole R&D phase to three to six months and decrease the cost to merely fifty to eighty thousand USD. For Hit Generation, Machine Learning Molecule Generation (MLMG) generates possible hits according to the molecular structure of the target protein while the Quantum Simulation (QS) filters molecules from the primary essay based on the reaction and binding effectiveness with the target protein. Then, For Lead Optimization, the resultant molecules generated and filtered from MLMG and QS are compared, and molecules that appear as a result of both processes will be made into dozens of molecular variations through Machine Learning Molecule Variation (MLMV), while others will only be made into a few variations. Lastly, all optimized molecules would undergo multiple rounds of QS filtering with a high standard for reaction effectiveness and safety, creating a few dozen pre-clinical-trail-ready drugs. This paper is based on our first paper, where we pitched the concept of machine learning combined with quantum simulations. In this paper we will go over the detailed design and framework of QMLS, including MLMG, MLMV, and QS.
</details>
<details>
<summary>摘要</summary>
研发（R&D）阶段是药品开发的长途和昂贵的过程。为了革新这个过程，我们提出了新的概念——量子机器学学习（QMLS），可以缩短整个R&D阶段的时间至3-6个月，并降低成本至50-80万美元。在潜在药物生成（Hit Generation）阶段，机器学学习分子生成（MLMG）根据目标蛋白质的分子结构生成可能的潜在药物，而量子模拟（QS）则从初步试验中筛选出与目标蛋白质具有强烈反应和结合效果的分子。在药物优化阶段，得到的分子 variants 由机器学学习分子变化（MLMV）进行了数十个变化，而其他分子则只进行了几个变化。最后，所有优化后的分子都会经过多轮QS筛选，以确保它们具有高效性和安全性，从而生成数十个前期临床药物。本文是我们之前的第一篇论文的续写，我们在这篇文章中将详细介绍QMLS的设计和框架，包括MLMG、MLMV和QS。
</details></li>
</ul>
<hr>
<h2 id="A-Time-aware-tensor-decomposition-for-tracking-evolving-patterns"><a href="#A-Time-aware-tensor-decomposition-for-tracking-evolving-patterns" class="headerlink" title="A Time-aware tensor decomposition for tracking evolving patterns"></a>A Time-aware tensor decomposition for tracking evolving patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07126">http://arxiv.org/abs/2308.07126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christos Chatzis, Max Pfeffer, Pedro Lind, Evrim Acar</li>
<li>for: 本研究旨在提取时间序列数据中的慢慢发展模式，并且能够考虑时间序列中的变化。</li>
<li>methods: 本文提出了一种基于PARAFAC2的时间regularization方法，即 temporal PARAFAC2（tPARAFAC2），用于抽取时间序列数据中的慢慢发展模式。</li>
<li>results: 经过广泛的实验 validate that tPARAFAC2可以准确地捕捉时间序列数据中的慢慢发展模式，并且表现比PARAFAC2和时间平滑矩阵因子化regularization方法更好。<details>
<summary>Abstract</summary>
Time-evolving data sets can often be arranged as a higher-order tensor with one of the modes being the time mode. While tensor factorizations have been successfully used to capture the underlying patterns in such higher-order data sets, the temporal aspect is often ignored, allowing for the reordering of time points. In recent studies, temporal regularizers are incorporated in the time mode to tackle this issue. Nevertheless, existing approaches still do not allow underlying patterns to change in time (e.g., spatial changes in the brain, contextual changes in topics). In this paper, we propose temporal PARAFAC2 (tPARAFAC2): a PARAFAC2-based tensor factorization method with temporal regularization to extract gradually evolving patterns from temporal data. Through extensive experiments on synthetic data, we demonstrate that tPARAFAC2 can capture the underlying evolving patterns accurately performing better than PARAFAC2 and coupled matrix factorization with temporal smoothness regularization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate("Time-evolving data sets can often be arranged as a higher-order tensor with one of the modes being the time mode. While tensor factorizations have been successfully used to capture the underlying patterns in such higher-order data sets, the temporal aspect is often ignored, allowing for the reordering of time points. In recent studies, temporal regularizers are incorporated in the time mode to tackle this issue. Nevertheless, existing approaches still do not allow underlying patterns to change in time (e.g., spatial changes in the brain, contextual changes in topics). In this paper, we propose temporal PARAFAC2 (tPARAFAC2): a PARAFAC2-based tensor factorization method with temporal regularization to extract gradually evolving patterns from temporal data. Through extensive experiments on synthetic data, we demonstrate that tPARAFAC2 can capture the underlying evolving patterns accurately, performing better than PARAFAC2 and coupled matrix factorization with temporal smoothness regularization.") result:时间演化数据集经常可以被视为一个高阶张量，其中一个方向是时间方向。虽然tensor分解已经成功地用于捕捉高阶数据集中的下面模式，但是时间方面通常被忽略，允许时间点的重新排序。在最近的研究中，temporal regularizers被添加到时间方面以解决这个问题。然而，现有的方法仍然不允许下面模式在时间上发生变化（例如，大脑中的空间变化，话题中的上下文变化）。在这篇论文中，我们提议时间PARAFAC2（tPARAFAC2）：基于PARAFAC2的张量分解方法，带有时间正则化，以EXTRACT从时间数据中逐渐发展的模式。通过对 sintetic数据进行了广泛的实验，我们示出了tPARAFAC2可以准确地捕捉下面模式，并且perform better than PARAFAC2和 Coupled Matrix Factorization with temporal smoothness regularization。
</details></li>
</ul>
<hr>
<h2 id="Active-Bird2Vec-Towards-End-to-End-Bird-Sound-Monitoring-with-Transformers"><a href="#Active-Bird2Vec-Towards-End-to-End-Bird-Sound-Monitoring-with-Transformers" class="headerlink" title="Active Bird2Vec: Towards End-to-End Bird Sound Monitoring with Transformers"></a>Active Bird2Vec: Towards End-to-End Bird Sound Monitoring with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07121">http://arxiv.org/abs/2308.07121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Rauch, Raphael Schwinger, Moritz Wirth, Bernhard Sick, Sven Tomforde, Christoph Scholz</li>
<li>for: 本研究旨在推动鸟叫声监测领域的终端学习转移，通过结合自动学习（SSL）和深度活动学习（DAL），以便直接处理原始音频数据，并生成高质量鸟叫声表示。</li>
<li>methods: 本研究使用变换器模型，并通过自动学习生成高质量鸟叫声表示，以便加速环境变化评估和决策过程。此外，通过深度活动学习，减少人工标注数据的依赖，提高了鸟叫声识别任务的效果。</li>
<li>results: 本研究通过对不同变换器模型进行比较分析，评估它们在鸟叫声识别任务中的效果。同时，通过使用Huggingface Datasets，生成了一个完整的任务集，以便提高未来的比较性和可重现性。<details>
<summary>Abstract</summary>
We propose a shift towards end-to-end learning in bird sound monitoring by combining self-supervised (SSL) and deep active learning (DAL). Leveraging transformer models, we aim to bypass traditional spectrogram conversions, enabling direct raw audio processing. ActiveBird2Vec is set to generate high-quality bird sound representations through SSL, potentially accelerating the assessment of environmental changes and decision-making processes for wind farms. Additionally, we seek to utilize the wide variety of bird vocalizations through DAL, reducing the reliance on extensively labeled datasets by human experts. We plan to curate a comprehensive set of tasks through Huggingface Datasets, enhancing future comparability and reproducibility of bioacoustic research. A comparative analysis between various transformer models will be conducted to evaluate their proficiency in bird sound recognition tasks. We aim to accelerate the progression of avian bioacoustic research and contribute to more effective conservation strategies.
</details>
<details>
<summary>摘要</summary>
我们提议将学习方法转换为终端学习，通过结合自动生成监督（SSL）和深度活动学习（DAL），利用变换器模型，以直接处理原始音频数据，并不需要传统的spectrogram转换。我们通过ActiveBird2Vec生成高质量的鸟叫表示，通过SSL可能加速环境变化评估和风车决策过程，同时通过DAL减少人工标注数据的依赖，提高生物听音研究的可比性和可重复性。我们计划使用Huggingface集成数据，并进行不同变换器模型之间的比较分析，以评估它们在鸟叫识别任务中的效果。我们希望通过加速鸟类生物听音研究，为生态保护策略做出更有效的贡献。
</details></li>
</ul>
<hr>
<h2 id="Neural-radiance-fields-in-the-industrial-and-robotics-domain-applications-research-opportunities-and-use-cases"><a href="#Neural-radiance-fields-in-the-industrial-and-robotics-domain-applications-research-opportunities-and-use-cases" class="headerlink" title="Neural radiance fields in the industrial and robotics domain: applications, research opportunities and use cases"></a>Neural radiance fields in the industrial and robotics domain: applications, research opportunities and use cases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07118">http://arxiv.org/abs/2308.07118</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maftej/iisnerf">https://github.com/maftej/iisnerf</a></li>
<li>paper_authors: Eugen Šlapak, Enric Pardo, Matúš Dopiriak, Taras Maksymyuk, Juraj Gazda</li>
<li>for: 这篇论文旨在探讨基于提供训练图像的神经辐射场（NeRF）在不同工业子领域的应用前景，以及未来研究方向。</li>
<li>methods: 本论文使用NeRF来学习3D场景表示，并提供了一系列证明NeRF在工业领域的应用可行性的实验。这些实验包括基于NeRF的视频压缩技术和使用NeRF进行3D运动估计以避免碰撞。</li>
<li>results: 在视频压缩实验中，我们获得了1920x1080和300x168分辨率下的压缩率为48%和74%。在3D动画中使用D-NeRF进行3D运动估计，得到了平均PSNR值为23 dB和SSIM值为0.97。<details>
<summary>Abstract</summary>
The proliferation of technologies, such as extended reality (XR), has increased the demand for high-quality three-dimensional (3D) graphical representations. Industrial 3D applications encompass computer-aided design (CAD), finite element analysis (FEA), scanning, and robotics. However, current methods employed for industrial 3D representations suffer from high implementation costs and reliance on manual human input for accurate 3D modeling. To address these challenges, neural radiance fields (NeRFs) have emerged as a promising approach for learning 3D scene representations based on provided training 2D images. Despite a growing interest in NeRFs, their potential applications in various industrial subdomains are still unexplored. In this paper, we deliver a comprehensive examination of NeRF industrial applications while also providing direction for future research endeavors. We also present a series of proof-of-concept experiments that demonstrate the potential of NeRFs in the industrial domain. These experiments include NeRF-based video compression techniques and using NeRFs for 3D motion estimation in the context of collision avoidance. In the video compression experiment, our results show compression savings up to 48\% and 74\% for resolutions of 1920x1080 and 300x168, respectively. The motion estimation experiment used a 3D animation of a robotic arm to train Dynamic-NeRF (D-NeRF) and achieved an average peak signal-to-noise ratio (PSNR) of disparity map with the value of 23 dB and an structural similarity index measure (SSIM) 0.97.
</details>
<details>
<summary>摘要</summary>
技术的普及，如扩展现实（XR），提高了高品质三维图形表示的需求。工业三维应用包括计算机支持设计（CAD）、Finite Element分析（FEA）、扫描和机器人。然而，现有的工业三维表示方法受到高实施成本和人工输入的限制，以获得准确的三维模型。为解决这些挑战，神经辐射场（NeRF）已经出现为了学习基于提供训练图像的三维场景表示方法。尽管有关NeRF的兴趣在不断增长，但它们在不同的工业子领域的潜在应用仍然未得到了足够的探索。在这篇论文中，我们提供了工业应用场景中NeRF的全面检查，并提供未来研究方向的指导。我们还提供了一系列的证明性实验，以示NeRF在工业领域的潜在应用。这些实验包括基于NeRF的视频压缩技术和使用NeRF进行3D运动估计，以避免碰撞。在视频压缩实验中，我们的结果表明，对于分辨率为1920x1080和300x168的视频，可以实现压缩率为48%和74%。在3D动画中使用D-NeRF进行3D运动估计实验，我们获得了平均的干扰比率（PSNR）为23 dB和结构相似度指标（SSIM）为0.97。
</details></li>
</ul>
<hr>
<h2 id="iSTFTNet2-Faster-and-More-Lightweight-iSTFT-Based-Neural-Vocoder-Using-1D-2D-CNN"><a href="#iSTFTNet2-Faster-and-More-Lightweight-iSTFT-Based-Neural-Vocoder-Using-1D-2D-CNN" class="headerlink" title="iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN"></a>iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07117">http://arxiv.org/abs/2308.07117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Shogo Seki</li>
<li>for: 快速、轻量级、高精度的语音合成</li>
<li>methods: 使用快速和轻量级的1D CNN作为基础网络，并将一些神经网络替换为iSTFT，以提高速度和轻量化。</li>
<li>results: iSTFTNet2比iSTFTNet更快速和轻量级，且音质相对保持不变。可以在<a target="_blank" rel="noopener" href="https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/%E4%B8%AD%E4%B8%8B%E8%BD%BD%E9%9F%B3%E9%A2%91%E6%A0%B7%E6%9C%AC%E3%80%82">https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/中下载音频样本。</a><details>
<summary>Abstract</summary>
The inverse short-time Fourier transform network (iSTFTNet) has garnered attention owing to its fast, lightweight, and high-fidelity speech synthesis. It obtains these characteristics using a fast and lightweight 1D CNN as the backbone and replacing some neural processes with iSTFT. Owing to the difficulty of a 1D CNN to model high-dimensional spectrograms, the frequency dimension is reduced via temporal upsampling. However, this strategy compromises the potential to enhance the speed. Therefore, we propose iSTFTNet2, an improved variant of iSTFTNet with a 1D-2D CNN that employs 1D and 2D CNNs to model temporal and spectrogram structures, respectively. We designed a 2D CNN that performs frequency upsampling after conversion in a few-frequency space. This design facilitates the modeling of high-dimensional spectrograms without compromising the speed. The results demonstrated that iSTFTNet2 made iSTFTNet faster and more lightweight with comparable speech quality. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（iSTFTNet）在最近引起了关注，因为它具有快速、轻量级和高精度的语音生成特点。它使用快速和轻量级的1D CNN作为基础模型，并将一些神经网络过程替换为iSTFT。由于1D CNN在模型高维спект罗格的问题上难以处理，因此在时间增サンプリング的策略可能会增加速度的约束。为了解决这个问题，我们提出了iSTFTNet2，它是iSTFTNet的改进版本，使用1D-2D CNN来模型时间和спект罗格结构。我们设计了一个2D CNN，它在几个频率空间中进行频率增サンプリング。这种设计允许模型高维спект罗格无需增加速度约束。结果表明，iSTFTNet2使得iSTFTNet更快速和轻量级，同时保持语音质量的同等性。有关audio samples的详细信息请参考https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/.
</details></li>
</ul>
<hr>
<h2 id="Ada-QPacknet-–-adaptive-pruning-with-bit-width-reduction-as-an-efficient-continual-learning-method-without-forgetting"><a href="#Ada-QPacknet-–-adaptive-pruning-with-bit-width-reduction-as-an-efficient-continual-learning-method-without-forgetting" class="headerlink" title="Ada-QPacknet – adaptive pruning with bit width reduction as an efficient continual learning method without forgetting"></a>Ada-QPacknet – adaptive pruning with bit width reduction as an efficient continual learning method without forgetting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07939">http://arxiv.org/abs/2308.07939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcin Pietroń, Dominik Żurek, Kamil Faber, Roberto Corizzo</li>
<li>for: 这个论文是为了解决深度学习模型在动态和复杂环境中学习效率差的问题而写的。</li>
<li>methods: 这个论文提出了一种基于架构的 kontinuous learning 方法，称为 Ada-QPacknet，它通过提取每个任务的子网络来实现。这种方法的关键特点是它的容量，它使用高效的线性和非线性归一化方法来减少模型的大小。</li>
<li>results: 在Well-known CL 场景中，hybrid 8和4位量化实现了浮点子网络的相似准确性。这个方法比大多数 CL 策略在任务和类增量enario中表现出色，并且在Well-known episode combinations 中测试了这个算法，与最流行的 CL 策略进行了比较。<details>
<summary>Abstract</summary>
Continual Learning (CL) is a process in which there is still huge gap between human and deep learning model efficiency. Recently, many CL algorithms were designed. Most of them have many problems with learning in dynamic and complex environments. In this work new architecture based approach Ada-QPacknet is described. It incorporates the pruning for extracting the sub-network for each task. The crucial aspect in architecture based CL methods is theirs capacity. In presented method the size of the model is reduced by efficient linear and nonlinear quantisation approach. The method reduces the bit-width of the weights format. The presented results shows that hybrid 8 and 4-bit quantisation achieves similar accuracy as floating-point sub-network on a well-know CL scenarios. To our knowledge it is the first CL strategy which incorporates both compression techniques pruning and quantisation for generating task sub-networks. The presented algorithm was tested on well-known episode combinations and compared with most popular algorithms. Results show that proposed approach outperforms most of the CL strategies in task and class incremental scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Age-Stratified-Differences-in-Morphological-Connectivity-Patterns-in-ASD-An-sMRI-and-Machine-Learning-Approach"><a href="#Age-Stratified-Differences-in-Morphological-Connectivity-Patterns-in-ASD-An-sMRI-and-Machine-Learning-Approach" class="headerlink" title="Age-Stratified Differences in Morphological Connectivity Patterns in ASD: An sMRI and Machine Learning Approach"></a>Age-Stratified Differences in Morphological Connectivity Patterns in ASD: An sMRI and Machine Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07356">http://arxiv.org/abs/2308.07356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gokul Manoj, Sandeep Singh Sengar, Jac Fredo Agastinose Ronickom</li>
<li>for: 这个研究的目的是为了比较不同年龄组的自闭症诊断使用形态特征（MF）和形态连接特征（MCF）的效果。</li>
<li>methods: 这个研究使用了两个公共可用的数据库—ABIDE-I和ABIDE-II—获得了Structural Magnetic Resonance Imaging（sMRI）数据，并将数据 pré-processed using a standard pipeline，然后将数据分割成根据Destrieux atlas的148个区域，EXTRACTED área、厚度、体积和平均弯曲信息，并使用了统计t检测（p&lt;0.05）来标识特征，然后使用Random Forest（RF）分类器进行训练。</li>
<li>results: 研究结果表明，6岁到11岁的年龄组的性能最高，其次是6岁到18岁和11岁到18岁的年龄组，在MF和MCF中都有高的表现。总的来说，MCF与RF在6岁到11岁的年龄组中表现最好，其准确率、F1 score、回归率和准确率分别为75.8%、83.1%、86%和80.4%。<details>
<summary>Abstract</summary>
Purpose: Age biases have been identified as an essential factor in the diagnosis of ASD. The objective of this study was to compare the effect of different age groups in classifying ASD using morphological features (MF) and morphological connectivity features (MCF). Methods: The structural magnetic resonance imaging (sMRI) data for the study was obtained from the two publicly available databases, ABIDE-I and ABIDE-II. We considered three age groups, 6 to 11, 11 to 18, and 6 to 18, for our analysis. The sMRI data was pre-processed using a standard pipeline and was then parcellated into 148 different regions according to the Destrieux atlas. The area, thickness, volume, and mean curvature information was then extracted for each region which was used to create a total of 592 MF and 10,878 MCF for each subject. Significant features were identified using a statistical t-test (p<0.05) which was then used to train a random forest (RF) classifier. Results: The results of our study suggested that the performance of the 6 to 11 age group was the highest, followed by the 6 to 18 and 11 to 18 ages in both MF and MCF. Overall, the MCF with RF in the 6 to 11 age group performed better in the classification than the other groups and produced an accuracy, F1 score, recall, and precision of 75.8%, 83.1%, 86%, and 80.4%, respectively. Conclusion: Our study thus demonstrates that morphological connectivity and age-related diagnostic model could be an effective approach to discriminating ASD.
</details>
<details>
<summary>摘要</summary>
目的：识别自闭症（ASD）的年龄因素已被证明是关键因素。本研究的目的是比较不同年龄组的分类ASD使用形态特征（MF）和形态连接特征（MCF）的效果。方法：我们从公共数据库ABIDE-I和ABIDE-II中获得了structural magnetic resonance imaging（sMRI）数据。我们分为三个年龄组：6-11岁、11-18岁和6-18岁进行分析。经过标准化处理后，sMRI数据被分割成根据Desitrieux大脑 Atlase所分的148个区域。然后，每个区域中的面积、厚度、体积和平均弯曲信息被提取，并用于创建共计592个MF和10878个MCF。通过统计t检测（p<0.05）进行了特征选择，并用于训练随机森林（RF）分类器。结果：我们的研究结果表明，6-11岁年龄组的性能最高，然后是6-18岁和11-18岁年龄组，在MF和MCF中都是如此。总的来说，在6-11岁年龄组中，MCF与RF的结合使得分类性能更高，其中的准确率、F1分数、回归率和精度分别为75.8%、83.1%、86%和80.4%。结论：这些结果表明，使用形态连接和年龄相关的诊断模型可以有效地识别ASD。
</details></li>
</ul>
<hr>
<h2 id="InsTag-Instruction-Tagging-for-Analyzing-Supervised-Fine-tuning-of-Large-Language-Models"><a href="#InsTag-Instruction-Tagging-for-Analyzing-Supervised-Fine-tuning-of-Large-Language-Models" class="headerlink" title="#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"></a>#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07074">http://arxiv.org/abs/2308.07074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ofa-sys/instag">https://github.com/ofa-sys/instag</a></li>
<li>paper_authors: Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan, Chang Zhou, Jingren Zhou</li>
<li>for: 这篇论文的目的是提高基础模型的 instruction-following 能力，并通过训练细化（SFT）来实现这一目标。</li>
<li>methods: 该论文使用了一种名为 InsTag 的开源细化标注工具，用于标注 SFT 数据集中的样本，并定义了 instrucion 多样性和复杂性的量化分析。</li>
<li>results: 研究发现，通过使用 InsTag 选择的6000个多样性和复杂性的样本，可以提高基础模型的表现，并且与训练数据量相比，TagLM 模型的表现更高。<details>
<summary>Abstract</summary>
Foundation language models obtain the instruction-following ability through supervised fine-tuning (SFT). Diversity and complexity are considered critical factors of a successful SFT dataset, while their definitions remain obscure and lack quantitative analyses. In this work, we propose InsTag, an open-set fine-grained tagger, to tag samples within SFT datasets based on semantics and intentions and define instruction diversity and complexity regarding tags. We obtain 6.6K tags to describe comprehensive user queries. Then we analyze popular open-sourced SFT datasets and find that the model ability grows with more diverse and complex data. Based on this observation, we propose a data selector based on InsTag to select 6K diverse and complex samples from open-source datasets and fine-tune models on InsTag-selected data. The resulting models, TagLM, outperform open-source models based on considerably larger SFT data evaluated by MT-Bench, echoing the importance of query diversity and complexity. We open-source InsTag in https://github.com/OFA-Sys/InsTag.
</details>
<details>
<summary>摘要</summary>
基础语言模型通过监督微调（SFT）获得指令遵从能力。多样性和复杂性被视为成功SFT数据集的关键因素，但其定义还未得到明确的量化分析。本工作提出InsTag，一种开放集标记器，用于在SFT数据集中标记样本基于 semantics和意图，并定义指令多样性和复杂性。我们获得了6.6K个标签来描述全面的用户查询。然后我们分析了流行的开源SFT数据集，发现模型能力随着数据集的多样性和复杂性增加。基于这个观察，我们提出了基于InsTag的数据选择器，选择6K个多样性和复杂性最高的样本从开源数据集进行练习。经过微调，我们获得了TagLM模型，其性能在MT-Bench评估中较开源模型高，证明了查询多样性和复杂性的重要性。我们在https://github.com/OFA-Sys/InsTag上开源了InsTag。
</details></li>
</ul>
<hr>
<h2 id="Machine-Unlearning-Solutions-and-Challenges"><a href="#Machine-Unlearning-Solutions-and-Challenges" class="headerlink" title="Machine Unlearning: Solutions and Challenges"></a>Machine Unlearning: Solutions and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07061">http://arxiv.org/abs/2308.07061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia</li>
<li>for: 本研究旨在提供一份系统性的机器学习忘记研究分类和分析，以便为 Selective Data Removal（SDR）技术的发展提供指导。</li>
<li>methods: 本研究分类了现有的机器学习忘记研究，包括精确忘记和近似忘记两种方法。精确忘记方法可以完全除去训练数据的影响，而近似忘记方法可以有效地减少影响。</li>
<li>results: 本研究对现有的机器学习忘记方法进行了 kritische 分析，并提出了未来研究的方向。通过这种分析，研究人员可以更好地了解机器学习忘记技术的优缺点，并为实际应用提供指导。<details>
<summary>Abstract</summary>
Machine learning models may inadvertently memorize sensitive, unauthorized, or malicious data, posing risks of privacy violations, security breaches, and performance deterioration. To address these issues, machine unlearning has emerged as a critical technique to selectively remove specific training data points' influence on trained models. This paper provides a comprehensive taxonomy and analysis of machine unlearning research. We categorize existing research into exact unlearning that algorithmically removes data influence entirely and approximate unlearning that efficiently minimizes influence through limited parameter updates. By reviewing the state-of-the-art solutions, we critically discuss their advantages and limitations. Furthermore, we propose future directions to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning. This paper provides researchers with a roadmap of open problems, encouraging impactful contributions to address real-world needs for selective data removal.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:机器学习模型可能偶发性记忆敏感、未授权或黑客数据，导致隐私违反、安全泄露和性能下降。为解决这些问题，机器忘记技术已经成为一种重要的解决方案，可以选择性地删除训练模型中具有特定影响的数据点。本文提供了机器忘记的全面分类和分析，并评估了现有的研究。我们将现有的研究分为单精度忘记和近似忘记两种，并评估了它们的优点和限制。此外，我们还提出了未来的方向，以推进机器忘记的发展，并将其视为可靠和适应式机器学习的重要能力。本文为研究人员提供了一个开启问题的路线图，促进了影响性的贡献，以解决实际需求中的选择性数据移除。
</details></li>
</ul>
<hr>
<h2 id="Diagnosis-of-Scalp-Disorders-using-Machine-Learning-and-Deep-Learning-Approach-–-A-Review"><a href="#Diagnosis-of-Scalp-Disorders-using-Machine-Learning-and-Deep-Learning-Approach-–-A-Review" class="headerlink" title="Diagnosis of Scalp Disorders using Machine Learning and Deep Learning Approach – A Review"></a>Diagnosis of Scalp Disorders using Machine Learning and Deep Learning Approach – A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07052">http://arxiv.org/abs/2308.07052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishabh Tiwari, Jatin Moolchandani, Shamla Mantri</li>
<li>for: 这篇论文主要针对scalp病的诊断和分类。</li>
<li>methods: 该论文使用了深度学习技术，包括Convolutional Neural Networks（CNN）和 Fully Connected Networks（FCN），以及一个APP，以帮助诊断scalp病。</li>
<li>results: 该论文的实验结果表明，使用深度学习模型可以高精度地诊断scalp病，其中一个方法的准确率为97.41%-99.09%，另一个方法的准确率为82.9%，而使用机器学习算法也可以高精度地诊断健康的scalp和脱发病。<details>
<summary>Abstract</summary>
The morbidity of scalp diseases is minuscule compared to other diseases, but the impact on the patient's life is enormous. It is common for people to experience scalp problems that include Dandruff, Psoriasis, Tinea-Capitis, Alopecia and Atopic-Dermatitis. In accordance with WHO research, approximately 70% of adults have problems with their scalp. It has been demonstrated in descriptive research that hair quality is impaired by impaired scalp, but these impacts are reversible with early diagnosis and treatment. Deep Learning advances have demonstrated the effectiveness of CNN paired with FCN in diagnosing scalp and skin disorders. In one proposed Deep-Learning-based scalp inspection and diagnosis system, an imaging microscope and a trained model are combined with an app that classifies scalp disorders accurately with an average precision of 97.41%- 99.09%. Another research dealt with classifying the Psoriasis using the CNN with an accuracy of 82.9%. As part of another study, an ML based algorithm was also employed. It accurately classified the healthy scalp and alopecia areata with 91.4% and 88.9% accuracy with SVM and KNN algorithms. Using deep learning models to diagnose scalp related diseases has improved due to advancements i computation capabilities and computer vision, but there remains a wide horizon for further improvements.
</details>
<details>
<summary>摘要</summary>
scalp 疾病的恶性相对其他疾病较少，但对病人的生活影响巨大。人们常经历披裤屑、 Psoriasis、Tinea-Capitis、Alopecia 和 Atopic-Dermatitis 等 scalp 问题。根据Who研究，约70%的成年人有 scalp 问题。研究表明，损害的毛发质量是由于损害 scalp 引起的，但这些影响可以通过早期诊断和治疗而reverse。深度学习技术的进步使得用 Deep Learning 模型进行 scalp 检查和诊断系统的精度提高了。在一个提议的 Deep-Learning-based scalp 检查和诊断系统中，一个图像镜和一个训练模型被与一个APP结合，可以准确地分类 scalp 疾病，其精度为97.41%-99.09%。另一项研究则是使用 CNN 分类 Psoriasis，其精度为82.9%。在另一项研究中，一种 ML 基本的算法也被应用，它可以准确地分类健康的 scalp 和 Alopecia areata，其精度为91.4% 和 88.9%。使用深度学习模型进行 scalp 相关疾病的诊断，由于计算机能力和计算机视觉的进步，已经得到了进一步改进的空间，但还有很大的可能性空间。
</details></li>
</ul>
<hr>
<h2 id="Fourier-neural-operator-for-learning-solutions-to-macroscopic-traffic-flow-models-Application-to-the-forward-and-inverse-problems"><a href="#Fourier-neural-operator-for-learning-solutions-to-macroscopic-traffic-flow-models-Application-to-the-forward-and-inverse-problems" class="headerlink" title="Fourier neural operator for learning solutions to macroscopic traffic flow models: Application to the forward and inverse problems"></a>Fourier neural operator for learning solutions to macroscopic traffic flow models: Application to the forward and inverse problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07051">http://arxiv.org/abs/2308.07051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bilal Thonnam Thodi, Sai Venkata Ramana Ambadipudi, Saif Eddin Jabari</li>
<li>for: 这个论文是用来研究深度学习方法在交通流动中的应用，特别是用于解决非线性半导体方程的问题。</li>
<li>methods: 这个论文使用了一种名为 нейрон运算器框架，它可以将不同和稀疏的交通数据映射到完整的交通状况中。在训练中，使用了一种名为 физи学信息冲激（π）-FNO的算子，它在训练中添加了一个物理损失函数，以便在训练中提高冲击预测。</li>
<li>results: 通过使用LWR交通流模型， authors发现了在预测环形路网和城市信号灯道路上的density dynamics的高精度预测。此外，他们发现了一个可以使用简单的交通密度动态，例如由2-3个汽车队列和1-2个交通信号ecycle组成的数据，并且可以预测具有不同汽车队列分布和多个交通信号cycle（大于2）的密度动态，并且误差在可接受范围内。在适当的模型架构和训练数据下，插值误差呈线性增长。添加物理正则化可以帮助学习长期交通密度动态，特别是在 periodic boundary data 上。<details>
<summary>Abstract</summary>
Deep learning methods are emerging as popular computational tools for solving forward and inverse problems in traffic flow. In this paper, we study a neural operator framework for learning solutions to nonlinear hyperbolic partial differential equations with applications in macroscopic traffic flow models. In this framework, an operator is trained to map heterogeneous and sparse traffic input data to the complete macroscopic traffic state in a supervised learning setting. We chose a physics-informed Fourier neural operator ($\pi$-FNO) as the operator, where an additional physics loss based on a discrete conservation law regularizes the problem during training to improve the shock predictions. We also propose to use training data generated from random piecewise constant input data to systematically capture the shock and rarefied solutions. From experiments using the LWR traffic flow model, we found superior accuracy in predicting the density dynamics of a ring-road network and urban signalized road. We also found that the operator can be trained using simple traffic density dynamics, e.g., consisting of $2-3$ vehicle queues and $1-2$ traffic signal cycles, and it can predict density dynamics for heterogeneous vehicle queue distributions and multiple traffic signal cycles $(\geq 2)$ with an acceptable error. The extrapolation error grew sub-linearly with input complexity for a proper choice of the model architecture and training data. Adding a physics regularizer aided in learning long-term traffic density dynamics, especially for problems with periodic boundary data.
</details>
<details>
<summary>摘要</summary>
深度学习方法在交通流动问题中得到广泛应用。在这篇论文中，我们研究了一种神经网络框架，用于解决非线性偏微分方程的问题，并应用于大规模交通流模型。在这个框架中，一个算子被训练，以将不同和稀疏的交通数据映射到完整的交通状态中。我们选择了一种带有物理约束的 fourier神经网络（π-FNO）作为算子，其中在训练过程中添加了物理损失，以提高震动预测。我们还提出了使用随机划分的杂ync constant输入数据来系统地捕捉震动和稀疏解。从实验使用LWR交通流模型来看，我们发现了在density动力学中的高精度预测。我们还发现算子可以通过简单的交通密度动力学，例如由2-3辆汽车队列和1-2个交通信号周期组成的系统，来预测密度动力学。此外，我们发现算子可以在不同的汽车队列分布和多个交通信号周期（至少2个）下预测密度动力学，并且误差在输入复杂性增长的速度下逐渐增加。添加物理约束可以帮助学习长期交通密度动力学，特别是在 periodic boundry data 的问题上。
</details></li>
</ul>
<hr>
<h2 id="UIPC-MF-User-Item-Prototype-Connection-Matrix-Factorization-for-Explainable-Collaborative-Filtering"><a href="#UIPC-MF-User-Item-Prototype-Connection-Matrix-Factorization-for-Explainable-Collaborative-Filtering" class="headerlink" title="UIPC-MF: User-Item Prototype Connection Matrix Factorization for Explainable Collaborative Filtering"></a>UIPC-MF: User-Item Prototype Connection Matrix Factorization for Explainable Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07048">http://arxiv.org/abs/2308.07048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Pan, Von-Wun Soo</li>
<li>for: 提高推荐系统的准确率和可解释性</li>
<li>methods: 使用prototype-based matrix factorization方法，即UIPC-MF，其中用户和 Item 都关联有一组原型，以增强推荐的可解释性</li>
<li>results: 相比其他原型基eline方法，UIPC-MF 在三个 dataset 上显示出较高的 Hit Ratio 和 Normalized Discounted Cumulative Gain，同时也提供了更好的透明度。<details>
<summary>Abstract</summary>
Recommending items to potentially interested users has been an important commercial task that faces two main challenges: accuracy and explainability. While most collaborative filtering models rely on statistical computations on a large scale of interaction data between users and items and can achieve high performance, they often lack clear explanatory power. We propose UIPC-MF, a prototype-based matrix factorization method for explainable collaborative filtering recommendations. In UIPC-MF, both users and items are associated with sets of prototypes, capturing general collaborative attributes. To enhance explainability, UIPC-MF learns connection weights that reflect the associative relations between user and item prototypes for recommendations. UIPC-MF outperforms other prototype-based baseline methods in terms of Hit Ratio and Normalized Discounted Cumulative Gain on three datasets, while also providing better transparency.
</details>
<details>
<summary>摘要</summary>
推荐预测已经是电商中一项非常重要的任务，面临着两个主要挑战：准确性和可读性。大多数共同推荐模型通过大规模的用户-物品交互数据进行统计计算，可以达到高性能，但通常缺乏明确的解释力。我们提出了UIPC-MF，一种基于原型的矩阵分解方法，用于可读性推荐。在UIPC-MF中，用户和物品都关联到一组原型，捕捉总的共同特征。为了增强可读性，UIPC-MF学习用户和物品原型之间的关联Weight，用于推荐。UIPC-MF在三个数据集上比基eline方法具有更高的 Hit Ratio 和 Normalized Discounted Cumulative Gain，同时也提供了更好的透明度。
</details></li>
</ul>
<hr>
<h2 id="No-Regularization-is-Needed-An-Efficient-and-Effective-Model-for-Incomplete-Label-Distribution-Learning"><a href="#No-Regularization-is-Needed-An-Efficient-and-Effective-Model-for-Incomplete-Label-Distribution-Learning" class="headerlink" title="No Regularization is Needed: An Efficient and Effective Model for Incomplete Label Distribution Learning"></a>No Regularization is Needed: An Efficient and Effective Model for Incomplete Label Distribution Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07047">http://arxiv.org/abs/2308.07047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Li, Songcan Chen</li>
<li>for: 本研究目的是解决因缺失数据而导致的不完整的分类器（Incomplete LDL，InLDL）性能下降问题，而不需要任何显式正则化。</li>
<li>methods: 我们提出使用分类器自身的标签分布作为正则化的先验知识，并设计了一种权重 schemes来强调小度和缺失度。</li>
<li>results: 我们的模型具有四个优点：1）没有需要显式正则化；2）具有闭式解决方案和易于实现（只需几行代码）；3）与大规模数据集相比，计算复杂度 linear；4）与当前状态对齐水平性能。<details>
<summary>Abstract</summary>
Label Distribution Learning (LDL) assigns soft labels, a.k.a. degrees, to a sample. In reality, it is always laborious to obtain complete degrees, giving birth to the Incomplete LDL (InLDL). However, InLDL often suffers from performance degeneration. To remedy it, existing methods need one or more explicit regularizations, leading to burdensome parameter tuning and extra computation. We argue that label distribution itself may provide useful prior, when used appropriately, the InLDL problem can be solved without any explicit regularization. In this paper, we offer a rational alternative to use such a prior. Our intuition is that large degrees are likely to get more concern, the small ones are easily overlooked, whereas the missing degrees are completely neglected in InLDL. To learn an accurate label distribution, it is crucial not to ignore the small observed degrees but to give them properly large weights, while gradually increasing the weights of the missing degrees. To this end, we first define a weighted empirical risk and derive upper bounds between the expected risk and the weighted empirical risk, which reveals in principle that weighting plays an implicit regularization role. Then, by using the prior of degrees, we design a weighted scheme and verify its effectiveness. To sum up, our model has four advantages, it is 1) model selection free, as no explicit regularization is imposed; 2) with closed form solution (sub-problem) and easy-to-implement (a few lines of codes); 3) with linear computational complexity in the number of samples, thus scalable to large datasets; 4) competitive with state-of-the-arts even without any explicit regularization.
</details>
<details>
<summary>摘要</summary>
标签分布学习（LDL）将软标签，即学习度，赋予样本。在实际应用中，完整的学习度往往很困难寻求，从而产生了偏差的LDL（InLDL）问题。然而，InLDL经常会导致性能下降。现有方法通常需要一或多个显式正则化，这会增加参数调整的复杂性和额外计算。我们认为标签分布本身可以提供有用的前提，当正确使用时，InLDL问题可以解决无需显式正则化。在本文中，我们提出了一种合理的使用此前提的方法。我们的启发是，大度标签更有可能受到注意，小度标签容易被忽略，而缺失的度标签完全被偏差的InLDL忽略。为了学习准确的标签分布，非常重要不是忽略小 observed degree，而是给它们适当的大量重要，同时逐渐增加缺失的度标签的重要性。我们首先定义了权重化的empirical risk，并 derivated upper bound между预期风险和权重化empirical risk，这 revelas in principle that weighting plays an implicit regularization role。然后，通过使用度标签的前提，我们设计了权重方案，并证明其效果。总之，我们的模型具有以下四个优点：1) 无需显式正则化，因为不需要任何显式正则化; 2) 具有关闭式解（sub-problem）和易于实现（只需几行代码）; 3) 对大量数据集 scales linearly，因此可扩展性好; 4) 与状态 искусственный지标下相当竞争，即无需显式正则化。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-Flow-Networks"><a href="#Bayesian-Flow-Networks" class="headerlink" title="Bayesian Flow Networks"></a>Bayesian Flow Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07037">http://arxiv.org/abs/2308.07037</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stefanradev93/BayesFlow">https://github.com/stefanradev93/BayesFlow</a></li>
<li>paper_authors: Alex Graves, Rupesh Kumar Srivastava, Timothy Atkinson, Faustino Gomez</li>
<li>for: 本研究提出了抽象概率流网络（BFN），一种新的生成模型，其中抽象概率流网络的参数通过 bayesian 推断在噪声数据样本的灯光下进行修改，然后通过神经网络输出第二个相互dependent的分布。</li>
<li>methods: 该研究提出了一种基于 bayesian 推断的生成过程，其中从简单的先验开始，逐步更新两个分布，得到一个类似于反diffusion 模型的生成过程，但是更加简单，不需要前向过程。</li>
<li>results: 在图像模型task上，BFNs  achieved competitive log-likelihoods on dynamically binarized MNIST and CIFAR-10，并在文本8字符级语言模型任务上超越所有已知的批diffusion 模型。<details>
<summary>Abstract</summary>
This paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in which the parameters of a set of independent distributions are modified with Bayesian inference in the light of noisy data samples, then passed as input to a neural network that outputs a second, interdependent distribution. Starting from a simple prior and iteratively updating the two distributions yields a generative procedure similar to the reverse process of diffusion models; however it is conceptually simpler in that no forward process is required. Discrete and continuous-time loss functions are derived for continuous, discretised and discrete data, along with sample generation procedures. Notably, the network inputs for discrete data lie on the probability simplex, and are therefore natively differentiable, paving the way for gradient-based sample guidance and few-step generation in discrete domains such as language modelling. The loss function directly optimises data compression and places no restrictions on the network architecture. In our experiments BFNs achieve competitive log-likelihoods for image modelling on dynamically binarized MNIST and CIFAR-10, and outperform all known discrete diffusion models on the text8 character-level language modelling task.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这篇论文介绍了 bayesian flow networks (BFNs)，一种新的生成模型，其中bayesian inference modify了一组独立分布的参数，然后将这些修改后的分布作为输入传递给神经网络，生成一个第二个、相互关联的分布。这个过程类似于Diffusion模型的反向过程，但是更加简单，不需要前向过程。模型可以处理整数、连续和整数化数据，并且使用本地差分导数，使得梯度导航和几步生成在整数领域如语言模型中变得更加容易。损失函数直接优化数据压缩，并不限制网络架构。在实验中，BFNs在 dynamically binarized MNIST和CIFAR-10上的图像模型 task中 achieved competitive log-likelihoods，并在text8 character-level语言模型任务上超过了所有已知的整数 diffusion models。
</details></li>
</ul>
<hr>
<h2 id="S3IM-Stochastic-Structural-SIMilarity-and-Its-Unreasonable-Effectiveness-for-Neural-Fields"><a href="#S3IM-Stochastic-Structural-SIMilarity-and-Its-Unreasonable-Effectiveness-for-Neural-Fields" class="headerlink" title="S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields"></a>S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07032">http://arxiv.org/abs/2308.07032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/madaoer/s3im_nerf">https://github.com/madaoer/s3im_nerf</a></li>
<li>paper_authors: Zeke Xie, Xindi Yang, Yujie Yang, Qi Sun, Yixiang Jiang, Haoran Wang, Yunfeng Cai, Mingming Sun</li>
<li>for: 该论文旨在提高NeRF和相关神经场方法的可视化质量，使其能够更好地渲染未知视角的场景图像。</li>
<li>methods: 该论文提出了一种非本地多重训练方法，通过一种新的随机结构相似性（S3IM）损失函数，将多个数据点处理为一个整体，而不是独立处理每个输入。</li>
<li>results: 对于八种视角合成任务和八种表面重建任务，S3IM可以减少测试MSE损失率超过90%，提高F1分数198%和Chamfer-$L_{1}$距离64%。此外，S3IM可以在缺少输入、损坏图像和动态场景下保持稳定性。<details>
<summary>Abstract</summary>
Recently, Neural Radiance Field (NeRF) has shown great success in rendering novel-view images of a given scene by learning an implicit representation with only posed RGB images. NeRF and relevant neural field methods (e.g., neural surface representation) typically optimize a point-wise loss and make point-wise predictions, where one data point corresponds to one pixel. Unfortunately, this line of research failed to use the collective supervision of distant pixels, although it is known that pixels in an image or scene can provide rich structural information. To the best of our knowledge, we are the first to design a nonlocal multiplex training paradigm for NeRF and relevant neural field methods via a novel Stochastic Structural SIMilarity (S3IM) loss that processes multiple data points as a whole set instead of process multiple inputs independently. Our extensive experiments demonstrate the unreasonable effectiveness of S3IM in improving NeRF and neural surface representation for nearly free. The improvements of quality metrics can be particularly significant for those relatively difficult tasks: e.g., the test MSE loss unexpectedly drops by more than 90% for TensoRF and DVGO over eight novel view synthesis tasks; a 198% F-score gain and a 64% Chamfer $L_{1}$ distance reduction for NeuS over eight surface reconstruction tasks. Moreover, S3IM is consistently robust even with sparse inputs, corrupted images, and dynamic scenes.
</details>
<details>
<summary>摘要</summary>
近期，神经辐射场（NeRF）已经取得了在渲染新视图图像中的成功，通过学习含义几何表示，只使用配置好的RGB图像。NeRF和相关的神经场方法（例如神经表面表示）通常是点 wise 损失优化和点 wise 预测，其中一个数据点对应一个像素。尽管这一线索的研究把握不到远程像素的集合supervision，即图像或场景中的像素可以提供丰富的结构信息。据我们所知，我们是首先设计了非本地多样training paradigm for NeRF和相关神经场方法，通过一种新的随机Structural SIMilarity（S3IM）损失函数，将多个数据点处理为一个整体而不是独立处理多个输入。我们的广泛实验表明，S3IM可以减少TensoRF和DVGO的测试MSE损失超过90%，并且 NeuS 的F-score提高198%，Chamfer $L_{1}$ 距离减少64%。此外，S3IM还能够在缺少输入、损坏图像和动态场景下保持稳定性。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-Physics-Informed-Neural-Network-for-the-Forward-and-Inverse-Simulation-of-Engineered-Nano-particles-Mobility-in-a-Contaminated-Aquifer"><a href="#Bayesian-Physics-Informed-Neural-Network-for-the-Forward-and-Inverse-Simulation-of-Engineered-Nano-particles-Mobility-in-a-Contaminated-Aquifer" class="headerlink" title="Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer"></a>Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07352">http://arxiv.org/abs/2308.07352</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikhar Nilabh, Fidel Grandia</li>
<li>For: This paper aims to develop a predictive tool for the mobility of engineered nanoparticles (ENPs) in groundwater, to support the development of an efficient remediation strategy for polluted groundwater sites.* Methods: The paper uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the mobility of ENPs within an aquifer, and to quantify the uncertainty in the predictions.* Results: The forward model demonstrates the effective capability of B-PINN in accurately predicting the ENPs mobility, and the inverse model output is used to predict the governing parameters for the ENPs mobility in a small-scale aquifer. The research demonstrates the capability of the tool to provide predictive insights for developing an efficient groundwater remediation strategy.Here’s the Chinese translation of the three key information points:* For: 这篇论文的目的是为了开发一种能够预测Engineered Nanoparticles（ENPs）在地下水中的移动性，以支持污染地下水站的清理和环境重建。* Methods: 这篇论文使用了一种 Bayesian Physics-Informed Neural Network（B-PINN）框架，来模拟ENPs在aquifer中的移动性，并量化预测结果的不确定性。* Results: 前向模型表明B-PINN在准确预测ENPs移动性的能力，而反向模型输出可以用来预测aquifer中ENPs移动性的主导参数。这项研究 demonstarte了这种工具的能力，可以为开发有效的地下水清理策略提供预测性的信息。<details>
<summary>Abstract</summary>
Globally, there are many polluted groundwater sites that need an active remediation plan for the restoration of local ecosystem and environment. Engineered nanoparticles (ENPs) have proven to be an effective reactive agent for the in-situ degradation of pollutants in groundwater. While the performance of these ENPs has been highly promising on the laboratory scale, their application in real field case conditions is still limited. The complex transport and retention mechanisms of ENPs hinder the development of an efficient remediation strategy. Therefore, a predictive tool to comprehend the transport and retention behavior of ENPs is highly required. The existing tools in the literature are dominated with numerical simulators, which have limited flexibility and accuracy in the presence of sparse datasets and the aquifer heterogeneity. This work uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the nano-particles mobility within an aquifer. The result from the forward model demonstrates the effective capability of B-PINN in accurately predicting the ENPs mobility and quantifying the uncertainty. The inverse model output is then used to predict the governing parameters for the ENPs mobility in a small-scale aquifer. The research demonstrates the capability of the tool to provide predictive insights for developing an efficient groundwater remediation strategy.
</details>
<details>
<summary>摘要</summary>
全球有很多污染的地下水点，需要有效的活动整治计划以恢复当地生态环境。工程化的奈米颗粒（ENPs）在地下水中的吸附和分解作用已经在室内实验室中得到了证明，但是在实际场景中的应用仍然受限。奈米颗粒的复杂的运输和保持机制限制了整治策略的发展。因此，一个可预测奈米颗粒的运输和保持行为的工具是非常重要。现有的文献中的工具主要是数值模拟器，它们在缺乏数据和地下水异常性时的灵活性和准确性受到限制。本研究使用泛函神经网络（B-PINN）框架来模拟奈米颗粒在aquifer中的 mobilidad。前向模型的输出结果表明B-PINN在准确预测奈米颗粒 mobilidad和评估不确定性的能力。逆向模型输出被用来预测 governing parameters 的奈米颗粒 mobilidad在小规模 aquifer 中。研究表明工具的可预测性可以为开发有效的地下水整治策略提供先进的预测性 Insight。
</details></li>
</ul>
<hr>
<h2 id="IOB-Integrating-Optimization-Transfer-and-Behavior-Transfer-for-Multi-Policy-Reuse"><a href="#IOB-Integrating-Optimization-Transfer-and-Behavior-Transfer-for-Multi-Policy-Reuse" class="headerlink" title="IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse"></a>IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07351">http://arxiv.org/abs/2308.07351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyuan Li, Hao Li, Jin Zhang, Zhen Wang, Peng Liu, Chongjie Zhang</li>
<li>for: 本研究旨在提出一种新的转移学习RL方法，以便在新任务上快速解决问题。</li>
<li>methods: 本方法使用actor-critic框架中的Q函数来导引策略选择，选择最大一步改进策略作为目标策略。我们同时实现了优化转移和行为转移（IOB），通过规范学习策略以便模仿指导策略，并将其与行为策略相结合。</li>
<li>results: 我们的方法在标准任务上超越了状态之前的转移RL基准值，并在连续学习场景中提高了最终性和知识传递性。此外，我们证明了我们的优化转移技术可以提高目标策略学习。<details>
<summary>Abstract</summary>
Humans have the ability to reuse previously learned policies to solve new tasks quickly, and reinforcement learning (RL) agents can do the same by transferring knowledge from source policies to a related target task. Transfer RL methods can reshape the policy optimization objective (optimization transfer) or influence the behavior policy (behavior transfer) using source policies. However, selecting the appropriate source policy with limited samples to guide target policy learning has been a challenge. Previous methods introduce additional components, such as hierarchical policies or estimations of source policies' value functions, which can lead to non-stationary policy optimization or heavy sampling costs, diminishing transfer effectiveness. To address this challenge, we propose a novel transfer RL method that selects the source policy without training extra components. Our method utilizes the Q function in the actor-critic framework to guide policy selection, choosing the source policy with the largest one-step improvement over the current target policy. We integrate optimization transfer and behavior transfer (IOB) by regularizing the learned policy to mimic the guidance policy and combining them as the behavior policy. This integration significantly enhances transfer effectiveness, surpasses state-of-the-art transfer RL baselines in benchmark tasks, and improves final performance and knowledge transferability in continual learning scenarios. Additionally, we show that our optimization transfer technique is guaranteed to improve target policy learning.
</details>
<details>
<summary>摘要</summary>
人类具有 reuse previously learned policies 来解决新任务的能力，同时 reinforcement learning (RL) 代理也可以通过将知识传递到相关的目标任务中来实现这一点。传输 RL 方法可以改变政策优化目标（优化传输）或者影响行为政策（行为传输）使用源政策。然而，在有限样本情况下选择合适的源政策是一大挑战。先前的方法可能会添加额外的组件，如层次政策或源政策价值函数的估计，这可能会导致非站点政策优化或者大量的样本成本，这将导致传输效果减退。为解决这个挑战，我们提出了一种新的传输 RL 方法，不需要训练额外的组件。我们利用 actor-critic 框架中的 Q 函数来导引政策选择，选择目标政策中一步改进最大的源政策。我们将优化传输和行为传输（IOB）相结合，通过规则化学习的政策来模仿指导政策，并将其与行为政策相结合。这种结合显著提高了传输效果，超越了基eline的传输 RL 标准 benchmark 任务，并在连续学习场景中提高了最终性和知识传递性。此外，我们证明了我们的优化传输技术能够提高目标政策学习。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Neural-PDE-Solvers-using-Quantization-Aware-Training"><a href="#Efficient-Neural-PDE-Solvers-using-Quantization-Aware-Training" class="headerlink" title="Efficient Neural PDE-Solvers using Quantization Aware Training"></a>Efficient Neural PDE-Solvers using Quantization Aware Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07350">http://arxiv.org/abs/2308.07350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Winfried van den Dool, Tijmen Blankevoort, Max Welling, Yuki M. Asano</li>
<li>for: 用 neural networks 代替经典数学方法解决 Partial Differential Equations (PDEs) 的应用，以减少计算成本。</li>
<li>methods: 使用现有的量化方法来降低计算成本，并保持性能。</li>
<li>results: 在四个标准 PDE 数据集和三个网络架构上，发现量化训练可以降低计算成本三个数量级，而且在不同设置下都能够保持性能。此外，我们还证明了在大多数情况下，只有通过包含量化来达到 Pareto 优化。<details>
<summary>Abstract</summary>
In the past years, the application of neural networks as an alternative to classical numerical methods to solve Partial Differential Equations has emerged as a potential paradigm shift in this century-old mathematical field. However, in terms of practical applicability, computational cost remains a substantial bottleneck. Classical approaches try to mitigate this challenge by limiting the spatial resolution on which the PDEs are defined. For neural PDE solvers, we can do better: Here, we investigate the potential of state-of-the-art quantization methods on reducing computational costs. We show that quantizing the network weights and activations can successfully lower the computational cost of inference while maintaining performance. Our results on four standard PDE datasets and three network architectures show that quantization-aware training works across settings and three orders of FLOPs magnitudes. Finally, we empirically demonstrate that Pareto-optimality of computational cost vs performance is almost always achieved only by incorporating quantization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-to-Optimize-LSM-trees-Towards-A-Reinforcement-Learning-based-Key-Value-Store-for-Dynamic-Workloads"><a href="#Learning-to-Optimize-LSM-trees-Towards-A-Reinforcement-Learning-based-Key-Value-Store-for-Dynamic-Workloads" class="headerlink" title="Learning to Optimize LSM-trees: Towards A Reinforcement Learning based Key-Value Store for Dynamic Workloads"></a>Learning to Optimize LSM-trees: Towards A Reinforcement Learning based Key-Value Store for Dynamic Workloads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07013">http://arxiv.org/abs/2308.07013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingheng Mo, Fanchao Chen, Siqiang Luo, Caihua Shan</li>
<li>For: 提高静态负荷下的系统性能，即使面临动态负荷。* Methods: 使用Reinforcement Learning（RL）引导LSM树转换，并提出了一种新的LSM树结构（FLSM树）以优化压缩策略的转换。* Results: 比较RL和传统的方法，RusKey在多种负荷下显示了4倍的终端性能优势，而无需先知工作负荷知识。<details>
<summary>Abstract</summary>
LSM-trees are widely adopted as the storage backend of key-value stores. However, optimizing the system performance under dynamic workloads has not been sufficiently studied or evaluated in previous work. To fill the gap, we present RusKey, a key-value store with the following new features: (1) RusKey is a first attempt to orchestrate LSM-tree structures online to enable robust performance under the context of dynamic workloads; (2) RusKey is the first study to use Reinforcement Learning (RL) to guide LSM-tree transformations; (3) RusKey includes a new LSM-tree design, named FLSM-tree, for an efficient transition between different compaction policies -- the bottleneck of dynamic key-value stores. We justify the superiority of the new design with theoretical analysis; (4) RusKey requires no prior workload knowledge for system adjustment, in contrast to state-of-the-art techniques. Experiments show that RusKey exhibits strong performance robustness in diverse workloads, achieving up to 4x better end-to-end performance than the RocksDB system under various settings.
</details>
<details>
<summary>摘要</summary>
LSM树是键值存储系统的常用后端存储方式。然而，在动态负荷下优化系统性能尚未得到充分研究和评估。为填补这一空白，我们提出了RusKey，一个具有以下新特点的键值存储系统：1. RusKey是首次在线上调度LSM树结构，以实现对动态负荷下的robust性表现;2. RusKey是首次使用强化学习（RL）引导LSM树转换;3. RusKey包含一种新的LSM树设计，名为FLSM树，用于高效地在不同压缩策略之间进行过渡;4. RusKey不需要先知工作负荷信息，与当前技术相比，更加灵活和易用。我们通过理论分析证明了新设计的优越性。实验结果显示，RusKey在多种工作负荷下表现出强大的性能稳定性，与RocksDB系统在不同设置下达到4倍的终端性能。
</details></li>
</ul>
<hr>
<h2 id="Greedy-online-change-point-detection"><a href="#Greedy-online-change-point-detection" class="headerlink" title="Greedy online change point detection"></a>Greedy online change point detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07012">http://arxiv.org/abs/2308.07012</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jou-Hui Ho, Felipe Tobar</li>
<li>for: 寻找时间序列中的变化点，以提高变化点检测的准确率和效率。</li>
<li>methods: 使用Greedy Online Change Point Detection（GOCPD）方法，该方法通过最大化数据来自两个独立模型（temporal）的概率来找到变化点。</li>
<li>results: 在synthetic数据和实际世界单variate和多variate设置中，GOCPD方法能够快速减少false discovery rate，并且在某些情况下比传统方法更高效。<details>
<summary>Abstract</summary>
Standard online change point detection (CPD) methods tend to have large false discovery rates as their detections are sensitive to outliers. To overcome this drawback, we propose Greedy Online Change Point Detection (GOCPD), a computationally appealing method which finds change points by maximizing the probability of the data coming from the (temporal) concatenation of two independent models. We show that, for time series with a single change point, this objective is unimodal and thus CPD can be accelerated via ternary search with logarithmic complexity. We demonstrate the effectiveness of GOCPD on synthetic data and validate our findings on real-world univariate and multivariate settings.
</details>
<details>
<summary>摘要</summary>
常规在线变点检测（CPD）方法通常会有较大的假阳性率，因为它们对异常值敏感。为了解决这个缺点，我们提议了简单在线变点检测（GOCPD）方法，它通过最大化数据来自两个独立模型（时间排序）的概率来检测变点。我们证明，对具有单个变点的时间序列，这个目标函数是单峰型，因此可以通过三元搜索来加速CPD，其复杂度为幂函数。我们在 sintetic 数据上证明了 GOCPD 的有效性，并在实际的单VAR 和多VAR 设置中验证了我们的结论。
</details></li>
</ul>
<hr>
<h2 id="Aggregating-Intrinsic-Information-to-Enhance-BCI-Performance-through-Federated-Learning"><a href="#Aggregating-Intrinsic-Information-to-Enhance-BCI-Performance-through-Federated-Learning" class="headerlink" title="Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning"></a>Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11636">http://arxiv.org/abs/2308.11636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Liu, Yuanyuan Chen, Anran Li, Yi Ding, Han Yu, Cuntai Guan<br>for: 这个研究旨在解决脑computer interfaces（BCI）建立高性能深度学习模型的长期挑战， BCIs 的数据多样性问题。methods: 这个研究提出了一个弹性联边学习（FLEEG）框架，让不同装备的数据可以在训练过程中合作。每个客户端都有自己的特定数据集，并训练一个层次化的专门化模型，以处理不同的数据格式。服务器则处理训练过程，将来自所有数据集的知识融合，以提高总性能。results: 这个框架在脑意图（MI）分类任务中，与9个由不同设备收集的EEG数据集合作，可以提高分类性能达16.7%。可视化结果显示，提案的框架可以让本地模型专注在任务相关的区域，从而获得更好的性能。<details>
<summary>Abstract</summary>
Insufficient data is a long-standing challenge for Brain-Computer Interface (BCI) to build a high-performance deep learning model. Though numerous research groups and institutes collect a multitude of EEG datasets for the same BCI task, sharing EEG data from multiple sites is still challenging due to the heterogeneity of devices. The significance of this challenge cannot be overstated, given the critical role of data diversity in fostering model robustness. However, existing works rarely discuss this issue, predominantly centering their attention on model training within a single dataset, often in the context of inter-subject or inter-session settings. In this work, we propose a hierarchical personalized Federated Learning EEG decoding (FLEEG) framework to surmount this challenge. This innovative framework heralds a new learning paradigm for BCI, enabling datasets with disparate data formats to collaborate in the model training process. Each client is assigned a specific dataset and trains a hierarchical personalized model to manage diverse data formats and facilitate information exchange. Meanwhile, the server coordinates the training procedure to harness knowledge gleaned from all datasets, thus elevating overall performance. The framework has been evaluated in Motor Imagery (MI) classification with nine EEG datasets collected by different devices but implementing the same MI task. Results demonstrate that the proposed frame can boost classification performance up to 16.7% by enabling knowledge sharing between multiple datasets, especially for smaller datasets. Visualization results also indicate that the proposed framework can empower the local models to put a stable focus on task-related areas, yielding better performance. To the best of our knowledge, this is the first end-to-end solution to address this important challenge.
</details>
<details>
<summary>摘要</summary>
BCIs 长期面临不充分数据的挑战，建立高性能深度学习模型困难。虽然许多研究机构和机构收集了多个 EEG 数据集，但是共享多个站点的 EEG 数据仍然困难，主要因为设备的不一致性。这个挑战的重要性无法被过度估计，因为数据多样性对模型的稳定性具有关键作用。然而，现有的研究很少讨论这个问题，通常是在单个数据集内进行模型训练，常在 между subject 或 session 上下文中进行。在这种情况下，我们提出了一种层次个性化 Federated Learning EEG 解码（FLEEG）框架，以解决这个挑战。这种创新的框架标志着 BCIs 新的学习模式，使得不同数据格式的数据集可以在模型训练过程中合作。每个客户端被分配特定数据集，并训练一个层次个性化模型，以处理多个数据格式的多样性，并且促进信息交换。同时，服务器协调训练过程，以利用所有数据集中所获得的知识，从而提高整体性能。我们在 Motor Imagery（MI） 分类任务中使用了 nine EEG 数据集，每个数据集由不同的设备收集，但都实现了相同的 MI 任务。结果表明，我们的框架可以提高分类性能达到 16.7%，尤其是对小数据集的提高。可视化结果还表明，我们的框架可以让本地模型固定焦点于任务相关区域，从而提高性能。到目前为止，我们的解决方案是 BCIs 首次尝试的综合解决方案。
</details></li>
</ul>
<hr>
<h2 id="Deep-convolutional-neural-networks-for-cyclic-sensor-data"><a href="#Deep-convolutional-neural-networks-for-cyclic-sensor-data" class="headerlink" title="Deep convolutional neural networks for cyclic sensor data"></a>Deep convolutional neural networks for cyclic sensor data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06987">http://arxiv.org/abs/2308.06987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Payman Goodarzi, Yannick Robin, Andreas Schütze, Tizian Schneider</li>
<li>for: 本研究旨在探讨基于感测器的维保维护，并应用深度学习技术来解决多感测器系统中的复杂性问题。</li>
<li>methods: 本研究使用了一个 hidraulic system testbed dataset，并比较了三个模型的性能：基线模型使用了 conventional methods，单个CNN模型使用了 early sensor fusion，并且二路CNN模型（2L-CNN）使用了 late sensor fusion。</li>
<li>results: 基线模型使用了 late sensor fusion，可以达到1%的测试错误率，但CNN模型由于感测器的多样性而遇到了问题，导致测试错误率达到20.5%。此外，我们还进行了每感测器都进行独立的训练，并观察到了几个感测器的准确率变化。此外，2L-CNN模型的性能表现了显著的改善，当考虑了最佳和最差的感测器时，错误率下降了33%。本研究重申了多感测器系统中的复杂性问题需要有效地解决。<details>
<summary>Abstract</summary>
Predictive maintenance plays a critical role in ensuring the uninterrupted operation of industrial systems and mitigating the potential risks associated with system failures. This study focuses on sensor-based condition monitoring and explores the application of deep learning techniques using a hydraulic system testbed dataset. Our investigation involves comparing the performance of three models: a baseline model employing conventional methods, a single CNN model with early sensor fusion, and a two-lane CNN model (2L-CNN) with late sensor fusion. The baseline model achieves an impressive test error rate of 1% by employing late sensor fusion, where feature extraction is performed individually for each sensor. However, the CNN model encounters challenges due to the diverse sensor characteristics, resulting in an error rate of 20.5%. To further investigate this issue, we conduct separate training for each sensor and observe variations in accuracy. Additionally, we evaluate the performance of the 2L-CNN model, which demonstrates significant improvement by reducing the error rate by 33% when considering the combination of the least and most optimal sensors. This study underscores the importance of effectively addressing the complexities posed by multi-sensor systems in sensor-based condition monitoring.
</details>
<details>
<summary>摘要</summary>
预测维护在产业系统不间断运行和降低系统故障风险的角色非常重要。本研究使用液压系统测试 datasets 进行探索，并应用深度学习技术进行condition monitoring。我们的调查包括比较三种模型的性能：基eline模型使用 convent ional 方法、单个CNN模型（1L-CNN）在早期整合感知器、以及两个CNN模型（2L-CNN）在晚期整合感知器。基eline模型通过使用晚期整合，实现了1%的测试错误率。然而，CNN模型由于感知器的多样性，导致20.5%的错误率。为了进一步调查这一问题，我们进行了每个感知器分别进行训练，并观察了准确性的变化。此外，我们还评估了2L-CNN模型的性能，其在考虑最佳和最差的感知器组合时显示了33%的下降。这一研究强调了condition monitoring中多感知器系统的复杂性需要得到有效地处理。
</details></li>
</ul>
<hr>
<h2 id="pNNCLR-Stochastic-Pseudo-Neighborhoods-for-Contrastive-Learning-based-Unsupervised-Representation-Learning-Problems"><a href="#pNNCLR-Stochastic-Pseudo-Neighborhoods-for-Contrastive-Learning-based-Unsupervised-Representation-Learning-Problems" class="headerlink" title="pNNCLR: Stochastic Pseudo Neighborhoods for Contrastive Learning based Unsupervised Representation Learning Problems"></a>pNNCLR: Stochastic Pseudo Neighborhoods for Contrastive Learning based Unsupervised Representation Learning Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06983">http://arxiv.org/abs/2308.06983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Momojit Biswas, Himanshu Buckchash, Dilip K. Prasad</li>
<li>for: 本文是为了提高 nearest neighbor 基于自助学习（SSL）的图像识别问题的表现而写的。</li>
<li>methods: 本文使用 nearest neighbor 方法，并引入 pseudo nearest neighbors (pNN) 来控制支持集质量，以提高表现。 另外，文中还使用了一种抽样策略和一种平滑重量更新策略来稳定 nearest neighbor 基于学习的uncertainty。</li>
<li>results: 根据文中的评估结果，提出的方法与基eline nearest neighbor 方法相比，在多个公共图像识别和医学图像识别 dataset 上表现出了8%的提升。此外，该方法与其他之前提出的 SSL 方法相比也具有相似的表现。<details>
<summary>Abstract</summary>
Nearest neighbor (NN) sampling provides more semantic variations than pre-defined transformations for self-supervised learning (SSL) based image recognition problems. However, its performance is restricted by the quality of the support set, which holds positive samples for the contrastive loss. In this work, we show that the quality of the support set plays a crucial role in any nearest neighbor based method for SSL. We then provide a refined baseline (pNNCLR) to the nearest neighbor based SSL approach (NNCLR). To this end, we introduce pseudo nearest neighbors (pNN) to control the quality of the support set, wherein, rather than sampling the nearest neighbors, we sample in the vicinity of hard nearest neighbors by varying the magnitude of the resultant vector and employing a stochastic sampling strategy to improve the performance. Additionally, to stabilize the effects of uncertainty in NN-based learning, we employ a smooth-weight-update approach for training the proposed network. Evaluation of the proposed method on multiple public image recognition and medical image recognition datasets shows that it performs up to 8 percent better than the baseline nearest neighbor method, and is comparable to other previously proposed SSL methods.
</details>
<details>
<summary>摘要</summary>
近邻采样（NN）提供了更多的 semantic variation than pre-defined transformation for self-supervised learning（SSL）based image recognition problems. However, its performance is restricted by the quality of the support set, which holds positive samples for the contrastive loss. In this work, we show that the quality of the support set plays a crucial role in any nearest neighbor based method for SSL. We then provide a refined baseline（pNNCLR）to the nearest neighbor based SSL approach（NNCLR）. To this end, we introduce pseudo nearest neighbors（pNN）to control the quality of the support set, wherein, rather than sampling the nearest neighbors, we sample in the vicinity of hard nearest neighbors by varying the magnitude of the resultant vector and employing a stochastic sampling strategy to improve the performance. Additionally, to stabilize the effects of uncertainty in NN-based learning, we employ a smooth-weight-update approach for training the proposed network. Evaluation of the proposed method on multiple public image recognition and medical image recognition datasets shows that it performs up to 8 percent better than the baseline nearest neighbor method, and is comparable to other previously proposed SSL methods.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Routing-Recovery-for-UAV-Networks-with-Deliberate-Attacks-A-Reinforcement-Learning-based-Approach"><a href="#Routing-Recovery-for-UAV-Networks-with-Deliberate-Attacks-A-Reinforcement-Learning-based-Approach" class="headerlink" title="Routing Recovery for UAV Networks with Deliberate Attacks: A Reinforcement Learning based Approach"></a>Routing Recovery for UAV Networks with Deliberate Attacks: A Reinforcement Learning based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06973">http://arxiv.org/abs/2308.06973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sijie He, Ziye Jia, Chao Dong, Wei Wang, Yilu Cao, Yang Yang, Qihui Wu</li>
<li>for: 本文关注在无人航空器（UAV）网络中的路由计划和恢复，以解决UAV网络受到意外攻击的问题。</li>
<li>methods: 本文提出了一种基于节点重要性的攻击模型，并设计了一种节点重要性排名机制，考虑了节点和链接重要性。此外，本文还提出了一种基于强化学习的智能算法，以恢复UAV网络中的路由路径当UAVs被攻击。</li>
<li>results: 数据 simulate 结果表明，提出的机制比其他相关方法更为有效。<details>
<summary>Abstract</summary>
The unmanned aerial vehicle (UAV) network is popular these years due to its various applications. In the UAV network, routing is significantly affected by the distributed network topology, leading to the issue that UAVs are vulnerable to deliberate damage. Hence, this paper focuses on the routing plan and recovery for UAV networks with attacks. In detail, a deliberate attack model based on the importance of nodes is designed to represent enemy attacks. Then, a node importance ranking mechanism is presented, considering the degree of nodes and link importance. However, it is intractable to handle the routing problem by traditional methods for UAV networks, since link connections change with the UAV availability. Hence, an intelligent algorithm based on reinforcement learning is proposed to recover the routing path when UAVs are attacked. Simulations are conducted and numerical results verify the proposed mechanism performs better than other referred methods.
</details>
<details>
<summary>摘要</summary>
“无人航空器（UAV）网络在近年得到广泛应用，但是它们的路由却受到分布网络架构的影响，导致UAV易受到意外攻击。因此，本文关注于UAV网络路由规划和恢复，并对攻击后路由路径的恢复进行了研究。具体来说，我们设计了一种基于节点重要性的攻击模型，并提出了一种考虑节点度和链接重要性的节点重要性排名机制。然而，由于UAV网络中链接的连接变化，传统方法无法有效地处理UAV网络的路由问题。因此，我们提出了一种基于强化学习算法的智能路由恢复方法，以恢复在攻击后的路由路径。我们通过实验和数值结果发现，提议的机制在攻击后路由恢复方面表现更好 than其他已知方法。”Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="AutoAssign-Automatic-Shared-Embedding-Assignment-in-Streaming-Recommendation"><a href="#AutoAssign-Automatic-Shared-Embedding-Assignment-in-Streaming-Recommendation" class="headerlink" title="AutoAssign+: Automatic Shared Embedding Assignment in Streaming Recommendation"></a>AutoAssign+: Automatic Shared Embedding Assignment in Streaming Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06965">http://arxiv.org/abs/2308.06965</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Applied-Machine-Learning-Lab/AutoAssign-Plus">https://github.com/Applied-Machine-Learning-Lab/AutoAssign-Plus</a></li>
<li>paper_authors: Ziru Liu, Kecheng Chen, Fengyi Song, Bo Chen, Xiangyu Zhao, Huifeng Guo, Ruiming Tang</li>
<li>for: addressing new user IDs or item IDs in streaming recommender systems</li>
<li>methods: utilizes reinforcement learning-driven framework with an Identity Agent and critic network to dynamically determine shared embeddings and retain&#x2F;eliminate ID features</li>
<li>results: significantly enhances recommendation performance and reduces memory usage by approximately 20-30%<details>
<summary>Abstract</summary>
In the domain of streaming recommender systems, conventional methods for addressing new user IDs or item IDs typically involve assigning initial ID embeddings randomly. However, this practice results in two practical challenges: (i) Items or users with limited interactive data may yield suboptimal prediction performance. (ii) Embedding new IDs or low-frequency IDs necessitates consistently expanding the embedding table, leading to unnecessary memory consumption. In light of these concerns, we introduce a reinforcement learning-driven framework, namely AutoAssign+, that facilitates Automatic Shared Embedding Assignment Plus. To be specific, AutoAssign+ utilizes an Identity Agent as an actor network, which plays a dual role: (i) Representing low-frequency IDs field-wise with a small set of shared embeddings to enhance the embedding initialization, and (ii) Dynamically determining which ID features should be retained or eliminated in the embedding table. The policy of the agent is optimized with the guidance of a critic network. To evaluate the effectiveness of our approach, we perform extensive experiments on three commonly used benchmark datasets. Our experiment results demonstrate that AutoAssign+ is capable of significantly enhancing recommendation performance by mitigating the cold-start problem. Furthermore, our framework yields a reduction in memory usage of approximately 20-30%, verifying its practical effectiveness and efficiency for streaming recommender systems.
</details>
<details>
<summary>摘要</summary>
在流媒体推荐系统领域，传统的新用户ID或项目ID处理方法通常是随机分配初始ID embedding。然而，这种做法会导致两个实际挑战：（i）有限交互数据的物品或用户可能会得到下标性的预测性能。（ii）为新ID或低频ID分配 embedding 表需要持续扩展 embedding 表，从而导致不必要的内存浪费。为了解决这些问题，我们提出了一个基于强化学习的框架，即 AutoAssign+。具体来说，AutoAssign+ 使用一个 Identity Agent 作为 actor 网络，该网络在两个角色中发挥作用：（i）通过将低频ID分配到一小set of shared embedding来提高初始化 embedding，并（ii）在 embedding 表中动态确定需要保留或删除的 ID 特征。Policy 网络的优化受到批评网络的指导。为评估我们的方法的效果，我们在三个常用的数据集上进行了广泛的实验。实验结果表明，AutoAssign+ 能够有效解决冷启点问题，并且减少内存使用率约 20-30%，证明我们的方法在流媒体推荐系统中具有实际效果和效率。
</details></li>
</ul>
<hr>
<h2 id="Graph-Structural-Residuals-A-Learning-Approach-to-Diagnosis"><a href="#Graph-Structural-Residuals-A-Learning-Approach-to-Diagnosis" class="headerlink" title="Graph Structural Residuals: A Learning Approach to Diagnosis"></a>Graph Structural Residuals: A Learning Approach to Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06961">http://arxiv.org/abs/2308.06961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Lukas Augustin, Oliver Niggemann</li>
<li>for: 提出了一种新的框架，将模型基于诊断结合深度图结构学习。</li>
<li>methods: 利用数据学习系统的下面结构，并通过两个不同的图邻元矩阵来提供动态观察。</li>
<li>results: 通过实验示范了一种数据驱动的诊断方法的潜在优势。<details>
<summary>Abstract</summary>
Traditional model-based diagnosis relies on constructing explicit system models, a process that can be laborious and expertise-demanding. In this paper, we propose a novel framework that combines concepts of model-based diagnosis with deep graph structure learning. This data-driven approach leverages data to learn the system's underlying structure and provide dynamic observations, represented by two distinct graph adjacency matrices. Our work facilitates a seamless integration of graph structure learning with model-based diagnosis by making three main contributions: (i) redefining the constructs of system representation, observations, and faults (ii) introducing two distinct versions of a self-supervised graph structure learning model architecture and (iii) demonstrating the potential of our data-driven diagnostic method through experiments on a system of coupled oscillators.
</details>
<details>
<summary>摘要</summary>
传统的模型基于诊断方法是通过构建明确的系统模型来进行，这可能是劳动密集且需要专家知识的。在这篇论文中，我们提出了一种新的框架，它结合了模型基于诊断和深度图结构学习的概念。这种数据驱动的方法利用数据来学习系统的下面结构，并提供动态观察结果，表示为两个不同的图邻接矩阵。我们的工作使得图结构学习与模型基于诊断的集成变得自然和简单，我们的主要贡献包括：1. 重新定义系统表示、观察和缺陷的构造2. 提出了两种不同的自我超级VI持模型建立方法3. 通过对振荡器系统进行实验，证明我们的数据驱动诊断方法的潜力。
</details></li>
</ul>
<hr>
<h2 id="Search-to-Fine-tune-Pre-trained-Graph-Neural-Networks-for-Graph-level-Tasks"><a href="#Search-to-Fine-tune-Pre-trained-Graph-Neural-Networks-for-Graph-level-Tasks" class="headerlink" title="Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks"></a>Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06960">http://arxiv.org/abs/2308.06960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhili Wang, Shimin Di, Lei Chen, Xiaofang Zhou</li>
<li>for: 本研究旨在提高预训练GNNs的表现，并设计一种适应性更高的微调策略。</li>
<li>methods: 我们提出了一种基于搜索的微调策略，称为S2PGNN，可以适应不同的下游任务和数据集。</li>
<li>results: 我们在10个著名的预训练GNNs上进行了实验，并证明了S2PGNN可以在不同的下游任务和数据集上提高模型的表现，并且比现有的微调策略更高效。<details>
<summary>Abstract</summary>
Recently, graph neural networks (GNNs) have shown its unprecedented success in many graph-related tasks. However, GNNs face the label scarcity issue as other neural networks do. Thus, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. Despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs to improve the model performance in this paper. Given a pre-trained GNN, we propose to search to fine-tune pre-trained graph neural networks for graph-level tasks (S2PGNN), which adaptively design a suitable fine-tuning framework for the given labeled data on the downstream task. To ensure the improvement brought by searching fine-tuning strategy, we carefully summarize a proper search space of fine-tuning framework that is suitable for GNNs. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance. Besides, S2PGNN achieves better performance than existing fine-tuning strategies within and outside the GNN area. Our code is publicly available at \url{https://anonymous.4open.science/r/code_icde2024-A9CB/}.
</details>
<details>
<summary>摘要</summary>
近些年来，图 нейрон网络（GNNs）在许多图关联任务中显示出前无似的成功。然而，GNNs still faces the label scarcity issue like other neural networks do. Therefore, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. Despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only a few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs to improve the model performance in this paper. Given a pre-trained GNN, we propose to search for a suitable fine-tuning framework for the given labeled data on the downstream task, which we call S2PGNN. To ensure the improvement brought by searching fine-tuning strategy, we carefully summarize a proper search space of fine-tuning framework that is suitable for GNNs. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance. Besides, S2PGNN achieves better performance than existing fine-tuning strategies within and outside the GNN area. Our code is publicly available at [uri].
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Allocation-of-Preventive-Care-With-Application-to-Diabetes-Mellitus-Type-II"><a href="#Data-Driven-Allocation-of-Preventive-Care-With-Application-to-Diabetes-Mellitus-Type-II" class="headerlink" title="Data-Driven Allocation of Preventive Care With Application to Diabetes Mellitus Type II"></a>Data-Driven Allocation of Preventive Care With Application to Diabetes Mellitus Type II</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06959">http://arxiv.org/abs/2308.06959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathias Kraus, Stefan Feuerriegel, Maytal Saar-Tsechansky</li>
<li>for: 这篇论文的目的是为了提出一个可靠的、成本效益的决策模型，用于分配预防性治疗给有风险的病人。</li>
<li>methods: 本论文使用了Counterfactual推理、机器学习和优化技术，搭建了可扩展的决策模型，可以利用现代医疗记录中的高维度医疗数据。</li>
<li>results: 根据89,191名 prediabetic 病人的电子医疗记录进行评估，我们的决策模型可以与现有的实践相比，实现每年的成本储储11亿美元。此外，我们还分析了不同预算水平下的成本效益。<details>
<summary>Abstract</summary>
Problem Definition. Increasing costs of healthcare highlight the importance of effective disease prevention. However, decision models for allocating preventive care are lacking.   Methodology/Results. In this paper, we develop a data-driven decision model for determining a cost-effective allocation of preventive treatments to patients at risk. Specifically, we combine counterfactual inference, machine learning, and optimization techniques to build a scalable decision model that can exploit high-dimensional medical data, such as the data found in modern electronic health records. Our decision model is evaluated based on electronic health records from 89,191 prediabetic patients. We compare the allocation of preventive treatments (metformin) prescribed by our data-driven decision model with that of current practice. We find that if our approach is applied to the U.S. population, it can yield annual savings of $1.1 billion. Finally, we analyze the cost-effectiveness under varying budget levels.   Managerial Implications. Our work supports decision-making in health management, with the goal of achieving effective disease prevention at lower costs. Importantly, our decision model is generic and can thus be used for effective allocation of preventive care for other preventable diseases.
</details>
<details>
<summary>摘要</summary>
问题定义：医疗费用的增长强调了疾病预防的重要性。然而，疾病预防投入决策模型缺失。方法ология/结果：在这篇论文中，我们开发了基于数据驱动的疾病预防投入决策模型，用于确定对患有风险的患者进行成本效果的预防治疗分配。我们结合了Counterfactual推理、机器学习和优化技术，构建了可扩展的决策模型，可以利用现代电子医疗记录中的高维医疗数据。我们的决策模型通过对89191名 prediabetic 患者的电子医疗记录进行评估。我们比较了我们的数据驱动决策模型与当前做法分配预防治疗（metformin）的情况。我们发现，如果我们的方法应用于美国人口，可以每年节省11亿美元。最后，我们分析了不同预算水平下的成本效果。管理意义：我们的工作支持医疗管理决策，以实现有效的疾病预防，并降低成本。重要的是，我们的决策模型是通用的，可以用于有效地分配预防治疗其他预防性疾病。
</details></li>
</ul>
<hr>
<h2 id="CEmb-SAM-Segment-Anything-Model-with-Condition-Embedding-for-Joint-Learning-from-Heterogeneous-Datasets"><a href="#CEmb-SAM-Segment-Anything-Model-with-Condition-Embedding-for-Joint-Learning-from-Heterogeneous-Datasets" class="headerlink" title="CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets"></a>CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06957">http://arxiv.org/abs/2308.06957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongik Shin, Beomsuk Kim, Seungjun Baek</li>
<li>for: 这篇论文是用于探讨如何将不同类型的静脉影像融合为一个共同的数据集，以提高医疗影像分类模型的通用能力。</li>
<li>methods: 这篇论文使用的方法是将不同类型的静脉影像融合为一个共同的数据集，然后使用Segment Anything模型（SAM）来进行静脉影像分类。此外，论文还提出了一个名为Condition Embedding block（CEmb）的新方法，可以将不同数据集的特性统计学 Normalization。</li>
<li>results: 实验结果显示，CEmb-SAM比基eline方法在静脉影像分类 задачі中表现更好，特别是在 péripheral nerves和breast cancer领域。这些结果显示了Cemb-SAM在医疗影像分类任务中学习不同数据集的能力。<details>
<summary>Abstract</summary>
Automated segmentation of ultrasound images can assist medical experts with diagnostic and therapeutic procedures. Although using the common modality of ultrasound, one typically needs separate datasets in order to segment, for example, different anatomical structures or lesions with different levels of malignancy. In this paper, we consider the problem of jointly learning from heterogeneous datasets so that the model can improve generalization abilities by leveraging the inherent variability among datasets. We merge the heterogeneous datasets into one dataset and refer to each component dataset as a subgroup. We propose to train a single segmentation model so that the model can adapt to each sub-group. For robust segmentation, we leverage recently proposed Segment Anything model (SAM) in order to incorporate sub-group information into the model. We propose SAM with Condition Embedding block (CEmb-SAM) which encodes sub-group conditions and combines them with image embeddings from SAM. The conditional embedding block effectively adapts SAM to each image sub-group by incorporating dataset properties through learnable parameters for normalization. Experiments show that CEmb-SAM outperforms the baseline methods on ultrasound image segmentation for peripheral nerves and breast cancer. The experiments highlight the effectiveness of Cemb-SAM in learning from heterogeneous datasets in medical image segmentation tasks.
</details>
<details>
<summary>摘要</summary>
自动分割超音波图像可以帮助医疗专家进行诊断和治疗过程。although using the common modality of ultrasound, one typically needs separate datasets in order to segment, for example, different anatomical structures or lesions with different levels of malignancy. 在这篇论文中，我们考虑了将异构数据集合在一起，以便模型可以提高通用能力，并且可以利用数据集的内在多样性。我们将异构数据集合为一个数据集，并将每个子组数据集称为子组。我们提议使用单个分割模型，以便模型可以适应每个子组。为了增强分割稳定性，我们利用最近提出的 Segment Anything model (SAM)，并在SAM中添加 Condition Embedding block (CEmb)，以编码子组条件并与图像嵌入结合。 conditional embedding block Effectively adapts SAM to each image subgroup by incorporating dataset properties through learnable parameters for normalization. 实验显示，CEmb-SAM在超音波图像分割任务中超过基eline方法表现，特别是在 péripheral nerves 和乳腺癌中。这些实验证明了 CEmb-SAM 在医学图像分割任务中学习异构数据集的有效性。
</details></li>
</ul>
<hr>
<h2 id="Channel-Wise-Contrastive-Learning-for-Learning-with-Noisy-Labels"><a href="#Channel-Wise-Contrastive-Learning-for-Learning-with-Noisy-Labels" class="headerlink" title="Channel-Wise Contrastive Learning for Learning with Noisy Labels"></a>Channel-Wise Contrastive Learning for Learning with Noisy Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06952">http://arxiv.org/abs/2308.06952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Kang, Sheng Liu, Huaxi Huang, Tongliang Liu</li>
<li>for: 本文针对受损标签学习（LNL）问题，旨在训练一个能够识别实际类别的分类器。</li>
<li>methods: 本文提出了通道级别对比学习（CWCL）方法，通过对不同通道进行对比学习，分离真实标签信息和噪声。</li>
<li>results: 对多个基准数据集进行评估，本文的方法与现有方法相比，具有更高的识别率和更好的抗噪声性。<details>
<summary>Abstract</summary>
In real-world datasets, noisy labels are pervasive. The challenge of learning with noisy labels (LNL) is to train a classifier that discerns the actual classes from given instances. For this, the model must identify features indicative of the authentic labels. While research indicates that genuine label information is embedded in the learned features of even inaccurately labeled data, it's often intertwined with noise, complicating its direct application. Addressing this, we introduce channel-wise contrastive learning (CWCL). This method distinguishes authentic label information from noise by undertaking contrastive learning across diverse channels. Unlike conventional instance-wise contrastive learning (IWCL), CWCL tends to yield more nuanced and resilient features aligned with the authentic labels. Our strategy is twofold: firstly, using CWCL to extract pertinent features to identify cleanly labeled samples, and secondly, progressively fine-tuning using these samples. Evaluations on several benchmark datasets validate our method's superiority over existing approaches.
</details>
<details>
<summary>摘要</summary>
实际数据集中，噪声标签是普遍存在的。学习噪声标签（LNL）的挑战是训练一个可以从给定的实例中分辨实际的类别的分类器。为此，模型必须标识表示实际标签的特征。虽然研究表明，正确的标签信息在噪声标签的数据中被学习的特征中嵌入，但它通常与噪声杂mix在一起，使其直接应用更加复杂。为解决这个问题，我们引入通道wise contrastive learning（CWCL）。这种方法通过在多个通道进行对比学习来 отличи出实际标签信息和噪声。与传统的实例wise contrastive learning（IWCL）不同，CWCL往往可以生成更加细化和鲜明的特征，与实际标签更加相似。我们的策略是两重的：首先，使用CWCL提取重要的特征，以便从干净标注的样本中分辨实际标签信息；其次，逐渐练化使用这些样本。我们在多个标准 benchmark 数据集上进行了评估，并证明了我们的方法与现有方法相比具有superiority。
</details></li>
</ul>
<hr>
<h2 id="Knowing-Where-to-Focus-Event-aware-Transformer-for-Video-Grounding"><a href="#Knowing-Where-to-Focus-Event-aware-Transformer-for-Video-Grounding" class="headerlink" title="Knowing Where to Focus: Event-aware Transformer for Video Grounding"></a>Knowing Where to Focus: Event-aware Transformer for Video Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06947">http://arxiv.org/abs/2308.06947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinhyunj/eatr">https://github.com/jinhyunj/eatr</a></li>
<li>paper_authors: Jinhyun Jang, Jungin Park, Jin Kim, Hyeongjun Kwon, Kwanghoon Sohn</li>
<li>for: 这 paper 的目的是提出一种事件意识的动态时刻查询方法，以便模型可以根据输入视频的内容和位置信息来更好地预测时刻。</li>
<li>methods: 这 paper 使用了一种叫做槽注意机制的事件分解技术，以及一种名叫网关融合变换层的时刻查询融合技术，来实现事件意识的动态时刻查询。</li>
<li>results: 根据实验结果，这 paper 的事件意识动态时刻查询方法在多个视频锚点识别 benchmark 上表现出了比州前方法更高的效果和效率。<details>
<summary>Abstract</summary>
Recent DETR-based video grounding models have made the model directly predict moment timestamps without any hand-crafted components, such as a pre-defined proposal or non-maximum suppression, by learning moment queries. However, their input-agnostic moment queries inevitably overlook an intrinsic temporal structure of a video, providing limited positional information. In this paper, we formulate an event-aware dynamic moment query to enable the model to take the input-specific content and positional information of the video into account. To this end, we present two levels of reasoning: 1) Event reasoning that captures distinctive event units constituting a given video using a slot attention mechanism; and 2) moment reasoning that fuses the moment queries with a given sentence through a gated fusion transformer layer and learns interactions between the moment queries and video-sentence representations to predict moment timestamps. Extensive experiments demonstrate the effectiveness and efficiency of the event-aware dynamic moment queries, outperforming state-of-the-art approaches on several video grounding benchmarks.
</details>
<details>
<summary>摘要</summary>
现代基于DETR的录像落幕模型已经直接预测时刻无需任何手工Component，如预先定义的提案或非最大抑制，通过学习时刻查询。然而，这些输入不具预设的时刻查询无法考虑录像的自然时间结构，仅提供有限的位置信息。在本文中，我们提出了事件意识的动态时刻查询，让模型能够根据输入内容和位置信息进行事件对话。为此，我们提出了两种逻辑：1）事件逻辑，使用槽注意力机制来捕捉录像中的特定事件单位；2）时刻逻辑，将时刻查询与输入句子的数据融合，透过闸道融合对应层来学习时刻查询与录像句子表示之间的互动，以预测时刻。实验结果显示了事件意识的动态时刻查询的有效性和高效性，在多个录像落幕 bencmarks 上出perform state-of-the-art 方法。
</details></li>
</ul>
<hr>
<h2 id="Semantic-aware-Network-for-Aerial-to-Ground-Image-Synthesis"><a href="#Semantic-aware-Network-for-Aerial-to-Ground-Image-Synthesis" class="headerlink" title="Semantic-aware Network for Aerial-to-Ground Image Synthesis"></a>Semantic-aware Network for Aerial-to-Ground Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06945">http://arxiv.org/abs/2308.06945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinhyunj/sanet">https://github.com/jinhyunj/sanet</a></li>
<li>paper_authors: Jinhyun Jang, Taeyong Song, Kwanghoon Sohn</li>
<li>for: 这个论文旨在解决飞行图像与地面图像的同构问题，以实现将飞行图像中的元素转映到地面图像中。</li>
<li>methods: 该论文提出了一个新的框架，通过增强结构对应和Semantic意识来解决这个问题。它 introduce了一种新的Semantic-attentive feature transformation模块，可以重建复杂的地理结构。此外，论文还提出了Semantic-aware的损失函数，通过利用预训练的分类网络，让网络synthesize出realistic的对象。</li>
<li>results: 对比之前的方法和简化研究，论文的方法得到了较高的效果， both qualitatively and quantitatively。<details>
<summary>Abstract</summary>
Aerial-to-ground image synthesis is an emerging and challenging problem that aims to synthesize a ground image from an aerial image. Due to the highly different layout and object representation between the aerial and ground images, existing approaches usually fail to transfer the components of the aerial scene into the ground scene. In this paper, we propose a novel framework to explore the challenges by imposing enhanced structural alignment and semantic awareness. We introduce a novel semantic-attentive feature transformation module that allows to reconstruct the complex geographic structures by aligning the aerial feature to the ground layout. Furthermore, we propose semantic-aware loss functions by leveraging a pre-trained segmentation network. The network is enforced to synthesize realistic objects across various classes by separately calculating losses for different classes and balancing them. Extensive experiments including comparisons with previous methods and ablation studies show the effectiveness of the proposed framework both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:空中到地面图像合成是一个emerging和挑战性的问题，目标是将空中图像转换为地面图像。由于空中和地面图像的布局和对象表示方式之间存在巨大差异，现有的方法通常无法将空中场景中的组件转移到地面场景中。在这篇论文中，我们提出了一个新的框架，以强化结构对Alignment和Semantic意识。我们引入了一个新的启发式Semantic-attentive特征转换模块，以将空中特征转换为地面布局。此外，我们提出了Semantic-aware的损失函数，通过利用预训练的分割网络来强制网络在不同类型的对象上synthesize出真实的对象。我们进行了广泛的实验，包括与前方法进行比较和简要的ablation研究，以证明我们的框架的有效性。
</details></li>
</ul>
<hr>
<h2 id="Insurance-pricing-on-price-comparison-websites-via-reinforcement-learning"><a href="#Insurance-pricing-on-price-comparison-websites-via-reinforcement-learning" class="headerlink" title="Insurance pricing on price comparison websites via reinforcement learning"></a>Insurance pricing on price comparison websites via reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06935">http://arxiv.org/abs/2308.06935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanut Treetanthiploet, Yufei Zhang, Lukasz Szpruch, Isaac Bowers-Barnard, Henrietta Ridley, James Hickey, Chris Pearce</li>
<li>for: 本研究旨在为保险公司在价格比较网站（PCW）上形ulation Effective 价格策略提供技术支持。</li>
<li>methods: 本研究使用了强化学习（RL）框架，通过结合模型基于和模型自由方法来学习价格策略。</li>
<li>results: 比较 experiment 表明，我们的方法在sample efficiency和累积奖励方面超过了6个参考方法，只有在市场情况具有完美信息时才能达到相同水平。<details>
<summary>Abstract</summary>
The emergence of price comparison websites (PCWs) has presented insurers with unique challenges in formulating effective pricing strategies. Operating on PCWs requires insurers to strike a delicate balance between competitive premiums and profitability, amidst obstacles such as low historical conversion rates, limited visibility of competitors' actions, and a dynamic market environment. In addition to this, the capital intensive nature of the business means pricing below the risk levels of customers can result in solvency issues for the insurer. To address these challenges, this paper introduces reinforcement learning (RL) framework that learns the optimal pricing policy by integrating model-based and model-free methods. The model-based component is used to train agents in an offline setting, avoiding cold-start issues, while model-free algorithms are then employed in a contextual bandit (CB) manner to dynamically update the pricing policy to maximise the expected revenue. This facilitates quick adaptation to evolving market dynamics and enhances algorithm efficiency and decision interpretability. The paper also highlights the importance of evaluating pricing policies using an offline dataset in a consistent fashion and demonstrates the superiority of the proposed methodology over existing off-the-shelf RL/CB approaches. We validate our methodology using synthetic data, generated to reflect private commercially available data within real-world insurers, and compare against 6 other benchmark approaches. Our hybrid agent outperforms these benchmarks in terms of sample efficiency and cumulative reward with the exception of an agent that has access to perfect market information which would not be available in a real-world set-up.
</details>
<details>
<summary>摘要</summary>
互联网价格比较网站（PCW）的出现对保险公司带来了独特的挑战。在PCW上运营时，保险公司需要维护一个折衔的平衡，以确保竞争力和利润之间的协调。这些挑战包括历史 conversions 率低、竞争对手动作的有限可见性以及动态的市场环境。此外，保险业务具有资本投入的特点，因此低于客户风险水平的价格可能会导致资本问题。为解决这些挑战，本文提出了一种基于强化学习（RL）框架的价格策略优化方法。RL框架结合模型基于和模型自由两种方法，通过在离线环境中训练代理人，避免冷启始问题，然后在Contextual Bandit（CB）上使用模型自由算法动态更新价格策略，以最大化预期收益。这有助于快速适应市场动态变化，提高算法效率和决策可读性。文章还强调了评估价格策略的离线数据集的一致性，并证明提议的方法在已有的RL/CB方法中表现出色。我们验证了方法使用人工生成的数据，模拟了实际保险公司的私人数据，并与6个参考方法进行比较。我们的混合代理人在样本效益和累积奖励方面都超越参考方法，只有具有完美市场信息的代理人能够在实际场景中匹配我们的方法。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Listing-Prices-In-Dynamic-Short-Term-Rental-Markets-Using-Machine-Learning-Models"><a href="#Predicting-Listing-Prices-In-Dynamic-Short-Term-Rental-Markets-Using-Machine-Learning-Models" class="headerlink" title="Predicting Listing Prices In Dynamic Short Term Rental Markets Using Machine Learning Models"></a>Predicting Listing Prices In Dynamic Short Term Rental Markets Using Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06929">http://arxiv.org/abs/2308.06929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sam Chapman, Seifey Mohammad, Kimberly Villegas</li>
<li>for: 预测Airbnb租赁价格，帮助hosts优化收益和助旅行者做出 Informed 预订决策。</li>
<li>methods: 使用机器学习模型方法，包括sentiment分析，对Airbnb租赁价格进行预测和分析。</li>
<li>results: 通过对Airbnb租赁价格进行预测和分析，提高了hosts的收益和旅行者的决策能力。<details>
<summary>Abstract</summary>
Our research group wanted to take on the difficult task of predicting prices in a dynamic market. And short term rentals such as Airbnb listings seemed to be the perfect proving ground to do such a thing. Airbnb has revolutionized the travel industry by providing a platform for homeowners to rent out their properties to travelers. The pricing of Airbnb rentals is prone to high fluctuations, with prices changing frequently based on demand, seasonality, and other factors. Accurate prediction of Airbnb rental prices is crucial for hosts to optimize their revenue and for travelers to make informed booking decisions. In this project, we aim to predict the prices of Airbnb rentals using a machine learning modeling approach.   Our project expands on earlier research in the area of analyzing Airbnb rental prices by taking a methodical machine learning approach as well as incorporating sentiment analysis into our feature engineering. We intend to gain a deeper understanding on periodic changes of Airbnb rental prices. The primary objective of this study is to construct an accurate machine learning model for predicting Airbnb rental prices specifically in Austin, Texas. Our project's secondary objective is to identify the key factors that drive Airbnb rental prices and to investigate how these factors vary across different locations and property types.
</details>
<details>
<summary>摘要</summary>
我们的研究小组想要解决难度较大的价格预测问题，并选择短期租赁如Airbnb列表作为证明场景。Airbnb已经革命化旅游业，提供了为房东租出房屋给旅行者的平台。Airbnb租赁价格受到高度波动的影响，价格随着需求、季节和其他因素而变化频繁。正确预测Airbnb租赁价格对房东来说是提高收益的关键，对旅行者来说也是为了做出 Informed 预订决策。在这个项目中，我们使用机器学习模型预测Airbnb租赁价格。我们的项目在对Airbnb租赁价格分析方面进行了深入探索，并且通过包括情感分析在内的特征工程来扩展我们的研究。我们的主要目标是在得克萨斯州奥斯汀建立一个准确的机器学习模型，用于预测Airbnb租赁价格。项目的次要目标是Identify 租赁价格的关键因素，以及这些因素在不同的地点和财产类型中的变化趋势。
</details></li>
</ul>
<hr>
<h2 id="CBA-Improving-Online-Continual-Learning-via-Continual-Bias-Adaptor"><a href="#CBA-Improving-Online-Continual-Learning-via-Continual-Bias-Adaptor" class="headerlink" title="CBA: Improving Online Continual Learning via Continual Bias Adaptor"></a>CBA: Improving Online Continual Learning via Continual Bias Adaptor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06925">http://arxiv.org/abs/2308.06925</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wqza/cba-online-cl">https://github.com/wqza/cba-online-cl</a></li>
<li>paper_authors: Quanziang Wang, Renzhen Wang, Yichen Wu, Xixi Jia, Deyu Meng</li>
<li>for: 这篇论文目的是为了解决在线上持续学习（Continual Learning，CL）中的分布变化问题，以确保模型能够稳定地学习新的知识和固化先前学习的知识。</li>
<li>methods: 本文提出了一个增强器（Continual Bias Adaptor，CBA）模组，用于在训练过程中将分类器网络调整为适应不断变化的分布，以避免模型对先前学习的知识忘记和偏向新的任务。</li>
<li>results: 本文透过实验证明了CBA模组能够有效地解决分布变化问题，并且不会增加训练过程中的计算成本和记忆遗传。<details>
<summary>Abstract</summary>
Online continual learning (CL) aims to learn new knowledge and consolidate previously learned knowledge from non-stationary data streams. Due to the time-varying training setting, the model learned from a changing distribution easily forgets the previously learned knowledge and biases toward the newly received task. To address this problem, we propose a Continual Bias Adaptor (CBA) module to augment the classifier network to adapt to catastrophic distribution change during training, such that the classifier network is able to learn a stable consolidation of previously learned tasks. In the testing stage, CBA can be removed which introduces no additional computation cost and memory overhead. We theoretically reveal the reason why the proposed method can effectively alleviate catastrophic distribution shifts, and empirically demonstrate its effectiveness through extensive experiments based on four rehearsal-based baselines and three public continual learning benchmarks.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在线 continual learning (CL) 目标是在非站点数据流中学习新知识并固化先前学习的知识。由于训练环境的时间变化，学习到的模型很容易忘记先前学习的知识，偏向新接收的任务。为解决这个问题，我们提议一个 Continual Bias Adaptor (CBA) 模块，用于在训练过程中增强分类网络，以适应不断变化的分布，使得分类网络能够稳定地固化先前学习的任务。在测试阶段，CBA可以被移除，无需额外的计算成本和内存占用。我们理论上解释了我们提议的方法可以有效缓解悬危分布变化的问题，并通过了四种基eline和三个公共 continual learning 标准 benchmark 的实验来证明其效果。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Ehanced-Move-Recognition-Algorithm-Based-on-Pre-trained-Models-with-Positional-Embeddings"><a href="#A-Novel-Ehanced-Move-Recognition-Algorithm-Based-on-Pre-trained-Models-with-Positional-Embeddings" class="headerlink" title="A Novel Ehanced Move Recognition Algorithm Based on Pre-trained Models with Positional Embeddings"></a>A Novel Ehanced Move Recognition Algorithm Based on Pre-trained Models with Positional Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10822">http://arxiv.org/abs/2308.10822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Wen, Jie Wang, Xiaodong Qiao</li>
<li>for: 本研究旨在提高中文科技论文摘要中的 Move 识别精度。</li>
<li>methods: 该研究提出了一种基于改进预训练模型和扩展网络含attend mechanism的新型加强 Move 识别算法。</li>
<li>results: 实验结果显示，该算法在分 Split 数据集上比原始数据集提高13.37%的精度，并与基本对比模型提高7.55%的精度。<details>
<summary>Abstract</summary>
The recognition of abstracts is crucial for effectively locating the content and clarifying the article. Existing move recognition algorithms lack the ability to learn word position information to obtain contextual semantics. This paper proposes a novel enhanced move recognition algorithm with an improved pre-trained model and a gated network with attention mechanism for unstructured abstracts of Chinese scientific and technological papers. The proposed algorithm first performs summary data segmentation and vocabulary training. The EP-ERNIE$\_$AT-GRU framework is leveraged to incorporate word positional information, facilitating deep semantic learning and targeted feature extraction. Experimental results demonstrate that the proposed algorithm achieves 13.37$\%$ higher accuracy on the split dataset than on the original dataset and a 7.55$\%$ improvement in accuracy over the basic comparison model.
</details>
<details>
<summary>摘要</summary>
“抽象概念识别是科技文献检索和理解的关键。现有的移动识别算法无法学习单词位置信息，导致Contextual semantics的学习受限。本文提出了一种基于EP-ERNIE$\_$AT-GRU框架的增强移动识别算法，用于处理中文科技文献抽象。该算法首先进行摘要数据分 segmentation和词汇训练。实验结果表明，提posed算法在分组数据集上的准确率高于原始数据集13.37%，并且与基本比较模型相比提高7.55%。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="CausalLM-is-not-optimal-for-in-context-learning"><a href="#CausalLM-is-not-optimal-for-in-context-learning" class="headerlink" title="CausalLM is not optimal for in-context learning"></a>CausalLM is not optimal for in-context learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06912">http://arxiv.org/abs/2308.06912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Ding, Tomer Levinboim, Jialin Wu, Sebastian Goodman, Radu Soricut</li>
<li>for: 本研究探讨了使用前缀语言模型（prefixLM）和 causalLanguage Model（causalLM）在卷积Transformer上的受限学习性能的比较。</li>
<li>methods: 本研究采用了理论方法来分析prefixLM和causalLM的参数构造下的收敛行为。</li>
<li>results: 研究发现，prefixLM在线性回归问题上 converges to its optimal solution，而causalLM的收敛动态类似于在线梯度下降算法，并不一定是最优解，即使数据量无限大。Empirical experiments over synthetic and real tasks verify that causalLM consistently underperforms prefixLM in all settings。<details>
<summary>Abstract</summary>
Recent empirical evidence indicates that transformer based in-context learning performs better when using a prefix language model (prefixLM), in which in-context samples can all attend to each other, compared to causal language models (causalLM), which use auto-regressive attention that prohibits in-context samples to attend to future samples. While this result is intuitive, it is not understood from a theoretical perspective. In this paper we take a theoretical approach and analyze the convergence behavior of prefixLM and causalLM under a certain parameter construction. Our analysis shows that both LM types converge to their stationary points at a linear rate, but that while prefixLM converges to the optimal solution of linear regression, causalLM convergence dynamics follows that of an online gradient descent algorithm, which is not guaranteed to be optimal even as the number of samples grows infinitely. We supplement our theoretical claims with empirical experiments over synthetic and real tasks and using various types of transformers. Our experiments verify that causalLM consistently underperforms prefixLM in all settings.
</details>
<details>
<summary>摘要</summary>
近期实验证据表明，基于转换器的增强学习在使用前缀语言模型（前缀LM）下表现更好，因为所有的增强样本都可以相互听说，而不使用 causalLM（ causalLM），它使用自动循环注意力，禁止增强样本听说未来的样本。虽然这种结果是直观的，但从理论角度不是很了解。在这篇论文中，我们采取了理论方法，分析了 prefixLM 和 causalLM 下的参数构造下的收敛行为。我们的分析表明，两种LM类型都会在一定的参数构造下收敛到其站点点，但是 prefixLM 会收敛到线性回归的优化解，而 causalLM 的收敛动力则类似于在线上的梯度下降算法，这并不是保证优化的，即使样本数量在无穷大。我们通过实验证明， causalLM 在所有设置下一直表现出下降性。
</details></li>
</ul>
<hr>
<h2 id="GIT-Mol-A-Multi-modal-Large-Language-Model-for-Molecular-Science-with-Graph-Image-and-Text"><a href="#GIT-Mol-A-Multi-modal-Large-Language-Model-for-Molecular-Science-with-Graph-Image-and-Text" class="headerlink" title="GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text"></a>GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06911">http://arxiv.org/abs/2308.06911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengfei Liu, Yiming Ren, Zhixiang Ren</li>
<li>for: 这个论文主要是为了提出一种多ModalLanguage模型，用于融合Graph、Image和Text信息，以提高分子数据的表示和生成能力。</li>
<li>methods: 这种模型使用GIT-Former架构，可以将所有modalities映射到一个共同准则空间中，以便进行多ModalLanguage的表示和计算。</li>
<li>results: 该研究提出了一种创新的任意语言分子翻译策略，提高了分子描述率10%-15%，提高了属性预测精度5%-10%，并提高了分子生成有效性20%。<details>
<summary>Abstract</summary>
Large language models have made significant strides in natural language processing, paving the way for innovative applications including molecular representation and generation. However, most existing single-modality approaches cannot capture the abundant and complex information in molecular data. Here, we introduce GIT-Mol, a multi-modal large language model that integrates the structure Graph, Image, and Text information, including the Simplified Molecular Input Line Entry System (SMILES) and molecular captions. To facilitate the integration of multi-modal molecular data, we propose GIT-Former, a novel architecture capable of mapping all modalities into a unified latent space. Our study develops an innovative any-to-language molecular translation strategy and achieves a 10%-15% improvement in molecular captioning, a 5%-10% accuracy increase in property prediction, and a 20% boost in molecule generation validity compared to baseline or single-modality models.
</details>
<details>
<summary>摘要</summary>
大型语言模型在自然语言处理方面做出了重要进步，开辟了创新应用，如分子表示和生成。然而，现有的单一模式方法无法捕捉分子数据中的丰富和复杂信息。在这里，我们介绍GIT-Mol，一个多模式大语言模型，它结合结构граф、图像和文本信息，包括简单分子输入系统（SMILES）和分子描述。为了实现多modal分子数据的整合，我们提出GIT-Former，一个新的架构，可以将所有模式转换到一个统一的潜在空间中。我们的研究开发了一种创新的任何语言分子翻译策略，并在分子描述、性能预测和分子生成领域中实现了10%-15%的改进，5%-10%的精度提高和20%的额外验证。
</details></li>
</ul>
<hr>
<h2 id="Generative-Interpretation"><a href="#Generative-Interpretation" class="headerlink" title="Generative Interpretation"></a>Generative Interpretation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06907">http://arxiv.org/abs/2308.06907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yonathanarbel/generativeinterpretation">https://github.com/yonathanarbel/generativeinterpretation</a></li>
<li>paper_authors: Yonathan A. Arbel, David Hoffman</li>
<li>for: 这篇论文旨在提出一种新的合同理解方法，使用大型自然语言模型来估计合同意义。</li>
<li>methods: 该论文采用了实践案例研究的方法，通过使用AI模型来查看不同的应用场景，并使用实际的合同文档来证明AI模型的能力。</li>
<li>results: 该论文显示了AI模型可以帮助法官和仲裁人员更好地理解合同的意义，量化含义的混淆度，并填充合同中的缺失。同时，该论文还描述了使用这些模型时的限制和风险，以及它们对法律实践和合同理论的影响。<details>
<summary>Abstract</summary>
We introduce generative interpretation, a new approach to estimating contractual meaning using large language models. As AI triumphalism is the order of the day, we proceed by way of grounded case studies, each illustrating the capabilities of these novel tools in distinct ways. Taking well-known contracts opinions, and sourcing the actual agreements that they adjudicated, we show that AI models can help factfinders ascertain ordinary meaning in context, quantify ambiguity, and fill gaps in parties' agreements. We also illustrate how models can calculate the probative value of individual pieces of extrinsic evidence. After offering best practices for the use of these models given their limitations, we consider their implications for judicial practice and contract theory. Using LLMs permits courts to estimate what the parties intended cheaply and accurately, and as such generative interpretation unsettles the current interpretative stalemate. Their use responds to efficiency-minded textualists and justice-oriented contextualists, who argue about whether parties will prefer cost and certainty or accuracy and fairness. Parties--and courts--would prefer a middle path, in which adjudicators strive to predict what the contract really meant, admitting just enough context to approximate reality while avoiding unguided and biased assimilation of evidence. As generative interpretation offers this possibility, we argue it can become the new workhorse of contractual interpretation.
</details>
<details>
<summary>摘要</summary>
我们引入生成式解释，一种新的方法来估计合同意义使用大型语言模型。在人工智能胜利的时代，我们采用实地案例来证明这些新工具的能力，每个案例都展示了这些工具在不同方面的能力。我们使用知名合同案例，并提供了实际协议，以示AI模型可以帮助事实发现者在文本上确定常见意义，衡量模糊性，并填充党们的协议中的空白。我们还示出了模型可以计算个别外部证据的证据价值。接着，我们提供了使用这些模型的最佳实践，以及其限制。我们考虑了这些模型在法律实践和合同理论方面的影响，并 argues that these models can become the new workhorse of contractual interpretation.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="Federated-Classification-in-Hyperbolic-Spaces-via-Secure-Aggregation-of-Convex-Hulls"><a href="#Federated-Classification-in-Hyperbolic-Spaces-via-Secure-Aggregation-of-Convex-Hulls" class="headerlink" title="Federated Classification in Hyperbolic Spaces via Secure Aggregation of Convex Hulls"></a>Federated Classification in Hyperbolic Spaces via Secure Aggregation of Convex Hulls</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06895">http://arxiv.org/abs/2308.06895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurav Prakash, Jin Sima, Chao Pan, Eli Chien, Olgica Milenkovic</li>
<li>for: 这个论文是为了研究在几何空间中进行分布式学习，以保护数据隐私。</li>
<li>methods: 该论文提出了一种基于几何空间的分布式学习方法，包括在Poincaré圆柱中分布式的支持向量机学习和一种基于整数B_h序列的标签恢复方法。</li>
<li>results: 该论文的实验结果表明，使用几何空间进行分布式学习可以提高分类精度，并且可以保护数据隐私。<details>
<summary>Abstract</summary>
Hierarchical and tree-like data sets arise in many applications, including language processing, graph data mining, phylogeny and genomics. It is known that tree-like data cannot be embedded into Euclidean spaces of finite dimension with small distortion. This problem can be mitigated through the use of hyperbolic spaces. When such data also has to be processed in a distributed and privatized setting, it becomes necessary to work with new federated learning methods tailored to hyperbolic spaces. As an initial step towards the development of the field of federated learning in hyperbolic spaces, we propose the first known approach to federated classification in hyperbolic spaces. Our contributions are as follows. First, we develop distributed versions of convex SVM classifiers for Poincar\'e discs. In this setting, the information conveyed from clients to the global classifier are convex hulls of clusters present in individual client data. Second, to avoid label switching issues, we introduce a number-theoretic approach for label recovery based on the so-called integer $B_h$ sequences. Third, we compute the complexity of the convex hulls in hyperbolic spaces to assess the extent of data leakage; at the same time, in order to limit the communication cost for the hulls, we propose a new quantization method for the Poincar\'e disc coupled with Reed-Solomon-like encoding. Fourth, at server level, we introduce a new approach for aggregating convex hulls of the clients based on balanced graph partitioning. We test our method on a collection of diverse data sets, including hierarchical single-cell RNA-seq data from different patients distributed across different repositories that have stringent privacy constraints. The classification accuracy of our method is up to $\sim 11\%$ better than its Euclidean counterpart, demonstrating the importance of privacy-preserving learning in hyperbolic spaces.
</details>
<details>
<summary>摘要</summary>
Hierarchical和树状数据集在许多应用中出现，包括语言处理、图数据挖掘、phylogeny和 genomics。已知树状数据无法在 finite 维 Euclidian 空间中嵌入，这问题可以通过使用抽象空间来缓解。在分布式和隐私化设置下，需要采用新的联邦学习方法，这是一个新的领域。作为这个领域的初步，我们提出了首个在抽象空间上的联邦分类方法。我们的贡献如下：1. 我们开发了分布式版本的凸 Support Vector Machine（SVM）分类器，用于Poincaré盘上的数据。在这个设置中，客户端上的信息是各个客户端数据中的封闭集。2. 为了避免标签交换问题，我们引入了一种数学推理的方法，基于 so-called 整数 $B_h$ 序列。3. 我们计算了抽象空间中的凸闭复杂度，以评估数据泄露程度，同时，我们提出了一种新的归一化方法，用于限制归一化成本。4. 在服务器端，我们引入了一种新的客户端归一化方法，基于平衡图分 partitioning。我们测试了我们的方法在多种多样的数据集上，包括层次单元 RNA-seq 数据集，来自不同的病人和不同的存储库，这些存储库具有严格的隐私限制。我们的方法的分类精度与其欧氏凸缩形相比，提高了约 11%，这表明了隐私保护在抽象空间上的学习的重要性。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Offline-Online-Evaluation-with-a-Time-dependent-and-Popularity-Bias-free-Offline-Metric-for-Recommenders"><a href="#Bridging-Offline-Online-Evaluation-with-a-Time-dependent-and-Popularity-Bias-free-Offline-Metric-for-Recommenders" class="headerlink" title="Bridging Offline-Online Evaluation with a Time-dependent and Popularity Bias-free Offline Metric for Recommenders"></a>Bridging Offline-Online Evaluation with a Time-dependent and Popularity Bias-free Offline Metric for Recommenders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06885">http://arxiv.org/abs/2308.06885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Petr Kasalický, Rodrigo Alves, Pavel Kordík</li>
<li>for: 研究和比较在线表现的Offline评估指标的选择，以提高live推荐系统中的选择。</li>
<li>methods: 使用减小流行item和考虑交易时间的评估方法，以提高选择的准确性。</li>
<li>results: 五个大型实际live数据中的平均结果，用于帮助学术社区更好地理解Offline评估和优化标准的选择。<details>
<summary>Abstract</summary>
The evaluation of recommendation systems is a complex task. The offline and online evaluation metrics for recommender systems are ambiguous in their true objectives. The majority of recently published papers benchmark their methods using ill-posed offline evaluation methodology that often fails to predict true online performance. Because of this, the impact that academic research has on the industry is reduced. The aim of our research is to investigate and compare the online performance of offline evaluation metrics. We show that penalizing popular items and considering the time of transactions during the evaluation significantly improves our ability to choose the best recommendation model for a live recommender system. Our results, averaged over five large-size real-world live data procured from recommenders, aim to help the academic community to understand better offline evaluation and optimization criteria that are more relevant for real applications of recommender systems.
</details>
<details>
<summary>摘要</summary>
评估推荐系统是一项复杂的任务。在线和离线评估指标对于推荐系统存在很多不确定性。大多数最近发表的论文使用不确定的离线评估方法来评估其方法的性能，这常导致实际上线性能和学术界的影响相差甚大。我们的研究目的是研究和比较离线评估指标对实时推荐系统的在线性能的影响。我们发现，对流行 item 的惩罚和在评估过程中考虑交易时间可以显著提高我们选择最佳推荐模型的能力。我们的结果，基于五个大型实际应用中的真实数据，希望能帮助学术界更好地理解推荐系统的离线评估和优化标准，以便更好地应用于实际应用中。
</details></li>
</ul>
<hr>
<h2 id="Multi-Receiver-Task-Oriented-Communications-via-Multi-Task-Deep-Learning"><a href="#Multi-Receiver-Task-Oriented-Communications-via-Multi-Task-Deep-Learning" class="headerlink" title="Multi-Receiver Task-Oriented Communications via Multi-Task Deep Learning"></a>Multi-Receiver Task-Oriented Communications via Multi-Task Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06884">http://arxiv.org/abs/2308.06884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus</li>
<li>for: 这 paper 研究了任务对应的通信系统，在 transmitter 与多个 receivers 之间进行任务完成和数据传输。</li>
<li>methods: 这 paper 提出了一种基于多任务深度学习的共同编码器和个别解码器的方法，用于对多个任务和多个接收器进行共同优化。</li>
<li>results: 实验结果表明，相比单任务传输系统，多任务传输系统可以更好地适应变化的通信频道条件，并且可以提高任务特定的目标 completions，同时减少传输负担。<details>
<summary>Abstract</summary>
This paper studies task-oriented, otherwise known as goal-oriented, communications, in a setting where a transmitter communicates with multiple receivers, each with its own task to complete on a dataset, e.g., images, available at the transmitter. A multi-task deep learning approach that involves training a common encoder at the transmitter and individual decoders at the receivers is presented for joint optimization of completing multiple tasks and communicating with multiple receivers. By providing efficient resource allocation at the edge of 6G networks, the proposed approach allows the communications system to adapt to varying channel conditions and achieves task-specific objectives while minimizing transmission overhead. Joint training of the encoder and decoders using multi-task learning captures shared information across tasks and optimizes the communication process accordingly. By leveraging the broadcast nature of wireless communications, multi-receiver task-oriented communications (MTOC) reduces the number of transmissions required to complete tasks at different receivers. Performance evaluation conducted on the MNIST, Fashion MNIST, and CIFAR-10 datasets (with image classification considered for different tasks) demonstrates the effectiveness of MTOC in terms of classification accuracy and resource utilization compared to single-task-oriented communication systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Quantifying-Outlierness-of-Funds-from-their-Categories-using-Supervised-Similarity"><a href="#Quantifying-Outlierness-of-Funds-from-their-Categories-using-Supervised-Similarity" class="headerlink" title="Quantifying Outlierness of Funds from their Categories using Supervised Similarity"></a>Quantifying Outlierness of Funds from their Categories using Supervised Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06882">http://arxiv.org/abs/2308.06882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhruv Desai, Ashmita Dhiman, Tushar Sharma, Deepika Sharma, Dhagash Mehta, Stefano Pasquali</li>
<li>for: 本研究旨在量化基金分类错误的影响，以便改善投资管理决策。</li>
<li>methods: 本研究使用机器学习方法，将基金分类错误形式化为距离度量学习问题，并计算每个数据点的类别异常度量。</li>
<li>results: 研究发现，基金分类错误与未来回报之间存在强相关关系，并讨论了这些结果的意义。<details>
<summary>Abstract</summary>
Mutual fund categorization has become a standard tool for the investment management industry and is extensively used by allocators for portfolio construction and manager selection, as well as by fund managers for peer analysis and competitive positioning. As a result, a (unintended) miscategorization or lack of precision can significantly impact allocation decisions and investment fund managers. Here, we aim to quantify the effect of miscategorization of funds utilizing a machine learning based approach. We formulate the problem of miscategorization of funds as a distance-based outlier detection problem, where the outliers are the data-points that are far from the rest of the data-points in the given feature space. We implement and employ a Random Forest (RF) based method of distance metric learning, and compute the so-called class-wise outlier measures for each data-point to identify outliers in the data. We test our implementation on various publicly available data sets, and then apply it to mutual fund data. We show that there is a strong relationship between the outlier measures of the funds and their future returns and discuss the implications of our findings.
</details>
<details>
<summary>摘要</summary>
资金基金分类已成为投资管理行业的标准工具，广泛用于配置股票和选择基金管理人，以及基金管理人对准竞对手的分析和竞争位置。因此，任何不当或精度不够的分类可能会对分配决策产生重大影响，并且对投资基金的管理人也有重要影响。在这种情况下，我们想要量化基金分类错误的影响，并使用机器学习的方法来解决这个问题。我们将基金分类问题定义为一个距离度量学习问题，其中异常值是与其他数据点之间的距离最大的数据点。我们使用随机森林（RF）方法来学习距离度量，并计算每个数据点的类别异常度量来确定异常值。我们在各种公开available的数据集上进行测试，然后应用于基金数据。我们发现基金的异常度量和未来回报之间存在强相关性，并讨论了这些发现的意义。
</details></li>
</ul>
<hr>
<h2 id="AutoSeqRec-Autoencoder-for-Efficient-Sequential-Recommendation"><a href="#AutoSeqRec-Autoencoder-for-Efficient-Sequential-Recommendation" class="headerlink" title="AutoSeqRec: Autoencoder for Efficient Sequential Recommendation"></a>AutoSeqRec: Autoencoder for Efficient Sequential Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06878">http://arxiv.org/abs/2308.06878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sliu675/autoseqrec">https://github.com/sliu675/autoseqrec</a></li>
<li>paper_authors: Sijia Liu, Jiahao Liu, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Ning Gu</li>
<li>for: 这篇论文旨在提出一种适合进行sequential recommendation tasks的增量推荐模型，即AutoSeqRec。</li>
<li>methods: AutoSeqRec 使用 autoencoder 架构，包括一个Encoder和三个Decoder。这些 комponents 考虑了用户-项目互动矩阵和项目转移矩阵的rows和columns。重建用户-项目互动矩阵可以捕捉用户长期偏好，而项目转移矩阵的rows和columns可以表示用户短期的兴趣。</li>
<li>results: 该论文的实验结果显示，AutoSeqRec 在精度方面比较高，并且具有优秀的可靠性和效率。<details>
<summary>Abstract</summary>
Sequential recommendation demonstrates the capability to recommend items by modeling the sequential behavior of users. Traditional methods typically treat users as sequences of items, overlooking the collaborative relationships among them. Graph-based methods incorporate collaborative information by utilizing the user-item interaction graph. However, these methods sometimes face challenges in terms of time complexity and computational efficiency. To address these limitations, this paper presents AutoSeqRec, an incremental recommendation model specifically designed for sequential recommendation tasks. AutoSeqRec is based on autoencoders and consists of an encoder and three decoders within the autoencoder architecture. These components consider both the user-item interaction matrix and the rows and columns of the item transition matrix. The reconstruction of the user-item interaction matrix captures user long-term preferences through collaborative filtering. In addition, the rows and columns of the item transition matrix represent the item out-degree and in-degree hopping behavior, which allows for modeling the user's short-term interests. When making incremental recommendations, only the input matrices need to be updated, without the need to update parameters, which makes AutoSeqRec very efficient. Comprehensive evaluations demonstrate that AutoSeqRec outperforms existing methods in terms of accuracy, while showcasing its robustness and efficiency.
</details>
<details>
<summary>摘要</summary>
sequential recommendation 示示了推荐ITEM的能力，通过模型用户的顺序行为。传统方法通常将用户视为ITEM的序列，忽略了用户之间的协作关系。基于图的方法可以利用用户-ITEM交互图，并 integrable 用户之间的协作信息。然而，这些方法有时会面临时间复杂度和计算效率的限制。为了解决这些限制，本文提出了AutoSeqRec，一种适用于顺序推荐任务的递增推荐模型。AutoSeqRec基于自适应器，包括一个Encoder和三个解码器在自适应器架构中。这些组件考虑了用户-ITEM交互矩阵和用户-ITEM交互矩阵的行列。重建用户-ITEM交互矩阵可以捕捉用户长期的偏好，通过共同筛选。此外，用户-ITEM交互矩阵的行列表示ITEM的出度和入度跳跃行为，可以模型用户短期的兴趣。在进行递增推荐时，只需更新输入矩阵，无需更新参数，这使得AutoSeqRec非常有效率。 comprehensive evaluations 表明AutoSeqRec在准确性方面高于现有方法，同时展现出了其稳定性和效率。
</details></li>
</ul>
<hr>
<h2 id="SpeechX-Neural-Codec-Language-Model-as-a-Versatile-Speech-Transformer"><a href="#SpeechX-Neural-Codec-Language-Model-as-a-Versatile-Speech-Transformer" class="headerlink" title="SpeechX: Neural Codec Language Model as a Versatile Speech Transformer"></a>SpeechX: Neural Codec Language Model as a Versatile Speech Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06873">http://arxiv.org/abs/2308.06873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaofei Wang, Manthan Thakker, Zhuo Chen, Naoyuki Kanda, Sefik Emre Eskimez, Sanyuan Chen, Min Tang, Shujie Liu, Jinyu Li, Takuya Yoshioka</li>
<li>for: 这篇论文旨在探讨一种能够实现多种语音转文字和语音处理任务的新型语音生成模型。</li>
<li>methods: 该模型使用了语音-文本提示的 Audio-Text 模型，并使用多任务学习和任务取向提示来实现一体化和可扩展的模型。</li>
<li>results: 实验结果表明，该模型在多种任务中表现出色，包括零shot TTS、噪声减少、目标说话人抽取、语音除去和背景噪声下的语音编辑等，并在不同任务中与专门的模型进行比较，表现相对或超过专门的模型。<details>
<summary>Abstract</summary>
Recent advancements in generative speech models based on audio-text prompts have enabled remarkable innovations like high-quality zero-shot text-to-speech. However, existing models still face limitations in handling diverse audio-text speech generation tasks involving transforming input speech and processing audio captured in adverse acoustic conditions. This paper introduces SpeechX, a versatile speech generation model capable of zero-shot TTS and various speech transformation tasks, dealing with both clean and noisy signals. SpeechX combines neural codec language modeling with multi-task learning using task-dependent prompting, enabling unified and extensible modeling and providing a consistent way for leveraging textual input in speech enhancement and transformation tasks. Experimental results show SpeechX's efficacy in various tasks, including zero-shot TTS, noise suppression, target speaker extraction, speech removal, and speech editing with or without background noise, achieving comparable or superior performance to specialized models across tasks. See https://aka.ms/speechx for demo samples.
</details>
<details>
<summary>摘要</summary>
近期的生成演说模型，基于音频文本提示，已经实现了高质量的零处理文本识别。然而，现有的模型仍然面临着处理多样化的音频文本演说生成任务的限制，包括转换输入speech和处理陌生频谱条件下的音频捕获。本文介绍SpeechX，一种多功能的演说生成模型，能够零处理TTS和多种演说转换任务，处理干净和噪音信号。SpeechX结合神经编码语言模型和多任务学习，使用任务висимы的提示，实现了一个简单、扩展的模型，并提供了一个通用的方法，用于挖掘文本输入在演说增强和转换任务中的作用。实验结果表明SpeechX在不同任务中具有优秀的表现，包括零处理TTS、噪音抑制、目标说话人EXTRACTION、演说除去和演说编辑等，与专门的模型相比，在任务中表现相似或更好。可以查看https://aka.ms/speechx的示例。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Dual-Stream-Self-Attentive-Adversarial-Graph-Contrastive-Learning-for-Cross-Subject-EEG-based-Emotion-Recognition"><a href="#Semi-Supervised-Dual-Stream-Self-Attentive-Adversarial-Graph-Contrastive-Learning-for-Cross-Subject-EEG-based-Emotion-Recognition" class="headerlink" title="Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive Learning for Cross-Subject EEG-based Emotion Recognition"></a>Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive Learning for Cross-Subject EEG-based Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11635">http://arxiv.org/abs/2308.11635</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weishan Ye, Zhiguo Zhang, Min Zhang, Fei Teng, Li Zhang, Linling Li, Gan Huang, Jianhong Wang, Dong Ni, Zhen Liang<br>for: 这篇论文是为了解决识别情绪的困难问题，具体来说是使用EEG数据进行情绪识别。methods: 该论文提出了一种半监督的双流自注意力对抗图像对比学习框架（简称DS-AGC），该框架包括两个平行的流程，一个是提取非结构的EEG特征，另一个是提取结构的EEG特征。results: 该论文的实验结果表明，在两个标准数据库（SEED和SEED-IV）上，提出的模型在不同的受测人数据下的 incomplete label 条件下表现出色，比如平均提高5.83%和6.99%。这表明该模型有效地解决了识别情绪的标签稀缺问题。<details>
<summary>Abstract</summary>
Electroencephalography (EEG) is an objective tool for emotion recognition with promising applications. However, the scarcity of labeled data remains a major challenge in this field, limiting the widespread use of EEG-based emotion recognition. In this paper, a semi-supervised Dual-stream Self-Attentive Adversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed to tackle the challenge of limited labeled data in cross-subject EEG-based emotion recognition. The DS-AGC framework includes two parallel streams for extracting non-structural and structural EEG features. The non-structural stream incorporates a semi-supervised multi-domain adaptation method to alleviate distribution discrepancy among labeled source domain, unlabeled source domain, and unknown target domain. The structural stream develops a graph contrastive learning method to extract effective graph-based feature representation from multiple EEG channels in a semi-supervised manner. Further, a self-attentive fusion module is developed for feature fusion, sample selection, and emotion recognition, which highlights EEG features more relevant to emotions and data samples in the labeled source domain that are closer to the target domain. Extensive experiments conducted on two benchmark databases (SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out cross-validation evaluation scheme show that the proposed model outperforms existing methods under different incomplete label conditions (with an average improvement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its effectiveness in addressing the label scarcity problem in cross-subject EEG-based emotion recognition.
</details>
<details>
<summary>摘要</summary>
电enzephalography (EEG) 是一种客观的表征工具，具有推荐的应用前景。然而，数据标注的缺乏仍然是这个领域的主要挑战，这限制了EEG基于情感认知的广泛应用。在这篇论文中，一种半supervised dual-stream Self-Attentive Adversarial Graph Contrastive learning框架（简称DS-AGC）被提出，以解决跨个体EEG基于情感认知的数据标注稀缺的问题。DS-AGC框架包括两个平行流，用于提取非结构和结构EEG特征。非结构流利用半supervised多元适应方法，以减轻来源领域、无标注领域和目标领域之间的分布差异。结构流发展了图像异常学学习方法，以从多个EEG通道中提取有效的图像特征表示。此外，一个自注意力融合模块被开发，用于特征融合、样本选择和情感认知，强调EEG特征更加关注情感和数据样本在标注领域中的更加相似性。经过对两个参考数据库（SEED和SEED-IV）的 semi-supervised cross-subject leave-one-subject-out cross-validation评估，提出的模型在不同的未完全标注条件下（SEED上提高了5.83%，SEED-IV上提高了6.99%）表现出色，表明它有效地解决了跨个体EEG基于情感认知的数据标注稀缺问题。
</details></li>
</ul>
<hr>
<h2 id="Effect-of-Choosing-Loss-Function-when-Using-T-batching-for-Representation-Learning-on-Dynamic-Networks"><a href="#Effect-of-Choosing-Loss-Function-when-Using-T-batching-for-Representation-Learning-on-Dynamic-Networks" class="headerlink" title="Effect of Choosing Loss Function when Using T-batching for Representation Learning on Dynamic Networks"></a>Effect of Choosing Loss Function when Using T-batching for Representation Learning on Dynamic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06862">http://arxiv.org/abs/2308.06862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/erfanloghmani/effect-of-loss-function-tbatching">https://github.com/erfanloghmani/effect-of-loss-function-tbatching</a></li>
<li>paper_authors: Erfan Loghmani, MohammadAmin Fazli</li>
<li>for: 这个论文旨在提出新的方法来实现动态network上的表征学习，并且利用时间信息来改善模型的精度和效率。</li>
<li>methods: 本论文使用了T-batching技术来训练动态网络模型，并提出了两种新的损失函数来解决训练损失的问题。</li>
<li>results: 实验结果显示，使用提案的两种损失函数可以超越原始的损失函数，实现更好的训练性能，并且在实际的动态网络上显示了更高的精度和效率。<details>
<summary>Abstract</summary>
Representation learning methods have revolutionized machine learning on networks by converting discrete network structures into continuous domains. However, dynamic networks that evolve over time pose new challenges. To address this, dynamic representation learning methods have gained attention, offering benefits like reduced learning time and improved accuracy by utilizing temporal information.   T-batching is a valuable technique for training dynamic network models that reduces training time while preserving vital conditions for accurate modeling. However, we have identified a limitation in the training loss function used with t-batching. Through mathematical analysis, we propose two alternative loss functions that overcome these issues, resulting in enhanced training performance.   We extensively evaluate the proposed loss functions on synthetic and real-world dynamic networks. The results consistently demonstrate superior performance compared to the original loss function. Notably, in a real-world network characterized by diverse user interaction histories, the proposed loss functions achieved more than 26.9% enhancement in Mean Reciprocal Rank (MRR) and more than 11.8% improvement in Recall@10. These findings underscore the efficacy of the proposed loss functions in dynamic network modeling.
</details>
<details>
<summary>摘要</summary>
“现代学习方法已经革命化机器学习领域中的网络结构，将离散网络结构转化为连续领域。然而，在时间演变的网络上 pose 新的挑战。为 Addressing 这些挑战，动态表示学习方法受到了关注，它们可以利用时间信息来提高模型的准确性和速度。 T-batching 是训练动态网络模型的有价值技术，它可以降低训练时间的同时保持模型的准确性。然而，我们发现了 t-batching 的训练损失函数中的一个限制。通过数学分析，我们提出了两种替代的损失函数，它们可以解决这些问题，从而提高训练性能。我们对 synthetic 和实际的动态网络进行了广泛的评估，结果 consistently 表明了我们提出的损失函数的超越性。特别是在一个实际网络中，其中用户交互历史多样化，我们的提议损失函数可以提高 Mean Reciprocal Rank (MRR) 的值超过 26.9%，并提高 Recall@10 的值超过 11.8%。这些发现讲述了我们提出的损失函数在动态网络模型中的效果。”
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Offensive-Gameplan-in-the-National-Basketball-Association-with-Machine-Learning"><a href="#Optimizing-Offensive-Gameplan-in-the-National-Basketball-Association-with-Machine-Learning" class="headerlink" title="Optimizing Offensive Gameplan in the National Basketball Association with Machine Learning"></a>Optimizing Offensive Gameplan in the National Basketball Association with Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06851">http://arxiv.org/abs/2308.06851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eamon Mukhopadhyay</li>
<li>for: 这篇论文是为了检验篮球metric的有效性而写的。</li>
<li>methods: 这篇论文使用了机器学习技术来模型已有的metric，并选择了一组特有的特征来评估metric的效果。</li>
<li>results: 该论文发现ORTG指数（由Dean Oliver提出）与不同的NBA战术类型有 statistically significant的相关性，但是使用神经网络回归模型而不是线性回归模型表现更好。<details>
<summary>Abstract</summary>
Throughout the analytical revolution that has occurred in the NBA, the development of specific metrics and formulas has given teams, coaches, and players a new way to see the game. However - the question arises - how can we verify any metrics? One method would simply be eyeball approximation (trying out many different gameplans) and/or trial and error - an estimation-based and costly approach. Another approach is to try to model already existing metrics with a unique set of features using machine learning techniques. The key to this approach is that with these features that are selected, we can try to gauge the effectiveness of these features combined, rather than using individual analysis in simple metric evaluation. If we have an accurate model, it can particularly help us determine the specifics of gameplan execution. In this paper, the statistic ORTG (Offensive Rating, developed by Dean Oliver) was found to have a correlation with different NBA playtypes using both a linear regression model and a neural network regression model, although ultimately, a neural network worked slightly better than linear regression. Using the accuracy of the models as a justification, the next step was to optimize the output of the model with test examples, which would demonstrate the combination of features to best achieve a highly functioning offense.
</details>
<details>
<summary>摘要</summary>
在NBA analytics革命中，发展特定指标和公式为球队、教练和球员提供了一种新的视角。然而，问题出现：如何验证这些指标呢？一种方法是通过试错和错误的方式来估算，这是一种估算基于估计的和昂贵的方法。另一种方法是使用机器学习技术来模型已有的指标，并选择一组独特的特征来评估这些指标的效果。如果我们有一个准确的模型，那么它可以帮助我们确定游戏计划执行的 especifics。在这篇论文中，由Dean Oliver开发的ORTG指标（进攻评估指标）与不同的NBA游戏类型之间显示了相关性，使用线性回归模型和神经网络回归模型，其中神经网络模型在精度上略微高一些。使用模型的准确性作为正当化，接下来的步骤是使用测试例子来优化模型的输出，以示出合理的游戏计划执行。
</details></li>
</ul>
<hr>
<h2 id="When-Monte-Carlo-Dropout-Meets-Multi-Exit-Optimizing-Bayesian-Neural-Networks-on-FPGA"><a href="#When-Monte-Carlo-Dropout-Meets-Multi-Exit-Optimizing-Bayesian-Neural-Networks-on-FPGA" class="headerlink" title="When Monte-Carlo Dropout Meets Multi-Exit: Optimizing Bayesian Neural Networks on FPGA"></a>When Monte-Carlo Dropout Meets Multi-Exit: Optimizing Bayesian Neural Networks on FPGA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06849">http://arxiv.org/abs/2308.06849</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/os-hxfan/bayesnn_fpga">https://github.com/os-hxfan/bayesnn_fpga</a></li>
<li>paper_authors: Hongxiang Fan, Hao Chen, Liam Castelli, Zhiqiang Que, He Li, Kenneth Long, Wayne Luk</li>
<li>for: 提高 Bayesian Neural Networks（BayesNNs）的实际应用，因为它们的算法复杂性和硬件性能妨碍了它们的应用。</li>
<li>methods: 该文提出了一种基于 Monte-Carlo Dropout（MCD）的多出口 BayesNN，可以实现准确预测，同时具有低算法复杂性。</li>
<li>results: 我们的自动生成的加速器在能效率方面高于 CPU、GPU 和其他现有硬件实现。<details>
<summary>Abstract</summary>
Bayesian Neural Networks (BayesNNs) have demonstrated their capability of providing calibrated prediction for safety-critical applications such as medical imaging and autonomous driving. However, the high algorithmic complexity and the poor hardware performance of BayesNNs hinder their deployment in real-life applications. To bridge this gap, this paper proposes a novel multi-exit Monte-Carlo Dropout (MCD)-based BayesNN that achieves well-calibrated predictions with low algorithmic complexity. To further reduce the barrier to adopting BayesNNs, we propose a transformation framework that can generate FPGA-based accelerators for multi-exit MCD-based BayesNNs. Several novel optimization techniques are introduced to improve hardware performance. Our experiments demonstrate that our auto-generated accelerator achieves higher energy efficiency than CPU, GPU, and other state-of-the-art hardware implementations.
</details>
<details>
<summary>摘要</summary>
bayesian neural networks (bayesNNs) 有能力提供准确的预测，用于安全关键应用程序，如医疗影像和自动驾驶。然而，bayesNNs 的算法复杂度和硬件性能妨碍其在实际应用中部署。为 bridge 这个差距，这篇文章提议一种新的多出口 Monte Carlo Dropout (MCD) 基于的 bayesNN，可以实现准确的预测，同时具有低的算法复杂度。此外，我们还提出了一种转换框架，可以生成 FPGA 加速器，用于multi-exit MCD 基于的 bayesNNs。我们还引入了一些新的优化技术，以提高硬件性能。我们的实验示例，我们自动生成的加速器在能耗效率方面高于 CPU、GPU 和其他现有硬件实现。
</details></li>
</ul>
<hr>
<h2 id="Generalizing-Topological-Graph-Neural-Networks-with-Paths"><a href="#Generalizing-Topological-Graph-Neural-Networks-with-Paths" class="headerlink" title="Generalizing Topological Graph Neural Networks with Paths"></a>Generalizing Topological Graph Neural Networks with Paths</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06838">http://arxiv.org/abs/2308.06838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quang Truong, Peter Chin</li>
<li>for: 该论文旨在探讨图 neural network (GNN) 在多种领域中的发展，但它们受到一种理论限制，即1-Weisfeiler-Lehmann测试。</li>
<li>methods: 该论文提出了一种以路径为中心的方法，强调图中的路径结构。该方法可以建立更一般的topological视角，并与其他已知的topological领域之间建立联系。</li>
<li>results: 该论文通过对多个benchmark进行测试，发现该方法可以超越之前的技术，在不假设图的子结构的前提下，达到状态艺术性的性能。<details>
<summary>Abstract</summary>
While Graph Neural Networks (GNNs) have made significant strides in diverse areas, they are hindered by a theoretical constraint known as the 1-Weisfeiler-Lehmann test. Even though latest advancements in higher-order GNNs can overcome this boundary, they typically center around certain graph components like cliques or cycles. However, our investigation goes a different route. We put emphasis on paths, which are inherent in every graph. We are able to construct a more general topological perspective and form a bridge to certain established theories about other topological domains. Interestingly, without any assumptions on graph sub-structures, our approach surpasses earlier techniques in this field, achieving state-of-the-art performance on several benchmarks.
</details>
<details>
<summary>摘要</summary>
While 图解网络（GNNs）在多个领域取得了 significiant progress, 它们受到一种理论限制，称为一个Weisfeiler-Lehmann测试。 latest advancements in higher-order GNNs可以突破这个boundary，但它们通常围绕某些图Component like cliques or cycles进行设计。 然而，我们的研究采取了不同的方向。 我们强调了路径，这是所有图的内在特征。 我们可以构建一个更通用的topological perspective，并与其他已知的topological domains建立联系。  Interestingly，无需任何图子结构的假设，我们的方法超越了之前在这个领域的技术，在多个标准测试上达到了state-of-the-art性能。
</details></li>
</ul>
<hr>
<h2 id="InTune-Reinforcement-Learning-based-Data-Pipeline-Optimization-for-Deep-Recommendation-Models"><a href="#InTune-Reinforcement-Learning-based-Data-Pipeline-Optimization-for-Deep-Recommendation-Models" class="headerlink" title="InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models"></a>InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08500">http://arxiv.org/abs/2308.08500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kabir Nagrecha, Lingyi Liu, Pablo Delgado, Prasanna Padmanabhan</li>
<li>for: 这 paper 的目的是研究深度学习基于推荐模型（DLRM）的训练方法，以及如何优化这些方法以提高效率和可扩展性。</li>
<li>methods: 这 paper 使用了人工智能的强化学习（RL）算法，以学习训练机器的 CPU 资源分配策略，以提高数据加载并行并发行为。</li>
<li>results: 这 paper 的实验结果表明，使用 InTune 可以在只需几分钟之内构建优化的数据管道配置，并且可以轻松地与现有训练工作流Integrate into existing workflows。 InTune 可以提高在线数据加载速率，从而降低模型执行时间的浪费和提高效率。<details>
<summary>Abstract</summary>
Deep learning-based recommender models (DLRMs) have become an essential component of many modern recommender systems. Several companies are now building large compute clusters reserved only for DLRM training, driving new interest in cost- and time- saving optimizations. The systems challenges faced in this setting are unique; while typical deep learning training jobs are dominated by model execution, the most important factor in DLRM training performance is often online data ingestion.   In this paper, we explore the unique characteristics of this data ingestion problem and provide insights into DLRM training pipeline bottlenecks and challenges. We study real-world DLRM data processing pipelines taken from our compute cluster at Netflix to observe the performance impacts of online ingestion and to identify shortfalls in existing pipeline optimizers. We find that current tooling either yields sub-optimal performance, frequent crashes, or else requires impractical cluster re-organization to adopt. Our studies lead us to design and build a new solution for data pipeline optimization, InTune.   InTune employs a reinforcement learning (RL) agent to learn how to distribute the CPU resources of a trainer machine across a DLRM data pipeline to more effectively parallelize data loading and improve throughput. Our experiments show that InTune can build an optimized data pipeline configuration within only a few minutes, and can easily be integrated into existing training workflows. By exploiting the responsiveness and adaptability of RL, InTune achieves higher online data ingestion rates than existing optimizers, thus reducing idle times in model execution and increasing efficiency. We apply InTune to our real-world cluster, and find that it increases data ingestion throughput by as much as 2.29X versus state-of-the-art data pipeline optimizers while also improving both CPU & GPU utilization.
</details>
<details>
<summary>摘要</summary>
InTune 使用了强化学习（RL）代理来学习如何在 DLRM 数据管道中分配训练机器的 CPU 资源，以更有效地并行数据加载并提高吞吐量。我们的实验表明，InTune 可以在只需几分钟之内构建优化数据管道配置，并且可以轻松地与现有训练工作流 integrate。通过RL的响应和适应性，InTune 可以在现有优化器的基础上提高在线数据接收速率，从而降低模型执行时间的浪费和提高效率。我们对实际集群进行应用，发现 InTune 可以提高数据接收吞吐量达到 2.29 倍，同时提高 CPU 和 GPU 资源利用率。
</details></li>
</ul>
<hr>
<h2 id="An-Ensemble-Approach-to-Question-Classification-Integrating-Electra-Transformer-GloVe-and-LSTM"><a href="#An-Ensemble-Approach-to-Question-Classification-Integrating-Electra-Transformer-GloVe-and-LSTM" class="headerlink" title="An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM"></a>An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06828">http://arxiv.org/abs/2308.06828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass, Osama Dorgham</li>
<li>for: 本研究旨在提出一种新的集成方法，用于问题分类，利用现代模型——Electra、GloVe和LSTM。</li>
<li>methods: 该模型使用了Electra、GloVe和LSTM三种现代模型，通过集成这些模型的优势，提供了一种robust和高效的问题分类解决方案。</li>
<li>results: 对于TREC数据集，提出的集成模型在所有评估指标上都超过了BERT、RoBERTa和DistilBERT等其他现代模型，实现了0.8的测试集准确率。这些结果表明集成方法在问题分类任务中具有显著的优势，并且鼓励进一步探索集成方法在自然语言处理领域中的应用。<details>
<summary>Abstract</summary>
This paper introduces a novel ensemble approach for question classification using state-of-the-art models -- Electra, GloVe, and LSTM. The proposed model is trained and evaluated on the TREC dataset, a well-established benchmark for question classification tasks. The ensemble model combines the strengths of Electra, a transformer-based model for language understanding, GloVe, a global vectors for word representation, and LSTM, a recurrent neural network variant, providing a robust and efficient solution for question classification. Extensive experiments were carried out to compare the performance of the proposed ensemble approach with other cutting-edge models, such as BERT, RoBERTa, and DistilBERT. Our results demonstrate that the ensemble model outperforms these models across all evaluation metrics, achieving an accuracy of 0.8 on the test set. These findings underscore the effectiveness of the ensemble approach in enhancing the performance of question classification tasks, and invite further exploration of ensemble methods in natural language processing.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的集成方法 для问题分类，使用当今最佳模型——Electra、GloVe和LSTM。该模型在TREC数据集上进行训练和评估，TREC数据集是问题分类任务的常见 benchmarck。集成模型结合了Electra、GloVe和LSTM的优势，提供了一个可靠和高效的问题分类解决方案。我们进行了广泛的实验，与其他最新的模型，如BERT、RoBERTa和DistilBERT进行比较。我们的结果表明，集成模型在所有评估指标上都超过了这些模型，在测试集上达到了0.8的准确率。这些结果证明了集成方法在问题分类任务中的效iveness，并邀请了进一步的对natural language processing领域中的集成方法进行探索。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Graph-Clustering-with-Unknown-Cluster-Number"><a href="#Reinforcement-Graph-Clustering-with-Unknown-Cluster-Number" class="headerlink" title="Reinforcement Graph Clustering with Unknown Cluster Number"></a>Reinforcement Graph Clustering with Unknown Cluster Number</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06827">http://arxiv.org/abs/2308.06827</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yueliu1999/awesome-deep-graph-clustering">https://github.com/yueliu1999/awesome-deep-graph-clustering</a></li>
<li>paper_authors: Yue Liu, Ke Liang, Jun Xia, Xihong Yang, Sihang Zhou, Meng Liu, Xinwang Liu, Stan Z. Li<br>for: 这个研究旨在提供一个不需要先知cluster number的深度图 clustering方法，并且与对图的不确定性进行适应。methods: 我们提出了一个名为Reinforcement Graph Clustering（RGC）的新方法，它通过强化学习机制让cluster number决定和无监督表现学习融合到一个整体框架中。在我们的方法中，首先learn出具有对称预测任务的描述性node表现，然后考虑 both node和cluster状态，以获得更加准确的图 clustering结果。results: 我们的方法在实验中表现出了优异的效能和效率，并且能够在对图中实现更好的适应性和稳定性。此外，我们还提供了一个包含多种深度图 clustering方法的 коллекции（paper、code和dataset），可以帮助研究人员更好地进行深度图 clustering的研究。<details>
<summary>Abstract</summary>
Deep graph clustering, which aims to group nodes into disjoint clusters by neural networks in an unsupervised manner, has attracted great attention in recent years. Although the performance has been largely improved, the excellent performance of the existing methods heavily relies on an accurately predefined cluster number, which is not always available in the real-world scenario. To enable the deep graph clustering algorithms to work without the guidance of the predefined cluster number, we propose a new deep graph clustering method termed Reinforcement Graph Clustering (RGC). In our proposed method, cluster number determination and unsupervised representation learning are unified into a uniform framework by the reinforcement learning mechanism. Concretely, the discriminative node representations are first learned with the contrastive pretext task. Then, to capture the clustering state accurately with both local and global information in the graph, both node and cluster states are considered. Subsequently, at each state, the qualities of different cluster numbers are evaluated by the quality network, and the greedy action is executed to determine the cluster number. In order to conduct feedback actions, the clustering-oriented reward function is proposed to enhance the cohesion of the same clusters and separate the different clusters. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method. The source code of RGC is shared at https://github.com/yueliu1999/RGC and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github.
</details>
<details>
<summary>摘要</summary>
深度图 clustering，目标是通过神经网络在无监督情况下将节点分组到不同的分支，在过去几年内吸引了广泛的关注。although 现有的方法已经大幅提高了性能，但是它们依赖于准确预定的分支数量，这在实际场景中并不总是可用。为了使深度图 clustering 算法不受预定分支数量的限制，我们提出了一种新的深度图 clustering 方法，称为奖励图 clustering（RGC）。在我们的提议方法中，集群数量决定和无监督表示学习被统一到一个奖励学习机制中。具体来说，首先通过对比预测任务学习描述性的节点表示。然后，为了准确地捕捉图中的集群状态，包括节点状态和集群状态。在每个状态下，通过质量网络评估不同的分支数量的质量，并执行滥购行动来确定分支数量。为了进行反馈行动，我们提出了一种集群 oriented 奖励函数，以增强同一个集群之间的凝结度和不同集群之间的分离度。我们的实验证明了我们的提议方法的效果和效率。RGC 的源代码可以在 GitHub 上获取：https://github.com/yueliu1999/RGC，而深度图 clustering 相关的代码、论文和数据集可以在 GitHub 上获取：https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering。
</details></li>
</ul>
<hr>
<h2 id="Approximate-and-Weighted-Data-Reconstruction-Attack-in-Federated-Learning"><a href="#Approximate-and-Weighted-Data-Reconstruction-Attack-in-Federated-Learning" class="headerlink" title="Approximate and Weighted Data Reconstruction Attack in Federated Learning"></a>Approximate and Weighted Data Reconstruction Attack in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06822">http://arxiv.org/abs/2308.06822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Wang, Yongcun Song, Enrique Zuazua</li>
<li>for: 本研究旨在攻击 Federated Learning（FL）中 horizontal Federated Averaging（FedAvg）场景中客户端的模型参数共享。</li>
<li>methods: 我们提出了一种 interpolation-based approximation 方法，可以使 fedavg 场景中客户端的模型参数攻击成为可能。此外，我们还设计了一种层Weighted loss function，可以提高数据重建质量。</li>
<li>results: 我们的 approximate and weighted attack（AWA）方法在不同评价指标中均表现出优于现有方法，特别是在图像数据重建中。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed learning paradigm that enables multiple clients to collaborate on building a machine learning model without sharing their private data. Although FL is considered privacy-preserved by design, recent data reconstruction attacks demonstrate that an attacker can recover clients' training data based on the parameters shared in FL. However, most existing methods fail to attack the most widely used horizontal Federated Averaging (FedAvg) scenario, where clients share model parameters after multiple local training steps. To tackle this issue, we propose an interpolation-based approximation method, which makes attacking FedAvg scenarios feasible by generating the intermediate model updates of the clients' local training processes. Then, we design a layer-wise weighted loss function to improve the data quality of reconstruction. We assign different weights to model updates in different layers concerning the neural network structure, with the weights tuned by Bayesian optimization. Finally, experimental results validate the superiority of our proposed approximate and weighted attack (AWA) method over the other state-of-the-art methods, as demonstrated by the substantial improvement in different evaluation metrics for image data reconstructions.
</details>
<details>
<summary>摘要</summary>
Федератированное обучение (FL) 是一种分布式学习 paradigma，允许多个客户端共同建立一个机器学习模型，无需共享其私人数据。虽然 FL 被视为隐私保护的设计，但最近的数据重建攻击表明，攻击者可以根据在 FL 中共享的参数重建客户端的训练数据。然而，现有方法大多不能攻击最常用的水平 Federated Averaging（FedAvg）场景，在这种场景下，客户端在多个本地训练步骤后共享模型参数。为解决这个问题，我们提出了一种 interpolating-based 方法，可以在 FedAvg 场景中生成客户端的本地训练过程中的中间模型更新。然后，我们设计了层wise 权重损失函数，以提高重建数据的质量。我们对模型更新在不同层中分配不同权重，并通过 Bayesian 优化调整这些权重。最后，我们对 AWA 方法进行实验 validate，并证明其在不同评价指标上具有明显的提高。
</details></li>
</ul>
<hr>
<h2 id="SoK-Realistic-Adversarial-Attacks-and-Defenses-for-Intelligent-Network-Intrusion-Detection"><a href="#SoK-Realistic-Adversarial-Attacks-and-Defenses-for-Intelligent-Network-Intrusion-Detection" class="headerlink" title="SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network Intrusion Detection"></a>SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network Intrusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06819">http://arxiv.org/abs/2308.06819</a></li>
<li>repo_url: None</li>
<li>paper_authors: João Vitorino, Isabel Praça, Eva Maia</li>
<li>For: The paper is written to provide a comprehensive overview of the state-of-the-art adversarial learning approaches for realistic example generation in the context of Network Intrusion Detection (NID) using machine learning (ML) models.* Methods: The paper consolidates and summarizes various adversarial attack methods and defense strategies, specifically tailored for the NID domain and realistic network traffic flows.* Results: The paper identifies open challenges and fundamental properties required for realistic adversarial examples in NID, providing guidelines for future research to ensure adequacy for real communication networks.Here’s the same information in Simplified Chinese text:* For: 这篇论文是为了提供网络入侵检测（NID）领域中机器学习（ML）模型的现状摘要，包括最新的敌对学习方法和防御策略。* Methods: 论文总结了各种敌对攻击方法和防御策略，特别适用于NID领域和真实的网络流量。* Results: 论文描述了NID领域中敌对学习模型的开放挑战和基本要求，并提供了未来研究的指导方针，以确保实际网络通信的合理性。<details>
<summary>Abstract</summary>
Machine Learning (ML) can be incredibly valuable to automate anomaly detection and cyber-attack classification, improving the way that Network Intrusion Detection (NID) is performed. However, despite the benefits of ML models, they are highly susceptible to adversarial cyber-attack examples specifically crafted to exploit them. A wide range of adversarial attacks have been created and researchers have worked on various defense strategies to safeguard ML models, but most were not intended for the specific constraints of a communication network and its communication protocols, so they may lead to unrealistic examples in the NID domain. This Systematization of Knowledge (SoK) consolidates and summarizes the state-of-the-art adversarial learning approaches that can generate realistic examples and could be used in real ML development and deployment scenarios with real network traffic flows. This SoK also describes the open challenges regarding the use of adversarial ML in the NID domain, defines the fundamental properties that are required for an adversarial example to be realistic, and provides guidelines for researchers to ensure that their future experiments are adequate for a real communication network.
</details>
<details>
<summary>摘要</summary>
This Systematization of Knowledge (SoK) consolidates and summarizes the state-of-the-art adversarial learning approaches that can generate realistic examples and can be used in real ML development and deployment scenarios with real network traffic flows. This SoK also identifies the open challenges regarding the use of adversarial ML in the NID domain, defines the fundamental properties that are required for an adversarial example to be realistic, and provides guidelines for researchers to ensure that their future experiments are adequate for a real communication network.
</details></li>
</ul>
<hr>
<h2 id="SAILOR-Structural-Augmentation-Based-Tail-Node-Representation-Learning"><a href="#SAILOR-Structural-Augmentation-Based-Tail-Node-Representation-Learning" class="headerlink" title="SAILOR: Structural Augmentation Based Tail Node Representation Learning"></a>SAILOR: Structural Augmentation Based Tail Node Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06801">http://arxiv.org/abs/2308.06801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jie-re/sailor">https://github.com/jie-re/sailor</a></li>
<li>paper_authors: Jie Liao, Jintang Li, Liang Chen, Bingzhe Wu, Yatao Bian, Zibin Zheng</li>
<li>for: 提高链接结构中tail节点的表示性</li>
<li>methods: 提出了一种基于 структур增强的tail节点表示学习框架，名为SAILOR</li>
<li>results: 对公共评估数据进行了广泛的实验，显示SAILOR可以显著提高tail节点的表示性，并超越当前的基准值<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have achieved state-of-the-art performance in representation learning for graphs recently. However, the effectiveness of GNNs, which capitalize on the key operation of message propagation, highly depends on the quality of the topology structure. Most of the graphs in real-world scenarios follow a long-tailed distribution on their node degrees, that is, a vast majority of the nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes since they lack structural information. In the pursuit of promoting the expressiveness of GNNs for tail nodes, we explore how the deficiency of structural information deteriorates the performance of tail nodes and propose a general Structural Augmentation based taIL nOde Representation learning framework, dubbed as SAILOR, which can jointly learn to augment the graph structure and extract more informative representations for tail nodes. Extensive experiments on public benchmark datasets demonstrate that SAILOR can significantly improve the tail node representations and outperform the state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
граф neural networks (GNNs) 在最近的表示学习中达到了状态的极品性表现。然而，GNNS的效果，它们基于消息传递操作，强度取决于图结构的质量。大多数实际场景中的图follows a long-tailed distribution on node degrees, that is, most nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes due to the lack of structural information. 为了提高GNNS的表达能力 для尾节点，我们研究了尾节点表示力下降的原因和提出了一种通用的结构扩充based taIL node representation learning框架，名为SAILOR，可以同时学习扩充图结构和提取更有用的尾节点表示。我们在公共 benchmark datasets上进行了广泛的实验，显示SAILOR可以显著提高尾节点表示和超越状态的基eline。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/14/cs.LG_2023_08_14/" data-id="clly3dvzi006e0988b9b75l3j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/15/eess.IV_2023_08_15/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-08-15 17:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/14/cs.SD_2023_08_14/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-14 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">104</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
