
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-08-09 18:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Density Crop-guided Semi-supervised Object Detection in Aerial Images paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.05032 repo_url: https:&#x2F;&#x2F;github.com&#x2F;akhilpm&#x2F;dronessod paper_authors: Akhil Meethal, Eric Grang">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-08-09 18:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/08/09/cs.LG_2023_08_09/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Density Crop-guided Semi-supervised Object Detection in Aerial Images paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.05032 repo_url: https:&#x2F;&#x2F;github.com&#x2F;akhilpm&#x2F;dronessod paper_authors: Akhil Meethal, Eric Grang">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-08T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:27.460Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.LG_2023_08_09/" class="article-date">
  <time datetime="2023-08-08T16:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-08-09 18:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images"><a href="#Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images" class="headerlink" title="Density Crop-guided Semi-supervised Object Detection in Aerial Images"></a>Density Crop-guided Semi-supervised Object Detection in Aerial Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05032">http://arxiv.org/abs/2308.05032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhilpm/dronessod">https://github.com/akhilpm/dronessod</a></li>
<li>paper_authors: Akhil Meethal, Eric Granger, Marco Pedersoli</li>
<li>for: 这种论文的目的是提出一种针对零类卷积检测器的 semi-supervised 检测方法，以优化小对象的检测效果。</li>
<li>methods: 该方法使用 pseudo-labels 和弱强一致性学习，并在训练时使用批量分割法将图像分成不同的区域，从而提高小对象的检测效果。</li>
<li>results: 对 VisDrone 和 DOTA 等 benchmark 进行了实验，并证明了该方法可以在 COCO 风格的 AP 上提高检测精度超过 2%。Here’s the translation of the three points in English:</li>
<li>for: The purpose of this paper is to propose a semi-supervised detection method for object detectors, to improve the detection effectiveness of small objects.</li>
<li>methods: The method uses pseudo-labels and weak-strong consistency learning, and applies batch partitioning to the image during training, to improve the detection of small objects.</li>
<li>results: The paper conducts experiments on the VisDrone and DOTA benchmarks and demonstrates that the method can improve the detection accuracy by more than 2% in the COCO style AP.<details>
<summary>Abstract</summary>
One of the important bottlenecks in training modern object detectors is the need for labeled images where bounding box annotations have to be produced for each object present in the image. This bottleneck is further exacerbated in aerial images where the annotators have to label small objects often distributed in clusters on high-resolution images. In recent days, the mean-teacher approach trained with pseudo-labels and weak-strong augmentation consistency is gaining popularity for semi-supervised object detection. However, a direct adaptation of such semi-supervised detectors for aerial images where small clustered objects are often present, might not lead to optimal results. In this paper, we propose a density crop-guided semi-supervised detector that identifies the cluster of small objects during training and also exploits them to improve performance at inference. During training, image crops of clusters identified from labeled and unlabeled images are used to augment the training set, which in turn increases the chance of detecting small objects and creating good pseudo-labels for small objects on the unlabeled images. During inference, the detector is not only able to detect the objects of interest but also regions with a high density of small objects (density crops) so that detections from the input image and detections from image crops are combined, resulting in an overall more accurate object prediction, especially for small objects. Empirical studies on the popular benchmarks of VisDrone and DOTA datasets show the effectiveness of our density crop-guided semi-supervised detector with an average improvement of more than 2\% over the basic mean-teacher method in COCO style AP. Our code is available at: https://github.com/akhilpm/DroneSSOD.
</details>
<details>
<summary>摘要</summary>
一个重要的瓶颈在现代物体检测器的训练中是需要标注的图像，其中需要为每个图像中的物体生成矩形框注释。这个瓶颈在飞行图像中更加突出，因为标注者需要为高分辨率图像上的小对象进行标注。在最近的日子里，使用pseudo-标签和弱强同步增强的mean-teacher方法在无监督物体检测中得到了广泛的应用。然而，直接适应这些无监督检测器于飞行图像中的小对象集中存在可能不会导致最佳结果。在这篇论文中，我们提出了一种基于密度裁剪的半监督物体检测器，它在训练时使用图像裁剪来增强训练集，从而提高小对象的检测率和生成 pseudo-标签的质量。在推理时，检测器不仅可以检测输入图像中的对象，还可以检测密度裁剪中的小对象集，因此可以将输入图像和密度裁剪中的检测结果结合起来，从而实现更高的物体预测精度，特别是 для小对象。我们的实验结果表明，我们的密度裁剪半监督物体检测器在COCO样式的AP上超过2%的提升，相比基本的mean-teacher方法。我们的代码可以在GitHub上找到：https://github.com/akhilpm/DroneSSOD。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-on-Using-Large-Language-Models-to-Analyze-Software-Supply-Chain-Security-Failures"><a href="#An-Empirical-Study-on-Using-Large-Language-Models-to-Analyze-Software-Supply-Chain-Security-Failures" class="headerlink" title="An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures"></a>An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04898">http://arxiv.org/abs/2308.04898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanmay Singla, Dharun Anandayuvaraj, Kelechi G. Kalu, Taylor R. Schorlemmer, James C. Davis</li>
<li>For: The paper aims to assess the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches.* Methods: The authors used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). They developed prompts for LLMs to categorize the failures by four dimensions: type of compromise, intent, nature, and impact.* Results: The authors found that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. The accuracy of GPT 3.5 and Bard, two LLMs used in the study, was 68% and 58%, respectively.<details>
<summary>Abstract</summary>
As we increasingly depend on software systems, the consequences of breaches in the software supply chain become more severe. High-profile cyber attacks like those on SolarWinds and ShadowHammer have resulted in significant financial and data losses, underlining the need for stronger cybersecurity. One way to prevent future breaches is by studying past failures. However, traditional methods of analyzing these failures require manually reading and summarizing reports about them. Automated support could reduce costs and allow analysis of more failures. Natural Language Processing (NLP) techniques such as Large Language Models (LLMs) could be leveraged to assist the analysis of failures. In this study, we assessed the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches. We used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). We developed prompts for LLMs to categorize these by four dimensions: type of compromise, intent, nature, and impact. GPT 3.5s categorizations had an average accuracy of 68% and Bard had an accuracy of 58% over these dimensions. We report that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. Future work can improve LLM performance in this context, and study a broader range of articles and failures.
</details>
<details>
<summary>摘要</summary>
随着我们对软件系统的依赖度越来越高，软件供应链攻击的后果变得更加严重。高 Profile的网络攻击，如SolarrWinds和ShadowHammer，导致了重大的金融和数据损失，这 highlights 了加强网络安全的需要。一种预防未来攻击的方法是通过研究过去的失败来做。然而，传统的失败分析方法需要手动阅读和概括报告。自动支持可以降低成本和允许分析更多的失败。自然语言处理（NLP）技术，如大型语言模型（LLMs），可以帮助分析失败。在这项研究中，我们评估了LLMs在历史软件供应链安全失败分析中的能力。我们使用LLMs将69个软件供应链安全失败 manually analyzed 的报告中的四维度分类：类型的攻击、意图、性质和影响。GPT 3.5的分类精度为68%，而Bard的精度为58%。我们发现LLMs可以有效地 caracterize software supply chain failures，但是需要源文章具有足够的细节，以便由人工分析员达成共识。未来的工作可以提高LLM的性能在这种情况下，并研究更广泛的文章和失败。
</details></li>
</ul>
<hr>
<h2 id="Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization"><a href="#Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization" class="headerlink" title="Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization"></a>Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05021">http://arxiv.org/abs/2308.05021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangming Li, Zhaozhi Qian, Mihaela van der Schaar</li>
<li>for: 提高 diffusion models 的精度和稳定性，避免 error propagation 问题。</li>
<li>methods: empirical 和 theoretical 分析，以及一种 regularization 方案来解决 error propagation 问题。</li>
<li>results: 经验结果表明，regularization 方案可以有效地避免 error propagation，并提高 diffusion models 的表现。<details>
<summary>Abstract</summary>
While diffusion models have achieved promising performances in data synthesis, they might suffer error propagation because of their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, a strict analysis is expected since many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation and we then propose a regularization to address this problem. Our theoretical analysis reveals that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module can't recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes. We further introduce a bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details>
<details>
<summary>摘要</summary>
Diffusion models 有 achieved promising performances in data synthesis, but they may suffer from error propagation due to their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation, and we propose a regularization to address this problem.我们的 teoretic analysis reveals that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module cannot recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes.我们还引入了一种 bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details></li>
</ul>
<hr>
<h2 id="When-and-How-Does-Known-Class-Help-Discover-Unknown-Ones-Provable-Understanding-Through-Spectral-Analysis"><a href="#When-and-How-Does-Known-Class-Help-Discover-Unknown-Ones-Provable-Understanding-Through-Spectral-Analysis" class="headerlink" title="When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis"></a>When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05017">http://arxiv.org/abs/2308.05017</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/nscl">https://github.com/deeplearning-wisc/nscl</a></li>
<li>paper_authors: Yiyou Sun, Zhenmei Shi, Yingyu Liang, Yixuan Li</li>
<li>for: 本研究的目的是提出一种基于知识的 Novel Class Discovery（NCD）方法，以便在无标签数据集中探索新的类别。</li>
<li>methods: 本研究使用了一种图学的表示方法，并引入了一种新的 Spectral Contrastive Loss（NSCL）函数来学习这种表示。NSCL 函数的目的是将图的邻接矩阵 factorized，从而得到一个可证明的错误约束和 Novel Class Discovery 的必要和 suficient condition。</li>
<li>results: 在实验中，NSCL 可以与多种强基elines相比赛，并且在常见的 benchmark 数据集上达到或超越这些基elines的性能，这是一种在实践中有理论保证的有appeal的方法。<details>
<summary>Abstract</summary>
Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
《新类发现（NCD）》目的是从已知类集（labeled set）中推断未知类（novel classes）。尽管NCD的理论基础缺乏，但这篇论文弥补了这一空白，提供了一个分析框架来正式化和研究已知类如何帮助发现新类。为了适应NCD问题，我们引入了一种图论表示，可以通过我们提出的新的NCDspectral Contrastive Loss（NSCL）来学习。最小化这个目标等价于对图 adjacency matrix 的 факторизация，从而可以 derivate一个可证的错误 bound 和提供 suficient and necessary condition for NCD。在实验中，NSCL可以与多种强基elines匹配或超越，这是在实践中具有理论保证的appealing选择。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Bugs-in-Open-Source-Federated-Learning-Framework"><a href="#An-Empirical-Study-of-Bugs-in-Open-Source-Federated-Learning-Framework" class="headerlink" title="An Empirical Study of Bugs in Open-Source Federated Learning Framework"></a>An Empirical Study of Bugs in Open-Source Federated Learning Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05014">http://arxiv.org/abs/2308.05014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Shao, Yuyang Gao, Fu Song, Sen Chen, Lingling Fan</li>
<li>for: 本研究的目的是研究 Federated Learning（FL）框架中的安全问题，以便更好地保护用户的隐私数据。</li>
<li>methods: 本研究使用 GitHub 上的 12 个开源 FL 框架中的 bugs 进行实证研究，分类、标注并构建了15种症状、12种根 causa 和 20种修复模式的病例库。</li>
<li>results: 研究发现了1,112个 FL 框架 bugs，其中有15种症状、12种根 causa 和 20种修复模式。研究还发现了9个发现，并对其意义进行了讨论和建议。<details>
<summary>Abstract</summary>
Federated learning (FL), as a decentralized machine learning solution to the protection of users' private data, has become an important learning paradigm in recent years, especially since the enforcement of stricter laws and regulations in most countries. Therefore, a variety of FL frameworks are released to facilitate the development and application of federated learning. Despite the considerable amount of research on the security and privacy of FL models and systems, the security issues in FL frameworks have not been systematically studied yet. In this paper, we conduct the first empirical study on 1,112 FL framework bugs to investigate their characteristics. These bugs are manually collected, classified, and labeled from 12 open-source FL frameworks on GitHub. In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs and investigate their correlations and distributions on 23 logical components and two main application scenarios. From the results of our study, we present nine findings, discuss their implications, and propound several suggestions to FL framework developers and security researchers on the FL frameworks.
</details>
<details>
<summary>摘要</summary>
随着国家的法规日益严格，联邦学习（FL）作为保护用户隐私数据的分布式机器学习解决方案，在最近几年内得到了重要的发展和应用。因此，许多FL框架被发布以便开发和应用联邦学习。尽管有很多关于FL模型和系统安全性的研究，但是FL框架的安全问题尚未得到了系统性的研究。在这篇论文中，我们进行了第一个实验性的研究， investigate FL框架中的1,112个漏洞的特点。这些漏洞由12个开源FL框架在GitHub上的手动收集、分类和标注。 Specifically, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs and investigate their correlations and distributions on 23 logical components and two main application scenarios.  From the results of our study, we present nine findings, discuss their implications, and propound several suggestions to FL framework developers and security researchers on the FL frameworks.
</details></li>
</ul>
<hr>
<h2 id="Multi-Class-Deep-SVDD-Anomaly-Detection-Approach-in-Astronomy-with-Distinct-Inlier-Categories"><a href="#Multi-Class-Deep-SVDD-Anomaly-Detection-Approach-in-Astronomy-with-Distinct-Inlier-Categories" class="headerlink" title="Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories"></a>Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05011">http://arxiv.org/abs/2308.05011</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mperezcarrasco/AnomalyALeRCE">https://github.com/mperezcarrasco/AnomalyALeRCE</a></li>
<li>paper_authors: Manuel Pérez-Carrasco, Guillermo Cabrera-Vives, Lorena Hernández-García, Francisco Forster, Paula Sánchez-Sáez, Alejandra Muñoz Arancibia, Nicolás Astorga, Franz Bauer, Amelia Bayo, Martina Cádiz-Leyton, Marcio Catelan</li>
<li>for: 这篇论文旨在提出一种基于深度学习的多类异常检测算法（MCDSVDD），用于探析现代天文观测 telescope 产生的大量数据。</li>
<li>methods: 这篇论文使用了一个神经网络将数据映射到对应不同对立类别的偏心球体中，以计算每个样本的异常分数。</li>
<li>results: 比较这篇论文中的异常检测算法与其他几种异常检测算法，发现MCDSVDD能够有效地检测异常源，并且能够利用不同的对立类别。<details>
<summary>Abstract</summary>
With the increasing volume of astronomical data generated by modern survey telescopes, automated pipelines and machine learning techniques have become crucial for analyzing and extracting knowledge from these datasets. Anomaly detection, i.e. the task of identifying irregular or unexpected patterns in the data, is a complex challenge in astronomy. In this paper, we propose Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically designed to handle different inlier categories with distinct data distributions. MCDSVDD uses a neural network to map the data into hyperspheres, where each hypersphere represents a specific inlier category. The distance of each sample from the centers of these hyperspheres determines the anomaly score. We evaluate the effectiveness of MCDSVDD by comparing its performance with several anomaly detection algorithms on a large dataset of astronomical light-curves obtained from the Zwicky Transient Facility. Our results demonstrate the efficacy of MCDSVDD in detecting anomalous sources while leveraging the presence of different inlier categories. The code and the data needed to reproduce our results are publicly available at https://github.com/mperezcarrasco/AnomalyALeRCE.
</details>
<details>
<summary>摘要</summary>
随着现代观测望远镜生成的天文数据量的增加，自动化管道和机器学习技术已成为分析和从数据中提取知识的关键。在天文学中，异常检测，即在数据中找到不寻常或意外的模式，是一项复杂的挑战。在这篇论文中，我们提出了多类深度支持向量数据描述（MCDSVDD），是一种基于现有异常检测算法一类深度支持向量数据描述（One-Class Deep SVDD）的扩展，特意为处理不同类准例的数据分布。MCDSVDD使用神经网络将数据映射到圆锥上，每个圆锥表示一个特定类准例。每个样本与这些圆锥的中心之间的距离决定了异常分数。我们通过对一个大量天文光谱数据集，从茨威基天体望远镜获得的数据进行比较，证明MCDSVDD可以有效地检测异常源，同时利用不同类准例的存在。代码和需要进行 reproduce 的数据可以在 <https://github.com/mperezcarrasco/AnomalyALeRCE> 上公开获取。
</details></li>
</ul>
<hr>
<h2 id="Transferable-Models-for-Bioacoustics-with-Human-Language-Supervision"><a href="#Transferable-Models-for-Bioacoustics-with-Human-Language-Supervision" class="headerlink" title="Transferable Models for Bioacoustics with Human Language Supervision"></a>Transferable Models for Bioacoustics with Human Language Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04978">http://arxiv.org/abs/2308.04978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/david-rx/biolingual">https://github.com/david-rx/biolingual</a></li>
<li>paper_authors: David Robinson, Adelaide Robinson, Lily Akrapongpisak</li>
<li>for: 跟踪全球生物多样性和人类活动对物种的影响</li>
<li>methods: 使用语音-文本预训练模型进行对比语言-声音表示的连接</li>
<li>results: 可以识别超过一千种动物叫声，完成零shot bioacoustic任务，并从自然文本查询中检索动物叫声记录Here’s the breakdown of each point:</li>
<li>for: The paper is written for tracking global biodiversity and anthropogenic impacts on species, using passive acoustic monitoring and deep learning techniques.</li>
<li>methods: The paper proposes a new model called BioLingual, which uses contrastive language-audio pretraining to connect language and audio representations and identify animal vocalizations.</li>
<li>results: The model can identify over a thousand species’ calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries, setting a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds.<details>
<summary>Abstract</summary>
Passive acoustic monitoring offers a scalable, non-invasive method for tracking global biodiversity and anthropogenic impacts on species. Although deep learning has become a vital tool for processing this data, current models are inflexible, typically cover only a handful of species, and are limited by data scarcity. In this work, we propose BioLingual, a new model for bioacoustics based on contrastive language-audio pretraining. We first aggregate bioacoustic archives into a language-audio dataset, called AnimalSpeak, with over a million audio-caption pairs holding information on species, vocalization context, and animal behavior. After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds. Given its broad taxa coverage and ability to be flexibly queried in human language, we believe this model opens new paradigms in ecological monitoring and research, including free-text search on the world's acoustic monitoring archives. We open-source our models, dataset, and code.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Adversarial-ModSecurity-Countering-Adversarial-SQL-Injections-with-Robust-Machine-Learning"><a href="#Adversarial-ModSecurity-Countering-Adversarial-SQL-Injections-with-Robust-Machine-Learning" class="headerlink" title="Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning"></a>Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04964">http://arxiv.org/abs/2308.04964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biagio Montaruli, Luca Demetrio, Andrea Valenza, Luca Compagna, Davide Ariu, Luca Piras, Davide Balzarotti, Battista Biggio</li>
<li>for: 本研究旨在改善ModSecurity的攻击检测能力，特别是对SQL注入攻击的检测。</li>
<li>methods: 本研究使用机器学习模型，使用CRS规则作为输入特征，并通过训练来检测 adversarial SQLi 攻击。</li>
<li>results: 实验结果表明，AdvModSec 能够提高 ModSecurity 的检测率，同时降低假阳性率，相比标准版 ModSecurity 与 CRS 的检测率提高了21%。此外，AdvModSec 还能够提高对 adversarial SQLi 攻击的鲁棒性，提高了42%。<details>
<summary>Abstract</summary>
ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towards the protected web services, achieves a better trade-off between detection and false positive rates, improving the detection rate of the vanilla version of ModSecurity with CRS by 21%. Moreover, our approach is able to improve its adversarial robustness against adversarial SQLi attacks by 42%, thereby taking a step forward towards building more robust and trustworthy WAFs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CasCIFF-A-Cross-Domain-Information-Fusion-Framework-Tailored-for-Cascade-Prediction-in-Social-Networks"><a href="#CasCIFF-A-Cross-Domain-Information-Fusion-Framework-Tailored-for-Cascade-Prediction-in-Social-Networks" class="headerlink" title="CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks"></a>CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04961">http://arxiv.org/abs/2308.04961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaoyuan011/casciff">https://github.com/xiaoyuan011/casciff</a></li>
<li>paper_authors: Hongjun Zhu, Shun Yuan, Xin Liu, Kuo Chen, Chaolong Jia, Ying Qian</li>
<li>for: 本研究旨在预测信息潮流。</li>
<li>methods: 本研究使用深度学习方法，利用多个域的信息进行融合，以提高预测性能。</li>
<li>results: 研究人员通过实验发现，对于信息潮流预测，使用深度学习方法可以提高预测性能，同时可以更好地捕捉信息的传播趋势。<details>
<summary>Abstract</summary>
Existing approaches for information cascade prediction fall into three main categories: feature-driven methods, point process-based methods, and deep learning-based methods. Among them, deep learning-based methods, characterized by its superior learning and representation capabilities, mitigates the shortcomings inherent of the other methods. However, current deep learning methods still face several persistent challenges. In particular, accurate representation of user attributes remains problematic due to factors such as fake followers and complex network configurations. Previous algorithms that focus on the sequential order of user activations often neglect the rich insights offered by activation timing. Furthermore, these techniques often fail to holistically integrate temporal and structural aspects, thus missing the nuanced propagation trends inherent in information cascades.To address these issues, we propose the Cross-Domain Information Fusion Framework (CasCIFF), which is tailored for information cascade prediction. This framework exploits multi-hop neighborhood information to make user embeddings robust. When embedding cascades, the framework intentionally incorporates timestamps, endowing it with the ability to capture evolving patterns of information diffusion. In particular, the CasCIFF seamlessly integrates the tasks of user classification and cascade prediction into a consolidated framework, thereby allowing the extraction of common features that prove useful for all tasks, a strategy anchored in the principles of multi-task learning.
</details>
<details>
<summary>摘要</summary>
现有的信息潮流预测方法可以分为三大类：特征驱动方法、点过程基于方法和深度学习基于方法。其中，深度学习基于方法，具有出色的学习和表示能力，有效解决了其他方法的缺陷。然而，当前的深度学习方法仍面临许多挑战。特别是，准确地表示用户特征仍然是一个问题，因为因素如假账户和复杂的网络配置。之前的算法通常将用户活动的顺序序列化，而忽略了活动时间的细腻特征。此外，这些技术frequently neglect the rich insights offered by activation timing. To address these issues, we propose the Cross-Domain Information Fusion Framework (CasCIFF), which is tailored for information cascade prediction. This framework exploits multi-hop neighborhood information to make user embeddings robust. When embedding cascades, the framework intentionally incorporates timestamps, endowing it with the ability to capture evolving patterns of information diffusion. In particular, the CasCIFF seamlessly integrates the tasks of user classification and cascade prediction into a consolidated framework, thereby allowing the extraction of common features that prove useful for all tasks, a strategy anchored in the principles of multi-task learning.
</details></li>
</ul>
<hr>
<h2 id="Representation-Learning-for-Audio-Privacy-Preservation-using-Source-Separation-and-Robust-Adversarial-Learning"><a href="#Representation-Learning-for-Audio-Privacy-Preservation-using-Source-Separation-and-Robust-Adversarial-Learning" class="headerlink" title="Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning"></a>Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04960">http://arxiv.org/abs/2308.04960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diep Luong, Minh Tran, Shayan Gharib, Konstantinos Drossos, Tuomas Virtanen</li>
<li>for: 实现智能音频监控系统中的隐私保护，避免因为声音录音而泄露个人隐私。</li>
<li>methods: 提案结合源分离和对抗学习来保护隐私，将声音录音转换为隐私保护的潜在表示。</li>
<li>results: 与不含源分离、不含对抗学习和不含任何隐私保护的系统相比，提案的系统可以优化声音隐私保护，同时维持音频监控任务的好性能。<details>
<summary>Abstract</summary>
Privacy preservation has long been a concern in smart acoustic monitoring systems, where speech can be passively recorded along with a target signal in the system's operating environment. In this study, we propose the integration of two commonly used approaches in privacy preservation: source separation and adversarial representation learning. The proposed system learns the latent representation of audio recordings such that it prevents differentiating between speech and non-speech recordings. Initially, the source separation network filters out some of the privacy-sensitive data, and during the adversarial learning process, the system will learn privacy-preserving representation on the filtered signal. We demonstrate the effectiveness of our proposed method by comparing our method against systems without source separation, without adversarial learning, and without both. Overall, our results suggest that the proposed system can significantly improve speech privacy preservation compared to that of using source separation or adversarial learning solely while maintaining good performance in the acoustic monitoring task.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传感器系统中的隐私保护已经是长期的关注点，其中语音可以通过系统运行环境中的传感器记录。在这种情况下，我们提议将通用的两种隐私保护方法集成：源分离和对抗学习。我们的提议的系统学习了听录录音的幂等表示，以防止区分语音和非语音录音。首先，源分离网络会过滤一些隐私敏感数据，而在对抗学习过程中，系统会学习隐私保护的表示。我们对我们的提议方法进行比较，包括不使用源分离、不使用对抗学习和不使用两者。我们的结果表明，我们的提议方法可以在语音隐私保护方面具有显著改善，同时保持良好的传感器监测性能。Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore, whereas Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks"><a href="#Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks" class="headerlink" title="Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks"></a>Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04958">http://arxiv.org/abs/2308.04958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc W. Brittain, Luis E. Alvarez, Kara Breeden</li>
<li>for: 提供增量的自动化交通运输方案，使用无人驾驶和电动飞机，以提高前未服务市场的交通效率。</li>
<li>methods: 使用分布式强化学习框架，解决低空飞机在高密度环境中安全和有效地自动分配空间问题，并使用速度和垂直运动来实现自动分配。</li>
<li>results: 经过numerical研究表明，提出的方案可以在具有多种不确定性的环境中保证安全和高效的飞机分配，并且可以在高训练样本通过率和高并发计算架构中实现高效训练。<details>
<summary>Abstract</summary>
Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details>
<details>
<summary>摘要</summary>
高级空中移动（AAM）介DUenced a new, efficient mode of transportation by using vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details></li>
</ul>
<hr>
<h2 id="Variations-on-the-Reinforcement-Learning-performance-of-Blackjack"><a href="#Variations-on-the-Reinforcement-Learning-performance-of-Blackjack" class="headerlink" title="Variations on the Reinforcement Learning performance of Blackjack"></a>Variations on the Reinforcement Learning performance of Blackjack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07329">http://arxiv.org/abs/2308.07329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack">https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack</a></li>
<li>paper_authors: Avish Buramdoyal, Tim Gebbie</li>
<li>for: 这篇论文是关于黑板子游戏（Blackjack）的优化策略和学习Agent的研究。</li>
<li>methods: 这篇论文使用q-学习算法来解决黑板子游戏的优化问题，并研究算法的学习速度是否与牌纸大小有关。</li>
<li>results: 研究发现，在黑板子游戏中，一个使用基础策略和高低系统的卡 COUNT可以让家家破产，而牌纸大小的变化会对这个结果产生影响。<details>
<summary>Abstract</summary>
Blackjack or "21" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.
</details>
<details>
<summary>摘要</summary>
黑板子或"21"是一款受欢迎的 карто牌游戏，旨在赢得手牌总值高于供应商的手牌而不超过21。理想的黑板子策略可以在长期内 maximize 财务回报，同时避免投资者的破产。黑板子的随机环境和内在的奖励结构，使得这个问题成为了理解增强学习代理在环境变化下的问题。我们考虑了一种q-学习解决方案，以便实现最佳的游戏策略，并 investigate 学习过程的速度是否与扑克牌大小相关。我们还实现了一个可以实现通用黑板子规则的黑板子模拟器，以示出一个卡计数员使用基本策略和高低系统可以让家庭铺垮，以及环境变化对这个结果的影响。我们的研究的新特点在于将这种概念理解与学习代理快速learns的速度相结合。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection"><a href="#Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection" class="headerlink" title="Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection"></a>Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04950">http://arxiv.org/abs/2308.04950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shafna81/fakenewsdetection">https://github.com/shafna81/fakenewsdetection</a></li>
<li>paper_authors: Shafna Fitria Nur Azizah, Hasan Dwi Cahyono, Sari Widya Sihwi, Wisnu Widiarto</li>
<li>For: The paper is written to detect fake news in Bahasa Indonesia using transformer models, specifically ALBERT, to improve the accuracy of fake news detection.* Methods: The paper uses transformer models, specifically BERT, ALBERT, and RoBERTa, to process text in parallel and produce rich and contextual word representations. The authors explore the use of these models for detecting fake news in Bahasa Indonesia and compare their performance.* Results: The paper finds that ALBERT outperforms other models with 87.6% accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s&#x2F;epoch) respectively.Here is the simplified Chinese text for the three key information points:* For: 这篇论文是用来探讨bahasa Indonesia中的假新闻检测，使用转换器模型，具体来说是ALBERT，以提高假新闻检测的准确性。* Methods: 论文使用转换器模型，具体来说是BERT、ALBERT和RoBERTa，来处理文本并生成丰富的上下文描述。作者们在bahasa Indonesia中检测假新闻的过程中使用这些模型，并比较其性能。* Results: 论文发现，ALBERT的性能比其他模型更高，具体来说是87.6%的准确率、86.9%的精度、86.9%的F1分数和174.5个run-time（s&#x2F;epoch）。<details>
<summary>Abstract</summary>
Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performance can be improved with the use of improved BERT models known as ALBERT and RoBERTa. However, the modified BERT models are not well explored for detecting fake news in Bahasa Indonesia. In this research, we explore those transformer models and found that ALBERT outperformed other models with 87.6% accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch) respectively. Source code available at: https://github.com/Shafna81/fakenewsdetection.git
</details>
<details>
<summary>摘要</summary>
假新闻是不正确的新闻材料，但是没有经过新闻机构的处理和检查。这种假材料可能会诋毁或者诋毁重要的实体或个人，或者为创作者的个人利益而创造。分辨假新闻和真实新闻是非常困难的，因为有限的领域知识和时间限制。据调查，居民最常受到诈骗和谣言的三个地区分别是望加、特区雅加达和西爪哇。 transformers 是一种人工智能（AI）自然语言处理领域的方法，利用深度学习架构。 transformers 使用强大的注意力机制，并在平行处理文本，生成丰富和Contextual 的单词表示。一些研究表明，改进的 BERT 模型（如 ALBERT 和 RoBERTa）可以超过非 transformer 方法的性能。然而，这些改进 BERT 模型在假新闻检测中并没有得到广泛的探索。在这项研究中，我们探索了这些 transformer 模型，并发现 ALBERT 模型在假新闻检测中的表现最佳，具体来说，ALBERT 模型在87.6%的准确率、86.9%的精度、86.9%的 F1 分数和174.5（s/epoch）的运行时间上表现出色。源代码可以在 GitHub 上找到：https://github.com/Shafna81/fakenewsdetection.git。
</details></li>
</ul>
<hr>
<h2 id="Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey"><a href="#Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey" class="headerlink" title="Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey"></a>Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04947">http://arxiv.org/abs/2308.04947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liping Wang, Jiawei Li, Lifan Zhao, Zhizhuo Kou, Xiaohan Wang, Xinyi Zhu, Hao Wang, Yanyan Shen, Lei Chen</li>
<li>For: This paper aims to provide a systematic and comprehensive overview of methods for acquiring external knowledge from various unstructured data sources and incorporating it into stock price prediction models.* Methods: The paper explores fusion methods for combining external knowledge with historical price features, and discusses relevant datasets for stock price prediction.* Results: The paper compiles and synthesizes previous studies on knowledge-enhanced stock price prediction methods, providing a comprehensive understanding of the different types of external knowledge that can be used to improve stock price prediction.<details>
<summary>Abstract</summary>
Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from various unstructured data sources and then incorporating it into stock price prediction models. We also explore fusion methods for combining external knowledge with historical price features. Moreover, this paper includes a compilation of relevant datasets and delves into potential future research directions in this domain.
</details>
<details>
<summary>摘要</summary>
预测股票价格是一个复杂的研究问题，因为股市的自然波动性和非线性性。在最近的几年中，基于知识的股票价格预测方法有着重要的突破，这些方法利用外部知识来理解股市。尽管这些方法的重要性，但是学术研究中有少量的评估前期研究的评价。特别是，外部知识可以被模型为不同的数据结构，我们分为非图结构和图结构两类：1）非图结构知识捕捉具体股票的上下文信息和多媒体描述; 2）图结构知识捕捉股市中的相互连接和依赖关系。本文旨在提供一种系统和完整的描述，包括从不同的不结构数据源中获取外部知识，然后将其与历史价格特征结合。此外，本文还探讨了外部知识与历史价格特征的融合方法，并提供了相关的数据集和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Differentially-Private-Graph-Neural-Network-with-Importance-Grained-Noise-Adaption"><a href="#Differentially-Private-Graph-Neural-Network-with-Importance-Grained-Noise-Adaption" class="headerlink" title="Differentially Private Graph Neural Network with Importance-Grained Noise Adaption"></a>Differentially Private Graph Neural Network with Importance-Grained Noise Adaption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04943">http://arxiv.org/abs/2308.04943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxin Qi, Xi Lin, Jun Wu</li>
<li>for: 保护图形数据的隐私，特别是节点具有个人敏感信息时。</li>
<li>methods: 提议一种基于不同节点重要性的隐私保护方法，包括节点重要性估计、隐私保护的集成和多层卷积学习。</li>
<li>results: 经验表明，NAP-GNN可以在保护隐私的同时实现更好的准确率。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) with differential privacy have been proposed to preserve graph privacy when nodes represent personal and sensitive information. However, the existing methods ignore that nodes with different importance may yield diverse privacy demands, which may lead to over-protect some nodes and decrease model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that need to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) with differential privacy have been proposed to protect graph privacy when nodes represent personal and sensitive information. However, existing methods ignore that nodes with different importance may have different privacy demands, which may lead to over-protect some nodes and decrease model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that need to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.Note: The translation is in Simplified Chinese, which is the standardized form of Chinese used in mainland China and Singapore. The traditional Chinese form of the translation would be slightly different.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-the-Effect-of-Data-Impurity-on-the-Detection-Performances-of-Mental-Disorders"><a href="#Analyzing-the-Effect-of-Data-Impurity-on-the-Detection-Performances-of-Mental-Disorders" class="headerlink" title="Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders"></a>Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05133">http://arxiv.org/abs/2308.05133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohan Kumar Gupta, Rohit Sinha</li>
<li>for: 本研究旨在提高Automatic Recognition of Mental Disorders的精度，尤其是对于主要抑郁症和 POST 应急压力症的识别。</li>
<li>methods: 本研究使用了一种新的方法，即从各种精神疾病中分离出特定疾病的特征，以提高分类器的准确率。</li>
<li>results: 研究结果表明，通过去除各种精神疾病的数据杂化，可以提高主要抑郁症和 POST 应急压力症的识别率。<details>
<summary>Abstract</summary>
The primary method for identifying mental disorders automatically has traditionally involved using binary classifiers. These classifiers are trained using behavioral data obtained from an interview setup. In this training process, data from individuals with the specific disorder under consideration are categorized as the positive class, while data from all other participants constitute the negative class. In practice, it is widely recognized that certain mental disorders share similar symptoms, causing the collected behavioral data to encompass a variety of attributes associated with multiple disorders. Consequently, attributes linked to the targeted mental disorder might also be present within the negative class. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, MDD and PTSD detection performances are significantly improved.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning"><a href="#An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning"></a>An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04938">http://arxiv.org/abs/2308.04938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究的目的是比较不同批处理方法在多智能演变学习中的表现，以及提出一种新的方法。</li>
<li>methods: 本研究使用了多种常见的批处理方法，包括DIAL、COMA和ST-DRU等。</li>
<li>results: 本研究发现，ST-DRU方法在多种环境中表现最佳，在所有测试环境中都达到了最好或接近最好的表现，而其他方法在某些环境中失败。<details>
<summary>Abstract</summary>
Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based on DIAL and COMA extended with learning rate scaling and adapted exploration. Using COMA-DIAL allows us to perform experiments on more complex environments. Our results show that the novel ST-DRU method, proposed in this paper, achieves the best results out of all discretization methods across the different environments. It achieves the best or close to the best performance in each of the experiments and is the only method that does not fail on any of the tested environments.
</details>
<details>
<summary>摘要</summary>
通信是多智能体学习中不可或缺的一部分，尤其当智能体无法观察环境的全部状态时。通常，使得学习得到的通信途径是使用可导的通信途径，allowing gradients to flow between agents as feedback。然而，当使用精简的消息时，这会变得困难，因为梯度不能流通精简的通信途径。前作已经提出了解决这个问题的方法，但这些方法在不同的通信学习架构和环境中进行测试，使其比较困难。在这篇论文中，我们比较了several state-of-the-art 精简方法以及一种新的方法。我们在通信学习中使用 gradients from other agents 进行测试，并在多个环境中进行测试。此外，我们还提出了 COMA-DIAL，一种基于 DIAL 和 COMA 的通信学习方法，其中包括学习速率缩放和适应性探索。使用 COMA-DIAL 让我们能够在更复杂的环境中进行实验。我们的结果显示，本文提出的新方法 ST-DRU 在不同环境中的表现最佳，它在每个实验中达到了最佳或 close to the best 性能，并且是唯一一个不会在任何测试环境中失败的方法。
</details></li>
</ul>
<hr>
<h2 id="JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition"><a href="#JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition" class="headerlink" title="JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition"></a>JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04934">http://arxiv.org/abs/2308.04934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucian Bicsi, Bogdan Alexe, Radu Tudor Ionescu, Marius Leordeanu</li>
<li>for: 这 paper 是为了提高机器学习模型的总体性和效果，使其能够在不同的数据集上进行推理和预测。</li>
<li>methods: 这 paper 使用了多个数据集的 semi-supervised learning 方法，通过将多个专家模型（每个专家模型在其自己的数据集上进行预训练）合并，以提高每个数据集上的学生模型的性能。</li>
<li>results: 实验结果表明，使用这种方法可以在四个视频动作识别数据集上显著提高模型的性能，并且同时考虑所有数据集，即使不具备很多标注数据，也可以获得良好的总体性能。<details>
<summary>Abstract</summary>
We propose JEDI, a multi-dataset semi-supervised learning method, which efficiently combines knowledge from multiple experts, learned on different datasets, to train and improve the performance of individual, per dataset, student models. Our approach achieves this by addressing two important problems in current machine learning research: generalization across datasets and limitations of supervised training due to scarcity of labeled data. We start with an arbitrary number of experts, pretrained on their own specific dataset, which form the initial set of student models. The teachers are immediately derived by concatenating the feature representations from the penultimate layers of the students. We then train all models in a student-teacher semi-supervised learning scenario until convergence. In our efficient approach, student-teacher training is carried out jointly and end-to-end, showing that both students and teachers improve their generalization capacity during training. We validate our approach on four video action recognition datasets. By simultaneously considering all datasets within a unified semi-supervised setting, we demonstrate significant improvements over the initial experts.
</details>
<details>
<summary>摘要</summary>
我们提议JEDI方法，这是一种多集数据半supervised学习方法，可以有效地将多个专家知识相结合，以提高每个特定dataset的学生模型的性能。我们的方法解决了当前机器学习研究中两个重要问题：跨集数据泛化和监督学习因数据稀缺而受限。我们从arbitrary数量的专家开始，先将专家模型预训练在自己专门的dataset上，这些专家模型组成初始的学生模型集。然后，我们将所有模型在学生-教师半supervised学习enario中同时训练，直到收敛。在我们的效率的方法中，学生-教师训练是 joint和端到端的，表明在训练过程中，学生和教师都会提高其泛化能力。我们验证了我们的方法在四个视频动作识别dataset上，并证明了同时考虑所有dataset在一个统一的半supervised设定下，可以获得显著提高。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery"><a href="#Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery" class="headerlink" title="Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery"></a>Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04923">http://arxiv.org/abs/2308.04923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nils Hampe, Sanne G. M. van Velzen, Jean-Paul Aben, Carlos Collet, Ivana Išgum<br>for:The paper is written to propose a deep learning-based method for predicting the fractional flow reserve (FFR) along the coronary artery from coronary computed tomography angiography (CCTA) scans.methods:The proposed method uses a variational autoencoder to characterize the artery and a convolutional neural network (CNN) to predict the FFR along the artery. The CNN is supervised by multiple loss functions, including a loss function inspired by the Earth Mover’s Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve.results:The resulting FFR curves show good agreement with the reference, allowing the distinction between diffuse and focal coronary artery disease (CAD) distributions in most cases. The mean absolute difference in the area under the FFR pullback curve (AUPC) is 1.7. The proposed method may pave the way towards fast, accurate, and automatic prediction of FFR along the artery from CCTA.<details>
<summary>Abstract</summary>
Functionally significant coronary artery disease (CAD) is caused by plaque buildup in the coronary arteries, potentially leading to narrowing of the arterial lumen, i.e. coronary stenosis, that significantly obstructs blood flow to the myocardium. The current reference for establishing the presence of a functionally significant stenosis is invasive fractional flow reserve (FFR) measurement. To avoid invasive measurements, non-invasive prediction of FFR from coronary CT angiography (CCTA) has emerged. For this, machine learning approaches, characterized by fast inference, are increasingly developed. However, these methods predict a single FFR value per artery i.e. they don't provide information about the stenosis location or treatment strategy. We propose a deep learning-based method to predict the FFR along the artery from CCTA scans. This study includes CCTA images of 110 patients who underwent invasive FFR pullback measurement in 112 arteries. First, a multi planar reconstruction (MPR) of the artery is fed to a variational autoencoder to characterize the artery, i.e. through the lumen area and unsupervised artery encodings. Thereafter, a convolutional neural network (CNN) predicts the FFR along the artery. The CNN is supervised by multiple loss functions, notably a loss function inspired by the Earth Mover's Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve. To train and evaluate our model, eight-fold cross-validation was performed. The resulting FFR curves show good agreement with the reference allowing the distinction between diffuse and focal CAD distributions in most cases. Quantitative evaluation yielded a mean absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The method may pave the way towards fast, accurate, automatic prediction of FFR along the artery from CCTA.
</details>
<details>
<summary>摘要</summary>
fonctionally significant coronary artery disease (CAD) 是由 coronary arteries 中的粘滓堆积引起的，可能导致 coronary arteries 的狭窄，即 coronary stenosis，significantly obstructs blood flow to the myocardium。现有的参照标准是侵入性的 fractional flow reserve (FFR) 测量。为了避免侵入性测量，Non-invasive prediction of FFR from coronary CT angiography (CCTA) 已经出现。这些方法具有快速的推理，但它们只预测每条 artery 的 FFR 值，没有提供狭窄的位置或治疗策略信息。我们提出了一种基于深度学习的方法，可以从 CCTA 图像中预测 FFR。这个研究包括 CCTA 图像的 110 名患者，其中每名患者有 112 条 artery 的侵入性 FFR pullback 测量。首先，一个 multi planar reconstruction (MPR) 的 artery 图像被 feed 到一个 variational autoencoder 中，以 caracterize the artery，即通过 luminal area 和不supervised artery encodings。然后，一个 convolutional neural network (CNN) 预测了 artery 中的 FFR。CNN 被多个损失函数supervise，包括一个由 Earth Mover's Distance (EMD)  inspirited loss function，以正确地预测狭窄的 FFR drop 位置，以及一个 histogram-based loss，以Explicitly supervise the slope of the FFR curve。为了训练和评估我们的模型，八个十字交叉验证被进行。得到的 FFR 曲线显示了良好的一致性，allowing the distinction between diffuse and focal CAD distributions in most cases。量化评估表明了 mean absolute difference 在 area under the FFR pullback curve (AUPC) 的值为 1.7。这种方法可能会为 CCTA 图像中的 FFR 预测提供快速、准确、自动的方法。
</details></li>
</ul>
<hr>
<h2 id="GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters"><a href="#GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters" class="headerlink" title="GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters"></a>GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04905">http://arxiv.org/abs/2308.04905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, José Suárez-Varela, Xiang Shi, Shihan Xiao, Xiangle Cheng, Pere Barlet-Ros, Albert Cabellos-Aparicio<br>for: 本文主要针对数据中心网络（DCN）中的堵塞控制（CC）问题，即如何在DCN中优化流量的分配和管理。methods: 本文提出了一种基于机器学习的分布式框架， named GraphCC， which combines Multi-agent Reinforcement Learning（MARL）和图神经网络（GNN）来自适应性地调整DCN中的Explicit Congestion Notification（ECN）配置。results: 在评估中，GraphCC在不同的场景下表现出优于现有的基eline，包括ACC。 GraphCC可以在不同的流量占用和网络状况下提供更好的流程完成时间和缓存占用率。 specifically, GraphCC可以在新的场景下提供$20%$的改进，并且在不同的失败和升级情况下保持稳定性。<details>
<summary>Abstract</summary>
Congestion Control (CC) plays a fundamental role in optimizing traffic in Data Center Networks (DCN). Currently, DCNs mainly implement two main CC protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are based on Explicit Congestion Notification (ECN), where intermediate switches mark packets when they detect congestion. The ECN configuration is thus a crucial aspect on the performance of CC protocols. Nowadays, network experts set static ECN parameters carefully selected to optimize the average network performance. However, today's high-speed DCNs experience quick and abrupt changes that severely change the network state (e.g., dynamic traffic workloads, incast events, failures). This leads to under-utilization and sub-optimal performance. This paper presents GraphCC, a novel Machine Learning-based framework for in-network CC optimization. Our distributed solution relies on a novel combination of Multi-agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN), and it is compatible with widely deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches that communicate with their neighbors to cooperate and optimize the global ECN configuration. In our evaluation, we test the performance of GraphCC under a wide variety of scenarios, focusing on the capability of this solution to adapt to new scenarios unseen during training (e.g., new traffic workloads, failures, upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for ECN tuning -- ACC -- and observe that our proposed solution outperforms the state-of-the-art baseline in all of the evaluation scenarios, showing improvements up to $20\%$ in Flow Completion Time as well as significant reductions in buffer occupancy ($38.0-85.7\%$).
</details>
<details>
<summary>摘要</summary>
优化数据中心网络（DCN）的压力控制（CC）在DCN中扮演了基本角色。目前，DCN主要实施两种主要的CC协议：DCTCP和DCQCN。这两种协议都基于显式压力通知（ECN），中间交换机会在检测压力时标识包。因此，ECN配置成为CC协议的关键方面。现在，网络专家通过精心选择ECN参数来优化平均网络性能。然而，今天的高速DCN快速和突然改变网络状态（例如，动态流量负荷、快速响应事件、故障），这会导致网络资源的过度使用和低效。本文介绍了一种基于机器学习的GraphCC框架，用于在网络中进行CC优化。我们的分布式解决方案基于多智能学习（MARL）和图神经网络（GNN），与广泛部署的ECN基本协议相容。GraphCC在交换机上部署分布式代理，与邻居交换机通信以协同优化全局ECN配置。在我们的评估中，我们测试了GraphCC在多种场景下的性能，特别是它在新的场景（例如，新的流量负荷、故障、升级）下的适应能力。我们与一种状态 искусственный智能（AI）基于MARL的ECN调节解决方案（ACC）进行比较，并观察到我们提议的解决方案在所有评估场景中都超过了基线，表现提高了$20\%$的流程完成时间以及显著减少了缓存占用($38.0-85.7\%$)。
</details></li>
</ul>
<hr>
<h2 id="Towards-true-discovery-of-the-differential-equations"><a href="#Towards-true-discovery-of-the-differential-equations" class="headerlink" title="Towards true discovery of the differential equations"></a>Towards true discovery of the differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04901">http://arxiv.org/abs/2308.04901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itmo-nss-team/klr2023_paper">https://github.com/itmo-nss-team/klr2023_paper</a></li>
<li>paper_authors: Alexander Hvatov, Roman Titov</li>
<li>for: 该论文旨在开发可解释性模型，尤其在自然相关应用中。</li>
<li>methods: 该论文使用机器学习子领域的差分方程发现技术，通过专业地包含通用参数形式的方程动力公式和适当的差分项，使算法能够自主挖掘数据中的方程。</li>
<li>results: 论文探讨了独立方程发现的前提和工具，并解决了评估发现方程的准确性问题，以提供不良方程发现的可靠性评估。<details>
<summary>Abstract</summary>
Differential equation discovery, a machine learning subfield, is used to develop interpretable models, particularly in nature-related applications. By expertly incorporating the general parametric form of the equation of motion and appropriate differential terms, algorithms can autonomously uncover equations from data. This paper explores the prerequisites and tools for independent equation discovery without expert input, eliminating the need for equation form assumptions. We focus on addressing the challenge of assessing the adequacy of discovered equations when the correct equation is unknown, with the aim of providing insights for reliable equation discovery without prior knowledge of the equation form.
</details>
<details>
<summary>摘要</summary>
通过机器学习子领域的差分方程发现，我们可以开发可解释的模型，特别是在自然相关的应用中。通过专业地包含普遍参数形式的运动方程和适当的差分项，算法可以自动从数据中找到方程。本文探讨独立差分方程发现的先决条件和工具，以消除专家参与的假设。我们主要关注评估发现的方程是否准确，即使正确的方程未知。我们的目标是提供可靠的方程发现无需先知方程形式的 Insights。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients"><a href="#Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients" class="headerlink" title="Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients"></a>Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05765">http://arxiv.org/abs/2308.05765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman, Mouli Bardhan Paul Angon</li>
<li>for: 预测心衰竭患者生存可能性，以便早期干预并提高患者结果。</li>
<li>methods: 利用数据预处理技术和Extra-Tree（ET）特征选择方法，并与Random Forest（RF）分类器结合，以提高心衰竭患者生存预测精度。</li>
<li>results: 通过使用ET特征选择算法，分别在不同的矩阵上进行了Grid Search，并最终选择了最佳的RF模型，实现了98.33%的准确率，这是现有工作中最高的准确率。<details>
<summary>Abstract</summary>
Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种可能致命的疾病，全球范围内有数百万人受其害。能准确预测患者存活可以提供早期干预，提高患者结果。本研究探讨了利用数据处理技术和EXTRA-TREE（ET）特征选择方法，与Random Forest（RF）分类器结合，以提高心力衰竭患者存活预测精度。通过利用ET特征选择算法，我们希望确定心力衰竭存活预测中最重要的预测因素。使用公共的UCL心力衰竭存活数据集，我们采用ET特征选择算法，并将选择出的特征作为RF模型的输入。最后，我们使用不同的矩阵进行RF模型的调整，并训练和评估模型。我们的方法实现了98.33%的准确率，这是已有工作中最高的精度。
</details></li>
</ul>
<hr>
<h2 id="Targeted-and-Troublesome-Tracking-and-Advertising-on-Children’s-Websites"><a href="#Targeted-and-Troublesome-Tracking-and-Advertising-on-Children’s-Websites" class="headerlink" title="Targeted and Troublesome: Tracking and Advertising on Children’s Websites"></a>Targeted and Troublesome: Tracking and Advertising on Children’s Websites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04887">http://arxiv.org/abs/2308.04887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Moti, Asuman Senol, Hamid Bostani, Frederik Zuiderveen Borgesius, Veelasha Moonsamy, Arunesh Mathur, Gunes Acar</li>
<li>for: 这项研究的目的是对于儿童Directed websites上的跟踪和广告实现监测和分析，以了解现有的隐私和广告安全问题。</li>
<li>methods: 该研究使用了多语言分类器和爬虫技术来检测和分类儿童Directed websites，并对这些网站上的跟踪和广告进行了评估。</li>
<li>results: 研究发现大约90%的儿童Directed websites中存在至少一个跟踪器，而27%的网站上显示了targeted广告，其中一些广告包含了不适和性化的图像和文本。这些结果表明许多广告商和儿童Directed websites不遵守隐私法规和广告安全标准。<details>
<summary>Abstract</summary>
On the modern web, trackers and advertisers frequently construct and monetize users' detailed behavioral profiles without consent. Despite various studies on web tracking mechanisms and advertisements, there has been no rigorous study focusing on websites targeted at children. To address this gap, we present a measurement of tracking and (targeted) advertising on websites directed at children. Motivated by lacking a comprehensive list of child-directed (i.e., targeted at children) websites, we first build a multilingual classifier based on web page titles and descriptions. Applying this classifier to over two million pages, we compile a list of two thousand child-directed websites. Crawling these sites from five vantage points, we measure the prevalence of trackers, fingerprinting scripts, and advertisements. Our crawler detects ads displayed on child-directed websites and determines if ad targeting is enabled by scraping ad disclosure pages whenever available. Our results show that around 90% of child-directed websites embed one or more trackers, and about 27% contain targeted advertisements--a practice that should require verifiable parental consent. Next, we identify improper ads on child-directed websites by developing an ML pipeline that processes both images and text extracted from ads. The pipeline allows us to run semantic similarity queries for arbitrary search terms, revealing ads that promote services related to dating, weight loss, and mental health; as well as ads for sex toys and flirting chat services. Some of these ads feature repulsive and sexually explicit imagery. In summary, our findings indicate a trend of non-compliance with privacy regulations and troubling ad safety practices among many advertisers and child-directed websites. To protect children and create a safer online environment, regulators and stakeholders must adopt and enforce more stringent measures.
</details>
<details>
<summary>摘要</summary>
现代网络上，跟踪者和广告商经常构建和利用用户的详细行为profile，而不需要用户的同意。虽然有各种研究关于网络跟踪机制和广告，但没有一份严格的研究关于向儿童targeted的网站。为了填补这一空白，我们提供了一项测量网络跟踪和targeted广告的研究。由于缺乏全面的儿童irected（即向儿童targeted）网站列表，我们首先基于网页标题和描述建立了多语言分类器。应用这个分类器到超过两百万页面后，我们编辑了二千个儿童irected网站的列表。从五个视角下载这些站点，我们测量了跟踪器、指纹脚本和广告的存在。我们的抓取器可以在儿童irected网站上显示广告并确定广告是否启用了透明的父母consent。我们的结果显示，大约90%的儿童irected网站包含一个或多个跟踪器，而约27%的网站包含targeted广告，这种实践应该需要可靠的父母consent。接着，我们使用ML管道来识别在儿童irected网站上的不当广告。这个管道可以处理图像和文本抽取自广告，并允许我们对任意搜索关键词进行语义相似性查询，暴露出promote services related to dating, weight loss, and mental health，以及sex toys和flirting chat services的广告。一些这些广告具有俗气和色情内容。总之，我们的发现表明许多广告商和child-directed网站存在隐私法规和不安全的广告实践的趋势。为了保护儿童和创造更安全的网络环境，Regulators和相关方需要采取和实施更加严格的措施。
</details></li>
</ul>
<hr>
<h2 id="Decorrelating-neurons-using-persistence"><a href="#Decorrelating-neurons-using-persistence" class="headerlink" title="Decorrelating neurons using persistence"></a>Decorrelating neurons using persistence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04870">http://arxiv.org/abs/2308.04870</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rballeba/decorrelatingneuronsusingpersistence">https://github.com/rballeba/decorrelatingneuronsusingpersistence</a></li>
<li>paper_authors: Rubén Ballester, Carles Casacuberta, Sergio Escalera</li>
<li>for: 提高深度学习模型的泛化能力</li>
<li>methods: 使用最小杂植树的谱边 weights 计算两个正则化项，以降低神经元之间的高相关性</li>
<li>results: 比较各种普遍的正则化项，证明了我们的正则化项的效果，并且表明了神经元之间的 redundancy 在人工神经网络中扮演着重要角色。<details>
<summary>Abstract</summary>
We propose a novel way to improve the generalisation capacity of deep learning models by reducing high correlations between neurons. For this, we present two regularisation terms computed from the weights of a minimum spanning tree of the clique whose vertices are the neurons of a given network (or a sample of those), where weights on edges are correlation dissimilarities. We provide an extensive set of experiments to validate the effectiveness of our terms, showing that they outperform popular ones. Also, we demonstrate that naive minimisation of all correlations between neurons obtains lower accuracies than our regularisation terms, suggesting that redundancies play a significant role in artificial neural networks, as evidenced by some studies in neuroscience for real networks. We include a proof of differentiability of our regularisers, thus developing the first effective topological persistence-based regularisation terms that consider the whole set of neurons and that can be applied to a feedforward architecture in any deep learning task such as classification, data generation, or regression.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来提高深度学习模型的泛化能力，通过减少神经元之间的高相关性。为此，我们提出了两种正则化项，它们是基于神经网络中最小拓扑树的节点（神经元）的权重的 correlate dissimilarity 的边 weights。我们进行了广泛的实验 validate 这些正则化项的效果，并证明它们超过了流行的正则化项。此外，我们还示出了使用所有神经元之间的相关性进行简单的最小化会导致模型的准确率下降，这表明神经网络中存在很多重复的结构，这与一些 neuroscience 研究中的真实神经网络相符。我们还证明了我们的正则化项是可导的，因此我们开发了首次有效的拓扑persistence-based 正则化项，可以应用于任何深度学习任务，如分类、数据生成或回归。
</details></li>
</ul>
<hr>
<h2 id="Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis"><a href="#Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis" class="headerlink" title="Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?"></a>Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05129">http://arxiv.org/abs/2308.05129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nina Weng, Siavash Bigdeli, Eike Petersen, Aasa Feragen</li>
<li>for: 这个研究旨在探讨胸部X射线诊断中的性别偏见的原因。</li>
<li>methods: 作者提出了一种新的采样方法，以解决两个公共数据集中每个病人记录的极度不均衡的问题，同时减少标签错误的影响。</li>
<li>results: 研究发现，数据集特有的因素，而不是基本的生理差异，是胸部X射线诊断中男女性能差异的主要驱动力。<details>
<summary>Abstract</summary>
While many studies have assessed the fairness of AI algorithms in the medical field, the causes of differences in prediction performance are often unknown. This lack of knowledge about the causes of bias hampers the efficacy of bias mitigation, as evidenced by the fact that simple dataset balancing still often performs best in reducing performance gaps but is unable to resolve all performance differences. In this work, we investigate the causes of gender bias in machine learning-based chest X-ray diagnosis. In particular, we explore the hypothesis that breast tissue leads to underexposure of the lungs and causes lower model performance. Methodologically, we propose a new sampling method which addresses the highly skewed distribution of recordings per patient in two widely used public datasets, while at the same time reducing the impact of label errors. Our comprehensive analysis of gender differences across diseases, datasets, and gender representations in the training set shows that dataset imbalance is not the sole cause of performance differences. Moreover, relative group performance differs strongly between datasets, indicating important dataset-specific factors influencing male/female group performance. Finally, we investigate the effect of breast tissue more specifically, by cropping out the breasts from recordings, finding that this does not resolve the observed performance gaps. In conclusion, our results indicate that dataset-specific factors, not fundamental physiological differences, are the main drivers of male--female performance gaps in chest X-ray analyses on widely used NIH and CheXpert Dataset.
</details>
<details>
<summary>摘要</summary>
尽管许多研究已经评估了人工智能算法在医疗领域的公平性，但对于不同性能的原因常常无法得知。这种不知道偏见的原因使得偏见缓和措施无法充分发挥作用，如果只通过简单地数据平衡来减少性能差距，但是无法解决所有的性能差距。在这项工作中，我们调查了机器学习基于胸部X射影的性别偏见的原因。特别是，我们研究了胸部肉体对肺部的Underexposure的影响，是否导致较低的模型性能。我们提出了一种新的采样方法，以解决两个广泛使用的公共数据集中记录每个患者的高度不均衡的问题，同时减少标签错误的影响。我们的全面分析表明，数据集偏见不是唯一的原因，而且男女群体性能之间的差距强烈地受到数据集特定的因素的影响。此外，我们发现在不同的疾病、数据集和训练集中，男女群体的表现差异很大，这表明了数据集特定的因素对男女群体表现的重要影响。最后，我们具体研究了胸部肉体的影响，通过从记录中cropping出胸部，发现这并不能解决观察到的性能差距。结论是，我们的结果表明，在广泛使用的NIH和CheXpert数据集中，数据集特定的因素，而不是基础的生理学差异，是 male--female 性能差距的主要驱动力。
</details></li>
</ul>
<hr>
<h2 id="Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning"><a href="#Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning"></a>Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04844">http://arxiv.org/abs/2308.04844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Thomas Somers, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 这 paper  investigate 多 Agent 系统中 Agent 之间的 Communication 协议，以实现 Goal。</li>
<li>methods: 该 paper 使用 Multi-Agent Reinforcement Learning 技术，学习 Communication 协议并 Action 协议。</li>
<li>results: 研究发现，增加信息量和 Agent 数量会影响 Message 编码方法的性能。mean Message Encoder consistently outperforms attention Message Encoder。Agents 使用 exponential 和 logarithmic 函数组合来确保信息不产生重要信息丢失。<details>
<summary>Abstract</summary>
Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the agents use a combination of an exponential and a logarithmic function in their communication policy to avoid the loss of important information after applying the mean message encoder.
</details>
<details>
<summary>摘要</summary>
多个自动机制系统需要间接机器人之间的交流以达到目标。通过使用多自动机器人学习回报学习技术，机器人可以适应决定需要交换哪些信息。然而，当机器人数量增加时，我们需要设计机器人之间信息的编码方式。在这篇论文中，我们研究增加信息内容的消息编码方法和机器人数量之间的影响。我们使用两种消息编码方法进行比较：平均消息编码器和注意力消息编码器。我们在矩阵环境中进行实验，结果显示，平均消息编码器一直高于注意力消息编码器。因此，我们分析了使用平均消息编码器的机器人通信策略，并结论机器人使用一种加速和对数函数在其通信策略中，以避免消息编码后重要信息的丢失。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI"><a href="#Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI" class="headerlink" title="Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI"></a>Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05764">http://arxiv.org/abs/2308.05764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oetu/mmcl-ecg-cmr">https://github.com/oetu/mmcl-ecg-cmr</a></li>
<li>paper_authors: Özgün Turgut, Philip Müller, Paul Hager, Suprosanna Shit, Sophie Starck, Martin J. Menten, Eimo Martens, Daniel Rueckert</li>
<li>for: 本研究旨在使用低成本和快速的电cardiogram（ECG）诊断工具，以便评估Cardiovascular health，但是更详细的Cardiac magnetic resonance（CMR）成像技术frequently preferred for cardiovascular disease diagnosis。</li>
<li>methods: 本研究提出了第一个自我超级对比方法，将CMR图像领域特有的信息传递到ECG嵌入中。该方法结合多模态对比学习和masked数据模型，以实现各种cardiac screening solely from ECG data。</li>
<li>results: 在40,044名UK BiobankSubjects的广泛实验中，我们证明了我们的方法的实用性和普遍性。我们预测了每个人specific risk of various cardiovascular diseases，并确定了各种cardiac phenotypes solely from ECG data。在质量分析中，我们示出了我们学习的ECG嵌入中包含了CMR图像区域特有的信息。<details>
<summary>Abstract</summary>
The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from ECG data. In a qualitative analysis, we demonstrate that our learned ECG embeddings incorporate information from CMR image regions of interest. We make our entire pipeline publicly available, including the source code and pre-trained model weights.
</details>
<details>
<summary>摘要</summary>
电 electrocardiogram (ECG) 是一种广泛可用的诊断工具，可以快速、效率地评估心血管健康。然而，更详细的检查通常使用昂贵的心血管 Ressonance 成像 (CMR) 技术进行诊断心血管疾病。虽然提供了详细的心血管解剖图像，但 CMR 成像因长时间扫描和高成本而不够普及。为解决这个问题，我们提出了首个自动超级对比方法，将域特异的信息从 CMR 图像传递到 ECG 嵌入。我们的方法结合多模态对比学习和遮盖数据模型，以实现基于 ECG 数据的整体卡ди亚屏检查。在使用 UK Biobank 数据集的广泛实验中，我们证明了我们的方法的实用性和普遍性。我们预测参与者的具体风险以及不同心血管疾病的各种Cardiac phenotypes  solely from ECG data。在质量分析中，我们示示了我们学习的 ECG 嵌入包含 CMR 图像区域关注的信息。我们整个气管系统公开了整个管道，包括源代码和预训练模型参数。
</details></li>
</ul>
<hr>
<h2 id="Intrinsic-Motivation-via-Surprise-Memory"><a href="#Intrinsic-Motivation-via-Surprise-Memory" class="headerlink" title="Intrinsic Motivation via Surprise Memory"></a>Intrinsic Motivation via Surprise Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04836">http://arxiv.org/abs/2308.04836</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opendilab/DI-engine">https://github.com/opendilab/DI-engine</a></li>
<li>paper_authors: Hung Le, Kien Do, Dung Nguyen, Svetha Venkatesh</li>
<li>for: 提出了一种新的计算模型，用于替代现有的惊讶驱动的探索。</li>
<li>methods: 使用了一种记忆网络来估计惊讶新意，并将其作为奖励。</li>
<li>results: 实验结果表明，该模型在缺乏奖励的环境中可以具有高效的探索行为，并在杂乱的Atari游戏中显示出显著的提高。<details>
<summary>Abstract</summary>
We present a new computing model for intrinsic rewards in reinforcement learning that addresses the limitations of existing surprise-driven explorations. The reward is the novelty of the surprise rather than the surprise norm. We estimate the surprise novelty as retrieval errors of a memory network wherein the memory stores and reconstructs surprises. Our surprise memory (SM) augments the capability of surprise-based intrinsic motivators, maintaining the agent's interest in exciting exploration while reducing unwanted attraction to unpredictable or noisy observations. Our experiments demonstrate that the SM combined with various surprise predictors exhibits efficient exploring behaviors and significantly boosts the final performance in sparse reward environments, including Noisy-TV, navigation and challenging Atari games.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的计算模型，用于内在奖励在机器学习中的惊喜探索。这种模型利用惊喜的新性而不是惊喜的 норма来计算奖励。我们使用记忆网络来估计惊喜的新性，并将其称为惊喜记忆（SM）。我们的SM可以增强惊喜基于内在奖励的能力，使代理人保持有趣的探索，同时减少不必要的吸引到随机或噪音观察的吸引力。我们的实验显示，SM与不同的惊喜预测器结合使用可以实现高效的探索行为，并在罕见奖励环境中提高最终性能，包括噪音电视、导航和复杂的Atari游戏。
</details></li>
</ul>
<hr>
<h2 id="TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks"><a href="#TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks" class="headerlink" title="TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks"></a>TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04832">http://arxiv.org/abs/2308.04832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 提高神经网络的数值稳定性</li>
<li>methods: 提出新的激活函数Truncated and Signed Square Root (TSSR)函数</li>
<li>results: TSSR函数在各种应用领域中的表现比其他状态OF-the-art激活函数更好<details>
<summary>Abstract</summary>
Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.
</details>
<details>
<summary>摘要</summary>
activation functions 是 neural network 的重要组件。本文提出了一新的 activation function，即 Truncated and Signed Square Root (TSSR) 函数。这个函数特别之处在于它是odd、非线性、单调的，梯度连续和一定的。这些属性使得 TSSR 函数有改善神经网络的数学稳定性的潜力。几个实验表明，提议的 TSSR 函数在比较当前的 activation functions 中表现更好。这种函数对神经网络模型的发展具有重要意义，可以应用于计算机视觉、自然语言处理和语音识别等领域。
</details></li>
</ul>
<hr>
<h2 id="On-the-Unexpected-Abilities-of-Large-Language-Models"><a href="#On-the-Unexpected-Abilities-of-Large-Language-Models" class="headerlink" title="On the Unexpected Abilities of Large Language Models"></a>On the Unexpected Abilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09720">http://arxiv.org/abs/2308.09720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Nolfi</li>
<li>for: 本文研究大型语言模型display的多种能力，包括预测人类写作的下一个词。</li>
<li>methods: 本文使用大型语言模型进行研究，分析其间接获得的能力和其与其他知名间接过程的关系。</li>
<li>results: 研究发现，大型语言模型通过间接获得的过程，开发出了一系列整体能力。此外，研究还发现这些能力的发展程度有一定的预测性。最后，本文 briefly discusses大型语言模型所获得的认知能力和人类认知之间的关系。<details>
<summary>Abstract</summary>
Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
</details>
<details>
<summary>摘要</summary>
大型语言模型可以显示广泛的能力，并不直接与它们的训练任务相关：预测人写的文本中的下一个字。在这篇文章中，我讨论这种 indirect acquisition 的过程和其他已知的 indirect process 的关系。我认为这种 indirect acquisition 的一个重要副作用是发展集成的能力。我讨论这些系统所获得的能力是否可预测。最后，我简 briefly discuss 这些系统所获得的认知技能和人类认知之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Bayes-Risk-Consistency-of-Nonparametric-Classification-Rules-for-Spike-Trains-Data"><a href="#Bayes-Risk-Consistency-of-Nonparametric-Classification-Rules-for-Spike-Trains-Data" class="headerlink" title="Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data"></a>Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04796">http://arxiv.org/abs/2308.04796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mirosław Pawlak, Mateusz Pabian, Dominik Rzepka</li>
<li>for: 这篇论文是用于探讨干扰讯号数据的应用和机器学习策略。</li>
<li>methods: 这篇论文使用了机器学习的神经网络和概率模型，特别是非 Parametric 方法。</li>
<li>results: 论文提出了一种基于 Bayes 规则的非 Parametric 核函数分类器，并证明了这种分类器在不断 recording time interval 和训练集大小的情况下的极限。<details>
<summary>Abstract</summary>
Spike trains data find a growing list of applications in computational neuroscience, imaging, streaming data and finance. Machine learning strategies for spike trains are based on various neural network and probabilistic models. The probabilistic approach is relying on parametric or nonparametric specifications of the underlying spike generation model. In this paper we consider the two-class statistical classification problem for a class of spike train data characterized by nonparametrically specified intensity functions. We derive the optimal Bayes rule and next form the plug-in nonparametric kernel classifier. Asymptotical properties of the rules are established including the limit with respect to the increasing recording time interval and the size of a training set. In particular the convergence of the kernel classifier to the Bayes rule is proved. The obtained results are supported by a finite sample simulation studies.
</details>
<details>
<summary>摘要</summary>
随着计算神经科学、成像、流动数据和金融等领域中的应用，锤形数据（spike train）在计算机科学中找到了一个不断增长的应用范围。机器学习策略 для锤形数据基于不同的神经网络和概率模型。概率方法基于锤形数据的下面参数化或非参数化模型规定。在本文中，我们考虑一种锤形数据的两类统计分类问题，其中锤形数据由非参数化强度函数特征。我们 derivate了最佳拟合规则，然后形成插入式非参数化核函数分类器。我们确定了这些规则的非正式性质，包括随着记录时间间隔的增长和训练集大小的限制。具体来说，我们证明了核函数分类器的拟合规则与拟合规则之间的连续性。获得的结果得到了finite sample simulations的支持。
</details></li>
</ul>
<hr>
<h2 id="PETformer-Long-term-Time-Series-Forecasting-via-Placeholder-enhanced-Transformer"><a href="#PETformer-Long-term-Time-Series-Forecasting-via-Placeholder-enhanced-Transformer" class="headerlink" title="PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer"></a>PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04791">http://arxiv.org/abs/2308.04791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengsheng Lin, Weiwei Lin, Wentai Wu, Songbo Wang, Yongxiang Wang</li>
<li>for: 这 paper  investigate 应用 Transformer 到长期时间序列预测（LTSF）任务中的三个关键问题，包括时间连续性、信息密度和多通道关系。</li>
<li>methods: 该 paper 提出了三种创新解决方案，包括 Placeholder Enhancement Technique (PET)、Long Sub-sequence Division (LSD) 和 Multi-channel Separation and Interaction (MSI)，这三种方法结合成一个 novel model 称为 PETformer。</li>
<li>results: 广泛的实验表明，PETformer 在八个公共数据集上实现了状态空间（SOTA）的表现，超过了所有目前可用的其他模型。这表明 Transformer 仍具有在 LTSF 任务中的强大能力。<details>
<summary>Abstract</summary>
Recently, Transformer-based models have shown remarkable performance in long-term time series forecasting (LTSF) tasks due to their ability to model long-term dependencies. However, the validity of Transformers for LTSF tasks remains debatable, particularly since recent work has shown that simple linear models can outperform numerous Transformer-based approaches. This suggests that there are limitations to the application of Transformer in LTSF. Therefore, this paper investigates three key issues when applying Transformer to LTSF: temporal continuity, information density, and multi-channel relationships. Accordingly, we propose three innovative solutions, including Placeholder Enhancement Technique (PET), Long Sub-sequence Division (LSD), and Multi-channel Separation and Interaction (MSI), which together form a novel model called PETformer. These three key designs introduce prior biases suitable for LTSF tasks. Extensive experiments have demonstrated that PETformer achieves state-of-the-art (SOTA) performance on eight commonly used public datasets for LTSF, outperforming all other models currently available. This demonstrates that Transformer still possesses powerful capabilities in LTSF.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:近期，基于Transformer的模型在长期时间序预测（LTSF）任务中表现出色，归功于它们能够模型长期相互关系。然而，使用Transformer进行LTSF任务的有效性仍然存在争议，尤其是最近的研究表明，简单的线性模型可以超越许多基于Transformer的方法。这表明在LTSF任务中使用Transformer存在限制。因此，本文研究了在应用Transformer到LTSF任务时的三个关键问题：时间连续性、信息密度和多通道关系。根据这些问题，我们提出了三个创新的解决方案，包括Placeholder增强技术（PET）、长 subsequences分配（LSD）和多通道分离和互动（MSI），这些设计共同组成了一个名为PETformer的新模型。这三个关键设计引入了适合LTSF任务的先验偏好。经过广泛的实验，我们发现PETformer在八个公共数据集上实现了状态的最佳表现（SOTA），比所有当前可用的模型都高。这表明Transformer在LTSF任务中仍然拥有强大的能力。
</details></li>
</ul>
<hr>
<h2 id="SUnAA-Sparse-Unmixing-using-Archetypal-Analysis"><a href="#SUnAA-Sparse-Unmixing-using-Archetypal-Analysis" class="headerlink" title="SUnAA: Sparse Unmixing using Archetypal Analysis"></a>SUnAA: Sparse Unmixing using Archetypal Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04771">http://arxiv.org/abs/2308.04771</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/behnoodrasti/sunaa">https://github.com/behnoodrasti/sunaa</a></li>
<li>paper_authors: Behnood Rasti, Alexandre Zouaoui, Julien Mairal, Jocelyn Chanussot</li>
<li>for: 本研究旨在提出一种新的稀疏分解技术，使用体例分析（SUnAA）。</li>
<li>methods: 我们提出了一种基于体例分析的新模型，假设需要的终结点是spectral库中提供的终结点的叠加。然后，我们提出了一个非凸最小化问题，并使用活动集算法进行迭代最小化。</li>
<li>results: 我们通过两个 simulations datasets的测试，发现SUnAA的性能比普通的稀疏分解方法和先进的方法更好，具有较低的信号征化误差。此外，我们还应用了SUnAA于Cuprite数据集，并与可用的地质地图进行比较，结果表明SUnAA可以成功估计矿物含量，并提高主要矿物的检测。<details>
<summary>Abstract</summary>
This paper introduces a new sparse unmixing technique using archetypal analysis (SUnAA). First, we design a new model based on archetypal analysis. We assume that the endmembers of interest are a convex combination of endmembers provided by a spectral library and that the number of endmembers of interest is known. Then, we propose a minimization problem. Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex. We minimize the optimization objective iteratively using an active set algorithm. Our method is robust to the initialization and only requires the number of endmembers of interest. SUnAA is evaluated using two simulated datasets for which results confirm its better performance over other conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to Cuprite dataset and the results are compared visually with the available geological map provided for this dataset. The qualitative assessment demonstrates the successful estimation of the minerals abundances and significantly improves the detection of dominant minerals compared to the conventional regression-based sparse unmixing methods. The Python implementation of SUnAA can be found at: https://github.com/BehnoodRasti/SUnAA.
</details>
<details>
<summary>摘要</summary>
The performance of SUnAA is evaluated using two simulated datasets, and the results show that it outperforms conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to the Cuprite dataset and the results are compared visually with the available geological map. The qualitative assessment demonstrates the successful estimation of mineral abundances and the improved detection of dominant minerals compared to conventional regression-based sparse unmixing methods.The Python implementation of SUnAA can be found at the following link: <https://github.com/BehnoodRasti/SUnAA>.Translated into Simplified Chinese:这篇论文介绍了一种新的稀疏混合技术基于形态分析（SUnAA）。该方法假设 interessant endmembers 是 spectral library 中的累累组合，并且知道 interested endmembers 的数量。然后，我们提出了一个非凸优化问题，并使用 active set 算法进行迭代优化。该方法具有初始化Robustness和只需要 interested endmembers 的数量。我们使用两个 simulated dataset 进行评估 SUnAA 的性能，结果显示它在 signal-to-reconstruction error 方面表现出色，超过了 conventional 和 advanced 方法。此外，我们还应用 SUnAA 于 Cuprite dataset，并与可用的地质地图进行比较。结果表明 SUnAA 能够成功估计矿物质含量，并提高 dominant 矿物质的检测。Python 实现 SUnAA 可以在以下链接中找到：<https://github.com/BehnoodRasti/SUnAA>。Translated into Traditional Chinese:这篇论文介绍了一种新的稀疏混合技术基于形态分析（SUnAA）。该方法假设 interessant endmembers 是 spectral library 中的累累组合，并且知道 interested endmembers 的数量。然后，我们提出了一个非凸优化问题，并使用 active set 算法进行迭代优化。该方法具有初始化Robustness和只需要 interested endmembers 的数量。我们使用两个 simulated dataset 进行评估 SUnAA 的性能，结果显示它在 signal-to-reconstruction error 方面表现出色，超过了 conventional 和 advanced 方法。此外，我们还应用 SUnAA 于 Cuprite dataset，并与可用的地质地图进行比较。结果表明 SUnAA 能够成功估计矿物质含量，并提高 dominant 矿物质的检测。Python 实现 SUnAA 可以在以下链接中找到：<https://github.com/BehnoodRasti/SUnAA>。
</details></li>
</ul>
<hr>
<h2 id="Tram-FL-Routing-based-Model-Training-for-Decentralized-Federated-Learning"><a href="#Tram-FL-Routing-based-Model-Training-for-Decentralized-Federated-Learning" class="headerlink" title="Tram-FL: Routing-based Model Training for Decentralized Federated Learning"></a>Tram-FL: Routing-based Model Training for Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04762">http://arxiv.org/abs/2308.04762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KotaMaejima/Tram-FL">https://github.com/KotaMaejima/Tram-FL</a></li>
<li>paper_authors: Kota Maejima, Takayuki Nishio, Asato Yamazaki, Yuko Hara-Azumi</li>
<li>for: 提高 federated learning 中 nodes 之间的交互频率和非独立同分布数据的准确性。</li>
<li>methods: 提出了一种新的 federated learning 方法，称为 Tram-FL，它逐渐改进全局模型，通过在节点之间传递模型，而不是通过交换和聚合本地模型。同时，引入了一种动态模型路由算法，以优化模型精度，尽可能减少前向传输。</li>
<li>results: 通过 MNIST、CIFAR-10 和 IMDb 数据集的实验表明，Tram-FL 并与提出的路由算法可以在非独立同分布条件下实现高精度模型，与基elines 相比，减少了交通成本。<details>
<summary>Abstract</summary>
In decentralized federated learning (DFL), substantial traffic from frequent inter-node communication and non-independent and identically distributed (non-IID) data challenges high-accuracy model acquisition. We propose Tram-FL, a novel DFL method, which progressively refines a global model by transferring it sequentially amongst nodes, rather than by exchanging and aggregating local models. We also introduce a dynamic model routing algorithm for optimal route selection, aimed at enhancing model precision with minimal forwarding. Our experiments using MNIST, CIFAR-10, and IMDb datasets demonstrate that Tram-FL with the proposed routing delivers high model accuracy under non-IID conditions, outperforming baselines while reducing communication costs.
</details>
<details>
<summary>摘要</summary>
在分布式联合学习（DFL）中，频繁的节点间通信和非独立同分布（非IID）数据对高精度模型获得带来了挑战。我们提出了Tram-FL方法，它逐步提高全球模型，通过在节点之间逐步传输全球模型，而不是通过交换和汇总本地模型。我们还提出了动态模型路由算法，用于优化路由，以提高模型精度并最小化前进通信成本。我们通过使用MNIST、CIFAR-10和IMDb数据集进行实验，显示Tram-FL与提议的路由可以在非IID条件下提高模型精度，而且比基eline减少通信成本。
</details></li>
</ul>
<hr>
<h2 id="Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning"><a href="#Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning" class="headerlink" title="Feature Matching Data Synthesis for Non-IID Federated Learning"></a>Feature Matching Data Synthesis for Non-IID Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04761">http://arxiv.org/abs/2308.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Li, Yuchang Sun, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, Jun Zhang</li>
<li>for: 这种论文是为了解决 Federated Learning (FL) 中的非独立和相同分布 (non-IID) 数据问题，提出了一种困难特征匹配数据生成 (HFMDS) 方法，以及一种硬特征增强方法，以提高模型通用性和隐私保护。</li>
<li>methods: 这种论文使用了一种基于 HFMDS 的 FL 框架，并提出了一种基于硬特征增强的匹配数据生成方法，以及一种理论分析，证明 HFMDS 方法的有效性。</li>
<li>results:  simulation 结果表明，与基eline 相比，该提议的 HFMDS-FL 算法在不同的 benchmark 数据集上达到了更高的准确率、隐私保护和计算成本。<details>
<summary>Abstract</summary>
Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Federated learning（FL）已经 emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed（non-IID）data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis（HFMDS）method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.Note: Please note that the translation is in Simplified Chinese, which is one of the two standardized Chinese scripts used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Learning-From-Distributed-Data-With-Differentially-Private-Synthetic-Twin-Data"><a href="#Collaborative-Learning-From-Distributed-Data-With-Differentially-Private-Synthetic-Twin-Data" class="headerlink" title="Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data"></a>Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04755">http://arxiv.org/abs/2308.04755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dpbayes/collaborative-learning-with-dp-synthetic-twin-data">https://github.com/dpbayes/collaborative-learning-with-dp-synthetic-twin-data</a></li>
<li>paper_authors: Lukas Prediger, Joonas Jälkö, Antti Honkela, Samuel Kaski</li>
<li>for: 这个论文是为了解决多个党部拥有敏感数据的问题，即如何协同学习人口级统计数据，而不论pooling敏感数据集。</li>
<li>methods: 作者提议了一种方案，即每个党部都将其敏感数据分配到一个隐私保护的同步双数据集中，然后这些同步双数据集可以被共同学习。</li>
<li>results: 作者发现，通过共同学习这些同步双数据集，党部可以获得更加准确的目标统计数据，尤其是在小型多样化数据集中。此外，参与更多党部时，共同学习的改进会变得更大和更一致。最后，作者发现，分享同步双数据可以帮助党部 Whose 数据包含少数群体更好地进行准确的分析。根据这些结果，作者结论，共同学习同步双数据是一种可靠的隐私保护方法，可以帮助党部学习敏感数据，即使个体数据集小或不代表整个人口。<details>
<summary>Abstract</summary>
Consider a setting where multiple parties holding sensitive data aim to collaboratively learn population level statistics, but pooling the sensitive data sets is not possible. We propose a framework in which each party shares a differentially private synthetic twin of their data. We study the feasibility of combining such synthetic twin data sets for collaborative learning on real-world health data from the UK Biobank. We discover that parties engaging in the collaborative learning via shared synthetic data obtain more accurate estimates of target statistics compared to using only their local data. This finding extends to the difficult case of small heterogeneous data sets. Furthermore, the more parties participate, the larger and more consistent the improvements become. Finally, we find that data sharing can especially help parties whose data contain underrepresented groups to perform better-adjusted analysis for said groups. Based on our results we conclude that sharing of synthetic twins is a viable method for enabling learning from sensitive data without violating privacy constraints even if individual data sets are small or do not represent the overall population well. The setting of distributed sensitive data is often a bottleneck in biomedical research, which our study shows can be alleviated with privacy-preserving collaborative learning methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>设想多个方持有敏感数据，它们想要共同学习人口级统计信息，但混合敏感数据集不可能。我们提议一个框架，每个方共享一个具有隐私保护的人工创造的数据集。我们研究将这些人工创造数据集结合在一起进行共同学习，并对UK Biobank实际数据进行研究。我们发现，通过共同学习这些人工创造数据集，各方可以获得更准确的目标统计信息，包括小型不同类型数据集。此外，越来越多的方参与，改进的效果越来越大和一致。最后，我们发现，在数据分享的情况下，特别是对于包含少数群体的数据，各方可以进行更好地调整分析。根据我们的结果，我们认为共享具有隐私保护的人工创造数据集是可以保持隐私协议的有效方法，即使个人数据集小或不代表总人口。这种设定frequently bottleneck在生物医学研究中，我们的研究表明，可以使用隐私保护的共同学习方法来缓解这种瓶颈。
</details></li>
</ul>
<hr>
<h2 id="Universal-Fuzzing-via-Large-Language-Models"><a href="#Universal-Fuzzing-via-Large-Language-Models" class="headerlink" title="Universal Fuzzing via Large Language Models"></a>Universal Fuzzing via Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04748">http://arxiv.org/abs/2308.04748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, Lingming Zhang</li>
<li>for: 这篇论文的目的是为了开发一个可以针对多种输入语言和多种语言特性的整体扫描工具（Fuzzer），以找到软件系统中的漏洞和漏洞。</li>
<li>methods: 这篇论文使用了大型自然语言模型（LLM）作为输入生成和变换引擎，并提出了一种自动推荐技术来创建适合扫描的 LLM 提示。它还提出了一种基于 LLM 的扫描循环，可以逐步更新提示来生成新的扫描输入。</li>
<li>results: 在九个系统下测试，这种整体扫描技术可以对六种不同的语言（C、C++、Go、SMT2、Java 和 Python）的输入进行扫描，并且在所有六种语言中都达到了更高的覆盖率。此外，这种整体扫描技术已经发现了76个bug，其中47个已经确认了开发人员为之前未知的漏洞。<details>
<summary>Abstract</summary>
Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4All on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 76 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 47 bugs already confirmed by developers as previously unknown.
</details>
<details>
<summary>摘要</summary>
团队发现了一种新的批处理技术，即基于大语言模型（LLM）的批处理，可以覆盖各种软件系统中的漏洞和敏感性。这种技术可以覆盖各种编程语言和形式语言，如C、C++、Go、SMT2、Java和Python等，并且可以快速生成各种语言的输入数据。我们通过一种新的自动提示技术和一种基于LLM的批处理循环来实现这一点。我们在9个测试系统中进行了评估，这些测试系统接受6种不同的语言（C、C++、Go、SMT2、Java和Python）作为输入。结果表明，通过使用这种通用批处理技术，可以在所有6种语言中提高批处理覆盖率，并且已经发现了76个在广泛使用的系统中的漏洞，其中47个已经被开发者确认为新发现的漏洞。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-a-Transformer-based-network-for-a-deep-learning-seismic-processing-workflow"><a href="#Optimizing-a-Transformer-based-network-for-a-deep-learning-seismic-processing-workflow" class="headerlink" title="Optimizing a Transformer-based network for a deep learning seismic processing workflow"></a>Optimizing a Transformer-based network for a deep learning seismic processing workflow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04739">http://arxiv.org/abs/2308.04739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Randy Harsuko, Tariq Alkhalifah</li>
<li>for: 本文是一篇针对多种地震处理任务的模型，通过预训练和精度调整的训练策略来适应不同的任务。</li>
<li>methods: 本文提议对模型中的圆满位编码和自注意机制进行修改，使用相对位置编码和低级别注意矩阵来替代原始的自注意机制。</li>
<li>results: 对于处理任务，提议的修改可以提高预训练速度和精度调整任务的结果，同时减少模型的训练参数量。<details>
<summary>Abstract</summary>
StorSeismic is a recently introduced model based on the Transformer to adapt to various seismic processing tasks through its pretraining and fine-tuning training strategy. In the original implementation, StorSeismic utilized a sinusoidal positional encoding and a conventional self-attention mechanism, both borrowed from the natural language processing (NLP) applications. For seismic processing they admitted good results, but also hinted to limitations in efficiency and expressiveness. We propose modifications to these two key components, by utilizing relative positional encoding and low-rank attention matrices as replacements to the vanilla ones. The proposed changes are tested on processing tasks applied to a realistic Marmousi and offshore field data as a sequential strategy, starting from denoising, direct arrival removal, multiple attenuation, and finally root-mean-squared velocity ($V_{RMS}$) prediction for normal moveout (NMO) correction. We observe faster pretraining and competitive results on the fine-tuning tasks and, additionally, fewer parameters to train compared to the vanilla model.
</details>
<details>
<summary>摘要</summary>
史托质地震是一个最近引入的模型，基于传播者来适应多种地震处理任务。在原始实现中，史托质地震使用了正弦波 пози对编码和传统自我注意机制，这些来自自然语言处理（NLP）应用。它们在地震处理中获得了好的结果，但也表现了效率和表现力的限制。我们提出了这两个关键 комponent的修改，使用相对位对编码和低矩降低矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降矩降
</details></li>
</ul>
<hr>
<h2 id="Going-Deeper-with-Five-point-Stencil-Convolutions-for-Reaction-Diffusion-Equations"><a href="#Going-Deeper-with-Five-point-Stencil-Convolutions-for-Reaction-Diffusion-Equations" class="headerlink" title="Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations"></a>Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04735">http://arxiv.org/abs/2308.04735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongho Kim, Yongho Choi</li>
<li>for: 用于解决具有不同初始条件的第二阶征Diffusion类型方程的问题。</li>
<li>methods: 使用五点维度卷积神经网络（FCNNs）来训练模型参数，并使用两个连续的快照来训练FCNNs。</li>
<li>results: 对各种初始条件的热、斑蛋白和艾兰-卡ahn方程进行了测试，并显示了深度FCNNs可以保持一定的准确性，而不同于FDMs崩溃。<details>
<summary>Abstract</summary>
Physics-informed neural networks have been widely applied to partial differential equations with great success because the physics-informed loss essentially requires no observations or discretization. However, it is difficult to optimize model parameters, and these parameters must be trained for each distinct initial condition. To overcome these challenges in second-order reaction-diffusion type equations, a possible way is to use five-point stencil convolutional neural networks (FCNNs). FCNNs are trained using two consecutive snapshots, where the time step corresponds to the step size of the given snapshots. Thus, the time evolution of FCNNs depends on the time step, and the time step must satisfy its CFL condition to avoid blow-up solutions. In this work, we propose deep FCNNs that have large receptive fields to predict time evolutions with a time step larger than the threshold of the CFL condition. To evaluate our models, we consider the heat, Fisher's, and Allen-Cahn equations with diverse initial conditions. We demonstrate that deep FCNNs retain certain accuracies, in contrast to FDMs that blow up.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks 已经广泛应用于 partial differential equations 中，因为物理学 Informed loss 不需要观察或离散。然而，困难在优化模型参数，这些参数需要为每个特定的初始条件进行训练。为了解决这些挑战，在第二阶段反应扩散类方程中，可以使用 five-point stencil convolutional neural networks (FCNNs)。FCNNs 通过两个连续的快照，其中时间步长对应快照的步长，来训练。因此，FCNNs 的时间演化取决于时间步长，并且时间步长必须满足其 CFL 条件，以避免出现潜在的爆炸解。在这种工作中，我们提出了深度 FCNNs，它们具有大见范围，可以预测时间演化，并且时间步长大于阈值 CF 条件。为评估我们的模型，我们考虑了热、费希尔和欧兰凡方程，并使用多种初始条件。我们发现，深度 FCNNs 可以保持一定的准确性，与 FDMs 不同，后者会爆炸。
</details></li>
</ul>
<hr>
<h2 id="JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models"><a href="#JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models" class="headerlink" title="JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models"></a>JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04729">http://arxiv.org/abs/2308.04729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peike Li, Boyu Chen, Yao Yao, Yikai Wang, Allen Wang, Alex Wang</li>
<li>for: 本文旨在提出一种高精度的文本到音乐生成模型（JEN-1），用于解决文本描述下的音乐生成问题。</li>
<li>methods: 该模型基于扩散学习，结合了 autoregressive 和 non-autoregressive 训练方法，通过在上下文学习来实现多种生成任务，包括文本引导的音乐生成、音乐填充和续写。</li>
<li>results: 对比之前的方法，JEN-1 在文本音乐对齐和音乐质量方面表现出色，同时保持了计算效率。我们提供了在 <a target="_blank" rel="noopener" href="http://futureverse.com/research/jen/demos/jen1">http://futureverse.com/research/jen/demos/jen1</a> 的示例。<details>
<summary>Abstract</summary>
Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at http://futureverse.com/research/jen/demos/jen1
</details>
<details>
<summary>摘要</summary>
音乐生成已经吸引了深入的研究，随着深度生成模型的进步，但是将文本描述转化为音乐，也就是文本到音乐，仍然是一项挑战，因为音乐结构的复杂性和高采样率的要求。虽然这项任务的重要性，现有的生成模型却存在音乐质量、计算效率和泛化等方面的限制。这篇论文介绍了JEN-1，一种通用的高精度模型，用于文本到音乐生成。JEN-1是一种扩散模型，通过在 контексте学习，可以完成不同的生成任务，包括文本指导的音乐生成、音乐填充和续写。评估表明JEN-1的性能在文本音乐对齐和音乐质量方面胜过现有的方法，同时保持计算效率。我们的 demo 可以在 http://futureverse.com/research/jen/demos/jen1 中找到。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection"><a href="#Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection" class="headerlink" title="Data-Free Model Extraction Attacks in the Context of Object Detection"></a>Data-Free Model Extraction Attacks in the Context of Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05127">http://arxiv.org/abs/2308.05127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar</li>
<li>for: 这个论文旨在攻击机器学习模型，具体来说是通过使用特制的查询来盗取目标模型。</li>
<li>methods: 这篇论文使用的方法包括使用生成器类似于生成对抗网络，并定义损失函数和新的生成器设置来提取目标模型。</li>
<li>results: 这篇论文的结果表明，使用合理的查询可以实现高度有效的模型提取。这种模型提取方法可以应用于物体检测任务中的回归问题，并且可以支持未来机器学习模型的安全。<details>
<summary>Abstract</summary>
A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. We find that the proposed model extraction method achieves significant results by using reasonable queries. The discovery of this object detection vulnerability will support future prospects for securing such models.
</details>
<details>
<summary>摘要</summary>
许多机器学习模型容易受到模型EXTRACTION攻击，这种攻击集中于使用特制的查询来盗取目标模型。这个任务在白盒环境中得以完美完成，只需使用目标模型的一部分训练数据或代理数据集来训练一个模仿目标模型的新模型。然而，在实际情况下，目标模型通常是基于私人数据集训练的，这些数据集不可 accessible 给敌方。我们提出了一种数据free模型EXTRACTION技术，该技术使用生成器类似于生成对抗网络中的生成器来生成训练数据。我们首次，至少知道，对目标模型进行黑盒攻击扩展到回归问题，用于预测物体检测中的 bounding box 坐标。在我们的研究中，我们发现了定义损失函数和使用新的生成器设置是EXTRACTION模型的关键方面。我们发现，我们提议的模型EXTRACTION方法可以使用合理的查询来实现显著的结果。该发现将对物体检测模型的安全提供支持。
</details></li>
</ul>
<hr>
<h2 id="Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning"><a href="#Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning" class="headerlink" title="Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning"></a>Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04712">http://arxiv.org/abs/2308.04712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang H. Nguyen, Chenwei Zhang, Ye Liu, Philip S. Yu</li>
<li>for: 这个论文的目的是解决任务对话系统中的自然语言理解问题，具体来说是寻找具有高端性的自然语言理解方法，以便在任务对话系统中实现竞争力强的表现。</li>
<li>methods: 该论文提出了一种基于无监督语言模型（PLM）的探索学习方法，通过利用PLM中的无监督 semantic knowledge和任务对话系统中可用的句子级意图标签信号，来适应具有不同意图的语言模型。</li>
<li>results: 该论文的实验结果表明，该方法可以在slot induction任务中取得高效的表现，并且可以与基于token级监督模型的模型相比，在两个NLU数据集上 bridge the gap。此外，该方法还可以在新意图下提高slot filling任务的表现。<details>
<summary>Abstract</summary>
Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning to exploit unsupervised semantic knowledge extracted from PLM and additional sentence-level intent label signals available from TOD. Our approach is effective in the SI task and can bridge the gap with token-level supervised models on two NLU benchmark datasets.Moreover, our SI objectives provide enhanced slot label representations, leading to improved performance on the Slot Filling task when generalized to emerging intents. Our approach has the potential to significantly reduce the amount of manual annotation required for TOD systems, making it more practical and efficient for real-world applications.
</details></li>
</ul>
<hr>
<h2 id="Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution"><a href="#Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution" class="headerlink" title="Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution"></a>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04708">http://arxiv.org/abs/2308.04708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idesan/gpa">https://github.com/idesan/gpa</a></li>
<li>paper_authors: Tsuyoshi Idé, Naoki Abe</li>
<li>for: 这 paper 的目的是解释黑盒回归中的异常分布。</li>
<li>methods: 该 paper 使用了一种新的概率异常归因框架，可以计算输入变量的异常归因分布。这种框架不同于主流的 XAI 方法（解释 AI），因为它们只是解释黑盒预测而不是黑盒模型本身。</li>
<li>results: 该 paper 提出了一种可以量化异常归因分布的方法，并且可以用来解释黑盒预测中的异常分布。这种方法基于一种生成过程，可以Counter-factually bring the observed anomalous observation back to normalcy。<details>
<summary>Abstract</summary>
We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.   We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We introduce a variational Bayes algorithm for deriving the distributions of per variable attribution scores. To the best of our knowledge, this is the first probabilistic anomaly attribution framework that is free from being deviation-agnostic.
</details>
<details>
<summary>摘要</summary>
我们考虑了黑盒回归 Setting 中的概率异常归因 зада题，其目标是计算每个输入变量的归因分布，给出观察到的异常。我们假设训练集不可用。这个任务与标准 XAI（可解释 AI）场景不同，我们想解释黑盒预测的异常偏差，而不是黑盒模型本身。我们首先表明，主流的无 modelo-agnostic 解释方法，如夏普利值，不适用于这个任务，因为它们的“偏差无关性”性。我们然后提出了一种新的概率异常归因框架，允许我们不仅计算归因分布，还能量 Quantify the uncertainty of those scores。这是通过考虑一种生成过程来对 perturbations 进行 counter-factual 恢复正常 Observation 来实现的。我们提出了一种变分 Bayes 算法来 derive the distributions of per variable attribution scores。到目前为止，这是我们知道的首个不受偏差影响的概率异常归因框架。
</details></li>
</ul>
<hr>
<h2 id="Pareto-Invariant-Representation-Learning-for-Multimedia-Recommendation"><a href="#Pareto-Invariant-Representation-Learning-for-Multimedia-Recommendation" class="headerlink" title="Pareto Invariant Representation Learning for Multimedia Recommendation"></a>Pareto Invariant Representation Learning for Multimedia Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04706">http://arxiv.org/abs/2308.04706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanshan Huang, Haoxuan Li, Qingsong Li, Chunyuan Zheng, Li Liu</li>
<li>for: 本研究旨在提高个性化推荐的精度和稳定性，帮助用户找到更加适合自己的 multimedia 内容。</li>
<li>methods: 本研究提出了一种名为 Pareto Invariant Representation Learning (PaInvRL) 的框架，它通过同时学习 invariant 表示和 variant 表示来mitigate 缺乏关联性的问题。PaInvRL 包括三个迭代执行的模块：（i）不同环境标识模块，用于反映用户-项目交互中的分布偏移；（ii）不变面生成模块，通过 Pareto-优补解决方案来学习不变面；（iii）转换模块，用于生成 variant 表示和 item-invariant 表示，以便训练一个多Modal 推荐模型，以减少缺乏关联性和保持在环境分布之间的总体化表现。</li>
<li>results: 对于 Movielens、Tiktok 和 Kwai 等三个公共 multimedia 推荐数据集，PaInvRL 与当前的推荐模型进行比较，实验结果证明 PaInvRL 在内部和跨环境学习中具有更高的精度和稳定性。<details>
<summary>Abstract</summary>
Multimedia recommendation involves personalized ranking tasks, where multimedia content is usually represented using a generic encoder. However, these generic representations introduce spurious correlations that fail to reveal users' true preferences. Existing works attempt to alleviate this problem by learning invariant representations, but overlook the balance between independent and identically distributed (IID) and out-of-distribution (OOD) generalization. In this paper, we propose a framework called Pareto Invariant Representation Learning (PaInvRL) to mitigate the impact of spurious correlations from an IID-OOD multi-objective optimization perspective, by learning invariant representations (intrinsic factors that attract user attention) and variant representations (other factors) simultaneously. Specifically, PaInvRL includes three iteratively executed modules: (i) heterogeneous identification module, which identifies the heterogeneous environments to reflect distributional shifts for user-item interactions; (ii) invariant mask generation module, which learns invariant masks based on the Pareto-optimal solutions that minimize the adaptive weighted Invariant Risk Minimization (IRM) and Empirical Risk (ERM) losses; (iii) convert module, which generates both variant representations and item-invariant representations for training a multi-modal recommendation model that mitigates spurious correlations and balances the generalization performance within and cross the environmental distributions. We compare the proposed PaInvRL with state-of-the-art recommendation models on three public multimedia recommendation datasets (Movielens, Tiktok, and Kwai), and the experimental results validate the effectiveness of PaInvRL for both within- and cross-environmental learning.
</details>
<details>
<summary>摘要</summary>
multimedia推荐 involve个人化排名任务，其中 multimedia 内容通常使用通用编码器表示。然而，这些通用表示引入了假设性的相关性， fail to reveal 用户的真实喜好。现有工作尝试通过学习不变表示来缓解这个问题，但忽视了IID和OOD总体化的平衡。在这篇论文中，我们提出了一个名为Pareto Invitable Representation Learning（PaInvRL）的框架，通过IID-OOD多对象函数优化的多元对象优化角度来缓解用户-项目交互中的假设性相关性，同时学习不变和variant表示。具体来说，PaInvRL包括以下三个iteratively执行的模块：(i) 不同环境标识模块，用于反映用户-项目交互中的分布Shift;(ii) 不变面积生成模块，通过Pareto优胜解决方案来学习不变面积，并与Adaptive Weighted Invariant Risk Minimization（IRM）和Empirical Risk（ERM）损失相对优胜;(iii) 转换模块，用于生成variant表示和item-invariant表示，以便训练一个多Modal推荐模型， mitigate 假设性相关性并保持内部和跨环境的总体化性。我们与现有的推荐模型进行比较，并在 Movielens、Tiktok 和 Kwai 三个公共 multimedia 推荐数据集上进行实验，结果证明PaInvRL在内部和跨环境学习中具有效果。
</details></li>
</ul>
<hr>
<h2 id="A-Feature-Set-of-Small-Size-for-the-PDF-Malware-Detection"><a href="#A-Feature-Set-of-Small-Size-for-the-PDF-Malware-Detection" class="headerlink" title="A Feature Set of Small Size for the PDF Malware Detection"></a>A Feature Set of Small Size for the PDF Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04704">http://arxiv.org/abs/2308.04704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Liu, Charles Nicholas</li>
<li>for: 这种研究旨在提出一个小型特征集，以便在PDF文档中探测针对性软件。</li>
<li>methods: 该研究使用六种不同的机器学习模型进行评估，并测试了一个小型特征集。</li>
<li>results: 该研究得到了99.75%的最高准确率，使用Random Forest模型。该小型特征集与当前领域中使用的大型特征集相比，具有相似的性能。<details>
<summary>Abstract</summary>
Machine learning (ML)-based malware detection systems are becoming increasingly important as malware threats increase and get more sophisticated. PDF files are often used as vectors for phishing attacks because they are widely regarded as trustworthy data resources, and are accessible across different platforms. Therefore, researchers have developed many different PDF malware detection methods. Performance in detecting PDF malware is greatly influenced by feature selection. In this research, we propose a small features set that don't require too much domain knowledge of the PDF file. We evaluate proposed features with six different machine learning models. We report the best accuracy of 99.75% when using Random Forest model. Our proposed feature set, which consists of just 12 features, is one of the most conciseness in the field of PDF malware detection. Despite its modest size, we obtain comparable results to state-of-the-art that employ a much larger set of features.
</details>
<details>
<summary>摘要</summary>
《机器学习（ML）基于的malware检测系统在面临增加的malware威胁和复杂化的情况下变得越来越重要。PDF文档经常被用为钓鱼攻击的载体，因为它们被广泛认为是可靠的数据资源，可以在不同的平台上访问。因此，研究人员已经开发出了许多不同的PDF malware检测方法。PDF malware检测性能受到特征选择的影响。在这项研究中，我们提议一个小型特征集，不需要太多领域知识。我们使用六种不同的机器学习模型进行评估。我们发现，使用Random Forest模型时的最佳准确率为99.75%。我们的提议的特征集，包含12个特征，是PDF malware检测领域中最短的一个。尽管它的规模不大，但我们可以获得与州对的结果，与使用许多更多特征的状态对照。》Note: The translation is done using Google Translate and may not be perfect. Please note that the translation is done in a simplified Chinese, if you need the translation in traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="An-Analytical-Study-of-Covid-19-Dataset-using-Graph-Based-Clustering-Algorithms"><a href="#An-Analytical-Study-of-Covid-19-Dataset-using-Graph-Based-Clustering-Algorithms" class="headerlink" title="An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms"></a>An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04697">http://arxiv.org/abs/2308.04697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, P. J. A. Alphonse, Selvakumar K</li>
<li>for: 本研究旨在针对 COVID-19 病毒的蛋白质与蛋白质间互作（Protein-Protein Interaction，PPI）网络进行 clustering 分析，以提供更多的类别分析和疾病理解。</li>
<li>methods: 本研究使用了三种 гра图基于的 clustering 算法进行 PPI 网络的分析，包括 degree-based clustering、betweenness-based clustering 和 PageRank-based clustering。</li>
<li>results: 本研究发现，这些 clustering 算法可以对 PPI 网络进行有效的分类，并提供了一些有用的类别分析和疾病理解。<details>
<summary>Abstract</summary>
Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is initially identified in Wuhan of China in December of 2019 and now this deadly disease has spread all over the world. According to World Health Organization (WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case, many methods, AI base techniques, and machine learning algorithms have been researched and are being used to save people from this pandemic. The SARS-CoV and the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences in the structure of cell proteins. Protein-protein interaction (PPI) is an essential process in our cells and plays a very important role in the development of medicines and gives ideas about the disease. In this study, we performed clustering on PPI networks generated from 92 genes of the Covi-19 dataset. We have used three graph-based clustering algorithms to give intuition to the analysis of clusters.
</details>
<details>
<summary>摘要</summary>
新型冠状病毒病（COVID-19）是一种新型病毒，于2019年12月在中国武汉首次被发现，现已在全球蔓延。根据世界卫生组织（WHO）的统计，2019年至2021年4月，全球共有3,124,905人死亡。在这种大流行中，许多方法、AI基础技术和机器学习算法已经被研究并应用，以拯救人们。SARS-CoV和2019-nCoV病毒会入侵我们的体内，导致细胞蛋白结构的变化。蛋白蛋白相互作用（PPI）是我们细胞中的一项重要过程，对于药物的开发和疾病的研究具有非常重要的意义。在本研究中，我们对COVI-19数据集中的92个基因生成的PPI网络进行了划分。我们使用了三种图基的划分算法，以便更好地了解划分结果。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects"><a href="#Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects" class="headerlink" title="Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects"></a>Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04696">http://arxiv.org/abs/2308.04696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soheyla Amirian, Luke A. Carlson, Matthew F. Gong, Ines Lohse, Kurt R. Weiss, Johannes F. Plate, Ahmad P. Tafti</li>
<li>for: 本研究旨在解决医疗机器学习模型中的解释性和可解释性问题，以便临床医生、外科医生和患者能够理解AI模型中的贡献因素。</li>
<li>methods: 本研究使用了多种方法来解决解释性和可解释性问题，包括开发可解释的AI模型和算法，以及与 клиниче专业人员和管理机构之间的合作。</li>
<li>results: 本研究发现了一些关键的挑战和机遇，包括解释性和可解释性问题的解决方法，以及在Orthopedics中应用XAI的标准和指南的设立。<details>
<summary>Abstract</summary>
While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在不同领域取得了许多成功应用，但在医疗领域的采纳相对落后一些。这可能是由多种因素引起的，如法规框架、医疗隐私问题和数据多样性。然而，在骨科领域中，AI的实现受到了解释和解读模型的缺乏的困难。为了解决骨科中的解释AI（XAI）问题，需要开发可透明和可解释的AI模型和算法，让临床医生、骨科专家和患者可以理解AI预测或描述模型中的决定因素。本贡献阐述了骨科中XAI问题的多个挑战和机遇，强调了在AI实践中跨学科合作的重要性，包括AI实践者、骨科专家和法规机构，以设立XAI的标准和指南。
</details></li>
</ul>
<hr>
<h2 id="Finite-Element-Operator-Network-for-Solving-Parametric-PDEs"><a href="#Finite-Element-Operator-Network-for-Solving-Parametric-PDEs" class="headerlink" title="Finite Element Operator Network for Solving Parametric PDEs"></a>Finite Element Operator Network for Solving Parametric PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04690">http://arxiv.org/abs/2308.04690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jae Yong Lee, Seungchan Ko, Youngjoon Hong</li>
<li>for: 解决 Parametric Partial Differential Equations (PDEs) 的计算问题，提供一种基于深度学习的 Finite Element Operator Network (FEONet) 方法。</li>
<li>methods: 使用 Finite Element Method 和深度学习结合，解决 Parametric PDEs 问题，不需要输入输出对应的训练数据。</li>
<li>results: 在一些标准测试问题上，FEONet 方法比现有的状态艺术方法更高精度、更好的泛化能力和计算灵活性。FEONet 框架可以应用于各种领域，其中 PDEs 扮演着重要的计算模型角色。<details>
<summary>Abstract</summary>
Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and singular behavior. Furthermore, we provide theoretical convergence analysis to support our approach, utilizing finite element approximation in numerical analysis.
</details>
<details>
<summary>摘要</summary>
“偏微分方程（PDEs）在许多领域中起着关键作用，包括物理、工程和金融等。但是解 parametric PDEs 是一项复杂的任务，需要有效的数值方法。在这篇论文中，我们提出了一种新的方法，使用 Finite Element Operator Network（FEONet）来解 parametric PDEs。我们的提议方法利用了深度学习和传统的数值方法，具体来说是finite element方法，来解 parametric PDEs 在没有任何输入输出培训数据的情况下。我们在一些标准问题上进行了评估，并证明了我们的方法在准确性、泛化和计算灵活性等方面都比现有的状态 искусственный智能方法更高。我们的 FEONet 框架在不同的领域中有潜在的应用，其中 PDEs 在模型复杂领域中的各种边界条件和特殊行为中扮演着关键角色。此外，我们还提供了理论的收敛分析，使用finite element aproximation进行数值分析。”
</details></li>
</ul>
<hr>
<h2 id="Two-Novel-Approaches-to-Detect-Community-A-Case-Study-of-Omicron-Lineage-Variants-PPI-Network"><a href="#Two-Novel-Approaches-to-Detect-Community-A-Case-Study-of-Omicron-Lineage-Variants-PPI-Network" class="headerlink" title="Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network"></a>Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05125">http://arxiv.org/abs/2308.05125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, Selvakumar K., P. J. A. Alphonse</li>
<li>for: 这项研究的目的是揭示变异型B.1.1.529病毒（Omicron病毒）中的社区结构，以便更好地理解这种病毒的生物学机制。</li>
<li>methods: 该研究使用了两种新的算法（ABCDE和ALCDE）和四种已知的算法（ Girvan-Newman、Louvain、Leiden和Label Propagation）来揭示变异型B.1.1.529病毒的社区结构。</li>
<li>results: 研究发现，使用不同算法可以揭示出变异型B.1.1.529病毒的不同社区结构，并且对这些社区进行了全面的比较和分析。<details>
<summary>Abstract</summary>
The capacity to identify and analyze protein-protein interactions, along with their internal modular organization, plays a crucial role in comprehending the intricate mechanisms underlying biological processes at the molecular level. We can learn a lot about the structure and dynamics of these interactions by using network analysis. We can improve our understanding of the biological roots of disease pathogenesis by recognizing network communities. This knowledge, in turn, holds significant potential for driving advancements in drug discovery and facilitating personalized medicine approaches for disease treatment. In this study, we aimed to uncover the communities within the variant B.1.1.529 (Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label Propagation algorithm. Each of these algorithms has established prominence in the field and offers unique perspectives on identifying communities within complex networks. We also compare the networks by the global properties, statistic summary, subgraph count, graphlet and validate by the modulaity. By employing these approaches, we sought to gain deeper insights into the structural organization and interconnections present within the Omicron virus network.
</details>
<details>
<summary>摘要</summary>
“蛋白质-蛋白质互作的能力和内部模块结构对于理解生物过程的分子水平机制具有重要作用。我们可以通过网络分析来了解这些互作的结构和动态。通过识别网络社区，我们可以更好地理解疾病发生的生物基础，从而推动药物发现和个性化医疗方法的发展。在这项研究中，我们使用了两种新的算法（ABCDE和ALCDE）和四种广泛使用的算法（吉万-恩文、奥尔班-劳伦、莱顿和标签卷）来揭示 variant B.1.1.529（奥米克隆病毒）中的社区。每种算法都有在领域中的卓越表现，并提供了不同的视角来识别复杂网络中的社区。我们还对这些网络进行了全球性质、统计摘要、子图计数、图лет和验证性的比较，以获得更深入的理解奥米克隆病毒网络中的结构组织和互连关系。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. Traditional Chinese is used in Taiwan and other countries, and the translation may be slightly different in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction"><a href="#TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction" class="headerlink" title="TBIN: Modeling Long Textual Behavior Data for CTR Prediction"></a>TBIN: Modeling Long Textual Behavior Data for CTR Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08483">http://arxiv.org/abs/2308.08483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Chen, Xiang Li, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang</li>
<li>for: 预测点击率 (CTR) 在推荐中发挥关键作用，文中提出了一种基于文本的用户行为数据组织方法，使用语言模型 (LM) 理解用户兴趣的含义。</li>
<li>methods: 文中提出的方法是文本行为数据的本地性敏感哈希算法和偏移量基于的自注意力，解决了自注意力计算量的问题，并使用多个用户多个兴趣的动态活化。</li>
<li>results: 实验结果表明，文中提出的TBIN方法在真实世界的食品推荐平台上获得了显著的效果。<details>
<summary>Abstract</summary>
Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details>
<details>
<summary>摘要</summary>
点阅率（CTR）预测在推荐中扮演重要的角色。受最近语言模型（LM）的盛行启发，一些工作将用户行为数据 format 为文本，并使用 LM 理解用户的 semantic 层次。 although promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model.在本文中，我们提出了 Textual Behavior-based Interest Chunking Network (TBIN)，以解决以下限制： combines an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details></li>
</ul>
<hr>
<h2 id="A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering"><a href="#A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering" class="headerlink" title="A General Implicit Framework for Fast NeRF Composition and Rendering"></a>A General Implicit Framework for Fast NeRF Composition and Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04669">http://arxiv.org/abs/2308.04669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Gao, Ziyi Yang, Yunlu Zhao, Yuxiang Sun, Xiaogang Jin, Changqing Zou</li>
<li>For: 该论文旨在提供一种通用的隐式管道，以快速组合NeRF对象。* Methods: 该方法使用神经雨花场（Neural Depth Fields, NeDF）来快速确定物体之间的空间关系，并通过神经网络来加速NeRF的查询。* Results: 该方法可以快速和交互地组合NeRF对象，同时也可以作为许多现有NeRF作品的预览插件。<details>
<summary>Abstract</summary>
A variety of Neural Radiance Fields (NeRF) methods have recently achieved remarkable success in high render speed. However, current accelerating methods are specialized and incompatible with various implicit methods, preventing real-time composition over various types of NeRF works. Because NeRF relies on sampling along rays, it is possible to provide general guidance for acceleration. To that end, we propose a general implicit pipeline for composing NeRF objects quickly. Our method enables the casting of dynamic shadows within or between objects using analytical light sources while allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations. Mainly, our work introduces a new surface representation known as Neural Depth Fields (NeDF) that quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.Our proposed method is the first to enable both the progressive and interactive composition of NeRF objects. Additionally, it also serves as a previewing plugin for a range of existing NeRF works.
</details>
<details>
<summary>摘要</summary>
各种神经辐射场（NeRF）方法在最近几年得到了非常出色的成果，但现有的加速方法受限于特定的隐式方法，不兼容多种NeRF工作，阻碍了实时组合。因为NeRF通过辐射进行采样，因此可以提供一般的指导方针。为了实现这一目标，我们提出了一个通用的隐式管道，用于快速组合NeRF对象。我们的方法允许在动态阴影中投射影响对象，并允许多个NeRF对象在任意旋转变换下准确地放置和渲染。主要，我们的工作引入了一种新的表面表示方法，即神经深度场（NeDF），它快速确定对象之间的空间关系，并允许直接计算辐射与隐式表面的交点。它利用一个交叉神经网络来询问NeRF的加速而不是依赖于显式空间结构。我们的提议的方法是首个允许NeRF对象进行进度式和交互式组合，同时也可以作为许多现有NeRF作品的预览插件。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors"><a href="#Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors" class="headerlink" title="Classification of lung cancer subtypes on CT images with synthetic pathological priors"></a>Classification of lung cancer subtypes on CT images with synthetic pathological priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04663">http://arxiv.org/abs/2308.04663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Zhu, Yuan Jin, Gege Ma, Geng Chen, Jan Egger, Shaoting Zhang, Dimitris N. Metaxas</li>
<li>for: 这个论文的目的是为了精准地分类肺癌不同亚型，以便进行跟踪治疗和诊断管理。</li>
<li>methods: 该论文提出了一种自生成混合特征网络（SGHF-Net），用于从计算机 Tomatoes（CT）图像中准确地分类肺癌亚型。该模型基于 Studies showing that there are cross-scale associations between the same case’s CT images and its pathological images， therefore, an innovative pathological feature synthetic module (PFSM) was developed to quantitatively map cross-modality associations through deep neural networks, and derive the “gold standard” information contained in the corresponding pathological images from CT images.</li>
<li>results: 实验结果表明，提出的模型在一个大规模多中心数据集（829个例）上表现出了明显的优势，与一系列state-of-the-art（SOTA）分类模型进行比较，其准确性、区域 beneath the curve（AUC）和F1得分均有显著提高。<details>
<summary>Abstract</summary>
The accurate diagnosis on pathological subtypes for lung cancer is of significant importance for the follow-up treatments and prognosis managements. In this paper, we propose self-generating hybrid feature network (SGHF-Net) for accurately classifying lung cancer subtypes on computed tomography (CT) images. Inspired by studies stating that cross-scale associations exist in the image patterns between the same case's CT images and its pathological images, we innovatively developed a pathological feature synthetic module (PFSM), which quantitatively maps cross-modality associations through deep neural networks, to derive the "gold standard" information contained in the corresponding pathological images from CT images. Additionally, we designed a radiological feature extraction module (RFEM) to directly acquire CT image information and integrated it with the pathological priors under an effective feature fusion framework, enabling the entire classification model to generate more indicative and specific pathologically related features and eventually output more accurate predictions. The superiority of the proposed model lies in its ability to self-generate hybrid features that contain multi-modality image information based on a single-modality input. To evaluate the effectiveness, adaptability, and generalization ability of our model, we performed extensive experiments on a large-scale multi-center dataset (i.e., 829 cases from three hospitals) to compare our model and a series of state-of-the-art (SOTA) classification models. The experimental results demonstrated the superiority of our model for lung cancer subtypes classification with significant accuracy improvements in terms of accuracy (ACC), area under the curve (AUC), and F1 score.
</details>
<details>
<summary>摘要</summary>
准确诊断肺癌分型对跟进治疗和 прогности治理有着重要的意义。在这篇论文中，我们提出了自动生成混合特征网络（SGHF-Net），用于精准地分类肺癌分型的 computed tomography（CT）图像。受到 Studies 表明跨模态关系存在在图像模式中的想法，我们创新地开发了 pathological feature synthetic module（PFSM），通过深度神经网络来量化跨模态关系，从 CT 图像中提取“标准”的 pathological 信息。此外，我们还设计了 radiological feature extraction module（RFEM），直接从 CT 图像中提取信息，并将其与 pathological 先验 fusion 在一个有效的特征融合框架中，使整个分类模型能够生成更指示和特定的 pathologically 相关特征，并最终输出更高精度的预测。我们的模型的优势在于它可以自动生成混合特征，其中包含多modal 图像信息，基于单 modal 输入。为了评估我们的模型的效果、适应性和普适性，我们在多中心 dataset（i.e., 829 例）上进行了广泛的实验，与一系列 state-of-the-art（SOTA）分类模型进行比较。实验结果表明，我们的模型在肺癌分型方面具有显著的高精度性，包括准确率（ACC）、抛物线下的曲线（AUC）和 F1 分数等指标上的显著提高。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bayesian-Optimization-with-Deep-Kernel-Learning-and-Transformer-Pre-trained-on-Multiple-Heterogeneous-Datasets"><a href="#Efficient-Bayesian-Optimization-with-Deep-Kernel-Learning-and-Transformer-Pre-trained-on-Multiple-Heterogeneous-Datasets" class="headerlink" title="Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets"></a>Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04660">http://arxiv.org/abs/2308.04660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Lyu, Shoubo Hu, Jie Chuai, Zhitang Chen</li>
<li>for: 这paper是为了提高黑盒优化问题中的优化效率而写的。</li>
<li>methods: 这paper使用了一种简单的预训练策略，使用Transformer编码器learned的深度特征来定义GPkernel，并提供了一种简单 yet effective的混合 initializationestrategy来加速新任务的整合。</li>
<li>results:  experiments表明，这paper提出的预训练和传输BO策略比现有方法更高效。<details>
<summary>Abstract</summary>
Bayesian optimization (BO) is widely adopted in black-box optimization problems and it relies on a surrogate model to approximate the black-box response function. With the increasing number of black-box optimization tasks solved and even more to solve, the ability to learn from multiple prior tasks to jointly pre-train a surrogate model is long-awaited to further boost optimization efficiency. In this paper, we propose a simple approach to pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined on deep features learned from a Transformer-based encoder, using datasets from prior tasks with possibly heterogeneous input spaces. In addition, we provide a simple yet effective mix-up initialization strategy for input tokens corresponding to unseen input variables and therefore accelerate new tasks' convergence. Experiments on both synthetic and real benchmark problems demonstrate the effectiveness of our proposed pre-training and transfer BO strategy over existing methods.
</details>
<details>
<summary>摘要</summary>
bayesian 优化 (BO) 广泛应用于黑盒优化问题中，它基于一个代理函数来近似黑盒响应函数。随着黑盒优化任务的数量不断增加，并且还有更多的任务需要解决，因此有必要将多个先前任务的知识共享以提高优化效率。在这篇论文中，我们提议一种简单的预训练方法，使用Transformer基于encoder学习的深度特征来定义GP的核函数。此外，我们还提供了一种简单 yet effective的混合初始化策略，以便快速启动新任务的整合。实验表明，我们提议的预训练和传递BO策略比既有方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores"><a href="#Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores" class="headerlink" title="Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores"></a>Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04653">http://arxiv.org/abs/2308.04653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pablo Cesar Quihui-Rubio, Daniel Flores-Araiza, Gilberto Ochoa-Ruiz, Miguel Gonzalez-Mendoza, Christian Mata</li>
<li>for: 这个研究旨在比较深度学习方法用于肠细胞分 segmentation和不确定度评估的肠细胞MRI图像。目标是改进肠癌检测和诊断的工作流程。</li>
<li>methods: 这个研究使用了七种不同的U-Net基建 Architecture，其中包括了Monte-Carlo dropout的增强。这些模型用于自动分类肠细胞中心区、周边区、过渡区和肿瘤，并且计算了不确定度。</li>
<li>results: 研究发现，Attention R2U-Net是最高效的模型，其中IoU平均值为76.3%，DSC平均值为85%。此外，Attention R2U-Net在过渡区和肿瘤边界处的不确定度值最低。<details>
<summary>Abstract</summary>
This study focuses on comparing deep learning methods for the segmentation and quantification of uncertainty in prostate segmentation from MRI images. The aim is to improve the workflow of prostate cancer detection and diagnosis. Seven different U-Net-based architectures, augmented with Monte-Carlo dropout, are evaluated for automatic segmentation of the central zone, peripheral zone, transition zone, and tumor, with uncertainty estimation. The top-performing model in this study is the Attention R2U-Net, achieving a mean Intersection over Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% for segmenting all zones. Additionally, Attention R2U-Net exhibits the lowest uncertainty values, particularly in the boundaries of the transition zone and tumor, when compared to the other models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Metric-Learning-for-the-Hemodynamics-Inference-with-Electrocardiogram-Signals"><a href="#Deep-Metric-Learning-for-the-Hemodynamics-Inference-with-Electrocardiogram-Signals" class="headerlink" title="Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals"></a>Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04650">http://arxiv.org/abs/2308.04650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyewon Jeong, Collin M. Stultz, Marzyeh Ghassemi</li>
<li>For: 这种研究旨在提出一种非侵入性的心脏压力测量方法，以便诊断和治疗心力衰竭病人的诊断和治疗预测。* Methods: 这种方法使用深度度量学习（DML），并提出了一种自适应DML方法，通过距离基本挖掘来提高模型的性能。* Results: 研究发现，使用ECG数据进行自适应DML模型训练，可以提高心脏压力的预测性能，并且这种模型在不同的患者群体中表现良好，即使某些患者群体在数据集中具有较少的表达。<details>
<summary>Abstract</summary>
Heart failure is a debilitating condition that affects millions of people worldwide and has a significant impact on their quality of life and mortality rates. An objective assessment of cardiac pressures remains an important method for the diagnosis and treatment prognostication for patients with heart failure. Although cardiac catheterization is the gold standard for estimating central hemodynamic pressures, it is an invasive procedure that carries inherent risks, making it a potentially dangerous procedure for some patients. Approaches that leverage non-invasive signals - such as electrocardiogram (ECG) - have the promise to make the routine estimation of cardiac pressures feasible in both inpatient and outpatient settings. Prior models trained to estimate intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP)) in a supervised fashion have shown good discriminatory ability but have been limited to the labeled dataset from the heart failure cohort. To address this issue and build a robust representation, we apply deep metric learning (DML) and propose a novel self-supervised DML with distance-based mining that improves the performance of a model with limited labels. We use a dataset that contains over 5.4 million ECGs without concomitant central pressure labels to pre-train a self-supervised DML model which showed improved classification of elevated mPCWP compared to self-supervised contrastive baselines. Additionally, the supervised DML model that is using ECGs with access to 8,172 mPCWP labels demonstrated significantly better performance on the mPCWP regression task compared to the supervised baseline. Moreover, our data suggest that DML yields models that are performant across patient subgroups, even when some patient subgroups are under-represented in the dataset. Our code is available at https://github.com/mandiehyewon/ssldml
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种严重的疾病，对全球多 millions of people 有很大的影响，影响他们的生活质量和死亡率。对心力衰竭患者的诊断和治疗预测，对心脏压力的 объектив评估仍然是非常重要。虽然心脏导管是诊断中心 hemodynamic pressures 的标准方法，但它是一种侵入性的过程，具有内生的风险，因此对某些患者来说可能是危险的。使用非侵入式信号 - 如电cardiogram (ECG) - 的方法可以使 Routine estimation of cardiac pressures 在医院和家庭设置中变得可能。先前的模型，通过supervised fashion 训练来估计 intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP)) 的表现能力很好，但它们受限于心衰竭 cohort 的标签数据集。为了解决这个问题并建立一个 Robust 的表现，我们运用 deep metric learning (DML) 和一种新的距离基本的自我监督 DML，可以提高具有有限标签的模型的性能。我们使用了包含超过 5.4 万个 ECG 的数据集，不含中心压力标签，来预训练一个自我监督 DML 模型，该模型在提高高 mPCWP 的分类性能方面表现出色，而且在对比自我监督对比的基线下，表现更好。此外，我们使用 ECG 和访问 8,172 个 mPCWP 标签， trains 一个 supervised DML 模型，其在 mPCWP 回归任务中表现出色，并且在不同患者 subgroup 中表现也很好。我们的代码可以在 https://github.com/mandiehyewon/ssldml 中找到。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Optimization-Performance-A-Novel-Hybridization-of-Gaussian-Crunching-Search-and-Powell’s-Method-for-Derivative-Free-Optimization"><a href="#Enhancing-Optimization-Performance-A-Novel-Hybridization-of-Gaussian-Crunching-Search-and-Powell’s-Method-for-Derivative-Free-Optimization" class="headerlink" title="Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell’s Method for Derivative-Free Optimization"></a>Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell’s Method for Derivative-Free Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04649">http://arxiv.org/abs/2308.04649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benny Wong</li>
<li>for: 优化复杂系统的最优解和找到Global Minimum</li>
<li>methods: hybridization of Gaussian Crunching Search (GCS) and Powell’s Method for derivative-free optimization</li>
<li>results: 显著提高优化性能，同时保留各方法的优点<details>
<summary>Abstract</summary>
This research paper presents a novel approach to enhance optimization performance through the hybridization of Gaussian Crunching Search (GCS) and Powell's Method for derivative-free optimization. While GCS has shown promise in overcoming challenges faced by traditional derivative-free optimization methods [1], it may not always excel in finding the local minimum. On the other hand, some traditional methods may have better performance in this regard. However, GCS demonstrates its strength in escaping the trap of local minima and approaching the global minima. Through experimentation, we discovered that by combining GCS with certain traditional derivative-free optimization methods, we can significantly boost performance while retaining the respective advantages of each method. This hybrid approach opens up new possibilities for optimizing complex systems and finding optimal solutions in a range of applications.
</details>
<details>
<summary>摘要</summary>
Note:* "GCS" is translated as " Gaussian Crunching Search" (格aussian逼擦搜索)* "Powell's Method" is translated as " Powell 方法" (波尔方法)* "derivative-free optimization" is translated as "无导数优化" (无导数优化)* "local minimum" is translated as "本地最小值" (本地最小值)* "global minima" is translated as "全球最小值" (全球最小值)
</details></li>
</ul>
<hr>
<h2 id="Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling"><a href="#Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling" class="headerlink" title="Sparse Binary Transformers for Multivariate Time Series Modeling"></a>Sparse Binary Transformers for Multivariate Time Series Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04637">http://arxiv.org/abs/2308.04637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matt Gorbett, Hossein Shirazi, Indrakshi Ray</li>
<li>for: 应用于多变量时间序问题的简洁神经网络模型</li>
<li>methods: 使用稀疏和二进制权重的 transformer 模型</li>
<li>results: 在三个时间序学习任务中取得了比较出色的结果：分类、异常检测和单步预测<details>
<summary>Abstract</summary>
Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attention mask to allow computation only at the current time step. Together, each compression technique and attention modification substantially reduces the number of non-zero operations necessary in the Transformer. We measure the computational savings of our approach over a range of metrics including parameter count, bit size, and floating point operation (FLOPs) count, showing up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</details>
<details>
<summary>摘要</summary>
压缩神经网络（Compressed Neural Networks）有可能在新的应用程序和较小的计算环境中实现深度学习。然而，了解这些模型在哪些学习任务中能够成功是不很了解。在这项工作中，我们使用稀疏和二进制权重的转换器（Transformers）来解决多变量时间序列问题，并证明了这些轻量级模型可以与同结构的精密浮点数Transformers具有相同的准确率。我们的模型在三个时间序列学习任务中表现良好：分类、异常检测和单步预测。此外，为了减少转换器的计算复杂度，我们应用了两种修改，其中一种是在分类任务中采用固定面积来压缩查询、键和值活动，另一种是在预测和异常检测任务中，通过在当前时间步计算的注意力掩码来减少计算量。总的来说，我们的方法可以减少参数数量、位数和浮点运算（FLOPs）数量，并且可以达到最多53倍的存储大小减少和10.5倍的FLOPs减少。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Online-Learnability-under-Bandit-Feedback"><a href="#Multiclass-Online-Learnability-under-Bandit-Feedback" class="headerlink" title="Multiclass Online Learnability under Bandit Feedback"></a>Multiclass Online Learnability under Bandit Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04620">http://arxiv.org/abs/2308.04620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ananth Raman, Vinod Raman, Unique Subedi, Ambuj Tewari</li>
<li>for: online multiclass classification under bandit feedback</li>
<li>methods: extend the results of (daniely2013price) and show the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability</li>
<li>results: complement the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unboundedHere’s the format you requested:</li>
<li>for: online multiclass classification under bandit feedback</li>
<li>methods: 扩展daniely2013price的结果，显示bandit online multiclass学习可行性需要和充分条件是bandit littlestone dimension的Finite-ness</li>
<li>results: 补充hanneke2023multiclass的研究，显示Littlestone dimension caracterizes online multiclass学习在全信息设置下的label space是无限的I hope this helps!<details>
<summary>Abstract</summary>
We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
</details>
<details>
<summary>摘要</summary>
我们研究在带标签反馈下进行在线多类分类。我们将daniely2013price的结果推广到无限个标签空间下，证明了带标签Littlestone维度的有限性是在线多类学习的必要和充分条件。我们的结果与hanneke2023multiclass的最近研究相 complement，他们在全信息设置下证明了Littlestone维度 caracterizes在线多类学习。
</details></li>
</ul>
<hr>
<h2 id="Improved-Activation-Clipping-for-Universal-Backdoor-Mitigation-and-Test-Time-Detection"><a href="#Improved-Activation-Clipping-for-Universal-Backdoor-Mitigation-and-Test-Time-Detection" class="headerlink" title="Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection"></a>Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04617">http://arxiv.org/abs/2308.04617</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wanghangpsu/mmac">https://github.com/wanghangpsu/mmac</a></li>
<li>paper_authors: Hang Wang, Zhen Xiang, David J. Miller, George Kesidis</li>
<li>for: 防止深度神经网络受到后门攻击 (Trojan)，攻击者在训练集中植入后门触发器，让神经网络在测试时将触发器分类到攻击者所指定的目标类。</li>
<li>methods: 使用后处理剪辑方法来mitigate backdoor攻击，通过在小量的净样集上学习内层活动的约束来限制内层活动的范围。</li>
<li>results: 与对手方法相比，提出了一种新的 activation bound choosing 方法，可以更好地防止后门攻击，同时具有强大的鲁棒性，可以抵御 adaptive 攻击、X2X 攻击和不同的数据集。<details>
<summary>Abstract</summary>
Deep neural networks are vulnerable to backdoor attacks (Trojans), where an attacker poisons the training set with backdoor triggers so that the neural network learns to classify test-time triggers to the attacker's designated target class. Recent work shows that backdoor poisoning induces over-fitting (abnormally large activations) in the attacked model, which motivates a general, post-training clipping method for backdoor mitigation, i.e., with bounds on internal-layer activations learned using a small set of clean samples. We devise a new such approach, choosing the activation bounds to explicitly limit classification margins. This method gives superior performance against peer methods for CIFAR-10 image classification. We also show that this method has strong robustness against adaptive attacks, X2X attacks, and on different datasets. Finally, we demonstrate a method extension for test-time detection and correction based on the output differences between the original and activation-bounded networks. The code of our method is online available.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到后门攻击（Trojan），攻击者在训练集中杀死后门触发器，使神经网络在测试时通过特定目标类划分测试触发器。最近的研究表明，后门毒害导致神经网络过度适应（测试时异常大的活动），这种情况 Motivates a general, post-training clipping method for backdoor mitigation, i.e., with bounds on internal-layer activations learned using a small set of clean samples。我们开发了一种新的这种方法，选择活动 bound 以限制分类margin。这种方法在对比它的同类方法时表现出优秀的性能，用于 CIFAR-10 图像分类。我们还证明了这种方法对适应攻击、X2X攻击和不同的 dataset 具有强大的 Robustness。最后，我们示出了基于输出差异的测试时检测和修复方法的扩展。我们的方法代码在线可用。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Deep-Learning-and-Data-Preprocessing-Techniques-for-Detection-Prediction-and-Monitoring-of-Stress-and-Stress-related-Mental-Disorders-A-Scoping-Review"><a href="#Machine-Learning-Deep-Learning-and-Data-Preprocessing-Techniques-for-Detection-Prediction-and-Monitoring-of-Stress-and-Stress-related-Mental-Disorders-A-Scoping-Review" class="headerlink" title="Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review"></a>Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04616">http://arxiv.org/abs/2308.04616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moein Razavi, Samira Ziyadidegan, Reza Jahromi, Saber Kazeminasab, Vahid Janfaza, Ahmadreza Mahmoudzadeh, Elaheh Baharlouei, Farzan Sasangohar</li>
<li>for: 本文系统性地评估了应用机器学习（ML）方法在压力和压力相关的精神疾病（MD）检测、预测和分析方面的研究。</li>
<li>methods: 该文综述了最新的ML算法、预处理技术和数据类型在压力和压力相关MD方面的应用。结果表明支持向量机（SVM）、神经网络（NN）和随机森林（RF）模型在所有评估的机器学习算法中具有最高的准确性和可靠性。</li>
<li>results: 文综述发现，Physiological parameters such as heart rate measurements and skin response are prevalently used as stress predictors in ML algorithms, due to their rich explanatory information concerning stress and stress-related MDs, as well as the relative ease of data acquisition. Additionally, the application of dimensionality reduction techniques, including mappings, feature selection, filtering, and noise reduction, is frequently observed as a crucial step preceding the training of ML algorithms.<details>
<summary>Abstract</summary>
This comprehensive review systematically evaluates Machine Learning (ML) methodologies employed in the detection, prediction, and analysis of mental stress and its consequent mental disorders (MDs). Utilizing a rigorous scoping review process, the investigation delves into the latest ML algorithms, preprocessing techniques, and data types employed in the context of stress and stress-related MDs. The findings highlight that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently exhibit superior accuracy and robustness among all machine learning algorithms examined. Furthermore, the review underscores that physiological parameters, such as heart rate measurements and skin response, are prevalently used as stress predictors in ML algorithms. This is attributed to their rich explanatory information concerning stress and stress-related MDs, as well as the relative ease of data acquisition. Additionally, the application of dimensionality reduction techniques, including mappings, feature selection, filtering, and noise reduction, is frequently observed as a crucial step preceding the training of ML algorithms. The synthesis of this review identifies significant research gaps and outlines future directions for the field. These encompass areas such as model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.
</details>
<details>
<summary>摘要</summary>
The findings show that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently demonstrate superior accuracy and robustness among all ML algorithms examined. Additionally, the review highlights that physiological parameters, such as heart rate measurements and skin response, are commonly used as stress predictors in ML algorithms due to their rich explanatory information and ease of data acquisition.The review also notes that dimensionality reduction techniques, including mappings, feature selection, filtering, and noise reduction, are frequently applied as a crucial step before training ML algorithms. The synthesis of this review identifies significant research gaps and outlines future directions for the field, including model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Array-Design-for-Direction-Finding-using-Deep-Learning"><a href="#Sparse-Array-Design-for-Direction-Finding-using-Deep-Learning" class="headerlink" title="Sparse Array Design for Direction Finding using Deep Learning"></a>Sparse Array Design for Direction Finding using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04615">http://arxiv.org/abs/2308.04615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Vijay Mishra, Ahmet M. Elbir, Koichi Ichige</li>
<li>for: 这些笔记是为了描述深度学习技术在设计稀疏数组方面的应用。</li>
<li>methods: 这些笔记使用的方法包括超vision学习和转移学习，以及元启发学习算法如模拟热化。</li>
<li>results: 这些笔记通过多个数值实验显示了深度学习技术在不同应用中的性能。这些应用包括认知雷达应用、无线通信应用和集成感知通信应用。<details>
<summary>Abstract</summary>
In the past few years, deep learning (DL) techniques have been introduced for designing sparse arrays. These methods offer the advantages of feature engineering and low prediction-stage complexity, which is helpful in tackling the combinatorial search inherent to finding a sparse array. In this chapter, we provide a synopsis of several direction finding applications of DL-based sparse arrays. We begin by examining supervised and transfer learning techniques that have applications in selecting sparse arrays for a cognitive radar application. Here, we also discuss the use of meta-heuristic learning algorithms such as simulated annealing for the case of designing two-dimensional sparse arrays. Next, we consider DL-based antenna selection for wireless communications, wherein sparse array problem may also be combined with channel estimation, beamforming, or localization. Finally, we provide an example of deep sparse array technique for integrated sensing and communications (ISAC) application, wherein a trade-off of radar and communications performance makes ISAC sparse array problem very challenging. For each setting, we illustrate the performance of model-based optimization and DL techniques through several numerical experiments. We discuss additional considerations required to ensure robustness of DL-based algorithms against various imperfections in array data.
</details>
<details>
<summary>摘要</summary>
在过去几年，深度学习（DL）技术被应用于设计稀疏阵列。这些方法具有特征工程和预测阶段复杂性的优点，可以帮助解决稀疏阵列中的 комбинаторional搜索问题。在这个章节中，我们提供了多个方向找应用的DL-based稀疏阵列 synopsis。我们开始是查看supervised和转移学习技术的应用，包括用于选择稀疏阵列的cognitive radar应用。此外，我们还讨论了meta-heuristic学习算法，如模拟热处理，用于两dimensional稀疏阵列的设计。接着，我们考虑了DL-based天线选择，用于无线通信，其中稀疏阵列问题可能也与通道估计、扫描、或定位相结合。最后，我们提供了一个例子，用于 интеграted sensing和通信（ISAC）应用，其中各种因素使得ISAC稀疏阵列问题非常困难。对于每个设置，我们通过多个数学实验ILLUSTRATE了模型基于优化和DL技术的性能。我们还讨论了对DL基于算法的稳定性进行保证，以防止数组数据中的各种不纯净。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Driven-Detection-of-Tsunami-Related-Internal-GravityWaves-a-path-towards-open-ocean-natural-hazards-detection"><a href="#Deep-Learning-Driven-Detection-of-Tsunami-Related-Internal-GravityWaves-a-path-towards-open-ocean-natural-hazards-detection" class="headerlink" title="Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection"></a>Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04611">http://arxiv.org/abs/2308.04611</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vc1492a/tidd">https://github.com/vc1492a/tidd</a></li>
<li>paper_authors: Valentino Constantinou, Michela Ravanelli, Hamlin Liu, Jacob Bortnik</li>
<li>for: 这个论文是为了探讨津波可以触发内部重力波（IGW）在 ionosphere 中，并对全球卫星导航系统（GNSS）的总电子Content（TEC）产生影响，从而提高津波早期预警系统的可靠性。</li>
<li>methods: 这个论文使用了深度学习技术，将大量的 GNSS 数据与 Computer Vision 技术相结合，以检测开 ocean 上的 TIDs。</li>
<li>results: 这个论文通过使用历史数据（2010 年智利大地震、2011 年日本东北地震、2012 年加拿大海地震）进行模型训练，并使用2015 年智利伊拉帕尔地震作为模型验证。结果显示，使用这个实验室框架可以达到 91.7% F1 分数。<details>
<summary>Abstract</summary>
Tsunamis can trigger internal gravity waves (IGWs) in the ionosphere, perturbing the Total Electron Content (TEC) - referred to as Traveling Ionospheric Disturbances (TIDs) that are detectable through the Global Navigation Satellite System (GNSS). The GNSS are constellations of satellites providing signals from Earth orbit - Europe's Galileo, the United States' Global Positioning System (GPS), Russia's Global'naya Navigatsionnaya Sputnikovaya Sistema (GLONASS) and China's BeiDou. The real-time detection of TIDs provides an approach for tsunami detection, enhancing early warning systems by providing open-ocean coverage in geographic areas not serviceable by buoy-based warning systems. Large volumes of the GNSS data is leveraged by deep learning, which effectively handles complex non-linear relationships across thousands of data streams. We describe a framework leveraging slant total electron content (sTEC) from the VARION (Variometric Approach for Real-Time Ionosphere Observation) algorithm by Gramian Angular Difference Fields (from Computer Vision) and Convolutional Neural Networks (CNNs) to detect TIDs in near-real-time. Historical data from the 2010 Maule, 2011 Tohoku and the 2012 Haida-Gwaii earthquakes and tsunamis are used in model training, and the later-occurring 2015 Illapel earthquake and tsunami in Chile for out-of-sample model validation. Using the experimental framework described in the paper, we achieved a 91.7% F1 score. Source code is available at: https://github.com/vc1492a/tidd. Our work represents a new frontier in detecting tsunami-driven IGWs in open-ocean, dramatically improving the potential for natural hazards detection for coastal communities.
</details>
<details>
<summary>摘要</summary>
TSUNAMIS可以触发内部重力波（IGW）在ionosphere中，影响Total Electron Content（TEC），被称为旅行 ionospheric Disturbances（TIDs），可以通过全球卫星定位系统（GNSS）进行检测。GNSS包括欧洲的Galileo、美国的Global Positioning System（GPS）、俄罗斯的Global'naya Navigatsionnaya Sputnikovaya Sistema（GLONASS）以及中国的BeiDou。实时检测TIDs可以增强洪水早期警报系统，提供开 ocean 覆盖，在海岸社区中增强自然灾害探测的潜力。通过深度学习，可以有效地处理复杂的非线性关系，并处理 thousands of 数据流。我们介绍了一个框架，利用 Slant Total Electron Content（sTEC）从VARION（Variometric Approach for Real-Time Ionosphere Observation）算法、Gramian Angular Difference Fields（从计算机视觉）和Convolutional Neural Networks（CNNs）来检测TIDs。历史数据来自2010年的 Maule、2011年的 Tohoku 和2012年的 Haida-Gwaii 海啸和地震，以及2015年的 Illapel 海啸。通过使用这些数据进行模型训练，并在模型验证中使用2015年的 Illapel 海啸。通过我们所描述的实验框架，我们实现了91.7%的 F1 分数。源代码可以在以下链接中找到：https://github.com/vc1492a/tidd。我们的工作代表了一种新的探测方式，可以在开 ocean 中探测海啸驱动的IGW，对海岸社区的自然灾害探测潜力做出了重要提高。
</details></li>
</ul>
<hr>
<h2 id="PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data"><a href="#PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data" class="headerlink" title="PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data"></a>PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04605">http://arxiv.org/abs/2308.04605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Shen, Han-Wei Shen</li>
<li>For: 这个论文主要针对科学数据超分辨化问题，即如何使用深度学习模型来提高低分辨化数据的分辨率，同时也考虑了量化结果的不确定性。* Methods: 这个论文提出了一种基于normalizing flow的生成模型，称为PSRFlow，它可以在科学数据超分辨化过程中带有量化结果的不确定性。PSRFlow采用了conditionaldistribution来学习高分辨化数据的征文分布，并通过随机抽取Gaussian积分空间中的样本来实现不同可能性的超分辨化输出。* Results: 论文的实验结果表明，PSRFlow可以在不同的数据缩放比例下进行灵活的超分辨化，并且可以准确量化超分辨化结果的不确定性。相比之下，使用插值和GAN基于的超分辨化网络，PSRFlow的性能更佳，并且可以在不同的数据缩放比例下进行灵活的超分辨化。<details>
<summary>Abstract</summary>
Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.
</details>
<details>
<summary>摘要</summary>
尽管在过去几年内出现了许多基于深度学习的超分辨率方法，但因为在推理阶段没有地面 truth 可用，因此只能很难量化和不确定性的超分辨率结果。在科学视觉应用中，却是非常重要的将结果中的不确定性传递给科学家，以避免生成错误或不正确的信息。在这篇论文中，我们提出了 PSRFlow，一种基于 normalizing flow 的生成模型，用于科学数据超分辨率中的不确定性量化。PSRFlow 学习了高分辨率数据的 conditional 分布，基于低分辨率数据。通过在 Gaussian 噪声空间中采样，可以生成不同可能性的超分辨率输出。在 Gaussian 噪声空间中高效采样，使我们的模型能够对超分辨率结果进行不确定性量化。在模型训练过程中，我们将训练数据中的样本扩展到不同的尺度，以使模型适应不同的输入数据，实现 flexible 的超分辨率。我们的结果表明，相比于现有的 interpolate 和 GAN 基于的超分辨率网络，PSRFlow 具有更高的性能和更稳定的不确定性量化。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Decentralized-Federated-Learning"><a href="#A-Survey-on-Decentralized-Federated-Learning" class="headerlink" title="A Survey on Decentralized Federated Learning"></a>A Survey on Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04604">http://arxiv.org/abs/2308.04604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edoardo Gabrielli, Giovanni Pica, Gabriele Tolomei</li>
<li>For: This paper reviews and summarizes existing decentralized federated learning (FL) approaches proposed in the literature, with the goal of mitigating the vulnerabilities of centralized FL systems.* Methods: The paper discusses various decentralized FL approaches that have been proposed to overcome the single-point-of-failure risks and man-in-the-middle attacks of classical FL systems. These approaches include decentralized FL with blockchain, decentralized FL with distributed optimization, and decentralized FL with edge computing.* Results: The paper identifies emerging challenges in decentralized FL and suggests promising research directions in this under-explored domain, including the need for better privacy guarantees, improved communication efficiency, and more robust fault tolerance mechanisms.Here is the same information in Simplified Chinese:* For: 这篇论文总结了现有的分布式联合学习（FL）方法，以减少分布式学习系统中中央服务器的敏感性。* Methods: 论文讨论了各种分布式FL方法，包括基于区块链的分布式FL、基于分布式优化的分布式FL、基于边缘计算的分布式FL等。* Results: 论文认为，分布式FL在 presente 还存在许多挑战，例如提供更好的隐私保证、改进通信效率、加强故障快灵机制等。<details>
<summary>Abstract</summary>
In recent years, federated learning (FL) has become a very popular paradigm for training distributed, large-scale, and privacy-preserving machine learning (ML) systems. In contrast to standard ML, where data must be collected at the exact location where training is performed, FL takes advantage of the computational capabilities of millions of edge devices to collaboratively train a shared, global model without disclosing their local private data. Specifically, in a typical FL system, the central server acts only as an orchestrator; it iteratively gathers and aggregates all the local models trained by each client on its private data until convergence. Although FL undoubtedly has several benefits over traditional ML (e.g., it protects private data ownership by design), it suffers from several weaknesses. One of the most critical challenges is to overcome the centralized orchestration of the classical FL client-server architecture, which is known to be vulnerable to single-point-of-failure risks and man-in-the-middle attacks, among others. To mitigate such exposure, decentralized FL solutions have emerged where all FL clients cooperate and communicate without a central server. This survey comprehensively summarizes and reviews existing decentralized FL approaches proposed in the literature. Furthermore, it identifies emerging challenges and suggests promising research directions in this under-explored domain.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Learning-based-Image-Watermarking-A-Brief-Survey"><a href="#Deep-Learning-based-Image-Watermarking-A-Brief-Survey" class="headerlink" title="Deep Learning based Image Watermarking: A Brief Survey"></a>Deep Learning based Image Watermarking: A Brief Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04603">http://arxiv.org/abs/2308.04603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zhong, Arjon Das, Fahad Alrasheedi, Abdullah Tanvir</li>
<li>for: 本文是一篇关于图像水印技术的评论文章，旨在对最新的深度学习基于图像水印技术进行总结和分析。</li>
<li>methods: 本文分为三类：Embedder-Extractor Joint Training、深度网络作为特征变换和混合方案。每个类型的研究方向也得到了分析和总结。</li>
<li>results: 本文对每种方法进行了评估和分析，并提出了未来研究的可能性，以便对图像水印技术的发展做出更多的贡献。<details>
<summary>Abstract</summary>
The act of secretly embedding and extracting a watermark on a cover image to protect it is known as image watermarking. In recent years, deep learning-based image watermarking techniques have been emerging one after another. To study the state-of-the-art, this survey categorizes cutting-edge deep learning-based image watermarking techniques into Embedder-Extractor Joint Training, Deep Networks as a Feature Transformation, and Hybrid schemes. Research directions in each category are also analyzed and summarized. Additionally, potential future research directions are discussed to envision future studies.
</details>
<details>
<summary>摘要</summary>
Image watermarking是一种将水印隐藏在封面图像中以保护它的技术。在过去几年，基于深度学习的图像水印技术不断推出。为了研究当前最佳实践，本文将这些技术分为三类：嵌入器-EXTRACTOR共同训练、深度网络作为特征变换以及混合方案。每个类别的研究方向也被分析和总结。此外，未来研究的可能性也被讨论，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Quantization-Aware-Factorization-for-Deep-Neural-Network-Compression"><a href="#Quantization-Aware-Factorization-for-Deep-Neural-Network-Compression" class="headerlink" title="Quantization Aware Factorization for Deep Neural Network Compression"></a>Quantization Aware Factorization for Deep Neural Network Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04595">http://arxiv.org/abs/2308.04595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daria Cherniuk, Stanislav Abukhovich, Anh-Huy Phan, Ivan Oseledets, Andrzej Cichocki, Julia Gusak</li>
<li>for: 压缩和优化神经网络模型，以适应移动或嵌入式设备的内存和功耗限制。</li>
<li>methods: 使用 Alternating Direction Method of Multipliers (ADMM) 进行 Canonical Polyadic (CP) 分解，并使用量化因子来实现精简。</li>
<li>results: 提出了一种新的压缩神经网络模型，可以同时保持模型的预测质量和性能。与现有的后期量化方法相比，我们的方法具有更高的灵活性和更好的质量-性能评价。<details>
<summary>Abstract</summary>
Tensor decomposition of convolutional and fully-connected layers is an effective way to reduce parameters and FLOP in neural networks. Due to memory and power consumption limitations of mobile or embedded devices, the quantization step is usually necessary when pre-trained models are deployed. A conventional post-training quantization approach applied to networks with decomposed weights yields a drop in accuracy. This motivated us to develop an algorithm that finds tensor approximation directly with quantized factors and thus benefit from both compression techniques while keeping the prediction quality of the model. Namely, we propose to use Alternating Direction Method of Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with factors whose elements lie on a specified quantization grid. We compress neural network weights with a devised algorithm and evaluate it's prediction quality and performance. We compare our approach to state-of-the-art post-training quantization methods and demonstrate competitive results and high flexibility in achiving a desirable quality-performance tradeoff.
</details>
<details>
<summary>摘要</summary>
tensor分解可以有效地减少神经网络中参数和FLOP，因此在移动或嵌入式设备上部署预训练模型时，通常需要进行量化步骤。然而，使用传统的后期量化方法可能会导致模型的准确率下降。这种情况引发了我们开发一种 direkt使用量化因子进行tensorapproximation的算法，以便同时利用压缩技术以及保持模型预测质量。具体来说，我们提出使用多元方程分解法（ADMM）来实现Canonical Polyadic（CP）分解，其中因子元素均 lie on a specified quantization grid。我们将神经网络权重压缩成一种新的算法，并评估其预测质量和性能。我们对比了我们的方法与现有的后期量化方法，并证明了我们的方法具有竞争力，并且可以在desirable quality-performance tradeoff中实现高灵活性。
</details></li>
</ul>
<hr>
<h2 id="ScatterUQ-Interactive-Uncertainty-Visualizations-for-Multiclass-Deep-Learning-Problems"><a href="#ScatterUQ-Interactive-Uncertainty-Visualizations-for-Multiclass-Deep-Learning-Problems" class="headerlink" title="ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems"></a>ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04588">http://arxiv.org/abs/2308.04588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mit-ll-responsible-ai/equine-webapp">https://github.com/mit-ll-responsible-ai/equine-webapp</a></li>
<li>paper_authors: Harry Li, Steven Jorgensen, John Holodnak, Allan Wollaber</li>
<li>for: This paper is written for machine learning (ML) consumers and engineers who need to understand and visualize the uncertainty of a model’s predictions, especially in multiclass labeling problems.</li>
<li>methods: The paper uses distance-aware neural networks and dimensionality reduction techniques to construct robust, 2-D scatter plots that explain the model’s predictions and uncertainty.</li>
<li>results: The paper demonstrates the effectiveness of the ScatterUQ system in explaining model uncertainty for a multiclass image classification on a distance-aware neural network trained on Fashion-MNIST and tested on Fashion-MNIST (in distribution) and MNIST digits (out of distribution), as well as a deep learning model for a cyber dataset. The results indicate that the ScatterUQ system should scale to arbitrary, multiclass datasets.Here is the same information in Simplified Chinese:</li>
<li>for: 这篇论文是为机器学习（ML）消费者和工程师编写的，他们需要理解和可视化模型预测结果的不确定性，特别是在多类标签问题中。</li>
<li>methods: 论文使用距离意识的神经网络和维度减少技术构建robust的2D散点图，解释模型预测结果和不确定性。</li>
<li>results: 论文证明了ScatterUQ系统在多类图像分类任务中适用，可以准确地解释模型预测结果的不确定性。试验结果表明，ScatterUQ系统可以扩展到任意多类数据集。<details>
<summary>Abstract</summary>
Recently, uncertainty-aware deep learning methods for multiclass labeling problems have been developed that provide calibrated class prediction probabilities and out-of-distribution (OOD) indicators, letting machine learning (ML) consumers and engineers gauge a model's confidence in its predictions. However, this extra neural network prediction information is challenging to scalably convey visually for arbitrary data sources under multiple uncertainty contexts. To address these challenges, we present ScatterUQ, an interactive system that provides targeted visualizations to allow users to better understand model performance in context-driven uncertainty settings. ScatterUQ leverages recent advances in distance-aware neural networks, together with dimensionality reduction techniques, to construct robust, 2-D scatter plots explaining why a model predicts a test example to be (1) in-distribution and of a particular class, (2) in-distribution but unsure of the class, and (3) out-of-distribution. ML consumers and engineers can visually compare the salient features of test samples with training examples through the use of a ``hover callback'' to understand model uncertainty performance and decide follow up courses of action. We demonstrate the effectiveness of ScatterUQ to explain model uncertainty for a multiclass image classification on a distance-aware neural network trained on Fashion-MNIST and tested on Fashion-MNIST (in distribution) and MNIST digits (out of distribution), as well as a deep learning model for a cyber dataset. We quantitatively evaluate dimensionality reduction techniques to optimize our contextually driven UQ visualizations. Our results indicate that the ScatterUQ system should scale to arbitrary, multiclass datasets. Our code is available at https://github.com/mit-ll-responsible-ai/equine-webapp
</details>
<details>
<summary>摘要</summary>
近些时间，有关uncertainty-aware深度学习方法的发展，可以提供批量分类问题中模型的信度预测概率和外部数据（OOD）指标，让机器学习（ML）用户和工程师可以评估模型对预测的信度。然而，这些额外神经网络预测信息具有多种不同的uncertainty context，具有挑战的可扩展性。为解决这些挑战，我们介绍了ScatterUQ，一个交互式系统，可以为用户提供targeted visualization，以便更好地理解模型在不同uncertainty setting下的性能。ScatterUQ利用了最新的距离意识神经网络和维度减少技术，构建了robust的2D分布图，解释了模型对测试示例的预测是（1）在distribution中，（2）在distribution中，但不确定的类，以及（3）out-of-distribution。通过使用“悬挂回调”，ML用户和工程师可以通过比较测试示例与训练示例的突出特征来理解模型的不确定性性能，并决定进一步的行动。我们在Fashion-MNIST和MNIST数字集上进行了多类图像分类 task的测试，以及一个cyber dataset上的深度学习模型。我们量化评估维度减少技术，以便最佳化我们的上下文驱动的UQ视觉表示。我们的结果表明，ScatterUQ系统可扩展到任意多类数据集。我们的代码可以在https://github.com/mit-ll-responsible-ai/equine-webapp中找到。
</details></li>
</ul>
<hr>
<h2 id="Kernel-Single-Proxy-Control-for-Deterministic-Confounding"><a href="#Kernel-Single-Proxy-Control-for-Deterministic-Confounding" class="headerlink" title="Kernel Single Proxy Control for Deterministic Confounding"></a>Kernel Single Proxy Control for Deterministic Confounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04585">http://arxiv.org/abs/2308.04585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyuan Xu, Arthur Gretton</li>
<li>for: 这个论文研究了 causal effect estimation 问题，特别是在存在隐藏的假设变量时。</li>
<li>methods: 该论文使用了 two proxy variables 来恢复真实的 causal effect，并且提出了两种基于 kernel 方法来实现这一目标。</li>
<li>results: 论文 prove 了这两种方法可以一致地估计 causal effect，并且通过 Synthetic 数据 实验 validate 了这一结论。<details>
<summary>Abstract</summary>
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
</details>
<details>
<summary>摘要</summary>
我团队考虑了一个 causal effect 估计问题，其中存在一个隐藏的干扰因素。我们观察到一个代理变量，该变量与干扰因素相关。虽然 Proxy Causal Learning（PCL）使用两个代理变量来恢复真正的 causal effect，但我们表明一个代理变量足够供 causal 估计，如果结果是 deterministic 生成的，总结 Control Outcome Calibration Approach（COCA）。我们提议了两种基于 kernel 方法来解决这个设置：第一种是两 stage 回归方法，第二种是基于最大 moments 约束方法。我们证明了这两种方法可靠地估计 causal effect，并在 synthetic 数据集上进行了实验验证。
</details></li>
</ul>
<hr>
<h2 id="RECipe-Does-a-Multi-Modal-Recipe-Knowledge-Graph-Fit-a-Multi-Purpose-Recommendation-System"><a href="#RECipe-Does-a-Multi-Modal-Recipe-Knowledge-Graph-Fit-a-Multi-Purpose-Recommendation-System" class="headerlink" title="RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?"></a>RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04579">http://arxiv.org/abs/2308.04579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Pesaranghader, Touqir Sajed<br>for:RECipe is designed to recommend recipes to users based on their natural language queries or images.methods:The RECipe framework consists of three subsystems: behavior-based recommender, review-based recommender, and image-based recommender, all of which rely on embedding representations of entities and relations in a multi-modal knowledge graph (MMKG). The framework uses a pre-trained model of Microsoft’s MPNet for textual entities, and a KGE-Guided variational autoencoder (KG-VAE) for visual components.results:The authors report that the KGE models have comparable performance to neural solutions, and demonstrate the application of RECipe in a multi-purpose recommendation setting. They also show that pre-trained NLP embeddings can be used for zero-shot inference for new users and conditional recommendation with respect to recipe categories.<details>
<summary>Abstract</summary>
Over the past two decades, recommendation systems (RSs) have used machine learning (ML) solutions to recommend items, e.g., movies, books, and restaurants, to clients of a business or an online platform. Recipe recommendation, however, has not yet received much attention compared to those applications. We introduce RECipe as a multi-purpose recipe recommendation framework with a multi-modal knowledge graph (MMKG) backbone. The motivation behind RECipe is to go beyond (deep) neural collaborative filtering (NCF) by recommending recipes to users when they query in natural language or by providing an image. RECipe consists of 3 subsystems: (1) behavior-based recommender, (2) review-based recommender, and (3) image-based recommender. Each subsystem relies on the embedding representations of entities and relations in the graph. We first obtain (pre-trained) embedding representations of textual entities, such as reviews or ingredients, from a fine-tuned model of Microsoft's MPNet. We initialize the weights of the entities with these embeddings to train our knowledge graph embedding (KGE) model. For the visual component, i.e., recipe images, we develop a KGE-Guided variational autoencoder (KG-VAE) to learn the distribution of images and their latent representations. Once KGE and KG-VAE models are fully trained, we use them as a multi-purpose recommendation framework. For benchmarking, we created two knowledge graphs (KGs) from public datasets on Kaggle for recipe recommendation. Our experiments show that the KGE models have comparable performance to the neural solutions. We also present pre-trained NLP embeddings to address important applications such as zero-shot inference for new users (or the cold start problem) and conditional recommendation with respect to recipe categories. We eventually demonstrate the application of RECipe in a multi-purpose recommendation setting.
</details>
<details>
<summary>摘要</summary>
RECipe consists of three subsystems: (1) behavior-based recommender, (2) review-based recommender, and (3) image-based recommender. Each subsystem relies on the embedding representations of entities and relations in the graph. We first obtain pre-trained embedding representations of textual entities, such as reviews or ingredients, from a fine-tuned model of Microsoft's MPNet. We initialize the weights of the entities with these embeddings to train our knowledge graph embedding (KGE) model. For the visual component, i.e., recipe images, we develop a KGE-Guided variational autoencoder (KG-VAE) to learn the distribution of images and their latent representations. Once the KGE and KG-VAE models are fully trained, we use them as a multi-purpose recommendation framework.For benchmarking, we created two knowledge graphs (KGs) from public datasets on Kaggle for recipe recommendation. Our experiments show that the KGE models have comparable performance to the neural solutions. We also present pre-trained NLP embeddings to address important applications such as zero-shot inference for new users (or the cold start problem) and conditional recommendation with respect to recipe categories. We eventually demonstrate the application of RECipe in a multi-purpose recommendation setting.
</details></li>
</ul>
<hr>
<h2 id="Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder"><a href="#Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder" class="headerlink" title="Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder"></a>Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05122">http://arxiv.org/abs/2308.05122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicha C. Dvornek, Catherine Sullivan, James S. Duncan, Abha R. Gupta</li>
<li>for: 本研究旨在开发一种能够集成基因数据、人口数据和功能磁共振成像数据的模型，以提高自适应发展干预和精准诊断autism spectrum disorder (ASD)的能力。</li>
<li>methods: 本研究使用的方法包括基因数据的拟合策略，以及基于注意力的方法，使得基因数据指导了功能磁共振成像特征的重要性。</li>
<li>results: 研究结果表明，基于注意力的模型在ASD分类和严重程度预测任务中表现出了更高的预测性，比其他多Modal方法更好。<details>
<summary>Abstract</summary>
The multifactorial etiology of autism spectrum disorder (ASD) suggests that its study would benefit greatly from multimodal approaches that combine data from widely varying platforms, e.g., neuroimaging, genetics, and clinical characterization. Prior neuroimaging-genetic analyses often apply naive feature concatenation approaches in data-driven work or use the findings from one modality to guide posthoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches.
</details>
<details>
<summary>摘要</summary>
多因素性的自闭症спектループ病（ASD）的研究受到多Modal的方法的帮助，这些方法结合了不同的平台数据，例如神经成像、遗传学和临床特征化。过去的神经成像-遗传学分析经常使用简单的特征 concatenation 方法，或者使用一个Modal的数据来导向另一个Modal的后期分析，错过了对归一化Multimodal数据的机会。在这篇论文中，我们开发了一种更一致的模型，用于结合遗传学、人口学和神经成像数据。受到遗传型的影响，我们提议使用注意力机制，使遗传学数据指导神经成像特征的重要性。遗传学数据来自拟合数值参数，而神经成像数据来自功能核磁共振成像。我们在ASD分类和严重程度预测任务中使用了10次交叉验证框架，并证明了我们的注意力机制模型在多Modal方法中的超越性。
</details></li>
</ul>
<hr>
<h2 id="From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data"><a href="#From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data" class="headerlink" title="From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data"></a>From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04553">http://arxiv.org/abs/2308.04553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maan Qraitem, Kate Saenko, Bryan A. Plummer</li>
<li>for: 降低训练集中孤立的偏见（Females），使计算机视觉模型更加公正。</li>
<li>methods: 使用生成模型生成偏见类别（Programmers）中少见的样本数据，以增加训练集的多样性。</li>
<li>results: 提高计算机视觉模型的性能，并避免训练集中的偏见。<details>
<summary>Abstract</summary>
Visual recognition models are prone to learning spurious correlations induced by an imbalanced training set where certain groups (\eg Females) are under-represented in certain classes (\eg Programmers). Generative models offer a promising direction in mitigating this bias by generating synthetic data for the minority samples and thus balancing the training set. However, prior work that uses these approaches overlooks that visual recognition models could often learn to differentiate between real and synthetic images and thus fail to unlearn the bias in the original dataset. In our work, we propose a novel two-stage pipeline to mitigate this issue where 1) we pre-train a model on a balanced synthetic dataset and then 2) fine-tune on the real data. Using this pipeline, we avoid training on both real and synthetic data, thus avoiding the bias between real and synthetic data. Moreover, we learn robust features against the bias in the first step that mitigate the bias in the second step. Moreover, our pipeline naturally integrates with bias mitigation methods; they can be simply applied to the fine-tuning step. As our experiments prove, our pipeline can further improve the performance of bias mitigation methods obtaining state-of-the-art performance on three large-scale datasets.
</details>
<details>
<summary>摘要</summary>
“视觉识别模型容易学习偏袋 induce 由偏袋训练集而引起的偏袋偏好，其中女性组是训练集中受到排斥的。生成模型提供了一种可能性，即通过生成少数样本的Synthetic数据来平衡训练集。然而，现有的方法忽略了视觉识别模型可能会学习 differentiate between real and Synthetic images，从而失去原始数据中的偏袋。在我们的工作中，我们提出了一种新的两阶段管道来解决这个问题，即先在Balanced Synthetic dataset上预训练模型，然后在Real数据上细化。这种管道可以避免训练在Real和Synthetic数据上，从而避免偏袋 между Real和Synthetic数据。此外，我们的管道可以自然地与偏袋缓解方法集成，这些方法可以简单地应用于细化步骤。根据我们的实验证明，我们的管道可以进一步提高偏袋缓解方法的性能，并在三个大规模数据集上达到了当前最佳性能。”
</details></li>
</ul>
<hr>
<h2 id="Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining"><a href="#Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining" class="headerlink" title="Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining"></a>Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04551">http://arxiv.org/abs/2308.04551</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bbrattoli/JigsawPuzzlePytorch">https://github.com/bbrattoli/JigsawPuzzlePytorch</a></li>
<li>paper_authors: Bidur Khanal, Binod Bhattarai, Bishesh Khanal, Cristian A. Linte</li>
<li>for: 这个研究旨在探索自我监督预训练可以帮助运算图像分类器对于噪音标签的学习。</li>
<li>methods: 这个研究使用了两种自我监督预训练方法：对比自我监督预训练和预设任务预训练。</li>
<li>results: 研究结果显示，使用自我监督预训练初始化的模型可以更好地适应噪音标签下的学习，并且在医疗图像分类任务中表现出色。<details>
<summary>Abstract</summary>
Noisy labels hurt deep learning-based supervised image classification performance as the models may overfit the noise and learn corrupted feature extractors. For natural image classification training with noisy labeled data, model initialization with contrastive self-supervised pretrained weights has shown to reduce feature corruption and improve classification performance. However, no works have explored: i) how other self-supervised approaches, such as pretext task-based pretraining, impact the learning with noisy label, and ii) any self-supervised pretraining methods alone for medical images in noisy label settings. Medical images often feature smaller datasets and subtle inter class variations, requiring human expertise to ensure correct classification. Thus, it is not clear if the methods improving learning with noisy labels in natural image datasets such as CIFAR would also help with medical images. In this work, we explore contrastive and pretext task-based self-supervised pretraining to initialize the weights of a deep learning classification model for two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100K tissue histological images and COVID-QU-Ex chest X-ray images. Our results show that models initialized with pretrained weights obtained from self-supervised learning can effectively learn better features and improve robustness against noisy labels.
</details>
<details>
<summary>摘要</summary>
噪音标签会妨碍深度学习基于监督图像分类的性能，因为模型可能会过拟合噪音并学习损坏的特征提取器。在自然图像分类训练中使用噪音标签时，使用对比自我超vised预训练的模型初始化可以减少特征损坏并提高分类性能。然而，没有任何研究探讨了：一、其他自我超视任务基于预训练的影响在噪音标签下的学习；二、任何自我超视任务alone可以在医疗图像中提高分类性能。医疗图像通常具有小数据量和柔微的类别变化，需要人工专业来确保正确的分类。因此，不清楚自然图像dataset中的方法会否帮助医疗图像。在这项工作中，我们探讨了对比和预tex任务基于自我超视预训练来初始化深度学习分类模型的效果，并应用于两个医疗图像dataset中的自induced噪音标签——NCT-CRC-HE-100K组织 Histological图像和COVID-QU-Ex胸部X射影像。我们的结果表明，使用自我超视预训练获得的预训练模型可以更好地学习特征和抗抗噪音标签的强健性。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures"><a href="#Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures" class="headerlink" title="Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures"></a>Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04539">http://arxiv.org/abs/2308.04539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash</li>
<li>for: 本研究旨在设计一个能够持续学习的智能系统，以应对实际世界中的不断更新和变化。</li>
<li>methods: 本研究使用了生物学中的 synaptic plasticity 机制和 neuromodulation，实现了在线进行持续学习，不需要使用条件 gradient descent 和储存 Buffer。</li>
<li>results: 比较其他记忆受限的学习方法，本研究在 Split-MNIST、Split-CIFAR-10 和 Split-CIFAR-100 数据集上表现出色，并且与使用条件 gradient descent 的记忆密集探险方法相符。此外，本研究还证明了 incorporating 生物学原理到机器学习模型中可以提高持续学习的精度。<details>
<summary>Abstract</summary>
The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent.   Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the effectiveness of our approach by integrating key design concepts into other backpropagation-based continual learning algorithms, significantly improving their accuracy. Our results provide compelling evidence for the importance of incorporating biological principles into machine learning models and offer insights into how we can leverage them to design more efficient and robust systems for online continual learning.
</details>
<details>
<summary>摘要</summary>
“持续学习”是智能系统设计的核心能力。许多持续学习方法 rely on 随机 gradient descent 和其变化，但这个方法需要运用 memory buffer 或 replay 来缓解其稳定性、贪婪性和短期记忆限制。为了解决这个问题，我们已经开发了一个基于生物学原理的轻量级神经网络架构，具有 synaptic plasticity 机制和 neuromodulation，因此可以通过本地错误信号进行线上持续学习，不需要随机 gradient descent。我们的方法在 Split-MNIST、Split-CIFAR-10 和 Split-CIFAR-100 数据集上展现出较好的线上持续学习性能，比较于其他记忆受限的学习方法和 matches 状态顶尖的记忆丰富 replay-based 方法。我们还将这些设计元素 integrate 到其他 backpropagation-based 持续学习算法中，很大提高了它们的精度。我们的结果提供了对生物学原理在机器学习模型中的应用的丰富证据，并且显示了如何运用这些原理设计更有效率和可靠的线上持续学习系统。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review"><a href="#Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review" class="headerlink" title="Deep Learning for Diverse Data Types Steganalysis: A Review"></a>Deep Learning for Diverse Data Types Steganalysis: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04522">http://arxiv.org/abs/2308.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Kheddar, Mustapha Hemis, Yassine Himeur, David Megías, Abbes Amira</li>
<li>for: 本文旨在提供一个系统性的回顾文献中，探讨使用深度学习技术进行隐藏信息检测的最新研究进展。</li>
<li>methods: 本文使用的方法包括深度学习技术，如深度训练学习（DTL）和深度强化学习（DRL），以提高隐藏信息检测系统的性能。</li>
<li>results: 本文对各种封隐媒体进行了检测，并对不同数据集的DTL基于隐藏信息检测方法进行了系统性的分析。<details>
<summary>Abstract</summary>
Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.
</details>
<details>
<summary>摘要</summary>
信息安全领域中，隐藏通信和找到隐藏通信的技术是两个相关的方面，它们分别称为隐藏通信（Steganography）和找到隐藏通信（Steganalysis）。隐藏通信是为了避免被捕获，而找到隐藏通信则是为了找到隐藏的信息。这两个方面在过去几年中吸引了很多关注，特别是由于许多国家禁止或限制 cryptography的使用，因此隐藏通信成为了违法活动的一种常见手段。为了暴露这些违法活动，了解最新的隐藏通信和找到隐藏通信技术是非常重要的。这篇文章提供了一个完整的隐藏通信和找到隐藏通信技术的文献综述，特别是使用深度学习来检测隐藏在数字媒体中的信息。文章覆盖了所有类型的隐藏媒体，包括图像、音频和视频，并讲解了最常用的深度学习技术。此外，文章还探讨了使用更高级的深度学习技术，如深度传输学习（DTL）和深度奖励学习（DRL），以提高隐藏检测系统的性能。文章还提供了最新的研究数据集和评价指标，以及DTL-based隐藏检测方法在不同数据集上的性能分析。文章结束于对深度学习基于隐藏检测的当前状况、挑战和未来研究方向的讨论。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Model-Agnostic-Reliability-Evaluation-of-Machine-Learning-Methods-Integrated-in-Instrumentation-Control-Systems"><a href="#Dynamic-Model-Agnostic-Reliability-Evaluation-of-Machine-Learning-Methods-Integrated-in-Instrumentation-Control-Systems" class="headerlink" title="Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems"></a>Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05120">http://arxiv.org/abs/2308.05120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edward Chen, Han Bao, Nam Dinh<br>for:This paper aims to address the lack of trustworthiness in data-driven neural network-based machine learning (ML) algorithms, specifically in the field of instrumentation and control systems.methods:The authors propose a real-time model-agnostic method called Laplacian distributed decay for reliability (LADDR) to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset.results:LADDR is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients. The results show that LADDR can determine the appropriateness of well-trained ML models in the context of operational conditions, and illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks.Here is the Chinese translation of the three key points:for:这篇论文目标是解决数据驱动神经网络基于机器学习（ML）算法在仪器控制系统中的可靠性问题。methods:作者提出了一种实时模型无关的方法called Laplacian distributed decay for reliability (LADDR)，用于评估ML预测的相对可靠性，通过训练集上的异常检测。results:LADDR在不同的流失转换中使用的一种Feedforward神经网络模型上进行了评估，结果表明LADDR可以在运维条件下评估已经训练过的ML模型的适用性，并 Illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks。<details>
<summary>Abstract</summary>
In recent years, the field of data-driven neural network-based machine learning (ML) algorithms has grown significantly and spurred research in its applicability to instrumentation and control systems. While they are promising in operational contexts, the trustworthiness of such algorithms is not adequately assessed. Failures of ML-integrated systems are poorly understood; the lack of comprehensive risk modeling can degrade the trustworthiness of these systems. In recent reports by the National Institute for Standards and Technology, trustworthiness in ML is a critical barrier to adoption and will play a vital role in intelligent systems' safe and accountable operation. Thus, in this work, we demonstrate a real-time model-agnostic method to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset. It is well documented that ML algorithms excel at interpolation (or near-interpolation) tasks but significantly degrade at extrapolation. This occurs when new samples are "far" from training samples. The method, referred to as the Laplacian distributed decay for reliability (LADDR), determines the difference between the operational and training datasets, which is used to calculate a prediction's relative reliability. LADDR is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients. LADDR is intended as a "data supervisor" and determines the appropriateness of well-trained ML models in the context of operational conditions. Ultimately, LADDR illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks.
</details>
<details>
<summary>摘要</summary>
近年来，数据驱动神经网络基本学习算法在控制系统领域得到了广泛的应用和研究。虽然它们在操作上表现良好，但对这些算法的可靠性还未充分评估。失败的机器学习integrated系统未得到充分了理解，缺乏全面的风险模型化可能导致这些系统的可靠性下降。在国家标准技术研究所的最近报告中，机器学习的可靠性被视为智能系统安全和负责任运行的关键障碍。因此，在这项工作中，我们提出了一种实时模型不依赖的方法来评估机器学习预测的相对可靠性。这种方法被称为Laplacian分布式衰减 для可靠性（LADDR）。LADDR通过对训练集和操作集之间的差异进行计算，来确定预测的相对可靠性。LADDR作为“数据监督”，可以确定机器学习模型在操作条件下是否正常。最终，LADDR表明了训练数据可以作为机器学习预测的可靠性证明，当用于常见的 interpolate 任务时。
</details></li>
</ul>
<hr>
<h2 id="MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting"><a href="#MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting" class="headerlink" title="MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting"></a>MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04511">http://arxiv.org/abs/2308.04511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/big-data-lab-umbc/sea-ice-prediction">https://github.com/big-data-lab-umbc/sea-ice-prediction</a></li>
<li>paper_authors: Sahara Ali, Jianwu Wang</li>
<li>for: 该研究旨在提出一种基于深度学习的 Arctic 海冰覆盖率预测模型（MT-IceNet），以提高 Arctic 海冰预测的准确性。</li>
<li>methods: 该模型采用了 UNet 网络架构，并使用了 skip 连接和多时间频率输入流进行 spatial 和 multi-temporal 数据处理。</li>
<li>results: 研究表明，与现有模型相比，该模型在 6 个月预测时间点上具有较高的预测精度（至多 60% 减少预测错误），并且可以更好地捕捉 Arctic 海冰的变化趋势。<details>
<summary>Abstract</summary>
Arctic amplification has altered the climate patterns both regionally and globally, resulting in more frequent and more intense extreme weather events in the past few decades. The essential part of Arctic amplification is the unprecedented sea ice loss as demonstrated by satellite observations. Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has been a major research question with fundamental challenges at play. In addition to physics-based Earth system models, researchers have been applying multiple statistical and machine learning models for sea ice forecasting. Looking at the potential of data-driven approaches to study sea ice variations, we propose MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model for forecasting Arctic sea ice concentration (SIC). The model uses an encoder-decoder architecture with skip connections and processes multi-temporal input streams to regenerate spatial maps at future timesteps. Using bi-monthly and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric and oceanic variables from ERA5 reanalysis product during 1979-2021, we show that our proposed model provides promising predictive performance for per-pixel SIC forecasting with up to 60% decrease in prediction error for a lead time of 6 months as compared to its state-of-the-art counterparts.
</details>
<details>
<summary>摘要</summary>
北极强化效应对地区和全球气候Patterns有所改变，过去几十年内发生的极端天气事件频繁性和严重程度增加。北极强化效应的关键部分是历史上无 precedent的海冰损失，这种现象可以通过卫星观测得到证明。预测北极海冰的演变是一个长期的研究问题，Physics-based Earth system models 以外，研究人员还应用了多种统计学和机器学习模型。对于海冰变化的数据驱动方法的潜在优势，我们提议MT-IceNet - 基于UNet的空间和多时间（MT）深度学习模型，用于预测北极海冰浓度（SIC）。该模型采用编码器-解码器架构，并使用跳跃连接，以处理多时间输入流，以生成未来时间步的空间地图。使用1979-2021年NSIDC通过卫星获取的月度和半月度海冰数据，以及ERA5分析产品中的大气和海洋变量，我们示出了我们提议的模型在6个月预测时的预测性能具有显著提高，比之前的状态艺术模型减少至60%。
</details></li>
</ul>
<hr>
<h2 id="Efficient-option-pricing-with-unary-based-photonic-computing-chip-and-generative-adversarial-learning"><a href="#Efficient-option-pricing-with-unary-based-photonic-computing-chip-and-generative-adversarial-learning" class="headerlink" title="Efficient option pricing with unary-based photonic computing chip and generative adversarial learning"></a>Efficient option pricing with unary-based photonic computing chip and generative adversarial learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04493">http://arxiv.org/abs/2308.04493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Lingxiao Wan, Sergi Ramos-Calderer, Yuancheng Zhan, Wai-Keong Mok, Hong Cai, Feng Gao, Xianshu Luo, Guo-Qiang Lo, Leong Chuan Kwek, José Ignacio Latorre, Ai Qun Liu</li>
<li>for: 这个研究是为了提高金融业中的计算能力和服务质量。</li>
<li>methods: 这个研究使用了光子学芯片，实现了欧洲选择权价格计算的单元方法，并与量子振荡估计算法相结合，实现了当前的古典 Monte Carlo 方法的二次倍速。该芯片由三个模组组成：分布模组、预期收益模组和量子振荡估计算法模组。在分布模组中，一个对抗学习网络被嵌入，以高效地学习和载入资产分布，精确地捕捉市场趋势。</li>
<li>results: 这个研究获得了与古典 Monte Carlo 方法相比的二次倍速的速度优化，并且显示出了对特定金融产品的高精度计算和评估能力。这个研究显示出了特殊的光子处理器在金融应用中的发展潜力，可能将改善金融服务的效率和质量。<details>
<summary>Abstract</summary>
In the modern financial industry system, the structure of products has become more and more complex, and the bottleneck constraint of classical computing power has already restricted the development of the financial industry. Here, we present a photonic chip that implements the unary approach to European option pricing, in combination with the quantum amplitude estimation algorithm, to achieve a quadratic speedup compared to classical Monte Carlo methods. The circuit consists of three modules: a module loading the distribution of asset prices, a module computing the expected payoff, and a module performing the quantum amplitude estimation algorithm to introduce speed-ups. In the distribution module, a generative adversarial network is embedded for efficient learning and loading of asset distributions, which precisely capture the market trends. This work is a step forward in the development of specialized photonic processors for applications in finance, with the potential to improve the efficiency and quality of financial services.
</details>
<details>
<summary>摘要</summary>
现代金融系统中，产品结构变得越来越复杂，甚至限制了金融业的发展。我们介绍了一款光学板，实现了欧洲选项价值方法的单元化方法，与量子振荡估算算法相结合，与经典 Monte Carlo 方法相比，实现了平方速度增加。该板件由三个模块组成：一个分布Module，一个预期收益Module，以及一个引入速度增加的量子振荡估算算法Module。在分布模块中，一个生成对抗网络被嵌入，以高效地学习和加载资产分布，准确捕捉市场趋势。这项工作是金融专用光学处理器的开发的一个重要步骤，有望提高金融服务的效率和质量。
</details></li>
</ul>
<hr>
<h2 id="When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations"><a href="#When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations" class="headerlink" title="When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations"></a>When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04431">http://arxiv.org/abs/2308.04431</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/basedrhys/ood-generalization">https://github.com/basedrhys/ood-generalization</a></li>
<li>paper_authors: Rhys Compton, Lily Zhang, Aahlad Puli, Rajesh Ranganath</li>
<li>for: 这个研究探讨了在机器学习中是否可以通过添加更多数据提高模型性能的问题。</li>
<li>methods: 研究者采用了大规模的实验方法，将四个开源胸部X射影数据集和九个标签进行组合，以检测在哪些情况下，通过添加外部数据集可能会降低模型的性能。</li>
<li>results: 研究发现，在43%的情况下，由两个医院的数据进行训练的模型会在两个医院的数据上 display 更差的最坏群组精度，即使外部数据使得训练分布更接近测试分布。这种情况发生的原因是医院特有的图像残余引起的假 correlate。研究者解释了在多个数据集训练中存在的贸易关系，并提出了在选择训练数据时需要小心的警示。<details>
<summary>Abstract</summary>
In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation. In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy. We contextualize our results within the literature on spurious correlations to help explain these outcomes. Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging. The risks outlined highlight the need for careful data selection and model evaluation in future research and practice.
</details>
<details>
<summary>摘要</summary>
在机器学习中，更多数据的添加经常被视为提高模型性能的可靠策略，但这项研究挑战了这一观点，示出在许多情况下，添加外部数据集可能会伤害模型的性能。我们在四个不同的开源胸部X射线数据集和九个标签的大规模实验中发现，在43%的情况下，由两个医院的数据进行训练的模型会比由单一医院数据进行训练的模型在最差群体准确率上表现较差。这种意外的结果尽管训练数据的分布变得更像测试数据的分布，但是由医院特有的图像artifacts导致的假 correlations的出现却导致这种情况。我们指出在多个数据集训练时，需要考虑这种交易的代价，即附加的数据可能会引入假 correlations，并且不一定有效地平衡数据集可以消除这种假 correlations。我们将这些结果与 литераature中的假 correlations相关的研究进行比较，以帮助解释这些结果。我们的实验表明，在机器学习模型训练中，特别是在医疗影像等领域，需要仔细选择数据，并且对模型进行仔细的评估。
</details></li>
</ul>
<hr>
<h2 id="SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore"><a href="#SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore" class="headerlink" title="SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore"></a>SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04430">http://arxiv.org/abs/2308.04430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kernelmachine/silo-lm">https://github.com/kernelmachine/silo-lm</a></li>
<li>paper_authors: Sewon Min, Suchin Gururangan, Eric Wallace, Hannaneh Hajishirzi, Noah A. Smith, Luke Zettlemoyer</li>
<li>for: 这个论文是关于训练语言模型（LM）时的法律风险的研究。</li>
<li>methods: 这个论文使用了一种新的方法，即在推理时使用一个可 modify的非 Parametric 存储系统，以使用高风险数据而不需要在训练时使用它。这个存储系统支持句子级数据归属和数据生产者 opt-out 功能。</li>
<li>results: 实验表明，使用这种方法可以提高LM的性能，并且可以避免训练语言模型时的法律风险。<details>
<summary>Abstract</summary>
The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.
</details>
<details>
<summary>摘要</summary>
法律性的语言模型（LM）在版权保护或限制数据上训练是正在激烈讨论中。然而，我们显示，如果只在低风险文本（如公共领域书籍或政府文档）上训练模型，则模型的性能会很差，因为它们的规模和领域覆盖率都很有限。我们介绍了一种新的语言模型，叫做SILO，它在推理过程中处理这种风险和性能之间的贸易。SILO通过（1）使用公共领域和允许使用的文本集（Open License Corpus，OLC）训练 Parametric LM，并（2）在推理过程中使用更通用和可修改的非参数数据存储（如包含版权书籍或新闻的数据）来增强性能。这个数据存储允许在推理过程中使用高风险数据，支持句子水平的数据归属，并允许数据生产者在模型中删除内容，以遵守数据使用法规，如美国的公平使用 doctrine 和欧盟的 GDPR。我们的实验表明， parametric LM 在不受 OLC 覆盖的领域上表现不佳，但是通过访问数据存储，可以大幅提高 OUT  OF  DOMAIN 的表现，减少90%的表现差，与基于 Pile 的 LM 相比，Pile 是一个更加多样化的句子集，主要包含高风险文本。我们还分析了不 Parametric 的方法是哪种最佳，哪些错误还存在，以及数据存储大小如何影响性能。我们的结果表明，可以在法律风险下建立高质量的语言模型。
</details></li>
</ul>
<hr>
<h2 id="Meta-Learning-Operators-to-Optimality-from-Multi-Task-Non-IID-Data"><a href="#Meta-Learning-Operators-to-Optimality-from-Multi-Task-Non-IID-Data" class="headerlink" title="Meta-Learning Operators to Optimality from Multi-Task Non-IID Data"></a>Meta-Learning Operators to Optimality from Multi-Task Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04428">http://arxiv.org/abs/2308.04428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas T. C. K. Zhang, Leonardo F. Toso, James Anderson, Nikolai Matni</li>
<li>for: 本研究目的是提高机器学习中的特征提取和泛化能力，通过从不同来源或任务中提取共同特征来减少计算量和统计泛化。</li>
<li>methods: 本文提出了一种恢复线性运算 matrix $M$ 从含有噪声的 вектор测量 $y &#x3D; Mx + w$ 中的方法，该方法可以处理非相关的数据和非对称的特征。</li>
<li>results: 研究人员在numerical simulations中证明了该方法的重要性，并提供了一种适应性的批处理方法 $\texttt{De-bias &amp; Feature-Whiten}$（$\texttt{DFW}$），该方法可以实现线性收敛到最佳表示，并且可以在不同来源数据中提取共同特征。<details>
<summary>Abstract</summary>
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}$ ($\texttt{DFW}$), of the popular alternating minimization-descent (AMD) scheme proposed in Collins et al., (2021), and establish linear convergence to the optimal representation with noise level scaling down with the $\textit{total}$ source data size. This leads to generalization bounds on the same order as an oracle empirical risk minimizer. We verify the vital importance of $\texttt{DFW}$ on various numerical simulations. In particular, we show that vanilla alternating-minimization descent fails catastrophically even for iid, but mildly non-isotropic data. Our analysis unifies and generalizes prior work, and provides a flexible framework for a wider range of applications, such as in controls and dynamical systems.
</details>
<details>
<summary>摘要</summary>
“一个强大的概念在现代机器学习中是提取资料来源或任务之间的共同特征。 intuitively，使用所有资料来学习共同表现函数可以节省计算努力和 statistically generalization，因为这样可以留下较少的参数来精确化每个任务。在理论基础上认养这些优点，我们提出了一个恢复线性算子 $M$ 的通用设定，其中 $y = Mx + w$ 是随机变数的 vector 观测，并且 $x$ 可能是非自相关的和非对称的。我们显示出现代不对称机器学习方法对于表现更新带来偏见，这会导致测量误差的构成因素发生不收敛的现象，从而导致表现学习的样本绩效被瓶颈在单一任务数据中。我们引入了一个适应化，即 $\texttt{De-bias & Feature-Whiten}$ ($\texttt{DFW}$)，它是 Collins et al. (2021) 提出的受欢迎的替换排程（AMD）的修改版本。我们证明了 $\texttt{DFW}$ 在数据大小增加时，随着 $\textit{total}$ 源数据大小下降的情况下，具有线性传播到最佳表现的优化。这导致了一个更加宽阔的应用范围，例如控制和动态系统。”
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces"><a href="#A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces" class="headerlink" title="A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces"></a>A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04426">http://arxiv.org/abs/2308.04426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikun Liu, Yuning Wang, Cheng Liu</li>
<li>for: 这个研究旨在提供一个深度学习方法，用于自动检测古代石刻上的自然衰老和人工损坏，以提高文物保护的精度和效率。</li>
<li>methods: 本研究使用了自动Encoder（AE）和生成对抗网络（GAN）deep learning方法，不需要大量的异常样本，并能够全面检测不可预测的异常。</li>
<li>results: 这个研究在长门洞窟的石刻上进行了一个实验，使用了一个无监理学习模型，实现了99.74%的重建精度，可以准确地检测到七种人工设计的异常。<details>
<summary>Abstract</summary>
Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation. Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN). The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies. the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing. Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstruction accuracy of 99.74\%. The method's evaluation revealed the proficient detection of seven artificially designed anomalies and demonstrated precision and reliability without false alarms. This research provides novel ideas and possibilities for the application of deep learning in the field of cultural heritage.
</details>
<details>
<summary>摘要</summary>
准确检测古代碑刻表面的自然衰丧和人工损害在第一时间是保护古迹的必要前提。现有的文化遗产保护方法并不能完美实现这一目标，因为很难平衡准确率、效率、时效性和成本。这篇论文提出了一种基于深度学习的方法，可以在实时中自动检测古石碑刻表面的紧急情况，使用自适应神经网络（AE）和生成对抗网络（GAN）。该方法超越了现有方法的局限性，不需要大量的异常样本，同时能够全面检测不可预测的异常。该方法包括监测、数据收集、预处理、模型设计和后处理等阶段。使用长门石窟的石碑刻为实例，提出了一种无监督学习模型，并在 reconstruction 精度达99.74%。模型的评估表明了高精度、可靠性和无假警示。这些研究提供了深度学习在文化遗产保护领域的新想法和可能性。
</details></li>
</ul>
<hr>
<h2 id="DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images"><a href="#DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images" class="headerlink" title="DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images"></a>DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04417">http://arxiv.org/abs/2308.04417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Zou, Kai Li, Junliang Xing, Yu Zhang, Shiying Wang, Lei Jin, Pin Tao</li>
<li>For: The paper aims to develop a novel framework for effective cloud removal from optical satellite images using conditional guided diffusion with deep convolutional networks.* Methods: The proposed method, called DiffCR, leverages a decoupled encoder for conditional image feature extraction and a novel time and condition fusion block to accurately simulate the correspondence between the appearance in the conditional image and the target image.* Results: The proposed method achieves state-of-the-art performance on all metrics, with reduced parameter and computational complexities compared to previous best methods, as demonstrated through extensive experimental evaluations on two benchmark datasets.Here’s the simplified Chinese text for the three key points:* 为: 本文目的是通过干扰导向扩散与深度卷积网络来提出一种高性能的云除法方法 для光学卫星图像。* 方法: 提议的方法称为DiffCR，它利用独立的编码器来提取条件图像的特征，以确保 Close similarity of appearance information between the conditional input and the synthesized output。此外，它还提出了一种新的时间和条件融合块，以准确地模拟条件图像中的出现与目标图像的相似性。* 结果: 根据实验证明，DiffCR在两个常用的 benchmark 数据集上具有最佳性能，与前一代方法的参数和计算复杂度相比，它的参数和计算复杂度分别降低到5.1%和5.4%。源代码、预训练模型和所有实验结果将在<a target="_blank" rel="noopener" href="https://github.com/XavierJiezou/DiffCR">https://github.com/XavierJiezou/DiffCR</a> 上公开。<details>
<summary>Abstract</summary>
Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis. Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction. While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. Extensive experimental evaluations on two commonly used benchmark datasets demonstrate that DiffCR consistently achieves state-of-the-art performance on all metrics, with parameter and computational complexities amounting to only 5.1% and 5.4%, respectively, of those previous best methods. The source code, pre-trained models, and all the experimental results will be publicly available at https://github.com/XavierJiezou/DiffCR upon the paper's acceptance of this work.
</details>
<details>
<summary>摘要</summary>
依靠光学卫星图像的数据源是一项关键的研究方向，但是云覆盖往往会降低图像质量，使图像应用和分析变得困难。因此，去云化 optical satellite images 成为了一项显著的研究方向。当前的云 removal 技术主要基于生成 adversarial networks，但这些网络可能会生成低质量的图像。 diffusion models 在多种图像生成任务中表现出色，这表明它们可能会解决这个挑战。这篇文章介绍了一种新的框架，称为 DiffCR，它利用 conditional guided diffusion 和深度卷积神经网络来实现高性能的云 removal for optical satellite imagery。 Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. 经验证实验表明，DiffCR 在两个常用的标准 benchmark dataset 上 consistently 实现了状态机器的性能，与参数和计算复杂度相对只有5.1%和5.4%，分别相对较少于之前的最佳方法。源代码、预训练模型和所有实验结果将在https://github.com/XavierJiezou/DiffCR 上公开发布， waits for the paper's acceptance of this work.
</details></li>
</ul>
<hr>
<h2 id="Vector-Embeddings-by-Sequence-Similarity-and-Context-for-Improved-Compression-Similarity-Search-Clustering-Organization-and-Manipulation-of-cDNA-Libraries"><a href="#Vector-Embeddings-by-Sequence-Similarity-and-Context-for-Improved-Compression-Similarity-Search-Clustering-Organization-and-Manipulation-of-cDNA-Libraries" class="headerlink" title="Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries"></a>Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05118">http://arxiv.org/abs/2308.05118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel H. Um, David A. Knowles, Gail E. Kaiser</li>
<li>for: 本研究旨在解决 flat string gene format (FASTA&#x2F;FASTQ5) 中存在的一些问题，如大型文件Size、慢速mapping和对Alignment进行处理，以及Contextual dependencies。这些挑战使得对相似序列进行查找变得困难。</li>
<li>methods: 本研究使用 organized numerical representations of genes 来解决这些问题。具体来说，通过将短序列赋予唯一的vector embedding，可以更有效地将相似序列 clustering 到同一个组中，并提高了压缩性能。此外，通过基于 codon triplets 的上下文学习 alternatively coordinate vector embeddings，可以基于 amino acid 性质进行 clustering。</li>
<li>results: 通过使用这种序列嵌入方法，可以快速地查找相似序列，并且可以 Coupling vector embeddings 与一种基于 Euclidean 空间的算法来确定vector proximity，从而提高了序列相似性搜索的时间复杂度。<details>
<summary>Abstract</summary>
This paper demonstrates the utility of organized numerical representations of genes in research involving flat string gene formats (i.e., FASTA/FASTQ5). FASTA/FASTQ files have several current limitations, such as their large file sizes, slow processing speeds for mapping and alignment, and contextual dependencies. These challenges significantly hinder investigations and tasks that involve finding similar sequences. The solution lies in transforming sequences into an alternative representation that facilitates easier clustering into similar groups compared to the raw sequences themselves. By assigning a unique vector embedding to each short sequence, it is possible to more efficiently cluster and improve upon compression performance for the string representations of cDNA libraries. Furthermore, through learning alternative coordinate vector embeddings based on the contexts of codon triplets, we can demonstrate clustering based on amino acid properties. Finally, using this sequence embedding method to encode barcodes and cDNA sequences, we can improve the time complexity of the similarity search by coupling vector embeddings with an algorithm that determines the proximity of vectors in Euclidean space; this allows us to perform sequence similarity searches in a quicker and more modular fashion.
</details>
<details>
<summary>摘要</summary>
The authors assign a unique vector embedding to each short sequence, allowing for more efficient clustering and improved compression performance for the string representations of cDNA libraries. Additionally, the authors use alternative coordinate vector embeddings based on the contexts of codon triplets to demonstrate clustering based on amino acid properties.Furthermore, the authors use this sequence embedding method to encode barcodes and cDNA sequences, allowing for quicker and more modular sequence similarity searches by coupling vector embeddings with an algorithm that determines the proximity of vectors in Euclidean space. This approach improves the time complexity of the similarity search, enabling researchers to perform searches more efficiently.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers"><a href="#Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers" class="headerlink" title="Probabilistic Invariant Learning with Randomized Linear Classifiers"></a>Probabilistic Invariant Learning with Randomized Linear Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04412">http://arxiv.org/abs/2308.04412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Cotta, Gal Yehuda, Assaf Schuster, Chris J. Maddison</li>
<li>for: 这篇论文是关于设计能够保持 Task 的表达能力和知识维护的模型的研究。</li>
<li>methods: 该论文使用随机化的方法，包括随机线性分类器（RLCs），以降低资源消耗而保持 Task 的表达能力和不变性。</li>
<li>results: 该论文通过验证RLCs在不同数据集上的表现，证明了这种随机化模型可以在保持 Task 的表达能力和不变性的情况下，使用较少的资源。<details>
<summary>Abstract</summary>
Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle.
</details>
<details>
<summary>摘要</summary>
设计模型能够同时表达力和保持已知的任务变换是一个日益困难的问题。现有的解决方案通常会让计算资源或内存储存量增加。在这项工作中，我们表明可以通过随机性来设计模型，以便同时保持表达力和变换不变性，并使用更少的资源。我们的关键发现是，接受随机的概念 universal approximation 和不变性可以降低我们的资源需求。更 specifically，我们提出了一类基于随机化的线性模型，即 Randomized Linear Classifiers (RLCs)。我们给出了参数和样本大小的条件，在这些条件下，RLCs 可以，高概率地，将任何（平滑）函数approximate，同时保持 compact group transformation 的不变性。利用这个结果，我们设计了三种 RLCs，其中每种都是具有概率不变性的对 classification tasks over sets, graphs, and spherical data 进行了验证。我们证明这些模型可以在不同的任务上实现概率不变性和通用性，并且使用更少的资源 чем（deterministic）神经网络和其不变counterparts。最后，我们通过实验证明这些新类型的模型在不变任务上具有优势。
</details></li>
</ul>
<hr>
<h2 id="XGBD-Explanation-Guided-Graph-Backdoor-Detection"><a href="#XGBD-Explanation-Guided-Graph-Backdoor-Detection" class="headerlink" title="XGBD: Explanation-Guided Graph Backdoor Detection"></a>XGBD: Explanation-Guided Graph Backdoor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04406">http://arxiv.org/abs/2308.04406</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanzihan/gnn_backdoor_detection">https://github.com/guanzihan/gnn_backdoor_detection</a></li>
<li>paper_authors: Zihan Guan, Mengnan Du, Ninghao Liu</li>
<li>For: 本研究旨在提出一种基于 topological feature 的 explanation-guided Graph Neural Network (GNN) 后门检测方法，以扩展现有的检测方法在图数据上的应用。* Methods: 本方法首先在 GNN 模型上进行训练，然后采用解释方法来归属模型预测结果到一个重要的子图。通过分析各个样本的归属结果，可以发现后门样本的归属分布与清洁样本不同，因此可以用这些归属结果来检测后门样本。* Results: 对多个流行的数据集和攻击方法进行了广泛的实验，结果表明我们的方法可以准确地检测后门样本，同时也可以提供明确的解释。代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/GuanZihan/GNN_backdoor_detection%E3%80%82">https://github.com/GuanZihan/GNN_backdoor_detection。</a><details>
<summary>Abstract</summary>
Backdoor attacks pose a significant security risk to graph learning models. Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, feed graph samples into the model, and then adopt explanation methods to attribute model prediction to an important subgraph. We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples. Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method. Our code is available: https://github.com/GuanZihan/GNN_backdoor_detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese:Backdoor attacks pose a significant security risk to graph learning models. Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, feed graph samples into the model, and then adopt explanation methods to attribute model prediction to an important subgraph. We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples. Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method. Our code is available: https://github.com/GuanZihan/GNN_backdoor_detection.Translate the text into Simplified Chinese:<<SYS>>针对图学习模型中的后门攻击，我们提出了一种具有扫描性的后门检测方法。在视觉和自然语言领域，利用训练集中混合后门和清洁样本的现象，模型的损失值对后门样本下降速度远比清洁样本快，因此可以通过选择损失值最低的样本来轻松地检测后门样本。然而，对图数据 direct 应用这种方法时，它的检测效果受到图数据的 topological 特征信息的限制。为此，我们提出了一种利用 topological 信息进行解释导向后门检测方法。具体来说，我们在图 dataset 上训练一个协助模型，然后将图样本传递给模型，并采用解释方法来归因模型预测结果到一个重要的子图。我们发现，后门样本的归因分布与清洁样本不同，因此可以通过解释子图来更好地检测后门样本。我们在多个流行的dataset和攻击方法上进行了广泛的实验，并证明了我们的方法的有效性和可解释性。我们的代码可以在 https://github.com/GuanZihan/GNN_backdoor_detection 上找到。
</details></li>
</ul>
<hr>
<h2 id="Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining"><a href="#Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining" class="headerlink" title="Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining"></a>Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04396">http://arxiv.org/abs/2308.04396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Blatt, Patrick Delfmann, Petra Schubert</li>
<li>For: The paper is written for the purpose of discovering process models from event logs of Enterprise Collaboration Systems (ECS), which are typically communication- and document-oriented.* Methods: The paper proposes a tailored event abstraction approach called ECSEA, which trains a model by comparing recorded actual user activities with the system-generated low-level traces, and allows for the automatic conversion of future low-level traces into an abstracted high-level log that can be used for Process Mining.* Results: The paper shows that the ECSEA approach produces accurate results, and is essential for the interpretation of collaborative work activity in ECS, which the authors call Social Process Mining.<details>
<summary>Abstract</summary>
One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM. Our evaluation shows that the algorithm produces accurate results. ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging"><a href="#Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging" class="headerlink" title="Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging"></a>Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04395">http://arxiv.org/abs/2308.04395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Nørgaard Llambias, Mads Nielsen, Mostafa Mehdipour Ghazi</li>
<li>for: 本研究旨在提出一种robust domain adaptation方法，以便在医疗影像领域应用深度学习模型。</li>
<li>methods: 该方法利用MRI特有的扩展技术来实现不supervised domain adaptation，并在多种数据集、模式和分类任务上进行了广泛的实验，与当前最佳方法进行了比较。</li>
<li>results: 研究结果显示，提议的方法在多种任务中具有高精度、广泛应用性和强大的鲁棒性，在大多数情况下超越了当前最佳性能。<details>
<summary>Abstract</summary>
Deep learning-based models in medical imaging often struggle to generalize effectively to new scans due to data heterogeneity arising from differences in hardware, acquisition parameters, population, and artifacts. This limitation presents a significant challenge in adopting machine learning models for clinical practice. We propose an unsupervised method for robust domain adaptation in brain MRI segmentation by leveraging MRI-specific augmentation techniques. To evaluate the effectiveness of our method, we conduct extensive experiments across diverse datasets, modalities, and segmentation tasks, comparing against the state-of-the-art methods. The results show that our proposed approach achieves high accuracy, exhibits broad applicability, and showcases remarkable robustness against domain shift in various tasks, surpassing the state-of-the-art performance in the majority of cases.
</details>
<details>
<summary>摘要</summary>
深度学习模型在医疗成像中经常陷于新扫描数据不具有效地泛化的问题，这是因为扫描设备、获取参数、人口和artefacts等因素引起的数据不一致性。这种限制使得机器学习模型在临床实践中采用困难。我们提议一种不supervised的robust领域适应方法，通过利用MRI特定的扩充技术来解决这个问题。为评估我们的方法的有效性，我们在多个数据集、Modalities和 segmentation任务中进行了广泛的实验，与当前状态艺的方法进行比较。结果表明，我们的提议方法可以 дости得高精度、具有广泛的应用性和在不同任务中强大的鲁棒性，在大多数情况下超越当前状态艺的性能。
</details></li>
</ul>
<hr>
<h2 id="Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries"><a href="#Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries" class="headerlink" title="Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries"></a>Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10875">http://arxiv.org/abs/2308.10875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elviscuihan/csoma">https://github.com/elviscuihan/csoma</a></li>
<li>paper_authors: Elvis Han Cui, Zizhao Zhang, Culsome Junwen Chen, Weng Kee Wong</li>
<li>for: 本研究使用一种新提出的自然引导算法，即竞争群体优化算法with mutated agents (CSO-MA)，以解决各种困难优化问题。</li>
<li>methods: 本研究使用CSO-MA算法，并证明其在不同的统计科学问题中的灵活性和竞争优势。</li>
<li>results: 研究发现，CSO-MA算法能够 efficiently 处理不同类型的优化问题，包括具有不同成本结构或多个用户指定的非线性约束的问题。应用包括生物信息学中的单细胞泛化趋势模型、教育研究中的 Rasch 模型、生命科学中的 Markov 级别模型以及两组织模型中的缺失值补充。此外，还应用到生态学问题中选取最佳变量，以及适用于汽车业的汽车燃油实验设计。<details>
<summary>Abstract</summary>
Nature-inspired metaheuristic algorithms are important components of artificial intelligence, and are increasingly used across disciplines to tackle various types of challenging optimization problems. We apply a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) and demonstrate its flexibility and out-performance relative to its competitors in a variety of optimization problems in the statistical sciences. In particular, we show the algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. Our applications include (i) finding maximum likelihood estimates of parameters in a single cell generalized trend model to study pseudotime in bioinformatics, (ii) estimating parameters in a commonly used Rasch model in education research, (iii) finding M-estimates for a Cox regression in a Markov renewal model and (iv) matrix completion to impute missing values in a two compartment model. In addition we discuss applications to (v) select variables optimally in an ecology problem and (vi) design a car refueling experiment for the auto industry using a logistic model with multiple interacting factors.
</details>
<details>
<summary>摘要</summary>
自然适应的metaheuristic算法在人工智能中具有重要的地位，并在不同领域面临各种复杂的优化问题时广泛应用。我们在一种新提出的自然适应metaheuristic算法 called 竞争群体优化算法（CSO-MA）中，示出其灵活性和与竞争者相比的出色性。我们在各种统计科学中应用了这种算法，包括：（i）在生物信息学中，找到单个维度泛化趋势模型中参数的最大可能性 estimators。（ii）在教育研究中，估算一种常用的Rasch模型中的参数。（iii）在一种Markov征显模型中，找到一种M-估计来描述一种Cox回归。（iv）在一种两个分组模型中，完成缺失值的填充。（v）在生态学中，选择变量以优化一个生态系统。（vi）在自动化工业中，使用一种Logistic模型来设计一个汽车燃油实验。我们还讨论了这种算法在不同领域中的应用，包括生态学和自动化工业。
</details></li>
</ul>
<hr>
<h2 id="AdaptEx-A-Self-Service-Contextual-Bandit-Platform"><a href="#AdaptEx-A-Self-Service-Contextual-Bandit-Platform" class="headerlink" title="AdaptEx: A Self-Service Contextual Bandit Platform"></a>AdaptEx: A Self-Service Contextual Bandit Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08650">http://arxiv.org/abs/2308.08650</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Black, Ercument Ilhan, Andrea Marchini, Vilda Markeviciute</li>
<li>for: 这篇论文是为了描述一种基于多支针算法的自助上下文ual bandit平台，用于在Expedia Group中大规模个性化用户体验。</li>
<li>methods: 这篇论文使用了多支针算法，考虑每个访客的特定上下文，选择最佳变种，并快速学习每次互动。</li>
<li>results: 这篇论文表明，AdaptEx可以快速减少传统测试方法相关的成本和时间，并在不断变化的内容和连续”冷启”情况下灵活应对。<details>
<summary>Abstract</summary>
This paper presents AdaptEx, a self-service contextual bandit platform widely used at Expedia Group, that leverages multi-armed bandit algorithms to personalize user experiences at scale. AdaptEx considers the unique context of each visitor to select the optimal variants and learns quickly from every interaction they make. It offers a powerful solution to improve user experiences while minimizing the costs and time associated with traditional testing methods. The platform unlocks the ability to iterate towards optimal product solutions quickly, even in ever-changing content and continuous "cold start" situations gracefully.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making"><a href="#Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making" class="headerlink" title="Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making"></a>Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04375">http://arxiv.org/abs/2308.04375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Hun Lee, Chong Jun Chew<br>for: 这个论文旨在探讨人工智能（AI）在高度决策领域（如医疗）中如何帮助人类做出决策，以及如何使人类更好地依靠AI。methods: 该论文使用了许多特征解释以及对比解释来使人类更好地分析AI建议，从而减少对AI的过分依赖。results: 研究发现，当AI建议正确时，人类的性能和一致性都有所提高，而对于错误的AI建议，使用对比解释可以减少人类对AI的过分依赖，特别是对于非专业人员而言。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented. While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在高度重要的决策领域（如医疗）中被越来越多地用于帮助人类做出决策。然而，研究人员已经提出了一个问题，即人们可能会过分依赖错误的AI模型建议，而不是寻求人类和AI的合作性能。在这种情况下，我们使用了突出特征解释以及对比解释，以帮助人们更加分析地评估AI建议，并研究这些解释对人们对AI的信任和依赖的影响。我们在评估stroke生存者的质量运动任务上进行了一个实验，并分析了参与者的表现、同意度和对AI的依赖度。我们的结果表明，带有突出特征和对比解释的AI模型可以帮助治疗师和非专业人员提高他们的表现和同意度。而且，对比解释可以帮助治疗师和非专业人员减少对“错误”AI输出的过分依赖，相比突出特征解释下降21%。具体来说，非专业人员在使用突出特征解释时表现下降18.0 f1-score，而使用对比解释时表现下降14.0 f1-score，而治疗师则表现下降8.6和2.8 f1-score。我们的工作表明，对比解释可以更好地估计AI模型的准确性，降低对“错误”AI输出的过分依赖，并带来人类-AI合作决策的改进。
</details></li>
</ul>
<hr>
<h2 id="Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning"><a href="#Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning" class="headerlink" title="Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning"></a>Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04373">http://arxiv.org/abs/2308.04373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Queyrut, Yérom-David Bromberg, Valerio Schiavoni</li>
<li>for: 保护用户数据隐私和模型安全，防止恶意扰乱模型训练</li>
<li>methods: 使用可信硬件（TEEs）实现防御机制，屏蔽部分反propagation链规则，防止攻击者利用此规则设计恶意样本</li>
<li>results: 对state-of-the-art集成模型进行测试，证明PELTA有效防御Self Attention Gradient攻击<details>
<summary>Abstract</summary>
The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device. This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes. However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples. We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack.
</details>
<details>
<summary>摘要</summary>
主要 premise 的 federated learning 是计算机机学模型更新在本地，特别是保护用户数据隐私，因为这些模型从没有离开设备的边界。这种机制假设总模型，一旦综合而成，可以广播到合作和不可靠的节点。然而，没有适当的防御，入侵的客户端可以轻松地探测模型内部的内容。例如，对于图像应用程序，攻击者可以通过在本地模型中添加微量的干扰（可以让人类无法注意）来让模型错分。这些攻击者可以后来将这些攻击样本传递给受害者节点的对等模型，以重新实现攻击。为了解决这种恶意探测问题，我们介绍了 Pelta，一种新的防御机制，利用可信硬件（TEEs）。 Pelta 隐藏了一部分的反射链规则，通常被攻击者利用来设计恶意样本。我们在一个 state-of-the-art 的 ensemble 模型上评估了 Pelta，并证明其效iveness 对Self Attention Gradient 攻击。
</details></li>
</ul>
<hr>
<h2 id="SLEM-Machine-Learning-for-Path-Modeling-and-Causal-Inference-with-Super-Learner-Equation-Modeling"><a href="#SLEM-Machine-Learning-for-Path-Modeling-and-Causal-Inference-with-Super-Learner-Equation-Modeling" class="headerlink" title="SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling"></a>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04365">http://arxiv.org/abs/2308.04365</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matthewvowels1/slem">https://github.com/matthewvowels1/slem</a></li>
<li>paper_authors: Matthew J. Vowels</li>
<li>for: 这篇论文的目的是提出一种新的方法来实现可靠的效应大小估计，该方法基于机器学习Super Learner ensemble的思想。</li>
<li>methods: 该方法使用Path models和Structural Equation Models（SEM）的组合，并通过机器学习Super Learner ensemble来避免函数错误估计。</li>
<li>results: 该方法可以提供可靠的效应大小估计，并且在对比SEM时表现竞争力强，特别是当关系非线性时。<details>
<summary>Abstract</summary>
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non-linear relationships. We provide open-source code, and a tutorial notebook with example usage, accentuating the easy-to-use nature of the method.
</details>
<details>
<summary>摘要</summary>
科学中的重要目标是 causal inference，即通过观察数据来得出干扰假设的有意义结论。路径模型、结构方程模型（SEM）和直接无环图（DAG）等方法可以准确地表达 causal 结构的假设。与 SEM 不同的是，它假设 linearity，这可能导致函数不准确，从而阻碍研究人员从数据中获得可靠的效果大小估计。在这个 контексте，我们提出 Super Learner Equation Modeling，一种将机器学习 Super Learner 集成的路径模型技术。我们经验表明，它可以提供一致和不偏估计的 causal 效果，并且在 linear 模型中与 SEM 相比，其性能更加竞争。此外，它在非线性关系时也表现出了superiority。我们提供了开源代码和教程 Notebook，强调该方法的易用性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.LG_2023_08_09/" data-id="clm0t8e0d006mv788fxjucg62" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/10/cs.LG_2023_08_10/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-08-10 18:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/08/09/cs.SD_2023_08_09/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-08-09 123:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
