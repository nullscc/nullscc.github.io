
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-08-31 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Learning Vision-based Pursuit-Evasion Robot Policies paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.16185 repo_url: None paper_authors: Andrea Bajcsy, Antonio Loquercio, Ashish Kumar, Jitendra Malik for: 这 pape">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-08-31">
<meta property="og:url" content="https://nullscc.github.io/2023/08/31/cs.AI_2023_08_31/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Learning Vision-based Pursuit-Evasion Robot Policies paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.16185 repo_url: None paper_authors: Andrea Bajcsy, Antonio Loquercio, Ashish Kumar, Jitendra Malik for: 这 pape">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-08-31T12:00:00.000Z">
<meta property="article:modified_time" content="2023-08-31T13:36:18.352Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_08_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/31/cs.AI_2023_08_31/" class="article-date">
  <time datetime="2023-08-31T12:00:00.000Z" itemprop="datePublished">2023-08-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-08-31
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Learning-Vision-based-Pursuit-Evasion-Robot-Policies"><a href="#Learning-Vision-based-Pursuit-Evasion-Robot-Policies" class="headerlink" title="Learning Vision-based Pursuit-Evasion Robot Policies"></a>Learning Vision-based Pursuit-Evasion Robot Policies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16185">http://arxiv.org/abs/2308.16185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Bajcsy, Antonio Loquercio, Ashish Kumar, Jitendra Malik</li>
<li>for: 这 paper 是为了学习在实际世界中进行策略性机器人行为的挑战，特别是在追逐逃脱交互中。</li>
<li>methods: 这 paper 使用了将这个难以解决的问题转化为一个监督学习问题，其中一个全 observable 机器人策略生成了一个 partially observable 机器人策略的超vision。</li>
<li>results: 研究发现，在追逐逃脱交互中，部分可见的机器人策略的训练信号质量取决于两个关键因素：逃脱者的行为均衡和模型假设的强度。这 paper 还在实际中部署了这种策略，并在物理四脚机器人上进行了追逐逃脱交互。<details>
<summary>Abstract</summary>
Learning strategic robot behavior -- like that required in pursuit-evasion interactions -- under real-world constraints is extremely challenging. It requires exploiting the dynamics of the interaction, and planning through both physical state and latent intent uncertainty. In this paper, we transform this intractable problem into a supervised learning problem, where a fully-observable robot policy generates supervision for a partially-observable one. We find that the quality of the supervision signal for the partially-observable pursuer policy depends on two key factors: the balance of diversity and optimality of the evader's behavior and the strength of the modeling assumptions in the fully-observable policy. We deploy our policy on a physical quadruped robot with an RGB-D camera on pursuit-evasion interactions in the wild. Despite all the challenges, the sensing constraints bring about creativity: the robot is pushed to gather information when uncertain, predict intent from noisy measurements, and anticipate in order to intercept. Project webpage: https://abajcsy.github.io/vision-based-pursuit/
</details>
<details>
<summary>摘要</summary>
学习策略性机器人行为 -- 如追逐避免交互 -- 在真实世界环境中是非常困难的。它需要利用交互动力学，并通过物理状态和潜在意图不确定性进行规划。在这篇论文中，我们将这个难以解决的问题转化为一个监督学习问题，其中一个完全可见的机器人政策生成了一个部分可见的追逐者政策的监督信号。我们发现了两个关键因素对 partially-observable pursuer policy 的质量监督信号产生影响：逃脱者的行为均衡和优化程度，以及完全可见政策中模型假设的强度。我们将我们的政策部署到一个物理四脚机器人上，并使用RGB-D摄像头进行追逐逃脱交互。尽管所有挑战，感知约束促使机器人在不确定时收集信息，从杂乱测量中预测意图，并在预测不准确时预测以 intercept。项目首页：https://abajcsy.github.io/vision-based-pursuit/
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Uncertainty-in-Answers-from-any-Language-Model-via-Intrinsic-and-Extrinsic-Confidence-Assessment"><a href="#Quantifying-Uncertainty-in-Answers-from-any-Language-Model-via-Intrinsic-and-Extrinsic-Confidence-Assessment" class="headerlink" title="Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment"></a>Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16175">http://arxiv.org/abs/2308.16175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuhai Chen, Jonas Mueller</li>
<li>for: detecting bad and speculative answers from a pretrained Large Language Model</li>
<li>methods: estimating a numeric confidence score for any output generated by the LLM, combining intrinsic and extrinsic assessments of confidence</li>
<li>results: more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures, and can obtain more accurate responses by sampling multiple responses and considering the one with the highest confidence score.Here’s the full translation in Simplified Chinese:</li>
<li>for: 用于探测预训练的大语言模型中的坏和推测答案</li>
<li>methods: 通过估算任何输出生成的数字信任分数，并将内在和外在评估信任相结合</li>
<li>results: 比alternative uncertainty estimation procedures更加准确地认定大语言模型的错误答案，并可以通过采样多个响应并考虑最高信任分的响应来获得更加准确的答案，无需额外训练步骤。<details>
<summary>Abstract</summary>
We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, and combines intrinsic and extrinsic assessments of confidence into a single trustworthiness estimate for any LLM response to a given prompt. Our method is extremely general and can applied to all of the best LLMs available today (whose training data remains unknown). By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that caution when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can additionally obtain more accurate responses from the same LLM, without any extra training steps.
</details>
<details>
<summary>摘要</summary>
我们介绍BSDetector，一种方法用于检测预训练大语言模型生成的差异和推测答案的 numeric 信任分数。我们的不确定性评估技术适用于任何可以通过黑色盒API访问的 LLM，并将内在和外在评估信任综合到一个 Trustworthiness 估计中。我们的方法非常通用，可以应用于今天最好的 LLM 中的任何一个（训练数据未知）。通过点些额外计算，用户可以通过 LLM API 获得同样的回答和信任估计，从而了解不要信任这个回答。在关闭和开放问答benchmark上进行实验，我们发现BSDetector可以更准确地确定 LLM 的错误回答，比alternative uncertainty estimation方法更好。此外，我们可以通过选择 LLM 生成的多个回答中信任分数最高的一个，以获得更准确的回答，无需任何额外训练步骤。
</details></li>
</ul>
<hr>
<h2 id="Algebraic-Topological-and-Mereological-Foundations-of-Existential-Granules"><a href="#Algebraic-Topological-and-Mereological-Foundations-of-Existential-Granules" class="headerlink" title="Algebraic, Topological, and Mereological Foundations of Existential Granules"></a>Algebraic, Topological, and Mereological Foundations of Existential Granules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16157">http://arxiv.org/abs/2308.16157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mani A</li>
<li>for: 本研究提出了新的存在主义 грануル（EG）概念，用于自我determination和环境互动。</li>
<li>methods: 本研究采用了 алгебраические、topological和merological方面的Characterization来描述EG。</li>
<li>results: 研究显示EG可以适应多种理论框架（axioms, adaptive等），并可以应用于分类问题和可能的总结扩展。 Additionally, many open problems are posed and directions provided.<details>
<summary>Abstract</summary>
In this research, new concepts of existential granules that determine themselves are invented, and are characterized from algebraic, topological, and mereological perspectives. Existential granules are those that determine themselves initially, and interact with their environment subsequently. Examples of the concept, such as those of granular balls, though inadequately defined, algorithmically established, and insufficiently theorized in earlier works by others, are already used in applications of rough sets and soft computing. It is shown that they fit into multiple theoretical frameworks (axiomatic, adaptive, and others) of granular computing. The characterization is intended for algorithm development, application to classification problems and possible mathematical foundations of generalizations of the approach. Additionally, many open problems are posed and directions provided.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们发明了新的存在ential granule概念，它们自己决定了自己的性质。这些granule从算术、拓扑和merkolojical的视角来 caracterized。存在ential granule是指 initially自己决定的granule，然后与环境交互。例如，granular balls这种概念，虽然在以前的作品中不充分定义、算法确定和理论化不够，但它们已经在粗集和软计算应用中使用。我们显示它们适合多种理论框架（axioms, adaptive等）的granular computing。characterization是为了开发算法、应用到分类问题以及可能的总体方法的数学基础。此外，我们还提出了许多开放问题和方向。Note: "existential granule" is a term I translated as "存在ential granule" in Simplified Chinese, which is a combination of "existential" and "granule".
</details></li>
</ul>
<hr>
<h2 id="Jais-and-Jais-chat-Arabic-Centric-Foundation-and-Instruction-Tuned-Open-Generative-Large-Language-Models"><a href="#Jais-and-Jais-chat-Arabic-Centric-Foundation-and-Instruction-Tuned-Open-Generative-Large-Language-Models" class="headerlink" title="Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models"></a>Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16149">http://arxiv.org/abs/2308.16149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, Lalit Pradhan, Zain Muhammad Mujahid, Massa Baali, Alham Fikri Aji, Zhengzhong Liu, Andy Hock, Andrew Feldman, Jonathan Lee, Andrew Jackson, Preslav Nakov, Timothy Baldwin, Eric Xing</li>
<li>for: 这个研究是为了开发一个新的阿拉伯语中心的基础模型和一个基于 instrucion 的大语言模型（LLM）。</li>
<li>methods: 这些模型基于 GPT-3 的解码器只架构，并在混合阿拉伯语和英语文本中进行预训练。它们具有13亿个参数，在阿拉伯语知识和理解方面表现出色，与任何现有的开放阿拉伯语和多语言模型相比，具有明显的优势。</li>
<li>results: 这些模型在英语中也能够与英语中心的开放模型相比，即使只使用了 Much less English data。我们提供了模型训练、调整、安全对齐和评估的详细描述。我们发布了两个开放版本的模型：基础 Jais 模型和基于 instrucion 的 Jais-chat 变体，以促进阿拉伯语 LLM 的研究。可以在 <a target="_blank" rel="noopener" href="https://huggingface.co/inception-mbzuai/jais-13b-chat">https://huggingface.co/inception-mbzuai/jais-13b-chat</a> 上下载。<details>
<summary>Abstract</summary>
We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://huggingface.co/inception-mbzuai/jais-13b-chat
</details>
<details>
<summary>摘要</summary>
我们介绍Jais和Jais-chat，这两个新的阿拉伯语中心基础和指导下的开放生成大语言模型（LLM）。这两个模型基于GPT-3核心Only架构，并在混合阿拉伯语和英语文本中进行预训练，包括不同编程语言的源代码。它们拥有13亿个参数，在阿拉伯语中表现出较好的知识和理解能力，比任何现有的开放阿拉伯语和多语言模型都更出色，根据广泛的评估。此外，这些模型在英语中也能够与英语中心的开放模型相比，即使它们在英语数据上进行了训练。我们提供了模型训练、调整、安全对齐和评估的详细描述。我们发布了两个开放版本的模型——基础Jais模型和指导下的Jais-chat变体——以便促进阿拉伯语LLM的研究。可以在https://huggingface.co/inception-mbzuai/jais-13b-chat上下载。
</details></li>
</ul>
<hr>
<h2 id="LM-Infinite-Simple-On-the-Fly-Length-Generalization-for-Large-Language-Models"><a href="#LM-Infinite-Simple-On-the-Fly-Length-Generalization-for-Large-Language-Models" class="headerlink" title="LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"></a>LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16137">http://arxiv.org/abs/2308.16137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chi Han, Qifan Wang, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang</li>
<li>for: 本研究目的是提高Transformer大型自然语言模型（LLM）在不同领域的性能，并在长序列上进行更长的理解和推理。</li>
<li>methods: 本研究使用了Lambda形掩码和距离限制，不需要参数更新或学习，可以在现有的LLM上进行实时长度总结。</li>
<li>results: LM-Infinite可以在ArXiv和OpenWebText2数据集上 Generate fluently和高质量的输出，并且在下游任务中继续工作，而vanilla模型在训练长度以下就会失败。 decoding速度提高2.72倍。<details>
<summary>Abstract</summary>
In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) factors contributing to this problem. Inspired by this diagnosis, we propose a simple yet effective solution for on-the-fly length generalization, LM-Infinite, which involves only a $\Lambda$-shaped attention mask and a distance limit while requiring no parameter updates or learning. We find it applicable to a variety of LLMs using relative-position encoding methods. LM-Infinite is computational efficient with $O(n)$ time and space, and demonstrates consistent fluency and generation quality to as long as 32k tokens on ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream task such as passkey retrieval, it continues to work on inputs much longer than training lengths where vanilla models fail immediately.
</details>
<details>
<summary>摘要</summary>
Recently, there have been significant advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for more complex tasks, they often need to conduct longer reasoning processes or understand larger contexts. However, when dealing with long sequences, LLMs often experience length generalization failure. Most pre-training schemes only train on sequences of a fixed length (such as 2048 for LLaMa), which can cause LLMs to struggle to generate fluent texts or perform downstream tasks when faced with longer contexts. Common solutions such as fine-tuning on longer corpora can be time-consuming and require careful process design. To more efficiently leverage the generation capacity of existing LLMs, we investigate the main out-of-distribution (OOD) factors contributing to this problem. Inspired by this diagnosis, we propose a simple yet effective solution called LM-Infinite, which involves a $\Lambda$-shaped attention mask and a distance limit, and requires no parameter updates or learning. We find it applicable to a variety of LLMs using relative-position encoding methods. LM-Infinite is computationally efficient with $O(n)$ time and space, and demonstrates consistent fluency and generation quality up to 32k tokens on ArXiv and OpenWebText2 datasets, with a decoding speedup of 2.72x. On downstream tasks such as passkey retrieval, it continues to work on inputs much longer than training lengths, where vanilla models fail immediately.
</details></li>
</ul>
<hr>
<h2 id="CorrEmbed-Evaluating-Pre-trained-Model-Image-Similarity-Efficacy-with-a-Novel-Metric"><a href="#CorrEmbed-Evaluating-Pre-trained-Model-Image-Similarity-Efficacy-with-a-Novel-Metric" class="headerlink" title="CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric"></a>CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16126">http://arxiv.org/abs/2308.16126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karl Audun Kagnes Borgersen, Morten Goodwin, Jivitesh Sharma, Tobias Aasmoe, Mari Leonhardsen, Gro Herredsvela Rørvik</li>
<li>for: 这篇论文是为了评估预训练的计算机视觉模型中的图像嵌入而写的。</li>
<li>methods: 这篇论文使用了一种新的方法 named CorrEmbed，该方法计算图像嵌入中距离与人工生成的标签向量距离之间的相关性。</li>
<li>results: 该方法可以评估预训练的计算机视觉模型中的图像嵌入，并发现一些模型的性能与标签相关性之间存在直线关系。此外，该方法还可以找出具有不同特征的模型。<details>
<summary>Abstract</summary>
Detecting visually similar images is a particularly useful attribute to look to when calculating product recommendations. Embedding similarity, which utilizes pre-trained computer vision models to extract high-level image features, has demonstrated remarkable efficacy in identifying images with similar compositions. However, there is a lack of methods for evaluating the embeddings generated by these models, as conventional loss and performance metrics do not adequately capture their performance in image similarity search tasks.   In this paper, we evaluate the viability of the image embeddings from numerous pre-trained computer vision models using a novel approach named CorrEmbed. Our approach computes the correlation between distances in image embeddings and distances in human-generated tag vectors. We extensively evaluate numerous pre-trained Torchvision models using this metric, revealing an intuitive relationship of linear scaling between ImageNet1k accuracy scores and tag-correlation scores. Importantly, our method also identifies deviations from this pattern, providing insights into how different models capture high-level image features.   By offering a robust performance evaluation of these pre-trained models, CorrEmbed serves as a valuable tool for researchers and practitioners seeking to develop effective, data-driven approaches to similar item recommendations in fashion retail.
</details>
<details>
<summary>摘要</summary>
检测类似图像是一项非常有用的特征，特别是在计算产品推荐时。嵌入相似性，使用预训练的计算机视觉模型提取高级图像特征，已经证明了惊人的效果。然而，没有方法来评估由这些模型生成的嵌入，因为常见的损失和性能指标不能够准确地捕捉图像相似搜索任务中的表现。在这篇论文中，我们评估了许多预训练的Torchvision模型的嵌入，使用一种新的方法 named CorrEmbed。我们的方法计算图像嵌入中距离与人工生成的标签 vector 距离之间的相关性。我们广泛评估了多种预训练的Torchvision模型，发现图像1000分类准确率和标签相关性分数之间存在直线关系。更重要的是，我们的方法还发现了不同模型捕捉高级图像特征的偏差，提供了对发展有效数据驱动方法的深入理解。  By offering a robust performance evaluation of these pre-trained models, CorrEmbed serves as a valuable tool for researchers and practitioners seeking to develop effective, data-driven approaches to similar item recommendations in fashion retail.
</details></li>
</ul>
<hr>
<h2 id="Response-Emergent-analogical-reasoning-in-large-language-models"><a href="#Response-Emergent-analogical-reasoning-in-large-language-models" class="headerlink" title="Response: Emergent analogical reasoning in large language models"></a>Response: Emergent analogical reasoning in large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16118">http://arxiv.org/abs/2308.16118</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hodeld/emergent_analogies_llm_fork">https://github.com/hodeld/emergent_analogies_llm_fork</a></li>
<li>paper_authors: Damian Hodel, Jevin West</li>
<li>for: 研究表明大语言模型如GPT-3已经获得了泛化逻辑能力，能够解决各种类比问题。</li>
<li>methods: 作者使用了GPT-3进行实验，测试其在不同类比问题中的能力。</li>
<li>results: 试验结果表明，GPT-3无法解决简单的类比问题， zero-shot 逻辑是一个过度的laim需要更多的证据。<details>
<summary>Abstract</summary>
In their recent Nature Human Behaviour paper, "Emergent analogical reasoning in large language models," (Webb, Holyoak, and Lu, 2023) the authors argue that "large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems." In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.
</details>
<details>
<summary>摘要</summary>
根据《自然人类行为》杂志（Webb、Holyoak、Lu，2023）的论文，作者认为大语言模型如GPT-3已经获得了zero-shot解决广泛的比喻问题的能力。在这个回应中，我们提供了字符串比喻的counterexample。在我们的测试中，GPT-3无法解决even the easiest variants of the problems presented in the original paper。zero-shot reasoning是一个非凡的声明，需要非凡的证据。我们在实验中没看到这种证据。为了强化人类类似的理解，如zero-shot reasoning，领域应该开发approaches来排除数据记忆。
</details></li>
</ul>
<hr>
<h2 id="survex-an-R-package-for-explaining-machine-learning-survival-models"><a href="#survex-an-R-package-for-explaining-machine-learning-survival-models" class="headerlink" title="survex: an R package for explaining machine learning survival models"></a>survex: an R package for explaining machine learning survival models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16113">http://arxiv.org/abs/2308.16113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikołaj Spytek, Mateusz Krzyziński, Sophie Hanna Langbein, Hubert Baniecki, Marvin N. Wright, Przemysław Biecek</li>
<li>for: The paper is written for those who use survival models in biomedical research and healthcare applications, and aims to provide a user-friendly tool to explain the internal operations and prediction rationales of these models.</li>
<li>methods: The paper proposes the survex R package, which applies explainable artificial intelligence techniques to survival models, allowing users to understand and diagnose the models, improve their reliability, and detect biases.</li>
<li>results: The proposed software can provide insights into the decision-making process of survival models, such as variable effects and importances, and can promote transparency and responsibility in sensitive areas like biomedical research and healthcare applications.<details>
<summary>Abstract</summary>
Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Grandma-Karl-is-27-years-old-–-research-agenda-for-pseudonymization-of-research-data"><a href="#Grandma-Karl-is-27-years-old-–-research-agenda-for-pseudonymization-of-research-data" class="headerlink" title="Grandma Karl is 27 years old – research agenda for pseudonymization of research data"></a>Grandma Karl is 27 years old – research agenda for pseudonymization of research data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16109">http://arxiv.org/abs/2308.16109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elena Volodina, Simon Dobnik, Therese Lindström Tiedemann, Xuan-Son Vu</li>
<li>for: 本研究旨在探讨 pseudonymization 的应用在不结构化数据中，以保护作者身份和隐私信息。</li>
<li>methods: 本研究提出了一个研究议程，包括对 pseudonymization 对不结构化数据的影响（如可读性和语言评估），以及 pseudonymization 的效果是否能够保护作者身份。</li>
<li>results: 研究计划通过开发 Context-sensitive 算法来检测、标记和替换个人信息，以保护作者身份和隐私信息。这个研究项目在 pseudonymization 方面提供了27年的探索和发展空间。<details>
<summary>Abstract</summary>
Accessibility of research data is critical for advances in many research fields, but textual data often cannot be shared due to the personal and sensitive information which it contains, e.g names or political opinions. General Data Protection Regulation (GDPR) suggests pseudonymization as a solution to secure open access to research data, but we need to learn more about pseudonymization as an approach before adopting it for manipulation of research data. This paper outlines a research agenda within pseudonymization, namely need of studies into the effects of pseudonymization on unstructured data in relation to e.g. readability and language assessment, as well as the effectiveness of pseudonymization as a way of protecting writer identity, while also exploring different ways of developing context-sensitive algorithms for detection, labelling and replacement of personal information in unstructured data. The recently granted project on pseudonymization Grandma Karl is 27 years old addresses exactly those challenges.
</details>
<details>
<summary>摘要</summary>
研究数据的可 accessible性是多个研究领域的进步的关键，但文本数据经常无法被共享，因为它们包含个人敏感信息，如名字或政治意见。欧盟通信标准（GDPR）建议使用 pseudonymization 作为保护开放研究数据的解决方案，但我们需要更多关于 pseudonymization 的研究，以便在处理研究数据时采取有效的保护措施。这篇论文提出了一个关于 pseudonymization 的研究计划，即对不结构化数据中的个人信息进行探测、标记和替换的Context-sensitive算法的开发，以及pseudonymization 对写者身份的保护效果和可读性的影响。这些挑战 precisley 由Recently granted project on pseudonymization Grandma Karl is 27 years old 所解决。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/31/cs.AI_2023_08_31/" data-id="clmjn91jd001b0j885svs9965" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/08/31/cs.CV_2023_08_31/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-08-31
        
      </div>
    </a>
  
  
    <a href="/2023/08/31/cs.LG_2023_08_31/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-08-31</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">69</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">32</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">112</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
