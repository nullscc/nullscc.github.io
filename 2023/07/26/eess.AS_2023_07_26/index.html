
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.AS - 2023-07-26 22:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sound Field Estimation around a Rigid Sphere with Physics-informed Neural Network paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.14013 repo_url: None paper_authors: Xingyu Chen, Fei Ma, Amy Bastine, Prasanga Sa">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.AS - 2023-07-26 22:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/07/26/eess.AS_2023_07_26/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Sound Field Estimation around a Rigid Sphere with Physics-informed Neural Network paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.14013 repo_url: None paper_authors: Xingyu Chen, Fei Ma, Amy Bastine, Prasanga Sa">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-07-25T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:20.993Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.AS_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/eess.AS_2023_07_26/" class="article-date">
  <time datetime="2023-07-25T16:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.AS - 2023-07-26 22:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Sound-Field-Estimation-around-a-Rigid-Sphere-with-Physics-informed-Neural-Network"><a href="#Sound-Field-Estimation-around-a-Rigid-Sphere-with-Physics-informed-Neural-Network" class="headerlink" title="Sound Field Estimation around a Rigid Sphere with Physics-informed Neural Network"></a>Sound Field Estimation around a Rigid Sphere with Physics-informed Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14013">http://arxiv.org/abs/2307.14013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyu Chen, Fei Ma, Amy Bastine, Prasanga Samarasinghe, Huiyuan Sun</li>
<li>for: used to estimate the sound field around a rigid sphere with limited measurements</li>
<li>methods: uses a physics-informed neural network that incorporates physical knowledge and constraints from the Helmholtz equation and zero radial velocity condition</li>
<li>results: outperforms the spherical harmonic method and plane-wave decomposition method in terms of accuracy and fitting ability<details>
<summary>Abstract</summary>
Accurate estimation of the sound field around a rigid sphere necessitates adequate sampling on the sphere, which may not always be possible. To overcome this challenge, this paper proposes a method for sound field estimation based on a physics-informed neural network. This approach integrates physical knowledge into the architecture and training process of the network. In contrast to other learning-based methods, the proposed method incorporates additional constraints derived from the Helmholtz equation and the zero radial velocity condition on the rigid sphere. Consequently, it can generate physically feasible estimations without requiring a large dataset. In contrast to the spherical harmonic-based method, the proposed approach has better fitting abilities and circumvents the ill condition caused by truncation. Simulation results demonstrate the effectiveness of the proposed method in achieving accurate sound field estimations from limited measurements, outperforming the spherical harmonic method and plane-wave decomposition method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>精度地估算固定球体周围的声场需要足够的采样在球体上，但这并不总是可能的。为了解决这个挑战，这篇论文提出了基于物理学习网络的声场估算方法。这种方法将物理知识integrated到网络体系和训练过程中。与其他学习基本方法不同，提出的方法在球体上添加了基于哈姆霍尔兹方程和零辐射速度条件的额外约束。因此，它可以生成物理可能的估算而无需大量数据。与圆柱声波分解方法不同，提出的方法具有更好的适应能力，并circumvent了由截断引起的糟糕条件。实验结果表明，提出的方法可以从有限测量数据中获得高精度的声场估算，超越圆柱声波分解方法和平面波分解方法。</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Speech-representation-learning-Learning-bidirectional-encoders-with-single-view-multi-view-and-multi-task-methods"><a href="#Speech-representation-learning-Learning-bidirectional-encoders-with-single-view-multi-view-and-multi-task-methods" class="headerlink" title="Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods"></a>Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00129">http://arxiv.org/abs/2308.00129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingming Tang</li>
<li>For: 本论文主要目标是为时空序列数据学习 repre sentation learning，以提高下游序列预测任务的性能。* Methods: 本论文使用了多种学习 Setting，包括supervised learning with auxiliary losses、Unsupervised learning、semi-supervised learning和多视图学习。同时，本论文还 explore multiple approaches for representation learning，包括 speech data。* Results: 本论文的研究发现，不同的学习 Setting和approaches可以获得不同的 repre sentation learning results。此外，本论文还发现一些findings可以在不同的Domain上应用。<details>
<summary>Abstract</summary>
This thesis focuses on representation learning for sequence data over time or space, aiming to improve downstream sequence prediction tasks by using the learned representations. Supervised learning has been the most dominant approach for training deep neural networks for learning good sequential representations. However, one limiting factor to scale supervised learning is the lack of enough annotated data. Motivated by this challenge, it is natural to explore representation learning methods that can utilize large amounts of unlabeled and weakly labeled data, as well as an additional data modality. I describe my broad study of representation learning for speech data. Unlike most other works that focus on a single learning setting, this thesis studies multiple settings: supervised learning with auxiliary losses, unsupervised learning, semi-supervised learning, and multi-view learning. Besides different learning problems, I also explore multiple approaches for representation learning. Though I focus on speech data, the methods described in this thesis can also be applied to other domains. Overall, the field of representation learning is developing rapidly. State-of-the-art results on speech related tasks are typically based on Transformers pre-trained with large-scale self-supervised learning, which aims to learn generic representations that can benefit multiple downstream tasks. Since 2020, large-scale pre-training has been the de facto choice to achieve good performance. This delayed thesis does not attempt to summarize and compare with the latest results on speech representation learning; instead, it presents a unique study on speech representation learning before the Transformer era, that covers multiple learning settings. Some of the findings in this thesis can still be useful today.
</details>
<details>
<summary>摘要</summary>
这个论文关注在时间或空间序列数据上进行表示学习，以提高下游序列预测任务的性能。supervised learning是训练深度神经网络以获得好的Sequential Representations的主要方法。然而，缺乏充足的标注数据是超vised learning的一个限制因素。为了解决这个挑战，我们可以探索使用大量未标注和弱标注数据，以及额外的数据模式来学习表示。我的研究涵盖了Speech数据的表示学习。与大多数其他工作一样，我们不仅关注单个学习环境，还研究了多种学习问题，包括supervised learning with auxiliary losses、unsupervised learning、semi-supervised learning和多视图学习。此外，我们还探索了不同的表示学习方法。尽管我们主要关注Speech数据，但所描述的方法也可以应用于其他领域。总的来说，表示学习领域在发展 rapidly，state-of-the-art results on speech related tasks通常基于Transformers预训练大规模自适应学习，旨在学习通用的表示，以便多个下游任务。自2020年以来，大规模预训练成为了下游任务的de facto选择。这个论文不尝试总结和与最新的Result on speech representation learning进行比较，而是提供了在Transformer时代之前的唯一研究Speech representation learning，涵盖了多种学习环境。一些本论文中的发现仍然有用。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/eess.AS_2023_07_26/" data-id="cllurrpbo00arsw88bql2gdl3" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/07/26/cs.SD_2023_07_26/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.SD - 2023-07-26 123:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/07/26/eess.IV_2023_07_26/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.IV - 2023-07-26 17:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">92</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
