
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-07-22 17:00:00 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Direct atomic number reconstruction of dual energy cargo radiographs using a semiempirical transparency model paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.12099 repo_url: None paper_authors: Peter Lalor, Areg">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-07-22 17:00:00">
<meta property="og:url" content="https://nullscc.github.io/2023/07/22/eess.IV_2023_07_22/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Direct atomic number reconstruction of dual energy cargo radiographs using a semiempirical transparency model paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.12099 repo_url: None paper_authors: Peter Lalor, Areg">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-07-21T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-27T10:02:19.197Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_07_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/22/eess.IV_2023_07_22/" class="article-date">
  <time datetime="2023-07-21T16:00:00.000Z" itemprop="datePublished">2023-07-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-07-22 17:00:00
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Direct-atomic-number-reconstruction-of-dual-energy-cargo-radiographs-using-a-semiempirical-transparency-model"><a href="#Direct-atomic-number-reconstruction-of-dual-energy-cargo-radiographs-using-a-semiempirical-transparency-model" class="headerlink" title="Direct atomic number reconstruction of dual energy cargo radiographs using a semiempirical transparency model"></a>Direct atomic number reconstruction of dual energy cargo radiographs using a semiempirical transparency model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12099">http://arxiv.org/abs/2307.12099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Lalor, Areg Danagoulian</li>
<li>for: 这个论文旨在提高货物检测系统的检测能力，特别是在检测涉猛物时。</li>
<li>methods: 该论文使用了一种高精度的原子数预测方法，该方法基于测量图像透射率值的 chi-squared 误差来减少误差。</li>
<li>results: 该论文通过使用这种方法，可以在噪声图像上获得准确的材料预测结果，并且可以适应屏障物的检测。<details>
<summary>Abstract</summary>
Dual energy cargo inspection systems are sensitive to both the area density and the atomic number of an imaged container due to the Z dependence of photon attenuation. The ability to identify cargo contents by their atomic number enables improved detection capabilities of illicit materials. Existing methods typically classify materials into a few material classes using an empirical calibration step. However, such a coarse label discretization limits atomic number selectivity and can yield inaccurate results if a material is near the midpoint of two bins. This work introduces a high resolution atomic number prediction method by minimizing the chi-squared error between measured transparency values and a semiempirical transparency model. Our previous work showed that by incorporating calibration step, the semiempirical transparency model can capture second order effects such as scattering. This method is benchmarked using two simulated radiographic phantoms, demonstrating the ability to obtain accurate material predictions on noisy input images by incorporating an image segmentation step. Furthermore, we show that this approach can be adapted to identify shielded objects after first determining the properties of the shielding, taking advantage of the closed-form nature of the transparency model.
</details>
<details>
<summary>摘要</summary>
双能量货物检测系统具有区域密度和原子数的敏感性，由于光子吸收的Z依赖性。能够根据物质的原子数进行识别，可以提高损害物检测的精度。现有方法通常通过一个Empirical calibration步骤来分类材料，但这会限制原子数选择性并可能导致不准确的结果，如果材料在两个分类中的中点。这项工作介绍了一种高分辨率原子数预测方法，通过最小化χ²错误值 между测量的透射值和一种半employmaterial模型来实现。我们之前的工作表明，通过包含Calibration步骤，半employmaterial模型可以捕捉二次效应，如散射。这种方法在使用两个模拟的放射学phantom中进行了 benchmarkevaluation，表明可以在噪声输入图像上获得准确的材料预测结果，通过包含图像分割步骤。此外，我们还示出了这种方法可以适应标定障碍物，首先确定障碍物的属性，利用透射模型的关闭形式性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Effectiveness-of-Spectral-Discriminators-for-Perceptual-Quality-Improvement"><a href="#On-the-Effectiveness-of-Spectral-Discriminators-for-Perceptual-Quality-Improvement" class="headerlink" title="On the Effectiveness of Spectral Discriminators for Perceptual Quality Improvement"></a>On the Effectiveness of Spectral Discriminators for Perceptual Quality Improvement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12027">http://arxiv.org/abs/2307.12027</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luciennnnnnn/dualformer">https://github.com/luciennnnnnn/dualformer</a></li>
<li>paper_authors: Xin Luo, Yunan Zhu, Shunxin Xu, Dong Liu</li>
<li>for: 这个研究旨在探讨spectral discriminator在图像生成模型中的应用，以提高SR图像质量。</li>
<li>methods: 该研究使用了spectral discriminator和ordinary discriminator，并对比了它们的效果。同时， authors提出了一种使用Transformer对spectral discriminator进行聚合的方法，以提高spectral discriminator的性能。</li>
<li>results: 研究发现，spectral discriminator在高频范围内表现更好，而ordinary discriminator在低频范围内表现更好。因此，authors建议同时使用spectral discriminator和ordinary discriminator。此外， authors verify了该方法的效果，通过PD质量评价和无参图像质量评价任务。<details>
<summary>Abstract</summary>
Several recent studies advocate the use of spectral discriminators, which evaluate the Fourier spectra of images for generative modeling. However, the effectiveness of the spectral discriminators is not well interpreted yet. We tackle this issue by examining the spectral discriminators in the context of perceptual image super-resolution (i.e., GAN-based SR), as SR image quality is susceptible to spectral changes. Our analyses reveal that the spectral discriminator indeed performs better than the ordinary (a.k.a. spatial) discriminator in identifying the differences in the high-frequency range; however, the spatial discriminator holds an advantage in the low-frequency range. Thus, we suggest that the spectral and spatial discriminators shall be used simultaneously. Moreover, we improve the spectral discriminators by first calculating the patch-wise Fourier spectrum and then aggregating the spectra by Transformer. We verify the effectiveness of the proposed method twofold. On the one hand, thanks to the additional spectral discriminator, our obtained SR images have their spectra better aligned to those of the real images, which leads to a better PD tradeoff. On the other hand, our ensembled discriminator predicts the perceptual quality more accurately, as evidenced in the no-reference image quality assessment task.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:Recent studies have proposed using spectral discriminators, which evaluate the Fourier spectra of images for generative modeling. However, the effectiveness of the spectral discriminators is not well understood. We investigate the spectral discriminators in the context of perceptual image super-resolution (i.e., GAN-based SR), as SR image quality is sensitive to spectral changes. Our analysis shows that the spectral discriminator performs better than the ordinary (a.k.a. spatial) discriminator in identifying differences in the high-frequency range, but the spatial discriminator has an advantage in the low-frequency range. Therefore, we suggest using both the spectral and spatial discriminators simultaneously. Moreover, we improve the spectral discriminators by first calculating the patch-wise Fourier spectrum and then aggregating the spectra using Transformer. We verify the effectiveness of the proposed method through twofold experiments. On the one hand, the additional spectral discriminator helps align the spectra of the obtained SR images with those of the real images, leading to a better PD tradeoff. On the other hand, our ensembled discriminator predicts perceptual quality more accurately, as shown in the no-reference image quality assessment task.
</details></li>
</ul>
<hr>
<h2 id="A-Cascade-Transformer-based-Model-for-3D-Dose-Distribution-Prediction-in-Head-and-Neck-Cancer-Radiotherapy"><a href="#A-Cascade-Transformer-based-Model-for-3D-Dose-Distribution-Prediction-in-Head-and-Neck-Cancer-Radiotherapy" class="headerlink" title="A Cascade Transformer-based Model for 3D Dose Distribution Prediction in Head and Neck Cancer Radiotherapy"></a>A Cascade Transformer-based Model for 3D Dose Distribution Prediction in Head and Neck Cancer Radiotherapy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12005">http://arxiv.org/abs/2307.12005</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ghtara/dose_prediction">https://github.com/ghtara/dose_prediction</a></li>
<li>paper_authors: Tara Gheshlaghi, Shahabedin Nabavi, Samire Shirzadikia, Mohsen Ebrahimi Moghaddam, Nima Rostampour</li>
<li>For: This paper aims to improve the accuracy and efficiency of radiation therapy planning for cancer treatment by using deep learning methods to predict dose distribution maps and segment organs at risk.* Methods: The proposed model consists of two cascade encoder-decoder networks: one for organs at risk segmentation and the other for dose distribution prediction. The segmentation network uses transformer blocks and multi-scale convolutional blocks, while the dose distribution prediction network employs a pyramid architecture.* Results: The proposed model outperformed state-of-the-art methods in terms of dose and DVH scores, especially in regions with low prescribed doses. The predicted dose maps showed good coincidence with ground truth, and the segmentation subnet achieved high Dice and HD95 scores.<details>
<summary>Abstract</summary>
Radiation therapy is the primary method used to treat cancer in the clinic. Its goal is to deliver a precise dose to the planning target volume (PTV) while protecting the surrounding organs at risk (OARs). However, the traditional workflow used by dosimetrists to plan the treatment is time-consuming and subjective, requiring iterative adjustments based on their experience. Deep learning methods can be used to predict dose distribution maps to address these limitations. The study proposes a cascade model for organs at risk segmentation and dose distribution prediction. An encoder-decoder network has been developed for the segmentation task, in which the encoder consists of transformer blocks, and the decoder uses multi-scale convolutional blocks. Another cascade encoder-decoder network has been proposed for dose distribution prediction using a pyramid architecture. The proposed model has been evaluated using an in-house head and neck cancer dataset of 96 patients and OpenKBP, a public head and neck cancer dataset of 340 patients. The segmentation subnet achieved 0.79 and 2.71 for Dice and HD95 scores, respectively. This subnet outperformed the existing baselines. The dose distribution prediction subnet outperformed the winner of the OpenKBP2020 competition with 2.77 and 1.79 for dose and DVH scores, respectively. The predicted dose maps showed good coincidence with ground truth, with a superiority after linking with the auxiliary segmentation task. The proposed model outperformed state-of-the-art methods, especially in regions with low prescribed doses.
</details>
<details>
<summary>摘要</summary>
医学中常用的放射疗法是用于治疗癌症的主要方法。其目标是尽可能准确地向规划目标体积（PTV）中注入精准的剂量，同时保护周围的有害组织（OARs）。然而，传统的规划工作流程由数 metrician 进行，是时间consuming 和主观的，需要不断的调整基于他们的经验。深度学习方法可以用来预测剂量分布图，以解决这些限制。本研究提出了顺序模型，用于组织致癌症和剂量分布预测。一个编码器-解码器网络已经为 segmentation 任务开发，其中编码器由 transformer 块组成，解码器使用多尺度 convolutional 块。另一个顺序编码器-解码器网络已经为剂量分布预测使用 pyramid 架构。提案的模型已经在自有的头颈癌 dataset 上进行了评估，包括 96 例的患者数据和 OpenKBP 公共头颈癌 dataset 上的 340 例患者数据。 segmentation 子网络在 Dice 和 HD95 分数上达到 0.79 和 2.71，分别高于现有的基线。剂量分布预测子网络在 OpenKBP2020 比赛中的赢家上达到 2.77 和 1.79，分别高于现有的基线。预测的剂量图与实际值有good coincidence，链接 auxiliary segmentation 任务后显示了superiority。提案的模型超越了当前的状态艺术方法，特别是在低剂量区域。
</details></li>
</ul>
<hr>
<h2 id="ELiOT-End-to-end-Lidar-Odometry-using-Transformer-Framework"><a href="#ELiOT-End-to-end-Lidar-Odometry-using-Transformer-Framework" class="headerlink" title="ELiOT : End-to-end Lidar Odometry using Transformer Framework"></a>ELiOT : End-to-end Lidar Odometry using Transformer Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11998">http://arxiv.org/abs/2307.11998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daegyu Lee, Hyunwoo Nam, D. Hyunchul Shim</li>
<li>for: 本 paper 是为了提出一种基于 transformer 架构的 LiDAR 附近推测方法，用于实现精准的 LiDAR Scene 跟踪。</li>
<li>methods: 该方法使用了 Self-attention flow embedding network，通过强调 LiDAR Scene 的自动关注，避免了传统的 3D-2D 投影方法。网络架构包括 3D transformer encoder-decoder，可以准确地预测 LiDAR Scene 的 pose。</li>
<li>results: 在 urbans 数据集上，该方法得到了鼓舞人的结果，平均翻译错误率为 7.59%，旋转错误率为 2.67%。这表明该方法可以准确地跟踪 LiDAR Scene，无需使用传统的 geometric 概念。<details>
<summary>Abstract</summary>
In recent years, deep-learning-based point cloud registration methods have shown significant promise. Furthermore, learning-based 3D detectors have demonstrated their effectiveness in encoding semantic information from LiDAR data. In this paper, we introduce ELiOT, an end-to-end LiDAR odometry framework built on a transformer architecture. Our proposed Self-attention flow embedding network implicitly represents the motion of sequential LiDAR scenes, bypassing the need for 3D-2D projections traditionally used in such tasks. The network pipeline, composed of a 3D transformer encoder-decoder, has shown effectiveness in predicting poses on urban datasets. In terms of translational and rotational errors, our proposed method yields encouraging results, with 7.59% and 2.67% respectively on the KITTI odometry dataset. This is achieved with an end-to-end approach that foregoes the need for conventional geometric concepts.
</details>
<details>
<summary>摘要</summary>
近年来，深度学习基于点云注册方法已经表现出了明显的承诺。此外，学习基于3D探测器已经证明可以从激光数据中提取 semantic 信息。在这篇文章中，我们介绍了 ELiOT，一种基于 transformer 架构的端到端 LiDAR 速度框架。我们提议的 Self-attention flow embedding 网络可以避免传统的 3D-2D 投影，并将Sequential LiDAR 场景中的运动嵌入到网络中。这个网络结构由3D transformer 编码器-解码器组成，在城市数据集上显示了Predict pose 的效果。在翻译和旋转错误方面，我们的提议方法实现了鼓舞人的结果，即7.59%和2.67% 分别在 KITTI 速度数据集上。这是一种端到端的方法，不需要传统的几何学概念。
</details></li>
</ul>
<hr>
<h2 id="Topology-Preserving-Automatic-Labeling-of-Coronary-Arteries-via-Anatomy-aware-Connection-Classifier"><a href="#Topology-Preserving-Automatic-Labeling-of-Coronary-Arteries-via-Anatomy-aware-Connection-Classifier" class="headerlink" title="Topology-Preserving Automatic Labeling of Coronary Arteries via Anatomy-aware Connection Classifier"></a>Topology-Preserving Automatic Labeling of Coronary Arteries via Anatomy-aware Connection Classifier</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11959">http://arxiv.org/abs/2307.11959</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zutsusemi/miccai2023-topolab-labels">https://github.com/zutsusemi/miccai2023-topolab-labels</a></li>
<li>paper_authors: Zhixing Zhang, Ziwei Zhao, Dong Wang, Shishuang Zhao, Yuhang Liu, Jia Liu, Liwei Wang</li>
<li>for: 本研究旨在提高自动脉络标注的精度，以便更好地诊断心血管疾病。</li>
<li>methods: 该研究提出了一种新的TopoLab框架，其利用了脉络的解剖连接来帮助准确地标注脉络段。具体来说，研究者提出了一种层次特征汇集策略和多个脉络连接类别标注方法。</li>
<li>results: 实验结果表明，TopoLab在orCaScore数据集和一个内部数据集上都达到了领先性的表现。<details>
<summary>Abstract</summary>
Automatic labeling of coronary arteries is an essential task in the practical diagnosis process of cardiovascular diseases. For experienced radiologists, the anatomically predetermined connections are important for labeling the artery segments accurately, while this prior knowledge is barely explored in previous studies. In this paper, we present a new framework called TopoLab which incorporates the anatomical connections into the network design explicitly. Specifically, the strategies of intra-segment feature aggregation and inter-segment feature interaction are introduced for hierarchical segment feature extraction. Moreover, we propose the anatomy-aware connection classifier to enable classification for each connected segment pair, which effectively exploits the prior topology among the arteries with different categories. To validate the effectiveness of our method, we contribute high-quality annotations of artery labeling to the public orCaScore dataset. The experimental results on both the orCaScore dataset and an in-house dataset show that our TopoLab has achieved state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
自动标注 coronary artery 是cardiovascular disease 诊断过程中的一项重要任务。经验丰富的 radiologist 知道， precisely determining the anatomical connections 是标注 artery segment 的关键，而这一点在前一 studies 中几乎没有被探讨。在这篇论文中，我们提出了一种新的框架called TopoLab，它Explicitly incorporates the anatomical connections into the network design. Specifically, we introduce the strategies of intra-segment feature aggregation and inter-segment feature interaction for hierarchical segment feature extraction. 更over, we propose the anatomy-aware connection classifier to enable classification for each connected segment pair, which effectively exploits the prior topology among the arteries with different categories. To validate the effectiveness of our method, we contribute high-quality annotations of artery labeling to the public orCaScore dataset. The experimental results on both the orCaScore dataset and an in-house dataset show that our TopoLab has achieved state-of-the-art performance.
</details></li>
</ul>
<hr>
<h2 id="PartDiff-Image-Super-resolution-with-Partial-Diffusion-Models"><a href="#PartDiff-Image-Super-resolution-with-Partial-Diffusion-Models" class="headerlink" title="PartDiff: Image Super-resolution with Partial Diffusion Models"></a>PartDiff: Image Super-resolution with Partial Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11926">http://arxiv.org/abs/2307.11926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Zhao, Alex Ling Yu Hung, Kaifeng Pang, Haoxin Zheng, Kyunghyun Sung</li>
<li>for: 本研究旨在提高 diffusion-based generative models 的计算效率，以便在各种图像生成任务中使用。</li>
<li>methods: 作者提出了 Partial Diffusion Model (PartDiff)，它在 diffusion 过程中直接往 intermediate latent state diffuse，而不是往 pure random noise Diffusion。在生成过程中，PartDiff 只执行部分的 denoising 步骤。此外，作者还引入了 “latent alignment”，以协调 low-resolution 和高resolution 图像的 latent 空间。</li>
<li>results: 对于 MRI 和自然图像，PartDiff 比 plain diffusion-based super-resolution methods 减少了 denoising 步骤数量，同时不 sacrificing 生成质量。<details>
<summary>Abstract</summary>
Denoising diffusion probabilistic models (DDPMs) have achieved impressive performance on various image generation tasks, including image super-resolution. By learning to reverse the process of gradually diffusing the data distribution into Gaussian noise, DDPMs generate new data by iteratively denoising from random noise. Despite their impressive performance, diffusion-based generative models suffer from high computational costs due to the large number of denoising steps.In this paper, we first observed that the intermediate latent states gradually converge and become indistinguishable when diffusing a pair of low- and high-resolution images. This observation inspired us to propose the Partial Diffusion Model (PartDiff), which diffuses the image to an intermediate latent state instead of pure random noise, where the intermediate latent state is approximated by the latent of diffusing the low-resolution image. During generation, Partial Diffusion Models start denoising from the intermediate distribution and perform only a part of the denoising steps. Additionally, to mitigate the error caused by the approximation, we introduce "latent alignment", which aligns the latent between low- and high-resolution images during training. Experiments on both magnetic resonance imaging (MRI) and natural images show that, compared to plain diffusion-based super-resolution methods, Partial Diffusion Models significantly reduce the number of denoising steps without sacrificing the quality of generation.
</details>
<details>
<summary>摘要</summary>
diffusion probabilistic models (DDPMs) 有 achieved impressive performance 在 various image generation tasks, including image super-resolution. By learning to reverse the process of gradually diffusing the data distribution into Gaussian noise, DDPMs generate new data by iteratively denoising from random noise. Despite their impressive performance, diffusion-based generative models suffer from high computational costs due to the large number of denoising steps.在这篇论文中，我们首先注意到，在 diffusing 一对 low-resolution 和 high-resolution 图像的 pairs, 中间的 latent states 逐渐凝固并变得不可分辨。这一观察点我们 inspirited 我们提出 Partial Diffusion Model (PartDiff), which diffuses the image to an intermediate latent state instead of pure random noise, where the intermediate latent state is approximated by the latent of diffusing the low-resolution image. During generation, Partial Diffusion Models start denoising from the intermediate distribution and perform only a part of the denoising steps.此外，为了缓解由 approximation 所引起的错误，我们引入 "latent alignment", 在训练中对 low-resolution 和 high-resolution 图像的 latent 进行 align. Experiments on both magnetic resonance imaging (MRI) 和 natural images show that, compared to plain diffusion-based super-resolution methods, Partial Diffusion Models significantly reduce the number of denoising steps without sacrificing the quality of generation.
</details></li>
</ul>
<hr>
<h2 id="Conditional-Temporal-Attention-Networks-for-Neonatal-Cortical-Surface-Reconstruction"><a href="#Conditional-Temporal-Attention-Networks-for-Neonatal-Cortical-Surface-Reconstruction" class="headerlink" title="Conditional Temporal Attention Networks for Neonatal Cortical Surface Reconstruction"></a>Conditional Temporal Attention Networks for Neonatal Cortical Surface Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11870">http://arxiv.org/abs/2307.11870</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m-qiang/cotan">https://github.com/m-qiang/cotan</a></li>
<li>paper_authors: Qiang Ma, Liu Li, Vanessa Kyriakopoulou, Joseph Hajnal, Emma C. Robinson, Bernhard Kainz, Daniel Rueckert</li>
<li>for: 这个论文的目的是为了提出一种高速、端到端的 Cortical surface reconstruction 方法，以模型新生儿脑发育的快速进程。</li>
<li>methods: 这个方法使用 Conditional Temporal Attention Network (CoTAN)，一种能够预测多分辨率 stationary velocity fields (SVF) 的端到端框架。CoTAN 通过计算每个 SVF 的重要性，并通过学习的注意力地図来学习一个 conditional time-varying velocity field (CTVF)。</li>
<li>results: CoTAN 可以减少 mesh 自交错错误，并且只需 0.21 秒可以将初始模板 mesh 扭曲到 cortical white matter 和 pial surfaces 上。与现有基线相比，CoTAN 可以达到优秀的性能，具有仅 0.12mm 的几何错误和 0.07% 的自交错错误。<details>
<summary>Abstract</summary>
Cortical surface reconstruction plays a fundamental role in modeling the rapid brain development during the perinatal period. In this work, we propose Conditional Temporal Attention Network (CoTAN), a fast end-to-end framework for diffeomorphic neonatal cortical surface reconstruction. CoTAN predicts multi-resolution stationary velocity fields (SVF) from neonatal brain magnetic resonance images (MRI). Instead of integrating multiple SVFs, CoTAN introduces attention mechanisms to learn a conditional time-varying velocity field (CTVF) by computing the weighted sum of all SVFs at each integration step. The importance of each SVF, which is estimated by learned attention maps, is conditioned on the age of the neonates and varies with the time step of integration. The proposed CTVF defines a diffeomorphic surface deformation, which reduces mesh self-intersection errors effectively. It only requires 0.21 seconds to deform an initial template mesh to cortical white matter and pial surfaces for each brain hemisphere. CoTAN is validated on the Developing Human Connectome Project (dHCP) dataset with 877 3D brain MR images acquired from preterm and term born neonates. Compared to state-of-the-art baselines, CoTAN achieves superior performance with only 0.12mm geometric error and 0.07% self-intersecting faces. The visualization of our attention maps illustrates that CoTAN indeed learns coarse-to-fine surface deformations automatically without intermediate supervision.
</details>
<details>
<summary>摘要</summary>
cortical surface reconstruction 在模型新生儿大脑发育的快速进程中扮演着基本的角色。在这项工作中，我们提议了 Conditional Temporal Attention Network（CoTAN），一种快速、端到端的杜尼诺瓦尔扩散表面重建框架。CoTAN 预测了多resolution stationary velocity field（SVF），从新生儿大脑磁共振成像图像（MRI）中预测。而不是将多个 SVF  интегра，CoTAN 引入了注意力机制，以学习一个 conditioned time-varying velocity field（CTVF），通过在每个集成步骤中计算所有 SVF 的权重的和。每个 SVF 的重要性，由学习的注意力地图所评估，与新生儿的年龄相关，随着集成步骤的变化而变化。提议的 CTVF 定义了一个 diffeomorphic surface deformation，可以有效减少缓冲自交错错误。它只需0.21秒可以将初始模板网格变换成 cortical white matter 和 pial surface  для每个脑半球。CoTAN 在 dHCP 数据集上进行了验证，与州流行基eline 相比，CoTAN 具有较好的性能，只有0.12mm的准确性和0.07%的自交错错误。我们的注意力地图可视化显示，CoTAN 实际上自动学习了粗细到细节的表面变换，无需中间监督。
</details></li>
</ul>
<hr>
<h2 id="Digital-Modeling-on-Large-Kernel-Metamaterial-Neural-Network"><a href="#Digital-Modeling-on-Large-Kernel-Metamaterial-Neural-Network" class="headerlink" title="Digital Modeling on Large Kernel Metamaterial Neural Network"></a>Digital Modeling on Large Kernel Metamaterial Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11862">http://arxiv.org/abs/2307.11862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quan Liu, Hanyu Zheng, Brandon T. Swartz, Ho hin Lee, Zuhayr Asad, Ivan Kravchenko, Jason G. Valentine, Yuankai Huo</li>
<li>for: 这篇论文的目的是提出一种基于光学计算单元的大型kernels neural network（LMNN），以最大化现代meta-optic neural network（MNN）的数字能力，同时考虑光学限制。</li>
<li>methods: 该论文使用了模型重新参数化和网络压缩技术，以maximize the learning capacity of MNN while modeling the physical restrictions of meta-optic。</li>
<li>results: 实验结果表明，提出的LMNN可以提高分类精度，同时降低计算延迟。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) utilized recently are physically deployed with computational units (e.g., CPUs and GPUs). Such a design might lead to a heavy computational burden, significant latency, and intensive power consumption, which are critical limitations in applications such as the Internet of Things (IoT), edge computing, and the usage of drones. Recent advances in optical computational units (e.g., metamaterial) have shed light on energy-free and light-speed neural networks. However, the digital design of the metamaterial neural network (MNN) is fundamentally limited by its physical limitations, such as precision, noise, and bandwidth during fabrication. Moreover, the unique advantages of MNN's (e.g., light-speed computation) are not fully explored via standard 3x3 convolution kernels. In this paper, we propose a novel large kernel metamaterial neural network (LMNN) that maximizes the digital capacity of the state-of-the-art (SOTA) MNN with model re-parametrization and network compression, while also considering the optical limitation explicitly. The new digital learning scheme can maximize the learning capacity of MNN while modeling the physical restrictions of meta-optic. With the proposed LMNN, the computation cost of the convolutional front-end can be offloaded into fabricated optical hardware. The experimental results on two publicly available datasets demonstrate that the optimized hybrid design improved classification accuracy while reducing computational latency. The development of the proposed LMNN is a promising step towards the ultimate goal of energy-free and light-speed AI.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）最近都是通过计算单元（例如CPU和GPU）进行物理部署。这种设计可能会导致重大的计算占用资源，显著的延迟和吃力的电源消耗，这些限制在互联网关系（IoT）、边缘计算和无人机应用中是关键的。最近，光学计算单元（例如元material）的进步带来了无源电能和光速神经网络。然而，光学设计的物理限制（例如精度、雷达和带宽）会限制MNN的数字设计。此外，MNN的独特优势（例如光速计算）没有通过标准3x3卷积核被完全探索。在本文中，我们提出了一种新的大kernel元material神经网络（LMNN），该方法可以最大化MNN的数字能力，同时考虑光学限制。新的数字学习方案可以在MNN中最大化学习能力，同时模拟元optic的物理限制。通过我们的提议的LMNN，计算前端的计算成本可以被卷积到制造过的光学硬件上。实验结果表明，通过优化hybrid设计，在两个公共可用的数据集上提高分类精度，降低计算延迟。开发LMNN是实现无源电能和光速AI的前景之一。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Hyperspectral-Pansharpening-on-large-scale-PRISMA-dataset"><a href="#Deep-Learning-Hyperspectral-Pansharpening-on-large-scale-PRISMA-dataset" class="headerlink" title="Deep Learning Hyperspectral Pansharpening on large scale PRISMA dataset"></a>Deep Learning Hyperspectral Pansharpening on large scale PRISMA dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11666">http://arxiv.org/abs/2307.11666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simone Zini, Mirko Paolo Barbato, Flavio Piccoli, Paolo Napoletano</li>
<li>for: 这个研究旨在评估多种深度学习策略对高spectral排比进行抗锈。</li>
<li>methods: 这个研究使用了多种现有的深度学习方法，并将其适应PRISMA高spectral数据集。</li>
<li>results: 研究发现，使用深度学习方法可以在高spectral排比 task 中表现更好，并且在 Reduced Resolution 和 Full Resolution 两种情况下都表现出色。<details>
<summary>Abstract</summary>
In this work, we assess several deep learning strategies for hyperspectral pansharpening. First, we present a new dataset with a greater extent than any other in the state of the art. This dataset, collected using the ASI PRISMA satellite, covers about 262200 km2, and its heterogeneity is granted by randomly sampling the Earth's soil. Second, we adapted several state of the art approaches based on deep learning to fit PRISMA hyperspectral data and then assessed, quantitatively and qualitatively, the performance in this new scenario. The investigation has included two settings: Reduced Resolution (RR) to evaluate the techniques in a supervised environment and Full Resolution (FR) for a real-world evaluation. The main purpose is the evaluation of the reconstruction fidelity of the considered methods. In both scenarios, for the sake of completeness, we also included machine-learning-free approaches. From this extensive analysis has emerged that data-driven neural network methods outperform machine-learning-free approaches and adapt better to the task of hyperspectral pansharpening, both in RR and FR protocols.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们评估了数字深度学习策略对光谱扫描图像进行缩进。首先，我们提供了一个新的数据集，其覆盖率比现有的状态 искусственный卫星PRISMA的数据集更大，约262200 km2。这个数据集通过随机采样地球的土壤来保证其多样性。然后，我们适应了一些现有的深度学习方法，以适应PRISMA的光谱数据。我们Then quantitatively and qualitatively evaluated the performance of these methods in two settings: Reduced Resolution (RR) and Full Resolution (FR).我们的主要目标是评估这些方法的重建准确性。在这种情况下，为了完整性，我们还包括了不含机器学习的方法。从这项广泛的分析中，我们发现 dass data-driven neural network methods outperform machine-learning-free approaches and adapt better to the task of hyperspectral pansharpening, both in RR and FR protocols.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/22/eess.IV_2023_07_22/" data-id="cllurrpc800crsw886ggcf3r9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/07/22/cs.LG_2023_07_22/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-07-22 18:00:00
        
      </div>
    </a>
  
  
    <a href="/2023/07/21/cs.LG_2023_07_21/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-07-21 18:00:00</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">92</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
