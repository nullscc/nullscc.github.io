
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-11-08 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04900 repo_url: https:&#x2F;&#x2F;github.com&#x2F;clay-lab&#x2F;structural-alte">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-11-08">
<meta property="og:url" content="https://nullscc.github.io/2023/11/08/cs.CL_2023_11_08/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04900 repo_url: https:&#x2F;&#x2F;github.com&#x2F;clay-lab&#x2F;structural-alte">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-08T11:00:00.000Z">
<meta property="article:modified_time" content="2023-11-09T07:48:31.895Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/cs.CL_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T11:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-11-08
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-Abstract-Is-Linguistic-Generalization-in-Large-Language-Models-Experiments-with-Argument-Structure"><a href="#How-Abstract-Is-Linguistic-Generalization-in-Large-Language-Models-Experiments-with-Argument-Structure" class="headerlink" title="How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure"></a>How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04900">http://arxiv.org/abs/2311.04900</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/clay-lab/structural-alternations">https://github.com/clay-lab/structural-alternations</a></li>
<li>paper_authors: Michael Wilson, Jackson Petty, Robert Frank</li>
<li>for: 这个论文主要研究了大型自然语言处理器（LLM）是否能够表征语言知识中的关系，以及这些关系如何在语言模型中表征。</li>
<li>methods: 研究者使用了Transformer基于的大型语言模型，通过对这些模型在不同上下文中的表现进行分析，来评估它们是否能够表征语言知识中的关系。</li>
<li>results: 研究者发现，LLM在某些情况下能够成功地推断novel noun argument的分布，但在其他情况下会表现出 linear order 的偏好，这指示现有的模型具有限制，并且需要更多的数据进行训练。<details>
<summary>Abstract</summary>
Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained Transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically-organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive.s reported here are available at https://github.com/clay-lab/structural-alternations.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）通常会被评估在特定上下文中的单个词的分布预测方面。然而，语言知识还包含词语上下文之间的关系，允许对词语分布进行推理。我们研究了大型Transformer基于模型（LLM）是否能够表达这些关系，特别是在语法结构领域。我们发现，LLM在已经在预训练中看到的上下文中的新词语分布推理非常好，通过利用词语嵌入空间的semantic排序结构。然而，在预训练中没有看到的相关上下文中，LLM会表现出线性顺序偏好，这表明当前模型存在一定的限制。这些结果可以在https://github.com/clay-lab/structural-alternations中找到。
</details></li>
</ul>
<hr>
<h2 id="Future-Lens-Anticipating-Subsequent-Tokens-from-a-Single-Hidden-State"><a href="#Future-Lens-Anticipating-Subsequent-Tokens-from-a-Single-Hidden-State" class="headerlink" title="Future Lens: Anticipating Subsequent Tokens from a Single Hidden State"></a>Future Lens: Anticipating Subsequent Tokens from a Single Hidden State</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04897">http://arxiv.org/abs/2311.04897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KoyenaPal/future-lens">https://github.com/KoyenaPal/future-lens</a></li>
<li>paper_authors: Koyena Pal, Jiuding Sun, Andrew Yuan, Byron C. Wallace, David Bau</li>
<li>for: 这个论文是为了检验Transformer模型中每个输入token的隐藏状态 Vector是否能够准确预测后续token的。</li>
<li>methods: 该论文使用了线性近似方法和 causal intervention 方法来评估Transformer模型中每个隐藏状态 Vector 是否能够预测后续token的。</li>
<li>results: 研究发现，在某些层次上，可以通过单个隐藏状态 Vector 来预测后续token的Accuracy 高于48%。此外，paper 还提出了一种“未来镜”视觉化方法，可以为Transformer模型的隐藏状态 Vector 创造一个新的视图。<details>
<summary>Abstract</summary>
We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at position $t$ in an input, can we reliably anticipate the tokens that will appear at positions $\geq t + 2$? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a "Future Lens" visualization that uses these methods to create a new view of transformer states.
</details>
<details>
<summary>摘要</summary>
我们推测隐藏状态向量对输入单词的预测具有充分的信息。更具体地说，在这篇论文中，我们问：给定输入中单个token的隐藏（内部）表示，可以准确预测输入中后续的多少个token？为了测试这一点，我们使用线性逼近和 causal intervention 方法来评估隐藏状态中是否含有可预测输入的信号。我们发现，在某些层次上，可以使用单个隐藏状态来预测后续token的输出，准确率高达48%以上。最后，我们介绍了一种“未来镜”视觉化，使用这些方法来创造一种新的 transformer 状态视图。
</details></li>
</ul>
<hr>
<h2 id="Bias-Runs-Deep-Implicit-Reasoning-Biases-in-Persona-Assigned-LLMs"><a href="#Bias-Runs-Deep-Implicit-Reasoning-Biases-in-Persona-Assigned-LLMs" class="headerlink" title="Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"></a>Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04892">http://arxiv.org/abs/2311.04892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/allenai/persona-bias">https://github.com/allenai/persona-bias</a></li>
<li>paper_authors: Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, Tushar Khot</li>
<li>for: 这研究探讨了大规模自然语言模型（LLMs）是如何在响应人工 persona 时表现出各种人类行为的能力，以及这种能力对 LLMs 的能力有什么影响。</li>
<li>methods: 这研究使用了 ChatGPT 进行基本逻辑任务的测试，并在不同的社会民生群体（种族、性别、宗教、残疾和政治倾向）中测试了 16 个多样化的人工 persona。</li>
<li>results: 研究发现，ChatGPT 具有各种社会民生群体下的偏见，包括逻辑任务中的数学能力偏见。这种偏见会导致 ChatGPT 在响应人工 persona 时表现出偏见和错误的假设，并导致基本逻辑任务的性能下降。这种偏见是广泛存在的、有 statistically significant 影响和可能对某些群体产生不良影响。<details>
<summary>Abstract</summary>
Recent works have showcased the ability of large-scale language models (LLMs) to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remain unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs, specifically ChatGPT, to perform basic reasoning tasks. Our study covers 24 reasoning datasets and 16 diverse personas spanning 5 socio-demographic groups: race, gender, religion, disability, and political affiliation. Our experiments unveil that ChatGPT carries deep rooted bias against various socio-demographics underneath a veneer of fairness. While it overtly rejects stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), it manifests stereotypical and often erroneous presumptions when prompted to answer questions while taking on a persona. These can be observed as abstentions in the model responses, e.g., 'As a Black person, I am unable to answer this question as it requires math knowledge', and generally result in a substantial drop in performance on reasoning tasks. We find that this inherent deep bias is ubiquitous - 80% of our personas demonstrated bias; it is significant - certain datasets had relative drops in performance of 70%+; and can be especially harmful for certain groups - certain personas had stat. sign. drops on more than 80% of the datasets. Further analysis shows that these persona-induced errors can be hard-to-discern and hard-to-avoid. Our findings serve as a cautionary tale that the practice of assigning personas to LLMs - a trend on the rise - can surface their deep-rooted biases and have unforeseeable and detrimental side-effects.
</details>
<details>
<summary>摘要</summary>
近期研究显示大型语言模型（LLM）能够体现多种人格 trait，如“你是יודा。解释 relativity 理论”的提示。这种能力允许个性化 LLM 和人类行为模拟，但其影响 LLM 的能力仍未得到清楚的解释。为了填补这个空白，我们提出了首次对 LLM 特征 Persona 分配的不良侧effect的系统性研究。我们的研究涵盖24个逻辑数据集和16种多样化的人格 trait，包括种族、性别、宗教、残疾和政治倾向。我们的实验发现，ChatGPT 具有各种社会化特征 trait 的深层隐藏偏见，尤其是对于不同的社会群体。尽管 ChatGPT 明确拒绝了一些刻板印象（如“黑人不会准确地做数学”），但在接受人格 trait 时，它会表现出偏见和错误的假设。这些假设可以通过 ChatGPT 的答案中的异常沉默（如“作为黑人，我无法回答这个问题，因为它需要数学知识”）来观察。这些假设通常会导致 ChatGPT 在逻辑任务中表现出显著的下降。我们发现这种深层偏见是普遍的 - 80%的人格 trait 表现出偏见；它是重要的 - certain dataset 上的相对下降超过 70%；并且可能对某些群体造成特别危害 - certain persona 上的more than 80% dataset 上的相对下降。进一步分析表明，这些人格 trait 引起的错误可能具有难以识别和难以避免的特征。我们的发现 serve as a cautionary tale，将 Persona 分配给 LLM 的做法（这是当前升温的趋势）可能会暴露 LLM 的深层偏见并导致不预期的和有害的副作用。
</details></li>
</ul>
<hr>
<h2 id="Profiling-Irony-Stereotype-Exploring-Sentiment-Topic-and-Lexical-Features"><a href="#Profiling-Irony-Stereotype-Exploring-Sentiment-Topic-and-Lexical-Features" class="headerlink" title="Profiling Irony &amp; Stereotype: Exploring Sentiment, Topic, and Lexical Features"></a>Profiling Irony &amp; Stereotype: Exploring Sentiment, Topic, and Lexical Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04885">http://arxiv.org/abs/2311.04885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tibor L. R. Krols, Marie Mortensen, Ninell Oldenburg</li>
<li>for: 本研究旨在创建一种推断Twitter用户发布的信息中带有讲究的语句的系统。</li>
<li>methods: 该研究使用TF-IDF、情感特征和主题模型来选择特定的子特征，并通过了一项系统的特征选择过程。</li>
<li>results: 模型的F1分数为0.84，超过了基线值。 lexical特征，特别是TF-IDF，对模型的性能做出了最大贡献，而情感和主题模型的特征则对模型的性能较少。<details>
<summary>Abstract</summary>
Social media has become a very popular source of information. With this popularity comes an interest in systems that can classify the information produced. This study tries to create such a system detecting irony in Twitter users. Recent work emphasize the importance of lexical features, sentiment features and the contrast herein along with TF-IDF and topic models. Based on a thorough feature selection process, the resulting model contains specific sub-features from these areas. Our model reaches an F1-score of 0.84, which is above the baseline. We find that lexical features, especially TF-IDF, contribute the most to our models while sentiment and topic modeling features contribute less to overall performance. Lastly, we highlight multiple interesting and important paths for further exploration.
</details>
<details>
<summary>摘要</summary>
社交媒体已成为信息来源的非常流行的地方。随着这种流行，有人对这些信息生成系统进行了关注。这个研究尝试创建一个检测Twitter用户中的讲究的系统。最近的研究强调了用语特征、情感特征以及这里的对比，同时还包括TF-IDF和话题模型。根据严格的特征选择过程，模型包含特定的子特征。我们的模型达到了0.84的F1分数，高于基线。我们发现，TF-IDF特征对模型的表现最大，情感和话题模型特征对表现较差。最后，我们提出了多个有趣和重要的探索方向。
</details></li>
</ul>
<hr>
<h2 id="Hierarchically-Gated-Recurrent-Neural-Network-for-Sequence-Modeling"><a href="#Hierarchically-Gated-Recurrent-Neural-Network-for-Sequence-Modeling" class="headerlink" title="Hierarchically Gated Recurrent Neural Network for Sequence Modeling"></a>Hierarchically Gated Recurrent Neural Network for Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04823">http://arxiv.org/abs/2311.04823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opennlplab/hgrn">https://github.com/opennlplab/hgrn</a></li>
<li>paper_authors: Zhen Qin, Songlin Yang, Yiran Zhong</li>
<li>for: 这个论文是为了提出一种基于Linear RNN的高效序列模型，它可以模型长期依赖关系和当地短期依赖关系。</li>
<li>methods: 该模型使用了闭包机制，并将忘记门Lower bound为学习值。这使得上层层模型长期依赖关系，而下层层模型更多的短期依赖关系。</li>
<li>results: 在语言模型、图像分类和长距离比赛 benchmark 上，该模型显示了高效性和有效性。源代码可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling. Recently, there has been a renewed interest in using linear RNNs for efficient sequence modeling. These linear RNNs often employ gating mechanisms in the output of the linear recurrence layer while ignoring the significance of using forget gates within the recurrence. In this paper, we propose a gated linear RNN model dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes forget gates that are lower bounded by a learnable value. The lower bound increases monotonically when moving up layers. This allows the upper layers to model long-term dependencies and the lower layers to model more local, short-term dependencies. Experiments on language modeling, image classification, and long-range arena benchmarks showcase the efficiency and effectiveness of our proposed model. The source code is available at https://github.com/OpenNLPLab/HGRN.
</details>
<details>
<summary>摘要</summary>
transformers 已经超过 RNNs 的受欢迎程度，这主要归功于它们在并行训练和长期依赖模型方面的优势。在最近，使用线性 RNNs  для高效序列模型化有新的兴趣。这些线性 RNNs 通常在输出 linear recurrence 层中使用阀门机制，而忽略使用 forget gates 的重要性。在这篇论文中，我们提出了一种名为层次阀门Recurrent Neural Network（HGRN）的模型，该模型包含 learnable 的下界值。这个下界值随层数增长 monotonically，这使得上层模型长期依赖，而下层模型更加本地、短期依赖。我们在语言模型、图像分类和长距离场景中进行了实验，结果表明我们的提议的模型具有高效性和有效性。代码可以在 <https://github.com/OpenNLPLab/HGRN> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Determination-of-toxic-comments-and-unintended-model-bias-minimization-using-Deep-learning-approach"><a href="#Determination-of-toxic-comments-and-unintended-model-bias-minimization-using-Deep-learning-approach" class="headerlink" title="Determination of toxic comments and unintended model bias minimization using Deep learning approach"></a>Determination of toxic comments and unintended model bias minimization using Deep learning approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04789">http://arxiv.org/abs/2311.04789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Azim Khan</li>
<li>for: 本研究旨在探讨评论中的恶意言语检测和性别、种族、宗教等特征偏见问题。</li>
<li>methods: 本研究使用BERT模型进行注意力调整，并应用权重损失函数来解决不均衡数据问题。</li>
<li>results: 研究发现， Fine-tuned BERT模型在恶意言语检测和偏见减少方面的性能比传统的逻辑回归模型高，并且可以减少不良评论中的性别、种族、宗教等特征偏见。<details>
<summary>Abstract</summary>
Online conversations can be toxic and subjected to threats, abuse, or harassment. To identify toxic text comments, several deep learning and machine learning models have been proposed throughout the years. However, recent studies demonstrate that because of the imbalances in the training data, some models are more likely to show unintended biases including gender bias and identity bias. In this research, our aim is to detect toxic comment and reduce the unintended bias concerning identity features such as race, gender, sex, religion by fine-tuning an attention based model called BERT(Bidirectional Encoder Representation from Transformers). We apply weighted loss to address the issue of unbalanced data and compare the performance of a fine-tuned BERT model with a traditional Logistic Regression model in terms of classification and bias minimization. The Logistic Regression model with the TFIDF vectorizer achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is available at https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git
</details>
<details>
<summary>摘要</summary>
在线聊天可能会出现攻击性、威胁、辱华或骚扰行为。为了识别攻击性文章评论，多种深度学习和机器学习模型已经被提出了多年来。然而，最近的研究表明，由于训练数据的不均衡，一些模型可能会显示不良偏见，包括性别偏见和身份偏见。在这项研究中，我们的目标是检测攻击性评论，并对身份特征（种族、性别、宗教等）进行降低不良偏见。我们使用了一种注意力基于模型（BERT）进行精度调整，并应用权重损失函数来解决不均衡数据的问题。我们与传统的Logistic Regression模型进行比较，并评估两种模型在分类和偏见降低方面的性能。Logistic Regression模型与TF-IDF vectorizer实现了57.1%的准确率，而精度调整后的BERT模型的准确率为89%。代码可以在https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git中找到。
</details></li>
</ul>
<hr>
<h2 id="Using-large-language-models-to-study-human-memory-for-meaningful-narratives"><a href="#Using-large-language-models-to-study-human-memory-for-meaningful-narratives" class="headerlink" title="Using large language models to study human memory for meaningful narratives"></a>Using large language models to study human memory for meaningful narratives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04742">http://arxiv.org/abs/2311.04742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mkatkov/llm-narrative-analysis">https://github.com/mkatkov/llm-narrative-analysis</a></li>
<li>paper_authors: Antonios Georgiou Tankut Can, Mikhail Katkov, Misha Tsodyks</li>
<li>for: 研究人类记忆的大语言模型可以作为科学工具，用于研究人类记忆的含义。</li>
<li>methods: 开发了大规模记忆实验的管道，并对获得的结果进行分析。实施了在线记忆实验，收集了不同长度的故事的记忆和回忆数据。发现故事长度和记忆性的关系是直线关系。</li>
<li>results: 发现，即使使用扰乱版故事，记忆性仍然保持 relativamente 不变，但回忆性却明显下降。这表明，记忆中的故事 Context 具有重要作用。<details>
<summary>Abstract</summary>
One of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary. Here we show that language models can be used as a scientific instrument for studying human memory for meaningful material. We developed a pipeline for designing large scale memory experiments and analyzing the obtained results. We performed online memory experiments with a large number of participants and collected recognition and recall data for narratives of different lengths. We found that both recall and recognition performance scale linearly with narrative length. Furthermore, in order to investigate the role of narrative comprehension in memory, we repeated these experiments using scrambled versions of the presented stories. We found that even though recall performance declined significantly, recognition remained largely unaffected. Interestingly, recalls in this condition seem to follow the original narrative order rather than the scrambled presentation, pointing to a contextual reconstruction of the story in memory.
</details>
<details>
<summary>摘要</summary>
一个AI革命的最引人注目的成就是大语言模型的开发，可以生成有意义的文本并遵循普通英语的指令，无需额外训练。我们表明了语言模型可以作为研究人类记忆的科学工具。我们开发了大规模记忆实验的管道和分析得到的结果。我们在大量参与者上线进行了记忆和回忆实验，收集了不同长度的故事的认知和回忆数据。我们发现，故事长度和记忆性的表现是直线关系。此外，为了研究故事理解对记忆的影响，我们重复使用故事的排序版本进行实验。我们发现，即使回忆性下降了很多，仍然可以保持认知的能力，而且回忆似乎遵循原始的故事顺序，表明在记忆中存在Contextual重建的story。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Generative-Ad-Hoc-Information-Retrieval"><a href="#Evaluating-Generative-Ad-Hoc-Information-Retrieval" class="headerlink" title="Evaluating Generative Ad Hoc Information Retrieval"></a>Evaluating Generative Ad Hoc Information Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04694">http://arxiv.org/abs/2311.04694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Gienapp, Harrisen Scells, Niklas Deckers, Janek Bevendorff, Shuai Wang, Johannes Kiesel, Shahbaz Syed, Maik Fröbe, Guide Zucoon, Benno Stein, Matthias Hagen, Martin Potthast</li>
<li>for: 这篇论文旨在研究基于大语言模型的生成搜索系统，以及如何评估这类系统的用户体验。</li>
<li>methods: 论文使用了现有的信息检索和自然语言处理文献来做一个搜索任务和系统结构的归纳，并开发了一个用户模型来评估生成搜索系统的性能。</li>
<li>results: 论文通过对生成搜索系统的理论分析提供了一个基础和新的发现，可以用于评估生成搜索系统的用户体验。<details>
<summary>Abstract</summary>
Recent advances in large language models have enabled the development of viable generative information retrieval systems. A generative retrieval system returns a grounded generated text in response to an information need instead of the traditional document ranking. Quantifying the utility of these types of responses is essential for evaluating generative retrieval systems. As the established evaluation methodology for ranking-based ad hoc retrieval may seem unsuitable for generative retrieval, new approaches for reliable, repeatable, and reproducible experimentation are required. In this paper, we survey the relevant information retrieval and natural language processing literature, identify search tasks and system architectures in generative retrieval, develop a corresponding user model, and study its operationalization. This theoretical analysis provides a foundation and new insights for the evaluation of generative ad hoc retrieval systems.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:大语言模型的最新进展已经实现了实用的生成信息搜寻系统。相比于传统的排名式搜寻，一个生成搜寻系统会返回一个对应的生成文本，以满足资讯需求。评估这种类型的回应的用度是评估生成搜寻系统的重要指标。由于传统的排名式搜寻评估方法可能不适用于生成搜寻，因此需要新的评估方法，以 Ensure reliable, repeatable, and reproducible experimentation。在这篇论文中，我们对信息搜寻和自然语言处理领域的相关文献进行了评价，识别了生成搜寻中的搜寻任务和系统架构，开发了用户模型，并进行了实现的研究。这个理论分析提供了一个基础和新的见解，用于评估生成随机搜寻系统。
</details></li>
</ul>
<hr>
<h2 id="Speech-language-models-lack-important-brain-relevant-semantics"><a href="#Speech-language-models-lack-important-brain-relevant-semantics" class="headerlink" title="Speech language models lack important brain-relevant semantics"></a>Speech language models lack important brain-relevant semantics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04664">http://arxiv.org/abs/2311.04664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subba Reddy Oota, Emin Çelik, Fatma Deniz, Mariya Toneva</li>
<li>for:  investigate the types of information that language models predict in the brain</li>
<li>methods: eliminate information related to specific low-level stimulus features in the language model representations and compare with speech-based language models</li>
<li>results: text-based language models align well with early sensory regions and later language regions, while speech-based models lose most of their alignment after removing low-level features, suggesting that speech-based models can be improved to better reflect brain-like language processing.<details>
<summary>Abstract</summary>
Despite known differences between reading and listening in the brain, recent work has shown that text-based language models predict both text-evoked and speech-evoked brain activity to an impressive degree. This poses the question of what types of information language models truly predict in the brain. We investigate this question via a direct approach, in which we eliminate information related to specific low-level stimulus features (textual, speech, and visual) in the language model representations, and observe how this intervention affects the alignment with fMRI brain recordings acquired while participants read versus listened to the same naturalistic stories. We further contrast our findings with speech-based language models, which would be expected to predict speech-evoked brain activity better, provided they model language processing in the brain well. Using our direct approach, we find that both text-based and speech-based language models align well with early sensory regions due to shared low-level features. Text-based models continue to align well with later language regions even after removing these features, while, surprisingly, speech-based models lose most of their alignment. These findings suggest that speech-based models can be further improved to better reflect brain-like language processing.
</details>
<details>
<summary>摘要</summary>
尽管已知文字和听 speech在脑中的差异， latest work 表明文字语言模型可以很好地预测文字诱发和说话诱发的脑活动。这意味着语言模型真正预测的信息是什么？我们通过直接方法来研究这个问题，在语言模型表示中消除了文字、说话和视觉相关的信息，然后观察到这种 intervención 对 fMRI 脑活动记录有多大的影响。我们进一步与speech-based语言模型进行比较，这些模型应该更好地预测说话诱发的脑活动，只要它们能够正确地模型脑中的语言处理。使用直接方法，我们发现了以下结论：文字基于的语言模型在消除低级特征后仍然能够准确地预测后续语言区域的脑活动，而speech-based模型则在消除低级特征后失去了大部分的Alignment。这些发现表明可以进一步改进speech-based模型，以更好地反映脑中的语言处理。
</details></li>
</ul>
<hr>
<h2 id="Massive-Editing-for-Large-Language-Models-via-Meta-Learning"><a href="#Massive-Editing-for-Large-Language-Models-via-Meta-Learning" class="headerlink" title="Massive Editing for Large Language Models via Meta Learning"></a>Massive Editing for Large Language Models via Meta Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04661">http://arxiv.org/abs/2311.04661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenmientan/malmen">https://github.com/chenmientan/malmen</a></li>
<li>paper_authors: Chenmien Tan, Ge Zhang, Jie Fu</li>
<li>for:  rectifying the knowledge of the language model (LM) after training, and editing multiple facts simultaneously with limited memory budgets</li>
<li>methods:  employing a hyper-network to generate parameter shift, formulating the parameter shift aggregation as the least square problem, and separating the computation on the hyper-network and LM to enable arbitrary batch size</li>
<li>results:  capable of editing hundreds of times more facts than strong baselines with the identical hyper-network architecture, and outperforming editor specifically designed for GPT<details>
<summary>Abstract</summary>
While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training. A promising approach involves employing a hyper-network to generate parameter shift, whereas existing hyper-networks suffer from inferior scalability in synchronous editing operation amount. To mitigate the problem, we propose the MAssive Language Model Editing Network (MALMEN), which formulates the parameter shift aggregation as the least square problem, subsequently updating the LM parameters using the normal equation. To accommodate editing multiple facts simultaneously with limited memory budgets, we separate the computation on the hyper-network and LM, enabling arbitrary batch size on both neural networks. Our method is evaluated by editing up to thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2, T5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks, i.e., closed book fact-checking and question answering. Remarkably, MALMEN is capable of editing hundreds of times more facts than strong baselines with the identical hyper-network architecture and outperforms editor specifically designed for GPT. Our code is available at https://github.com/ChenmienTan/malmen.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经允许我们从预训练 corpora 中学习语言知识，但是这些学习的知识可能会随着时间的推移而变得不正确或过时，因此需要在训练后对语言模型（LM）进行修正。一种有前途的方法是使用 hyper-network 生成参数变化，但是现有的 hyper-network 受到同步编辑操作量的限制，导致它们的扩展性不够。为了解决这个问题，我们提出了 MAssive Language Model Editing Network（MALMEN），它将参数变化的汇集视为最小二乘问题，然后使用常数方程更新 LM 参数。为了在有限内存预算下同时编辑多个事实，我们将计算在 hyper-network 和 LM 之间分离，以便在两个神经网络上使用任意批处理大小。我们的方法在不同的语言模型架构（BERT-base、GPT-2、T5-XL 2.8B、GPT-J 6B）上进行了编辑，并在closed book fact-checking 和问答 tasks 上达到了remarkable的性能。特别是，MALMEN 能够编辑 hundreds 个事实，比strong baseline 高得多，并且超过了专门为 GPT 设计的编辑器。我们的代码可以在 <https://github.com/ChenmienTan/malmen> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Nature-of-Disagreements-on-Mid-Scale-Ratings-A-Case-Study-on-the-Abstractness-Concreteness-Continuum"><a href="#Investigating-the-Nature-of-Disagreements-on-Mid-Scale-Ratings-A-Case-Study-on-the-Abstractness-Concreteness-Continuum" class="headerlink" title="Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum"></a>Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04563">http://arxiv.org/abs/2311.04563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Urban Knupleš, Diego Frassinelli, Sabine Schulte im Walde</li>
<li>for: 这个研究的目的是提高评估中的一致性，尤其是在中等级别的词汇上。</li>
<li>methods: 这个研究使用了相关性和批处学习来 indentify 中等级别词汇的特征，并应用硬件 clustering 来检测评估者之间的不一致。</li>
<li>results: 研究结果表明，需要对中等级别词汇进行细化或滤除，以提高评估的一致性。<details>
<summary>Abstract</summary>
Humans tend to strongly agree on ratings on a scale for extreme cases (e.g., a CAT is judged as very concrete), but judgements on mid-scale words exhibit more disagreement. Yet, collected rating norms are heavily exploited across disciplines. Our study focuses on concreteness ratings and (i) implements correlations and supervised classification to identify salient multi-modal characteristics of mid-scale words, and (ii) applies a hard clustering to identify patterns of systematic disagreement across raters. Our results suggest to either fine-tune or filter mid-scale target words before utilising them.
</details>
<details>
<summary>摘要</summary>
人们往往在极端情况下（例如，一只猫被评为非常具体）达成强调的共识，但在中间级单词上存在更大的不一致。然而，收集的评分标准在不同领域中得到了广泛的利用。我们的研究关注了具体性评分，并（i）利用相关性和有监督的分类来挖掘多Modal特征，以及（ii）通过固定分 clustering来描述评分者之间的系统性不一致。我们的结果表明，在使用中间级单词之前，应该进行细化或过滤。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Distractors-in-Multiple-Choice-Tests"><a href="#Assessing-Distractors-in-Multiple-Choice-Tests" class="headerlink" title="Assessing Distractors in Multiple-Choice Tests"></a>Assessing Distractors in Multiple-Choice Tests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04554">http://arxiv.org/abs/2311.04554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vatsal Raina, Adian Liusie, Mark Gales</li>
<li>For: The paper aims to improve the quality of distractors in multiple-choice reading comprehension tests by proposing automated assessment metrics.* Methods: The paper uses a combination of classification ability, distractor confidence, and embedding-based equivalence metric to assess the quality of distractors.* Results: The paper validates the proposed metrics by comparing them against candidate distributions and a ChatGPT model’s interpretation of distractor plausibility and diversity.Here are the three key points in Simplified Chinese:* For: 该 paper 目的是提高多项选择评估测试中的吸引选项质量，通过提出自动评估指标。* Methods: 该 paper 使用组合 classification 能力、吸引选项信任度和基于嵌入的等价度量来评估吸引选项质量。* Results: 该 paper 通过与候选分布和 ChatGPT 模型的吸引选项可能性和多样性的比较来验证提出的指标。<details>
<summary>Abstract</summary>
Multiple-choice tests are a common approach for assessing candidates' comprehension skills. Standard multiple-choice reading comprehension exams require candidates to select the correct answer option from a discrete set based on a question in relation to a contextual passage. For appropriate assessment, the distractor answer options must by definition be incorrect but plausible and diverse. However, generating good quality distractors satisfying these criteria is a challenging task for content creators. We propose automated assessment metrics for the quality of distractors in multiple-choice reading comprehension tests. Specifically, we define quality in terms of the incorrectness, plausibility and diversity of the distractor options. We assess incorrectness using the classification ability of a binary multiple-choice reading comprehension system. Plausibility is assessed by considering the distractor confidence - the probability mass associated with the distractor options for a standard multi-class multiple-choice reading comprehension system. Diversity is assessed by pairwise comparison of an embedding-based equivalence metric between the distractors of a question. To further validate the plausibility metric we compare against candidate distributions over multiple-choice questions and agreement with a ChatGPT model's interpretation of distractor plausibility and diversity.
</details>
<details>
<summary>摘要</summary>
多选测试是评估候选人的理解能力的常见方法。标准多选读取理解测试要求候选人从问题相关的文本中选择正确的答案选项。为了有效评估，拥有者必须生成正确但不可靠、多样化的干扰答案。然而，生成高质量干扰答案是内容创建者的挑战。我们提议使用自动评估指标来评估干扰答案的质量。 Specifically，我们定义质量为干扰答案的不正确性、可能性和多样性。我们评估不正确性使用多选读取理解系统的分类能力。可能性是通过考虑问题相关的干扰选项的信任度来评估的。多样性是通过对干扰选项的对比来评估的。为了进一步验证可能性指标，我们与多个多选问题的候选人分布和ChatGPT模型的干扰可能性和多样性解释进行比较。
</details></li>
</ul>
<hr>
<h2 id="Large-GPT-like-Models-are-Bad-Babies-A-Closer-Look-at-the-Relationship-between-Linguistic-Competence-and-Psycholinguistic-Measures"><a href="#Large-GPT-like-Models-are-Bad-Babies-A-Closer-Look-at-the-Relationship-between-Linguistic-Competence-and-Psycholinguistic-Measures" class="headerlink" title="Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures"></a>Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04547">http://arxiv.org/abs/2311.04547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julius Steuer, Marius Mosbach, Dietrich Klakow</li>
<li>for: 这项研究的目的是检验语言模型（LM）的认知可能性，并探讨语言模型如何模型语言知识和处理语言任务。</li>
<li>methods: 本研究使用了一系列基于GPT的语言模型，对这些模型进行了不同的大小和深度的训练，并测试其在多个挑战任务（BLiMP、GLUE、MSGS）中的表现。</li>
<li>results: 研究发现，LM的大小和表现之间存在正相关关系，而且不同任务中对模型宽度和深度的选择也有不同的偏好。此外，研究还发现，模型处理时间预测Task中LM的大小和表现之间存在负相关关系，表明模型语言知识和处理语言任务可能需要采用不同的方法。<details>
<summary>Abstract</summary>
Research on the cognitive plausibility of language models (LMs) has so far mostly concentrated on modelling psycholinguistic response variables such as reading times, gaze durations and N400/P600 EEG signals, while mostly leaving out the dimension of what Mahowald et al. (2023) described as formal and functional linguistic competence, and developmental plausibility. We address this gap by training a series of GPT-like language models of different sizes on the strict version of the BabyLM pretraining corpus, evaluating on the challenge tasks (BLiMP, GLUE, MSGS) and an additional reading time prediction task. We find a positive correlation between LM size and performance on all three challenge tasks, with different preferences for model width and depth in each of the tasks. In contrast, a negative correlation was found between LM size and reading time fit of linear mixed-effects models using LM surprisal as a predictor, with the second-smallest LM achieving the largest log-likelihood reduction over a baseline model without surprisal. This suggests that modelling processing effort and linguistic competence may require an approach different from training GPT-like LMs on a developmentally plausible corpus.
</details>
<details>
<summary>摘要</summary>
研究语言模型（LM）的认知可能性的研究大多集中在模拟心理语言反应变量，如阅读时间、视线持续时间和N400/P600 EEG信号，而忽略了语言模型的形式和功能语言能力、发展可能性的维度。我们填补这个空白，通过在严格版本的BabyLM预学材料上训练一系列GPT-like语言模型不同大小，并在BLiMP、GLUE和MSGS挑战任务以及额外的阅读时间预测任务上评估其表现。我们发现LM大小和任务中的表现之间存在正相关，不同任务中LM宽度和深度的偏好有所不同。同时，我们发现LM大小和使用LMsurprisal作为预测变量的线性混合效应模型的阅读时间适应性存在负相关，第二小的LM在log-likelihood下得到了最大减少。这表明，模拟处理努力和语言能力可能需要一种不同于训练GPT-like LMs在发展可能性的 corpus 的方法。
</details></li>
</ul>
<hr>
<h2 id="Loss-Masking-Is-Not-Needed-in-Decoder-only-Transformer-for-Discrete-token-Based-ASR"><a href="#Loss-Masking-Is-Not-Needed-in-Decoder-only-Transformer-for-Discrete-token-Based-ASR" class="headerlink" title="Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token Based ASR"></a>Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token Based ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04534">http://arxiv.org/abs/2311.04534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Shiliang Zhang, Chong Deng, Yukun Ma, Hai Yu, Jiaqing Liu, Chong Zhang</li>
<li>for: 这个论文主要针对的是基于普通话语音识别任务的单个decoder-only transformer模型。</li>
<li>methods: 该论文使用了损失压缩（Loss Masking）来模型输入语音标签的序列结构，但发现这种方法不能一直提高ASR性能。因此，该论文提出了一种新的方法，即简化标签散列（Smoothed Label Distillation，SLD），通过在输入语音标签上添加KL散列损失来有效地模型语音标签序列。</li>
<li>results: 实验表明，SLD方法可以超越损失压缩和文本散列方法，并且可以适应不同的语音分词方法。<details>
<summary>Abstract</summary>
Recently, unified speech-text models, such as SpeechGPT, VioLA, and AudioPaLM, have achieved remarkable performance on speech tasks. These models convert continuous speech signals into discrete tokens (speech discretization) and merge text and speech tokens into a shared vocabulary. Then they train a single decoder-only Transformer on a mixture of speech tasks. Specifically, all these models utilize Loss Masking on the input speech tokens for the ASR task, which means that these models do not explicitly model the dependency between the speech tokens. In this paper, we attempt to model the sequence of speech tokens in an autoregressive manner like text. However, we find that applying the conventional cross-entropy loss on input speech tokens does not consistently improve the ASR performance over Loss Masking. Therefore, we propose a novel approach denoted Smoothed Label Distillation (SLD), which introduces a KL divergence loss with smoothed labels on the input speech tokens to effectively model speech tokens. Experiments demonstrate that our SLD approach alleviates the limitations of the cross-entropy loss and consistently outperforms Loss Masking for decoder-only Transformer based ASR using different speech discretization methods.
</details>
<details>
<summary>摘要</summary>
最近，一些听说模型，如SpeechGPT、VioLA和AudioPaLM，在听说任务上表现出色。这些模型将连续的听说信号转换为精确的token（听说精确），然后将文本和听说token合并到共享词汇中。然后，它们使用单个decoder-only transformer来训练混合的听说任务。具体来说，所有这些模型都使用输入听说token的损失掩蔽（loss masking）来实现ASR任务，这意味着这些模型不需要直接模型听说token之间的依赖关系。在这篇论文中，我们尝试模型听说token的序列在抽象的方式上，但我们发现，将输入听说token的普通十字积分损失应用于听说token上不一定能够提高ASR性能。因此，我们提出了一种新的方法，称为简化标签混合（SLD），它在输入听说token上引入KL散度损失和缓和标签来有效地模型听说token。实验表明，我们的SLD方法可以解决普通十字积分损失的局限性，并在不同的听说精确方法下一直超越损失掩蔽。
</details></li>
</ul>
<hr>
<h2 id="Conversation-Understanding-using-Relational-Temporal-Graph-Neural-Networks-with-Auxiliary-Cross-Modality-Interaction"><a href="#Conversation-Understanding-using-Relational-Temporal-Graph-Neural-Networks-with-Auxiliary-Cross-Modality-Interaction" class="headerlink" title="Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction"></a>Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04507">http://arxiv.org/abs/2311.04507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cam-Van Thi Nguyen, Anh-Tuan Mai, The-Son Le, Hai-Dang Kieu, Duc-Trong Le</li>
<li>for: 这篇论文主要针对人工智能对话理解中的情绪识别问题，具体来说是在多modal数据下进行情绪识别。</li>
<li>methods: 本文提出了一种新的神经网络框架，即Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction（CORECT），该框架能够有效地捕捉对话水平的跨modal交互以及每个句子的时间依赖关系，同时还能够利用modal特定的表示方式进行情绪识别。</li>
<li>results: 对于IEMOCAP和CMU-MOSEI datasets上的多modal ERC任务，CORECT得到了状态之Art的Result，证明了其效果性。<details>
<summary>Abstract</summary>
Emotion recognition is a crucial task for human conversation understanding. It becomes more challenging with the notion of multimodal data, e.g., language, voice, and facial expressions. As a typical solution, the global- and the local context information are exploited to predict the emotional label for every single sentence, i.e., utterance, in the dialogue. Specifically, the global representation could be captured via modeling of cross-modal interactions at the conversation level. The local one is often inferred using the temporal information of speakers or emotional shifts, which neglects vital factors at the utterance level. Additionally, most existing approaches take fused features of multiple modalities in an unified input without leveraging modality-specific representations. Motivating from these problems, we propose the Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction (CORECT), an novel neural network framework that effectively captures conversation-level cross-modality interactions and utterance-level temporal dependencies with the modality-specific manner for conversation understanding. Extensive experiments demonstrate the effectiveness of CORECT via its state-of-the-art results on the IEMOCAP and CMU-MOSEI datasets for the multimodal ERC task.
</details>
<details>
<summary>摘要</summary>
情感识别是人工对话理解中的关键任务。在多模式数据下，情感识别变得更加挑战性，例如语言、声音和脸部表达。为解决这问题，通常采用全局和本地上下文信息来预测对话中每个句子的情感标签。特别是，全局表示可以通过对话水平的交互模型来捕捉全局信息。本地一是通过说话者的时间信息或情感变化来推断，忽略了对话中每个句子的重要因素。此外，大多数现有方法具有融合多模式特征的Input而不利用特定模式的表示。为此，我们提出了一种新的神经网络框架：相互关系图神经网络with协助交互（CORECT），可以有效地捕捉对话水平的交互和每个句子的时间依赖关系，同时还能够利用特定模式的表示来提高对话理解。我们对IEMOCAP和CMU-MOSEI数据集进行了广泛的实验，并证明了CORECT的效果。
</details></li>
</ul>
<hr>
<h2 id="Multi-label-and-Multi-target-Sampling-of-Machine-Annotation-for-Computational-Stance-Detection"><a href="#Multi-label-and-Multi-target-Sampling-of-Machine-Annotation-for-Computational-Stance-Detection" class="headerlink" title="Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection"></a>Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04495">http://arxiv.org/abs/2311.04495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/seq-to-mind/Stance_MA">https://github.com/seq-to-mind/Stance_MA</a></li>
<li>paper_authors: Zhengyuan Liu, Hai Leong Chieu, Nancy F. Chen</li>
<li>for: 这篇论文主要用于研究自动化标注的可行性和效果，以及如何使用大语言模型进行计算意见探测。</li>
<li>methods: 该论文使用了大语言模型进行自动化标注，并采用了多标签多目标采样策略来优化标注质量。</li>
<li>results: 实验结果表明，使用该方法可以显著提高计算意见探测的性能和学习效果。<details>
<summary>Abstract</summary>
Data collection from manual labeling provides domain-specific and task-aligned supervision for data-driven approaches, and a critical mass of well-annotated resources is required to achieve reasonable performance in natural language processing tasks. However, manual annotations are often challenging to scale up in terms of time and budget, especially when domain knowledge, capturing subtle semantic features, and reasoning steps are needed. In this paper, we investigate the efficacy of leveraging large language models on automated labeling for computational stance detection. We empirically observe that while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation. We introduce a multi-label and multi-target sampling strategy to optimize the annotation quality. Experimental results on the benchmark stance detection corpora show that our method can significantly improve performance and learning efficacy.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本收集自手动标注提供域 especific 和任务aligned 的监督 для数据驱动方法，并需要一个可观的标注资源来达到自然语言处理任务的合理性。然而，手动标注经常困难Scaling up в时间和预算方面，特别是当域知识、捕捉微妙 semantics 和reasoning步骤需要。在这篇论文中，我们调查使用大型自然语言模型进行自动标注的可能性。我们经验证显示，虽然大型自然语言模型在人工标注者的替代者中表现出色，但是它们对任务特定的指示和自身偏见带来了有趣却独特的挑战。我们提出了一种多标签多目标采样策略，以提高标注质量。实验结果表明，我们的方法可以在标准折衔检测 corpora 上显著提高性能和学习效果。Note: Simplified Chinese is the standard writing system used in mainland China, and it is different from Traditional Chinese, which is used in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="CLearViD-Curriculum-Learning-for-Video-Description"><a href="#CLearViD-Curriculum-Learning-for-Video-Description" class="headerlink" title="CLearViD: Curriculum Learning for Video Description"></a>CLearViD: Curriculum Learning for Video Description</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04480">http://arxiv.org/abs/2311.04480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yueyue0401/CLV">https://github.com/yueyue0401/CLV</a></li>
<li>paper_authors: Cheng-Yu Chuang, Pooyan Fazli</li>
<li>for: 这 paper 是为了提出一种基于 transformer 的视频描述生成模型，以便自动生成 coherent 的自然语言句子，描述视频的内容。</li>
<li>methods: 这 paper 使用了两种 curriculum 策略：首先，通过逐渐应用 Gaussian 噪声到视频数据来逐渐暴露模型更加困难的样本，其次，通过 dropout 技术逐渐减少网络的容量，以便让模型学习更加稳定和泛化的特征。此外，这 paper 还使用了 Mish 激活函数，该函数提供了非线性和非凸性，帮助解决梯度消失问题。</li>
<li>results: 根据两个 dataset， namely ActivityNet Captions 和 YouCook2，我们的 CLearViD 模型在评价精度和多样性指标上具有显著的优势，与现有的状态数据模型相比， CLearViD 能够更好地描述视频的内容。<details>
<summary>Abstract</summary>
Video description entails automatically generating coherent natural language sentences that narrate the content of a given video. We introduce CLearViD, a transformer-based model for video description generation that leverages curriculum learning to accomplish this task. In particular, we investigate two curriculum strategies: (1) progressively exposing the model to more challenging samples by gradually applying a Gaussian noise to the video data, and (2) gradually reducing the capacity of the network through dropout during the training process. These methods enable the model to learn more robust and generalizable features. Moreover, CLearViD leverages the Mish activation function, which provides non-linearity and non-monotonicity and helps alleviate the issue of vanishing gradients. Our extensive experiments and ablation studies demonstrate the effectiveness of the proposed model. The results on two datasets, namely ActivityNet Captions and YouCook2, show that CLearViD significantly outperforms existing state-of-the-art models in terms of both accuracy and diversity metrics.
</details>
<details>
<summary>摘要</summary>
<SYS>转化文本到简化中文。</SYS>视频描述包括自动生成 coherent 的自然语言句子，描述视频内容。我们介绍 CLearViD，一种基于 transformer 的模型，用于视频描述生成。特别是，我们调查了两种课程策略：（1）逐渐对视频数据应用 Gaussian 噪声，以慢慢地暴露模型更加具有挑战性的样本，以及（2）在训练过程中逐渐减少网络的容量，通过 dropout 来逐渐减少网络的复杂性。这些方法使得模型可以学习更加强健和普适的特征。此外，CLearViD 还使用 Mish 活动函数，该函数提供了非线性和非凸性，帮助解决梯度消失问题。我们进行了广泛的实验和简单化研究，展示了提案的模型的效果。结果在 ActivityNet Captions 和 YouCook2 两个 datasets 上表明，CLearViD 在精度和多样性指标上显著超越了现有的状态机制模型。
</details></li>
</ul>
<hr>
<h2 id="Twitter-Sentiment-Analysis-of-Covid-Vacciness"><a href="#Twitter-Sentiment-Analysis-of-Covid-Vacciness" class="headerlink" title="Twitter Sentiment Analysis of Covid Vacciness"></a>Twitter Sentiment Analysis of Covid Vacciness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04479">http://arxiv.org/abs/2311.04479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenbo Zhu, Tiechuan Hu</li>
<li>for: 这个研究旨在对Twitter上关于COVID-19疫苗的 opinioins进行分类和排名，以便尽可能准确地理解用户对疫苗的看法，并影响用户决策和行为。</li>
<li>methods: 该研究使用自然语言处理技术来分类和排名Twitter上的 opinioins，并使用两种不同的排名策略来评估分类精度。</li>
<li>results: 研究发现，使用自然语言处理技术可以准确地分类和排名Twitter上的 opinioins，并且使用不同的排名策略可以提高分类精度。<details>
<summary>Abstract</summary>
In this paper, we look at a database of tweets sorted by various keywords that could indicate the users sentiment towards covid vaccines. With social media becoming such a prevalent source of opinion, sorting and ranking tweets that hold important information such as opinions on covid vaccines is of utmost importance. Two different ranking scales were used, and ranking a tweet in this way could represent the difference between an opinion being lost and an opinion being featured on the site, which affects the decisions and behavior of people, and why researchers were interested in it. Using natural language processing techniques, our aim is to determine and categorize opinions about covid vaccines with the highest accuracy possible.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了一个关键词汇分类的推特数据库，以便分析用户对 COVID-19 疫苗的看法。随着社交媒体在意见表达方面的普遍性，分类和排名推特中包含有价值信息的 tweet 的重要性日益增加。我们采用了两种不同的排名级别，排名一 tweet 可能代表了意见被排除或者被Site 上特有的意见，这会影响人们的决策和行为，因此研究人员对其很感兴趣。使用自然语言处理技术，我们目标是尽可能准确地确定和分类 COVID-19 疫苗的看法。
</details></li>
</ul>
<hr>
<h2 id="Lewis’s-Signaling-Game-as-beta-VAE-For-Natural-Word-Lengths-and-Segments"><a href="#Lewis’s-Signaling-Game-as-beta-VAE-For-Natural-Word-Lengths-and-Segments" class="headerlink" title="Lewis’s Signaling Game as beta-VAE For Natural Word Lengths and Segments"></a>Lewis’s Signaling Game as beta-VAE For Natural Word Lengths and Segments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04453">http://arxiv.org/abs/2311.04453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryo Ueda, Tadahiro Taniguchi</li>
<li>for: 本研究的目的是使emergent communication（EC）中的通信协议（emergent language）具有自然语言的统计性质。</li>
<li>methods: 本研究使用了beta-VAE重新解释了Lewis的信号游戏（一种常用的EC设定），并重新设定了目标函数为ELBO。</li>
<li>results: 研究发现，选择合适的先验分布可以使emergent language更容易遵循Zipf的压缩法（ZLA）和Harris的词法分析（HAS）。在传统的目标函数下，emergent language并不遵循这两个法则。通过实验，研究证明了这一点。<details>
<summary>Abstract</summary>
As a sub-discipline of evolutionary and computational linguistics, emergent communication (EC) studies communication protocols, called emergent languages, arising in simulations where agents communicate. A key goal of EC is to give rise to languages that share statistical properties with natural languages. In this paper, we reinterpret Lewis's signaling game, a frequently used setting in EC, as beta-VAE and reformulate its objective function as ELBO. Consequently, we clarify the existence of prior distributions of emergent languages and show that the choice of the priors can influence their statistical properties. Specifically, we address the properties of word lengths and segmentation, known as Zipf's law of abbreviation (ZLA) and Harris's articulation scheme (HAS), respectively. It has been reported that the emergent languages do not follow them when using the conventional objective. We experimentally demonstrate that by selecting an appropriate prior distribution, more natural segments emerge, while suggesting that the conventional one prevents the languages from following ZLA and HAS.
</details>
<details>
<summary>摘要</summary>
EC（emergent communication）是一个演化语言和计算语言的子领域，研究在代理人之间进行通信的协议，称为emergent language，并寻求这些语言与自然语言共享统计特征。在这篇论文中，我们将划重点到 Lewis 的信号游戏，这是 EC 中 frequently 使用的设定，并重新解释其目标函数为 ELBO。因此，我们可以明确emergent language的先前分布的存在，并证明选择合适的先前分布可以影响其统计特征。特别是，我们关注word lengths和分 segmentation，即Zipf's law of abbreviation (ZLA)和Harris's articulation scheme (HAS)。据报道，使用传统的目标函数时，emergent language不会遵循这些法律。我们通过实验表明，选择合适的先前分布可以使emergent language更加自然，并建议传统的目标函数阻碍语言遵循ZLA和HAS。
</details></li>
</ul>
<hr>
<h2 id="Recursion-in-Recursion-Two-Level-Nested-Recursion-for-Length-Generalization-with-Scalability"><a href="#Recursion-in-Recursion-Two-Level-Nested-Recursion-for-Length-Generalization-with-Scalability" class="headerlink" title="Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability"></a>Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04449">http://arxiv.org/abs/2311.04449</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jrc1995/beamrecursionfamily">https://github.com/jrc1995/beamrecursionfamily</a></li>
<li>paper_authors: Jishnu Ray Chowdhury, Cornelia Caragea</li>
<li>for: 这篇论文的目的是提出一种新的框架，即嵌套嵌套的回归框架（RIR），以解决深度回归模型在长序列任务上的缺点和中间回归模型在结构敏感任务上的缺点。</li>
<li>methods: 这篇论文使用了一种二重嵌套的回归模型，即外层是一个 $k$-ary 平衡二叉树模型，内层是一个嵌套的回归模型（内层回归）。内层回归使用的是 Beam Tree RvNN（BT-RvNN）。为了调整 BT-RvNN 在 RIR 中，提出了一种新的扩散策略。</li>
<li>results: 作者们的最佳 RIR-based 模型可以在 ListOps 上达到高于 90% 的长度总结束性性能，并且可以在长序列输入上进行训练，而不需要特殊的初始化。此外，在 LRA 语言任务中，这个模型与 Structured State Space Models（SSMs）竞争，并且在长序列输入上表现更好。<details>
<summary>Abstract</summary>
Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according to a preset balanced binary tree structure. Thus, their non-linear recursion depth is just $\log_2 n$ ($n$ being the sequence length). Such logarithmic scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as Long Range Arena (LRA). However, such computational efficiency comes at a cost because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the flip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other structure-sensitive tasks like formal logical inference) are generally several times more expensive than even RNNs. In this paper, we introduce a novel framework -- Recursion in Recursion (RIR) to strike a balance between the two sides - getting some of the benefits from both worlds. In RIR, we use a form of two-level nested recursion - where the outer recursion is a $k$-ary balanced tree model with another recursive model (inner recursion) implementing its cell function. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To adjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment. Overall, this entails that the total recursive depth in RIR is upper-bounded by $k \log_k n$. Our best RIR-based model is the first model that demonstrates high ($\geq 90\%$) length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA. Moreover, in terms of accuracy in the LRA language tasks, it performs competitively with Structured State Space Models (SSMs) without any special initialization - outperforming Transformers by a large margin. On the other hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to length-generalize on ListOps. Our code is available at: \url{https://github.com/JRC1995/BeamRecursionFamily/}.
</details>
<details>
<summary>摘要</summary>
binary 平衡树 RvNNs (BBT-RvNNs) 强制序列组合按照预先设定的平衡二进制树结构进行。因此，它们的非线性循环深度只是 log2 n（n 是序列长度）。这种对数循环深度的扩展使 BBT-RvNNs 在长序列任务上如Long Range Arena (LRA) 中高效并可扩展。然而，这种计算效率的代价是 BBT-RvNNs 无法解决简单的数学任务，如 ListOps。相反，使用 RvNNs（例如 Beam Tree RvNN）可以在 ListOps 和其他结构敏感任务中达到更高的性能，但是它们通常比 RNNs 多出几个数量级。在这篇论文中，我们介绍了一种新的框架---Recursion in Recursion (RIR)，以实现这两个方面之间的平衡。在 RIR 中，我们使用 $k$-ary 平衡树模型，其中另一个嵌入的 Recursive 模型（内嵌 recursion）实现其细胞函数。对于内嵌 recursion，我们选择 Beam Tree RvNNs (BT-RvNN)。为了调整 BT-RvNNs 在 RIR 中，我们还提出了一种新的扩展策略---排队对alignment。总的来说，RIR 的全 recursive depth upper bound 为 $k \log_k n$。我们的最佳 RIR-based 模型可以在 ListOps 上达到长度普遍性（大于 90%）的性能，同时可以在 Long Range Arena (LRA) 中训练长序列输入。此外，在 LRA 语言任务中，它的准确性与 Structured State Space Models (SSMs) 相当，而不需要特殊的初始化。相比之下，SSMs 可以在 LRA 上marginally 超过 RIR，但是它们无法长度普遍化在 ListOps。我们的代码可以在以下链接中找到：\url{https://github.com/JRC1995/BeamRecursionFamily/}。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/cs.CL_2023_11_08/" data-id="clorjzl5f00e3f1883667ce7z" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/08/cs.AI_2023_11_08/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-11-08
        
      </div>
    </a>
  
  
    <a href="/2023/11/08/cs.LG_2023_11_08/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-11-08</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
