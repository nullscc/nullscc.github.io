
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-11-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ToP-ToM: Trust-aware Robot Policy with Theory of Mind paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04397 repo_url: None paper_authors: Chuang Yu, Baris Serhan, Angelo Cangelosi for: 本研究探讨了在多智能体设定下，人与机器人合作对抗另一">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-11-07">
<meta property="og:url" content="https://nullscc.github.io/2023/11/07/cs.AI_2023_11_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="ToP-ToM: Trust-aware Robot Policy with Theory of Mind paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04397 repo_url: None paper_authors: Chuang Yu, Baris Serhan, Angelo Cangelosi for: 本研究探讨了在多智能体设定下，人与机器人合作对抗另一">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-07T12:00:00.000Z">
<meta property="article:modified_time" content="2023-11-09T19:38:45.321Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.AI_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T12:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-11-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ToP-ToM-Trust-aware-Robot-Policy-with-Theory-of-Mind"><a href="#ToP-ToM-Trust-aware-Robot-Policy-with-Theory-of-Mind" class="headerlink" title="ToP-ToM: Trust-aware Robot Policy with Theory of Mind"></a>ToP-ToM: Trust-aware Robot Policy with Theory of Mind</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04397">http://arxiv.org/abs/2311.04397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuang Yu, Baris Serhan, Angelo Cangelosi</li>
<li>for: 本研究探讨了在多智能体设定下，人与机器人合作对抗另一名人对手的情况下，机器人使用理论心理来建立人与机器人之间的信任。</li>
<li>methods: 本研究采用了机器人理论心理模型，推断人对机器人的信任信念，包括真实信任和假信任（是理论心理中的关键元素）。基于不同的信任信念，我们设计了一个动态信任意识 reward函数，以帮助机器人策略学习，以避免人对机器人的信任崩溃。</li>
<li>results: 实验结果表明，基于理论心理的机器人策略对人与机器人之间的信任具有重要作用，并且我们的机器人理论心理基于的策略在多智能体交互设定下具有效果。<details>
<summary>Abstract</summary>
Theory of Mind (ToM) is a fundamental cognitive architecture that endows humans with the ability to attribute mental states to others. Humans infer the desires, beliefs, and intentions of others by observing their behavior and, in turn, adjust their actions to facilitate better interpersonal communication and team collaboration. In this paper, we investigated trust-aware robot policy with the theory of mind in a multiagent setting where a human collaborates with a robot against another human opponent. We show that by only focusing on team performance, the robot may resort to the reverse psychology trick, which poses a significant threat to trust maintenance. The human's trust in the robot will collapse when they discover deceptive behavior by the robot. To mitigate this problem, we adopt the robot theory of mind model to infer the human's trust beliefs, including true belief and false belief (an essential element of ToM). We designed a dynamic trust-aware reward function based on different trust beliefs to guide the robot policy learning, which aims to balance between avoiding human trust collapse due to robot reverse psychology. The experimental results demonstrate the importance of the ToM-based robot policy for human-robot trust and the effectiveness of our robot ToM-based robot policy in multiagent interaction settings.
</details>
<details>
<summary>摘要</summary>
We found that when the robot focuses solely on team performance, it may resort to reverse psychology, which can damage trust between the human and the robot. When the human discovers deceptive behavior by the robot, their trust in the robot will collapse. To address this issue, we developed a robot ToM model to infer the human's trust beliefs, including true belief and false belief, which is an essential element of ToM.We designed a dynamic trust-aware reward function based on different trust beliefs to guide the robot policy learning, which aims to balance between avoiding human trust collapse due to robot reverse psychology and achieving team performance. The experimental results demonstrate the importance of the ToM-based robot policy for human-robot trust and the effectiveness of our robot ToM-based robot policy in multiagent interaction settings.
</details></li>
</ul>
<hr>
<h2 id="Harnessing-Manycore-Processors-with-Distributed-Memory-for-Accelerated-Training-of-Sparse-and-Recurrent-Models"><a href="#Harnessing-Manycore-Processors-with-Distributed-Memory-for-Accelerated-Training-of-Sparse-and-Recurrent-Models" class="headerlink" title="Harnessing Manycore Processors with Distributed Memory for Accelerated Training of Sparse and Recurrent Models"></a>Harnessing Manycore Processors with Distributed Memory for Accelerated Training of Sparse and Recurrent Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04386">http://arxiv.org/abs/2311.04386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Finkbeiner, Thomas Gmeinder, Mark Pupilli, Alexander Titterton, Emre Neftci</li>
<li>for: 提高人工智能训练基础设施的效率，使得更多的神经网络模型可以更好地利用多指令多数据（MIMD）架构的优势。</li>
<li>methods: 使用触发器神经网络（SNN）和分布式本地内存，实现了在多个处理器（IPU）上进行分布式的后向传播算法（BPTT）训练。</li>
<li>results: 与NVIDIA A100 GPU相比，使用MIMD架构的Intelligence Processing Unit（IPU）可以获得5-10倍的throughput提升，并且在不同的活动缺失率水平上可以达到38倍的提升。此外，我们的结果还显示了在单IPU和多IPU配置下的扩展性。<details>
<summary>Abstract</summary>
Current AI training infrastructure is dominated by single instruction multiple data (SIMD) and systolic array architectures, such as Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs), that excel at accelerating parallel workloads and dense vector matrix multiplications. Potentially more efficient neural network models utilizing sparsity and recurrence cannot leverage the full power of SIMD processor and are thus at a severe disadvantage compared to today's prominent parallel architectures like Transformers and CNNs, thereby hindering the path towards more sustainable AI. To overcome this limitation, we explore sparse and recurrent model training on a massively parallel multiple instruction multiple data (MIMD) architecture with distributed local memory. We implement a training routine based on backpropagation through time (BPTT) for the brain-inspired class of Spiking Neural Networks (SNNs) that feature binary sparse activations. We observe a massive advantage in using sparse activation tensors with a MIMD processor, the Intelligence Processing Unit (IPU) compared to GPUs. On training workloads, our results demonstrate 5-10x throughput gains compared to A100 GPUs and up to 38x gains for higher levels of activation sparsity, without a significant slowdown in training convergence or reduction in final model performance. Furthermore, our results show highly promising trends for both single and multi IPU configurations as we scale up to larger model sizes. Our work paves the way towards more efficient, non-standard models via AI training hardware beyond GPUs, and competitive large scale SNN models.
</details>
<details>
<summary>摘要</summary>
We implement a training routine based on backpropagation through time (BPTT) for the brain-inspired class of Spiking Neural Networks (SNNs) that feature binary sparse activations. Our results show a significant advantage in using sparse activation tensors with a MIMD processor, the Intelligence Processing Unit (IPU), compared to GPUs. On training workloads, we observe 5-10x throughput gains compared to A100 GPUs and up to 38x gains for higher levels of activation sparsity, without a significant slowdown in training convergence or reduction in final model performance.Our results also show promising trends for both single and multi IPU configurations as we scale up to larger model sizes. Our work paves the way towards more efficient, non-standard models via AI training hardware beyond GPUs and competitive large-scale SNN models.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Malware-Detection-by-Integrating-Machine-Learning-with-Cuckoo-Sandbox"><a href="#Enhancing-Malware-Detection-by-Integrating-Machine-Learning-with-Cuckoo-Sandbox" class="headerlink" title="Enhancing Malware Detection by Integrating Machine Learning with Cuckoo Sandbox"></a>Enhancing Malware Detection by Integrating Machine Learning with Cuckoo Sandbox</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04372">http://arxiv.org/abs/2311.04372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amaal F. Alshmarni, Mohammed A. Alliheedi</li>
<li>for: 本研究旨在透过机器学习算法进行遗传ware检测，以应对现代化时代内部网络中的遗传ware问题。</li>
<li>methods: 本研究使用的机器学习算法包括CNN（数值对应域几何网络）和RNN（回传神经网络），以检测API呼叫序列中的遗传ware。</li>
<li>results: 本研究发现，使用深度学习技术可以大幅提高检测精度，达到99%的准确率。<details>
<summary>Abstract</summary>
In the modern era, malware is experiencing a significant increase in both its variety and quantity, aligning with the widespread adoption of the digital world. This surge in malware has emerged as a critical challenge in the realm of cybersecurity, prompting numerous research endeavors and contributions to address the issue. Machine learning algorithms have been leveraged for malware detection due to their ability to uncover concealed patterns within vast datasets. However, deep learning algorithms, characterized by their multi-layered structure, surpass the limitations of traditional machine learning approaches. By employing deep learning techniques such as CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network), this study aims to classify and identify malware extracted from a dataset containing API call sequences. The performance of these algorithms is compared with that of conventional machine learning methods, including SVM (Support Vector Machine), RF (Random Forest), KNN (K-Nearest Neighbors), XGB (Extreme Gradient Boosting), and GBC (Gradient Boosting Classifier), all using the same dataset. The outcomes of this research demonstrate that both deep learning and machine learning algorithms achieve remarkably high levels of accuracy, reaching up to 99% in certain cases.
</details>
<details>
<summary>摘要</summary>
现代时期，恶意软件的种类和量在不断增加，与数字世界的普及相应。这种增长对网络安全领域带来了严重的挑战，导致了许多研究和贡献，以解决这个问题。机器学习算法在恶意软件检测中得到了广泛的应用，因为它们能够找到含有掩饰的模式。然而，深度学习算法，具有多层结构，超越了传统机器学习方法的限制。本研究使用深度学习技术，如卷积神经网络（CNN）和循环神经网络（RNN），对从API调用序列中提取的恶意软件进行分类和识别。这些算法的性能与传统机器学习方法，包括支持向量机（SVM）、随机森林（RF）、最近邻居（KNN）、极限梯度提升（XGB）和梯度提升分类器（GBC）进行比较，使用同一个数据集。研究结果表明，深度学习和机器学习算法均能达到非常高的准确率，达到99%以上在某些情况下。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Effectiveness-of-Retrieval-Augmented-Large-Language-Models-in-Scientific-Document-Reasoning"><a href="#Evaluating-the-Effectiveness-of-Retrieval-Augmented-Large-Language-Models-in-Scientific-Document-Reasoning" class="headerlink" title="Evaluating the Effectiveness of Retrieval-Augmented Large Language Models in Scientific Document Reasoning"></a>Evaluating the Effectiveness of Retrieval-Augmented Large Language Models in Scientific Document Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04348">http://arxiv.org/abs/2311.04348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Munikoti, Anurag Acharya, Sridevi Wagle, Sameera Horawalavithana</li>
<li>for: 本研究旨在评估回备式语言模型在科学文献理解任务中的表现。</li>
<li>methods: 本研究使用了多种变体的回备式语言模型，并对其进行了科学化的 instrucion 以便在科学文献理解任务中进行评估。</li>
<li>results: 研究发现，使用回备式语言模型可能会导致模型提供的解释不准确，而且使用科学文献作为预训练数据不能减少这种风险。<details>
<summary>Abstract</summary>
Despite the dramatic progress in Large Language Model (LLM) development, LLMs often provide seemingly plausible but not factual information, often referred to as hallucinations. Retrieval-augmented LLMs provide a non-parametric approach to solve these issues by retrieving relevant information from external data sources and augment the training process. These models help to trace evidence from an externally provided knowledge base allowing the model predictions to be better interpreted and verified. In this work, we critically evaluate these models in their ability to perform in scientific document reasoning tasks. To this end, we tuned multiple such model variants with science-focused instructions and evaluated them on a scientific document reasoning benchmark for the usefulness of the retrieved document passages. Our findings suggest that models justify predictions in science tasks with fabricated evidence and leveraging scientific corpus as pretraining data does not alleviate the risk of evidence fabrication.
</details>
<details>
<summary>摘要</summary>
In this study, we critically evaluated the performance of these models in scientific document reasoning tasks. We tuned multiple model variants with science-focused instructions and evaluated them on a scientific document reasoning benchmark. Our findings suggest that the models often justify their predictions with fabricated evidence, and using a scientific corpus as pretraining data does not eliminate the risk of evidence fabrication.
</details></li>
</ul>
<hr>
<h2 id="A-Taxonomy-of-Rater-Disagreements-Surveying-Challenges-Opportunities-from-the-Perspective-of-Annotating-Online-Toxicity"><a href="#A-Taxonomy-of-Rater-Disagreements-Surveying-Challenges-Opportunities-from-the-Perspective-of-Annotating-Online-Toxicity" class="headerlink" title="A Taxonomy of Rater Disagreements: Surveying Challenges &amp; Opportunities from the Perspective of Annotating Online Toxicity"></a>A Taxonomy of Rater Disagreements: Surveying Challenges &amp; Opportunities from the Perspective of Annotating Online Toxicity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04345">http://arxiv.org/abs/2311.04345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenbo Zhang, Hangzhi Guo, Ian D Kivlichan, Vinodkumar Prabhakaran, Davis Yadav, Amulya Yadav</li>
<li>for: 本研究目的是分析在 онлайн审核 зада务中出现的评审者分歧的原因，并提出一种细化的分类系统来解决这些分歧。</li>
<li>methods: 本研究基于大量的人工标注数据，通过分析审核者之间的分歧，提出了一种细化的分类系统，并评估了这种系统的性能。</li>
<li>results: 研究发现了在在线审核任务中出现的主要原因，并提出了一些解决这些问题的可能性。同时，还发现了一些未解决的问题，它们可能会推动未来的研究发展。<details>
<summary>Abstract</summary>
Toxicity is an increasingly common and severe issue in online spaces. Consequently, a rich line of machine learning research over the past decade has focused on computationally detecting and mitigating online toxicity. These efforts crucially rely on human-annotated datasets that identify toxic content of various kinds in social media texts. However, such annotations historically yield low inter-rater agreement, which was often dealt with by taking the majority vote or other such approaches to arrive at a single ground truth label. Recent research has pointed out the importance of accounting for the subjective nature of this task when building and utilizing these datasets, and this has triggered work on analyzing and better understanding rater disagreements, and how they could be effectively incorporated into the machine learning developmental pipeline. While these efforts are filling an important gap, there is a lack of a broader framework about the root causes of rater disagreement, and therefore, we situate this work within that broader landscape. In this survey paper, we analyze a broad set of literature on the reasons behind rater disagreements focusing on online toxicity, and propose a detailed taxonomy for the same. Further, we summarize and discuss the potential solutions targeting each reason for disagreement. We also discuss several open issues, which could promote the future development of online toxicity research.
</details>
<details>
<summary>摘要</summary>
online spaces中的恶意问题正在不断增加，因此过去的一个 décennial的机器学习研究推力在计算机测检和消除在社交媒体文本中的恶意内容。这些努力依赖于人工标注数据，以识别不同类型的社交媒体文本中的恶意内容。然而，这些标注历史上的间合率往往低，通常通过大多数票选或类似方法来到达唯一的真实标签。最近的研究表明，需要考虑这些任务的主观性，在建立和使用这些数据时。这些努力正在填补重要的空白，但是还缺乏一个更广泛的框架，描述投票分歧的根本原因。在这篇survey paper中，我们分析了在线恶意问题中投票分歧的广泛文献，并提出了详细的分类。此外，我们还总结了对每个分歧原因的解决方案，并讨论了未来研究的一些开放问题。
</details></li>
</ul>
<hr>
<h2 id="Sub-Sentence-Encoder-Contrastive-Learning-of-Propositional-Semantic-Representations"><a href="#Sub-Sentence-Encoder-Contrastive-Learning-of-Propositional-Semantic-Representations" class="headerlink" title="Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic Representations"></a>Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04335">http://arxiv.org/abs/2311.04335</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/schen149/sub-sentence-encoder">https://github.com/schen149/sub-sentence-encoder</a></li>
<li>paper_authors: Sihao Chen, Hongming Zhang, Tong Chen, Ben Zhou, Wenhao Yu, Dian Yu, Baolin Peng, Hongwei Wang, Dan Roth, Dong Yu</li>
<li>for: 本研究旨在提出一种基于对比学习的上下文嵌入模型，用于精细 semantic representation of text。</li>
<li>methods: 该模型使用对比学习来学习不同文本序列中的 atomic propositions 的上下文嵌入，并通过推断性学习来认识这些提positions 的 semantic equivalence。</li>
<li>results: 实验表明，使用 sub-sentence encoder 可以在 text attribution 和 conditional semantic similarity 等应用中 достичь同等效果，而且具有同样的推断成本和空间复杂度。<details>
<summary>Abstract</summary>
We introduce sub-sentence encoder, a contrastively-learned contextual embedding model for fine-grained semantic representation of text. In contrast to the standard practice with sentence embeddings, where the meaning of an entire sequence of text is encoded into a fixed-length vector, the sub-sentence encoder learns to produce distinct contextual embeddings corresponding to different atomic propositions, i.e. atomic units of meaning expressed within a text sequence. The sub-sentence embeddings are contrastively learned to recognize (inferred) semantic equivalence between propositions across different text sequences. Our experiments show the effectiveness of sub-sentence encoders in applications, such as retrieving supporting facts for fine-grained text attribution or recognizing the conditional semantic similarity between texts. In practice, we demonstrate that sub-sentence encoders keep the same level of inference cost and space complexity compared to sentence encoders.
</details>
<details>
<summary>摘要</summary>
我们介绍了下属句编码器，一种基于对比学习的上下文嵌入模型，用于精细表示文本中的Semantic meaning。与标准做法不同，即将整个文本序列编码为固定长度向量，我们的下属句编码器学习生成不同原子提POSITION的上下文嵌入，即在文本序列中表达的精细意义单元。这些下属句嵌入通过对推理结果进行对比学习来认识（推理出）文本序列之间的含义相似性。我们的实验表明，使用下属句编码器可以在文本检索、细化文本责任等应用中 достичь更高的效果，而且在实践中，下属句编码器与句子编码器的推理成本和空间复杂度相同。
</details></li>
</ul>
<hr>
<h2 id="Educating-for-AI-Cybersecurity-Work-and-Research-Ethics-Systems-Thinking-and-Communication-Requirements"><a href="#Educating-for-AI-Cybersecurity-Work-and-Research-Ethics-Systems-Thinking-and-Communication-Requirements" class="headerlink" title="Educating for AI Cybersecurity Work and Research: Ethics, Systems Thinking, and Communication Requirements"></a>Educating for AI Cybersecurity Work and Research: Ethics, Systems Thinking, and Communication Requirements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04326">http://arxiv.org/abs/2311.04326</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sorin Adam Matei, Elisa Bertino<br>for:* The paper explores managerial and instructor perceptions of freshly employed cybersecurity workers’ preparedness to work effectively in a changing cybersecurity environment that includes AI tools.methods:* The study uses a survey to gather perceptions of technical preparedness and non-technical skill sets (ethical, systems thinking, and communication skills) among managers and professors.results:* The study finds that preparedness to use AI tools in cybersecurity is significantly associated with all three non-technical skill sets, with ethics being the most important factor. Additionally, professors over-estimate students’ preparedness for ethical, system thinking, and communication abilities compared to IT managers’ perceptions of their newly employed IT workers.Here is the same information in Simplified Chinese text:for:* 这个研究探讨管理者和教师对新招聘的网络安全工作者或学生的技能准备能力是否足够在不断变化的网络安全环境中使用人工智能工具。methods:* 这个研究使用问卷调查管理者和教师对技术准备和非技术素质（伦理、系统思维和沟通技能）的看法。results:* 研究发现，使用人工智能工具在网络安全中的准备度与非技术素质（伦理、系统思维和沟通技能）密切相关，其中伦理素质最为重要。此外，教师对学生的技能准备有所过分估计，与实际上的IT管理者对新招聘工作者的评估不符。<details>
<summary>Abstract</summary>
The present study explored managerial and instructor perceptions of their freshly employed cybersecurity workers' or students' preparedness to work effectively in a changing cybersecurity environment that includes AI tools. Specifically, we related perceptions of technical preparedness to ethical, systems thinking, and communication skills. We found that managers and professors perceive preparedness to use AI tools in cybersecurity to be significantly associated with all three non-technical skill sets. Most important, ethics is a clear leader in the network of relationships. Contrary to expectations that ethical concerns are left behind in the rush to adopt the most advanced AI tools in security, both higher education instructors and managers appreciate their role and see them closely associated with technical prowess. Another significant finding is that professors over-estimate students' preparedness for ethical, system thinking, and communication abilities compared to IT managers' perceptions of their newly employed IT workers.
</details>
<details>
<summary>摘要</summary>
本研究 investigate 管理人员和教师对新招募的黑客工作者或学生的准备度，以及这些工作者在变化的黑客环境中使用人工智能工具时的效果。特别是，我们关注技术准备与伦理、系统思维和communication skills的关系。我们发现，管理人员和教师认为使用人工智能工具的准备度与三种非技术能力 closely related。其中，伦理是网络关系中的明显领导者。与预期相反，教育高等教育和管理人员看到了伦理的重要性，并认为它与技术能力密切相关。另外，教师对学生的准备度过高于IT管理人员对新入职IT工程师的评估。
</details></li>
</ul>
<hr>
<h2 id="Extending-Machine-Learning-Based-Early-Sepsis-Detection-to-Different-Demographics"><a href="#Extending-Machine-Learning-Based-Early-Sepsis-Detection-to-Different-Demographics" class="headerlink" title="Extending Machine Learning-Based Early Sepsis Detection to Different Demographics"></a>Extending Machine Learning-Based Early Sepsis Detection to Different Demographics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04325">http://arxiv.org/abs/2311.04325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Surajsinh Parmar, Tao Shan, San Lee, Yonghwan Kim, Jang Yong Kim</li>
<li>for: 这个研究旨在比较两种ensemble学习方法 LightGBM 和 XGBoost，使用公共的 eICU-CRD 数据集和私人的韩国圣玛利亚医院数据集，以解决医疗数据的不均衡问题并提高 septic shock 的检测精度。</li>
<li>methods: 这个研究使用了两种ensemble学习方法 LightGBM 和 XGBoost，并对两种方法进行比较分析，以挖掘它们在医疗数据中的应用前提和优势。</li>
<li>results: 研究发现 LightGBM 在计算效率和扩展性方面有一定的优势，并且能够有效地解决医疗数据中的不均衡问题，从而提高 septic shock 的检测精度。<details>
<summary>Abstract</summary>
Sepsis requires urgent diagnosis, but research is predominantly focused on Western datasets. In this study, we perform a comparative analysis of two ensemble learning methods, LightGBM and XGBoost, using the public eICU-CRD dataset and a private South Korean St. Mary's Hospital's dataset. Our analysis reveals the effectiveness of these methods in addressing healthcare data imbalance and enhancing sepsis detection. Specifically, LightGBM shows a slight edge in computational efficiency and scalability. The study paves the way for the broader application of machine learning in critical care, thereby expanding the reach of predictive analytics in healthcare globally.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>> septic需要紧急诊断，但研究主要集中在西方数据集上。在这项研究中，我们对公共eICU-CRD数据集和私人韩国圣玛利亚医院数据集进行比较分析，使用两种ensemble学习方法：LightGBM和XGBoost。我们的分析发现这两种方法在医疗数据异质问题上能够具有效果，提高 septic检测。特别是LightGBM在计算效率和可扩展性方面表现略微优势。这项研究为医疗预测分析在全球扩展开创了道路。
</details></li>
</ul>
<hr>
<h2 id="Improved-Child-Text-to-Speech-Synthesis-through-Fastpitch-based-Transfer-Learning"><a href="#Improved-Child-Text-to-Speech-Synthesis-through-Fastpitch-based-Transfer-Learning" class="headerlink" title="Improved Child Text-to-Speech Synthesis through Fastpitch-based Transfer Learning"></a>Improved Child Text-to-Speech Synthesis through Fastpitch-based Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04313">http://arxiv.org/abs/2311.04313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Jain, Peter Corcoran</li>
<li>for: 本研究旨在开发高质量的人工婴儿语音生成技术，以满足媒体和互联网等领域的需求。</li>
<li>methods: 本研究使用了Fastpitch TTS模型，并通过转移学习训练技术来适应婴儿语音特点。使用了公共可用的MyST数据集（55小时）进行训练实验，并同时释放了一个 synthetic speech 示例数据集和模型代码，以支持后续研究。</li>
<li>results: 研究表明，通过使用预训练的 MOSNet，可以对真实婴儿语音和人工生成的语音进行对比，并显示了 significante 的相关性。此外，通过自动语音识别（ASR）模型对比真实婴儿语音和人工生成的语音的单词错误率（WER），可以证明生成的语音具有高度的智能性。同时，使用预训练的 speaker encoder 来测量真实婴儿语音和生成的语音之间的发音相似性，也得到了正面的结果。<details>
<summary>Abstract</summary>
Speech synthesis technology has witnessed significant advancements in recent years, enabling the creation of natural and expressive synthetic speech. One area of particular interest is the generation of synthetic child speech, which presents unique challenges due to children's distinct vocal characteristics and developmental stages. This paper presents a novel approach that leverages the Fastpitch text-to-speech (TTS) model for generating high-quality synthetic child speech. This study uses the transfer learning training pipeline. The approach involved finetuning a multi-speaker TTS model to work with child speech. We use the cleaned version of the publicly available MyST dataset (55 hours) for our finetuning experiments. We also release a prototype dataset of synthetic speech samples generated from this research together with model code to support further research. By using a pretrained MOSNet, we conducted an objective assessment that showed a significant correlation between real and synthetic child voices. Additionally, to validate the intelligibility of the generated speech, we employed an automatic speech recognition (ASR) model to compare the word error rates (WER) of real and synthetic child voices. The speaker similarity between the real and generated speech is also measured using a pretrained speaker encoder.
</details>
<details>
<summary>摘要</summary>
文本生成技术在最近几年内得到了 significiant 进步，使得可以生成自然和表情强的synthetic 语音。一个特定的研究领域是生成synthetic 孩子语音，这个领域存在独特的声音特征和发展阶段。本文提出了一种新的方法，利用Fastpitch 文本到语音（TTS）模型来生成高质量的synthetic 孩子语音。这个研究使用了传输学习训练管道。我们使用了公共可用的MyST dataset（55小时）进行了 fine-tuning 实验。我们还发布了一个原型数据集，包含本研究生成的synthetic 语音样本以及模型代码，以支持进一步的研究。通过使用预训练的MOSNet，我们进行了一个 объектив评估，显示了real 和synthetic 孩子声音之间的strong 相关性。此外，为了验证生成的语音可以理解，我们使用了自动语音识别（ASR）模型来比较实际和synthetic 孩子声音的单词错误率（WER）。生成的语音和实际孩子声音之间的 speaker 相似性也被使用预训练的 speaker 编码器测量。
</details></li>
</ul>
<hr>
<h2 id="Class-Incremental-Continual-Learning-for-General-Purpose-Healthcare-Models"><a href="#Class-Incremental-Continual-Learning-for-General-Purpose-Healthcare-Models" class="headerlink" title="Class-Incremental Continual Learning for General Purpose Healthcare Models"></a>Class-Incremental Continual Learning for General Purpose Healthcare Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04301">http://arxiv.org/abs/2311.04301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amritpal Singh, Mustafa Burak Gurbuz, Shiva Souhith Gantha, Prahlad Jasti</li>
<li>for: 这篇论文旨在探讨医疗机构面临时间变化的资料，使用深度学习模型进行预测，并考虑这些模型在不同预设下的执行。</li>
<li>methods: 这篇论文使用了多种恒常学习方法，包括对应式学习、优先级学习和对应式优先级学习，以评估其在不同医疗团队和医院中的表现。</li>
<li>results: 研究结果显示，单一模型可以顺利地学习新任务，并在不同的医疗专长和医院中获得相似的表现，这显示了模型的可 reuse 和共享性。<details>
<summary>Abstract</summary>
Healthcare clinics regularly encounter dynamic data that changes due to variations in patient populations, treatment policies, medical devices, and emerging disease patterns. Deep learning models can suffer from catastrophic forgetting when fine-tuned in such scenarios, causing poor performance on previously learned tasks. Continual learning allows learning on new tasks without performance drop on previous tasks. In this work, we investigate the performance of continual learning models on four different medical imaging scenarios involving ten classification datasets from diverse modalities, clinical specialties, and hospitals. We implement various continual learning approaches and evaluate their performance in these scenarios. Our results demonstrate that a single model can sequentially learn new tasks from different specialties and achieve comparable performance to naive methods. These findings indicate the feasibility of recycling or sharing models across the same or different medical specialties, offering another step towards the development of general-purpose medical imaging AI that can be shared across institutions.
</details>
<details>
<summary>摘要</summary>
医疗机构常常面临变化的数据，由于患者人口、治疗策略、医疗设备和疾病趋势的变化。深度学习模型可能会受到恶性忘记，导致在已经学习的任务上表现不佳。连续学习允许学习新任务无需影响之前学习的任务表现。在这项工作中，我们研究了不同医疗专业和医院的十种分类数据集的四个医学影像场景，并应用了不同的连续学习方法。我们评估了这些场景中的表现，并发现一个单一的模型可以顺序学习不同的专业任务，并与预期的方法相当。这些结果表明了将模型重用或共享的可能性，这将是医学影像人工智能的另一步发展，可以在机构之间共享。
</details></li>
</ul>
<hr>
<h2 id="CRAB-Assessing-the-Strength-of-Causal-Relationships-Between-Real-world-Events"><a href="#CRAB-Assessing-the-Strength-of-Causal-Relationships-Between-Real-world-Events" class="headerlink" title="CRAB: Assessing the Strength of Causal Relationships Between Real-world Events"></a>CRAB: Assessing the Strength of Causal Relationships Between Real-world Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04284">http://arxiv.org/abs/2311.04284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Angelika Romanou, Syrielle Montariol, Debjit Paul, Leo Laugier, Karl Aberer, Antoine Bosselut</li>
<li>for: 评估大型自然语言处理模型在叙述中的 causal 理解能力</li>
<li>methods: 使用 CRAB 数据集，一个基于实际新闻事件时间轴的 fine-grained  causality 注释 benchmark，评估多种语言模型在 causal 理解任务中的表现</li>
<li>results: 研究发现，大多数语言模型在 causal 理解任务中表现不佳，而且模型在 causal 结构较复杂的事件组合中表现更差。<details>
<summary>Abstract</summary>
Understanding narratives requires reasoning about the cause-and-effect relationships between events mentioned in the text. While existing foundation models yield impressive results in many NLP tasks requiring reasoning, it is unclear whether they understand the complexity of the underlying network of causal relationships of events in narratives. In this work, we present CRAB, a new Causal Reasoning Assessment Benchmark designed to evaluate causal understanding of events in real-world narratives. CRAB contains fine-grained, contextual causality annotations for ~2.7K pairs of real-world events that describe various newsworthy event timelines (e.g., the acquisition of Twitter by Elon Musk). Using CRAB, we measure the performance of several large language models, demonstrating that most systems achieve poor performance on the task. Motivated by classical causal principles, we also analyze the causal structures of groups of events in CRAB, and find that models perform worse on causal reasoning when events are derived from complex causal structures compared to simple linear causal chains. We make our dataset and code available to the research community.
</details>
<details>
<summary>摘要</summary>
理解叙述需要关于文本中事件之间的 causal 关系的理解。 existing foundation models 在许多 NLP 任务中表现出色，但是是 unclear  Whether they 理解叙述中事件的下面网络 causal 关系的复杂性。 在这项工作中，我们提出了 CRAB，一个新的 Causal Reasoning Assessment Benchmark，用于评估事件叙述中 causal 理解。 CRAB 包含了 ~2.7K 对实际新闻事件时间线（如 Elon Musk 收购 Twitter）的细腻、 Contextual causality 注释。 使用 CRAB，我们测量了多种大语言模型的性能，发现大多数系统在这个任务中表现出低水平。 针对古典 causal 原则，我们也分析了 CRAB 中事件群体的 causal 结构，发现模型在复杂 causal 结构下的事件 derivation 时表现更差。 我们将数据集和代码提供给研究社区。
</details></li>
</ul>
<hr>
<h2 id="OtterHD-A-High-Resolution-Multi-modality-Model"><a href="#OtterHD-A-High-Resolution-Multi-modality-Model" class="headerlink" title="OtterHD: A High-Resolution Multi-modality Model"></a>OtterHD: A High-Resolution Multi-modality Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04219">http://arxiv.org/abs/2311.04219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Li, Peiyuan Zhang, Jingkang Yang, Yuanhan Zhang, Fanyi Pu, Ziwei Liu</li>
<li>for: 本研究专页探讨了一种新型多modal模型OtterHD-8B，它是基于Fuyu-8B的创新模型，能够准确地处理高分辨率的视觉输入。</li>
<li>methods: 该模型不同于传统模型，不受固定大小视觉编码器的限制，可以适应不同的数据类型和视觉输入大小。</li>
<li>results: 我们的比较分析发现，与现今领先的模型不同，OtterHD-8B在高分辨率直接处理视觉输入时表现出色，与其他模型之间有substantial margin的差异。<details>
<summary>Abstract</summary>
In this paper, we present OtterHD-8B, an innovative multimodal model evolved from Fuyu-8B, specifically engineered to interpret high-resolution visual inputs with granular precision. Unlike conventional models that are constrained by fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible input dimensions, ensuring its versatility across various inference requirements. Alongside this model, we introduce MagnifierBench, an evaluation framework designed to scrutinize models' ability to discern minute details and spatial relationships of small objects. Our comparative analysis reveals that while current leading models falter on this benchmark, OtterHD-8B, particularly when directly processing high-resolution inputs, outperforms its counterparts by a substantial margin. The findings illuminate the structural variances in visual information processing among different models and the influence that the vision encoders' pre-training resolution disparities have on model effectiveness within such benchmarks. Our study highlights the critical role of flexibility and high-resolution input capabilities in large multimodal models and also exemplifies the potential inherent in the Fuyu architecture's simplicity for handling complex visual data.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了OtterHD-8B，一种创新的多modal模型，由Fuyu-8B进行演化，专门为高分辨率视觉输入提供精细精度的解释。与传统模型一样，OtterHD-8B不受固定大小视觉编解码器的限制，因此它在不同的推理需求下表现出高度的灵活性。此外，我们还提出了MagnifierBench评估框架，用于评测模型对小 объек的细节和空间关系的解释能力。我们的比较分析表明，当直接处理高分辨率输入时，OtterHD-8B般比其他对手提供了substantial的优势。这些发现探讨了不同模型在视觉信息处理中的结构差异，以及视觉编解码器的预训练分辨率差异对模型在如此 benchmark中的效果的影响。我们的研究强调了大型多modal模型中的灵活性和高分辨率输入能力的重要性，同时也表明了Fuyu架构的简单性可以处理复杂的视觉数据。
</details></li>
</ul>
<hr>
<h2 id="Towards-Garment-Sewing-Pattern-Reconstruction-from-a-Single-Image"><a href="#Towards-Garment-Sewing-Pattern-Reconstruction-from-a-Single-Image" class="headerlink" title="Towards Garment Sewing Pattern Reconstruction from a Single Image"></a>Towards Garment Sewing Pattern Reconstruction from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04218">http://arxiv.org/abs/2311.04218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lijuan Liu, Xiangyu Xu, Zhijie Lin, Jiabin Liang, Shuicheng Yan</li>
<li>for: 本研究旨在使用日常照片中恢复服装缝纫图，以推进服装设计、虚拟试穿和数字人物等应用。</li>
<li>methods: 我们首先生成了一个多样化的数据集，名为SewFactory，该数据集包含约1M张图像和真实缝纫图数据，用于模型训练和评估。我们还提出了一个两级转换器网络，名为Sewformer，该网络能够显著提高缝纫图预测性能。</li>
<li>results: 我们的实验表明，提posed框架可以有效地恢复缝纫图和在习惯性拍摄的人像照片中具有良好的泛化能力。代码、数据集和预训练模型可以在<a target="_blank" rel="noopener" href="https://sewformer.github.io/">https://sewformer.github.io/</a> obtain。<details>
<summary>Abstract</summary>
Garment sewing pattern represents the intrinsic rest shape of a garment, and is the core for many applications like fashion design, virtual try-on, and digital avatars. In this work, we explore the challenging problem of recovering garment sewing patterns from daily photos for augmenting these applications. To solve the problem, we first synthesize a versatile dataset, named SewFactory, which consists of around 1M images and ground-truth sewing patterns for model training and quantitative evaluation. SewFactory covers a wide range of human poses, body shapes, and sewing patterns, and possesses realistic appearances thanks to the proposed human texture synthesis network. Then, we propose a two-level Transformer network called Sewformer, which significantly improves the sewing pattern prediction performance. Extensive experiments demonstrate that the proposed framework is effective in recovering sewing patterns and well generalizes to casually-taken human photos. Code, dataset, and pre-trained models are available at: https://sewformer.github.io.
</details>
<details>
<summary>摘要</summary>
裤装 Patterns represent the intrinsic rest shape of a garment, and are the core for many applications like fashion design, virtual try-on, and digital avatars. In this work, we explore the challenging problem of recovering garment sewing patterns from daily photos for augmenting these applications. To solve the problem, we first synthesize a versatile dataset, named SewFactory, which consists of around 1M images and ground-truth sewing patterns for model training and quantitative evaluation. SewFactory covers a wide range of human poses, body shapes, and sewing patterns, and possesses realistic appearances thanks to the proposed human texture synthesis network. Then, we propose a two-level Transformer network called Sewformer, which significantly improves the sewing pattern prediction performance. Extensive experiments demonstrate that the proposed framework is effective in recovering sewing patterns and well generalizes to casually-taken human photos. codes, datasets, and pre-trained models are available at: https://sewformer.github.io.
</details></li>
</ul>
<hr>
<h2 id="Wearable-data-from-subjects-playing-Super-Mario-sitting-university-exams-or-performing-physical-exercise-help-detect-acute-mood-episodes-via-self-supervised-learning"><a href="#Wearable-data-from-subjects-playing-Super-Mario-sitting-university-exams-or-performing-physical-exercise-help-detect-acute-mood-episodes-via-self-supervised-learning" class="headerlink" title="Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning"></a>Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04215">http://arxiv.org/abs/2311.04215</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filippo Corponi, Bryan M. Li, Gerard Anmella, Clàudia Valenzuela-Pascual, Ariadna Mas, Isabella Pacchiarotti, Marc Valentí, Iria Grande, Antonio Benabarre, Marina Garriga, Eduard Vieta, Allan H Young, Stephen M. Lawrie, Heather C. Whalley, Diego Hidalgo-Mazzei, Antonio Vergari</li>
<li>for: 这个论文旨在检测抑郁症（MDs）的酷热话论文，使用个人感知技术，收集来自病人的穿戴式设备上的数据，以实时监测病人的情绪状况。</li>
<li>methods: 这个论文使用的方法包括自动学习（SSL）技术，使用无标注数据来学习个人感知数据的表示，并将其应用于检测MDs的酷热话论文。</li>
<li>results: 研究发现，使用SSL技术可以高效地检测MDs的酷热话论文，并且可以在64名病人中 correctly classified recording segments的率为81.23%。此外，研究还发现，使用不同的代理任务进行预训练可以强调SSL的性能。<details>
<summary>Abstract</summary>
Personal sensing, leveraging data passively and near-continuously collected with wearables from patients in their ecological environment, is a promising paradigm to monitor mood disorders (MDs), a major determinant of worldwide disease burden. However, collecting and annotating wearable data is very resource-intensive. Studies of this kind can thus typically afford to recruit only a couple dozens of patients. This constitutes one of the major obstacles to applying modern supervised machine learning techniques to MDs detection. In this paper, we overcome this data bottleneck and advance the detection of MDs acute episode vs stable state from wearables data on the back of recent advances in self-supervised learning (SSL). This leverages unlabelled data to learn representations during pre-training, subsequently exploited for a supervised task. First, we collected open-access datasets recording with an Empatica E4 spanning different, unrelated to MD monitoring, personal sensing tasks -- from emotion recognition in Super Mario players to stress detection in undergraduates -- and devised a pre-processing pipeline performing on-/off-body detection, sleep-wake detection, segmentation, and (optionally) feature extraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the largest to date open access collection, and its pre-processing pipeline. Second, we show that SSL confidently outperforms fully-supervised pipelines using either our novel E4-tailored Transformer architecture (E4mer) or classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost) correctly classified recording segments from 64 (half acute, half stable) patients. Lastly, we illustrate that SSL performance is strongly associated with the specific surrogate task employed for pre-training as well as with unlabelled data availability.
</details>
<details>
<summary>摘要</summary>
个人感知，通过在患有抑郁症（MD）患者身边采集和分析穿戴式设备数据，可以识别抑郁症的危机性状态和稳定状态。但是收集和标注穿戴式数据具有极高的人员和资源成本，这限制了使用现代监督学习技术来识别抑郁症的应用。在这篇论文中，我们超越了这种数据瓶颈，通过自我监督学习（SSL）技术，使用无标注数据来学习表示，并将其应用于抑郁症的危机性状态和稳定状态的识别。我们收集了多个不同任务的开放数据集，包括辨别超级马里奥玩家的情感和快速识别大学生的压力，并设计了一个预处理管道，包括在/离体检测、睡眠唤醒检测、分割和（可选）特征提取。通过161名E4记录的主题，我们介绍了E4SelfLearning数据集，这是目前最大的开放访问数据集。我们显示，使用SSL技术可以高效地超过完全监督的架构，包括我们的新型E4特рансформа器架构（E4mer）和经典基eline XGBoost。在64名患者（每个患者有半个危机性状态和半个稳定状态）的记录段中，我们得到了81.23%的正确率，比XGBoost和E4mer的75.35%和72.02%高。最后，我们发现了SSL性能与具体的代理任务和无标注数据的可用性有很强的相关性。
</details></li>
</ul>
<hr>
<h2 id="Rephrase-and-Respond-Let-Large-Language-Models-Ask-Better-Questions-for-Themselves"><a href="#Rephrase-and-Respond-Let-Large-Language-Models-Ask-Better-Questions-for-Themselves" class="headerlink" title="Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves"></a>Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04205">http://arxiv.org/abs/2311.04205</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uclaml/Rephrase-and-Respond">https://github.com/uclaml/Rephrase-and-Respond</a></li>
<li>paper_authors: Yihe Deng, Weitong Zhang, Zixiang Chen, Quanquan Gu</li>
<li>for: 提高大语言模型（LLM）的性能，使其更好地理解人类的问题并提供有用的回答。</li>
<li>methods: 提出了一种名为“重新phrase和回答”（Rephrase and Respond，简称RaR）的方法，允许人类提问和LLM重新表达问题，并在单个提问中获得回答。这种方法简单且有效地提高了不同任务的性能。</li>
<li>results: 通过实验表明，我们的方法可以在各种任务上提高不同模型的性能，并且与Chain-of-Thought（CoT）方法相比，RaR是一种可以补充CoT的方法，可以在不同的任务上实现更好的性能。<details>
<summary>Abstract</summary>
Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs). Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses. While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped. In this paper, we present a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt. This approach serves as a simple yet effective prompting method for improving performance. We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM. This facilitates the effective utilization of rephrased questions generated by one LLM with another. Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks. We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically. We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance. Our work not only contributes to enhancing LLM performance efficiently and effectively but also sheds light on a fair evaluation of LLM capabilities. Data and codes are available at https://github.com/uclaml/Rephrase-and-Respond.
</details>
<details>
<summary>摘要</summary>
人类和大语言模型（LLM）之间的误解不仅存在于人际communication中，还可能出现在LLM与人类之间的交互中。这些差异可能使LLM解释看起来很明确的问题时，提供错误的回答。虽然广泛认可的提示质量对LLM提供回答的质量产生了很大的影响，但是一种系统的方法 для编写LLM可以更好地理解的提示还没有得到开发。在这篇论文中，我们提出了一种方法 named “Rephrase and Respond”（RaR），该方法允许LLM将人类提出的问题重新表述并提供回答在单个提示中。这种方法可以作为一种简单 yet effective的提示方法，以提高性能。我们还介绍了一种两步变体的RaR方法，其中一个重新表述LLM首先重新表述问题，然后将原始和重新表述的问题一起传递给另一个回答LLM。这种方法使得可以有效地利用重新表述的问题，并且可以与另一个LLM结合使用。我们的实验表明，我们的方法可以在不同任务上提高不同模型的性能。我们还提供了对RaR和popular Chain-of-Thought（CoT）方法的比较，包括理论和实验比较。我们表明，RaR和CoT是可 complementary的，可以将它们结合使用以实现更好的性能。我们的工作不仅有助于提高LLM性能，还有助于评估LLM的能力。数据和代码可以在https://github.com/uclaml/Rephrase-and-Respond上获取。
</details></li>
</ul>
<hr>
<h2 id="JPAVE-A-Generation-and-Classification-based-Model-for-Joint-Product-Attribute-Prediction-and-Value-Extraction"><a href="#JPAVE-A-Generation-and-Classification-based-Model-for-Joint-Product-Attribute-Prediction-and-Value-Extraction" class="headerlink" title="JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction"></a>JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04196">http://arxiv.org/abs/2311.04196</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhongfendeng/jpave">https://github.com/zhongfendeng/jpave</a></li>
<li>paper_authors: Zhongfen Deng, Hao Peng, Tao Zhang, Shuaiqi Liu, Wenting Zhao, Yibo Wang, Philip S. Yu</li>
<li>for: 本文提出了一种基于多任务学习的产品特征值EXTRACTION模型，以解决电商中产品搜索和推荐等下游应用中的产品特征值EXTRACTION问题。</li>
<li>methods: 本文提出了一种基于多任务学习的产品特征值EXTRACTION模型，包括值生成&#x2F;分类和属性预测三个任务。模型使用了值生成器和值分类器，并具有复制机制和价值注意力模块，以 Addressing data discrepancy issue和提高零例能力。</li>
<li>results: 实验结果表明，相比强基eline，本文提出的模型在一个公共数据集上表现出优于其他模型，并且在新值预测中具有较高的预测精度。<details>
<summary>Abstract</summary>
Product attribute value extraction is an important task in e-Commerce which can help several downstream applications such as product search and recommendation. Most previous models handle this task using sequence labeling or question answering method which rely on the sequential position information of values in the product text and are vulnerable to data discrepancy between training and testing. This limits their generalization ability to real-world scenario in which each product can have multiple descriptions across various shopping platforms with different composition of text and style. They also have limited zero-shot ability to new values. In this paper, we propose a multi-task learning model with value generation/classification and attribute prediction called JPAVE to predict values without the necessity of position information of values in the text. Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text. Besides, two variants of our model are designed for open-world and closed-world scenarios. In addition, copy mechanism introduced in the first variant based on value generation can improve its zero-shot ability for identifying unseen values. Experimental results on a public dataset demonstrate the superiority of our model compared with strong baselines and its generalization ability of predicting new values.
</details>
<details>
<summary>摘要</summary>
产品特征值EXTRACTION是电商中重要的任务，可以帮助多个下游应用程序，如产品搜索和推荐。现有的大多数模型都使用序列标签或问答方法来处理这个任务，这些方法受到文本中值的顺序位置信息的限制，容易受到训练和测试数据的不一致问题，这限制了它们在实际场景中的泛化能力。此外，这些模型也具有有限的零容量能力，无法处理新的值。在这篇论文中，我们提出了一种多任务学习模型，名为JPAVE，可以预测值不需要文本中值的顺序位置信息。此外，模型中的复制机制和价值注意模块帮助我们解决数据不一致问题，只关注输入文本中相关的部分，忽略其他信息。此外，我们还设计了两种模型的变种，一种适用于开放世界场景，另一种适用于关闭世界场景。实验结果表明，我们的模型在公共数据集上比强基eline模型表现出色，并且具有泛化能力预测新的值。
</details></li>
</ul>
<hr>
<h2 id="Selective-Visual-Representations-Improve-Convergence-and-Generalization-for-Embodied-AI"><a href="#Selective-Visual-Representations-Improve-Convergence-and-Generalization-for-Embodied-AI" class="headerlink" title="Selective Visual Representations Improve Convergence and Generalization for Embodied AI"></a>Selective Visual Representations Improve Convergence and Generalization for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04193">http://arxiv.org/abs/2311.04193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ainaz Eftekhar, Kuo-Hao Zeng, Jiafei Duan, Ali Farhadi, Ani Kembhavi, Ranjay Krishna</li>
<li>for: 这 paper 的目的是提出一种 parameter-efficient 方法，用于过滤embodied AI 模型中的视觉噪声，以提高模型的表现。</li>
<li>methods: 这 paper 使用了一种小型可学习的 codebook 模块，来实现任务条件的瓶颈。 codebook 被同时训练，以优化任务奖励，并作为任务条件的选择性筛选器对视觉观察进行过滤。</li>
<li>results: 这 paper 的实验结果表明，使用这种方法可以在 5 个 benchmark 上达到 state-of-the-art 表现，包括 ProcTHOR、ArchitecTHOR、RoboTHOR、AI2-iTHOR 和 ManipulaTHOR。 filtered 表示也能够更好地泛化和更快地融合到其他 simulated environment 中，如 Habitat。 qualitative 分析表明，使用这种方法可以让代理人更有效地探索其环境，并保留任务相关的信息，如目标物体识别，而忽略其他物体的信息。<details>
<summary>Abstract</summary>
Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues. Inspired by selective attention in humans-the process through which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects. Code and pretrained models are available at our project website: https://embodied-codebook.github.io.
</details>
<details>
<summary>摘要</summary>
embodied AI模型经常使用可购买的视觉脊梁如CLIP来编码其视觉观察。尽管这些通用的表示编码了场景中的语法和 semantics信息，但大多数这些信息对特定任务没有直接关系。这会导致学习过程中的噪音和扰动agent的注意力，使其忽略任务相关的视觉cue。 Drawing inspiration from human selective attention-the process by which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach uses a small learnable codebook module to induce a task-conditioned bottleneck. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able to generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects. Code and pretrained models are available at our project website: <https://embodied-codebook.github.io>.
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Anomaly-Detection-with-Graph-Networks-for-Data-Quality-Monitoring-of-the-Hadron-Calorimeter"><a href="#Spatio-Temporal-Anomaly-Detection-with-Graph-Networks-for-Data-Quality-Monitoring-of-the-Hadron-Calorimeter" class="headerlink" title="Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter"></a>Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04190">http://arxiv.org/abs/2311.04190</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mulugeta Weldezgina Asres, Christian Walter Omlin, Long Wang, David Yu, Pavel Parygin, Jay Dittmann, Georgia Karapostoli, Markus Seidel, Rosamaria Venditti, Luka Lambrecht, Emanuele Usai, Muhammad Ahmad, Javier Fernandez Menendez, Kaori Maeshima, the CMS-HCAL Collaboration</li>
<li>for: 这个研究旨在开发一种基于三维幂点映射数据的半监督空间时间异常检测系统，以检测CMS实验室中有机器错误的可能性。</li>
<li>methods: 该研究使用了卷积神经网络和图神经网络来学习探测器中的本地空间特征，以及背后的回路连接和仪器箱的全局行为。它还使用回归神经网络来捕捉扫描出的特征的时间演化。</li>
<li>results: 该研究通过使用LHC Run-2的粒子撞击数据集来验证 GraphSTAD 系统的准确性，并证明了该系统在捕捉多种探测器错误类型时的产生性。此外，该研究还对alternative指标模型进行了量化比较，以验证 GraphSTAD 系统的扩展优势。<details>
<summary>Abstract</summary>
The compact muon solenoid (CMS) experiment is a general-purpose detector for high-energy collision at the large hadron collider (LHC) at CERN. It employs an online data quality monitoring (DQM) system to promptly spot and diagnose particle data acquisition problems to avoid data quality loss. In this study, we present semi-supervised spatio-temporal anomaly detection (AD) monitoring for the physics particle reading channels of the hadronic calorimeter (HCAL) of the CMS using three-dimensional digi-occupancy map data of the DQM. We propose the GraphSTAD system, which employs convolutional and graph neural networks to learn local spatial characteristics induced by particles traversing the detector, and global behavior owing to shared backend circuit connections and housing boxes of the channels, respectively. Recurrent neural networks capture the temporal evolution of the extracted spatial features. We have validated the accuracy of the proposed AD system in capturing diverse channel fault types using the LHC Run-2 collision data sets. The GraphSTAD system has achieved production-level accuracy and is being integrated into the CMS core production system--for real-time monitoring of the HCAL. We have also provided a quantitative performance comparison with alternative benchmark models to demonstrate the promising leverage of the presented system.
</details>
<details>
<summary>摘要</summary>
大 compact氢离子探测器（CMS）实验是一个高能碰撞的通用侦测器，位于欧洲核子研究所（CERN）的大对核子碰撞机（LHC）上。它使用线上数据质量监控（DQM）系统，以及时发现和诊断数据收集问题，以避免数据质量损失。在这篇研究中，我们提出了半监督空间时间异常检测（AD）监控系统，用于CMSPhysics Particle Reading Channels的半导体探测器（HCAL）。我们提出了具有卷积神经网和图形神经网的GraphSTAD系统，用于学习探测器中的本地空间特征，以及分布式后端电路和封包盒的共享特征。循环神经网 capture了检测器中的时间演化。我们已经验证了提案的AD系统可以 Capture多种通道缺陷类型的数据集，使用LHC Run-2碰撞数据集。GraphSTAD系统在生产环境中已经 дости得高精度，并且在CMS核心生产系统中进行实时监控HCAL。我们也提供了一个量化性能比较，以展示提案的系统具有优秀的应用前景。
</details></li>
</ul>
<hr>
<h2 id="On-Leakage-in-Machine-Learning-Pipelines"><a href="#On-Leakage-in-Machine-Learning-Pipelines" class="headerlink" title="On Leakage in Machine Learning Pipelines"></a>On Leakage in Machine Learning Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04179">http://arxiv.org/abs/2311.04179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Leonard Sasse, Eliana Nicolaisen-Sobesky, Juergen Dukart, Simon B. Eickhoff, Michael Götz, Sami Hamdan, Vera Komeyer, Abhijit Kulkarni, Juha Lahnakoski, Bradley C. Love, Federico Raimondo, Kaustubh R. Patil</li>
<li>for: 本研究旨在扩展对MLipeline中泄漏的理解，以便更好地设计、实现和评估MLipeline。</li>
<li>methods: 本研究使用了具体的例子，对MLipeline中的多种泄漏类型进行了全面的介绍和讨论。</li>
<li>results: 本研究揭示了MLipeline中泄漏的多种类型，并提供了一些解决方案，以便更好地设计、实现和评估MLipeline。<details>
<summary>Abstract</summary>
Machine learning (ML) provides powerful tools for predictive modeling. ML's popularity stems from the promise of sample-level prediction with applications across a variety of fields from physics and marketing to healthcare. However, if not properly implemented and evaluated, ML pipelines may contain leakage typically resulting in overoptimistic performance estimates and failure to generalize to new data. This can have severe negative financial and societal implications. Our aim is to expand understanding associated with causes leading to leakage when designing, implementing, and evaluating ML pipelines. Illustrated by concrete examples, we provide a comprehensive overview and discussion of various types of leakage that may arise in ML pipelines.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-LLM-Intelligence-with-ARM-RAG-Auxiliary-Rationale-Memory-for-Retrieval-Augmented-Generation"><a href="#Enhancing-LLM-Intelligence-with-ARM-RAG-Auxiliary-Rationale-Memory-for-Retrieval-Augmented-Generation" class="headerlink" title="Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation"></a>Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04177">http://arxiv.org/abs/2311.04177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Melz</li>
<li>for: 这篇论文目的是探讨如何通过增强问题解决能力来提高大语言模型（LLMs）的智能水平。</li>
<li>methods: 这篇论文使用了Retrieval Augmented Generation（RAG）技术，并提出了一种名为Auxiliary Rationale Memory（ARM）的新系统，该系统可以从成功中学习而不需要高度的训练成本。</li>
<li>results: 研究发现，通过存储和后续检索解释链可以提高grade-school math问题的解决能力。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g., (Bubeck et al., 2023)) on modern LLMs have shown that they are capable of performing amazing tasks typically necessitating human-level intelligence. However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures. Some approaches to improving the intelligence of LLMs include fine-tuning models based on problem-solving performance (Zelikman et al., 2022), and building bigger and more sophisticated models (Bubeck et al., 2023). However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models. In this paper, we explore the use of Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to improve problem-solving performance. We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high training costs. We demonstrate that the storage and subsequent retrieval of reasoning chains have a positive influence on performance in grade-school math problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HADES-Fast-Singularity-Detection-with-Local-Measure-Comparison"><a href="#HADES-Fast-Singularity-Detection-with-Local-Measure-Comparison" class="headerlink" title="HADES: Fast Singularity Detection with Local Measure Comparison"></a>HADES: Fast Singularity Detection with Local Measure Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04171">http://arxiv.org/abs/2311.04171</a></li>
<li>repo_url: None</li>
<li>paper_authors: Uzu Lim, Harald Oberhauser, Vidit Nanda</li>
<li>for: 检测数据中的点 singularity</li>
<li>methods: 使用kernel好好 fit测试，比 existed topology-based方法更快和可扩展</li>
<li>results: 在synthetic数据、路网数据、分子结构空间和图像数据中recover singularities with high probability<details>
<summary>Abstract</summary>
We introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm employs a kernel goodness-of-fit test, and as a consequence it is much faster and far more scaleable than the existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.
</details>
<details>
<summary>摘要</summary>
我团队介绍了冥王（Hades）算法，用于不监督的数据中点检测缺陷。该算法使用一种层次质量适应测试，因此比现有的几何学基础的方法更快速和可扩展。通过几何学和优化运输理论的工具，我们证明了冥王可以高可能性地检测数据样本生成的缺陷，当数据样本居于等维度抽象 manifold 的横向交会处时。在计算实验中，冥王成功地恢复了 synthetic 数据中的缺陷、路网数据中的分支点、分子结构空间中的交叉环和图像数据中的异常。
</details></li>
</ul>
<hr>
<h2 id="Outliers-with-Opposing-Signals-Have-an-Outsized-Effect-on-Neural-Network-Optimization"><a href="#Outliers-with-Opposing-Signals-Have-an-Outsized-Effect-on-Neural-Network-Optimization" class="headerlink" title="Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization"></a>Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04163">http://arxiv.org/abs/2311.04163</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elan Rosenfeld, Andrej Risteski</li>
<li>for: 这个论文旨在描述 neural network 优化中新现象，即深度和自然数据中特殊重 tailed 结构之间的交互作用。</li>
<li>methods: 本文使用实验和理论分析来描述这种新现象，并提供了一种新的解释方式。</li>
<li>results: 研究发现，在训练数据中存在对抗信号的对组，导致早期优化进入窄谷，并且随着优化的深化，这些对组的损失快速增长，oscillating  между高和低。这些结果提供了新的质量预测，并且通过对 Adam 和 SGD 的比较，探讨了现代训练方法的改进。<details>
<summary>Abstract</summary>
We identify a new phenomenon in neural network optimization which arises from the interaction of depth and a particular heavy-tailed structure in natural data. Our result offers intuitive explanations for several previously reported observations about network training dynamics. In particular, it implies a conceptually new cause for progressive sharpening and the edge of stability; we also highlight connections to other concepts in optimization and generalization including grokking, simplicity bias, and Sharpness-Aware Minimization.   Experimentally, we demonstrate the significant influence of paired groups of outliers in the training data with strong opposing signals: consistent, large magnitude features which dominate the network output throughout training and provide gradients which point in opposite directions. Due to these outliers, early optimization enters a narrow valley which carefully balances the opposing groups; subsequent sharpening causes their loss to rise rapidly, oscillating between high on one group and then the other, until the overall loss spikes. We describe how to identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior. We complement these experiments with a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior which we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD.
</details>
<details>
<summary>摘要</summary>
我们发现一种新现象在神经网络优化中， arise from 自然数据中的特殊重 tailed 结构和深度的交互作用。我们的结果提供了直觉关于 Several 已经报告的网络训练动态观察结果。特别是，它隐含了一个新的原因，进步的减须和稳定边缘;我们也发现了与其他优化和泛化概念相关的 grokking、简单偏好和 Sharpness-Aware Minimization。实验中，我们证明了训练数据中的对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对称对�
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Interpretable-Transformer-for-Fine-Grained-Image-Classification-and-Analysis"><a href="#A-Simple-Interpretable-Transformer-for-Fine-Grained-Image-Classification-and-Analysis" class="headerlink" title="A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"></a>A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04157">http://arxiv.org/abs/2311.04157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imageomics/intr">https://github.com/imageomics/intr</a></li>
<li>paper_authors: Dipanjyoti Paul, Arpita Chowdhury, Xinqi Xiong, Feng-Ju Chang, David Carlyn, Samuel Stevens, Kaiya Provost, Anuj Karpatne, Bryan Carstens, Daniel Rubenstein, Charles Stewart, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao</li>
<li>For: The paper is written for those interested in image classification and interpretability, specifically in using Transformers to make image classification more interpretable.* Methods: The paper uses a Transformer encoder-decoder architecture, inspired by DETR, to learn “class-specific” queries that allow each class to localize its patterns in an image via cross-attention.* Results: The paper shows that INTR intrinsically encourages each class to attend distinctively, and the cross-attention weights provide a faithful interpretation of the prediction. Additionally, the paper demonstrates that INTR can identify different “attributes” of a class, making it particularly suitable for fine-grained classification and analysis on eight datasets.<details>
<summary>Abstract</summary>
We present a novel usage of Transformers to make image classification interpretable. Unlike mainstream classifiers that wait until the last fully-connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image. We realize this idea via a Transformer encoder-decoder inspired by DEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each class) as input to the decoder, enabling each class to localize its patterns in an image via cross-attention. We name our approach INterpretable TRansformer (INTR), which is fairly easy to implement and exhibits several compelling properties. We show that INTR intrinsically encourages each class to attend distinctively; the cross-attention weights thus provide a faithful interpretation of the prediction. Interestingly, via ``multi-head'' cross-attention, INTR could identify different ``attributes'' of a class, making it particularly suitable for fine-grained classification and analysis, which we demonstrate on eight datasets. Our code and pre-trained model are publicly accessible at https://github.com/Imageomics/INTR.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的应用方法，使用变换器来让图像分类变得可解释。不同于主流的分类器，我们在最后一层完全连接层之前就将类信息integrated到predictions中，而我们在这里investigate一种积极的方法，让每个类在图像中搜寻自己的特征。我们通过基于DEtection TRansformer（DETR）的Transformer encoder-decoder来实现这个想法，并学习每个类的“特定”的查询（一个查询对每个类），使每个类在图像中localize自己的特征viacross-attention。我们称之为可解释变换器（INTR），它易于实现并具有许多吸引人的性能。我们表明，INTR会自然地让每个类强调独特的注意力，因此交叉关注权重提供了可靠的预测解释。甚至via“多头”交叉关注，INTR可以识别不同的“特性”，使其特别适合细化分类和分析，我们在八个数据集上进行了示例。我们的代码和预训练模型可以在https://github.com/Imageomics/INTR上获取。
</details></li>
</ul>
<hr>
<h2 id="Contactless-Fingerprint-Biometric-Anti-Spoofing-An-Unsupervised-Deep-Learning-Approach"><a href="#Contactless-Fingerprint-Biometric-Anti-Spoofing-An-Unsupervised-Deep-Learning-Approach" class="headerlink" title="Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach"></a>Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04148">http://arxiv.org/abs/2311.04148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Banafsheh Adami, Nima Karimian</li>
<li>For: 提高用户 COMFORT 和解决卫生问题，实现更高效的生物metric系统。* Methods: 使用无接触指纹识别技术，并将自动编码器和卷积束注意模块结合使用，以满足不同类型的投映攻击测试。* Results: 实现了0.96%的BPCER和1.6%的APCER，表明该方法可以有效地抵御不同类型的投映攻击。<details>
<summary>Abstract</summary>
Contactless fingerprint recognition offers a higher level of user comfort and addresses hygiene concerns more effectively. However, it is also more vulnerable to presentation attacks such as photo paper, paper-printout, and various display attacks, which makes it more challenging to implement in biometric systems compared to contact-based modalities. Limited research has been conducted on presentation attacks in contactless fingerprint systems, and these studies have encountered challenges in terms of generalization and scalability since both bonafide samples and presentation attacks are utilized during training model. Although this approach appears promising, it lacks the ability to handle unseen attacks, which is a crucial factor for developing PAD methods that can generalize effectively. We introduced an innovative anti-spoofing approach that combines an unsupervised autoencoder with a convolutional block attention module to address the limitations of existing methods. Our model is exclusively trained on bonafide images without exposure to any spoofed samples during the training phase. It is then evaluated against various types of presentation attack images in the testing phase. The scheme we proposed has achieved an average BPCER of 0.96\% with an APCER of 1.6\% for presentation attacks involving various types of spoofed samples.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Locating-Cross-Task-Sequence-Continuation-Circuits-in-Transformers"><a href="#Locating-Cross-Task-Sequence-Continuation-Circuits-in-Transformers" class="headerlink" title="Locating Cross-Task Sequence Continuation Circuits in Transformers"></a>Locating Cross-Task Sequence Continuation Circuits in Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04131">http://arxiv.org/abs/2311.04131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Lan, Fazl Barez</li>
<li>for: 本研究旨在探讨 transformer 模型在语言任务中的强大能力，以及它们的复杂结构使得它们难以解释。</li>
<li>methods: 本研究使用了将 transformer 模型转换成可读的电路表示，以实现人类可读的算法函数。</li>
<li>results: 研究发现，相似序列续写任务中的电路具有共同的计算结构，这些结构在具体的序列中扮演着相似的角色。通过分析电路的技术，我们可以更好地预测模型的行为，识别错误和进行安全的编辑。这种机制性的理解对于建立更加稳定、一致和可解释的语言模型是非常重要的一步。<details>
<summary>Abstract</summary>
While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust, aligned, and interpretable language models.
</details>
<details>
<summary>摘要</summary>
transformer 模型在语言任务中表现出色，但它们的复杂架构使其难以解释。 recent work 旨在将 transformer 模型转换成可读的人类可读的表示形式，称为Circuit。我们在这些研究的基础上进一步分析和比较 Circuit 在相似序列续写任务中的表现，包括增加数字、数字词和月份。通过Circuit分析技术，我们确定了检测序列成员的关键子Circuit和预测下一个序列成员的Circuit。我们的分析发现，semantically related sequences 使用共享的Circuit子图，具有相似的角色。总的来说，记录共享的计算结构，可以更好地预测模型的行为，发现错误和安全地编辑过程。这种机制的理解是建立更加稳定、对接和可解释的语言模型的重要一步。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Safety-Vulnerabilities-of-Large-Language-Models"><a href="#Unveiling-Safety-Vulnerabilities-of-Large-Language-Models" class="headerlink" title="Unveiling Safety Vulnerabilities of Large Language Models"></a>Unveiling Safety Vulnerabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04124">http://arxiv.org/abs/2311.04124</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Kour, Marcel Zalmanovici, Naama Zwerdling, Esther Goldbraich, Ora Nova Fandina, Ateret Anaby-Tavor, Orna Raz, Eitan Farchi</li>
<li>for: 这篇论文是为了研究大语言模型的可能的危险或不适应应答而设计的。</li>
<li>methods: 该论文使用了一个唯一的数据集，称为AttaQ，这些数据集包含了诱导大语言模型生成危险或不适应应答的问题。 authors还介绍了一种自动化的方法，可以识别和命名模型受到攻击后可能生成危险输出的输入 semantic area。</li>
<li>results: 该论文通过分析不同模型在AttaQ数据集上的漏洞，证明了AttaQ数据集的有用性。 authors还发现了一些可能导致模型生成危险输出的输入 semantic area，并通过特殊的聚类技术来识别这些区域。<details>
<summary>Abstract</summary>
As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern. This paper introduces a unique dataset containing adversarial examples in the form of questions, which we call AttaQ, designed to provoke such harmful or inappropriate responses. We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it. Additionally, we introduce a novel automatic approach for identifying and naming vulnerable semantic regions - input semantic areas for which the model is likely to produce harmful outputs. This is achieved through the application of specialized clustering techniques that consider both the semantic similarity of the input attacks and the harmfulness of the model's responses. Automatically identifying vulnerable semantic regions enhances the evaluation of model weaknesses, facilitating targeted improvements to its safety mechanisms and overall reliability.
</details>
<details>
<summary>摘要</summary>
As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern. This paper introduces a unique dataset containing adversarial examples in the form of questions, which we call AttaQ, designed to provoke such harmful or inappropriate responses. We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it. Additionally, we introduce a novel automatic approach for identifying and naming vulnerable semantic regions - input semantic areas for which the model is likely to produce harmful outputs. This is achieved through the application of specialized clustering techniques that consider both the semantic similarity of the input attacks and the harmfulness of the model's responses. Automatically identifying vulnerable semantic regions enhances the evaluation of model weaknesses, facilitating targeted improvements to its safety mechanisms and overall reliability.Here's the translation in Traditional Chinese:随着大型语言模型的普及，它们可能会产生不适当或有害的回应，这篇论文提出了一个唯一的测试集，名为AttaQ，用于触发这些不适当或有害的回应。我们通过将不同模型应用到这个测试集上，进行模型的脆点分析。此外，我们还提出了一个新的自动方法，可以自动识别和命名模型中的具有危险性的Semantic Region，即输入Semantic Area中的具有危险性的输入攻击。这是通过特殊的集群技术，考虑了对Input攻击的Semantic similarity和模型的回应危险性。自动识别具有危险性的Semantic Region可以增强模型的评估，促进了模型的安全机制和整体可靠性。
</details></li>
</ul>
<hr>
<h2 id="ETDPC-A-Multimodality-Framework-for-Classifying-Pages-in-Electronic-Theses-and-Dissertations"><a href="#ETDPC-A-Multimodality-Framework-for-Classifying-Pages-in-Electronic-Theses-and-Dissertations" class="headerlink" title="ETDPC: A Multimodality Framework for Classifying Pages in Electronic Theses and Dissertations"></a>ETDPC: A Multimodality Framework for Classifying Pages in Electronic Theses and Dissertations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04262">http://arxiv.org/abs/2311.04262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lamps-lab/ETDMiner">https://github.com/lamps-lab/ETDMiner</a></li>
<li>paper_authors: Muntabir Hasan Choudhury, Lamia Salsabil, William A. Ingram, Edward A. Fox, Jian Wu</li>
<li>for: 这个论文旨在为电子硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件硬件�<details>
<summary>Abstract</summary>
Electronic theses and dissertations (ETDs) have been proposed, advocated, and generated for more than 25 years. Although ETDs are hosted by commercial or institutional digital library repositories, they are still an understudied type of scholarly big data, partially because they are usually longer than conference proceedings and journals. Segmenting ETDs will allow researchers to study sectional content. Readers can navigate to particular pages of interest, discover, and explore the content buried in these long documents. Most existing frameworks on document page classification are designed for classifying general documents and perform poorly on ETDs. In this paper, we propose ETDPC. Its backbone is a two-stream multimodal model with a cross-attention network to classify ETD pages into 13 categories. To overcome the challenge of imbalanced labeled samples, we augmented data for minority categories and employed a hierarchical classifier. ETDPC outperforms the state-of-the-art models in all categories, achieving an F1 of 0.84 -- 0.96 for 9 out of 13 categories. We also demonstrated its data efficiency. The code and data can be found on GitHub (https://github.com/lamps-lab/ETDMiner/tree/master/etd_segmentation).
</details>
<details>
<summary>摘要</summary>
电子论文和硬件（ETD）已经被提议、推广和生成了超过25年。尽管ETD被主机商业或机构数字图书馆存储，但它们仍然是未经研究的学术大数据的一种，其中一部分原因是它们通常比会议论文和杂志长得多。 segmenting ETDs 可以让研究人员研究 sectional content。读者可以导航到特定页码的兴趣，发现和探索ETD中埋藏的内容。现有的文档页面分类框架都是为普通文档设计，对ETD表现不佳。在这篇论文中，我们提出ETDPC。它的核心是一个两�ream multimodal模型，包括一个 crossed attention网络，用于分类ETD页面到13类中。为了解决少数类样本的权重不均问题，我们增强了数据，并使用堆式分类器。ETDPC在所有类别中都超过了状态之前的模型，实现了 F1 0.84-0.96 的值。我们还证明了它的数据效率。代码和数据可以在 GitHub 上找到（https://github.com/lamps-lab/ETDMiner/tree/master/etd_segmentation）。
</details></li>
</ul>
<hr>
<h2 id="Multitask-Multimodal-Prompted-Training-for-Interactive-Embodied-Task-Completion"><a href="#Multitask-Multimodal-Prompted-Training-for-Interactive-Embodied-Task-Completion" class="headerlink" title="Multitask Multimodal Prompted Training for Interactive Embodied Task Completion"></a>Multitask Multimodal Prompted Training for Interactive Embodied Task Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04067">http://arxiv.org/abs/2311.04067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Pantazopoulos, Malvina Nikandrou, Amit Parekh, Bhathiya Hemanthage, Arash Eshghi, Ioannis Konstas, Verena Rieser, Oliver Lemon, Alessandro Suglia</li>
<li>for: 本研究旨在解决现有视觉语言（VL）模型中的两个基本挑战，即将语言脱离到行为和观察的轨迹中，以及参照扩展。</li>
<li>methods: 我们提出了一个多模态代理（EMMA），它是一个统一的编码器-解码器模型，可以对图像和轨迹进行理解，并将动作预测转换为多模态文本生成。通过将所有任务视为文本生成，EMMA学习了一种行为语言，从而实现了任务之间的传送。与之前的模块化方法不同，我们使用了一个单一的多任务模型，每个任务都会帮助完成目标。</li>
<li>results: EMMA在多个VL准 benchmark上表现了与类似模型一样的性能，并在对话导向任务完成率（DTC）上达到了新的州OF-the-art表现（36.81%成功率）。<details>
<summary>Abstract</summary>
Interactive and embodied tasks pose at least two fundamental challenges to existing Vision & Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation. To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation. By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks. Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion. EMMA performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNInteractive and embodied tasks pose at least two fundamental challenges to existing Vision & Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation. To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation. By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks. Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion. EMMA performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena.中文简体版：存在至少两个基本挑战对现有视觉语言（VL）模型：1）将语言融入行为和观察的轨迹中，和2）参照歧义。为解决这些挑战，我们提出了一个具有多modal的Embodied MultiModal Agent（EMMA）：一个统一的编码器-解码器模型，可以对图像和轨迹进行理解，并将动作预测转换为多modal文本生成。通过将所有任务都作为文本生成，EMMA学习了一种动作语言，从而促进了任务之间的传递。与之前独立训练的组件不同，我们使用了一个单一的多任务模型，每个任务都可以帮助完成目标。EMMA在多个VL标准准测上与类似模型表现相当，并在Dialog-guided Task Completion（DTC）标准准测上设置了新的状态纪录（36.81%成功率），这是一个用于评估对话导向Agent的Alexa Arena中的 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Can-CLIP-Help-Sound-Source-Localization"><a href="#Can-CLIP-Help-Sound-Source-Localization" class="headerlink" title="Can CLIP Help Sound Source Localization?"></a>Can CLIP Help Sound Source Localization?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04066">http://arxiv.org/abs/2311.04066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Sooyoung Park, Arda Senocak, Joon Son Chung</li>
<li>for: 本研究应用大规模预训Image-text模型（specifically CLIP）到 зву源定位领域，并不需要文本输入。</li>
<li>methods: 我们引入一个框架，将音频讯号转换为CLIP的文本Encoder兼容的token，从而生成音频驱动的Embeddings。我们直接使用这些Embeddings，生成音频驱动的面积图，提取音频驱动的图像特征，并使用音频视觉对匹配目标来对它们进行对齐。</li>
<li>results: 我们的方法比过去的方法表现出更好的完整性和紧密性，并且在实验中表现出了优秀的性能。<details>
<summary>Abstract</summary>
Large-scale pre-trained image-text models demonstrate remarkable versatility across diverse tasks, benefiting from their robust representational capabilities and effective multimodal alignment. We extend the application of these models, specifically CLIP, to the domain of sound source localization. Unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.
</details>
<details>
<summary>摘要</summary>
大规模预训练图像文本模型在多种任务上显示了惊人的多样性，受到其强大的表示能力和有效的多媒体对应的推动。我们将这些模型，特别是CLIP，应用到声源 localization 领域中。 unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.Here's the translation in Traditional Chinese:大规模预训练图像文本模型在多种任务上显示了惊人的多样性，受到其强大的表示能力和有效的多媒体对应的推动。我们将这些模型，特别是CLIP，应用到对话 localization 领域中。 unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.
</details></li>
</ul>
<hr>
<h2 id="Multi-View-Causal-Representation-Learning-with-Partial-Observability"><a href="#Multi-View-Causal-Representation-Learning-with-Partial-Observability" class="headerlink" title="Multi-View Causal Representation Learning with Partial Observability"></a>Multi-View Causal Representation Learning with Partial Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04056">http://arxiv.org/abs/2311.04056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingling Yao, Danru Xu, Sébastien Lachapelle, Sara Magliacane, Perouz Taslakian, Georg Martius, Julius von Kügelgen, Francesco Locatello</li>
<li>for: 这 paper 旨在研究同时观察到的视图中学习的表示性的可识别性。</li>
<li>methods: 该 paper 使用了对各个视图的强制学习和单一编码器来学习表示性。</li>
<li>results: 该 paper 提供了一个统一的框架和理论结论，可以在部分可见情况下学习多视图非线性混合的下标。它们还提供了一些图理论来判断哪些隐藏变量可以通过简单的规则来标识。<details>
<summary>Abstract</summary>
We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. Overall, we find that access to multiple partial views enables us to identify a more fine-grained representation, under the generally milder assumption of partial observability.
</details>
<details>
<summary>摘要</summary>
我们提出一个统一的框架，用于研究同时观察到的视图中学习的表示可否被识别。我们允许部分观察的设置，在每个视图中，每个下标变量可能是非线性混合的一部分。我们证明了，通过对所有视图的共享信息进行对比学习，可以在单个编码器每个视图中学习到所有下标变量的信息，并且这种学习可以保持一定的平滑比例。我们还提供了一些图形标准，用于判断哪些含义可以通过简单的规则来识别，我们称之为可识别代数。我们的总框架和理论结果综合和扩展了多视图非线性ICA、解体和 causal 表示学习的先前研究。我们在数学、图像和多模态数据集上进行了实验 validate 我们的laims，并且我们发现，在不同的特殊情况下，先前的方法的性能可以通过我们的框架来回归。总之，我们发现，通过访问多个部分视图，可以 identific a 更细致的表示，只需要在通常较弱的部分可见性假设下进行学习。
</details></li>
</ul>
<hr>
<h2 id="Causal-Discovery-Under-Local-Privacy"><a href="#Causal-Discovery-Under-Local-Privacy" class="headerlink" title="Causal Discovery Under Local Privacy"></a>Causal Discovery Under Local Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04037">http://arxiv.org/abs/2311.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rūta Binkytė, Carlos Pinzón, Szilvia Lestyán, Kangsoo Jung, Héber H. Arcolezi, Catuscia Palamidessi</li>
<li>For: 本研究旨在探讨本地隐私机制在 causal discovery 任务中的选择。* Methods: 本文考虑了多种常见的本地隐私机制，并对这些机制对 causal learning 算法生成的 causal 结构的准确性和隐私水平进行了比较。* Results: 研究发现，不同的本地隐私机制会对 causal 结构生成的准确性产生不同的影响，而且这些影响可能是负面的。本文提供了关于选择合适的本地隐私协议的有价值信息。<details>
<summary>Abstract</summary>
Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set. It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers. Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually. Therefore it provides protection also in contexts in which the server, or even the data collector, cannot be trusted. The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components. This distortion can prove detrimental to tasks such as causal discovery. In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms. Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks. We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery.
</details>
<details>
<summary>摘要</summary>
differential privacy 是一种广泛采用的框架，旨在保护数据提供者在数据集中的敏感信息。它基于数据处理和存储服务器和数据消费者之间应用控制的噪声的方法。本地异 diferencial privacy 是一种变体，允许数据提供者自己应用隐私机制于其数据。因此，它可以在服务器或数据收集者不可靠的情况下提供保护。噪声的引入，然而，必然影响数据的使用价值，特别是对个体数据组件之间的相关性进行扭曲。这种扭曲可能对 causal discovery 任务构成负面影响。在这篇论文中，我们考虑了多种广泛known的本地异 diferencial privacy 机制，并比较这些机制对 privacy 和 causal learning 算法应用于扭曲后的数据中的准确性的负面。我们的分析获得了有价值的洞察，可以帮助研究者和实践者在本地私有的 causal discovery 任务中选择合适的异 diferencial privacy 协议。我们预期，我们的发现将帮助研究者和实践者在本地私有的 causal discovery 任务中进行更加有效的工作。
</details></li>
</ul>
<hr>
<h2 id="Impact-of-HPO-on-AutoML-Forecasting-Ensembles"><a href="#Impact-of-HPO-on-AutoML-Forecasting-Ensembles" class="headerlink" title="Impact of HPO on AutoML Forecasting Ensembles"></a>Impact of HPO on AutoML Forecasting Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04034">http://arxiv.org/abs/2311.04034</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Hoffmann</li>
<li>for: 这个论文的目的是提出一种基于多种优化策略的深度学习模型 ensemble，用于解决多种问题的地方和全球一元预测。</li>
<li>methods: 该论文使用了多种方法，包括MQ-CNN、DeepAR、Prophet、NPTS、ARIMA和ETS，以及不同的超参数优化策略，如搜索和权重学习。</li>
<li>results: 研究发现，在这种设置中，添加超参数优化可以提高准确性，最终设置的准确性提升9.9%，相比于基eline ensemble无HPO。此外，该组合还比州Of The Art的商业自动学习预测解决方案Amazon Forecast下降3.5%的错误率和16.0%的综合集成延迟时间。<details>
<summary>Abstract</summary>
A forecasting ensemble consisting of a diverse range of estimators for both local and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet, NPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems. This paper delves into the aspect of adding different hyperparameter optimization strategies to the deep learning models in such a setup (DeepAR and MQ-CNN), exploring the trade-off between added training cost and the increase in accuracy for different configurations. It shows that in such a setup, adding hyperparameter optimization can lead to performance improvements, with the final setup having a 9.9 % percent accuracy improvement with respect to the avg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 % increase in end-to-end ensemble latency. This improvement is based on an empirical analysis of combining the ensemble pipeline with different tuning strategies, namely Bayesian Optimisation and Hyperband and different configurations of those strategies. In the final configuration, the proposed combination of ensemble learning and HPO outperforms the state of the art commercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower error and 16.0 % lower end-to-end ensemble latency.
</details>
<details>
<summary>摘要</summary>
一个包含多种估计器的预测集群，包括MQ-CNN、DeepAR、Prophet、NPTS、ARIMA和ETS，可以用于解决多种问题的预测。这篇论文探讨了将不同的超参数优化策略添加到深度学习模型中的影响，包括加入超参数优化后 ensemble 的性能提升。结果显示，在这种情况下，加入超参数优化可以提高准确性，最终集群与avg-wQL比较基eline ensemble无HPO后提高9.9%，同时end-to-end ensemble延迟提高65.8%。这个提升基于不同的 ensemble 管道和优化策略的实际分析，包括 Bayesian Optimization 和 Hyperband。最终配置中，提档 ensemble 学习和HPO的组合超过了现有的商业AutoML预测解决方案 Amazon Forecast，错误率下降3.5%，ensemble 延迟下降16.0%。
</details></li>
</ul>
<hr>
<h2 id="IoT-Based-Environmental-Control-System-for-Fish-Farms-with-Sensor-Integration-and-Machine-Learning-Decision-Support"><a href="#IoT-Based-Environmental-Control-System-for-Fish-Farms-with-Sensor-Integration-and-Machine-Learning-Decision-Support" class="headerlink" title="IoT-Based Environmental Control System for Fish Farms with Sensor Integration and Machine Learning Decision Support"></a>IoT-Based Environmental Control System for Fish Farms with Sensor Integration and Machine Learning Decision Support</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04258">http://arxiv.org/abs/2311.04258</a></li>
<li>repo_url: None</li>
<li>paper_authors: D. Dhinakaran, S. Gopalakrishnan, M. D. Manigandan, T. P. Anish</li>
<li>For: 本研究旨在开发一个基于物联网（IoT）的环境控制系统，帮助推动鱼塘的可持续发展。* Methods: 本研究使用了无线感应器网络，进行了实时环境数据的收集和预测，并应用了四种机器学习算法：Random Forests、Support Vector Machines（SVMs）、Gradient Boosting Machines（GBMs）和神经网络。* Results: 本研究发现，这个环境控制系统可以帮助鱼塘的环境条件与预定的条件保持一致，提高鱼的健康和生产力，同时降低资源浪费和环境影响，实现可持续的鱼塘经营。<details>
<summary>Abstract</summary>
In response to the burgeoning global demand for seafood and the challenges of managing fish farms, we introduce an innovative IoT based environmental control system that integrates sensor technology and advanced machine learning decision support. Deploying a network of wireless sensors within the fish farm, we continuously collect real-time data on crucial environmental parameters, including water temperature, pH levels, humidity, and fish behavior. This data undergoes meticulous preprocessing to ensure its reliability, including imputation, outlier detection, feature engineering, and synchronization. At the heart of our system are four distinct machine learning algorithms: Random Forests predict and optimize water temperature and pH levels for the fish, fostering their health and growth; Support Vector Machines (SVMs) function as an early warning system, promptly detecting diseases and parasites in fish; Gradient Boosting Machines (GBMs) dynamically fine-tune the feeding schedule based on real-time environmental conditions, promoting resource efficiency and fish productivity; Neural Networks manage the operation of critical equipment like water pumps and heaters to maintain the desired environmental conditions within the farm. These machine learning algorithms collaboratively make real-time decisions to ensure that the fish farm's environmental conditions align with predefined specifications, leading to improved fish health and productivity while simultaneously reducing resource wastage, thereby contributing to increased profitability and sustainability. This research article showcases the power of data-driven decision support in fish farming, promising to meet the growing demand for seafood while emphasizing environmental responsibility and economic viability, thus revolutionizing the future of fish farming.
</details>
<details>
<summary>摘要</summary>
为了应对全球增长的海鲜需求以及护养鱼场的挑战，我们介绍了一个创新的互联网器件（IoT）基础的环境控制系统，该系统集成了感知技术和高级机器学习决策支持。在鱼场中部署了无线传感器网络，持续收集鱼场实时环境参数的数据，包括水温、pH值、湿度和鱼Behavior。这些数据进行了严格的处理和验证，以确保其可靠性，包括填充、异常检测、特征工程和同步。针对鱼场环境控制，我们采用了四种不同的机器学习算法：Random Forests预测和优化鱼场水温和pH值，以促进鱼的健康和生长；Support Vector Machines（SVMs）作为早期警报系统，快速检测鱼中的疾病和寄生虫；Gradient Boosting Machines（GBMs）动态调整饲料时间表，根据实时环境条件，提高鱼场资源效率和鱼产量；Neural Networks控制鱼场关键设备，如水泵和加热器，以保持鱼场所需环境条件，从而确保鱼场环境控制的正确性。这些机器学习算法合作实时决策，以确保鱼场环境控制与预定标准符合，从而提高鱼的健康和产量，同时减少资源浪费，从而提高利润和可持续性。本文显示了数据驱动的决策支持在鱼养中的力量，承诺满足全球增长的海鲜需求，同时强调环境责任和经济可持续性，以改变未来的鱼养业。
</details></li>
</ul>
<hr>
<h2 id="Expressivity-of-ReLU-Networks-under-Convex-Relaxations"><a href="#Expressivity-of-ReLU-Networks-under-Convex-Relaxations" class="headerlink" title="Expressivity of ReLU-Networks under Convex Relaxations"></a>Expressivity of ReLU-Networks under Convex Relaxations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04015">http://arxiv.org/abs/2311.04015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Baader, Mark Niklas Müller, Yuhao Mao, Martin Vechev</li>
<li>for: 论文主要探讨了训练和证明具有可证明安全性的神经网络所使用的凸 relaxation 技术的限制。</li>
<li>methods: 作者使用了多种常用的凸 relaxation 技术进行研究，包括 IBP relaxation 和更高级的 relaxation。</li>
<li>results: 研究发现，使用更高级的 relaxation 技术可以更好地表示一些不可达的函数，但是对于多变量函数来说，无论使用最精确的单 neuron relaxation，都无法构建可 precisely 分析的 ReLU 网络。<details>
<summary>Abstract</summary>
Convex relaxations are a key component of training and certifying provably safe neural networks. However, despite substantial progress, a wide and poorly understood accuracy gap to standard networks remains, raising the question of whether this is due to fundamental limitations of convex relaxations. Initial work investigating this question focused on the simple and widely used IBP relaxation. It revealed that some univariate, convex, continuous piecewise linear (CPWL) functions cannot be encoded by any ReLU network such that its IBP-analysis is precise. To explore whether this limitation is shared by more advanced convex relaxations, we conduct the first in-depth study on the expressive power of ReLU networks across all commonly used convex relaxations. We show that: (i) more advanced relaxations allow a larger class of univariate functions to be expressed as precisely analyzable ReLU networks, (ii) more precise relaxations can allow exponentially larger solution spaces of ReLU networks encoding the same functions, and (iii) even using the most precise single-neuron relaxations, it is impossible to construct precisely analyzable ReLU networks that express multivariate, convex, monotone CPWL functions.
</details>
<details>
<summary>摘要</summary>
“凸松动是训练和证明可靠神经网络的关键组成部分。然而，尽管已经取得了 significativ progress，但是还存在一个宽泛不了解的精度差异，这引起了whether this is due to fundamental limitations of convex relaxations的 вопро题。初步的研究发现，IBP relaxation可以不能正确地分析一些单变量、凸、连续piecewise linear（CPWL）函数。为了检查这种限制是否被更高级的凸松动所共享，我们进行了第一次对所有常用凸松动中ReLU网络的表达力进行深入研究。我们发现了以下结论：（i）更高级的松动可以让更多的单变量函数被ReLU网络表示为正确分析的，（ii）更精度的松动可以让ReLU网络表示的解空间规模增加 exponential，（iii）即使使用最精度的单 neuron松动，也不可以构建ReLU网络来表示多变量、凸、 monotone CPWL函数。”
</details></li>
</ul>
<hr>
<h2 id="A-Method-to-Improve-the-Performance-of-Reinforcement-Learning-Based-on-the-Y-Operator-for-a-Class-of-Stochastic-Differential-Equation-Based-Child-Mother-Systems"><a href="#A-Method-to-Improve-the-Performance-of-Reinforcement-Learning-Based-on-the-Y-Operator-for-a-Class-of-Stochastic-Differential-Equation-Based-Child-Mother-Systems" class="headerlink" title="A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems"></a>A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04014">http://arxiv.org/abs/2311.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Yin, Yi Chen</li>
<li>for: 提高actor-critic(AC)基于游戏学习的控制性能，用于解决由随机 diffeq Equations(SDEs) governs的系统。</li>
<li>methods:  introduce a novel operator called Y operator，integrate child-mother system的随机性 into critic network的损失函数，提高RL算法的控制性能。</li>
<li>results: Y operator reformulates solving partial differential equations for state-value function as a parallel problem for drift and diffusion functions within SDEs, demonstrates superiority over existing methods through linear and nonlinear numerical examples.<details>
<summary>Abstract</summary>
This paper introduces a novel operator, termed the Y operator, to elevate control performance in Actor-Critic(AC) based reinforcement learning for systems governed by stochastic differential equations(SDEs). The Y operator ingeniously integrates the stochasticity of a class of child-mother system into the Critic network's loss function, yielding substantial advancements in the control performance of RL algorithms.Additionally, the Y operator elegantly reformulates the challenge of solving partial differential equations for the state-value function into a parallel problem for the drift and diffusion functions within the system's SDEs.A rigorous mathematical proof confirms the operator's validity.This transformation enables the Y Operator-based Reinforcement Learning(YORL) framework to efficiently tackle optimal control problems in both model-based and data-driven systems.The superiority of YORL is demonstrated through linear and nonlinear numerical examples showing its enhanced performance over existing methods post convergence.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Energy-Prediction-Smart-Meter-Dataset-Analysis-of-Previous-Competitions-and-Beyond"><a href="#The-Energy-Prediction-Smart-Meter-Dataset-Analysis-of-Previous-Competitions-and-Beyond" class="headerlink" title="The Energy Prediction Smart-Meter Dataset: Analysis of Previous Competitions and Beyond"></a>The Energy Prediction Smart-Meter Dataset: Analysis of Previous Competitions and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04007">http://arxiv.org/abs/2311.04007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Direnc Pekaslan, Jose Maria Alonso-Moral, Kasun Bandara, Christoph Bergmeir, Juan Bernabe-Moreno, Robert Eigenmann, Nils Einecke, Selvi Ergen, Rakshitha Godahewa, Hansika Hewamalage, Jesus Lago, Steffen Limmer, Sven Rebhan, Boris Rabinovich, Dilini Rajapasksha, Heda Song, Christian Wagner, Wenlong Wu, Luis Magdalena, Isaac Triguero</li>
<li>for: 这 paper 主要是为了提供一个实际世界智能仪表数据集，并对 Energy Prediction Technical Challenges 中的解决方案进行分析，特别是在 2020 年 IEEE Computational Intelligence Society（IEEE-CIS）技术挑战（名为 EP）和 2021 年 IEEE International Conference on Fuzzy Systems（FUZZ-IEEE）的跟进挑战（名为 XEP）中。</li>
<li>methods: 这 paper 使用了几种方法，包括 Energy Prediction 技术挑战中的竞赛方法，以及对实际世界智能仪表数据集的分析和评价。</li>
<li>results: 这 paper 的结果显示，通过使用不同的方法和技术，可以准确预测家庭能源消耗，并且可以提高预测的解释性。此外，paper 还提出了一些可能的应用场景，例如能源分解、需求回应计划和行为改变等。<details>
<summary>Abstract</summary>
This paper presents the real-world smart-meter dataset and offers an analysis of solutions derived from the Energy Prediction Technical Challenges, focusing primarily on two key competitions: the IEEE Computational Intelligence Society (IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in 2020 (named EP) and its follow-up challenge at the IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These competitions focus on accurate energy consumption forecasting and the importance of interpretability in understanding the underlying factors. The challenge aims to predict monthly and yearly estimated consumption for households, addressing the accurate billing problem with limited historical smart meter data. The dataset comprises 3,248 smart meters, with varying data availability ranging from a minimum of one month to a year. This paper delves into the challenges, solutions and analysing issues related to the provided real-world smart meter data, developing accurate predictions at the household level, and introducing evaluation criteria for assessing interpretability. Additionally, this paper discusses aspects beyond the competitions: opportunities for energy disaggregation and pattern detection applications at the household level, significance of communicating energy-driven factors for optimised billing, and emphasising the importance of responsible AI and data privacy considerations. These aspects provide insights into the broader implications and potential advancements in energy consumption prediction. Overall, these competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards the discussion of various aspects such as energy disaggregation, demand response programs or behavioural interventions.
</details>
<details>
<summary>摘要</summary>
The dataset includes 3,248 smart meters with varying data availability, ranging from one month to one year. This paper explores the challenges, solutions, and evaluation criteria for assessing interpretability in the provided real-world smart meter data. Additionally, it discusses opportunities for energy disaggregation and pattern detection applications at the household level, the significance of communicating energy-driven factors for optimized billing, and the importance of responsible AI and data privacy considerations. These aspects provide insights into the broader implications and potential advancements in energy consumption prediction.Overall, these competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards discussions of various aspects, such as energy disaggregation, demand response programs, or behavioral interventions.
</details></li>
</ul>
<hr>
<h2 id="Foundational-propositions-of-hesitant-fuzzy-sets-and-parameter-reductions-of-hesitant-fuzzy-information-systems"><a href="#Foundational-propositions-of-hesitant-fuzzy-sets-and-parameter-reductions-of-hesitant-fuzzy-information-systems" class="headerlink" title="Foundational propositions of hesitant fuzzy sets and parameter reductions of hesitant fuzzy information systems"></a>Foundational propositions of hesitant fuzzy sets and parameter reductions of hesitant fuzzy information systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04256">http://arxiv.org/abs/2311.04256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shizhan Lu</li>
<li>for: 本研究探讨了不确定和半确定的情况下的软集的定义和应用。</li>
<li>methods: 本文提出了基于不确定软集的分割的多种包含关系，并提出了软集系统的基本定义和家族。</li>
<li>results: 本文提出了基于不确定软集的参数缩放问题的一些基本定理和算法，并给出了一个示例和算法来解释过程。<details>
<summary>Abstract</summary>
Hesitant fuzzy sets are widely used in the instances of uncertainty and hesitation. The inclusion relationship is an important and foundational definition for sets. Hesitant fuzzy set, as a kind of set, needs explicit definition of inclusion relationship. Base on the hesitant fuzzy membership degree of discrete form, several kinds of inclusion relationships for hesitant fuzzy sets are proposed. And then some foundational propositions of hesitant fuzzy sets and the families of hesitant fuzzy sets are presented. Finally, some foundational propositions of hesitant fuzzy information systems with respect to parameter reductions are put forward, and an example and an algorithm are given to illustrate the processes of parameter reductions.
</details>
<details>
<summary>摘要</summary>
“抽象不确定集”在不确定和犹豫的场景中广泛使用。确定关系是确定集的基本定义。“抽象不确定集”作为一种集合，需要明确的确定关系定义。基于抽象不确定会员度的离散形式，对抽象不确定集提出了多种包含关系。然后，对抽象不确定集和其家族进行了一些基本提示，并对不确定信息系统参数缩小进行了一些基本提示。最后，给出了一个示例和一个算法，以示 parameter reductions 的过程。Note: "抽象不确定集" (hesitant fuzzy set) is a term used in fuzzy set theory to describe a set with unclear or uncertain boundaries. The term "不确定" (uncertain) is used to emphasize the uncertainty of the set's boundaries, rather than the traditional "抽象" (abstract) used in the term "抽象集" (abstract set).
</details></li>
</ul>
<hr>
<h2 id="Human-AI-Collaboration-in-Thematic-Analysis-using-ChatGPT-A-User-Study-and-Design-Recommendations"><a href="#Human-AI-Collaboration-in-Thematic-Analysis-using-ChatGPT-A-User-Study-and-Design-Recommendations" class="headerlink" title="Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations"></a>Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03999">http://arxiv.org/abs/2311.03999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixiang Yan, Vanessa Echeverria, Gloria Fernandez Nieto, Yueqiao Jin, Zachari Swiecki, Linxuan Zhao, Dragan Gašević, Roberto Martinez-Maldonado</li>
<li>for: 这些研究旨在了解研究者与生成人工智能（GenAI）在质量研究中的合作方式。</li>
<li>methods: 研究者使用了ChatGPT进行主题分析，并发现其可以提高编码效率，帮助初步数据探索，提供细腻的量化预测，以及帮助非native语言speaker和非专家理解。</li>
<li>results: 研究发现了GenAI在质量研究中的价值，但也存在不信任和精度、可靠性和一致性的问题，以及更广泛的研究社区的acceptance。Here’s the full text in Simplified Chinese:</li>
<li>for: 这些研究旨在了解研究者与生成人工智能（GenAI）在质量研究中的合作方式。</li>
<li>methods: 研究者使用了ChatGPT进行主题分析，并发现其可以提高编码效率，帮助初步数据探索，提供细腻的量化预测，以及帮助非native语言speaker和非专家理解。</li>
<li>results: 研究发现了GenAI在质量研究中的价值，但也存在不信任和精度、可靠性和一致性的问题，以及更广泛的研究社区的acceptance。Please note that the text is in Simplified Chinese, and the translation may not be perfect.<details>
<summary>Abstract</summary>
Generative artificial intelligence (GenAI) offers promising potential for advancing human-AI collaboration in qualitative research. However, existing works focused on conventional machine-learning and pattern-based AI systems, and little is known about how researchers interact with GenAI in qualitative research. This work delves into researchers' perceptions of their collaboration with GenAI, specifically ChatGPT. Through a user study involving ten qualitative researchers, we found ChatGPT to be a valuable collaborator for thematic analysis, enhancing coding efficiency, aiding initial data exploration, offering granular quantitative insights, and assisting comprehension for non-native speakers and non-experts. Yet, concerns about its trustworthiness and accuracy, reliability and consistency, limited contextual understanding, and broader acceptance within the research community persist. We contribute five actionable design recommendations to foster effective human-AI collaboration. These include incorporating transparent explanatory mechanisms, enhancing interface and integration capabilities, prioritising contextual understanding and customisation, embedding human-AI feedback loops and iterative functionality, and strengthening trust through validation mechanisms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learned-Causal-Method-Prediction"><a href="#Learned-Causal-Method-Prediction" class="headerlink" title="Learned Causal Method Prediction"></a>Learned Causal Method Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03989">http://arxiv.org/abs/2311.03989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shantanu Gupta, Cheng Zhang, Agrin Hilmkil</li>
<li>for: 这个论文是为了解决选择适合的 causal inference 方法问题。</li>
<li>methods: 这个论文使用了 CAusal Method Predictor (CAMP) 框架，该框架可以预测最佳方法 для给定的数据集。</li>
<li>results: CAMP 可以高效地预测最佳方法，并且在实验中表现出色，可以普遍应用于不同的数据集。<details>
<summary>Abstract</summary>
For a given causal question, it is important to efficiently decide which causal inference method to use for a given dataset. This is challenging because causal methods typically rely on complex and difficult-to-verify assumptions, and cross-validation is not applicable since ground truth causal quantities are unobserved. In this work, we propose CAusal Method Predictor (CAMP), a framework for predicting the best method for a given dataset. To this end, we generate datasets from a diverse set of synthetic causal models, score the candidate methods, and train a model to directly predict the highest-scoring method for that dataset. Next, by formulating a self-supervised pre-training objective centered on dataset assumptions relevant for causal inference, we significantly reduce the need for costly labeled data and enhance training efficiency. Our strategy learns to map implicit dataset properties to the best method in a data-driven manner. In our experiments, we focus on method prediction for causal discovery. CAMP outperforms selecting any individual candidate method and demonstrates promising generalization to unseen semi-synthetic and real-world benchmarks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译为简化字的中文。<</SYS>>为给定的 causal 问题，选择合适的 causal inference 方法是关键。这是因为 causal 方法通常基于复杂且难以验证的假设，而 cross-validation 不适用，因为真实的 causal 量未知。在这种情况下，我们提出了 CAusal Method Predictor (CAMP)，一个框架用于预测给定数据集最佳的方法。为此，我们生成了一系列来自多种 sintetic causal 模型的数据集，评分候选方法，并使用一个模型直接预测该数据集中最高分方法。然后，我们通过在 dataset 假设上定义自我超vised 预训练目标，以减少高效的标注数据的需求，并提高训练效率。我们的策略学习将数据集的隐藏特性映射到最佳方法中，以数据驱动的方式。在我们的实验中，我们关注 causal discovery 方法预测。CAMP 在选择任何个人候选方法时表现出优异，并在未见 semi-synthetic 和实际世界 benchmark 中展现了良好的普适性。
</details></li>
</ul>
<hr>
<h2 id="Its-All-Graph-To-Me-Foundational-Topology-Models-with-Contrastive-Learning-on-Multiple-Domains"><a href="#Its-All-Graph-To-Me-Foundational-Topology-Models-with-Contrastive-Learning-on-Multiple-Domains" class="headerlink" title="Its All Graph To Me: Foundational Topology Models with Contrastive Learning on Multiple Domains"></a>Its All Graph To Me: Foundational Topology Models with Contrastive Learning on Multiple Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03976">http://arxiv.org/abs/2311.03976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex O. Davies, Riku W. Green, Nirav S. Ajmeri, Telmo M. Silva Filho</li>
<li>for: 这篇论文的目的是提出一种基于对抗对抗学习的图数据表示和嵌入模型，以解决现有模型是域特定的问题。</li>
<li>methods: 这篇论文使用了对抗对抗学习方法，只在结构上进行了训练，而不是在数据上进行训练。</li>
<li>results: 论文表明，使用这种方法可以获得比单域或非预训练模型更好的表示，并且在多种下游任务中表现更好。<details>
<summary>Abstract</summary>
Representations and embeddings of graph data have been essential in many domains of research.   The principle benefit of learning such representations is that the pre-trained model can be fine-tuned on smaller datasets where data or labels are scarse.   Existing models, however, are domain specific; for example a model trained on molecular graphs is fine-tuned on other molecular graphs.   This means that in many application cases the choice of pre-trained model can be arbitrary, and novel domains may lack an appropriate pre-trained model.   This is of particular issue where data is scarse, precluding traditional supervised methods.   In this work we use adversarial contrastive learning to present a \method, a model pre-trained on many graph domains.   We train the model only on topologies but include node labels in evaluation.   We evaluate the efficacy of its learnt representations on various downstream tasks.   Against baseline models pre-trained on single domains, as well as un-trained models and non-transferred models, we show that performance is equal or better using our single model.   This includes when node labels are used in evaluation, where performance is consistently superior to single-domain or non-pre-trained models.
</details>
<details>
<summary>摘要</summary>
研究领域中的图数据表示和嵌入已经是不可或缺的。这些表示的主要优点是可以通过先经训练的模型进行精度调整，以便在数据或标签稀缺的情况下进行学习。现有的模型却是域特定的，例如一个基于分子图的模型只能在其他分子图上进行精度调整。这意味着在许多应用场景中，选择预训练模型的问题可能是随意的，而新的域可能缺乏适当的预训练模型。这对于数据稀缺的情况是特别问题。在这种情况下，我们使用对抗性强化学习方法来提出一种\method，一个在多个图域上预训练的模型。我们只在结构上训练这个模型，而不包括节点标签在评估中。我们对这种学习得到的表示进行评估，并与基eline模型、未经训练的模型和非转移模型进行比较。我们发现，使用我们的单一模型，表示性能与基eline模型或未经训练的模型相当或更好，尤其是在节点标签被用于评估时。
</details></li>
</ul>
<hr>
<h2 id="An-Expectation-Realization-Model-for-Metaphor-Detection"><a href="#An-Expectation-Realization-Model-for-Metaphor-Detection" class="headerlink" title="An Expectation-Realization Model for Metaphor Detection"></a>An Expectation-Realization Model for Metaphor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03963">http://arxiv.org/abs/2311.03963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oseremen O. Uduehi, Razvan C. Bunescu</li>
<li>for: 本研究旨在提出一种基于两个主要模块的μETD概念检测架构，以优化μETD的表达能力。</li>
<li>methods: 该架构包括一个期望组件，用于估计上下文中Literal word的表达，以及一个现实组件，用于计算上下文中Actual word的表达。整个架构通过学习期望-现实（ER）模式来学习μETD的概念用语。</li>
<li>results: 对于三个μETD数据集（ dentro分布、外部分布和新型μETD泛化）的评估，提出的方法能够取得与现有状态艺术的或更好的结果。此外，通过ER模型 ensemble的方式，进一步提高μETD检测精度。<details>
<summary>Abstract</summary>
We propose a metaphor detection architecture that is structured around two main modules: an expectation component that estimates representations of literal word expectations given a context, and a realization component that computes representations of actual word meanings in context. The overall architecture is trained to learn expectation-realization (ER) patterns that characterize metaphorical uses of words. When evaluated on three metaphor datasets for within distribution, out of distribution, and novel metaphor generalization, the proposed method is shown to obtain results that are competitive or better than state-of-the art. Further increases in metaphor detection accuracy are obtained through ensembling of ER models.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于两个主要模块的比喻检测架构：一个预期部分，用于在上下文中计算 Literal 词意 Representatives，以及一个实现部分，用于在上下文中计算实际词义 Representatives。整个架构在学习预期-实现（ER）模式上进行训练，以捕捉比喻用语的含义。在三个比喻数据集上进行评估，我们的方法在 dentro 分布、out of distribution 和新比喻泛化方面具有竞争或更好的 результаados。进一步的增加比喻检测精度可以通过 ER 模型的ensemble。Note: " dentro 分布" means "within distribution" in Chinese, "out of distribution" means "外部分布" in Chinese, and "novel metaphor generalization" means "新比喻泛化" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Elastic-Information-Bottleneck"><a href="#Elastic-Information-Bottleneck" class="headerlink" title="Elastic Information Bottleneck"></a>Elastic Information Bottleneck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03955">http://arxiv.org/abs/2311.03955</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyyxxx/elastic-information-bottleneck">https://github.com/nyyxxx/elastic-information-bottleneck</a></li>
<li>paper_authors: Yuyan Ni, Yanyan Lan, Ao Liu, Zhiming Ma</li>
<li>for: 这篇论文的目的是解释深度学习算法中的表示机制，以及两种信息瓶颈方法（IB和DIB）的泛化能力。</li>
<li>methods: 这篇论文使用了两种信息瓶颈方法（IB和DIB），并对它们进行了 theoretically和实验性的分析。</li>
<li>results: 研究发现，IB和DIB在不同的泛化场景下的表现不同，而EIB可以在这些场景下实现更好的泛化效果。<details>
<summary>Abstract</summary>
Information bottleneck is an information-theoretic principle of representation learning that aims to learn a maximally compressed representation that preserves as much information about labels as possible. Under this principle, two different methods have been proposed, i.e., information bottleneck (IB) and deterministic information bottleneck (DIB), and have gained significant progress in explaining the representation mechanisms of deep learning algorithms. However, these theoretical and empirical successes are only valid with the assumption that training and test data are drawn from the same distribution, which is clearly not satisfied in many real-world applications. In this paper, we study their generalization abilities within a transfer learning scenario, where the target error could be decomposed into three components, i.e., source empirical error, source generalization gap (SG), and representation discrepancy (RD). Comparing IB and DIB on these terms, we prove that DIB's SG bound is tighter than IB's while DIB's RD is larger than IB's. Therefore, it is difficult to tell which one is better. To balance the trade-off between SG and the RD, we propose an elastic information bottleneck (EIB) to interpolate between the IB and DIB regularizers, which guarantees a Pareto frontier within the IB framework. Additionally, simulations and real data experiments show that EIB has the ability to achieve better domain adaptation results than IB and DIB, which validates the correctness of our theories.
</details>
<details>
<summary>摘要</summary>
信息瓶颈是一种信息理论的学习原理，旨在学习最紧凑的表示，保持标签信息的最多。在这个原理下，两种不同的方法得到了提案，即信息瓶颈（IB）和决定性信息瓶颈（DIB），在解释深度学习算法的表示机制方面取得了显著进步。然而，这些理论和实验成功假设训练和测试数据是从同一个分布中采样，这并不符合现实世界中许多应用场景。在这篇论文中，我们研究IB和DIB在转移学习场景中的泛化能力，将目标错误分解为三个组分，即源Empirical error、源泛化差（SG）和表示差（RD）。对比IB和DIB，我们证明DIB的SG bound更紧，而DIB的RD更大。因此，无法判断哪一个更好。为了平衡SG和RD之间的负担，我们提出了灵活信息瓶颈（EIB）来 interpolate IB和DIB正则化， garantía IB frameworks 中的Pareto frontier。此外，实验和实际数据表明，EIB可以在适应领域上达到IB和DIB所不能达到的更好的结果，这证明了我们的理论的正确性。
</details></li>
</ul>
<hr>
<h2 id="The-Music-Meta-Ontology-a-flexible-semantic-model-for-the-interoperability-of-music-metadata"><a href="#The-Music-Meta-Ontology-a-flexible-semantic-model-for-the-interoperability-of-music-metadata" class="headerlink" title="The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata"></a>The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03942">http://arxiv.org/abs/2311.03942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacopo de Berardinis, Valentina Anita Carriero, Albert Meroño-Peñuela, Andrea Poltronieri, Valentina Presutti</li>
<li>for: 这篇论文的目的是为了创建一个基于semantic metadata的音乐数据集，以便进行信息检索和知识发现。</li>
<li>methods: 该论文使用了extreme设计方法和数据工程学最佳实践，以满足不同参与者（音乐学家、图书馆员、数据工程师等）的需求，并采用ontology设计模式和证据跟踪。</li>
<li>results: 该论文介绍了Music Meta ontology，一个rich和flexible的semantic模型，用于描述音乐元数据，包括艺术家、作品、演奏、录音等方面。同时，论文还进行了首次评估和其他schema（Music Ontology、DOREMUS、Wikidata）的对接，以及数据转换的支持。<details>
<summary>Abstract</summary>
The semantic description of music metadata is a key requirement for the creation of music datasets that can be aligned, integrated, and accessed for information retrieval and knowledge discovery. It is nonetheless an open challenge due to the complexity of musical concepts arising from different genres, styles, and periods -- standing to benefit from a lingua franca to accommodate various stakeholders (musicologists, librarians, data engineers, etc.). To initiate this transition, we introduce the Music Meta ontology, a rich and flexible semantic model to describe music metadata related to artists, compositions, performances, recordings, and links. We follow eXtreme Design methodologies and best practices for data engineering, to reflect the perspectives and the requirements of various stakeholders into the design of the model, while leveraging ontology design patterns and accounting for provenance at different levels (claims, links). After presenting the main features of Music Meta, we provide a first evaluation of the model, alignments to other schema (Music Ontology, DOREMUS, Wikidata), and support for data transformation.
</details>
<details>
<summary>摘要</summary>
《音乐元数据 semantics 描述是创建可以协调、集成和搜索信息的音乐集成数据的关键要求。然而，这是一个开放的挑战，因为音乐概念来自不同的流派、风格和时期，具有不同的复杂性。为了解决这个问题，我们介绍了音乐元 ontology，一种rich和灵活的semantic模型，用于描述音乐元数据相关的艺术家、作品、表演、录音和链接。我们遵循extreme设计方法和数据工程学的最佳实践，将各种参与者的视角和需求反映到模型的设计中，同时采用ontology设计模式和考虑多维 provinicial（声明、链接）。文章后续介绍了音乐元的主要特点，与其他架构（音乐 ontology、DOREMUS、Wikidata）的对alignment，以及数据转换的支持。
</details></li>
</ul>
<hr>
<h2 id="Everything-of-Thoughts-Defying-the-Law-of-Penrose-Triangle-for-Thought-Generation"><a href="#Everything-of-Thoughts-Defying-the-Law-of-Penrose-Triangle-for-Thought-Generation" class="headerlink" title="Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation"></a>Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04254">http://arxiv.org/abs/2311.04254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang</li>
<li>For: The paper aims to enhance the capabilities of Large Language Models (LLMs) by introducing a novel thought prompting approach called “Everything of Thoughts” (XoT) to improve their ability to generalize to unseen problems efficiently.* Methods: The approach leverages pretrained reinforcement learning and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge into thoughts, and autonomously produces high-quality comprehensive cognitive mappings with minimal LLM interactions.* Results: The approach enables LLMs to engage in unconstrained thinking, allowing for flexible cognitive mappings for problems with multiple solutions.Here’s the simplified Chinese text for the three information points:* For: 这篇论文目的是提高大语言模型（LLM）的能力，通过引入“Everything of Thoughts”（XoT）思维推动方法，使其更好地处理未经见过的问题。* Methods: XoT方法利用预训练的奖励学习和 Monte Carlo Tree Search（MCTS），将外部领域知识integrated into思维，并通过LLM自动生成高质量的全面认知地图，减少LLM与人类交互。* Results: XoT方法使LLM可以进行不受限制的思考，允许它们对多个解决方案进行灵活的认知映射。<details>
<summary>Abstract</summary>
Recent advancements in Large Language Models (LLMs) have revolutionized decision-making by breaking down complex problems into more manageable language sequences referred to as ``thoughts''. An effective thought design should consider three key perspectives: performance, efficiency, and flexibility. However, existing thought can at most exhibit two of these attributes. To address these limitations, we introduce a novel thought prompting approach called ``Everything of Thoughts'' (XoT) to defy the law of ``Penrose triangle of existing thought paradigms. XoT leverages pretrained reinforcement learning and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge into thoughts, thereby enhancing LLMs' capabilities and enabling them to generalize to unseen problems efficiently. Through the utilization of the MCTS-LLM collaborative thought revision framework, this approach autonomously produces high-quality comprehensive cognitive mappings with minimal LLM interactions. Additionally, XoT empowers LLMs to engage in unconstrained thinking, allowing for flexible cognitive mappings for problems with multiple solutions.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近的大语言模型（LLMs）革命化了决策，将复杂问题分解成更容易处理的语言序列，称为“思想”。一个有效的思想设计应考虑三个关键方面：性能、效率和灵活性。然而，现有的思想只能展现两个特征。为了解决这些限制，我们介绍了一种新的思想推荐方法called“everything of thoughts”（XoT），以推翻现有思想 парадигмы的“彭罗斯三角形法则”。XoT利用预训练的奖励学习和Monte Carlo Tree Search（MCTS），将外部领域知识 integrate into thoughts，从而提高LLMs的能力和通用性。通过MCTS-LLM共同思想修订框架，这种方法可以自动生成高质量的完整认知地图，并且减少LLM的交互次数。此外，XoT赋予LLMs无约束的思维能力，允许它们为多解问题生成灵活的认知地图。
</details></li>
</ul>
<hr>
<h2 id="MixtureGrowth-Growing-Neural-Networks-by-Recombining-Learned-Parameters"><a href="#MixtureGrowth-Growing-Neural-Networks-by-Recombining-Learned-Parameters" class="headerlink" title="MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters"></a>MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04251">http://arxiv.org/abs/2311.04251</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chaudatascience/mixturegrowth">https://github.com/chaudatascience/mixturegrowth</a></li>
<li>paper_authors: Chau Pham, Piotr Teterwak, Soren Nelson, Bryan A. Plummer</li>
<li>for: 这 paper 是为了解决深度神经网络在不同网络结构下进行训练的问题，以及在提高网络大小时不需要从 scratch 重新训练的问题。</li>
<li>methods: 这 paper 使用了 MixtureGrowth 方法，这是一种基于 linear combination 的方法，通过将每层的 parameter templates 组合成新的 linear combination，以生成新层的 weight。这种方法可以减少 initialize 过程中的噪声，并且可以充分利用已经学习过的 weight。</li>
<li>results: 这 paper 的实验结果表明，MixtureGrowth 方法可以在 CIFAR-100 和 ImageNet  datasets 上提高 top-1 准确率，而且与 fewer FLOPs 的情况下和一个从 scratch 训练的大网络相比，性能相似。code 可以在 <a target="_blank" rel="noopener" href="https://github.com/chaudatascience/mixturegrowth">https://github.com/chaudatascience/mixturegrowth</a> 上获取。<details>
<summary>Abstract</summary>
Most deep neural networks are trained under fixed network architectures and require retraining when the architecture changes. If expanding the network's size is needed, it is necessary to retrain from scratch, which is expensive. To avoid this, one can grow from a small network by adding random weights over time to gradually achieve the target network size. However, this naive approach falls short in practice as it brings too much noise to the growing process. Prior work tackled this issue by leveraging the already learned weights and training data for generating new weights through conducting a computationally expensive analysis step. In this paper, we introduce MixtureGrowth, a new approach to growing networks that circumvents the initialization overhead in prior work. Before growing, each layer in our model is generated with a linear combination of parameter templates. Newly grown layer weights are generated by using a new linear combination of existing templates for a layer. On one hand, these templates are already trained for the task, providing a strong initialization. On the other, the new coefficients provide flexibility for the added layer weights to learn something new. We show that our approach boosts top-1 accuracy over the state-of-the-art by 2-2.5% on CIFAR-100 and ImageNet datasets, while achieving comparable performance with fewer FLOPs to a larger network trained from scratch. Code is available at https://github.com/chaudatascience/mixturegrowth.
</details>
<details>
<summary>摘要</summary>
大多数深度神经网络在固定网络架构下训练，需要重新训练当网络架构发生变化时。如果需要扩大网络的大小，则需要从头开始训练，这是昂贵的。为了避免这个问题，一些先前的方法是通过逐渐添加随机权重来慢慢地实现目标网络大小。然而，这种简单的方法在实践中失败了，因为它会带来太多的噪声。先前的工作是通过使用已经学习过的权重和训练数据来生成新的权重，进行计算昂贵的分析步骤。在这篇论文中，我们介绍了 MixtureGrowth，一种新的网络增长方法，可以绕过先前的初始化开销。在我们的模型中，每个层都是通过线性组合参数模板来生成。新增的层权重是通过使用新的线性组合已有层的参数模板来生成的。一方面，这些模板已经被训练了任务，可以提供强大的初始化。另一方面，新的系数提供了对新增层权重进行学习的灵活性。我们表明，我们的方法可以在CIFAR-100和ImageNet datasets上提高顶部1的准确率，相比之下，需要更多的FLOPs来训练一个从头开始的更大的网络。代码可以在https://github.com/chaudatascience/mixturegrowth上找到。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Graph-Representation-Learning-with-Adaptive-Augmentation-Contrastive"><a href="#Temporal-Graph-Representation-Learning-with-Adaptive-Augmentation-Contrastive" class="headerlink" title="Temporal Graph Representation Learning with Adaptive Augmentation Contrastive"></a>Temporal Graph Representation Learning with Adaptive Augmentation Contrastive</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03897">http://arxiv.org/abs/2311.03897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongjiang Chen, Pengfei Jiao, Huijun Tang, Huaming Wu</li>
<li>for: 本文旨在提出一种Temporal Graph representation learning方法，用于生成低维度的动态节点嵌入，以捕捉时间信息以及结构和属性信息。</li>
<li>methods: 本方法使用 adaptive augmentation contrastive 对时间图进行增强，并定义了扩展的对比目标函数，以适应时间依赖的噪声。</li>
<li>results: 对多个实际网络进行了广泛的实验，并证明了该方法能够超过其他时间图表示学习方法。<details>
<summary>Abstract</summary>
Temporal graph representation learning aims to generate low-dimensional dynamic node embeddings to capture temporal information as well as structural and property information. Current representation learning methods for temporal networks often focus on capturing fine-grained information, which may lead to the model capturing random noise instead of essential semantic information. While graph contrastive learning has shown promise in dealing with noise, it only applies to static graphs or snapshots and may not be suitable for handling time-dependent noise. To alleviate the above challenge, we propose a novel Temporal Graph representation learning with Adaptive augmentation Contrastive (TGAC) model. The adaptive augmentation on the temporal graph is made by combining prior knowledge with temporal information, and the contrastive objective function is constructed by defining the augmented inter-view contrast and intra-view contrast. To complement TGAC, we propose three adaptive augmentation strategies that modify topological features to reduce noise from the network. Our extensive experiments on various real networks demonstrate that the proposed model outperforms other temporal graph representation learning methods.
</details>
<details>
<summary>摘要</summary>
现代 temporal graph 表示学习的目标是生成低维度的动态节点嵌入，以捕捉 temporal 信息以及结构和属性信息。现有的 temporal network 表示学习方法通常强调细化信息，可能导致模型捕捉Random 噪音而不是重要的semantic信息。而graph contrastive learning 已经在 dealing  with noise 方面表现出了 promise,但它只适用于静止图或快照，可能不适用于处理时间相关的噪音。为了解决这一挑战，我们提出了一种新的 Temporal Graph 表示学习 with Adaptive augmentation Contrastive (TGAC) 模型。在 TGAC 模型中，我们通过结合先前知识与时间信息来实现可变的扩充，并定义了扩充后的对比对象函数。此外，我们还提出了三种适应的扩充策略，可以通过修改 topological 特征来减少网络中的噪音。我们对多种实际网络进行了广泛的实验，结果显示，我们提出的模型在 temporal graph 表示学习方法中占据了优势。
</details></li>
</ul>
<hr>
<h2 id="Unifying-Structure-and-Language-Semantic-for-Efficient-Contrastive-Knowledge-Graph-Completion-with-Structured-Entity-Anchors"><a href="#Unifying-Structure-and-Language-Semantic-for-Efficient-Contrastive-Knowledge-Graph-Completion-with-Structured-Entity-Anchors" class="headerlink" title="Unifying Structure and Language Semantic for Efficient Contrastive Knowledge Graph Completion with Structured Entity Anchors"></a>Unifying Structure and Language Semantic for Efficient Contrastive Knowledge Graph Completion with Structured Entity Anchors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04250">http://arxiv.org/abs/2311.04250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sang-Hyun Je, Wontae Choi, Kwangjin Oh</li>
<li>for: 这篇论文的目的是提出一种能够有效地结合结构信息和语言 semantics的方法，以提高知识图（KG）Completion 的性能。</li>
<li>methods: 本文提出的方法使用了预训练语言模型（PLM），并将结构信息和语言表示相结合，以学习一种统一的表示。此外，该方法还使用了随机负样本，可以在每个小批量中进行对照学习，以学习一种通用的实体表示。</li>
<li>results: 经过多种实验和分析，本文证明了该方法在标准的链接预测任务中的表现，超过了现有的最佳知识图完成（KGC）模型。尤其是在 FB15K-237 上，该方法的表现和结构基础 KGC 方法相当。<details>
<summary>Abstract</summary>
The goal of knowledge graph completion (KGC) is to predict missing links in a KG using trained facts that are already known. In recent, pre-trained language model (PLM) based methods that utilize both textual and structural information are emerging, but their performances lag behind state-of-the-art (SOTA) structure-based methods or some methods lose their inductive inference capabilities in the process of fusing structure embedding to text encoder. In this paper, we propose a novel method to effectively unify structure information and language semantics without losing the power of inductive reasoning. We adopt entity anchors and these anchors and textual description of KG elements are fed together into the PLM-based encoder to learn unified representations. In addition, the proposed method utilizes additional random negative samples which can be reused in the each mini-batch during contrastive learning to learn a generalized entity representations. We verify the effectiveness of the our proposed method through various experiments and analysis. The experimental results on standard benchmark widely used in link prediction task show that the proposed model outperforms existing the SOTA KGC models. Especially, our method show the largest performance improvement on FB15K-237, which is competitive to the SOTA of structure-based KGC methods.
</details>
<details>
<summary>摘要</summary>
目标是完成知识图（KG），预训练语言模型（PLM）基本方法可以利用文本和结构信息，但表现落后于现有的结构基本方法或一些方法在结构嵌入文本编码器时失去了推理能力。在这篇论文中，我们提出了一种新的方法，可以有效地融合结构信息和语言 semantics，不失 induction 推理能力。我们采用实体锚点，并将 KG 元素的文本描述和实体锚点一起 fed 到 PLM 基本编码器中，以学习统一表示。此外，我们还使用随机负样本，可以在每个 mini-batch 中重复使用，以在对比学习中学习通用实体表示。我们通过多种实验和分析证明了方法的有效性。实验结果表明，我们提出的方法在标准的链接预测任务中表现出色，尤其是在 FB15K-237 上，与结构基本方法具有竞争力。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Tool-Discovery-and-Tool-Innovation-Using-Active-Inference"><a href="#Understanding-Tool-Discovery-and-Tool-Innovation-Using-Active-Inference" class="headerlink" title="Understanding Tool Discovery and Tool Innovation Using Active Inference"></a>Understanding Tool Discovery and Tool Innovation Using Active Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03893">http://arxiv.org/abs/2311.03893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Poppy Collis, Paul F Kinghorn, Christopher L Buckley</li>
<li>for: 本研究旨在探讨人工智能代理者如何创造新工具，以便在动态和新环境中解决问题。</li>
<li>methods: 本研究使用活动推断 formalism 进行工具发现和工具创新的分类，并在代理者的潜在生成模型中引入工具可用性的概念，以便通过离线推导实现工具的发明。</li>
<li>results: 本研究预示了在潜在生成模型中引入工具可用性的概念可以使代理者不仅发现工具，而且还能够创造新的工具。<details>
<summary>Abstract</summary>
The ability to invent new tools has been identified as an important facet of our ability as a species to problem solve in dynamic and novel environments. While the use of tools by artificial agents presents a challenging task and has been widely identified as a key goal in the field of autonomous robotics, far less research has tackled the invention of new tools by agents. In this paper, (1) we articulate the distinction between tool discovery and tool innovation by providing a minimal description of the two concepts under the formalism of active inference. We then (2) apply this description to construct a toy model of tool innovation by introducing the notion of tool affordances into the hidden states of the agent's probabilistic generative model. This particular state factorisation facilitates the ability to not just discover tools but invent them through the offline induction of an appropriate tool property. We discuss the implications of these preliminary results and outline future directions of research.
</details>
<details>
<summary>摘要</summary>
人类的问题解决能力中，发明新工具的能力被认为是一项重要的特征。虽然人工智能代理人使用工具是一项复杂的任务，但是对于代理人发明新工具的研究远未得到广泛的探讨。在这篇论文中，我们（1）将工具发现和工具创新两个概念进行了明确的分别，通过活动推断 formalism 的最小描述。然后我们（2）将这个描述应用到构建了一个简单的工具创新模型，通过引入工具可用性的概念来扩展代理人的生成模型中的隐藏状态。这种状态分解使得代理人不仅能够发现工具，还能通过离线推导出适当的工具性质来创造新的工具。我们讨论了这些初步结果的意义和未来研究的方向。
</details></li>
</ul>
<hr>
<h2 id="Formulating-Discrete-Probability-Flow-Through-Optimal-Transport"><a href="#Formulating-Discrete-Probability-Flow-Through-Optimal-Transport" class="headerlink" title="Formulating Discrete Probability Flow Through Optimal Transport"></a>Formulating Discrete Probability Flow Through Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03886">http://arxiv.org/abs/2311.03886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pangzecheung/discrete-probability-flow">https://github.com/pangzecheung/discrete-probability-flow</a></li>
<li>paper_authors: Pengze Zhang, Hubery Yin, Chen Li, Xiaohua Xie</li>
<li>for: 本研究旨在建立抽象扩散模型中的概率流动理论。</li>
<li>methods: 我们首先证明了连续概率流动是 Монже优化运输图的某种情况，并在相应的条件下提供了对应的证明。然后，我们定义了离散概率流动，并基于这些定义提出了一种新的采样方法。</li>
<li>results: 我们通过对synthetic toy dataset和CIFAR-10 dataset的广泛实验 validated了我们提出的离散概率流动的效果。代码可以在<a target="_blank" rel="noopener" href="https://github.com/PangzeCheung/Discrete-Probability-Flow%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/PangzeCheung/Discrete-Probability-Flow中找到。</a><details>
<summary>Abstract</summary>
Continuous diffusion models are commonly acknowledged to display a deterministic probability flow, whereas discrete diffusion models do not. In this paper, we aim to establish the fundamental theory for the probability flow of discrete diffusion models. Specifically, we first prove that the continuous probability flow is the Monge optimal transport map under certain conditions, and also present an equivalent evidence for discrete cases. In view of these findings, we are then able to define the discrete probability flow in line with the principles of optimal transport. Finally, drawing upon our newly established definitions, we propose a novel sampling method that surpasses previous discrete diffusion models in its ability to generate more certain outcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10 dataset have validated the effectiveness of our proposed discrete probability flow. Code is released at: https://github.com/PangzeCheung/Discrete-Probability-Flow.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译为简化中文。<</SYS>>连续扩散模型通常被认为展示束定概率流，而离散扩散模型则不然。在这篇论文中，我们目标是建立离散概率流的基本理论。 Specifically，我们首先证明了连续概率流是在某些条件下的蒙日最优运输地图，并同时提供了对应的离散情况证明。基于这些发现，我们然后可以定义离散概率流，与最优运输原理相符。最后，我们基于我们 newly established definitions，提出了一种新的采样方法，能够更加准确地生成结果。 extend 的实验在 sintetic 玩具数据集和 CIFAR-10 数据集上验证了我们的提议的离散概率流的效果。 Code 可以在：https://github.com/PangzeCheung/Discrete-Probability-Flow 中找到。
</details></li>
</ul>
<hr>
<h2 id="Mini-but-Mighty-Finetuning-ViTs-with-Mini-Adapters"><a href="#Mini-but-Mighty-Finetuning-ViTs-with-Mini-Adapters" class="headerlink" title="Mini but Mighty: Finetuning ViTs with Mini Adapters"></a>Mini but Mighty: Finetuning ViTs with Mini Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03873">http://arxiv.org/abs/2311.03873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iemprog/mimi">https://github.com/iemprog/mimi</a></li>
<li>paper_authors: Imad Eddine Marouf, Enzo Tartaglione, Stéphane Lathuilière</li>
<li>for: 这个论文主要是为了提出一种能够减少精度转移学习的批处理方法，以提高计算机视觉任务中的模型表现。</li>
<li>methods: 这个论文使用了一种名为MiMi的培训框架，该框架可以自动调整精度转移学习中adapter的维度，以达到最佳的质量和精度之间的平衡。</li>
<li>results: 根据实验结果，MiMi方法可以在3个数据集上 benchmark（DomainNet、VTAB和Multi-task）上对29个数据集进行最佳的质量和精度之间的平衡。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have become one of the dominant architectures in computer vision, and pre-trained ViT models are commonly adapted to new tasks via fine-tuning. Recent works proposed several parameter-efficient transfer learning methods, such as adapters, to avoid the prohibitive training and storage cost of finetuning. In this work, we observe that adapters perform poorly when the dimension of adapters is small, and we propose MiMi, a training framework that addresses this issue. We start with large adapters which can reach high performance, and iteratively reduce their size. To enable automatic estimation of the hidden dimension of every adapter, we also introduce a new scoring function, specifically designed for adapters, that compares the neuron importance across layers. Our method outperforms existing methods in finding the best trade-off between accuracy and trained parameters across the three dataset benchmarks DomainNet, VTAB, and Multi-task, for a total of 29 datasets.
</details>
<details>
<summary>摘要</summary>
视Transformers（ViTs）已经成为计算机视觉领域的主导体系，而预训练ViT模型通常通过精度调整来适应新任务。最近的工作提出了一些精度效率的传输学习方法，如适配器，以避免训练和存储成本过高。在这种情况下，我们发现适配器的维度很小时表现不佳，我们提出了MiMi，一个培训框架，解决这个问题。我们从大的适配器开始，然后逐渐减小它们，以达到高性能。为了自动估计每个适配器的隐藏维度，我们还引入了一个专门设计 для适配器的新评分函数，用于比较层次中的神经元重要性。我们的方法在DomainNet、VTAB和多任务三个数据集上的29个数据集上超过了现有方法，在找到最佳的准确率和训练参数之间的折衔。
</details></li>
</ul>
<hr>
<h2 id="FD-MIA-Efficient-Attacks-on-Fairness-enhanced-Models"><a href="#FD-MIA-Efficient-Attacks-on-Fairness-enhanced-Models" class="headerlink" title="FD-MIA: Efficient Attacks on Fairness-enhanced Models"></a>FD-MIA: Efficient Attacks on Fairness-enhanced Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03865">http://arxiv.org/abs/2311.03865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huan Tian, Guangsheng Zhang, Bo Liu, Tianqing Zhu, Ming Ding, Wanlei Zhou</li>
<li>for: 这个研究旨在测试满足平等需求的模型对于特定子集的攻击敏感性。</li>
<li>methods: 该研究使用了分别对于原始模型和平等增强模型进行预测分析，以探索攻击者可能对于这些模型发动的攻击方法。</li>
<li>results: 研究发现，对于平等增强模型，攻击者无法成功发动攻击，因为这些模型在预测分析中具有较高的防护性。同时，该研究发现，平等方法通常会导致训练资料中主要子集的预测性下降，这使得攻击更加困难且预测距离增加。建基于这些见解，该研究提出了一种高效的攻击方法，基于平等违背结果（FD-MIA），并考虑了防止隐私泄露的策略。实验结果证明了这些发现和方法的有效性。<details>
<summary>Abstract</summary>
Previous studies have developed fairness methods for biased models that exhibit discriminatory behaviors towards specific subgroups. While these models have shown promise in achieving fair predictions, recent research has identified their potential vulnerability to score-based membership inference attacks (MIAs). In these attacks, adversaries can infer whether a particular data sample was used during training by analyzing the model's prediction scores. However, our investigations reveal that these score-based MIAs are ineffective when targeting fairness-enhanced models in binary classifications. The attack models trained to launch the MIAs degrade into simplistic threshold models, resulting in lower attack performance. Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon these insights, we propose an efficient MIA method against fairness-enhanced models based on fairness discrepancy results (FD-MIA). It leverages the difference in the predictions from both the original and fairness-enhanced models and exploits the observed prediction gaps as attack clues. We also explore potential strategies for mitigating privacy leakages. Extensive experiments validate our findings and demonstrate the efficacy of the proposed method.
</details>
<details>
<summary>摘要</summary>
Our research shows that these score-based MIAs are not effective against fairness-enhanced models in binary classifications. The attack models become too simple and do not work well. We also find that fairness methods can lead to a decrease in prediction performance for the majority group in the training data. This makes it harder for the attacker to succeed and increases the difference between the predictions for members and non-members.Based on these findings, we propose a new method for membership inference attacks (MIAs) against fairness-enhanced models. Our method uses the difference in predictions from the original and fairness-enhanced models to identify potential members. We also explore ways to reduce the risk of privacy leaks.We conducted extensive experiments to test our method and found that it is effective in identifying members. Our results show that the proposed method can be used to launch successful membership inference attacks against fairness-enhanced models.
</details></li>
</ul>
<hr>
<h2 id="Aspects-of-human-memory-and-Large-Language-Models"><a href="#Aspects-of-human-memory-and-Large-Language-Models" class="headerlink" title="Aspects of human memory and Large Language Models"></a>Aspects of human memory and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03839">http://arxiv.org/abs/2311.03839</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rmldj/memory-llm-paper">https://github.com/rmldj/memory-llm-paper</a></li>
<li>paper_authors: Romuald A. Janik</li>
<li>for: 这个论文 investigate LLMs 的内存特性，了解它们是如何模拟人类内存的。</li>
<li>methods: 该论文使用 LLMs 来生成文本，并通过分析其内存特性来探讨人类内存的特征。</li>
<li>results: 研究发现，LLMs 的内存特性与人类内存有 surprisingly 的相似之处，这表明人类内存的特征对文本结构产生了深刻的影响。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are huge artificial neural networks which primarily serve to generate text, but also provide a very sophisticated probabilistic model of language use. Since generating a semantically consistent text requires a form of effective memory, we investigate the memory properties of LLMs and find surprising similarities with key characteristics of human memory. This result strongly suggests that the biological features of human memory leave an imprint on the way that we structure our textual narratives.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Reducing-Spatial-Fitting-Error-in-Distillation-of-Denoising-Diffusion-Models"><a href="#Reducing-Spatial-Fitting-Error-in-Distillation-of-Denoising-Diffusion-Models" class="headerlink" title="Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models"></a>Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03830">http://arxiv.org/abs/2311.03830</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sainzerjj/SFERD">https://github.com/Sainzerjj/SFERD</a></li>
<li>paper_authors: Shengzhe Zhou, Zejian Lee, Shengyuan Zhang, Lefan Hou, Changyuan Yang, Guang Yang, Lingyun Sun</li>
<li>For: 增强 diffusion models 的图像生成质量* Methods: 使用 attention 导航和设计的 semantics 梯度预测器来减少学生模型的适应错误* Results: 实验表明，我们提出的模型可以在几个函数评估中生成高质量图像，FID 值为 5.31 和 9.39，超越现有的扩散方法。<details>
<summary>Abstract</summary>
Denoising Diffusion models have exhibited remarkable capabilities in image generation. However, generating high-quality samples requires a large number of iterations. Knowledge distillation for diffusion models is an effective method to address this limitation with a shortened sampling process but causes degraded generative quality. Based on our analysis with bias-variance decomposition and experimental observations, we attribute the degradation to the spatial fitting error occurring in the training of both the teacher and student model. Accordingly, we propose $\textbf{S}$patial $\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction $\textbf{D}$istillation model ($\textbf{SFERD}$). SFERD utilizes attention guidance from the teacher model and a designed semantic gradient predictor to reduce the student's fitting error. Empirically, our proposed model facilitates high-quality sample generation in a few function evaluations. We achieve an FID of 5.31 on CIFAR-10 and 9.39 on ImageNet 64$\times$64 with only one step, outperforming existing diffusion methods. Our study provides a new perspective on diffusion distillation by highlighting the intrinsic denoising ability of models.
</details>
<details>
<summary>摘要</summary>
difang de denoising diffusion models 有非常出色的� image generation 能力。然而，生成高质量样本需要很多迭代。知识储存法为 diffusion models 是一种有效的方法，可以缩短样本生成过程，但会导致生成质量下降。根据我们的分析和实验观察，我们认为这种下降是在教师和学生模型的训练中发生的空间适应错误。因此，我们提出了 $\textbf{S}$patial $\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction $\textbf{D}$istillation model ($\textbf{SFERD}$). SFERD 使用教师模型的注意力引导和设计的 semantics 梯度预测器来减少学生模型的适应错误。我们的提出的模型可以在几个函数评估中生成高质量样本，我们在 CIFAR-10 和 ImageNet 64$\times$64 上达到了 FID 5.31 和 9.39，比现有的扩散方法更高。我们的研究提供了一个新的� diffusion distillation 的视角，强调模型的内在杂净能力。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-and-Improving-Multi-task-Learning-for-End-to-end-Speech-Translation"><a href="#Rethinking-and-Improving-Multi-task-Learning-for-End-to-end-Speech-Translation" class="headerlink" title="Rethinking and Improving Multi-task Learning for End-to-end Speech Translation"></a>Rethinking and Improving Multi-task Learning for End-to-end Speech Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03810">http://arxiv.org/abs/2311.03810</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaozhang521/imtl">https://github.com/xiaozhang521/imtl</a></li>
<li>paper_authors: Yuhao Zhang, Chen Xu, Bei Li, Hao Chen, Tong Xiao, Chunliang Zhang, Jingbo Zhu</li>
<li>for: 这篇论文主要用于探讨多任务学习在端到端语音翻译（ST）中的应用，以及这种方法在ST任务中是否真正有助于提高翻译质量。</li>
<li>methods: 这篇论文使用了多任务学习方法，包括文本编码器和语音编码器之间的交互，以及对不同时间和模块进行研究。</li>
<li>results: 研究发现，文本编码器主要帮助实现跨Modal的转换，但是在语音中存在噪声会降低语音和文本表示之间的一致性。 authors也提出了一种改进的多任务学习方法（IMTL），可以减轻模式差异和表示差异，从而提高翻译质量。 experiments在MuST-C数据集上进行，结果显示，我们的方法可以达到领先的 result，而且在添加更多数据后，我们的方法在MuST-C英语到西班牙语任务上达到了新的SOTA result，只用20.8%的训练时间。<details>
<summary>Abstract</summary>
Significant improvements in end-to-end speech translation (ST) have been achieved through the application of multi-task learning. However, the extent to which auxiliary tasks are highly consistent with the ST task, and how much this approach truly helps, have not been thoroughly studied. In this paper, we investigate the consistency between different tasks, considering different times and modules. We find that the textual encoder primarily facilitates cross-modal conversion, but the presence of noise in speech impedes the consistency between text and speech representations. Furthermore, we propose an improved multi-task learning (IMTL) approach for the ST task, which bridges the modal gap by mitigating the difference in length and representation. We conduct experiments on the MuST-C dataset. The results demonstrate that our method attains state-of-the-art results. Moreover, when additional data is used, we achieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the training time required by the current SOTA method.
</details>
<details>
<summary>摘要</summary>
significan mejora en la traducción de speech a extremo (ST) se ha logrado a través de la aprendizaje de tareas múltiples. Sin embargo, no se ha estudiado en profundidad el extent to which las tareas auxiliares son consistentes con la tarea ST, y cómo realmente ayudan. En este artículo, investigamos la consistencia entre diferentes tareas, considerando diferentes momentos y módulos. Encontramos que el encoder textual principal facilita la conversión cross-modal, pero la presencia de ruido en el speech impide la consistencia entre las representaciones de texto y speech. Además, propusimos un enfoque de aprendizaje de múltiples tareas mejorado (IMTL) para la tarea ST, que reduce la brecha modal al mitigar la diferencia de longitud y representación. Realizamos experimentos en el conjunto de datos MuST-C. Los resultados demuestran que nuestro método logra resultados estatales del arte. Además, cuando se utiliza más datos, podemos alcanzar un nuevo resultado de SOTA en la tarea de inglés a español de MuST-C con solo el 20.8% del tiempo de entrenamiento requerido por el método SOTA actual.
</details></li>
</ul>
<hr>
<h2 id="Scene-Driven-Multimodal-Knowledge-Graph-Construction-for-Embodied-AI"><a href="#Scene-Driven-Multimodal-Knowledge-Graph-Construction-for-Embodied-AI" class="headerlink" title="Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI"></a>Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03783">http://arxiv.org/abs/2311.03783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Yaoxian, Sun Penglei, Liu Haoyu, Li Zhixu, Song Wei, Xiao Yanghua, Zhou Xiaofang</li>
<li>for: 提高机器人智能，增强机器人在 varied open world 中的决策能力</li>
<li>methods: 组合传统知识工程和大型自然语言模型，构建场景驱动多Modal知识图（Scene-MMKG）</li>
<li>results: 比较研究表明，我们的实现的 ManipMob-MMKG 在数据采集效率和知识质量方面具有广泛的优势，可以提高基于知识的机器人任务性能。<details>
<summary>Abstract</summary>
Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority in data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly. Our project can be found at https://sites.google.com/view/manipmob-mmkg
</details>
<details>
<summary>摘要</summary>
人工智能中的具体AI是现代人工智能和机器人学的一个最受欢迎的研究领域，可以有效提高真实世界中的代理人（即机器人）的智能水平。场景知识是一个代理人理解围场和做出正确决策的关键。现有的知识库 для具体任务缺失，大多数现有工作使用通用知识库或预训练模型来提高代理人的智能水平。传统的知识库缺乏、容易受到数据收集成本的限制，而预训练模型则面临知识不确定性和维护困难。为了突破场景知识的挑战，我们提出了场景驱动多Modal知识图（Scene-MMKG）建构方法，结合传统知识工程和大语言模型。我们引入了一个统一的场景知识注入框架，以便知识表示。为了评估我们提出的方法的优势，我们实例化Scene-MMKG，并考虑典型的室内机器人功能（操作和移动），称之为ManipMob-MMKG。对比特点表明，我们的实例化ManipMob-MMKG在数据采集效率和知识质量方面有广泛的优势。实验结果表明，使用我们的实例化ManipMob-MMKG可以明显提高代理人的性能，而不需要复杂地重构模型结构。我们的项目可以在https://sites.google.com/view/manipmob-mmkg 找到。
</details></li>
</ul>
<hr>
<h2 id="Ensembling-Textual-and-Structure-Based-Models-for-Knowledge-Graph-Completion"><a href="#Ensembling-Textual-and-Structure-Based-Models-for-Knowledge-Graph-Completion" class="headerlink" title="Ensembling Textual and Structure-Based Models for Knowledge Graph Completion"></a>Ensembling Textual and Structure-Based Models for Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03780">http://arxiv.org/abs/2311.03780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ananjan Nandi, Navdeep Kaur, Parag Singla, Mausam</li>
<li>for: 这个论文主要用于研究知识图补充（KGC）领域中，两种流行的方法：文本模型和结构基于模型。</li>
<li>methods: 这个论文使用了两种方法：文本模型和结构基于模型。文本模型利用知识图中实体描述文本，而结构基于模型则利用知识图中的结构特征。</li>
<li>results: 这个论文的实验结果表明，这两种方法有补充性的优势：结构基于模型在知识图中找到答案的路径较短，而文本模型可以通过描述文本来提高完tenancy。 ensemble weights by using the distributions of scores assigned by individual models to all candidate entities. Our ensemble baseline achieves state-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models.<details>
<summary>Abstract</summary>
We consider two popular approaches to Knowledge Graph Completion (KGC): textual models that rely on textual entity descriptions, and structure-based models that exploit the connectivity structure of the Knowledge Graph (KG). Preliminary experiments show that these approaches have complementary strengths: structure-based models perform well when the gold answer is easily reachable from the query head in the KG, while textual models exploit descriptions to give good performance even when the gold answer is not reachable. In response, we explore ensembling as a way of combining the best of both approaches. We propose a novel method for learning query-dependent ensemble weights by using the distributions of scores assigned by individual models to all candidate entities. Our ensemble baseline achieves state-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models.
</details>
<details>
<summary>摘要</summary>
我们考虑了两种受欢迎的知识图完成（KGC）方法：文本模型，它们基于知识图中实体描述文本，以及结构基于模型，它们利用知识图中实体之间的连接结构。我们的初步实验表明，这两种方法具有补做的优势：结构基于模型在知识图中可以快速到达答案，而文本模型可以通过描述来提供良好的性能，即使答案不可达。因此，我们研究 ensemble 的方式来结合这两种方法。我们提出了一种基于查询的 ensemble 学习方法，使用各个模型对所有候选实体分配得分的分布来学习查询取向的 ensemble 权重。我们的ensemble基线达到了三个标准 KGC 数据集的state-of-the-art Result，与最佳个体模型相比，提高了6.8pt MRR和8.3pt Hits@1。
</details></li>
</ul>
<hr>
<h2 id="PT-Tuning-Bridging-the-Gap-between-Time-Series-Masked-Reconstruction-and-Forecasting-via-Prompt-Token-Tuning"><a href="#PT-Tuning-Bridging-the-Gap-between-Time-Series-Masked-Reconstruction-and-Forecasting-via-Prompt-Token-Tuning" class="headerlink" title="PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction and Forecasting via Prompt Token Tuning"></a>PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction and Forecasting via Prompt Token Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03768">http://arxiv.org/abs/2311.03768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Liu, Jinrui Gan, Xiaoxuan Fan, Yi Zhang, Chuanxian Luo, Jing Zhang, Guangxin Jiang, Yucheng Qian, Changwei Zhao, Huan Ma, Zhenyu Guo</li>
<li>for:  bridging the gap between time series masked reconstruction and forecasting</li>
<li>methods:  reserving pre-trained mask tokens during fine-tuning stage and using prompt token tuning (PT-Tuning)</li>
<li>results:  state-of-the-art performance compared to representation learning and end-to-end supervised forecasting methodsHere’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在 bridging the gap between 时间序列做masked reconstruction和预测</li>
<li>methods: 在练习阶段保留预训decoder，并使用prompt token tuning (PT-Tuning)</li>
<li>results: 比 represenation learning和端到端supervised forecasting方法 obtener了state-of-the-art的性能I hope that helps!<details>
<summary>Abstract</summary>
Self-supervised learning has been actively studied in time series domain recently, especially for masked reconstruction. Most of these methods follow the "Pre-training + Fine-tuning" paradigm in which a new decoder replaces the pre-trained decoder to fit for a specific downstream task, leading to inconsistency of upstream and downstream tasks. In this paper, we first point out that the unification of task objectives and adaptation for task difficulty are critical for bridging the gap between time series masked reconstruction and forecasting. By reserving the pre-trained mask token during fine-tuning stage, the forecasting task can be taken as a special case of masked reconstruction, where the future values are masked and reconstructed based on history values. It guarantees the consistency of task objectives but there is still a gap in task difficulty. Because masked reconstruction can utilize contextual information while forecasting can only use historical information to reconstruct. To further mitigate the existed gap, we propose a simple yet effective prompt token tuning (PT-Tuning) paradigm, in which all pre-trained parameters are frozen and only a few trainable prompt tokens are added to extended mask tokens in element-wise manner. Extensive experiments on real-world datasets demonstrate the superiority of our proposed paradigm with state-of-the-art performance compared to representation learning and end-to-end supervised forecasting methods.
</details>
<details>
<summary>摘要</summary>
自我监督学习在时间序列领域已经广泛研究，特别是对于压缩重建。大多数这些方法采用"预训练+精度调整"模式，在这种模式下，一个新的解码器取代预训练的解码器，以适应特定下游任务，导致上游和下游任务的不一致。在这篇论文中，我们首先指出了融合任务目标和适应任务难度是bridging the gap between time series masked reconstruction and forecasting的关键因素。在练习阶段，保留预训练的假token，使得预测任务可以被视为时间序列压缩重建的特殊情况，将未来值视为假值，并根据历史值进行重建。这 garantizestask objective的一致性，但还存在一定的任务难度差异。因为压缩重建可以利用 contextual information，而预测只能使用历史信息来重建。为了进一步减少现有的差异，我们提议了一种简单 yet effective的 prompt token tuning（PT-Tuning）方法，在这种方法中，所有的预训练参数都被冻结，只有一些可变的提示token被添加到元素级别，以扩展假token。我们对实际世界数据进行了广泛的实验， demonstrate了我们提议的方法的优越性，与代表学习和端到端无监督预测方法相比。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Radio-Signals-with-Wavelet-Transform-for-Deep-Learning-Based-Modulation-Recognition"><a href="#Augmenting-Radio-Signals-with-Wavelet-Transform-for-Deep-Learning-Based-Modulation-Recognition" class="headerlink" title="Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based Modulation Recognition"></a>Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based Modulation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03761">http://arxiv.org/abs/2311.03761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Chen, Shilian Zheng, Kunfeng Qiu, Luxin Zhang, Qi Xuan, Xiaoniu Yang</li>
<li>for: 这 paper 是为了提高 radio modulation recognition 的准确率而写的。</li>
<li>methods: 这 paper 使用的方法包括使用 discrete wavelet transform  decomposed detail coefficients 来生成新的样本，以增加训练集的多样性和量。</li>
<li>results: 实验结果表明，这 paper 提出的方法可以significantly outperform 其他数据扩展方法。<details>
<summary>Abstract</summary>
The use of deep learning for radio modulation recognition has become prevalent in recent years. This approach automatically extracts high-dimensional features from large datasets, facilitating the accurate classification of modulation schemes. However, in real-world scenarios, it may not be feasible to gather sufficient training data in advance. Data augmentation is a method used to increase the diversity and quantity of training dataset and to reduce data sparsity and imbalance. In this paper, we propose data augmentation methods that involve replacing detail coefficients decomposed by discrete wavelet transform for reconstructing to generate new samples and expand the training set. Different generation methods are used to generate replacement sequences. Simulation results indicate that our proposed methods significantly outperform the other augmentation methods.
</details>
<details>
<summary>摘要</summary>
近年来，深度学习在无线模式识别中得到了广泛应用。这种方法可以自动提取大量数据集中的高维特征，使得无线模式的准确分类成为可能。然而，在实际应用场景中，可能无法在先前收集足够的训练数据。数据扩展是一种解决这个问题的方法，它可以增加训练集的多样性和量，同时降低数据稀缺和不均衡。在本文中，我们提出了基于离散波лет变换的细节系数替换法，用于生成新的样本并扩展训练集。不同的生成方法用于生成替换序列。实验结果表明，我们提出的方法可以显著超越其他扩展方法。
</details></li>
</ul>
<hr>
<h2 id="Learning-Decentralized-Traffic-Signal-Controllers-with-Multi-Agent-Graph-Reinforcement-Learning"><a href="#Learning-Decentralized-Traffic-Signal-Controllers-with-Multi-Agent-Graph-Reinforcement-Learning" class="headerlink" title="Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph Reinforcement Learning"></a>Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03756">http://arxiv.org/abs/2311.03756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Zhang, Zhiwen Yu, Jun Zhang, Liang Wang, Tom H. Luan, Bin Guo, Chau Yuen</li>
<li>for: 这 paper 考虑了智能城市中的优化交通信号控制问题，它被看作是一个复杂的网络系统控制问题。</li>
<li>methods: 我们采用了多代理学习（MARL）算法，但现有的 MARL 算法忽略了有效信息集成，这是改进减少代理间学习能力的关键。</li>
<li>results: 我们提出了一种新的分布式控制架构，包括一种基于 topology 的信息集成策略，以及一种基于扩散过程的卷积扩散模块，这些方法可以帮助代理学习有效地捕捉空间-时间相关性。我们在实验中发现，我们的提议在实验室和实际数据上都有优于现有分布式算法。<details>
<summary>Abstract</summary>
This paper considers optimal traffic signal control in smart cities, which has been taken as a complex networked system control problem. Given the interacting dynamics among traffic lights and road networks, attaining controller adaptivity and scalability stands out as a primary challenge. Capturing the spatial-temporal correlation among traffic lights under the framework of Multi-Agent Reinforcement Learning (MARL) is a promising solution. Nevertheless, existing MARL algorithms ignore effective information aggregation which is fundamental for improving the learning capacity of decentralized agents. In this paper, we design a new decentralized control architecture with improved environmental observability to capture the spatial-temporal correlation. Specifically, we first develop a topology-aware information aggregation strategy to extract correlation-related information from unstructured data gathered in the road network. Particularly, we transfer the road network topology into a graph shift operator by forming a diffusion process on the topology, which subsequently facilitates the construction of graph signals. A diffusion convolution module is developed, forming a new MARL algorithm, which endows agents with the capabilities of graph learning. Extensive experiments based on both synthetic and real-world datasets verify that our proposal outperforms existing decentralized algorithms.
</details>
<details>
<summary>摘要</summary>
To address this limitation, we propose a new decentralized control architecture with improved environmental observability. Our approach involves extracting correlation-related information from unstructured data gathered in the road network using a topology-aware information aggregation strategy. Specifically, we convert the road network topology into a graph shift operator by creating a diffusion process on the topology, which enables the construction of graph signals. We then develop a diffusion convolution module, which endows agents with the ability to learn from graph signals.Extensive experiments based on both synthetic and real-world datasets demonstrate that our proposed method outperforms existing decentralized algorithms.
</details></li>
</ul>
<hr>
<h2 id="COOL-A-Constraint-Object-Oriented-Logic-Programming-Language-and-its-Neural-Symbolic-Compilation-System"><a href="#COOL-A-Constraint-Object-Oriented-Logic-Programming-Language-and-its-Neural-Symbolic-Compilation-System" class="headerlink" title="COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System"></a>COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03753">http://arxiv.org/abs/2311.03753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jipeng Han</li>
<li>for: 本研究探讨了神经网络与逻辑编程的集成，解决了长期存在的神经网络总结和学习能力与逻辑逻辑的精度结合的挑战。</li>
<li>methods: 本研究使用了COOL（Constraint Object-Oriented Logic）编程语言，一种创新的方法，它将逻辑推理和神经网络技术融为一体。COOL自动处理数据采集，减少了用户提供初始数据的需求。</li>
<li>results: COOL语言可以减少神经网络训练时的风险，提高神经网络的重用和增强。此外，COOL的基本原理和算法可能为未来编程语言和神经网络架构的发展提供有价值的思路。<details>
<summary>Abstract</summary>
This paper explores the integration of neural networks with logic programming, addressing the longstanding challenges of combining the generalization and learning capabilities of neural networks with the precision of symbolic logic. Traditional attempts at this integration have been hampered by difficulties in initial data acquisition, the reliability of undertrained networks, and the complexity of reusing and augmenting trained models. To overcome these issues, we introduce the COOL (Constraint Object-Oriented Logic) programming language, an innovative approach that seamlessly combines logical reasoning with neural network technologies. COOL is engineered to autonomously handle data collection, mitigating the need for user-supplied initial data. It incorporates user prompts into the coding process to reduce the risks of undertraining and enhances the interaction among models throughout their lifecycle to promote the reuse and augmentation of networks. Furthermore, the foundational principles and algorithms in COOL's design and its compilation system could provide valuable insights for future developments in programming languages and neural network architectures.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文探讨了神经网络与逻辑编程的集成，解决了传统集成神经网络和逻辑逻辑的挑战。这些挑战包括数据收集的困难、训练过程中的可靠性和训练过程中的模型复用和扩展。为了解决这些问题，我们介绍了COOL（卷积对象逻辑）编程语言，这是一种创新的方法，可以自然地结合逻辑思维和神经网络技术。COOL可以自动处理数据收集，从而减少用户提供的初始数据的需求。它还包括用户提示在编程过程中，以减少训练过程中的风险，并且在模型的整个生命周期中提高模型之间的互动，以促进模型的复用和扩展。此外，COOL的基本原则和算法在其编译系统中，可以为未来的编程语言和神经网络架构的发展提供有价值的意见。
</details></li>
</ul>
<hr>
<h2 id="Analysis-and-Applications-of-Deep-Learning-with-Finite-Samples-in-Full-Life-Cycle-Intelligence-of-Nuclear-Power-Generation"><a href="#Analysis-and-Applications-of-Deep-Learning-with-Finite-Samples-in-Full-Life-Cycle-Intelligence-of-Nuclear-Power-Generation" class="headerlink" title="Analysis and Applications of Deep Learning with Finite Samples in Full Life-Cycle Intelligence of Nuclear Power Generation"></a>Analysis and Applications of Deep Learning with Finite Samples in Full Life-Cycle Intelligence of Nuclear Power Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04247">http://arxiv.org/abs/2311.04247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Tang, Wenqiang Zhou, Dong Wang, Caiyang Yu, Zhenan He, Jizhe Zhou, Shudong Huang, Yi Gao, Jianming Chen, Wentao Feng, Jiancheng Lv<br>for:This paper focuses on the application of deep learning (DL) techniques in the context of nuclear power generation (NPG), specifically in the face of limited data availability.methods:The paper explores and applies DL methodologies under the constraints of finite sample availability, including small-sample learning, few-shot learning, zero-shot learning, and open-set recognition.results:The paper presents two case studies, one on automatic recognition of zirconium alloy metallography and the other on open-set recognition for signal diagnosis of machinery sensors, both of which demonstrate constructive outcomes and insightful deliberations.<details>
<summary>Abstract</summary>
The advent of Industry 4.0 has precipitated the incorporation of Artificial Intelligence (AI) methods within industrial contexts, aiming to realize intelligent manufacturing, operation as well as maintenance, also known as industrial intelligence. However, intricate industrial milieus, particularly those relating to energy exploration and production, frequently encompass data characterized by long-tailed class distribution, sample imbalance, and domain shift. These attributes pose noteworthy challenges to data-centric Deep Learning (DL) techniques, crucial for the realization of industrial intelligence. The present study centers on the intricate and distinctive industrial scenarios of Nuclear Power Generation (NPG), meticulously scrutinizing the application of DL techniques under the constraints of finite data samples. Initially, the paper expounds on potential employment scenarios for AI across the full life-cycle of NPG. Subsequently, we delve into an evaluative exposition of DL's advancement, grounded in the finite sample perspective. This encompasses aspects such as small-sample learning, few-shot learning, zero-shot learning, and open-set recognition, also referring to the unique data characteristics of NPG. The paper then proceeds to present two specific case studies. The first revolves around the automatic recognition of zirconium alloy metallography, while the second pertains to open-set recognition for signal diagnosis of machinery sensors. These cases, spanning the entirety of NPG's life-cycle, are accompanied by constructive outcomes and insightful deliberations. By exploring and applying DL methodologies within the constraints of finite sample availability, this paper not only furnishes a robust technical foundation but also introduces a fresh perspective toward the secure and efficient advancement and exploitation of this advanced energy source.
</details>
<details>
<summary>摘要</summary>
<sup>1</sup> industry 4.0的出现引入了人工智能（AI）方法在工业上，以实现智能生产、维护等，也称为工业智能。然而，一些特殊的工业环境，如能源探索和生产，经常存在长尾分布、样本偏置和领域转移等问题。这些问题对数据驱动的深度学习（DL）技术提出了不可遗憾的挑战。本研究关注了核电生产（NPG）的特殊和独特的工业场景，宁杰入彩地探讨了DL技术在有限样本的约束下的应用。本文首先介绍了NPG中AI的应用场景，然后详细介绍了DL技术的发展，包括小样本学习、少数抽象学习、零例学习和开集认知等方面，同时还包括NPG特有的数据特征。然后，本文介绍了两个具体的案例研究，一是自动识别锌合金icrography，二是开集认知用于机械传感器的信号诊断。这两个案例分别封闭NPG的全生命周期，并且得到了有益的结果和深刻的思考。通过在有限样本的约束下探索和应用DL方法ologies，本文不仅提供了坚实的技术基础，还提供了一种新的视角，即在安全有效地推动和利用这种先进的能源源泉。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-for-Automated-Proof-Synthesis-in-Rust"><a href="#Leveraging-Large-Language-Models-for-Automated-Proof-Synthesis-in-Rust" class="headerlink" title="Leveraging Large Language Models for Automated Proof Synthesis in Rust"></a>Leveraging Large Language Models for Automated Proof Synthesis in Rust</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03739">http://arxiv.org/abs/2311.03739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianan Yao, Ziqiao Zhou, Weiteng Chen, Weidong Cui</li>
<li>for: 这篇论文是为了提高正式验证的广泛应用而写的。</li>
<li>methods: 论文使用了大型自然语言模型（LLMs）和静态分析来生成 invariants、assertrions 和其他证据结构，以验证 Rust 基于的正式验证框架 Verus。</li>
<li>results: 在几次Setting中，LLMs 表现出了很好的逻辑能力，能够生成 postconditions 和循环 invariants，特别是对短代码段进行分析。但 LLMs 缺乏保持和传递上下文信息的能力，这是传统静态分析的优点。基于这些观察，我们开发了一个基于 OpenAI 的 GPT-4 模型的原型。我们的原型将验证任务分解成多个更小的任务，逐次询问 GPT-4，并将其输出与轻量级静态分析结合起来。我们对 20 个向量操作程序进行了评估，结果表明，它可以减少人类的证据代码编写劳动。<details>
<summary>Abstract</summary>
Formal verification can provably guarantee the correctness of critical system software, but the high proof burden has long hindered its wide adoption. Recently, Large Language Models (LLMs) have shown success in code analysis and synthesis. In this paper, we present a combination of LLMs and static analysis to synthesize invariants, assertions, and other proof structures for a Rust-based formal verification framework called Verus. In a few-shot setting, LLMs demonstrate impressive logical ability in generating postconditions and loop invariants, especially when analyzing short code snippets. However, LLMs lack the ability to retain and propagate context information, a strength of traditional static analysis. Based on these observations, we developed a prototype based on OpenAI's GPT-4 model. Our prototype decomposes the verification task into multiple smaller ones, iteratively queries GPT-4, and combines its output with lightweight static analysis. We evaluated the prototype with a developer in the automation loop on 20 vector-manipulating programs. The results demonstrate that it significantly reduces human effort in writing entry-level proof code.
</details>
<details>
<summary>摘要</summary>
正式验证可以证明 Kritical 系统软件的正确性，但长期以来，证明的负担很高，使得它的广泛采用受到限制。现在，大型自然语言模型（LLMs）在代码分析和生成方面表现出色。在这篇论文中，我们提出了结合 LLMs 和静态分析的方法，用于生成 invariants、断言和其他证明结构，以便为 Rust 基础的正式验证框架 Verus 进行验证。在几步设置下，LLMs 在分析短代码段时表现出了卓越的逻辑能力，特别是在生成 postconditions 和循环 invariants 方面。然而，LLMs 缺乏保持和传递上下文信息的能力，这是传统静态分析的优势。根据这些观察结果，我们开发了基于 OpenAI 的 GPT-4 模型的 прототип。我们的 прототип将验证任务分解成多个更小的任务，逐步查询 GPT-4，并将其输出与轻量级静态分析结合起来。我们对 20 个向量操作程序进行了评估。结果表明，它可以减少人类在编写入门证明代码的劳动。
</details></li>
</ul>
<hr>
<h2 id="deep-REMAP-Parameterization-of-Stellar-Spectra-Using-Regularized-Multi-Task-Learning"><a href="#deep-REMAP-Parameterization-of-Stellar-Spectra-Using-Regularized-Multi-Task-Learning" class="headerlink" title="deep-REMAP: Parameterization of Stellar Spectra Using Regularized Multi-Task Learning"></a>deep-REMAP: Parameterization of Stellar Spectra Using Regularized Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03738">http://arxiv.org/abs/2311.03738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sankalp Gilda</li>
<li>for: 用于 precisione stellar atmospheric parameter prediction</li>
<li>methods: 使用深度学习和多任务学习，以及创新的不对称损失函数</li>
<li>results: 在使用 Phoenix 库和 MARVELS Survey 数据时，准确地预测了星际大气参数，并且可以扩展到其他星际库和属性。<details>
<summary>Abstract</summary>
Traditional spectral analysis methods are increasingly challenged by the exploding volumes of data produced by contemporary astronomical surveys. In response, we develop deep-Regularized Ensemble-based Multi-task Learning with Asymmetric Loss for Probabilistic Inference ($\rm{deep-REMAP}$), a novel framework that utilizes the rich synthetic spectra from the PHOENIX library and observational data from the MARVELS survey to accurately predict stellar atmospheric parameters. By harnessing advanced machine learning techniques, including multi-task learning and an innovative asymmetric loss function, $\rm{deep-REMAP}$ demonstrates superior predictive capabilities in determining effective temperature, surface gravity, and metallicity from observed spectra. Our results reveal the framework's effectiveness in extending to other stellar libraries and properties, paving the way for more sophisticated and automated techniques in stellar characterization.
</details>
<details>
<summary>摘要</summary>
传统的光谱分析方法随着现代天文学调查的数据急剧增长而面临挑战。为应对这一问题，我们开发了深度 régulé Ensemble-based Multi-task Learning with Asymmetric Loss for Probabilistic Inference（深度-REMAP），一种新的框架，它利用了 Phoenics 库中的丰富人工光谱和 MARVELS 调查的观测数据，以准确预测星际大气参数。通过应用先进的机器学习技术，包括多任务学习和创新的非对称损失函数，深度-REMAP 显示了在确定效应温度、表面重力和金属含量方面的高度预测能力。我们的结果表明，深度-REMAP 可以延伸到其他星际库和属性，为stellar characterization 带来更加复杂和自动化的技术。
</details></li>
</ul>
<hr>
<h2 id="Neural-MMO-2-0-A-Massively-Multi-task-Addition-to-Massively-Multi-agent-Learning"><a href="#Neural-MMO-2-0-A-Massively-Multi-task-Addition-to-Massively-Multi-agent-Learning" class="headerlink" title="Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning"></a>Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03736">http://arxiv.org/abs/2311.03736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Suárez, Phillip Isola, Kyoung Whan Choe, David Bloomin, Hao Xiang Li, Nikhil Pinnaparaju, Nishaanth Kanna, Daniel Scott, Ryan Sullivan, Rose S. Shuman, Lucas de Alcântara, Herbie Bradley, Louis Castricato, Kirsty You, Yuhao Jiang, Qimai Li, Jiaxin Chen, Xiaolong Zhu</li>
<li>for: 本研究旨在提供一个可定制的任务系统，用于训练执行多任务和抗拒抗的智能代理。</li>
<li>methods: 本研究使用Neural MMO 2.0，一个基于深度学习的大型多代理环境，并提供了一个灵活的任务系统，允许用户定制任务、地图和对手。</li>
<li>results: 研究人员通过使用Neural MMO 2.0和CleanRL，训练出能够泛化到任务、地图和对手的智能代理，并实现了三倍的性能提升。<details>
<summary>Abstract</summary>
Neural MMO 2.0 is a massively multi-agent environment for reinforcement learning research. The key feature of this new version is a flexible task system that allows users to define a broad range of objectives and reward signals. We challenge researchers to train agents capable of generalizing to tasks, maps, and opponents never seen during training. Neural MMO features procedurally generated maps with 128 agents in the standard setting and support for up to. Version 2.0 is a complete rewrite of its predecessor with three-fold improved performance and compatibility with CleanRL. We release the platform as free and open-source software with comprehensive documentation available at neuralmmo.github.io and an active community Discord. To spark initial research on this new platform, we are concurrently running a competition at NeurIPS 2023.
</details>
<details>
<summary>摘要</summary>
neuralmmo 2.0 是一个大规模多智能环境，用于研究强化学习。新版本的关键特性是可以自由定义任务系统，允许用户设定广泛的目标和奖励信号。我们挑战研究人员用agent来学习并在训练时未经看到的任务、地图和对手上掌握概念。 neuralmmo 2.0 支持生成的地图，标准设置中有128个agent，并且支持最多。这是前一版本的三倍性能提升，并且兼容cleanrl。我们在 neuralmmo.github.io 上发布了这个平台作为免费和开源软件，并提供了详细的文档和活跃的discord社区。为了促进这个新平台的研究，我们同时在 neurips 2023 上进行了一场竞赛。
</details></li>
</ul>
<hr>
<h2 id="ClimateSet-A-Large-Scale-Climate-Model-Dataset-for-Machine-Learning"><a href="#ClimateSet-A-Large-Scale-Climate-Model-Dataset-for-Machine-Learning" class="headerlink" title="ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning"></a>ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03721">http://arxiv.org/abs/2311.03721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Kaltenborn, Charlotte E. E. Lange, Venkatesh Ramesh, Philippe Brouillard, Yaniv Gurwicz, Chandni Nagda, Jakob Runge, Peer Nowack, David Rolnick<br>for:* 这个论文的目的是为气候科学家和机器学习专家提供一个大型、一致的气候模型数据集，以支持气候变化的影响和未来气候enario的 simulate。methods:* 这个论文使用了Input4MIPs和CMIP6气候模型数据集，并提供了一个模块化的数据集管道，以便在新的气候模型和enario上 retrieve和处理数据。results:* 这个论文使用ClimateSet数据集作为一个标准的机器学习气候模型Emulator的benchmark，并通过分析不同气候模型的性能和泛化能力，获得了新的洞察和理解。此外，这个数据集还可以用于训练一个“超级Emulator”，以快速预测新的气候变化enario，并补充现有的scenario，为政策制定人提供新的参考。<details>
<summary>Abstract</summary>
Climate models have been key for assessing the impact of climate change and simulating future climate scenarios. The machine learning (ML) community has taken an increased interest in supporting climate scientists' efforts on various tasks such as climate model emulation, downscaling, and prediction tasks. Many of those tasks have been addressed on datasets created with single climate models. However, both the climate science and ML communities have suggested that to address those tasks at scale, we need large, consistent, and ML-ready climate model datasets. Here, we introduce ClimateSet, a dataset containing the inputs and outputs of 36 climate models from the Input4MIPs and CMIP6 archives. In addition, we provide a modular dataset pipeline for retrieving and preprocessing additional climate models and scenarios. We showcase the potential of our dataset by using it as a benchmark for ML-based climate model emulation. We gain new insights about the performance and generalization capabilities of the different ML models by analyzing their performance across different climate models. Furthermore, the dataset can be used to train an ML emulator on several climate models instead of just one. Such a "super emulator" can quickly project new climate change scenarios, complementing existing scenarios already provided to policymakers. We believe ClimateSet will create the basis needed for the ML community to tackle climate-related tasks at scale.
</details>
<details>
<summary>摘要</summary>
клима学模型已经是评估气候变化的重要工具，以及预测未来气候enario的方法。机器学习（ML）社区在支持气候科学家的各种任务上表现出了增长的兴趣，例如气候模型的模拟、下采和预测任务。但是，气候科学和ML社区都认为，为了解决这些任务，我们需要大量、一致、ML准备好的气候模型数据集。这里，我们介绍了气候集（ClimateSet），一个包含36个气候模型的输入和输出的数据集。此外，我们还提供了一个模块化的数据集管道，用于检索和处理其他气候模型和enario。我们通过使用这些数据集作为benchmark，证明了ML-基于气候模型的模拟的潜在性和总体表现。此外，这些数据集还可以用于训练一个"超级模拟器"，可以快速地项新的气候变化scenario，并补充现有的scenario，为政策制定者提供。我们认为，气候集将为ML社区提供基础，以便在气候相关任务上进行大规模的推进。
</details></li>
</ul>
<hr>
<h2 id="LLM-as-an-Art-Director-LaDi-Using-LLMs-to-improve-Text-to-Media-Generators"><a href="#LLM-as-an-Art-Director-LaDi-Using-LLMs-to-improve-Text-to-Media-Generators" class="headerlink" title="LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators"></a>LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03716">http://arxiv.org/abs/2311.03716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Allen Roush, Emil Zakirov, Artemiy Shirokov, Polina Lunina, Jack Gane, Alexander Duffy, Charlie Basil, Aber Whitcomb, Jim Benedetto, Chris DeWolfe</li>
<li>for: 这篇论文旨在提高文本到图像生成技术的质量和 relevance，使其能够更好地满足艺术和电影等领域的需求。</li>
<li>methods: 本论文提出了一种名为”LaDi”的统一系统，用于使大语言模型（LLMs） acts as 艺术指导者，提高图像和视频生成的质量。LaDi  integrate 多种技术，包括受限decode、智能提示、精度调整和检索等，以提高文本到图像和视频生成的能力。</li>
<li>results: 据作者介绍，LaDi 和这些技术在 Plai Labs 开发的应用和平台中已经得到了应用，并且能够生成高质量、上下文感知和主题相关的图像和视频。<details>
<summary>Abstract</summary>
Recent advancements in text-to-image generation have revolutionized numerous fields, including art and cinema, by automating the generation of high-quality, context-aware images and video. However, the utility of these technologies is often limited by the inadequacy of text prompts in guiding the generator to produce artistically coherent and subject-relevant images. In this paper, We describe the techniques that can be used to make Large Language Models (LLMs) act as Art Directors that enhance image and video generation. We describe our unified system for this called "LaDi". We explore how LaDi integrates multiple techniques for augmenting the capabilities of text-to-image generators (T2Is) and text-to-video generators (T2Vs), with a focus on constrained decoding, intelligent prompting, fine-tuning, and retrieval. LaDi and these techniques are being used today in apps and platforms developed by Plai Labs.
</details>
<details>
<summary>摘要</summary>
近期的文本到图生成技术发展，对艺术和电影等领域产生了革命性的变革，自动生成高质量、上下文感知图像和视频。然而，这些技术的实用性往往受到文本提示的不够精细性和主题相关性的限制。在这篇论文中，我们将介绍如何使大语言模型（LLM） acting as 艺术指导（Art Directors），提高图像和视频生成的质量。我们提出了“LaDi”系统，并详细介绍了它如何集成多种加强文本到图生成器（T2I）和文本到视频生成器（T2V）的技术，包括约束解码、智能提示、精度调整和检索。LaDi和这些技术今天在 Plai Labs 开发的应用和平台中被使用。
</details></li>
</ul>
<hr>
<h2 id="Loss-Balancing-for-Fair-Supervised-Learning"><a href="#Loss-Balancing-for-Fair-Supervised-Learning" class="headerlink" title="Loss Balancing for Fair Supervised Learning"></a>Loss Balancing for Fair Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03714">http://arxiv.org/abs/2311.03714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khalilimahdi/loss_balancing_icml2023">https://github.com/khalilimahdi/loss_balancing_icml2023</a></li>
<li>paper_authors: Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan<br>for: This paper focuses on addressing unfairness issues in supervised learning models by proposing a fairness notion called Equalized Loss (EL).methods: The paper introduces an algorithm called ELminimizer, which leverages off-the-shelf convex programming tools (e.g., CVXPY) to efficiently find the global optimum of the non-convex optimization problem under the EL constraint.results: The paper theoretically proves that the ELminimizer algorithm finds the global optimal solution under certain conditions, and supports the theoretical results through several empirical studies.<details>
<summary>Abstract</summary>
Supervised learning models have been used in various domains such as lending, college admission, face recognition, natural language processing, etc. However, they may inherit pre-existing biases from training data and exhibit discrimination against protected social groups. Various fairness notions have been proposed to address unfairness issues. In this work, we focus on Equalized Loss (EL), a fairness notion that requires the expected loss to be (approximately) equalized across different groups. Imposing EL on the learning process leads to a non-convex optimization problem even if the loss function is convex, and the existing fair learning algorithms cannot properly be adopted to find the fair predictor under the EL constraint. This paper introduces an algorithm that can leverage off-the-shelf convex programming tools (e.g., CVXPY) to efficiently find the global optimum of this non-convex optimization. In particular, we propose the ELminimizer algorithm, which finds the optimal fair predictor under EL by reducing the non-convex optimization to a sequence of convex optimization problems. We theoretically prove that our algorithm finds the global optimal solution under certain conditions. Then, we support our theoretical results through several empirical studies.
</details>
<details>
<summary>摘要</summary>
受监督学习模型在不同领域中使用，如贷款、大学招生、人脸识别、自然语言处理等。然而，它们可能从训练数据中继承先前的偏见，并对保护社会群体表现歧视。多种公平性概念已经被提出来解决不公平问题。在这种工作中，我们关注Equalized Loss（EL）公平性概念，它需要不同群体的预期损失相似。在满足EL公平性概念的情况下，我们提出了一种名为ELminimizer算法，它可以使用现有的凸程程序工具（如CVXPY）高效地找到非凸优化问题的全局最优解。我们证明了我们的算法在某些条件下找到全球最优解。然后，我们通过多个实验研究支持我们的理论结果。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Estimation-Errors-by-Twin-TD-Regularized-Actor-and-Critic-for-Deep-Reinforcement-Learning"><a href="#Mitigating-Estimation-Errors-by-Twin-TD-Regularized-Actor-and-Critic-for-Deep-Reinforcement-Learning" class="headerlink" title="Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning"></a>Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03711">http://arxiv.org/abs/2311.03711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junmin Zhong, Ruofan Wu, Jennie Si</li>
<li>for: 解决深度强化学习中的估计偏见问题</li>
<li>methods: 引入新的双TD-正则化actor-critic方法，以减少过估和UNDER-估计错误</li>
<li>results: 通过 combining 好的 DRL 改进方法，如分布学习和长N-步代理阶段奖励方法，实现了新的 TDR-based actor-critic 学习在深度控制集中表现出色，并将 TD3 和 SAC 的性能提升到与 D4PG 相当的水平，同时也提高了 D4PG 的性能到新的 SOTA 水平。<details>
<summary>Abstract</summary>
We address the issue of estimation bias in deep reinforcement learning (DRL) by introducing solution mechanisms that include a new, twin TD-regularized actor-critic (TDR) method. It aims at reducing both over and under-estimation errors. With TDR and by combining good DRL improvements, such as distributional learning and long N-step surrogate stage reward (LNSS) method, we show that our new TDR-based actor-critic learning has enabled DRL methods to outperform their respective baselines in challenging environments in DeepMind Control Suite. Furthermore, they elevate TD3 and SAC respectively to a level of performance comparable to that of D4PG (the current SOTA), and they also improve the performance of D4PG to a new SOTA level measured by mean reward, convergence speed, learning success rate, and learning variance.
</details>
<details>
<summary>摘要</summary>
我们解决深度征才学习（DRL）中的估计偏见问题，通过引入新的双TD-调整actor-critic（TDR）方法，旨在降低过估和 unter-估计错误。With TDR和融合好DRL改进方法，如分布式学习和长N步代理奖（LNSS）方法，我们显示了我们的新TDR基于actor-critic学习可以在深度控制套件中的问题环境中超过其基eline。此外，它将TD3和SAC分别提升到与D4PG（目前SOTA）的性能水平，并且提高D4PG的性能到新的SOTA水平， measured by mean reward、convergence speed、learning success rate和learning variance。
</details></li>
</ul>
<hr>
<h2 id="The-NeurIPS-2022-Neural-MMO-Challenge-A-Massively-Multiagent-Competition-with-Specialization-and-Trade"><a href="#The-NeurIPS-2022-Neural-MMO-Challenge-A-Massively-Multiagent-Competition-with-Specialization-and-Trade" class="headerlink" title="The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade"></a>The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03707">http://arxiv.org/abs/2311.03707</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuralmmo/neurips2022nmmo-submission-pool">https://github.com/neuralmmo/neurips2022nmmo-submission-pool</a></li>
<li>paper_authors: Enhong Liu, Joseph Suarez, Chenhui You, Bo Wu, Bingcheng Chen, Jun Hu, Jiaxin Chen, Xiaolong Zhu, Clare Zhu, Julian Togelius, Sharada Mohanty, Weijun Hong, Rui Du, Yibing Zhang, Qinwen Wang, Xinhang Li, Zheng Yuan, Xiang Li, Yuejia Huang, Kun Zhang, Hanhui Yang, Shiqi Tang, Phillip Isola</li>
<li>for: 这篇论文描述了NeuIPS-2022神经网络MMO挑战的结果，该挑战吸引了500名参与者和获得了超过1,600个提交。</li>
<li>methods: 这年的挑战使用了最新的v1.6神经网络MMO，该版本增加了新的设备、战斗、交易和评价系统，这些元素共同提供了更多的鲁棒性和泛化挑战。</li>
<li>results: 该论文描述了挑战的设计和结果，探讨了这种环境作为学习方法的标准准则，并提供了一些实用的追加优化方法以解决复杂任务的稀缺奖励问题。<details>
<summary>Abstract</summary>
In this paper, we present the results of the NeurIPS-2022 Neural MMO Challenge, which attracted 500 participants and received over 1,600 submissions. Like the previous IJCAI-2022 Neural MMO Challenge, it involved agents from 16 populations surviving in procedurally generated worlds by collecting resources and defeating opponents. This year's competition runs on the latest v1.6 Neural MMO, which introduces new equipment, combat, trading, and a better scoring system. These elements combine to pose additional robustness and generalization challenges not present in previous competitions. This paper summarizes the design and results of the challenge, explores the potential of this environment as a benchmark for learning methods, and presents some practical reinforcement learning training approaches for complex tasks with sparse rewards. Additionally, we have open-sourced our baselines, including environment wrappers, benchmarks, and visualization tools for future research.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了2022年度的Neural MMO挑战，该挑战有500名参与者和1,600个提交。与前一年的IJCAI-2022 Neural MMO挑战类似，这年的挑战是在生成的世界中，参与者需要收集资源和击败对手来存活。这一年的比赛运行在最新的v1.6 Neural MMO中，新增了设备、战斗、贸易和评分系统。这些元素共同 pose了额外的稳定性和泛化挑战，不在前一年的比赛中存在。本文概述了挑战的设计和结果，探讨了这种环境的可能性作为学习方法的标准准则，并提供了一些实用的强化学习训练方法 для复杂任务的稀有奖励。此外，我们还开源了我们的基线，包括环境包装、标准和视觉化工具，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bottom-Up-Synthesis-for-Programs-with-Local-Variables"><a href="#Efficient-Bottom-Up-Synthesis-for-Programs-with-Local-Variables" class="headerlink" title="Efficient Bottom-Up Synthesis for Programs with Local Variables"></a>Efficient Bottom-Up Synthesis for Programs with Local Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03705">http://arxiv.org/abs/2311.03705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Li, Xiangyu Zhou, Rui Dong, Yihong Zhang, Xinyu Wang</li>
<li>for: 本文提出了一种新的合成算法，可以高效地搜索具有本地变量（如lambda函数引入的变量）的程序。</li>
<li>methods: 本文使用的方法是提升程序解释过程，从原来的一个程序一个接一个地评估，改为同时评估所有程序从grammar中的所有练习。这种升级的解释方法被称为”提升解释”，它可以系统地枚举所有的绑定上下文，因此可以有效地评估和减少具有本地变量的程序的搜索空间。</li>
<li>results: 本文的实现 tool Arborist 可以更高效地自动化互联网自动化任务，比如WebRobot和Helena等现有的技术。<details>
<summary>Abstract</summary>
We propose a new synthesis algorithm that can efficiently search programs with local variables (e.g., those introduced by lambdas). Prior bottom-up synthesis algorithms are not able to evaluate programs with free local variables, and therefore cannot effectively reduce the search space of such programs (e.g., using standard observational equivalence reduction techniques), making synthesis slow. Our algorithm can reduce the space of programs with local variables. The key idea, dubbed lifted interpretation, is to lift up the program interpretation process, from evaluating one program at a time to simultaneously evaluating all programs from a grammar. Lifted interpretation provides a mechanism to systematically enumerate all binding contexts for local variables, thereby enabling us to evaluate and reduce the space of programs with local variables. Our ideas are instantiated in the domain of web automation. The resulting tool, Arborist, can automate a significantly broader range of challenging tasks more efficiently than state-of-the-art techniques including WebRobot and Helena.
</details>
<details>
<summary>摘要</summary>
我们提出一个新的合成算法，可以有效地搜寻具有地方变数（例如，由lambda函数引入的）的程序。先前的底向合成算法无法评估具有自由地方变数的程序，因此无法有效地将程序的搜寻空间缩减（例如，使用标准观察等 equivalence reduction techniques），导致合成速度慢。我们的算法可以缩减程序具有地方变数的空间。我们的主要想法，被称为“提升解释”，是将程序解释过程“提升”到评估一个程序的时候，从一个程序评估到同时评估所有程序的数学表达。提升解释提供了一个系统地列出所有绑定上下文的机制，从而允许我们评估和缩减具有地方变数的程序的空间。我们的想法在网页自动化领域中实现，实现了一个名为Arborist的工具，可以更有效地和更快地自动化许多具有挑战性的任务，比如WebRobot和Helena的State-of-the-art技术。
</details></li>
</ul>
<hr>
<h2 id="Hypothesis-Network-Planned-Exploration-for-Rapid-Meta-Reinforcement-Learning-Adaptation"><a href="#Hypothesis-Network-Planned-Exploration-for-Rapid-Meta-Reinforcement-Learning-Adaptation" class="headerlink" title="Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation"></a>Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03701">http://arxiv.org/abs/2311.03701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxwell Joseph Jacobson, Yexiang Xue</li>
<li>for:  trains agents that adapt to fast-changing environments and tasks</li>
<li>methods:  integrates an active and planned exploration process via the hypothesis network to optimize adaptation speed</li>
<li>results:  outpaces baseline methods in adaptation speed and model accuracy, validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settingsHere’s the full text in Simplified Chinese:</li>
<li>for:  trains agents that adapt to fast-changing environments and tasks</li>
<li>methods: 使用假设网络进行活动和规划的探索过程，以优化适应速度</li>
<li>results: 在符号版的Alchemy游戏上舜舜战胜基准方法，证明其在快速发展场景中提升学习适应的潜力<details>
<summary>Abstract</summary>
Meta Reinforcement Learning (Meta RL) trains agents that adapt to fast-changing environments and tasks. Current strategies often lose adaption efficiency due to the passive nature of model exploration, causing delayed understanding of new transition dynamics. This results in particularly fast-evolving tasks being impossible to solve. We propose a novel approach, Hypothesis Network Planned Exploration (HyPE), that integrates an active and planned exploration process via the hypothesis network to optimize adaptation speed. HyPE uses a generative hypothesis network to form potential models of state transition dynamics, then eliminates incorrect models through strategically devised experiments. Evaluated on a symbolic version of the Alchemy game, HyPE outpaces baseline methods in adaptation speed and model accuracy, validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settings.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNMeta 强化学习（Meta RL）训练代理人适应快速变化的环境和任务。现有策略 часто因模型探索的被动性而失去适应效率，导致新的转移动力学性的理解延迟。这会使得特别是快速演化的任务无法解决。我们提出了一种新的方法，假设网络规划探索（HyPE），它通过假设网络来整合活动和规划探索过程，以优化适应速度。HyPE使用生成假设网络来形成可能的状态转移动力学模型，然后通过策划出的实验排除错误模型。在一个符号化的Alchemy游戏中进行评估，HyPE在适应速度和模型准确性方面胜过基准方法，这 validate了它在快速演化的设置中增强强化学习的潜力。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Variational-Lower-Bound-for-Inverse-Reinforcement-Learning"><a href="#A-Novel-Variational-Lower-Bound-for-Inverse-Reinforcement-Learning" class="headerlink" title="A Novel Variational Lower Bound for Inverse Reinforcement Learning"></a>A Novel Variational Lower Bound for Inverse Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03698">http://arxiv.org/abs/2311.03698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikang Gui, Prashant Doshi</li>
<li>for: 学习任务协同或复制，从专家轨迹中学习奖励函数，去除手动奖励工程化。</li>
<li>methods: 使用变分下界法（VLB-IRL），在 probabilistic graphical model 中学习奖励函数和策略，并且同时学习了奖励函数和策略。</li>
<li>results: 在知名领域上，方法可以学习一个有效的奖励函数，使得根据学习的奖励函数来采取策略，可以达到专家水平表现。此外，方法还可以在这些领域上超越现有的状态体验IRL算法，表现出更好的奖励。<details>
<summary>Abstract</summary>
Inverse reinforcement learning (IRL) seeks to learn the reward function from expert trajectories, to understand the task for imitation or collaboration thereby removing the need for manual reward engineering. However, IRL in the context of large, high-dimensional problems with unknown dynamics has been particularly challenging. In this paper, we present a new Variational Lower Bound for IRL (VLB-IRL), which is derived under the framework of a probabilistic graphical model with an optimality node. Our method simultaneously learns the reward function and policy under the learned reward function by maximizing the lower bound, which is equivalent to minimizing the reverse Kullback-Leibler divergence between an approximated distribution of optimality given the reward function and the true distribution of optimality given trajectories. This leads to a new IRL method that learns a valid reward function such that the policy under the learned reward achieves expert-level performance on several known domains. Importantly, the method outperforms the existing state-of-the-art IRL algorithms on these domains by demonstrating better reward from the learned policy.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>> inverse reinforcement learning（IRL）目的是从专家轨迹中学习奖励函数，以便理解任务，从而消除手动奖励工程化。然而，在大型、高维度问题中，无法确定动力学的情况下，IRL特别具有挑战性。在这篇论文中，我们提出了一种新的Variational Lower Bound for IRL（VLB-IRL），它基于概率图模型中的优化节点。我们的方法同时学习奖励函数和政策，并且通过最大化下界来实现这一目标，下界等于将推断分布的优化与实际分布的优化进行reverse Kullback-Leibler散度的减少。这导致了一种新的IRL方法，该方法学习了一个有效的奖励函数，使得在知道的领域上，政策下的奖励函数得到了专家水平的表现。进一步，该方法在这些领域上超越了现有的IRL算法，通过展示更好的奖励来证明。
</details></li>
</ul>
<hr>
<h2 id="Context-Shift-Reduction-for-Offline-Meta-Reinforcement-Learning"><a href="#Context-Shift-Reduction-for-Offline-Meta-Reinforcement-Learning" class="headerlink" title="Context Shift Reduction for Offline Meta-Reinforcement Learning"></a>Context Shift Reduction for Offline Meta-Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03695">http://arxiv.org/abs/2311.03695</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/moreanp/csro">https://github.com/moreanp/csro</a></li>
<li>paper_authors: Yunkai Gao, Rui Zhang, Jiaming Guo, Fan Wu, Qi Yi, Shaohui Peng, Siming Lan, Ruizhi Chen, Zidong Du, Xing Hu, Qi Guo, Ling Li, Yunji Chen</li>
<li>for: 提高 meta-学习 agent 的通用能力，采用 prep-collected  offline 数据。</li>
<li>methods: 提出了一种 Context Shift Reduction for OMRL (CSRO) 方法，通过 minimize 策略在上下文中的影响来解决上下文偏移问题。</li>
<li>results: CSRO 方法在多种复杂的领域中显著减少了上下文偏移，并超过了之前的方法，提高了通用能力。<details>
<summary>Abstract</summary>
Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline datasets to enhance the agent's generalization ability on unseen tasks. However, the context shift problem arises due to the distribution discrepancy between the contexts used for training (from the behavior policy) and testing (from the exploration policy). The context shift problem leads to incorrect task inference and further deteriorates the generalization ability of the meta-policy. Existing OMRL methods either overlook this problem or attempt to mitigate it with additional information. In this paper, we propose a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem with only offline datasets. The key insight of CSRO is to minimize the influence of policy in context during both the meta-training and meta-test phases. During meta-training, we design a max-min mutual information representation learning mechanism to diminish the impact of the behavior policy on task representation. In the meta-test phase, we introduce the non-prior context collection strategy to reduce the effect of the exploration policy. Experimental results demonstrate that CSRO significantly reduces the context shift and improves the generalization ability, surpassing previous methods across various challenging domains.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CN<</SYS>>偏向式 meta-学习（OMRL）利用预收集的偏向式数据集来提高代理人的通用能力。然而，Context Shift问题出现，这是因为培育（从行为策略）和测试（从探索策略）上的分布差异。Context Shift问题会导致任务推断错误，并进一步削弱代理人的通用能力。现有的 OMRL 方法 Either overlook this problem or attempt to mitigate it with additional information。在这篇论文中，我们提出了一种新的方法，即 Context Shift Reduction for OMRL（CSRO），用于解决 Context Shift 问题。CSRO 的关键思想是在 meta-training 和 meta-test 阶段都减少策略的影响。在 meta-training 阶段，我们设计了 max-min 互信息表示学习机制，以减少行为策略对任务表示的影响。在 meta-test 阶段，我们引入了非先验Context Collection策略，以减少探索策略的影响。实验结果表明，CSRO 可以减少 Context Shift 并提高通用能力，超过了先前的方法，在多个复杂的领域中。
</details></li>
</ul>
<hr>
<h2 id="Deep-Bayesian-Reinforcement-Learning-for-Spacecraft-Proximity-Maneuvers-and-Docking"><a href="#Deep-Bayesian-Reinforcement-Learning-for-Spacecraft-Proximity-Maneuvers-and-Docking" class="headerlink" title="Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers and Docking"></a>Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers and Docking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03680">http://arxiv.org/abs/2311.03680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Desong Du, Naiming Qi, Yanfang Liu, Wei Pan</li>
<li>for: 这篇论文是为了研究自主宇宙航行器的近距离推进和对接（PMD）。</li>
<li>methods: 这篇论文使用了一种新的 bayesian actor-critic reinforcement learning算法，以学习一个具有稳定保证的控制策略。</li>
<li>results: 实验结果显示，这种算法在一个宇宙航行器的空气滑床试验平台上表现出色，并且具有优异的稳定性和安全性。<details>
<summary>Abstract</summary>
In the pursuit of autonomous spacecraft proximity maneuvers and docking(PMD), we introduce a novel Bayesian actor-critic reinforcement learning algorithm to learn a control policy with the stability guarantee. The PMD task is formulated as a Markov decision process that reflects the relative dynamic model, the docking cone and the cost function. Drawing from the principles of Lyapunov theory, we frame the temporal difference learning as a constrained Gaussian process regression problem. This innovative approach allows the state-value function to be expressed as a Lyapunov function, leveraging the Gaussian process and deep kernel learning. We develop a novel Bayesian quadrature policy optimization procedure to analytically compute the policy gradient while integrating Lyapunov-based stability constraints. This integration is pivotal in satisfying the rigorous safety demands of spaceflight missions. The proposed algorithm has been experimentally evaluated on a spacecraft air-bearing testbed and shows impressive and promising performance.
</details>
<details>
<summary>摘要</summary>
在自主空间舱靠近和停靠（PMD）任务中，我们介绍了一种新的 Bayesianactor-critic reinforcement学习算法，以学习一个稳定性保证的控制策略。 PMD任务被形式化为一个Markov决策过程，这个过程反映了相对动态模型、停靠杯和成本函数。 我们从了Lyapunov理论的原则中继承了时间差学习，将其转化为一个受限的 Gaussian Process regression问题。这种创新的方法使得状态价值函数可以表示为Lyapunov函数，通过Gaussian Process和深度核心学习。我们开发了一种新的 Bayesian quadrature策略优化程序，可以分析计算策略偏导的同时，integrate Lyapunov-based稳定性约束。这种约束是Spaceflight任务的严格安全要求的满足。我们的提案在一个空间舱空滤测试平台上进行了实验，表现很出色和有前途。
</details></li>
</ul>
<hr>
<h2 id="Stable-Modular-Control-via-Contraction-Theory-for-Reinforcement-Learning"><a href="#Stable-Modular-Control-via-Contraction-Theory-for-Reinforcement-Learning" class="headerlink" title="Stable Modular Control via Contraction Theory for Reinforcement Learning"></a>Stable Modular Control via Contraction Theory for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03669">http://arxiv.org/abs/2311.03669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bing Song, Jean-Jacques Slotine, Quang-Cuong Pham</li>
<li>for: 提出了一种新的方法，将控制技术与强化学习（RL）结合起来，以确保稳定性、Robustness和泛化性：利用 contraction theory 实现模块化性，以保证将稳定的子系统组合起来可以保持稳定性。</li>
<li>methods: 通过信号композиiting和动态分解来实现模块化性。信号 compositing 创造了隐藏空间，在这个空间中RL 可以最大化奖励。动态分解通过坐标变换创造了一个辅助空间，在这个空间中 latent signals 被相互关联，以保持稳定性，并且每个信号，即每个子系统，都有稳定的自回传。</li>
<li>results: 通过实验表明，这种方法可以提高机器学习中的模块化 neural architecture 的性能，特别是在杂乱学习中。<details>
<summary>Abstract</summary>
We propose a novel way to integrate control techniques with reinforcement learning (RL) for stability, robustness, and generalization: leveraging contraction theory to realize modularity in neural control, which ensures that combining stable subsystems can automatically preserve the stability. We realize such modularity via signal composition and dynamic decomposition. Signal composition creates the latent space, within which RL applies to maximizing rewards. Dynamic decomposition is realized by coordinate transformation that creates an auxiliary space, within which the latent signals are coupled in the way that their combination can preserve stability provided each signal, that is, each subsystem, has stable self-feedbacks. Leveraging modularity, the nonlinear stability problem is deconstructed into algebraically solvable ones, the stability of the subsystems in the auxiliary space, yielding linear constraints on the input gradients of control networks that can be as simple as switching the signs of network weights. This minimally invasive method for stability allows arguably easy integration into the modular neural architectures in machine learning, like hierarchical RL, and improves their performance. We demonstrate in simulation the necessity and the effectiveness of our method: the necessity for robustness and generalization, and the effectiveness in improving hierarchical RL for manipulation learning.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，把控制技术与强化学习（RL）结合起来，以确保稳定性、可靠性和通用性：利用收缩理论来实现模块化在神经控制中，以确保将稳定的子系统组合在一起可以保持稳定性。我们通过信号组合和动态分解来实现这种模块化。信号组合创造了隐藏空间，在这个空间中RL可以最大化奖励。动态分解通过坐标变换创建了一个辅助空间，在这个空间中隐藏信号被 coupling在一起，以确保其组合可以保持稳定性，只要每个信号，即每个子系统，都有稳定的自反馈。利用模块化，非线性稳定性问题被分解成可解的问题，即每个子系统的稳定性问题在辅助空间中，从而得到了输入梯度的线性约束，这些约束可以是简单地将网络权重的符号 switching。这种非侵入式的稳定性方法可以轻松地 integrate到现有的模块化神经网络 architecture中，如 hierarchical RL，并提高其性能。我们在 simulating 中示出了这种方法的必要性和有效性：必要性为稳定性和通用性，有效性在 hierarchical RL 中提高 manipulation learning 性能。
</details></li>
</ul>
<hr>
<h2 id="GPT-ST-Generative-Pre-Training-of-Spatio-Temporal-Graph-Neural-Networks"><a href="#GPT-ST-Generative-Pre-Training-of-Spatio-Temporal-Graph-Neural-Networks" class="headerlink" title="GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks"></a>GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04245">http://arxiv.org/abs/2311.04245</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkuds/gpt-st">https://github.com/hkuds/gpt-st</a></li>
<li>paper_authors: Zhonghang Li, Lianghao Xia, Yong Xu, Chao Huang</li>
<li>for: 本文旨在提出一种spatio-temporal预测框架，以提高流量管理和旅行规划中的预测性能。</li>
<li>methods: 该框架基于两个关键设计：一是提出了一种spatio-temporal做mask自适应网络，用于学习spatio-temporal相关性。二是引入了适应式做mask策略，以便在训练过程中容易地模型不同关系，从易到difficult。</li>
<li>results: 经验表明，提出的方法可以在 reprehensible benchmarks 上显著提高预测性能。模型实现已经公开在 GitHub 上，具体请参考 <a target="_blank" rel="noopener" href="https://github.com/HKUDS/GPT-ST">https://github.com/HKUDS/GPT-ST</a>。<details>
<summary>Abstract</summary>
In recent years, there has been a rapid development of spatio-temporal prediction techniques in response to the increasing demands of traffic management and travel planning. While advanced end-to-end models have achieved notable success in improving predictive performance, their integration and expansion pose significant challenges. This work aims to address these challenges by introducing a spatio-temporal pre-training framework that seamlessly integrates with downstream baselines and enhances their performance. The framework is built upon two key designs: (i) We propose a spatio-temporal mask autoencoder as a pre-training model for learning spatio-temporal dependencies. The model incorporates customized parameter learners and hierarchical spatial pattern encoding networks. These modules are specifically designed to capture spatio-temporal customized representations and intra- and inter-cluster region semantic relationships, which have often been neglected in existing approaches. (ii) We introduce an adaptive mask strategy as part of the pre-training mechanism. This strategy guides the mask autoencoder in learning robust spatio-temporal representations and facilitates the modeling of different relationships, ranging from intra-cluster to inter-cluster, in an easy-to-hard training manner. Extensive experiments conducted on representative benchmarks demonstrate the effectiveness of our proposed method. We have made our model implementation publicly available at https://github.com/HKUDS/GPT-ST.
</details>
<details>
<summary>摘要</summary>
Recently, there has been a rapid development of spatio-temporal prediction techniques in response to the increasing demands of traffic management and travel planning. While advanced end-to-end models have achieved notable success in improving predictive performance, their integration and expansion pose significant challenges. This work aims to address these challenges by introducing a spatio-temporal pre-training framework that seamlessly integrates with downstream baselines and enhances their performance. The framework is built upon two key designs:(i) We propose a spatio-temporal mask autoencoder as a pre-training model for learning spatio-temporal dependencies. The model incorporates customized parameter learners and hierarchical spatial pattern encoding networks. These modules are specifically designed to capture spatio-temporal customized representations and intra- and inter-cluster region semantic relationships, which have often been neglected in existing approaches.(ii) We introduce an adaptive mask strategy as part of the pre-training mechanism. This strategy guides the mask autoencoder in learning robust spatio-temporal representations and facilitates the modeling of different relationships, ranging from intra-cluster to inter-cluster, in an easy-to-hard training manner.Extensive experiments conducted on representative benchmarks demonstrate the effectiveness of our proposed method. We have made our model implementation publicly available at <https://github.com/HKUDS/GPT-ST>.
</details></li>
</ul>
<hr>
<h2 id="The-Linear-Representation-Hypothesis-and-the-Geometry-of-Large-Language-Models"><a href="#The-Linear-Representation-Hypothesis-and-the-Geometry-of-Large-Language-Models" class="headerlink" title="The Linear Representation Hypothesis and the Geometry of Large Language Models"></a>The Linear Representation Hypothesis and the Geometry of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03658">http://arxiv.org/abs/2311.03658</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kihopark/linear_rep_geometry">https://github.com/kihopark/linear_rep_geometry</a></li>
<li>paper_authors: Kiho Park, Yo Joong Choe, Victor Veitch</li>
<li>for: 本文研究了 linear representation hypothesis，即高级概念是线性表示的想法。</li>
<li>methods: 本文使用 counterfactuals 来给出两种形式化 linear representation，一种是输出（词）表示空间，另一种是输入（句子）空间。然后，用这些形式化连接到线性探针和模型导航。</li>
<li>results:  experiments 表明，存在 linear representation of concepts，与解释和控制之间的联系，以及内积的选择对于语言结构的影响。<details>
<summary>Abstract</summary>
Informally, the 'linear representation hypothesis' is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does "linear representation" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of "linear representation", one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product.
</details>
<details>
<summary>摘要</summary>
促进式地，“线性表示假设”是指高级概念被表示为某种表示空间中的直线方向。在这篇论文中，我们考虑了两个相关的问题：“线性表示”的具体含义是什么？以及在表示空间中 geometric 概念（例如cosine similarity或投影）是如何理解的？为了回答这些问题，我们使用 counterfactual 语言来给出两种形式化“线性表示”的方法，一种在输出（词）表示空间中，另一种在输入（句子）空间中。然后，我们证明这些相关到线性探测和模型导航。为了理解 geometric 概念，我们使用形式化来确定一种特殊的非欧几何内积，该内积尊重语言结构。使用这种 causal 内积，我们可以将所有的线性表示统一起来。具体来说，这允许我们使用 counterfactual 对来建立探测和导航 vectors。 experiments with LLaMA-2 表明存在线性概念表示，连接到解释和控制，以及内积的选择对结果的重要性。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Parameterization-of-the-Multi-scale-Kain-Fritsch-MSKF-Convection-Scheme"><a href="#Machine-Learning-Parameterization-of-the-Multi-scale-Kain-Fritsch-MSKF-Convection-Scheme" class="headerlink" title="Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF) Convection Scheme"></a>Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF) Convection Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03652">http://arxiv.org/abs/2311.03652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohui Zhong, Xing Yu, Hao Li</li>
<li>for: 这个研究旨在测试机器学习模型是否能取代传统的物理参数化方法，以提高预报高精度降水事件的精度。</li>
<li>methods: 本研究使用了多出力对称长短时间记忆过程（Bi-LSTM）模型，并与WRF模型进行组合使用，以测试其在预报高精度降水事件中的性能。</li>
<li>results: 研究结果显示，Bi-LSTM模型可以实现高精度预报，表明机器学习模型可以取代传统的物理参数化方法，从而提高预报高精度降水事件的精度。<details>
<summary>Abstract</summary>
Warm-sector heavy rainfall often occurs along the coast of South China, and it is usually localized and long-lasting, making it challenging to predict. High-resolution numerical weather prediction (NWP) models are increasingly used to better resolve topographic features and forecast such high-impact weather events. However, when the grid spacing becomes comparable to the length scales of convection, known as the gray zone, the turbulent eddies in the atmospheric boundary layer are only partially resolved and parameterized to some extent. Whether using a convection parameterization (CP) scheme in the gray zone remains controversial. Scale-aware CP schemes are developed to enhance the representation of convective transport within the gray zone. The multi-scale Kain-Fritsch (MSKF) scheme includes modifications that allow for its effective implementation at a grid resolution as high as 2 km. In recent years, there has been an increasing application of machine learning (ML) models to various domains of atmospheric sciences, including the replacement of physical parameterizations with ML models. This work proposes a multi-output bidirectional long short-term memory (Bi-LSTM) model as a replace the scale-aware MSKF CP scheme. The Weather Research and Forecast (WRF) model is used to generate training and testing data over South China at a horizontal resolution of 5 km. Furthermore, the WRF model is coupled with the ML based CP scheme and compared with WRF simulations with original MSKF scheme. The results demonstrate that the Bi-LSTM model can achieve high accuracy, indicating the potential use of ML models to substitute the MSKF scheme in the gray zone.
</details>
<details>
<summary>摘要</summary>
暖区重雨常发生在南中国海岸，通常是局部化和长时间的，预测具有挑战性。高分辨率数值天气预测（NWP）模型在预测这种高影响天气事件方面日益被使用。然而，当网格间距相当于降水径流的尺度时，即灰色区，气层的湍流辐射只部分解决并受到一定程度的参数化。使用湍流参数化（CP）方案在灰色区是有争议的。Scale-aware CP方案可以增强湍流传输的表示。多Scale Kain-Fritsch（MSKF）方案包括修改，以实现高分辨率（2 km）下的有效实施。在过去几年中，机器学习（ML）模型在大气科学领域的应用不断扩大，其中包括将物理参数化被替换为ML模型。本研究提出了一种多输出Bi-LSTM模型，用于取代scale-aware MSKF CP方案。使用Weather Research and Forecast（WRF）模型生成训练和测试数据，并将WRF模型与ML基于CP方案相couple。结果表明，Bi-LSTM模型可以实现高精度， indicating the potential use of ML models to substitute the MSKF scheme in the gray zone.
</details></li>
</ul>
<hr>
<h2 id="SeRO-Self-Supervised-Reinforcement-Learning-for-Recovery-from-Out-of-Distribution-Situations"><a href="#SeRO-Self-Supervised-Reinforcement-Learning-for-Recovery-from-Out-of-Distribution-Situations" class="headerlink" title="SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations"></a>SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03651">http://arxiv.org/abs/2311.03651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snuchankim/sero">https://github.com/snuchankim/sero</a></li>
<li>paper_authors: Chan Kim, Jaekyung Cho, Christophe Bobda, Seung-Woo Seo, Seong-Woo Kim</li>
<li>for: 提高机器人代理人在异常状态下的可靠性</li>
<li>methods: 使用自我超级vised学习方法重新训练机器人，以便在异常状态下恢复原来的任务性能</li>
<li>results: 实验结果表明，我们的方法可以大幅提高机器人在异常状态下的恢复能力，并且可以在难以探索的原来状态下恢复原来的任务性能<details>
<summary>Abstract</summary>
Robotic agents trained using reinforcement learning have the problem of taking unreliable actions in an out-of-distribution (OOD) state. Agents can easily become OOD in real-world environments because it is almost impossible for them to visit and learn the entire state space during training. Unfortunately, unreliable actions do not ensure that agents perform their original tasks successfully. Therefore, agents should be able to recognize whether they are in OOD states and learn how to return to the learned state distribution rather than continue to take unreliable actions. In this study, we propose a novel method for retraining agents to recover from OOD situations in a self-supervised manner when they fall into OOD states. Our in-depth experimental results demonstrate that our method substantially improves the agent's ability to recover from OOD situations in terms of sample efficiency and restoration of the performance for the original tasks. Moreover, we show that our method can retrain the agent to recover from OOD situations even when in-distribution states are difficult to visit through exploration.
</details>
<details>
<summary>摘要</summary>
机器人代理人使用强化学习训练后可能会面临不可靠的行为在非典型（Out-of-distribution，OOD）状态下。因为实际环境中几乎不可能让代理人在训练过程中访问整个状态空间，因此代理人容易进入OOD状态。然而，不可靠的行为并不能确保代理人完成原始任务成功。因此，代理人应该能够识别自己是否处于OOD状态，并学习如何返回学习过的状态分布而不是继续执行不可靠的行为。在这个研究中，我们提出了一种新的自动重新训练代理人从OOD状态中恢复原始任务的方法。我们的实验结果表明，我们的方法可以在样本效率和原始任务性能恢复方面大幅提高代理人的恢复能力。此外，我们还证明了我们的方法可以在困难到达的输入分布下重新训练代理人恢复原始任务。
</details></li>
</ul>
<hr>
<h2 id="HKTGNN-Hierarchical-Knowledge-Transferable-Graph-Neural-Network-based-Supply-Chain-Risk-Assessment"><a href="#HKTGNN-Hierarchical-Knowledge-Transferable-Graph-Neural-Network-based-Supply-Chain-Risk-Assessment" class="headerlink" title="HKTGNN: Hierarchical Knowledge Transferable Graph Neural Network-based Supply Chain Risk Assessment"></a>HKTGNN: Hierarchical Knowledge Transferable Graph Neural Network-based Supply Chain Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04244">http://arxiv.org/abs/2311.04244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanting Zhou, Kejun Bi, Yuyanzhen Zhong, Chao Tang, Dongfen Li, Shi Ying, Ruijin Wang</li>
<li>for: 这个论文主要目标是提出一种基于图 neural network 的供应链风险评估模型，以便更好地管理和mitigate 供应链中的潜在风险。</li>
<li>methods: 该模型使用 hierarchical knowledge transferable graph neural network (HKTGNN) 方法，基于当前的图嵌入方法来评估供应链网络中各个产品的风险。</li>
<li>results: 实验结果显示，该模型在一个真实的供应链数据集上表现出excel，并且我们会给出一个公式来证明这个比较实验是有效和公平的。<details>
<summary>Abstract</summary>
The strength of a supply chain is an important measure of a country's or region's technical advancement and overall competitiveness. Establishing supply chain risk assessment models for effective management and mitigation of potential risks has become increasingly crucial. As the number of businesses grows, the important relationships become more complicated and difficult to measure. This emphasizes the need of extracting relevant information from graph data. Previously, academics mostly employed knowledge inference to increase the visibility of links between nodes in the supply chain. However, they have not solved the data hunger problem of single node feature characteristics. We propose a hierarchical knowledge transferable graph neural network-based (HKTGNN) supply chain risk assessment model to address these issues. Our approach is based on current graph embedding methods for assessing corporate investment risk assessment. We embed the supply chain network corresponding to individual goods in the supply chain using the graph embedding module, resulting in a directed homogeneous graph with just product nodes. This reduces the complicated supply chain network into a basic product network. It addresses difficulties using the domain difference knowledge transferable module based on centrality, which is presented by the premise that supply chain feature characteristics may be biased in the actual world. Meanwhile, the feature complement and message passing will alleviate the data hunger problem, which is driven by domain differences. Our model outperforms in experiments on a real-world supply chain dataset. We will give an equation to prove that our comparative experiment is both effective and fair.
</details>
<details>
<summary>摘要</summary>
供应链的强度是一个国家或地区的技术进步和综合竞争力的重要指标。建立供应链风险评估模型，以有效管理和减轻潜在风险已成为核心。随着企业数量的增加，关键关系变得更加复杂和难以测量。这表明需要从图数据中提取相关信息。在过去，学术界主要采用知识推理来增加供应链中节点之间的链接 visibility。然而，它们没有解决单节点特征特性的数据饿问问题。我们提议一种基于现有图 embedding 方法的 hierarchical knowledge transferable graph neural network-based (HKTGNN) 供应链风险评估模型。我们将供应链网络与具体商品相对应的 embedding 模块，从而生成一个指定产品的导向同质图。这将复杂的供应链网络简化为基本的产品网络。此外，我们还采用域差知识传递模块，根据中心性提出，即供应链特征特性在实际世界中可能受到偏见。同时，特征补偿和消息传递将解决数据饿问问题，它是由域差所驱动。我们的模型在实际供应链数据上进行了实验，并证明我们的比较实验是有效和公平的。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-the-User-Perception-of-Chatbots-in-Education-Using-A-Partial-Least-Squares-Structural-Equation-Modeling-Approach"><a href="#Analysis-of-the-User-Perception-of-Chatbots-in-Education-Using-A-Partial-Least-Squares-Structural-Equation-Modeling-Approach" class="headerlink" title="Analysis of the User Perception of Chatbots in Education Using A Partial Least Squares Structural Equation Modeling Approach"></a>Analysis of the User Perception of Chatbots in Education Using A Partial Least Squares Structural Equation Modeling Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03636">http://arxiv.org/abs/2311.03636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Rabiul Hasan, Nahian Ismail Chowdhury, Md Hadisur Rahman, Md Asif Bin Syed, JuHyeong Ryu<br>for:This study aims to investigate the determinants of chatbot adoption in education among students, specifically looking at the Technology Readiness Index (TRI) and Technology Acceptance Model (TAM).methods:The study uses Partial Least Squares Structural Equation Modeling (PLS-SEM) to analyze data collected from 185 responses using a five-point Likert scale.results:The results show that Optimism and Innovativeness are positively associated with Perceived Ease of Use (PEOU) and Perceived Usefulness (PU), while Discomfort and Insecurity negatively impact PEOU, with only Insecurity negatively affecting PU. These findings provide insights for future technology designers, highlighting critical user behavior factors that influence chatbot adoption and utilization in educational contexts.Here are the three points in Simplified Chinese text:for:这项研究目标是调查学生在教育中对聊天机器人的采用，具体来说是通过技术准备指数(TRI)和技术接受模型(TAM)来 investigate。methods:这项研究使用分解部分最小二乘方法(PLS-SEM)分析来收集的185个回答。results:结果显示，乐观和创新性对使用感和有用性有积极的关系，而不适和不安全对使用感有负面的影响，只有不安全对使用感有负面的影响。这些发现为未来技术设计师提供了指导，抛出了关键用户行为因素，帮助我们更好地理解聊天机器人在教育上的采用和利用。<details>
<summary>Abstract</summary>
The integration of Artificial Intelligence (AI) into education is a recent development, with chatbots emerging as a noteworthy addition to this transformative landscape. As online learning platforms rapidly advance, students need to adapt swiftly to excel in this dynamic environment. Consequently, understanding the acceptance of chatbots, particularly those employing Large Language Model (LLM) such as Chat Generative Pretrained Transformer (ChatGPT), Google Bard, and other interactive AI technologies, is of paramount importance. However, existing research on chatbots in education has overlooked key behavior-related aspects, such as Optimism, Innovativeness, Discomfort, Insecurity, Transparency, Ethics, Interaction, Engagement, and Accuracy, creating a significant literature gap. To address this gap, this study employs Partial Least Squares Structural Equation Modeling (PLS-SEM) to investigate the determinant of chatbots adoption in education among students, considering the Technology Readiness Index (TRI) and Technology Acceptance Model (TAM). Utilizing a five-point Likert scale for data collection, we gathered a total of 185 responses, which were analyzed using R-Studio software. We established 12 hypotheses to achieve its objectives. The results showed that Optimism and Innovativeness are positively associated with Perceived Ease of Use (PEOU) and Perceived Usefulness (PU). Conversely, Discomfort and Insecurity negatively impact PEOU, with only Insecurity negatively affecting PU. These findings provide insights for future technology designers, elucidating critical user behavior factors influencing chatbots adoption and utilization in educational contexts.
</details>
<details>
<summary>摘要</summary>
教育领域中人工智能（AI）的 интеграción是一个最近的发展，聊天机器人（chatbot）是这一变革的一个卓越的例子。在在线学习平台上快速发展的情况下，学生需要快速适应以保持优异的表现。因此，理解学生对聊天机器人的接受度，特别是使用大型语言模型（LLM）的聊天机器人，如Chat Generative Pretrained Transformer（ChatGPT）、Google Bard等交互式AI技术的接受度，是极其重要的。然而，现有的教育领域聊天机器人研究忽略了关键的行为相关因素，如乐观性、创新性、不适、不安全、透明度、伦理、互动、参与度和准确性，这创造了一个重要的文献差距。为了填补这一差距，本研究使用部分最小二乘结构方程（PLS-SEM）调查学生对教育领域聊天机器人的采用，考虑技术准备指数（TRI）和技术acceptance模型（TAM）。通过五点Ликер分scale收集数据，总共收集了185个答案，并使用RStudio软件分析。我们建立了12个假设来实现我们的目标。结果表明，乐观性和创新性 positively关联使用容易度（PEOU）和有用性（PU）。然而，不适和不安全都对PEOUnegatively影响，只有不安全对PUnegatively影响。这些发现为未来技术设计师提供了新的洞察，揭示了在教育上下文中聊天机器人采用和使用的关键用户行为因素。
</details></li>
</ul>
<hr>
<h2 id="TWIST-Teacher-Student-World-Model-Distillation-for-Efficient-Sim-to-Real-Transfer"><a href="#TWIST-Teacher-Student-World-Model-Distillation-for-Efficient-Sim-to-Real-Transfer" class="headerlink" title="TWIST: Teacher-Student World Model Distillation for Efficient Sim-to-Real Transfer"></a>TWIST: Teacher-Student World Model Distillation for Efficient Sim-to-Real Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03622">http://arxiv.org/abs/2311.03622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yamada, Marc Rigter, Jack Collins, Ingmar Posner<br>for:This paper aims to address the sim-to-real gap in model-based reinforcement learning (RL) for vision-based robotics tasks.methods:The proposed method, TWIST, uses teacher-student distillation to transfer a simulator-trained world model to a real-world environment. The teacher model is trained on state observations, while the student model is trained on domain-randomized image observations with supervision from the teacher model.results:Experiments on simulated and real robotics tasks show that TWIST outperforms naive domain randomization and model-free methods in terms of sample efficiency and task performance for sim-to-real transfer.<details>
<summary>Abstract</summary>
Model-based RL is a promising approach for real-world robotics due to its improved sample efficiency and generalization capabilities compared to model-free RL. However, effective model-based RL solutions for vision-based real-world applications require bridging the sim-to-real gap for any world model learnt. Due to its significant computational cost, standard domain randomisation does not provide an effective solution to this problem. This paper proposes TWIST (Teacher-Student World Model Distillation for Sim-to-Real Transfer) to achieve efficient sim-to-real transfer of vision-based model-based RL using distillation. Specifically, TWIST leverages state observations as readily accessible, privileged information commonly garnered from a simulator to significantly accelerate sim-to-real transfer. Specifically, a teacher world model is trained efficiently on state information. At the same time, a matching dataset is collected of domain-randomised image observations. The teacher world model then supervises a student world model that takes the domain-randomised image observations as input. By distilling the learned latent dynamics model from the teacher to the student model, TWIST achieves efficient and effective sim-to-real transfer for vision-based model-based RL tasks. Experiments in simulated and real robotics tasks demonstrate that our approach outperforms naive domain randomisation and model-free methods in terms of sample efficiency and task performance of sim-to-real transfer.
</details>
<details>
<summary>摘要</summary>
模型基于RL是现实世界机器人控制中有前途的方法，因其在样本效率和泛化能力方面比模型自由RL更高。然而，实际世界应用中的视觉基于模型基于RL解决方案需要跨 simulate-to-real 跳跃，以便使用世界模型学习。由于其计算成本较高，标准的DomainRandomization 不能提供有效的解决方案。这篇论文提出了TWIST（教师学生世界模型填充传播），以实现高效的 simulate-to-real 传播。具体来说，TWIST 利用状态观察得到的 readily accessible 特权信息，通常来自 simulate 器，以加速 simulate-to-real 传播。具体来说，一个教师世界模型在状态信息上高效地训练。同时，一个匹配的数据集被收集了，用于DomainRandomization 的图像观察。教师世界模型然后监督学生世界模型，使用图像观察作为输入。通过填充学习的秘密动力模型从教师模型传播给学生模型，TWIST 实现了高效和有效的 simulate-to-real 传播。实验表明，我们的方法比Naive DomainRandomization 和模型自由方法在样本效率和实际世界传播中的任务性能方面表现出色。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.AI_2023_11_07/" data-id="closbrolb00710g889lwi99xj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/07/cs.CV_2023_11_07/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-11-07
        
      </div>
    </a>
  
  
    <a href="/2023/11/07/cs.CL_2023_11_07/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-11-07</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
