
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-11-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="OtterHD: A High-Resolution Multi-modality Model paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04219 repo_url: None paper_authors: Bo Li, Peiyuan Zhang, Jingkang Yang, Yuanhan Zhang, Fanyi Pu, Ziwei Liu for: 这项">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-11-07">
<meta property="og:url" content="https://nullscc.github.io/2023/11/07/cs.AI_2023_11_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="OtterHD: A High-Resolution Multi-modality Model paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04219 repo_url: None paper_authors: Bo Li, Peiyuan Zhang, Jingkang Yang, Yuanhan Zhang, Fanyi Pu, Ziwei Liu for: 这项">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-07T12:00:00.000Z">
<meta property="article:modified_time" content="2023-11-08T18:37:26.544Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.AI_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T12:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-11-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="OtterHD-A-High-Resolution-Multi-modality-Model"><a href="#OtterHD-A-High-Resolution-Multi-modality-Model" class="headerlink" title="OtterHD: A High-Resolution Multi-modality Model"></a>OtterHD: A High-Resolution Multi-modality Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04219">http://arxiv.org/abs/2311.04219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Li, Peiyuan Zhang, Jingkang Yang, Yuanhan Zhang, Fanyi Pu, Ziwei Liu</li>
<li>for: 这项研究旨在开发一种可以处理高分辨率视觉输入的多模式模型，以提高模型对小物体的识别精度和空间关系的能力。</li>
<li>methods: 这种模型基于Fuyu-8B架构，并通过采用可变输入维度的方式，使得模型具有更高的灵活性，可以适应不同的推理需求。</li>
<li>results: 对比当前领先模型，OtterHD-8B在MagnifierBench测试框架上表现出优异的表现，特别是在直接处理高分辨率输入时，其与对手的差距非常大。这些结果表明不同的视觉模型在处理小物体的细节和空间关系方面存在结构性差异，同时也表明Fuyu架构的简单性和高分辨率输入能力在处理复杂视觉数据方面的潜在潜力。<details>
<summary>Abstract</summary>
In this paper, we present OtterHD-8B, an innovative multimodal model evolved from Fuyu-8B, specifically engineered to interpret high-resolution visual inputs with granular precision. Unlike conventional models that are constrained by fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible input dimensions, ensuring its versatility across various inference requirements. Alongside this model, we introduce MagnifierBench, an evaluation framework designed to scrutinize models' ability to discern minute details and spatial relationships of small objects. Our comparative analysis reveals that while current leading models falter on this benchmark, OtterHD-8B, particularly when directly processing high-resolution inputs, outperforms its counterparts by a substantial margin. The findings illuminate the structural variances in visual information processing among different models and the influence that the vision encoders' pre-training resolution disparities have on model effectiveness within such benchmarks. Our study highlights the critical role of flexibility and high-resolution input capabilities in large multimodal models and also exemplifies the potential inherent in the Fuyu architecture's simplicity for handling complex visual data.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了OtterHD-8B，一种创新的多模态模型，由Fuyu-8B模型进化而来，专门用于处理高分辨率视觉输入。与传统模型不同，OtterHD-8B具有可变输入维度的能力，使其在不同的推理需求中表现弹性。此外，我们还提出了MagnifierBench评价框架，用于测试模型对小 объек的细节和空间关系的掌握能力。我们的比较分析表明，当直接处理高分辨率输入时，OtterHD-8B在相同的比较中减少了对手的差距。这些发现揭示了不同模型在视觉信息处理中的结构差异以及视觉编码器预训练分辨率差异对模型效果的影响。我们的研究强调了大型多模态模型的灵活性和高分辨率输入能力的重要性，以及Fuyu架构的简单性在处理复杂视觉数据方面的潜在能力。
</details></li>
</ul>
<hr>
<h2 id="Towards-Garment-Sewing-Pattern-Reconstruction-from-a-Single-Image"><a href="#Towards-Garment-Sewing-Pattern-Reconstruction-from-a-Single-Image" class="headerlink" title="Towards Garment Sewing Pattern Reconstruction from a Single Image"></a>Towards Garment Sewing Pattern Reconstruction from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04218">http://arxiv.org/abs/2311.04218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lijuan Liu, Xiangyu Xu, Zhijie Lin, Jiabin Liang, Shuicheng Yan</li>
<li>for: 本研究旨在实现从日常照片中提取衣物缝线图样，以推进时装设计、虚拟试穿和数码人偶等应用。</li>
<li>methods: 本研究首先Synthesize了一个多样化的数据集，名为SewFactory，包含约100万帧照片和相应的缝线图样数据，并提出了一个Two-level Transformer网络，名为Sewformer，以改进缝线图样预测性能。</li>
<li>results: 实验结果显示，提出的框架能够有效地从日常照片中提取缝线图样，并具有广泛的应用前景和优良的普遍化性。<details>
<summary>Abstract</summary>
Garment sewing pattern represents the intrinsic rest shape of a garment, and is the core for many applications like fashion design, virtual try-on, and digital avatars. In this work, we explore the challenging problem of recovering garment sewing patterns from daily photos for augmenting these applications. To solve the problem, we first synthesize a versatile dataset, named SewFactory, which consists of around 1M images and ground-truth sewing patterns for model training and quantitative evaluation. SewFactory covers a wide range of human poses, body shapes, and sewing patterns, and possesses realistic appearances thanks to the proposed human texture synthesis network. Then, we propose a two-level Transformer network called Sewformer, which significantly improves the sewing pattern prediction performance. Extensive experiments demonstrate that the proposed framework is effective in recovering sewing patterns and well generalizes to casually-taken human photos. Code, dataset, and pre-trained models are available at: https://sewformer.github.io.
</details>
<details>
<summary>摘要</summary>
裤衣缝纹模式表示裤衣的内在自然形状，是许多应用程序 like 时尚设计、虚拟试穿和数字化人物的核心。在这项工作中，我们探讨了从日常照片中回归裤衣缝纹的困难问题。为解决这个问题，我们首先合成了一个多样化的数据集，名为 SewFactory，该数据集包含约1M张图像和真实缝纹模式的 Label 数据，用于模型训练和量化评估。 SewFactory 覆盖了人体姿势、身体形态和缝纹模式的广泛范围，并具有真实的人体Texture Synthesis 网络所提供的现实生动的外观。然后，我们提出了一个两级 Transformer 网络，名为 Sewformer，该网络可以有效地预测缝纹模式。广泛的实验表明，我们的框架可以有效地回归缝纹模式，并在习惯性拍摄的人像照片中广泛适用。代码、数据集和预训练模型可以在以下链接获取：https://sewformer.github.io。
</details></li>
</ul>
<hr>
<h2 id="Wearable-data-from-subjects-playing-Super-Mario-sitting-university-exams-or-performing-physical-exercise-help-detect-acute-mood-episodes-via-self-supervised-learning"><a href="#Wearable-data-from-subjects-playing-Super-Mario-sitting-university-exams-or-performing-physical-exercise-help-detect-acute-mood-episodes-via-self-supervised-learning" class="headerlink" title="Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning"></a>Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04215">http://arxiv.org/abs/2311.04215</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filippo Corponi, Bryan M. Li, Gerard Anmella, Clàudia Valenzuela-Pascual, Ariadna Mas, Isabella Pacchiarotti, Marc Valentí, Iria Grande, Antonio Benabarre, Marina Garriga, Eduard Vieta, Allan H Young, Stephen M. Lawrie, Heather C. Whalley, Diego Hidalgo-Mazzei, Antonio Vergari</li>
<li>for: 监测情绪障碍（MDs），使用数据科学技术实现跟踪和识别 MDs 的发病频率和病理特征。</li>
<li>methods: 利用无监督学习（SSL）技术，将无标的数据用于学习表征，并将这些表征转换为监督学习任务中的特征。</li>
<li>results: 在使用 E4 认知器和 XGBoost 等方法进行分析后，发现 SSL 能够优于传统的监督学习方法，具体来说是在 81.23% 的记录段中正确地识别发病和稳定的记录段。<details>
<summary>Abstract</summary>
Personal sensing, leveraging data passively and near-continuously collected with wearables from patients in their ecological environment, is a promising paradigm to monitor mood disorders (MDs), a major determinant of worldwide disease burden. However, collecting and annotating wearable data is very resource-intensive. Studies of this kind can thus typically afford to recruit only a couple dozens of patients. This constitutes one of the major obstacles to applying modern supervised machine learning techniques to MDs detection. In this paper, we overcome this data bottleneck and advance the detection of MDs acute episode vs stable state from wearables data on the back of recent advances in self-supervised learning (SSL). This leverages unlabelled data to learn representations during pre-training, subsequently exploited for a supervised task. First, we collected open-access datasets recording with an Empatica E4 spanning different, unrelated to MD monitoring, personal sensing tasks -- from emotion recognition in Super Mario players to stress detection in undergraduates -- and devised a pre-processing pipeline performing on-/off-body detection, sleep-wake detection, segmentation, and (optionally) feature extraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the largest to date open access collection, and its pre-processing pipeline. Second, we show that SSL confidently outperforms fully-supervised pipelines using either our novel E4-tailored Transformer architecture (E4mer) or classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost) correctly classified recording segments from 64 (half acute, half stable) patients. Lastly, we illustrate that SSL performance is strongly associated with the specific surrogate task employed for pre-training as well as with unlabelled data availability.
</details>
<details>
<summary>摘要</summary>
人工感知，通过利用搭配着护身器收集的数据，在患者的生态环境中进行不间断监测，是识别情绪障碍（MDs）的有力的方法。然而，收集和标注护身器数据是非常耗资的。这类研究通常只能招募几十名病人。这是应用现代supervised machine learning技术于MDs检测的主要障碍。在这篇论文中，我们解决了这种数据瓶颈问题，并通过近期的自我监控学习（SSL）技术提高了MDs检测的精度。我们使用不标注的数据来学习表示，然后将其应用于supervised任务。我们首先收集了来自Empatica E4的开放访问数据集，包括不同的、与MD监测无关的个人感知任务，如Super Mario游戏中的情绪识别和大学生中的压力检测。我们设计了一个预处理管道，包括在/离体检测、睡眠划分、分割和（可选）特征提取。通过161名E4记录的主题，我们介绍了E4SelfLearning数据集和预处理管道。我们表明，使用SSL技术可以超越完全标注的管道，并使用我们的新型E4特化Transformer架构（E4mer）或传统基线XGBoost。在64名患者（其中有半数是陡发的）的记录段中，我们获得了81.23%的正确率，比75.35%（E4mer）和72.02%（XGBoost）高。最后，我们发现SSL性能与特定的代表任务的预处理和不标注数据的可用性有很强的相关性。
</details></li>
</ul>
<hr>
<h2 id="Rephrase-and-Respond-Let-Large-Language-Models-Ask-Better-Questions-for-Themselves"><a href="#Rephrase-and-Respond-Let-Large-Language-Models-Ask-Better-Questions-for-Themselves" class="headerlink" title="Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves"></a>Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04205">http://arxiv.org/abs/2311.04205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihe Deng, Weitong Zhang, Zixiang Chen, Quanquan Gu</li>
<li>for: 提高 Large Language Model (LLM) 的性能，尤其是在听到普通的问题时。</li>
<li>methods: 提出一种名为 “Rephrase and Respond” (RaR) 的方法，让 LLM 可以将人类提出的问题重新推敲并提供回答。这种方法可以帮助 LLM 更好地理解人类的问题，从而提高它们的性能。</li>
<li>results: 经过实验表明，我们的方法可以有效地提高不同任务的模型性能。我们还对 RaR 和 Chain-of-Thought (CoT) 方法进行了比较，并证明了 RaR 和 CoT 是 complementary 的。<details>
<summary>Abstract</summary>
Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs). Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses. While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped. In this paper, we present a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt. This approach serves as a simple yet effective prompting method for improving performance. We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM. This facilitates the effective utilization of rephrased questions generated by one LLM with another. Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks. We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically. We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance. Our work not only contributes to enhancing LLM performance efficiently and effectively but also sheds light on a fair evaluation of LLM capabilities. Data and codes are available at https://github.com/uclaml/Rephrase-and-Respond.
</details>
<details>
<summary>摘要</summary>
misunderstandings 不只出现在人际交流中，还可能发生在人类和大语言模型（LLM）之间。这些差异可能使 LLM 解释看似明确的问题时，提供错误的答案。虽然广泛认可的词语质量对 LLM 提供答案质量产生显著影响，但是一种系统化的问题构造方法仍然在开发阶段。在这篇论文中，我们提出了一种名为“重新phrase和回答”（Rephrase and Respond，RaR）的方法，可以让 LLM 重新构造和扩展人类提出的问题，并提供回答。这种方法可以提高 LLM 的性能，并且可以与Chain-of-Thought（CoT）方法相结合，以实现更好的性能。我们的实验表明，我们的方法可以在多种任务上提高不同模型的性能。此外，我们还提供了对 RaR 和 CoT 的比较，从理论和实际角度出发，以便更好地评估 LLM 的能力。我们的工作不仅可以有效地提高 LLM 性能，还可以为 LLM 评估提供新的思路。数据和代码可以在 GitHub 上找到：https://github.com/uclaml/Rephrase-and-Respond。
</details></li>
</ul>
<hr>
<h2 id="JPAVE-A-Generation-and-Classification-based-Model-for-Joint-Product-Attribute-Prediction-and-Value-Extraction"><a href="#JPAVE-A-Generation-and-Classification-based-Model-for-Joint-Product-Attribute-Prediction-and-Value-Extraction" class="headerlink" title="JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction"></a>JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04196">http://arxiv.org/abs/2311.04196</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhongfendeng/jpave">https://github.com/zhongfendeng/jpave</a></li>
<li>paper_authors: Zhongfen Deng, Hao Peng, Tao Zhang, Shuaiqi Liu, Wenting Zhao, Yibo Wang, Philip S. Yu</li>
<li>for: 这篇论文的目的是提出一种基于多任务学习的产品属性值提取模型，以解决电子商务中产品搜索和推荐等下游应用中的产品属性值提取问题。</li>
<li>methods: 该模型使用了一种叫做JPAVE的多任务学习模型，包括产品值生成&#x2F;分类和属性预测。该模型不需要值的序列位置信息，可以在不同的购物平台上适应不同的文本结构和风格。另外，模型还使用了复制机制和价值注意模块，以解决数据不一致问题。</li>
<li>results: 实验结果表明，JPAVE模型在一个公共数据集上表现出色，比强基elines表现出优异性和泛化能力，并且在面对新的值时具有Zero-shot能力。<details>
<summary>Abstract</summary>
Product attribute value extraction is an important task in e-Commerce which can help several downstream applications such as product search and recommendation. Most previous models handle this task using sequence labeling or question answering method which rely on the sequential position information of values in the product text and are vulnerable to data discrepancy between training and testing. This limits their generalization ability to real-world scenario in which each product can have multiple descriptions across various shopping platforms with different composition of text and style. They also have limited zero-shot ability to new values. In this paper, we propose a multi-task learning model with value generation/classification and attribute prediction called JPAVE to predict values without the necessity of position information of values in the text. Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text. Besides, two variants of our model are designed for open-world and closed-world scenarios. In addition, copy mechanism introduced in the first variant based on value generation can improve its zero-shot ability for identifying unseen values. Experimental results on a public dataset demonstrate the superiority of our model compared with strong baselines and its generalization ability of predicting new values.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Selective-Visual-Representations-Improve-Convergence-and-Generalization-for-Embodied-AI"><a href="#Selective-Visual-Representations-Improve-Convergence-and-Generalization-for-Embodied-AI" class="headerlink" title="Selective Visual Representations Improve Convergence and Generalization for Embodied AI"></a>Selective Visual Representations Improve Convergence and Generalization for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04193">http://arxiv.org/abs/2311.04193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ainaz Eftekhar, Kuo-Hao Zeng, Jiafei Duan, Ali Farhadi, Ani Kembhavi, Ranjay Krishna</li>
<li>for: 这个论文旨在提高embodied AI模型中的视觉处理，使其更加灵活和有效。</li>
<li>methods: 这篇论文提出了一种基于小型学习代码库模块的方法，用于过滤视觉刺激，以便实现更好的任务目标导航和物体移动。</li>
<li>results: 实验表明，该方法可以在5个 benchmark中达到顶尖性能，并且在不同的 simulate环境中进行适应和泛化。代码和预训练模型可以在项目网站（<a target="_blank" rel="noopener" href="https://embodied-codebook.github.io)上获得./">https://embodied-codebook.github.io）上获得。</a><details>
<summary>Abstract</summary>
Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues. Inspired by selective attention in humans-the process through which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects. Code and pretrained models are available at our project website: https://embodied-codebook.github.io.
</details>
<details>
<summary>摘要</summary>
人工智能模型经常使用可购买的视觉背bone如CLIP来编码其视觉观察。尽管这些通用的表征编码场景中的语言和Semantic信息，但这些信息通常对特定任务无关，这会在学习过程中引入噪音并让机器人的注意力分散到不重要的视觉征。 Drawing inspiration from human selective attention, we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach uses a small learnable codebook module to induce a task-conditioned bottleneck, which is trained jointly to optimize task reward. This codebook acts as a task-conditioned selective filter over the visual observation, allowing the agent to focus on task-relevant visual cues. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able to generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and retain task-relevant information like target object recognition while ignoring superfluous information about other objects. 我们的代码和预训练模型可以在我们项目网站（https://embodied-codebook.github.io）上获得。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Anomaly-Detection-with-Graph-Networks-for-Data-Quality-Monitoring-of-the-Hadron-Calorimeter"><a href="#Spatio-Temporal-Anomaly-Detection-with-Graph-Networks-for-Data-Quality-Monitoring-of-the-Hadron-Calorimeter" class="headerlink" title="Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter"></a>Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04190">http://arxiv.org/abs/2311.04190</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mulugeta Weldezgina Asres, Christian Walter Omlin, Long Wang, David Yu, Pavel Parygin, Jay Dittmann, Georgia Karapostoli, Markus Seidel, Rosamaria Venditti, Luka Lambrecht, Emanuele Usai, Muhammad Ahmad, Javier Fernandez Menendez, Kaori Maeshima, the CMS-HCAL Collaboration</li>
<li>for: 这个论文是为了研究一种基于三维干扰图数据的半监督空间时间异常检测方法，以便在CMS实验中实时监测加速器中的物理凝聚器读取通道。</li>
<li>methods: 这个方法使用了卷积神经网络和图神经网络来学习干扰图中的本地空间特征，以及全部backend电路和仪器盒的共享连接和住宿特征。它还使用了循环神经网络来捕捉干扰图中的时间演化。</li>
<li>results: 该方法在使用LHC Run-2的Collision数据集上验证了多种通道故障类型的准确率，并在CMS核心生产系统中实现了生产级别的准确率。此外，该方法还与其他参考模型进行了性能比较，以证明其在实际应用中的潜在优势。<details>
<summary>Abstract</summary>
The compact muon solenoid (CMS) experiment is a general-purpose detector for high-energy collision at the large hadron collider (LHC) at CERN. It employs an online data quality monitoring (DQM) system to promptly spot and diagnose particle data acquisition problems to avoid data quality loss. In this study, we present semi-supervised spatio-temporal anomaly detection (AD) monitoring for the physics particle reading channels of the hadronic calorimeter (HCAL) of the CMS using three-dimensional digi-occupancy map data of the DQM. We propose the GraphSTAD system, which employs convolutional and graph neural networks to learn local spatial characteristics induced by particles traversing the detector, and global behavior owing to shared backend circuit connections and housing boxes of the channels, respectively. Recurrent neural networks capture the temporal evolution of the extracted spatial features. We have validated the accuracy of the proposed AD system in capturing diverse channel fault types using the LHC Run-2 collision data sets. The GraphSTAD system has achieved production-level accuracy and is being integrated into the CMS core production system--for real-time monitoring of the HCAL. We have also provided a quantitative performance comparison with alternative benchmark models to demonstrate the promising leverage of the presented system.
</details>
<details>
<summary>摘要</summary>
大型强子对撞器（LHC）的强子物理读取通道（HCAL）的某些检测问题，CMS实验室使用在线数据质量监测（DQM）系统来迅速发现和诊断数据质量问题，以避免数据质量损失。在这项研究中，我们提出了一种半监督的三维尺度卡住强度图数据的异常检测（AD）监测系统，使用 convolutional neural network（CNN）和图 neural network（GraphNN）来学习检测器中的本地空间特征，以及通信后端电路和仪器盒的共享连接关系。另外，使用循环 нейрон网络（RNN）来捕捉尺度图数据中的时间演化特征。我们在LHC Run-2的碰撞数据集上验证了提案的AD系统的准确性，并达到了生产级别的准确率。此外，我们还对一些参考模型进行了评估，以示出提案的系统在异常检测方面的承诺。
</details></li>
</ul>
<hr>
<h2 id="On-Leakage-in-Machine-Learning-Pipelines"><a href="#On-Leakage-in-Machine-Learning-Pipelines" class="headerlink" title="On Leakage in Machine Learning Pipelines"></a>On Leakage in Machine Learning Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04179">http://arxiv.org/abs/2311.04179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Leonard Sasse, Eliana Nicolaisen-Sobesky, Juergen Dukart, Simon B. Eickhoff, Michael Götz, Sami Hamdan, Vera Komeyer, Abhijit Kulkarni, Juha Lahnakoski, Bradley C. Love, Federico Raimondo, Kaustubh R. Patil</li>
<li>for: 提高机器学习（ML）ipeline的设计、实现和评估，以避免泄漏和过估性能。</li>
<li>methods: 通过实际示例，描述了机器学习管道中可能出现的多种泄漏类型，并对它们进行了全面的概述和讨论。</li>
<li>results: 通过描述和分析不同类型的泄漏，本文旨在扩大机器学习管道中泄漏的理解，以避免因设计、实现和评估不当而导致的负面影响。<details>
<summary>Abstract</summary>
Machine learning (ML) provides powerful tools for predictive modeling. ML's popularity stems from the promise of sample-level prediction with applications across a variety of fields from physics and marketing to healthcare. However, if not properly implemented and evaluated, ML pipelines may contain leakage typically resulting in overoptimistic performance estimates and failure to generalize to new data. This can have severe negative financial and societal implications. Our aim is to expand understanding associated with causes leading to leakage when designing, implementing, and evaluating ML pipelines. Illustrated by concrete examples, we provide a comprehensive overview and discussion of various types of leakage that may arise in ML pipelines.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-LLM-Intelligence-with-ARM-RAG-Auxiliary-Rationale-Memory-for-Retrieval-Augmented-Generation"><a href="#Enhancing-LLM-Intelligence-with-ARM-RAG-Auxiliary-Rationale-Memory-for-Retrieval-Augmented-Generation" class="headerlink" title="Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation"></a>Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04177">http://arxiv.org/abs/2311.04177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Melz</li>
<li>for: 这篇论文旨在探讨如何提高语言模型的智能水平，并研究一种名为 Retrieval Augmented Generation（RAG）的方法。</li>
<li>methods: 该论文使用了一种名为 Auxiliary Rationale Memory（ARM）的系统，该系统通过记忆并回忆问题解决方法来学习。</li>
<li>results: 研究发现，通过存储并回忆解释链可以提高grade-school math问题的解决性能。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g., (Bubeck et al., 2023)) on modern LLMs have shown that they are capable of performing amazing tasks typically necessitating human-level intelligence. However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures. Some approaches to improving the intelligence of LLMs include fine-tuning models based on problem-solving performance (Zelikman et al., 2022), and building bigger and more sophisticated models (Bubeck et al., 2023). However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models. In this paper, we explore the use of Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to improve problem-solving performance. We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high training costs. We demonstrate that the storage and subsequent retrieval of reasoning chains have a positive influence on performance in grade-school math problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HADES-Fast-Singularity-Detection-with-Local-Measure-Comparison"><a href="#HADES-Fast-Singularity-Detection-with-Local-Measure-Comparison" class="headerlink" title="HADES: Fast Singularity Detection with Local Measure Comparison"></a>HADES: Fast Singularity Detection with Local Measure Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04171">http://arxiv.org/abs/2311.04171</a></li>
<li>repo_url: None</li>
<li>paper_authors: Uzu Lim, Harald Oberhauser, Vidit Nanda</li>
<li>for: 检测数据中的点 singularity</li>
<li>methods: 使用kernel好好测试，比较快速和扩展性良好</li>
<li>results: 在synthetic数据、路网数据、分子结构空间和图像数据中 correctly detect singularities with high probability<details>
<summary>Abstract</summary>
We introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm employs a kernel goodness-of-fit test, and as a consequence it is much faster and far more scaleable than the existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.
</details>
<details>
<summary>摘要</summary>
我团队 introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm uses a kernel goodness-of-fit test, which makes it much faster and more scalable than existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.Here's the translation in Traditional Chinese:我们团队 introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm uses a kernel goodness-of-fit test, which makes it much faster and more scalable than existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.
</details></li>
</ul>
<hr>
<h2 id="Outliers-with-Opposing-Signals-Have-an-Outsized-Effect-on-Neural-Network-Optimization"><a href="#Outliers-with-Opposing-Signals-Have-an-Outsized-Effect-on-Neural-Network-Optimization" class="headerlink" title="Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization"></a>Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04163">http://arxiv.org/abs/2311.04163</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elan Rosenfeld, Andrej Risteski</li>
<li>for: 这paper探讨了神经网络优化中新现象，即深度和自然数据中特殊重 tailed 结构之间的交互作用。</li>
<li>methods: 该 paper 使用了实验和理论分析方法，包括对训练数据中对抗信号的研究和一个简单的线性网络的 teoretic 分析。</li>
<li>results: 该 paper 发现了一种新的训练过程 Dynamic 的特点，即在训练过程中慢慢地增加精度，然后快速增加损失，最终导致损失快速增加。此外，paper 还发现了一些与这种现象相关的现象，如泛化能力和简洁偏好。<details>
<summary>Abstract</summary>
We identify a new phenomenon in neural network optimization which arises from the interaction of depth and a particular heavy-tailed structure in natural data. Our result offers intuitive explanations for several previously reported observations about network training dynamics. In particular, it implies a conceptually new cause for progressive sharpening and the edge of stability; we also highlight connections to other concepts in optimization and generalization including grokking, simplicity bias, and Sharpness-Aware Minimization.   Experimentally, we demonstrate the significant influence of paired groups of outliers in the training data with strong opposing signals: consistent, large magnitude features which dominate the network output throughout training and provide gradients which point in opposite directions. Due to these outliers, early optimization enters a narrow valley which carefully balances the opposing groups; subsequent sharpening causes their loss to rise rapidly, oscillating between high on one group and then the other, until the overall loss spikes. We describe how to identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior. We complement these experiments with a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior which we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD.
</details>
<details>
<summary>摘要</summary>
Experiments show that paired groups of outliers in the training data with strong opposing signals can significantly influence the optimization process. These outliers cause early optimization to enter a narrow valley that carefully balances the opposing groups, leading to rapid loss oscillations between high on one group and then the other, until the overall loss spikes. We identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior.We also provide a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior that we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Interpretable-Transformer-for-Fine-Grained-Image-Classification-and-Analysis"><a href="#A-Simple-Interpretable-Transformer-for-Fine-Grained-Image-Classification-and-Analysis" class="headerlink" title="A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"></a>A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04157">http://arxiv.org/abs/2311.04157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imageomics/intr">https://github.com/imageomics/intr</a></li>
<li>paper_authors: Dipanjyoti Paul, Arpita Chowdhury, Xinqi Xiong, Feng-Ju Chang, David Carlyn, Samuel Stevens, Kaiya Provost, Anuj Karpatne, Bryan Carstens, Daniel Rubenstein, Charles Stewart, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao</li>
<li>for: 这 paper 的目的是使 Image Classification 更加可读性。</li>
<li>methods: 该 paper 使用 Transformer encoder-decoder 和 DETR 的 inspirations，实现了一种名为 INterpretable TRansformer (INTR) 的方法。INTR 通过学习每个类别的特有的“查询”，让每个类别在图像中搜索自己的特征。</li>
<li>results: 该 paper 的实验结果表明，INTR 可以帮助每个类别强调自己的特征，并且通过“多头”横规比较，可以识别不同类别的“特征”。这使得 INTR 非常适合细腻的分类和分析。<details>
<summary>Abstract</summary>
We present a novel usage of Transformers to make image classification interpretable. Unlike mainstream classifiers that wait until the last fully-connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image. We realize this idea via a Transformer encoder-decoder inspired by DEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each class) as input to the decoder, enabling each class to localize its patterns in an image via cross-attention. We name our approach INterpretable TRansformer (INTR), which is fairly easy to implement and exhibits several compelling properties. We show that INTR intrinsically encourages each class to attend distinctively; the cross-attention weights thus provide a faithful interpretation of the prediction. Interestingly, via ``multi-head'' cross-attention, INTR could identify different ``attributes'' of a class, making it particularly suitable for fine-grained classification and analysis, which we demonstrate on eight datasets. Our code and pre-trained model are publicly accessible at https://github.com/Imageomics/INTR.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的应用方法，使用转换器来帮助图像分类变得可读性更高。与主流分类器不同，我们在最后一层完全连接层之前就将类信息integrated到预测中，而我们在DEtection TRansformer（DETR）的Encoder-Decoder结构下实现了这个想法。我们在decoder中学习了每个类的``特有''查询（每个类都有一个），使得每个类可以通过交叉关注来找到自己的图像模式。我们称之为INterpretable TRansformer（INTR），它较容易实现并且具有一些吸引人的性能。我们表明，INTR会自然地让每个类各自听取，因此交叉关注权重可以准确地解释预测结果。另外，通过``多头''交叉关注，INTR可以识别不同的``特征''，使其特别适用于细致分类和分析，我们在八个数据集上进行了证明。我们的代码和预训练模型可以在https://github.com/Imageomics/INTR上获取。
</details></li>
</ul>
<hr>
<h2 id="Contactless-Fingerprint-Biometric-Anti-Spoofing-An-Unsupervised-Deep-Learning-Approach"><a href="#Contactless-Fingerprint-Biometric-Anti-Spoofing-An-Unsupervised-Deep-Learning-Approach" class="headerlink" title="Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach"></a>Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04148">http://arxiv.org/abs/2311.04148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Banafsheh Adami, Nima Karimian</li>
<li>For: 这个论文的目的是提出一种新的反射式识别方法，以提高无接触指纹识别系统的安全性和可靠性。* Methods: 这个论文使用了一种新的无接触指纹识别方法， combining an unsupervised autoencoder with a convolutional block attention module。* Results: 这个方法在测试阶段对各种表现攻击样本进行评估，并达到了0.96%的BPCER和1.6%的APCER。<details>
<summary>Abstract</summary>
Contactless fingerprint recognition offers a higher level of user comfort and addresses hygiene concerns more effectively. However, it is also more vulnerable to presentation attacks such as photo paper, paper-printout, and various display attacks, which makes it more challenging to implement in biometric systems compared to contact-based modalities. Limited research has been conducted on presentation attacks in contactless fingerprint systems, and these studies have encountered challenges in terms of generalization and scalability since both bonafide samples and presentation attacks are utilized during training model. Although this approach appears promising, it lacks the ability to handle unseen attacks, which is a crucial factor for developing PAD methods that can generalize effectively. We introduced an innovative anti-spoofing approach that combines an unsupervised autoencoder with a convolutional block attention module to address the limitations of existing methods. Our model is exclusively trained on bonafide images without exposure to any spoofed samples during the training phase. It is then evaluated against various types of presentation attack images in the testing phase. The scheme we proposed has achieved an average BPCER of 0.96\% with an APCER of 1.6\% for presentation attacks involving various types of spoofed samples.
</details>
<details>
<summary>摘要</summary>
无接触指纹识别技术可提供更高水平的用户体验和更有效地解决卫生问题。然而，它也更容易受到展示攻击，如照片纸、打印机纸和各种显示攻击，这使其在生物特征系统中实现更加困难。已有限的研究被进行在无接触指纹系统中的展示攻击，而这些研究又遇到了总结和扩展的问题，因为训练模型时需要使用真实样本和攻击样本。这种方法虽然看上去有前途，但缺乏对未看到的攻击的处理能力，这是开发PAD方法的关键因素。我们提出了一种创新的反射攻击方法，该方法结合了无监督 autoencoder 和卷积束注意模块来解决现有方法的局限性。我们的模型在训练阶段不曝光于任何假样本，然后在测试阶段进行了对各种展示攻击样本的评估。我们的方案实现了平均拒绝率0.96%， False Positive Rate 1.6%。
</details></li>
</ul>
<hr>
<h2 id="Locating-Cross-Task-Sequence-Continuation-Circuits-in-Transformers"><a href="#Locating-Cross-Task-Sequence-Continuation-Circuits-in-Transformers" class="headerlink" title="Locating Cross-Task Sequence Continuation Circuits in Transformers"></a>Locating Cross-Task Sequence Continuation Circuits in Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04131">http://arxiv.org/abs/2311.04131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Lan, Fazl Barez</li>
<li>for: 本研究旨在探讨transformer模型在语言任务中表现出色，但其复杂的架构使其难以解释。现有研究把transformer模型转化为可读的人类可读表示，称为Circuit。本文继续这项研究，对同类序列续写任务进行分析和比较Circuit。</li>
<li>methods: 本研究使用了Circuit分析技术，对同类序列续写任务进行分析和比较。通过分析，我们发现了检测序列成员和预测下一个序列成员的关键子Circuit，以及这些子Circuit在不同序列类型下的共同计算结构。</li>
<li>results: 本研究发现，semantically相关的序列归于共同的Circuit子图，具有相同的角色。通过文本分析技术，我们发现了预测下一个序列成员的关键因素，并且在不同序列类型下的模型行为预测得到了改进。总之，这项研究为建立更加稳定、对接和可解释的语言模型提供了重要的机制理解。<details>
<summary>Abstract</summary>
While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust, aligned, and interpretable language models.
</details>
<details>
<summary>摘要</summary>
transformer 模型在语言任务中表现出了强大的能力，但它们的复杂的架构使得它们难以解释。 recent work 通过将 transformer 模型转换成可读的人类可读的表示，即 circuit，来实现算法功能。 我们在这个研究中扩展这项工作，对同类序列续写任务进行了分析和比较，包括增加数字、数字词和月份。通过应用Circuit分析技术，我们已经发现了定义序列成员的关键子circuit，以及预测下一个序列成员的子circuit。我们的分析发现，semantically 相关的序列都是通过共享的circuit subgraphs来实现，这些subgraphs具有相似的角色。总之，通过记录模型行为的共同计算结构，我们可以更好地预测模型的行为，发现错误，并进行更安全的编辑过程。这种机制的理解是建立更加robust、aligned和可解释的语言模型的重要一步。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Safety-Vulnerabilities-of-Large-Language-Models"><a href="#Unveiling-Safety-Vulnerabilities-of-Large-Language-Models" class="headerlink" title="Unveiling Safety Vulnerabilities of Large Language Models"></a>Unveiling Safety Vulnerabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04124">http://arxiv.org/abs/2311.04124</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Kour, Marcel Zalmanovici, Naama Zwerdling, Esther Goldbraich, Ora Nova Fandina, Ateret Anaby-Tavor, Orna Raz, Eitan Farchi</li>
<li>for: 该论文旨在提供一个含有攻击示例的数据集，以检测大型自然语言模型的潜在危险或不适应 responses。</li>
<li>methods: 该论文使用了特有的 clustering 技术，对模型的输入 semantic areas 进行自动识别和命名，以便更好地评估模型的弱点和可靠性。</li>
<li>results: 该论文通过分析模型对含有攻击示例的数据集的应答，评估了模型的安全性和可靠性。<details>
<summary>Abstract</summary>
As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern. This paper introduces a unique dataset containing adversarial examples in the form of questions, which we call AttaQ, designed to provoke such harmful or inappropriate responses. We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it. Additionally, we introduce a novel automatic approach for identifying and naming vulnerable semantic regions - input semantic areas for which the model is likely to produce harmful outputs. This is achieved through the application of specialized clustering techniques that consider both the semantic similarity of the input attacks and the harmfulness of the model's responses. Automatically identifying vulnerable semantic regions enhances the evaluation of model weaknesses, facilitating targeted improvements to its safety mechanisms and overall reliability.
</details>
<details>
<summary>摘要</summary>
如大语言模型日益普遍，它们可能的危险或不适应答也成为了关心的话题。这篇论文提出了一个唯一的数据集，称为AttaQ，这些问题的形式是针对模型引起危险或不适应答的攻击数据集。我们通过对不同模型在这些数据集上的抵抗性进行分析，评估了我们的数据集的有效性。此外，我们还提出了一种新的自动化方法，可以自动地标识和命名模型容易受攻击的语义区域，即输入语义区域，使得模型可能生成危险输出的输入。这种方法基于特殊的聚类技术，考虑了输入攻击的语义相似性和模型的危险响应。自动地标识容易受攻击的语义区域，可以提高模型的评估，推进模型的安全机制和总可靠性的改进。
</details></li>
</ul>
<hr>
<h2 id="Multitask-Multimodal-Prompted-Training-for-Interactive-Embodied-Task-Completion"><a href="#Multitask-Multimodal-Prompted-Training-for-Interactive-Embodied-Task-Completion" class="headerlink" title="Multitask Multimodal Prompted Training for Interactive Embodied Task Completion"></a>Multitask Multimodal Prompted Training for Interactive Embodied Task Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04067">http://arxiv.org/abs/2311.04067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Pantazopoulos, Malvina Nikandrou, Amit Parekh, Bhathiya Hemanthage, Arash Eshghi, Ioannis Konstas, Verena Rieser, Oliver Lemon, Alessandro Suglia</li>
<li>for: 这个研究是为了解决视力和语言（VL）模型在实时和肢体任务中的问题，包括将语言与动作和观察之间的关联和语言对象化。</li>
<li>methods: 这个研究提出了一个具有多modal的代理人（EMMA），它是一个统一的encoder-decoder模型，可以理解图像和路径，并将动作预测设置为多modal的文本生成。</li>
<li>results: EMMA在多个VL标准库上表现不俗，并在Dialog-guided Task Completion（DTC）标准上设置新的州态艺术（36.81%成功率）。<details>
<summary>Abstract</summary>
Interactive and embodied tasks pose at least two fundamental challenges to existing Vision & Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation. To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation. By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks. Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion. EMMA performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena
</details>
<details>
<summary>摘要</summary>
现有的视觉语言（VL）模型面临两个基本挑战：1）将语言与动作轨迹和观察相关联，2）确定参照扩展。为解决这些挑战，我们提议一个具有多模态特征的embodied multimodal agent（EMMA）：一个统一编码解码模型，可以理解图像和轨迹，并将动作预测作为多Modal文本生成。通过将所有任务统一为文本生成，EMMA学习了一种动作语言，该语言可以促进任务转移。不同于之前的模块化方法，我们使用单一多任务模型，其中每个任务启发完成目标。EMMA在多个VL标准准测上与同类模型一样好，并在Dialog-guided Task Completion（DTC）标准上达到了新的州OF-THE-ART性能（36.81%成功率），这是评估对话引导者在Alexa Arena的一个 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Can-CLIP-Help-Sound-Source-Localization"><a href="#Can-CLIP-Help-Sound-Source-Localization" class="headerlink" title="Can CLIP Help Sound Source Localization?"></a>Can CLIP Help Sound Source Localization?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04066">http://arxiv.org/abs/2311.04066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Sooyoung Park, Arda Senocak, Joon Son Chung</li>
<li>for: 本研究用于扩展CLIP模型到声音来源Localization领域，并使用预训练的图像文本模型来提高声音地标化的精度和效率。</li>
<li>methods: 我们使用预训练CLIP模型，并对其进行特殊的修改，以便在没有文本输入的情况下，通过音频视频对应关系来生成声音地标。我们还提出了一种抽象音频信号为Token的方法，以便将其与CLIP模型的文本编码器进行对应。</li>
<li>results: 我们的方法可以生成更加完整和紧凑的声音地标图，并在多个实验中胜过了现有的方法，提高了声音地标的精度和效率。<details>
<summary>Abstract</summary>
Large-scale pre-trained image-text models demonstrate remarkable versatility across diverse tasks, benefiting from their robust representational capabilities and effective multimodal alignment. We extend the application of these models, specifically CLIP, to the domain of sound source localization. Unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.
</details>
<details>
<summary>摘要</summary>
大规模预训练图像文本模型在多种任务上表现出了惊人的多样性，受益于其强大的表示能力和有效的多Modal对应。我们将这些模型，特别是CLIP，应用到声源localization领域。 unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.Here is the word-for-word translation of the text into Simplified Chinese:大规模预训练图像文本模型在多种任务上表现出了惊人的多样性，受益于其强大的表示能力和有效的多Modal对应。我们将这些模型，特别是CLIP，应用到声源localization领域。与传统方法不同，我们使用预训练CLIP模型无需文本输入，仅仅利用声音-视频对应。为此，我们提出了一个框架，将audio信号转换为CLIP文本编码器兼容的token，生成audio驱动的嵌入。通过直接使用这些嵌入，我们的方法生成了声音驱动的面积映射，提取了声音驱动的图像特征从高亮区域，并将其与声音驱动的嵌入进行对应使用声音-视频对应目标。我们的发现表明，利用预训练图像文本模型可以使我们的模型生成更加完整和更加紧凑的localization图。广泛的实验表明，我们的方法在比较任务上高效地超越了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Multi-View-Causal-Representation-Learning-with-Partial-Observability"><a href="#Multi-View-Causal-Representation-Learning-with-Partial-Observability" class="headerlink" title="Multi-View Causal Representation Learning with Partial Observability"></a>Multi-View Causal Representation Learning with Partial Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04056">http://arxiv.org/abs/2311.04056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingling Yao, Danru Xu, Sébastien Lachapelle, Sara Magliacane, Perouz Taslakian, Georg Martius, Julius von Kügelgen, Francesco Locatello</li>
<li>for: 研究同时观察到的视图中学习表示的唯一性，包括不同数据模式的同时观察。</li>
<li>methods: 使用对准学习和每个视图一个编码器来学习对所有视图中信息的共享，并提供可以判断哪些 latent variable 可以通过简单规则进行标识的图像 критерий。</li>
<li>results:  theoretically 和实验ally  validate 多视图非线性ICA、解耦和 causal 表示学习的扩展和统一，并在不同特殊情况下回归到先前的方法性能。 通过多个部分视图，可以实现更细化的表示，只需要较轻松的假设Conditional observability。<details>
<summary>Abstract</summary>
We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. Overall, we find that access to multiple partial views enables us to identify a more fine-grained representation, under the generally milder assumption of partial observability.
</details>
<details>
<summary>摘要</summary>
我们提出一个统一的框架来研究同时观察到的视图中学习的表示性的可 identificability，例如不同数据模式。我们允许部分观察的设置，在每个视图中每个下标变量的非线性混合中包含一些基本的 latent variable。我们证明了所有视图集的信息可以通过对冲学学习和单个编码器来学习，并且可以到达一个平滑的 bijection。我们还提供了一些图形标准，可以通过简单的规则来判断 latent variable 的可 identificability。我们的总框架和理论结果将多视图非线性 ICAR、解体和 causal 表示学习的前期工作统一和扩展。我们在数字、图像和多模式数据集上进行了实验 validate 我们的声明，并且表明了特殊情况下的先前方法的性能可以被回归。总之，我们发现了多个部分视图可以为我们提供更细化的表示，在一般更轻松的部分可见性假设下。
</details></li>
</ul>
<hr>
<h2 id="Causal-Discovery-Under-Local-Privacy"><a href="#Causal-Discovery-Under-Local-Privacy" class="headerlink" title="Causal Discovery Under Local Privacy"></a>Causal Discovery Under Local Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04037">http://arxiv.org/abs/2311.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rūta Binkytė, Carlos Pinzón, Szilvia Lestyán, Kangsoo Jung, Héber H. Arcolezi, Catuscia Palamidessi</li>
<li>For: 本研究旨在探讨了本地均勋 privacy  Mechanism 在 causal discovery 任务中的选择。* Methods: 本研究考虑了多种常见的本地均勋 privacy 机制，并对这些机制在 causal discovery 任务中的准确性和隐私提供了比较。* Results: 研究发现，不同的本地均勋 privacy 机制对 causal discovery 任务中的准确性和隐私提供了不同的贡献。 这些结果可以帮助研究人员和实践者在进行本地私有 causal discovery 时进行选择。<details>
<summary>Abstract</summary>
Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set. It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers. Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually. Therefore it provides protection also in contexts in which the server, or even the data collector, cannot be trusted. The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components. This distortion can prove detrimental to tasks such as causal discovery. In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms. Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks. We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery.
</details>
<details>
<summary>摘要</summary>
diffe革� Privacy 是一种广泛采用的框架，用于保护数据提供者在数据集中的敏感信息。它基于数据存储和处理服务器和数据consumer之间的控制随机噪声的应用。本地 diffe革� Privacy 是一种变体，允许数据提供者本地应用随机噪声机制，以提供隐私保护。因此，它可以在服务器或数据收集者不可靠的情况下提供保护。然而，随机噪声的引入不可避免地影响数据的用户性，特别是对数据组件之间的相关性进行扭曲。这种扭曲可能对 causal 发现任务产生负面影响。在这篇论文中，我们考虑了多种知名的本地随机隐私机制，并比较这些机制提供的隐私和 causal 结构产生算法应用于数据做隐私处理后的准确性的负面关系。我们的分析提供了选择合适的本地随机隐私协议的有价值信息，以帮助研究者和实践者进行本地私人 causal 发现。
</details></li>
</ul>
<hr>
<h2 id="Impact-of-HPO-on-AutoML-Forecasting-Ensembles"><a href="#Impact-of-HPO-on-AutoML-Forecasting-Ensembles" class="headerlink" title="Impact of HPO on AutoML Forecasting Ensembles"></a>Impact of HPO on AutoML Forecasting Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04034">http://arxiv.org/abs/2311.04034</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Hoffmann</li>
<li>for: 这 paper 是为了研究如何使用不同的 Hyperparameter Optimization 策略来提高深度学习模型的预测性能。</li>
<li>methods: 这 paper 使用了一个多元预测集合，包括 MQ-CNN、DeepAR、Prophet、NPTS、ARIMA 和 ETS，来预测不同的问题。它还研究了在这些深度学习模型中添加不同的 Hyperparameter Optimization 策略的影响。</li>
<li>results: 这 paper 的结果表明，在这种 setup 中添加 Hyperparameter Optimization 可以提高预测性能，最终组合的设置比基eline 集合 ohne HPO 提高了9.9%的准确率，并且降低了65.8%的总体集合延迟时间。这个改进基于对不同的 ensemble pipeline 和 tuning 策略的实验分析，包括 Bayesian Optimization 和 Hyperband。最终的组合还超过了商业 AutoML 预测解决方案 Amazon Forecast，具有3.5%的较低的错误率和16.0%的较低的总体集合延迟时间。<details>
<summary>Abstract</summary>
A forecasting ensemble consisting of a diverse range of estimators for both local and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet, NPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems. This paper delves into the aspect of adding different hyperparameter optimization strategies to the deep learning models in such a setup (DeepAR and MQ-CNN), exploring the trade-off between added training cost and the increase in accuracy for different configurations. It shows that in such a setup, adding hyperparameter optimization can lead to performance improvements, with the final setup having a 9.9 % percent accuracy improvement with respect to the avg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 % increase in end-to-end ensemble latency. This improvement is based on an empirical analysis of combining the ensemble pipeline with different tuning strategies, namely Bayesian Optimisation and Hyperband and different configurations of those strategies. In the final configuration, the proposed combination of ensemble learning and HPO outperforms the state of the art commercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower error and 16.0 % lower end-to-end ensemble latency.
</details>
<details>
<summary>摘要</summary>
一个包含多种估计器的预测集群，包括MQ-CNN、DeepAR、Prophet、NPTS、ARIMA和ETS，可以用于解决多种问题的预测。这篇论文探讨了在深度学习模型中添加不同的超参数优化策略的方面（DeepAR和MQ-CNN），探讨了增加训练成本和准确性提升的交互关系。结果显示，在这种设置下，添加超参数优化可以提高表现，最终设置与avg-wQL相比增加9.9%的准确性，同时增加65.8%的终端集群延迟。这种提升基于对 ensemble 管道与不同的调试策略（bayesian 优化和 Hyperband）的实际分析。在最终配置下，提案的集群学习和HPO组合超过了商业 AutoML 预测解决方案Amazon Forecast，具有3.5%更低的错误率和16.0%更低的终端集群延迟。
</details></li>
</ul>
<hr>
<h2 id="Expressivity-of-ReLU-Networks-under-Convex-Relaxations"><a href="#Expressivity-of-ReLU-Networks-under-Convex-Relaxations" class="headerlink" title="Expressivity of ReLU-Networks under Convex Relaxations"></a>Expressivity of ReLU-Networks under Convex Relaxations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04015">http://arxiv.org/abs/2311.04015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Baader, Mark Niklas Müller, Yuhao Mao, Martin Vechev</li>
<li>for: 这篇论文探讨了使用 convex relaxations 训练和证明神经网络的可证明安全性。</li>
<li>methods: 这篇论文使用了多种常用的 convex relaxations，包括 IBP relaxation，以研究神经网络可以表示什么样的函数。</li>
<li>results: 研究发现，使用更高级别的 convex relaxations，可以让更多的单变量函数被神经网络精确地表示。同时，使用最精确的单 neuron relaxations，也无法构建多变量、凸、 monotone CPWL 函数被神经网络精确地表示。<details>
<summary>Abstract</summary>
Convex relaxations are a key component of training and certifying provably safe neural networks. However, despite substantial progress, a wide and poorly understood accuracy gap to standard networks remains, raising the question of whether this is due to fundamental limitations of convex relaxations. Initial work investigating this question focused on the simple and widely used IBP relaxation. It revealed that some univariate, convex, continuous piecewise linear (CPWL) functions cannot be encoded by any ReLU network such that its IBP-analysis is precise. To explore whether this limitation is shared by more advanced convex relaxations, we conduct the first in-depth study on the expressive power of ReLU networks across all commonly used convex relaxations. We show that: (i) more advanced relaxations allow a larger class of univariate functions to be expressed as precisely analyzable ReLU networks, (ii) more precise relaxations can allow exponentially larger solution spaces of ReLU networks encoding the same functions, and (iii) even using the most precise single-neuron relaxations, it is impossible to construct precisely analyzable ReLU networks that express multivariate, convex, monotone CPWL functions.
</details>
<details>
<summary>摘要</summary>
凸relaxation是训练和证明可靠神经网络的关键组件。然而，尽管取得了重要进步，但是仍存在一个宽泛不寻常的准确缺陷，使得是否由凸relaxation的基本限制而导致的问题得到了提出。初期的研究表明，使用IBP relaxation时，一些单变量、凸、连续piecewise线性（CPWL）函数无法被ReLU网络编码，使得其IBP分析不准确。为了探讨这一限制是否适用于更先进的凸relaxation，我们进行了所有常用凸relaxation的深入研究。我们发现了以下结论：1.更先进的relaxation允许更多的单变量函数被ReLU网络编码，并且其IBP分析是precise。2.更精准的relaxation可以让ReLU网络编码的函数空间 exponentially大，而不损失准确性。3. même使用最精准的单 neuron relaxation，无法构建precise的ReLU网络，用于表示多变量、凸、 monotone CPWL函数。
</details></li>
</ul>
<hr>
<h2 id="A-Method-to-Improve-the-Performance-of-Reinforcement-Learning-Based-on-the-Y-Operator-for-a-Class-of-Stochastic-Differential-Equation-Based-Child-Mother-Systems"><a href="#A-Method-to-Improve-the-Performance-of-Reinforcement-Learning-Based-on-the-Y-Operator-for-a-Class-of-Stochastic-Differential-Equation-Based-Child-Mother-Systems" class="headerlink" title="A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems"></a>A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04014">http://arxiv.org/abs/2311.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Yin, Yi Chen</li>
<li>for: 提高actor-critic基于渐变方程学习控制性能</li>
<li>methods: 引入Y运算符，将儿童系统的随机性 интеGRATE INTO critic网络的损失函数中，提高RL算法的控制性能</li>
<li>results: Y运算符可以快速和高效地解决优化控制问题，在线性和非线性数学示例中显示出增强的性能 compared to 现有方法 post convergence。<details>
<summary>Abstract</summary>
This paper introduces a novel operator, termed the Y operator, to elevate control performance in Actor-Critic(AC) based reinforcement learning for systems governed by stochastic differential equations(SDEs). The Y operator ingeniously integrates the stochasticity of a class of child-mother system into the Critic network's loss function, yielding substantial advancements in the control performance of RL algorithms.Additionally, the Y operator elegantly reformulates the challenge of solving partial differential equations for the state-value function into a parallel problem for the drift and diffusion functions within the system's SDEs.A rigorous mathematical proof confirms the operator's validity.This transformation enables the Y Operator-based Reinforcement Learning(YORL) framework to efficiently tackle optimal control problems in both model-based and data-driven systems.The superiority of YORL is demonstrated through linear and nonlinear numerical examples showing its enhanced performance over existing methods post convergence.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的运算符，称之为Y运算符，用于提高基于actor-critic(AC)的激励学习控制性能，适用于具有渐变方程(SDEs)的系统。Y运算符巧妙地将儿系统中的随机性 интеGRATE到批处网络的损失函数中，从而实现了RL算法的控制性能的显著提高。此外，Y运算符也美化地将解决部分梯度方程的问题转化为在SDEs中的并行问题。一个严格的数学证明证明了运算符的有效性。这种转换使得基于Y运算符的激励学习框架(YORL)可以高效地解决模型基于和数据驱动的优化控制问题。在线性和非线性数字例子中，YORL表现出了与现有方法相比的提高。
</details></li>
</ul>
<hr>
<h2 id="The-Energy-Prediction-Smart-Meter-Dataset-Analysis-of-Previous-Competitions-and-Beyond"><a href="#The-Energy-Prediction-Smart-Meter-Dataset-Analysis-of-Previous-Competitions-and-Beyond" class="headerlink" title="The Energy Prediction Smart-Meter Dataset: Analysis of Previous Competitions and Beyond"></a>The Energy Prediction Smart-Meter Dataset: Analysis of Previous Competitions and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04007">http://arxiv.org/abs/2311.04007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Direnc Pekaslan, Jose Maria Alonso-Moral, Kasun Bandara, Christoph Bergmeir, Juan Bernabe-Moreno, Robert Eigenmann, Nils Einecke, Selvi Ergen, Rakshitha Godahewa, Hansika Hewamalage, Jesus Lago, Steffen Limmer, Sven Rebhan, Boris Rabinovich, Dilini Rajapasksha, Heda Song, Christian Wagner, Wenlong Wu, Luis Magdalena, Isaac Triguero</li>
<li>for: 这篇论文探讨了基于智能计量器数据的能源预测技术挑战，主要关注2020年IEEE计算智能学会（IEEE-CIS）技术挑战和2021年IEEE国际 Conference on Fuzzy Systems（FUZZ-IEEE）的跟进挑战。</li>
<li>methods: 这篇论文使用了智能计量器数据进行实际世界的数据集分析，并提出了一些解决方案，包括精准的能源消耗预测和解释性能量预测。</li>
<li>results: 这篇论文通过分析智能计量器数据集，发现了一些挑战和解决方案，并提出了一些新的应用前景，如能源分解、需求约束计划和行为改变等。<details>
<summary>Abstract</summary>
This paper presents the real-world smart-meter dataset and offers an analysis of solutions derived from the Energy Prediction Technical Challenges, focusing primarily on two key competitions: the IEEE Computational Intelligence Society (IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in 2020 (named EP) and its follow-up challenge at the IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These competitions focus on accurate energy consumption forecasting and the importance of interpretability in understanding the underlying factors. The challenge aims to predict monthly and yearly estimated consumption for households, addressing the accurate billing problem with limited historical smart meter data. The dataset comprises 3,248 smart meters, with varying data availability ranging from a minimum of one month to a year. This paper delves into the challenges, solutions and analysing issues related to the provided real-world smart meter data, developing accurate predictions at the household level, and introducing evaluation criteria for assessing interpretability. Additionally, this paper discusses aspects beyond the competitions: opportunities for energy disaggregation and pattern detection applications at the household level, significance of communicating energy-driven factors for optimised billing, and emphasising the importance of responsible AI and data privacy considerations. These aspects provide insights into the broader implications and potential advancements in energy consumption prediction. Overall, these competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards the discussion of various aspects such as energy disaggregation, demand response programs or behavioural interventions.
</details>
<details>
<summary>摘要</summary>
The dataset includes 3,248 smart meters with varying data availability, ranging from one month to one year. The paper explores the challenges, solutions, and evaluation criteria for developing accurate predictions at the household level. Additionally, it discusses opportunities for energy disaggregation and pattern detection applications, the significance of communicating energy-driven factors for optimized billing, and the importance of responsible AI and data privacy considerations.These competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards discussions of various aspects such as energy disaggregation, demand response programs, or behavioral interventions. Overall, this paper provides insights into the broader implications and potential advancements in energy consumption prediction.
</details></li>
</ul>
<hr>
<h2 id="Human-AI-Collaboration-in-Thematic-Analysis-using-ChatGPT-A-User-Study-and-Design-Recommendations"><a href="#Human-AI-Collaboration-in-Thematic-Analysis-using-ChatGPT-A-User-Study-and-Design-Recommendations" class="headerlink" title="Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations"></a>Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03999">http://arxiv.org/abs/2311.03999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixiang Yan, Vanessa Echeverria, Gloria Fernandez Nieto, Yueqiao Jin, Zachari Swiecki, Linxuan Zhao, Dragan Gašević, Roberto Martinez-Maldonado</li>
<li>for: 这个论文旨在探讨研究者与生成人工智能（GenAI）在质量研究中的合作方式，以帮助提高人类-AI协作的效率。</li>
<li>methods: 本研究使用了ChatGPT作为研究者的合作对象，通过对10名质量研究者的用户研究来探讨他们与GenAI的协作方式。</li>
<li>results: 研究发现，ChatGPT可以帮助研究者进行主题分析，提高编码效率，帮助初步数据探索，提供细腻的量化意义，以及帮助非native speaker和非专家理解。然而，研究人员对其可靠性、一致性和广泛acceptance在研究社区的担忧仍然存在。<details>
<summary>Abstract</summary>
Generative artificial intelligence (GenAI) offers promising potential for advancing human-AI collaboration in qualitative research. However, existing works focused on conventional machine-learning and pattern-based AI systems, and little is known about how researchers interact with GenAI in qualitative research. This work delves into researchers' perceptions of their collaboration with GenAI, specifically ChatGPT. Through a user study involving ten qualitative researchers, we found ChatGPT to be a valuable collaborator for thematic analysis, enhancing coding efficiency, aiding initial data exploration, offering granular quantitative insights, and assisting comprehension for non-native speakers and non-experts. Yet, concerns about its trustworthiness and accuracy, reliability and consistency, limited contextual understanding, and broader acceptance within the research community persist. We contribute five actionable design recommendations to foster effective human-AI collaboration. These include incorporating transparent explanatory mechanisms, enhancing interface and integration capabilities, prioritising contextual understanding and customisation, embedding human-AI feedback loops and iterative functionality, and strengthening trust through validation mechanisms.
</details>
<details>
<summary>摘要</summary>
人工智能生成技术（GenAI）在质量研究中具有普遍的潜在优势，但现有的研究主要集中在传统的机器学习和模式基于的人工智能系统上，对GenAI在质量研究中的人类与AI合作的研究相对落后。本研究探讨了十名质量研究者对ChatGPT的合作体验，发现ChatGPT作为主题分析的合作伙伴，可以提高编码效率，帮助初步数据探索，提供细致的量化预测，并帮助非native speaker和非专家理解。然而，对其可靠性和准确性、可靠性和一致性、局部理解和自适应性、以及研究社区更广泛的acceptance仍然存在问题。我们提出五个可行的设计建议，以促进人类与AI合作的有效性，包括：在设计中加入透明的解释机制，提高界面和集成能力，优先级contextual understanding和个性化，嵌入人类与AI反馈循环和迭代功能，以及加强信任通过验证机制。
</details></li>
</ul>
<hr>
<h2 id="Learned-Causal-Method-Prediction"><a href="#Learned-Causal-Method-Prediction" class="headerlink" title="Learned Causal Method Prediction"></a>Learned Causal Method Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03989">http://arxiv.org/abs/2311.03989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shantanu Gupta, Cheng Zhang, Agrin Hilmkil</li>
<li>for: 这 paper 用于选择最佳 causal inference 方法，以便有效地处理 causal discovery 问题。</li>
<li>methods: 这 paper 使用 CAusal Method Predictor (CAMP) 框架，通过生成多种同源 causal 模型，对 candidate methods 进行评分，并使用一个模型来直接预测最高分方法。</li>
<li>results: CAMP 在实验中表现出色，可以有效地预测最佳方法，并且在未看到真实数据的情况下，可以减少高成本的标注数据。 CAMP 还在 semi-synthetic 和实际世界 benchmark 上表现了扎根的一致性。<details>
<summary>Abstract</summary>
For a given causal question, it is important to efficiently decide which causal inference method to use for a given dataset. This is challenging because causal methods typically rely on complex and difficult-to-verify assumptions, and cross-validation is not applicable since ground truth causal quantities are unobserved.In this work, we propose CAusal Method Predictor (CAMP), a framework for predicting the best method for a given dataset. To this end, we generate datasets from a diverse set of synthetic causal models, score the candidate methods, and train a model to directly predict the highest-scoring method for that dataset. Next, by formulating a self-supervised pre-training objective centered on dataset assumptions relevant for causal inference, we significantly reduce the need for costly labeled data and enhance training efficiency. Our strategy learns to map implicit dataset properties to the best method in a data-driven manner. In our experiments, we focus on method prediction for causal discovery. CAMP outperforms selecting any individual candidate method and demonstrates promising generalization to unseen semi-synthetic and real-world benchmarks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>为给定的 causal 问题，效率地选择适合的 causal inference 方法是挑战。这是因为 causal 方法通常需要复杂和难以验证的假设，并且 cross-validation 不适用，因为真实的 causal 量未经观察。在这种情况下，我们提出了 CAusal Method Predictor (CAMP)，一个框架用于预测最佳方法。为此，我们生成了基于多种 synthetic causal 模型的数据集，评分候选方法，并使用一个模型直接预测该数据集中最高分的方法。接着，我们通过 centering on dataset 假设 relevante 于 causal inference 来降低需要贵重标注数据的需求，并提高训练效率。我们的策略可以在数据驱动的方式下将隐藏在数据中的 dataset 特性映射到最佳方法上。在我们的实验中，我们将注重 causal discovery 中的方法预测。CAMP 在比较任何个人候选方法时表现出色，并在未看到 semi-synthetic 和实际世界 benchmark 上展现了扎根的普适性。
</details></li>
</ul>
<hr>
<h2 id="Its-All-Graph-To-Me-Foundational-Topology-Models-with-Contrastive-Learning-on-Multiple-Domains"><a href="#Its-All-Graph-To-Me-Foundational-Topology-Models-with-Contrastive-Learning-on-Multiple-Domains" class="headerlink" title="Its All Graph To Me: Foundational Topology Models with Contrastive Learning on Multiple Domains"></a>Its All Graph To Me: Foundational Topology Models with Contrastive Learning on Multiple Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03976">http://arxiv.org/abs/2311.03976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex O. Davies, Riku W. Green, Nirav S. Ajmeri, Telmo M. Silva Filho</li>
<li>for:  This paper aims to address the issue of domain-specific pre-trained models for graph data, and to present a method that can be fine-tuned on multiple graph domains.</li>
<li>methods: The proposed method uses adversarial contrastive learning to pre-train a model on many graph domains, without requiring labeled data from the target domain. The model is trained only on topologies, but includes node labels in evaluation.</li>
<li>results: The authors show that the learnt representations of the proposed method are effective in various downstream tasks, and outperform baseline models pre-trained on single domains, as well as un-trained models and non-transferred models. The performance is consistently superior when node labels are used in evaluation.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文的目标是解决图数据中域特定预训练模型的问题，并提出一种方法可以在多个图域上进行预训练。</li>
<li>methods: 提议的方法使用对抗抑制学习来预训练一个模型在多个图域上，不需要目标域的标注数据。模型仅在结构上进行训练，但在评估中包含节点标签。</li>
<li>results: 作者表明，提议的方法的学习表现在下游任务中是有效的，并超过了基准模型预训练单个域、无预训练模型和非预训练模型。在使用节点标签进行评估时，性能一直高于单个域或无预训练模型。<details>
<summary>Abstract</summary>
Representations and embeddings of graph data have been essential in many domains of research.   The principle benefit of learning such representations is that the pre-trained model can be fine-tuned on smaller datasets where data or labels are scarse.   Existing models, however, are domain specific; for example a model trained on molecular graphs is fine-tuned on other molecular graphs.   This means that in many application cases the choice of pre-trained model can be arbitrary, and novel domains may lack an appropriate pre-trained model.   This is of particular issue where data is scarse, precluding traditional supervised methods.   In this work we use adversarial contrastive learning to present a \method, a model pre-trained on many graph domains.   We train the model only on topologies but include node labels in evaluation.   We evaluate the efficacy of its learnt representations on various downstream tasks.   Against baseline models pre-trained on single domains, as well as un-trained models and non-transferred models, we show that performance is equal or better using our single model.   This includes when node labels are used in evaluation, where performance is consistently superior to single-domain or non-pre-trained models.
</details>
<details>
<summary>摘要</summary>
研究领域中的图数据表示和嵌入已经是不可或缺的。这些表示的主要优点在于可以使用预训练模型进行精度调整，从而在数据或标签稀缺的情况下进行预测。现有的模型却是域特定的，例如一个用于分子图的模型只能在其他分子图上进行精度调整。这意味着在许多应用场景中，选择预训练模型的问题可能是随意的，而新的域可能缺乏适合的预训练模型。这是特别是在数据稀缺的情况下，传统的监督学习方法无法进行。在这项工作中，我们使用对抗对抗学习来提出一种方法，这是一个在多个图域上预训练的模型。我们只在图结构上进行训练，并在评估中包含节点标签。我们对此模型在多个下游任务上的表现进行评估，并与基eline模型、无预训练模型和非传递模型进行比较。我们发现，使用我们的单一模型，表现和基eline模型相当或更好，尤其是在节点标签在评估中使用时。
</details></li>
</ul>
<hr>
<h2 id="An-Expectation-Realization-Model-for-Metaphor-Detection"><a href="#An-Expectation-Realization-Model-for-Metaphor-Detection" class="headerlink" title="An Expectation-Realization Model for Metaphor Detection"></a>An Expectation-Realization Model for Metaphor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03963">http://arxiv.org/abs/2311.03963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oseremen O. Uduehi, Razvan C. Bunescu</li>
<li>for: 这个论文主要针对的是如何检测比喻。</li>
<li>methods: 该论文提出了一种基于两个主要模块的比喻检测架构：一个预期组件，该计算给定上下文中 literal word 的预期表示，以及一个实现组件，该计算actual word 的含义在上下文中。整个架构通过学习预期-实现（ER）模式来学习比喻的用法。</li>
<li>results: 该论文在三个比喻数据集上进行了评估，包括在分布内、分布外以及新比喻泛化等三个情况下的评估。结果显示，提出的方法在这些情况下都能够获得竞争或更好的结果，而且通过 ensemble ER 模型可以进一步提高比喻检测精度。<details>
<summary>Abstract</summary>
We propose a metaphor detection architecture that is structured around two main modules: an expectation component that estimates representations of literal word expectations given a context, and a realization component that computes representations of actual word meanings in context. The overall architecture is trained to learn expectation-realization (ER) patterns that characterize metaphorical uses of words. When evaluated on three metaphor datasets for within distribution, out of distribution, and novel metaphor generalization, the proposed method is shown to obtain results that are competitive or better than state-of-the art. Further increases in metaphor detection accuracy are obtained through ensembling of ER models.
</details>
<details>
<summary>摘要</summary>
我们提出了一种使用两个主要模块的比喻检测建筑：一个预期部件，用于在 контексте中估计literal字的预期表示，以及一个现实部件，用于在 контексте中计算实际字的含义。整个建筑是通过学习预期-现实（ER）模式来学习比喻的用法。在三个比喻数据集上进行评估，包括在分布内、分布外和新比喻泛化，我们的方法比或超过了当前最佳的结果。进一步的增加了比喻检测精度的ensemble ER模型。
</details></li>
</ul>
<hr>
<h2 id="Elastic-Information-Bottleneck"><a href="#Elastic-Information-Bottleneck" class="headerlink" title="Elastic Information Bottleneck"></a>Elastic Information Bottleneck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03955">http://arxiv.org/abs/2311.03955</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyyxxx/elastic-information-bottleneck">https://github.com/nyyxxx/elastic-information-bottleneck</a></li>
<li>paper_authors: Yuyan Ni, Yanyan Lan, Ao Liu, Zhiming Ma</li>
<li>for: 本研究旨在探讨信息瓶颈（IB）和决定性信息瓶颈（DIB）在转移学习场景下的泛化能力。</li>
<li>methods: 本研究使用了IB和DIB两种方法，并对它们的泛化能力进行了分析。</li>
<li>results: 研究结果表明，DIB的泛化能力较IB更强，但是DIB的表示差（RD）较IB更大。为了平衡这两个因素，我们提出了一种灵活信息瓶颈（EIB）方法，可以在IB框架中实现最优平衡。实验结果表明，EIB可以在适用于实际数据上实现更好的领域适应性。<details>
<summary>Abstract</summary>
Information bottleneck is an information-theoretic principle of representation learning that aims to learn a maximally compressed representation that preserves as much information about labels as possible. Under this principle, two different methods have been proposed, i.e., information bottleneck (IB) and deterministic information bottleneck (DIB), and have gained significant progress in explaining the representation mechanisms of deep learning algorithms. However, these theoretical and empirical successes are only valid with the assumption that training and test data are drawn from the same distribution, which is clearly not satisfied in many real-world applications. In this paper, we study their generalization abilities within a transfer learning scenario, where the target error could be decomposed into three components, i.e., source empirical error, source generalization gap (SG), and representation discrepancy (RD). Comparing IB and DIB on these terms, we prove that DIB's SG bound is tighter than IB's while DIB's RD is larger than IB's. Therefore, it is difficult to tell which one is better. To balance the trade-off between SG and the RD, we propose an elastic information bottleneck (EIB) to interpolate between the IB and DIB regularizers, which guarantees a Pareto frontier within the IB framework. Additionally, simulations and real data experiments show that EIB has the ability to achieve better domain adaptation results than IB and DIB, which validates the correctness of our theories.
</details>
<details>
<summary>摘要</summary>
信息瓶颈是一种信息理论的学习原理，旨在学习最高度压缩的表示，以保持最多的信息关于标签。在这个原理下，有两种不同的方法被提出：信息瓶颈（IB）和决定性信息瓶颈（DIB），它们在理论和实验方面做出了重要的进步，解释了深度学习算法的表示机制。但是，这些理论和实验成功假设训练和测试数据来自同一个分布，这并不符合现实世界中的许多应用场景。在这篇论文中，我们研究IB和DIB在转移学习场景下的泛化能力，将目标错误分解为三个组件：源采样错误（SE）、源泛化差（SG）和表示差异（RD）。比较IB和DIB的 bound，我们证明DIB的 SG bound 更紧，而DIB的 RD 更大。因此，无法判断哪一个更好。为了平衡SG和RD的负担，我们提出了灵活信息瓶颈（EIB），可以在IB框架中 interpolate  междуIB和DIB正则化，这 garantía一个Pareto前沿。此外，实验和实际数据表明，EIB可以在适应域中实现更好的适应结果，这证明了我们的理论的正确性。
</details></li>
</ul>
<hr>
<h2 id="The-Music-Meta-Ontology-a-flexible-semantic-model-for-the-interoperability-of-music-metadata"><a href="#The-Music-Meta-Ontology-a-flexible-semantic-model-for-the-interoperability-of-music-metadata" class="headerlink" title="The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata"></a>The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03942">http://arxiv.org/abs/2311.03942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacopo de Berardinis, Valentina Anita Carriero, Albert Meroño-Peñuela, Andrea Poltronieri, Valentina Presutti</li>
<li>for:  This paper aims to provide a semantic model for music metadata to facilitate the creation of music datasets that can be aligned, integrated, and accessed for information retrieval and knowledge discovery.</li>
<li>methods:  The paper introduces the Music Meta ontology, which is a rich and flexible semantic model that describes music metadata related to artists, compositions, performances, recordings, and links. The authors follow eXtreme Design methodologies and best practices for data engineering to ensure that the model reflects the perspectives and requirements of various stakeholders.</li>
<li>results:  The paper provides a first evaluation of the Music Meta model, including alignments to other schema (Music Ontology, DOREMUS, Wikidata) and support for data transformation.<details>
<summary>Abstract</summary>
The semantic description of music metadata is a key requirement for the creation of music datasets that can be aligned, integrated, and accessed for information retrieval and knowledge discovery. It is nonetheless an open challenge due to the complexity of musical concepts arising from different genres, styles, and periods -- standing to benefit from a lingua franca to accommodate various stakeholders (musicologists, librarians, data engineers, etc.). To initiate this transition, we introduce the Music Meta ontology, a rich and flexible semantic model to describe music metadata related to artists, compositions, performances, recordings, and links. We follow eXtreme Design methodologies and best practices for data engineering, to reflect the perspectives and the requirements of various stakeholders into the design of the model, while leveraging ontology design patterns and accounting for provenance at different levels (claims, links). After presenting the main features of Music Meta, we provide a first evaluation of the model, alignments to other schema (Music Ontology, DOREMUS, Wikidata), and support for data transformation.
</details>
<details>
<summary>摘要</summary>
“音乐元数据的 semantic 描述是创建可以一致、 интеграción和搜索信息的音乐数据集的关键要求。然而，这是一个打开的挑战，因为音乐的概念来自不同的流派、风格和时期，需要一种 lingua franca 来容纳各种参与者（音乐学家、图书馆员、数据工程师等）。为了实现这一目标，我们介绍了 Music Meta  Ontology，这是一个rich和flexible的semantic模型，用于描述音乐元数据，包括艺术家、作品、表演、录音和链接。我们遵循 eXtreme Design 方法和数据工程的最佳实践，将参与者的视角和需求反映到模型的设计中，同时遵循 ontology 设计模式和考虑多级宣告（laims、链接）的来源。在介绍 Music Meta 的主要特点后，我们提供了模型的初步评估、与 Music Ontology 和 DOREMUS 的对接以及数据转换支持。”Note: "Simplified Chinese" is used to refer to the standardized form of Chinese used in mainland China and Singapore, which is different from "Traditional Chinese" used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Temporal-Graph-Representation-Learning-with-Adaptive-Augmentation-Contrastive"><a href="#Temporal-Graph-Representation-Learning-with-Adaptive-Augmentation-Contrastive" class="headerlink" title="Temporal Graph Representation Learning with Adaptive Augmentation Contrastive"></a>Temporal Graph Representation Learning with Adaptive Augmentation Contrastive</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03897">http://arxiv.org/abs/2311.03897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongjiang Chen, Pengfei Jiao, Huijun Tang, Huaming Wu</li>
<li>for: 本文旨在提出一种基于强化对比的图像学习模型，以便在时间序列中提取低维度的动态节点嵌入，同时捕捉时间信息、结构信息和属性信息。</li>
<li>methods: 本文提出的模型是基于强化对比的图像学习模型，具有适应增强的特点，可以在时间序列中适应不同的噪声。</li>
<li>results: 实验结果表明，提出的模型在各种实际网络上表现出优于其他时间图像学习方法。<details>
<summary>Abstract</summary>
Temporal graph representation learning aims to generate low-dimensional dynamic node embeddings to capture temporal information as well as structural and property information. Current representation learning methods for temporal networks often focus on capturing fine-grained information, which may lead to the model capturing random noise instead of essential semantic information. While graph contrastive learning has shown promise in dealing with noise, it only applies to static graphs or snapshots and may not be suitable for handling time-dependent noise. To alleviate the above challenge, we propose a novel Temporal Graph representation learning with Adaptive augmentation Contrastive (TGAC) model. The adaptive augmentation on the temporal graph is made by combining prior knowledge with temporal information, and the contrastive objective function is constructed by defining the augmented inter-view contrast and intra-view contrast. To complement TGAC, we propose three adaptive augmentation strategies that modify topological features to reduce noise from the network. Our extensive experiments on various real networks demonstrate that the proposed model outperforms other temporal graph representation learning methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translation_direction=zh-Hans Temporal graph representation learning aims to generate low-dimensional dynamic node embeddings to capture temporal information as well as structural and property information. Current representation learning methods for temporal networks often focus on capturing fine-grained information, which may lead to the model capturing random noise instead of essential semantic information. While graph contrastive learning has shown promise in dealing with noise, it only applies to static graphs or snapshots and may not be suitable for handling time-dependent noise. To alleviate the above challenge, we propose a novel Temporal Graph representation learning with Adaptive augmentation Contrastive (TGAC) model. The adaptive augmentation on the temporal graph is made by combining prior knowledge with temporal information, and the contrastive objective function is constructed by defining the augmented inter-view contrast and intra-view contrast. To complement TGAC, we propose three adaptive augmentation strategies that modify topological features to reduce noise from the network. Our extensive experiments on various real networks demonstrate that the proposed model outperforms other temporal graph representation learning methods.Note: The translation is in Simplified Chinese, which is one of the two standardized Chinese writing systems. The other one is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Understanding-Tool-Discovery-and-Tool-Innovation-Using-Active-Inference"><a href="#Understanding-Tool-Discovery-and-Tool-Innovation-Using-Active-Inference" class="headerlink" title="Understanding Tool Discovery and Tool Innovation Using Active Inference"></a>Understanding Tool Discovery and Tool Innovation Using Active Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03893">http://arxiv.org/abs/2311.03893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Poppy Collis, Paul F Kinghorn, Christopher L Buckley</li>
<li>for: 本研究旨在探讨人工智能代理的工具创新能力。</li>
<li>methods: 本文使用 active inference  formalism 分析工具发现和工具创新的两个概念，并在拟合一种工具创新模型中引入工具可能性的概念。</li>
<li>results: 本研究发现，通过在机器学习模型中隐藏状态中引入工具可能性，可以不仅发现工具，还可以创造新的工具。<details>
<summary>Abstract</summary>
The ability to invent new tools has been identified as an important facet of our ability as a species to problem solve in dynamic and novel environments. While the use of tools by artificial agents presents a challenging task and has been widely identified as a key goal in the field of autonomous robotics, far less research has tackled the invention of new tools by agents. In this paper, (1) we articulate the distinction between tool discovery and tool innovation by providing a minimal description of the two concepts under the formalism of active inference. We then (2) apply this description to construct a toy model of tool innovation by introducing the notion of tool affordances into the hidden states of the agent's probabilistic generative model. This particular state factorisation facilitates the ability to not just discover tools but invent them through the offline induction of an appropriate tool property. We discuss the implications of these preliminary results and outline future directions of research.
</details>
<details>
<summary>摘要</summary>
人类的问题解决能力是通过创造新工具的能力，这被认为是我们种族的重要特征之一。虽然人工智能代理人使用工具是一个挑战性任务，但相比之下，代理人创造新工具的研究得到了更少的关注。在这篇论文中，我们将（1）描述工具发现和工具创新之间的区别，通过活动推断来提供最小的描述。然后我们（2）将这种描述应用于构建一个简单的工具创新模型，通过引入工具可用性的概念来加入代理人隐藏状态的概率生成模型中。这种特征分解使得代理人不仅能够发现工具，还能够通过离线推导适应性的工具属性来创造新的工具。我们讨论了这些初步结果的意义和未来研究的方向。
</details></li>
</ul>
<hr>
<h2 id="Formulating-Discrete-Probability-Flow-Through-Optimal-Transport"><a href="#Formulating-Discrete-Probability-Flow-Through-Optimal-Transport" class="headerlink" title="Formulating Discrete Probability Flow Through Optimal Transport"></a>Formulating Discrete Probability Flow Through Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03886">http://arxiv.org/abs/2311.03886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pangzecheung/discrete-probability-flow">https://github.com/pangzecheung/discrete-probability-flow</a></li>
<li>paper_authors: Pengze Zhang, Hubery Yin, Chen Li, Xiaohua Xie</li>
<li>for: 这个论文的目的是建立抽象概率流的基本理论，以便更好地理解数字扩散模型中的概率流。</li>
<li>methods: 作者首先证明了连续概率流是在某些条件下的蒙地奥提伦运输图，并提供了对应的数字情况的证明。然后，作者根据这些发现定义了数字概率流，并在这个定义下提出了一种新的采样方法。</li>
<li>results: 作者通过对synthetic toy dataset和CIFAR-10 dataset的广泛实验证明了他们提出的数字概率流的有效性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/PangzeCheung/Discrete-Probability-Flow%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/PangzeCheung/Discrete-Probability-Flow中下载。</a><details>
<summary>Abstract</summary>
Continuous diffusion models are commonly acknowledged to display a deterministic probability flow, whereas discrete diffusion models do not. In this paper, we aim to establish the fundamental theory for the probability flow of discrete diffusion models. Specifically, we first prove that the continuous probability flow is the Monge optimal transport map under certain conditions, and also present an equivalent evidence for discrete cases. In view of these findings, we are then able to define the discrete probability flow in line with the principles of optimal transport. Finally, drawing upon our newly established definitions, we propose a novel sampling method that surpasses previous discrete diffusion models in its ability to generate more certain outcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10 dataset have validated the effectiveness of our proposed discrete probability flow. Code is released at: https://github.com/PangzeCheung/Discrete-Probability-Flow.
</details>
<details>
<summary>摘要</summary>
CONTINUOUS DIFFUSION MODELS 通常被承认为 Display deterministic probability flow，而 DISCRETE DIFFUSION MODELS 则不然。在这篇论文中，我们想要建立 DISCRETE DIFFUSION MODELS 的可定义流的基本理论。specifically，我们首先证明了 continuous probability flow 是 Monge 优质量运输图 under certain conditions，并 auch present 了等价的证明 для discrete cases。 Based on these findings，我们可以定义 DISCRETE PROBABILITY FLOW 以符合优质量运输的原则。最后，我们根据我们 newly established definitions 提出了一种新的采样方法，可以更加准确地生成 outcome。我们在 synthetic toy dataset 和 CIFAR-10 dataset 进行了广泛的实验，并证明了我们的提议的 DISCRETE PROBABILITY FLOW 的效果。Code 在：https://github.com/PangzeCheung/Discrete-Probability-Flow。
</details></li>
</ul>
<hr>
<h2 id="Mini-but-Mighty-Finetuning-ViTs-with-Mini-Adapters"><a href="#Mini-but-Mighty-Finetuning-ViTs-with-Mini-Adapters" class="headerlink" title="Mini but Mighty: Finetuning ViTs with Mini Adapters"></a>Mini but Mighty: Finetuning ViTs with Mini Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03873">http://arxiv.org/abs/2311.03873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iemprog/mimi">https://github.com/iemprog/mimi</a></li>
<li>paper_authors: Imad Eddine Marouf, Enzo Tartaglione, Stéphane Lathuilière</li>
<li>for: 这个研究旨在提高对新任务的适应性，并且降低训练和储存成本。</li>
<li>methods: 我们提出了一个名为MiMi的训练框架，它可以对小型扩展器进行自动调整，以提高其性能。</li>
<li>results: 我们的方法在三个dataset benchmarcks（DomainNet、VTAB和Multi-task）上，对29个dataset进行了最佳的搜寻，并且超过了现有方法的性能。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have become one of the dominant architectures in computer vision, and pre-trained ViT models are commonly adapted to new tasks via fine-tuning. Recent works proposed several parameter-efficient transfer learning methods, such as adapters, to avoid the prohibitive training and storage cost of finetuning. In this work, we observe that adapters perform poorly when the dimension of adapters is small, and we propose MiMi, a training framework that addresses this issue. We start with large adapters which can reach high performance, and iteratively reduce their size. To enable automatic estimation of the hidden dimension of every adapter, we also introduce a new scoring function, specifically designed for adapters, that compares the neuron importance across layers. Our method outperforms existing methods in finding the best trade-off between accuracy and trained parameters across the three dataset benchmarks DomainNet, VTAB, and Multi-task, for a total of 29 datasets.
</details>
<details>
<summary>摘要</summary>
计算机视觉领域中，视 transformer（ViT）架构已成为当前主导性的建筑，而预训练 ViT 模型通常通过精度调整来适应新任务。latest works proposed several parameter-efficient transfer learning methods, such as adapters, to avoid the prohibitive training and storage cost of fine-tuning.在这个工作中，我们发现小个数的适应器（adapters）表现不佳，我们提出了 MiMi，一种培训框架，解决这个问题。我们从大的适应器开始，然后逐渐减小它们的大小。为了自动估计每个适应器的隐藏维度，我们也引入了一个新的评分函数，专门为适应器设计，用于比较层次中每个神经元的重要性。我们的方法在三个数据集标准 benchmarck（DomainNet、VTAB 和 Multi-task）上，对共计29个数据集进行了比较，并超过了现有方法。
</details></li>
</ul>
<hr>
<h2 id="FD-MIA-Efficient-Attacks-on-Fairness-enhanced-Models"><a href="#FD-MIA-Efficient-Attacks-on-Fairness-enhanced-Models" class="headerlink" title="FD-MIA: Efficient Attacks on Fairness-enhanced Models"></a>FD-MIA: Efficient Attacks on Fairness-enhanced Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03865">http://arxiv.org/abs/2311.03865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huan Tian, Guangsheng Zhang, Bo Liu, Tianqing Zhu, Ming Ding, Wanlei Zhou</li>
<li>for: 本研究旨在攻击使用加入了公平约束的模型，以便通过分析模型预测分数来推断数据样本是否在训练过程中使用。</li>
<li>methods: 本研究使用了一种基于公平差异结果的有效MIA方法，即FD-MIA。它利用了两个模型（原始模型和公平模型）对数据样本的预测结果的差异，并利用这些预测差异作为攻击征。</li>
<li>results: 实验结果表明，FD-MIA方法可以高效地攻击使用加入了公平约束的模型，并且可以避免由于加入公平约束而导致的隐私泄露问题。<details>
<summary>Abstract</summary>
Previous studies have developed fairness methods for biased models that exhibit discriminatory behaviors towards specific subgroups. While these models have shown promise in achieving fair predictions, recent research has identified their potential vulnerability to score-based membership inference attacks (MIAs). In these attacks, adversaries can infer whether a particular data sample was used during training by analyzing the model's prediction scores. However, our investigations reveal that these score-based MIAs are ineffective when targeting fairness-enhanced models in binary classifications. The attack models trained to launch the MIAs degrade into simplistic threshold models, resulting in lower attack performance. Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon these insights, we propose an efficient MIA method against fairness-enhanced models based on fairness discrepancy results (FD-MIA). It leverages the difference in the predictions from both the original and fairness-enhanced models and exploits the observed prediction gaps as attack clues. We also explore potential strategies for mitigating privacy leakages. Extensive experiments validate our findings and demonstrate the efficacy of the proposed method.
</details>
<details>
<summary>摘要</summary>
Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon these insights, we propose an efficient MIA method against fairness-enhanced models based on fairness discrepancy results (FD-MIA). It leverages the difference in the predictions from both the original and fairness-enhanced models and exploits the observed prediction gaps as attack clues.We also explore potential strategies for mitigating privacy leakages. Extensive experiments validate our findings and demonstrate the efficacy of the proposed method.
</details></li>
</ul>
<hr>
<h2 id="Aspects-of-human-memory-and-Large-Language-Models"><a href="#Aspects-of-human-memory-and-Large-Language-Models" class="headerlink" title="Aspects of human memory and Large Language Models"></a>Aspects of human memory and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03839">http://arxiv.org/abs/2311.03839</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rmldj/memory-llm-paper">https://github.com/rmldj/memory-llm-paper</a></li>
<li>paper_authors: Romuald A. Janik</li>
<li>for:  investigate the memory properties of LLMs and their relationship to human memory</li>
<li>methods:  use of large language models (LLMs) and their probabilistic model of language use</li>
<li>results:  surprising similarities between the memory properties of LLMs and human memory, suggesting that biological features of human memory influence the way we structure textual narratives<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are huge artificial neural networks which primarily serve to generate text, but also provide a very sophisticated probabilistic model of language use. Since generating a semantically consistent text requires a form of effective memory, we investigate the memory properties of LLMs and find surprising similarities with key characteristics of human memory. This result strongly suggests that the biological features of human memory leave an imprint on the way that we structure our textual narratives.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Reducing-Spatial-Fitting-Error-in-Distillation-of-Denoising-Diffusion-Models"><a href="#Reducing-Spatial-Fitting-Error-in-Distillation-of-Denoising-Diffusion-Models" class="headerlink" title="Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models"></a>Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03830">http://arxiv.org/abs/2311.03830</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sainzerjj/SFERD">https://github.com/Sainzerjj/SFERD</a></li>
<li>paper_authors: Shengzhe Zhou, Zejian Lee, Shengyuan Zhang, Lefan Hou, Changyuan Yang, Guang Yang, Lingyun Sun</li>
<li>for: 提高Diffusion模型的频繁样本生成质量</li>
<li>methods: 使用注意力导航和设计的semantic gradient预测器减少学生模型的适应错误</li>
<li>results: 在几个函数评估中生成高质量样本，FID值为5.31在CIFAR-10和9.39在ImageNet 64x64中，超过现有的扩散方法<details>
<summary>Abstract</summary>
Denoising Diffusion models have exhibited remarkable capabilities in image generation. However, generating high-quality samples requires a large number of iterations. Knowledge distillation for diffusion models is an effective method to address this limitation with a shortened sampling process but causes degraded generative quality. Based on our analysis with bias-variance decomposition and experimental observations, we attribute the degradation to the spatial fitting error occurring in the training of both the teacher and student model. Accordingly, we propose $\textbf{S}$patial $\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction $\textbf{D}$istillation model ($\textbf{SFERD}$). SFERD utilizes attention guidance from the teacher model and a designed semantic gradient predictor to reduce the student's fitting error. Empirically, our proposed model facilitates high-quality sample generation in a few function evaluations. We achieve an FID of 5.31 on CIFAR-10 and 9.39 on ImageNet 64$\times$64 with only one step, outperforming existing diffusion methods. Our study provides a new perspective on diffusion distillation by highlighting the intrinsic denoising ability of models.
</details>
<details>
<summary>摘要</summary>
Diffusion模型在图像生成方面表现出了惊人的能力，但是生成高质量样本需要大量的迭代过程。知识传授 dla diffusion模型是一种有效的方法，可以缩短样本生成过程，但会导致生成质量下降。根据我们的分析和实验观察，我们认为这种下降是由 diffusion模型在训练中的空间适应错误引起的。因此，我们提出了 $\textbf{S}$patial $\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction $\textbf{D}$istillation模型（$\textbf{SFERD}$）。SFERD使用教师模型的注意力引导和设计的semantic gradient预测器来减少学生模型的适应错误。我们的提议模型在几个功能评估中能够生成高质量样本，我们在CIFAR-10和ImageNet 64x64上达到了5.31和9.39的FID值，只需要一步，超越了现有的扩散方法。我们的研究提供了一新的视角，强调扩散模型的内在杂音能力。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-and-Improving-Multi-task-Learning-for-End-to-end-Speech-Translation"><a href="#Rethinking-and-Improving-Multi-task-Learning-for-End-to-end-Speech-Translation" class="headerlink" title="Rethinking and Improving Multi-task Learning for End-to-end Speech Translation"></a>Rethinking and Improving Multi-task Learning for End-to-end Speech Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03810">http://arxiv.org/abs/2311.03810</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaozhang521/imtl">https://github.com/xiaozhang521/imtl</a></li>
<li>paper_authors: Yuhao Zhang, Chen Xu, Bei Li, Hao Chen, Tong Xiao, Chunliang Zhang, Jingbo Zhu</li>
<li>for: 本研究旨在 investigate the consistency between different tasks in end-to-end speech translation (ST), and propose an improved multi-task learning (IMTL) approach to mitigate the difference in length and representation.</li>
<li>methods: 本研究使用 multi-task learning 方法，包括 textual encoder 和 speech encoder，以及一种 improved multi-task learning (IMTL) approach。</li>
<li>results: 研究结果显示，我们的方法可以实现 state-of-the-art 的结果，并且在额外训练数据 disponibles 时，可以实现新的 SOTA 结果。另外，我们的方法只需要 20.8% 的训练时间，比现有 SOTA 方法要少。<details>
<summary>Abstract</summary>
Significant improvements in end-to-end speech translation (ST) have been achieved through the application of multi-task learning. However, the extent to which auxiliary tasks are highly consistent with the ST task, and how much this approach truly helps, have not been thoroughly studied. In this paper, we investigate the consistency between different tasks, considering different times and modules. We find that the textual encoder primarily facilitates cross-modal conversion, but the presence of noise in speech impedes the consistency between text and speech representations. Furthermore, we propose an improved multi-task learning (IMTL) approach for the ST task, which bridges the modal gap by mitigating the difference in length and representation. We conduct experiments on the MuST-C dataset. The results demonstrate that our method attains state-of-the-art results. Moreover, when additional data is used, we achieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the training time required by the current SOTA method.
</details>
<details>
<summary>摘要</summary>
很大的改进在端到端语音翻译（ST）中实现了，通过多任务学习。然而，auxiliary任务和ST任务之间的一致性，以及这种方法对ST任务的真正帮助，尚未得到了充分的研究。在这篇论文中，我们研究了不同任务之间的一致性，考虑不同的时间和模块。我们发现，文本Encoder主要帮助cross-modal转换，但是在语音中存在噪音会降低语音和文本表示之间的一致性。此外，我们提出了一种改进的多任务学习（IMTL）方法，用于ST任务，可以bridge模态差距，减少语音和文本表示之间的差异。我们在MuST-C dataset上进行了实验。结果表明，我们的方法实现了状态的最佳结果。此外，当使用了额外数据时，我们在MuST-C英语到西班牙语任务上获得了新的SOTA结果，仅用20.8%的训练时间。
</details></li>
</ul>
<hr>
<h2 id="Scene-Driven-Multimodal-Knowledge-Graph-Construction-for-Embodied-AI"><a href="#Scene-Driven-Multimodal-Knowledge-Graph-Construction-for-Embodied-AI" class="headerlink" title="Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI"></a>Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03783">http://arxiv.org/abs/2311.03783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Yaoxian, Sun Penglei, Liu Haoyu, Li Zhixu, Song Wei, Xiao Yanghua, Zhou Xiaofang</li>
<li>for: 本研究旨在提高现实世界中的机器人智能，通过Scene-MMKG构建方法，增强机器人对Scene知识的理解，以提高机器人的决策能力和功能表现。</li>
<li>methods: 本研究提出了Scene-MMKG构建方法， combinig conventional knowledge engineering和大型自然语言模型，实现了Scene知识的可导入和可迁移。</li>
<li>results: 实验结果表明，使用我们的Instantiated ManipMob-MMKG可以明显提高embodied任务的性能，而无需复杂地重构模型结构。<details>
<summary>Abstract</summary>
Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority in data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly. Our project can be found at https://sites.google.com/view/manipmob-mmkg
</details>
<details>
<summary>摘要</summary>
现代人工智能和机器人学中最受欢迎的研究之一是体验AI，它可以有效提高实际世界中的智能机器人服务人类。场景知识是一个机器人理解环境和做出正确决策的关键。然而，目前存在场景知识库缺失，大多数现有工作使用通用知识库或预训练模型来提高机器人的智能水平。传统的知识库缺乏，容易受到数据收集成本的影响，而预训练模型受到知识不确定性和维护困难。为了缓解场景知识的挑战，我们提出了场景驱动多模态知识图（Scene-MMKG）建构方法，结合传统知识工程和大型自然语言模型。我们引入了一个统一的场景知识注入框架，以便场景知识表示。为评估我们提出的方法的优势，我们实例化Scene-MMKG，并考虑典型的室内 роботиче功能（操作和移动），称之为ManipMob-MMKG。对比分析表明，我们的实例化ManipMob-MMKG在数据采集效率和知识质量方面具有广泛的优势。实验结果表明，使用我们的实例化ManipMob-MMKG可以明显提高实际任务的性能，而不需要复杂地重新设计模型结构。更多信息可以在https://sites.google.com/view/manipmob-mmkg上找到。
</details></li>
</ul>
<hr>
<h2 id="Ensembling-Textual-and-Structure-Based-Models-for-Knowledge-Graph-Completion"><a href="#Ensembling-Textual-and-Structure-Based-Models-for-Knowledge-Graph-Completion" class="headerlink" title="Ensembling Textual and Structure-Based Models for Knowledge Graph Completion"></a>Ensembling Textual and Structure-Based Models for Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03780">http://arxiv.org/abs/2311.03780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ananjan Nandi, Navdeep Kaur, Parag Singla, Mausam</li>
<li>for: 本研究旨在提高知识图完成任务的性能，通过结合文本模型和结构基本模型。</li>
<li>methods: 本研究使用了结构基本模型和文本模型，并提出了一种新的查询依赖ensemble权重学习方法。</li>
<li>results: 本研究的基准 ensemble方法在三个标准知识图完成 datasets 上 achieved state-of-the-art result, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models。<details>
<summary>Abstract</summary>
We consider two popular approaches to Knowledge Graph Completion (KGC): textual models that rely on textual entity descriptions, and structure-based models that exploit the connectivity structure of the Knowledge Graph (KG). Preliminary experiments show that these approaches have complementary strengths: structure-based models perform well when the gold answer is easily reachable from the query head in the KG, while textual models exploit descriptions to give good performance even when the gold answer is not reachable. In response, we explore ensembling as a way of combining the best of both approaches. We propose a novel method for learning query-dependent ensemble weights by using the distributions of scores assigned by individual models to all candidate entities. Our ensemble baseline achieves state-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models.
</details>
<details>
<summary>摘要</summary>
我们考虑了两种受欢迎的知识 graphs 完成（KGC）方法：文本模型，它们依靠知识 graphs 中实体的文本描述，以及结构基于模型，它们利用知识 graphs 的连接结构来完成。我们的初步实验显示这两种方法有辅相互补偿的优点：结构基于模型在知识 graphs 中找到答案的路径较短，而文本模型则可以透过描述来实现更好的性能，即使答案不在知识 graphs 中可达。因此，我们探讨 ensemble 的方法，以 combin 两种方法的最佳特点。我们提出了一种学习查询相依 ensemble 权重的新方法，使用各个模型对所有候选实体的分布 scores 来学习查询相依 ensemble 权重。我们的ensemble基准得到了三个标准 KGC 资料集的state-of-the-art 结果，与最佳个体模型相对提高了6.8pt MRR和8.3pt Hits@1。
</details></li>
</ul>
<hr>
<h2 id="PT-Tuning-Bridging-the-Gap-between-Time-Series-Masked-Reconstruction-and-Forecasting-via-Prompt-Token-Tuning"><a href="#PT-Tuning-Bridging-the-Gap-between-Time-Series-Masked-Reconstruction-and-Forecasting-via-Prompt-Token-Tuning" class="headerlink" title="PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction and Forecasting via Prompt Token Tuning"></a>PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction and Forecasting via Prompt Token Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03768">http://arxiv.org/abs/2311.03768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Liu, Jinrui Gan, Xiaoxuan Fan, Yi Zhang, Chuanxian Luo, Jing Zhang, Guangxin Jiang, Yucheng Qian, Changwei Zhao, Huan Ma, Zhenyu Guo</li>
<li>for:  bridging the gap between time series masked reconstruction and forecasting</li>
<li>methods:  reserved pre-trained mask token during fine-tuning stage, and proposed prompt token tuning (PT-Tuning) paradigm</li>
<li>results:  state-of-the-art performance compared to representation learning and end-to-end supervised forecasting methods<details>
<summary>Abstract</summary>
Self-supervised learning has been actively studied in time series domain recently, especially for masked reconstruction. Most of these methods follow the "Pre-training + Fine-tuning" paradigm in which a new decoder replaces the pre-trained decoder to fit for a specific downstream task, leading to inconsistency of upstream and downstream tasks. In this paper, we first point out that the unification of task objectives and adaptation for task difficulty are critical for bridging the gap between time series masked reconstruction and forecasting. By reserving the pre-trained mask token during fine-tuning stage, the forecasting task can be taken as a special case of masked reconstruction, where the future values are masked and reconstructed based on history values. It guarantees the consistency of task objectives but there is still a gap in task difficulty. Because masked reconstruction can utilize contextual information while forecasting can only use historical information to reconstruct. To further mitigate the existed gap, we propose a simple yet effective prompt token tuning (PT-Tuning) paradigm, in which all pre-trained parameters are frozen and only a few trainable prompt tokens are added to extended mask tokens in element-wise manner. Extensive experiments on real-world datasets demonstrate the superiority of our proposed paradigm with state-of-the-art performance compared to representation learning and end-to-end supervised forecasting methods.
</details>
<details>
<summary>摘要</summary>
自适应学习在时间序列领域已经广泛研究，特别是对于偏挥恢复。大多数这些方法采用“预训练+精度调整”模式，在这种模式下，一个新的解码器取代预训练的解码器，以适应特定下游任务，导致上游和下游任务的不一致。在这篇论文中，我们首先指出了对时间序列偏挥恢复和预测的统一任务目标和适应任务难度是关键的。通过保留预训练的偏挥token during fine-tuning阶段，我们可以将预测任务视为时间序列偏挥恢复的特殊情况，将未来值视为偏挥的，并根据历史值进行重建。这保证了任务目标的一致性，但是还存在一定的任务难度差异。因为偏挥恢复可以使用 contextual information，而预测只能使用历史信息来重建。为了进一步减少这个差异，我们提议了一种简单 yet effective的 prompt token tuning（PT-Tuning）方法。在这种方法中，所有的预训练参数被冻结，只有一些可变的提示符被添加到元素级别上，以扩展偏挥token。我们在实际的世界数据集上进行了广泛的实验，并证明了我们的提议方法可以与现有的表示学习和端到端超参数学习方法匹配或超越。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Radio-Signals-with-Wavelet-Transform-for-Deep-Learning-Based-Modulation-Recognition"><a href="#Augmenting-Radio-Signals-with-Wavelet-Transform-for-Deep-Learning-Based-Modulation-Recognition" class="headerlink" title="Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based Modulation Recognition"></a>Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based Modulation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03761">http://arxiv.org/abs/2311.03761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Chen, Shilian Zheng, Kunfeng Qiu, Luxin Zhang, Qi Xuan, Xiaoniu Yang</li>
<li>for: 这篇论文是为了提出一种基于深度学习的无线电变换识别方法，并且使用数据增强法增加训练数据的多样性和量。</li>
<li>methods: 这篇论文使用的方法包括使用数字波лет变换对细节系数进行分解，并将其恢复为新的数据amples，以增加训练数据的多样性和量。不同的生成方法是用来生成更多的替补序列。</li>
<li>results:  simulation 结果显示，这篇论文所提出的方法与其他增强方法相比，能够获得更高的识别精度和准确率。<details>
<summary>Abstract</summary>
The use of deep learning for radio modulation recognition has become prevalent in recent years. This approach automatically extracts high-dimensional features from large datasets, facilitating the accurate classification of modulation schemes. However, in real-world scenarios, it may not be feasible to gather sufficient training data in advance. Data augmentation is a method used to increase the diversity and quantity of training dataset and to reduce data sparsity and imbalance. In this paper, we propose data augmentation methods that involve replacing detail coefficients decomposed by discrete wavelet transform for reconstructing to generate new samples and expand the training set. Different generation methods are used to generate replacement sequences. Simulation results indicate that our proposed methods significantly outperform the other augmentation methods.
</details>
<details>
<summary>摘要</summary>
使用深度学习进行广播模式识别已在最近几年内变得普遍。这种方法自动提取大量数据集中的特征，使得广播模式的准确识别变得可能。然而，在实际应用中，可能无法在 advance 收集充足的训练数据。数据扩展是一种方法，用于增加训练集的多样性和量，并降低数据稀缺和偏度。在这篇论文中，我们提议了一种数据扩展方法，该方法包括将离散波лет变换 decomposed 的细节系数替换为重建新样本，以扩大训练集。不同的生成方法用于生成替换序列。实验结果表明，我们的提议方法在其他扩展方法的基础上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Learning-Decentralized-Traffic-Signal-Controllers-with-Multi-Agent-Graph-Reinforcement-Learning"><a href="#Learning-Decentralized-Traffic-Signal-Controllers-with-Multi-Agent-Graph-Reinforcement-Learning" class="headerlink" title="Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph Reinforcement Learning"></a>Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03756">http://arxiv.org/abs/2311.03756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Zhang, Zhiwen Yu, Jun Zhang, Liang Wang, Tom H. Luan, Bin Guo, Chau Yuen</li>
<li>For: 这个论文关注智能城市中的优化交通信号控制问题，它被视为一个复杂的网络系统控制问题。在交通灯和道路网络之间的互动动力学中，实现控制器适应性和扩展性是一个主要挑战。* Methods: 我们采用Multi-Agent Reinforcement Learning（MARL）框架，但现有的MARL算法忽略了有效信息聚合，这是改善各自代理的学习能力的关键。在这篇论文中，我们设计了一种新的分布式控制架构，其中包括改进的环境观察性，以捕捉交通灯之间的空间-时间相关性。* Results: 我们在synthetic和实际数据集上进行了广泛的实验，并证明了我们的提议在已有的分布式算法中表现出优于性。<details>
<summary>Abstract</summary>
This paper considers optimal traffic signal control in smart cities, which has been taken as a complex networked system control problem. Given the interacting dynamics among traffic lights and road networks, attaining controller adaptivity and scalability stands out as a primary challenge. Capturing the spatial-temporal correlation among traffic lights under the framework of Multi-Agent Reinforcement Learning (MARL) is a promising solution. Nevertheless, existing MARL algorithms ignore effective information aggregation which is fundamental for improving the learning capacity of decentralized agents. In this paper, we design a new decentralized control architecture with improved environmental observability to capture the spatial-temporal correlation. Specifically, we first develop a topology-aware information aggregation strategy to extract correlation-related information from unstructured data gathered in the road network. Particularly, we transfer the road network topology into a graph shift operator by forming a diffusion process on the topology, which subsequently facilitates the construction of graph signals. A diffusion convolution module is developed, forming a new MARL algorithm, which endows agents with the capabilities of graph learning. Extensive experiments based on both synthetic and real-world datasets verify that our proposal outperforms existing decentralized algorithms.
</details>
<details>
<summary>摘要</summary>
To address this limitation, we propose a new decentralized control architecture with enhanced environmental observability. Our approach includes a topology-aware information aggregation strategy to extract correlation-related information from unstructured data gathered in the road network. We transform the road network topology into a graph shift operator by creating a diffusion process on the topology, which facilitates the construction of graph signals. We then develop a diffusion convolution module, which endows agents with the ability of graph learning.Extensive experiments based on both synthetic and real-world datasets demonstrate that our proposed method outperforms existing decentralized algorithms. Our approach enables more effective and efficient traffic signal control, leading to improved traffic flow and reduced congestion in smart cities.
</details></li>
</ul>
<hr>
<h2 id="COOL-A-Constraint-Object-Oriented-Logic-Programming-Language-and-its-Neural-Symbolic-Compilation-System"><a href="#COOL-A-Constraint-Object-Oriented-Logic-Programming-Language-and-its-Neural-Symbolic-Compilation-System" class="headerlink" title="COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System"></a>COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03753">http://arxiv.org/abs/2311.03753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jipeng Han</li>
<li>for: 本研究旨在整合神经网络与逻辑编程，解决长期存在的神经网络总结和学习能力与逻辑逻辑的结合问题。</li>
<li>methods: 我们提出了COOL（约束对象 oriented逻辑）编程语言，一种创新的方法，可以自动处理数据收集，减少用户提供初始数据的需求。</li>
<li>results: COOL语言可以减少神经网络训练时的风险，提高神经网络的重用和扩展，并且其基本原则和算法可以为未来编程语言和神经网络架构的发展提供有价值的思路。<details>
<summary>Abstract</summary>
This paper explores the integration of neural networks with logic programming, addressing the longstanding challenges of combining the generalization and learning capabilities of neural networks with the precision of symbolic logic. Traditional attempts at this integration have been hampered by difficulties in initial data acquisition, the reliability of undertrained networks, and the complexity of reusing and augmenting trained models. To overcome these issues, we introduce the COOL (Constraint Object-Oriented Logic) programming language, an innovative approach that seamlessly combines logical reasoning with neural network technologies. COOL is engineered to autonomously handle data collection, mitigating the need for user-supplied initial data. It incorporates user prompts into the coding process to reduce the risks of undertraining and enhances the interaction among models throughout their lifecycle to promote the reuse and augmentation of networks. Furthermore, the foundational principles and algorithms in COOL's design and its compilation system could provide valuable insights for future developments in programming languages and neural network architectures.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文探讨了神经网络与逻辑编程的集成，解决了长期存在的神经网络的通用和学习能力与逻辑逻辑的精度问题。传统的集成尝试受到数据收集初始化问题、神经网络训练不可靠和已训练模型重用和增强问题的限制。为解决这些问题，我们介绍了COOL（约束对象逻辑）编程语言，这是一种创新的方法，可以自然地将逻辑推理与神经网络技术结合在一起。COOL可以自动处理数据收集，从而减少用户提供初始数据的需求。它还 incorporates用户提示到编程过程中，以降低训练不足的风险，并在模型生命周期中提高模型之间的交互，以促进模型的重用和增强。此外，COOL的设计原则和编译系统的算法可以为未来编程语言和神经网络架构的发展提供有价值的思想和技术指导。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-for-Automated-Proof-Synthesis-in-Rust"><a href="#Leveraging-Large-Language-Models-for-Automated-Proof-Synthesis-in-Rust" class="headerlink" title="Leveraging Large Language Models for Automated Proof Synthesis in Rust"></a>Leveraging Large Language Models for Automated Proof Synthesis in Rust</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03739">http://arxiv.org/abs/2311.03739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianan Yao, Ziqiao Zhou, Weiteng Chen, Weidong Cui</li>
<li>for: 这 paper 的目的是提出一种基于 Large Language Models (LLMs) 和静态分析的形式验证框架，以便提高形式验证的可靠性和效率。</li>
<li>methods: 这 paper 使用了 LLMs 和静态分析来生成 invariants、assertions 和其他证明结构，并通过多个小任务和 OpenAI 的 GPT-4 模型来减少人工劳动。</li>
<li>results: 对于 20 个向量操作程序，这个 прототип 能够显著减少人工劳动，并且可以帮助开发者快速编写入门级证明代码。<details>
<summary>Abstract</summary>
Formal verification can provably guarantee the correctness of critical system software, but the high proof burden has long hindered its wide adoption. Recently, Large Language Models (LLMs) have shown success in code analysis and synthesis. In this paper, we present a combination of LLMs and static analysis to synthesize invariants, assertions, and other proof structures for a Rust-based formal verification framework called Verus. In a few-shot setting, LLMs demonstrate impressive logical ability in generating postconditions and loop invariants, especially when analyzing short code snippets. However, LLMs lack the ability to retain and propagate context information, a strength of traditional static analysis. Based on these observations, we developed a prototype based on OpenAI's GPT-4 model. Our prototype decomposes the verification task into multiple smaller ones, iteratively queries GPT-4, and combines its output with lightweight static analysis. We evaluated the prototype with a developer in the automation loop on 20 vector-manipulating programs. The results demonstrate that it significantly reduces human effort in writing entry-level proof code.
</details>
<details>
<summary>摘要</summary>
正式验证可以有可证明性地保证重要的系统软件正确性，但高证明负担长期间妨碍了它的广泛采用。现在，大型自然语言模型（LLM）在代码分析和生成方面表现出色。在这篇论文中，我们提出了结合LLM和静态分析的方法，用于生成 invariants、断言和其他证据结构，以适应基于Rust的正式验证框架Verus。在几个步骤的设定下，LLM示出了在分析短代码剖面时的卓越逻辑能力，特别是生成后置条件和循环 invariants。然而，LLM缺乏保持和传播上下文信息的能力，是传统静态分析的优点。基于这些观察，我们开发了一个基于OpenAI的GPT-4模型的原型。我们的原型将验证任务分解为多个更小的任务，逐步查询GPT-4，并将其输出与轻量级静态分析结合。我们对20个向量操作程序进行了测试，结果表明，它可以减少人类的证明代码写作努力。
</details></li>
</ul>
<hr>
<h2 id="deep-REMAP-Parameterization-of-Stellar-Spectra-Using-Regularized-Multi-Task-Learning"><a href="#deep-REMAP-Parameterization-of-Stellar-Spectra-Using-Regularized-Multi-Task-Learning" class="headerlink" title="deep-REMAP: Parameterization of Stellar Spectra Using Regularized Multi-Task Learning"></a>deep-REMAP: Parameterization of Stellar Spectra Using Regularized Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03738">http://arxiv.org/abs/2311.03738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sankalp Gilda</li>
<li>for: 用于精准地测量恒星大气 Parameters (有效温度、表面重力和金属含量) 从观测 спектrum 中.</li>
<li>methods: 使用深度学习技术，包括多任务学习和创新的不对称损失函数，将 Phoenix 库中的辐射 Synthetic spectra 和 MARVELS survey 的观测数据作为输入，并使用 deep-REMAP 框架进行预测.</li>
<li>results: $\rm{deep-REMAP}$ 可以准确地预测恒星大气 Parameters，并且可以扩展到其他恒星库和特性。<details>
<summary>Abstract</summary>
Traditional spectral analysis methods are increasingly challenged by the exploding volumes of data produced by contemporary astronomical surveys. In response, we develop deep-Regularized Ensemble-based Multi-task Learning with Asymmetric Loss for Probabilistic Inference ($\rm{deep-REMAP}$), a novel framework that utilizes the rich synthetic spectra from the PHOENIX library and observational data from the MARVELS survey to accurately predict stellar atmospheric parameters. By harnessing advanced machine learning techniques, including multi-task learning and an innovative asymmetric loss function, $\rm{deep-REMAP}$ demonstrates superior predictive capabilities in determining effective temperature, surface gravity, and metallicity from observed spectra. Our results reveal the framework's effectiveness in extending to other stellar libraries and properties, paving the way for more sophisticated and automated techniques in stellar characterization.
</details>
<details>
<summary>摘要</summary>
传统的spectral分析方法随着现代天文学观测数据的急剧增长，日益面临挑战。为应对这一问题，我们开发了深度REGULARIZED Ensemble-based Multi-task Learning with Asymmetric Loss for Probabilistic Inference（深度-REMAP），一种新的框架，利用 Phoebe 图书馆中的辐射谱 synthetic spectra 和 MARVELS 观测数据，准确预测星际大气参数。通过应用先进的机器学习技术，包括多任务学习和创新的非对称损失函数，深度-REMAP 表现出了在确定效果温度、表面重力和金属含量方面的超越性Predictive 能力。我们的结果表明，这种框架可以扩展到其他星际图书馆和性能，为stellar 特征化提供更加复杂和自动化的技术。
</details></li>
</ul>
<hr>
<h2 id="Neural-MMO-2-0-A-Massively-Multi-task-Addition-to-Massively-Multi-agent-Learning"><a href="#Neural-MMO-2-0-A-Massively-Multi-task-Addition-to-Massively-Multi-agent-Learning" class="headerlink" title="Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning"></a>Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03736">http://arxiv.org/abs/2311.03736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Suárez, Phillip Isola, Kyoung Whan Choe, David Bloomin, Hao Xiang Li, Nikhil Pinnaparaju, Nishaanth Kanna, Daniel Scott, Ryan Sullivan, Rose S. Shuman, Lucas de Alcântara, Herbie Bradley, Louis Castricato, Kirsty You, Yuhao Jiang, Qimai Li, Jiaxin Chen, Xiaolong Zhu</li>
<li>for: 本研究用于探索多智能体环境下的强化学习问题。</li>
<li>methods: 本文使用Neural MMO 2.0平台，该平台具有灵活的任务系统，可以定制各种目标和奖励信号。</li>
<li>results: 本文比较了Neural MMO 2.0与前一版本的性能，发现其性能提高了三倍，并且与CleanRL兼容。<details>
<summary>Abstract</summary>
Neural MMO 2.0 is a massively multi-agent environment for reinforcement learning research. The key feature of this new version is a flexible task system that allows users to define a broad range of objectives and reward signals. We challenge researchers to train agents capable of generalizing to tasks, maps, and opponents never seen during training. Neural MMO features procedurally generated maps with 128 agents in the standard setting and support for up to. Version 2.0 is a complete rewrite of its predecessor with three-fold improved performance and compatibility with CleanRL. We release the platform as free and open-source software with comprehensive documentation available at neuralmmo.github.io and an active community Discord. To spark initial research on this new platform, we are concurrently running a competition at NeurIPS 2023.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ClimateSet-A-Large-Scale-Climate-Model-Dataset-for-Machine-Learning"><a href="#ClimateSet-A-Large-Scale-Climate-Model-Dataset-for-Machine-Learning" class="headerlink" title="ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning"></a>ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03721">http://arxiv.org/abs/2311.03721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Kaltenborn, Charlotte E. E. Lange, Venkatesh Ramesh, Philippe Brouillard, Yaniv Gurwicz, Chandni Nagda, Jakob Runge, Peer Nowack, David Rolnick</li>
<li>for: 这项研究的目的是为气候科学家和机器学习专家提供一个大规模、一致的气候模型数据集，以支持气候变化的影响和未来气候enario的预测。</li>
<li>methods: 这项研究使用了Input4MIPs和CMIP6气候模型数据库中的36个气候模型的输入和输出，并提供了一个模块化的数据集管道，以便在不同的气候模型和enario下获取和处理数据。</li>
<li>results: 研究人员通过使用ClimateSet数据集作为ML模型投影的标准 benchmark，发现了不同的ML模型在不同的气候模型下的性能和泛化能力。此外，ClimateSet数据集还可以用于训练一个“超级 emulator”，以快速预测新的气候变化scenario，并补充现有的scenario，为政策制定者提供更多的选择。<details>
<summary>Abstract</summary>
Climate models have been key for assessing the impact of climate change and simulating future climate scenarios. The machine learning (ML) community has taken an increased interest in supporting climate scientists' efforts on various tasks such as climate model emulation, downscaling, and prediction tasks. Many of those tasks have been addressed on datasets created with single climate models. However, both the climate science and ML communities have suggested that to address those tasks at scale, we need large, consistent, and ML-ready climate model datasets. Here, we introduce ClimateSet, a dataset containing the inputs and outputs of 36 climate models from the Input4MIPs and CMIP6 archives. In addition, we provide a modular dataset pipeline for retrieving and preprocessing additional climate models and scenarios. We showcase the potential of our dataset by using it as a benchmark for ML-based climate model emulation. We gain new insights about the performance and generalization capabilities of the different ML models by analyzing their performance across different climate models. Furthermore, the dataset can be used to train an ML emulator on several climate models instead of just one. Such a "super emulator" can quickly project new climate change scenarios, complementing existing scenarios already provided to policymakers. We believe ClimateSet will create the basis needed for the ML community to tackle climate-related tasks at scale.
</details>
<details>
<summary>摘要</summary>
CLIMATE MODELS HAVE BEEN CRUCIAL FOR ASSESSING THE IMPACT OF CLIMATE CHANGE AND SIMULATING FUTURE CLIMATE SCENARIOS. THE MACHINE LEARNING (ML) COMMUNITY HAS TAKEN AN INCREASED INTEREST IN SUPPORTING CLIMATE SCIENTISTS' EFFORTS ON VARIOUS TASKS SUCH AS CLIMATE MODEL EMULATION, DOWNscaling, AND PREDICTION TASKS. MANY OF THOSE TASKS HAVE BEEN ADDRESSED ON DATASETS CREATED WITH SINGLE CLIMATE MODELS. HOWEVER, BOTH THE CLIMATE SCIENCE AND ML COMMUNITIES HAVE SUGGESTED THAT TO ADDRESS THOSE TASKS AT SCALE, WE NEED LARGE, CONSISTENT, AND ML-READY CLIMATE MODEL DATASETS. HERE, WE INTRODUCE CLIMATESET, A DATASET CONTAINING THE INPUTS AND OUTPUTS OF 36 CLIMATE MODELS FROM THE INPUT4MIPs AND CMIP6 ARCHIVES. IN ADDITION, WE PROVIDE A MODULAR DATASET PIPELINE FOR RETRIEVING AND PREPROCESSING ADDITIONAL CLIMATE MODELS AND SCENARIOS. WE SHOWCASE THE POTENTIAL OF OUR DATASET BY USING IT AS A BENCHMARK FOR ML-BASED CLIMATE MODEL EMULATION. WE GAIN NEW INSIGHTS ABOUT THE PERFORMANCE AND GENERALIZATION CAPABILITIES OF THE DIFFERENT ML MODELS BY ANALYZING THEIR PERFORMANCE ACROSS DIFFERENT CLIMATE MODELS. FURTHERMORE, THE DATASET CAN BE USED TO TRAIN AN ML EMULATOR ON SEVERAL CLIMATE MODELS INSTEAD OF JUST ONE. SUCH A "SUPER EMULATOR" CAN QUICKLY PROJECT NEW CLIMATE CHANGE SCENARIOS, COMPLEMENTING EXISTING SCENARIOS ALREADY PROVIDED TO POLICYMAKERS. WE BELIEVE CLIMATESET WILL CREATE THE BASIS NEEDED FOR THE ML COMMUNITY TO TACKLE CLIMATE-RELATED TASKS AT SCALE.
</details></li>
</ul>
<hr>
<h2 id="LLM-as-an-Art-Director-LaDi-Using-LLMs-to-improve-Text-to-Media-Generators"><a href="#LLM-as-an-Art-Director-LaDi-Using-LLMs-to-improve-Text-to-Media-Generators" class="headerlink" title="LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators"></a>LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03716">http://arxiv.org/abs/2311.03716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Allen Roush, Emil Zakirov, Artemiy Shirokov, Polina Lunina, Jack Gane, Alexander Duffy, Charlie Basil, Aber Whitcomb, Jim Benedetto, Chris DeWolfe</li>
<li>for: 这 paper 旨在描述如何使用 Large Language Models (LLMs) 作为艺术指导，提高图像和视频生成的质量。</li>
<li>methods: 这 paper 使用多种技术来增强图像和视频生成器的能力，包括受限的解码、智能提示、精度调整和检索。</li>
<li>results: 这 paper 的实验结果表明，LaDi 系统可以帮助创建更加艺术一致和主题相关的图像和视频。<details>
<summary>Abstract</summary>
Recent advancements in text-to-image generation have revolutionized numerous fields, including art and cinema, by automating the generation of high-quality, context-aware images and video. However, the utility of these technologies is often limited by the inadequacy of text prompts in guiding the generator to produce artistically coherent and subject-relevant images. In this paper, We describe the techniques that can be used to make Large Language Models (LLMs) act as Art Directors that enhance image and video generation. We describe our unified system for this called "LaDi". We explore how LaDi integrates multiple techniques for augmenting the capabilities of text-to-image generators (T2Is) and text-to-video generators (T2Vs), with a focus on constrained decoding, intelligent prompting, fine-tuning, and retrieval. LaDi and these techniques are being used today in apps and platforms developed by Plai Labs.
</details>
<details>
<summary>摘要</summary>
In this paper, we introduce the techniques used to make Large Language Models (LLMs) act as Art Directors, enhancing image and video generation. Our unified system, called "LaDi", combines multiple methods to improve the capabilities of text-to-image generators (T2Is) and text-to-video generators (T2Vs), including constrained decoding, intelligent prompting, fine-tuning, and retrieval.LaDi and these techniques are currently being used in apps and platforms developed by Plai Labs. By leveraging the power of LLMs, we can create more sophisticated and artistic images and videos, pushing the boundaries of what is possible in the field of text-to-image generation.
</details></li>
</ul>
<hr>
<h2 id="Loss-Balancing-for-Fair-Supervised-Learning"><a href="#Loss-Balancing-for-Fair-Supervised-Learning" class="headerlink" title="Loss Balancing for Fair Supervised Learning"></a>Loss Balancing for Fair Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03714">http://arxiv.org/abs/2311.03714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khalilimahdi/loss_balancing_icml2023">https://github.com/khalilimahdi/loss_balancing_icml2023</a></li>
<li>paper_authors: Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan</li>
<li>for: 本文旨在提出一种能够快速和精准地找到符合平等损失原则（Equalized Loss，EL）的最佳公平预测器。</li>
<li>methods: 本文提出了一种基于 convex programming 工具（如 CVXPY）的算法，可以快速地解决不等损失原则下的非 convex 优化问题。</li>
<li>results: 本文的算法可以准确地找到符合 EL 原则的最佳公平预测器，并且在几种实验中得到了证明。<details>
<summary>Abstract</summary>
Supervised learning models have been used in various domains such as lending, college admission, face recognition, natural language processing, etc. However, they may inherit pre-existing biases from training data and exhibit discrimination against protected social groups. Various fairness notions have been proposed to address unfairness issues. In this work, we focus on Equalized Loss (EL), a fairness notion that requires the expected loss to be (approximately) equalized across different groups. Imposing EL on the learning process leads to a non-convex optimization problem even if the loss function is convex, and the existing fair learning algorithms cannot properly be adopted to find the fair predictor under the EL constraint. This paper introduces an algorithm that can leverage off-the-shelf convex programming tools (e.g., CVXPY) to efficiently find the global optimum of this non-convex optimization. In particular, we propose the ELminimizer algorithm, which finds the optimal fair predictor under EL by reducing the non-convex optimization to a sequence of convex optimization problems. We theoretically prove that our algorithm finds the global optimal solution under certain conditions. Then, we support our theoretical results through several empirical studies.
</details>
<details>
<summary>摘要</summary>
超vised learning模型在不同领域中使用，如借款、大学招生、面部识别、自然语言处理等。然而，它们可能从训练数据中继承预先存在的偏见，并对保护社会群体中的人们产生歧视。各种公平性观念被提出来解决不公平问题。在这项工作中，我们关注Equalized Loss（EL），一种公平性观念，它要求不同群体的预期损失相对平等。在满足EL条件下，训练过程中的损失函数会变得不 convex。现有的公平学习算法无法正确地采用EL约束来找到公平预测器。本文介绍了一种可以利用现有的凸编程工具（如CVXPY）来高效地找到非凸优化问题的解。我们提出的ELminimizer算法可以在EL约束下找到最优公平预测器。我们理论上证明了我们的算法可以在某些条件下找到全球最优解。然后，我们通过一些实验研究来支持我们的理论结果。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Estimation-Errors-by-Twin-TD-Regularized-Actor-and-Critic-for-Deep-Reinforcement-Learning"><a href="#Mitigating-Estimation-Errors-by-Twin-TD-Regularized-Actor-and-Critic-for-Deep-Reinforcement-Learning" class="headerlink" title="Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning"></a>Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03711">http://arxiv.org/abs/2311.03711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junmin Zhong, Ruofan Wu, Jennie Si</li>
<li>for: 减少深度奖励学习（DRL）估计偏误</li>
<li>methods: 引入新的双TD-正则化演员评分（TDR）方法，以减少过估和under-估错误</li>
<li>results: TDR和distributional learning、LNSS方法结合使得新的演员评分学习方法在深度控制集成中表现出优于基eline，并将TD3和SAC等方法提升到与D4PG相当的水平，同时也提高了D4PG的表现。Translation:</li>
<li>for: Addressing the issue of estimation bias in deep reinforcement learning (DRL)</li>
<li>methods: Introducing a new, twin TD-regularized actor-critic (TDR) method to reduce both over and under-estimation errors</li>
<li>results: The TDR method, combined with distributional learning and LNSS, outperforms the baselines in challenging environments in the DeepMind Control Suite, elevating TD3 and SAC to a level comparable to D4PG, and improving D4PG’s performance to a new SOTA level in terms of mean reward, convergence speed, learning success rate, and learning variance.<details>
<summary>Abstract</summary>
We address the issue of estimation bias in deep reinforcement learning (DRL) by introducing solution mechanisms that include a new, twin TD-regularized actor-critic (TDR) method. It aims at reducing both over and under-estimation errors. With TDR and by combining good DRL improvements, such as distributional learning and long N-step surrogate stage reward (LNSS) method, we show that our new TDR-based actor-critic learning has enabled DRL methods to outperform their respective baselines in challenging environments in DeepMind Control Suite. Furthermore, they elevate TD3 and SAC respectively to a level of performance comparable to that of D4PG (the current SOTA), and they also improve the performance of D4PG to a new SOTA level measured by mean reward, convergence speed, learning success rate, and learning variance.
</details>
<details>
<summary>摘要</summary>
我们对深度强化学习（DRL）中的估计偏见进行了解决方案，包括一个新的双TD调整者-评估员（TDR）方法。这个方法目的是将过估和未估的错误减少。将TDR与其他好的DRL改进方法，如分布式学习和长N步代理阶段奖励（LNSS）方法，混合使用，我们发现了我们的新TDR基本actor-critic学习方法可以在深度控制套件中的具有挑战性环境中超越其基准。此外，它将TD3和SAC的表现提升到与D4PG（目前的SOTA）的水平，并且将D4PG的表现提升到新的SOTA水平， measured by mean reward, convergence speed, learning success rate, and learning variance。
</details></li>
</ul>
<hr>
<h2 id="The-NeurIPS-2022-Neural-MMO-Challenge-A-Massively-Multiagent-Competition-with-Specialization-and-Trade"><a href="#The-NeurIPS-2022-Neural-MMO-Challenge-A-Massively-Multiagent-Competition-with-Specialization-and-Trade" class="headerlink" title="The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade"></a>The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03707">http://arxiv.org/abs/2311.03707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enhong Liu, Joseph Suarez, Chenhui You, Bo Wu, Bingcheng Chen, Jun Hu, Jiaxin Chen, Xiaolong Zhu, Clare Zhu, Julian Togelius, Sharada Mohanty, Weijun Hong, Rui Du, Yibing Zhang, Qinwen Wang, Xinhang Li, Zheng Yuan, Xiang Li, Yuejia Huang, Kun Zhang, Hanhui Yang, Shiqi Tang, Phillip Isola</li>
<li>for: 这个论文描述了 NeurIPS-2022 神经网络多player挑战的结果，这个挑战吸引了500名参与者并收到了1,600份提交。</li>
<li>methods: 这个挑战使用了最新的 v1.6 神经网络多player环境，这个环境引入了新的设备、战斗、贸易和评价系统，这些元素共同提供了更多的鲁棒性和泛化挑战。</li>
<li>results: 这个论文描述了挑战的设计和结果，还explored了这个环境的可能性作为学习方法的标准 bencmark，并提供了一些实用的强化学习训练方法 для复杂任务。<details>
<summary>Abstract</summary>
In this paper, we present the results of the NeurIPS-2022 Neural MMO Challenge, which attracted 500 participants and received over 1,600 submissions. Like the previous IJCAI-2022 Neural MMO Challenge, it involved agents from 16 populations surviving in procedurally generated worlds by collecting resources and defeating opponents. This year's competition runs on the latest v1.6 Neural MMO, which introduces new equipment, combat, trading, and a better scoring system. These elements combine to pose additional robustness and generalization challenges not present in previous competitions. This paper summarizes the design and results of the challenge, explores the potential of this environment as a benchmark for learning methods, and presents some practical reinforcement learning training approaches for complex tasks with sparse rewards. Additionally, we have open-sourced our baselines, including environment wrappers, benchmarks, and visualization tools for future research.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了2022年的NeurIPS neural MMO挑战的结果，该挑战吸引了500名参与者并收到了1,600份提交。与前一年的IJCAI neural MMO挑战相同，这年的挑战中 agents从16个 популяции中生存在生成的世界中，收集资源和击败对手。这一年的比赛运行在最新的v1.6神经MMO上，新增了设备、战斗、贸易和评价系统。这些元素共同 pose 新的可靠性和泛化挑战，不存在在前一年的比赛中。本文总结了挑战的设计和结果，探讨了这种环境作为学习方法的标准 benchmark，并提出了一些实用的强化学习训练方法为复杂任务的稀衍奖励。此外，我们还开源了我们的基线，包括环境包装器、标准测试和可视化工具，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bottom-Up-Synthesis-for-Programs-with-Local-Variables"><a href="#Efficient-Bottom-Up-Synthesis-for-Programs-with-Local-Variables" class="headerlink" title="Efficient Bottom-Up Synthesis for Programs with Local Variables"></a>Efficient Bottom-Up Synthesis for Programs with Local Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03705">http://arxiv.org/abs/2311.03705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Li, Xiangyu Zhou, Rui Dong, Yihong Zhang, Xinyu Wang</li>
<li>for: 该论文旨在提出一种新的合成算法，能够效率地搜索具有本地变量（如lambda引入的程序）。</li>
<li>methods: 该算法使用提升 интерпрета器的想法，从一个程序一次性解释，提升到同时解释所有程序的语法树。这种方法可以系统地列出所有本地变量的绑定上下文，使得合成更快。</li>
<li>results: 该算法在网络自动化领域实现了成功，可以更高效地完成更多的复杂任务，比如WebRobot和Helena等现有技术。<details>
<summary>Abstract</summary>
We propose a new synthesis algorithm that can efficiently search programs with local variables (e.g., those introduced by lambdas). Prior bottom-up synthesis algorithms are not able to evaluate programs with free local variables, and therefore cannot effectively reduce the search space of such programs (e.g., using standard observational equivalence reduction techniques), making synthesis slow. Our algorithm can reduce the space of programs with local variables. The key idea, dubbed lifted interpretation, is to lift up the program interpretation process, from evaluating one program at a time to simultaneously evaluating all programs from a grammar. Lifted interpretation provides a mechanism to systematically enumerate all binding contexts for local variables, thereby enabling us to evaluate and reduce the space of programs with local variables. Our ideas are instantiated in the domain of web automation. The resulting tool, Arborist, can automate a significantly broader range of challenging tasks more efficiently than state-of-the-art techniques including WebRobot and Helena.
</details>
<details>
<summary>摘要</summary>
我们提出了一新的合成算法，可以效率地搜寻具有本地变数（例如 lambda 引入的）的程序。先前的底部合成算法无法评估具有自由本地变数的程序，因此无法有效缩小这些程序的搜寻空间（例如使用标准观察对等缩小技术），使合成变得慢。我们的算法可以缩小具有本地变数的程序的空间。我们的主要想法是将程序解释过程“升级”到同时评估所有程序的 grammar 中，这称为“提升解释”。提升解释提供了一个系统地列出所有本地变数的绑定上下文，因此可以实现评估和缩小具有本地变数的程序的空间。我们的想法在网页自动化领域中实现， Resulting tool Arborist 可以更高效地完成更多的具有挑战性的任务，比如 WebRobot 和 Helena 的技术。
</details></li>
</ul>
<hr>
<h2 id="Hypothesis-Network-Planned-Exploration-for-Rapid-Meta-Reinforcement-Learning-Adaptation"><a href="#Hypothesis-Network-Planned-Exploration-for-Rapid-Meta-Reinforcement-Learning-Adaptation" class="headerlink" title="Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation"></a>Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03701">http://arxiv.org/abs/2311.03701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxwell Joseph Jacobson, Yexiang Xue</li>
<li>for: 增强循环学习的适应能力，使agent能够适应快速变化的环境和任务。</li>
<li>methods:  integrate an active and planned exploration process via the hypothesis network to optimize adaptation speed, using a generative hypothesis network to form potential models of state transition dynamics, then eliminating incorrect models through strategically devised experiments.</li>
<li>results: 在一个符号化的Alchemy游戏中，HyPE方法比基线方法更快地适应和更准确地模型状态转移动力学， Validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settings.<details>
<summary>Abstract</summary>
Meta Reinforcement Learning (Meta RL) trains agents that adapt to fast-changing environments and tasks. Current strategies often lose adaption efficiency due to the passive nature of model exploration, causing delayed understanding of new transition dynamics. This results in particularly fast-evolving tasks being impossible to solve. We propose a novel approach, Hypothesis Network Planned Exploration (HyPE), that integrates an active and planned exploration process via the hypothesis network to optimize adaptation speed. HyPE uses a generative hypothesis network to form potential models of state transition dynamics, then eliminates incorrect models through strategically devised experiments. Evaluated on a symbolic version of the Alchemy game, HyPE outpaces baseline methods in adaptation speed and model accuracy, validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settings.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNMeta Reinforcement Learning (Meta RL) 训练代理人 adapt to 快速变化环境和任务。当前策略常常因模型探索的 pasive 性而导致适应率下降，从而导致特别快速演化的任务无法解决。我们提出了一种新的方法，假设网络规划探索 (HyPE)，它通过假设网络来整合活跃和规划探索过程，以优化适应速度。HyPE 使用生成假设网络来构建状态转移动力学模型，然后通过策划的实验排除错误模型。在使用 symbolic 版本的 Alchemy 游戏进行评估中，HyPE 在适应速度和模型准确率方面胜过基准方法，证明其在快速演化的设置中增强了学习适应能力。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Variational-Lower-Bound-for-Inverse-Reinforcement-Learning"><a href="#A-Novel-Variational-Lower-Bound-for-Inverse-Reinforcement-Learning" class="headerlink" title="A Novel Variational Lower Bound for Inverse Reinforcement Learning"></a>A Novel Variational Lower Bound for Inverse Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03698">http://arxiv.org/abs/2311.03698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikang Gui, Prashant Doshi</li>
<li>for: 学习任务和协同努力的 reward 函数，从专家轨迹中学习，以实现无需人工奖励工程。</li>
<li>methods: 基于 probabilistic graphical model 和优化节点的 Variational Lower Bound for IRL (VLB-IRL)，同时学习奖励函数和Policy。</li>
<li>results: 在多个知名领域中，比如游戏和 робоット学习等，超过了现有的状态 искус�imum IRL 算法，并且通过 demonstrating better reward from the learned policy 来证明了学习的有效性。<details>
<summary>Abstract</summary>
Inverse reinforcement learning (IRL) seeks to learn the reward function from expert trajectories, to understand the task for imitation or collaboration thereby removing the need for manual reward engineering. However, IRL in the context of large, high-dimensional problems with unknown dynamics has been particularly challenging. In this paper, we present a new Variational Lower Bound for IRL (VLB-IRL), which is derived under the framework of a probabilistic graphical model with an optimality node. Our method simultaneously learns the reward function and policy under the learned reward function by maximizing the lower bound, which is equivalent to minimizing the reverse Kullback-Leibler divergence between an approximated distribution of optimality given the reward function and the true distribution of optimality given trajectories. This leads to a new IRL method that learns a valid reward function such that the policy under the learned reward achieves expert-level performance on several known domains. Importantly, the method outperforms the existing state-of-the-art IRL algorithms on these domains by demonstrating better reward from the learned policy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> invert reinforcement learning (IRL) 目的是从专家轨迹中学习奖励函数，以便理解任务并模仿或协作，从而消除手动奖励工程化的需求。然而，在大型、高维度问题中， unknown dynamics 下的 IRL 特别困难。在这篇论文中，我们提出了一种新的 Variational Lower Bound for IRL (VLB-IRL)，它是基于 probabilistic graphical model 中的 optimality node 框架 derivation。我们的方法同时学习奖励函数和策略，以便在学习到奖励函数后，Policy 可以达到专家水平的表现。我们的方法通过最大化下界来实现这一目标，下界等于将 approximated distribution of optimality 与 true distribution of optimality 的 Kullback-Leibler divergence inverse。这导致了一种新的 IRL 方法，该方法可以学习一个有效的奖励函数，使得 Policy 根据学习到的奖励函数达到专家水平的表现。更重要的是，我们的方法在已知领域上超过了现有的 state-of-the-art IRL 算法的表现， demonstrating better reward from the learned policy。>>>
</details></li>
</ul>
<hr>
<h2 id="Context-Shift-Reduction-for-Offline-Meta-Reinforcement-Learning"><a href="#Context-Shift-Reduction-for-Offline-Meta-Reinforcement-Learning" class="headerlink" title="Context Shift Reduction for Offline Meta-Reinforcement Learning"></a>Context Shift Reduction for Offline Meta-Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03695">http://arxiv.org/abs/2311.03695</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/moreanp/csro">https://github.com/moreanp/csro</a></li>
<li>paper_authors: Yunkai Gao, Rui Zhang, Jiaming Guo, Fan Wu, Qi Yi, Shaohui Peng, Siming Lan, Ruizhi Chen, Zidong Du, Xing Hu, Qi Guo, Ling Li, Yunji Chen</li>
<li>for: 提高 meta-学习 agents 的通用能力。</li>
<li>methods: 使用 max-min 矩阵嵌入学习机制和非假先导收集策略来减少政策的影响。</li>
<li>results: 在多个复杂的领域中，CSRO 能够显著减少上下文偏移并提高通用能力，超过先前的方法。<details>
<summary>Abstract</summary>
Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline datasets to enhance the agent's generalization ability on unseen tasks. However, the context shift problem arises due to the distribution discrepancy between the contexts used for training (from the behavior policy) and testing (from the exploration policy). The context shift problem leads to incorrect task inference and further deteriorates the generalization ability of the meta-policy. Existing OMRL methods either overlook this problem or attempt to mitigate it with additional information. In this paper, we propose a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem with only offline datasets. The key insight of CSRO is to minimize the influence of policy in context during both the meta-training and meta-test phases. During meta-training, we design a max-min mutual information representation learning mechanism to diminish the impact of the behavior policy on task representation. In the meta-test phase, we introduce the non-prior context collection strategy to reduce the effect of the exploration policy. Experimental results demonstrate that CSRO significantly reduces the context shift and improves the generalization ability, surpassing previous methods across various challenging domains.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline datasets to enhance the agent's generalization ability on unseen tasks. However, the context shift problem arises due to the distribution discrepancy between the contexts used for training (from the behavior policy) and testing (from the exploration policy). The context shift problem leads to incorrect task inference and further deteriorates the generalization ability of the meta-policy. Existing OMRL methods either overlook this problem or attempt to mitigate it with additional information. In this paper, we propose a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem with only offline datasets. The key insight of CSRO is to minimize the influence of policy in context during both the meta-training and meta-test phases. During meta-training, we design a max-min mutual information representation learning mechanism to diminish the impact of the behavior policy on task representation. In the meta-test phase, we introduce the non-prior context collection strategy to reduce the effect of the exploration policy. Experimental results demonstrate that CSRO significantly reduces the context shift and improves the generalization ability, surpassing previous methods across various challenging domains."into Simplified Chinese:Offline meta-学习（OMRL）利用预收集的下载数据来提高智能体的未经见任务总结能力。然而，上下文差异问题出现，由于训练上下文（从行为策略）和测试上下文（从探索策略）的数据分布不一致。这会导致任务推断错误，并进一步下降meta策略的总结能力。现有OMRL方法可能忽略这个问题，或者尝试通过额外信息来缓解。在这篇论文中，我们提出了一种新的方法called Context Shift Reduction for OMRL（CSRO），用于解决上下文差异问题，只使用下载数据。CSRO的关键思想是在meta训练和meta测试阶段都尽量减少策略对上下文的影响。在meta训练阶段，我们设计了max-min共享信息学习机制，以减少行为策略对任务表示的影响。在meta测试阶段，我们引入了非先验上下文收集策略，以减少探索策略对上下文的影响。实验结果表明，CSRO可以减少上下文差异，提高总结能力，超越了前一些难度更高的领域。
</details></li>
</ul>
<hr>
<h2 id="Deep-Bayesian-Reinforcement-Learning-for-Spacecraft-Proximity-Maneuvers-and-Docking"><a href="#Deep-Bayesian-Reinforcement-Learning-for-Spacecraft-Proximity-Maneuvers-and-Docking" class="headerlink" title="Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers and Docking"></a>Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers and Docking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03680">http://arxiv.org/abs/2311.03680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Desong Du, Naiming Qi, Yanfang Liu, Wei Pan</li>
<li>for: 这个研究是为了解决自主太空船的近距离运动和对接（PMD）任务中的控制策略，并提供稳定性保证。</li>
<li>methods: 本研究使用了一种新的 bayesian actor-critic reinforcement learning算法，将控制策略表示为一个 Lyapunov 函数，并通过对问题进行几何加速来实现。</li>
<li>results: 实验结果显示，提出的算法在太空船空滑试验平台上表现出色，并且具有优秀的稳定性和可靠性。<details>
<summary>Abstract</summary>
In the pursuit of autonomous spacecraft proximity maneuvers and docking(PMD), we introduce a novel Bayesian actor-critic reinforcement learning algorithm to learn a control policy with the stability guarantee. The PMD task is formulated as a Markov decision process that reflects the relative dynamic model, the docking cone and the cost function. Drawing from the principles of Lyapunov theory, we frame the temporal difference learning as a constrained Gaussian process regression problem. This innovative approach allows the state-value function to be expressed as a Lyapunov function, leveraging the Gaussian process and deep kernel learning. We develop a novel Bayesian quadrature policy optimization procedure to analytically compute the policy gradient while integrating Lyapunov-based stability constraints. This integration is pivotal in satisfying the rigorous safety demands of spaceflight missions. The proposed algorithm has been experimentally evaluated on a spacecraft air-bearing testbed and shows impressive and promising performance.
</details>
<details>
<summary>摘要</summary>
在探索自主宇宙飞船靠近和停机（PMD）中，我们提出了一种新的 Bayesianactor-critic reinforcement学习算法，以学习一个具有稳定保证的控制策略。 PMD任务被表示为一个Markov决策过程，这个过程反映了相对动态模型、停机 cone 以及成本函数。 基于Lyapunov理论，我们将时间差学习转换为一个受限Gaussian process regression问题。这种创新的方法使得状态价值函数可以表示为Lyapunov函数，利用Gaussian process和深度kernel学习。我们开发了一种 Bayesianquadrature策略优化过程，以分析计算策略偏导数，同时满足Lyapunov基础的稳定性限制。这种稳定性限制是Spaceflight任务中的严格安全要求的保证。我们的提案已经在宇宙飞船空气托器上进行了实验，并表现出了惊喜和漫漫的表现。
</details></li>
</ul>
<hr>
<h2 id="Stable-Modular-Control-via-Contraction-Theory-for-Reinforcement-Learning"><a href="#Stable-Modular-Control-via-Contraction-Theory-for-Reinforcement-Learning" class="headerlink" title="Stable Modular Control via Contraction Theory for Reinforcement Learning"></a>Stable Modular Control via Contraction Theory for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03669">http://arxiv.org/abs/2311.03669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bing Song, Jean-Jacques Slotine, Quang-Cuong Pham</li>
<li>for: 本研究旨在将控制技术与强化学习（RL）结合，以确保稳定性、可靠性和泛化性。</li>
<li>methods: 本研究提出了一种新的方法，利用Contract Theory来实现模块化控制，使得将稳定的子系统组合起来可以保持稳定性。这种模块化控制通过信号组合和动态分解实现。</li>
<li>results: 本研究通过实验表明，使用本方法可以提高层次RL的性能，并且可以保持稳定性和泛化性。<details>
<summary>Abstract</summary>
We propose a novel way to integrate control techniques with reinforcement learning (RL) for stability, robustness, and generalization: leveraging contraction theory to realize modularity in neural control, which ensures that combining stable subsystems can automatically preserve the stability. We realize such modularity via signal composition and dynamic decomposition. Signal composition creates the latent space, within which RL applies to maximizing rewards. Dynamic decomposition is realized by coordinate transformation that creates an auxiliary space, within which the latent signals are coupled in the way that their combination can preserve stability provided each signal, that is, each subsystem, has stable self-feedbacks. Leveraging modularity, the nonlinear stability problem is deconstructed into algebraically solvable ones, the stability of the subsystems in the auxiliary space, yielding linear constraints on the input gradients of control networks that can be as simple as switching the signs of network weights. This minimally invasive method for stability allows arguably easy integration into the modular neural architectures in machine learning, like hierarchical RL, and improves their performance. We demonstrate in simulation the necessity and the effectiveness of our method: the necessity for robustness and generalization, and the effectiveness in improving hierarchical RL for manipulation learning.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，将控制技术与强化学习（RL）结合起来，以确保稳定性、可靠性和通用性：通过ontraction theory来实现模块化在神经控制中，以确保将稳定的子系统组合起来，可以保持稳定性。我们通过信号组合和动态分解来实现模块化。信号组合创造了隐藏空间，在这个空间中，RL可以最大化奖励。动态分解通过坐标变换来创造一个辅助空间，在这个空间中，隐藏信号被联系在一起，以保持稳定性，条件是每个信号，即每个子系统，都有稳定的自反馈。通过模块化，非线性稳定性问题被拆分成可解的问题，即每个子系统的稳定性问题在auxiliary space中，导致输入梯度的控制网络的线性约束，可以非常简单地是将网络权重的信号改变。这种非常少的改变方法可以轻松地 интеGRATE到现有的模块化神经网络架构中，如层次RL，并提高其性能。我们在模拟中证明了我们的方法的必要性和有效性：必要性是为了稳定性和通用性，有效性是在对掌控学习进行改进。
</details></li>
</ul>
<hr>
<h2 id="The-Linear-Representation-Hypothesis-and-the-Geometry-of-Large-Language-Models"><a href="#The-Linear-Representation-Hypothesis-and-the-Geometry-of-Large-Language-Models" class="headerlink" title="The Linear Representation Hypothesis and the Geometry of Large Language Models"></a>The Linear Representation Hypothesis and the Geometry of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03658">http://arxiv.org/abs/2311.03658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiho Park, Yo Joong Choe, Victor Veitch</li>
<li>for: 本研究旨在解释“线性表示”的含义，以及如何在表示空间中理解几何概念（如cosine相似性或投影）。</li>
<li>methods: 本研究使用 counterfactuals 来给出两种“线性表示”的正式定义，一种在输出（单词）表示空间中，另一种在输入（句子）空间中。然后，使用这些定义来连接到线性探针和模型导航。</li>
<li>results: 通过使用 counterfactual pairs，本研究显示了线性表示的概念的存在，以及与解释和控制的连接。此外，研究还表明了选择内积的重要性，并通过实验验证了 LLMA-2 模型的性能。<details>
<summary>Abstract</summary>
Informally, the 'linear representation hypothesis' is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does "linear representation" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of "linear representation", one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product.
</details>
<details>
<summary>摘要</summary>
文中提出了一个称为“线性表示假设”的想法，即高级概念是在某种表示空间中线性表示的。在这篇论文中，我们考虑了两个相关的问题：“线性表示”的具体意思是什么？以及在表示空间中的几何概念（如cosine相似性或投影）是如何理解的？为了回答这些问题，我们使用counterfactual语言来给出了两种对“线性表示”的正式定义，一种在输出（词）表示空间中，另一种在输入（句子）空间中。然后我们证明这两种定义与直探和模型导航相连接。为了理解几何概念，我们使用这些定义来确定一种特殊的非欧几何内积，该内积满足语言结构的一定条件。使用这种 causal 内积，我们可以将所有的线性表示概念统一起来。具体来说，这允许我们使用counterfactual对来构建探测器和导航向量。LLaMA-2实验表明了线性表示的存在、相关性和内积的选择对语言理解和控制的重要性。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Parameterization-of-the-Multi-scale-Kain-Fritsch-MSKF-Convection-Scheme"><a href="#Machine-Learning-Parameterization-of-the-Multi-scale-Kain-Fritsch-MSKF-Convection-Scheme" class="headerlink" title="Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF) Convection Scheme"></a>Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF) Convection Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03652">http://arxiv.org/abs/2311.03652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohui Zhong, Xing Yu, Hao Li<br>for: 这个研究旨在测试一种基于机器学习（ML）模型的气象预报模型，以取代传统的物理参数化方法。methods: 研究使用了一种多出力对称长短Term Memory（Bi-LSTM）模型，并与气象预报模型（WRF）相互运行。results: 研究结果显示，Bi-LSTM模型可以实现高精度，表明ML模型可以取代传统的物理参数化方法。<details>
<summary>Abstract</summary>
Warm-sector heavy rainfall often occurs along the coast of South China, and it is usually localized and long-lasting, making it challenging to predict. High-resolution numerical weather prediction (NWP) models are increasingly used to better resolve topographic features and forecast such high-impact weather events. However, when the grid spacing becomes comparable to the length scales of convection, known as the gray zone, the turbulent eddies in the atmospheric boundary layer are only partially resolved and parameterized to some extent. Whether using a convection parameterization (CP) scheme in the gray zone remains controversial. Scale-aware CP schemes are developed to enhance the representation of convective transport within the gray zone. The multi-scale Kain-Fritsch (MSKF) scheme includes modifications that allow for its effective implementation at a grid resolution as high as 2 km. In recent years, there has been an increasing application of machine learning (ML) models to various domains of atmospheric sciences, including the replacement of physical parameterizations with ML models. This work proposes a multi-output bidirectional long short-term memory (Bi-LSTM) model as a replace the scale-aware MSKF CP scheme. The Weather Research and Forecast (WRF) model is used to generate training and testing data over South China at a horizontal resolution of 5 km. Furthermore, the WRF model is coupled with the ML based CP scheme and compared with WRF simulations with original MSKF scheme. The results demonstrate that the Bi-LSTM model can achieve high accuracy, indicating the potential use of ML models to substitute the MSKF scheme in the gray zone.
</details>
<details>
<summary>摘要</summary>
暖 sector 重降水 часто发生在南中国沿海地区，通常是局部化和长时间的，预测具有挑战性。高分解能数值天气预测模型（NWP）已经越来越被用来更好地解析地形特征并预测这些高影响天气事件。然而，当网格间距相当于气团尺度时，称为灰色区域，大气界面层中的液体摇树只部分解析并被部分参数化。使用气动参数化（CP）算法在灰色区域是有争议的。基于尺度意识的CP算法被开发以提高在灰色区域中的液体运输表现。多尺度Kain-Fritsch（MSKF）算法包括修改，以便在2 km的网格分辨率下实现有效。在过去几年中，机器学习（ML）模型在大气科学领域中的应用越来越普遍，包括替代物理参数化的ML模型。本研究提出了一种多输出双向长短期记忆（Bi-LSTM）模型，用于取代尺度意识的MSKF CP算法。使用Weather Research and Forecast（WRF）模型生成训练和测试数据，并将WRF模型与ML基于CP算法相couple。结果表明，Bi-LSTM模型可以 дости得高准确率，表明ML模型可以在灰色区域中取代MSKF算法。
</details></li>
</ul>
<hr>
<h2 id="SeRO-Self-Supervised-Reinforcement-Learning-for-Recovery-from-Out-of-Distribution-Situations"><a href="#SeRO-Self-Supervised-Reinforcement-Learning-for-Recovery-from-Out-of-Distribution-Situations" class="headerlink" title="SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations"></a>SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03651">http://arxiv.org/abs/2311.03651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snuchankim/sero">https://github.com/snuchankim/sero</a></li>
<li>paper_authors: Chan Kim, Jaekyung Cho, Christophe Bobda, Seung-Woo Seo, Seong-Woo Kim</li>
<li>for: 解决机器人代理人在异常情况下（out-of-distribution，OOD）行为不可靠的问题。</li>
<li>methods: 提出了一种自然语言学习方法，使代理人在OOD状态下重新训练以恢复原始任务性能。</li>
<li>results: 实验结果表明，该方法可以substantially提高代理人在OOD状态下恢复原始任务性能的效率和可靠性，并且可以在难以探索的IN Distribution状态下重新训练代理人。<details>
<summary>Abstract</summary>
Robotic agents trained using reinforcement learning have the problem of taking unreliable actions in an out-of-distribution (OOD) state. Agents can easily become OOD in real-world environments because it is almost impossible for them to visit and learn the entire state space during training. Unfortunately, unreliable actions do not ensure that agents perform their original tasks successfully. Therefore, agents should be able to recognize whether they are in OOD states and learn how to return to the learned state distribution rather than continue to take unreliable actions. In this study, we propose a novel method for retraining agents to recover from OOD situations in a self-supervised manner when they fall into OOD states. Our in-depth experimental results demonstrate that our method substantially improves the agent's ability to recover from OOD situations in terms of sample efficiency and restoration of the performance for the original tasks. Moreover, we show that our method can retrain the agent to recover from OOD situations even when in-distribution states are difficult to visit through exploration.
</details>
<details>
<summary>摘要</summary>
机器人代理人使用强化学习受训时会面临异常状态（out-of-distribution，OOD）下的不可靠行为问题。因为实际环境中很难让代理人在训练时访问整个状态空间，因此代理人容易陷入OOD状态。不幸的是，不可靠的行为并不能确保代理人完成原始任务成功。因此，代理人应该能够识别自己是否处于OOD状态，并学习返回学习过的状态分布而不是继续执行不可靠的行为。在这项研究中，我们提出了一种基于自我监督的方法，可以在OOD状态下重新训练代理人，以便在OOD状态下恢复原始任务的性能。我们的实验结果表明，我们的方法可以很快地提高代理人在OOD状态下的恢复能力，并且可以在难以探索的状态下重新训练代理人。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-the-User-Perception-of-Chatbots-in-Education-Using-A-Partial-Least-Squares-Structural-Equation-Modeling-Approach"><a href="#Analysis-of-the-User-Perception-of-Chatbots-in-Education-Using-A-Partial-Least-Squares-Structural-Equation-Modeling-Approach" class="headerlink" title="Analysis of the User Perception of Chatbots in Education Using A Partial Least Squares Structural Equation Modeling Approach"></a>Analysis of the User Perception of Chatbots in Education Using A Partial Least Squares Structural Equation Modeling Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03636">http://arxiv.org/abs/2311.03636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Rabiul Hasan, Nahian Ismail Chowdhury, Md Hadisur Rahman, Md Asif Bin Syed, JuHyeong Ryu</li>
<li>for: 本研究旨在探讨学生对教育中的 chatbot 的使用情况，尤其是 Large Language Model (LLM) 技术如 Chat Generative Pretrained Transformer (ChatGPT) 和 Google Bard 等交互式人工智能技术在教育中的采用。</li>
<li>methods: 本研究使用 Partial Least Squares Structural Equation Modeling (PLS-SEM) 方法 investigate 学生对 chatbot 的采用，考虑技术就绪指数 (TRI) 和技术接受度模型 (TAM)。数据采集使用 five-point Likert 级，共收集到 185 个答案，使用 R-Studio 软件进行分析。</li>
<li>results: 研究结果显示，optimism 和创新性都对 Perceived Ease of Use (PEOU) 和 Perceived Usefulness (PU) 表现正相关，而不适和不安全度则对 PEOU 表现负相关，只有不安全度对 PU 表现负影响。这些发现可以帮助未来的技术设计师，提供关键的用户行为因素，以便更好地理解学生对 chatbot 的采用和利用情况。<details>
<summary>Abstract</summary>
The integration of Artificial Intelligence (AI) into education is a recent development, with chatbots emerging as a noteworthy addition to this transformative landscape. As online learning platforms rapidly advance, students need to adapt swiftly to excel in this dynamic environment. Consequently, understanding the acceptance of chatbots, particularly those employing Large Language Model (LLM) such as Chat Generative Pretrained Transformer (ChatGPT), Google Bard, and other interactive AI technologies, is of paramount importance. However, existing research on chatbots in education has overlooked key behavior-related aspects, such as Optimism, Innovativeness, Discomfort, Insecurity, Transparency, Ethics, Interaction, Engagement, and Accuracy, creating a significant literature gap. To address this gap, this study employs Partial Least Squares Structural Equation Modeling (PLS-SEM) to investigate the determinant of chatbots adoption in education among students, considering the Technology Readiness Index (TRI) and Technology Acceptance Model (TAM). Utilizing a five-point Likert scale for data collection, we gathered a total of 185 responses, which were analyzed using R-Studio software. We established 12 hypotheses to achieve its objectives. The results showed that Optimism and Innovativeness are positively associated with Perceived Ease of Use (PEOU) and Perceived Usefulness (PU). Conversely, Discomfort and Insecurity negatively impact PEOU, with only Insecurity negatively affecting PU. These findings provide insights for future technology designers, elucidating critical user behavior factors influencing chatbots adoption and utilization in educational contexts.
</details>
<details>
<summary>摘要</summary>
学术界最近才开始启用人工智能（AI），聊天机器人（chatbot）是这一变革的一个显著添加。在在线学习平台快速进步的情况下，学生需要快速适应，因此理解聊天机器人的acceptance，特别是使用大语言模型（LLM）的聊天机器人，如Chat Generative Pretrained Transformer（ChatGPT）、Google Bard等交互式AI技术的acceptance，是非常重要的。然而，现有关于聊天机器人在教育中的研究，忽略了关键的行为相关方面，如乐观性、创新性、不适感、不安全感、透明度、伦理、交互、参与度和准确性，这创造了一个重要的文献差距。为了填补这个差距，本研究使用部分最小二乘方程模型（PLS-SEM）调查聊天机器人在教育中的采用，考虑技术 readiness index（TRI）和技术接受度模型（TAM）。通过五点likert分级的数据收集，我们总共收集了185个答案，并使用RStudio软件分析。我们设置了12个假设，以达到研究的目标。结果显示，乐观性和创新性 positively associated with perceived ease of use（PEOU）和 perceived usefulness（PU），而不适感和不安全感 negatively impact PEOU，只有不安全感 negatively affecting PU。这些发现为未来技术设计师提供了新的思路，揭示了在教育上的聊天机器人采用和利用中的关键用户行为因素。
</details></li>
</ul>
<hr>
<h2 id="TWIST-Teacher-Student-World-Model-Distillation-for-Efficient-Sim-to-Real-Transfer"><a href="#TWIST-Teacher-Student-World-Model-Distillation-for-Efficient-Sim-to-Real-Transfer" class="headerlink" title="TWIST: Teacher-Student World Model Distillation for Efficient Sim-to-Real Transfer"></a>TWIST: Teacher-Student World Model Distillation for Efficient Sim-to-Real Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03622">http://arxiv.org/abs/2311.03622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yamada, Marc Rigter, Jack Collins, Ingmar Posner</li>
<li>for: 这个论文旨在提出一种能够有效地实现模型基于RL中的 sim-to-real 转移的方法，以便在实际世界中应用vision-based模型基于RL。</li>
<li>methods: 该论文提出了一种名为 TWIST（教师学生世界模型填充法）的方法，该方法通过填充教师世界模型中学习的秘密动力学模型到学生世界模型中来实现高效的sim-to-real转移。</li>
<li>results: 实验结果表明，相比于Randomization的标准方法和模型自由RL方法，TWIST方法在模型基于RL中的sim-to-real转移中具有更高的效率和更好的任务性能。<details>
<summary>Abstract</summary>
Model-based RL is a promising approach for real-world robotics due to its improved sample efficiency and generalization capabilities compared to model-free RL. However, effective model-based RL solutions for vision-based real-world applications require bridging the sim-to-real gap for any world model learnt. Due to its significant computational cost, standard domain randomisation does not provide an effective solution to this problem. This paper proposes TWIST (Teacher-Student World Model Distillation for Sim-to-Real Transfer) to achieve efficient sim-to-real transfer of vision-based model-based RL using distillation. Specifically, TWIST leverages state observations as readily accessible, privileged information commonly garnered from a simulator to significantly accelerate sim-to-real transfer. Specifically, a teacher world model is trained efficiently on state information. At the same time, a matching dataset is collected of domain-randomised image observations. The teacher world model then supervises a student world model that takes the domain-randomised image observations as input. By distilling the learned latent dynamics model from the teacher to the student model, TWIST achieves efficient and effective sim-to-real transfer for vision-based model-based RL tasks. Experiments in simulated and real robotics tasks demonstrate that our approach outperforms naive domain randomisation and model-free methods in terms of sample efficiency and task performance of sim-to-real transfer.
</details>
<details>
<summary>摘要</summary>
模型基于RL是现实世界机器人控制中有前途的方法，因其在样本效率和泛化能力方面比模型自由RL更出色。然而，为实际视觉应用场景中的模型基于RL解决方案，需要跨 sim-to-real 隔目拟合，以便将任何世界模型学习到实际世界中。由于其计算成本很高，标准的随机化Domain不提供有效的解决方案。本文提出了TWIST（教师学生世界模型精炼 для sim-to-real 传输）来实现高效的 sim-to-real 传输。specifically，TWIST 利用状态观察得到了可以轻松地获得的、特权信息，通常来自模拟器中获得。特别是，一个教师世界模型在状态信息上进行高效地训练。同时，一个匹配的数据集被收集了，其中包含了随机化的图像观察。然后，教师世界模型监督学生世界模型使用随机化的图像观察作为输入。通过在教师模型中学习的latent动力模型的精炼，TWIST 实现了高效和有效的 sim-to-real 传输。实验表明，我们的方法在模拟和实际机器人控制任务中比随机化Domain和模型自由RL方法更高效和有更好的任务性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.AI_2023_11_07/" data-id="cloqtaene006rgh88hlur71kt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/07/cs.CV_2023_11_07/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-11-07
        
      </div>
    </a>
  
  
    <a href="/2023/11/07/cs.CL_2023_11_07/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-11-07</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
