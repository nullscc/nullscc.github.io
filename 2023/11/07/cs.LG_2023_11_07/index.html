
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-11-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04161 repo_url: None paper_authors: Nikita Puchkin, Eduard Gorbunov, Nikolay Kutuzov, A">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-11-07">
<meta property="og:url" content="https://nullscc.github.io/2023/11/07/cs.LG_2023_11_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04161 repo_url: None paper_authors: Nikita Puchkin, Eduard Gorbunov, Nikolay Kutuzov, A">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-07T10:00:00.000Z">
<meta property="article:modified_time" content="2023-11-08T18:37:43.581Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.LG_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T10:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-11-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Breaking-the-Heavy-Tailed-Noise-Barrier-in-Stochastic-Optimization-Problems"><a href="#Breaking-the-Heavy-Tailed-Noise-Barrier-in-Stochastic-Optimization-Problems" class="headerlink" title="Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems"></a>Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04161">http://arxiv.org/abs/2311.04161</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Puchkin, Eduard Gorbunov, Nikolay Kutuzov, Alexander Gasnikov</li>
<li>for:  Stochastic optimization problems with heavy-tailed noise and structured density.</li>
<li>methods:  Smoothed medians of means to stabilize stochastic gradients, clipped-SGD and clipped-SSTM.</li>
<li>results:  Faster convergence rates than $\mathcal{O}(K^{-2(\alpha - 1)&#x2F;\alpha})$ with negligible bias and controllable variance.<details>
<summary>Abstract</summary>
We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$, when the stochastic gradients have finite moments of order $\alpha \in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup.
</details>
<details>
<summary>摘要</summary>
我们考虑了随机优化问题，其中噪声具有重 tailed 分布。我们显示，在这类问题中，可以获得更快的速度减少，比如 $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$，当涉及到随机梯度的噪声具有有限 moment 的情况下。特别是，我们的分析允许噪声范围的期望无穷。为了实现这些结果，我们稳定了随机梯度，使用平滑的中值。我们证明了这些估计具有可控的方差和较小的偏差。这使得我们可以在 clipped-SGD 和 clipped-SSTM 中精心包含这些估计，并 derive 新的高probability 复杂性 bound 在考虑的设置下。
</details></li>
</ul>
<hr>
<h2 id="Computing-Approximate-ell-p-Sensitivities"><a href="#Computing-Approximate-ell-p-Sensitivities" class="headerlink" title="Computing Approximate $\ell_p$ Sensitivities"></a>Computing Approximate $\ell_p$ Sensitivities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04158">http://arxiv.org/abs/2311.04158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Swati Padmanabhan, David P. Woodruff, Qiuyi, Zhang</li>
<li>for: This paper is focused on developing efficient algorithms for approximating sensitivities in dimensionality reduction for regression tasks.</li>
<li>methods: The paper introduces new methods for approximating $\ell_p$ sensitivities and related summary statistics of a given matrix, including an algorithm based on importance sampling of $\ell_p$ Lewis weights.</li>
<li>results: The paper provides provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling, and experiments show that the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have low intrinsic effective dimensionality.<details>
<summary>Abstract</summary>
Recent works in dimensionality reduction for regression tasks have introduced the notion of sensitivity, an estimate of the importance of a specific datapoint in a dataset, offering provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling. However, fast algorithms for approximating $\ell_p$ sensitivities, which we show is equivalent to approximate $\ell_p$ regression, are known for only the $\ell_2$ setting, in which they are termed leverage scores.   In this work, we provide efficient algorithms for approximating $\ell_p$ sensitivities and related summary statistics of a given matrix. In particular, for a given $n \times d$ matrix, we compute $\alpha$-approximation to its $\ell_1$ sensitivities at the cost of $O(n/\alpha)$ sensitivity computations. For estimating the total $\ell_p$ sensitivity (i.e. the sum of $\ell_p$ sensitivities), we provide an algorithm based on importance sampling of $\ell_p$ Lewis weights, which computes a constant factor approximation to the total sensitivity at the cost of roughly $O(\sqrt{d})$ sensitivity computations. Furthermore, we estimate the maximum $\ell_1$ sensitivity, up to a $\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all these results to $\ell_p$ norms for $p > 1$. Lastly, we experimentally show that for a wide class of matrices in real-world datasets, the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have low intrinsic effective dimensionality.
</details>
<details>
<summary>摘要</summary>
近期对回归任务中的维度减少方法提出了敏感度的概念，即数据点的重要性度量，可提供可证明的保证，认为可以通过抽取低敏感度数据点进行下抽样来提高回归的质量。然而，快速计算 $\ell_p$ 敏感度的快速算法仅限于 $\ell_2$  Setting，称为杠杆分数。在这个工作中，我们提供了高效的 $\ell_p$ 敏感度和相关摘要统计量的计算方法。特别是，对于给定 $n \times d$ 矩阵，我们可以在 $\alpha$  approximations 的代价下计算 $\ell_1$ 敏感度，其中 $\alpha$ 是一个常量。此外，我们还提供了一种基于 $\ell_p$ Lewis 权重的重要抽样方法，可以在 $O(\sqrt{d})$ 敏感度计算的代价下计算总 $\ell_p$ 敏感度。此外，我们还可以使用 $O(d)$ 敏感度计算来估算最大 $\ell_1$ 敏感度，带有 $\sqrt{d}$ 因子。最后，我们推广了这些结果到 $\ell_p$  нор准的 $p > 1$ 情况。在实际中，我们发现了许多实际数据集的内在有效维度远低于理论预测，这说明了实际数据集的敏感度远低于理论预测。
</details></li>
</ul>
<hr>
<h2 id="Kernel-mean-and-noise-marginalised-Gaussian-processes-for-exoplanet-transits-and-H-0-inference"><a href="#Kernel-mean-and-noise-marginalised-Gaussian-processes-for-exoplanet-transits-and-H-0-inference" class="headerlink" title="Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet transits and $H_0$ inference"></a>Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet transits and $H_0$ inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04153">http://arxiv.org/abs/2311.04153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Namu Kroupa, David Yallup, Will Handley, Michael Hobson</li>
<li>for: 这个论文的目的是扩展了完全权重方法，使其能够包括核函数选择和核函数参数的 marginalization。此外，通过证据来比较模型。</li>
<li>methods: 该论文使用的方法包括 Gaussian Process regression 和 Bayesian模型比较。具体来说，通过在更高维的空间中嵌入核函数选择和参数，并使用嵌入样本来实现转型样本。</li>
<li>results: 该论文的结果表明，在低噪声区域，true kernel 可以被回归，而在更高噪声区域，无法确定核函数。此外，通过对物理行星参数进行推测，可以去除偏见、宽化 posterior 或提高推测的准确性。最后，该方法被扩展到包括平均函数和噪声模型的 marginalization，并应用于实际数据进行 $H_0$ 的推测。<details>
<summary>Abstract</summary>
Using a fully Bayesian approach, Gaussian Process regression is extended to include marginalisation over the kernel choice and kernel hyperparameters. In addition, Bayesian model comparison via the evidence enables direct kernel comparison. The calculation of the joint posterior was implemented with a transdimensional sampler which simultaneously samples over the discrete kernel choice and their hyperparameters by embedding these in a higher-dimensional space, from which samples are taken using nested sampling. This method was explored on synthetic data from exoplanet transit light curve simulations. The true kernel was recovered in the low noise region while no kernel was preferred for larger noise. Furthermore, inference of the physical exoplanet hyperparameters was conducted. In the high noise region, either the bias in the posteriors was removed, the posteriors were broadened or the accuracy of the inference was increased. In addition, the uncertainty in mean function predictive distribution increased due to the uncertainty in the kernel choice. Subsequently, the method was extended to marginalisation over mean functions and noise models and applied to the inference of the present-day Hubble parameter, $H_0$, from real measurements of the Hubble parameter as a function of redshift, derived from the cosmologically model-independent cosmic chronometer and {\Lambda}CDM-dependent baryon acoustic oscillation observations. The inferred $H_0$ values from the cosmic chronometers, baryon acoustic oscillations and combined datasets are $H_0$ = 66$\pm$6 km/s/Mpc, $H_0$ = 67$\pm$10 km/s/Mpc and $H_0$ = 69$\pm$6 km/s/Mpc, respectively. The kernel posterior of the cosmic chronometers dataset prefers a non-stationary linear kernel. Finally, the datasets are shown to be not in tension with ln(R)=12.17$\pm$0.02.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HyperS2V-A-Framework-for-Structural-Representation-of-Nodes-in-Hyper-Networks"><a href="#HyperS2V-A-Framework-for-Structural-Representation-of-Nodes-in-Hyper-Networks" class="headerlink" title="HyperS2V: A Framework for Structural Representation of Nodes in Hyper Networks"></a>HyperS2V: A Framework for Structural Representation of Nodes in Hyper Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04149">http://arxiv.org/abs/2311.04149</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liushu2019/hypers2v">https://github.com/liushu2019/hypers2v</a></li>
<li>paper_authors: Shu Liu, Cameron Lai, Fujio Toriumi</li>
<li>for: 本研究旨在提出一种基于结构相似性的节点嵌入方法，以便应用机器学习方法到网络数据上。</li>
<li>methods: 本方法基于多尺度随机扫描 Framework，并使用 hyper-degree 捕捉网络结构特性。</li>
<li>results: 实验结果表明，HyperS2V 方法在 both 内在和外在测试中具有更高的解释性和可应用性。<details>
<summary>Abstract</summary>
In contrast to regular (simple) networks, hyper networks possess the ability to depict more complex relationships among nodes and store extensive information. Such networks are commonly found in real-world applications, such as in social interactions. Learning embedded representations for nodes involves a process that translates network structures into more simplified spaces, thereby enabling the application of machine learning approaches designed for vector data to be extended to network data. Nevertheless, there remains a need to delve into methods for learning embedded representations that prioritize structural aspects. This research introduces HyperS2V, a node embedding approach that centers on the structural similarity within hyper networks. Initially, we establish the concept of hyper-degrees to capture the structural properties of nodes within hyper networks. Subsequently, a novel function is formulated to measure the structural similarity between different hyper-degree values. Lastly, we generate structural embeddings utilizing a multi-scale random walk framework. Moreover, a series of experiments, both intrinsic and extrinsic, are performed on both toy and real networks. The results underscore the superior performance of HyperS2V in terms of both interpretability and applicability to downstream tasks.
</details>
<details>
<summary>摘要</summary>
对比常见（简单）网络，超网络具有更复杂的节点间关系和大量信息存储能力。这些网络在实际应用中很常见，如社交互动。学习节点嵌入表示需要将网络结构简化成简单的空间，以便应用机器学习方法到网络数据上。然而，还需要研究优化节点嵌入学习方法，以便更好地考虑网络结构特性。本研究介绍了HyperS2V节点嵌入方法，它关注超网络中节点的结构相似性。首先，我们定义了超节点度来捕捉超网络中节点的结构特性。然后，我们定义了一种新的函数来衡量不同超节点度值之间的结构相似性。最后，我们使用多Scale Random Walk框架生成结构嵌入。此外，我们在各种内在和外在实验中，对真实和模拟网络进行了多种测试。结果表明HyperS2V在 interpretability 和下游任务应用方面具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Multi-resolution-Time-Series-Transformer-for-Long-term-Forecasting"><a href="#Multi-resolution-Time-Series-Transformer-for-Long-term-Forecasting" class="headerlink" title="Multi-resolution Time-Series Transformer for Long-term Forecasting"></a>Multi-resolution Time-Series Transformer for Long-term Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04147">http://arxiv.org/abs/2311.04147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitian Zhang, Liheng Ma, Soumyasundar Pal, Yingxue Zhang, Mark Coates</li>
<li>For: 这个论文主要是为了提高时间序列预测的性能，特别是利用块的方式来学习时间序列中的复杂模式。* Methods: 本论文提出了一个新的框架，即多分辨率时间序列trasformer（MTST），这个框架包含多条分支架构，用于同时模型不同的时间模式。此外，本论文还使用相对位置编码，这样可以更好地提取不同尺度的周期性。* Results: 实验结果显示，MTST比state-of-the-art的预测技术更有效率，特别是在处理长期季节性和趋势的任务上。<details>
<summary>Abstract</summary>
The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.
</details>
<details>
<summary>摘要</summary>
《多解时序变换器的表现在时间序列预测中有了 significi cant改善。 current architectures 通过将时间序列分割成固定大小的块，并将块作为token来学习复杂的时间序列模式。块大小控制了 transformers 的能力来学习不同频率的时间序列模式： shorter patches 更有利于学习本地化、高频模式，而 longer patches 则更适合挖掘长期季节性和趋势。 inspired by this observation， we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Generative-learning-for-nonlinear-dynamics"><a href="#Generative-learning-for-nonlinear-dynamics" class="headerlink" title="Generative learning for nonlinear dynamics"></a>Generative learning for nonlinear dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04128">http://arxiv.org/abs/2311.04128</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Gilpin</li>
<li>for: 本研究探讨了现代生成机器学习模型如何创造真实的输出，超出它们的训练数据，如高清艺术作品、准确的蛋白质结构或对话文本。这些成功表明生成模型学习了如何有效地参数化和采样无法预测的分布。</li>
<li>methods: 本文使用了非线性动力学的古典工具，如信息理论，来推导 chaos 的属性，从而开发了 Parametrizing chaos 的算法。</li>
<li>results: 本研究发现，古典拥挤重建可以用来预测 latent 表示的约束，而 symbolic 近似可以用来比较最小的 discrete 生成器在复杂过程中的作用。 Emerging 跨学科工作将非线性动力学和学习理论相结合，例如操作理论方法应用于复杂液体流动，或在生物数据中探测破碎的平衡。<details>
<summary>Abstract</summary>
Modern generative machine learning models demonstrate surprising ability to create realistic outputs far beyond their training data, such as photorealistic artwork, accurate protein structures, or conversational text. These successes suggest that generative models learn to effectively parametrize and sample arbitrarily complex distributions. Beginning half a century ago, foundational works in nonlinear dynamics used tools from information theory to infer properties of chaotic attractors from time series, motivating the development of algorithms for parametrizing chaos in real datasets. In this perspective, we aim to connect these classical works to emerging themes in large-scale generative statistical learning. We first consider classical attractor reconstruction, which mirrors constraints on latent representations learned by state space models of time series. We next revisit early efforts to use symbolic approximations to compare minimal discrete generators underlying complex processes, a problem relevant to modern efforts to distill and interpret black-box statistical models. Emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets. We anticipate that future machine learning techniques may revisit other classical concepts from nonlinear dynamics, such as transinformation decay and complexity-entropy tradeoffs.
</details>
<details>
<summary>摘要</summary>
现代生成机器学习模型显示出不可思议的能力，创造出真实的输出，远 exceeding its training data，如 фото真实的艺术作品、准确的蛋白结构或对话文本。这些成功表明生成模型可以有效地参数化和随机抽取复杂分布。五十年前，基础性的工作在非线性动力学使用信息理论工具来推导 chaotic attractor 的属性，推动了 Parametrizing chaos 在实际数据中的算法的发展。在这个视角中，我们想要连接这些古典工作与现代大规模生成统计学学习的主题。我们首先考虑古典拟合器重建，这与 state space models 学习的秘密表示有约束。然后我们回到了早期使用 симвоlicapproximations 来比较基本的 discrete generator 下面 complex process 的问题，这与现代尝试distill和interpret黑盒统计模型有关。emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets。我们预计未来机器学习技术可能会回到其他古典非线性动力学概念，如 transinformation decay 和 complexity-entropy tradeoffs。
</details></li>
</ul>
<hr>
<h2 id="Do-Language-Models-Learn-Semantics-of-Code-A-Case-Study-in-Vulnerability-Detection"><a href="#Do-Language-Models-Learn-Semantics-of-Code-A-Case-Study-in-Vulnerability-Detection" class="headerlink" title="Do Language Models Learn Semantics of Code? A Case Study in Vulnerability Detection"></a>Do Language Models Learn Semantics of Code? A Case Study in Vulnerability Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04109">http://arxiv.org/abs/2311.04109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Steenhoek, Md Mahbubur Rahman, Shaila Sharmin, Wei Le</li>
<li>for: 这个论文的目的是分析基于预训练语言模型的漏洞检测性能，以及这些模型是否学习了代码中漏洞检测相关的语义。</li>
<li>methods: 这个论文使用了三种不同的方法来分析模型：解释性工具、注意力分析和交互矩阵分析。</li>
<li>results: 研究发现， Better-performing 模型也更好地与潜在漏洞语句（PVS）相关，但模型很难强制对PVS进行匹配，而且模型对漏洞路径进行匹配也很差。基于这些分析结果，研究人员开发了两种注释方法，以帮助模型更好地理解代码中的漏洞语义。这些注释方法在大多数情况下（11个出于16个）提高了模型的性能，并且发现模型在使用这些注释时对潜在漏洞语句进行了更好的匹配。<details>
<summary>Abstract</summary>
Recently, pretrained language models have shown state-of-the-art performance on the vulnerability detection task. These models are pretrained on a large corpus of source code, then fine-tuned on a smaller supervised vulnerability dataset. Due to the different training objectives and the performance of the models, it is interesting to consider whether the models have learned the semantics of code relevant to vulnerability detection, namely bug semantics, and if so, how the alignment to bug semantics relates to model performance. In this paper, we analyze the models using three distinct methods: interpretability tools, attention analysis, and interaction matrix analysis. We compare the models' influential feature sets with the bug semantic features which define the causes of bugs, including buggy paths and Potentially Vulnerable Statements (PVS). We find that (1) better-performing models also aligned better with PVS, (2) the models failed to align strongly to PVS, and (3) the models failed to align at all to buggy paths. Based on our analysis, we developed two annotation methods which highlight the bug semantics inside the model's inputs. We evaluated our approach on four distinct transformer models and four vulnerability datasets and found that our annotations improved the models' performance in the majority of settings - 11 out of 16, with up to 9.57 points improvement in F1 score compared to conventional fine-tuning. We further found that with our annotations, the models aligned up to 232% better to potentially vulnerable statements. Our findings indicate that it is helpful to provide the model with information of the bug semantics, that the model can attend to it, and motivate future work in learning more complex path-based bug semantics. Our code and data are available at https://figshare.com/s/4a16a528d6874aad51a0.
</details>
<details>
<summary>摘要</summary>
近期，预训语言模型已经显示出了检测漏洞性能的状态导航权。这些模型先被预训在大量源代码库上，然后通过一个更小的监督漏洞数据集进行精度调整。由于模型的不同目标和性能，我们想要看看这些模型是否学习了代码漏洞相关的 semantics，即漏洞 semantics，并如何对这种对应进行分析。在这篇论文中，我们使用三种不同的方法进行分析：解释工具、注意力分析和交互矩阵分析。我们将模型的影响因素与漏洞 semantics 的定义，包括潜在漏洞（PVS）和漏洞路径进行比较。我们发现：1. 性能更高的模型也更好地与 PVS 相对应。2. 模型没有强烈对 PVS 进行对应。3. 模型没有对漏洞路径进行对应。基于我们的分析，我们开发了两种标注方法，以便在模型的输入中高亮 bug semantics。我们在四种 transformer 模型和四个漏洞数据集上进行了评估，并发现我们的标注可以提高模型的性能，在大多数情况下达到11个出版物中的9.57分准确率提高。我们还发现，通过我们的标注，模型可以更好地对潜在漏洞进行响应，并且可以达到232%的响应提高。我们的发现表明，向模型提供 bug semantics 信息可以帮助模型更好地attend to它，并促进未来的工作，学习更复杂的路径基本漏洞 semantics。我们的代码和数据可以在 figshare 上找到。
</details></li>
</ul>
<hr>
<h2 id="Time-Efficient-Reinforcement-Learning-with-Stochastic-Stateful-Policies"><a href="#Time-Efficient-Reinforcement-Learning-with-Stochastic-Stateful-Policies" class="headerlink" title="Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"></a>Time-Efficient Reinforcement Learning with Stochastic Stateful Policies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04082">http://arxiv.org/abs/2311.04082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Firas Al-Hafez, Guoping Zhao, Jan Peters, Davide Tateo</li>
<li>for: 提高强化学习中的状态策略训练效率和稳定性，如处理部分可见环境、增强对策性或直接在策略结构中增加逻辑假设。</li>
<li>methods: 基于状态内部状态核和无状态策略的新方法，通过跟踪状态策略梯度来同时优化状态策略和无状态策略。提出了不同版本的状态策略梯度定理，使得可以轻松实现状态策略的变体。</li>
<li>results: 在复杂的 kontinuous control 任务中，如人型行走，提出的新梯度估计比 BPTT 更快、更简单，并且可以有效扩展到更高的任务复杂度。<details>
<summary>Abstract</summary>
Stateful policies play an important role in reinforcement learning, such as handling partially observable environments, enhancing robustness, or imposing an inductive bias directly into the policy structure. The conventional method for training stateful policies is Backpropagation Through Time (BPTT), which comes with significant drawbacks, such as slow training due to sequential gradient propagation and the occurrence of vanishing or exploding gradients. The gradient is often truncated to address these issues, resulting in a biased policy update. We present a novel approach for training stateful policies by decomposing the latter into a stochastic internal state kernel and a stateless policy, jointly optimized by following the stateful policy gradient. We introduce different versions of the stateful policy gradient theorem, enabling us to easily instantiate stateful variants of popular reinforcement learning and imitation learning algorithms. Furthermore, we provide a theoretical analysis of our new gradient estimator and compare it with BPTT. We evaluate our approach on complex continuous control tasks, e.g., humanoid locomotion, and demonstrate that our gradient estimator scales effectively with task complexity while offering a faster and simpler alternative to BPTT.
</details>
<details>
<summary>摘要</summary>
状态ful策略在强化学习中发挥重要作用，如处理半可见环境、增强Robustness或直接在策略结构中强制一致性。传统的状态ful策略训练方法是Backpropagation Through Time（BPTT），它具有许多缺点，如顺序梯度传播导致训练慢，以及gradient溢出或消失现象。为解决这些问题，我们提出了一种新的状态ful策略训练方法，即将状态ful策略分解为随机内部状态核心和状态eless策略，并将其同时优化。我们还提出了不同版本的状态ful策略梯度定理，可以方便地实现状态ful variants of 各种强化学习和模仿学习算法。此外，我们提供了对我们新的梯度估计器的理论分析，并与BPTT进行比较。我们在复杂的连续控制任务中，如人工智能步行，进行了评估，并证明了我们的梯度估计器可以随任务复杂度增长而快速增长，而且更简单、更高效地替代BPTT。
</details></li>
</ul>
<hr>
<h2 id="Estimator-Coupled-Reinforcement-Learning-for-Robust-Purely-Tactile-In-Hand-Manipulation"><a href="#Estimator-Coupled-Reinforcement-Learning-for-Robust-Purely-Tactile-In-Hand-Manipulation" class="headerlink" title="Estimator-Coupled Reinforcement Learning for Robust Purely Tactile In-Hand Manipulation"></a>Estimator-Coupled Reinforcement Learning for Robust Purely Tactile In-Hand Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04060">http://arxiv.org/abs/2311.04060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lennart Röstel, Johannes Pitz, Leon Sievers, Berthold Bäuml</li>
<li>for: 这篇论文旨在解决 robotic in-hand manipulation 中的问题，具体是用于对于手持下的物体进行精确的重新Orienting，并且在实际中进行 sim2real 转移。</li>
<li>methods: 本文使用了一种组合学习和状态推理的方法，将控制策略和状态推理器在训练时结合在一起，以提高状态推理的精确性和控制策略的可靠性。</li>
<li>results: 本文的方法在实验中实现了对四种不同的物体进行24个 orientations的 sim2real 转移，并且成功地让一个立方体 consecutively 到达九个目标。这是之前的方法在这个具有挑战性的设定中无法实现的。<details>
<summary>Abstract</summary>
This paper identifies and addresses the problems with naively combining (reinforcement) learning-based controllers and state estimators for robotic in-hand manipulation. Specifically, we tackle the challenging task of purely tactile, goal-conditioned, dextrous in-hand reorientation with the hand pointing downwards. Due to the limited sensing available, many control strategies that are feasible in simulation when having full knowledge of the object's state do not allow for accurate state estimation. Hence, separately training the controller and the estimator and combining the two at test time leads to poor performance. We solve this problem by coupling the control policy to the state estimator already during training in simulation. This approach leads to more robust state estimation and overall higher performance on the task while maintaining an interpretability advantage over end-to-end policy learning. With our GPU-accelerated implementation, learning from scratch takes a median training time of only 6.5 hours on a single, low-cost GPU. In simulation experiments with the DLR-Hand II and for four significantly different object shapes, we provide an in-depth analysis of the performance of our approach. We demonstrate the successful sim2real transfer by rotating the four objects to all 24 orientations in the $\pi/2$ discretization of SO(3), which has never been achieved for such a diverse set of shapes. Finally, our method can reorient a cube consecutively to nine goals (median), which was beyond the reach of previous methods in this challenging setting.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Feature-Space-Renormalization-for-Semi-supervised-Learning"><a href="#Feature-Space-Renormalization-for-Semi-supervised-Learning" class="headerlink" title="Feature Space Renormalization for Semi-supervised Learning"></a>Feature Space Renormalization for Semi-supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04055">http://arxiv.org/abs/2311.04055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Sun, Zhongjie Mao, Chao Li, Chao Zhou, Xiao-Jun Wu</li>
<li>For: The paper aims to improve the performance of semi-supervised learning (SSL) models by introducing a feature space renormalization (FSR) mechanism to learn better discriminative features.* Methods: The paper proposes a novel SSL model called FreMatch, which combines the FSR mechanism with pseudo-labelling to improve the performance of SSL models.* Results: The experimental results show that the proposed method can achieve better performance on a variety of standard SSL benchmark datasets, and the FSR mechanism can also enhance the performance of other SSL approaches.<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) has been proven to be a powerful method for leveraging unlabelled data to alleviate models' dependence on large labelled datasets. The common framework among recent approaches is to train the model on a large amount of unlabelled data with consistency regularization to constrain the model predictions to be invariant to input perturbation. However, the existing SSL frameworks still have room for improvement in the consistency regularization method. Instead of regularizing category predictions in the label space as in existing frameworks, this paper proposes a feature space renormalization (FSR) mechanism for SSL. First, we propose a feature space renormalization mechanism to substitute for the commonly used consistency regularization mechanism to learn better discriminative features. To apply this mechanism, we start by building a basic model and an empirical model and then introduce our mechanism to renormalize the feature learning of the basic model with the guidance of the empirical model. Second, we combine the proposed mechanism with pseudo-labelling to obtain a novel effective SSL model named FreMatch. The experimental results show that our method can achieve better performance on a variety of standard SSL benchmark datasets, and the proposed feature space renormalization mechanism can also enhance the performance of other SSL approaches.
</details>
<details>
<summary>摘要</summary>
半supervised learning（SSL）已经证明是一种有力的方法，可以使用无标签数据来减轻模型对大量标签数据的依赖。现有的方法框架中的共同特点是通过在大量无标签数据上进行训练，使模型预测结果具有输入扰动的抗变性。然而，现有的SSL框架仍然存在改进的可能性。而不是在标签空间进行常见的一致规范化（consistency regularization），这篇论文提议在特征空间进行特征空间正规化（feature space renormalization，FSR）机制。我们的方法包括两个主要组成部分：首先，我们提议一种特征空间正规化机制，以取代常见的一致规范化机制，以学习更好的抽象特征。其次，我们将这种机制与pseudo-labeling结合，并提出一种新的有效的SSL模型，即FreMatch。实验结果表明，我们的方法可以在多种标准SSL验证数据集上达到更好的性能，并且提议的特征空间正规化机制也可以提高其他SSL方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Extracting-human-interpretable-structure-property-relationships-in-chemistry-using-XAI-and-large-language-models"><a href="#Extracting-human-interpretable-structure-property-relationships-in-chemistry-using-XAI-and-large-language-models" class="headerlink" title="Extracting human interpretable structure-property relationships in chemistry using XAI and large language models"></a>Extracting human interpretable structure-property relationships in chemistry using XAI and large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04047">http://arxiv.org/abs/2311.04047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geemi P. Wellawatte, Philippe Schwaller</li>
<li>For: The paper aims to address the opaque nature of machine learning models in the field of Explainable Artificial Intelligence (XAI) and improve the accessibility of XAI methods for non-technical users.* Methods: The paper proposes the XpertAI framework, which integrates XAI methods with large language models (LLMs) to generate accessible natural language explanations of raw chemical data automatically.* Results: The paper conducts 5 case studies to evaluate the performance of XpertAI and shows that it combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.Here are the three points in Simplified Chinese text:</li>
<li>for: 该 paper 目的是解决人工智能模型的不透明性，并使Explainable Artificial Intelligence (XAI) 方法更加可 accessible  для非技术用户。</li>
<li>methods: 该 paper 提出了 XpertAI 框架，该框架将 XAI 方法与大型自然语言模型 (LLMs) 结合起来，自动生成化学数据的可读性atural language explanations。</li>
<li>results: 该 paper 通过5个案例研究证明，XpertAI 组合了 LLMs 和 XAI 工具的优点，能够生成特定、科学和可解释的解释。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence (XAI) is an emerging field in AI that aims to address the opaque nature of machine learning models. Furthermore, it has been shown that XAI can be used to extract input-output relationships, making them a useful tool in chemistry to understand structure-property relationships. However, one of the main limitations of XAI methods is that they are developed for technically oriented users. We propose the XpertAI framework that integrates XAI methods with large language models (LLMs) accessing scientific literature to generate accessible natural language explanations of raw chemical data automatically. We conducted 5 case studies to evaluate the performance of XpertAI. Our results show that XpertAI combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.
</details>
<details>
<summary>摘要</summary>
simplify:Explainable Artificial Intelligence (XAI) 是一个 emerging 领域的 AI，旨在解释机器学习模型的不透明性。此外，已经证明 XAI 可以用来提取输入输出关系，使其成为化学领域理解结构属性关系的有用工具。然而，XAI 方法的主要局限性在于它们是为技术启用户而设计的。我们提出了 XpertAI 框架，该框架将 XAI 方法与大量自然语言模型（LLM）结合起来，自动生成可读的化学数据原始数据的自然语言解释。我们进行了 5 个案例研究，以评估 XpertAI 的性能。我们的结果表明，XpertAI 可以结合 LLM 和 XAI 工具的优势，生成特定、科学和可解释的解释。Note: " simplify" is not a word in Chinese, but it is implied that the text is written in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Discordance-Minimization-based-Imputation-Algorithms-for-Missing-Values-in-Rating-Data"><a href="#Discordance-Minimization-based-Imputation-Algorithms-for-Missing-Values-in-Rating-Data" class="headerlink" title="Discordance Minimization-based Imputation Algorithms for Missing Values in Rating Data"></a>Discordance Minimization-based Imputation Algorithms for Missing Values in Rating Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04035">http://arxiv.org/abs/2311.04035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Woong Park, Jinhak Kim, Dan Zhu</li>
<li>for: 这个论文主要是为了处理合并的评分列表中的缺失评分问题。</li>
<li>methods: 该论文使用了特定的分析方法和优化模型来填充缺失评分，这些方法基于了对具体的数据集进行了分析，并且使用了只知道评分信息来优化模型。</li>
<li>results: 该论文的计算实验表明，提订的方法在实际世界数据集和synthetic数据集上具有较高的填充精度，比对比的普通替换方法更高。<details>
<summary>Abstract</summary>
Ratings are frequently used to evaluate and compare subjects in various applications, from education to healthcare, because ratings provide succinct yet credible measures for comparing subjects. However, when multiple rating lists are combined or considered together, subjects often have missing ratings, because most rating lists do not rate every subject in the combined list. In this study, we propose analyses on missing value patterns using six real-world data sets in various applications, as well as the conditions for applicability of imputation algorithms. Based on the special structures and properties derived from the analyses, we propose optimization models and algorithms that minimize the total rating discordance across rating providers to impute missing ratings in the combined rating lists, using only the known rating information. The total rating discordance is defined as the sum of the pairwise discordance metric, which can be written as a quadratic function. Computational experiments based on real-world and synthetic rating data sets show that the proposed methods outperform the state-of-the-art general imputation methods in the literature in terms of imputation accuracy.
</details>
<details>
<summary>摘要</summary>
用Frequency来评估和比较不同领域中的主题，从教育到医疗，因为评分提供简洁又可靠的评估方法。然而，当多个评分列表合并或考虑 вместе时，主题经常有 missing 评分，因为大多数评分列表不会对所有主题进行评分。在这个研究中，我们对 missing value 模式进行分析，使用 six 个真实世界数据集，来评估不同应用场景中的 condition for applicability 和 imputation 算法的可行性。基于分析结果，我们提出了优化模型和算法，以最小化总评分不一致的总和，使用只知道的评分信息进行补做 missing 评分。总评分不一致的定义为所有评分提供者的评分不一致之和，可以写作 quadratic function。通过基于真实世界和 sintetic 评分数据集的计算实验，我们发现我们提出的方法在 imputation 精度方面与文献中的通用 imputation 方法相比较出色。
</details></li>
</ul>
<hr>
<h2 id="Joint-model-for-longitudinal-and-spatio-temporal-survival-data"><a href="#Joint-model-for-longitudinal-and-spatio-temporal-survival-data" class="headerlink" title="Joint model for longitudinal and spatio-temporal survival data"></a>Joint model for longitudinal and spatio-temporal survival data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04008">http://arxiv.org/abs/2311.04008</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor Medina-Olivares, Finn Lindgren, Raffaella Calabrese, Jonathan Crook</li>
<li>for: 这个论文的目的是predicting a borrower’s time-to-event in credit risk analysis, specifically using joint models for longitudinal and survival data to capture spatial and temporal effects and their interaction.</li>
<li>methods: 该论文提出了一种 bayesian hierarchical joint model called Spatio-Temporal Joint Model (STJM), which considers the survival effect of unobserved heterogeneity among borrowers located in the same region at a particular time. 用于大规模数据的估计方法是Integrated Nested Laplace Approximation (INLA) methodology.</li>
<li>results: 实际结果表明，包含空间效应可以一直提高Join Model的表现，但是添加空间-时间交互的效果 less definitive.<details>
<summary>Abstract</summary>
In credit risk analysis, survival models with fixed and time-varying covariates are widely used to predict a borrower's time-to-event. When the time-varying drivers are endogenous, modelling jointly the evolution of the survival time and the endogenous covariates is the most appropriate approach, also known as the joint model for longitudinal and survival data. In addition to the temporal component, credit risk models can be enhanced when including borrowers' geographical information by considering spatial clustering and its variation over time. We propose the Spatio-Temporal Joint Model (STJM) to capture spatial and temporal effects and their interaction. This Bayesian hierarchical joint model reckons the survival effect of unobserved heterogeneity among borrowers located in the same region at a particular time. To estimate the STJM model for large datasets, we consider the Integrated Nested Laplace Approximation (INLA) methodology. We apply the STJM to predict the time to full prepayment on a large dataset of 57,258 US mortgage borrowers with more than 2.5 million observations. Empirical results indicate that including spatial effects consistently improves the performance of the joint model. However, the gains are less definitive when we additionally include spatio-temporal interactions.
</details>
<details>
<summary>摘要</summary>
在信用风险分析中，Fixed和时间变量的生存模型广泛使用来预测借款人的时间事件。当时间变量 Driver 是内生的时，模型同时考虑生存时间的演化和内生 covariates 的演化是最佳的方法，也称为长itudinal and survival data 的共同模型。此外，信用风险模型可以通过考虑借款人的地理信息来增强，包括空间聚集和时间变化的相互作用。我们提出了空间-时间共同模型（STJM），以捕捉空间和时间效应以及其交互作用。这个 bayesian 层次模型reckons 借款人所在地区的时间点上的生存效应。为处理大数据集，我们考虑了 Integrated Nested Laplace Approximation（INLA）方法。我们应用 STJM 模型来预测57,258名美国 mortgage 借款人的全 prepayment 时间，共有 más than 2.5 百万观察数据。实际结果表明，包括空间效应可以一直提高生存模型的性能，但是添加空间-时间交互作用后的效果较弱。
</details></li>
</ul>
<hr>
<h2 id="An-Initialization-Schema-for-Neuronal-Networks-on-Tabular-Data"><a href="#An-Initialization-Schema-for-Neuronal-Networks-on-Tabular-Data" class="headerlink" title="An Initialization Schema for Neuronal Networks on Tabular Data"></a>An Initialization Schema for Neuronal Networks on Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03996">http://arxiv.org/abs/2311.03996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wolfgang Fuhl</li>
<li>for: 这项研究的目的是提出一种使用神经网络处理粗粒度数据的简单 yet effective 方法。</li>
<li>methods: 该方法使用了初始化团队学习的schema，并对批处理中的梯度进行遮盖，以便在神经网络中 jointly 训练集成体。</li>
<li>results: 研究人员在多个公共数据集上评估了该方法，并证明了它在对粗粒度数据进行预测和分类 task 中的改进表现。In English, the three key points are:</li>
<li>for: The purpose of this research is to propose a simple yet effective method for processing tabular data using neural networks.</li>
<li>methods: The method uses a schema for initializing team learning, and adds gradient masking to batches to enable joint training in neural networks.</li>
<li>results: The authors evaluate the method on multiple public datasets and show improved performance compared to other neural network-based approaches.<details>
<summary>Abstract</summary>
Nowadays, many modern applications require heterogeneous tabular data, which is still a challenging task in terms of regression and classification. Many approaches have been proposed to adapt neural networks for this task, but still, boosting and bagging of decision trees are the best-performing methods for this task. In this paper, we show that a binomial initialized neural network can be used effectively on tabular data. The proposed approach shows a simple but effective approach for initializing the first hidden layer in neural networks. We also show that this initializing schema can be used to jointly train ensembles by adding gradient masking to batch entries and using the binomial initialization for the last layer in a neural network. For this purpose, we modified the hinge binary loss and the soft max loss to make them applicable for joint ensemble training. We evaluate our approach on multiple public datasets and showcase the improved performance compared to other neural network-based approaches. In addition, we discuss the limitations and possible further research of our approach for improving the applicability of neural networks to tabular data.   Link: https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list
</details>
<details>
<summary>摘要</summary>
现在，许多现代应用需要异ogeneous的表格数据，这是对回归和分类 зада务中的一个挑战。许多方法已经被提出来适应神经网络，但是强化和袋包的决策树仍然是这些任务中最佳的方法。在这篇论文中，我们展示了一种使用初始化的神经网络可以有效地处理表格数据。我们还展示了一种初始化Schema可以用来初始化神经网络中的第一层。此外，我们还将Gradient Masking添加到批处理中，并使用最后一层的初始化Schema来联合训练集。为此，我们修改了折级二进制损失函数和软MAX损失函数，使其适用于联合集成训练。我们在多个公共数据集上评估了我们的方法，并证明了与其他神经网络基于方法相比，我们的方法显著提高了性能。此外，我们还讨论了我们的方法的局限性和可能的进一步研究，以提高神经网络对表格数据的应用性。Link: <https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list>
</details></li>
</ul>
<hr>
<h2 id="Bandit-Pareto-Set-Identification-the-Fixed-Budget-Setting"><a href="#Bandit-Pareto-Set-Identification-the-Fixed-Budget-Setting" class="headerlink" title="Bandit Pareto Set Identification: the Fixed Budget Setting"></a>Bandit Pareto Set Identification: the Fixed Budget Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03992">http://arxiv.org/abs/2311.03992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrille Kone, Emilie Kaufmann, Laura Richert</li>
<li>for: 本研究探讨了一个多目标纯探索问题，其中每个臂相关于一个未知多变量分布，目标是确定这些分布的含义，使其不 worse than 另一个分布：Pareto优化集。</li>
<li>methods: 我们提出了首个针对固定预算Pareto集标识任务的算法，它们结合了精心估计每个臂是否在Pareto集的“difficulty to classify”特征，以及一种通用的排除方案。</li>
<li>results: 我们证明了两种特定实现，EGE-SR和EGE-SH，其错误概率与预算相关的衰减速率为指数型，并且支持信息理论下界。我们还通过实验使用实际数据和 sintetic数据，发现我们的算法表现良好。<details>
<summary>Abstract</summary>
We study a multi-objective pure exploration problem in a multi-armed bandit model. Each arm is associated to an unknown multi-variate distribution and the goal is to identify the distributions whose mean is not uniformly worse than that of another distribution: the Pareto optimal set. We propose and analyze the first algorithms for the \emph{fixed budget} Pareto Set Identification task. We propose Empirical Gap Elimination, a family of algorithms combining a careful estimation of the ``hardness to classify'' each arm in or out of the Pareto set with a generic elimination scheme. We prove that two particular instances, EGE-SR and EGE-SH, have a probability of error that decays exponentially fast with the budget, with an exponent supported by an information theoretic lower-bound. We complement these findings with an empirical study using real-world and synthetic datasets, which showcase the good performance of our algorithms.
</details>
<details>
<summary>摘要</summary>
我们研究一个多目标纯探索问题在多重机关模型中。每棒有一个未知多变数据分布，目标是确定这些分布的含义不比另一个分布 uniformly 差。我们提出并分析了首个预算 Pareto 集标定 зада务的算法。我们提出了 Empirical Gap Elimination，一种组合精心估计每棒在 Pareto 集内或外的困难程度与一种通用淘汰方案的算法家族。我们证明了两个特定实例 EGE-SR 和 EGE-SH 的概率错误与预算相关，具有 exponentially 快衰减速率，其下支持信息论下界。我们补充这些发现与实际数据集和 sintetic 数据集的实验，显示了我们的算法表现良好。Note that Simplified Chinese is a written language, and the translation is based on the standardized grammar and vocabulary of Simplified Chinese. The sentence structure and wording may be different from Traditional Chinese, which is spoken in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Cup-Curriculum-Curriculum-Learning-on-Model-Capacity"><a href="#Cup-Curriculum-Curriculum-Learning-on-Model-Capacity" class="headerlink" title="Cup Curriculum: Curriculum Learning on Model Capacity"></a>Cup Curriculum: Curriculum Learning on Model Capacity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03956">http://arxiv.org/abs/2311.03956</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luca-scharr/cupcurriculum">https://github.com/luca-scharr/cupcurriculum</a></li>
<li>paper_authors: Luca Scharr, Vanessa Toborek</li>
<li>for: 提高自然语言处理模型的性能</li>
<li>methods: 使用迭代幅度减小法减少模型容量，然后在第二阶段重新引入这些 weights，使模型容量展示 Cup 形曲线</li>
<li>results: 比较 Early Stopping 和 Cup Curriculum 两种方法，显示 Cup Curriculum 可靠地超越 Early Stopping，并具有高鲁棒性 against overfitting。<details>
<summary>Abstract</summary>
Curriculum learning (CL) aims to increase the performance of a learner on a given task by applying a specialized learning strategy. This strategy focuses on either the dataset, the task, or the model. There is little to no work analysing the possibilities to apply CL on the model capacity in natural language processing. To close this gap, we propose the cup curriculum. In a first phase of training we use a variation of iterative magnitude pruning to reduce model capacity. These weights are reintroduced in a second phase, resulting in the model capacity to show a cup-shaped curve over the training iterations. We empirically evaluate different strategies of the cup curriculum and show that it outperforms early stopping reliably while exhibiting a high resilience to overfitting.
</details>
<details>
<summary>摘要</summary>
学习轨迹（CL）目的是提高学习者在给定任务上的表现，通过特殊的学习策略。这种策略可以对数据集、任务或模型进行特殊化。然而，有很少关于应用CL在模型容量上的研究。为了填补这个空白，我们提出了杯训练策略。在首 phase of 训练中，我们使用迭代幅度减少的方法来减少模型容量。这些参数在第二 phase 的训练中被重新引入，导致模型容量示出了杯形曲线的变化趋势。我们对不同的杯训练策略进行实验性评估，并证明了它可靠地超越早期停止，同时具有高度适应性。
</details></li>
</ul>
<hr>
<h2 id="Structure-of-universal-formulas"><a href="#Structure-of-universal-formulas" class="headerlink" title="Structure of universal formulas"></a>Structure of universal formulas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03910">http://arxiv.org/abs/2311.03910</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smith86n/wiki-is-mostly-fake-radom-words-word-genrationr-">https://github.com/smith86n/wiki-is-mostly-fake-radom-words-word-genrationr-</a></li>
<li>paper_authors: Dmitry Yarotsky</li>
<li>for: 本文研究 parameterized analytic expressions 的高度表达能力，包括一些形式为神经网络的模型。</li>
<li>methods: 本文分析了这些高度表达能力的模型的结构元素，并提出了一系列分类结果。</li>
<li>results: 本文证明了一些函数家族的Global Approximability Property，并给出了一些不能在所有定义域上适用的函数例子。<details>
<summary>Abstract</summary>
By universal formulas we understand parameterized analytic expressions that have a fixed complexity, but nevertheless can approximate any continuous function on a compact set. There exist various examples of such formulas, including some in the form of neural networks. In this paper we analyze the essential structural elements of these highly expressive models. We introduce a hierarchy of expressiveness classes connecting the global approximability property to the weaker property of infinite VC dimension, and prove a series of classification results for several increasingly complex functional families. In particular, we introduce a general family of polynomially-exponentially-algebraic functions that, as we prove, is subject to polynomial constraints. As a consequence, we show that fixed-size neural networks with not more than one layer of neurons having transcendental activations (e.g., sine or standard sigmoid) cannot in general approximate functions on arbitrary finite sets. On the other hand, we give examples of functional families, including two-hidden-layer neural networks, that approximate functions on arbitrary finite sets, but fail to do that on the whole domain of definition.
</details>
<details>
<summary>摘要</summary>
通过通用方程式我们理解参数化分析表达式，它们具有固定的复杂性，但可以将任何连续函数在有界集上 aproximate。存在多种这种表达式的例子，包括一些形式为神经网络。在这篇论文中，我们分析了高表达能力模型的基本结构元素。我们建立了一个表达能力层次结构，将全球approx性质连接到更弱的无限VCdimension质量，并证明了一系列分类结果 для多个逐渐复杂的函数家族。特别是，我们引入了一个通用的多项式幂函数，并证明它们受到多项式约束。这意味着，Fixed-size神经网络没有超过一层神经元有跨度活动（例如，三角函数或标准 sigmoid）不能在一般的有限集上逼近函数。然而，我们给出了一些函数家族的示例，包括两层隐藏层神经网络，它们在有限集上逼近函数，但在整个定义域上不能逼近函数。
</details></li>
</ul>
<hr>
<h2 id="Learning-Based-Latency-Constrained-Fronthaul-Compression-Optimization-in-C-RAN"><a href="#Learning-Based-Latency-Constrained-Fronthaul-Compression-Optimization-in-C-RAN" class="headerlink" title="Learning-Based Latency-Constrained Fronthaul Compression Optimization in C-RAN"></a>Learning-Based Latency-Constrained Fronthaul Compression Optimization in C-RAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03899">http://arxiv.org/abs/2311.03899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Axel Grönland, Bleron Klaiqi, Xavier Gelabert</li>
<li>for: 这个研究是为了提高无线 mobilenetworks中Radio Access Network（RAN）功能的cloud化，并且提供了一个可靠的对于Fronthaul（FH）压缩技术的方法来满足FH的容量和延迟需求。</li>
<li>methods: 本研究使用了一个无模型的深度学习（DRL）基础的FH压缩框架，通过调整不同的配置参数，例如模ulation order、precoder粒度和precoder重量Quantization，以控制FH压缩的程度，并且 simultanoeusly optimize FH的负载和无线对应性。</li>
<li>results: 实验结果显示，DRL-FC比对照方案（即没有压缩）在不同的FH负载水平上显示出了significantly高的FH使用率（68.7%的平均值）和无线对应性。同时，DRL-FC框架还能够遵循对FH延迟需求（在我们的情况下是260 $\mu$s）的前定限制，在不同的FH负载水平下具有可靠的性能。<details>
<summary>Abstract</summary>
The evolution of wireless mobile networks towards cloudification, where Radio Access Network (RAN) functions can be hosted at either a central or distributed locations, offers many benefits like low cost deployment, higher capacity, and improved hardware utilization. Nevertheless, the flexibility in the functional deployment comes at the cost of stringent fronthaul (FH) capacity and latency requirements. One possible approach to deal with these rigorous constraints is to use FH compression techniques. To ensure that FH capacity and latency requirements are met, more FH compression is applied during high load, while less compression is applied during medium and low load to improve FH utilization and air interface performance. In this paper, a model-free deep reinforcement learning (DRL) based FH compression (DRL-FC) framework is proposed that dynamically controls FH compression through various configuration parameters such as modulation order, precoder granularity, and precoder weight quantization that affect both FH load and air interface performance. Simulation results show that DRL-FC exhibits significantly higher FH utilization (68.7% on average) and air interface throughput than a reference scheme (i.e. with no applied compression) across different FH load levels. At the same time, the proposed DRL-FC framework is able to meet the predefined FH latency constraints (in our case set to 260 $\mu$s) under various FH loads.
</details>
<details>
<summary>摘要</summary>
In this paper, a model-free deep reinforcement learning (DRL) based fronthaul compression (DRL-FC) framework is proposed that dynamically controls FH compression through various configuration parameters such as modulation order, precoder granularity, and precoder weight quantization that affect both FH load and air interface performance. Simulation results show that DRL-FC exhibits significantly higher FH utilization (68.7% on average) and air interface throughput than a reference scheme (i.e. with no applied compression) across different FH load levels. At the same time, the proposed DRL-FC framework is able to meet the predefined FH latency constraints (in our case set to 260 $\mu$s) under various FH loads.
</details></li>
</ul>
<hr>
<h2 id="An-Explainable-Framework-for-Machine-learning-Based-Reactive-Power-Optimization-of-Distribution-Network"><a href="#An-Explainable-Framework-for-Machine-learning-Based-Reactive-Power-Optimization-of-Distribution-Network" class="headerlink" title="An Explainable Framework for Machine learning-Based Reactive Power Optimization of Distribution Network"></a>An Explainable Framework for Machine learning-Based Reactive Power Optimization of Distribution Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03863">http://arxiv.org/abs/2311.03863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Liao, Benjamin Schäfer, Dalin Qin, Gonghao Zhang, Zhixian Wang, Zhe Yang</li>
<li>for: 优化分布网络的反应力能源，使用机器学习模型，以提高分布网络的运行效率和稳定性。</li>
<li>methods: 提出了一种可解释的机器学习框架，通过使用盖比投资分析法来衡量每个输入特征对分布网络的反应力优化解决方案的贡献。</li>
<li>results: 通过使用可视化分析工具，从全局和具体两个角度来准确地解释机器学习模型基于的反应力优化解决方案的决策过程中的潜在偏见或错误。<details>
<summary>Abstract</summary>
To reduce the heavy computational burden of reactive power optimization of distribution networks, machine learning models are receiving increasing attention. However, most machine learning models (e.g., neural networks) are usually considered as black boxes, making it challenging for power system operators to identify and comprehend potential biases or errors in the decision-making process of machine learning models. To address this issue, an explainable machine-learning framework is proposed to optimize the reactive power in distribution networks. Firstly, a Shapley additive explanation framework is presented to measure the contribution of each input feature to the solution of reactive power optimizations generated from machine learning models. Secondly, a model-agnostic approximation method is developed to estimate Shapley values, so as to avoid the heavy computational burden associated with direct calculations of Shapley values. The simulation results show that the proposed explainable framework can accurately explain the solution of the machine learning model-based reactive power optimization by using visual analytics, from both global and instance perspectives. Moreover, the proposed explainable framework is model-agnostic, and thus applicable to various models (e.g., neural networks).
</details>
<details>
<summary>摘要</summary>
Firstly, a Shapley additive explanation framework is presented to measure the contribution of each input feature to the solution of reactive power optimizations generated from machine learning models. Secondly, a model-agnostic approximation method is developed to estimate Shapley values, so as to avoid the heavy computational burden associated with direct calculations of Shapley values.The simulation results show that the proposed explainable framework can accurately explain the solution of the machine learning model-based reactive power optimization by using visual analytics, from both global and instance perspectives. Moreover, the proposed explainable framework is model-agnostic, and thus applicable to various models (e.g., neural networks).translate into Simplified Chinese:为了减轻分布网络中的计算拥塞，机器学习模型在得到越来越多的注意力。然而，大多数机器学习模型（例如神经网络）通常被视为黑盒子，使得电力系统运营员很难了解和理解机器学习模型的决策过程中的可能的偏见或错误。为解决这个问题，一种可解释的机器学习框架被提议用于分布网络中的待能优化。首先，一种基于Shapley添加的解释框架被提出来度量每个输入特征对机器学习模型中的解决方案中的贡献。其次，一种模型无关的估计方法被开发以估计Shapley值，以避免直接计算Shapley值的重要计算负担。实验结果表明，提议的可解释框架可以准确地解释基于机器学习模型的分布网络中的待能优化解决方案，使用视觉分析，从全局和实例两个角度来看。此外，提议的可解释框架是模型无关的，因此可以应用于不同的模型（例如神经网络）。
</details></li>
</ul>
<hr>
<h2 id="Improved-MDL-Estimators-Using-Fiber-Bundle-of-Local-Exponential-Families-for-Non-exponential-Families"><a href="#Improved-MDL-Estimators-Using-Fiber-Bundle-of-Local-Exponential-Families-for-Non-exponential-Families" class="headerlink" title="Improved MDL Estimators Using Fiber Bundle of Local Exponential Families for Non-exponential Families"></a>Improved MDL Estimators Using Fiber Bundle of Local Exponential Families for Non-exponential Families</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03852">http://arxiv.org/abs/2311.03852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kohei Miyamoto, Andrew R. Barron, Jun’ichi Takeuchi</li>
<li>for: 这个论文是为了研究最小描述长度（MDL）估计器，特别是使用两部分代码来实现通用编码。</li>
<li>methods: 论文使用了两部分代码的方法，其中一部分是用于描述数据的地方分布，另一部分是用于描述模型家族的结构。</li>
<li>results: 论文提出了一种基于Barron和Cover（1991）理论的risk和loss的下界，并应用到了杂合家族（mixture families）中。这个结果表明，使用这种方法可以在非线性家族中实现比较好的估计性能。<details>
<summary>Abstract</summary>
Minimum Description Length (MDL) estimators, using two-part codes for universal coding, are analyzed. For general parametric families under certain regularity conditions, we introduce a two-part code whose regret is close to the minimax regret, where regret of a code with respect to a target family M is the difference between the code length of the code and the ideal code length achieved by an element in M. This is a generalization of the result for exponential families by Gr\"unwald. Our code is constructed by using an augmented structure of M with a bundle of local exponential families for data description, which is not needed for exponential families. This result gives a tight upper bound on risk and loss of the MDL estimators based on the theory introduced by Barron and Cover in 1991. Further, we show that we can apply the result to mixture families, which are a typical example of non-exponential families.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化字符串。<</SYS>>我们研究了最小描述长度（MDL）估计器，使用两部分代码进行通用编码。对于普遍的参数家族，在某些正则条件下，我们引入了一个两部分代码，其忽略差异与最小值估计器的目标家族M之间的差异。这是对于指数家族的结果的总体推广。我们的代码使用了增强结构M中的一个包装的本地指数家族来描述数据，这不需要在指数家族上进行。这个结果给出了基于柯本和覆盖于1991年提出的理论的紧张Upper bound，对MDL估计器的风险和损失进行评估。此外，我们还证明了我们可以将结果应用到杂合家族，这是非指数家族的典型例子。
</details></li>
</ul>
<hr>
<h2 id="User-level-Differentially-Private-Stochastic-Convex-Optimization-Efficient-Algorithms-with-Optimal-Rates"><a href="#User-level-Differentially-Private-Stochastic-Convex-Optimization-Efficient-Algorithms-with-Optimal-Rates" class="headerlink" title="User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates"></a>User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03797">http://arxiv.org/abs/2311.03797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hilal Asi, Daogao Liu</li>
<li>for: 这 paper 描述了一种用户级 differentially private stochastic convex optimization (DP-SCO) 算法，用于保护每个用户可能拥有多个数据项的情况下的隐私。</li>
<li>methods: 该 paper 使用了多重通道 DP-SGD 算法，并结合了一种私有的平均值估计过程，用于处理异常数据。</li>
<li>results: 该 paper 实现了对凸函数和强凸函数的优化，并且需要用户数量在维度上增长只需 logarithmic。此外，该 paper 还实现了对不含积函数的优化，并且在 polynomial time 内完成。<details>
<summary>Abstract</summary>
We study differentially private stochastic convex optimization (DP-SCO) under user-level privacy, where each user may hold multiple data items. Existing work for user-level DP-SCO either requires super-polynomial runtime [Ghazi et al. (2023)] or requires the number of users to grow polynomially with the dimensionality of the problem with additional strict assumptions [Bassily et al. (2023)]. We develop new algorithms for user-level DP-SCO that obtain optimal rates for both convex and strongly convex functions in polynomial time and require the number of users to grow only logarithmically in the dimension. Moreover, our algorithms are the first to obtain optimal rates for non-smooth functions in polynomial time. These algorithms are based on multiple-pass DP-SGD, combined with a novel private mean estimation procedure for concentrated data, which applies an outlier removal step before estimating the mean of the gradients.
</details>
<details>
<summary>摘要</summary>
我们研究具有用户级隐私的减衰 Stochastic Convex Optimization (DP-SCO)，每个用户可能持有多个数据项目。现有的用户级DP-SCO工作 either requires super-polynomial runtime [Ghazi et al. (2023)] 或需要问题的维度 polynomially grows with the number of users and additional strict assumptions [Bassily et al. (2023)]. We develop new algorithms for user-level DP-SCO that obtain optimal rates for both convex and strongly convex functions in polynomial time and require the number of users to grow only logarithmically in the dimension. Moreover, our algorithms are the first to obtain optimal rates for non-smooth functions in polynomial time. These algorithms are based on multiple-pass DP-SGD, combined with a novel private mean estimation procedure for concentrated data, which applies an outlier removal step before estimating the mean of the gradients.
</details></li>
</ul>
<hr>
<h2 id="Neuro-GPT-Developing-A-Foundation-Model-for-EEG"><a href="#Neuro-GPT-Developing-A-Foundation-Model-for-EEG" class="headerlink" title="Neuro-GPT: Developing A Foundation Model for EEG"></a>Neuro-GPT: Developing A Foundation Model for EEG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03764">http://arxiv.org/abs/2311.03764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhui Cui, Woojae Jeong, Philipp Thölke, Takfarinas Medani, Karim Jerbi, Anand A. Joshi, Richard M. Leahy</li>
<li>for: addressing the challenges of data scarcity and heterogeneity in Brain-Computer Interface (BCI) tasks</li>
<li>methods: using a foundation model consisting of an EEG encoder and a GPT model, pre-trained on a large-scale public EEG dataset with a self-supervised task, and fine-tuning on a Motor Imagery Classification task with only 9 subjects</li>
<li>results: significant improvement in classification performance compared to a model trained from scratch, demonstrating the advanced generalizability of the foundation model and its ability to address data scarcity and heterogeneity issues<details>
<summary>Abstract</summary>
To handle the scarcity and heterogeneity of electroencephalography (EEG) data in Brain-Computer Interface (BCI) tasks, and to harness the vast public data, we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT model. The foundation model is pre-trained on a large-scale public EEG dataset, using a self-supervised task which learns how to reconstruct the masked chunk in EEG. We then fine-tune the foundation model on a Motor Imagery Classification task where only 9 subjects are available. Experiments demonstrated that applying foundation model can significantly improve classification performance compared to the model trained from scratch, which provides evidence for the advanced generalizability of foundation model and the ability to address the challenges of data scarcity and heterogeneity.
</details>
<details>
<summary>摘要</summary>
为了处理电энцеfalography（EEG）数据的缺乏和多样性在Brain-Computer Interface（BCI）任务中，并利用大规模公共数据，我们提议Neuro-GPT基础模型，包括EEG编码器和GPT模型。基础模型在大规模公共EEG数据集上自动学习，使用遮盖块的自我超视图学习任务，学习如何重建遮盖块。然后，我们在只有9名参与者的电冲想象分类任务上练习基础模型，实验表明，将基础模型应用于任务中可以显著提高分类性能，这提供了基础模型的进步通用性和数据缺乏和多样性的能力。
</details></li>
</ul>
<hr>
<h2 id="Posterior-Sampling-Based-Bayesian-Optimization-with-Tighter-Bayesian-Regret-Bounds"><a href="#Posterior-Sampling-Based-Bayesian-Optimization-with-Tighter-Bayesian-Regret-Bounds" class="headerlink" title="Posterior Sampling-Based Bayesian Optimization with Tighter Bayesian Regret Bounds"></a>Posterior Sampling-Based Bayesian Optimization with Tighter Bayesian Regret Bounds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03760">http://arxiv.org/abs/2311.03760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shion Takeno, Yu Inatsu, Masayuki Karasuyama, Ichiro Takeuchi</li>
<li>for: 这篇论文是关于搜索空间中的搜索函数（Acquisition Function，AF）的研究，尤其是 Gaussian Process Upper Confidence Bound（GP-UCB）和 Thompson Sampling（TS）两种已知的AF的性能。</li>
<li>methods: 本文首先证明TS实现了更紧的Bayesian Cumulative Regret（BCR）bound，然后通过实验比较GP-UCB、TS和一种新的AF called Probability of Improvement from the Maximum of a Sample Path（PIMS）的性能。</li>
<li>results: 本文的实验结果表明，PIMS可以实现BCR bound，并且不需要手动调整参数，而GP-UCB和TS则经常受到参数调整和过度探索的问题。<details>
<summary>Abstract</summary>
Among various acquisition functions (AFs) in Bayesian optimization (BO), Gaussian process upper confidence bound (GP-UCB) and Thompson sampling (TS) are well-known options with established theoretical properties regarding Bayesian cumulative regret (BCR). Recently, it has been shown that a randomized variant of GP-UCB achieves a tighter BCR bound compared with GP-UCB, which we call the tighter BCR bound for brevity. Inspired by this study, this paper first shows that TS achieves the tighter BCR bound. On the other hand, GP-UCB and TS often practically suffer from manual hyperparameter tuning and over-exploration issues, respectively. To overcome these difficulties, we propose yet another AF called a probability of improvement from the maximum of a sample path (PIMS). We show that PIMS achieves the tighter BCR bound and avoids the hyperparameter tuning, unlike GP-UCB. Furthermore, we demonstrate a wide range of experiments, focusing on the effectiveness of PIMS that mitigates the practical issues of GP-UCB and TS.
</details>
<details>
<summary>摘要</summary>
among various acquisition functions (AFs) in Bayesian optimization (BO), Gaussian process upper confidence bound (GP-UCB) and Thompson sampling (TS) are well-known options with established theoretical properties regarding Bayesian cumulative regret (BCR).  Recently, it has been shown that a randomized variant of GP-UCB achieves a tighter BCR bound compared with GP-UCB, which we call the tighter BCR bound for brevity. Inspired by this study, this paper first shows that TS achieves the tighter BCR bound. On the other hand, GP-UCB and TS often practically suffer from manual hyperparameter tuning and over-exploration issues, respectively. To overcome these difficulties, we propose yet another AF called a probability of improvement from the maximum of a sample path (PIMS). We show that PIMS achieves the tighter BCR bound and avoids the hyperparameter tuning, unlike GP-UCB. Furthermore, we demonstrate a wide range of experiments, focusing on the effectiveness of PIMS that mitigates the practical issues of GP-UCB and TS.Note: Please note that the translation is in Simplified Chinese, and the grammar and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Manifold-learning-what-how-and-why"><a href="#Manifold-learning-what-how-and-why" class="headerlink" title="Manifold learning: what, how, and why"></a>Manifold learning: what, how, and why</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03757">http://arxiv.org/abs/2311.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marina Meilă, Hanyu Zhang</li>
<li>for: 这篇论文主要是为了介绍抽象学习（Manifold Learning，ML）的原理、方法和统计基础。</li>
<li>methods: 论文使用了许多常见的ML方法，包括ISOMAP、LOCally Linear Embedding（LLE）、Hessian LLE（HLLE）、diffusion maps等。</li>
<li>results: 论文提供了一个实践统计学家的视角，概述了ML方法的负面和优点，以及选择参数和算法时的贸易OFF。<details>
<summary>Abstract</summary>
Manifold learning (ML), known also as non-linear dimension reduction, is a set of methods to find the low dimensional structure of data. Dimension reduction for large, high dimensional data is not merely a way to reduce the data; the new representations and descriptors obtained by ML reveal the geometric shape of high dimensional point clouds, and allow one to visualize, de-noise and interpret them. This survey presents the principles underlying ML, the representative methods, as well as their statistical foundations from a practicing statistician's perspective. It describes the trade-offs, and what theory tells us about the parameter and algorithmic choices we make in order to obtain reliable conclusions.
</details>
<details>
<summary>摘要</summary>
多样性学习（ML），也称为非线性维度减少，是一组方法来找出数据的低维度结构。对于大量、高维度数据，维度减少不仅是一种减少数据的方式，新的表示和描述器由ML获得的减少结构可以描述高维度点云的几何形状，允许我们可视化、去噪和理解它们。这篇评论介绍了ML的原则、代表方法以及其统计基础，从实践统计家的角度出发。它描述了 Parameters and algorithmic choices 的交易和理论告诉我们可以获得可靠的结论。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Enhanced-physics-informed-neural-networks-with-domain-scaling-and-residual-correction-methods-for-multi-frequency-elliptic-problems"><a href="#Enhanced-physics-informed-neural-networks-with-domain-scaling-and-residual-correction-methods-for-multi-frequency-elliptic-problems" class="headerlink" title="Enhanced physics-informed neural networks with domain scaling and residual correction methods for multi-frequency elliptic problems"></a>Enhanced physics-informed neural networks with domain scaling and residual correction methods for multi-frequency elliptic problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03746">http://arxiv.org/abs/2311.03746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deok-Kyu Jang, Hyea Hyun Kim, Kyungsoo Kim</li>
<li>for: 这个论文是为了研究基于神经网络的偏微分方程 approximate 方法。</li>
<li>methods: 论文提出了一种基于神经网络的偏微分方程 Approximation 方法，具有不受不同偏微分方程的形式或问题域的形状或维度的限制的优点。</li>
<li>results: 论文通过对多频解 Solution 问题进行研究，发现神经网络 Approximation 方法的性能和准确性受到高频和低频部分的对比度的影响，并提出了频谱缩放和差异级 correction 方法来解决这个问题。<details>
<summary>Abstract</summary>
In this paper, neural network approximation methods are developed for elliptic partial differential equations with multi-frequency solutions. Neural network work approximation methods have advantages over classical approaches in that they can be applied without much concerns on the form of the differential equations or the shape or dimension of the problem domain. When applied to problems with multi-frequency solutions, the performance and accuracy of neural network approximation methods are strongly affected by the contrast of the high- and low-frequency parts in the solutions. To address this issue, domain scaling and residual correction methods are proposed. The efficiency and accuracy of the proposed methods are demonstrated for multi-frequency model problems.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们开发了基于神经网络的几频解方法，用于解决带几频解的几频偏微分方程。神经网络方法在解决这类问题时具有优势，因为它们不受偏微分方程的形式或问题域的形状或维度的限制。当应用于具有多频解的问题时，神经网络方法的性能和准确性受到带几频解的高频和低频部分的对比的影响。为解决这个问题，我们提出了域扩张和剩余修正方法。我们通过多种多样的模拟问题示出了提议的方法的效率和准确性。
</details></li>
</ul>
<hr>
<h2 id="Improved-weight-initialization-for-deep-and-narrow-feedforward-neural-network"><a href="#Improved-weight-initialization-for-deep-and-narrow-feedforward-neural-network" class="headerlink" title="Improved weight initialization for deep and narrow feedforward neural network"></a>Improved weight initialization for deep and narrow feedforward neural network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03733">http://arxiv.org/abs/2311.03733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunwoo Lee, Yunho Kim, Seungyeop Yang, Hayoung Choi</li>
<li>for: 解决深度神经网络训练中ReLU活化函数导致神经元死亡的问题。</li>
<li>methods: 提出了一种新的初始 веса方法，并证明了该方法的初始 веса矩阵的性质，以便有效地传递信号 вектор。</li>
<li>results: 通过一系列实验和比较 existed 方法，证明了新 initialization 方法的效果。<details>
<summary>Abstract</summary>
Appropriate weight initialization settings, along with the ReLU activation function, have been a cornerstone of modern deep learning, making it possible to train and deploy highly effective and efficient neural network models across diverse artificial intelligence. The problem of dying ReLU, where ReLU neurons become inactive and yield zero output, presents a significant challenge in the training of deep neural networks with ReLU activation function. Theoretical research and various methods have been introduced to address the problem. However, even with these methods and research, training remains challenging for extremely deep and narrow feedforward networks with ReLU activation function. In this paper, we propose a new weight initialization method to address this issue. We prove the properties of the proposed initial weight matrix and demonstrate how these properties facilitate the effective propagation of signal vectors. Through a series of experiments and comparisons with existing methods, we demonstrate the effectiveness of the new initialization method.
</details>
<details>
<summary>摘要</summary>
modern深度学习中的重要基础之一是适当的初始化设定和ReLU活化函数，使得可以训练和部署高效和高效的神经网络模型。ReLU神经元死亡问题在深度神经网络训练中存在 significannot challenge。有许多理论研究和方法被提出来解决这个问题，但是even with these methods and research, training still remains challenging for extremely deep and narrow feedforward networks with ReLU activation function.在这篇论文中，我们提出了一种新的初始化方法来解决这个问题。我们证明了提案的初始 вес矩阵的属性，并示出这些属性使得信号 вектор的效果propagation。通过一系列实验和现有方法的比较，我们证明了新初始化方法的效果。
</details></li>
</ul>
<hr>
<h2 id="Pipeline-Parallelism-for-DNN-Inference-with-Practical-Performance-Guarantees"><a href="#Pipeline-Parallelism-for-DNN-Inference-with-Practical-Performance-Guarantees" class="headerlink" title="Pipeline Parallelism for DNN Inference with Practical Performance Guarantees"></a>Pipeline Parallelism for DNN Inference with Practical Performance Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03703">http://arxiv.org/abs/2311.03703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaron Archer, Matthew Fahrbach, Kuikui Liu, Prakash Prabhu</li>
<li>for: 提高深度神经网络（DNN）推理的管道并行处理效率，通过将模型图分割为 $k$ 个阶段并最小化瓶颈阶段的运行时间，包括通信。</li>
<li>methods: 提出实用的算法解决这个NP困难问题，并通过对于生产数据进行评估，显示这些算法在实践中几乎是优化的。还使用了新的混合整数程序（MIP）形式来获得更强的下界。</li>
<li>results: 通过应用这些算法和下界方法，在生产模型中实现了较大的近似保证比，比如在 $k&#x3D;16$ 个管道阶段下，通过几何平均值来评估，提高了下界的两倍多，从 $2.175$ 提高到 $1.058$。这种研究表明，虽然最大吞吐量分配是理论上困难，但在实践中，我们已经有了对算法问题的控制，主要是开发更加准确的成本模型，以便将其 feed 到分配算法中。<details>
<summary>Abstract</summary>
We optimize pipeline parallelism for deep neural network (DNN) inference by partitioning model graphs into $k$ stages and minimizing the running time of the bottleneck stage, including communication. We design practical algorithms for this NP-hard problem and show that they are nearly optimal in practice by comparing against strong lower bounds obtained via novel mixed-integer programming (MIP) formulations. We apply these algorithms and lower-bound methods to production models to achieve substantially improved approximation guarantees compared to standard combinatorial lower bounds. For example, evaluated via geometric means across production data with $k=16$ pipeline stages, our MIP formulations more than double the lower bounds, improving the approximation ratio from $2.175$ to $1.058$. This work shows that while max-throughput partitioning is theoretically hard, we have a handle on the algorithmic side of the problem in practice and much of the remaining challenge is in developing more accurate cost models to feed into the partitioning algorithms.
</details>
<details>
<summary>摘要</summary>
我们优化深度神经网络（DNN）推断的管线并行性，通过分解模型图到$k$个阶段，最小化瓶须时间，包括交互时间。我们设计了实用的算法来解决这个NP困难的问题，并证明它们在实践中几乎是最佳的。我们使用这些算法和新的混合整数程式（MIP）表示法来与生产模型进行比较，实现了明显改善的近似保证比率。例如，通过考虑生产数据中的$k=16$个管线阶段，我们的MIP表示法可以超过标准的 combinatorial 下界，从$2.175$提高到$1.058$。这个工作显示，处理器的最大运行速率分配是理论上困难的，但在实践中，我们已经掌握了算法的一个 Handle ，而主要的挑战在于发展更准确的成本模型，以便将其输入到分配算法中。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Non-monotone-Submodular-Maximization"><a href="#Dynamic-Non-monotone-Submodular-Maximization" class="headerlink" title="Dynamic Non-monotone Submodular Maximization"></a>Dynamic Non-monotone Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03685">http://arxiv.org/abs/2311.03685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiarash Banihashem, Leyla Biabani, Samira Goudarzi, MohammadTaghi Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh</li>
<li>for: 本研究旨在提出动态算法来解决非升序子模杂函数最大化问题。</li>
<li>methods: 作者使用了减少函数的技术来解决本问题，并提出了一种基于减少函数的动态算法。</li>
<li>results: 作者通过一种减少函数的转化，实现了解决非升序子模杂函数最大化问题的动态算法，并且可以保证算法的精度在8加eps的级别。<details>
<summary>Abstract</summary>
Maximizing submodular functions has been increasingly used in many applications of machine learning, such as data summarization, recommendation systems, and feature selection. Moreover, there has been a growing interest in both submodular maximization and dynamic algorithms. In 2020, Monemizadeh and Lattanzi, Mitrovic, Norouzi{-}Fard, Tarnawski, and Zadimoghaddam initiated developing dynamic algorithms for the monotone submodular maximization problem under the cardinality constraint $k$. Recently, there have been some improvements on the topic made by Banihashem, Biabani, Goudarzi, Hajiaghayi, Jabbarzade, and Monemizadeh. In 2022, Chen and Peng studied the complexity of this problem and raised an important open question: "Can we extend [fully dynamic] results (algorithm or hardness) to non-monotone submodular maximization?". We affirmatively answer their question by demonstrating a reduction from maximizing a non-monotone submodular function under the cardinality constraint $k$ to maximizing a monotone submodular function under the same constraint. Through this reduction, we obtain the first dynamic algorithms to solve the non-monotone submodular maximization problem under the cardinality constraint $k$. Our algorithms maintain an $(8+\epsilon)$-approximate of the solution and use expected amortized $O(\epsilon^{-3}k^3\log^3(n)\log(k))$ or $O(\epsilon^{-1}k^2\log^3(k))$ oracle queries per update, respectively. Furthermore, we showcase the benefits of our dynamic algorithm for video summarization and max-cut problems on several real-world data sets.
</details>
<details>
<summary>摘要</summary>
Maximizing submodular functions has been increasingly used in many machine learning applications, such as data summarization, recommendation systems, and feature selection. In addition, there has been growing interest in both submodular maximization and dynamic algorithms. In 2020, Monemizadeh and Lattanzi, Mitrovic, Norouzi-Fard, Tarnawski, and Zadimoghaddam began developing dynamic algorithms for the monotone submodular maximization problem under the cardinality constraint $k$. Recently, there have been some improvements on the topic made by Banihashem, Biabani, Goudarzi, Hajiaghayi, Jabbarzade, and Monemizadeh. In 2022, Chen and Peng studied the complexity of this problem and raised an important open question: "Can we extend [fully dynamic] results (algorithm or hardness) to non-monotone submodular maximization?" We answer their question affirmatively by demonstrating a reduction from maximizing a non-monotone submodular function under the cardinality constraint $k$ to maximizing a monotone submodular function under the same constraint. Through this reduction, we obtain the first dynamic algorithms to solve the non-monotone submodular maximization problem under the cardinality constraint $k$. Our algorithms achieve an $(8+\epsilon)$-approximation of the solution and use expected amortized $O(\epsilon^{-3}k^3\log^3(n)\log(k))$ or $O(\epsilon^{-1}k^2\log^3(k))$ oracle queries per update, respectively. Furthermore, we demonstrate the benefits of our dynamic algorithm for video summarization and max-cut problems on several real-world data sets.
</details></li>
</ul>
<hr>
<h2 id="Preventing-Arbitrarily-High-Confidence-on-Far-Away-Data-in-Point-Estimated-Discriminative-Neural-Networks"><a href="#Preventing-Arbitrarily-High-Confidence-on-Far-Away-Data-in-Point-Estimated-Discriminative-Neural-Networks" class="headerlink" title="Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks"></a>Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03683">http://arxiv.org/abs/2311.03683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Rashid, Serena Hacker, Guojun Zhang, Agustinus Kristiadi, Pascal Poupart</li>
<li>for: 这个论文旨在解决过去的数据分类问题中的过度自信问题，使用添加一个类别的条件函数来避免这个问题。</li>
<li>methods: 本文使用了一种简单的条件函数来让神经网络在训练时具有适当的自信水平，并且不需要更改现有的训练方法。</li>
<li>results: 本文的实验结果显示，这种技巧可以强制神经网络在训练和测试时具有更好的自信水平，并且在不同的benchmark测试中都有出色的表现。<details>
<summary>Abstract</summary>
Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks -- a popular class of neural network architectures -- have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data.This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance against competitive baselines on both far-away and realistic OOD data.
</details>
<details>
<summary>摘要</summary>
deterministic神经网络在分类问题上是实际选择。然而，它们在不同领域测试集上表现出状态的最佳结果，但它们往往对不同领域测试集数据进行过于自信。例如，ReLU网络——一种流行的神经网络体系——在测试数据远离训练集时总是给出高自信度预测，即使它们在训练集上使用不同领域测试集数据。我们解决这个问题的方法是添加神经网络输出的一个项目，该项目对应于一个额外的类别的логи值，我们设计其在测试数据远离训练集时dominate其他类别的LOGIT。这种技术可以证明地防止不可预期的高自信度在远离训练集的测试数据上，而不需要复杂的权重学习或泛化学习。我们在不同的benchmark上进行评估，并证明了与竞争对手的基准值在不同的OOD数据上具有强大的表现。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Networks-for-Power-Grid-Operational-Risk-Assessment"><a href="#Graph-Neural-Networks-for-Power-Grid-Operational-Risk-Assessment" class="headerlink" title="Graph Neural Networks for Power Grid Operational Risk Assessment"></a>Graph Neural Networks for Power Grid Operational Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03661">http://arxiv.org/abs/2311.03661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yadong Zhang, Pranav M Karve, Sankaran Mahadevan</li>
<li>for:  investigate the utility of graph neural network (GNN) surrogates for Monte Carlo (MC) sampling-based risk quantification in daily operations of power grid</li>
<li>methods: train GNN surrogates using supervised learning to obtain Monte Carlo samples of the quantities of interest (operating reserve, transmission line flow) given the (hours-ahead) probabilistic wind generation and load forecast</li>
<li>results: GNN surrogates are sufficiently accurate for predicting the (bus-level, branch-level and system-level) grid state and enable fast as well as accurate operational risk quantification for power gridsHere’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope that helps!<details>
<summary>Abstract</summary>
In this article, the utility of graph neural network (GNN) surrogates for Monte Carlo (MC) sampling-based risk quantification in daily operations of power grid is investigated. The MC simulation process necessitates solving a large number of optimal power flow (OPF) problems corresponding to the sample values of stochastic grid variables (power demand and renewable generation), which is computationally prohibitive. Computationally inexpensive surrogates of the OPF problem provide an attractive alternative for expedited MC simulation. GNN surrogates are especially suitable due to their superior ability to handle graph-structured data. Therefore, GNN surrogates of OPF problem are trained using supervised learning. They are then used to obtain Monte Carlo (MC) samples of the quantities of interest (operating reserve, transmission line flow) given the (hours-ahead) probabilistic wind generation and load forecast. The utility of GNN surrogates is evaluated by comparing OPF-based and GNN-based grid reliability and risk for IEEE Case118 synthetic grid. It is shown that the GNN surrogates are sufficiently accurate for predicting the (bus-level, branch-level and system-level) grid state and enable fast as well as accurate operational risk quantification for power grids. The article thus develops various tools for fast reliability and risk quantification for real-world power grids using GNNs.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们调查了图型神经网络（GNN）伪函数的应用于随机产生 Monte Carlo（MC）样本基础的电力网络风险评估。MC仿真过程需要解决大量的优化电力流（OPF）问题，这是计算昂贵的。使用计算成本低的GNN伪函数提供了一个有利的选择，以促进MC仿真。GNN伪函数特别适用于处理图结构数据，因此通过直接supervised学习来训练GNN伪函数。然后，GNN伪函数被用来在(时间前) probabilistic风力发电和需求预测基础上获得MC样本中的量据（运行储备、电力传送）。GNN伪函数的使用效果被评估通过比较OPF基础和GNN基础上的电力网络可靠性和风险。结果显示，GNN伪函数具有足够的准确性，可以预测(电气站级、电力线级和系统级)电力网络状态，并且可以快速并准确地进行操作风险评估。文章因此开发了基于GNN的快速可靠性和风险评估工具，以便应用于实际电力网络。
</details></li>
</ul>
<hr>
<h2 id="A-Physics-Guided-Bi-Fidelity-Fourier-Featured-Operator-Learning-Framework-for-Predicting-Time-Evolution-of-Drag-and-Lift-Coefficients"><a href="#A-Physics-Guided-Bi-Fidelity-Fourier-Featured-Operator-Learning-Framework-for-Predicting-Time-Evolution-of-Drag-and-Lift-Coefficients" class="headerlink" title="A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning Framework for Predicting Time Evolution of Drag and Lift Coefficients"></a>A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning Framework for Predicting Time Evolution of Drag and Lift Coefficients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03639">http://arxiv.org/abs/2311.03639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Mollaali, Izzet Sahin, Iqrar Raza, Christian Moya, Guillermo Paniagua, Guang Lin</li>
<li>For: 提高计算效率，减少计算资源，实现高精度结果。* Methods: 使用深度学习网络，组合低精度和高精度数据，充分利用低精度数据的优势，并通过物理指导和傅里叶特征网络进行提升。* Results: 实验结果表明，physics-guided Fourier-featured deep operator network具有更高的预测精度，并且可以减少计算资源。<details>
<summary>Abstract</summary>
In the pursuit of accurate experimental and computational data while minimizing effort, there is a constant need for high-fidelity results. However, achieving such results often requires significant computational resources. To address this challenge, this paper proposes a deep operator learning-based framework that requires a limited high-fidelity dataset for training. We introduce a novel physics-guided, bi-fidelity, Fourier-featured Deep Operator Network (DeepONet) framework that effectively combines low and high-fidelity datasets, leveraging the strengths of each. In our methodology, we began by designing a physics-guided Fourier-featured DeepONet, drawing inspiration from the intrinsic physical behavior of the target solution. Subsequently, we train this network to primarily learn the low-fidelity solution, utilizing an extensive dataset. This process ensures a comprehensive grasp of the foundational solution patterns. Following this foundational learning, the low-fidelity deep operator network's output is enhanced using a physics-guided Fourier-featured residual deep operator network. This network refines the initial low-fidelity output, achieving the high-fidelity solution by employing a small high-fidelity dataset for training. Notably, in our framework, we employ the Fourier feature network as the Trunk network for the DeepONets, given its proficiency in capturing and learning the oscillatory nature of the target solution with high precision. We validate our approach using a well-known 2D benchmark cylinder problem, which aims to predict the time trajectories of lift and drag coefficients. The results highlight that the physics-guided Fourier-featured deep operator network, serving as a foundational building block of our framework, possesses superior predictive capability for the lift and drag coefficients compared to its data-driven counterparts.
</details>
<details>
<summary>摘要</summary>
在寻求准确的实验和计算数据的同时最小化努力的过程中，需要高精度的结果。然而，获得这些结果frequently需要显著的计算资源。为解决这个挑战，这篇文章提出了一个基于深度学习的深度运算网络（DeepONet）框架，只需要一小量高精度数据进行训练。我们提出了一种新的物理导向的、双精度的、傅里埃特征的深度运算网络（DeepONet）框架，可以有效地结合低精度和高精度数据，利用每个数据集的优点。在我们的方法中，我们首先设计了物理导向的傅里埃特征的深度运算网络， drawing inspiration from the intrinsic physical behavior of the target solution。然后，我们通过一个广泛的数据集来训练这个网络，以主要学习低精度解。这个过程确保了我们对基础解决方案的全面的掌握。接着，我们使用物理导向的傅里埃特征的深度运算网络来进一步加强低精度深度运算网络的输出，以实现高精度解。在我们的框架中，我们利用傅里埃特网络作为深度运算网络的核心网络，因为它能够高精度地捕捉和学习目标解的oscillatory nature。我们验证了我们的方法使用一个well-known 2D benchmark cylinder problem，该问题的目标是预测缝翼和推力强度的时间轨迹。结果显示，物理导向的傅里埃特特征的深度运算网络，作为我们框架的基础建筑块，在预测缝翼和推力强度方面具有更高的预测能力，相比于其数据驱动的对手。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Data-Augmentation-with-Contrastive-Learning"><a href="#Counterfactual-Data-Augmentation-with-Contrastive-Learning" class="headerlink" title="Counterfactual Data Augmentation with Contrastive Learning"></a>Counterfactual Data Augmentation with Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03630">http://arxiv.org/abs/2311.03630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Aloui, Juncheng Dong, Cat P. Le, Vahid Tarokh</li>
<li>for: 这篇论文的目的是提出一种model-agnostic data augmentation方法，用于改善 conditional average treatment effect（CATE）估计中的statistical disparity问题。</li>
<li>methods: 这篇论文使用contrastive learning方法来学习一个代表空间和一个相似度量，以便将近似的个体（即来自不同治疗群的对照群个体）的潜在结果预测为可靠。</li>
<li>results: 论文的实验研究表明，这种方法可以对CATE估计模型增加 significiant improvement in both performance和防止过滤溢loss，并且在实际应用中具有良好的适用性。<details>
<summary>Abstract</summary>
Statistical disparity between distinct treatment groups is one of the most significant challenges for estimating Conditional Average Treatment Effects (CATE). To address this, we introduce a model-agnostic data augmentation method that imputes the counterfactual outcomes for a selected subset of individuals. Specifically, we utilize contrastive learning to learn a representation space and a similarity measure such that in the learned representation space close individuals identified by the learned similarity measure have similar potential outcomes. This property ensures reliable imputation of counterfactual outcomes for the individuals with close neighbors from the alternative treatment group. By augmenting the original dataset with these reliable imputations, we can effectively reduce the discrepancy between different treatment groups, while inducing minimal imputation error. The augmented dataset is subsequently employed to train CATE estimation models. Theoretical analysis and experimental studies on synthetic and semi-synthetic benchmarks demonstrate that our method achieves significant improvements in both performance and robustness to overfitting across state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
“统计差异 между不同治疗组是估计 Conditional Average Treatment Effects (CATE) 中最大的挑战。为解决这个问题，我们提出了一种模型无关的数据扩充方法，该方法在选择的一 subset of individuals 中进行了归一化。specifically, we utilize contrastive learning to learn a representation space and a similarity measure, such that in the learned representation space, close individuals identified by the learned similarity measure have similar potential outcomes. This property ensures reliable imputation of counterfactual outcomes for the individuals with close neighbors from the alternative treatment group. By augmenting the original dataset with these reliable imputations, we can effectively reduce the discrepancy between different treatment groups, while inducing minimal imputation error. The augmented dataset is subsequently employed to train CATE estimation models. theoretical analysis and experimental studies on synthetic and semi-synthetic benchmarks demonstrate that our method achieves significant improvements in both performance and robustness to overfitting across state-of-the-art models.”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Are-Words-Enough-On-the-semantic-conditioning-of-affective-music-generation"><a href="#Are-Words-Enough-On-the-semantic-conditioning-of-affective-music-generation" class="headerlink" title="Are Words Enough? On the semantic conditioning of affective music generation"></a>Are Words Enough? On the semantic conditioning of affective music generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03624">http://arxiv.org/abs/2311.03624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorge Forero, Gilberto Bernardes, Mónica Mendes</li>
<li>for: 本研究的目的是分析和讨论自动生成音乐中的情感表达方法。</li>
<li>methods: 本研究涉及了两种主要的方法：规则驱动的模型和深度学习模型。深度学习模型可以自动生成高质量的音乐从文本描述中。</li>
<li>results: 研究发现，使用深度学习与自然语言结合可以为创作业界提供强大的工具，以便提示和生成新的音乐作品。<details>
<summary>Abstract</summary>
Music has been commonly recognized as a means of expressing emotions. In this sense, an intense debate emerges from the need to verbalize musical emotions. This concern seems highly relevant today, considering the exponential growth of natural language processing using deep learning models where it is possible to prompt semantic propositions to generate music automatically. This scoping review aims to analyze and discuss the possibilities of music generation conditioned by emotions. To address this topic, we propose a historical perspective that encompasses the different disciplines and methods contributing to this topic. In detail, we review two main paradigms adopted in automatic music generation: rules-based and machine-learning models. Of note are the deep learning architectures that aim to generate high-fidelity music from textual descriptions. These models raise fundamental questions about the expressivity of music, including whether emotions can be represented with words or expressed through them. We conclude that overcoming the limitation and ambiguity of language to express emotions through music, some of the use of deep learning with natural language has the potential to impact the creative industries by providing powerful tools to prompt and generate new musical works.
</details>
<details>
<summary>摘要</summary>
音乐已被广泛认为是表达情感的手段。在这意义上，有一场激烈的辩论，即如何用语言表达音乐中的情感。这个问题在今天更加有 relevance，因为深度学习模型的批处理能力在自动生成音乐方面得到了极大的提高。本综述的目的是分析和讨论情感决定自动生成音乐的可能性。为此，我们提出了历史背景，涵盖了不同领域和方法对这个话题的贡献。在详细介绍中，我们评论了两种主要的自动音乐生成方法：规则based和机器学习模型。特别是深度学习架构，可以生成高质量的音乐从文本描述。这些模型提出了音乐表达性的基本问题，包括情感是否可以通过语言表达，或者是通过语言表达出来的。我们认为，通过深度学习与自然语言的结合，可以超越语言表达情感的限制和歧义，对创作业场产生强大的影响，提供 poderful工具来促进和生成新的音乐作品。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Latent-Spaces-of-Tonal-Music-using-Variational-Autoencoders"><a href="#Exploring-Latent-Spaces-of-Tonal-Music-using-Variational-Autoencoders" class="headerlink" title="Exploring Latent Spaces of Tonal Music using Variational Autoencoders"></a>Exploring Latent Spaces of Tonal Music using Variational Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03621">http://arxiv.org/abs/2311.03621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NadiaCarvalho/Latent-Tonal-Music">https://github.com/NadiaCarvalho/Latent-Tonal-Music</a></li>
<li>paper_authors: Nádia Carvalho, Gilberto Bernardes</li>
<li>for: 这个论文的目的是使用变形自动编码器（VAEs）模型生成含有听觉和semantic值的秘密表示。</li>
<li>methods: 这个论文使用了多种VAEs编码方法，包括钢琴滚珍、MIDI、ABC、 Tonnetz、振荡函数等。</li>
<li>results: 研究发现，使用ABC编码方法可以最好地重建原始数据，而振荡函数编码方法可以从秘密空间中提取更多的信息。此外，研究还发现，使用12个主或副调谱的对比可以量化每个键的听觉空间之间的对应关系，并且发现这些关系与认知的折衔空间之间存在着明确的对应关系。<details>
<summary>Abstract</summary>
Variational Autoencoders (VAEs) have proven to be effective models for producing latent representations of cognitive and semantic value. We assess the degree to which VAEs trained on a prototypical tonal music corpus of 371 Bach's chorales define latent spaces representative of the circle of fifths and the hierarchical relation of each key component pitch as drawn in music cognition. In detail, we compare the latent space of different VAE corpus encodings -- Piano roll, MIDI, ABC, Tonnetz, DFT of pitch, and pitch class distributions -- in providing a pitch space for key relations that align with cognitive distances. We evaluate the model performance of these encodings using objective metrics to capture accuracy, mean square error (MSE), KL-divergence, and computational cost. The ABC encoding performs the best in reconstructing the original data, while the Pitch DFT seems to capture more information from the latent space. Furthermore, an objective evaluation of 12 major or minor transpositions per piece is adopted to quantify the alignment of 1) intra- and inter-segment distances per key and 2) the key distances to cognitive pitch spaces. Our results show that Pitch DFT VAE latent spaces align best with cognitive spaces and provide a common-tone space where overlapping objects within a key are fuzzy clusters, which impose a well-defined order of structural significance or stability -- i.e., a tonal hierarchy. Tonal hierarchies of different keys can be used to measure key distances and the relationships of their in-key components at multiple hierarchies (e.g., notes and chords). The implementation of our VAE and the encodings framework are made available online.
</details>
<details>
<summary>摘要</summary>
Variational Autoencoders (VAEs) 已经证明是有效的模型，用于生成含义和语义价值的潜在表示。我们评估了 Vaes 在 Bach chorales 批处理的词汇桶中定义的潜在空间是否与圆形五度和每个键Component折射的层次关系相align。在详细的描述中，我们比较了不同的 Vaes 桶编码 -- Piano Roll、MIDI、ABC、 Tonnetz、DFT 折射和折射分布 -- 在提供一个折射空间来支持键关系的层次结构是否与认知距离相align。我们使用对象 metric 评估这些编码的表现，包括准确率、平方差误差（MSE）、KL散度和计算成本。ABC 编码表现最好地重建原始数据，而 Pitch DFT 则在潜在空间中捕捉更多信息。此外，我们采用对象评估方法，对每个键中的 12 个主或调谱进行12个主或调谱的转换，以衡量每个键之间的距离和认知折射空间之间的对应关系。我们的结果表明，Pitch DFT VAE 潜在空间最好地与认知空间对align，提供了一个通用频谱，在这里，每个键的内部对象在一个共同频谱中具有杂散的团集结构，这种结构具有明确的顺序或稳定性 -- i.e., tonal hierarchy。不同键的折射层次可以用来测量键之间的距离和各个键中的结构重要性。我们的 VAE 和编码框架在线上进行实现。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.LG_2023_11_07/" data-id="cloqtaeuy00t7gh882ylfd86k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/07/cs.CL_2023_11_07/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CL - 2023-11-07
        
      </div>
    </a>
  
  
    <a href="/2023/11/07/eess.IV_2023_11_07/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.IV - 2023-11-07</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
