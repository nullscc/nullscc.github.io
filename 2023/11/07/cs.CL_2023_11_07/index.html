
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-11-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04199 repo_url: None paper_authors: Peilin Zhou, Meng Cao, You-Liang Huang, Qichen">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-11-07">
<meta property="og:url" content="https://nullscc.github.io/2023/11/07/cs.CL_2023_11_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04199 repo_url: None paper_authors: Peilin Zhou, Meng Cao, You-Liang Huang, Qichen">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-07T11:00:00.000Z">
<meta property="article:modified_time" content="2023-11-08T18:37:32.207Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.CL_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T11:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-11-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Exploring-Recommendation-Capabilities-of-GPT-4V-ision-A-Preliminary-Case-Study"><a href="#Exploring-Recommendation-Capabilities-of-GPT-4V-ision-A-Preliminary-Case-Study" class="headerlink" title="Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study"></a>Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04199">http://arxiv.org/abs/2311.04199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peilin Zhou, Meng Cao, You-Liang Huang, Qichen Ye, Peiyan Zhang, Junling Liu, Yueqi Xie, Yining Hua, Jaeboum Kim</li>
<li>for: 这研究旨在探索使用OpenAI发布的GPT-4V大型多Modal模型（LMMs）在推荐任务中的应用潜力。</li>
<li>methods: 我们使用了一系列质量测试样本，来评估GPT-4V在推荐场景中的回答质量。</li>
<li>results: 我们发现GPT-4V在多个领域的推荐任务中表现出色，归功于它的视觉文本理解能力和广泛的通用知识。但我们还发现GPT-4V在推荐任务中存在一些局限性，如给定相似输入时提供相似的回答。<details>
<summary>Abstract</summary>
Large Multimodal Models (LMMs) have demonstrated impressive performance across various vision and language tasks, yet their potential applications in recommendation tasks with visual assistance remain unexplored. To bridge this gap, we present a preliminary case study investigating the recommendation capabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a series of qualitative test samples spanning multiple domains and employ these samples to assess the quality of GPT-4V's responses within recommendation scenarios. Evaluation results on these test samples prove that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains, thanks to its robust visual-text comprehension capabilities and extensive general knowledge. However, we have also identified some limitations in using GPT-4V for recommendations, including a tendency to provide similar responses when given similar inputs. This report concludes with an in-depth discussion of the challenges and research opportunities associated with utilizing GPT-4V in recommendation scenarios. Our objective is to explore the potential of extending LMMs from vision and language tasks to recommendation tasks. We hope to inspire further research into next-generation multimodal generative recommendation models, which can enhance user experiences by offering greater diversity and interactivity. All images and prompts used in this report will be accessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.
</details>
<details>
<summary>摘要</summary>
大型多Modal模型（LMM）已经在视觉和语言任务上表现出色，但它们在推荐任务中的应用前景尚未得到探索。为了填补这个空白，我们提出了一项初步的案例研究，检查GPT-4V（ison），一个最近发布的LMM，在推荐任务中的表现。我们构建了多个qualitative测试样本，覆盖多个领域，并使用这些样本来评估GPT-4V在推荐场景中的回答质量。eval结果表明，GPT-4V在多个领域的零批 recommendation能力非常出色，归功于它的强大的视觉文本理解能力和广泛的通用知识。然而，我们还发现了使用GPT-4V进行推荐时的一些局限性，包括对输入相似的回答倾向于相似。本报告结束于对使用GPT-4V进行推荐的挑战和研究机遇的深入讨论。我们的目标是探索如何扩展LMM从视觉和语言任务到推荐任务，以提高用户体验，并且提供更多的多样性和互动性。所有图像和提示用于这份报告将在GitHub上公开，请参考https://github.com/PALIN2018/Evaluate_GPT-4V_Rec。
</details></li>
</ul>
<hr>
<h2 id="JaSPICE-Automatic-Evaluation-Metric-Using-Predicate-Argument-Structures-for-Image-Captioning-Models"><a href="#JaSPICE-Automatic-Evaluation-Metric-Using-Predicate-Argument-Structures-for-Image-Captioning-Models" class="headerlink" title="JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models"></a>JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04192">http://arxiv.org/abs/2311.04192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/keio-smilab23/JaSPICE">https://github.com/keio-smilab23/JaSPICE</a></li>
<li>paper_authors: Yuiga Wada, Kanta Kaneda, Komei Sugiura</li>
<li>for: 本研究旨在提出一种用于评估日语描述文本的自动评价指标，以提高现有的自动评价指标的准确性。</li>
<li>methods: 本研究使用了依赖关系和 predicate-argument 结构生成场景图，并使用同义词扩展图。</li>
<li>results: 我们在使用 STAIR Captions 和 PFN-PIC 进行训练的 10 个图像描述模型上进行了实验，并构建了 Shichimi 数据集，其包含 103,170 个人评估。结果表明，我们的指标在与人类评估的相关系数上表现出了优异性。<details>
<summary>Abstract</summary>
Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR. However, such n-gram-based metrics have been shown to correlate poorly with human evaluation, leading to the proposal of alternative metrics such as SPICE for English; however, no equivalent metrics have been established for other languages. Therefore, in this study, we propose an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs. The proposed method generates a scene graph from dependencies and the predicate-argument structure, and extends the graph using synonyms. We conducted experiments employing 10 image captioning models trained on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which contains 103,170 human evaluations. The results showed that our metric outperformed the baseline metrics for the correlation coefficient with the human evaluation.
</details>
<details>
<summary>摘要</summary>
研究者强调图像描述学 heavily rely 于自动评估指标，如 BLEU 和 METEOR。但是，这些 n-gram 基的指标与人工评估相关性很差，导致提出了替代指标，如 SPICE  для英语。然而，其他语言没有相应的指标。因此，在这种研究中，我们提议一种自动评估指标，即 JaSPICE，该指标基于场景图和依赖关系。我们的方法从依赖关系和 predicate-argument 结构中生成场景图，并使用同义词扩展图。我们在 STAIR Captions 和 PFN-PIC 上训练了 10 个图像描述模型，并建立了 Shichimi 数据集，该数据集包含 103,170 个人工评估。结果表明，我们的指标在人工评估相关性方面与基准指标相比，表现出了更高的拟合度。
</details></li>
</ul>
<hr>
<h2 id="SpaDeLeF-A-Dataset-for-Hierarchical-Classification-of-Lexical-Functions-for-Collocations-in-Spanish"><a href="#SpaDeLeF-A-Dataset-for-Hierarchical-Classification-of-Lexical-Functions-for-Collocations-in-Spanish" class="headerlink" title="SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish"></a>SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04189">http://arxiv.org/abs/2311.04189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yevhen Kostiuk, Grigori Sidorov, Olga Kolesnikova</li>
<li>For:  This paper presents a dataset of Spanish verb-noun collocations and their corresponding lexical functions, aiming to support the development of language models for hierarchical classification of lexical functions.* Methods: The dataset was created by dependency tree parsing and matching of phrases in Spanish news, and each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task.* Results: The paper introduces classification objectives for each level of the structure and provides baselines and data splits for each objective, aiming to support the development of effective language models for Spanish text.<details>
<summary>Abstract</summary>
In natural language processing (NLP), lexical function is a concept to unambiguously represent semantic and syntactic features of words and phrases in text first crafted in the Meaning-Text Theory. Hierarchical classification of lexical functions involves organizing these features into a tree-like hierarchy of categories or labels. This is a challenging task as it requires a good understanding of the context and the relationships among words and phrases in text. It also needs large amounts of labeled data to train language models effectively. In this paper, we present a dataset of most frequent Spanish verb-noun collocations and sentences where they occur, each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task. Each class represents a relation between the noun and the verb in a collocation involving their semantic and syntactic features. We combine the classes in a tree-based structure, and introduce classification objectives for each level of the structure. The dataset was created by dependency tree parsing and matching of the phrases in Spanish news. We provide baselines and data splits for each objective.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）中， lexical function 是一个概念，用于不同性和语法特征的词和短语在文本中的无ambiguity 表示。 hierarchical classification of lexical functions 涉及将这些特征分类为一棵树状结构中的类别或标签。这是一项具有挑战性的任务，因为它需要对文本中词和短语之间的上下文和关系有好的理解，以及大量的标注数据来训练语言模型。在这篇论文中，我们提供了西班牙语动词-名词 collocation 的最常见集和它们在文本中出现的句子，每个 collocation 被分配到了 37 个定义的类型，每个类型表示在 collocation 中动词和名词之间的 semantic 和语法特征的关系。我们将这些类型组织成树状结构，并引入每级结构的分类目标。这些数据由西班牙语新闻中的依赖树分析和匹配短语而创建。我们提供了基线和数据分割 для每个目标。
</details></li>
</ul>
<hr>
<h2 id="Perturbed-examples-reveal-invariances-shared-by-language-models"><a href="#Perturbed-examples-reveal-invariances-shared-by-language-models" class="headerlink" title="Perturbed examples reveal invariances shared by language models"></a>Perturbed examples reveal invariances shared by language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04166">http://arxiv.org/abs/2311.04166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruchit Rawal, Mariya Toneva</li>
<li>for: 本研究旨在比较两种自然语言处理模型，以揭示它们共同具有可解释的输入扰动的共轭性。</li>
<li>methods: 本研究使用了一种新的框架，通过设计target Specific linguistic capability (例如，同义词替换、打印 typo 等)的可解释输入扰动，来评估两种模型的不同。</li>
<li>results: 经过多个实验，研究发现大语言模型具有许多共轭性，而这些共轭性只存在于其他大型模型中。这些结果表明，拥有多种共轭性可能是大语言模型的成功原因，并且本研究的框架可以帮助我们理解新模型中具有哪些共轭性。<details>
<summary>Abstract</summary>
An explosion of work in language is leading to ever-increasing numbers of available natural language processing models, with little understanding of how new models compare to better-understood models. One major reason for this difficulty is saturating benchmark datasets, which may not reflect well differences in model performance in the wild. In this work, we propose a novel framework for comparing two natural language processing models by revealing their shared invariance to interpretable input perturbations that are designed to target a specific linguistic capability (e.g., Synonym-Invariance, Typo-Invariance). Via experiments on models from within the same and across different architecture families, this framework offers a number of insights about how changes in models (e.g., distillation, increase in size, amount of pre-training) affect multiple well-defined linguistic capabilities. Furthermore, we also demonstrate how our framework can enable evaluation of the invariances shared between models that are available as commercial black-box APIs (e.g., InstructGPT family) and models that are relatively better understood (e.g., GPT-2). Across several experiments, we observe that large language models share many of the invariances encoded by models of various sizes, whereas the invariances encoded by large language models are only shared by other large models. Possessing a wide variety of invariances may be a key reason for the recent successes of large language models, and our framework can shed light on the types of invariances that are retained by or emerge in new models.
</details>
<details>
<summary>摘要</summary>
一些新的自然语言处理模型的出现导致了无止境的语言处理模型数量的增加，但是对于这些新模型的性能的理解却很困难。一个主要的原因是溢出的标准测试集，这些测试集可能不能准确反映模型在实际场景中的表现。在这项工作中，我们提出了一种新的比较 frameworks，可以揭示两个自然语言处理模型的共同不变量，这些不变量是通过设计targetspecific linguistic capability（例如，同义词不变量、 typos not varying）来实现的。通过对不同架构家族的模型进行实验，这个框架提供了许多有用的信息，包括如何改变模型（例如，缩小、增大模型大小、预训练）对多个明确定义的语言功能的影响。此外，我们还示出了如何使用我们的框架来评估黑盒API（例如，InstructGPT家族）和比较好理解的模型（例如，GPT-2）之间的共同不变量。在多个实验中，我们发现大语言模型共享许多共同不变量，而大模型的共同不变量只有大模型才能共享。拥有多种共同不变量可能是大语言模型的最近成功的关键原因，我们的框架可以揭示这些共同不变量是如何被新模型保留或 emerge。
</details></li>
</ul>
<hr>
<h2 id="Black-Box-Prompt-Optimization-Aligning-Large-Language-Models-without-Model-Training"><a href="#Black-Box-Prompt-Optimization-Aligning-Large-Language-Models-without-Model-Training" class="headerlink" title="Black-Box Prompt Optimization: Aligning Large Language Models without Model Training"></a>Black-Box Prompt Optimization: Aligning Large Language Models without Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04155">http://arxiv.org/abs/2311.04155</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-coai/bpo">https://github.com/thu-coai/bpo</a></li>
<li>paper_authors: Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang</li>
<li>for: 提高大语言模型（LLM）的用户指令遵循率，不需要更改LLM的参数。</li>
<li>methods: 使用黑盒提示优化（BPO）方法，通过优化用户提示来使LLM更好地理解用户的意图。</li>
<li>results: BPO可以提高ChatGPT的赢利率22%，并且可以超过PPO和DPO等方法所带来的性能提升。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem. To make LLMs better follow user instructions, existing alignment methods mostly focus on further training them. However, the extra training of LLMs are usually expensive in terms of GPU compute; worse still, LLMs of interest are oftentimes not accessible for user-demanded training, such as GPTs. In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments. The idea is to optimize user prompts to suit LLMs' input understanding, so as to best realize users' intents without updating LLMs' parameters. BPO is model-agnostic and the empirical results demonstrate that the BPO-aligned ChatGPT yields a 22\% increase in the win rate against its original version, and 10\% for GPT-4. Importantly, the \model-aligned LLMs can outperform the same models aligned by PPO and DPO, and it also brings additional performance gains when combining \model with PPO or DPO. Code and datasets are released at https://github.com/thu-coai/BPO.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）在各种应用场景中表现出色，但它们常不具备人类意图的含义，这引起了对它们的调整问题。为使LLM更好地遵从用户的指令，现有的准确方法主要是进一步训练它们。然而，这些额外训练通常需要大量的GPU计算资源，而且LLM对用户需求的训练不可达，如GPT。在这项工作中，我们采用了一种不同的视角——黑盒子提示优化（BPO）——来实现对 LLM 的调整。我们的想法是，通过优化用户的提示，使LLM更好地理解输入，以实现用户的意图，无需更新 LLM 的参数。BPO 是无关模型的，并且我们的实验结果表明，BPO 对适配的 ChatGPT 可以提高胜率达22%，而对 GPT-4 的提高为10%。此外，我们发现，使用 BPO 对 LLM 进行适配，可以超越使用 PPO 和 DPO 进行适配的同样模型，并且在组合 BPO 和 PPO 或 DPO 时，带来额外的性能提升。我们在 GitHub 上公开了代码和数据集，请参考 https://github.com/thu-coai/BPO。
</details></li>
</ul>
<hr>
<h2 id="What-is-Lost-in-Knowledge-Distillation"><a href="#What-is-Lost-in-Knowledge-Distillation" class="headerlink" title="What is Lost in Knowledge Distillation?"></a>What is Lost in Knowledge Distillation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04142">http://arxiv.org/abs/2311.04142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manas Mohanty, Tanya Roosta, Peyman Passban</li>
<li>for: 本研究旨在investigate知识塑化（KD）过程中是否存在信息损失，以及这些损失是否按照特定的模式发生。</li>
<li>methods: 本研究使用了知识塑化技术，以减少深度神经网络（DNNs）的训练和维护成本。</li>
<li>results: 本研究发现，知识塑化过程中的信息损失可以按照特定的模式进行分类，并且不同任务的敏感度异常大。这些结果可以帮助选择合适的配置，以实现最佳的信息传递between大型（教师）和小型（学生）模型。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have improved NLP tasks significantly, but training and maintaining such networks could be costly. Model compression techniques, such as, knowledge distillation (KD), have been proposed to address the issue; however, the compression process could be lossy. Motivated by this, our work investigates how a distilled student model differs from its teacher, if the distillation process causes any information losses, and if the loss follows a specific pattern. Our experiments aim to shed light on the type of tasks might be less or more sensitive to KD by reporting data points on the contribution of different factors, such as the number of layers or attention heads. Results such as ours could be utilized when determining effective and efficient configurations to achieve optimal information transfers between larger (teacher) and smaller (student) models.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）已经大幅提高了自然语言处理（NLP）任务的性能，但训练和维护这些网络可能会很昂贵。为了解决这个问题，知识填充技术（KD）已经被提议，但压缩过程可能会导致信息损失。我们的工作探讨了填充学生模型与其教师模型之间的差异，以及压缩过程是否会导致信息损失，以及损失是否会跟踪特定的模式。我们的实验旨在为选择合适的任务和配置提供数据点，以便在确定最佳信息传输的过程中尽可能地实现效率和可行性。
</details></li>
</ul>
<hr>
<h2 id="Modelling-Sentiment-Analysis-LLMs-and-data-augmentation-techniques"><a href="#Modelling-Sentiment-Analysis-LLMs-and-data-augmentation-techniques" class="headerlink" title="Modelling Sentiment Analysis: LLMs and data augmentation techniques"></a>Modelling Sentiment Analysis: LLMs and data augmentation techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04139">http://arxiv.org/abs/2311.04139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillem Senabre Prades</li>
<li>for: 这篇论文是为了提出一种基于小训练集的 binary sentiment classification 方法。</li>
<li>methods: 本论文使用了 LLMS 技术，包括 BERT、RoBERTa 和 XLNet，以实现 sentiment analysis 的高度表现。</li>
<li>results: 本论文通过实验表明，使用 LLMS 技术可以在小训练集上实现高度的 binary sentiment classification 性能。<details>
<summary>Abstract</summary>
This paper provides different approaches for a binary sentiment classification on a small training dataset. LLMs that provided state-of-the-art results in sentiment analysis and similar domains are being used, such as BERT, RoBERTa and XLNet.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了不同的方法来进行二分类句子情感分类，使用了一些 LLMS 提供了状态艺术的结果，如 BERT、RoBERTa 和 XLNet。Here's a breakdown of the translation:* " LLMS" 是简化中文的 "Large Language Models" (大语言模型)* "二分类" 是简化中文的 "binary classification" (二分类)* "句子情感分类" 是简化中文的 "sentiment classification" (情感分类)* "状态艺术" 是简化中文的 "state-of-the-art" (状态艺术)I hope this helps! Let me know if you have any other questions.
</details></li>
</ul>
<hr>
<h2 id="Personality-Style-Recognition-via-Machine-Learning-Identifying-Anaclitic-and-Introjective-Personality-Styles-from-Patients’-Speech"><a href="#Personality-Style-Recognition-via-Machine-Learning-Identifying-Anaclitic-and-Introjective-Personality-Styles-from-Patients’-Speech" class="headerlink" title="Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients’ Speech"></a>Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients’ Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04088">http://arxiv.org/abs/2311.04088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Semere Kiros Bitew, Vincent Schelstraete, Klim Zaporojets, Kimberly Van Nieuwenhove, Reitske Meganck, Chris Develder</li>
<li>for: 这个研究的目的是用自然语言处理（NLP）和标准机器学习工具来推断患有主要抑郁症（MDD）患者的个性类型，以更准确地识别个性类型，并且可能比传统的问卷方法更加准确。</li>
<li>methods: 这个研究使用了 recorded clinical diagnostic interviews（CDI）数据集，包含79名患有MDD的患者，并将其分为两个个性类型：帮助型（anaclitic）和寂静型（introjective）。研究人员首先分析了口头会议，以便了解每个类型的语言特征，然后开发了自动分类器，包括基于标准问卷回答（a）、基本文本特征（b）、更高级的文本特征（c），以及音频特征。</li>
<li>results: 研究发现，使用语言 derive 的特征（例如 LIWC）自动分类的表现比问卷基本类型更好，而将 LIWC 与问卷特征相结合的表现更加出色。这些结果表明，用语言 derive 的特征来推断个性类型可能比传统的问卷方法更加准确，但问卷仍然有一定的补充作用。<details>
<summary>Abstract</summary>
In disentangling the heterogeneity observed in psychopathology, personality of the patients is considered crucial. While it has been demonstrated that personality traits are reflected in the language used by a patient, we hypothesize that this enables automatic inference of the personality type directly from speech utterances, potentially more accurately than through a traditional questionnaire-based approach explicitly designed for personality classification. To validate this hypothesis, we adopt natural language processing (NLP) and standard machine learning tools for classification. We test this on a dataset of recorded clinical diagnostic interviews (CDI) on a sample of 79 patients diagnosed with major depressive disorder (MDD) -- a condition for which differentiated treatment based on personality styles has been advocated -- and classified into anaclitic and introjective personality styles. We start by analyzing the interviews to see which linguistic features are associated with each style, in order to gain a better understanding of the styles. Then, we develop automatic classifiers based on (a) standardized questionnaire responses; (b) basic text features, i.e., TF-IDF scores of words and word sequences; (c) more advanced text features, using LIWC (linguistic inquiry and word count) and context-aware features using BERT (bidirectional encoder representations from transformers); (d) audio features. We find that automated classification with language-derived features (i.e., based on LIWC) significantly outperforms questionnaire-based classification models. Furthermore, the best performance is achieved by combining LIWC with the questionnaire features. This suggests that more work should be put into developing linguistically based automated techniques for characterizing personality, however questionnaires still to some extent complement such methods.
</details>
<details>
<summary>摘要</summary>
在解剖 психопатологи中的多样性，病人的人格 trait 被视为关键。已经证明了患者的语言使用会反映他们的人格特质，我们假设可以通过自动识别语言特征来直接推断病人的人格类型，可能更准确地 than through traditional questionnaire-based approach for personality classification. 为了验证这个假设，我们采用自然语言处理（NLP）和标准机器学习工具 для分类。我们在一个记录的临床诊断采访（CDI）中的79名患有主要抑郁症（MDD）患者的样本上进行测试，并将其分为安慰性和 introjective 人格样式。我们首先分析采访，以确定各样式之间的语言特征，以更好地理解这些样式。然后，我们开发自动分类器，基于（a）标准问卷回答；（b）基本文本特征，即TF-IDF 分数的词和word sequences；（c）更高级的文本特征，使用 LIWC （语言Query和词 counting）和BERT（ transformers 中的 bidirectional encoder representations）；（d）音频特征。我们发现，基于语言 derive 的特征（即 LIWC）的自动分类表现出色，significantly outperform questionnaire-based classification models。此外，我们发现，将 LIWC 与问卷特征结合使用的表现最佳。这表示，更多的工作应该投入到开发基于语言特征的自动分类技术，但是，questionnaires 仍然有一定的补做作用。
</details></li>
</ul>
<hr>
<h2 id="Do-LLMs-exhibit-human-like-response-biases-A-case-study-in-survey-design"><a href="#Do-LLMs-exhibit-human-like-response-biases-A-case-study-in-survey-design" class="headerlink" title="Do LLMs exhibit human-like response biases? A case study in survey design"></a>Do LLMs exhibit human-like response biases? A case study in survey design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04076">http://arxiv.org/abs/2311.04076</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lindiatjuatja/biasmonkey">https://github.com/lindiatjuatja/biasmonkey</a></li>
<li>paper_authors: Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, Graham Neubig</li>
<li>for: 这个研究用于检测大语言模型（LLM）是否能够模拟人类的意见，以及LLM是否会受到问题表达的影响。</li>
<li>methods: 该研究使用了问卷设计作为案例研究，利用了社会心理学中已有的研究，设计了一个数据集和一个评估框架，以评估 LLM 是否会表现出人类类似的响应偏见。</li>
<li>results: 研究发现，流行的开源和商业 LLM 通常不会模拟人类的行为，尤其是在问题表达的排序和重要性上。此外，even if a model shows a significant change in the same direction as humans, 研究发现，这种变化可能是由其他各种各样的相关性引起的，而不是受到问题表达的直接影响。这些结果指出，使用 LLM 代替人类进行某些注解阶段可能存在隐藏的风险，并且更加重要地，需要更加细化的模型行为描述。<details>
<summary>Abstract</summary>
As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording -- but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of ``prompts'' have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior. These inconsistencies tend to be more prominent in models that have been instruction fine-tuned. Furthermore, even if a model shows a significant change in the same direction as humans, we find that perturbations that are not meant to elicit significant changes in humans may also result in a similar change, suggesting that such a result could be partially due to other spurious correlations. These results highlight the potential pitfalls of using LLMs to substitute humans in parts of the annotation pipeline, and further underscore the importance of finer-grained characterizations of model behavior. Our code, dataset, and collected samples are available at https://github.com/lindiatjuatja/BiasMonkey
</details>
<details>
<summary>摘要</summary>
随着大语言模型（LLM）的能力不断提高，有越来越多的人对使用LLM作为人类代理进行实际任务，如调查和意见调查而感到兴奋。然而，一个广泛提到的障碍是LLM的敏感性 towards prompt wording （提问词的选择）——但是人类也会因为提问词的变化而产生偏见。因此，如果要使用LLM来 aproximate human opinions，那么就需要investigate whether LLMs also exhibit human-like response biases。在这个工作中，我们使用调查设计为case study，因为人类响应的偏见已经在调查中得到了广泛的研究。基于社会心理学的前期工作，我们设计了数据集和提出了一种框架，以评估LLM是否 Display human-like response biases in survey questionnaires。我们对九种模型进行了全面的评估，发现大多数开源和商业模型通常不能准确地表现出人类的响应偏见。这些偏见通常会在模型被 instrucion fine-tuned 时更加明显。此外，即使模型表现出人类的方向性变化，我们发现可能存在其他的干扰因素，导致模型的行为不准确。这些结果表明使用LLM代替人类在一些标注过程中可能存在隐患，并且高亮了需要更加细化的模型行为Characterization。我们的代码、数据集和收集的样本可以在https://github.com/lindiatjuatja/BiasMonkey 上获取。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Imitation-Leveraging-Fine-grained-Quality-Signals-for-Alignment"><a href="#Beyond-Imitation-Leveraging-Fine-grained-Quality-Signals-for-Alignment" class="headerlink" title="Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"></a>Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04072">http://arxiv.org/abs/2311.04072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geyang Guo, Ranchi Zhao, Tianyi Tang, Wayne Xin Zhao, Ji-Rong Wen</li>
<li>for: 这个论文的目的是提出一种改进的对齐方法，以便大语言模型（LLMs）能够更好地适应人类的偏好。</li>
<li>methods: 这个论文使用了精细的质量信号，来指导Language Model（LM）的学习对齐。</li>
<li>results: 实验表明，该方法可以提高LLMs的对齐性，并且比传统的对齐方法（如人类反馈学习）更加简单和efficient。<details>
<summary>Abstract</summary>
Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的对人类偏好的对适性是一个欲有的性能。现在，主要的对适性方法是基于人类反馈学习（RLHF）。 Despite the effectiveness of RLHF, it is intricate to implement and train, so recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning（SFT）. However, a major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function that can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.
</details></li>
</ul>
<hr>
<h2 id="Implementation-and-Comparison-of-Methods-to-Extract-Reliability-KPIs-out-of-Textual-Wind-Turbine-Maintenance-Work-Orders"><a href="#Implementation-and-Comparison-of-Methods-to-Extract-Reliability-KPIs-out-of-Textual-Wind-Turbine-Maintenance-Work-Orders" class="headerlink" title="Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders"></a>Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04064">http://arxiv.org/abs/2311.04064</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc-Alexander Lutz, Bastian Schäfermeier, Rachael Sexton, Michael Sharp, Alden Dima, Stefan Faulstich, Jagan Mohini Aluri</li>
<li>for: 本文目的是提高风力机的运行和维护。</li>
<li>methods: 本文使用了三种不同的方法来计算可靠性关键性能指标从维护工作令。第一种方法是由领域专家手动标注维护工作令，使用工业标准定义的架构来分别标注。第二种方法是通过文本分类方法开发一个自动标注模型。第三种方法是使用人工智能辅助标注工具来标注和结构维护工作令中的原始维护信息。</li>
<li>results: 三种方法可以更有效地提取维护信息从维护工作令，并且可以评估风力机的可靠性关键性能指标。质量和时间花费被用作评价标准。总的来说，这三种方法可以帮助优化风力机的运行和维护。<details>
<summary>Abstract</summary>
Maintenance work orders are commonly used to document information about wind turbine operation and maintenance. This includes details about proactive and reactive wind turbine downtimes, such as preventative and corrective maintenance. However, the information contained in maintenance work orders is often unstructured and difficult to analyze, making it challenging for decision-makers to use this information for optimizing operation and maintenance. To address this issue, this work presents three different approaches to calculate reliability key performance indicators from maintenance work orders. The first approach involves manual labeling of the maintenance work orders by domain experts, using the schema defined in an industrial guideline to assign the label accordingly. The second approach involves the development of a model that automatically labels the maintenance work orders using text classification methods. The third technique uses an AI-assisted tagging tool to tag and structure the raw maintenance information contained in the maintenance work orders. The resulting calculated reliability key performance indicator of the first approach are used as a benchmark for comparison with the results of the second and third approaches. The quality and time spent are considered as criteria for evaluation. Overall, these three methods make extracting maintenance information from maintenance work orders more efficient, enable the assessment of reliability key performance indicators and therefore support the optimization of wind turbine operation and maintenance.
</details>
<details>
<summary>摘要</summary>
维护工作令 commonly used to record风机运行和维护信息。这些信息包括推动和反应式风机停机时间，如预防维护和修复维护。然而，维护工作令中的信息通常是不结构化的，困难分析，使得决策者无法使用这些信息优化运行和维护。为解决这个问题，本工作提出了三种不同的方法来计算可靠性关键性能指标从维护工作令中。首先，第一种方法是通过域专家手动标注维护工作令，使用行业标准的 schema 分配标签。第二种方法是开发一种自动标注维护工作令的模型，使用文本分类方法。第三种技术是使用人工智能帮助标记工具来标记和结构化维护工作令中的原始维护信息。计算的可靠性关键性能指标的结果被用作比较第二和第三种方法的标准。评价标准包括质量和时间。总的来说，这三种方法使维护信息从维护工作令中提取更加效率，可以评估可靠性关键性能指标，因此支持风机运行和维护优化。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-Fine-tuning-of-Language-Models-is-Biased-Towards-More-Extractable-Features"><a href="#Reinforcement-Learning-Fine-tuning-of-Language-Models-is-Biased-Towards-More-Extractable-Features" class="headerlink" title="Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features"></a>Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04046">http://arxiv.org/abs/2311.04046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diogo Cruz, Edoardo Pona, Alex Holness-Tofts, Elias Schmied, Víctor Abia Alonso, Charlie Griffin, Bogdan-Ionut Cirstea</li>
<li>for: 本研究探究了自然语言处理模型（LLM）在强化学习环境中是否遵循顺序学习的原则。</li>
<li>methods: 研究人员采用了两种方法来测试假设：一是通过synthetic语言任务测试，二是通过自然语言任务测试。</li>
<li>results: 研究人员发现，在强化学习环境中，模型更倾向于采用更容易提取的特征，而不是更复杂的特征。此外，研究人员还发现，在强化学习过程中，模型对特征的选择具有 statistically significant 的相关性。<details>
<summary>Abstract</summary>
Many capable large language models (LLMs) are developed via self-supervised pre-training followed by a reinforcement-learning fine-tuning phase, often based on human or AI feedback. During this stage, models may be guided by their inductive biases to rely on simpler features which may be easier to extract, at a cost to robustness and generalisation. We investigate whether principles governing inductive biases in the supervised fine-tuning of LLMs also apply when the fine-tuning process uses reinforcement learning. Following Lovering et al (2021), we test two hypotheses: that features more $\textit{extractable}$ after pre-training are more likely to be utilised by the final policy, and that the evidence for/against a feature predicts whether it will be utilised. Through controlled experiments on synthetic and natural language tasks, we find statistically significant correlations which constitute strong evidence for these hypotheses.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="P-Bench-A-Multi-level-Privacy-Evaluation-Benchmark-for-Language-Models"><a href="#P-Bench-A-Multi-level-Privacy-Evaluation-Benchmark-for-Language-Models" class="headerlink" title="P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models"></a>P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04044">http://arxiv.org/abs/2311.04044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Li, Dadi Guo, Donghao Li, Wei Fan, Qi Hu, Xin Liu, Chunkit Chan, Duanyi Yao, Yangqiu Song</li>
<li>for: This paper aims to address the privacy risks of language models (LMs) and propose a privacy evaluation benchmark called P-Bench to evaluate the privacy leakage of LMs.</li>
<li>methods: The proposed P-Bench benchmark uses a multi-faceted approach to evaluate the privacy of LMs during private fine-tuning, including defining privacy objectives and constructing a unified pipeline for private fine-tuning.</li>
<li>results: The paper conducts extensive experiments on three datasets of GLUE for mainstream LMs to evaluate the privacy leakage of various privacy-preserving language models (PPLMs) using the P-Bench benchmark. The results provide a fair and intuitive evaluation of the privacy leakage of different PPLMs.<details>
<summary>Abstract</summary>
The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage. To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP). Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs. In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs. Instead of only protecting and measuring the privacy of protected data with DP parameters, P-Bench sheds light on the neglected inference data privacy during actual usage. P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning. Then, P-Bench constructs a unified pipeline to perform private fine-tuning. Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results. The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs. We conduct extensive experiments on three datasets of GLUE for mainstream LMs.
</details>
<details>
<summary>摘要</summary>
快速发展的语言模型（LM）带来了前所未有的可访问性和使用性，对于模型和用户来说都是有益的。然而，随着更多的注意力转移到不受限制的模型访问，可能会导致隐私问题的泄露。为解决这些问题，许多最近的工作提出了隐私保护语言模型（PPLM），使用分布式隐私（DP）来保护用户的隐私。然而，不同的DP实现使得对现有PPLM进行比较变得困难。在这篇论文中，我们提出了P-Bench，一个多角度隐私评估准则，用来实际和直观地评估LM的隐私泄露。而不是仅仅保护和测量保护数据的隐私，P-Bench也探讨在实际使用过程中的推理数据隐私。P-Bench首先明确了在私有精细调整时的多重隐私目标。然后，P-Bench构建了一个统一的私有精细调整管道。最后，P-Bench对LM进行现有隐私攻击，并使用预定的隐私目标作为实际评估结果。我们对GLUE数据集进行了广泛的实验，并发现P-Bench可以帮助评估不同PPLM的隐私泄露。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Film-Adaptation-through-Narrative-Alignment"><a href="#Analyzing-Film-Adaptation-through-Narrative-Alignment" class="headerlink" title="Analyzing Film Adaptation through Narrative Alignment"></a>Analyzing Film Adaptation through Narrative Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04020">http://arxiv.org/abs/2311.04020</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanzir Pial, Shahreen Salim, Charuta Pethe, Allen Kim, Steven Skiena</li>
<li>for: 这个论文研究了电影改编的过程，特别是对剧本和小说之间的文本相似性进行自动分析。</li>
<li>methods: 研究者使用了Smith-Waterman本地对接算法和SBERT嵌入距离来建立叙述对应关系，以衡量电影和小说之间的文本相似性。</li>
<li>results: 研究发现，电影改编过程中对剧本的 faithfulness、对话的重要性、叙述顺序的保留和gender表现问题等方面存在一些问题，这些问题可以通过自动分析来发现和解决。<details>
<summary>Abstract</summary>
Novels are often adapted into feature films, but the differences between the two media usually require dropping sections of the source text from the movie script. Here we study this screen adaptation process by constructing narrative alignments using the Smith-Waterman local alignment algorithm coupled with SBERT embedding distance to quantify text similarity between scenes and book units. We use these alignments to perform an automated analysis of 40 adaptations, revealing insights into the screenwriting process concerning (i) faithfulness of adaptation, (ii) importance of dialog, (iii) preservation of narrative order, and (iv) gender representation issues reflective of the Bechdel test.
</details>
<details>
<summary>摘要</summary>
小说经常被改编成电影，但两媒体之间的差异通常会导致电影剧本中去掉来自原始文本的部分。我们通过构建叙事对应关系使用斯密特-沃特曼本地对Alignment算法和SBERT嵌入距离来衡量场景和书单之间的文本相似性。我们使用这些对应关系来自动分析40个改编作品，探讨电影编剧过程中的忠诚度、对话重要性、叙事顺序保持和gender表现问题，这些问题与Bechdel测试有关。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Jiu-Jitsu-Argumentation-for-Writing-Peer-Review-Rebuttals"><a href="#Exploring-Jiu-Jitsu-Argumentation-for-Writing-Peer-Review-Rebuttals" class="headerlink" title="Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals"></a>Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03998">http://arxiv.org/abs/2311.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sukannya Purkayastha, Anne Lauscher, Iryna Gurevych</li>
<li>for: 本研究旨在提出一种基于情感根和主题的辩论风格，以应对现代辩论中的护卫者心理学。</li>
<li>methods: 本研究使用了已有的评论结构数据集，并对其进行了扩展和修改，以满足新的任务需求。然后，通过培育专业的模型，实现了情感根和主题导向的护卫回复生成。</li>
<li>results: 本研究通过两个子任务和综合评价来评估了新的辩论风格的效果，并取得了良好的结果。这些结果表明，基于情感根和主题的辩论风格可以更好地满足现代辩论中的需求，并且可以帮助人们更好地理解和回应对手的观点。<details>
<summary>Abstract</summary>
In many domains of argumentation, people's arguments are driven by so-called attitude roots, i.e., underlying beliefs and world views, and their corresponding attitude themes. Given the strength of these latent drivers of arguments, recent work in psychology suggests that instead of directly countering surface-level reasoning (e.g., falsifying given premises), one should follow an argumentation style inspired by the Jiu-Jitsu 'soft' combat system (Hornsey and Fielding, 2017): first, identify an arguer's attitude roots and themes, and then choose a prototypical rebuttal that is aligned with those drivers instead of invalidating those. In this work, we are the first to explore Jiu-Jitsu argumentation for peer review by proposing the novel task of attitude and theme-guided rebuttal generation. To this end, we enrich an existing dataset for discourse structure in peer reviews with attitude roots, attitude themes, and canonical rebuttals. To facilitate this process, we recast established annotation concepts from the domain of peer reviews (e.g., aspects a review sentence is relating to) and train domain-specific models. We then propose strong rebuttal generation strategies, which we benchmark on our novel dataset for the task of end-to-end attitude and theme-guided rebuttal generation and two subtasks.
</details>
<details>
<summary>摘要</summary>
在许多论证领域，人们的论证受到 socalled 的态度根和世界观的影响，这些基础和主题对应的态度驱动了他们的论证。由于这些潜在的驱动者的力量，现代心理学研究建议，而不是直接对表面水平的理据（例如，证据反驳），应该采用基于柔气斗技（Jiu-Jitsu）的论证风格（Hornsey和Fielding，2017）：首先，认定论证人的态度根和主题，然后选择与这些驱动器相对应的典型反驳。在这项工作中，我们是第一个探讨Jiu-Jitsu论证在同行评审中的应用，我们提出了novel任务：对态度和主题导向的反驳生成。为此，我们增强了现有的 peer review 数据集，添加了态度根、态度主题和 canonical 反驳。为了实现这一目标，我们重新定义了Established annotation concepts从 peer review 领域（例如，sentence 上的方面），并训练域pecific 模型。我们最后提出了强大的反驳生成策略，并在我们的新数据集上进行了终到端态度和主题导向的反驳生成和两个子任务的benchmark。
</details></li>
</ul>
<hr>
<h2 id="Factoring-Hate-Speech-A-New-Annotation-Framework-to-Study-Hate-Speech-in-Social-Media"><a href="#Factoring-Hate-Speech-A-New-Annotation-Framework-to-Study-Hate-Speech-in-Social-Media" class="headerlink" title="Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media"></a>Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03969">http://arxiv.org/abs/2311.03969</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gal Ron, Effi Levi, Odelia Oshri, Shaul R. Shenhav</li>
<li>for: 本研究提出了一种新的报告方案，用于分类习惯性攻击语言。</li>
<li>methods: 本研究使用了Twitter上超过29万条帖子，并将其分为5个分类。</li>
<li>results: 研究人员通过对1050个帖子的注释，发现了5种不同的报告类型。<details>
<summary>Abstract</summary>
In this work we propose a novel annotation scheme which factors hate speech into five separate discursive categories. To evaluate our scheme, we construct a corpus of over 2.9M Twitter posts containing hateful expressions directed at Jews, and annotate a sample dataset of 1,050 tweets. We present a statistical analysis of the annotated dataset as well as discuss annotation examples, and conclude by discussing promising directions for future work.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的注释方案，它将仇恨言论分解成五个分开的讲话类别。为评估我们的方案，我们构建了包含超过290万个推文的推特帖子集，并对1,050个推文进行了注释。我们提供了推文集的统计分析以及注释示例，并在结尾提出了未来工作的可能方向。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Dialogue-Repair-in-Voice-Assistants"><a href="#An-Analysis-of-Dialogue-Repair-in-Voice-Assistants" class="headerlink" title="An Analysis of Dialogue Repair in Voice Assistants"></a>An Analysis of Dialogue Repair in Voice Assistants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03952">http://arxiv.org/abs/2311.03952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Galbraith</li>
<li>for: 本研究探讨了虚拟助手与用户之间的对话修复，以及虚拟助手如何利用对话语言来修复 misunderstanding。</li>
<li>methods: 本研究通过分析Google助手和Siri在用户与虚拟助手之间的交互来分析对话修复的使用和响应。</li>
<li>results: 研究发现虚拟助手使用了多种自己的策略，但无法模仿人类对话修复策略，如“嗯？”。用户Acceptability调查显示英语和西班牙语用户对修复策略的偏好有所不同，虚拟助手使用也存在一些语言不同的地方。这些结果指出了人机交互中对话语言的不均衡，并且强调了进一步研究人机交互中对话语言的影响。<details>
<summary>Abstract</summary>
Spoken dialogue systems have transformed human-machine interaction by providing real-time responses to queries. However, misunderstandings between the user and system persist. This study explores the significance of interactional language in dialogue repair between virtual assistants and users by analyzing interactions with Google Assistant and Siri, focusing on their utilization and response to the other-initiated repair strategy "huh?" prevalent in human-human interaction. Findings reveal several assistant-generated strategies but an inability to replicate human-like repair strategies such as "huh?". English and Spanish user acceptability surveys show differences in users' repair strategy preferences and assistant usage, with both similarities and disparities among the two surveyed languages. These results shed light on inequalities between interactional language in human-human interaction and human-machine interaction, underscoring the need for further research on the impact of interactional language in human-machine interaction in English and beyond.
</details>
<details>
<summary>摘要</summary>
人工智能对话系统已经改变了人机交互，提供了实时回应。然而，用户和系统之间的 misunderstanding 仍然存在。这项研究探讨了对话修复在虚拟助手和用户之间的语言互动意义，通过分析 Google Assistant 和 Siri 对 "huh?" 等其他发起修复策略的应用和回应。发现虚拟助手采用了多种策略，但无法模仿人类对话修复策略。英语和西班牙语用户对修复策略的偏好和虚拟助手使用情况有所不同和相似之处，这些结果 shed light 到人机交互中语言互动不平等，高亮了需要进一步研究人机交互中语言互动的影响。
</details></li>
</ul>
<hr>
<h2 id="Improving-Korean-NLP-Tasks-with-Linguistically-Informed-Subword-Tokenization-and-Sub-character-Decomposition"><a href="#Improving-Korean-NLP-Tasks-with-Linguistically-Informed-Subword-Tokenization-and-Sub-character-Decomposition" class="headerlink" title="Improving Korean NLP Tasks with Linguistically Informed Subword Tokenization and Sub-character Decomposition"></a>Improving Korean NLP Tasks with Linguistically Informed Subword Tokenization and Sub-character Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03928">http://arxiv.org/abs/2311.03928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/taeheejeon22/morphsubdecomp-korean">https://github.com/taeheejeon22/morphsubdecomp-korean</a></li>
<li>paper_authors: Taehee Jeon, Bongseok Yang, Changhwan Kim, Yoonseob Lim</li>
<li>for: 该研究旨在提高预训练语言模型（PLM）在语法和 semantics 领域的表现，通过使用 morpheme-aware 子词Tokenization 方法来应对韩语的特殊语法和书写系统。</li>
<li>methods: 该方法使用 sub-character decomposition 来应对 BPE 的挑战，并考虑了语言学性的精度和计算效率的平衡。</li>
<li>results: 对 NIKL-CoLA 任务的评估表明，该技术在总体上达到了好的表现，特别是在语法任务中提高了表现，这表示integrating morpheme type information 可以提高语言模型的语法和 semantics 能力，并且可以进一步提高表现 beyond standard morphological analysis。<details>
<summary>Abstract</summary>
We introduce a morpheme-aware subword tokenization method that utilizes sub-character decomposition to address the challenges of applying Byte Pair Encoding (BPE) to Korean, a language characterized by its rich morphology and unique writing system. Our approach balances linguistic accuracy with computational efficiency in Pre-trained Language Models (PLMs). Our evaluations show that this technique achieves good performances overall, notably improving results in the syntactic task of NIKL-CoLA. This suggests that integrating morpheme type information can enhance language models' syntactic and semantic capabilities, indicating that adopting more linguistic insights can further improve performance beyond standard morphological analysis.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于字符串分词的 morpheme-aware 方法，利用字符串分解来Addressing the challenges of applying Byte Pair Encoding (BPE) to Korean, a language with rich morphology and unique writing system. Our approach balances linguistic accuracy with computational efficiency in Pre-trained Language Models (PLMs). Our evaluations show that this technique achieves good performances overall, notably improving results in the syntactic task of NIKL-CoLA. This suggests that integrating morpheme type information can enhance language models' syntactic and semantic capabilities, indicating that adopting more linguistic insights can further improve performance beyond standard morphological analysis.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="iACOS-Advancing-Implicit-Sentiment-Extraction-with-Informative-and-Adaptive-Negative-Examples"><a href="#iACOS-Advancing-Implicit-Sentiment-Extraction-with-Informative-and-Adaptive-Negative-Examples" class="headerlink" title="iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples"></a>iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03896">http://arxiv.org/abs/2311.03896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiancai Xu, Jia-Dong Zhang, Lei Xiong, Zhishang Liu</li>
<li>for: 本文提出了一种新的方法iACOS，用于从文本中提取隐式方面和意见。</li>
<li>methods: 本方法首先在文本中添加了两个隐式标记，以获取Context-aware表示所有Token，包括隐式方面和意见。然后，该方法采用了一种顺序标注模型，以同时提取显式和隐式方面和意见。最后，该方法使用了特殊多头注意力 Mechanism来同时预测方面意见对的类别和情感。</li>
<li>results: 实验结果显示，iACOSsignificantly outperforms其他四元提取基线，根据F1分数在两个公共benchmark datasets上。<details>
<summary>Abstract</summary>
Aspect-based sentiment analysis (ABSA) have been extensively studied, but little light has been shed on the quadruple extraction consisting of four fundamental elements: aspects, categories, opinions and sentiments, especially with implicit aspects and opinions. In this paper, we propose a new method iACOS for extracting Implicit Aspects with Categories and Opinions with Sentiments. First, iACOS appends two implicit tokens at the end of a text to capture the context-aware representation of all tokens including implicit aspects and opinions. Second, iACOS develops a sequence labeling model over the context-aware token representation to co-extract explicit and implicit aspects and opinions. Third, iACOS devises a multi-label classifier with a specialized multi-head attention for discovering aspect-opinion pairs and predicting their categories and sentiments simultaneously. Fourth, iACOS leverages informative and adaptive negative examples to jointly train the multi-label classifier and the other two classifiers on categories and sentiments by multi-task learning. Finally, the experimental results show that iACOS significantly outperforms other quadruple extraction baselines according to the F1 score on two public benchmark datasets.
</details>
<details>
<summary>摘要</summary>
<SYS>translate("Aspect-based sentiment analysis (ABSA) have been extensively studied, but little light has been shed on the quadruple extraction consisting of four fundamental elements: aspects, categories, opinions and sentiments, especially with implicit aspects and opinions. In this paper, we propose a new method iACOS for extracting Implicit Aspects with Categories and Opinions with Sentiments. First, iACOS appends two implicit tokens at the end of a text to capture the context-aware representation of all tokens including implicit aspects and opinions. Second, iACOS develops a sequence labeling model over the context-aware token representation to co-extract explicit and implicit aspects and opinions. Third, iACOS devises a multi-label classifier with a specialized multi-head attention for discovering aspect-opinion pairs and predicting their categories and sentiments simultaneously. Fourth, iACOS leverages informative and adaptive negative examples to jointly train the multi-label classifier and the other two classifiers on categories and sentiments by multi-task learning. Finally, the experimental results show that iACOS significantly outperforms other quadruple extraction baselines according to the F1 score on two public benchmark datasets.")</SYS>以下是将文本翻译成简化中文： aspect-based sentiment analysis (ABSA) 已经广泛研究，但是它们对四元素抽取（包括方面、类别、意见和情感）尤其是对于隐式方面和意见进行了少量的研究。在这篇论文中，我们提出了一种新的方法iACOS，用于抽取隐式方面和意见。这个方法包括以下四个步骤：1. 将文本结尾添加两个隐式符号，以捕捉所有token的上下文感知表示，包括隐式方面和意见。2. 使用上下文感知的字符串表示来进行序列标签模型，以同时提取显式和隐式方面和意见。3. 开发一种特殊的多头注意力的多标签分类器，用于同时发现方面-意见对和其类别和情感的预测。4. 使用有用和适应的负例来同时训练多标签分类器和其他两个分类器，以进行类别和情感的多任务学习。最后，实验结果表明，iACOS在两个公共的 benchmark 数据集上的 F1 分数明显高于其他四元素抽取基线。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Contrastive-Learning-of-Sentence-Embeddings"><a href="#Sparse-Contrastive-Learning-of-Sentence-Embeddings" class="headerlink" title="Sparse Contrastive Learning of Sentence Embeddings"></a>Sparse Contrastive Learning of Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03881">http://arxiv.org/abs/2311.03881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruize An, Chen Zhang, Dawei Song<br>for:这个论文的目的是证明对句子嵌入模型进行Parameter sparseification可以提高模型性能，并且通过对标准semantic textual similarity(STS)任务和转移学习任务的实验，证明了这种方法的可行性和稳定性。methods:这个论文使用了对句子嵌入模型进行Parameter sparseification，并通过对Alignment和Uniformity scores进行分析，从而确定了危险参数的存在和其影响。results:这个论文的实验结果表明，对于STS任务和转移学习任务，使用了Parameter sparseification的SparseCSE模型在性能上表现出色，并且对比于SimCSE模型，它具有更高的Alignment和Uniformity scores。<details>
<summary>Abstract</summary>
Recently, SimCSE has shown the feasibility of contrastive learning in training sentence embeddings and illustrates its expressiveness in spanning an aligned and uniform embedding space. However, prior studies have shown that dense models could contain harmful parameters that affect the model performance, and it is no wonder that SimCSE can as well be invented with such parameters. Driven by this, parameter sparsification is applied, where alignment and uniformity scores are used to measure the contribution of each parameter to the overall quality of sentence embeddings. Drawing from a preliminary study, we consider parameters with minimal contributions to be detrimental, as their sparsification results in improved model performance. To discuss the ubiquity of detrimental parameters and remove them, more experiments on the standard semantic textual similarity (STS) tasks and transfer learning tasks are conducted, and the results show that the proposed sparsified SimCSE (SparseCSE) has excellent performance in comparison with SimCSE. Furthermore, through in-depth analysis, we establish the validity and stability of our sparsification method, showcasing that the embedding space generated by SparseCSE exhibits improved alignment compared to that produced by SimCSE. Importantly, the uniformity yet remains uncompromised.
</details>
<details>
<summary>摘要</summary>
最近，SimCSE已经证明了对比学习在生成句子嵌入中的可行性，并 Illustrates its expressiveness in spanning an aligned and uniform embedding space。然而，先前的研究表明，dense模型可能包含有害参数，这会影响模型性能。这种情况下，参数精简是应用的，通过对适应性和一致性分数来评估每个参数对整体句子嵌入质量的贡献。根据初步研究，我们认为parameters with minimal contributions are detrimental，因为它们的精简会提高模型性能。为了评估这些detrimental parameters的普遍性和移除它们，我们进行了更多的STS任务和转移学习任务的实验，结果显示，我们的精简SimCSE（SparseCSE）具有与SimCSE相比杰出的性能。此外，我们还进行了深入分析，并证明了我们的精简方法的有效性和稳定性，显示了生成的嵌入空间在SparseCSE中比SimCSE更高度一致，而均匀性却保持不变。
</details></li>
</ul>
<hr>
<h2 id="OLaLa-Ontology-Matching-with-Large-Language-Models"><a href="#OLaLa-Ontology-Matching-with-Large-Language-Models" class="headerlink" title="OLaLa: Ontology Matching with Large Language Models"></a>OLaLa: Ontology Matching with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03837">http://arxiv.org/abs/2311.03837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sven Hertling, Heiko Paulheim</li>
<li>for: 这个论文旨在探讨如何使用大语言模型来提高ontology匹配task的性能。</li>
<li>methods: 该论文使用了零例或几例提示的方法，并应用于不同的OAEI任务上。</li>
<li>results: 研究发现，只需要几个示例和一个Well-designed提示，就可以达到与超级vised匹配系统相同的性能水平。<details>
<summary>Abstract</summary>
Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth.
</details>
<details>
<summary>摘要</summary>
ontology (和更广义的知识图) 匹配是一项具有挑战性的任务，信息在自然语言中是匹配管道中最重要的信号之一。随着大语言模型的出现，可以更好地将这些知识integrated into匹配管道中。仍需要做出一些决策，例如如何生成有用的提示，如何在提示中表达知识图信息，哪种大语言模型最合适，如何提供现有的匹配，如何生成候选者等。在这篇论文中，我们提出了一个原型，通过零shot和几shot提示，使用多个开放的大语言模型对不同的OAEI任务进行应用。我们表明，只需很少的示例和一个Well-designed提示，就可以达到与经过监督匹配系统使用的许多真实数据匹配的效果。
</details></li>
</ul>
<hr>
<h2 id="Conversations-in-Galician-a-Large-Language-Model-for-an-Underrepresented-Language"><a href="#Conversations-in-Galician-a-Large-Language-Model-for-an-Underrepresented-Language" class="headerlink" title="Conversations in Galician: a Large Language Model for an Underrepresented Language"></a>Conversations in Galician: a Large Language Model for an Underrepresented Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03812">http://arxiv.org/abs/2311.03812</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.irlab.org/irlab/cabuxa">https://gitlab.irlab.org/irlab/cabuxa</a></li>
<li>paper_authors: Eliseo Bao, Anxo Pérez, Javier Parapar</li>
<li>for: 这项研究的目的是提高大型自然语言处理（NLP）模型对 га利西安语言的支持，以便更好地包括所有语言社区在大语言模型的开发中。</li>
<li>methods: 这项研究使用了一个新的加利西安语言适应 dataset，包括 52,000 个 instruction 和 demonstration，以及 fine-tuning LLaMA-7B 模型，以便更好地遵循提供的 instruction。</li>
<li>results: 研究发现，通过使用加利西安语言适应 dataset 和 fine-tuning LLaMA-7B 模型，可以使模型更好地理解和回答加利西安语言的问题，并且可以通过知道相关语言的概念来生成 coherent 的文本。<details>
<summary>Abstract</summary>
The recent proliferation of Large Conversation Language Models has highlighted the economic significance of widespread access to this type of AI technologies in the current information age. Nevertheless, prevailing models have primarily been trained on corpora consisting of documents written in popular languages. The dearth of such cutting-edge tools for low-resource languages further exacerbates their underrepresentation in the current economic landscape, thereby impacting their native speakers. This paper introduces two novel resources designed to enhance Natural Language Processing (NLP) for the Galician language. We present a Galician adaptation of the Alpaca dataset, comprising 52,000 instructions and demonstrations. This dataset proves invaluable for enhancing language models by fine-tuning them to more accurately adhere to provided instructions. Additionally, as a demonstration of the dataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician, a language not originally supported by the model, by following the Alpaca format. This work contributes to the research on multilingual models tailored for low-resource settings, a crucial endeavor in ensuring the inclusion of all linguistic communities in the development of Large Language Models. Another noteworthy aspect of this research is the exploration of how knowledge of a closely related language, in this case, Portuguese, can assist in generating coherent text when training resources are scarce. Both the Galician Alpaca dataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we have made the source code available to facilitate replication of this experiment and encourage further advancements for underrepresented languages.
</details>
<details>
<summary>摘要</summary>
最近大量对话语言模型的普及，抛砖了现代信息时代对这种人工智能技术的经济意义。然而，现有模型主要在受欢迎语言的文献库进行训练。这Result in low-resource语言的不足，进一步削弱了它们在当前经济景观中的表现，从而影响当地的native speakers。本文介绍了两个新资源，旨在提高 galician 语言的自然语言处理（NLP）。我们提供了一个 galician 化的 Alpaca 数据集，包括 52,000 个说明和示例。这个数据集对于提高语言模型进行精度的调整是非常有价值。此外，我们通过 Alpaca 格式，使用 LLaMA-7B 模型以 galician 语言进行理解和回答，这是原本不支持该语言的模型。这项研究对于针对低资源设置的多语言模型的研究具有重要意义，这是确保所有语言社区在大语言模型的发展中得到包容。此外，我们还发现了一个关键的发现：当资源稀缺时，了解相关语言的知识（在这种情况下是葡萄牙语）可以帮助生成 coherent 的文本。galician Alpaca 数据集和 Cabuxa-7B 模型都公开 accessible 在我们的 Huggingface Hub 上，并且我们已经提供了源代码，以便复现这个实验和促进低资源语言的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Pair-Corrector-for-Dense-Retrieval"><a href="#Noisy-Pair-Corrector-for-Dense-Retrieval" class="headerlink" title="Noisy Pair Corrector for Dense Retrieval"></a>Noisy Pair Corrector for Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03798">http://arxiv.org/abs/2311.03798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang Zhang, Yeyun Gong, Xingwei He, Dayiheng Liu, Daya Guo, Jiancheng Lv, Jian Guo</li>
<li>for: 本研究探讨了 dense retrieval 模型在受到匹配错误的情况下的表现，并提出了一种名为 Noisy Pair Corrector (NPC) 的解决方案。</li>
<li>methods: NPC 方法包括检测模块和修正模块，检测模块通过计算 позитив答案和易得负答案的抖擞来估算噪声对的对。修正模块使用 Exponential Moving Average (EMA) 模型提供一个软监督信号，以帮助减少噪声的影响。</li>
<li>results: 实验结果表明，NPC 在 Natural Question 和 TriviaQA 等文本检索 benchmark 上 exhibits 出色的表现，可以减少噪声对的影响并提高模型的表现。<details>
<summary>Abstract</summary>
Most dense retrieval models contain an implicit assumption: the training query-document pairs are exactly matched. Since it is expensive to annotate the corpus manually, training pairs in real-world applications are usually collected automatically, which inevitably introduces mismatched-pair noise. In this paper, we explore an interesting and challenging problem in dense retrieval, how to train an effective model with mismatched-pair noise. To solve this problem, we propose a novel approach called Noisy Pair Corrector (NPC), which consists of a detection module and a correction module. The detection module estimates noise pairs by calculating the perplexity between annotated positive and easy negative documents. The correction module utilizes an exponential moving average (EMA) model to provide a soft supervised signal, aiding in mitigating the effects of noise. We conduct experiments on text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks StaQC and SO-DS. Experimental results show that NPC achieves excellent performance in handling both synthetic and realistic noise.
</details>
<details>
<summary>摘要</summary>
大多数密集检索模型假设训练查询文档对是匹配的，但在实际应用中，训练对不可能手动注释整个库，这会导致匹配对杂谔噪声。在这篇论文中，我们研究一个有趣且挑战的 dense retrieval 问题：如何在匹配对杂谔噪声的情况下训练一个有效的模型。为解决这个问题，我们提出了一种新的方法called Noisy Pair Corrector (NPC)，它包括检测模块和修正模块。检测模块通过计算标注正方和易取负方文档的凝固性来估计噪声对。修正模块使用抽象移动平均（EMA）模型提供一个软件指导信号，以帮助减轻噪声的影响。我们在 Natural Question 和 TriviaQA 等文本检索标准套件上进行了实验，结果表明，NPC在处理 sintetic 和实际噪声方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Character-Level-Bangla-Text-to-IPA-Transcription-Using-Transformer-Architecture-with-Sequence-Alignment"><a href="#Character-Level-Bangla-Text-to-IPA-Transcription-Using-Transformer-Architecture-with-Sequence-Alignment" class="headerlink" title="Character-Level Bangla Text-to-IPA Transcription Using Transformer Architecture with Sequence Alignment"></a>Character-Level Bangla Text-to-IPA Transcription Using Transformer Architecture with Sequence Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03792">http://arxiv.org/abs/2311.03792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakir Hasan, Shrestha Datta, Ameya Debnath</li>
<li>For: The paper is written for the purpose of developing an Artificial Intelligence and Machine Learning-based system for accurate IPA mapping of Bangla words.* Methods: The paper uses a transformer-based sequence-to-sequence model at the letter and symbol level to map the IPA of each Bangla word. The model consists of 8.5 million parameters and only one decoder and encoder layer. Additionally, manual mapping is used to handle punctuation marks and foreign languages in the text.* Results: The paper achieves the top position in the public ranking of DataVerse Challenge - ITVerse 2023 with a word error rate of 0.10582.<details>
<summary>Abstract</summary>
The International Phonetic Alphabet (IPA) is indispensable in language learning and understanding, aiding users in accurate pronunciation and comprehension. Additionally, it plays a pivotal role in speech therapy, linguistic research, accurate transliteration, and the development of text-to-speech systems, making it an essential tool across diverse fields. Bangla being 7th as one of the widely used languages, gives rise to the need for IPA in its domain. Its IPA mapping is too diverse to be captured manually giving the need for Artificial Intelligence and Machine Learning in this field. In this study, we have utilized a transformer-based sequence-to-sequence model at the letter and symbol level to get the IPA of each Bangla word as the variation of IPA in association of different words is almost null. Our transformer model only consisted of 8.5 million parameters with only a single decoder and encoder layer. Additionally, to handle the punctuation marks and the occurrence of foreign languages in the text, we have utilized manual mapping as the model won't be able to learn to separate them from Bangla words while decreasing our required computational resources. Finally, maintaining the relative position of the sentence component IPAs and generation of the combined IPA has led us to achieve the top position with a word error rate of 0.10582 in the public ranking of DataVerse Challenge - ITVerse 2023 (https://www.kaggle.com/competitions/dataverse_2023/).
</details>
<details>
<summary>摘要</summary>
国际音声字母（IPA）是语言学习和理解的不可或缺的工具，帮助用户正确发音和理解。同时，它在语音疾病治疗、语言研究、准确转写和文本读取系统的开发中扮演着关键性的角色，因此在多个领域都是必备的工具。孟加拉语是全球第七大使用语言之一，因此在它的领域中也存在IPA的需求。孟加拉语的IPA映射非常复杂，需要使用人工智能和机器学习来处理。在这项研究中，我们使用了基于转换器的序列到序列模型，在字母和符号层次上进行了每个孟加拉语单词的IPA映射。我们的转换器模型只有8500万参数，仅有一个解码和编码层。此外，为了处理文本中的括号和外语，我们使用了手动映射，因为模型无法从孟加拉语单词中分离它们。最后，我们保持了句子组成部分的IPA相对位置，并生成了组合的IPA，使我们在DataVerse Challenge - ITVerse 2023（https://www.kaggle.com/competitions/dataverse_2023）公开排名中获得了第一名，word error rate为0.10582。
</details></li>
</ul>
<hr>
<h2 id="Language-Representation-Projection-Can-We-Transfer-Factual-Knowledge-across-Languages-in-Multilingual-Language-Models"><a href="#Language-Representation-Projection-Can-We-Transfer-Factual-Knowledge-across-Languages-in-Multilingual-Language-Models" class="headerlink" title="Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?"></a>Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03788">http://arxiv.org/abs/2311.03788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoyang Xu, Junzhuo Li, Deyi Xiong</li>
<li>for: 本研究探讨了将英语知识转移到非英语语言中的可能性，以提高多语言预训练语言模型中的事实知识探索性能。</li>
<li>methods: 我们提出了两种参数free的语言表示 проекtion模块（LRP2），以将非英语表示转换成英语相似的表示，并将英语表示还原回非英语语言的表示。</li>
<li>results: 实验结果表明，LRP2能够显著提高事实知识检索精度，并且可以在多种非英语语言中传递知识。我们还从语义表示空间和cross-语言知识神经的角度进行了机制分析。<details>
<summary>Abstract</summary>
Multilingual pretrained language models serve as repositories of multilingual factual knowledge. Nevertheless, a substantial performance gap of factual knowledge probing exists between high-resource languages and low-resource languages, suggesting limited implicit factual knowledge transfer across languages in multilingual pretrained language models. This paper investigates the feasibility of explicitly transferring relatively rich factual knowledge from English to non-English languages. To accomplish this, we propose two parameter-free $\textbf{L}$anguage $\textbf{R}$epresentation $\textbf{P}$rojection modules (LRP2). The first module converts non-English representations into English-like equivalents, while the second module reverts English-like representations back into representations of the corresponding non-English language. Experimental results on the mLAMA dataset demonstrate that LRP2 significantly improves factual knowledge retrieval accuracy and facilitates knowledge transferability across diverse non-English languages. We further investigate the working mechanism of LRP2 from the perspectives of representation space and cross-lingual knowledge neuron.
</details>
<details>
<summary>摘要</summary>
多语言预训成本模型作为多语言事实知识存储库。然而，高资源语言和低资源语言之间的事实知识探测性能存在显著差距，表明多语言预训模型之间的隐式事实知识传递有限。本文探究可以将英语上的较富事实知识显式传递到非英语语言上。为此，我们提议了两个参数无关的语言表示 проекtion模块（LRP2）。首先模块将非英语表示转换成英语相似的表示，其次模块将英语相似的表示恢复回到非英语语言的表示中。实验结果表明，LRP2能够显著提高事实知识检索精度和促进不同非英语语言之间的知识传递性。我们进一步从语言表示空间和跨语言知识神经的角度研究LRP2的工作机制。
</details></li>
</ul>
<hr>
<h2 id="Gender-Inflected-or-Bias-Inflicted-On-Using-Grammatical-Gender-Cues-for-Bias-Evaluation-in-Machine-Translation"><a href="#Gender-Inflected-or-Bias-Inflicted-On-Using-Grammatical-Gender-Cues-for-Bias-Evaluation-in-Machine-Translation" class="headerlink" title="Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation"></a>Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03767">http://arxiv.org/abs/2311.03767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iampushpdeep/gender-bias-hi-en-eval">https://github.com/iampushpdeep/gender-bias-hi-en-eval</a></li>
<li>paper_authors: Pushpdeep Singh</li>
<li>for: 这个研究的目的是评估基于印地语的自然语言处理机器翻译模型中的性别偏见。</li>
<li>methods: 这个研究使用了印地语的两个集成集：OTSC-Hindi和WinoMT-Hindi，用于自动评估不同的印地语-英语（HI-EN）机器翻译系统中的性别偏见。</li>
<li>results: 这个研究发现，基于印地语的机器翻译系统中存在性别偏见，并且这种偏见与英语为源语言的研究结果不同。这个研究指出，在设计外部偏见评估数据集时，需要考虑语言的性质。<details>
<summary>Abstract</summary>
Neural Machine Translation (NMT) models are state-of-the-art for machine translation. However, these models are known to have various social biases, especially gender bias. Most of the work on evaluating gender bias in NMT has focused primarily on English as the source language. For source languages different from English, most of the studies use gender-neutral sentences to evaluate gender bias. However, practically, many sentences that we encounter do have gender information. Therefore, it makes more sense to evaluate for bias using such sentences. This allows us to determine if NMT models can identify the correct gender based on the grammatical gender cues in the source sentence rather than relying on biased correlations with, say, occupation terms. To demonstrate our point, in this work, we use Hindi as the source language and construct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi that we use to evaluate different Hindi-English (HI-EN) NMT systems automatically for gender bias. Our work highlights the importance of considering the nature of language when designing such extrinsic bias evaluation datasets.
</details>
<details>
<summary>摘要</summary>
神经机器翻译（NMT）模型目前是翻译机器学会的国际标准。然而，这些模型经常带有各种社会偏见，特别是性别偏见。大多数对NMT模型的性别偏见评估都集中在英语作为源语言。对于不同的源语言，大多数研究使用中性句子来评估性别偏见。然而，在实际生活中，我们常遇到带有性别信息的句子。因此，更加合理地评估NMT模型是否能够根据源句子中的 grammatical gender 信息正确地识别性别。为了证明我们的点，在这项工作中，我们使用旁遮普语作为源语言，并构建了两个 gender-specific 句子集：OTSC-Hindi 和 WinoMT-Hindi，以自动评估不同的旁遮普语-英语（HI-EN） NMT 系统的性别偏见。我们的工作强调了在设计这类外部偏见评估数据时应考虑语言的特点。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Mathematical-Autoformalization"><a href="#Multilingual-Mathematical-Autoformalization" class="headerlink" title="Multilingual Mathematical Autoformalization"></a>Multilingual Mathematical Autoformalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03755">http://arxiv.org/abs/2311.03755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albertqjiang/mma">https://github.com/albertqjiang/mma</a></li>
<li>paper_authors: Albert Q. Jiang, Wenda Li, Mateja Jamnik</li>
<li>for: 该论文目的是提出一个大型、灵活、多语言、多领域的自动化形式化数据集，以便提高自动化形式化研究的进步。</li>
<li>methods: 该论文使用语言模型将正式数学陈述翻译成相应的非正式陈述，以创建一个大型、多语言、多领域的自动化形式化数据集。</li>
<li>results: 实验表明，将语言模型在$\texttt{MMA}$数据集上进行微调，可以提高自动化形式化模型在$\texttt{miniF2F}$和$\texttt{ProofNet}$测试 benchmark 上的表现，从0%提高到16-18%。此外，该研究还示出了在多语言正式数据上进行微调可以提高自动化形式化模型在单语言任务上的表现。<details>
<summary>Abstract</summary>
Autoformalization is the task of translating natural language materials into machine-verifiable formalisations. Progress in autoformalization research is hindered by the lack of a sizeable dataset consisting of informal-formal pairs expressing the same essence. Existing methods tend to circumvent this challenge by manually curating small corpora or using few-shot learning with large language models. But these methods suffer from data scarcity and formal language acquisition difficulty. In this work, we create $\texttt{MMA}$, a large, flexible, multilingual, and multi-domain dataset of informal-formal pairs, by using a language model to translate in the reverse direction, that is, from formal mathematical statements into corresponding informal ones. Experiments show that language models fine-tuned on $\texttt{MMA}$ produce $16-18\%$ of statements acceptable with minimal corrections on the $\texttt{miniF2F}$ and $\texttt{ProofNet}$ benchmarks, up from $0\%$ with the base model. We demonstrate that fine-tuning on multilingual formal data results in more capable autoformalization models even when deployed on monolingual tasks.
</details>
<details>
<summary>摘要</summary>
自然语言材料的自动化正式化任务是将自然语言材料翻译成机器可验证的形式化表达。研究进步受到没有大量的正式-非正式对应对的数据集的限制。现有方法通常使用手动批处小样本或使用大语言模型几招学习来绕过这个挑战。但这些方法受到数据缺乏和正式语言学习困难的限制。在这项工作中，我们创建了$\texttt{MMA}$数据集，这是一个大型、灵活、多语言和多领域的正式-非正式对应对数据集，我们使用语言模型将正式数学陈述翻译到对应的非正式陈述中。实验显示，将语言模型在$\texttt{MMA}$上进行 fine-tuning 后，在 $\texttt{miniF2F}$ 和 $\texttt{ProofNet}$ 测试benchmark上的AcceptableStatement数增加了16-18%，与基本模型相比增加了0%。我们示出了在多语言正式数据上进行 fine-tuning 后，在单语言任务上部署的自动化正式化模型会更具备能力。
</details></li>
</ul>
<hr>
<h2 id="Which-is-better-Exploring-Prompting-Strategy-For-LLM-based-Metrics"><a href="#Which-is-better-Exploring-Prompting-Strategy-For-LLM-based-Metrics" class="headerlink" title="Which is better? Exploring Prompting Strategy For LLM-based Metrics"></a>Which is better? Exploring Prompting Strategy For LLM-based Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03754">http://arxiv.org/abs/2311.03754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin Lee, Seung Hun Han, Jiyoon Lee, Pilsung Kang</li>
<li>for: 这 paper 描述了在 Prompting Large Language Models as Explainable Metrics 共同任务中提交的 DSBA 提交，系统在两个 tracks：小summarization 和 large summarization  tracks 上进行了评估。</li>
<li>methods: 这 paper 使用了高级的 Large Language Models (LLMs) 如 GPT-4，以评估自然语言生成质量（NLG）的新方法。传统的相似性基于metric 如 BLEU 和 ROUGE 已经显示出来了与人类评估不一致，不适合开放式生成任务。为了解决这个问题，我们探索了 LLM-based metric 的潜在能力，特别是使用开源 LLMs。在这种研究中，我们系统地分析了各种提示和提示技术，并使用三种方法：提示策略、分数聚合和解释性。</li>
<li>results: 我们的研究表明，使用开源 LLMs 可以获得更高的评估精度，并且可以通过提示策略和分数聚合来提高NLG质量评估的可靠性。此外，我们还发现，通过生成 rationales 可以提供更多的解释，并且可以通过分析这些解释来了解 LLMs 的性能。<details>
<summary>Abstract</summary>
This paper describes the DSBA submissions to the Prompting Large Language Models as Explainable Metrics shared task, where systems were submitted to two tracks: small and large summarization tracks. With advanced Large Language Models (LLMs) such as GPT-4, evaluating the quality of Natural Language Generation (NLG) has become increasingly paramount. Traditional similarity-based metrics such as BLEU and ROUGE have shown to misalign with human evaluation and are ill-suited for open-ended generation tasks. To address this issue, we explore the potential capability of LLM-based metrics, especially leveraging open-source LLMs. In this study, wide range of prompts and prompting techniques are systematically analyzed with three approaches: prompting strategy, score aggregation, and explainability. Our research focuses on formulating effective prompt templates, determining the granularity of NLG quality scores and assessing the impact of in-context examples on LLM-based evaluation. Furthermore, three aggregation strategies are compared to identify the most reliable method for aggregating NLG quality scores. To examine explainability, we devise a strategy that generates rationales for the scores and analyzes the characteristics of the explanation produced by the open-source LLMs. Extensive experiments provide insights regarding evaluation capabilities of open-source LLMs and suggest effective prompting strategies.
</details>
<details>
<summary>摘要</summary>
The study systematically analyzes a wide range of prompts and prompting techniques using three approaches: prompting strategy, score aggregation, and explainability. The focus is on formulating effective prompt templates, determining the granularity of NLG quality scores, and assessing the impact of in-context examples on LLM-based evaluation. Additionally, the paper compares three aggregation strategies to determine the most reliable method for aggregating NLG quality scores. To examine explainability, the paper devises a strategy that generates rationales for the scores and analyzes the characteristics of the explanations produced by the open-source LLMs.Extensive experiments provide insights into the evaluation capabilities of open-source LLMs and suggest effective prompting strategies. The paper concludes that LLM-based metrics have the potential to provide more accurate evaluations of NLG quality, and that careful consideration of prompting strategies and score aggregation methods is essential for obtaining reliable results.
</details></li>
</ul>
<hr>
<h2 id="Unified-Low-Resource-Sequence-Labeling-by-Sample-Aware-Dynamic-Sparse-Finetuning"><a href="#Unified-Low-Resource-Sequence-Labeling-by-Sample-Aware-Dynamic-Sparse-Finetuning" class="headerlink" title="Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning"></a>Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03748">http://arxiv.org/abs/2311.03748</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/fish-dip">https://github.com/psunlpgroup/fish-dip</a></li>
<li>paper_authors: Sarkar Snigdha Sarathi Das, Ranran Haoran Zhang, Peng Shi, Wenpeng Yin, Rui Zhang</li>
<li>for: 提高sequence labeling任务中的模型性能，尤其是在数据有限的情况下。</li>
<li>methods: 提出了一种sample-aware dynamic sparse finetuning策略，通过在精度训练过程中选择一部分参数，根据反馈从高度预测错误的示例而决定，以便增强通用化。</li>
<li>results: 在五种sequence labeling任务上，实现了在低资源环境下缓和模型优化，提高性能，最高可达40%，并与另外的parameter-efficient fine-tuning和in-context learning策略相比，在极低资源环境下表现较好。<details>
<summary>Abstract</summary>
Unified Sequence Labeling that articulates different sequence labeling problems such as Named Entity Recognition, Relation Extraction, Semantic Role Labeling, etc. in a generalized sequence-to-sequence format opens up the opportunity to make the maximum utilization of large language model knowledge toward structured prediction. Unfortunately, this requires formatting them into specialized augmented format unknown to the base pretrained language model (PLMs) necessitating finetuning to the target format. This significantly bounds its usefulness in data-limited settings where finetuning large models cannot properly generalize to the target format. To address this challenge and leverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic sparse finetuning strategy that selectively focuses on a fraction of parameters, informed by feedback from highly regressing examples, during the fine-tuning process. By leveraging the dynamism of sparsity, our approach mitigates the impact of well-learned samples and prioritizes underperforming instances for improvement in generalization. Across five tasks of sequence labeling, we demonstrate that FISH-DIP can smoothly optimize the model in low resource settings offering upto 40% performance improvements over full fine-tuning depending on target evaluation settings. Also, compared to in-context learning and other parameter-efficient fine-tuning approaches, FISH-DIP performs comparably or better, notably in extreme low-resource settings.
</details>
<details>
<summary>摘要</summary>
通用序列标签（Unified Sequence Labeling）可以将不同的序列标签问题（如命名实体识别、关系抽取、Semantic Role Labeling等）转换为通用的序列到序列的格式，从而使最大化语言模型知识的应用于结构预测。然而，这需要将其格式化为特殊的扩展格式，这些格式不знаком于基础预训练语言模型（PLMs），因此需要进行迁移学习。这会限制其在数据有限的设置中的使用，因为大型模型在目标格式上不能良好总结。为解决这个挑战并有效地利用PLM知识，我们提出了鱼雏钻探（FISH-DIP），一种样本意识的动态稀疏训练策略。通过在训练过程中选择一部分参数，并在这些参数上进行稀疏训练，我们的方法可以减轻已经学习好的样本的影响，并且优先级推动不良表现的实例进行改进。在五种序列标签任务上，我们示出了FISH-DIP可以在低资源设置下细化模型，提供大约40%的性能提升，具体取决于目标评估设置。同时，相比卷积学习和其他参数效率的训练方法，FISH-DIP在极低资源设置下表现相当或更好。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Structured-Information-for-Explainable-Multi-hop-Question-Answering-and-Reasoning"><a href="#Leveraging-Structured-Information-for-Explainable-Multi-hop-Question-Answering-and-Reasoning" class="headerlink" title="Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning"></a>Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03734">http://arxiv.org/abs/2311.03734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruosen Li, Xinya Du</li>
<li>for: 本研究旨在探讨如何通过提取文本中的semantic结构来提高多步问答中的推理能力。</li>
<li>methods: 本研究使用信息提取技术来提取文本中的实体、关系和事件，并构建了基于这些结构的多步问答框架。</li>
<li>results: 实验和人类评价表明，我们的框架可以生成更加 faithful的推理链和显著提高两个标准测试集的问答性能。此外，提取的结构本身就提供了固有的解释，比如生成的推理链和优先级基于的解释更受人类喜欢。<details>
<summary>Abstract</summary>
Neural models, including large language models (LLMs), achieve superior performance on multi-hop question-answering. To elicit reasoning capabilities from LLMs, recent works propose using the chain-of-thought (CoT) mechanism to generate both the reasoning chain and the answer, which enhances the model's capabilities in conducting multi-hop reasoning. However, several challenges still remain: such as struggling with inaccurate reasoning, hallucinations, and lack of interpretability. On the other hand, information extraction (IE) identifies entities, relations, and events grounded to the text. The extracted structured information can be easily interpreted by humans and machines (Grishman, 2019). In this work, we investigate constructing and leveraging extracted semantic structures (graphs) for multi-hop question answering, especially the reasoning process. Empirical results and human evaluations show that our framework: generates more faithful reasoning chains and substantially improves the QA performance on two benchmark datasets. Moreover, the extracted structures themselves naturally provide grounded explanations that are preferred by humans, as compared to the generated reasoning chains and saliency-based explanations.
</details>
<details>
<summary>摘要</summary>
神经网络模型，包括大型语言模型（LLM），在多步问答中表现出优秀的性能。为了从LLM中提取逻辑能力， latest works提议使用链条思维（CoT）机制来生成问答和逻辑链，从而提高模型的多步逻辑能力。然而，还有一些挑战需要解决：如果推理不准确，幻觉和解释性不足。对此，信息提取（IE）可以识别文本中的实体、关系和事件，并将其与文本相关联。提取的结构化信息可以轻松地被人类和机器解释（Grishman，2019）。在这项工作中，我们研究构建和利用提取的semantic structures（图）来进行多步问答，特别是逻辑过程。实验结果和人工评价表明，我们的框架：生成更加 faithful的逻辑链和对两个 benchmark datasets 的问答性能提高了很多。此外，提取的结构本身就自然提供了基于实体的解释，与生成的逻辑链和saliency-based解释相比，更受人类喜欢。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Learn-for-Few-shot-Continual-Active-Learning"><a href="#Learning-to-Learn-for-Few-shot-Continual-Active-Learning" class="headerlink" title="Learning to Learn for Few-shot Continual Active Learning"></a>Learning to Learn for Few-shot Continual Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03732">http://arxiv.org/abs/2311.03732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stella Ho, Ming Liu, Shang Gao, Longxiang Gao</li>
<li>for: 这篇论文旨在解决对于前置任务的稳定性和新任务的灵活性之间的冲突，特别是在自然语言处理领域。</li>
<li>methods: 这篇论文提出了一个简单 yet efficient的方法，called Meta-Continual Active Learning，并使用meta-学习和经验回顾来解决稳定性和灵活性之间的冲突。</li>
<li>results: 实验结果显示，这篇论文的提案方法可以快速地适应新任务，同时避免遗传性忘记。另外，我们还分析了不同的活动学习策略和内存抽样方法在几个shot CAL设定下的效果。<details>
<summary>Abstract</summary>
Continual learning strives to ensure stability in solving previously seen tasks while demonstrating plasticity in a novel domain. Recent advances in CL are mostly confined to a supervised learning setting, especially in NLP domain. In this work, we consider a few-shot continual active learning (CAL) setting where labeled data is inadequate, and unlabeled data is abundant but with a limited annotation budget. We propose a simple but efficient method, called Meta-Continual Active Learning. Specifically, we employ meta-learning and experience replay to address the trade-off between stability and plasticity. As a result, it finds an optimal initialization that efficiently utilizes annotated information for fast adaptation while preventing catastrophic forgetting of past tasks. We conduct extensive experiments to validate the effectiveness of the proposed method and analyze the effect of various active learning strategies and memory sample selection methods in a few-shot CAL setup. Our experiment results demonstrate that random sampling is the best default strategy for both active learning and memory sample selection to solve few-shot CAL problems.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Large-Language-Models-Attribution"><a href="#A-Survey-of-Large-Language-Models-Attribution" class="headerlink" title="A Survey of Large Language Models Attribution"></a>A Survey of Large Language Models Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03731">http://arxiv.org/abs/2311.03731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/awesome-llm-attributions">https://github.com/HITsz-TMG/awesome-llm-attributions</a></li>
<li>paper_authors: Dongfang Li, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Ziyang Chen, Baotian Hu, Aiguo Wu, Min Zhang</li>
<li>for: 本研究旨在批判开放领域生成系统中使用的归因机制，特别是大语言模型。</li>
<li>methods: 本文综述了开放领域生成系统中归因机制的应用，包括归因搜索引擎等。</li>
<li>results: 本研究发现，归因机制可以提高开放领域生成系统的可靠性和准确性，但也存在问题，如知识库含义不明确、内置偏见和过度归因等。<details>
<summary>Abstract</summary>
Open-domain generative systems have gained significant attention in the field of conversational AI (e.g., generative search engines). This paper presents a comprehensive review of the attribution mechanisms employed by these systems, particularly large language models. Though attribution or citation improve the factuality and verifiability, issues like ambiguous knowledge reservoirs, inherent biases, and the drawbacks of excessive attribution can hinder the effectiveness of these systems. The aim of this survey is to provide valuable insights for researchers, aiding in the refinement of attribution methodologies to enhance the reliability and veracity of responses generated by open-domain generative systems. We believe that this field is still in its early stages; hence, we maintain a repository to keep track of ongoing studies at https://github.com/HITsz-TMG/awesome-llm-attributions.
</details>
<details>
<summary>摘要</summary>
开放领域生成系统在对话AI领域已经吸引了广泛的注意力（例如生成搜索引擎）。本文对这些系统使用的归因机制进行了全面的审查，特别是大语言模型。归因或参考可以提高回答的 фактиче性和可靠性，但是存在困难的知识库、内置偏见和过度归因的问题可能会妨碍这些系统的效iveness。本评论的目的是为研究人员提供有价值的洞察，以便通过修正归因方法来提高开放领域生成系统的可靠性和真实性。我们认为这个领域还处于早期阶段，因此我们维护了一个Repository，以跟踪进行中的研究：https://github.com/HITsz-TMG/awesome-llm-attributions。
</details></li>
</ul>
<hr>
<h2 id="Bilingual-Corpus-Mining-and-Multistage-Fine-Tuning-for-Improving-Machine-Translation-of-Lecture-Transcripts"><a href="#Bilingual-Corpus-Mining-and-Multistage-Fine-Tuning-for-Improving-Machine-Translation-of-Lecture-Transcripts" class="headerlink" title="Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine Translation of Lecture Transcripts"></a>Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine Translation of Lecture Transcripts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03696">http://arxiv.org/abs/2311.03696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shyyhs/CourseraParallelCorpusMining">https://github.com/shyyhs/CourseraParallelCorpusMining</a></li>
<li>paper_authors: Haiyue Song, Raj Dabre, Chenhui Chu, Atsushi Fujita, Sadao Kurohashi</li>
<li>for: 这 paper 是为了提高在线课程学习译文质量的研究。</li>
<li>methods: 这 paper 使用了一种框架，用于从 Coursera 上的公开课课程中提取并构建平行 corpora，并使用动态计划法进行句子对齐。</li>
<li>results: 这 paper 的实验表明，使用这些自动生成的平行 corpora可以提高 lecture 笔记翻译质量，并且可以与预处理的平行 corpora相比肃。此外，这 paper 还提供了一些有关收集和清洁 corpora、提取平行句子和创建高质量评估分割的指南。<details>
<summary>Abstract</summary>
Lecture transcript translation helps learners understand online courses, however, building a high-quality lecture machine translation system lacks publicly available parallel corpora. To address this, we examine a framework for parallel corpus mining, which provides a quick and effective way to mine a parallel corpus from publicly available lectures on Coursera. To create the parallel corpora, we propose a dynamic programming based sentence alignment algorithm which leverages the cosine similarity of machine-translated sentences. The sentence alignment F1 score reaches 96%, which is higher than using the BERTScore, LASER, or sentBERT methods. For both English--Japanese and English--Chinese lecture translations, we extracted parallel corpora of approximately 50,000 lines and created development and test sets through manual filtering for benchmarking translation performance. Through machine translation experiments, we show that the mined corpora enhance the quality of lecture transcript translation when used in conjunction with out-of-domain parallel corpora via multistage fine-tuning. Furthermore, this study also suggests guidelines for gathering and cleaning corpora, mining parallel sentences, cleaning noise in the mined data, and creating high-quality evaluation splits. For the sake of reproducibility, we have released the corpora as well as the code to create them. The dataset is available at https://github.com/shyyhs/CourseraParallelCorpusMining.
</details>
<details>
<summary>摘要</summary>
讲义笔录翻译帮助学习者理解在线课程，但建立高质量讲义翻译系统缺乏公共可用的平行 corpora。为解决这问题，我们提出了平行 corpora 挖掘框架，该框架可以快速并有效地挖掘来自 Coursera 上公共讲义的平行 corpora。为创建平行 corpora，我们提议使用动态编程基于 sentence alignment 算法，利用机器翻译后的句子之间的 косинуsimilarity。 sentence alignment F1 分数达96%，高于使用 BERTScore、LASER 或 sentBERT 方法。对英语--日语和英语--中文讲义翻译，我们提取了约50,000行的平行 corpora，并通过手动筛选创建了开发测试集。通过机器翻译实验，我们示示了挖掘后的 corpora 可以提高讲义笔录翻译质量。此外，本研究还提供了收集和清洁 corpora、挖掘平行句子、清理挖掘后数据中的噪音以及创建高质量评估分割的指南。为保持可重现性，我们已经发布了 corpora 以及创建它们所需的代码，数据集可在 GitHub 上获取：https://github.com/shyyhs/CourseraParallelCorpusMining。
</details></li>
</ul>
<hr>
<h2 id="Dissecting-the-Runtime-Performance-of-the-Training-Fine-tuning-and-Inference-of-Large-Language-Models"><a href="#Dissecting-the-Runtime-Performance-of-the-Training-Fine-tuning-and-Inference-of-Large-Language-Models" class="headerlink" title="Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models"></a>Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03687">http://arxiv.org/abs/2311.03687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longteng Zhang, Xiang Liu, Zeyu Li, Xinglin Pan, Peijie Dong, Ruibo Fan, Rui Guo, Xin Wang, Qiong Luo, Shaohuai Shi, Xiaowen Chu</li>
<li>for: 本文旨在 benchmarking 大型语言模型（LLMs）在不同硬件和软件栈上的运行性能，以帮助用户更好地选择配置并优化系统架构。</li>
<li>methods: 本文使用了多种优化技术，包括 ZeRO、量化、重computation 和 FlashAttention，以提高 LLMS 的运行性能。</li>
<li>results: 本文的结果表明，在不同硬件和软件栈上，不同大小的 LLMS 的运行性能有很大差异。通过对不同优化技术和硬件平台的分析，本文可以帮助用户更好地选择配置并优化系统架构。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have seen great advance in both academia and industry, and their popularity results in numerous open-source frameworks and techniques in accelerating LLM pre-training, fine-tuning, and inference. Training and deploying LLMs are expensive as it requires considerable computing resources and memory, hence many efficient approaches have been developed for improving system pipelines as well as operators. However, the runtime performance can vary significantly across hardware and software stacks, which makes it difficult to choose the best configuration. In this work, we aim to benchmark the performance from both macro and micro perspectives. First, we benchmark the end-to-end performance of pre-training, fine-tuning, and serving LLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and 70B) on three 8-GPU platforms with and without individual optimization techniques, including ZeRO, quantization, recomputation, FlashAttention. Then, we dive deeper to provide a detailed runtime analysis of the sub-modules, including computing and communication operators in LLMs. For end users, our benchmark and findings help better understand different optimization techniques, training and inference frameworks, together with hardware platforms in choosing configurations for deploying LLMs. For researchers, our in-depth module-wise analyses discover potential opportunities for future work to further optimize the runtime performance of LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CBSiMT-Mitigating-Hallucination-in-Simultaneous-Machine-Translation-with-Weighted-Prefix-to-Prefix-Training"><a href="#CBSiMT-Mitigating-Hallucination-in-Simultaneous-Machine-Translation-with-Weighted-Prefix-to-Prefix-Training" class="headerlink" title="CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation with Weighted Prefix-to-Prefix Training"></a>CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation with Weighted Prefix-to-Prefix Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03672">http://arxiv.org/abs/2311.03672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengge Liu, Wen Zhang, Xiang Li, Yanzhi Tian, Yuhang Guo, Jian Luan, Bin Wang, Shuoying Chen</li>
<li>for: 提高同时翻译（SiMT）任务中的翻译质量，特别是在源语言句子只有部分内容时开始翻译。</li>
<li>methods: 使用 prefix-to-prefix 框架，学习预测目标单词使用只有部分源prefix。但是由于语言的单词顺序不同，可能会导致模型uffer hallucination问题，即目标输出不符合源输入。</li>
<li>results: 提出了一种 Confidence-Based Simultaneous Machine Translation（CBSiMT）框架，通过模型自信度来识别hallucination单词，并通过加权 prefix-to-prefix 训练来缓解其影响。实验结果在 MuST-C 英语-中文和 WMT15 德语-英语 SiMT任务上表明，我们的方法可以在不同的延迟情况下， consistent 提高翻译质量，最高达到 2 BLEU 分数提升。<details>
<summary>Abstract</summary>
Simultaneous machine translation (SiMT) is a challenging task that requires starting translation before the full source sentence is available. Prefix-to-prefix framework is often applied to SiMT, which learns to predict target tokens using only a partial source prefix. However, due to the word order difference between languages, misaligned prefix pairs would make SiMT models suffer from serious hallucination problems, i.e. target outputs that are unfaithful to source inputs. Such problems can not only produce target tokens that are not supported by the source prefix, but also hinder generating the correct translation by receiving more source words. In this work, we propose a Confidence-Based Simultaneous Machine Translation (CBSiMT) framework, which uses model confidence to perceive hallucination tokens and mitigates their negative impact with weighted prefix-to-prefix training. Specifically, token-level and sentence-level weights are calculated based on model confidence and acted on the loss function. We explicitly quantify the faithfulness of the generated target tokens using the token-level weight, and employ the sentence-level weight to alleviate the disturbance of sentence pairs with serious word order differences on the model. Experimental results on MuST-C English-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our method can consistently improve translation quality at most latency regimes, with up to 2 BLEU scores improvement at low latency.
</details>
<details>
<summary>摘要</summary>
同时机器翻译（SiMT）是一项具有挑战性的任务，需要在源句子完全可用之前开始翻译。prefix-to-prefix框架经常用于SiMT，这种方法学习预测目标字符串使用只有部分源前缀。然而，由于语言之间的单词顺序差异，不一致的前缀对SiMT模型会导致严重的幻觉问题，即目标输出不符合源输入。这些问题不仅会生成不支持源前缀的目标字符串，还会阻碍正确翻译的生成 by receiving more source words。在这项工作中，我们提出了一种信息量基础同时机器翻译（CBSiMT）框架，使用模型信息量来识别幻觉字符串并减轻其影响。具体来说，我们计算了基于模型信息量的字符串级和句子级权重，并将其作用到损失函数中。我们Explicitly量化生成的目标字符串的准确程度使用字符串级权重，并使用句子级权重来减轻 Word order differences between sentences on the model.实验结果表明，我们的方法可以在不同的延迟级别上 consistently 提高翻译质量，并在低延迟级别上达到2 BLEU 分数的提高。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-NLP-Models-Notion-and-Causation"><a href="#Generalization-of-NLP-Models-Notion-and-Causation" class="headerlink" title="Generalization of NLP Models: Notion and Causation"></a>Generalization of NLP Models: Notion and Causation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03663">http://arxiv.org/abs/2311.03663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aparna Elangovan, Jiayuan He, Yuan Li, Karin Verspoor</li>
<li>for: 这篇论文主要是为了探讨机器学习模型在自然语言处理领域的总体化能力和可重用性。</li>
<li>methods: 论文使用了严格的实验设计和数据分析方法来研究机器学习模型的可重用性。</li>
<li>results: 研究发现，在不同的数据集上，机器学习模型的性能会受到“外部随机效应”的影响，导致模型的总体化能力受到限制。<details>
<summary>Abstract</summary>
The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to "out-of-distribution'' effects. Here, we explore the foundations of generalizability and study the various factors that affect it, articulating generalizability lessons from clinical studies. In clinical research generalizability depends on (a) internal validity of experiments to ensure controlled measurement of cause and effect, and (b) external validity or transportability of the results to the wider population. We present the need to ensure internal validity when building machine learning models in natural language processing, especially where results may be impacted by spurious correlations in the data. We demonstrate how spurious factors, such as the distance between entities in relation extraction tasks, can affect model internal validity and in turn adversely impact generalization. We also offer guidance on how to analyze generalization failures.
</details>
<details>
<summary>摘要</summary>
《NLP社区通常通过模型在保留测试集上的性能来评估通用性。测试集外的性能下降通常被归结为“非常区”的效果。本文探讨通用性的基础和不同因素的影响，从临床研究中提取通用性评估的教训。在自然语言处理中建模时，特别是当结果受到数据中的偶极相关性的影响时，需要保证内部有效性。我们示例了如何使用距离Entity之间的关系提取任务中的偶极相关性，对模型的内部有效性产生影响，从而对通用性产生负面影响。我们还提供了分析通用性失败的指导。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Innovation-and-Word-Usage-Patterns-in-Machine-Learning"><a href="#Innovation-and-Word-Usage-Patterns-in-Machine-Learning" class="headerlink" title="Innovation and Word Usage Patterns in Machine Learning"></a>Innovation and Word Usage Patterns in Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03633">http://arxiv.org/abs/2311.03633</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vitorbborges/monografia-PET22">https://github.com/vitorbborges/monografia-PET22</a></li>
<li>paper_authors: Vítor Bandeira Borges, Daniel Oliveira Cajueiro</li>
<li>for: 本研究探讨机器学习研究的动态景观演化。</li>
<li>methods: 通过矩阵Dirichlet分配来归纳出重要主题和基本概念，并对这些主题进行了全面的演化分析。</li>
<li>results: 通过使用卷积-莱布器分配度量，量化研究贡献的新颖度和偏离度，并发现了一些重要的研究人员和学术会议在机器学习领域的积极作用。<details>
<summary>Abstract</summary>
In this study, we delve into the dynamic landscape of machine learning research evolution. Initially, through the utilization of Latent Dirichlet Allocation, we discern pivotal themes and fundamental concepts that have emerged within the realm of machine learning. Subsequently, we undertake a comprehensive analysis to track the evolutionary trajectories of these identified themes. To quantify the novelty and divergence of research contributions, we employ the Kullback-Leibler Divergence metric. This statistical measure serves as a proxy for ``surprise'', indicating the extent of differentiation between the content of academic papers and the subsequent developments in research. By amalgamating these insights, we gain the ability to ascertain the pivotal roles played by prominent researchers and the significance of specific academic venues (periodicals and conferences) within the machine learning domain.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们探索机器学习研究脉络的动态景观。首先，通过使用秘密分配方法，我们分析出机器学习领域中突出的主题和基本概念。然后，我们进行了全面的分析，跟踪这些确定的主题的进化轨迹。为了量化研究贡献的新鲜性和偏离度，我们使用废弃抽象熵度量。这个统计指标作为一种代表“惊喜”的指标，反映了研究论文中的内容与后续研究的不同程度。通过结合这些洞察，我们得到了机器学习领域中重要研究者和期刊（杂志和会议）的重要性。
</details></li>
</ul>
<hr>
<h2 id="GNAT-A-General-Narrative-Alignment-Tool"><a href="#GNAT-A-General-Narrative-Alignment-Tool" class="headerlink" title="GNAT: A General Narrative Alignment Tool"></a>GNAT: A General Narrative Alignment Tool</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03627">http://arxiv.org/abs/2311.03627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanzir Pial, Steven Skiena</li>
<li>for: 本研究旨在开发一种通用的narativeAlignment算法，用于对短版文本之间进行对比和对alignment。</li>
<li>methods: 该算法结合Smith-Waterman算法和现代文本相似度指标，可以快速和准确地找到在短版文本之间的相似性。</li>
<li>results: 研究人员通过应用GNAT算法在四个不同的问题领域进行了评估，包括摘要到书籍对齐、翻译书籍对齐、短篇对齐和抄袭检测，并达到了良好的性能。<details>
<summary>Abstract</summary>
Algorithmic sequence alignment identifies similar segments shared between pairs of documents, and is fundamental to many NLP tasks. But it is difficult to recognize similarities between distant versions of narratives such as translations and retellings, particularly for summaries and abridgements which are much shorter than the original novels.   We develop a general approach to narrative alignment coupling the Smith-Waterman algorithm from bioinformatics with modern text similarity metrics. We show that the background of alignment scores fits a Gumbel distribution, enabling us to define rigorous p-values on the significance of any alignment. We apply and evaluate our general narrative alignment tool (GNAT) on four distinct problem domains differing greatly in both the relative and absolute length of documents, namely summary-to-book alignment, translated book alignment, short story alignment, and plagiarism detection -- demonstrating the power and performance of our methods.
</details>
<details>
<summary>摘要</summary>
算法序列Alignment标识 Shared between pairs of documents Similar segments, and is fundamental to many NLP tasks. However, it is difficult to recognize similarities between distant versions of narratives such as translations and retellings, particularly for summaries and abridgments, which are much shorter than the original novels.  We develop a general approach to narrative alignment, coupling the Smith-Waterman algorithm from bioinformatics with modern text similarity metrics. We show that the background of alignment scores fits a Gumbel distribution, enabling us to define rigorous p-values on the significance of any alignment. We apply and evaluate our general narrative alignment tool (GNAT) on four distinct problem domains differing greatly in both the relative and absolute length of documents, namely summary-to-book alignment, translated book alignment, short story alignment, and plagiarism detection -- demonstrating the power and performance of our methods.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.CL_2023_11_07/" data-id="cloqtaepn00e2gh8874k50m8z" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/07/cs.AI_2023_11_07/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-11-07
        
      </div>
    </a>
  
  
    <a href="/2023/11/07/cs.LG_2023_11_07/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-11-07</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
