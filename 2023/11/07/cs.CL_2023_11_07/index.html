
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-11-07 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04378 repo_url: None paper_authors: Hanlin Zhang, Benjamin L. Edelman, Danilo Fr">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-11-07">
<meta property="og:url" content="https://nullscc.github.io/2023/11/07/cs.CL_2023_11_07/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04378 repo_url: None paper_authors: Hanlin Zhang, Benjamin L. Edelman, Danilo Fr">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-07T11:00:00.000Z">
<meta property="article:modified_time" content="2023-11-09T07:31:44.175Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.CL_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T11:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-11-07
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Watermarks-in-the-Sand-Impossibility-of-Strong-Watermarking-for-Generative-Models"><a href="#Watermarks-in-the-Sand-Impossibility-of-Strong-Watermarking-for-Generative-Models" class="headerlink" title="Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models"></a>Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04378">http://arxiv.org/abs/2311.04378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanlin Zhang, Benjamin L. Edelman, Danilo Francati, Daniele Venturi, Giuseppe Ateniese, Boaz Barak</li>
<li>for:  This paper studies the (im)possibility of strong watermarking schemes for generative models.</li>
<li>methods:  The paper introduces a generic efficient watermark attack that can remove watermarks planted by existing schemes with only minor quality degradation. The attack is based on two assumptions: access to a “quality oracle” and “perturbation oracle”.</li>
<li>results:  The paper proves that strong watermarking is impossible to achieve under well-specified and natural assumptions, even in the private detection algorithm setting. The attack is demonstrated to be feasible by instantiating it to attack three existing watermarking schemes for large language models.<details>
<summary>Abstract</summary>
Watermarking generative models consists of planting a statistical signal (watermark) in a model's output so that it can be later verified that the output was generated by the given model. A strong watermarking scheme satisfies the property that a computationally bounded attacker cannot erase the watermark without causing significant quality degradation. In this paper, we study the (im)possibility of strong watermarking schemes. We prove that, under well-specified and natural assumptions, strong watermarking is impossible to achieve. This holds even in the private detection algorithm setting, where the watermark insertion and detection algorithms share a secret key, unknown to the attacker. To prove this result, we introduce a generic efficient watermark attack; the attacker is not required to know the private key of the scheme or even which scheme is used. Our attack is based on two assumptions: (1) The attacker has access to a "quality oracle" that can evaluate whether a candidate output is a high-quality response to a prompt, and (2) The attacker has access to a "perturbation oracle" which can modify an output with a nontrivial probability of maintaining quality, and which induces an efficiently mixing random walk on high-quality outputs. We argue that both assumptions can be satisfied in practice by an attacker with weaker computational capabilities than the watermarked model itself, to which the attacker has only black-box access. Furthermore, our assumptions will likely only be easier to satisfy over time as models grow in capabilities and modalities. We demonstrate the feasibility of our attack by instantiating it to attack three existing watermarking schemes for large language models: Kirchenbauer et al. (2023), Kuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully removes the watermarks planted by all three schemes, with only minor quality degradation.
</details>
<details>
<summary>摘要</summary>
水印生成模型的水印是在模型的输出中植入一个统计信号，以便后续可以验证输出是由该模型生成的。一个强大的水印方案需要在计算限制的攻击者无法完全移除水印而导致质量下降的情况下保持水印。在这篇论文中，我们研究水印方案的可能性。我们证明，在我们提出的具体和自然假设下，强大的水印方案是不可能实现的。这种结论是even在私人探测算法设置下也成立，在涉及私钥的情况下，攻击者无法获得私钥。为证明这一结论，我们提出了一种通用的高效水印攻击方法。攻击者不需要知道私钥或使用哪种方案。我们的攻击方法基于以下两个假设：（1）攻击者有访问一个"质量套件"，可以评估提示的输出是否为高质量回答，（2）攻击者有访问一个"杂化套件"，可以对输出进行非正式的修改，并且可以在高质量输出上引入高效混杂的随机漫步。我们 argue That both assumptions can be satisfied in practice by an attacker with weaker computational capabilities than the watermarked model itself, and that our assumptions will likely only become easier to satisfy over time as models grow in capabilities and modalities. We demonstrate the feasibility of our attack by instantiating it to attack three existing watermarking schemes for large language models: Kirchenbauer et al. (2023), Kuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully removes the watermarks planted by all three schemes, with only minor quality degradation.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-multiple-large-language-models-in-pediatric-ophthalmology"><a href="#Evaluating-multiple-large-language-models-in-pediatric-ophthalmology" class="headerlink" title="Evaluating multiple large language models in pediatric ophthalmology"></a>Evaluating multiple large language models in pediatric ophthalmology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04368">http://arxiv.org/abs/2311.04368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jason Holmes, Rui Peng, Yiwei Li, Jinyu Hu, Zhengliang Liu, Zihao Wu, Huan Zhao, Xi Jiang, Wei Liu, Hong Wei, Jie Zou, Tianming Liu, Yi Shao<br>for: The paper aims to evaluate the performance of large language models (LLMs) in pediatric ophthalmology consultations and compare their performance with medical students and physicians at different levels.methods: The study uses a 100-question exam based on pediatric ophthalmology to assess the performance of three LLMs (ChatGPT, GPT-4, and PaLM2) and three human cohorts (medical students, postgraduate students, and attending physicians).results: GPT-4 performs comparably to attending physicians, while ChatGPT (GPT-3.5) and PaLM2 outperform medical students but slightly trail behind postgraduate students. GPT-4 also exhibits greater stability and confidence in responding to inquiries compared to the other two LLMs.<details>
<summary>Abstract</summary>
IMPORTANCE The response effectiveness of different large language models (LLMs) and various individuals, including medical students, graduate students, and practicing physicians, in pediatric ophthalmology consultations, has not been clearly established yet. OBJECTIVE Design a 100-question exam based on pediatric ophthalmology to evaluate the performance of LLMs in highly specialized scenarios and compare them with the performance of medical students and physicians at different levels. DESIGN, SETTING, AND PARTICIPANTS This survey study assessed three LLMs, namely ChatGPT (GPT-3.5), GPT-4, and PaLM2, were assessed alongside three human cohorts: medical students, postgraduate students, and attending physicians, in their ability to answer questions related to pediatric ophthalmology. It was conducted by administering questionnaires in the form of test papers through the LLM network interface, with the valuable participation of volunteers. MAIN OUTCOMES AND MEASURES Mean scores of LLM and humans on 100 multiple-choice questions, as well as the answer stability, correlation, and response confidence of each LLM. RESULTS GPT-4 performed comparably to attending physicians, while ChatGPT (GPT-3.5) and PaLM2 outperformed medical students but slightly trailed behind postgraduate students. Furthermore, GPT-4 exhibited greater stability and confidence when responding to inquiries compared to ChatGPT (GPT-3.5) and PaLM2. CONCLUSIONS AND RELEVANCE Our results underscore the potential for LLMs to provide medical assistance in pediatric ophthalmology and suggest significant capacity to guide the education of medical students.
</details>
<details>
<summary>摘要</summary>
重要性：不同的大型自然语言模型（LLM）和各种个人，包括医学生、硬件学生和实践医生，在педиатрия眼科咨询中的回应效果没有得到明确定义。目标：设计一份100题测验，用于评估不同的LLM在特殊化场景中的表现，并与医学生和医生不同水平的表现进行比较。设计、场景和参与者：这项调查研究分别评估了三个LLM： namely ChatGPT（GPT-3.5）、GPT-4和PaLM2，与三个人类团体：医学生、硬件学生和实践医生，在 Pediatric Ophthalmology 方面的问题回答能力。通过LLM网络 интерフェース传达测验纸，经过志愿者的参与。主要结果和测量：LLM和人类的平均分数100个多选题，以及每个LLM的回答稳定性、相关性和回答自信度。结论和重要性：我们的结果表明LLM可以在 Pediatric Ophthalmology 中提供医疗帮助，并表明LLM可以导导医学生的教育。
</details></li>
</ul>
<hr>
<h2 id="Syntax-Guided-Transformers-Elevating-Compositional-Generalization-and-Grounding-in-Multimodal-Environments"><a href="#Syntax-Guided-Transformers-Elevating-Compositional-Generalization-and-Grounding-in-Multimodal-Environments" class="headerlink" title="Syntax-Guided Transformers: Elevating Compositional Generalization and Grounding in Multimodal Environments"></a>Syntax-Guided Transformers: Elevating Compositional Generalization and Grounding in Multimodal Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04364">http://arxiv.org/abs/2311.04364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danial Kamali, Parisa Kordjamshidi</li>
<li>for: 本研究旨在解决AI模型在多modal环境中的组合普适泛化问题，特别是通过语言 syntax 结构来提高组合普适泛化能力。</li>
<li>methods: 本研究使用了 attention masking 技术， derivated from text input parsing，来强化语言 syntax 的挂钩。</li>
<li>results: 研究表明，通过使用语言 syntax 信息可以提高多modal grounding 问题的性能，并在多种任务上达到新的州OF-the-art。<details>
<summary>Abstract</summary>
Compositional generalization, the ability of intelligent models to extrapolate understanding of components to novel compositions, is a fundamental yet challenging facet in AI research, especially within multimodal environments. In this work, we address this challenge by exploiting the syntactic structure of language to boost compositional generalization. This paper elevates the importance of syntactic grounding, particularly through attention masking techniques derived from text input parsing. We introduce and evaluate the merits of using syntactic information in the multimodal grounding problem. Our results on grounded compositional generalization underscore the positive impact of dependency parsing across diverse tasks when utilized with Weight Sharing across the Transformer encoder. The results push the state-of-the-art in multimodal grounding and parameter-efficient modeling and provide insights for future research.
</details>
<details>
<summary>摘要</summary>
“组成总结”——人工智能模型对新组合的理解推广——是人工智能研究中的基本 yet 挑战性问题，尤其在多模态环境中。在这种情况下，我们利用语言的语法结构来提高组成总结的能力。我们提出并评估了使用语法信息进行多模态固定问题的解决方案。我们的结果表明，在多模态情境下，使用依赖分析技术可以提高权重共享TransformerEncoder的性能，并提高参数效率。这些结果对多模态固定和参数效率的研究提供了新的思路和洞察。
</details></li>
</ul>
<hr>
<h2 id="Uncovering-Causal-Variables-in-Transformers-using-Circuit-Probing"><a href="#Uncovering-Causal-Variables-in-Transformers-using-Circuit-Probing" class="headerlink" title="Uncovering Causal Variables in Transformers using Circuit Probing"></a>Uncovering Causal Variables in Transformers using Circuit Probing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04354">http://arxiv.org/abs/2311.04354</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlepori1/circuit_probing">https://github.com/mlepori1/circuit_probing</a></li>
<li>paper_authors: Michael A. Lepori, Thomas Serre, Ellie Pavlick</li>
<li>for: 了解神经网络模型中的算法实现是如何工作的，以及模型是如何处理特定任务的。</li>
<li>methods: 使用新的分析技术——电路探钻，自动找到神经网络中假设的低级别电路，并通过针对模型参数进行targeted ablation来进行 causal 分析。</li>
<li>results: 在简单的数学任务上训练神经网络模型后，使用电路探钻技术可以：（1）解读神经网络模型学习的算法，（2）揭示神经网络模型的模块结构，（3）跟踪模型训练过程中电路的发展。并且与其他分析方法进行比较，电路探钻技术在这些实验中几乎与其他方法一样有效，甚至更有效。最后，在一个真实的应用场景中，使用电路探钻技术揭示了GPT2-Small和GPT2-Medium中的主题-动词协调和反射反身协调的电路。<details>
<summary>Abstract</summary>
Neural network models have achieved high performance on a wide variety of complex tasks, but the algorithms that they implement are notoriously difficult to interpret. In order to understand these algorithms, it is often necessary to hypothesize intermediate variables involved in the network's computation. For example, does a language model depend on particular syntactic properties when generating a sentence? However, existing analysis tools make it difficult to test hypotheses of this type. We propose a new analysis technique -- circuit probing -- that automatically uncovers low-level circuits that compute hypothesized intermediate variables. This enables causal analysis through targeted ablation at the level of model parameters. We apply this method to models trained on simple arithmetic tasks, demonstrating its effectiveness at (1) deciphering the algorithms that models have learned, (2) revealing modular structure within a model, and (3) tracking the development of circuits over training. We compare circuit probing to other methods across these three experiments, and find it on par or more effective than existing analysis methods. Finally, we demonstrate circuit probing on a real-world use case, uncovering circuits that are responsible for subject-verb agreement and reflexive anaphora in GPT2-Small and Medium.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Formal-Aspects-of-Language-Modeling"><a href="#Formal-Aspects-of-Language-Modeling" class="headerlink" title="Formal Aspects of Language Modeling"></a>Formal Aspects of Language Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04329">http://arxiv.org/abs/2311.04329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Gninos/CIM-With-Transition-Systems">https://github.com/Gninos/CIM-With-Transition-Systems</a></li>
<li>paper_authors: Ryan Cotterell, Anej Svete, Clara Meister, Tianyu Liu, Li Du</li>
<li>for: 这篇论文主要是为了解释大语言模型的数学基础和如何实现。</li>
<li>methods: 本论文使用了形式化的理论方法来描述语言模型的概念和结构。</li>
<li>results: 本论文提供了一个系统的理论基础，以便开发者和研究人员更好地理解和实现大语言模型。<details>
<summary>Abstract</summary>
Large language models have become one of the most commonly deployed NLP inventions. In the past half-decade, their integration into core natural language processing tools has dramatically increased the performance of such tools, and they have entered the public discourse surrounding artificial intelligence. Consequently, it is important for both developers and researchers alike to understand the mathematical foundations of large language models, as well as how to implement them. These notes are the accompaniment to the theoretical portion of the ETH Z\"urich course on large language models, covering what constitutes a language model from a formal, theoretical perspective.
</details>
<details>
<summary>摘要</summary>
大型语言模型已经成为人工智能领域中最为常见的自然语言处理发明之一。过去半个 décennial，它们的整合到主流自然语言处理工具中，对自然语言处理工具的性能产生了巨大的提升，并进入了人工智能的公共讨论。因此，开发者和研究人员都需要深入了解大型语言模型的数学基础和实现方法。这些笔记是ETH Zurich大学课程《大型语言模型》的理论部分的伴手笔，涵盖了语言模型从形式、理论上的定义和分析。
</details></li>
</ul>
<hr>
<h2 id="Aspect-based-Meeting-Transcript-Summarization-A-Two-Stage-Approach-with-Weak-Supervision-on-Sentence-Classification"><a href="#Aspect-based-Meeting-Transcript-Summarization-A-Two-Stage-Approach-with-Weak-Supervision-on-Sentence-Classification" class="headerlink" title="Aspect-based Meeting Transcript Summarization: A Two-Stage Approach with Weak Supervision on Sentence Classification"></a>Aspect-based Meeting Transcript Summarization: A Two-Stage Approach with Weak Supervision on Sentence Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04292">http://arxiv.org/abs/2311.04292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongfen Deng, Seunghyun Yoon, Trung Bui, Franck Dernoncourt, Quan Hung Tran, Shuaiqi Liu, Wenting Zhao, Tao Zhang, Yibo Wang, Philip S. Yu</li>
<li>for: 本研究旨在生成多个摘要，每个摘要专注于一个会议笔记中的一个方面。</li>
<li>methods: 我们提出了一种两阶段方法来实现方面基于会议笔记摘要。首先，我们使用一个句子分类器在一个基于AMI corpus的 dataset上进行 pseudo-labeling，以选择与特定方面相关的句子。然后，我们将这些选择的句子 merged 为特定方面的输入，并使用摘要器生成相应的摘要。</li>
<li>results: 我们在AMI corpus上进行实验，与许多强大的基线实现相比，我们的提出的方法表现出色，为方面基于会议笔记摘要提供了有效的解决方案。<details>
<summary>Abstract</summary>
Aspect-based meeting transcript summarization aims to produce multiple summaries, each focusing on one aspect of content in a meeting transcript. It is challenging as sentences related to different aspects can mingle together, and those relevant to a specific aspect can be scattered throughout the long transcript of a meeting. The traditional summarization methods produce one summary mixing information of all aspects, which cannot deal with the above challenges of aspect-based meeting transcript summarization. In this paper, we propose a two-stage method for aspect-based meeting transcript summarization. To select the input content related to specific aspects, we train a sentence classifier on a dataset constructed from the AMI corpus with pseudo-labeling. Then we merge the sentences selected for a specific aspect as the input for the summarizer to produce the aspect-based summary. Experimental results on the AMI corpus outperform many strong baselines, which verifies the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
<SYS> translate("Aspect-based meeting transcript summarization aims to produce multiple summaries, each focusing on one aspect of content in a meeting transcript. It is challenging as sentences related to different aspects can mingle together, and those relevant to a specific aspect can be scattered throughout the long transcript of a meeting. The traditional summarization methods produce one summary mixing information of all aspects, which cannot deal with the above challenges of aspect-based meeting transcript summarization. In this paper, we propose a two-stage method for aspect-based meeting transcript summarization.")</SYS>以下是文本的Simplified Chinese翻译：<SYS>通过生成多个各关注一个方面的内容笔记简要，以解决会议笔记中不同方面的句子可能杂mix在一起，而具体方面的句子可能在会议笔记中散布在多处的挑战。传统的笔记简要方法会混合所有方面的信息，无法处理上述方面基笔要简要的挑战。在本文中，我们提出了一种两个阶段的方法 для方面基笔要简要。首先，我们使用基于AMI词库的假标签来训练句子分类器，以选择与特定方面相关的输入内容。然后，我们将选择的句子 merge为特定方面的输入，以便使用笔记简要器生成相应的方面基笔要简要。实验结果表明，我们的提议方法在AMI词库上表现出色，超过了许多强大的基线。）</SYS>
</details></li>
</ul>
<hr>
<h2 id="Exploring-Recommendation-Capabilities-of-GPT-4V-ision-A-Preliminary-Case-Study"><a href="#Exploring-Recommendation-Capabilities-of-GPT-4V-ision-A-Preliminary-Case-Study" class="headerlink" title="Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study"></a>Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04199">http://arxiv.org/abs/2311.04199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peilin Zhou, Meng Cao, You-Liang Huang, Qichen Ye, Peiyan Zhang, Junling Liu, Yueqi Xie, Yining Hua, Jaeboum Kim<br>for:This paper explores the potential of using Large Multimodal Models (LMMs) in recommendation tasks with visual assistance.methods:The authors use GPT-4V, a recently released LMM by OpenAI, to assess the quality of its responses within recommendation scenarios. They construct a series of qualitative test samples spanning multiple domains and employ these samples to evaluate GPT-4V’s performance.results:The evaluation results show that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains, thanks to its robust visual-text comprehension capabilities and extensive general knowledge. However, the authors also identify some limitations, including a tendency to provide similar responses when given similar inputs.Here is the same information in Simplified Chinese text:for:这篇论文探讨了使用大型多modal模型（LMMs）在视觉帮助下的推荐任务的可能性。methods:作者使用OpenAI最新发布的GPT-4V模型来评估其在推荐场景中的回答质量。他们构建了覆盖多个领域的质量测试样本，并使用这些样本来评估GPT-4V的性能。results:评估结果表明，GPT-4V在多个领域的零shot推荐任务中表现出色，归功于它的视觉文本理解能力和广泛的通用知识。然而，作者还发现了一些限制，包括对同类输入提供相同的回答的倾向。<details>
<summary>Abstract</summary>
Large Multimodal Models (LMMs) have demonstrated impressive performance across various vision and language tasks, yet their potential applications in recommendation tasks with visual assistance remain unexplored. To bridge this gap, we present a preliminary case study investigating the recommendation capabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a series of qualitative test samples spanning multiple domains and employ these samples to assess the quality of GPT-4V's responses within recommendation scenarios. Evaluation results on these test samples prove that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains, thanks to its robust visual-text comprehension capabilities and extensive general knowledge. However, we have also identified some limitations in using GPT-4V for recommendations, including a tendency to provide similar responses when given similar inputs. This report concludes with an in-depth discussion of the challenges and research opportunities associated with utilizing GPT-4V in recommendation scenarios. Our objective is to explore the potential of extending LMMs from vision and language tasks to recommendation tasks. We hope to inspire further research into next-generation multimodal generative recommendation models, which can enhance user experiences by offering greater diversity and interactivity. All images and prompts used in this report will be accessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.
</details>
<details>
<summary>摘要</summary>
大型多模式模型（LMM）已经在视觉和语言任务上表现出色，但它们在推荐任务中的应用尚未得到广泛探索。为了填补这一空白，我们提出了一个初步的案例研究，检查GPT-4V（ison），由OpenAI最近发布的一种新的LMM，在推荐任务中的表现。我们构建了覆盖多个领域的质量测试样本，并使用这些样本来评估GPT-4V在推荐场景中的答案质量。评估结果表明，GPT-4V在多个领域的零shot推荐任务中表现出色，归功于它的视觉文本理解能力和广泛的通用知识。然而，我们也发现了使用GPT-4V进行推荐的一些限制，包括对同样输入提供相似的答案的倾向。本报告结束于对使用GPT-4V进行推荐的挑战和研究机遇的深入讨论。我们的目标是探索将LMM从视觉语言任务扩展到推荐任务的可能性，以提高用户体验的多样性和互动性。所有图像和提示用于这份报告将在GitHub上提供，请参考https://github.com/PALIN2018/Evaluate_GPT-4V_Rec。
</details></li>
</ul>
<hr>
<h2 id="JaSPICE-Automatic-Evaluation-Metric-Using-Predicate-Argument-Structures-for-Image-Captioning-Models"><a href="#JaSPICE-Automatic-Evaluation-Metric-Using-Predicate-Argument-Structures-for-Image-Captioning-Models" class="headerlink" title="JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models"></a>JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04192">http://arxiv.org/abs/2311.04192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/keio-smilab23/JaSPICE">https://github.com/keio-smilab23/JaSPICE</a></li>
<li>paper_authors: Yuiga Wada, Kanta Kaneda, Komei Sugiura</li>
<li>for: 本研究的目的是提出一种用于评估日语描述文本的自动评估指标，以提高现有的自动评估指标的准确性。</li>
<li>methods: 本研究使用了依赖关系和 predicate-argument结构生成场景图，并通过同义词扩展场景图。</li>
<li>results: 我们的方法在使用10种基于STAIR Captions和PFN-PIC的图像描述模型，并使用 constructed Shichimi 数据集（包含103,170个人评估）进行实验后，与基准指标相比，显示了更高的相关系数与人工评估。<details>
<summary>Abstract</summary>
Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR. However, such n-gram-based metrics have been shown to correlate poorly with human evaluation, leading to the proposal of alternative metrics such as SPICE for English; however, no equivalent metrics have been established for other languages. Therefore, in this study, we propose an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs. The proposed method generates a scene graph from dependencies and the predicate-argument structure, and extends the graph using synonyms. We conducted experiments employing 10 image captioning models trained on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which contains 103,170 human evaluations. The results showed that our metric outperformed the baseline metrics for the correlation coefficient with the human evaluation.
</details>
<details>
<summary>摘要</summary>
研究者强调使用自动评价指标，如BLEU和METEOR，但这些n-gram基于指标与人类评估不符，导致提出了相应的指标，如SPICE（英语）。然而，其他语言没有相应的指标。因此，在这种研究中，我们提议一种自动评价指标，即JaSPICE，用于评估日语描述。该方法根据依赖关系和 predicate-argument结构生成场景图，并使用同义词扩展图。我们在STAIR Captions和PFN-PIC上训练了10种图像描述模型，并构建了Shichimi数据集，该数据集包含103,170个人评估。结果表明，我们的指标与人类评估的相关度高于基准指标。
</details></li>
</ul>
<hr>
<h2 id="SpaDeLeF-A-Dataset-for-Hierarchical-Classification-of-Lexical-Functions-for-Collocations-in-Spanish"><a href="#SpaDeLeF-A-Dataset-for-Hierarchical-Classification-of-Lexical-Functions-for-Collocations-in-Spanish" class="headerlink" title="SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish"></a>SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04189">http://arxiv.org/abs/2311.04189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yevhen Kostiuk, Grigori Sidorov, Olga Kolesnikova</li>
<li>for: 这个论文的目的是为了提出一个基于意义文本理论的语言处理（NLP）中lexical函数的层次分类方法。</li>
<li>methods: 这篇论文使用了一个大量标注数据来训练语言模型，并使用了一种基于树结构的分类目标。</li>
<li>results: 这篇论文提供了一个包含最常见的西班牙语动词-名词 collocation 和它们在文本中出现的句子的数据集，每个 collocation 被分配到了37种lexical函数中的一个类别。<details>
<summary>Abstract</summary>
In natural language processing (NLP), lexical function is a concept to unambiguously represent semantic and syntactic features of words and phrases in text first crafted in the Meaning-Text Theory. Hierarchical classification of lexical functions involves organizing these features into a tree-like hierarchy of categories or labels. This is a challenging task as it requires a good understanding of the context and the relationships among words and phrases in text. It also needs large amounts of labeled data to train language models effectively. In this paper, we present a dataset of most frequent Spanish verb-noun collocations and sentences where they occur, each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task. Each class represents a relation between the noun and the verb in a collocation involving their semantic and syntactic features. We combine the classes in a tree-based structure, and introduce classification objectives for each level of the structure. The dataset was created by dependency tree parsing and matching of the phrases in Spanish news. We provide baselines and data splits for each objective.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）领域，lexical function是一个概念，用于不ambiguously表示文本中单词和短语的 semantics和 sintaxis特征。 hierarchical classification of lexical functions involves organizing these features into a tree-like hierarchy of categories or labels. 这是一项具有挑战性的任务，因为它需要对文本中单词和短语之间的关系和语言模型有good understanding。 In addition, it requires large amounts of labeled data to train language models effectively.在这篇论文中，我们提供了最常见的西班牙语动词-名词配合和它们出现的句子，每个配合被分配到37个定义了类的 hierarchical classification任务中。每个类表示在名词和动词之间的关系，包括semantic和syntactic特征。 We combine the classes in a tree-based structure, and introduce classification objectives for each level of the structure. The dataset was created by dependency tree parsing and matching of the phrases in Spanish news. We provide baselines and data splits for each objective.
</details></li>
</ul>
<hr>
<h2 id="Perturbed-examples-reveal-invariances-shared-by-language-models"><a href="#Perturbed-examples-reveal-invariances-shared-by-language-models" class="headerlink" title="Perturbed examples reveal invariances shared by language models"></a>Perturbed examples reveal invariances shared by language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04166">http://arxiv.org/abs/2311.04166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruchit Rawal, Mariya Toneva</li>
<li>for: 本研究的目的是比较两个自然语言处理模型的表现，以了解它们在不同领域中的差异。</li>
<li>methods: 本研究使用了一种新的比较框架，通过描述target一个特定的语言能力（例如同义词变换、字误变换）来揭示模型之间的共同不变性。</li>
<li>results: 研究发现，大型语言模型在多种语言任务中具有许多共同的不变性，而这些不变性只存在于其他大型模型中。这些结果表明，拥有多种不变性可能是大型语言模型的成功的关键因素，并且该框架可以帮助我们理解新模型中 retained 的不变性和 emerge 的不变性。<details>
<summary>Abstract</summary>
An explosion of work in language is leading to ever-increasing numbers of available natural language processing models, with little understanding of how new models compare to better-understood models. One major reason for this difficulty is saturating benchmark datasets, which may not reflect well differences in model performance in the wild. In this work, we propose a novel framework for comparing two natural language processing models by revealing their shared invariance to interpretable input perturbations that are designed to target a specific linguistic capability (e.g., Synonym-Invariance, Typo-Invariance). Via experiments on models from within the same and across different architecture families, this framework offers a number of insights about how changes in models (e.g., distillation, increase in size, amount of pre-training) affect multiple well-defined linguistic capabilities. Furthermore, we also demonstrate how our framework can enable evaluation of the invariances shared between models that are available as commercial black-box APIs (e.g., InstructGPT family) and models that are relatively better understood (e.g., GPT-2). Across several experiments, we observe that large language models share many of the invariances encoded by models of various sizes, whereas the invariances encoded by large language models are only shared by other large models. Possessing a wide variety of invariances may be a key reason for the recent successes of large language models, and our framework can shed light on the types of invariances that are retained by or emerge in new models.
</details>
<details>
<summary>摘要</summary>
“ языковая обработка естественного языка（NLP） 领域正在急速发展，导致大量可用的自然语言处理模型出现，但对这些新模型的理解却很少。一个主要原因是溢出的benchmark数据集，可能不准确反映模型在实际场景中的表现差异。在这项工作中，我们提出了一种新的比较框架，通过揭示模型对可理解的输入扰动的共同不变性（如同onym-invariance、typo-invariance）来比较两个NLP模型。通过对同一architecture家族和不同家族的模型进行实验，我们的框架提供了许多关于模型变化（如distillation、模型大小增加、预训练量）对多种明确的语言能力的影响的反思。此外，我们还示例了如何使用我们的框架评估黑盒API模型（如InstructGPT家族）和比较好理解的模型（如GPT-2）之间的共同不变性。在多个实验中，我们发现大语言模型共享许多不变性，而大模型中的不变性只被其他大模型共享。拥有多种不变性可能是大语言模型的近期成功的关键因素，我们的框架可以探讨这些不变性是如何在新模型中保留或emerge。”
</details></li>
</ul>
<hr>
<h2 id="Black-Box-Prompt-Optimization-Aligning-Large-Language-Models-without-Model-Training"><a href="#Black-Box-Prompt-Optimization-Aligning-Large-Language-Models-without-Model-Training" class="headerlink" title="Black-Box Prompt Optimization: Aligning Large Language Models without Model Training"></a>Black-Box Prompt Optimization: Aligning Large Language Models without Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04155">http://arxiv.org/abs/2311.04155</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-coai/bpo">https://github.com/thu-coai/bpo</a></li>
<li>paper_authors: Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang</li>
<li>for: 这个论文的目的是提出一种新的自然语言处理技术，即黑盒子提示优化（BPO），用于调整大型自然语言模型（LLM）的输入理解，以实现用户的意图。</li>
<li>methods: 这个论文使用的方法是黑盒子提示优化（BPO），它是一种模型独立的方法，不需要更新 LLM 的参数。BPO 通过优化用户提交的提示，使 LLM 更好地理解用户的意图。</li>
<li>results: 论文的实验结果表明，使用 BPO 可以提高 ChatGPT 的胜率 by 22%，并且可以超过 PPO 和 DPO 的 alignment 方法。同时，BPO 也可以与 PPO 或 DPO 结合使用，以获得更高的性能。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem. To make LLMs better follow user instructions, existing alignment methods mostly focus on further training them. However, the extra training of LLMs are usually expensive in terms of GPU compute; worse still, LLMs of interest are oftentimes not accessible for user-demanded training, such as GPTs. In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments. The idea is to optimize user prompts to suit LLMs' input understanding, so as to best realize users' intents without updating LLMs' parameters. BPO is model-agnostic and the empirical results demonstrate that the BPO-aligned ChatGPT yields a 22% increase in the win rate against its original version, and 10% for GPT-4. Importantly, the BPO-aligned LLMs can outperform the same models aligned by PPO and DPO, and it also brings additional performance gains when combining BPO with PPO or DPO. Code and datasets are released at https://github.com/thu-coai/BPO.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="What-is-Lost-in-Knowledge-Distillation"><a href="#What-is-Lost-in-Knowledge-Distillation" class="headerlink" title="What is Lost in Knowledge Distillation?"></a>What is Lost in Knowledge Distillation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04142">http://arxiv.org/abs/2311.04142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manas Mohanty, Tanya Roosta, Peyman Passban</li>
<li>for: 这个研究旨在investigating how a distilled student model differs from its teacher, and if the distillation process causes any information losses.</li>
<li>methods: 这个研究使用了知识储存（KD）技术来压缩模型，并对其进行分析，以了解压缩过程中是否存在信息损失。</li>
<li>results: 研究发现，压缩过程中的信息损失可以遵循一定的规律，并且不同的任务可能对压缩过程的敏感程度有所不同。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have improved NLP tasks significantly, but training and maintaining such networks could be costly. Model compression techniques, such as, knowledge distillation (KD), have been proposed to address the issue; however, the compression process could be lossy. Motivated by this, our work investigates how a distilled student model differs from its teacher, if the distillation process causes any information losses, and if the loss follows a specific pattern. Our experiments aim to shed light on the type of tasks might be less or more sensitive to KD by reporting data points on the contribution of different factors, such as the number of layers or attention heads. Results such as ours could be utilized when determining effective and efficient configurations to achieve optimal information transfers between larger (teacher) and smaller (student) models.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）已经大幅提高了自然语言处理（NLP）任务的性能，但训练和维护这些网络可能会很昂贵。以知识塑化（KD）为例，模型压缩技术已经被提出来解决这个问题，但压缩过程可能会导致信息损失。我们的工作探讨了压缩学生模型与其教师模型之间的差异，以及压缩过程是否会导致信息损失，以及损失是否遵循某种特定的模式。我们的实验旨在为确定效果和效率的配置提供数据点，以便在更大的教师模型和更小的学生模型之间实现优化的信息传递。我们的结果可能会用于确定适合哪些任务可以更好地承受KD的信息损失。
</details></li>
</ul>
<hr>
<h2 id="Modelling-Sentiment-Analysis-LLMs-and-data-augmentation-techniques"><a href="#Modelling-Sentiment-Analysis-LLMs-and-data-augmentation-techniques" class="headerlink" title="Modelling Sentiment Analysis: LLMs and data augmentation techniques"></a>Modelling Sentiment Analysis: LLMs and data augmentation techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04139">http://arxiv.org/abs/2311.04139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillem Senabre Prades</li>
<li>for: 本研究旨在提出一种用于小训练集 binary sentiment classification 的不同方法。</li>
<li>methods: 本研究使用了 LLMS  such as BERT、RoBERTa 和 XLNet，这些模型在 sentiment analysis 和相关领域已经提供了 state-of-the-art 的结果。</li>
<li>results: 研究所得到的结果表明，使用 LLMS 可以在小训练集上实现高度的 binary sentiment classification 性能。<details>
<summary>Abstract</summary>
This paper provides different approaches for a binary sentiment classification on a small training dataset. LLMs that provided state-of-the-art results in sentiment analysis and similar domains are being used, such as BERT, RoBERTa and XLNet.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一些方法用于对小训练集进行二分 sentiment 分类。使用了 LLMS 提供的state-of-the-art 结果，包括 BERT、RoBERTa 和 XLNet。
</details></li>
</ul>
<hr>
<h2 id="Personality-Style-Recognition-via-Machine-Learning-Identifying-Anaclitic-and-Introjective-Personality-Styles-from-Patients’-Speech"><a href="#Personality-Style-Recognition-via-Machine-Learning-Identifying-Anaclitic-and-Introjective-Personality-Styles-from-Patients’-Speech" class="headerlink" title="Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients’ Speech"></a>Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients’ Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04088">http://arxiv.org/abs/2311.04088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Semere Kiros Bitew, Vincent Schelstraete, Klim Zaporojets, Kimberly Van Nieuwenhove, Reitske Meganck, Chris Develder<br>for: 这个研究的目的是用自然语言处理技术和机器学习算法来自动推断患有主要抑郁症的病人的人格类型，以更高的准确率和效果。methods: 这个研究使用了自然语言处理技术和标准的机器学习工具来进行分类，并测试了不同的语言特征和音频特征来推断病人的人格类型。results: 研究发现，使用语言特征（如 LIWC）来进行自动分类的性能明显高于使用问卷来进行分类。此外，结合问卷和语言特征得到的结果最佳。这 suggets that 更多的工作应该投入到开发基于语言特征的自动分类技术，但问卷仍然有一定的补充作用。<details>
<summary>Abstract</summary>
In disentangling the heterogeneity observed in psychopathology, personality of the patients is considered crucial. While it has been demonstrated that personality traits are reflected in the language used by a patient, we hypothesize that this enables automatic inference of the personality type directly from speech utterances, potentially more accurately than through a traditional questionnaire-based approach explicitly designed for personality classification. To validate this hypothesis, we adopt natural language processing (NLP) and standard machine learning tools for classification. We test this on a dataset of recorded clinical diagnostic interviews (CDI) on a sample of 79 patients diagnosed with major depressive disorder (MDD) -- a condition for which differentiated treatment based on personality styles has been advocated -- and classified into anaclitic and introjective personality styles. We start by analyzing the interviews to see which linguistic features are associated with each style, in order to gain a better understanding of the styles. Then, we develop automatic classifiers based on (a) standardized questionnaire responses; (b) basic text features, i.e., TF-IDF scores of words and word sequences; (c) more advanced text features, using LIWC (linguistic inquiry and word count) and context-aware features using BERT (bidirectional encoder representations from transformers); (d) audio features. We find that automated classification with language-derived features (i.e., based on LIWC) significantly outperforms questionnaire-based classification models. Furthermore, the best performance is achieved by combining LIWC with the questionnaire features. This suggests that more work should be put into developing linguistically based automated techniques for characterizing personality, however questionnaires still to some extent complement such methods.
</details>
<details>
<summary>摘要</summary>
在解剖精神疾病中的多样性中，患者的人性被视为关键。我们认为，通过语言来反映患者的人性特征，可以自动获取患者的人性类型，可能更准确地进行人性分类，相比于使用传统的问卷方法进行人性分类。为验证这一假设，我们采用自然语言处理（NLP）和标准的机器学习工具进行分类。我们在一个79名患有主要抑郁症（MDD）的患者群体中进行了实验，并将这些患者分为两个类型：帮助型（anaclitic）和内化型（introjective）。我们首先分析了口述会议，以便了解每个风格的语言特征。然后，我们开发了自动分类器，基于（a）标准问卷回答；（b）基本文本特征（TF-IDF分数）；（c）更高级的文本特征，使用LIWC（语言学和词汇计数）和BERT（端到端Encoder Representations from Transformers）；（d）音频特征。我们发现，基于语言 derive 的特征（即LIWC）自动分类表现出色，超过问卷基本分类模型。此外，将 LIWC 与问卷特征结合使用时，表现最佳。这表明，在发展自动基于语言特征的人性分类技术方面，还需要更多的工作。尽管如此，问卷仍然在一定程度上补充这些方法。
</details></li>
</ul>
<hr>
<h2 id="Do-LLMs-exhibit-human-like-response-biases-A-case-study-in-survey-design"><a href="#Do-LLMs-exhibit-human-like-response-biases-A-case-study-in-survey-design" class="headerlink" title="Do LLMs exhibit human-like response biases? A case study in survey design"></a>Do LLMs exhibit human-like response biases? A case study in survey design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04076">http://arxiv.org/abs/2311.04076</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lindiatjuatja/biasmonkey">https://github.com/lindiatjuatja/biasmonkey</a></li>
<li>paper_authors: Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, Graham Neubig</li>
<li>for: 这个论文旨在检验大型自然语言模型（LLM）是否能够像人类一样受到表达方式的影响，以及这种影响是否会导致模型表现出人类样式的偏见。</li>
<li>methods: 作者使用了评估框架和数据集来研究 LLM 是否会 Display human-like response biases，并 compare 了九种不同的模型。</li>
<li>results: 研究发现，流行的开源和商业 LLM 通常不会模仿人类的行为，而且这种不同性更加明显在 instruction fine-tuned 的模型中。此外，即使模型表现出人类样式的偏见，也可能因为其他各种各样的相关性而导致这种偏见。这些结果表明使用 LLM 代替人类在某些批注阶段可能存在隐患，并且更加重要地，需要更加细化的模型行为Characterization。<details>
<summary>Abstract</summary>
As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording -- but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of ``prompts'' have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior. These inconsistencies tend to be more prominent in models that have been instruction fine-tuned. Furthermore, even if a model shows a significant change in the same direction as humans, we find that perturbations that are not meant to elicit significant changes in humans may also result in a similar change, suggesting that such a result could be partially due to other spurious correlations. These results highlight the potential pitfalls of using LLMs to substitute humans in parts of the annotation pipeline, and further underscore the importance of finer-grained characterizations of model behavior. Our code, dataset, and collected samples are available at https://github.com/lindiatjuatja/BiasMonkey
</details>
<details>
<summary>摘要</summary>
随着大语言模型（LLM）的能力不断提高，有越来越多的人们对使用LLM作为人类代理的可能性感到激动。然而，一个广泛被提到的障碍是LLM的句子编写敏感性——但是人类也会因为指令变化而产生偏见。因此，如果LLM将被用来 aproximate human opinions，那么必须调查LLM是否也会呈现人类类似的偏见。在这种情况下，我们使用survey设计作为 caso study，因为人类响应变化的研究已经广泛进行。从社会心理学的先前研究中，我们设计了一个数据集和一个框架，以评估LLM是否会展现人类类似的偏见。我们对九个模型进行了全面的评估，发现流行的开源和商业LLM通常不会模拟人类的行为。这些偏差通常在模型被 instruction fine-tuned 时更加明显。此外，即使模型displayed significant changes in the same direction as humans, we found that perturbations that are not meant to elicit significant changes in humans may also result in a similar change, suggesting that such a result could be partially due to other spurious correlations。这些结果 highlights the potential pitfalls of using LLMs to substitute humans in parts of the annotation pipeline, and further underscore the importance of finer-grained characterizations of model behavior。我们的代码、数据集和收集的样本可以在https://github.com/lindiatjuatja/BiasMonkey 中找到。
</details></li>
</ul>
<hr>
<h2 id="Fully-Automated-Task-Management-for-Generation-Execution-and-Evaluation-A-Framework-for-Fetch-and-Carry-Tasks-with-Natural-Language-Instructions-in-Continuous-Space"><a href="#Fully-Automated-Task-Management-for-Generation-Execution-and-Evaluation-A-Framework-for-Fetch-and-Carry-Tasks-with-Natural-Language-Instructions-in-Continuous-Space" class="headerlink" title="Fully Automated Task Management for Generation, Execution, and Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language Instructions in Continuous Space"></a>Fully Automated Task Management for Generation, Execution, and Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language Instructions in Continuous Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04260">http://arxiv.org/abs/2311.04260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Motonari Kambara, Komei Sugiura</li>
<li>for: 这篇论文目的是开发一个基于视觉信息的机器人执行任务的框架，以响应自然语言指令进行Fetch-and-Carry with Object Grounding (FCOG)任务。</li>
<li>methods: 本文提出了一种框架，可以自动生成、执行和评估FCOG任务。此外， authors还提出了将FCOG任务分解成四个不同的互斥任务的方法。</li>
<li>results: 本文的实验结果表明，该框架可以自动生成和执行FCOG任务，并且可以在不同的环境和对象下实现高效的任务执行。<details>
<summary>Abstract</summary>
This paper aims to develop a framework that enables a robot to execute tasks based on visual information, in response to natural language instructions for Fetch-and-Carry with Object Grounding (FCOG) tasks. Although there have been many frameworks, they usually rely on manually given instruction sentences. Therefore, evaluations have only been conducted with fixed tasks. Furthermore, many multimodal language understanding models for the benchmarks only consider discrete actions. To address the limitations, we propose a framework for the full automation of the generation, execution, and evaluation of FCOG tasks. In addition, we introduce an approach to solving the FCOG tasks by dividing them into four distinct subtasks.
</details>
<details>
<summary>摘要</summary>
本文目的是开发一个框架，让机器人通过视觉信息执行基于自然语言指令的Fetch-and-Carry with Object Grounding（FCOG）任务。虽然有很多框架，但它们通常依赖于手动提供的指令句子。因此，评估只能进行固定任务。此外，许多多模态语言理解模型只考虑简单的动作。为了解决这些限制，我们提议一个框架，自动生成、执行和评估FCOG任务。此外，我们还介绍了解决FCOG任务的四个不同子任务的方法。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Imitation-Leveraging-Fine-grained-Quality-Signals-for-Alignment"><a href="#Beyond-Imitation-Leveraging-Fine-grained-Quality-Signals-for-Alignment" class="headerlink" title="Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"></a>Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04072">http://arxiv.org/abs/2311.04072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geyang Guo, Ranchi Zhao, Tianyi Tang, Wayne Xin Zhao, Ji-Rong Wen</li>
<li>for: 提高大语言模型（LLM）的对人类偏好的适应性。</li>
<li>methods: 基于精细调整（SFT）和强制学习人类反馈（RLHF）两种方法。</li>
<li>results: 提出了一种改进的对适应方法，名为FIGLA，并通过对比好的和坏的回答来提供细致的质量信号。经过广泛的实验，FIGLA的方法可以与多种竞争性基准进行比较。<details>
<summary>Abstract</summary>
Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的对人类偏好的适配性是一个欲有的性能。现在的主要对齐方法是基于人类反馈学习（RLHF）。 despite RLHF的效果，它实现和训练相当复杂，所以现有的研究则是如何发展基于监督微调（SFT）的替代对齐方法。 however，SFT的主要限制是它实际上只是做复制学习，无法完全理解预期的行为。 To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.
</details></li>
</ul>
<hr>
<h2 id="Implementation-and-Comparison-of-Methods-to-Extract-Reliability-KPIs-out-of-Textual-Wind-Turbine-Maintenance-Work-Orders"><a href="#Implementation-and-Comparison-of-Methods-to-Extract-Reliability-KPIs-out-of-Textual-Wind-Turbine-Maintenance-Work-Orders" class="headerlink" title="Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders"></a>Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04064">http://arxiv.org/abs/2311.04064</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc-Alexander Lutz, Bastian Schäfermeier, Rachael Sexton, Michael Sharp, Alden Dima, Stefan Faulstich, Jagan Mohini Aluri</li>
<li>for: 本研究用于提高风力机的运行和维护，通过对维护工作令的整理和分析，提高风力机的可靠性指标。</li>
<li>methods: 本研究使用了三种不同的方法来计算风力机的可靠性指标，包括人工标注、自动标注和人工协助标注。</li>
<li>results: 研究发现，人工标注法可以作为标准，自动标注法和人工协助标注法可以减少人工干预时间和提高标注质量。三种方法都可以提高风力机的可靠性指标，但人工标注法的标准性较高。<details>
<summary>Abstract</summary>
Maintenance work orders are commonly used to document information about wind turbine operation and maintenance. This includes details about proactive and reactive wind turbine downtimes, such as preventative and corrective maintenance. However, the information contained in maintenance work orders is often unstructured and difficult to analyze, making it challenging for decision-makers to use this information for optimizing operation and maintenance. To address this issue, this work presents three different approaches to calculate reliability key performance indicators from maintenance work orders. The first approach involves manual labeling of the maintenance work orders by domain experts, using the schema defined in an industrial guideline to assign the label accordingly. The second approach involves the development of a model that automatically labels the maintenance work orders using text classification methods. The third technique uses an AI-assisted tagging tool to tag and structure the raw maintenance information contained in the maintenance work orders. The resulting calculated reliability key performance indicator of the first approach are used as a benchmark for comparison with the results of the second and third approaches. The quality and time spent are considered as criteria for evaluation. Overall, these three methods make extracting maintenance information from maintenance work orders more efficient, enable the assessment of reliability key performance indicators and therefore support the optimization of wind turbine operation and maintenance.
</details>
<details>
<summary>摘要</summary>
维保工作令是通常用于记录风机运行和维保信息的。这些信息包括掌控性维保和修复维保的时间，以及相关的预防维保和修复维保活动。然而，维保工作令中的信息通常是不结构化的，困难分析，使得决策者困难使用这些信息优化运行和维保。为解决这个问题，本工作提出了三种不同的方法来计算可靠度关键性表现指标从维保工作令中。第一种方法是通过域专家 manually 标签维保工作令，使用工业指南定义的 schema 将标签应用 accordingly。第二种方法是开发一种自动标签维保工作令的模型，使用文本分类方法进行标签。第三种技术使用 AI 助手标注工具来标记和结构化维保工作令中的原始维保信息。第一种方法的计算的可靠度关键性表现指标作为基准，与第二和第三种方法的结果进行比较。评估标准包括质量和时间花费。总的来说，这三种方法使得从维保工作令中提取维保信息更加效率，可以评估可靠度关键性表现指标，因此支持风机运行和维保优化。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-Fine-tuning-of-Language-Models-is-Biased-Towards-More-Extractable-Features"><a href="#Reinforcement-Learning-Fine-tuning-of-Language-Models-is-Biased-Towards-More-Extractable-Features" class="headerlink" title="Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features"></a>Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04046">http://arxiv.org/abs/2311.04046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diogo Cruz, Edoardo Pona, Alex Holness-Tofts, Elias Schmied, Víctor Abia Alonso, Charlie Griffin, Bogdan-Ionut Cirstea</li>
<li>for: 这个论文 investigate whether principles governing inductive biases in the supervised fine-tuning of large language models (LLMs) also apply when the fine-tuning process uses reinforcement learning.</li>
<li>methods: 研究采用了控制实验，测试了两个假设：一是预训练后可以更容易提取的特征更可能被最终策略使用，二是特征的证据是否支持或反对它的使用。</li>
<li>results: 通过控制实验测试两个假设，发现存在 statistically significant correlations，这是强有力的证据支持这两个假设。<details>
<summary>Abstract</summary>
Many capable large language models (LLMs) are developed via self-supervised pre-training followed by a reinforcement-learning fine-tuning phase, often based on human or AI feedback. During this stage, models may be guided by their inductive biases to rely on simpler features which may be easier to extract, at a cost to robustness and generalisation. We investigate whether principles governing inductive biases in the supervised fine-tuning of LLMs also apply when the fine-tuning process uses reinforcement learning. Following Lovering et al (2021), we test two hypotheses: that features more $\textit{extractable}$ after pre-training are more likely to be utilised by the final policy, and that the evidence for/against a feature predicts whether it will be utilised. Through controlled experiments on synthetic and natural language tasks, we find statistically significant correlations which constitute strong evidence for these hypotheses.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="P-Bench-A-Multi-level-Privacy-Evaluation-Benchmark-for-Language-Models"><a href="#P-Bench-A-Multi-level-Privacy-Evaluation-Benchmark-for-Language-Models" class="headerlink" title="P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models"></a>P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04044">http://arxiv.org/abs/2311.04044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Li, Dadi Guo, Donghao Li, Wei Fan, Qi Hu, Xin Liu, Chunkit Chan, Duanyi Yao, Yangqiu Song</li>
<li>for: This paper focuses on the privacy risks of language models (LMs) and proposes a multi-perspective privacy evaluation benchmark called P-Bench to evaluate the privacy leakage of LMs.</li>
<li>methods: The paper uses a unified pipeline for private fine-tuning and conducts empirical attacks on LMs to evaluate their privacy leakage.</li>
<li>results: The paper conducts extensive experiments on three datasets of GLUE for mainstream LMs and provides empirical evaluation results to fairly and intuitively evaluate the privacy leakage of various privacy-preserving language models (PPLMs).Here is the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文关注语言模型（LMs）的隐私风险，提出了一个多方面隐私评估 benchmark called P-Bench，用于评估 LMs 的隐私泄露。</li>
<li>methods: 该篇论文使用了一个统一的私有化管道进行私有训练，并对 LMs 进行实际的隐私攻击，以评估其隐私泄露。</li>
<li>results: 该篇论文对 GLUE 三个 dataset 进行了广泛的实验，提供了对各种隐私保护语言模型（PPLMs）的实际评估结果，以便对其隐私泄露进行公正和直观的评估。<details>
<summary>Abstract</summary>
The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage. To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP). Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs. In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs. Instead of only protecting and measuring the privacy of protected data with DP parameters, P-Bench sheds light on the neglected inference data privacy during actual usage. P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning. Then, P-Bench constructs a unified pipeline to perform private fine-tuning. Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results. The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs. We conduct extensive experiments on three datasets of GLUE for mainstream LMs.
</details>
<details>
<summary>摘要</summary>
LM的快速发展提供了前所未有的可访问性和使用性，同时也带来了一些隐私风险。一方面，强大的LM通过庞大的文本数据进行训练，在许多下游NLP任务中实现了状态机器人的性能。另一方面，越来越多的注意力被转移到不受限制的模型访问中，可能会导致数据泄露的隐私风险。为了解决这些问题，许多最近的研究提出了隐私保护语言模型（PPLM），并采用了各种隐私保护技术。然而，不同的隐私保护实现方式使得对现有PPLM的比较变得困难。在这篇论文中，我们提出了P-Bench，一个多方面隐私评估benchmark，用于Empirically和直观地评估LM的隐私泄露。而不是仅仅保护和测量保护数据的隐私，P-Bench shed light on在实际使用时被忽略的推理数据隐私。P-Bench首先明确了多方面隐私目标 durante private fine-tuning。然后，P-Bench构建了一个统一的管道来执行private fine-tuning。最后，P-Bench对LMs进行了预先定义的隐私目标为empirical attack results。这些empirical attack results用于评估不同PPLMs的隐私泄露。我们对GLUE dataset进行了广泛的实验。
</details></li>
</ul>
<hr>
<h2 id="mPLUG-Owl2-Revolutionizing-Multi-modal-Large-Language-Model-with-Modality-Collaboration"><a href="#mPLUG-Owl2-Revolutionizing-Multi-modal-Large-Language-Model-with-Modality-Collaboration" class="headerlink" title="mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration"></a>mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04257">http://arxiv.org/abs/2311.04257</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/X-PLUG/mPLUG-Owl/tree/main/mPLUG-Owl2">https://github.com/X-PLUG/mPLUG-Owl/tree/main/mPLUG-Owl2</a></li>
<li>paper_authors: Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Haowei Liu, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou</li>
<li>for: 这个论文主要 targets 多modal大语言模型（MLLMs）的开放任务表现。</li>
<li>methods: 这个论文提出了一种多元模块化网络设计，使用语言解码器作为多种Modalities的通用接口，并在不同modalities之间进行功能模块共享和启用模态特征保留模块。</li>
<li>results: 对多种文本任务和多modal任务进行广泛的实验，发现mPLUG-Owl2可以通过一个通用模型实现状态之最高表现，并且在多modal任务中实现模态协作现象，为未来多modal基础模型的发展开拓了先河。<details>
<summary>Abstract</summary>
Multi-modal Large Language Models (MLLMs) have demonstrated impressive instruction abilities across various open-ended tasks. However, previous methods primarily focus on enhancing multi-modal capabilities. In this work, we introduce a versatile multi-modal large language model, mPLUG-Owl2, which effectively leverages modality collaboration to improve performance in both text and multi-modal tasks. mPLUG-Owl2 utilizes a modularized network design, with the language decoder acting as a universal interface for managing different modalities. Specifically, mPLUG-Owl2 incorporates shared functional modules to facilitate modality collaboration and introduces a modality-adaptive module that preserves modality-specific features. Extensive experiments reveal that mPLUG-Owl2 is capable of generalizing both text tasks and multi-modal tasks and achieving state-of-the-art performances with a single generic model. Notably, mPLUG-Owl2 is the first MLLM model that demonstrates the modality collaboration phenomenon in both pure-text and multi-modal scenarios, setting a pioneering path in the development of future multi-modal foundation models.
</details>
<details>
<summary>摘要</summary>
多模式大语言模型（MLLM）已经表现出了惊人的指令能力在多种开放任务中。然而，先前的方法主要关注于增强多模式能力。在这项工作中，我们介绍了一种多模式大语言模型，名为mPLUG-Owl2，可以有效利用模式合作来提高文本和多模式任务的性能。mPLUG-Owl2使用分解化网络设计，语言解码器作为多Modal interfaces的通用接口来管理不同模式。具体来说，mPLUG-Owl2包含共享功能模块来促进模式合作，并引入一个适应模式特征的模块。广泛的实验表明，mPLUG-Owl2能够泛化文本任务和多模式任务，并在单个通用模型下实现状态的最佳性能。值得一提的是，mPLUG-Owl2是首个在纯文本和多模式场景中显示出模式合作现象的 MLLM 模型，这为未来多模式基础模型的发展留下了先河。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Film-Adaptation-through-Narrative-Alignment"><a href="#Analyzing-Film-Adaptation-through-Narrative-Alignment" class="headerlink" title="Analyzing Film Adaptation through Narrative Alignment"></a>Analyzing Film Adaptation through Narrative Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04020">http://arxiv.org/abs/2311.04020</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanzir Pial, Shahreen Salim, Charuta Pethe, Allen Kim, Steven Skiena</li>
<li>for: 本研究用 Smith-Waterman 本地Alignment 算法和 SBERT 嵌入距离来研究电影剧本的改编过程，以便自动分析40个改编作品，从而探讨改编过程中的 faithfulness 问题、对话的重要性、叙述顺序的保留以及 gender 表现问题。</li>
<li>methods: 本研究使用 Smith-Waterman 本地Alignment 算法和 SBERT 嵌入距离来建立叙述对应关系，以便衡量电影剧本与原著之间的文本相似性。</li>
<li>results: 研究发现，改编过程中对 диалог的重要性具有显著影响，而叙述顺序的保留也具有较高的相似性。此外，研究还发现 gender 表现问题存在某些偏见。<details>
<summary>Abstract</summary>
Novels are often adapted into feature films, but the differences between the two media usually require dropping sections of the source text from the movie script. Here we study this screen adaptation process by constructing narrative alignments using the Smith-Waterman local alignment algorithm coupled with SBERT embedding distance to quantify text similarity between scenes and book units. We use these alignments to perform an automated analysis of 40 adaptations, revealing insights into the screenwriting process concerning (i) faithfulness of adaptation, (ii) importance of dialog, (iii) preservation of narrative order, and (iv) gender representation issues reflective of the Bechdel test.
</details>
<details>
<summary>摘要</summary>
小说经常被改编成电影，但两媒体之间的差异通常需要从电影剧本中剔除部分源文本。我们通过构建 narative 对应关系，使用 Smith-Waterman 地方对应算法和 SBERT 嵌入距离来衡量场景和书单之间的文本相似性。我们使用这些对应关系来自动分析 40 个改编作品，探讨改编过程中的 faithfulness 问题、对话的重要性、情节的顺序和 gender 表达问题，包括 Bechdel 测试。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Jiu-Jitsu-Argumentation-for-Writing-Peer-Review-Rebuttals"><a href="#Exploring-Jiu-Jitsu-Argumentation-for-Writing-Peer-Review-Rebuttals" class="headerlink" title="Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals"></a>Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03998">http://arxiv.org/abs/2311.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sukannya Purkayastha, Anne Lauscher, Iryna Gurevych</li>
<li>for: 这个论文的目的是为了研究基于态度根和主题的对话战斗系统（Jiu-Jitsu）的 arguecation 风格，以便更好地处理人们的论点。</li>
<li>methods: 这篇论文使用了对话战斗系统（Jiu-Jitsu）的技巧，包括first, 标识对方的态度根和主题，然后选择与这些驱动器相符的抗驳。</li>
<li>results: 这篇论文提出了一种新的任务——态度和主题导向的抗驳生成，并对现有的评论结构数据进行扩充，以便更好地实现这一任务。<details>
<summary>Abstract</summary>
In many domains of argumentation, people's arguments are driven by so-called attitude roots, i.e., underlying beliefs and world views, and their corresponding attitude themes. Given the strength of these latent drivers of arguments, recent work in psychology suggests that instead of directly countering surface-level reasoning (e.g., falsifying given premises), one should follow an argumentation style inspired by the Jiu-Jitsu 'soft' combat system (Hornsey and Fielding, 2017): first, identify an arguer's attitude roots and themes, and then choose a prototypical rebuttal that is aligned with those drivers instead of invalidating those. In this work, we are the first to explore Jiu-Jitsu argumentation for peer review by proposing the novel task of attitude and theme-guided rebuttal generation. To this end, we enrich an existing dataset for discourse structure in peer reviews with attitude roots, attitude themes, and canonical rebuttals. To facilitate this process, we recast established annotation concepts from the domain of peer reviews (e.g., aspects a review sentence is relating to) and train domain-specific models. We then propose strong rebuttal generation strategies, which we benchmark on our novel dataset for the task of end-to-end attitude and theme-guided rebuttal generation and two subtasks.
</details>
<details>
<summary>摘要</summary>
在许多辩论领域，人们的论据受到称为“态度根”的下面启发和世界观的影响，以及其相应的态度主题。由于这些潜在驱动者的力量，最近的心理学研究表明，而不是直接对表面水平的逻辑（例如，证据反驳），更应该采用基于柔敏战斗系统（Jiu-Jitsu）的辩论风格。 specifically, 我们是首次在 peer review 中 explore Jiu-Jitsu 辩论，并提出了 novel task of 态度和主题导向的反驳生成。 To this end, we enrich an existing dataset for discourse structure in peer reviews with attitude roots, attitude themes, and canonical rebuttals. To facilitate this process, we recast established annotation concepts from the domain of peer reviews (e.g., aspects a review sentence is relating to) and train domain-specific models. We then propose strong rebuttal generation strategies, which we benchmark on our novel dataset for the task of end-to-end 态度和主题导向的反驳生成 and two subtasks.Note: "态度根" (attitude roots) and "态度主题" (attitude themes) are not exact translations, but rather concepts that are commonly used in the field of psychology to refer to underlying beliefs and world views that drive people's arguments.
</details></li>
</ul>
<hr>
<h2 id="Factoring-Hate-Speech-A-New-Annotation-Framework-to-Study-Hate-Speech-in-Social-Media"><a href="#Factoring-Hate-Speech-A-New-Annotation-Framework-to-Study-Hate-Speech-in-Social-Media" class="headerlink" title="Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media"></a>Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03969">http://arxiv.org/abs/2311.03969</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gal Ron, Effi Levi, Odelia Oshri, Shaul R. Shenhav</li>
<li>for: 本研究提出了一种新的注释方案，将仇恨言论分为五个分类。</li>
<li>methods: 我们使用了 Twitter 上独特表达仇恨言论的More than 2.9 万句 tweet 数据集，并将样本集中的 1,050 句 tweet 进行注释。</li>
<li>results: 我们通过统计分析注释数据集，以及展示注释示例，并将在未来工作中的可能方向进行讨论。<details>
<summary>Abstract</summary>
In this work we propose a novel annotation scheme which factors hate speech into five separate discursive categories. To evaluate our scheme, we construct a corpus of over 2.9M Twitter posts containing hateful expressions directed at Jews, and annotate a sample dataset of 1,050 tweets. We present a statistical analysis of the annotated dataset as well as discuss annotation examples, and conclude by discussing promising directions for future work.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的注释方案，它将仇恨言论分解为五个分开的说话类别。为评估我们的方案，我们构建了超过290万条推特帖子中含有仇恨表达的集合，并将一个采样集中的1,050条帖子进行注释。我们提供了一些统计分析的数据，以及注释示例，最后讨论了未来工作的可能的方向。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Dialogue-Repair-in-Voice-Assistants"><a href="#An-Analysis-of-Dialogue-Repair-in-Voice-Assistants" class="headerlink" title="An Analysis of Dialogue Repair in Voice Assistants"></a>An Analysis of Dialogue Repair in Voice Assistants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03952">http://arxiv.org/abs/2311.03952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Galbraith</li>
<li>for: 本研究探讨了虚拟助手和用户之间的对话维护，尤其是虚拟助手如何使用和应对用户发起的修复策略”huh?”。</li>
<li>methods: 研究通过分析Google助手和Siri对话的交互语言使用情况，发现虚拟助手使用了一些自己的修复策略，但无法模仿人类对话修复策略。</li>
<li>results: 英语和西班牙用户acceptability调查显示了用户修复策略的偏好和虚拟助手使用情况的相似性和差异，其中存在一些语言间的不平等。这些结果 shed light on 人机交互语言中的不平等， highlighting the need for further research on the impact of interactional language in human-machine interaction.<details>
<summary>Abstract</summary>
Spoken dialogue systems have transformed human-machine interaction by providing real-time responses to queries. However, misunderstandings between the user and system persist. This study explores the significance of interactional language in dialogue repair between virtual assistants and users by analyzing interactions with Google Assistant and Siri, focusing on their utilization and response to the other-initiated repair strategy "huh?" prevalent in human-human interaction. Findings reveal several assistant-generated strategies but an inability to replicate human-like repair strategies such as "huh?". English and Spanish user acceptability surveys show differences in users' repair strategy preferences and assistant usage, with both similarities and disparities among the two surveyed languages. These results shed light on inequalities between interactional language in human-human interaction and human-machine interaction, underscoring the need for further research on the impact of interactional language in human-machine interaction in English and beyond.
</details>
<details>
<summary>摘要</summary>
人工智能对话系统已经改变了人机交互，提供了实时回答用户问题。然而，用户和系统之间的错误仍然存在。这项研究探讨了对话修复在虚拟助手和用户之间的语言互动的重要性，通过分析Google助手和Siri在用户发起修复策略"huh?"的情况。发现虚拟助手采用了多种策略，但无法模仿人类对话修复策略"huh?".英语和西班牙语用户接受度调查显示了用户修复策略的差异和虚拟助手使用情况之间的相似性和差异，这些结果推翻了人类对话修复语言和人机交互语言之间的不等。这些结果也 highlights the need for further research on the impact of interactional language in human-machine interaction in English and beyond.
</details></li>
</ul>
<hr>
<h2 id="Improving-Korean-NLP-Tasks-with-Linguistically-Informed-Subword-Tokenization-and-Sub-character-Decomposition"><a href="#Improving-Korean-NLP-Tasks-with-Linguistically-Informed-Subword-Tokenization-and-Sub-character-Decomposition" class="headerlink" title="Improving Korean NLP Tasks with Linguistically Informed Subword Tokenization and Sub-character Decomposition"></a>Improving Korean NLP Tasks with Linguistically Informed Subword Tokenization and Sub-character Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03928">http://arxiv.org/abs/2311.03928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/taeheejeon22/morphsubdecomp-korean">https://github.com/taeheejeon22/morphsubdecomp-korean</a></li>
<li>paper_authors: Taehee Jeon, Bongseok Yang, Changhwan Kim, Yoonseob Lim</li>
<li>for: 本研究旨在提高韩语语言模型的 sintactic 和 semantics 能力，通过使用 morpheme-aware subword tokenization 方法，解决 byte pair encoding (BPE) 在韩语中的挑战。</li>
<li>methods: 本研究使用 sub-character decomposition 方法，结合 Pre-trained Language Models (PLMs)，以保持语言学正确性和计算效率之间的平衡。</li>
<li>results: 对 NIKL-CoLA 任务的评估表明，该方法可以在总体上获得良好的表现，尤其是在 sintactic 任务中，表明 integrating morpheme type information 可以提高语言模型的 sintactic 和 semantics 能力。<details>
<summary>Abstract</summary>
We introduce a morpheme-aware subword tokenization method that utilizes sub-character decomposition to address the challenges of applying Byte Pair Encoding (BPE) to Korean, a language characterized by its rich morphology and unique writing system. Our approach balances linguistic accuracy with computational efficiency in Pre-trained Language Models (PLMs). Our evaluations show that this technique achieves good performances overall, notably improving results in the syntactic task of NIKL-CoLA. This suggests that integrating morpheme type information can enhance language models' syntactic and semantic capabilities, indicating that adopting more linguistic insights can further improve performance beyond standard morphological analysis.
</details>
<details>
<summary>摘要</summary>
我们介绍一种基于 morpheme 的 subword  tokenization 方法，利用 sub-character 分解来Addressing the challenges of applying Byte Pair Encoding (BPE) to Korean, a language characterized by its rich morphology and unique writing system. Our approach balances linguistic accuracy with computational efficiency in Pre-trained Language Models (PLMs). Our evaluations show that this technique achieves good performances overall, notably improving results in the syntactic task of NIKL-CoLA. This suggests that integrating morpheme type information can enhance language models' syntactic and semantic capabilities, indicating that adopting more linguistic insights can further improve performance beyond standard morphological analysis.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="iACOS-Advancing-Implicit-Sentiment-Extraction-with-Informative-and-Adaptive-Negative-Examples"><a href="#iACOS-Advancing-Implicit-Sentiment-Extraction-with-Informative-and-Adaptive-Negative-Examples" class="headerlink" title="iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples"></a>iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03896">http://arxiv.org/abs/2311.03896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiancai Xu, Jia-Dong Zhang, Lei Xiong, Zhishang Liu</li>
<li>for: 本研究旨在提出一种新的方法iACOS，用于从文本中提取含义不明确的方面、类别和意见。</li>
<li>methods: iACOS方法首先在文本中追加两个隐式token，以获取全 Token的上下文感知表示。然后，iACOS使用一个顺序标签模型，在上下文感知Token表示上进行同时抽取explicit和隐式方面、类别和意见。第三个步骤是开发一种特殊多头注意力的多标签分类器，用于同时发现方面意见对的对应分类和 sentiment。</li>
<li>results: 实验结果表明，iACOS方法在两个公共 benchmark datasets上的F1分数明显高于其他四元EXTRACTION基线。<details>
<summary>Abstract</summary>
Aspect-based sentiment analysis (ABSA) have been extensively studied, but little light has been shed on the quadruple extraction consisting of four fundamental elements: aspects, categories, opinions and sentiments, especially with implicit aspects and opinions. In this paper, we propose a new method iACOS for extracting Implicit Aspects with Categories and Opinions with Sentiments. First, iACOS appends two implicit tokens at the end of a text to capture the context-aware representation of all tokens including implicit aspects and opinions. Second, iACOS develops a sequence labeling model over the context-aware token representation to co-extract explicit and implicit aspects and opinions. Third, iACOS devises a multi-label classifier with a specialized multi-head attention for discovering aspect-opinion pairs and predicting their categories and sentiments simultaneously. Fourth, iACOS leverages informative and adaptive negative examples to jointly train the multi-label classifier and the other two classifiers on categories and sentiments by multi-task learning. Finally, the experimental results show that iACOS significantly outperforms other quadruple extraction baselines according to the F1 score on two public benchmark datasets.
</details>
<details>
<summary>摘要</summary>
它的核心思想是通过附加两个隐式标签来捕捉文本中的上下文意识，并对这些标签进行序列标签化，以同时抽取显式和隐式方面、意见和情感。其次，它采用多标签分类器，并在特定情况下采用多头注意力，同时找到方面意见对应的类别和情感。最后，它使用有用和适应性负例来共同培训多标签分类器和其他两个分类器，通过多任务学习。实验结果表明，iACOS在两个公共 benchmark 数据集上显著超越了其他四元EXTRACTION 基线。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Contrastive-Learning-of-Sentence-Embeddings"><a href="#Sparse-Contrastive-Learning-of-Sentence-Embeddings" class="headerlink" title="Sparse Contrastive Learning of Sentence Embeddings"></a>Sparse Contrastive Learning of Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03881">http://arxiv.org/abs/2311.03881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruize An, Chen Zhang, Dawei Song</li>
<li>for: 本研究旨在证明对句子嵌入进行精简Parameterization可以提高模型性能，并且通过对标准 semantics textual similarity (STS) 任务和转移学习任务进行更多的实验，证明了我们的精简方法的可行性和稳定性。</li>
<li>methods: 本研究使用了对句子嵌入进行精简Parameterization，通过对每个参数计算对总质量的贡献度来确定不必要的参数，并将其精简掉。</li>
<li>results: 结果表明，使用我们的精简方法可以提高模型性能，并且在STS任务和转移学习任务中表现出色。进一步的分析也证明了我们的精简方法的有效性和稳定性。<details>
<summary>Abstract</summary>
Recently, SimCSE has shown the feasibility of contrastive learning in training sentence embeddings and illustrates its expressiveness in spanning an aligned and uniform embedding space. However, prior studies have shown that dense models could contain harmful parameters that affect the model performance, and it is no wonder that SimCSE can as well be invented with such parameters. Driven by this, parameter sparsification is applied, where alignment and uniformity scores are used to measure the contribution of each parameter to the overall quality of sentence embeddings. Drawing from a preliminary study, we consider parameters with minimal contributions to be detrimental, as their sparsification results in improved model performance. To discuss the ubiquity of detrimental parameters and remove them, more experiments on the standard semantic textual similarity (STS) tasks and transfer learning tasks are conducted, and the results show that the proposed sparsified SimCSE (SparseCSE) has excellent performance in comparison with SimCSE. Furthermore, through in-depth analysis, we establish the validity and stability of our sparsification method, showcasing that the embedding space generated by SparseCSE exhibits improved alignment compared to that produced by SimCSE. Importantly, the uniformity yet remains uncompromised.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="OLaLa-Ontology-Matching-with-Large-Language-Models"><a href="#OLaLa-Ontology-Matching-with-Large-Language-Models" class="headerlink" title="OLaLa: Ontology Matching with Large Language Models"></a>OLaLa: Ontology Matching with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03837">http://arxiv.org/abs/2311.03837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sven Hertling, Heiko Paulheim</li>
<li>for: 本研究的目的是探讨如何使用大型自然语言模型（Large Language Model，LLM）提高 Ontology 匹配的效果。</li>
<li>methods: 本研究使用了零shot和几shot提问法，并应用于多种开放的 LLM 上不同的任务，以评估 Ontology Alignment Evaluation Initiative（OAEI）中的不同任务。</li>
<li>results: 研究发现，只需要一些示例和一个良好的提问，就可以达到与supervised matching系统相当的效果，而这些系统使用了许多更多的真实数据。<details>
<summary>Abstract</summary>
Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Conversations-in-Galician-a-Large-Language-Model-for-an-Underrepresented-Language"><a href="#Conversations-in-Galician-a-Large-Language-Model-for-an-Underrepresented-Language" class="headerlink" title="Conversations in Galician: a Large Language Model for an Underrepresented Language"></a>Conversations in Galician: a Large Language Model for an Underrepresented Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03812">http://arxiv.org/abs/2311.03812</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.irlab.org/irlab/cabuxa">https://gitlab.irlab.org/irlab/cabuxa</a></li>
<li>paper_authors: Eliseo Bao, Anxo Pérez, Javier Parapar</li>
<li>for: 提高加利西亚语言处理（NLP）技术的可用性和准确性，以便更好地包括所有语言社区在大语言模型的发展中。</li>
<li>methods: 提出了两种新资源，包括加利西亚语言适应的Alpaca数据集和Cabuxa-7B语言模型，以便进一步推动加利西亚语言的NLP研究。</li>
<li>results: 通过 fine-tuning LLaMA-7B语言模型，成功地使其能够理解和回答加利西亚语言，并证明了该数据集的重要性和可用性。<details>
<summary>Abstract</summary>
The recent proliferation of Large Conversation Language Models has highlighted the economic significance of widespread access to this type of AI technologies in the current information age. Nevertheless, prevailing models have primarily been trained on corpora consisting of documents written in popular languages. The dearth of such cutting-edge tools for low-resource languages further exacerbates their underrepresentation in the current economic landscape, thereby impacting their native speakers. This paper introduces two novel resources designed to enhance Natural Language Processing (NLP) for the Galician language. We present a Galician adaptation of the Alpaca dataset, comprising 52,000 instructions and demonstrations. This dataset proves invaluable for enhancing language models by fine-tuning them to more accurately adhere to provided instructions. Additionally, as a demonstration of the dataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician, a language not originally supported by the model, by following the Alpaca format. This work contributes to the research on multilingual models tailored for low-resource settings, a crucial endeavor in ensuring the inclusion of all linguistic communities in the development of Large Language Models. Another noteworthy aspect of this research is the exploration of how knowledge of a closely related language, in this case, Portuguese, can assist in generating coherent text when training resources are scarce. Both the Galician Alpaca dataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we have made the source code available to facilitate replication of this experiment and encourage further advancements for underrepresented languages.
</details>
<details>
<summary>摘要</summary>
现代信息时代，大型对话语言模型的普及已经启示出了这类人工智能技术在经济领域的经济意义。然而，目前的模型主要是通过流行语言的文献来训练的，这导致了少数语言的下发不足，从而影响了这些语言的原生使用者。本文介绍了两个新资源，旨在提高加利西亚语的自然语言处理（NLP）能力。我们提供了一个加利西亚语版的Alpaca数据集，包含52,000个指令和示例。这个数据集对于提高语言模型来说是非常有价值的，可以通过微调来使模型更加准确地遵循提供的指令。此外，我们还通过使用Alpaca格式来让LLaMA-7B模型能够理解和回答加利西亚语，这是模型原本不支持的语言。这项研究对于开发适用于低资源环境的多语言模型做出了贡献，这是确保所有语言社区参与大语言模型的发展中的关键任务。此外，我们还发现了在资源匮乏时，知道相关语言的知识（在这种情况下是葡萄牙语）可以帮助生成有 coherence 的文本。加利西亚Alpaca数据集和Cabuxa-7B模型都公开 accessible 在我们的Huggingface Hub上，并且我们已经将源代码公开，以便复现这个实验和促进低资源语言的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Pair-Corrector-for-Dense-Retrieval"><a href="#Noisy-Pair-Corrector-for-Dense-Retrieval" class="headerlink" title="Noisy Pair Corrector for Dense Retrieval"></a>Noisy Pair Corrector for Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03798">http://arxiv.org/abs/2311.03798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang Zhang, Yeyun Gong, Xingwei He, Dayiheng Liu, Daya Guo, Jiancheng Lv, Jian Guo</li>
<li>for: 本研究旨在解决 dense retrieval 模型中存在隐式假设：训练查询文档对的匹配是精确的。由于在实际应用中收集训练对不可能进行手动注释，因此实际上存在匹配错误的问题。</li>
<li>methods: 我们提出了一种新的方法called Noisy Pair Corrector (NPC)，它包括检测模块和修正模块。检测模块通过计算标注正方和易获得负方文档的减拟率来估计噪声对。修正模块使用 exponential moving average (EMA) 模型提供软监督信号，以抑制噪声的影响。</li>
<li>results: 我们在 Natural Question 和 TriviaQA 文本检索benchmark上、 StaQC 和 SO-DS 代码检索benchmark上进行实验，结果显示 NPC 能够有效地处理各种噪声。<details>
<summary>Abstract</summary>
Most dense retrieval models contain an implicit assumption: the training query-document pairs are exactly matched. Since it is expensive to annotate the corpus manually, training pairs in real-world applications are usually collected automatically, which inevitably introduces mismatched-pair noise. In this paper, we explore an interesting and challenging problem in dense retrieval, how to train an effective model with mismatched-pair noise. To solve this problem, we propose a novel approach called Noisy Pair Corrector (NPC), which consists of a detection module and a correction module. The detection module estimates noise pairs by calculating the perplexity between annotated positive and easy negative documents. The correction module utilizes an exponential moving average (EMA) model to provide a soft supervised signal, aiding in mitigating the effects of noise. We conduct experiments on text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks StaQC and SO-DS. Experimental results show that NPC achieves excellent performance in handling both synthetic and realistic noise.
</details>
<details>
<summary>摘要</summary>
大多数紧凑检索模型假设训练查询文档对是 preciselly matched。由于在实际应用中annotate文档是非常昂贵的，因此训练对在实际应用中是不可避免的具有匹配错误的噪声。在这篇论文中，我们研究了紧凑检索中一个有趣和挑战的问题：如何训练有效的模型在匹配错误的情况下。为解决这个问题，我们提出了一种新的方法，即噪声对纠正器（NPC）。NPC包括检测模块和修正模块。检测模块通过计算可读性来估算噪声对。修正模块使用指数移动平均（EMA）模型提供软件支持信号，以帮助减轻噪声的影响。我们在自然问答和智能问答等文本检索 bencmarks 上进行了实验， результаados 表明 NPC 在处理 sintétic和实际噪声方面具有杰出的表现。
</details></li>
</ul>
<hr>
<h2 id="Character-Level-Bangla-Text-to-IPA-Transcription-Using-Transformer-Architecture-with-Sequence-Alignment"><a href="#Character-Level-Bangla-Text-to-IPA-Transcription-Using-Transformer-Architecture-with-Sequence-Alignment" class="headerlink" title="Character-Level Bangla Text-to-IPA Transcription Using Transformer Architecture with Sequence Alignment"></a>Character-Level Bangla Text-to-IPA Transcription Using Transformer Architecture with Sequence Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03792">http://arxiv.org/abs/2311.03792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakir Hasan, Shrestha Datta, Ameya Debnath</li>
<li>for: 这个研究旨在应用人工智能和机器学习来生成孟加拉语的国际音标（IPA），以掌握正确的读音和理解。</li>
<li>methods: 本研究使用了一个基于序列转换器的字母和符号级别的模型，以生成孟加拉语每个词的 IPA。</li>
<li>results: 研究获得了在DataVerse Challenge - ITVerse 2023 公开排名中的第一名，word error rate为0.10582。<details>
<summary>Abstract</summary>
The International Phonetic Alphabet (IPA) is indispensable in language learning and understanding, aiding users in accurate pronunciation and comprehension. Additionally, it plays a pivotal role in speech therapy, linguistic research, accurate transliteration, and the development of text-to-speech systems, making it an essential tool across diverse fields. Bangla being 7th as one of the widely used languages, gives rise to the need for IPA in its domain. Its IPA mapping is too diverse to be captured manually giving the need for Artificial Intelligence and Machine Learning in this field. In this study, we have utilized a transformer-based sequence-to-sequence model at the letter and symbol level to get the IPA of each Bangla word as the variation of IPA in association of different words is almost null. Our transformer model only consisted of 8.5 million parameters with only a single decoder and encoder layer. Additionally, to handle the punctuation marks and the occurrence of foreign languages in the text, we have utilized manual mapping as the model won't be able to learn to separate them from Bangla words while decreasing our required computational resources. Finally, maintaining the relative position of the sentence component IPAs and generation of the combined IPA has led us to achieve the top position with a word error rate of 0.10582 in the public ranking of DataVerse Challenge - ITVerse 2023 (https://www.kaggle.com/competitions/dataverse_2023/).
</details>
<details>
<summary>摘要</summary>
国际音声字母（IPA）是语言学习和理解的不可或缺工具，帮助用户准确发音和理解。它在语音治疗、语言研究、精确转写和文本读取系统的发展中扮演着关键性角色，因此在多个领域都是必不可少的工具。孟加拉语是最广泛使用的7种语言之一，因此IPA在其领域的需求增加。孟加拉语IPA映射非常复杂，需要使用人工智能和机器学习来解决。在这项研究中，我们使用了基于转换器的序列到序列模型，以获取孟加拉语每个单词的IPA，因为孟加拉语单词的IPA变化非常小。我们的转换器模型只有850万参数，仅有一个解码和编码层。此外，为了处理括号和外语文本中的特殊符号，我们使用了手动映射。最后，保持句子元素IPA的相对位置和生成组合IPA，我们实现了公开排名的第一名，word error rate为0.10582（https://www.kaggle.com/competitions/dataverse_2023/)。
</details></li>
</ul>
<hr>
<h2 id="Language-Representation-Projection-Can-We-Transfer-Factual-Knowledge-across-Languages-in-Multilingual-Language-Models"><a href="#Language-Representation-Projection-Can-We-Transfer-Factual-Knowledge-across-Languages-in-Multilingual-Language-Models" class="headerlink" title="Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?"></a>Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03788">http://arxiv.org/abs/2311.03788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoyang Xu, Junzhuo Li, Deyi Xiong</li>
<li>for: 本研究探讨了在多语言预训练语言模型中具有可读性的知识的可行性，以及如何通过显式传递来增强多语言知识的共享。</li>
<li>methods: 该研究提出了两个参数化的语言表示 projekt 模块 (LRP2)，用于将非英语表示转换成英语相似的表示，并将英语表示转换回非英语语言的表示。</li>
<li>results: 实验结果表明，LRP2可以显著提高多语言知识检索准确率，并且可以增强多语言知识的共享性。<details>
<summary>Abstract</summary>
Multilingual pretrained language models serve as repositories of multilingual factual knowledge. Nevertheless, a substantial performance gap of factual knowledge probing exists between high-resource languages and low-resource languages, suggesting limited implicit factual knowledge transfer across languages in multilingual pretrained language models. This paper investigates the feasibility of explicitly transferring relatively rich factual knowledge from English to non-English languages. To accomplish this, we propose two parameter-free $\textbf{L}$anguage $\textbf{R}$epresentation $\textbf{P}$rojection modules (LRP2). The first module converts non-English representations into English-like equivalents, while the second module reverts English-like representations back into representations of the corresponding non-English language. Experimental results on the mLAMA dataset demonstrate that LRP2 significantly improves factual knowledge retrieval accuracy and facilitates knowledge transferability across diverse non-English languages. We further investigate the working mechanism of LRP2 from the perspectives of representation space and cross-lingual knowledge neuron.
</details>
<details>
<summary>摘要</summary>
多语言预训言语模型作为多语言事实知识的存储库，但是存在高Resource语言和lowResource语言之间的事实知识检测性能差距，表明在多语言预训言语模型中，各语言之间的知识传递是有限的。本文研究了将英语的较为充足的事实知识转移到非英语语言中的可能性。为此，我们提出了两个参数无关的语言表示项投影模块（LRP2）。第一个模块将非英语表示转换成英语相似的表示，而第二个模块将英语相似的表示恢复回到对应的非英语语言表示。在mLAMA数据集上进行实验，我们发现LRP2能够显著提高事实知识检测精度和提高非英语语言之间的知识传递性。我们还从语料空间和 crossing-lingual知识神经的角度进行了LRP2的工作机制的调查。
</details></li>
</ul>
<hr>
<h2 id="Gender-Inflected-or-Bias-Inflicted-On-Using-Grammatical-Gender-Cues-for-Bias-Evaluation-in-Machine-Translation"><a href="#Gender-Inflected-or-Bias-Inflicted-On-Using-Grammatical-Gender-Cues-for-Bias-Evaluation-in-Machine-Translation" class="headerlink" title="Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation"></a>Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03767">http://arxiv.org/abs/2311.03767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iampushpdeep/gender-bias-hi-en-eval">https://github.com/iampushpdeep/gender-bias-hi-en-eval</a></li>
<li>paper_authors: Pushpdeep Singh</li>
<li>for: 这个研究旨在评估不同语言源语言的神经机器翻译模型中存在的社会偏见，特别是对 gender 的偏见。</li>
<li>methods: 该研究使用了 Hindi 作为源语言，并构建了两组 gender-specific 句子集：OTSC-Hindi 和 WinoMT-Hindi，以自动评估不同的 Hindi-English (HI-EN) NMT 系统的性偏见。</li>
<li>results: 该研究显示了考虑语言的性质在设计 extrinsic bias 评估数据集时的重要性。<details>
<summary>Abstract</summary>
Neural Machine Translation (NMT) models are state-of-the-art for machine translation. However, these models are known to have various social biases, especially gender bias. Most of the work on evaluating gender bias in NMT has focused primarily on English as the source language. For source languages different from English, most of the studies use gender-neutral sentences to evaluate gender bias. However, practically, many sentences that we encounter do have gender information. Therefore, it makes more sense to evaluate for bias using such sentences. This allows us to determine if NMT models can identify the correct gender based on the grammatical gender cues in the source sentence rather than relying on biased correlations with, say, occupation terms. To demonstrate our point, in this work, we use Hindi as the source language and construct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi that we use to evaluate different Hindi-English (HI-EN) NMT systems automatically for gender bias. Our work highlights the importance of considering the nature of language when designing such extrinsic bias evaluation datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multilingual-Mathematical-Autoformalization"><a href="#Multilingual-Mathematical-Autoformalization" class="headerlink" title="Multilingual Mathematical Autoformalization"></a>Multilingual Mathematical Autoformalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03755">http://arxiv.org/abs/2311.03755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albertqjiang/mma">https://github.com/albertqjiang/mma</a></li>
<li>paper_authors: Albert Q. Jiang, Wenda Li, Mateja Jamnik</li>
<li>for: 这个论文的目的是为了提高自动ormalization的研究进步，即将自然语言材料翻译成机器可验证的形式化表述。</li>
<li>methods: 这篇论文使用了一种语言模型来将正式数学陈述翻译成相应的不正式陈述，即在反向向き中使用语言模型进行翻译。</li>
<li>results: 实验表明，对于 $\texttt{MMA}$ dataset进行精度调整后，语言模型在 $\texttt{miniF2F}$ 和 $\texttt{ProofNet}$ 测试准则上的表现提高了 $16-18%$，比基础模型的表现提高了 $0%$。这表明，在多语言正式数学数据上进行精度调整后，自动ormalization模型在单语言任务上也能够更强大。<details>
<summary>Abstract</summary>
Autoformalization is the task of translating natural language materials into machine-verifiable formalisations. Progress in autoformalization research is hindered by the lack of a sizeable dataset consisting of informal-formal pairs expressing the same essence. Existing methods tend to circumvent this challenge by manually curating small corpora or using few-shot learning with large language models. But these methods suffer from data scarcity and formal language acquisition difficulty. In this work, we create $\texttt{MMA}$, a large, flexible, multilingual, and multi-domain dataset of informal-formal pairs, by using a language model to translate in the reverse direction, that is, from formal mathematical statements into corresponding informal ones. Experiments show that language models fine-tuned on $\texttt{MMA}$ produce $16-18\%$ of statements acceptable with minimal corrections on the $\texttt{miniF2F}$ and $\texttt{ProofNet}$ benchmarks, up from $0\%$ with the base model. We demonstrate that fine-tuning on multilingual formal data results in more capable autoformalization models even when deployed on monolingual tasks.
</details>
<details>
<summary>摘要</summary>
自然语言材料的自动化正式化任务是将自然语言材料翻译成机器可验证的形式化表达。研究进步受到有限的大量数据集阻碍，其中包含同一主题的 Informal-Formal 对应对。现有方法通常使用手动抽象小 corpus 或几shot学习大语言模型。但这些方法受到数据稀缺和正式语言学习困难的限制。在这种工作中，我们创建了 $\texttt{MMA}$  dataset，它是一个大型、灵活、多语言、多领域的 informal-formal 对应对。我们使用语言模型将 formal 数学陈述翻译到对应的 informal 陈述，从而创建了这个 dataset。实验显示，在 $\texttt{MMA}$ 上进行 fine-tuning 后，模型在 $\texttt{miniF2F}$ 和 $\texttt{ProofNet}$ benchmark 上可以提交 $16-18\%$ 的声明，与基础模型相比增加了 $0\%$。我们还证明了在多语言正式数据上进行 fine-tuning 可以创造更强的自动化正式化模型，即使在单语言任务上部署。
</details></li>
</ul>
<hr>
<h2 id="Which-is-better-Exploring-Prompting-Strategy-For-LLM-based-Metrics"><a href="#Which-is-better-Exploring-Prompting-Strategy-For-LLM-based-Metrics" class="headerlink" title="Which is better? Exploring Prompting Strategy For LLM-based Metrics"></a>Which is better? Exploring Prompting Strategy For LLM-based Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03754">http://arxiv.org/abs/2311.03754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin Lee, Seung Hun Han, Jiyoon Lee, Pilsung Kang</li>
<li>for: 本研究探讨了使用大型自然语言处理模型（LLM）来评估自然语言生成（NLG）质量的可能性，以提高传统的相似性基于的评价 metric 的精度。</li>
<li>methods: 本研究使用了多种提问和提问技术来系统地分析NLG质量的评估，包括提问策略、分数汇总和解释性分析。</li>
<li>results: 研究发现了一些有效的提问模板和分数汇总策略，以及在具体上进行NLG质量评估时的解释性分析。此外，研究还发现了一些可靠的分数汇总策略，并对open-source LLM的解释性进行了分析。<details>
<summary>Abstract</summary>
This paper describes the DSBA submissions to the Prompting Large Language Models as Explainable Metrics shared task, where systems were submitted to two tracks: small and large summarization tracks. With advanced Large Language Models (LLMs) such as GPT-4, evaluating the quality of Natural Language Generation (NLG) has become increasingly paramount. Traditional similarity-based metrics such as BLEU and ROUGE have shown to misalign with human evaluation and are ill-suited for open-ended generation tasks. To address this issue, we explore the potential capability of LLM-based metrics, especially leveraging open-source LLMs. In this study, wide range of prompts and prompting techniques are systematically analyzed with three approaches: prompting strategy, score aggregation, and explainability. Our research focuses on formulating effective prompt templates, determining the granularity of NLG quality scores and assessing the impact of in-context examples on LLM-based evaluation. Furthermore, three aggregation strategies are compared to identify the most reliable method for aggregating NLG quality scores. To examine explainability, we devise a strategy that generates rationales for the scores and analyzes the characteristics of the explanation produced by the open-source LLMs. Extensive experiments provide insights regarding evaluation capabilities of open-source LLMs and suggest effective prompting strategies.
</details>
<details>
<summary>摘要</summary>
The study systematically analyzes a wide range of prompts and prompting techniques using three approaches: prompting strategy, score aggregation, and explainability. The focus is on formulating effective prompt templates, determining the granularity of NLG quality scores, and assessing the impact of in-context examples on LLM-based evaluation. Additionally, the paper compares three aggregation strategies to identify the most reliable method for aggregating NLG quality scores. To examine explainability, the paper devises a strategy that generates rationales for the scores and analyzes the characteristics of the explanations produced by the open-source LLMs.Extensive experiments provide insights into the evaluation capabilities of open-source LLMs and suggest effective prompting strategies. The findings suggest that LLM-based metrics have the potential to provide more accurate evaluations of NLG quality than traditional metrics, and that prompting techniques can significantly impact the quality of the generated text. The study contributes to the development of more effective and reliable evaluation methods for NLG systems, which is essential for advancing the field of natural language processing.
</details></li>
</ul>
<hr>
<h2 id="Unified-Low-Resource-Sequence-Labeling-by-Sample-Aware-Dynamic-Sparse-Finetuning"><a href="#Unified-Low-Resource-Sequence-Labeling-by-Sample-Aware-Dynamic-Sparse-Finetuning" class="headerlink" title="Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning"></a>Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03748">http://arxiv.org/abs/2311.03748</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/fish-dip">https://github.com/psunlpgroup/fish-dip</a></li>
<li>paper_authors: Sarkar Snigdha Sarathi Das, Ranran Haoran Zhang, Peng Shi, Wenpeng Yin, Rui Zhang</li>
<li>For: 这 paper 的目的是 addresses the challenge of leveraging pre-trained language models (PLMs) for sequence labeling tasks in data-limited settings, where finetuning large models cannot properly generalize to the target format.* Methods: 该 paper 提出了 FISH-DIP，一种 sample-aware dynamic sparse finetuning strategy that selectively focuses on a fraction of parameters, informed by feedback from highly regressing examples, during the fine-tuning process.* Results:  compared to full fine-tuning, FISH-DIP can smoothly optimize the model in low resource settings, offering up to 40% performance improvements depending on the target evaluation settings. Additionally, FISH-DIP performs comparably or better than in-context learning and other parameter-efficient fine-tuning approaches, notably in extreme low-resource settings.<details>
<summary>Abstract</summary>
Unified Sequence Labeling that articulates different sequence labeling problems such as Named Entity Recognition, Relation Extraction, Semantic Role Labeling, etc. in a generalized sequence-to-sequence format opens up the opportunity to make the maximum utilization of large language model knowledge toward structured prediction. Unfortunately, this requires formatting them into specialized augmented format unknown to the base pretrained language model (PLMs) necessitating finetuning to the target format. This significantly bounds its usefulness in data-limited settings where finetuning large models cannot properly generalize to the target format. To address this challenge and leverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic sparse finetuning strategy that selectively focuses on a fraction of parameters, informed by feedback from highly regressing examples, during the fine-tuning process. By leveraging the dynamism of sparsity, our approach mitigates the impact of well-learned samples and prioritizes underperforming instances for improvement in generalization. Across five tasks of sequence labeling, we demonstrate that FISH-DIP can smoothly optimize the model in low resource settings offering upto 40% performance improvements over full fine-tuning depending on target evaluation settings. Also, compared to in-context learning and other parameter-efficient fine-tuning approaches, FISH-DIP performs comparably or better, notably in extreme low-resource settings.
</details>
<details>
<summary>摘要</summary>
通过普适化序列标签问题，如命名实体识别、关系提取、semantic role labeling等，到通用的序列到序列形式开放了最大利用大语言模型知识的可能性。然而，这需要将它们格式化为特定的扩展格式，不знаком于基础预训练语言模型（PLMs），因此需要训练目标格式。这会限制其在数据有限的情况下使用，因为大型模型在目标格式上不能充分泛化。为解决这个挑战并有效地利用PLM知识，我们提出了鱼钓式动态稀缺训练策略（FISH-DIP）。在精细化过程中，我们 selectively 针对一部分参数，根据高度反例反馈，进行稀缺训练。通过利用动态稀缺的优势，我们的方法可以减轻已学习的样本的影响，并且优先级为不良实例进行改进，以提高通用性。在五种序列标签任务上，我们示示了FISH-DIP可以在低资源设置下简单地优化模型，提供最多40%的性能提升，具体取决于目标评估设置。此外，相比受 Context 学习和其他参数效率精细化方法，FISH-DIP在极低资源设置下表现相对或更好，特别是在极低资源设置下。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Structured-Information-for-Explainable-Multi-hop-Question-Answering-and-Reasoning"><a href="#Leveraging-Structured-Information-for-Explainable-Multi-hop-Question-Answering-and-Reasoning" class="headerlink" title="Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning"></a>Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03734">http://arxiv.org/abs/2311.03734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruosen Li, Xinya Du</li>
<li>for: 这个论文主要目标是提高大型语言模型（LLM）在多步问答中的表现，以及提高模型的推理能力。</li>
<li>methods: 这个论文使用了链条机制（CoT）来生成推理链和答案，以提高模型的多步推理能力。</li>
<li>results: 这个论文的实验和人工评估结果显示，该框架可以生成更准确的推理链，并在两个标准数据集上显著提高问答性能。此外，提取的 semantic structures 自然地提供了可读性好的解释，而不是生成的推理链和重要性基于的解释。<details>
<summary>Abstract</summary>
Neural models, including large language models (LLMs), achieve superior performance on multi-hop question-answering. To elicit reasoning capabilities from LLMs, recent works propose using the chain-of-thought (CoT) mechanism to generate both the reasoning chain and the answer, which enhances the model's capabilities in conducting multi-hop reasoning. However, several challenges still remain: such as struggling with inaccurate reasoning, hallucinations, and lack of interpretability. On the other hand, information extraction (IE) identifies entities, relations, and events grounded to the text. The extracted structured information can be easily interpreted by humans and machines (Grishman, 2019). In this work, we investigate constructing and leveraging extracted semantic structures (graphs) for multi-hop question answering, especially the reasoning process. Empirical results and human evaluations show that our framework: generates more faithful reasoning chains and substantially improves the QA performance on two benchmark datasets. Moreover, the extracted structures themselves naturally provide grounded explanations that are preferred by humans, as compared to the generated reasoning chains and saliency-based explanations.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLMs）在多步问答 task 上表现出色，以便激发理解能力。为了从 LLMs 中提取理解能力，latest works 提议使用链条思维（CoT）机制生成问答链和答案，从而提高模型在多步理解中的能力。然而，还有一些挑战：如偏差的理解、幻觉和解释不可读性。在另一方面，信息抽取（IE）可以提取到文本中的实体、关系和事件，并将其固化为结构化的信息，这些信息可以轻松地被人类和机器解释（Grishman, 2019）。在这个工作中，我们研究构建和利用提取的semantic structure（图）来进行多步问答，特别是理解过程。我们的实验结果和人类评估表明，我们的框架：可以生成更 faithful 的理解链和substantially 改善在两个 benchmark 数据集上的问答性能。此外，提取的结构本身就提供了固化的解释，与生成的理解链和Saliency-based解释相比，更被人类首选。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Learn-for-Few-shot-Continual-Active-Learning"><a href="#Learning-to-Learn-for-Few-shot-Continual-Active-Learning" class="headerlink" title="Learning to Learn for Few-shot Continual Active Learning"></a>Learning to Learn for Few-shot Continual Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03732">http://arxiv.org/abs/2311.03732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stella Ho, Ming Liu, Shang Gao, Longxiang Gao</li>
<li>for: 解决几个任务的稳定性和新领域的пластично性问题。</li>
<li>methods: 使用元学习和经验回放来解决稳定性和пластично性之间的贸易OFF。</li>
<li>results: 通过随机抽取活动学习和记忆样本选择策略，实现了快速适应新任务的目标。<details>
<summary>Abstract</summary>
Continual learning strives to ensure stability in solving previously seen tasks while demonstrating plasticity in a novel domain. Recent advances in CL are mostly confined to a supervised learning setting, especially in NLP domain. In this work, we consider a few-shot continual active learning (CAL) setting where labeled data is inadequate, and unlabeled data is abundant but with a limited annotation budget. We propose a simple but efficient method, called Meta-Continual Active Learning. Specifically, we employ meta-learning and experience replay to address the trade-off between stability and plasticity. As a result, it finds an optimal initialization that efficiently utilizes annotated information for fast adaptation while preventing catastrophic forgetting of past tasks. We conduct extensive experiments to validate the effectiveness of the proposed method and analyze the effect of various active learning strategies and memory sample selection methods in a few-shot CAL setup. Our experiment results demonstrate that random sampling is the best default strategy for both active learning and memory sample selection to solve few-shot CAL problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Survey-of-Large-Language-Models-Attribution"><a href="#A-Survey-of-Large-Language-Models-Attribution" class="headerlink" title="A Survey of Large Language Models Attribution"></a>A Survey of Large Language Models Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03731">http://arxiv.org/abs/2311.03731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/awesome-llm-attributions">https://github.com/HITsz-TMG/awesome-llm-attributions</a></li>
<li>paper_authors: Dongfang Li, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Ziyang Chen, Baotian Hu, Aiguo Wu, Min Zhang</li>
<li>for: 这篇论文主要为了探讨开放领域生成系统中使用的归因机制，特别是大语言模型。</li>
<li>methods: 论文提出了各种归因方法，包括权重调整、排名、权重评估等方法。</li>
<li>results: 论文指出，归因机制可以提高对话型AI系统的可靠性和准确性，但同时也存在一些问题，如知识库的抽象、内置的偏见和过度归因的缺点。<details>
<summary>Abstract</summary>
Open-domain generative systems have gained significant attention in the field of conversational AI (e.g., generative search engines). This paper presents a comprehensive review of the attribution mechanisms employed by these systems, particularly large language models. Though attribution or citation improve the factuality and verifiability, issues like ambiguous knowledge reservoirs, inherent biases, and the drawbacks of excessive attribution can hinder the effectiveness of these systems. The aim of this survey is to provide valuable insights for researchers, aiding in the refinement of attribution methodologies to enhance the reliability and veracity of responses generated by open-domain generative systems. We believe that this field is still in its early stages; hence, we maintain a repository to keep track of ongoing studies at https://github.com/HITsz-TMG/awesome-llm-attributions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本翻译成简化中文。<</SYS>>开放领域生成系统在对话AI中受到了广泛关注（例如生成搜索引擎）。这篇评论文章介绍了这些系统使用的归因机制，特别是大语言模型。虽然归因或参考可以提高事实性和可靠性，但是存在杂乱知识库、内生偏见和过度归因的问题可能会妨碍这些系统的效果。本评论的目的是为研究人员提供有价值的洞察，以便通过修复归因方法来提高开放领域生成系统的可靠性和真实性。我们认为这个领域还处在早期阶段，因此我们维护了一个存储库，以跟踪进行中的研究：https://github.com/HITsz-TMG/awesome-llm-attributions。
</details></li>
</ul>
<hr>
<h2 id="Bilingual-Corpus-Mining-and-Multistage-Fine-Tuning-for-Improving-Machine-Translation-of-Lecture-Transcripts"><a href="#Bilingual-Corpus-Mining-and-Multistage-Fine-Tuning-for-Improving-Machine-Translation-of-Lecture-Transcripts" class="headerlink" title="Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine Translation of Lecture Transcripts"></a>Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine Translation of Lecture Transcripts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03696">http://arxiv.org/abs/2311.03696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shyyhs/CourseraParallelCorpusMining">https://github.com/shyyhs/CourseraParallelCorpusMining</a></li>
<li>paper_authors: Haiyue Song, Raj Dabre, Chenhui Chu, Atsushi Fujita, Sadao Kurohashi<br>for: 这个论文主要目的是为了提高在线课程笔记翻译系统的质量。methods: 这篇论文提出了一种框架，用于从Coursera上公开的讲座中挖掘并构建平行 corpora，以提高笔记翻译系统的性能。这个框架使用了动态Programming基于 sentences的对齐算法，并使用cosine similarity来衡量对齐的准确率。results: 这篇论文的实验结果表明，使用这个框架和方法可以从Coursera上公开的讲座中挖掘出高质量的平行 corpora，并且可以提高笔记翻译系统的性能。在英文–日语和英文–中文讲座翻译中，这个框架提取了约50,000行的平行 corpora，并通过手动筛选创建了开发和测试集。通过机器翻译实验，这个研究表明了这些挖掘出来的平行 corpora可以帮助提高讲座笔记翻译质量。此外，这个研究还提供了收集和清洁 corpora、挖掘平行句、清理受到干扰的数据、创建高质量评估分割的指南。<details>
<summary>Abstract</summary>
Lecture transcript translation helps learners understand online courses, however, building a high-quality lecture machine translation system lacks publicly available parallel corpora. To address this, we examine a framework for parallel corpus mining, which provides a quick and effective way to mine a parallel corpus from publicly available lectures on Coursera. To create the parallel corpora, we propose a dynamic programming based sentence alignment algorithm which leverages the cosine similarity of machine-translated sentences. The sentence alignment F1 score reaches 96%, which is higher than using the BERTScore, LASER, or sentBERT methods. For both English--Japanese and English--Chinese lecture translations, we extracted parallel corpora of approximately 50,000 lines and created development and test sets through manual filtering for benchmarking translation performance. Through machine translation experiments, we show that the mined corpora enhance the quality of lecture transcript translation when used in conjunction with out-of-domain parallel corpora via multistage fine-tuning. Furthermore, this study also suggests guidelines for gathering and cleaning corpora, mining parallel sentences, cleaning noise in the mined data, and creating high-quality evaluation splits. For the sake of reproducibility, we have released the corpora as well as the code to create them. The dataset is available at https://github.com/shyyhs/CourseraParallelCorpusMining.
</details>
<details>
<summary>摘要</summary>
讲义笔记翻译帮助学习者理解在线课程，但建立高质量讲义机器翻译系统缺乏公共可用并行词库。为此，我们提出了并行词库挖掘框架，该框架可以快速地挖掘来自Coursera上公开的讲义课程中的并行词库。为创建并行词库，我们提议使用动态计划方法进行句子对齐算法，利用机器翻译后的句子的央角相似性。句子对齐F1分数达96%，高于使用BERTScore、LASER或sentBERT方法。我们对英语-日语和英语-中文讲义笔记翻译进行了约50,000行的并行词库抽取，并通过手动筛选创建了开发和测试集。通过机器翻译实验，我们证明了挖掘出来的 corpora 可以提高讲义笔记翻译质量，并且可以与来自不同领域的并行词库进行多Stage精细调整。此外，这种研究还提供了搜集和清洁 corpora 的指南，以及挖掘并行句子、清理句子中噪音的方法。为了保持可重现性，我们将 corpora 及其创建代码发布到 GitHub。数据集可在https://github.com/shyyhs/CourseraParallelCorpusMining 中下载。
</details></li>
</ul>
<hr>
<h2 id="Dissecting-the-Runtime-Performance-of-the-Training-Fine-tuning-and-Inference-of-Large-Language-Models"><a href="#Dissecting-the-Runtime-Performance-of-the-Training-Fine-tuning-and-Inference-of-Large-Language-Models" class="headerlink" title="Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models"></a>Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03687">http://arxiv.org/abs/2311.03687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longteng Zhang, Xiang Liu, Zeyu Li, Xinglin Pan, Peijie Dong, Ruibo Fan, Rui Guo, Xin Wang, Qiong Luo, Shaohuai Shi, Xiaowen Chu</li>
<li>for: 本研究旨在对大语言模型（LLMs）的预训练、精度调整和服务器端的性能进行Benchmark，以便更好地选择适合的硬件和软件栈。</li>
<li>methods: 本研究使用了7B、13B和70B参数大小的LLMs，在三个8 GPU平台上进行了端到端性能测试，并对各种优化技术进行了评估，包括ZeRO、量化、重计算和FlashAttention。同时，本研究还进行了LLMs中各模块的Runtime分析。</li>
<li>results: 研究发现，在不同的硬件和软件栈上，LLMs的运行时间可以有很大差异。在不同的优化技术和硬件平台上，可以获得更好的性能。此外，本研究还发现了一些可能的优化机会，可以帮助研究人员在未来更好地优化LLMs的运行时间。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have seen great advance in both academia and industry, and their popularity results in numerous open-source frameworks and techniques in accelerating LLM pre-training, fine-tuning, and inference. Training and deploying LLMs are expensive as it requires considerable computing resources and memory, hence many efficient approaches have been developed for improving system pipelines as well as operators. However, the runtime performance can vary significantly across hardware and software stacks, which makes it difficult to choose the best configuration. In this work, we aim to benchmark the performance from both macro and micro perspectives. First, we benchmark the end-to-end performance of pre-training, fine-tuning, and serving LLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and 70B) on three 8-GPU platforms with and without individual optimization techniques, including ZeRO, quantization, recomputation, FlashAttention. Then, we dive deeper to provide a detailed runtime analysis of the sub-modules, including computing and communication operators in LLMs. For end users, our benchmark and findings help better understand different optimization techniques, training and inference frameworks, together with hardware platforms in choosing configurations for deploying LLMs. For researchers, our in-depth module-wise analyses discover potential opportunities for future work to further optimize the runtime performance of LLMs.
</details>
<details>
<summary>摘要</summary>
首先，我们将在不同大小的 LLMs （7B、13B和70B）上进行终端性能测试，并在三个8核心平台上测试，包括无ZeRO、量化、重computation和FlashAttention等个性化优化技术。然后，我们会进行详细的运行时分析，探讨 LLMs 中计算和通信操作的性能。对于用户来说，我们的benchmark和发现可以帮助他们更好地理解不同的优化技术、训练和推理框架以及硬件平台，以便更好地选择 LLMs 的部署配置。对于研究人员来说，我们的深入模块化分析可以探讨未来可能出现的可能性，以便进一步优化 LLMs 的运行时性能。
</details></li>
</ul>
<hr>
<h2 id="CBSiMT-Mitigating-Hallucination-in-Simultaneous-Machine-Translation-with-Weighted-Prefix-to-Prefix-Training"><a href="#CBSiMT-Mitigating-Hallucination-in-Simultaneous-Machine-Translation-with-Weighted-Prefix-to-Prefix-Training" class="headerlink" title="CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation with Weighted Prefix-to-Prefix Training"></a>CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation with Weighted Prefix-to-Prefix Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03672">http://arxiv.org/abs/2311.03672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengge Liu, Wen Zhang, Xiang Li, Yanzhi Tian, Yuhang Guo, Jian Luan, Bin Wang, Shuoying Chen</li>
<li>for: 该研究旨在提高同时翻译（SiMT）任务中的翻译质量，尤其是在开始翻译前只有部分源语句可用时。</li>
<li>methods: 该研究提出了一种自信量基于的同时翻译机器翻译（CBSiMT）框架，利用模型自信量来识别幻化token并通过加权前缀-前缀训练来减少其影响。</li>
<li>results: 实验结果表明，该方法可以在不同的延迟环境下提高翻译质量，最高达2个BLEU分数提升，并且可以在低延迟环境下提供更好的翻译结果。<details>
<summary>Abstract</summary>
Simultaneous machine translation (SiMT) is a challenging task that requires starting translation before the full source sentence is available. Prefix-to-prefix framework is often applied to SiMT, which learns to predict target tokens using only a partial source prefix. However, due to the word order difference between languages, misaligned prefix pairs would make SiMT models suffer from serious hallucination problems, i.e. target outputs that are unfaithful to source inputs. Such problems can not only produce target tokens that are not supported by the source prefix, but also hinder generating the correct translation by receiving more source words. In this work, we propose a Confidence-Based Simultaneous Machine Translation (CBSiMT) framework, which uses model confidence to perceive hallucination tokens and mitigates their negative impact with weighted prefix-to-prefix training. Specifically, token-level and sentence-level weights are calculated based on model confidence and acted on the loss function. We explicitly quantify the faithfulness of the generated target tokens using the token-level weight, and employ the sentence-level weight to alleviate the disturbance of sentence pairs with serious word order differences on the model. Experimental results on MuST-C English-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our method can consistently improve translation quality at most latency regimes, with up to 2 BLEU scores improvement at low latency.
</details>
<details>
<summary>摘要</summary>
simultaneous机器翻译（SiMT）是一项具有挑战性的任务，需要在源句子完全可用之前开始翻译。 prefix-to-prefix框架经常用于SiMT，这种框架学习使用只有部分源前缀来预测目标符。然而，由于语言之间的单词顺序差异，可能会出现误差的前缀对，导致SiMT模型受到严重的幻觉问题，即目标输出不符合源输入。这些问题不仅会生成不支持源前缀的目标符，还会阻碍模型生成正确的翻译。在这种情况下，我们提出了一种 confidence-based 同时机器翻译（CBSiMT）框架，使用模型 confidence 来识别幻觉符并通过轮征 prefix-to-prefix 训练来减少其影响。具体来说，我们根据模型 confidence 计算 token-level 和 sentence-level 权重，然后在损失函数中应用这些权重。我们使用 token-level 权重来评估生成的目标符的具体性，并使用 sentence-level 权重来减轻word order差异的影响。我们在 MuST-C 英-中翻译和 WMT15 德-英翻译 SiMT 任务上进行实验，结果表明，我们的方法可以在不同的延迟环境下一直提高翻译质量，最高达到2 BLEU 分数提升。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-NLP-Models-Notion-and-Causation"><a href="#Generalization-of-NLP-Models-Notion-and-Causation" class="headerlink" title="Generalization of NLP Models: Notion and Causation"></a>Generalization of NLP Models: Notion and Causation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03663">http://arxiv.org/abs/2311.03663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aparna Elangovan, Jiayuan He, Yuan Li, Karin Verspoor</li>
<li>for: 本研究旨在探讨模型在不同数据集中的普适性，以及各种因素对模型普适性的影响。</li>
<li>methods: 本研究使用了严格的实验方法，以确保内部有效性，并对数据中的假 correlate进行分析，以避免模型受到假 correlate的影响。</li>
<li>results: 研究发现，模型在不同数据集中的性能会受到各种因素的影响，包括数据中的假 correlate。通过对实验中的假 correlate进行分析，可以更好地理解模型在不同数据集中的普适性。<details>
<summary>Abstract</summary>
The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to "out-of-distribution'' effects. Here, we explore the foundations of generalizability and study the various factors that affect it, articulating generalizability lessons from clinical studies. In clinical research generalizability depends on (a) internal validity of experiments to ensure controlled measurement of cause and effect, and (b) external validity or transportability of the results to the wider population. We present the need to ensure internal validity when building machine learning models in natural language processing, especially where results may be impacted by spurious correlations in the data. We demonstrate how spurious factors, such as the distance between entities in relation extraction tasks, can affect model internal validity and in turn adversely impact generalization. We also offer guidance on how to analyze generalization failures.
</details>
<details>
<summary>摘要</summary>
nlp社区通常通过模型在封闭测试集上的表现来评估泛化性。模型在外部数据集上的表现下降通常被归结为“非常区”的效果。我们探究泛化性的基础和它受到哪些因素的影响，从临床研究中提炼泛化性评价的教训。在自然语言处理领域建立机器学习模型时，特别是在数据中存在误差相关性的情况下，需要确保模型的内部有效性。我们示例了如何使用误差因素分析泛化失败的原因。Note: "泛化性" (generalizability) in Chinese is often translated as "泛化" (generalization), but the two terms have slightly different connotations. "泛化" generally refers to the ability of a model to perform well on new, unseen data, while "泛化性" emphasizes the robustness and general applicability of the model across different domains or populations. In this text, I have used "泛化性" to emphasize the importance of considering the broader context and potential applications of the model.
</details></li>
</ul>
<hr>
<h2 id="Innovation-and-Word-Usage-Patterns-in-Machine-Learning"><a href="#Innovation-and-Word-Usage-Patterns-in-Machine-Learning" class="headerlink" title="Innovation and Word Usage Patterns in Machine Learning"></a>Innovation and Word Usage Patterns in Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03633">http://arxiv.org/abs/2311.03633</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vitorbborges/monografia-PET22">https://github.com/vitorbborges/monografia-PET22</a></li>
<li>paper_authors: Vítor Bandeira Borges, Daniel Oliveira Cajueiro</li>
<li>for: 本研究探讨机器学习研究的动态领域发展。</li>
<li>methods: 通过矩阵 Dirichlet 分配，检测出机器学习领域中突出的主题和基本概念，然后进行全面分析，跟踪这些主题的演化轨迹。</li>
<li>results: 通过卷积-黑eli均度度量，衡量研究贡献的新颖度和差异度，得出机器学习领域中主要研究人员和期刊&#x2F;会议的重要性。<details>
<summary>Abstract</summary>
In this study, we delve into the dynamic landscape of machine learning research evolution. Initially, through the utilization of Latent Dirichlet Allocation, we discern pivotal themes and fundamental concepts that have emerged within the realm of machine learning. Subsequently, we undertake a comprehensive analysis to track the evolutionary trajectories of these identified themes. To quantify the novelty and divergence of research contributions, we employ the Kullback-Leibler Divergence metric. This statistical measure serves as a proxy for ``surprise'', indicating the extent of differentiation between the content of academic papers and the subsequent developments in research. By amalgamating these insights, we gain the ability to ascertain the pivotal roles played by prominent researchers and the significance of specific academic venues (periodicals and conferences) within the machine learning domain.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们探讨机器学习研究的动态景观。首先，通过利用秘密分配（Latent Dirichlet Allocation），我们找到了机器学习领域中突出的主题和基本概念。然后，我们进行了全面的分析，跟踪这些确定的主题的演化轨迹。为了衡量研究贡献的新鲜度和偏离度，我们使用库拉克-莱布лер分配度量。这个统计量作为“意外”的代表，反映了学术论文的内容和后续研究的差异。通过汇集这些意见，我们获得了评估机器学习领域中重要研究者和期刊（期刊和会议）的重要性的能力。
</details></li>
</ul>
<hr>
<h2 id="GNAT-A-General-Narrative-Alignment-Tool"><a href="#GNAT-A-General-Narrative-Alignment-Tool" class="headerlink" title="GNAT: A General Narrative Alignment Tool"></a>GNAT: A General Narrative Alignment Tool</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03627">http://arxiv.org/abs/2311.03627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanzir Pial, Steven Skiena</li>
<li>for: 本研究是为了解决对短版文本的 narrative alignment 问题，尤其是对翻译和摘要等短文本的对比和对Alignment。</li>
<li>methods: 本研究使用 Smith-Waterman 算法和现代文本相似度指标，将生物信息学和现代文本分析相结合，实现了一种通用的 narrative alignment 方法。</li>
<li>results: 本研究在四个不同的问题领域中应用和评估了GNAT工具，包括摘要到书籍对 alignment、翻译书籍对 alignment、短篇文本对 alignment 和 плаги产检测等，并达到了高度和性能。<details>
<summary>Abstract</summary>
Algorithmic sequence alignment identifies similar segments shared between pairs of documents, and is fundamental to many NLP tasks. But it is difficult to recognize similarities between distant versions of narratives such as translations and retellings, particularly for summaries and abridgements which are much shorter than the original novels.   We develop a general approach to narrative alignment coupling the Smith-Waterman algorithm from bioinformatics with modern text similarity metrics. We show that the background of alignment scores fits a Gumbel distribution, enabling us to define rigorous p-values on the significance of any alignment. We apply and evaluate our general narrative alignment tool (GNAT) on four distinct problem domains differing greatly in both the relative and absolute length of documents, namely summary-to-book alignment, translated book alignment, short story alignment, and plagiarism detection -- demonstrating the power and performance of our methods.
</details>
<details>
<summary>摘要</summary>
算法序列对齐可以识别文档对的相似段落，这是许多自然语言处理任务的基础。但是对于远程的 narrative 翻译和重新 narración，特别是摘要和缩写，寻找相似之处很难。我们开发了一种通用的 narative 对齐方法，结合 Smith-Waterman 算法和现代文本相似度度量。我们发现对齐背景的对齐分布适合 Gumbel 分布，因此我们可以定义精确的 p-值，用于评估对齐的重要性。我们应用和评估我们的通用 narative 对齐工具（GNAT）在四种不同的问题领域中，包括摘要到书籍对齐、翻译书籍对齐、短篇对齐和抄袭检测，并在这些领域中证明了我们的方法的能力和性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.CL_2023_11_07/" data-id="clorjzl5g00e5f188dh7x57az" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/07/cs.AI_2023_11_07/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-11-07
        
      </div>
    </a>
  
  
    <a href="/2023/11/07/cs.LG_2023_11_07/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-11-07</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
