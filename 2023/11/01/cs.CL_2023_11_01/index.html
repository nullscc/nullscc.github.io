
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-11-01 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.00697 repo_url: https:&#x2F;&#x2F;github.com&#x2F;amazon-science&#x2F;stac-speech-translation paper_auth">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-11-01">
<meta property="og:url" content="https://nullscc.github.io/2023/11/01/cs.CL_2023_11_01/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.00697 repo_url: https:&#x2F;&#x2F;github.com&#x2F;amazon-science&#x2F;stac-speech-translation paper_auth">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-01T11:00:00.000Z">
<meta property="article:modified_time" content="2023-11-02T12:53:34.191Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.CL_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T11:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-11-01
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="End-to-End-Single-Channel-Speaker-Turn-Aware-Conversational-Speech-Translation"><a href="#End-to-End-Single-Channel-Speaker-Turn-Aware-Conversational-Speech-Translation" class="headerlink" title="End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation"></a>End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00697">http://arxiv.org/abs/2311.00697</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amazon-science/stac-speech-translation">https://github.com/amazon-science/stac-speech-translation</a></li>
<li>paper_authors: Juan Zuluaga-Gomez, Zhaocheng Huang, Xing Niu, Rohit Paturi, Sundararajan Srinivasan, Prashant Mathur, Brian Thompson, Marcello Federico</li>
<li>for: 这 paper 是为了解决单 Channel 多说话人 conversational speech-to-text 系统的问题。</li>
<li>methods: 这 paper 使用了一种 serialized labeling format 的 end-to-end 和 multi-task 训练模型，名为 Speaker-Turn Aware Conversational Speech Translation，它结合了自动语音识别、语音翻译和说话人turn detection。</li>
<li>results:  experiments 表明，在 Fisher-CALLHOME 数据集上，我们的模型在多说话人 Condition 下表现出了优于参照系统，而在单说话人 Condition 下表现与参照系统相当。<details>
<summary>Abstract</summary>
Conventional speech-to-text translation (ST) systems are trained on single-speaker utterances, and they may not generalize to real-life scenarios where the audio contains conversations by multiple speakers. In this paper, we tackle single-channel multi-speaker conversational ST with an end-to-end and multi-task training model, named Speaker-Turn Aware Conversational Speech Translation, that combines automatic speech recognition, speech translation and speaker turn detection using special tokens in a serialized labeling format. We run experiments on the Fisher-CALLHOME corpus, which we adapted by merging the two single-speaker channels into one multi-speaker channel, thus representing the more realistic and challenging scenario with multi-speaker turns and cross-talk. Experimental results across single- and multi-speaker conditions and against conventional ST systems, show that our model outperforms the reference systems on the multi-speaker condition, while attaining comparable performance on the single-speaker condition. We release scripts for data processing and model training.
</details>
<details>
<summary>摘要</summary>
传统的语音到文本翻译（ST）系统通常在单个说话人的单个话语中训练，这些系统可能无法泛化到真实生活中的多人对话场景。在这篇论文中，我们解决了单通道多说话人对话的语音到文本翻译问题，使用一个端到端和多任务训练模型，名为Speaker-Turn Aware Conversational Speech Translation。该模型结合了自动语音识别、语音翻译和说话人转换检测，使用特殊的标记Format进行串行化。我们在Fisher-CALLHOME corpus上进行实验，将两个单个说话人通道合并到一个多个说话人通道上，从而更加真实和挑战性地表现出多个说话人的转换和交叉对话。实验结果表明，我们的模型在多个说话人条件下比参照系统高效，而在单个说话人条件下也能够达到相似的性能。我们释放了数据处理和模型训练脚本。
</details></li>
</ul>
<hr>
<h2 id="Little-Giants-Exploring-the-Potential-of-Small-LLMs-as-Evaluation-Metrics-in-Summarization-in-the-Eval4NLP-2023-Shared-Task"><a href="#Little-Giants-Exploring-the-Potential-of-Small-LLMs-as-Evaluation-Metrics-in-Summarization-in-the-Eval4NLP-2023-Shared-Task" class="headerlink" title="Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task"></a>Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00686">http://arxiv.org/abs/2311.00686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neema Kotonya, Saran Krishnasamy, Joel Tetreault, Alejandro Jaimes</li>
<li>for: 本研究参与2023年Eval4NLP共享任务，旨在评估基于提示技术的大语言模型对质量评估机器翻译和摘要的效果。</li>
<li>methods: 我们采用了不同的提示技术，包括标准提示、根据评分员指导的提示和创新的链式思维提示。此外，我们还将这些方法与零shot和一shot学习方法结合使用，以最大化评估过程的效果。</li>
<li>results: 我们的研究发现，通过结合这些方法使用一个”小”的开源模型（orca_mini_v3_7B）可以获得竞争性的结果。<details>
<summary>Abstract</summary>
This paper describes and analyzes our participation in the 2023 Eval4NLP shared task, which focuses on assessing the effectiveness of prompt-based techniques to empower Large Language Models to handle the task of quality estimation, particularly in the context of evaluating machine translations and summaries. We conducted systematic experiments with various prompting techniques, including standard prompting, prompts informed by annotator instructions, and innovative chain-of-thought prompting. In addition, we integrated these approaches with zero-shot and one-shot learning methods to maximize the efficacy of our evaluation procedures. Our work reveals that combining these approaches using a "small", open source model (orca_mini_v3_7B) yields competitive results.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Attention-Alignment-and-Flexible-Positional-Embeddings-Improve-Transformer-Length-Extrapolation"><a href="#Attention-Alignment-and-Flexible-Positional-Embeddings-Improve-Transformer-Length-Extrapolation" class="headerlink" title="Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation"></a>Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00684">http://arxiv.org/abs/2311.00684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ta-Chung Chi, Ting-Han Fan, Alexander I. Rudnicky</li>
<li>for: 这个论文目的是探讨一种可以处理长于训练长度的Transformer语言模型，以提高其长Context处理能力。</li>
<li>methods: 论文使用了T5家族的大型预训练语言模型，并对其 позицион嵌入进行了调整，以提高它对长输入序列的处理能力。</li>
<li>results: 研究发现，通过调整T5的 pozitional embedding 和 temperature scaling 可以提高模型对长输入序列的处理能力，无需进行任何细化。这些发现可以提高Transformer语言模型在语言模型、检索和多文档问答等任务中的长Context处理能力。<details>
<summary>Abstract</summary>
An ideal length-extrapolatable Transformer language model can handle sequences longer than the training length without any long sequence fine-tuning. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.\footnote{\url{https://github.com/chijames/Attention-Alignment-Transformer-Length-Extrapolation}
</details>
<details>
<summary>摘要</summary>
一个理想的长度扩展可以处理的Transformer语言模型应该能够处理 longer than the training length without any fine-tuning of long sequences. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.Here's the word-for-word translation:一个理想的长度扩展可以处理的Transformer语言模型应该能够处理 longer than the training length without any fine-tuning of long sequences. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.
</details></li>
</ul>
<hr>
<h2 id="Are-Large-Language-Models-Reliable-Judges-A-Study-on-the-Factuality-Evaluation-Capabilities-of-LLMs"><a href="#Are-Large-Language-Models-Reliable-Judges-A-Study-on-the-Factuality-Evaluation-Capabilities-of-LLMs" class="headerlink" title="Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs"></a>Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00681">http://arxiv.org/abs/2311.00681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xue-Yong Fu, Md Tahmid Rahman Laskar, Cheng Chen, Shashi Bhushan TN</li>
<li>for: 本研究探讨了大型语言模型（LLM）是否可靠地评估生成模型生成的摘要中的事实准确性。</li>
<li>methods: 本研究提出了一种新的方法，使用单个LLM进行整个问答型事实评分过程。然后，研究者对不同的LLM进行了直接事实评分，并与传统测量和人工评分进行比较。</li>
<li>results: 研究结果表明，与人类评分的相关性较低，特别是对GPT-4和PaLM-2。只有GPT-3.5在两个事实分类中显示了 Notable的相关性。这些结果表明现有LLMs可能无法准确评估事实准确性。<details>
<summary>Abstract</summary>
In recent years, Large Language Models (LLMs) have gained immense attention due to their notable emergent capabilities, surpassing those seen in earlier language models. A particularly intriguing application of LLMs is their role as evaluators for texts produced by various generative models.   In this study, we delve into the potential of LLMs as reliable assessors of factual consistency in summaries generated by text-generation models. Initially, we introduce an innovative approach for factuality assessment using LLMs. This entails employing a singular LLM for the entirety of the question-answering-based factuality scoring process. Following this, we examine the efficacy of various LLMs in direct factuality scoring, benchmarking them against traditional measures and human annotations.   Contrary to initial expectations, our results indicate a lack of significant correlations between factuality metrics and human evaluations, specifically for GPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 across two factuality subcategories. These consistent findings across various factual error categories suggest a fundamental limitation in the current LLMs' capability to accurately gauge factuality.   This version presents the information more concisely while maintaining the main points and findings of the original text.
</details>
<details>
<summary>摘要</summary>
We propose an innovative approach for factuality assessment using a single LLM throughout the question-answering-based scoring process. We then compare the efficacy of various LLMs in direct factuality scoring, benchmarking them against traditional measures and human annotations.Surprisingly, our results show a lack of significant correlations between factuality metrics and human evaluations for GPT-4 and PaLM-2, with only GPT-3.5 displaying notable correlations across two factual error categories. These findings suggest a fundamental limitation in current LLMs' ability to accurately assess factuality.This concise version maintains the main points and findings of the original text, highlighting the potential of LLMs as assessors of factual consistency and the limitations of current LLMs in accurately gauging factuality.
</details></li>
</ul>
<hr>
<h2 id="Emotion-Detection-for-Misinformation-A-Review"><a href="#Emotion-Detection-for-Misinformation-A-Review" class="headerlink" title="Emotion Detection for Misinformation: A Review"></a>Emotion Detection for Misinformation: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00671">http://arxiv.org/abs/2311.00671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Liu, Tianlin Zhang, Kailai Yang, Paul Thompson, Zeping Yu, Sophia Ananiadou</li>
<li>for: 本研究的目的是寻找基于情感的谣言检测方法，以便在社交媒体上减少谣言的散布。</li>
<li>methods: 该研究使用了多种情感、 sentiment和立场基本特征，包括语言模型、 sentiment分析和机器学习算法，以检测谣言。</li>
<li>results: 研究发现，基于情感的方法可以减少谣言的散布，但还存在一些挑战，如大语言模型、多平台多语言、注释、多模式和解释性。<details>
<summary>Abstract</summary>
With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people's lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.
</details>
<details>
<summary>摘要</summary>
We begin by explaining the strong connections between emotions and misinformation. We then provide a detailed analysis of a range of misinformation detection methods that use a variety of emotion, sentiment, and stance-based features, and describe their strengths and weaknesses. Finally, we discuss several ongoing challenges in emotion-based misinformation detection using large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.
</details></li>
</ul>
<hr>
<h2 id="Explicit-Morphological-Knowledge-Improves-Pre-training-of-Language-Models-for-Hebrew"><a href="#Explicit-Morphological-Knowledge-Improves-Pre-training-of-Language-Models-for-Hebrew" class="headerlink" title="Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew"></a>Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00658">http://arxiv.org/abs/2311.00658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eylon Gueta, Omer Goldman, Reut Tsarfaty</li>
<li>for: 本研究目的是检验Language-agnostic pre-trained language models (PLMs)是否能够有效地处理 morphologically-rich languages (MRLs)。</li>
<li>methods: 研究人员提出了多种基于 morphological knowledge的tokenization方法，以便让模型利用 morphological cues beyond raw text。</li>
<li>results: 实验结果表明，基于 morphological knowledge的tokenization方法在 Hebrew 语言中表现出了改善的 результаTS， compared to standard language-agnostic tokenization。这些结果表明， incorporating morphological knowledge holds the potential for further improving PLMs for MRLs。<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have shown remarkable successes in acquiring a wide range of linguistic knowledge, relying solely on self-supervised training on text streams. Nevertheless, the effectiveness of this language-agnostic approach has been frequently questioned for its sub-optimal performance when applied to morphologically-rich languages (MRLs). We investigate the hypothesis that incorporating explicit morphological knowledge in the pre-training phase can improve the performance of PLMs for MRLs. We propose various morphologically driven tokenization methods enabling the model to leverage morphological cues beyond raw text. We pre-train multiple language models utilizing the different methods and evaluate them on Hebrew, a language with complex and highly ambiguous morphology. Our experiments show that morphologically driven tokenization demonstrates improved results compared to a standard language-agnostic tokenization, on a benchmark of both semantic and morphologic tasks. These findings suggest that incorporating morphological knowledge holds the potential for further improving PLMs for morphologically rich languages.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Formal-Translation-from-Reversing-Petri-Nets-to-Coloured-Petri-Nets"><a href="#Formal-Translation-from-Reversing-Petri-Nets-to-Coloured-Petri-Nets" class="headerlink" title="Formal Translation from Reversing Petri Nets to Coloured Petri Nets"></a>Formal Translation from Reversing Petri Nets to Coloured Petri Nets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00629">http://arxiv.org/abs/2311.00629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamila Barylska, Anna Gogolinska, Lukasz Mikulski, Anna Philippou, Marcin Piatkowski, Kyriaki Psara</li>
<li>for: 这个论文旨在探讨逆计算 paradigm 的应用，具体来说是通过在计算过程中逆转操作顺序来实现低功耗计算和各种应用领域的相关性。</li>
<li>methods: 这篇论文使用了 extend Petri nets 来实现逆计算，其中使用了名称的 tokens 可以组合在一起形成键。这些 tokens  along with a history function ，使得可以记忆过去的行为，并且允许逆转。</li>
<li>results: 这篇论文报告了一种从 RPNs 到 CPNs 的结构翻译方法，该方法可以处理 RPNs 中Token的多态性。此外， paper 还报告了一种工具，可以自动将 RPNs 翻译成 CPNs，并且可以进行逆计算和分析。<details>
<summary>Abstract</summary>
Reversible computation is an emerging computing paradigm that allows any sequence of operations to be executed in reverse order at any point during computation. Its appeal lies in its potential for lowpower computation and its relevance to a wide array of applications such as chemical reactions, quantum computation, robotics, and distributed systems. Reversing Petri nets are a recently-proposed extension of Petri nets that implements the three main forms of reversibility, namely, backtracking, causal reversing, and out-of-causal-order reversing. Their distinguishing feature is the use of named tokens that can be combined together to form bonds. Named tokens along with a history function, constitute the means of remembering past behaviour, thus, enabling reversal. In recent work, we have proposed a structural translation from a subclass of RPNs to the model of Coloured Petri Nets (CPNs), an extension of traditional Petri nets where tokens carry data values. In this paper, we extend the translation to handle RPNs with token multiplicity under the individual-token interpretation, a model which allows multiple tokens of the same type to exist in a system. To support the three types of reversibility, tokens are associated with their causal history and, while tokens of the same type are equally eligible to fire a transition when going forward, when going backwards they are able to reverse only the transitions they have previously fired. The new translation, in addition to lifting the restriction on token uniqueness, presents a refined approach for transforming RPNs to CPNs through a unifying approach that allows instantiating each of the three types of reversibility. The paper also reports on a tool that implements this translation, paving the way for automated translations and analysis of reversible systems using CPN Tools.
</details>
<details>
<summary>摘要</summary>
<<SYS>>描述文本为 Traditional Chinese.<</SYS>>可逆计算是一种emerging计算模式，允许任何操作序列在计算过程中执行逆序。它的吸引点在于其可能性低功耗计算和广泛应用领域，如化学反应、量子计算、机器人和分布式系统。在这些应用领域中，可逆计算可以提供更高效的方法来解决问题。可逆 Petri nets 是一种最近提出的扩展，它实现了计算机科学中三种主要的可逆性形式，namely，backtracking，causal reversing和out-of-causal-order reversing。它们的特点在于使用名称的 токен，可以组合在一起形成缔造。名称的tokен，一起与历史函数，使得可以记忆过去的行为，因此可以进行逆转。在我们的最近工作中，我们提出了一种结构性的翻译方法，将一个子集的 RPNs 翻译为 Coloured Petri Nets (CPNs) 模型，这是传统 Petri nets 的扩展，tokentoken carry data values。在这篇论文中，我们将这种翻译扩展到处理 RPNs 的token多样性，使得每个tokentype可以在系统中存在多个实例。为支持三种可逆性，tokentoken被与其 causal history 相关联，当前进时，tokentype的所有实例都可以触发过渡，但是在逆转时，只有以前触发过渡的tokentype实例才能逆转。这种新的翻译方法，不仅废除了tokentype唯一性的限制，还提供了一种统一的approach来转换 RPNs 到 CPNs，并且可以实现每种类型的可逆性。论文还报告了一种实现这种翻译的工具，为可逆系统的自动翻译和分析提供了道路。
</details></li>
</ul>
<hr>
<h2 id="Crosslingual-Retrieval-Augmented-In-context-Learning-for-Bangla"><a href="#Crosslingual-Retrieval-Augmented-In-context-Learning-for-Bangla" class="headerlink" title="Crosslingual Retrieval Augmented In-context Learning for Bangla"></a>Crosslingual Retrieval Augmented In-context Learning for Bangla</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00587">http://arxiv.org/abs/2311.00587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoqian Li, Ercong Nie, Sheng Liang</li>
<li>for: 提高 Bangla 语言处理 tasks 的表现</li>
<li>methods: 使用 cross-lingual retrieval augmented in-context learning</li>
<li>results: 实现了提高 MPLMs 在 Bangla 任务上的表现，并且 steady improvements over zero-shot performance。Here’s the full text in Simplified Chinese:</li>
<li>for: 提高 Bangla 语言处理任务的表现</li>
<li>methods: 使用 cross-lingual retrieval augmented in-context learning</li>
<li>results: 实现了提高 MPLMs 在 Bangla 任务上的表现，并且 steady improvements over zero-shot performance。<details>
<summary>Abstract</summary>
The promise of Large Language Models (LLMs) in Natural Language Processing has often been overshadowed by their limited performance in low-resource languages such as Bangla. To address this, our paper presents a pioneering approach that utilizes cross-lingual retrieval augmented in-context learning. By strategically sourcing semantically similar prompts from high-resource language, we enable multilingual pretrained language models (MPLMs), especially the generative model BLOOMZ, to successfully boost performance on Bangla tasks. Our extensive evaluation highlights that the cross-lingual retrieval augmented prompts bring steady improvements to MPLMs over the zero-shot performance.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理中的大语言模型（LLMs）的承诺经常被低资源语言 such as Bangla 语言表现所压制。为了解决这个问题，我们的论文提出了一种创新的方法，利用跨语言检索增强在场景学习。我们策略性地从高资源语言中抽取semantically similar的提示，以帮助多语言预训练语言模型（MPLMs），特别是生成模型BLOOMZ，在 Bangla 任务上成功提高表现。我们进行了广泛的评估，发现跨语言检索增强提示可以稳定地提高 MPLMs 的零 shot 性能。
</details></li>
</ul>
<hr>
<h2 id="An-Embedded-Diachronic-Sense-Change-Model-with-a-Case-Study-from-Ancient-Greek"><a href="#An-Embedded-Diachronic-Sense-Change-Model-with-a-Case-Study-from-Ancient-Greek" class="headerlink" title="An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek"></a>An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00541">http://arxiv.org/abs/2311.00541</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/schyanzafar/edisc">https://github.com/schyanzafar/edisc</a></li>
<li>paper_authors: Schyan Zafar, Geoff K. Nicholls</li>
<li>for: 本研究旨在分析古希腊文本资料库中的词汇变化。</li>
<li>methods: 研究使用了无监督学习的GASC和DiSC生成模型，用MCMC方法来衡量词汇变化。</li>
<li>results: 研究发现，使用EDiSC模型可以提高预测准确率、真实恢复率和不确定度评估，同时具有更好的采样效率和可扩展性。<details>
<summary>Abstract</summary>
Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.
</details>
<details>
<summary>摘要</summary>
Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.Here's the translation in Traditional Chinese:Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.
</details></li>
</ul>
<hr>
<h2 id="Text-Rendering-Strategies-for-Pixel-Language-Models"><a href="#Text-Rendering-Strategies-for-Pixel-Language-Models" class="headerlink" title="Text Rendering Strategies for Pixel Language Models"></a>Text Rendering Strategies for Pixel Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00522">http://arxiv.org/abs/2311.00522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas F. Lotz, Elizabeth Salesky, Phillip Rust, Desmond Elliott</li>
<li>for: 这篇论文是关于Pixel模型的语言模型处理文本的研究，旨在提高语言模型的可扩展性和性能。</li>
<li>methods: 论文使用四种不同的文本渲染方法来进行研究，其中一种是简单的字符大rams渲染方法，这种方法可以提高句子级任务的性能而无需妥协Multilingual任务或Token级任务的性能。</li>
<li>results: 研究发现，使用简单的字符大rams渲染方法可以提高模型的性能，但是这种方法会导致模型的patch embedding空间具有不均匀分布，这与图像patch和语言模型之间的连接有关。<details>
<summary>Abstract</summary>
Pixel-based language models process text rendered as images, which allows them to handle any script, making them a promising approach to open vocabulary language modelling. However, recent approaches use text renderers that produce a large set of almost-equivalent input patches, which may prove sub-optimal for downstream tasks, due to redundancy in the input representations. In this paper, we investigate four approaches to rendering text in the PIXEL model (Rust et al., 2023), and find that simple character bigram rendering brings improved performance on sentence-level tasks without compromising performance on token-level or multilingual tasks. This new rendering strategy also makes it possible to train a more compact model with only 22M parameters that performs on par with the original 86M parameter model. Our analyses show that character bigram rendering leads to a consistently better model but with an anisotropic patch embedding space, driven by a patch frequency bias, highlighting the connections between image patch- and tokenization-based language models.
</details>
<details>
<summary>摘要</summary>
Pixel基于语言模型处理文本作为图像，可以处理任何文本，这使得它们成为开 vocabulary 语言模型的有力的方法。然而，现有的方法使用生成大量几乎相同的输入 patches 的文本渲染器，这可能会对下游任务造成冗余在输入表示中，从而降低性能。在这篇论文中，我们研究了 PIXEL 模型（Rust et al., 2023）中四种渲染文本的方法，并发现，使用简单的字符bigram渲染可以提高句子级任务的性能，而不会对Token级或多语言任务产生负面影响。这新的渲染策略还使得可以训练一个更加 компакт的模型，只有 22M 参数，与原始 86M 参数模型在同等水平上表现。我们的分析显示，字符bigram渲染导致一个一致性更好的模型，但是 embedding 空间具有不均匀的分布，受到 patch 频率偏好的影响，这 highlights 图像 patch 和 tokenization 基于的语言模型之间的连接。
</details></li>
</ul>
<hr>
<h2 id="Rule-Based-Error-Classification-for-Analyzing-Differences-in-Frequent-Errors"><a href="#Rule-Based-Error-Classification-for-Analyzing-Differences-in-Frequent-Errors" class="headerlink" title="Rule-Based Error Classification for Analyzing Differences in Frequent Errors"></a>Rule-Based Error Classification for Analyzing Differences in Frequent Errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00513">http://arxiv.org/abs/2311.00513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Taku Matsumoto, Md Faizul Ibne Amin, Yutaka Watanobe</li>
<li>for: 本研究旨在揭示初学者和高级程序员之间错误的差异，并提供有用的建议 для每个学习水平。</li>
<li>methods: 我们提出了一种基于规则的错误分类工具，用于对代码对的错误进行分类。我们分析了95631个代码对，平均错误数为3.47，并用于分析初学者和高级程序员之间错误的差异。</li>
<li>results: 分析结果表明，初学者的错误主要是由于programming知识的缺乏，而高级程序员的错误主要是由于解决问题的不同方式或读取问题的精疲。这种工具可以用于创建错误标注的数据集，并用于进一步的代码相关教育研究。<details>
<summary>Abstract</summary>
Finding and fixing errors is a time-consuming task not only for novice programmers but also for expert programmers. Prior work has identified frequent error patterns among various levels of programmers. However, the differences in the tendencies between novices and experts have yet to be revealed. From the knowledge of the frequent errors in each level of programmers, instructors will be able to provide helpful advice for each level of learners. In this paper, we propose a rule-based error classification tool to classify errors in code pairs consisting of wrong and correct programs. We classify errors for 95,631 code pairs and identify 3.47 errors on average, which are submitted by various levels of programmers on an online judge system. The classified errors are used to analyze the differences in frequent errors between novice and expert programmers. The analyzed results show that, as for the same introductory problems, errors made by novices are due to the lack of knowledge in programming, and the mistakes are considered an essential part of the learning process. On the other hand, errors made by experts are due to misunderstandings caused by the carelessness of reading problems or the challenges of solving problems differently than usual. The proposed tool can be used to create error-labeled datasets and for further code-related educational research.
</details>
<details>
<summary>摘要</summary>
查找和修复错误是一项时间耗费的任务，不仅对于初学者而且对于专家程序员也是如此。先前的工作已经确定了不同程度的程序员中的错误模式。然而，初学者和专家之间的差异仍未得到揭示。通过了解每个程度的错误频率，教师将能够提供有用的建议 для每个学习者。在这篇论文中，我们提出了一种基于规则的错误分类工具，用于分类代码对的正确和错误程序。我们对95631个代码对进行分类，并发现每个代码对平均含3.47个错误。这些错误是由不同程度的程序员在在线评审系统上提交的。我们分析了错误的差异，发现初学者的错误主要是因为编程知识不足，而且这些错误是学习过程中的一部分。相比之下，专家的错误主要是由于阅读问题不够仔细或解决问题不同于惯常的方式而导致的。我们提出的工具可以用于创建错误标注的数据集，以及进一步的编程教育研究。
</details></li>
</ul>
<hr>
<h2 id="Robustness-Tests-for-Automatic-Machine-Translation-Metrics-with-Adversarial-Attacks"><a href="#Robustness-Tests-for-Automatic-Machine-Translation-Metrics-with-Adversarial-Attacks" class="headerlink" title="Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks"></a>Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00508">http://arxiv.org/abs/2311.00508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i-need-sleep/eval_attack">https://github.com/i-need-sleep/eval_attack</a></li>
<li>paper_authors: Yichen Huang, Timothy Baldwin</li>
<li>for: 研究MT评估指标在针对性synthesized文本中的性能，以探讨评估指标的Robustness。</li>
<li>methods: 使用word-和character-level攻击对三种流行的机器翻译指标进行实验：BERTScore、BLEURT和COMET。</li>
<li>results: 人工实验 validate that自动指标倾斜地对针对性下降的翻译进行评估，并发现BERTScore指标存在不一致的问题，它将原始句子和针对性下降的句子评估为相似，而对参考的评估则评估为不同。<details>
<summary>Abstract</summary>
We investigate MT evaluation metric performance on adversarially-synthesized texts, to shed light on metric robustness. We experiment with word- and character-level attacks on three popular machine translation metrics: BERTScore, BLEURT, and COMET. Our human experiments validate that automatic metrics tend to overpenalize adversarially-degraded translations. We also identify inconsistencies in BERTScore ratings, where it judges the original sentence and the adversarially-degraded one as similar, while judging the degraded translation as notably worse than the original with respect to the reference. We identify patterns of brittleness that motivate more robust metric development.
</details>
<details>
<summary>摘要</summary>
我们研究了一些 Popular machine translation  metric 在 adversarially-synthesized 文本上的表现，以了解 metric 的 Robustness。我们对 Word-level 和 Character-level 攻击进行了实验，测试了三种 популяр的 machine translation  metric：BERTScore、BLEURT 和 COMET。我们的人工实验表明，自动 metric 往往会对 adversarially-degraded 翻译过程进行过分 penalty。我们还发现了 BERTScore 的不一致性，它将原始句子和 adversarially-degraded 句子视为类似，而对参考译文进行评分时则评价了 adversarially-degraded 翻译为不同。我们发现了一些 brittleness 的模式，这些模式激励我们更加Robust metric 的发展。
</details></li>
</ul>
<hr>
<h2 id="Comparing-Optimization-Targets-for-Contrast-Consistent-Search"><a href="#Comparing-Optimization-Targets-for-Contrast-Consistent-Search" class="headerlink" title="Comparing Optimization Targets for Contrast-Consistent Search"></a>Comparing Optimization Targets for Contrast-Consistent Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00488">http://arxiv.org/abs/2311.00488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hugo Fry, Seamus Fallows, Ian Fan, Jamie Wright, Nandi Schoots</li>
<li>for: 优化对比逻辑搜索（CCS）的内部表示真理的回归。</li>
<li>methods: 提出了一种新的损失函数——中点差分（MD）损失函数。</li>
<li>results: 在特定的超参数值下，MD损失函数导致了一个与CCS几乎相同的搜索器。此外，我们还证明了这个超参数不是最佳的，可以通过更好的超参数来使MD损失函数在测试精度上超过CCS。<details>
<summary>Abstract</summary>
We investigate the optimization target of Contrast-Consistent Search (CCS), which aims to recover the internal representations of truth of a large language model. We present a new loss function that we call the Midpoint-Displacement (MD) loss function. We demonstrate that for a certain hyper-parameter value this MD loss function leads to a prober with very similar weights to CCS. We further show that this hyper-parameter is not optimal and that with a better hyper-parameter the MD loss function attains a higher test accuracy than CCS.
</details>
<details>
<summary>摘要</summary>
我团队 investigate Contrast-Consistent Search（CCS）的优化目标，它的目标是恢复大语言模型中真实的内部表示。我们提出了一种新的损失函数，称为中点偏移（MD）损失函数。我们示出，对于某个特定的超参数值，MD损失函数会导致 probers 的重量与 CCS 非常相似。此外，我们还证明了这个超参数并不是最佳的，并且通过更好的超参数，MD 损失函数在测试准确率方面超过 CCS。
</details></li>
</ul>
<hr>
<h2 id="Style-Locality-for-Controllable-Generation-with-kNN-Language-Models"><a href="#Style-Locality-for-Controllable-Generation-with-kNN-Language-Models" class="headerlink" title="Style Locality for Controllable Generation with kNN Language Models"></a>Style Locality for Controllable Generation with kNN Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00475">http://arxiv.org/abs/2311.00475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gilles Nawezi, Lucie Flek, Charles Welch</li>
<li>for: 本研究旨在控制文本风格，提高模型的流畅性和风格质量。</li>
<li>methods: 本研究使用 nearest neighbor 语言模型，并添加了地方层来学习Weight邻居的相对位置。</li>
<li>results: 我们的模型可以控制文本风格，并提供了更好的流畅性-风格质量的贸易。<details>
<summary>Abstract</summary>
Recent language models have been improved by the addition of external memory. Nearest neighbor language models retrieve similar contexts to assist in word prediction. The addition of locality levels allows a model to learn how to weight neighbors based on their relative location to the current text in source documents, and have been shown to further improve model performance. Nearest neighbor models have been explored for controllable generation but have not examined the use of locality levels. We present a novel approach for this purpose and evaluate it using automatic and human evaluation on politeness, formality, supportiveness, and toxicity textual data. We find that our model is successfully able to control style and provides a better fluency-style trade-off than previous work.
</details>
<details>
<summary>摘要</summary>
最近的语言模型已经得到了外部记忆的改进。 nearest neighbor语言模型可以在文本中找到类似的上下文，以帮助预测单词。通过本地层次可以让模型学习将邻居按照其相对于当前文本的位置在源文档中进行权重，这有助于进一步提高模型性能。 nearest neighbor模型在可控生成中被研究，但尚未检查了本地层次的使用。我们提出了一种新的方法，并通过自动和人工评估在礼貌、正式、支持性和攻击性文本数据中评估其性能。我们发现我们的模型能够成功地控制风格，并提供了更好的流畅度-风格质量的负担。
</details></li>
</ul>
<hr>
<h2 id="Discourse-Relations-Classification-and-Cross-Framework-Discourse-Relation-Classification-Through-the-Lens-of-Cognitive-Dimensions-An-Empirical-Investigation"><a href="#Discourse-Relations-Classification-and-Cross-Framework-Discourse-Relation-Classification-Through-the-Lens-of-Cognitive-Dimensions-An-Empirical-Investigation" class="headerlink" title="Discourse Relations Classification and Cross-Framework Discourse Relation Classification Through the Lens of Cognitive Dimensions: An Empirical Investigation"></a>Discourse Relations Classification and Cross-Framework Discourse Relation Classification Through the Lens of Cognitive Dimensions: An Empirical Investigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00451">http://arxiv.org/abs/2311.00451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingxue Fu</li>
<li>for: 这篇论文的目的是提出一种基于 Sanders et al. (2018) 的简单 когнитив发现的维度，用于捕捉不同框架中的 DISCOURSE RELATIONS。</li>
<li>methods: 该论文使用了跨框架 DISCOURSE RELATIONS 分类实验，通过 transferred knowledge 将一个框架中的 DISCOURSE RELATIONS 转移到另一个框架中。</li>
<li>results: 实验结果表明，使用这些维度可以有效地捕捉不同框架中的 DISCOURSE RELATIONS，并且不同的维度对不同类型的 DISCOURSE RELATIONS 有不同的影响。<details>
<summary>Abstract</summary>
Existing discourse formalisms use different taxonomies of discourse relations, which require expert knowledge to understand, posing a challenge for annotation and automatic classification. We show that discourse relations can be effectively captured by some simple cognitively inspired dimensions proposed by Sanders et al.(2018). Our experiments on cross-framework discourse relation classification (PDTB & RST) demonstrate that it is possible to transfer knowledge of discourse relations for one framework to another framework by means of these dimensions, in spite of differences in discourse segmentation of the two frameworks. This manifests the effectiveness of these dimensions in characterizing discourse relations across frameworks. Ablation studies reveal that different dimensions influence different types of discourse relations. The patterns can be explained by the role of dimensions in characterizing and distinguishing different relations. We also report our experimental results on automatic prediction of these dimensions.
</details>
<details>
<summary>摘要</summary>
现有的讨论形式学派使用不同的讨论关系分类法，需要专家知识来理解， pose 一个标注和自动分类的挑战。我们显示，讨论关系可以通过 Sanders 等人（2018）提出的一些简单的认知启发的维度来有效地捕捉。我们在 PDTB 和 RST 两个框架之间的跨框架讨论关系分类实验中表明，可以通过这些维度来传递一个框架中的讨论关系知识到另一个框架，尽管这两个框架在讨论分割上存在差异。这种现象表明了这些维度在不同框架之间的讨论关系的捕捉效果。我们还进行了不同维度的缺省研究，发现不同的维度对不同类型的讨论关系有不同的影响。这些模式可以通过维度在不同类型的讨论关系中的角色来解释。我们还报告了自动预测这些维度的实验结果。
</details></li>
</ul>
<hr>
<h2 id="Distil-Whisper-Robust-Knowledge-Distillation-via-Large-Scale-Pseudo-Labelling"><a href="#Distil-Whisper-Robust-Knowledge-Distillation-via-Large-Scale-Pseudo-Labelling" class="headerlink" title="Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling"></a>Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00430">http://arxiv.org/abs/2311.00430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchit Gandhi, Patrick von Platen, Alexander M. Rush</li>
<li>for: 这篇论文的目的是要开发一个可以在低延迟和资源受限的环境中运行的小型语音识别模型，并且可以与大型预训练模型相比。</li>
<li>methods: 这篇论文使用pseudo-labeling技术来构建一个大规模的开源数据集，然后使用这个数据集来将Whisper模型精简为一个小型模型，称为Distil-Whisper。这个精简模型比原始模型更快速，并且在零执行状况下可以保持与原始模型相同的表现。</li>
<li>results: 根据论文的结果，Distil-Whisper模型比原始模型更快速，并且在零执行状况下可以保持与原始模型相同的表现。此外，Distil-Whisper模型还可以与Whisper模型配合进行推测运算，实现2倍的速度提升。<details>
<summary>Abstract</summary>
As the size of pre-trained speech recognition models increases, running these large models in low-latency or resource-constrained environments becomes challenging. In this work, we leverage pseudo-labelling to assemble a large-scale open-source dataset which we use to distill the Whisper model into a smaller variant, called Distil-Whisper. Using a simple word error rate (WER) heuristic, we select only the highest quality pseudo-labels for training. The distilled model is 5.8 times faster with 51% fewer parameters, while performing to within 1% WER on out-of-distribution test data in a zero-shot transfer setting. Distil-Whisper maintains the robustness of the Whisper model to difficult acoustic conditions, while being less prone to hallucination errors on long-form audio. Distil-Whisper is designed to be paired with Whisper for speculative decoding, yielding a 2 times speed-up while mathematically ensuring the same outputs as the original model. To facilitate further research in this domain, we make our training code, inference code and models publicly accessible.
</details>
<details>
<summary>摘要</summary>
随着预训练语音识别模型的大小增加，运行这些大模型在低延迟或资源受限的环境中变得困难。在这项工作中，我们利用假标签来组织大规模的开源数据集，并使用简单的单词错误率（WER）归一化来选择最高质量的假标签进行训练。经过筛选后，我们提取了一个尺寸更小的变体，称为Distil-Whisper，它比原始模型快5.8倍，参数数量减少51%，并在零推导 Setting下测试数据上保持1% WER的水平。Distil-Whisper保持了Whisper模型对听频条件的鲁棒性，而且对长声道数据库的投射错误减少。Distil-Whisper是与Whisper模型推测的快速版本，可以在不改变输出的前提下提高速度2倍。为便于进一步的研究，我们将训练代码、推测代码和模型公开 accessible。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Human-AI-Coordination-via-Preparatory-Language-based-Convention"><a href="#Efficient-Human-AI-Coordination-via-Preparatory-Language-based-Convention" class="headerlink" title="Efficient Human-AI Coordination via Preparatory Language-based Convention"></a>Efficient Human-AI Coordination via Preparatory Language-based Convention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00416">http://arxiv.org/abs/2311.00416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Guan, Lichao Zhang, Chunpeng Fan, Yichen Li, Feng Chen, Lihe Li, Yunjia Tian, Lei Yuan, Yang Yu</li>
<li>For: The paper aims to develop a method for human-AI coordination that can effectively guide both human and AI agents in achieving their goals.* Methods: The proposed method employs a large language model (LLM) to generate a convention that specifies individual roles and actions, facilitating orderly coordination between humans and AI. The convention is generated based on task requirements, human preferences, and other pertinent information.* Results: The proposed method outperforms existing learning-based approaches in the Overcooked-AI environment and achieves better alignment with human preferences when coordinating with real humans. The average performance improvement is 15% compared to the state-of-the-art.<details>
<summary>Abstract</summary>
Developing intelligent agents capable of seamless coordination with humans is a critical step towards achieving artificial general intelligence. Existing methods for human-AI coordination typically train an agent to coordinate with a diverse set of policies or with human models fitted from real human data. However, the massively diverse styles of human behavior present obstacles for AI systems with constrained capacity, while high quality human data may not be readily available in real-world scenarios. In this study, we observe that prior to coordination, humans engage in communication to establish conventions that specify individual roles and actions, making their coordination proceed in an orderly manner. Building upon this observation, we propose employing the large language model (LLM) to develop an action plan (or equivalently, a convention) that effectively guides both human and AI. By inputting task requirements, human preferences, the number of agents, and other pertinent information into the LLM, it can generate a comprehensive convention that facilitates a clear understanding of tasks and responsibilities for all parties involved. Furthermore, we demonstrate that decomposing the convention formulation problem into sub-problems with multiple new sessions being sequentially employed and human feedback, will yield a more efficient coordination convention. Experimental evaluations conducted in the Overcooked-AI environment, utilizing a human proxy model, highlight the superior performance of our proposed method compared to existing learning-based approaches. When coordinating with real humans, our method achieves better alignment with human preferences and an average performance improvement of 15% compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
发展智能代理可以轻松协调人类是达到人工总智能的关键一步。现有的人机协调方法通常是训练一个代理可以协调一个多样化的政策集或者从真实人类数据中适应人类模型。然而，人类行为的极其多样性对具有限制的AI系统来说是一个很大的挑战，而高质量的人类数据可能在实际场景中不易获得。在这项研究中，我们发现在协调之前，人类会通过交流来确定协调的标准和行动，使其协调顺序进行。基于这一观察，我们提议使用大语言模型（LLM）来开发一个行动计划（或等效地，一个会议），以便导引人类和AI进行协调。通过输入任务需求、人类偏好、代理数量和其他相关信息到LLM，它可以生成一份全面的会议，以便帮助所有参与者理解任务和责任。此外，我们还证明了将会议形式问题分解成多个新会议，并采用人类反馈，可以提高协调会议的效率。在Overcooked-AI环境中的实验评估中，我们的提议方法与现有的学习基于方法相比，显示了更高的性能。当与真正的人类协调时，我们的方法可以更好地与人类偏好相协调，并在平均上提高15%的性能。
</details></li>
</ul>
<hr>
<h2 id="AdaSent-Efficient-Domain-Adapted-Sentence-Embeddings-for-Few-Shot-Classification"><a href="#AdaSent-Efficient-Domain-Adapted-Sentence-Embeddings-for-Few-Shot-Classification" class="headerlink" title="AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification"></a>AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00408">http://arxiv.org/abs/2311.00408</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ukplab/adasent">https://github.com/ukplab/adasent</a></li>
<li>paper_authors: Yongxin Huang, Kexin Wang, Sourav Dutta, Raj Nath Patel, Goran Glavaš, Iryna Gurevych</li>
<li>For:  investigate strategies for domain-specialization in the context of few-shot sentence classification with Pre-trained Sentence Encoders (SEs)* Methods:  unsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language Model (PLM), training a SEPT adapter on the base PLM to decouple SEPT from DAPT* Results:  substantially improves the accuracy of few-shot sentence classification, matches or surpasses the performance of full SEPT on DAPT-ed PLM, while substantially reducing the training costs<details>
<summary>Abstract</summary>
Recent work has found that few-shot sentence classification based on pre-trained Sentence Encoders (SEs) is efficient, robust, and effective. In this work, we investigate strategies for domain-specialization in the context of few-shot sentence classification with SEs. We first establish that unsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language Model (PLM) (i.e., not an SE) substantially improves the accuracy of few-shot sentence classification by up to 8.4 points. However, applying DAPT on SEs, on the one hand, disrupts the effects of their (general-domain) Sentence Embedding Pre-Training (SEPT). On the other hand, applying general-domain SEPT on top of a domain-adapted base PLM (i.e., after DAPT) is effective but inefficient, since the computationally expensive SEPT needs to be executed on top of a DAPT-ed PLM of each domain. As a solution, we propose AdaSent, which decouples SEPT from DAPT by training a SEPT adapter on the base PLM. The adapter can be inserted into DAPT-ed PLMs from any domain. We demonstrate AdaSent's effectiveness in extensive experiments on 17 different few-shot sentence classification datasets. AdaSent matches or surpasses the performance of full SEPT on DAPT-ed PLM, while substantially reducing the training costs. The code for AdaSent is available.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhanced-Knowledge-Injection-for-Radiology-Report-Generation"><a href="#Enhanced-Knowledge-Injection-for-Radiology-Report-Generation" class="headerlink" title="Enhanced Knowledge Injection for Radiology Report Generation"></a>Enhanced Knowledge Injection for Radiology Report Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00399">http://arxiv.org/abs/2311.00399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingqiu Li, Jilan Xu, Runtian Yuan, Mohan Chen, Yuejie Zhang, Rui Feng, Xiaobo Zhang, Shang Gao</li>
<li>for: 提高自动生成医学图像报告的精度，alleviate 医生的工作负担，并提醒新手医生可能存在的异常。</li>
<li>methods: 提出了一个增强知识注入框架，包括两个分支：Weighted Concept Knowledge（WCK）分支和Multimodal Retrieval Knowledge（MRK）分支。WCK分支通过TF-IDF scores来权重医学概念，而MRK分支则从相似报告中提取 triplets，强调关键的临床信息和存在关系。</li>
<li>results: 对两个公共 benchmark 进行了广泛的实验，证明了我们的方法在其他状态之前的方法之上表现出色。剥离学 validate 两个提取的知识来源的效果。<details>
<summary>Abstract</summary>
Automatic generation of radiology reports holds crucial clinical value, as it can alleviate substantial workload on radiologists and remind less experienced ones of potential anomalies. Despite the remarkable performance of various image captioning methods in the natural image field, generating accurate reports for medical images still faces challenges, i.e., disparities in visual and textual data, and lack of accurate domain knowledge. To address these issues, we propose an enhanced knowledge injection framework, which utilizes two branches to extract different types of knowledge. The Weighted Concept Knowledge (WCK) branch is responsible for introducing clinical medical concepts weighted by TF-IDF scores. The Multimodal Retrieval Knowledge (MRK) branch extracts triplets from similar reports, emphasizing crucial clinical information related to entity positions and existence. By integrating this finer-grained and well-structured knowledge with the current image, we are able to leverage the multi-source knowledge gain to ultimately facilitate more accurate report generation. Extensive experiments have been conducted on two public benchmarks, demonstrating that our method achieves superior performance over other state-of-the-art methods. Ablation studies further validate the effectiveness of two extracted knowledge sources.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HARE-Explainable-Hate-Speech-Detection-with-Step-by-Step-Reasoning"><a href="#HARE-Explainable-Hate-Speech-Detection-with-Step-by-Step-Reasoning" class="headerlink" title="HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning"></a>HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00321">http://arxiv.org/abs/2311.00321</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joonkeekim/hare-hate-speech">https://github.com/joonkeekim/hare-hate-speech</a></li>
<li>paper_authors: Yongjin Yang, Joonkee Kim, Yujin Kim, Namgyu Ho, James Thorne, Se-young Yun</li>
<li>for: 针对社交媒体上的仇恨言论的准确检测，以确保在线安全。</li>
<li>methods: 利用大型自然语言模型（LLMs）的逻辑能力来填充现有涉 hate speech 的注释 schemes 中的理解漏洞，以便准确地训练检测模型。</li>
<li>results: 使用模型生成数据，与基eline比较，显示我们的方法在 SBIC 和 Implicit Hate benchmark 上表现出色，可以提高检测模型的准确性和泛化能力。<details>
<summary>Abstract</summary>
With the proliferation of social media, accurate detection of hate speech has become critical to ensure safety online. To combat nuanced forms of hate speech, it is important to identify and thoroughly explain hate speech to help users understand its harmful effects. Recent benchmarks have attempted to tackle this issue by training generative models on free-text annotations of implications in hateful text. However, we find significant reasoning gaps in the existing annotations schemes, which may hinder the supervision of detection models. In this paper, we introduce a hate speech detection framework, HARE, which harnesses the reasoning capabilities of large language models (LLMs) to fill these gaps in explanations of hate speech, thus enabling effective supervision of detection models. Experiments on SBIC and Implicit Hate benchmarks show that our method, using model-generated data, consistently outperforms baselines, using existing free-text human annotations. Analysis demonstrates that our method enhances the explanation quality of trained models and improves generalization to unseen datasets. Our code is available at https://github.com/joonkeekim/hare-hate-speech.git.
</details>
<details>
<summary>摘要</summary>
随着社交媒体的普及，准确检测仇恨言语已经成为在线保障安全的关键。为了对抗仇恨言语的复杂形式，需要识别并详细解释仇恨言语，以便用户理解其有害的效果。现有的标准监测方案存在重要的理解漏洞，这可能会阻碍检测模型的超级视图。在这篇论文中，我们介绍了一种仇恨言语检测框架，称为HARE，它利用大型自然语言模型（LLMs）的理解能力来填充现有标准监测方案中的解释漏洞，从而为检测模型提供有效的监测。我们的实验表明，使用我们的方法，使用模型生成的数据，可以在SBIC和隐式仇恨benchmark上 consistently outperform基elines，使用现有的自由文本人工监测。分析表明，我们的方法可以提高训练模型的解释质量和对未经见过的数据的泛化。我们的代码可以在https://github.com/joonkeekim/hare-hate-speech.git中获取。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Code-Translation-with-Comparable-Corpora-and-Multiple-References"><a href="#Data-Augmentation-for-Code-Translation-with-Comparable-Corpora-and-Multiple-References" class="headerlink" title="Data Augmentation for Code Translation with Comparable Corpora and Multiple References"></a>Data Augmentation for Code Translation with Comparable Corpora and Multiple References</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00317">http://arxiv.org/abs/2311.00317</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Veronicium/CMTrans">https://github.com/Veronicium/CMTrans</a></li>
<li>paper_authors: Yiqing Xie, Atharva Naik, Daniel Fried, Carolyn Rose</li>
<li>for: 本研究旨在解决翻译代码 между不同编程语言时的一个主要挑战，即并不具备并行训练数据。</li>
<li>methods: 本研究提出了两种数据扩充技术，一是建立可比较的代码库（i.e., 代码对应的功能相似的代码集），另一是将现有的并行数据扩充多个参考翻译。特别是，我们使用自然语言文档生成代码模型生成的程序来建立多种可比较的代码库，并对可用的并行数据进行自动生成多个翻译参考，并对其进行单元测试滤波，从而增加目标翻译的多样性。</li>
<li>results: 我们的数据扩充技术可以显著提高CodeT5在Java、Python和C++之间的翻译精度，准确率平均提高7.5% Computational Accuracy (CA@1)，这证明了翻译的正确性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Veronicium/CMTrans%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Veronicium/CMTrans中下载。</a><details>
<summary>Abstract</summary>
One major challenge of translating code between programming languages is that parallel training data is often limited. To overcome this challenge, we present two data augmentation techniques, one that builds comparable corpora (i.e., code pairs with similar functionality), and another that augments existing parallel data with multiple reference translations. Specifically, we build and analyze multiple types of comparable corpora, including programs generated from natural language documentation using a code generation model. Furthermore, to reduce overfitting to a single reference translation, we automatically generate additional translation references for available parallel data and filter the translations by unit tests, which increases variation in target translations. Experiments show that our data augmentation techniques significantly improve CodeT5 for translation between Java, Python, and C++ by an average of 7.5% Computational Accuracy (CA@1), which verifies the correctness of translations by execution. The code is available at https://github.com/Veronicium/CMTrans.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在代码之间的翻译是平行训练数据的有限性。为了解决这个挑战，我们提出了两种数据扩充技术，一种建立相似代码对（i.e., 代码对的功能相似），另一种将现有平行数据扩充多个参考翻译。我们首先构建多种类型的相似代码对，包括从自然语言文档生成的代码。此外，为了减少参考翻译的过拟合，我们自动生成了多个翻译参考，并使用单元测试过滤target翻译，从而增加目标翻译的多样性。实验表明，我们的数据扩充技术可以在Java、Python和C++之间的翻译中提高CodeT5的平均计算准确率（CA@1）约7.5%，这 verify了翻译的正确性。代码可以在https://github.com/Veronicium/CMTrans中找到。
</details></li>
</ul>
<hr>
<h2 id="Probing-Explicit-and-Implicit-Gender-Bias-through-LLM-Conditional-Text-Generation"><a href="#Probing-Explicit-and-Implicit-Gender-Bias-through-LLM-Conditional-Text-Generation" class="headerlink" title="Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation"></a>Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00306">http://arxiv.org/abs/2311.00306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangjue Dong, Yibo Wang, Philip S. Yu, James Caverlee<br>for:This paper aims to evaluate the gender bias of large language models (LLMs) without relying on predefined gender-related phrases or stereotypes.methods:The proposed approach uses three types of inputs generated through three distinct strategies to probe LLMs for evidence of explicit and implicit gender biases.results:The experiments show that all tested LLMs exhibit explicit and&#x2F;or implicit gender bias, even when explicit gender stereotypes are absent in the inputs. Additionally, an increased model size does not consistently lead to enhanced fairness.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which are challenging to be comprehensively collected and are limited to explicit bias evaluation. In addition, we believe that instances devoid of gender-related language or explicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in this work, we propose a conditional text generation mechanism without the need for predefined gender phrases and stereotypes. This approach employs three types of inputs generated through three distinct strategies to probe LLMs, aiming to show evidence of explicit and implicit gender biases in LLMs. We also utilize explicit and implicit evaluation metrics to evaluate gender bias in LLMs under different strategies. Our experiments demonstrate that an increased model size does not consistently lead to enhanced fairness and all tested LLMs exhibit explicit and/or implicit gender bias, even when explicit gender stereotypes are absent in the inputs.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The translation is written in a more formal and literary style, which may be different from the way the text would be written in spoken Chinese.
</details></li>
</ul>
<hr>
<h2 id="Detecting-Syllable-Level-Pronunciation-Stress-with-A-Self-Attention-Model"><a href="#Detecting-Syllable-Level-Pronunciation-Stress-with-A-Self-Attention-Model" class="headerlink" title="Detecting Syllable-Level Pronunciation Stress with A Self-Attention Model"></a>Detecting Syllable-Level Pronunciation Stress with A Self-Attention Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00301">http://arxiv.org/abs/2311.00301</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangweiying303/stress-detection-model">https://github.com/wangweiying303/stress-detection-model</a></li>
<li>paper_authors: Wang Weiying, Nakajima Akinori</li>
<li>for: 这篇论文是为了研究如何使用自注意模型来检测英语说话时的句子强调水平的。</li>
<li>methods: 这篇论文使用了多种语音和分类特征，如抑压水平、干扰度、持续时间和元音等，输入到自注意模型中，并预测每个句子中的强调水平。</li>
<li>results: 研究发现，使用最简单的模型可以在不同的数据集上达到88%以上的准确率和93%以上的准确率，而更先进的模型可以提供更高的准确率。这些模型可以应用于在线会议和英语学习等场景。<details>
<summary>Abstract</summary>
One precondition of effective oral communication is that words should be pronounced clearly, especially for non-native speakers. Word stress is the key to clear and correct English, and misplacement of syllable stress may lead to misunderstandings. Thus, knowing the stress level is important for English speakers and learners. This paper presents a self-attention model to identify the stress level for each syllable of spoken English. Various prosodic and categorical features, including the pitch level, intensity, duration and type of the syllable and its nuclei (the vowel of the syllable), are explored. These features are input to the self-attention model, and syllable-level stresses are predicted. The simplest model yields an accuracy of over 88% and 93% on different datasets, while more advanced models provide higher accuracy. Our study suggests that the self-attention model can be promising in stress-level detection. These models could be applied to various scenarios, such as online meetings and English learning.
</details>
<details>
<summary>摘要</summary>
一个听众交流的先件是使用英语Clearly pronounce words, especially for non-native speakers.  Correct word stress is crucial for clear and accurate English, and misplacing syllable stress can lead to misunderstandings. Therefore, knowing the stress level is essential for English speakers and learners. This paper proposes a self-attention model to identify the stress level for each syllable of spoken English. Various prosodic and categorical features, such as pitch level, intensity, duration, and type of the syllable and its nuclei (the vowel of the syllable), are explored. These features are input to the self-attention model, and syllable-level stresses are predicted. The simplest model achieves an accuracy of over 88% and 93% on different datasets, while more advanced models provide higher accuracy. Our study suggests that the self-attention model is promising in stress-level detection and can be applied to various scenarios, such as online meetings and English learning.
</details></li>
</ul>
<hr>
<h2 id="Entity-Alignment-Method-of-Science-and-Technology-Patent-based-on-Graph-Convolution-Network-and-Information-Fusion"><a href="#Entity-Alignment-Method-of-Science-and-Technology-Patent-based-on-Graph-Convolution-Network-and-Information-Fusion" class="headerlink" title="Entity Alignment Method of Science and Technology Patent based on Graph Convolution Network and Information Fusion"></a>Entity Alignment Method of Science and Technology Patent based on Graph Convolution Network and Information Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00300">http://arxiv.org/abs/2311.00300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runze Fang, Yawen Li, Yingxia Shao, Zeli Guan, Zhe Xue</li>
<li>for: 该研究旨在提高科技专利知识图中实体对应关系的准确率，通过利用图 convolutional neural network 和 BERT 模型， simultaneously fusing 多种信息，包括图структуры信息和实体属性信息。</li>
<li>methods: 该方法使用图 convolutional neural network 和 BERT 模型，对科技专利知识图中的实体进行嵌入和表示，实现多信息融合，以提高实体对应关系的准确率。</li>
<li>results: 实验结果表明，提案的方法在三个数据集上的评价指标均高于现有方法。<details>
<summary>Abstract</summary>
The entity alignment of science and technology patents aims to link the equivalent entities in the knowledge graph of different science and technology patent data sources. Most entity alignment methods only use graph neural network to obtain the embedding of graph structure or use attribute text description to obtain semantic representation, ignoring the process of multi-information fusion in science and technology patents. In order to make use of the graphic structure and auxiliary information such as the name, description and attribute of the patent entity, this paper proposes an entity alignment method based on the graph convolution network for science and technology patent information fusion. Through the graph convolution network and BERT model, the structure information and entity attribute information of the science and technology patent knowledge graph are embedded and represented to achieve multi-information fusion, thus improving the performance of entity alignment. Experiments on three benchmark data sets show that the proposed method Hit@K The evaluation indicators are better than the existing methods.
</details>
<details>
<summary>摘要</summary>
<SYS> translate(The entity alignment of science and technology patents aims to link the equivalent entities in the knowledge graph of different science and technology patent data sources. Most entity alignment methods only use graph neural network to obtain the embedding of graph structure or use attribute text description to obtain semantic representation, ignoring the process of multi-information fusion in science and technology patents. In order to make use of the graphic structure and auxiliary information such as the name, description and attribute of the patent entity, this paper proposes an entity alignment method based on the graph convolution network for science and technology patent information fusion. Through the graph convolution network and BERT model, the structure information and entity attribute information of the science and technology patent knowledge graph are embedded and represented to achieve multi-information fusion, thus improving the performance of entity alignment. Experiments on three benchmark data sets show that the proposed method Hit@K The evaluation indicators are better than the existing methods.)</SYS>Here's the translation in Simplified Chinese:科技专利实体对Alignment的目标是将不同科技专利数据源知识图中的相同实体相互链接。大多数实体对齐方法只是使用图 neural network获取图 структуры的嵌入或者使用特征文本描述获取 semantic表示，忽略了科技专利中的多信息融合过程。为了利用图结构和辅助信息such as 专利名称、描述和属性，本文提出了基于图 convolution network的科技专利信息融合的实体对齐方法。通过图 convolution network和BERT模型，科技专利知识图的结构信息和实体属性信息被嵌入和表示，实现多信息融合，提高实体对齐性能。对三个 Referenced data set进行实验，评估指标比现有方法更好。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Representation-Learning-of-Scientific-Literature-based-on-Adaptive-Feature-and-Graph-Neural-Network"><a href="#Semantic-Representation-Learning-of-Scientific-Literature-based-on-Adaptive-Feature-and-Graph-Neural-Network" class="headerlink" title="Semantic Representation Learning of Scientific Literature based on Adaptive Feature and Graph Neural Network"></a>Semantic Representation Learning of Scientific Literature based on Adaptive Feature and Graph Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00296">http://arxiv.org/abs/2311.00296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongrui Gao, Yawen Li, Meiyu Liang, Zeli Guan, Zhe Xue</li>
<li>for: 科学文献semantic representation学习，以提高文献分类的能力。</li>
<li>methods: 提议使用自适应特征方法和图神经网络，对科学文献进行 semantic representation 学习。图神经网络可以捕捉本地和全球信息，提高文献分类的准确率。</li>
<li>results: 实验结果显示，提议的方法可以在基于科学文献分类的情况下达到比较好的效果，并且比传统方法更高的准确率。<details>
<summary>Abstract</summary>
Because most of the scientific literature data is unmarked, it makes semantic representation learning based on unsupervised graph become crucial. At the same time, in order to enrich the features of scientific literature, a learning method of semantic representation of scientific literature based on adaptive features and graph neural network is proposed. By introducing the adaptive feature method, the features of scientific literature are considered globally and locally. The graph attention mechanism is used to sum the features of scientific literature with citation relationship, and give each scientific literature different feature weights, so as to better express the correlation between the features of different scientific literature. In addition, an unsupervised graph neural network semantic representation learning method is proposed. By comparing the mutual information between the positive and negative local semantic representation of scientific literature and the global graph semantic representation in the potential space, the graph neural network can capture the local and global information, thus improving the learning ability of the semantic representation of scientific literature. The experimental results show that the proposed learning method of semantic representation of scientific literature based on adaptive feature and graph neural network is competitive on the basis of scientific literature classification, and has achieved good results.
</details>
<details>
<summary>摘要</summary>
因为大多数科学文献数据未经标记，因此使得基于无监督图的 semantic representation 学习成为关键。同时，为了丰富科学文献的特征，一种基于自适应特征和图神经网络的科学文献semantic representation 学习方法被提议。通过引入自适应特征方法，科学文献的特征被考虑在全球和本地方面。使用图注意力机制将科学文献之间的引用关系权重调整，以更好地表达不同科学文献之间的相关性。此外，一种无监督图神经网络 semantic representation 学习方法被提议。通过比较科学文献的正向和负向本地semantic representation在潜在空间中的互信息，图神经网络可以捕捉本地和全球信息，从而提高 semantic representation 的学习能力。实验结果表明，提议的基于自适应特征和图神经网络的科学文献semantic representation 学习方法在科学文献分类任务上具有竞争力，并实现了良好的效果。
</details></li>
</ul>
<hr>
<h2 id="IBADR-an-Iterative-Bias-Aware-Dataset-Refinement-Framework-for-Debiasing-NLU-models"><a href="#IBADR-an-Iterative-Bias-Aware-Dataset-Refinement-Framework-for-Debiasing-NLU-models" class="headerlink" title="IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models"></a>IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00292">http://arxiv.org/abs/2311.00292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyue Wang, Xin Liu, Lijie Wang, Yaoxiang Wang, Jinsong Su, Hua Wu</li>
<li>for: 本研究旨在提出一种基于迭代偏好感知的数据精炼框架，以减少自然语言理解（NLU）模型中的偏好。</li>
<li>methods: 我们提出了一种迭代偏好感知（IBADR）框架，它不需要先定义偏好特征，可以自动检测和修复偏好。我们维护了一个迭代扩展的样本池，并在每次迭代中使用一个浅度模型来评估样本中偏好的程度。</li>
<li>results: 我们的实验结果和深入分析表明，IBADR不仅可以大幅超越现有的数据精炼方法，还可以与模型中心的方法兼容。IBADR可以生成具有更少偏好特征的 Pseudo 样本，从而提高 NLU 模型的性能。<details>
<summary>Abstract</summary>
As commonly-used methods for debiasing natural language understanding (NLU) models, dataset refinement approaches heavily rely on manual data analysis, and thus maybe unable to cover all the potential biased features. In this paper, we propose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which debiases NLU models without predefining biased features. We maintain an iteratively expanded sample pool. Specifically, at each iteration, we first train a shallow model to quantify the bias degree of samples in the pool. Then, we pair each sample with a bias indicator representing its bias degree, and use these extended samples to train a sample generator. In this way, this generator can effectively learn the correspondence relationship between bias indicators and samples. Furthermore, we employ the generator to produce pseudo samples with fewer biased features by feeding specific bias indicators. Finally, we incorporate the generated pseudo samples into the pool. Experimental results and in-depth analyses on two NLU tasks show that IBADR not only significantly outperforms existing dataset refinement approaches, achieving SOTA, but also is compatible with model-centric methods.
</details>
<details>
<summary>摘要</summary>
通常使用的自然语言理解（NLU）模型偏见纠正方法， dataset 纠正方法倚靠手动数据分析，因此可能无法涵盖所有潜在的偏见特征。在这篇论文中，我们提议 IBADR，一种迭代偏见意识数据纠正框架，无需先定偏见特征来纠正 NLU 模型。我们保持一个迭代扩展的样本池。具体来说，在每一轮中，我们首先使用一个浅度模型来评估样本池中每个样本的偏见度。然后，我们对每个样本分别生成一个偏见指标，表示其偏见度。这些扩展后的样本与模型进行训练，使得这些模型可以有效地学习偏见指标与样本之间的对应关系。此外，我们使用这些模型生成具有更少偏见特征的 Pseudo 样本。最后，我们将生成的 Pseudo 样本添加到样本池中。实验结果和深入分析表明， IBADR 不仅能够显著超越现有的 dataset 纠正方法，达到最佳性能，而且可以与模型中心方法兼容。
</details></li>
</ul>
<hr>
<h2 id="SoulChat-Improving-LLMs’-Empathy-Listening-and-Comfort-Abilities-through-Fine-tuning-with-Multi-turn-Empathy-Conversations"><a href="#SoulChat-Improving-LLMs’-Empathy-Listening-and-Comfort-Abilities-through-Fine-tuning-with-Multi-turn-Empathy-Conversations" class="headerlink" title="SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations"></a>SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00273">http://arxiv.org/abs/2311.00273</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scutcyr/soulchat">https://github.com/scutcyr/soulchat</a></li>
<li>paper_authors: Yirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng, Zhenyu Wang, Qi Liu, Xiangmin Xu</li>
<li>for: 这研究旨在提高大语言模型在心理咨询领域的同理能力。</li>
<li>methods: 研究人员构建了一个多turn对话context数据集，并使用多turn对话历史和更加接近心理咨询员的回应进行finetuning，以提高大语言模型的同理能力。</li>
<li>results: 实验结果显示，通过使用多turn对话历史和更加接近心理咨询员的回应进行finetuning，可以显著提高大语言模型的同理能力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Syntactic-Inductive-Bias-in-Transformer-Language-Models-Especially-Helpful-for-Low-Resource-Languages"><a href="#Syntactic-Inductive-Bias-in-Transformer-Language-Models-Especially-Helpful-for-Low-Resource-Languages" class="headerlink" title="Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?"></a>Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00268">http://arxiv.org/abs/2311.00268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Gessler, Nathan Schneider</li>
<li>for: 这个研究是为了检查使用语法印欧特征来增强预训练过程的效果，特别是在低资源语言中。</li>
<li>methods: 这个研究使用了Transformer基于模型，如BERT，并在预训练过程中添加了语法印欧特征。</li>
<li>results: 研究发现，在低资源语言中，这些语法印欧特征方法的效果不均，并且在大多数情况下提供了Surprisingly little benefit。<details>
<summary>Abstract</summary>
A line of work on Transformer-based language models such as BERT has attempted to use syntactic inductive bias to enhance the pretraining process, on the theory that building syntactic structure into the training process should reduce the amount of data needed for training. But such methods are often tested for high-resource languages such as English. In this work, we investigate whether these methods can compensate for data sparseness in low-resource languages, hypothesizing that they ought to be more effective for low-resource languages. We experiment with five low-resource languages: Uyghur, Wolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic inductive bias methods produce uneven results in low-resource settings, and provide surprisingly little benefit in most cases.
</details>
<details>
<summary>摘要</summary>
一种工作使用基于转移器的语言模型，如BERT，尝试使用 sintactic inductive bias 来增强预训练过程，理解建立语法结构在训练过程中应该减少数据量需要。但这些方法通常在高资源语言 such as English 上测试。在这个工作中，我们调查了这些方法是否可以在低资源语言中资源不足的情况下提供更好的效果，假设它们应该更有效果于低资源语言。我们在五种低资源语言中进行了实验：维吾尔语、沃洛语、马耳他语、古埃及语和古希腊语。我们发现这些 sintactic inductive bias 方法在低资源设置下的结果不均匀，并且在大多数情况下提供了不足的 beneficial 效果。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Exemplars-Make-Large-Language-Models-More-Robust-A-Domain-Agnostic-Behavioral-Analysis"><a href="#Noisy-Exemplars-Make-Large-Language-Models-More-Robust-A-Domain-Agnostic-Behavioral-Analysis" class="headerlink" title="Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis"></a>Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00258">http://arxiv.org/abs/2311.00258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust">https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust</a></li>
<li>paper_authors: Hongyi Zheng, Abulhair Saparov</li>
<li>for: 研究 LLM 在多步逻辑理解任务中的稳定性。</li>
<li>methods: 使用多级抽象的干扰（如 Typos 和中间逻辑步骤的包含）进行Behavioral Analysis。</li>
<li>results: 发现模型更敏感于替换单词为同义词的干扰，并证明增加干扰示例的比例可以提高少量示例引导方法的稳定性。<details>
<summary>Abstract</summary>
Recent advances in prompt engineering enable large language models (LLMs) to solve multi-hop logical reasoning problems with impressive accuracy. However, there is little existing work investigating the robustness of LLMs with few-shot prompting techniques. Therefore, we introduce a systematic approach to test the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic perturbations. We include perturbations at multiple levels of abstractions (e.g. lexical perturbations such as typos, and semantic perturbations such as the inclusion of intermediate reasoning steps in the questions) to conduct behavioral analysis on the LLMs. Throughout our experiments, we find that models are more sensitive to certain perturbations such as replacing words with their synonyms. We also demonstrate that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近的提示工程技术突破使得大型自然语言模型（LLM）在多步逻辑推理任务中表现出色。然而，现有的工作却很少研究了LLM在几步提示技术下的Robustness。因此，我们提出了一种系统的方法来测试LLM在多步逻辑推理任务中的Robustness，通过具有多级抽象水平的随机变化（如Typos和中间推理步骤的包含）来进行行为分析。在我们的实验中，我们发现模型对某些变化（如替换单词）更为敏感。此外，我们还证明了在提示中增加受到干扰的 exemplars 的比例可以提高几步提示方法的Robustness。
</details></li>
</ul>
<hr>
<h2 id="The-Mystery-and-Fascination-of-LLMs-A-Comprehensive-Survey-on-the-Interpretation-and-Analysis-of-Emergent-Abilities"><a href="#The-Mystery-and-Fascination-of-LLMs-A-Comprehensive-Survey-on-the-Interpretation-and-Analysis-of-Emergent-Abilities" class="headerlink" title="The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities"></a>The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00237">http://arxiv.org/abs/2311.00237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Zhou, Jiazheng Li, Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He</li>
<li>For: This paper aims to provide a comprehensive survey of the interpretation and analysis of emergent abilities in large language models (LLMs), including their mechanistic and empirical interpretability.* Methods: The paper uses a macro perspective to examine the mathematical foundations of emergent abilities, as well as a micro perspective to study the factors associated with these abilities through empirical research.* Results: The paper highlights the challenges encountered in interpreting and analyzing emergent abilities in LLMs, and suggests potential avenues for future research to better understand and utilize these capabilities.Here is the same information in Simplified Chinese text:* For: 这篇论文目的是为了对大型自然语言模型（LLM）中的emergent能力进行全面的审查和分析，包括它们的机制性和实际性可解性。* Methods: 论文使用了macro perspective来检查emergent能力的数学基础，以及micro perspective来研究这些能力与这些因素的关系。* Results: 论文指出了对emergent能力的解释和分析存在挑战，并提出了将来研究的可能性，以更好地理解和利用这些能力。<details>
<summary>Abstract</summary>
Understanding emergent abilities, such as in-context learning (ICL) and chain-of-thought (CoT) prompting in large language models (LLMs), is of utmost importance. This importance stems not only from the better utilization of these capabilities across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns of truthfulness, bias, and toxicity, that may arise alongside these capabilities. In this paper, we present a thorough survey on the interpretation and analysis of emergent abilities of LLMs. First, we provide a concise introduction to the background and definition of emergent abilities. Then, we give an overview of advancements from two perspectives: 1) a macro perspective, emphasizing studies on the mechanistic interpretability and delving into the mathematical foundations behind emergent abilities; and 2) a micro-perspective, concerning studies that focus on empirical interpretability by examining factors associated with these abilities. We conclude by highlighting the challenges encountered and suggesting potential avenues for future research. We believe that our work establishes the basis for further exploration into the interpretation of emergent abilities.
</details>
<details>
<summary>摘要</summary>
理解大语言模型（LLM）中的emergent能力（如上下文学习（ICL）和串行思维（CoT））对我们非常重要。这种重要性不仅来自于更好地利用这些能力在各种任务上，而且还来自于积极发现和 mitigate potential risks，包括可能出现的真实性、偏见和恶势力问题。在这篇论文中，我们提供了一份广泛的survey关于LLM的emergent能力的解释和分析。首先，我们提供了一个简洁的引入，概述背景和emergent能力的定义。然后，我们给出了两个视角的总结：1）一个 macro 视角，强调机制可读性和数学基础之间的关系; 2）一个 micro 视角，关注关于这些能力的实际可读性，通过分析这些能力相关的因素。我们 conclude by highlighting the challenges encountered and suggesting potential avenues for future research.我们认为，我们的工作laying the foundation for further exploration of emergent abilities的解释。
</details></li>
</ul>
<hr>
<h2 id="Distort-Distract-Decode-Instruction-Tuned-Model-Can-Refine-its-Response-from-Noisy-Instructions"><a href="#Distort-Distract-Decode-Instruction-Tuned-Model-Can-Refine-its-Response-from-Noisy-Instructions" class="headerlink" title="Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions"></a>Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00233">http://arxiv.org/abs/2311.00233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taehyeon Kim, Joonkee Kim, Gihun Lee, Se-Young Yun</li>
<li>for: 提高 instruction-tuned 模型的 zero-shot 泛化能力</li>
<li>methods: 使用干扰版本的原始 instruction 生成潜在可能的回答，并对 next-token 预测 logits 进行冲突调整</li>
<li>results: 在不同的 instruction-tuned 模型和任务上实现了显著的性能提升，无需进行额外参数更新<details>
<summary>Abstract</summary>
While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that augments the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessitating any additional parameter updates. Notably, utilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum divergence from the original instruction, consistently produces the most significant performance gains across multiple models and tasks.
</details>
<details>
<summary>摘要</summary>
While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that enhances the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessitating any additional parameter updates. Notably, utilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum divergence from the original instruction, consistently produces the most significant performance gains across multiple models and tasks.Here is the translation in Traditional Chinese:虽然受训语言模型已经展示了很好的零例外推导能力，但这些模型在面对不同于训练集的指令时，通常会显示出低准确性。本文提出了几个简单 yet effective的方法，包括几个 Instructive Decoding (ID) 技术，以提高受训语言模型的效能。特别是，ID 会在下一个字prediction中调整 logits 的排名，使其在不同的指令下具有更高的弹性。我们在不同的噪音指令下进行了实验，包括在指令中插入随机词或使用 'opposite' 类型的噪音指令，以诱发模型产生更多的偏离。我们发现，使用 'opposite' 类型的噪音指令可以对多个模型和任务产生最大的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Is-GPT-Powerful-Enough-to-Analyze-the-Emotions-of-Memes"><a href="#Is-GPT-Powerful-Enough-to-Analyze-the-Emotions-of-Memes" class="headerlink" title="Is GPT Powerful Enough to Analyze the Emotions of Memes?"></a>Is GPT Powerful Enough to Analyze the Emotions of Memes?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00223">http://arxiv.org/abs/2311.00223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingjing Wang, Joshua Luo, Grace Yang, Allen Hong, Feng Luo</li>
<li>for: 本研究旨在探讨GPT-3.5在互联网趣味图文（meme）中的情感分析能力。</li>
<li>methods: 本研究使用GPT-3.5模型进行趣味图文的情感分类、幽默类型的确定以及带有偏见的恶意趣味图文的检测。</li>
<li>results: 研究发现GPT-3.5在处理主观任务时存在一定的限制，包括理解社会规范、文化背景和含义层次的理解等。尽管GPT-3.5在一些任务上表现出色，但在某些情况下，其响应仍然需要人工审核和改进。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), representing a significant achievement in artificial intelligence (AI) research, have demonstrated their ability in a multitude of tasks. This project aims to explore the capabilities of GPT-3.5, a leading example of LLMs, in processing the sentiment analysis of Internet memes. Memes, which include both verbal and visual aspects, act as a powerful yet complex tool for expressing ideas and sentiments, demanding an understanding of societal norms and cultural contexts. Notably, the detection and moderation of hateful memes pose a significant challenge due to their implicit offensive nature. This project investigates GPT's proficiency in such subjective tasks, revealing its strengths and potential limitations. The tasks include the classification of meme sentiment, determination of humor type, and detection of implicit hate in memes. The performance evaluation, using datasets from SemEval-2020 Task 8 and Facebook hateful memes, offers a comparative understanding of GPT responses against human annotations. Despite GPT's remarkable progress, our findings underscore the challenges faced by these models in handling subjective tasks, which are rooted in their inherent limitations including contextual understanding, interpretation of implicit meanings, and data biases. This research contributes to the broader discourse on the applicability of AI in handling complex, context-dependent tasks, and offers valuable insights for future advancements.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Transformers-as-Recognizers-of-Formal-Languages-A-Survey-on-Expressivity"><a href="#Transformers-as-Recognizers-of-Formal-Languages-A-Survey-on-Expressivity" class="headerlink" title="Transformers as Recognizers of Formal Languages: A Survey on Expressivity"></a>Transformers as Recognizers of Formal Languages: A Survey on Expressivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00208">http://arxiv.org/abs/2311.00208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lena Strobl, William Merrill, Gail Weiss, David Chiang, Dana Angluin</li>
<li>for: 这篇论文探讨了使用形式语言处理问题，以了解transformer模型可以解决哪些问题，以及它们与其他模型和变体之间的比较。</li>
<li>methods: 论文使用了正式语言处理的方法，探讨了不同假设的影响，并提供了一个统一的框架来协调 aparently contradictory findings。</li>
<li>results: 论文提供了一个广泛的survey，涵盖了不同假设的影响，并提供了一个统一的框架来协调 aparently contradictory findings。<details>
<summary>Abstract</summary>
As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring questions such as this will help to compare transformers with other models, and transformer variants with one another, for various tasks. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings.
</details>
<details>
<summary>摘要</summary>
为了探讨自然语言处理中transformer的表现，一些研究人员已经对这些问题进行了理论分析，将问题视为 формаль语言。这种研究将帮助比较transformer和其他模型，以及不同transformer变体之间的比较，在不同任务中。在这个子领域中，工作有了很大的进步，我们在这篇文章中会进行一个系统的评论，整理不同假设的结果，并提供一个统一的框架，将可能的矛盾结果融合起来。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.CL_2023_11_01/" data-id="clohum96c00dlpj889ophbp0k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/01/cs.AI_2023_11_01/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-11-01
        
      </div>
    </a>
  
  
    <a href="/2023/11/01/cs.LG_2023_11_01/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-11-01</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
