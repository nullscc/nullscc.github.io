
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-11-20 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.12028 repo_url: None paper_authors: Wenhao Li, Mengyuan Liu, Hong Liu, Pichao Wang, Ji">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-11-20">
<meta property="og:url" content="https://nullscc.github.io/2023/11/20/cs.AI_2023_11_20/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.12028 repo_url: None paper_authors: Wenhao Li, Mengyuan Liu, Hong Liu, Pichao Wang, Ji">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-20T12:00:00.000Z">
<meta property="article:modified_time" content="2023-11-21T10:06:16.039Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.AI_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T12:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-11-20
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Hourglass-Tokenizer-for-Efficient-Transformer-Based-3D-Human-Pose-Estimation"><a href="#Hourglass-Tokenizer-for-Efficient-Transformer-Based-3D-Human-Pose-Estimation" class="headerlink" title="Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation"></a>Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12028">http://arxiv.org/abs/2311.12028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhao Li, Mengyuan Liu, Hong Liu, Pichao Wang, Jialun Cai, Nicu Sebe</li>
<li>for: efficient transformer-based 3D human pose estimation from videos</li>
<li>methods: pruning-and-recovering framework, token pruning cluster, token recovering attention</li>
<li>results: improved model efficiency, high estimation accuracy, reduced FLOPs (compared to original VPT models)<details>
<summary>Abstract</summary>
Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a plug-and-play pruning-and-recovering framework, called Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose estimation from videos. Our HoT begins with pruning pose tokens of redundant frames and ends with recovering full-length tokens, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. To effectively achieve this, we propose a token pruning cluster (TPC) that dynamically selects a few representative tokens with high semantic diversity while eliminating the redundancy of video frames. In addition, we develop a token recovering attention (TRA) to restore the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and MPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and estimation accuracy compared to the original VPT models. For instance, applying to MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs without sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop, respectively. Our source code will be open-sourced.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的转换器模型在视频基于3D人姿估计领域已经得到成功应用。然而，这些视频转换器（VPT）的计算成本很高，使得在有限的资源设备上实现不可靠。在这篇论文中，我们提出了一种插件化剪辑和恢复框架，called Hourglass Tokenizer（HoT），用于高效地使用转换器进行视频基于3D人姿估计。我们的HoT开始于剪辑人姿块（TPC），选择视频帧中缺乏重复的块，然后通过恢复全长块（TRA）来恢复原始的块，从而提高模型的效率。为了有效实现这一点，我们提出了一种动态选择高Semantic多样性的块的 Token Pruning Cluster（TPC），并开发了一种基于选择的块的 Token Recovering Attention（TRA），以恢复原始的块。我们的方法可以在两个标准数据集（i.e., Human3.6M和MPI-INF-3DHP）上进行广泛的实验，结果表明，我们的方法可以同时实现高效和高准确性。例如，在应用于MotionBERT和MixSTE上的Human3.6M数据集上，我们的HoT可以节省约50%的计算成本，无需牺牲准确性，或者节省约40%的计算成本，只有0.2%的准确性下降。我们将源代码公开源。<<SYS>>
</details></li>
</ul>
<hr>
<h2 id="GPQA-A-Graduate-Level-Google-Proof-Q-A-Benchmark"><a href="#GPQA-A-Graduate-Level-Google-Proof-Q-A-Benchmark" class="headerlink" title="GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark"></a>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12022">http://arxiv.org/abs/2311.12022</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idavidrein/gpqa">https://github.com/idavidrein/gpqa</a></li>
<li>paper_authors: David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman</li>
<li>for: The paper is written to present a challenging dataset of multiple-choice questions to evaluate the ability of AI systems and human experts to answer difficult questions in biology, physics, and chemistry.</li>
<li>methods: The paper uses a dataset of 448 questions written by domain experts, which are high-quality and extremely difficult even for PhD-holding experts. The authors also use a strongest GPT-4 based baseline to evaluate the performance of state-of-the-art AI systems.</li>
<li>results: The paper shows that the questions in the dataset are difficult for both human experts and AI systems, with the experts reaching 65% accuracy and the AI system reaching 39% accuracy. The results suggest that scalable oversight methods are needed to ensure that human experts can reliably get truthful information from AI systems that surpass human capabilities.<details>
<summary>Abstract</summary>
We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are "Google-proof"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.
</details>
<details>
<summary>摘要</summary>
我们提供了GPQA，一个具有挑战性的448道多选问题集，由领域专家写成的生物、物理和化学领域。我们确保了问题的质量和极其困难：具有或正在追求博士学位的专家达到65%的准确率（74%，减去明显的后悔），而非专家验证人员仅达到34%的准确率，即使花费平均超过30分钟，并且有无限时间 accessing the web（即问题是"Google-proof"）。这些问题还是前沿AI系统的挑战，我们最强的基于GPT-4的基线只达39%的准确率。如果我们想使用未来的AI系统来帮助我们回答非常困难的问题，例如在科学发展新知识时，我们需要开发可扩展的监督方法，以便人类可以监督AI系统的输出，这可能是非常困难，即使监督人员本身具备技能和知识。GPQA的困难程度不仅对非专家和前沿AI系统来说是挑战，也可以帮助我们实施可扩展的监督实验，以便开发可靠地获取AI系统输出的真实信息的方法。
</details></li>
</ul>
<hr>
<h2 id="Steering-Responsible-AI-A-Case-for-Algorithmic-Pluralism"><a href="#Steering-Responsible-AI-A-Case-for-Algorithmic-Pluralism" class="headerlink" title="Steering Responsible AI: A Case for Algorithmic Pluralism"></a>Steering Responsible AI: A Case for Algorithmic Pluralism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12010">http://arxiv.org/abs/2311.12010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefaan G. Verhulst</li>
<li>for: 本文探讨人工智能中立性问题，通过现有的媒介和多元媒体学术研究。</li>
<li>methods: 本文使用现有的媒介和多元媒体学术研究来探讨AI中立性问题。</li>
<li>results: 本文认为，思考algorithmic pluralism可能有助于维护多样性、多元性和包容性，这些价值对民主社会至关重要。<details>
<summary>Abstract</summary>
In this paper, I examine questions surrounding AI neutrality through the prism of existing literature and scholarship about mediation and media pluralism. Such traditions, I argue, provide a valuable theoretical framework for how we should approach the (likely) impending era of AI mediation. In particular, I suggest examining further the notion of algorithmic pluralism. Contrasting this notion to the dominant idea of algorithmic transparency, I seek to describe what algorithmic pluralism may be, and present both its opportunities and challenges. Implemented thoughtfully and responsibly, I argue, Algorithmic or AI pluralism has the potential to sustain the diversity, multiplicity, and inclusiveness that are so vital to democracy.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我探讨人工智能中立性的问题，通过现有的媒介和多元媒体学术研究。这些传统提供了valuable的理论框架，以便我们在（可能的）人工智能仲裁时期应对问题。特别是，我建议更深入研究算法多元主义。与算法透明度主义的主流想法相对，我想要描述算法多元主义是什么，并提出这种概念的机遇和挑战。如果想明智地和责任地实施，我认为算法或人工智能多元主义有potential sustain多样性、多元性和包容性，这些特质是民主的基础。
</details></li>
</ul>
<hr>
<h2 id="BrainWash-A-Poisoning-Attack-to-Forget-in-Continual-Learning"><a href="#BrainWash-A-Poisoning-Attack-to-Forget-in-Continual-Learning" class="headerlink" title="BrainWash: A Poisoning Attack to Forget in Continual Learning"></a>BrainWash: A Poisoning Attack to Forget in Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11995">http://arxiv.org/abs/2311.11995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Abbasi, Parsa Nooralinejad, Hamed Pirsiavash, Soheil Kolouri</li>
<li>for: 这篇研究旨在测试深度学习模型在继续学习中的攻击性，尤其是对于导致遗传的情况。</li>
<li>methods: 本研究提出了一种名为“BrainWash”的数据污染方法，用于强制深度学习模型忘记先前学习的任务。这种攻击方法不需要攻击者有previous任务的数据，只需要 possession of the model’s current parameters 和最新任务的数据即可。</li>
<li>results: 实验结果显示，BrainWash 方法可以对多种常用的定期学习方法进行成功攻击，导致模型的性能下降剧烈。<details>
<summary>Abstract</summary>
Continual learning has gained substantial attention within the deep learning community, offering promising solutions to the challenging problem of sequential learning. Yet, a largely unexplored facet of this paradigm is its susceptibility to adversarial attacks, especially with the aim of inducing forgetting. In this paper, we introduce "BrainWash," a novel data poisoning method tailored to impose forgetting on a continual learner. By adding the BrainWash noise to a variety of baselines, we demonstrate how a trained continual learner can be induced to forget its previously learned tasks catastrophically, even when using these continual learning baselines. An important feature of our approach is that the attacker requires no access to previous tasks' data and is armed merely with the model's current parameters and the data belonging to the most recent task. Our extensive experiments highlight the efficacy of BrainWash, showcasing degradation in performance across various regularization-based continual learning methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-Lip-Segmentation-Techniques-in-Computer-Vision-A-Comparative-Analysis"><a href="#Exploring-Lip-Segmentation-Techniques-in-Computer-Vision-A-Comparative-Analysis" class="headerlink" title="Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis"></a>Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11992">http://arxiv.org/abs/2311.11992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro B. S. Masur, Francisco Braulio Oliveira, Lucas Moreira Medino, Emanuel Huber, Milene Haraguchi Padilha, Cassio de Alcantara, Renata Sellaro</li>
<li>for: 这个研究的目的是对 lip segmentation 模型进行比较性评估，以找到最佳的模型。</li>
<li>methods: 这个研究使用了 five 种 lip segmentation 模型，包括 EHANet、Mask2Former、BiSeNet V2、PIDNet 和 STDC1。这些模型被选择基于其报告的性能、执行时间、代码可用性、新颖性和受欢迎度。</li>
<li>results: 研究发现，Mask2Former 和 EHANet 在 mIoU 分数上表现最佳，BiSeNet V2 表现稍差一些，而 PIDNet 在准确率方面表现出色，但精度较低。大多数模型在 Raspberry Pi4 上的执行时间在 1000-3000 毫秒之间，PIDNet 的平均执行时间最低。<details>
<summary>Abstract</summary>
Lip segmentation is crucial in computer vision, especially for lip reading. Despite extensive face segmentation research, lip segmentation has received limited attention. The aim of this study is to compare state-of-the-art lip segmentation models using a standardized setting and a publicly available dataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and STDC1, are qualitatively selected based on their reported performance, inference time, code availability, recency, and popularity. The CelebAMask-HQ dataset, comprising manually annotated face images, is used to fairly assess the lip segmentation performance of the selected models. Inference experiments are conducted on a Raspberry Pi4 to emulate limited computational resources. The results show that Mask2Former and EHANet have the best performances in terms of mIoU score. BiSeNet V2 demonstrate competitive performance, while PIDNet excels in recall but has lower precision. Most models present inference time ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with PIDNet having the lowest mean inference time. This study provides a comprehensive evaluation of lip segmentation models, highlighting their performance and inference times. The findings contribute to the development of lightweight techniques and establish benchmarks for future advances in lip segmentation, especially in IoT and edge computing scenarios.
</details>
<details>
<summary>摘要</summary>
lip 分割是计算机视觉中非常重要的一环，特别是 lip 读。Despite 广泛的面部分割研究，lip 分割却受到了有限的关注。本研究的目标是比较当前最佳的 lip 分割模型，使用标准化的设置和公共可用的数据集进行评估。五种技术，namely EHANet、Mask2Former、BiSeNet V2、PIDNet和STDC1，被选择基于其报道的性能、推理时间、代码可用性、新颖性和流行度。使用 CelebAMask-HQ 数据集，包含手动标注的 face 图像，对选择的模型进行公平的评估。在 Raspberry Pi4 上进行推理实验，以模拟有限的计算资源。结果显示，Mask2Former 和 EHANet 在 mIoU 分数上表现最佳，BiSeNet V2 表现稍逊一些，而 PIDNet 在准确率方面表现出色，但精度较低。大多数模型在 Raspberry Pi4 上的推理时间在 1000-3000 毫秒之间，PIDNet 的平均推理时间最低。本研究提供了 lip 分割模型的全面评估，揭示了它们的性能和推理时间。这些发现对于 lip 分割技术的发展，特别是在 IoT 和边缘计算方面，具有重要的意义。
</details></li>
</ul>
<hr>
<h2 id="Categorizing-the-Visual-Environment-and-Analyzing-the-Visual-Attention-of-Dogs"><a href="#Categorizing-the-Visual-Environment-and-Analyzing-the-Visual-Attention-of-Dogs" class="headerlink" title="Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs"></a>Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11988">http://arxiv.org/abs/2311.11988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shreyas Sundara Raman, Madeline H. Pelgrim, Daphna Buchsbaum, Thomas Serre</li>
<li>for: 这个论文的目的是研究狗的视觉行为和与物理世界的互动。</li>
<li>methods: 该论文使用了头戴式眼动跟踪设备收集和研究了11只狗在日常户外环境中 gaze 的数据，并使用了这些数据来微调MaskRCNN模型以自动分类狗的视觉定点。</li>
<li>results: 研究发现，狗寻找的对象主要包括汽车、植物、路面和建筑机器，并且发现了一些个体差异。这个研究为了解狗的视觉行为和与物理世界的互动提供了一个重要的步骤。<details>
<summary>Abstract</summary>
Dogs have a unique evolutionary relationship with humans and serve many important roles e.g. search and rescue, blind assistance, emotional support. However, few datasets exist to categorize visual features and objects available to dogs, as well as how dogs direct their visual attention within their environment. We collect and study a dataset with over 11,698 gazes to categorize the objects available to be gazed at by 11 dogs in everyday outdoor environments i.e. a walk around a college campus and urban area. We explore the availability of these object categories and the visual attention of dogs over these categories using a head mounted eye tracking apparatus. A small portion (approx. 600 images or < 20% of total dataset) of the collected data is used to fine tune a MaskRCNN for the novel image domain to segment objects present in the scene, enabling further statistical analysis on the visual gaze tendencies of dogs. The MaskRCNN, with eye tracking apparatus, serves as an end to end model for automatically classifying the visual fixations of dogs. The fine tuned MaskRCNN performs far better than chance. There are few individual differences between the 11 dogs and we observe greater visual fixations on buses, plants, pavement, and construction equipment. This work takes a step towards understanding visual behavior of dogs and their interaction with the physical world.
</details>
<details>
<summary>摘要</summary>
狗具有独特的进化关系与人类，扮演多种重要角色，如搜寻救援、导盲帮助和情感支持。然而，有少量的数据集存在以描述狗可以看到的视觉特征和物体，以及狗在环境中如何指向视觉注意力。我们收集和研究了一个数据集，包含11只狗在日常户外环境中（如大学校园和城市区）的11,698次视觉定位数据，以分类可见的物体类别。我们发现狗偏好注视汽车、植物、路面和建筑设备等物体类别，这些结果可能为狗的视觉行为和与物理世界的互动提供了新的理解。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Previous-Facial-Action-Units-Knowledge-for-Emotion-Recognition-on-Faces"><a href="#Leveraging-Previous-Facial-Action-Units-Knowledge-for-Emotion-Recognition-on-Faces" class="headerlink" title="Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces"></a>Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11980">http://arxiv.org/abs/2311.11980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro B. S. Masur, Willams Costa, Lucas S. Figueredo, Veronica Teichrieb</li>
<li>For: The paper aims to improve emotion recognition techniques using Facial Action Units (AUs) recognition.* Methods: The proposed method uses a machine learning system based on the Facial Action Coding System (FACS) to recognize emotions from facial expressions. The method builds upon and expands the existing EmotiRAM approach for multi-cue emotion recognition.* Results: The proposed method is expected to improve the accuracy of emotion recognition techniques by leveraging the information provided by Facial Action Units.<details>
<summary>Abstract</summary>
People naturally understand emotions, thus permitting a machine to do the same could open new paths for human-computer interaction. Facial expressions can be very useful for emotion recognition techniques, as these are the biggest transmitters of non-verbal cues capable of being correlated with emotions. Several techniques are based on Convolutional Neural Networks (CNNs) to extract information in a machine learning process. However, simple CNNs are not always sufficient to locate points of interest on the face that can be correlated with emotions. In this work, we intend to expand the capacity of emotion recognition techniques by proposing the usage of Facial Action Units (AUs) recognition techniques to recognize emotions. This recognition will be based on the Facial Action Coding System (FACS) and computed by a machine learning system. In particular, our method expands over EmotiRAM, an approach for multi-cue emotion recognition, in which we improve over their facial encoding module.
</details>
<details>
<summary>摘要</summary>
人们自然地理解情感，因此让机器也能够这样做可能会开启新的人机交互方式。脸部表达是情感识别技术中最大的非语言指示器，可以与情感相关。多种技术基于卷积神经网络（CNNs）来提取信息，但简单的CNNs不足以定位面部上的点点感兴趣，与情感相关。在这项工作中，我们计划通过使用表情动作单元（AU）识别技术来识别情感。这种识别基于人脸动作编码系统（FACS），由机器学习系统计算。具体来说，我们的方法超越EmotiRAM，一种多cue情感识别方法中的脸部编码模块。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Supervision-Levels-Trade-Offs-for-Infrared-Based-People-Counting"><a href="#Evaluating-Supervision-Levels-Trade-Offs-for-Infrared-Based-People-Counting" class="headerlink" title="Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting"></a>Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11974">http://arxiv.org/abs/2311.11974</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Latortue, Moetez Kdayem, Fidel A Guerrero Peña, Eric Granger, Marco Pedersoli</li>
<li>for: 人数计算（人肉定位）在多个应用中广泛使用，但需要贵重的 bounding box 注释数据进行训练。为保持隐私，这些模型越来越依赖于红外图像，这使得任务变得更加困难。</li>
<li>methods: 我们使用深度人数计算建筑物模型进行图像分类和点级定位。我们的实验表明，使用 CNN 图像级模型可以达到与 YOLO 检测器和点级模型相当的性能，但具有更高的帧率和相似的模型参数。</li>
<li>results: 我们的实验结果表明，使用 CNN 图像级模型可以达到与 YOLO 检测器和点级模型相当的性能，但具有更高的帧率和相似的模型参数。<details>
<summary>Abstract</summary>
Object detection models are commonly used for people counting (and localization) in many applications but require a dataset with costly bounding box annotations for training. Given the importance of privacy in people counting, these models rely more and more on infrared images, making the task even harder. In this paper, we explore how weaker levels of supervision can affect the performance of deep person counting architectures for image classification and point-level localization. Our experiments indicate that counting people using a CNN Image-Level model achieves competitive results with YOLO detectors and point-level models, yet provides a higher frame rate and a similar amount of model parameters.
</details>
<details>
<summary>摘要</summary>
人数检测模型通常用于人数统计（和位置确定）在许多应用中，但需要费时的 bounding box 注释 для训练。由于人数统计中的隐私很重要，这些模型越来越依赖于红外图像，使得任务变得更加困难。在这篇论文中，我们探讨弱级超级vision对深度人数计算机 arquitectures 的影响。我们的实验结果表明，使用 CNN 图像级模型进行人数统计可以与 YOLO 探测器和点级模型具有竞争力，同时提供更高的帧率和相似的模型参数。
</details></li>
</ul>
<hr>
<h2 id="NNG-Mix-Improving-Semi-supervised-Anomaly-Detection-with-Pseudo-anomaly-Generation"><a href="#NNG-Mix-Improving-Semi-supervised-Anomaly-Detection-with-Pseudo-anomaly-Generation" class="headerlink" title="NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation"></a>NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11961">http://arxiv.org/abs/2311.11961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/donghao51/nng-mix">https://github.com/donghao51/nng-mix</a></li>
<li>paper_authors: Hao Dong, Gaëtan Frusque, Yue Zhao, Eleni Chatzi, Olga Fink</li>
<li>for: 本研究旨在提出一种新的数据增强算法，用于增加异常样本数量，以提高异常检测性能。</li>
<li>methods: 该算法基于 nearest neighbor Gaussian mixture 的思想，能够充分利用限量的异常样本和大量的无标注数据信息，生成更多的异常样本。</li>
<li>results: 对于57个 benchmark 数据集，比较了不同的数据增强方法，发现 NNG-Mix 方法可以提高异常检测性能，相比基eline 提高了16.4%、8.8% 和8.0%。<details>
<summary>Abstract</summary>
Anomaly detection (AD) is essential in identifying rare and often critical events in complex systems, finding applications in fields such as network intrusion detection, financial fraud detection, and fault detection in infrastructure and industrial systems. While AD is typically treated as an unsupervised learning task due to the high cost of label annotation, it is more practical to assume access to a small set of labeled anomaly samples from domain experts, as is the case for semi-supervised anomaly detection. Semi-supervised and supervised approaches can leverage such labeled data, resulting in improved performance. In this paper, rather than proposing a new semi-supervised or supervised approach for AD, we introduce a novel algorithm for generating additional pseudo-anomalies on the basis of the limited labeled anomalies and a large volume of unlabeled data. This serves as an augmentation to facilitate the detection of new anomalies. Our proposed algorithm, named Nearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information from both labeled and unlabeled data to generate pseudo-anomalies. We compare the performance of this novel algorithm with commonly applied augmentation techniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various existing semi-supervised and supervised anomaly detection algorithms on the original training data along with the generated pseudo-anomalies. Through extensive experiments on 57 benchmark datasets in ADBench, reflecting different data types, we demonstrate that NNG-Mix outperforms other data augmentation methods. It yields significant performance improvements compared to the baselines trained exclusively on the original training data. Notably, NNG-Mix yields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP datasets in ADBench. Our source code will be available at https://github.com/donghao51/NNG-Mix.
</details>
<details>
<summary>摘要</summary>
《异常检测（AD）是在复杂系统中发现罕见和critical事件的 essencial 任务，应用于网络侵入检测、金融诈骗检测和基础设施和工业系统的故障检测等领域。由于AD通常被视为无监督学习任务，因此在实际应用中通常只有限量的标注异常样本可以获得。在本文中，而不是提出一种新的半监督或监督学习方法，我们介绍了一种新的算法，可以生成基于有限的标注异常样本和大量的无标注数据的 Pseudo-异常。这种方法被称为 Nearest Neighbor Gaussian Mixup（NNG-Mix）。NNG-Mix 有效地利用了标注和无标注数据的信息，生成 Pseudo-异常。我们与常见的 Mixup 和 Cutout 等数据增强技术进行比较，通过在原始训练数据上训练不同的半监督和监督学习算法，评估 NNG-Mix 的性能。我们在 ADBench 上的 57 个标准 benchmark 上进行了广泛的实验，发现 NNG-Mix 在不同的数据类型上达到了显著的性能改进。它与基准值相比，在 Classical、CV 和 NLP 等类型上提高了16.4%、8.8% 和 8.0%。我们将源代码发布在 GitHub 上，地址为 <https://github.com/donghao51/NNG-Mix>。
</details></li>
</ul>
<hr>
<h2 id="Correlated-Attention-in-Transformers-for-Multivariate-Time-Series"><a href="#Correlated-Attention-in-Transformers-for-Multivariate-Time-Series" class="headerlink" title="Correlated Attention in Transformers for Multivariate Time Series"></a>Correlated Attention in Transformers for Multivariate Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11959">http://arxiv.org/abs/2311.11959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quang Minh Nguyen, Lam M. Nguyen, Subhro Das</li>
<li>for: 本研究旨在提出一种新的相关注意机制，以提高基于Transformer的多变量时间序列（MTS）分析模型的表现。</li>
<li>methods: 该机制可以快速发现时间序列中的相关性，同时可以在不同特征通道之间进行相关性捕捉，从而更好地捕捉复杂的动力系统中的相关性。</li>
<li>results: 对于各种任务，包括填充、异常检测和分类，与基于Transformer的基本模型相比，具有相关注意机制的模型显示出了明显的优势，并在实验中取得了领先的 результаados。<details>
<summary>Abstract</summary>
Multivariate time series (MTS) analysis prevails in real-world applications such as finance, climate science and healthcare. The various self-attention mechanisms, the backbone of the state-of-the-art Transformer-based models, efficiently discover the temporal dependencies, yet cannot well capture the intricate cross-correlation between different features of MTS data, which inherently stems from complex dynamical systems in practice. To this end, we propose a novel correlated attention mechanism, which not only efficiently captures feature-wise dependencies, but can also be seamlessly integrated within the encoder blocks of existing well-known Transformers to gain efficiency improvement. In particular, correlated attention operates across feature channels to compute cross-covariance matrices between queries and keys with different lag values, and selectively aggregate representations at the sub-series level. This architecture facilitates automated discovery and representation learning of not only instantaneous but also lagged cross-correlations, while inherently capturing time series auto-correlation. When combined with prevalent Transformer baselines, correlated attention mechanism constitutes a better alternative for encoder-only architectures, which are suitable for a wide range of tasks including imputation, anomaly detection and classification. Extensive experiments on the aforementioned tasks consistently underscore the advantages of correlated attention mechanism in enhancing base Transformer models, and demonstrate our state-of-the-art results in imputation, anomaly detection and classification.
</details>
<details>
<summary>摘要</summary>
多变量时间序列（MTS）分析在现实应用中广泛存在，如金融、气候科学和医疗保健等领域。各种自我注意机制，现代Transformer模型的基础，能够高效发现时间相关性，但是无法好地捕捉MTS数据中不同特征之间的复杂相关性，这种相关性源于实际的复杂动态系统。为此，我们提出了一种新的相关注意机制，不仅可以高效捕捉特征wise相关性，还可以轻松地与现有的Transformer模型集成，以提高效率。具体来说，相关注意机制在特征通道之间计算特征Query和特征Key的差值 Matrix，并选择ively归一化特征表示。这种架构可以自动发现和学习特征wise相关性，以及延迟相关性，同时自然地捕捉时间序列自相关。当与常见Transformer基eline结合使用时，相关注意机制组成了更好的encoder-only架构，适用于许多任务，如缺失值估计、异常检测和分类。我们在这些任务上进行了广泛的实验，并 consistently demonstrates the advantages of our proposed mechanism in enhancing base Transformer models, and achieves state-of-the-art results in imputation, anomaly detection and classification.
</details></li>
</ul>
<hr>
<h2 id="FinanceBench-A-New-Benchmark-for-Financial-Question-Answering"><a href="#FinanceBench-A-New-Benchmark-for-Financial-Question-Answering" class="headerlink" title="FinanceBench: A New Benchmark for Financial Question Answering"></a>FinanceBench: A New Benchmark for Financial Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11944">http://arxiv.org/abs/2311.11944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, Bertie Vidgen</li>
<li>for: The paper is written to evaluate the performance of large language models (LLMs) on open book financial question answering (QA).</li>
<li>methods: The paper uses a test suite called FinanceBench, which consists of 10,231 questions about publicly traded companies, to evaluate the performance of 16 state-of-the-art LLM configurations. The authors manually review the answers to the questions (n&#x3D;2,400) and find that existing LLMs have clear limitations for financial QA.</li>
<li>results: The paper shows that existing LLMs have weaknesses such as hallucinations that limit their suitability for use by enterprises. Specifically, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81% of questions, and augmentation techniques such as using longer context windows to feed in relevant evidence improve performance but are unrealistic for enterprise settings due to increased latency.<details>
<summary>Abstract</summary>
FinanceBench is a first-of-its-kind test suite for evaluating the performance of LLMs on open book financial question answering (QA). It comprises 10,231 questions about publicly traded companies, with corresponding answers and evidence strings. The questions in FinanceBench are ecologically valid and cover a diverse set of scenarios. They are intended to be clear-cut and straightforward to answer to serve as a minimum performance standard. We test 16 state of the art model configurations (including GPT-4-Turbo, Llama2 and Claude2, with vector stores and long context prompts) on a sample of 150 cases from FinanceBench, and manually review their answers (n=2,400). The cases are available open-source. We show that existing LLMs have clear limitations for financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81% of questions. While augmentation techniques such as using longer context window to feed in relevant evidence improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. We find that all models examined exhibit weaknesses, such as hallucinations, that limit their suitability for use by enterprises.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Ovarian-Cancer-Data-Analysis-using-Deep-Learning-A-Systematic-Review-from-the-Perspectives-of-Key-Features-of-Data-Analysis-and-AI-Assurance"><a href="#Ovarian-Cancer-Data-Analysis-using-Deep-Learning-A-Systematic-Review-from-the-Perspectives-of-Key-Features-of-Data-Analysis-and-AI-Assurance" class="headerlink" title="Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance"></a>Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11932">http://arxiv.org/abs/2311.11932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker</li>
<li>For: The paper is written to provide a systematic review of deep learning (DL)-driven ovarian cancer data analysis, specifically focusing on the key features and AI assurance (AIA) perspectives.* Methods: The study uses the PRISMA framework to conduct comprehensive searches in three journal databases, including only peer-reviewed studies published between 2015 and 2023.* Results: The review finds that most studies (71%) focus on detection and diagnosis, with a limited number of studies (33%) performing integrated analyses and only 8.3% validating their models using external and diverse data sets. Additionally, the inclusion of AIA in cancer data analysis is in a very early stage, with only 2.1% of the studies explicitly addressing explainability.Here’s the information in Simplified Chinese text:* For: 这篇论文是为了提供一种系统性的检查，以便了解抑血癌数据分析中使用深度学习（DL）的特点和人工智能保障（AIA）的视角。* Methods: 这篇论文使用PRISMA框架进行了三个期刊数据库的全面搜索，仅包括在2015年至2023年间发表的同行评审论文。* Results: 这篇论文发现，大多数研究（71%）是关于抑血癌检测和诊断，而很少有研究（33%）进行了集成分析，而且只有8.3%的研究使用了外部和多样化数据集进行验证。此外，抑血癌数据分析中的AIA还处于非常早期的阶段，只有2.1%的研究直接地考虑了解释性。<details>
<summary>Abstract</summary>
Background and objectives: By extracting this information, Machine or Deep Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and cancer researchers in discovering patterns and relationships from complex data sets. Many DL-based analyses on ovarian cancer (OC) data have recently been published. These analyses are highly diverse in various aspects of cancer (e.g., subdomain(s) and cancer type they address) and data analysis features. However, a comprehensive understanding of these analyses in terms of these features and AI assurance (AIA) is currently lacking. This systematic review aims to fill this gap by examining the existing literature and identifying important aspects of OC data analysis using DL, explicitly focusing on the key features and AI assurance perspectives. Methods: The PRISMA framework was used to conduct comprehensive searches in three journal databases. Only studies published between 2015 and 2023 in peer-reviewed journals were included in the analysis. Results: In the review, a total of 96 DL-driven analyses were examined. The findings reveal several important insights regarding DL-driven ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on detection and diagnosis, while no study addressed the prediction and prevention of OC. - The analyses were predominantly based on samples from a non-diverse population (75% (72/96 studies)), limited to a geographic location or country. - Only a small proportion of studies (only 33% (32/96)) performed integrated analyses, most of which used homogeneous data (clinical or omics). - Notably, a mere 8.3% (8/96) of the studies validated their models using external and diverse data sets, highlighting the need for enhanced model validation, and - The inclusion of AIA in cancer data analysis is in a very early stage; only 2.1% (2/96) explicitly addressed AIA through explainability.
</details>
<details>
<summary>摘要</summary>
背景和目标：通过提取这些信息，机器学习或深度学习（ML/DL）基于自动化数据分析工具可以帮助医生和癌症研究人员发现复杂数据集中的模式和关系。最近几年，在卵巢癌（OC）数据上进行了许多DL驱动的分析。这些分析方法非常多样化，包括不同的抑战域和癌症类型。但是，对这些分析方法的全面理解，特别是关键特征和人工智能确保（AI安全）的视角，目前缺乏一个系统性的回顾。这项系统性综述的目的是填补这一空白，通过检查现有文献，找到OC数据分析中DL驱动的重要方面和AI安全方面的关键特征。方法：根据PRISMA框架，在三个期刊库进行了全面的检索。只有2015年至2023年间在 peer-reviewed 期刊上发表的研究被包括在分析中。结果：在这些分析中，总共有96个DL驱动的分析被评估。结果显示，OC数据分析中DL驱动的一些重要发现：①大多数研究（71%，68/96）集中于检测和诊断，而没有一个研究关于预测和预防OC。②大多数分析（75%，72/96）基于非多样化的样本（75%，72/96），受限于特定的地理位置或国家。③只有一小部分研究（33%，32/96）进行了集成分析，大多数使用同种数据（临床或omiCS）。④备注的是，只有8.3%（8/96）的研究使用了外部和多样化的数据集进行验证，显示了模型验证的需求。⑤只有2.1%（2/96）的研究直接地考虑了AI安全，通过解释性来实现。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-Fitness-Exercise-Recognition-from-Doppler-Measurements-by-Domain-adaption-and-Few-Shot-Learning"><a href="#Generalization-of-Fitness-Exercise-Recognition-from-Doppler-Measurements-by-Domain-adaption-and-Few-Shot-Learning" class="headerlink" title="Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning"></a>Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11910">http://arxiv.org/abs/2311.11910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biying Fu, Naser Damer, Florian Kirchbuchner, Arjan Kuijper</li>
<li>for: 本研究旨在提高用于识别全身运动的移动应用程序的性能。</li>
<li>methods: 本研究使用了改进后的商业Off-the-shelf智能手机，以及基于ultrasound Doppler探测的方法。</li>
<li>results: 研究发现，通过使用小量适应数据来改进模型泛化性能，可以提高识别精度，比基eline高两至六倍。<details>
<summary>Abstract</summary>
In previous works, a mobile application was developed using an unmodified commercial off-the-shelf smartphone to recognize whole-body exercises. The working principle was based on the ultrasound Doppler sensing with the device built-in hardware. Applying such a lab-environment trained model on realistic application variations causes a significant drop in performance, and thus decimate its applicability. The reason of the reduced performance can be manifold. It could be induced by the user, environment, and device variations in realistic scenarios. Such scenarios are often more complex and diverse, which can be challenging to anticipate in the initial training data. To study and overcome this issue, this paper presents a database with controlled and uncontrolled subsets of fitness exercises. We propose two concepts to utilize small adaption data to successfully improve model generalization in an uncontrolled environment, increasing the recognition accuracy by two to six folds compared to the baseline for different users.
</details>
<details>
<summary>摘要</summary>
在前一些研究中，我们已经开发了一款基于商业市场上可获得的不改进的智能手机应用程序，用于识别全身运动。工作原理基于 Ultrasound Doppler 探测设备自带的硬件。在实际应用中，使用室内环境训练的模型对实际应用变化会导致性能下降，从而减少其实用性。这种下降的原因可能是用户、环境和设备变化的结合影响，这些变化在实际场景中是复杂多样的，难以预测在初始训练数据中。为了研究和解决这个问题，本文提出了一个包含控制和无控制subset的健身动作数据库。我们提出了两种概念，使用小数据适应来成功提高模型在无控制环境中的泛化性，对不同用户的识别精度提高2-6倍 compare to基准值。
</details></li>
</ul>
<hr>
<h2 id="Continual-Learning-Applications-and-the-Road-Forward"><a href="#Continual-Learning-Applications-and-the-Road-Forward" class="headerlink" title="Continual Learning: Applications and the Road Forward"></a>Continual Learning: Applications and the Road Forward</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11908">http://arxiv.org/abs/2311.11908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eli Verwimp, Shai Ben-David, Matthias Bethge, Andrea Cossu, Alexander Gepperth, Tyler L. Hayes, Eyke Hüllermeier, Christopher Kanan, Dhireesha Kudithipudi, Christoph H. Lampert, Martin Mundt, Razvan Pascanu, Adrian Popescu, Andreas S. Tolias, Joost van de Weijer, Bing Liu, Vincenzo Lomonaco, Tinne Tuytelaars, Gido M. van de Ven</li>
<li>for: 本文探讨了机器学习领域中的连续学习，并问道：为什么应该关注连续学习？作者通过对最新的连续学习论文进行抽样，发现了许多报告中的设置受到内存约束的限制。然后，作者讨论了五个开放问题，包括模型编辑、个性化、在设备上学习、快速（重）训练和奖励学习。作者表明，连续学习将是这些问题的一部分解决方案。</li>
<li>methods: 本文不提供实际方法，而是通过对现有研究进行抽样和讨论，探讨了连续学习的未来发展趋势和挑战。</li>
<li>results: 本文未提供实际结果，而是通过对现有研究进行抽样和讨论，探讨了连续学习的未来发展趋势和挑战。<details>
<summary>Abstract</summary>
Continual learning is a sub-field of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: "Why should one care about continual learning in the first place?". We set the stage by surveying recent continual learning papers published at three major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model-editing, personalization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.
</details>
<details>
<summary>摘要</summary>
（简体中文）continuous learning是机器学习的一个子领域，旨在让机器学习模型在新数据上不断学习，而不会忘记过去学习的知识。在这篇文章中，我们做了一个总结，并问：“为什么应该关注持续学习呢？”。我们在三个主要的机器学习会议上发表的最近的持续学习论文中进行了调查，发现内存限制是领域的主导。然后，我们讨论了五个机器学习中的开放问题，尽管这些问题初始看起来与持续学习没有直接关系，但我们表明持续学习是它们的解决方案的一部分。这些问题包括模型编辑、个性化、在设备上学习、更快的重新训练和奖励学习。最后，我们比较了这些未解决的问题的需求和当前持续学习中的假设，并讨论了四个未来持续学习研究的方向。我们希望这篇文章可以提供一个有趣的未来持续学习的视角，同时展示其潜在价值和我们需要追求的道路，以便它成功。这篇文章是在2023年3月的达斯图尔学术会议上的讨论的结果。
</details></li>
</ul>
<hr>
<h2 id="Towards-Exploratory-Reformulation-of-Constraint-Models"><a href="#Towards-Exploratory-Reformulation-of-Constraint-Models" class="headerlink" title="Towards Exploratory Reformulation of Constraint Models"></a>Towards Exploratory Reformulation of Constraint Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11868">http://arxiv.org/abs/2311.11868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ian Miguel, András Z. Salamon, Christopher Stone</li>
<li>for:  solves the problem of choosing the best model for a given problem class</li>
<li>methods:  uses a process of reformulation guided by performance on training instances</li>
<li>results:  explores the space of models to find the best one for the problem at hand<details>
<summary>Abstract</summary>
It is well established that formulating an effective constraint model of a problem of interest is crucial to the efficiency with which it can subsequently be solved. Following from the observation that it is difficult, if not impossible, to know a priori which of a set of candidate models will perform best in practice, we envisage a system that explores the space of models through a process of reformulation from an initial model, guided by performance on a set of training instances from the problem class under consideration. We plan to situate this system in a refinement-based approach, where a user writes a constraint specification describing a problem above the level of abstraction at which many modelling decisions are made. In this position paper we set out our plan for an exploratory reformulation system, and discuss progress made so far.
</details>
<details>
<summary>摘要</summary>
“已经有许多研究表明，实现问题的有效约束模型是解决问题的重要前提。由于不知道哪一个候选模型会在实际中表现最好，因此我们预见一个能够在模型的空间进行探索，并且受到问题类型的训练实例指导。我们打算将这个系统设计为一个修复基础的方法，让用户在高抽象层级上撰写约束规定，描述问题。在这个位置论文中，我们愿意说明我们的实验修复系统计划，并讨论到目前已经做出了多少进展。”Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Emissions-and-Energy-Efficiency-in-Mixed-Traffic-Control-at-Unsignalized-Intersections"><a href="#Analyzing-Emissions-and-Energy-Efficiency-in-Mixed-Traffic-Control-at-Unsignalized-Intersections" class="headerlink" title="Analyzing Emissions and Energy Efficiency in Mixed Traffic Control at Unsignalized Intersections"></a>Analyzing Emissions and Energy Efficiency in Mixed Traffic Control at Unsignalized Intersections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11866">http://arxiv.org/abs/2311.11866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Villarreal, Dawei Wang, Jia Pan, Weizi Li</li>
<li>For: 降低交通相关排放，减少交通堵塞和等待时间。* Methods: 使用混合交通控制策略， robot车（RV）在拥堵交叉口实施排气控制策略，提高沟通效率和减少排放。* Results: RVs 在至少10%的推动率下，可以降低燃料消耗和NOx排放，相比Signalized intersections下降低至27%和28%。同时，RVs 在至少30%的推动率下，可以降低CO和HC排放，相比Signalized intersections下降低至42%和43%。此外，RVs 可以降低整个网络的排放，只要在交叉口使用其策略。<details>
<summary>Abstract</summary>
Greenhouse gas emissions have dramatically risen since the early 1900s with U.S. transportation generating 28% of the U.S' emissions. As such, there is interest in reducing transportation-related emissions. Specifically, sustainability research has sprouted around signalized intersections as intersections allow different streams of traffic to cross and change directions. Recent research has developed mixed traffic control eco-driving strategies at signalized intersections to decrease emissions. However, the inherent structure of a signalized intersection generates increased emissions by creating frequent acceleration/deceleration events, excessive idling from traffic congestion, and stop-and-go waves. Thus, we believe unsignalized intersections hold potential for further sustainability improvements. In this work, we provide an emissions analysis on unsignalized intersections with complex, real-world topologies and traffic demands where mixed traffic control strategies are employed by robot vehicles (RVs) to reduce waiting times and congestion. We find with at least 10% RV penetration rate, RVs generate less fuel consumption and NOx emissions than signalized intersections by up to 27% and 28%, respectively. With at least 30% RVs, CO and HC emissions are reduced by up to 42% and 43%, respectively. Additionally, RVs can reduce emissions across the whole network despite only employing their strategies at the intersections.
</details>
<details>
<summary>摘要</summary>
美国交通运输中气候排放量自20世纪初期以来呈指数增长趋势，美国交通运输占总排放量的28%。为了降低交通相关排放量，可持续发展研究在信号交叉口方面进行了广泛的研究。特别是在信号交叉口处，有许多可持续发展的混合交通控制策略得到了应用。然而，信号交叉口的本质结构会产生频繁加速/减速事件、交通堵塞导致的辅助机器过度停靠和停靠波。因此，我们认为不信号交叉口具有更好的可持续发展潜力。在这项工作中，我们对无信号交叉口进行了排放分析，使用机器人车（RV）实施混合交通控制策略，以降低等待时间和堵塞。我们发现，在至少10%的RV涵盖率下，RV会比信号交叉口减少燃料消耗和NOx排放达27%和28%，分别。在至少30%的RV涵盖率下，CO和HC排放量减少至42%和43%，分别。此外，RV可以在整个网络中减少排放，即使只在交叉口处应用其策略。
</details></li>
</ul>
<hr>
<h2 id="Establishing-Central-Sensitization-Inventory-Cut-off-Values-in-patients-with-Chronic-Low-Back-Pain-by-Unsupervised-Machine-Learning"><a href="#Establishing-Central-Sensitization-Inventory-Cut-off-Values-in-patients-with-Chronic-Low-Back-Pain-by-Unsupervised-Machine-Learning" class="headerlink" title="Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning"></a>Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11862">http://arxiv.org/abs/2311.11862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xzheng93/csi_cutoff_establishment">https://github.com/xzheng93/csi_cutoff_establishment</a></li>
<li>paper_authors: Xiaoping Zheng, Claudine JC Lamoth, Hans Timmerman, Ebert Otten, Michiel F Reneman</li>
<li>For: 本研究旨在确定chronic low back pain (CLBP) patient中中枢敏感性（HACS）的分化点，考虑到痛情（如CLBP）和性别因素。* Methods: 研究使用无监督归类方法来自动发现HACS相关的模式，并评估了归类性能。接着，使用征 receive operator characteristic 分析来确定最佳分化点。* Results: 研究包括151名参与者，其中63名健康控制者和88名CLBP患者。层次归类方法获得最佳结果，将患者分为三个群：健康组、CLBP with low HACS level组和CLBP with high HACS level组。对于总体分化点，结果表明CLBP的最佳分化点为35。对于性别因素，女性的分化点为34，而男性的分化点为35。<details>
<summary>Abstract</summary>
Human Assumed Central Sensitization is involved in the development and maintenance of chronic low back pain (CLBP). The Central Sensitization Inventory (CSI) was developed to evaluate the presence of HACS, with a cut-off value of 40/100 based on patients with chronic pain. However, various factors including pain conditions (e.g., CLBP), and gender may influence this cut-off value. For chronic pain condition such as CLBP, unsupervised clustering approaches can take these factors into consideration and automatically learn the HACS-related patterns. Therefore, this study aimed to determine the cut-off values for a Dutch-speaking population with CLBP, considering the total group and stratified by gender based on unsupervised machine learning. In this study, questionnaire data covering pain, physical, and psychological aspects were collected from patients with CLBP and aged-matched pain-free adults (referred to as healthy controls, HC). Four clustering approaches were applied to identify HACS-related clusters based on the questionnaire data and gender. The clustering performance was assessed using internal and external indicators. Subsequently, receiver operating characteristic analysis was conducted on the best clustering results to determine the optimal cut-off values. The study included 151 subjects, consisting of 63 HCs and 88 patients with CLBP. Hierarchical clustering yielded the best results, identifying three clusters: healthy group, CLBP with low HACS level, and CLBP with high HACS level groups. Based on the low HACS levels group (including HC and CLBP with low HACS level) and high HACS level group, the cut-off value for the overall groups were 35, 34 for females, and 35 for. The findings suggest that the optimal cut-off values for CLBP is 35. The gender-related cut-off values should be interpreted with caution due to the unbalanced gender distribution in the sample.
</details>
<details>
<summary>摘要</summary>
人类假设中央敏感性（HACS）参与了慢性低脊梁痛（CLBP）的发展和维持。中央敏感性评价器（CSI）是用来评估HACS的存在，其分割值为40/100，基于患有慢性疼痛的患者。然而，不同的因素，包括疼痛情况（如CLBP）和性别可能影响这个分割值。为了慢性疼痛状况如CLBP，无监督聚类方法可以考虑这些因素并自动发现HACS相关的模式。因此，本研究的目的是确定慢性低脊梁痛患者的分割值，考虑总体群体和按性别分类。在本研究中，问卷调查评估疼痛、物理和心理方面，收集了患有CLBP的病人和年龄匹配的疼痛自适应者（HC）的数据。四种聚类方法被应用来确定HACS相关的聚类，以及性别基础的分割值。聚类性能被评估使用内部和外部指标。随后，基于最佳聚类结果，进行了征 Receiver Operating Characteristic（ROC）分析，以确定最佳分割值。研究包括151名参与者，其中63名HC和88名CLBP患者。幂等聚类方法得到最佳结果，并将患者分为三个群体：健康组、CLBP低HACS水平组和CLBP高HACS水平组。基于低HACS水平组（包括HC和CLBP低HACS水平）和高HACS水平组的分割值为35，34 для女性，和35。这些结果表明，CLBP的最佳分割值为35。性别基础的分割值应该被解释以及谨慎，由于样本中性别分布不均衡。
</details></li>
</ul>
<hr>
<h2 id="Generating-Valid-and-Natural-Adversarial-Examples-with-Large-Language-Models"><a href="#Generating-Valid-and-Natural-Adversarial-Examples-with-Large-Language-Models" class="headerlink" title="Generating Valid and Natural Adversarial Examples with Large Language Models"></a>Generating Valid and Natural Adversarial Examples with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11861">http://arxiv.org/abs/2311.11861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen</li>
<li>for: 本研究旨在提出一种基于大语言模型（LLM）的语言processing（NLP）攻击模型，以提高攻击效果和自然性。</li>
<li>methods: 该模型采用两个阶段：首先，使用word importance ranking来找到最容易攻击的单词；然后，使用word synonym replacement来替换这些单词。</li>
<li>results: 对于Movie Review（MR）、IMDB和Yelp Review Polarity datasets，LLM-Attack模型比基eline adversarial attack模型表现出色，在人工和GPT-4评估中也具有显著的优势。模型可以生成自然和有效的攻击示例，保留 semantic meaning、grammaticality和人类隐身性。<details>
<summary>Abstract</summary>
Deep learning-based natural language processing (NLP) models, particularly pre-trained language models (PLMs), have been revealed to be vulnerable to adversarial attacks. However, the adversarial examples generated by many mainstream word-level adversarial attack models are neither valid nor natural, leading to the loss of semantic maintenance, grammaticality, and human imperceptibility. Based on the exceptional capacity of language understanding and generation of large language models (LLMs), we propose LLM-Attack, which aims at generating both valid and natural adversarial examples with LLMs. The method consists of two stages: word importance ranking (which searches for the most vulnerable words) and word synonym replacement (which substitutes them with their synonyms obtained from LLMs). Experimental results on the Movie Review (MR), IMDB, and Yelp Review Polarity datasets against the baseline adversarial attack models illustrate the effectiveness of LLM-Attack, and it outperforms the baselines in human and GPT-4 evaluation by a significant margin. The model can generate adversarial examples that are typically valid and natural, with the preservation of semantic meaning, grammaticality, and human imperceptibility.
</details>
<details>
<summary>摘要</summary>
深度学习基本的自然语言处理（NLP）模型，特别是预训练语言模型（PLM），已经被发现容易受到攻击。然而，由多种主流单词级 adversarial attack 模型生成的攻击示例通常并不是有效的，会导致语义维护、 grammaticality 和人类隐蔽性的损失。基于大语言模型（LLM）的异常容量，我们提出了 LLM-Attack，该方法的目标是使用 LLM 生成有效和自然的攻击示例。该方法包括两个阶段：单词重要性排名（搜索最容易攻击的单词）和单词同义补充（使用 LLM 生成的单词同义词替换）。实验结果表明，LLM-Attack 在 MR、IMDB 和 Yelp Review Polarity 数据集上比基线攻击模型更有效，在人类和 GPT-4 评估中也以显著的差距超过了基eline。模型可以生成有效和自然的攻击示例，保留语义意义、 grammaticality 和人类隐蔽性。
</details></li>
</ul>
<hr>
<h2 id="Kandinsky-Conformal-Prediction-Efficient-Calibration-of-Image-Segmentation-Algorithms"><a href="#Kandinsky-Conformal-Prediction-Efficient-Calibration-of-Image-Segmentation-Algorithms" class="headerlink" title="Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms"></a>Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11837">http://arxiv.org/abs/2311.11837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joren Brunekreef, Eric Marcus, Ray Sheombarsing, Jan-Jakob Sonke, Jonas Teuwen</li>
<li>for: 这个论文的目的是提出一种名为“卡任尼基 calibration”的新的核心点采样方法，用于在有限的数据情况下进行像素级准确性评估。</li>
<li>methods: 该方法使用自然图像的空间结构，同时对“相似”的像素进行准确性评估，从而更好地利用可用的数据进行准确性评估。</li>
<li>results: 实验表明，使用“卡任尼基 calibration”方法可以显著改善图像分割算法的覆盖率，并且与像素级和图像级准确性评估相比，该方法的覆盖率错误较低， indicating that the method is effective in low-data scenarios.<details>
<summary>Abstract</summary>
Image segmentation algorithms can be understood as a collection of pixel classifiers, for which the outcomes of nearby pixels are correlated. Classifier models can be calibrated using Inductive Conformal Prediction, but this requires holding back a sufficiently large calibration dataset for computing the distribution of non-conformity scores of the model's predictions. If one only requires only marginal calibration on the image level, this calibration set consists of all individual pixels in the images available for calibration. However, if the goal is to attain proper calibration for each individual pixel classifier, the calibration set consists of individual images. In a scenario where data are scarce (such as the medical domain), it may not always be possible to set aside sufficiently many images for this pixel-level calibration. The method we propose, dubbed ``Kandinsky calibration'', makes use of the spatial structure present in the distribution of natural images to simultaneously calibrate the classifiers of ``similar'' pixels. This can be seen as an intermediate approach between marginal (imagewise) and conditional (pixelwise) calibration, where non-conformity scores are aggregated over similar image regions, thereby making more efficient use of the images available for calibration. We run experiments on segmentation algorithms trained and calibrated on subsets of the public MS-COCO and Medical Decathlon datasets, demonstrating that Kandinsky calibration method can significantly improve the coverage. When compared to both pixelwise and imagewise calibration on little data, the Kandinsky method achieves much lower coverage errors, indicating the data efficiency of the Kandinsky calibration.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="System-2-Attention-is-something-you-might-need-too"><a href="#System-2-Attention-is-something-you-might-need-too" class="headerlink" title="System 2 Attention (is something you might need too)"></a>System 2 Attention (is something you might need too)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11829">http://arxiv.org/abs/2311.11829</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danderfer/Comp_Sci_Sem_2">https://github.com/danderfer/Comp_Sci_Sem_2</a></li>
<li>paper_authors: Jason Weston, Sainbayar Sukhbaatar</li>
<li>for: 提高 transformer 基于语言模型（LLM）中的软注意力，以减少在下一个 token 生成时 incorporate 不相关信息。</li>
<li>methods: 引入 System 2 Attention（S2A），利用 LLM 理解自然语言并遵循指令，决定要注意的内容。 S2A 首先重新生成输入Context，并在重新生成的 Context 上进行注意力。</li>
<li>results: S2A 在三种任务中（包括问答、数学问题和长文生成）表现出色，与标准注意力基于 LLM 相比，增加了事实和公正性，而减少了偏袋。<details>
<summary>Abstract</summary>
Soft attention in Transformer-based Large Language Models (LLMs) is susceptible to incorporating irrelevant information from the context into its latent representations, which adversely affects next token generations. To help rectify these issues, we introduce System 2 Attention (S2A), which leverages the ability of LLMs to reason in natural language and follow instructions in order to decide what to attend to. S2A regenerates the input context to only include the relevant portions, before attending to the regenerated context to elicit the final response. In experiments, S2A outperforms standard attention-based LLMs on three tasks containing opinion or irrelevant information, QA, math word problems and longform generation, where S2A increases factuality and objectivity, and decreases sycophancy.
</details>
<details>
<summary>摘要</summary>
含有强制注意力的转换器基于大语言模型（LLM）容易吸收上下文中不相关的信息，这会对下一个 Token 生成产生负面影响。为了解决这些问题，我们介绍 System 2 Attention（S2A），它利用 LLM 的自然语言理解能力和遵从指令来决定需要注意的内容。S2A 将输入上下文重新生成为只包含相关部分，然后对重新生成的上下文进行注意，以提取最终响应。在实验中，S2A 比标准注意力基于 LLM 高于三种任务中的 opinione 和 irrelevante 信息，包括问答、数学问题和长文生成，S2A 可以提高事实性和公正性，而减少偏袋性。
</details></li>
</ul>
<hr>
<h2 id="Graph-Variational-Embedding-Collaborative-Filtering"><a href="#Graph-Variational-Embedding-Collaborative-Filtering" class="headerlink" title="Graph Variational Embedding Collaborative Filtering"></a>Graph Variational Embedding Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11824">http://arxiv.org/abs/2311.11824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narges Sadat Fazeli Dehkordi, Hadi Zare, Parham Moradi, Mahdi Jalili</li>
<li>for: 提高用户体验，特别是在电商、音乐和搜索等领域的推荐系统。</li>
<li>methods: 使用图基方法，并采用自变量嵌入来改进Feature传播。</li>
<li>results: 在测试数据上达到13.78%的提升率，与传统方法相比有显著提高。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The customization of recommended content to users holds significant importance in enhancing user experiences across a wide spectrum of applications such as e-commerce, music, and shopping. Graph-based methods have achieved considerable performance by capturing user-item interactions. However, these methods tend to utilize randomly constructed embeddings in the dataset used for training the recommender, which lacks any user preferences. Here, we propose the concept of variational embeddings as a means of pre-training the recommender system to improve the feature propagation through the layers of graph convolutional networks (GCNs). The graph variational embedding collaborative filtering (GVECF) is introduced as a novel framework to incorporate representations learned through a variational graph auto-encoder which are embedded into a GCN-based collaborative filtering. This approach effectively transforms latent high-order user-item interactions into more trainable vectors, ultimately resulting in better performance in terms of recall and normalized discounted cumulative gain(NDCG) metrics. The experiments conducted on benchmark datasets demonstrate that our proposed method achieves up to 13.78% improvement in the recall over the test data.
</details>
<details>
<summary>摘要</summary>
“个性化内容推荐对用户体验产生重要影响，广泛应用于电商、音乐和购物等领域。图基方法在捕捉用户Item交互方面已经取得了显著的表现。然而，这些方法通常使用训练 dataset 中随机构建的嵌入，缺乏用户喜好。我们提出了变量嵌入的概念，以增强预训练推荐系统，从而改善层次 Graph Convolutional Networks (GCNs) 中的特征传播。我们提出了基于变量图自动编码器的图变量嵌入集成推荐(GVECF)方法，将 learned 的表示embedded 到 GCN-based 集成推荐中。这种方法可以将高级用户Item交互转换成更可训练的向量，最终导致推荐性能的提升，测试数据中的准确率提高了13.78%。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Generalized-super-resolution-4D-Flow-MRI-–-using-ensemble-learning-to-extend-across-the-cardiovascular-system"><a href="#Generalized-super-resolution-4D-Flow-MRI-–-using-ensemble-learning-to-extend-across-the-cardiovascular-system" class="headerlink" title="Generalized super-resolution 4D Flow MRI – using ensemble learning to extend across the cardiovascular system"></a>Generalized super-resolution 4D Flow MRI – using ensemble learning to extend across the cardiovascular system</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11819">http://arxiv.org/abs/2311.11819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Ericsson, Adam Hjalmarsson, Muhammad Usman Akbar, Edward Ferdian, Mia Bonini, Brandon Hardy, Jonas Schollenberger, Maria Aristova, Patrick Winter, Nicholas Burris, Alexander Fyrdahl, Andreas Sigfridsson, Susanne Schnell, C. Alberto Figueroa, David Nordsletten, Alistair A. Young, David Marlevi</li>
<li>for: This paper aims to improve the spatial resolution of 4D Flow MRI images, which is limited by image noise and spatial resolution, by incorporating trained super-resolution (SR) networks.</li>
<li>methods: The authors use a combination of heterogeneous training sets and dedicated ensemble learning to explore the generalizability of SR 4D Flow MRI. They generate synthetic training data across three disparate domains and evaluate the performance of varying convolutional base and ensemble learners.</li>
<li>results: The results show that both bagging and stacking ensembling enhance SR performance across domains, accurately predicting high-resolution velocities from low-resolution input data in-silico. The optimized networks also successfully recover native resolution velocities from downsampled in-vivo data, and show qualitative potential in generating denoised SR-images from clinical level input data.<details>
<summary>Abstract</summary>
4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive measurement technique capable of quantifying blood flow across the cardiovascular system. While practical use is limited by spatial resolution and image noise, incorporation of trained super-resolution (SR) networks has potential to enhance image quality post-scan. However, these efforts have predominantly been restricted to narrowly defined cardiovascular domains, with limited exploration of how SR performance extends across the cardiovascular system; a task aggravated by contrasting hemodynamic conditions apparent across the cardiovasculature. The aim of our study was to explore the generalizability of SR 4D Flow MRI using a combination of heterogeneous training sets and dedicated ensemble learning. With synthetic training data generated across three disparate domains (cardiac, aortic, cerebrovascular), varying convolutional base and ensemble learners were evaluated as a function of domain and architecture, quantifying performance on both in-silico and acquired in-vivo data from the same three domains. Results show that both bagging and stacking ensembling enhance SR performance across domains, accurately predicting high-resolution velocities from low-resolution input data in-silico. Likewise, optimized networks successfully recover native resolution velocities from downsampled in-vivo data, as well as show qualitative potential in generating denoised SR-images from clinical level input data. In conclusion, our work presents a viable approach for generalized SR 4D Flow MRI, with ensemble learning extending utility across various clinical areas of interest.
</details>
<details>
<summary>摘要</summary>
四维流体磁共振成像（4D Flow MRI）是一种无侵入的测量技术，可以量化心血管系统中血液流动的质量。 although practical applications are limited by spatial resolution and image noise, incorporating trained super-resolution (SR) networks has the potential to enhance image quality after scanning. However, these efforts have been mainly focused on narrowly defined cardiovascular domains, with limited exploration of how SR performance extends across the cardiovascular system; this task is further complicated by the contrasting hemodynamic conditions present across the cardiovasculature.我们的研究的目标是探索SR 4D Flow MRI的通用性，使用不同的域类和ensemble学习来评估SR性能的一致性。我们使用了synthetic数据生成器生成了三个不同的域类（心血管、血管和脑血管），并使用不同的卷积基和ensemble学习来评估SR性能。结果表明，使用bagging和stacking ensemble学习可以提高SR性能 across domains，从低分辨率输入数据中预测高分辨率速度值。此外，优化的网络还能够从下采样的实际数据中恢复原始分辨率的速度值，并且显示出了对临床数据进行整合的质量提升的可能性。因此，我们的研究提出了一种可行的通用SR 4D Flow MRI方法，通过ensemble学习来扩展到不同的临床领域。
</details></li>
</ul>
<hr>
<h2 id="Improving-Real-Estate-Appraisal-with-POI-Integration-and-Areal-Embedding"><a href="#Improving-Real-Estate-Appraisal-with-POI-Integration-and-Areal-Embedding" class="headerlink" title="Improving Real Estate Appraisal with POI Integration and Areal Embedding"></a>Improving Real Estate Appraisal with POI Integration and Areal Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11812">http://arxiv.org/abs/2311.11812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumin Han, Youngjun Park, Sonia Sabir, Jisun An, Dongman Lee</li>
<li>for: 本研究的目的是解决现有房地产评估方法中的两个挑战，即点位 interess（POI）对房价的影响和空间理解。</li>
<li>methods: 本研究使用了一种改进的POI特征提取方法和基于区域嵌入的MASKED Multihead Attention-based Spatial Interpolation for House Price Prediction（AMMASI）模型，以提高房价预测的准确性。</li>
<li>results:  compared with现有的基线模型，本研究的AMMASI模型在房价预测中显示出了更高的准确性和可靠性，并且也提供了未来房地产评估方法的可能的优化方向。<details>
<summary>Abstract</summary>
Despite advancements in real estate appraisal methods, this study primarily focuses on two pivotal challenges. Firstly, we explore the often-underestimated impact of Points of Interest (POI) on property values, emphasizing the necessity for a comprehensive, data-driven approach to feature selection. Secondly, we integrate road-network-based Areal Embedding to enhance spatial understanding for real estate appraisal. We first propose a revised method for POI feature extraction, and discuss the impact of each POI for house price appraisal. Then we present the Areal embedding-enabled Masked Multihead Attention-based Spatial Interpolation for House Price Prediction (AMMASI) model, an improvement upon the existing ASI model, which leverages masked multi-head attention on geographic neighbor houses and similar-featured houses. Our model outperforms current baselines and also offers promising avenues for future optimization in real estate appraisal methodologies.
</details>
<details>
<summary>摘要</summary>
尽管现有的房地产评估方法有所进步，这项研究主要关注两个重要挑战。首先，我们研究点位对房产价值的影响，并提出了一种全面、数据驱动的特征选择方法。其次，我们将路网基于的空间嵌入技术与房产评估相结合，以提高房产评估的空间理解。我们首先提出了一种改进的POI特征提取方法，然后介绍了每个POI对房价评估的影响。最后，我们提出了基于masked multihead attention的空间 interpolating模型（AMMASI），这是现有ASI模型的改进版本，可以更好地利用邻居和相似特征的房屋。我们的模型在现有基线上表现出色，并且也提供了未来房地产评估方法的有优点的可能性。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-and-Explainable-Law-a-Hybrid-Methodology"><a href="#Large-Language-Models-and-Explainable-Law-a-Hybrid-Methodology" class="headerlink" title="Large Language Models and Explainable Law: a Hybrid Methodology"></a>Large Language Models and Explainable Law: a Hybrid Methodology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11811">http://arxiv.org/abs/2311.11811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Billi, Alessandro Parenti, Giuseppe Pisano, Marco Sanchi</li>
<li>for: 提高法律系统的可访问性、使用性和解释性，以推进法律科技的民主和利益oriented视角。</li>
<li>methods: 使用自然语言处理技术和高级编程语言来翻译规则系统的解释，以便各种用户快速、清晰、可访问地与这些技术进行交互。</li>
<li>results: 通过自动化法律比较和解释，让非专业人士可以通过一系列提示来执行复杂的法律任务，并且可以在同一个事实情况下对不同的规则系统进行自主比较。<details>
<summary>Abstract</summary>
The paper advocates for LLMs to enhance the accessibility, usage and explainability of rule-based legal systems, contributing to a democratic and stakeholder-oriented view of legal technology. A methodology is developed to explore the potential use of LLMs for translating the explanations produced by rule-based systems, from high-level programming languages to natural language, allowing all users a fast, clear, and accessible interaction with such technologies. The study continues by building upon these explanations to empower laypeople with the ability to execute complex juridical tasks on their own, using a Chain of Prompts for the autonomous legal comparison of different rule-based inferences, applied to the same factual case.
</details>
<details>
<summary>摘要</summary>
文章强调使用LLM增强法律系统的可达性、使用度和解释性，帮助建立一种民主和利益相关的法律技术视角。文章提出了一种方法，以寻找使用LLM将高级编程语言中的解释翻译成自然语言，以便所有用户快速、明了、可访问地与这些技术交互。研究继续发展，基于这些解释，赋予非专业人士执行复杂的法律任务的能力，使用一串提示来自动比较不同的规则基于推理结果，应用到同一个实际案例中。
</details></li>
</ul>
<hr>
<h2 id="DocPedia-Unleashing-the-Power-of-Large-Multimodal-Model-in-the-Frequency-Domain-for-Versatile-Document-Understanding"><a href="#DocPedia-Unleashing-the-Power-of-Large-Multimodal-Model-in-the-Frequency-Domain-for-Versatile-Document-Understanding" class="headerlink" title="DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding"></a>DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11810">http://arxiv.org/abs/2311.11810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Feng, Qi Liu, Hao Liu, Wengang Zhou, Houqiang Li, Can Huang</li>
<li>for:  DocPedia是一种大型多Modal模型（LMM），用于无需OCR的文档理解，可以处理高分辨率图像。</li>
<li>methods: DocPedia使用频域处理视觉输入，而不是像素空间处理，这使得它可以更好地捕捉视觉和文本信息。</li>
<li>results: 对多种文档类型进行了广泛的量化和质量测试，证明了 DocPedia 的高效性和超越性。<details>
<summary>Abstract</summary>
This work presents DocPedia, a novel large multimodal model (LMM) for versatile OCR-free document understanding, capable of parsing images up to 2,560$\times$2,560 resolution. Unlike existing work either struggle with high-resolution documents or give up the large language model thus vision or language ability constrained, our DocPedia directly processes visual input in the frequency domain rather than the pixel space. The unique characteristic enables DocPedia to capture a greater amount of visual and textual information using a limited number of visual tokens. To consistently enhance both perception and comprehension abilities of our model, we develop a dual-stage training strategy and enrich instructions/annotations of all training tasks covering multiple document types. Extensive quantitative and qualitative experiments conducted on various publicly available benchmarks confirm the mutual benefits of jointly learning perception and comprehension tasks. The results provide further evidence of the effectiveness and superior performance of our DocPedia over other methods.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这个工作介绍了一种新的大型多模式模型（LMM），名为DocPedia，可以无需OCR进行文档理解，并且可以处理高分辨率图像（最大2560 x 2560）。与现有方法不同，DocPedia直接在频谱空间处理视觉输入，而不是像素空间。这种特点使得DocPedia可以更好地捕捉视觉和文本信息，使用有限的视觉token。为了进一步增强我们模型的感知和理解能力，我们开发了双阶段训练策略，并对所有训练任务进行了丰富的指导和注释。经验证明，我们的DocPedia在多种公开的benchmark上表现出色，证明了我们的方法的有效性和超越性。
</details></li>
</ul>
<hr>
<h2 id="Age-Friendly-Route-Planner-Calculating-Comfortable-Routes-for-Senior-Citizens"><a href="#Age-Friendly-Route-Planner-Calculating-Comfortable-Routes-for-Senior-Citizens" class="headerlink" title="Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens"></a>Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11802">http://arxiv.org/abs/2311.11802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andoni Aranguren, Eneko Osaba, Silvia Urra-Uriarte, Patricia Molina-Costa</li>
<li>for: 提高城市老年人的生活体验</li>
<li>methods: 使用偏好基于路径和舒适元素的路径规划算法</li>
<li>results: 实现了基于年轻人的路径规划算法，并且可以帮助创建适应老年人的友好路径<details>
<summary>Abstract</summary>
The application of routing algorithms to real-world situations is a widely studied research topic. Despite this, routing algorithms and applications are usually developed for a general purpose, meaning that certain groups, such as ageing people, are often marginalized due to the broad approach of the designed algorithms. This situation may pose a problem in cities which are suffering a slow but progressive ageing of their populations. With this motivation in mind, this paper focuses on describing our implemented Age-Friendly Route Planner, whose goal is to improve the experience in the city for senior citizens. In order to measure the age-friendliness of a route, several variables have been deemed, such as the number of amenities along the route, the amount of comfortable elements found, or the avoidance of sloppy sections. In this paper, we describe one of the main features of the Age-Friendly Route Planner: the preference-based routes, and we also demonstrate how it can contribute to the creation of adapted friendly routes.
</details>
<details>
<summary>摘要</summary>
Application of routing algorithms to real-world situations is a widely studied research topic. However, these algorithms and applications are often developed for a general purpose, which can lead to marginalization of certain groups, such as the elderly, due to the broad approach of the designed algorithms. This situation can be particularly problematic in cities with aging populations. Motivated by this, this paper describes our implemented Age-Friendly Route Planner, which aims to improve the experience of senior citizens in the city. To measure the age-friendliness of a route, we have considered several variables, such as the number of amenities along the route, the presence of comfortable elements, and the avoidance of slippery sections. One of the main features of the Age-Friendly Route Planner is preference-based routes, which we will also demonstrate how it can contribute to the creation of adapted, friendly routes.
</details></li>
</ul>
<hr>
<h2 id="Igniting-Language-Intelligence-The-Hitchhiker’s-Guide-From-Chain-of-Thought-Reasoning-to-Language-Agents"><a href="#Igniting-Language-Intelligence-The-Hitchhiker’s-Guide-From-Chain-of-Thought-Reasoning-to-Language-Agents" class="headerlink" title="Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents"></a>Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11797">http://arxiv.org/abs/2311.11797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zoeyyao27/cot-igniting-agent">https://github.com/zoeyyao27/cot-igniting-agent</a></li>
<li>paper_authors: Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, Hai Zhao</li>
<li>for: 本研究旨在探讨链条理解（CoT）的应用在自主语言代理人方面，包括其效果、理论基础和潜在应用领域。</li>
<li>methods: 本研究采用了CoT技术，包括链条推理、中间步骤生成和解释性分析等方法，以探讨自主语言代理人的可行性和效果。</li>
<li>results: 研究发现CoT技术能够提高自主语言代理人的推理能力和可读性，并且可以应用于多种语言和任务上。此外，研究还发现CoT技术在自主语言代理人中的应用可以提高代理人的可控性和灵活性。<details>
<summary>Abstract</summary>
Large language models (LLMs) have dramatically enhanced the field of language intelligence, as demonstrably evidenced by their formidable empirical performance across a spectrum of complex reasoning tasks. Additionally, theoretical proofs have illuminated their emergent reasoning capabilities, providing a compelling showcase of their advanced cognitive abilities in linguistic contexts. Critical to their remarkable efficacy in handling complex reasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning techniques, obliging them to formulate intermediate steps en route to deriving an answer. The CoT reasoning approach has not only exhibited proficiency in amplifying reasoning performance but also in enhancing interpretability, controllability, and flexibility. In light of these merits, recent research endeavors have extended CoT reasoning methodologies to nurture the development of autonomous language agents, which adeptly adhere to language instructions and execute actions within varied environments. This survey paper orchestrates a thorough discourse, penetrating vital research dimensions, encompassing: (i) the foundational mechanics of CoT techniques, with a focus on elucidating the circumstances and justification behind its efficacy; (ii) the paradigm shift in CoT; and (iii) the burgeoning of language agents fortified by CoT approaches. Prospective research avenues envelop explorations into generalization, efficiency, customization, scaling, and safety. This paper caters to a wide audience, including beginners seeking comprehensive knowledge of CoT reasoning and language agents, as well as experienced researchers interested in foundational mechanics and engaging in cutting-edge discussions on these topics. A repository for the related papers is available at https://github.com/Zoeyyao27/CoT-Igniting-Agent.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经带来显著改善语言智能领域，证据在各种复杂推理任务上的杰出表现。另外，理论证据也显示了他们在语言上的高级推理能力，提供了语言智能领域的杰出表现。这些能力的关键是LLMs在解释过程中运用的连锁思维（CoT）推理技术，让它们在得出答案之前需要形成中间步骤。CoT推理方法不仅具有增强推理性能的功能，而且还有提高可读性、可控性和灵活性等优点。这些优点使研究人员对CoT推理方法进行扩展，以开发具有自主语言代理人的语言智能系统。这篇评论文探讨了这些研究方向，包括：（i）CoT技术的基础机制，专注于解释其效果的原因和情况；（ii）CoT推理方法的概念变革；以及（iii）由CoT方法推动的语言代理人的崛起。未来的研究方向包括探讨缩减、效率、自定义、扩展和安全等问题。这篇文章适合各种读者，包括对CoT推理和语言代理人有兴趣的初学者，以及有经验的研究人员，想要了解这些领域的基础机制和进行前沿探讨。相关文献可以在https://github.com/Zoeyyao27/CoT-Igniting-Agent上获得。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Boundaries-A-Comprehensive-Survey-of-Transferable-Attacks-on-AI-Systems"><a href="#Beyond-Boundaries-A-Comprehensive-Survey-of-Transferable-Attacks-on-AI-Systems" class="headerlink" title="Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems"></a>Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11796">http://arxiv.org/abs/2311.11796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan<br>for: This paper focuses on the threat of transferable attacks in various domains, including image, text, graph, audio, and video, and their impact on cyber-physical security.methods: The paper reviews and categorizes existing attacks from different viewpoints, including data, process, model, and system.results: The paper highlights the ubiquitous and pervasive nature of transferable attacks in different domains and outlines potential research directions to address these threats.<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) systems such as autonomous vehicles, facial recognition, and speech recognition systems are increasingly integrated into our daily lives. However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks. In particular, numerous attacks are designed to target a particular model or system, yet their effects can spread to additional targets, referred to as transferable attacks. Although considerable efforts have been directed toward developing transferable attacks, a holistic understanding of the advancements in transferable attacks remains elusive. In this paper, we comprehensively explore learning-based attacks from the perspective of transferability, particularly within the context of cyber-physical security. We delve into different domains -- the image, text, graph, audio, and video domains -- to highlight the ubiquitous and pervasive nature of transferable attacks. This paper categorizes and reviews the architecture of existing attacks from various viewpoints: data, process, model, and system. We further examine the implications of transferable attacks in practical scenarios such as autonomous driving, speech recognition, and large language models (LLMs). Additionally, we outline the potential research directions to encourage efforts in exploring the landscape of transferable attacks. This survey offers a holistic understanding of the prevailing transferable attacks and their impacts across different domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Responsible-AI-Research-Needs-Impact-Statements-Too"><a href="#Responsible-AI-Research-Needs-Impact-Statements-Too" class="headerlink" title="Responsible AI Research Needs Impact Statements Too"></a>Responsible AI Research Needs Impact Statements Too</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11776">http://arxiv.org/abs/2311.11776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandra Olteanu, Michael Ekstrand, Carlos Castillo, Jina Suh</li>
<li>for: 这篇论文主要是为了探讨责任意增进人工智能（RAI）、道德AI和AI道德问题中的不良影响。</li>
<li>methods: 该论文使用了文献综述和理论分析的方法，探讨了不良影响的定义、类型和示例，以及对RAI、道德AI和AI道德的影响。</li>
<li>results: 该论文发现了许多不良影响的例子，包括负面影响、潜在的不公正和隐私问题等，并提出了一些遏制不良影响的建议和方法。<details>
<summary>Abstract</summary>
All types of research, development, and policy work can have unintended, adverse consequences - work in responsible artificial intelligence (RAI), ethical AI, or ethics in AI is no exception.
</details>
<details>
<summary>摘要</summary>
所有类型的研究、开发、政策工作都可能有意外、不良影响 - 负责任人工智能（RAI）、伦理AI或AI伦理工作也不例外。Here's a breakdown of the translation:* 所有类型 (all types) - 所有类型的研究、开发、政策工作 (all types of research, development, and policy work)* 都可能 (can) - 可能 (may)* 有意外 (unintended) - 意外 (unintended)* 不良影响 (adverse consequences) - 不良影响 (adverse consequences)* - 工作 (work)* 负责任人工智能 (RAI) - 负责任人工智能 (RAI)* 或 (or)* AI伦理工作 (ethical AI) - AI伦理工作 (ethics in AI)* 也不例外 (also not exceptional)
</details></li>
</ul>
<hr>
<h2 id="Intelligent-methods-for-business-rule-processing-State-of-the-art"><a href="#Intelligent-methods-for-business-rule-processing-State-of-the-art" class="headerlink" title="Intelligent methods for business rule processing: State-of-the-art"></a>Intelligent methods for business rule processing: State-of-the-art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11775">http://arxiv.org/abs/2311.11775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cristiano André da Costa, Uélison Jean Lopes dos Santos, Eduardo Souza dos Reis, Rodolfo Stoffel Antunes, Henrique Chaves Pacheco, Thaynã da Silva França, Rodrigo da Rosa Righi, Jorge Luis Victória Barbosa, Franklin Jebadoss, Jorge Montalvao, Rogerio Kunkel</li>
<li>for: 本研究实际应用在企业规则处理方面，探讨最新的智能技术。</li>
<li>methods: 本研究使用了机器学习和其他智能方法进行探讨。</li>
<li>results: 研究发现了market的Top供应商和其主要解决方案。<details>
<summary>Abstract</summary>
In this article, we provide an overview of the latest intelligent techniques used for processing business rules. We have conducted a comprehensive survey of the relevant literature on robot process automation, with a specific focus on machine learning and other intelligent approaches. Additionally, we have examined the top vendors in the market and their leading solutions to tackle this issue.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们提供了对最新的智能技术处理商业规则的概述。我们进行了全面的文献综述，专注于机器学习和其他智能方法。此外，我们还审查了市场上领先的供应商和他们的主要解决方案。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Unseen-Potential-of-Graph-Learning-through-MLPs-Effective-Graph-Learners-Using-Propagation-Embracing-MLPs"><a href="#Unveiling-the-Unseen-Potential-of-Graph-Learning-through-MLPs-Effective-Graph-Learners-Using-Propagation-Embracing-MLPs" class="headerlink" title="Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs"></a>Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11759">http://arxiv.org/abs/2311.11759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong-Min Shin, Won-Yong Shin</li>
<li>for: 本研究旨在利用多层感知器（MLP）解决 semi-supervised 节点分类问题，通过在知识储存（KD）过程中训练学生 MLP，从教师图 neural network（GNN）中学习。</li>
<li>methods: 我们提出了一种名为 Propagate &amp; Distill（P&amp;D）的方法，它将教师 GNN 的输出传播给学生 MLP，并可以解释为逆传播 $\Pi^{-1}$ 的一种近似过程。</li>
<li>results: 我们通过使用实际世界 benchmark 数据集进行了广泛的评估，并表明了 P&amp;D 方法可以提高学生 MLP 的性能。<details>
<summary>Abstract</summary>
Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve semi-supervised node classification on graphs, by training a student MLP by knowledge distillation (KD) from a teacher graph neural network (GNN). While previous studies have focused mostly on training the student MLP by matching the output probability distributions between the teacher and student models during KD, it has not been systematically studied how to inject the structural information in an explicit and interpretable manner. Inspired by GNNs that separate feature transformation $T$ and propagation $\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\Pi$. Although this can be achieved by applying the inverse propagation $\Pi^{-1}$ before distillation from the teacher GNN, it still comes with a high computational cost from large matrix multiplications during training. To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing further performance boost of the student MLP.
</details>
<details>
<summary>摘要</summary>
Inspired by GNNs that separate feature transformation $T$ and propagation $\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\Pi$. This can be achieved by applying the inverse propagation $\Pi^{-1}$ before distillation from the teacher GNN, but this comes with a high computational cost from large matrix multiplications during training.To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing a further performance boost of the student MLP.
</details></li>
</ul>
<hr>
<h2 id="LSTM-CNN-An-efficient-diagnostic-network-for-Parkinson’s-disease-utilizing-dynamic-handwriting-analysis"><a href="#LSTM-CNN-An-efficient-diagnostic-network-for-Parkinson’s-disease-utilizing-dynamic-handwriting-analysis" class="headerlink" title="LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis"></a>LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11756">http://arxiv.org/abs/2311.11756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Wang, Junqing Huang, Sven Nomm, Marianna Chatzakou, Kadri Medijainen, Aaro Toomela, Michael Ruzhansky<br>for: 这种研究的目的是用Dynamic Handwriting Analysis方法对parkinson病患者的手写能力进行诊断。methods: 该方法基于混合深度学习方法，包括LSTM和CNNs两种不同的深度学习模型。LSTM块用于提取时间变化特征，而CNNs块使用一维核函数进行低计算成本。此外，该方法还进行了ablation研究以提高性能。results: 该方法在我们新建的DraWritePD数据集上达到了96.2%的分类精度，并在PaHaW数据集上达到了90.7%的分类精度。此外，该方法还具有轻量级的参数量和快速的CPU执行速度。<details>
<summary>Abstract</summary>
Background and objectives: Dynamic handwriting analysis, due to its non-invasive and readily accessible nature, has recently emerged as a vital adjunctive method for the early diagnosis of Parkinson's disease. In this study, we design a compact and efficient network architecture to analyse the distinctive handwriting patterns of patients' dynamic handwriting signals, thereby providing an objective identification for the Parkinson's disease diagnosis.   Methods: The proposed network is based on a hybrid deep learning approach that fully leverages the advantages of both long short-term memory (LSTM) and convolutional neural networks (CNNs). Specifically, the LSTM block is adopted to extract the time-varying features, while the CNN-based block is implemented using one-dimensional convolution for low computational cost. Moreover, the hybrid model architecture is continuously refined under ablation studies for superior performance. Finally, we evaluate the proposed method with its generalization under a five-fold cross-validation, which validates its efficiency and robustness.   Results: The proposed network demonstrates its versatility by achieving impressive classification accuracies on both our new DraWritePD dataset ($96.2\%$) and the well-established PaHaW dataset ($90.7\%$). Moreover, the network architecture also stands out for its excellent lightweight design, occupying a mere $0.084$M of parameters, with a total of only $0.59$M floating-point operations. It also exhibits near real-time CPU inference performance, with inference times ranging from $0.106$ to $0.220$s.   Conclusions: We present a series of experiments with extensive analysis, which systematically demonstrate the effectiveness and efficiency of the proposed hybrid neural network in extracting distinctive handwriting patterns for precise diagnosis of Parkinson's disease.
</details>
<details>
<summary>摘要</summary>
背景和目标：动态手写分析因为非侵入性和ready accessible的特点，最近在诊断 Parkinson's disease 的早期阶段出现了非常有价值的辅助方法。在这种研究中，我们设计了一种具有高效率和紧凑的网络架构，以分析患者的动态手写信号中的特征特征，以提供对 Parkinson's disease 诊断的 объектив标识。方法：我们的方法基于一种混合深度学习方法，旨在挖掘患者的动态手写特征。具体来说，我们采用了LSTM块来提取时间变化特征，而CNN基于的块则是通过一维核函数进行低计算成本的实现。此外，我们还进行了缩进研究，以提高模型的性能。最后，我们使用五fold十分钟验证来评估我们的方法，并证明其高效和可靠。结果：我们的方法在我们新建的DraWritePD数据集上($96.2\%$)和已知的PaHaW数据集上($90.7\%$)都达到了非常出色的分类精度。此外，我们的网络架构还具有优秀的轻量级设计，占用仅 $0.084$M的参数，总共仅 $0.59$M的浮点运算。此外，我们的模型还展示了近实时的CPU执行速度，执行时间在 $0.106$ 到 $0.220$s之间。结论：我们通过了系列的实验和分析，证明了我们的混合神经网络在诊断 Parkinson's disease 的早期阶段中提取动态手写特征的效果和高效性。
</details></li>
</ul>
<hr>
<h2 id="A-Large-Scale-Car-Parts-LSCP-Dataset-for-Lightweight-Fine-Grained-Detection"><a href="#A-Large-Scale-Car-Parts-LSCP-Dataset-for-Lightweight-Fine-Grained-Detection" class="headerlink" title="A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection"></a>A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11754">http://arxiv.org/abs/2311.11754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Jie, Zhong Yilin, Cao Qianqian</li>
<li>for: 本研究是为了弥补现有的自动驾驶系统和车辆分类任务中使用的汽车相关数据集的缺失，提供了一个大规模和细致的汽车AI数据集，用于检测12种不同的车部。</li>
<li>methods: 本研究提出了一种新的半监督自动标注方法，利用现有的预训练检测器来减轻人工标注的劳动ious burden。此外，我们也研究了黑洞均值网络（Grounding DINO）的零shot标注的局限性。</li>
<li>results: 我们通过使用一些轻量级的YOLO系列检测器进行细致的车部检测，证明了我们提出的数据集的有效性。<details>
<summary>Abstract</summary>
Automotive related datasets have previously been used for training autonomous driving systems or vehicle classification tasks. However, there is a lack of datasets in the field of automotive AI for car parts detection, and most available datasets are limited in size and scope, struggling to cover diverse scenarios. To address this gap, this paper presents a large-scale and fine-grained automotive dataset consisting of 84,162 images for detecting 12 different types of car parts. This dataset was collected from natural cameras and online websites which covers various car brands, scenarios, and shooting angles. To alleviate the burden of manual annotation, we propose a novel semi-supervised auto-labeling method that leverages state-of-the-art pre-trained detectors. Moreover, we study the limitations of the Grounding DINO approach for zero-shot labeling. Finally, we evaluate the effectiveness of our proposed dataset through fine-grained car parts detection by training several lightweight YOLO-series detectors.
</details>
<details>
<summary>摘要</summary>
《自动驾驶系统训练数据集》（Automotive related datasets）在过去已经用于训练自动驾驶系统或车辆类型标注任务。然而，在汽车AI领域中的车 spare parts检测数据集却缺乏，而且现有的数据集通常很小，缺乏多样化的场景覆盖。为解决这个空白，本文提出了一个大规模、细化的汽车数据集，包括12种不同的车 spare parts的84,162张图像。这个数据集来自于自然摄像头和网络上的图片，覆盖了多种汽车品牌、场景和拍摄角度。为了避免手动标注的劳动ious burden，我们提出了一种新的半监督自动标注方法，该方法利用了当前最佳的预训练检测器。此外，我们还研究了针对零shot标注的Grounding DINO方法的局限性。最后，我们通过使用一些轻量级的YOLO系列检测器进行细化的车 spare parts检测，证明了我们提posed的数据集的有效性。
</details></li>
</ul>
<hr>
<h2 id="Sparse4D-v3-Advancing-End-to-End-3D-Detection-and-Tracking"><a href="#Sparse4D-v3-Advancing-End-to-End-3D-Detection-and-Tracking" class="headerlink" title="Sparse4D v3: Advancing End-to-End 3D Detection and Tracking"></a>Sparse4D v3: Advancing End-to-End 3D Detection and Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11722">http://arxiv.org/abs/2311.11722</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linxuewu/sparse4d">https://github.com/linxuewu/sparse4d</a></li>
<li>paper_authors: Xuewu Lin, Zixiang Pei, Tianwei Lin, Lichao Huang, Zhizhong Su</li>
<li>for: This paper focuses on improving the detection and tracking performance of 3D objects in autonomous driving perception systems, building upon the Sparse4D framework.</li>
<li>methods: The authors introduce two auxiliary training tasks and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. They also extend the detector into a tracker using a straightforward approach that assigns instance ID during inference.</li>
<li>results: The proposed improvements achieve significant enhancements in detection performance, with ResNet50 as the backbone, witnessing enhancements of 3.0%, 2.2%, and 7.6% in mAP, NDS, and AMOTA, respectively. The best model achieved 71.9% NDS and 67.7% AMOTA on the nuScenes test set.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这篇论文将关注自动驾驶感知系统中3D对象检测和跟踪性能的提升，基于Sparse4D框架。</li>
<li>methods: 作者们引入了两个辅助训练任务（时间实例干扰和质量估计），并提出了分离注意力的方法，导致检测性能得到了显著提升。他们还将检测器转换成跟踪器，使用直观的方法，在推理过程中分配实例ID。</li>
<li>results: 提案的改进得到了显著的检测性能提升，使用ResNet50作为背景网络，观察到了3.0%、2.2%和7.6%的mAP、NDS和AMOTA提升，分别达到46.9%、56.1%和49.0%。最佳模型在nuScenes测试集上达到了71.9%的NDS和67.7%的AMOTA。代码将在\url{<a target="_blank" rel="noopener" href="https://github.com/linxuewu/Sparse4D%7D%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/linxuewu/Sparse4D}上发布。</a><details>
<summary>Abstract</summary>
In autonomous driving perception systems, 3D detection and tracking are the two fundamental tasks. This paper delves deeper into this field, building upon the Sparse4D framework. We introduce two auxiliary training tasks (Temporal Instance Denoising and Quality Estimation) and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. Additionally, we extend the detector into a tracker using a straightforward approach that assigns instance ID during inference, further highlighting the advantages of query-based algorithms. Extensive experiments conducted on the nuScenes benchmark validate the effectiveness of the proposed improvements. With ResNet50 as the backbone, we witnessed enhancements of 3.0\%, 2.2\%, and 7.6\% in mAP, NDS, and AMOTA, achieving 46.9\%, 56.1\%, and 49.0\%, respectively. Our best model achieved 71.9\% NDS and 67.7\% AMOTA on the nuScenes test set. Code will be released at \url{https://github.com/linxuewu/Sparse4D}.
</details>
<details>
<summary>摘要</summary>
自主驾驶感知系统中，3D探测和跟踪是两项基本任务。这篇论文在这个领域进行深入探索，基于Sparse4D框架。我们引入了两项辅助训练任务（时间实例噪声纠正和质量评估），并提出了分离注意力的方法，导致探测性能得到了显著提高。此外，我们扩展了探测器，使其在探测过程中分配实例ID，进一步展示了查询基本算法的优势。广泛的实验在nuScenes数据集上验证了我们的提案的有效性。使用ResNet50作为背景网络时，我们观察到了3.0\%、2.2\%和7.6\%的提高，达到了46.9\%、56.1\%和49.0\%的MAP、NDS和AMOTA。我们的最佳模型在nuScenes测试集上达到了71.9\%的NDS和67.7\%的AMOTA。代码将在\url{https://github.com/linxuewu/Sparse4D}上发布。
</details></li>
</ul>
<hr>
<h2 id="Can-we-infer-the-presence-of-Differential-Privacy-in-Deep-Learning-models’-weights-Towards-more-secure-Deep-Learning"><a href="#Can-we-infer-the-presence-of-Differential-Privacy-in-Deep-Learning-models’-weights-Towards-more-secure-Deep-Learning" class="headerlink" title="Can we infer the presence of Differential Privacy in Deep Learning models’ weights? Towards more secure Deep Learning"></a>Can we infer the presence of Differential Privacy in Deep Learning models’ weights? Towards more secure Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11717">http://arxiv.org/abs/2311.11717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xehartnort/dp-from-weights">https://github.com/xehartnort/dp-from-weights</a></li>
<li>paper_authors: Jiménez-López, Daniel, Rodríguez-Barroso, Nuria, Luzón, M. Victoria, Herrera, Francisco</li>
<li>for: 保护数据和模型免受攻击，实现数据隐私。</li>
<li>methods: 使用Diffferentially Private Stochastic Gradient Descent（DP-SGD）来实现数据隐私。</li>
<li>results: 通过分析DL模型的 weights，可以判断DL模型是否在训练过程中使用了数据隐私。<details>
<summary>Abstract</summary>
Differential Privacy (DP) is a key property to protect data and models from integrity attacks. In the Deep Learning (DL) field, it is commonly implemented through the Differentially Private Stochastic Gradient Descent (DP-SGD). However, when a model is shared or released, there is no way to check whether it is differentially private, that is, it required to trust the model provider. This situation poses a problem when data privacy is mandatory, specially with current data regulations, as the presence of DP can not be certificated consistently by any third party. Thus, we face the challenge of determining whether a DL model has been trained with DP, according to the title question: Can we infer the presence of Differential Privacy in Deep Learning models' weights? Since the DP-SGD significantly changes the training process of a DL model, we hypothesize that DP leaves an imprint in the weights of a DL model, which can be used to predict whether a model has been trained with DP regardless of its architecture and the training dataset. In this paper, we propose to employ the imprint in model weights of using DP to infer the presence of DP training in a DL model. To substantiate our hypothesis, we developed an experimental methodology based on two datasets of weights of DL models, each with models with and without DP training and a meta-classifier to infer whether DP was used in the training process of a DL model, by accessing its weights. We accomplish both, the removal of the requirement of a trusted model provider and a strong foundation for this interesting line of research. Thus, our contribution is an additional layer of security on top of the strict private requirements of DP training in DL models, towards to DL models.
</details>
<details>
<summary>摘要</summary>
diferencial privacidad (DP) es una propiedad clave para proteger datos y modelos de ataques de integridad. En el campo de aprendizaje profundo (DL), se implementa comúnmente a través de el aprendizaje diferencial privado (DP-SGD). Sin embargo, cuando un modelo se comparte o se libera, no hay manera de verificar si ha sido entrenado con DP, lo que plantea un problema cuando la privacidad de datos es esencial, especialmente con las regulaciones actuales de datos. En este sentido, nos enfrentamos al desafío de determinar si un modelo de DL ha sido entrenado con DP, según la pregunta del título: ¿Podemos inferir la presencia de Privacidad Diferencial en los pesos de los modelos de aprendizaje profundo? Dado que el DP-SGD cambia significativamente el proceso de entrenamiento de un modelo de DL, hipotetizamos que la DP deja una huella en los pesos del modelo, lo que se puede utilizar para predecir si un modelo ha sido entrenado con DP, independientemente de su arquitectura y del conjunto de entrenamiento. En este artículo, propugnamos emplear la huella en los pesos del modelo para inferir la presencia de entrenamiento con DP en un modelo de DL. Para substanciar nuestra hipótesis, desarrollamos un método experimental basado en dos conjuntos de pesos de modelos de DL, cada uno con modelos entrenados con y sin DP, y un clasificador meta para inferir si se utilizó DP en el proceso de entrenamiento de un modelo de DL, accediendo a sus pesos. De esta manera, eliminamos la necesidad de confiar en el proveedor del modelo y establecemos una base sólida para esta línea de investigación interesante. Por lo tanto, nuestra contribución es una capa adicional de seguridad sobre la privacidad estricta de los modelos de DL entrenados con DP.
</details></li>
</ul>
<hr>
<h2 id="Control-in-Hybrid-Chatbots"><a href="#Control-in-Hybrid-Chatbots" class="headerlink" title="Control in Hybrid Chatbots"></a>Control in Hybrid Chatbots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11701">http://arxiv.org/abs/2311.11701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Thomas Rüdel, Jochen L. Leidner</li>
<li>for: 本研究旨在描述一个商业规则引擎和一个 интегразирован的神经语音助手的集成方式，以及这种集成方式对控制水平的影响。</li>
<li>methods: 本研究使用了商业规则引擎和大量预训练语言模型的集成方式，以实现更高的控制性和准确性。</li>
<li>results: 研究发现，通过合理的集成方式，可以实现更高的控制性和准确性，同时避免模型“幻觉”现象。<details>
<summary>Abstract</summary>
Customer data typically is held in database systems, which can be seen as rule-based knowledge base, whereas businesses increasingly want to benefit from the capabilities of large, pre-trained language models.   In this technical report, we describe a case study of how a commercial rule engine and an integrated neural chatbot may be integrated, and what level of control that particular integration mode leads to. We also discuss alternative ways (including past ways realized in other systems) how researchers strive to maintain control and avoid what has recently been called model "hallucination".
</details>
<details>
<summary>摘要</summary>
客户数据通常会被储存在数据库系统中，可以看作为规则式知识库。而企业则希望从大型预训语言模型中获益。在这份技术报告中，我们详细描述了一个商业规则引擎和一个集成的神经聊天机器人的integraion情况，以及该integraion模式带来的控制水平。我们还讨论了其他研究人员如何维持控制并避免最近被称为“模型幻视”的情况。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Low-rank-Adaptation-of-Pre-trained-Language-Models"><a href="#Sparse-Low-rank-Adaptation-of-Pre-trained-Language-Models" class="headerlink" title="Sparse Low-rank Adaptation of Pre-trained Language Models"></a>Sparse Low-rank Adaptation of Pre-trained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11696">http://arxiv.org/abs/2311.11696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsinghuac3i/sora">https://github.com/tsinghuac3i/sora</a></li>
<li>paper_authors: Ning Ding, Xingtai Lv, Qiaosen Wang, Yulin Chen, Bowen Zhou, Zhiyuan Liu, Maosong Sun</li>
<li>for: 这种研究旨在提高预训练的大语言模型的精度和效率，通过在批处理阶段进行精度补做和简化。</li>
<li>methods: 我们提出了一种扩展LoRA的方法，称为缺省低维化适应（SoRA），具有可动的内置维度，通过在训练阶段使用抑制器单元和距离梯度法来控制维度的占位。在推理阶段，我们可以将无效的参数块排除掉，使每个SoRA模块变为一个简洁又优化的LoRA模块。</li>
<li>results: 我们的实验结果表明，SoRA可以与其他基准值相比，即使保留70%的参数和训练时间，也可以达到更高的表现。此外，我们还提出了一种简化调度器，以便研究SoRA模块中参数的数量对模型的记忆和泛化的影响。<details>
<summary>Abstract</summary>
Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of non-zero parameters on the model's memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.
</details>
<details>
<summary>摘要</summary>
大量语言模型的精细调整已广泛研究，以提高效率和表现。LoRA（低级别适应）方法是一种受欢迎的方法，假设适应过程是低维度的。虽然LoRA已经显示出了良好的表现，但它使用固定和不可变的内在级别，这可能不总是最佳选择。为了更多的灵活性，我们扩展了LoRA的方法，提出了一种动态调整内在级别的方法，即干扰（SoRA）。我们在训练阶段通过使用逐步逼近法优化的门控单元，控制级别的卡通数，使得SoRA模块在执行阶段可以减少参数块。在执行阶段，我们可以根据门控单元的值来Zero出不必要的参数块，以降低SoRA模块的参数数量。我们的方法可以增强LoRA的表现力，同时fficiently控制参数数量，使得模型具有更好的泛化能力和记忆力。此外，我们还提出了一种缩短调整器来研究SoRA模块中参数的数量对模型的记忆和泛化的影响。我们的实验结果表明，SoRA可以在70% retained parameters和70% 的训练时间下超过其他基线。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Text-Retrieval-with-Progressive-Learning"><a href="#Towards-Robust-Text-Retrieval-with-Progressive-Learning" class="headerlink" title="Towards Robust Text Retrieval with Progressive Learning"></a>Towards Robust Text Retrieval with Progressive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11691">http://arxiv.org/abs/2311.11691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Wu, Yulei Qin, Enwei Zhang, Zihan Xu, Yuting Gao, Ke Li, Xing Sun</li>
<li>for: 提高大语言模型（LLM）的可靠性和准确性，使其能够更好地处理最新的和域специфи的信息。</li>
<li>methods: 提出了一种进展式学习的embeddings方法，通过增加训练集中负样本的数量和多样性，同时使用进程学习机制来动态调整模型对样本的注意力。</li>
<li>results: 在C-MTEB和DuReader等测试集上，PEG模型已经超过了现有的embeddings模型，在true positives retrieval方面表现出色，demonstrating its significant potential for applications in LLMs。<details>
<summary>Abstract</summary>
Retrieval augmentation has become an effective solution to empower large language models (LLMs) with external and verified knowledge sources from the database, which overcomes the limitations and hallucinations of LLMs in handling up-to-date and domain-specific information. However, existing embedding models for text retrieval usually have three non-negligible limitations. First, the number and diversity of samples in a batch are too restricted to supervise the modeling of textual nuances at scale. Second, the high proportional noise are detrimental to the semantic correctness and consistency of embeddings. Third, the equal treatment to easy and difficult samples would cause sub-optimum convergence of embeddings with poorer generalization. In this paper, we propose the PEG, a progressively learned embeddings for robust text retrieval. Specifically, we increase the training in-batch negative samples to 80,000, and for each query, we extracted five hard negatives. Concurrently, we incorporated a progressive learning mechanism, enabling the model to dynamically modulate its attention to the samples throughout the entire training process. Additionally, PEG is trained on more than 100 million data, encompassing a wide range of domains (e.g., finance, medicine, and tourism) and covering various tasks (e.g., question-answering, machine reading comprehension, and similarity matching). Extensive experiments conducted on C-MTEB and DuReader demonstrate that PEG surpasses state-of-the-art embeddings in retrieving true positives, highlighting its significant potential for applications in LLMs. Our model is publicly available at https://huggingface.co/TownsWu/PEG.
</details>
<details>
<summary>摘要</summary>
启发式增强技术已成为大语言模型（LLM）吸收外部验证知识源数据库的有效解决方案，超越LLM在处理最新和域 especific 信息方面的局限性和偏见。然而，现有的文本检索嵌入模型通常具有三种不可忽略的局限性。首先，批处理中样本数量和多样性过于限制，缺乏可以强制模型处理文本细节的规模。其次，高比例的噪音对文本嵌入的semantic正确性和一致性有害。第三，对于易训练和难训练样本的平等对待会导致嵌入的优化不佳，影响其泛化性。在这篇论文中，我们提出了PEG，一种可进步学习的文本检索嵌入。具体来说，我们增加了训练 batch 中负样本的数量到 80,000，并为每个查询提取五个困难的负样本。同时，我们 integrate了一种进程学习机制，让模型在整个训练过程中动态调整对样本的注意力。此外，PEG 在1000万个数据上进行了训练，覆盖了多个领域（如金融、医学和旅游）和多种任务（如问答、机器阅读理解和相似性匹配）。我们在 C-MTEB 和 DuReader 上进行了广泛的实验，得出PEG 可以高效地检索真正的积分， highlighting its significant potential for LLM applications。我们的模型可以在https://huggingface.co/TownsWu/PEG 上下载。
</details></li>
</ul>
<hr>
<h2 id="Refactoring-Programs-Using-Large-Language-Models-with-Few-Shot-Examples"><a href="#Refactoring-Programs-Using-Large-Language-Models-with-Few-Shot-Examples" class="headerlink" title="Refactoring Programs Using Large Language Models with Few-Shot Examples"></a>Refactoring Programs Using Large Language Models with Few-Shot Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11690">http://arxiv.org/abs/2311.11690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Yusuke Oda, Jun Suzuki, Makoto Morishita, Yutaka Watanobe</li>
<li>for: 提高程式码维护和改进，并增加学习机会。</li>
<li>methods: 使用大型自然语言模型（LLM）GPT-3.5，提供更少的复杂程式码版本，以吸引开发者对程式码进行改进。</li>
<li>results: 根据实验结果，95.68%的程式码可以通过生成10个候选者进行 refactoring，实现了17.35%的减少Cyclomatic complexity和25.84%的减少行数。此外，质性评估显示出了优秀的程式码格式化能力，但也发现了一些不必要的行为，例如删除或转换注释。<details>
<summary>Abstract</summary>
A less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. However, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. To mitigate this, we demonstrate the application of using a large language model (LLM), GPT-3.5, to suggest less complex versions of the user-written Python program, aiming to encourage users to learn how to write better programs. We propose a method to leverage the prompting with few-shot examples of the LLM by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. The quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. Furthermore, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.
</details>
<details>
<summary>摘要</summary>
一个更简单和直观的程式是一个重要的因素，可以增加程式的维护和修改的容易度，并使写出的程式更加安全和无错。然而，由于它的严重工作负载和可能性的程式码 refactoring 会导致程式码中断，因此开发者们通常不愿意进行 refactoring。这会导致学习机会的损失。为了解决这个问题，我们示范了使用大型自然语言模型（LLM）GPT-3.5，以提出更简单的版本的使用者写的 Python 程式，以便鼓励用户学习写更好的程式。我们提出了一种方法，利用 LLM 的提示，选择适合每个目标程式设计问题的最佳代码 refactoring 示例，根据先前评估的提示一个例子。量化评估显示，95.68%的程式可以通过生成10个候选者，从而实现17.35%的均值周期复杂度和25.84%的均值行数下降。此外， качеitative评估显示了优秀的代码格式化能力，而不必要的行为，如删除或转换注解，也被观察到。
</details></li>
</ul>
<hr>
<h2 id="Causal-Structure-Learning-Supervised-by-Large-Language-Model"><a href="#Causal-Structure-Learning-Supervised-by-Large-Language-Model" class="headerlink" title="Causal Structure Learning Supervised by Large Language Model"></a>Causal Structure Learning Supervised by Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11689">http://arxiv.org/abs/2311.11689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tymadara/ils-csl">https://github.com/tymadara/ils-csl</a></li>
<li>paper_authors: Taiyu Ban, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, Huanhuan Chen<br>for:This paper aims to enhance the efficiency and accuracy of causal structure learning (CSL) from observational data by integrating large language models (LLMs) with CSL.methods:The proposed method, ILS-CSL, iteratively incorporates LLM-based causal inference with CSL, leveraging feedback from LLMs to refine the causal DAG and generate more robust structural constraints.results:The proposed ILS-CSL method demonstrates superior performance in CSL efficacy, outperforming existing approaches on eight real-world datasets and setting a new standard in the field. The codes are available at \url{<a target="_blank" rel="noopener" href="https://github.com/tyMadara/ILS-CSL%7D">https://github.com/tyMadara/ILS-CSL}</a>.<details>
<summary>Abstract</summary>
Causal discovery from observational data is pivotal for deciphering complex relationships. Causal Structure Learning (CSL), which focuses on deriving causal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast DAG spaces and data sparsity. The integration of Large Language Models (LLMs), recognized for their causal reasoning capabilities, offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences. However, existing approaches utilizing LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses. In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process, refining the causal DAG using feedback from LLMs. This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies. Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery. The codes are available at \url{https://github.com/tyMadara/ILS-CSL}.
</details>
<details>
<summary>摘要</summary>
causal discovery from observational data 是很重要的，因为它可以帮助我们理解复杂的关系。 causal Structure Learning (CSL) 是一种 derivate  causal Directed Acyclic Graphs (DAGs) 的方法，但是它面临着庞大 DAG 空间和数据缺乏的挑战。 integrating Large Language Models (LLMs) ，Recognized for their causal reasoning capabilities，offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences。However，existing approaches using LLMs for CSL have encountered issues，including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses。In response，we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework。ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process，refining the causal DAG using feedback from LLMs。This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies。Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance，setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery。codes are available at \url{https://github.com/tyMadara/ILS-CSL}.
</details></li>
</ul>
<hr>
<h2 id="ViP-Mixer-A-Convolutional-Mixer-for-Video-Prediction"><a href="#ViP-Mixer-A-Convolutional-Mixer-for-Video-Prediction" class="headerlink" title="ViP-Mixer: A Convolutional Mixer for Video Prediction"></a>ViP-Mixer: A Convolutional Mixer for Video Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11683">http://arxiv.org/abs/2311.11683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zheng, Ziang Peng, Yuan Cao, Hongming Shan, Junping Zhang</li>
<li>for: 预测未来帧数据，提高视频预测性能</li>
<li>methods: 使用卷积混合器（ViP-Mixer）模型视频 espacio-temporal 演化，并在层次结构中进行特征混合</li>
<li>results: 实验表明，提出的方法在三个标准视频数据集上达到了新的领先性能水平<details>
<summary>Abstract</summary>
Video prediction aims to predict future frames from a video's previous content. Existing methods mainly process video data where the time dimension mingles with the space and channel dimensions from three distinct angles: as a sequence of individual frames, as a 3D volume in spatiotemporal coordinates, or as a stacked image where frames are treated as separate channels. Most of them generally focus on one of these perspectives and may fail to fully exploit the relationships across different dimensions. To address this issue, this paper introduces a convolutional mixer for video prediction, termed ViP-Mixer, to model the spatiotemporal evolution in the latent space of an autoencoder. The ViP-Mixers are stacked sequentially and interleave feature mixing at three levels: frames, channels, and locations. Extensive experiments demonstrate that our proposed method achieves new state-of-the-art prediction performance on three benchmark video datasets covering both synthetic and real-world scenarios.
</details>
<details>
<summary>摘要</summary>
视频预测目标是预测视频的未来帧。现有方法主要处理视频数据，其时间维度杂mix WITH space和channel维度，从三个不同的角度来看：为一系列个帧、为3D维度坐标或为排列的图像，其中每帧都是不同的通道。大多数它们都很偏向一种视角，可能会不充分利用不同维度之间的关系。为解决这个问题，这篇论文提出了一种卷积混合器 для视频预测，称为ViP-Mixer，用于模型视频空间演化的秘密空间 autoencoder 中。ViP-Mixer 堆叠在一起，并在三级Feature混合：帧、通道和位置。广泛的实验表明，我们提出的方法可以达到新的状态纪录级别的预测性能，在三个标准视频数据集上，这些数据集包括 both synthetic 和实际场景。
</details></li>
</ul>
<hr>
<h2 id="MGCT-Mutual-Guided-Cross-Modality-Transformer-for-Survival-Outcome-Prediction-using-Integrative-Histopathology-Genomic-Features"><a href="#MGCT-Mutual-Guided-Cross-Modality-Transformer-for-Survival-Outcome-Prediction-using-Integrative-Histopathology-Genomic-Features" class="headerlink" title="MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features"></a>MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11659">http://arxiv.org/abs/2311.11659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingxin Liu, Yunzan Liu, Hui Cui, Chunquan Li, Jiquan Ma<br>for:* The paper is written to address the challenges of integrating whole slide images (WSIs) and genomic features for cancer prognosis in the rapidly emerging field of deep learning-based computational pathology.methods:* The proposed method, Mutual-Guided Cross-Modality Transformer (MGCT), is a weakly-supervised, attention-based multimodal learning framework that combines histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment.results:* The experimental results using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA) consistently show that MGCT outperforms the state-of-the-art (SOTA) methods.<details>
<summary>Abstract</summary>
The rapidly emerging field of deep learning-based computational pathology has shown promising results in utilizing whole slide images (WSIs) to objectively prognosticate cancer patients. However, most prognostic methods are currently limited to either histopathology or genomics alone, which inevitably reduces their potential to accurately predict patient prognosis. Whereas integrating WSIs and genomic features presents three main challenges: (1) the enormous heterogeneity of gigapixel WSIs which can reach sizes as large as 150,000x150,000 pixels; (2) the absence of a spatially corresponding relationship between histopathology images and genomic molecular data; and (3) the existing early, late, and intermediate multimodal feature fusion strategies struggle to capture the explicit interactions between WSIs and genomics. To ameliorate these issues, we propose the Mutual-Guided Cross-Modality Transformer (MGCT), a weakly-supervised, attention-based multimodal learning framework that can combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment. To validate the effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA). Extensive experimental results consistently emphasize that MGCT outperforms the state-of-the-art (SOTA) methods.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:深度学习计算pathology领域的快速发展已经表现出了用整个染色体图像(WSIs)对肿瘤病人的诊断和预测的承诺。但是，现有的诊断方法大多限定于 Histopathology或 genomics alone，这会导致它们对病人诊断的准确性受到限制。而 integrating WSIs 和 genomic 特征会存在以下三个主要挑战：1. WSIs 的巨大多样性，可以达到 150,000 x 150,000 像素的大小;2. histopathology 图像和 genomic 分子数据之间缺乏空间相匹配关系;3. 现有的早期、晚期和中期多模式融合策略难以捕捉 WSIs 和 genomics 之间的显式交互。为了解决这些问题，我们提出了 Mutual-Guided Cross-Modality Transformer (MGCT)，一种弱监督的、注意力基于的多模式学习框架，可以将 histology 特征和 genomic 特征融合以模型肿瘤微环境中的 genotype-phenotype 交互。为验证 MGCT 的效果，我们在 The Cancer Genome Atlas (TCGA) 中获得了 nearly 3,600 个 gigapixel WSIs 的数据，并进行了广泛的实验。结果表明，MGCT 能够在不同的肿瘤类型上具有显著的优势。Simplified Chinese:深度学习计算pathology领域的快速发展已经表现出了用整个染色体图像(WSIs)对肿瘤病人的诊断和预测的承诺。但是，现有的诊断方法大多限定于 Histopathology或 genomics alone，这会导致它们对病人诊断的准确性受到限制。而 integrating WSIs 和 genomic 特征会存在以下三个主要挑战：1. WSIs 的巨大多样性，可以达到 150,000 x 150,000 像素的大小;2. histopathology 图像和 genomic 分子数据之间缺乏空间相匹配关系;3. 现有的早期、晚期和中期多模式融合策略难以捕捉 WSIs 和 genomics 之间的显式交互。为了解决这些问题，我们提出了 Mutual-Guided Cross-Modality Transformer (MGCT)，一种弱监督的、注意力基于的多模式学习框架，可以将 histology 特征和 genomic 特征融合以模型肿瘤微环境中的 genotype-phenotype 交互。为验证 MGCT 的效果，我们在 The Cancer Genome Atlas (TCGA) 中获得了 nearly 3,600 个 gigapixel WSIs 的数据，并进行了广泛的实验。结果表明，MGCT 能够在不同的肿瘤类型上具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Peeking-Inside-the-Schufa-Blackbox-Explaining-the-German-Housing-Scoring-System"><a href="#Peeking-Inside-the-Schufa-Blackbox-Explaining-the-German-Housing-Scoring-System" class="headerlink" title="Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System"></a>Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11655">http://arxiv.org/abs/2311.11655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean-Robin Kern, Gunnar Stevens, Erik Dethier, Sidra Naveed, Fatemeh Alizadeh, Delong Du, Md Shajalal</li>
<li>for: 这个论文主要是为了研究用户需要和预期的解释方面，以及如何通过域专的上下文来开发特定的解释方案。</li>
<li>methods: 这篇论文使用了探索设计方法，询问了业务信息学生对住房信用分数解释的用户界面设计。</li>
<li>results: 我们的初步发现结果表明，虽然有一些通用的需求，但也有因角色和实际情况而冲突的需求。我们的研究贡献了未来的人类中心XAI研究的未来研究方向。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence is a concept aimed at making complex algorithms transparent to users through a uniform solution. Researchers have highlighted the importance of integrating domain specific contexts to develop explanations tailored to end users. In this study, we focus on the Schufa housing scoring system in Germany and investigate how users information needs and expectations for explanations vary based on their roles. Using the speculative design approach, we asked business information students to imagine user interfaces that provide housing credit score explanations from the perspectives of both tenants and landlords. Our preliminary findings suggest that although there are general needs that apply to all users, there are also conflicting needs that depend on the practical realities of their roles and how credit scores affect them. We contribute to Human centered XAI research by proposing future research directions that examine users explanatory needs considering their roles and agencies.
</details>
<details>
<summary>摘要</summary>
人工智能可解释（Explainable Artificial Intelligence）是一种概念，旨在让复杂算法对用户透明度加以统一解释。研究人员强调了在发展专业背景下整合域务特定上下文来开发专门为用户开发解释的重要性。本研究将在德国的Schufa住房评分系统中进行调查，探讨用户信息需求和对解释的期望是否受到角色影响。我们使用探索设计方法，请商业信息学生想象提供住房信贷分数解释，从商业租赁者和房东的角度出发。我们的初步发现结果表明，尽管有一些通用的需求，但也有因角色实际情况而冲突的需求。我们对人类中心的XAI研究做出贡献，提出将用户解释需求与角色和机构进行研究的未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Web-News-Timeline-Generation-with-Extended-Task-Prompting"><a href="#Web-News-Timeline-Generation-with-Extended-Task-Prompting" class="headerlink" title="Web News Timeline Generation with Extended Task Prompting"></a>Web News Timeline Generation with Extended Task Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11652">http://arxiv.org/abs/2311.11652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sha Wang, Yuchen Li, Hanhua Xiao, Lambert Deng, Yanfei Dong</li>
<li>for: 新闻时间轴的创造对于全面和Contextual understanding of events over time是非常重要，帮助找到事件发展的趋势和关系，并理解新闻项目的更广泛意义。</li>
<li>methods: 我们使用了一种延展任务提示技术来评估过去新闻的相关性，并在不同的新闻数据集上进行了证明。</li>
<li>results: 我们发现，通过增强传统提示的扩展任务，可以提高LLMs的效果，使新闻时间轴生成成为专业使用的现实。这种技术已经被应用于一个公共可达扩展程序中，并在我们的网络中得到了推广使用。<details>
<summary>Abstract</summary>
The creation of news timeline is essential for a comprehensive and contextual understanding of events as they unfold over time. This approach aids in discerning patterns and trends that might be obscured when news is viewed in isolation. By organizing news in a chronological sequence, it becomes easier to track the development of stories, understand the interrelation of events, and grasp the broader implications of news items. This is particularly helpful in sectors like finance and insurance, where timely understanding of the event development-ranging from extreme weather to political upheavals and health crises-is indispensable for effective risk management. While traditional natural language processing (NLP) techniques have had some success, they often fail to capture the news with nuanced relevance that are readily apparent to domain experts, hindering broader industry integration. The advance of Large Language Models (LLMs) offers a renewed opportunity to tackle this challenge. However, direct prompting LLMs for this task is often ineffective. Our study investigates the application of an extended task prompting technique to assess past news relevance. We demonstrate that enhancing conventional prompts with additional tasks boosts their effectiveness on various news dataset, rendering news timeline generation practical for professional use. This work has been deployed as a publicly accessible browser extension which is adopted within our network.
</details>
<details>
<summary>摘要</summary>
新闻时间轴的创建是对事件的全面和Contextual comprehension具有重要意义，帮助发现事件发展的趋势和Patterns。通过将新闻按照时间顺序排序，可以较容易地跟踪事件的发展，理解事件之间的相互关系，并捕捉新闻项目的更大意义。特别在金融和保险领域，时间轴生成具有重要的实用意义，可以帮助管理风险。传统的自然语言处理（NLP）技术有一定的成功，但它们经常无法捕捉域专家所认为的新闻 relevance，这限制了业务的整合。大语言模型（LLMs）的进步提供了一个新的机会，以解决这个挑战。但直接对LLMs进行prompting是不够有效的。我们的研究发现，通过扩展任务提示技术，可以提高传统的提示效果，并在不同的新闻数据集上进行评估。我们的工作已经被部署为公共可访问的扩展，并在我们的网络中得到了采纳。
</details></li>
</ul>
<hr>
<h2 id="A-novel-transformer-based-approach-for-soil-temperature-prediction"><a href="#A-novel-transformer-based-approach-for-soil-temperature-prediction" class="headerlink" title="A novel transformer-based approach for soil temperature prediction"></a>A novel transformer-based approach for soil temperature prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11626">http://arxiv.org/abs/2311.11626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammet Mucahit Enes Yurtsever, Ayhan Kucukmanisa, Zeynep Hilal Kilimci</li>
<li>for: 这个研究旨在预测土壤温度，以便更好地理解高山冰川的能量、动力学、水文、生态稳定性等方面的过程。</li>
<li>methods: 本研究使用了变换器模型，这是首次应用变 transformation 模型预测土壤温度。试验使用了六个FLUXNET站，并模型了五种不同的变换器模型，即 Vanilla Transformer、Informer、Autoformer、Reformer 和 ETSformer。</li>
<li>results: 实验结果表明，通过使用变换器模型可以在预测土壤温度方面做出显著贡献，并超越深度学习方法和文献研究。这些结果表明，变换器模型在预测土壤温度方面具有重要的优势。<details>
<summary>Abstract</summary>
Soil temperature is one of the most significant parameters that plays a crucial role in glacier energy, dynamics of mass balance, processes of surface hydrological, coaction of glacier-atmosphere, nutrient cycling, ecological stability, the management of soil, water, and field crop. In this work, we introduce a novel approach using transformer models for the purpose of forecasting soil temperature prediction. To the best of our knowledge, the usage of transformer models in this work is the very first attempt to predict soil temperature. Experiments are carried out using six different FLUXNET stations by modeling them with five different transformer models, namely, Vanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To demonstrate the effectiveness of the proposed model, experiment results are compared with both deep learning approaches and literature studies. Experiment results show that the utilization of transformer models ensures a significant contribution to the literature, thence determining the new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
土壤温度是冰川能源中最重要的参数，对冰川动力、质量平衡、表面水文过程、冰川大气相互作用、营养循环和生态稳定性具有关键作用。在这项工作中，我们提出了一种新的方法，使用变换器模型进行土壤温度预测。据我们所知，这是首次使用变换器模型进行土壤温度预测。我们在六个FLUXNET站上进行了实验，使用五种不同的变换器模型，namely，Vanilla Transformer、Informer、Autoformer、Reformer和ETSformer。为证明提出的模型的效果，我们对深度学习方法和文献研究进行了比较。实验结果显示，使用变换器模型对 literature 做出了重要贡献，因此决定了新的州Of-the-art。
</details></li>
</ul>
<hr>
<h2 id="Taiyi-A-Bilingual-Fine-Tuned-Large-Language-Model-for-Diverse-Biomedical-Tasks"><a href="#Taiyi-A-Bilingual-Fine-Tuned-Large-Language-Model-for-Diverse-Biomedical-Tasks" class="headerlink" title="Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks"></a>Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11608">http://arxiv.org/abs/2311.11608</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dutir-bionlp/taiyi-llm">https://github.com/dutir-bionlp/taiyi-llm</a></li>
<li>paper_authors: Ling Luo, Jinzhong Ning, Yingwen Zhao, Zhijun Wang, Zeyuan Ding, Peng Chen, Weiru Fu, Qinyu Han, Guangtao Xu, Yunzhi Qiu, Dinghao Pan, Jiru Li, Hao Li, Wenduo Feng, Senbo Tu, Yuqi Liu, Zhihao Yang, Jian Wang, Yuanyuan Sun, Hongfei Lin</li>
<li>for: 这个研究旨在测试一个适应多种生医自然语言处理任务的大型自然语言模型（LLM），并评估其在不同语言和任务上的效果。</li>
<li>methods: 研究使用了一个双语（英文和中文）精致化的LLM，并提出了一个两阶段的超级练习策略来优化模型在不同任务上的性能。</li>
<li>results: 实验结果显示，该模型在13个测试集上（包括命名实体识别、关系EXTRACTION、文本分类、问答任务）具有较高的性能，并且在额外的生医自然语言处理任务中也表现出了较好的多任务适应能力。<details>
<summary>Abstract</summary>
Recent advancements in large language models (LLMs) have shown promising results across a variety of natural language processing (NLP) tasks. The application of LLMs to specific domains, such as biomedicine, has achieved increased attention. However, most biomedical LLMs focus on enhancing performance in monolingual biomedical question answering and conversation tasks. To further investigate the effectiveness of the LLMs on diverse biomedical NLP tasks in different languages, we present Taiyi, a bilingual (English and Chinese) fine-tuned LLM for diverse biomedical tasks. In this work, we first curated a comprehensive collection of 140 existing biomedical text mining datasets across over 10 task types. Subsequently, a two-stage strategy is proposed for supervised fine-tuning to optimize the model performance across varied tasks. Experimental results on 13 test sets covering named entity recognition, relation extraction, text classification, question answering tasks demonstrate Taiyi achieves superior performance compared to general LLMs. The case study involving additional biomedical NLP tasks further shows Taiyi's considerable potential for bilingual biomedical multi-tasking. The source code, datasets, and model for Taiyi are freely available at https://github.com/DUTIR-BioNLP/Taiyi-LLM.
</details>
<details>
<summary>摘要</summary>
近期大语言模型（LLMs）的进步在自然语言处理（NLP）任务中表现出色，尤其是在生物医学领域。然而，大多数生物医学语言模型（biomedical LLMs）都是专注于提高单语言生物医学问答和对话任务的性能。为了进一步调查LLMs在不同语言和任务之间的效果，我们提出了 Taiyi，一个可以在英语和中文两种语言之间进行精细调整的大语言模型。在这项工作中，我们首先着手了140个现有的生物医学文本挖掘数据集，覆盖了多种任务类型。然后，我们提出了一种两阶段策略，通过精细调整来优化模型在不同任务之间的性能。实验结果表明，Taiyi在13个测试集上（包括命名实体识别、关系提取、文本分类、问答任务）表现出色，比普通的LLMs更高。此外，我们还进行了更多的生物医学NLP任务的案例研究，显示Taiyi在多任务多语言中的潜在能力很大。Taiyi的源代码、数据集和模型可以免费下载于https://github.com/DUTIR-BioNLP/Taiyi-LLM。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-based-malware-detection-for-IoT-devices-using-control-flow-data"><a href="#Machine-learning-based-malware-detection-for-IoT-devices-using-control-flow-data" class="headerlink" title="Machine learning-based malware detection for IoT devices using control-flow data"></a>Machine learning-based malware detection for IoT devices using control-flow data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11605">http://arxiv.org/abs/2311.11605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gergely Hevesi</li>
<li>for: 提高互联网物联网设备的安全性，防止黑客利用这些设备进行攻击和劫持。</li>
<li>methods: 使用机器学习算法和反编译工具对exe文件进行分析，从而检测到恶意软件。</li>
<li>results: 通过对ARM架构的应用程序进行分析，实现了基于控制流相关数据的恶意软件检测方法，并通过训练神经网络模型来实现恶意软件检测的高精度。<details>
<summary>Abstract</summary>
Embedded devices are specialised devices designed for one or only a few purposes. They are often part of a larger system, through wired or wireless connection. Those embedded devices that are connected to other computers or embedded systems through the Internet are called Internet of Things (IoT for short) devices.   With their widespread usage and their insufficient protection, these devices are increasingly becoming the target of malware attacks. Companies often cut corners to save manufacturing costs or misconfigure when producing these devices. This can be lack of software updates, ports left open or security defects by design. Although these devices may not be as powerful as a regular computer, their large number makes them suitable candidates for botnets. Other types of IoT devices can even cause health problems since there are even pacemakers connected to the Internet. This means, that without sufficient defence, even directed assaults are possible against people.   The goal of this thesis project is to provide better security for these devices with the help of machine learning algorithms and reverse engineering tools. Specifically, I study the applicability of control-flow related data of executables for malware detection. I present a malware detection method with two phases. The first phase extracts control-flow related data using static binary analysis. The second phase classifies binary executables as either malicious or benign using a neural network model. I train the model using a dataset of malicious and benign ARM applications.
</details>
<details>
<summary>摘要</summary>
“嵌入式设备是特殊设备，设计用途仅专注于一个或几个任务。它们通常是大型系统的一部分，通过网络或无线连接。当这些嵌入式设备与其他电脑或嵌入式系统通过互联网连接时，它们被称为互联网物件（IoT）设备。由于它们的广泛使用和不足的保护，这些设备在不断增长的Malware攻击中成为目标。公司通常为了降低生产成本或不当配置时，会导致这些设备缺乏软件更新、保持开启的 ports 或设计中的安全漏洞。虽然这些设备可能不如常规电脑强大，但由于它们的大量使用，它们成为了恶意软件的合适目标。甚至有些 IoT 设备可能导致健康问题，因为还有 pacemakers 连接到互联网。这意味着，如果没有足够的防护，甚至可能有对人的导向攻击。”“这个研究专案的目标是为这些设备提供更好的安全保障，使用机器学习算法和反向工程工具。具体来说，我研究适用于执行档控制流相关数据的恶意软件探测方法。我提出了一个具有两个阶段的恶意软件探测方法。第一阶段使用静态二进制分析方法提取控制流相关数据。第二阶段使用神经网模型将二进制档案分为伪阳性或伪阴性。我将模型训练使用 ARM 应用程序的增坏和恶意样本。”
</details></li>
</ul>
<hr>
<h2 id="A-Multi-In-Single-Out-Network-for-Video-Frame-Interpolation-without-Optical-Flow"><a href="#A-Multi-In-Single-Out-Network-for-Video-Frame-Interpolation-without-Optical-Flow" class="headerlink" title="A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow"></a>A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11602">http://arxiv.org/abs/2311.11602</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/J911/MISO-VFI">https://github.com/J911/MISO-VFI</a></li>
<li>paper_authors: Jaemin Lee, Minseok Seo, Sangwoo Lee, Hyobin Park, Dong-Geol Choi</li>
<li>for: 这篇论文主要是为了提出一种基于多输入单输出（MISO）的视频帧 interpolate（VFI）方法，用于解决传统VFI方法中的 occlusion 和非线性运动问题。</li>
<li>methods: 我们的MISO-VFI方法不需要计算运动 вектор，可以更好地模型 occlusion 和非线性运动。我们还引入了一种新的运动感知损失，以便MISO-VFI更好地捕捉视频帧中的空间时间相关性。</li>
<li>results: 我们的MISO-VFI方法在 Vimeo90K、Middlebury 和 UCF101 等视频帧 interpolate 标准测试集上达到了状态方法的表现，与现有方法相比有 significante 性能差距。<details>
<summary>Abstract</summary>
In general, deep learning-based video frame interpolation (VFI) methods have predominantly focused on estimating motion vectors between two input frames and warping them to the target time. While this approach has shown impressive performance for linear motion between two input frames, it exhibits limitations when dealing with occlusions and nonlinear movements. Recently, generative models have been applied to VFI to address these issues. However, as VFI is not a task focused on generating plausible images, but rather on predicting accurate intermediate frames between two given frames, performance limitations still persist. In this paper, we propose a multi-in-single-out (MISO) based VFI method that does not rely on motion vector estimation, allowing it to effectively model occlusions and nonlinear motion. Additionally, we introduce a novel motion perceptual loss that enables MISO-VFI to better capture the spatio-temporal correlations within the video frames. Our MISO-VFI method achieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and UCF101, with a significant performance gap compared to existing approaches.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the official translation rules and conventions of the Chinese language.)
</details></li>
</ul>
<hr>
<h2 id="DesignGPT-Multi-Agent-Collaboration-in-Design"><a href="#DesignGPT-Multi-Agent-Collaboration-in-Design" class="headerlink" title="DesignGPT: Multi-Agent Collaboration in Design"></a>DesignGPT: Multi-Agent Collaboration in Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11591">http://arxiv.org/abs/2311.11591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu Qiu, Chunlei Chai</li>
<li>for: 这篇论文是为了探讨生成AI在产品设计过程中的应用，以及如何使用人工智能代理人来帮助设计师创新。</li>
<li>methods: 这篇论文使用了设计思维和设计过程来开发了多代理人协作框架DesignGPT，这个框架使用人工智能代理人模拟设计公司中不同角色的人员，并让设计师与他们进行自然语言的合作。</li>
<li>results: 实验结果显示，与单独的AI工具相比，DesignGPT可以提高设计师的表现，强调了应用多代理人系统在产品方案设计中的潜在应用。<details>
<summary>Abstract</summary>
Generative AI faces many challenges when entering the product design workflow, such as interface usability and interaction patterns. Therefore, based on design thinking and design process, we developed the DesignGPT multi-agent collaboration framework, which uses artificial intelligence agents to simulate the roles of different positions in the design company and allows human designers to collaborate with them in natural language. Experimental results show that compared with separate AI tools, DesignGPT improves the performance of designers, highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design.
</details>
<details>
<summary>摘要</summary>
<?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" />生成AI在产品设计工作流中面临许多挑战，如界面使用性和交互模式。因此，基于设计思维和设计过程，我们开发了DesignGPT多代理协作框架，用人工智能代理模拟设计公司不同职位的角色，让人类设计师与其进行自然语言协作。实验结果显示，相比单独的AI工具，DesignGPT改善设计师的表现，highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design。Here's the breakdown of the text into Simplified Chinese characters:生成AI (generated AI)产品设计 (product design)工作流 (workflow)面临 (face)许多挑战 (many challenges)界面使用性 (interface usability)交互模式 (interaction patterns)因此 (therefore)基于 (based on)设计思维 (design thinking)和 (and)设计过程 (design process)开发 (developed)DesignGPT (DesignGPT)多代理协作 (multi-agent collaboration)框架 (framework)用 (use)人工智能 (artificial intelligence)代理模拟 (proxy simulation)设计公司 (design company)不同职位 (different positions)角色 (roles)让 (allow)人类设计师 (human designers)与 (with)其 (it)进行 (to conduct)自然语言 (natural language)协作 (collaboration)实验结果 (experimental results)显示 (show)相比 (compared with)单独 (individually)AI工具 (AI tools)DesignGPT (DesignGPT)改善 (improve)设计师 (designers)表现 (performance)highlighting (highlighting)the potential (the potential)应用 (apply)多代理系统 (multi-agent systems) интегра (integrate)设计领域 (design domain)知识 (knowledge)产品方案 (product scheme)设计。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Urban-Renewal-An-Automated-Approach-to-Generating-Historical-Arcade-Facades-with-Stable-Diffusion-Models"><a href="#Advancing-Urban-Renewal-An-Automated-Approach-to-Generating-Historical-Arcade-Facades-with-Stable-Diffusion-Models" class="headerlink" title="Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models"></a>Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11590">http://arxiv.org/abs/2311.11590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheyuan Kuang, Jiaxin Zhang, Yiying Huang, Yunqin Li</li>
<li>for: 城市更新和转化过程中保护历史城市质量的重要性，特别是具有建筑和历史意义的区域。</li>
<li>methods: 我们的研究使用Stable Diffusion模型来自动生成历史风格的建筑立面图像，并使用文本描述来控制图像的风格特征。我们还使用了多个低级适应（LoRA）模型和控制网络（ControlNet）来提高图像的精度和 AUTHENTICITY。</li>
<li>results: 我们的方法能够生成高精度、AUTHENTICITY和多样性的图像，表明了在城市更新项目中的应用潜力。这种新的方法可以提供更有效率和准确的城市更新设计方案，并且可以减少传统设计过程中的细节不准确和风格多样性有限的问题。<details>
<summary>Abstract</summary>
Urban renewal and transformation processes necessitate the preservation of the historical urban fabric, particularly in districts known for their architectural and historical significance. These regions, with their diverse architectural styles, have traditionally required extensive preliminary research, often leading to subjective results. However, the advent of machine learning models has opened up new avenues for generating building facade images. Despite this, creating high-quality images for historical district renovations remains challenging, due to the complexity and diversity inherent in such districts. In response to these challenges, our study introduces a new methodology for automatically generating images of historical arcade facades, utilizing Stable Diffusion models conditioned on textual descriptions. By classifying and tagging a variety of arcade styles, we have constructed several realistic arcade facade image datasets. We trained multiple low-rank adaptation (LoRA) models to control the stylistic aspects of the generated images, supplemented by ControlNet models for improved precision and authenticity. Our approach has demonstrated high levels of precision, authenticity, and diversity in the generated images, showing promising potential for real-world urban renewal projects. This new methodology offers a more efficient and accurate alternative to conventional design processes in urban renewal, bypassing issues of unconvincing image details, lack of precision, and limited stylistic variety. Future research could focus on integrating this two-dimensional image generation with three-dimensional modeling techniques, providing a more comprehensive solution for renovating architectural facades in historical districts.
</details>
<details>
<summary>摘要</summary>
城市更新和转化过程中，保留历史城区的历史建筑遗产非常重要。这些区域具有多样化的建筑风格，过去经常需要详细的前期研究，并且结果往往是主观的。然而，机器学习模型的出现已经开辟了新的可能性，可以自动生成建筑立面图像。然而，为历史区域翻新而生成高质量图像仍然是一项挑战，因为这些区域的复杂性和多样性。为了解决这些挑战，我们的研究推出了一种新的方法，可以自动生成历史廊式建筑图像，使用稳定扩散模型，并且通过文本描述来控制图像的风格特征。我们分类和标注了多种廊式风格，并创建了许多真实的廊式建筑图像数据集。我们使用多个低级适应（LoRA）模型来控制生成图像的风格方面，并且使用控制网络（ControlNet）模型来提高图像的精度和准确性。我们的方法在生成图像时达到了高度的精度、准确性和多样性，显示出了在实际城市更新项目中的潜在潜力。这种新的方法可以更有效率地替代传统的城市更新设计过程，避免不真实的图像细节、缺乏精度和限制的风格多样性问题。未来的研究可以将这种二维图像生成技术与三维模型技术结合，为历史区域的建筑翻新提供更全面的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Decoupled-DETR-For-Few-shot-Object-Detection"><a href="#Decoupled-DETR-For-Few-shot-Object-Detection" class="headerlink" title="Decoupled DETR For Few-shot Object Detection"></a>Decoupled DETR For Few-shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11570">http://arxiv.org/abs/2311.11570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Shangguan, Lian Huai, Tong Liu, Xingqun Jiang</li>
<li>for: 提高ew-shot object detection（FSOD）的性能，解决数据繁殖问题。</li>
<li>methods: 提出基于DETR的base-novel categories decoupled DETR模型，并 explore skip connection between encoder and decoder，以及在decoder中动态 fusion intermediate layer的Output feature。</li>
<li>results: 在PASCAL VOC和MSCOCO等常用 datasets上评估，模型可以稳定提高5%-10%，并超越最近的最高得分。<details>
<summary>Abstract</summary>
Few-shot object detection (FSOD), an efficient method for addressing the severe data-hungry problem, has been extensively discussed. Current works have significantly advanced the problem in terms of model and data. However, the overall performance of most FSOD methods still does not fulfill the desired accuracy. In this paper we improve the FSOD model to address the severe issue of sample imbalance and weak feature propagation. To alleviate modeling bias from data-sufficient base classes, we examine the effect of decoupling the parameters for classes with sufficient data and classes with few samples in various ways. We design a base-novel categories decoupled DETR (DeDETR) for FSOD. We also explore various types of skip connection between the encoder and decoder for DETR. Besides, we notice that the best outputs could come from the intermediate layer of the decoder instead of the last layer; therefore, we build a unified decoder module that could dynamically fuse the decoder layers as the output feature. We evaluate our model on commonly used datasets such as PASCAL VOC and MSCOCO. Our results indicate that our proposed module could achieve stable improvements of 5% to 10% in both fine-tuning and meta-learning paradigms and has outperformed the highest score in recent works.
</details>
<details>
<summary>摘要</summary>
《几个样本对象检测》（FSOD），一种高效的方法来解决数据充足的问题，已经广泛讨论。现有工作已经在模型和数据上做出了重要进步，但大多数FSOD方法的总性表现仍未达到所需的准确率。在这篇论文中，我们改进了FSOD模型，以解决数据不均衡和弱feature传递的严重问题。为了避免数据充足的基类模型偏见，我们研究了在不同方式下解couple类 Parameters的效果。我们设计了基-新类划分DETR（DeDETR）模型，并 explore了不同类型的跳跃连接 междуencoder和decoder。此外，我们注意到最佳输出可能来自解oder层的中间层而不是最后层，因此我们构建了一个可动 fusion decoder层的统一decoder模块。我们对常用的PASCAL VOC和MSCOCO数据集进行评估，结果显示，我们的模块在微调和元学习 paradigms中均可以稳定地提高5%-10%，并超过了最近的最高分。
</details></li>
</ul>
<hr>
<h2 id="Replay-enhanced-Continual-Reinforcement-Learning"><a href="#Replay-enhanced-Continual-Reinforcement-Learning" class="headerlink" title="Replay-enhanced Continual Reinforcement Learning"></a>Replay-enhanced Continual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11557">http://arxiv.org/abs/2311.11557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiantian Zhang, Kevin Zehua Shen, Zichuan Lin, Bo Yuan, Xueqian Wang, Xiu Li, Deheng Ye</li>
<li>for: 避免 continual reinforcement learning 中的严重遗传问题</li>
<li>methods: 使用 replay-enhanced 方法，包括 adaptive normalization 和 policy distillation</li>
<li>results: 在 Continual World  benchmark 上表现出色，比 purely perfect memory replay 更好，并与现有的 continual learning 方法相比具有相似或更好的全局性能<details>
<summary>Abstract</summary>
Replaying past experiences has proven to be a highly effective approach for averting catastrophic forgetting in supervised continual learning. However, some crucial factors are still largely ignored, making it vulnerable to serious failure, when used as a solution to forgetting in continual reinforcement learning, even in the context of perfect memory where all data of previous tasks are accessible in the current task. On the one hand, since most reinforcement learning algorithms are not invariant to the reward scale, the previously well-learned tasks (with high rewards) may appear to be more salient to the current learning process than the current task (with small initial rewards). This causes the agent to concentrate on those salient tasks at the expense of generality on the current task. On the other hand, offline learning on replayed tasks while learning a new task may induce a distributional shift between the dataset and the learned policy on old tasks, resulting in forgetting. In this paper, we introduce RECALL, a replay-enhanced method that greatly improves the plasticity of existing replay-based methods on new tasks while effectively avoiding the recurrence of catastrophic forgetting in continual reinforcement learning. RECALL leverages adaptive normalization on approximate targets and policy distillation on old tasks to enhance generality and stability, respectively. Extensive experiments on the Continual World benchmark show that RECALL performs significantly better than purely perfect memory replay, and achieves comparable or better overall performance against state-of-the-art continual learning methods.
</details>
<details>
<summary>摘要</summary>
重现过去的经验已被证明是预测灵活学习中避免灾难性忘记的高效方法。然而，一些关键因素仍然被忽视，使其在练习强化学习中具有潜在的失败隐患。其中一个原因是，大多数强化学习算法不具有奖励敏感性，因此以前的任务（高奖励）可能会在当前任务（初始奖励小）中显得更加吸引人。这会让代理人偏好以前任务，而忽略当前任务。另一方面，在重复任务时在学习新任务期间进行离线学习可能会导致扩散差分，从而导致忘记。在这篇论文中，我们介绍了RECALL方法，它可以在新任务上大幅提高现有重复方法的灵活性，而无需担忧灾难性忘记。RECALL通过adaptive normalization approximate target和policy distillation old task来增强通用性和稳定性。广泛的实验表明，RECALL在Continual World benchmark上表现出色，与纯粹的完美记忆重复相比，表现出色，并与当前领先的循环学习方法相当或更好。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Prompting-Large-Language-Models-as-Explainable-Metrics"><a href="#Exploring-Prompting-Large-Language-Models-as-Explainable-Metrics" class="headerlink" title="Exploring Prompting Large Language Models as Explainable Metrics"></a>Exploring Prompting Large Language Models as Explainable Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11552">http://arxiv.org/abs/2311.11552</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics">https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics</a></li>
<li>paper_authors: Ghazaleh Mahmoudi</li>
<li>for: 本研究描述了我们在Eval4NLP 2023杯赛中提交的Prompting Large Language Models as Explainable Metrics Shared Task的实验报告。</li>
<li>methods: 我们提议了一种零样本提示基础策略来评估摘要任务中的语言模型（LLMs）。我们在实验中使用了少量和零量样本来评估LLMs的评估效果。</li>
<li>results: 实验结果显示，LLMs可以作为NLP领域中摘要任务的评估指标，特别是在少量和零量样本情况下。我们的最佳提供的提示得到了人工评估的0.477权重相关性在测试数据上。<details>
<summary>Abstract</summary>
This paper describes the IUST NLP Lab submission to the Prompting Large Language Models as Explainable Metrics Shared Task at the Eval4NLP 2023 Workshop on Evaluation & Comparison of NLP Systems. We have proposed a zero-shot prompt-based strategy for explainable evaluation of the summarization task using Large Language Models (LLMs). The conducted experiments demonstrate the promising potential of LLMs as evaluation metrics in Natural Language Processing (NLP), particularly in the field of summarization. Both few-shot and zero-shot approaches are employed in these experiments. The performance of our best provided prompts achieved a Kendall correlation of 0.477 with human evaluations in the text summarization task on the test data. Code and results are publicly available on GitHub.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了我们在Eval4NLP 2023工作坊上提交的Prompting Large Language Models as Explainable Metrics Shared Task的实验报告。我们提议了一种零批量基于提示的方法来评估摘要任务中的大自然语言模型（LLMs）。我们进行了实验，并证明了LLMs在自然语言处理（NLP）领域中的评估能力具有普遍的潜在性。我们在这些实验中使用了少量和零量的提示方法。我们的最佳提示的性能在文本摘要任务中的测试数据上达到了0.477的科尔 correlate的水平与人类评估。我们在GitHub上公开了代码和结果。
</details></li>
</ul>
<hr>
<h2 id="Which-AI-Technique-Is-Better-to-Classify-Requirements-An-Experiment-with-SVM-LSTM-and-ChatGPT"><a href="#Which-AI-Technique-Is-Better-to-Classify-Requirements-An-Experiment-with-SVM-LSTM-and-ChatGPT" class="headerlink" title="Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT"></a>Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11547">http://arxiv.org/abs/2311.11547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelkarim El-Hajjami, Nicolas Fafin, Camille Salinesi</li>
<li>For: This paper evaluates the performance of Large Language Models (LLMs) in requirements classification, specifically comparing them to traditional methods like Support Vector Machine (SVM) and Long Short-Term Memory (LSTM).* Methods: The paper uses five diverse datasets and conducts an extensive empirical evaluation of ChatGPT models in both zero-shot and few-shot settings.* Results: The paper finds that ChatGPT consistently outperforms LSTM and is more effective than SVM in classifying functional requirements, but SVM is better in classifying non-functional requirements. Additionally, the few-shot setting does not always lead to enhanced performance, and in most instances, it was found to be suboptimal.Here is the same information in Simplified Chinese text:* For: 这篇论文评估了Large Language Models（LLMs）在需求分类中的表现，比较它们与传统方法如支持向量机（SVM）和长期快速储存（LSTM）。* Methods: 该论文使用五个多样化的数据集，进行了广泛的empirical评估，包括零shot和几个shot设置。* Results: 论文发现，ChatGPT在需求分类中一直表现出优异，并且在功能需求（FR）中表现更好 than SVM，但是在非功能需求（NFR）中，SVM表现更好。此外，几个shot设置并不总是提高性能的，在大多数情况下，它是不 оптималь的。<details>
<summary>Abstract</summary>
Context and motivation: Recently, Large Language Models (LLMs) like ChatGPT have demonstrated remarkable proficiency in various Natural Language Processing (NLP) tasks. Their application in Requirements Engineering (RE), especially in requirements classification, has gained increasing interest. Question/problem: In our research, we conducted an extensive empirical evaluation of ChatGPT models including text-davinci-003, gpt-3.5-turbo, and gpt-4 in both zero-shot and few-shot settings for requirements classification. The question arises as to how these models compare to traditional classification methods, specifically Support Vector Machine (SVM) and Long Short-Term Memory (LSTM). Principal ideas/results: Based on five diverse datasets, our results show that ChatGPT consistently outperforms LSTM, and while ChatGPT is more effective than SVM in classifying functional requirements (FR), SVM is better in classifying non-functional requirements (NFR). Our results also show that contrary to our expectations, the few-shot setting does not always lead to enhanced performance; in most instances, it was found to be suboptimal. Contribution: Our findings underscore the potential of LLMs in the RE domain, suggesting that they could play a pivotal role in future software engineering processes, particularly as tools to enhance requirements classification.
</details>
<details>
<summary>摘要</summary>
Context and motivation: 近些年来，大型自然语言模型（LLM）如ChatGPT在自然语言处理（NLP）任务中表现了惊人的能力。其应用于需求工程（RE）领域，特别是需求分类，已经引起了越来越多的兴趣。问题/问题：在我们的研究中，我们进行了广泛的empirical evaluation of ChatGPT模型，包括text-davinci-003、gpt-3.5-turbo和gpt-4等模型，在零shot和几shot设置下对需求进行分类。问题是，这些模型与传统的分类方法相比，如支持向量机（SVM）和长短期记忆（LSTM）是如何相对？主要想法/结果：根据五个多样化的数据集，我们的结果表明，ChatGPT在分类功能需求（FR）方面表现出了superior的性能，而与LSTM相比，ChatGPT在分类非功能需求（NFR）方面的性能也是比较出色。此外，我们的结果还显示，预期中，几shot设置并不总是能够提高性能，反之，大多数情况下发现它们是不 оптиimal的。贡献：我们的发现表明LLMs在RE领域中具有潜在的潜力，建议它们可能在未来的软件工程过程中扮演着关键的角色，特别是作为需求分类工具。
</details></li>
</ul>
<hr>
<h2 id="Data-driven-project-planning-An-integrated-network-learning-and-constraint-relaxation-approach-in-favor-of-scheduling"><a href="#Data-driven-project-planning-An-integrated-network-learning-and-constraint-relaxation-approach-in-favor-of-scheduling" class="headerlink" title="Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling"></a>Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11542">http://arxiv.org/abs/2311.11542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Izack Cohen<br>for:这个论文主要是为了探讨数据驱动项目规划的方法和技术。methods:该论文提出了一种基于历史数据学习的项目网络，并通过发现项目时间约束的松弛来提高项目规划和调度的灵活性。此外，论文还提出了一种基于决策规则和循环路径的项目网络增强技术。results:通过使用两个实际项目数据集，论文表明了该方法可以为项目规划提供显著的灵活性（最多减少项目 kritical path 的26%），帮助决策者在数据支持下自动进行项目规划。<details>
<summary>Abstract</summary>
Our focus is on projects, i.e., business processes, which are emerging as the economic drivers of our times. Differently from day-to-day operational processes that do not require detailed planning, a project requires planning and resource-constrained scheduling for coordinating resources across sub- or related projects and organizations. A planner in charge of project planning has to select a set of activities to perform, determine their precedence constraints, and schedule them according to temporal project constraints. We suggest a data-driven project planning approach for classes of projects such as infrastructure building and information systems development projects. A project network is first learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, from which one has to be selected, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for: 1) decoding a project variation such that it forms a new project plan, and 2) applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation. Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.
</details>
<details>
<summary>摘要</summary>
First, a project network is learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for:1. Decoding a project variation to form a new project plan.2. Applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation.Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.
</details></li>
</ul>
<hr>
<h2 id="A-New-Approach-to-Intuitionistic-Fuzzy-Decision-Making-Based-on-Projection-Technology-and-Cosine-Similarity-Measure"><a href="#A-New-Approach-to-Intuitionistic-Fuzzy-Decision-Making-Based-on-Projection-Technology-and-Cosine-Similarity-Measure" class="headerlink" title="A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure"></a>A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11539">http://arxiv.org/abs/2311.11539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Yang, Wei Su</li>
<li>For: 本研究旨在开发一种基于投影技术和偏向相似度量的多属性决策方法和医疗诊断方法，用于处理INTUITIONISTIC FUZZY SETS(IFSs)中的不确定和不完整信息。* Methods: 本研究提出了一种基于投影技术和偏向相似度量的IFS Similarity Measure，它考虑了INTUITIONISTIC FUZZY SETS(IFSs)的方向和长度，从而更好地处理不确定和不完整的信息。* Results: 实验结果表明，提出的算法可以准确地确定优质方案，并且比存在的方法更有优势。在医疗诊断领域，该方法可以快速诊断疾病。此外，本方法可以扩展到其他INTERVAL-VALUED INTUITIONISTIC FUZZY SETS(IVIFSs)中。<details>
<summary>Abstract</summary>
For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy number(IFN). Intuitionistic fuzzy set (IFS) plays an important role in dealing with un-certain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which con-siders the direction and length of IFSs at the same time, is first proposed in this paper. The objective of the presented pa-per is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some exist-ing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In medical diagnosis area, it can be used to quickly diagnose disease. The proposed method enriches the exist-ing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets(IVIFSs) as well.
</details>
<details>
<summary>摘要</summary>
For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy numbers (IFN). Intuitionistic fuzzy sets (IFS) play an important role in dealing with uncertain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which considers the direction and length of IFSs at the same time, is first proposed in this paper. The objective of the presented paper is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some existing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In the medical diagnosis area, it can be used to quickly diagnose diseases. The proposed method enriches the existing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets (IVIFSs) as well.Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Assessing-Prompt-Injection-Risks-in-200-Custom-GPTs"><a href="#Assessing-Prompt-Injection-Risks-in-200-Custom-GPTs" class="headerlink" title="Assessing Prompt Injection Risks in 200+ Custom GPTs"></a>Assessing Prompt Injection Risks in 200+ Custom GPTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11538">http://arxiv.org/abs/2311.11538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Yu, Yuhang Wu, Dong Shu, Mingyu Jin, Xinyu Xing</li>
<li>for: 这项研究的目的是阐述用户自定义GPT模型时存在的重要安全漏洞，以及这些漏洞的可能的缓解方法。</li>
<li>methods: 该研究使用了对超过200个用户定制GPT模型的测试，通过对这些模型发送敌意提示来检测和分析漏洞。</li>
<li>results: 研究发现，用户自定义GPT模型容易受到提示攻击，导致敏感信息泄露和文件访问等安全问题。这项研究提供了一种首次分析和评估漏洞缓解方法。<details>
<summary>Abstract</summary>
In the rapidly evolving landscape of artificial intelligence, ChatGPT has been widely used in various applications. The new feature: customization of ChatGPT models by users to cater to specific needs has opened new frontiers in AI utility. However, this study reveals a significant security vulnerability inherent in these user-customized GPTs: prompt injection attacks. Through comprehensive testing of over 200 user-designed GPT models via adversarial prompts, we demonstrate that these systems are susceptible to prompt injections. Through prompt injection, an adversary can not only extract the customized system prompts but also access the uploaded files. This paper provides a first-hand analysis of the prompt injection, alongside the evaluation of the possible mitigation of such attacks. Our findings underscore the urgent need for robust security frameworks in the design and deployment of customizable GPT models. The intent of this paper is to raise awareness and prompt action in the AI community, ensuring that the benefits of GPT customization do not come at the cost of compromised security and privacy.
</details>
<details>
<summary>摘要</summary>
在人工智能领域的快速发展中，ChatGPT已经广泛应用在各种应用程序中。新的特点：用户自定义ChatGPT模型以满足特定需求，开启了人工智能的新前iers。但是，这项研究发现了自定义GPT模型中的一定安全漏洞：提示插入攻击。通过对超过200个用户自定义GPT模型进行了对抗提示测试，我们证明了这些系统容易受到提示插入攻击。通过提示插入，恶意actor可以不仅提取自定义系统提示，还可以访问上传文件。本文提供了提示插入分析，以及可能的防范措施的评估。我们的发现强调了在设计和部署自定义GPT模型时需要建立 Robust安全框架，以确保人工智能的发展不会导致安全和隐私的泄露。本文的目的是提醒人工智能社区，以便通过加强安全框架，确保自定义GPT模型的利用不会伴随着安全和隐私的泄露。
</details></li>
</ul>
<hr>
<h2 id="ADAPTER-RL-Adaptation-of-Any-Agent-using-Reinforcement-Learning"><a href="#ADAPTER-RL-Adaptation-of-Any-Agent-using-Reinforcement-Learning" class="headerlink" title="ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning"></a>ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11537">http://arxiv.org/abs/2311.11537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhao Jin, Greg Slabaugh, Simon Lucas</li>
<li>for: 该论文旨在探讨游戏强化学习（Reinforcement Learning，RL） Agent 在培育环境外的挑战，包括适应性问题、迷失问题和样本不足问题。</li>
<li>methods: 该论文提出了一种新的适应策略，通过将适应器与强化学习环境结合起来，以提高基础代理的训练效率和性能。此外，该策略可以与预训练神经网络和规则引导代理结合使用，以整合人类专家知识。</li>
<li>results: 实验表明，该适应策略可以提高基础代理的性能，并且可以在各种不同的环境下进行适应。此外，该策略可以减少样本数量和训练时间，从而提高训练效率。<details>
<summary>Abstract</summary>
Deep Reinforcement Learning (DRL) agents frequently face challenges in adapting to tasks outside their training distribution, including issues with over-fitting, catastrophic forgetting and sample inefficiency. Although the application of adapters has proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper delves into the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and improvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy (RTS) game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.
</details>
<details>
<summary>摘要</summary>
深度强化学习（DRL）代理频繁面临外部任务适应性问题，包括适应过拟合、灾难性忘记和样本不足问题。虽然在超vision和自然语言处理等超话语言中应用适配器已经证明有效，但在DRL领域其潜力仍然尚未得到充分探索。本文介绍了在强化学习中适配器的集成，并提出了一种创新的适配策略，在nanoRTS环境中实验证明了基础代理的增强和训练效率的提高。我们的提议的通用方法不仅Compatible with预训练神经网络，还可以与规则型代理集成，为抽取人类专家知识提供了一种途径。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Hyperparameter-ε-for-Adaptive-Stochastic-Optimizers-through-Gradient-Histograms"><a href="#Optimal-Hyperparameter-ε-for-Adaptive-Stochastic-Optimizers-through-Gradient-Histograms" class="headerlink" title="Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers through Gradient Histograms"></a>Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers through Gradient Histograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11532">http://arxiv.org/abs/2311.11532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gustavo Silva, Paul Rodriguez</li>
<li>for: This paper aims to improve the training of deep neural network models by analyzing and optimizing the hyperparameters of adaptive optimizers, specifically the safeguard factor $\epsilon$ and momentum factor $\beta$.</li>
<li>methods: The paper proposes a new framework based on gradient histograms to analyze and justify the optimal performance of adaptive optimizers, as well as a novel algorithm that automatically estimates the reduced and accurate search space for the safeguard hyperparameter $\epsilon$.</li>
<li>results: The proposed algorithm is able to accurately estimate the optimal value of $\epsilon$ and improve the performance of adaptive optimizers. The paper also provides a comprehensive analysis of the relationships and dependencies among hyperparameters in leading adaptive optimizers.<details>
<summary>Abstract</summary>
Optimizers are essential components for successfully training deep neural network models. In order to achieve the best performance from such models, designers need to carefully choose the optimizer hyperparameters. However, this can be a computationally expensive and time-consuming process. Although it is known that all optimizer hyperparameters must be tuned for maximum performance, there is still a lack of clarity regarding the individual influence of minor priority hyperparameters, including the safeguard factor $\epsilon$ and momentum factor $\beta$, in leading adaptive optimizers (specifically, those based on the Adam optimizers). In this manuscript, we introduce a new framework based on gradient histograms to analyze and justify important attributes of adaptive optimizers, such as their optimal performance and the relationships and dependencies among hyperparameters. Furthermore, we propose a novel gradient histogram-based algorithm that automatically estimates a reduced and accurate search space for the safeguard hyperparameter $\epsilon$, where the optimal value can be easily found.
</details>
<details>
<summary>摘要</summary>
优化器是深度神经网络训练的关键组件。为了 достичь最佳性能，设计者需要精心选择优化器超参数。然而，这可以是一个计算昂贵的和时间消耗的过程。虽然已知所有优化器超参数都需要调整以实现最佳性能，但还没有准确地了解小优化器超参数，包括安全因子$\epsilon$和抓取因子$\beta$在领先的自适应优化器中的影响。在这篇论文中，我们提出了一个基于梯度 histogram的新框架，用于分析和证明自适应优化器的优化性和超参数之间的关系和依赖关系。此外，我们还提议了一种基于梯度 histogram的新算法，可以自动估算并且精度地查找 $\epsilon$ 的最佳值。
</details></li>
</ul>
<hr>
<h2 id="GPT-in-Data-Science-A-Practical-Exploration-of-Model-Selection"><a href="#GPT-in-Data-Science-A-Practical-Exploration-of-Model-Selection" class="headerlink" title="GPT in Data Science: A Practical Exploration of Model Selection"></a>GPT in Data Science: A Practical Exploration of Model Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11516">http://arxiv.org/abs/2311.11516</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathalia Nascimento, Cristina Tavares, Paulo Alencar, Donald Cowan</li>
<li>for: 本研究旨在探讨大型自然语言模型（LLM）如何在数据管理和数据科学过程中发挥作用，以及这种 интеграción 的可靠性和决策方法。</li>
<li>methods: 本研究使用了变量模型来描述选择模型的因素，并使用了小型数据集来评估模型和实现采用的各种规则。</li>
<li>results: 研究发现，GPT-4 的模型选择方法具有一定的特点和假设，可以帮助数据科学家更好地选择合适的模型，并且可以提高模型的可读性和可理解性。<details>
<summary>Abstract</summary>
There is an increasing interest in leveraging Large Language Models (LLMs) for managing structured data and enhancing data science processes. Despite the potential benefits, this integration poses significant questions regarding their reliability and decision-making methodologies. It highlights the importance of various factors in the model selection process, including the nature of the data, problem type, performance metrics, computational resources, interpretability vs accuracy, assumptions about data, and ethical considerations. Our objective is to elucidate and express the factors and assumptions guiding GPT-4's model selection recommendations. We employ a variability model to depict these factors and use toy datasets to evaluate both the model and the implementation of the identified heuristics. By contrasting these outcomes with heuristics from other platforms, our aim is to determine the effectiveness and distinctiveness of GPT-4's methodology. This research is committed to advancing our comprehension of AI decision-making processes, especially in the realm of model selection within data science. Our efforts are directed towards creating AI systems that are more transparent and comprehensible, contributing to a more responsible and efficient practice in data science.
</details>
<details>
<summary>摘要</summary>
有越来越多的 интерес在使用大型自然语言模型（LLMs）来管理结构化数据和提高数据科学过程。尽管有这些潜在的利点，但这种整合也提出了许多关于其可靠性和决策过程的问题。这些问题包括数据的性质、问题的类型、性能指标、计算资源、解释性vs准确性、数据的假设以及伦理考虑因素。我们的目标是使用变量模型来描述这些因素，并使用小型数据集来评估模型和实现的标准操作。通过对这些结果与其他平台的启发进行比较，我们希望可以确定GPT-4的方法论的效果和特点。这项研究的目标是深入探索人工智能决策过程中的模型选择过程，特别是在数据科学领域。我们的努力是创造更透明和可解释的AI系统，以便更负责任地实践数据科学。
</details></li>
</ul>
<hr>
<h2 id="MultiLoRA-Democratizing-LoRA-for-Better-Multi-Task-Learning"><a href="#MultiLoRA-Democratizing-LoRA-for-Better-Multi-Task-Learning" class="headerlink" title="MultiLoRA: Democratizing LoRA for Better Multi-Task Learning"></a>MultiLoRA: Democratizing LoRA for Better Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11501">http://arxiv.org/abs/2311.11501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Wang, Yu Lin, Xiaodong Zeng, Guannan Zhang</li>
<li>for: 这篇论文是为了提高 LoRA 模型在多任务场景中的适应性和性能而写的。</li>
<li>methods: 论文使用了 LoRA 模型，并通过缩放 LoRA 模块和修改初始化参数来减少顶层特征值的影响，以提高多任务适应性。</li>
<li>results: 与单个 LoRA 对照组比较，MultiLoRA 具有更好的多任务适应性和性能，只需增加 2.5% 的参数量。此外，对 MultiLoRA 的参数更新矩阵的分析表明，它具有更多的卷积特征值贡献。<details>
<summary>Abstract</summary>
LoRA achieves remarkable resource efficiency and comparable performance when adapting LLMs for specific tasks. Since ChatGPT demonstrated superior performance on various tasks, there has been a growing desire to adapt one model for all tasks. However, the explicit low-rank of LoRA limits the adaptation performance in complex multi-task scenarios. LoRA is dominated by a small number of top singular vectors while fine-tuning decomposes into a set of less important unitary transforms. In this paper, we propose MultiLoRA for better multi-task adaptation by reducing the dominance of top singular vectors observed in LoRA. MultiLoRA scales LoRA modules horizontally and change parameter initialization of adaptation matrices to reduce parameter dependency, thus yields more balanced unitary subspaces. We unprecedentedly construct specialized training data by mixing datasets of instruction follow, natural language understanding, world knowledge, to cover semantically and syntactically different samples. With only 2.5% of additional parameters, MultiLoRA outperforms single LoRA counterparts and fine-tuning on multiple benchmarks and model scales. Further investigation into weight update matrices of MultiLoRA exhibits reduced dependency on top singular vectors and more democratic unitary transform contributions.
</details>
<details>
<summary>摘要</summary>
LoRA 实现了非常出色的资源效率和相对性能，当适应特定任务时。由于 ChatGPT 在多种任务上表现出色，因此有越来越多的欲适应一模型 для所有任务。然而，LoRA 的明确低级别限制了复杂多任务场景中的适应性能。LoRA 由一小数量的顶部射影 вектор控制，而 fine-tuning 分解为一组 less important 的射影变换。在这篇论文中，我们提议 MultiLoRA 来改善多任务适应性能。MultiLoRA 缩放 LoRA 模块水平，并改变适应矩阵的参数初始化，从而减少参数依赖性，因此生成更均衡的射影空间。我们在特定数据集上构建了专门的训练数据，混合了 instruction follow、自然语言理解、世界知识等数据集，以覆盖Semantic 和 Sintactic 不同的样本。尽管增加了 2.5% 的参数，MultiLoRA 仍然超越了单个 LoRA 对手和 fine-tuning 多个benchmark和模型缩放。进一步的调查表明，MultiLoRA 的Weight 更新矩阵中减少了顶部射影 vector 的依赖性，并且各个射影变换均有更大的贡献。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-in-Machine-Learning-on-the-Interplay-with-Explainability-Predictive-Performances-and-Models"><a href="#Interpretability-in-Machine-Learning-on-the-Interplay-with-Explainability-Predictive-Performances-and-Models" class="headerlink" title="Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models"></a>Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11491">http://arxiv.org/abs/2311.11491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Leblanc, Pascal Germain</li>
<li>for: 本文旨在清楚地解释机器学习领域中的可解释性概念，以帮助读者理解这个抽象概念，并且�challenge 一些关于可解释性的常见 misunderstanding。</li>
<li>methods: 本文使用了一种Position paper的形式，通过对机器学习中的重要概念进行分析和讨论，来帮助读者更深入地理解可解释性的关系。</li>
<li>results: 本文的结论是，可解释性和解释性不是可交换的概念，而且一个机器学习模型的可解释性不可能与它的预测性能直接相关。<details>
<summary>Abstract</summary>
Interpretability has recently gained attention in the field of machine learning, for it is crucial when it comes to high-stakes decisions or troubleshooting. This abstract concept is hard to grasp and has been associated, over time, with many labels and preconceived ideas. In this position paper, in order to clarify some misunderstandings regarding interpretability, we discuss its relationship with significant concepts in machine learning: explainability, predictive performances, and machine learning models. For instance, we challenge the idea that interpretability and explainability are substitutes to one another, or that a fixed degree of interpretability can be associated with a given machine learning model.
</details>
<details>
<summary>摘要</summary>
《 interpretability 在机器学习领域最近受到了关注，因为它在高风险决策或维护问题时是非常重要的。这个抽象的概念很难理解，并且在过去有很多标签和先入为主的想法。在这篇Position paper中，我们为了解决一些关于 interpretability 的误解，讨论了它与机器学习中重要的概念之间的关系，如 explainability、预测性能和机器学习模型。例如，我们挑战了认为 interpretability 和 explainability 是可交换的想法，或者一个固定的 interpretability 水平可以与某种机器学习模型相关联。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Multi-Center-Study-on-the-Adaptability-of-a-Shared-Foundation-Model-for-Electronic-Health-Records"><a href="#A-Multi-Center-Study-on-the-Adaptability-of-a-Shared-Foundation-Model-for-Electronic-Health-Records" class="headerlink" title="A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records"></a>A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11483">http://arxiv.org/abs/2311.11483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Lawrence Guo, Jason Fries, Ethan Steinberg, Scott Lanyon Fleming, Keith Morse, Catherine Aftandilian, Jose Posada, Nigam Shah, Lillian Sung</li>
<li>for: 这个论文的目的是检验基础模型在不同医院中的适用性以及对本地任务的适应性。</li>
<li>methods: 这个论文使用了基础模型，并在不同医院的数据上进行了适应性测试。</li>
<li>results: 研究发现，通过继续预训基础模型在本地数据上，可以提高模型的性能，并且可以比基于所有数据进行本地训练的模型减少训练样本的百分比。<details>
<summary>Abstract</summary>
Foundation models hold promise for transforming AI in healthcare by providing modular components that are easily adaptable to downstream healthcare tasks, making AI development more scalable and cost-effective. Structured EHR foundation models, trained on coded medical records from millions of patients, demonstrated benefits including increased performance with fewer training labels, and improved robustness to distribution shifts. However, questions remain on the feasibility of sharing these models across different hospitals and their performance for local task adaptation. This multi-center study examined the adaptability of a recently released structured EHR foundation model ($FM_{SM}$), trained on longitudinal medical record data from 2.57M Stanford Medicine patients. Experiments were conducted using EHR data at The Hospital for Sick Children and MIMIC-IV. We assessed both adaptability via continued pretraining on local data, and task adaptability compared to baselines of training models from scratch at each site, including a local foundation model. We evaluated the performance of these models on 8 clinical prediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$ matched the performance of GBM models locally trained on all data while providing a 13% improvement in settings with few task-specific training labels. With continued pretraining on local data, label efficiency substantially improved, such that $FM_{SM}$ required fewer than 1% of training examples to match the fully trained GBM's performance. Continued pretraining was also 60 to 90% more sample-efficient than training local foundation models from scratch. Our findings show that adapting shared EHR foundation models across hospitals provides improved prediction performance at less cost, underscoring the utility of base foundation models as modular components to streamline the development of healthcare AI.
</details>
<details>
<summary>摘要</summary>
基础模型在医疗健康领域中的应用显示了承诺，它们可以提供可重用的组件，使AI开发更加扩展和成本效果。在结构化电子医疗记录（EHR）基础模型上，训练在CODED医疗记录数据上 millions of patients 的情况下，显示了几个优点，包括增加性能，采用 fewer training labels，和鲁棒性提升。然而，在不同医院共享这些模型的问题仍然存在。本多中心研究检查了一个最近发布的结构化EHR基础模型($FM_{SM}$) ，训练在斯坦福医学院的长期医疗记录数据上2.57M 个患者。实验使用了医疗记录数据在医疗儿童医院和MIMIC-IV上。我们评估了这些模型在8个临床预测任务上的适应性和任务适应性，并与基线模型从 scratch 训练在每个站点上进行比较。我们发现，在两个数据集上，通过继续预训 $FM_{SM}$ 可以与基线模型在本地训练所达到的性能匹配，并且提供了13%的提高。在具有少量任务特定训练标签的情况下，通过继续预训，标签效率显著提高，使 $FM_{SM}$ 需要 fewer than 1% of training examples 来匹配完全训练的 GBM 的性能。继续预训还比从 scratch 训练本地基础模型60%-90% 更sample-efficient。我们的发现表明，在医疗机构之间共享EHR基础模型可以提供改进的预测性能，并且可以降低成本，这些基础模型作为医疗AI开发的模块化组件，可以加速开发。
</details></li>
</ul>
<hr>
<h2 id="Meta-Prompting-for-AGI-Systems"><a href="#Meta-Prompting-for-AGI-Systems" class="headerlink" title="Meta Prompting for AGI Systems"></a>Meta Prompting for AGI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11482">http://arxiv.org/abs/2311.11482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meta-prompting/meta-prompting">https://github.com/meta-prompting/meta-prompting</a></li>
<li>paper_authors: Yifan Zhang</li>
<li>for: 本研究探讨了一种新型的大语言模型（LLM）、多Modal基础模型和人工智能系统的问题解决和数据解释方法——Meta Prompting。</li>
<li>methods: 本研究使用了类型理论和类型理论来强调信息结构和 syntax，提供了一种独特的框架，超越传统的内容重点方法。</li>
<li>results: 本研究展示了Meta Prompting在复杂逻辑问题解决方面的优势，能够将复杂问题分解成可管理的子问题，从而实现步骤化、详细的问题解决方式，提高了Token效率和对问题解决方案的公平比较。此外，本研究还推广了Meta Prompting到多Modal基础模型设置，实现了多种数据类型的集成，并处理了复杂多方面的数据。<details>
<summary>Abstract</summary>
This paper presents an in-depth exploration of Meta Prompting, a novel technique that revolutionizes the way large language models (LLMs), multi-modal foundation models, and AI systems approach problem-solving and data interpretation. Meta Prompting, rooted in type theory and category theory, prioritizes the structure and syntax of information, providing a unique framework that transcends traditional content-focused methods. We delve into the formal definitions of Meta Prompting, contrasting it with Few-Shot Prompting, and highlight its applicability and superiority in various AI applications.   Key to this exploration is the expansion of Meta Prompting into the realm of complex reasoning. Here, we demonstrate how this technique adeptly breaks down intricate problems into manageable sub-problems, facilitating a step-by-step, detailed approach to problem-solving. This method proves especially advantageous in terms of token efficiency and offering a fair comparison in problem-solving scenarios, standing out against few-shot example approaches.   Furthermore, the paper breaks new ground by extending Meta Prompting into multi-modal foundation model settings. This extension addresses the integration of diverse data types, such as images, audio, and video, within the structured framework of Meta Prompting, highlighting both the challenges and the vast potential of this approach in handling complex, multi-faceted data (The code is available at https://github.com/meta-prompting/meta-prompting).
</details>
<details>
<summary>摘要</summary>
Key to this exploration is the expansion of Meta Prompting into the realm of complex reasoning. This technique breaks down intricate problems into manageable sub-problems, facilitating a step-by-step, detailed approach to problem-solving. This method is especially advantageous in terms of token efficiency and offers a fair comparison in problem-solving scenarios, standing out against few-shot example approaches.Furthermore, the paper extends Meta Prompting into multi-modal foundation model settings, addressing the integration of diverse data types, such as images, audio, and video, within the structured framework of Meta Prompting. This approach highlights the challenges and vast potential of handling complex, multi-faceted data. The code is available at https://github.com/meta-prompting/meta-prompting.Translation Notes:1. 大language model (LLMs) 翻译为 "大型语言模型"2. multi-modal foundation models 翻译为 "多Modal基础模型"3. Few-Shot Prompting 翻译为 "少数示例提示"4. Token efficiency 翻译为 "Token效率"5. problem-solving scenarios 翻译为 "问题解决场景"6.  multi-faceted data 翻译为 "多方面数据"
</details></li>
</ul>
<hr>
<h2 id="Empowering-remittance-management-in-the-digitised-landscape-A-real-time-Data-Driven-Decision-Support-with-predictive-abilities-for-financial-transactions"><a href="#Empowering-remittance-management-in-the-digitised-landscape-A-real-time-Data-Driven-Decision-Support-with-predictive-abilities-for-financial-transactions" class="headerlink" title="Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions"></a>Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11476">http://arxiv.org/abs/2311.11476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rashikala Weerawarna, Shah J Miah</li>
<li>for: 这项研究是为了探讨区块链技术在移动财务领域的应用和优势，并开发了一种数据驱动预测决策支持方法，以帮助管理层决策者在面对不确定的数字化领域中更好地管理移动财务公司。</li>
<li>methods: 该研究采用了理论生成的设计科学研究方法，通过分析交易大数据，发现了预测能力的emergence。该方法结合预测统计和机器学习，以实时监测移动财务，使管理层能够更好地 Address challenges in the uncertain digitized landscape of blockchain-oriented remittance companies。</li>
<li>results: 该研究不仅增强了移动财务领域的安全性，还为未来的预测决策支持解决方案 lay the foundation。此外，通过实施这种方法，生成了一些有价值的理论，扩展了设计科学研究的领域，并促进了在信息系统领域的理论发展。<details>
<summary>Abstract</summary>
The advent of Blockchain technology (BT) revolutionised the way remittance transactions are recorded. Banks and remittance organisations have shown a growing interest in exploring blockchain's potential advantages over traditional practices. This paper presents a data-driven predictive decision support approach as an innovative artefact designed for the blockchain-oriented remittance industry. Employing a theory-generating Design Science Research (DSR) approach, we have uncovered the emergence of predictive capabilities driven by transactional big data. The artefact integrates predictive analytics and Machine Learning (ML) to enable real-time remittance monitoring, empowering management decision-makers to address challenges in the uncertain digitised landscape of blockchain-oriented remittance companies. Bridging the gap between theory and practice, this research not only enhances the security of the remittance ecosystem but also lays the foundation for future predictive decision support solutions, extending the potential of predictive analytics to other domains. Additionally, the generated theory from the artifact's implementation enriches the DSR approach and fosters grounded and stakeholder theory development in the information systems domain.
</details>
<details>
<summary>摘要</summary>
随着区块链技术（BT）的出现，Remittance交易记录方式发生了革命性的变革。银行和投递机构对区块链的潜在优势表示了增加的兴趣。这篇论文介绍了一种基于区块链的数据驱动预测决策支持方法，作为区块链投递业的创新艺品。通过使用理论生成Design Science Research（DSR）方法，我们发现了基于交易大数据的预测能力的出现。该艺品集成预测分析和机器学习（ML），以实时监控投递，让管理决策者在区块链投递公司的不确定数字化景观中做出更加有力的决策。这项研究不仅提高了投递生态系统的安全性，还为未来的预测决策支持解决方案提供了基础，扩展了预测分析的潜在应用范围。此外，艺品实施中生成的理论不仅扩充了DSR方法，还激发了在信息系统领域的基准和参与者理论的发展。
</details></li>
</ul>
<hr>
<h2 id="CSGNN-Conquering-Noisy-Node-labels-via-Dynamic-Class-wise-Selection"><a href="#CSGNN-Conquering-Noisy-Node-labels-via-Dynamic-Class-wise-Selection" class="headerlink" title="CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection"></a>CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11473">http://arxiv.org/abs/2311.11473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Li, Zhen Tan, Kai Shu, Zongsheng Cao, Yu Kong, Huan Liu</li>
<li>for: 本文旨在提出一种基于图 neural network 的选择算法，以适应图像数据中的分类异常和标签噪声问题。</li>
<li>methods: 本文提出了一种名为 CSGNN 的新方法，它使用邻居积分的秘密空间来适应不同类别的信任计算机。特别是，通过使用动态分类选择机制和邻居积分的清洁节点选择算法，CSGNN 可以避免全局阈值技术中的偏袋问题。</li>
<li>results: 经过广泛的实验，CSGNN 比前STATE-OF-THE-ART 方法更高效和更稳定。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have emerged as a powerful tool for representation learning on graphs, but they often suffer from overfitting and label noise issues, especially when the data is scarce or imbalanced. Different from the paradigm of previous methods that rely on single-node confidence, in this paper, we introduce a novel Class-wise Selection for Graph Neural Networks, dubbed CSGNN, which employs a neighbor-aggregated latent space to adaptively select reliable nodes across different classes. Specifically, 1) to tackle the class imbalance issue, we introduce a dynamic class-wise selection mechanism, leveraging the clustering technique to identify clean nodes based on the neighbor-aggregated confidences. In this way, our approach can avoid the pitfalls of biased sampling which is common with global threshold techniques. 2) To alleviate the problem of noisy labels, built on the concept of the memorization effect, CSGNN prioritizes learning from clean nodes before noisy ones, thereby iteratively enhancing model performance while mitigating label noise. Through extensive experiments, we demonstrate that CSGNN outperforms state-of-the-art methods in terms of both effectiveness and robustness.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 已经成为图像学习中的一种强大工具，但它们经常受到预测和标签噪声问题的影响，特别是当数据稀缺或不均衡时。与过去的方法不同，在这篇论文中，我们提出了一种新的类别选择方法 для GRAPH NEURAL NETWORKS，名为CSGNN，该方法使用邻居聚合的秘密空间来自适应性地选择可靠的节点。specifically，我们实现了以下两点：1. 解决类别不均衡问题，我们引入了动态类别选择机制，基于邻居聚合的信任程度来 indentify 干净的节点。这种方法可以避免全局阈值技术中的偏袋sampling问题。2. 为了缓解标签噪声问题，CSGNN 利用了记忆效应的概念，在干净的节点之前学习从噪声节点，从而逐步提高模型性能而减少标签噪声。通过广泛的实验，我们证明了CSGNN 在效果和稳定性两个方面都能够超越当前的状态态法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.AI_2023_11_20/" data-id="clp869tsh0084k588eer12enz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/20/cs.CV_2023_11_20/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-11-20
        
      </div>
    </a>
  
  
    <a href="/2023/11/20/cs.CL_2023_11_20/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-11-20</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
