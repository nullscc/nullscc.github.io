
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-11-20 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.12023 repo_url: https:&#x2F;&#x2F;github.com&#x2F;hanguo97&#x2F;lq-lora paper_authors: Ha">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-11-20">
<meta property="og:url" content="https://nullscc.github.io/2023/11/20/cs.CL_2023_11_20/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.12023 repo_url: https:&#x2F;&#x2F;github.com&#x2F;hanguo97&#x2F;lq-lora paper_authors: Ha">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-20T11:00:00.000Z">
<meta property="article:modified_time" content="2023-11-21T10:06:16.080Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.CL_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T11:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-11-20
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="LQ-LoRA-Low-rank-Plus-Quantized-Matrix-Decomposition-for-Efficient-Language-Model-Finetuning"><a href="#LQ-LoRA-Low-rank-Plus-Quantized-Matrix-Decomposition-for-Efficient-Language-Model-Finetuning" class="headerlink" title="LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning"></a>LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12023">http://arxiv.org/abs/2311.12023</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanguo97/lq-lora">https://github.com/hanguo97/lq-lora</a></li>
<li>paper_authors: Han Guo, Philip Greengard, Eric P. Xing, Yoon Kim</li>
<li>for:  Memory-efficient adaptation of pretrained language models</li>
<li>methods:  Iterative algorithm for decomposing pretrained matrices into low-rank and quantized components, integer linear programming for dynamic configuration of quantization parameters, data-aware version of the algorithm using approximation of Fisher information matrix</li>
<li>results:  Outperforms strong baselines and enables more aggressive quantization, able to learn a 2.5-bit model that is competitive with a 4-bit model, and can be used for model compression with a 2.75-bit model that is competitive with the original model in full precision.Here’s the Chinese text in the format you requested:</li>
<li>for: 该文章提出了一种简单的方法来实现准确精炼的语言模型适应。</li>
<li>methods: 该方法使用迭代算法将预训练矩阵分解为精度高低维度组件和快速量化组件。在训练中，量化组件保持不变，只有低维度组件进行更新。文章还提出了一种基于 Fisher 信息矩阵的估计的数据意识版本，用于在矩阵分解中Weight reconstruction 目标。</li>
<li>results:  experiments 表明，该方法可以超越强基elines 和 GPTQ-LoRA 基elines，并且可以实现更加减少量化。例如，在 OpenAssistant 测试集上，LQ-LoRA 可以学习一个2.5位LLaMA-2 模型，与4位 QLoRA 基elines 相当。此外，当用于语言模型训练集时，LQ-LoRA 也可以用于模型压缩。在这种情况下，我们的2.75位LLaMA-2-70B 模型（其中2.85位平均包括低维度组件）与原始模型相当，需要27GB的GPU内存。<details>
<summary>Abstract</summary>
We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative algorithm to decompose each pretrained matrix into a high-precision low-rank component and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget. We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the reconstruction objective during matrix decomposition. Experiments on adapting RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and moreover enables more aggressive quantization. For example, on the OpenAssistant benchmark LQ-LoRA is able to learn a 2.5-bit LLaMA-2 model that is competitive with a model finetuned with 4-bit QLoRA. When finetuned on a language modeling calibration dataset, LQ-LoRA can also be used for model compression; in this setting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when including the low-rank components and requires 27GB of GPU memory) is competitive with the original model in full precision.
</details>
<details>
<summary>摘要</summary>
我们提出一种简单的方法用于快速适应预训练语言模型，该方法使用迭代算法将预训练矩阵 decomposed 成高精度低级分量和快速量化分量。在训练期间，量化分量保持不变，只有低级分量进行更新。我们提出一个整数线性程序表示 Quantization 分量，可以动态配置量化参数（例如，比特宽、块大小）给每个矩阵，以达到总目标内存预算。我们进一步探索使用投影函数来权重矩阵分解的数据意识版本，并在实验中表明这种方法可以超越强QLoRA和GPTQ-LoRA基elines，并且可以实现更加迅速的量化。例如，在 OpenAssistant benchmark 上，LQ-LoRA 可以学习一个 2.5 位 LLaMA-2 模型，与使用 4 位 QLoRA 基eline 学习的模型相当。当训练在语言模型调整数据集时，LQ-LoRA 还可以用于模型压缩；在这种设置下，我们的 2.75 位 LLaMA-2-70B 模型（其中 2.85 位在包括低级分量时）与原始模型相当，需要 27GB 的 GPU 内存。
</details></li>
</ul>
<hr>
<h2 id="GPT-4V-ision-for-Robotics-Multimodal-Task-Planning-from-Human-Demonstration"><a href="#GPT-4V-ision-for-Robotics-Multimodal-Task-Planning-from-Human-Demonstration" class="headerlink" title="GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration"></a>GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12015">http://arxiv.org/abs/2311.12015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi</li>
<li>For: This paper enhances a general-purpose Vision Language Model, GPT-4V(ision), to facilitate robotic manipulation by integrating observations of human actions.* Methods: The system analyzes videos of humans performing tasks and creates executable robot programs that incorporate affordance insights. The computation starts by analyzing the videos with GPT-4V to convert environmental and action details into text, followed by a GPT-4-empowered task planner. Vision systems then reanalyze the video with the task plan, using an open-vocabulary object detector to ground object names and detect the moment of grasping and releasing.* Results: Experiments across various scenarios demonstrate the method’s efficacy in achieving real robots’ operations from human demonstrations in a zero-shot manner.Here’s the Chinese translation of the three information points:* For: 这篇论文用GPT-4V(ision)扩展一个通用视力语言模型，以便机器人操作。* Methods: 该系统通过分析人类行为视频来生成可执行的机器人程序，并将环境和动作细节转化为文本。计算开始于GPT-4V分析视频，然后是由GPT-4强化的任务规划器。然后，视觉系统再次分析视频，使用开放词汇物体检测器将物体名称降到实际物体上。* Results: 实验结果表明，该方法在不同场景下可以实现人类示例操作的真正机器人操作，无需预先训练或示例数据。<details>
<summary>Abstract</summary>
We introduce a pipeline that enhances a general-purpose Vision Language Model, GPT-4V(ision), by integrating observations of human actions to facilitate robotic manipulation. This system analyzes videos of humans performing tasks and creates executable robot programs that incorporate affordance insights. The computation starts by analyzing the videos with GPT-4V to convert environmental and action details into text, followed by a GPT-4-empowered task planner. In the following analyses, vision systems reanalyze the video with the task plan. Object names are grounded using an open-vocabulary object detector, while focus on the hand-object relation helps to detect the moment of grasping and releasing. This spatiotemporal grounding allows the vision systems to further gather affordance data (e.g., grasp type, way points, and body postures). Experiments across various scenarios demonstrate this method's efficacy in achieving real robots' operations from human demonstrations in a zero-shot manner. The prompts of GPT-4V/GPT-4 are available at this project page: https://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/
</details>
<details>
<summary>摘要</summary>
我们介绍一个管线，将通用视觉语言模型GPT-4V（vision）与人类行为观察结合，以便帮助机器人进行操作。这个系统会分析人们在完成任务时的视频，并将任务规划转换为可执行的机器人程式码。首先，我们使用GPT-4V分析视频，将环境和动作细节转换为文本。接着，我们使用GPT-4来实现任务规划。在进一步的分析中，我们使用视觉系统重新分析视频，并使用开放 vocabulary 物体检测器来固定物体名称。这种空间时间联系允许视觉系统进一步获取可行性资料（例如抓取型态、方向点和身体姿态）。实验结果显示，这种方法可以将人类示例中的实际机器人操作实现在零条件下。GPT-4V/GPT-4的提示可以在这个项目页面获取：https://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/
</details></li>
</ul>
<hr>
<h2 id="H-COAL-Human-Correction-of-AI-Generated-Labels-for-Biomedical-Named-Entity-Recognition"><a href="#H-COAL-Human-Correction-of-AI-Generated-Labels-for-Biomedical-Named-Entity-Recognition" class="headerlink" title="H-COAL: Human Correction of AI-Generated Labels for Biomedical Named Entity Recognition"></a>H-COAL: Human Correction of AI-Generated Labels for Biomedical Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11981">http://arxiv.org/abs/2311.11981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojing Duan, John P. Lalor</li>
<li>for: 这个论文的目的是提出一种新的人工智能生成标签 corrections 框架，以便在医疗领域中使用。</li>
<li>methods: 该论文使用了一种新的排名方法，可以选择性地更正人工智能生成的标签，以达到黄金标准性的表现（100%的人工标注），但需要 significatively less human effort。</li>
<li>results: 研究发现，对5%的标签进行更正，可以提高表现相对评估的改善率达64%，对20%的标签进行更正，可以提高表现相对评估的改善率达86%。<details>
<summary>Abstract</summary>
With the rapid advancement of machine learning models for NLP tasks, collecting high-fidelity labels from AI models is a realistic possibility. Firms now make AI available to customers via predictions as a service (PaaS). This includes PaaS products for healthcare. It is unclear whether these labels can be used for training a local model without expensive annotation checking by in-house experts. In this work, we propose a new framework for Human Correction of AI-Generated Labels (H-COAL). By ranking AI-generated outputs, one can selectively correct labels and approach gold standard performance (100% human labeling) with significantly less human effort. We show that correcting 5% of labels can close the AI-human performance gap by up to 64% relative improvement, and correcting 20% of labels can close the performance gap by up to 86% relative improvement.
</details>
<details>
<summary>摘要</summary>
随着机器学习模型对自然语言处理任务的快速进步，收集高准确度标签从AI模型是一个现实可能性。现在，企业通过预测作为服务（PaaS）提供AI给客户。这包括医疗领域的Paas产品。未知的是，这些标签是否可以用于本地模型的训练而不需要高昂的人工标注检查。在这种工作中，我们提出了一个新的人工纠正AI生成标签的框架（H-COAL）。通过对AI生成输出进行排名，可以选择性地纠正标签，并 approaching gold standard performance（100%人工标注）with significantly less human effort。我们显示，对5%的标签进行纠正可以在相对改进率为64%之间关闭AI-人工性能差距，而对20%的标签进行纠正可以在相对改进率为86%之间关闭性能差距。
</details></li>
</ul>
<hr>
<h2 id="On-the-Potential-and-Limitations-of-Few-Shot-In-Context-Learning-to-Generate-Metamorphic-Specifications-for-Tax-Preparation-Software"><a href="#On-the-Potential-and-Limitations-of-Few-Shot-In-Context-Learning-to-Generate-Metamorphic-Specifications-for-Tax-Preparation-Software" class="headerlink" title="On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software"></a>On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11979">http://arxiv.org/abs/2311.11979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dananjay Srinivas, Rohan Das, Saeid Tizpaz-Niari, Ashutosh Trivedi, Maria Leonor Pacheco</li>
<li>for: 这篇论文是为了探讨如何使用自然语言处理技术生成税务软件测试用例的。</li>
<li>methods: 该论文使用了大语言模型进行语料处理，并将 extracted from tax documents 表示为对照逻辑逻辑形式进行翻译。</li>
<li>results: 该论文提出了一个研究计划，旨在自动生成税务软件测试用例。<details>
<summary>Abstract</summary>
Due to the ever-increasing complexity of income tax laws in the United States, the number of US taxpayers filing their taxes using tax preparation software (henceforth, tax software) continues to increase. According to the U.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed their individual income taxes using tax software. Given the legal consequences of incorrectly filing taxes for the taxpayer, ensuring the correctness of tax software is of paramount importance. Metamorphic testing has emerged as a leading solution to test and debug legal-critical tax software due to the absence of correctness requirements and trustworthy datasets. The key idea behind metamorphic testing is to express the properties of a system in terms of the relationship between one input and its slightly metamorphosed twinned input. Extracting metamorphic properties from IRS tax publications is a tedious and time-consuming process. As a response, this paper formulates the task of generating metamorphic specifications as a translation task between properties extracted from tax documents - expressed in natural language - to a contrastive first-order logic form. We perform a systematic analysis on the potential and limitations of in-context learning with Large Language Models(LLMs) for this task, and outline a research agenda towards automating the generation of metamorphic specifications for tax preparation software.
</details>
<details>
<summary>摘要</summary>
Metamorphic testing has emerged as a leading solution to test and debug legal-critical tax software due to the lack of correctness requirements and trustworthy datasets. The core idea of metamorphic testing is to express the properties of a system in terms of the relationship between one input and its slightly modified twin input. However, extracting metamorphic properties from IRS tax publications is a laborious and time-consuming process.To address this challenge, this paper proposes the task of generating metamorphic specifications as a translation task between properties extracted from tax documents (expressed in natural language) and a contrastive first-order logic form. We conduct a systematic analysis of the potential and limitations of in-context learning with large language models (LLMs) for this task and outline a research agenda towards automating the generation of metamorphic specifications for tax preparation software.
</details></li>
</ul>
<hr>
<h2 id="Context-aware-Neural-Machine-Translation-for-English-Japanese-Business-Scene-Dialogues"><a href="#Context-aware-Neural-Machine-Translation-for-English-Japanese-Business-Scene-Dialogues" class="headerlink" title="Context-aware Neural Machine Translation for English-Japanese Business Scene Dialogues"></a>Context-aware Neural Machine Translation for English-Japanese Business Scene Dialogues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11976">http://arxiv.org/abs/2311.11976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/su0315/discourse_context_mt">https://github.com/su0315/discourse_context_mt</a></li>
<li>paper_authors: Sumire Honda, Patrick Fernandes, Chrysoula Zerva</li>
<li>for: 这个论文的目的是提高英日商务对话翻译的性能，并研究Context-awareness如何改善现有的Neural Machine Translation（NMT）模型。</li>
<li>methods: 该论文使用了预训练的mBART模型，并在多句话对话数据上进行了微调。 authors还提出了一些新的上下文编码方法，如说话人转换和场景类型。</li>
<li>results: 研究发现，模型可以利用以前句子和EXTRA-sentential context（使用CXMI指标），并且在增加上下文大小时，翻译质量得到了改善。 authors还提供了一些关于荣誉译法的更加细化的分析。<details>
<summary>Abstract</summary>
Despite the remarkable advancements in machine translation, the current sentence-level paradigm faces challenges when dealing with highly-contextual languages like Japanese. In this paper, we explore how context-awareness can improve the performance of the current Neural Machine Translation (NMT) models for English-Japanese business dialogues translation, and what kind of context provides meaningful information to improve translation. As business dialogue involves complex discourse phenomena but offers scarce training resources, we adapted a pretrained mBART model, finetuning on multi-sentence dialogue data, which allows us to experiment with different contexts. We investigate the impact of larger context sizes and propose novel context tokens encoding extra-sentential information, such as speaker turn and scene type. We make use of Conditional Cross-Mutual Information (CXMI) to explore how much of the context the model uses and generalise CXMI to study the impact of the extra-sentential context. Overall, we find that models leverage both preceding sentences and extra-sentential context (with CXMI increasing with context size) and we provide a more focused analysis on honorifics translation. Regarding translation quality, increased source-side context paired with scene and speaker information improves the model performance compared to previous work and our context-agnostic baselines, measured in BLEU and COMET metrics.
</details>
<details>
<summary>摘要</summary>
尽管机器翻译技术已取得了很大进步，但当面临高Contextual语言如日语时，现有句子级别模型却遇到了挑战。在这篇论文中，我们 explore了如何通过Context-awareness提高当前的Neural Machine Translation（NMT）模型在英日商业对话翻译中的表现，以及哪些Context提供了有用信息以提高翻译。商业对话具有复杂的Discourse现象，但受限于scarce的训练资源，我们采用了预训练的mBART模型，并在多句话对话数据上进行了微调。我们调查了不同Context大小的影响和提出了新的Context字符串编码方法，以捕捉extra-sentential信息，如发言人轮换和场景类型。我们使用Conditional Cross-Mutual Information（CXMI）来探索模型如何使用Context，并推广CXMI来研究额外的Context的影响。总之，我们发现模型可以利用前一句和extra-sententialContext（CXMI随着Context大小增加），并对尊敬语翻译进行了更加精细的分析。在翻译质量方面，增加源 сторо面Context，并将场景和发言人信息加入，与前一个工作和无Context基eline相比，提高了模型的表现， measured by BLEU和COMET指标。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Training-Distributions-with-Scalable-Online-Bilevel-Optimization"><a href="#Adaptive-Training-Distributions-with-Scalable-Online-Bilevel-Optimization" class="headerlink" title="Adaptive Training Distributions with Scalable Online Bilevel Optimization"></a>Adaptive Training Distributions with Scalable Online Bilevel Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11973">http://arxiv.org/abs/2311.11973</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Grangier, Pierre Ablin, Awni Hannun</li>
<li>for: 这个研究是为了改善现代机器学习中使用大规模神经网络的情况，特别是当预训数据的分布与应用领域的分布不同时。</li>
<li>methods: 这个研究提出了一个基于线上两层优化问题的算法，具体来说是使用预训数据中的一小批数据来修改预训分布，以提高模型在应用领域的性能。</li>
<li>results: 这个研究透过实验表明，在某些情况下，这种方法可以比过去对应领域的预训方法perform better，但在其他情况下可能不会成功。研究还提出了一个简单的测试方法，可以判断这种方法是否适合使用。<details>
<summary>Abstract</summary>
Large neural networks pretrained on web-scale corpora are central to modern machine learning. In this paradigm, the distribution of the large, heterogeneous pretraining data rarely matches that of the application domain. This work considers modifying the pretraining distribution in the case where one has a small sample of data reflecting the targeted test conditions. We propose an algorithm motivated by a recent formulation of this setting as an online, bilevel optimization problem. With scalability in mind, our algorithm prioritizes computing gradients at training points which are likely to most improve the loss on the targeted distribution. Empirically, we show that in some cases this approach is beneficial over existing strategies from the domain adaptation literature but may not succeed in other cases. We propose a simple test to evaluate when our approach can be expected to work well and point towards further research to address current limitations.
</details>
<details>
<summary>摘要</summary>
大型神经网络在现代机器学习中扮演着重要角色。在这个思想模式下，大规模预训练数据的分布罕见与应用领域的分布相匹配。本文考虑在有限个数据样本表征目标测试条件时修改预训练分布。我们提出一种由最近的线性Programming问题概念激发的算法。针对可扩展性，我们的算法优先计算预训练点的梯度，以便最大化目标分布上的损失。实验表明，在某些情况下，我们的方法可以超越现有的领域适应Literature中的策略，但在其他情况下可能不成功。我们提出一种简单的测试方法，用于评估我们的方法在哪些情况下能够取得良好效果，并指向进一步的研究以解决当前的限制。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Analysis-of-Substantiation-in-Scientific-Peer-Reviews"><a href="#Automatic-Analysis-of-Substantiation-in-Scientific-Peer-Reviews" class="headerlink" title="Automatic Analysis of Substantiation in Scientific Peer Reviews"></a>Automatic Analysis of Substantiation in Scientific Peer Reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11967">http://arxiv.org/abs/2311.11967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanzhu Guo, Guokan Shang, Virgile Rennard, Michalis Vazirgiannis, Chloé Clavel</li>
<li>for: 提高 NLP 会议上 peer review 质量的自动控制 measure。</li>
<li>methods: 使用 claim-evidence 对 peer review 进行自动评估，基于 SubstanReview 数据集进行训练。</li>
<li>results: 通过 SubstanReview 数据集的分析，获得了对 peer review 质量的深入理解，并可以自动评估 peer review 的质量。<details>
<summary>Abstract</summary>
With the increasing amount of problematic peer reviews in top AI conferences, the community is urgently in need of automatic quality control measures. In this paper, we restrict our attention to substantiation -- one popular quality aspect indicating whether the claims in a review are sufficiently supported by evidence -- and provide a solution automatizing this evaluation process. To achieve this goal, we first formulate the problem as claim-evidence pair extraction in scientific peer reviews, and collect SubstanReview, the first annotated dataset for this task. SubstanReview consists of 550 reviews from NLP conferences annotated by domain experts. On the basis of this dataset, we train an argument mining system to automatically analyze the level of substantiation in peer reviews. We also perform data analysis on the SubstanReview dataset to obtain meaningful insights on peer reviewing quality in NLP conferences over recent years.
</details>
<details>
<summary>摘要</summary>
随着顶尖人工智能会议中的问题atic peer review的增加，社区urgently需要自动质量控制措施。在这篇论文中，我们只考虑substantiation——一种流行的质量方面，表示评论中的laims是否充分supported by evidence。我们提供一种自动评估这种评估过程的解决方案。为实现这个目标，我们首先将问题定义为科学 peer review中的claim-evidence对extracting问题，并收集了SubstanReview数据集，这是第一个关于这个任务的注解数据集。SubstanReview包含550篇来自NLP会议的评论，由领域专家注释。基于这个数据集，我们训练了一个意义挖掘系统，以自动分析 peer review 中的证据水平。我们还对SubstanReview数据集进行了数据分析，以获得有用的洞察与顶尖人工智能会议过去几年 peer review 质量的意义ful insights。
</details></li>
</ul>
<hr>
<h2 id="LLMs-as-Visual-Explainers-Advancing-Image-Classification-with-Evolving-Visual-Descriptions"><a href="#LLMs-as-Visual-Explainers-Advancing-Image-Classification-with-Evolving-Visual-Descriptions" class="headerlink" title="LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions"></a>LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11904">http://arxiv.org/abs/2311.11904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songhao Han, Le Zhuo, Yue Liao, Si Liu</li>
<li>for: 提高图像分类的准确率和可解释性</li>
<li>methods: 提交了一种新的图像分类框架， combining VLMs 和 LLMs， named Iterative Optimization with Visual Feedback，通过使用进化优化策略来优化类描述符，并在 VLM 分类指标中 incorporate 视觉反馈来导向优化过程。</li>
<li>results: 对于一系列图像分类 benchmark 进行了实验，实现了3.47% 的平均提高，并且所得到的描述符具有可解释性和robustness，可以在不同的底层模型上提高表现。<details>
<summary>Abstract</summary>
Vision-language models (VLMs) offer a promising paradigm for image classification by comparing the similarity between images and class embeddings. A critical challenge lies in crafting precise textual representations for class names. While previous studies have leveraged recent advancements in large language models (LLMs) to enhance these descriptors, their outputs often suffer from ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent reliance on textual interactions with LLMs, leading to a mismatch between the generated text and the visual content in VLMs' latent space - a phenomenon we term the "explain without seeing" dilemma. 2) The oversight of the inter-class relationships, resulting in descriptors that fail to differentiate similar classes effectively. To address these issues, we propose a novel image classification framework combining VLMs with LLMs, named Iterative Optimization with Visual Feedback. In particular, our method develops an LLM-based agent, employing an evolutionary optimization strategy to refine class descriptors. Crucially, we incorporate visual feedback from VLM classification metrics, thereby guiding the optimization process with concrete visual data. Our method leads to improving accuracy on a wide range of image classification benchmarks, with 3.47\% average gains over state-of-the-art methods. We also highlight the resulting descriptions serve as explainable and robust features that can consistently improve the performance across various backbone models.
</details>
<details>
<summary>摘要</summary>
视力语言模型（VLM）提供了一个有前途的思路，通过比较图像和类别嵌入的相似性来进行图像分类。然而，一个重要挑战是制定精确的文本表述方法。在前一些研究中，通过利用大型语言模型（LLM）来提高描述符的精度。但是，这些输出经常受到歧义和不准确的影响。我们认为这有两个主要原因：1. 依赖于语言模型的文本交互，导致VLM中的 latent space 中的图像和文本之间的匹配不佳 - 我们称之为 "解释不见" 困难。2. 忽视类之间的关系，使得描述符不能有效地区分类似的类。为了解决这些问题，我们提出了一种新的图像分类框架， combining VLM 和 LLM，名为 Iterative Optimization with Visual Feedback。具体来说，我们的方法使用进化优化策略来精细调整类别描述符。更重要的是，我们在 VLM 分类指标中包含视觉反馈，从而使优化过程受到具体的视觉数据的引导。我们的方法在各种图像分类 benchmark 上实现了3.47%的平均提升，并且说明得出的描述符具有可解释和稳定的特性，可以在不同的后凹模型上保持高性能。
</details></li>
</ul>
<hr>
<h2 id="Evil-Geniuses-Delving-into-the-Safety-of-LLM-based-Agents"><a href="#Evil-Geniuses-Delving-into-the-Safety-of-LLM-based-Agents" class="headerlink" title="Evil Geniuses: Delving into the Safety of LLM-based Agents"></a>Evil Geniuses: Delving into the Safety of LLM-based Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11855">http://arxiv.org/abs/2311.11855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/t1ans1r/evil-geniuses">https://github.com/t1ans1r/evil-geniuses</a></li>
<li>paper_authors: Yu Tian, Xiao Yang, Jingyuan Zhang, Yinpeng Dong, Hang Su</li>
<li>for: 这篇论文探讨了 LLM 基本的安全问题，以及 LLM 基本在不同角色和系统中的漏洞。</li>
<li>methods: 该论文使用了手动攻击和虚拟对话方式进行了系列的探讨，以检测 LLM 基本的安全性。</li>
<li>results: 该论文发现了三种现象：1） LLM 基本具有减少的攻击抵抗力；2） attacked agents 可以提供更加细腻的回应；3） 检测生成的不当回应的困难度更高。这些发现提醒我们质疑 LLM 基本是否能够免疫攻击，并且在不同的系统和角色水平上找到了漏洞。<details>
<summary>Abstract</summary>
The rapid advancements in large language models (LLMs) have led to a resurgence in LLM-based agents, which demonstrate impressive human-like behaviors and cooperative capabilities in various interactions and strategy formulations. However, evaluating the safety of LLM-based agents remains a complex challenge. This paper elaborately conducts a series of manual jailbreak prompts along with a virtual chat-powered evil plan development team, dubbed Evil Geniuses, to thoroughly probe the safety aspects of these agents. Our investigation reveals three notable phenomena: 1) LLM-based agents exhibit reduced robustness against malicious attacks. 2) the attacked agents could provide more nuanced responses. 3) the detection of the produced improper responses is more challenging. These insights prompt us to question the effectiveness of LLM-based attacks on agents, highlighting vulnerabilities at various levels and within different role specializations within the system/agent of LLM-based agents. Extensive evaluation and discussion reveal that LLM-based agents face significant challenges in safety and yield insights for future research. Our code is available at https://github.com/T1aNS1R/Evil-Geniuses.
</details>
<details>
<summary>摘要</summary>
LLM 的快速进步导致了 LLM 基于的代理人 return to human-like behaviors and cooperative capabilities in various interactions and strategy formulations. However, evaluating the safety of LLM-based agents remains a complex challenge. This paper conducts a series of manual jailbreak prompts along with a virtual chat-powered evil plan development team, dubbed Evil Geniuses, to thoroughly probe the safety aspects of these agents. Our investigation reveals three notable phenomena: 1) LLM-based agents exhibit reduced robustness against malicious attacks. 2) the attacked agents could provide more nuanced responses. 3) the detection of the produced improper responses is more challenging. These insights prompt us to question the effectiveness of LLM-based attacks on agents, highlighting vulnerabilities at various levels and within different role specializations within the system/agent of LLM-based agents. Extensive evaluation and discussion reveal that LLM-based agents face significant challenges in safety and yield insights for future research. Our code is available at https://github.com/T1aNS1R/Evil-Geniuses.Note: Please keep in mind that the translation is done using a machine translation tool, and may not be perfect or entirely accurate.
</details></li>
</ul>
<hr>
<h2 id="Deepparse-An-Extendable-and-Fine-Tunable-State-Of-The-Art-Library-for-Parsing-Multinational-Street-Addresses"><a href="#Deepparse-An-Extendable-and-Fine-Tunable-State-Of-The-Art-Library-for-Parsing-Multinational-Street-Addresses" class="headerlink" title="Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses"></a>Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11846">http://arxiv.org/abs/2311.11846</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Beauchemin, Marouane Yassine</li>
<li>For: The paper is written for developing an open-source, extendable, and fine-tunable address parsing solution using deep learning algorithms.* Methods: The paper uses state-of-the-art deep learning algorithms and a pre-trained model to parse addresses written in any language and using any address standard, with no pre-processing or post-processing needed.* Results: The pre-trained model achieves an average parsing accuracy of 99% on the countries used for training, and the library supports fine-tuning with new data to generate a custom address parser.<details>
<summary>Abstract</summary>
Segmenting an address into meaningful components, also known as address parsing, is an essential step in many applications from record linkage to geocoding and package delivery. Consequently, a lot of work has been dedicated to develop accurate address parsing techniques, with machine learning and neural network methods leading the state-of-the-art scoreboard. However, most of the work on address parsing has been confined to academic endeavours with little availability of free and easy-to-use open-source solutions.   This paper presents Deepparse, a Python open-source, extendable, fine-tunable address parsing solution under LGPL-3.0 licence to parse multinational addresses using state-of-the-art deep learning algorithms and evaluated on over 60 countries. It can parse addresses written in any language and use any address standard. The pre-trained model achieves average $99~\%$ parsing accuracies on the countries used for training with no pre-processing nor post-processing needed. Moreover, the library supports fine-tuning with new data to generate a custom address parser.
</details>
<details>
<summary>摘要</summary>
segmenting an address into meaningful components, also known as address parsing, is an essential step in many applications, from record linkage to geocoding and package delivery. consequently, a lot of work has been dedicated to developing accurate address parsing techniques, with machine learning and neural network methods leading the state-of-the-art scoreboard. however, most of the work on address parsing has been confined to academic endeavors with little availability of free and easy-to-use open-source solutions.this paper presents deepparse, a python open-source, extendable, and fine-tunable address parsing solution under the LGPL-3.0 license to parse multinational addresses using state-of-the-art deep learning algorithms. the pre-trained model achieves an average of $99\%$ parsing accuracies on the countries used for training with no pre-processing nor post-processing needed. moreover, the library supports fine-tuning with new data to generate a custom address parser.
</details></li>
</ul>
<hr>
<h2 id="How-to-Use-Large-Language-Models-for-Text-Coding-The-Case-of-Fatherhood-Roles-in-Public-Policy-Documents"><a href="#How-to-Use-Large-Language-Models-for-Text-Coding-The-Case-of-Fatherhood-Roles-in-Public-Policy-Documents" class="headerlink" title="How to Use Large Language Models for Text Coding: The Case of Fatherhood Roles in Public Policy Documents"></a>How to Use Large Language Models for Text Coding: The Case of Fatherhood Roles in Public Policy Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11844">http://arxiv.org/abs/2311.11844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Lupo, Oscar Magnusson, Dirk Hovy, Elin Naurin, Lena Wängnerud<br>for: 这个研究的目的是评估大语言模型（LLMs）在政治科学研究中的文本分析能力。methods: 这个研究使用了三个原始的代码任务来测试LLMs的性能，并提供了一个通用的工作流程指南 для在政治科学研究中使用LLMs进行文本分析。results: 研究发现，当提供了详细的标签定义和编码示例时，一个LLM可以与人类标注员相当或者甚至更好，而且比人类编码更快（可以达到百度 times），更便宜（可以达到60%的成本下降），并且更易扩展到大量文本。总之，LLMs 是大多数文本编码项目的可靠选择。<details>
<summary>Abstract</summary>
Recent advances in large language models (LLMs) like GPT-3 and GPT-4 have opened up new opportunities for text analysis in political science. They promise automation with better results and less programming. In this study, we evaluate LLMs on three original coding tasks of non-English political science texts, and we provide a detailed description of a general workflow for using LLMs for text coding in political science research. Our use case offers a practical guide for researchers looking to incorporate LLMs into their research on text analysis. We find that, when provided with detailed label definitions and coding examples, an LLM can be as good as or even better than a human annotator while being much faster (up to hundreds of times), considerably cheaper (costing up to 60% less than human coding), and much easier to scale to large amounts of text. Overall, LLMs present a viable option for most text coding projects.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)最近的大语言模型（LLM）如GPT-3和GPT-4的进步，为政治科学中的文本分析开创了新的机遇。它们承诺自动化可以获得更好的结果，需要更少的编程。在这项研究中，我们对政治科学非英文文本中的三个原创编码任务进行了LLM的评估。我们还提供了政治科学研究中使用LLM进行文本编码的通用工作流程的详细描述。我们的使用案例为研究人员寻求在文本分析中包含LLM的研究提供了实践指南。我们发现，当提供了详细的标签定义和编码示例时，一个LLM可以与人类标注员相当或更好，而且速度可以是人类标注的百倍，成本可以是人类标注的60%以下，并且可以轻松扩展到大量文本。总之，LLMs在大多数文本编码项目中是一个可行的选择。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Grammatical-Error-Correction-Via-Multi-Task-Training-and-Optimized-Training-Schedule"><a href="#Efficient-Grammatical-Error-Correction-Via-Multi-Task-Training-and-Optimized-Training-Schedule" class="headerlink" title="Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule"></a>Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11813">http://arxiv.org/abs/2311.11813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrey Bout, Alexander Podolskiy, Sergey Nikolenko, Irina Piontkovskaya</li>
<li>for: 提高神经语法错误纠正（GEC）的进步受到数据缺乏标注的限制。</li>
<li>methods: 我们提出了两种方法来使用现有数据更有效率：一是利用对应文本的对应 corrections 进行预测，形式化为序列-到-序列问题进行多任务训练；二是调查训练数据的顺序和实例顺序对最终性能的影响，并找到最佳训练计划。</li>
<li>results: 这两种方法共同导致了显著的改进，我们的结果超过了基于 T5-XXL（11B参数）的最佳模型，并且使用 BART 模型（400M参数）。<details>
<summary>Abstract</summary>
Progress in neural grammatical error correction (GEC) is hindered by the lack of annotated training data. Sufficient amounts of high-quality manually annotated data are not available, so recent research has relied on generating synthetic data, pretraining on it, and then fine-tuning on real datasets; performance gains have been achieved either by ensembling or by using huge pretrained models such as XXL-T5 as the backbone. In this work, we explore an orthogonal direction: how to use available data more efficiently. First, we propose auxiliary tasks that exploit the alignment between the original and corrected sentences, such as predicting a sequence of corrections. We formulate each task as a sequence-to-sequence problem and perform multi-task training. Second, we discover that the order of datasets used for training and even individual instances within a dataset may have important effects on the final performance, so we set out to find the best training schedule. Together, these two ideas lead to significant improvements, producing results that improve state of the art with much smaller models; in particular, we outperform the best models based on T5-XXL (11B parameters) with a BART-based model (400M parameters).
</details>
<details>
<summary>摘要</summary>
Progress in neural grammatical error correction (GEC) 是受到annotated training data的缺乏所妨碍的。lack of sufficient high-quality manually annotated data，therefore recent research has relied on generating synthetic data, pretraining on it, and then fine-tuning on real datasets; performance gains have been achieved either by ensembling or by using huge pretrained models such as XXL-T5 as the backbone. In this work, we explore an orthogonal direction: how to use available data more efficiently. First, we propose auxiliary tasks that exploit the alignment between the original and corrected sentences, such as predicting a sequence of corrections. We formulate each task as a sequence-to-sequence problem and perform multi-task training. Second, we discover that the order of datasets used for training and even individual instances within a dataset may have important effects on the final performance, so we set out to find the best training schedule. Together, these two ideas lead to significant improvements, producing results that improve state of the art with much smaller models; in particular, we outperform the best models based on T5-XXL (11B parameters) with a BART-based model (400M parameters).
</details></li>
</ul>
<hr>
<h2 id="Encoding-Speaker-Specific-Latent-Speech-Feature-for-Speech-Synthesis"><a href="#Encoding-Speaker-Specific-Latent-Speech-Feature-for-Speech-Synthesis" class="headerlink" title="Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis"></a>Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11745">http://arxiv.org/abs/2311.11745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jungil Kong, Junmo Lee, Jeongmin Kim, Beomjeong Kim, Jihoon Park, Dohee Kong, Changheon Lee, Sangjin Kim</li>
<li>for: 这个论文旨在提出一种新的多个说话者模型，可以详细表达说话者的总体特征，而不需要额外训练目标说话者的数据集。</li>
<li>methods: 该方法使用特征抽象和conditioning来学习和表达目标说话者的speech特征，并使用一种speech sintesis模型来评估表达的质量。</li>
<li>results: 该方法在主观相似性评价中获得了与训练的多个说话者模型相比较高的相似性mean opinion score（SMOS），并在零 shot情况下也表现出了显著的优势。此外，该方法还可以生成新的人工说话者，并且表明了encode的秘密特征足够完整地重建原始说话者的speech。<details>
<summary>Abstract</summary>
In this work, we propose a novel method for modeling numerous speakers, which enables expressing the overall characteristics of speakers in detail like a trained multi-speaker model without additional training on the target speaker's dataset. Although various works with similar purposes have been actively studied, their performance has not yet reached that of trained multi-speaker models due to their fundamental limitations. To overcome previous limitations, we propose effective methods for feature learning and representing target speakers' speech characteristics by discretizing the features and conditioning them to a speech synthesis model. Our method obtained a significantly higher similarity mean opinion score (SMOS) in subjective similarity evaluation than seen speakers of a best-performing multi-speaker model, even with unseen speakers. The proposed method also outperforms a zero-shot method by significant margins. Furthermore, our method shows remarkable performance in generating new artificial speakers. In addition, we demonstrate that the encoded latent features are sufficiently informative to reconstruct an original speaker's speech completely. It implies that our method can be used as a general methodology to encode and reconstruct speakers' characteristics in various tasks.
</details>
<details>
<summary>摘要</summary>
“在这项工作中，我们提出了一种新的方法，用于模型多个说话人，以达到没有额外训练目标说话人数据集的情况下，表达说话人的总特征如一种训练过的多说话人模型一样。虽然有许多类似目标的研究在活跃进行，但它们的性能还没有达到多说话人模型的水平，因为它们的基本限制。为了超越这些限制，我们提出了有效的特征学习方法和表示目标说话人的speech特征，通过精度地抽象特征来conditioning一个speech sintesis模型。我们的方法在主观相似度评估中获得了与见过的说话人模型相比，即使面对未见过的说话人，也具有显著的优势。此外，我们的方法在生成新的人工说话人方面也表现出了很好的性能。此外，我们还证明了编码的潜在特征足够具有重建原始说话人的speech完整的能力。这表示我们的方法可以作为一种通用的方法ологи，用于编码和重建说话人的特征在不同任务中。”
</details></li>
</ul>
<hr>
<h2 id="Addressing-the-Length-Bias-Problem-in-Document-Level-Neural-Machine-Translation"><a href="#Addressing-the-Length-Bias-Problem-in-Document-Level-Neural-Machine-Translation" class="headerlink" title="Addressing the Length Bias Problem in Document-Level Neural Machine Translation"></a>Addressing the Length Bias Problem in Document-Level Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11601">http://arxiv.org/abs/2311.11601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/salvation-z/LengthBiasDNMT">https://github.com/salvation-z/LengthBiasDNMT</a></li>
<li>paper_authors: Zhuocheng Zhang, Shuhao Gu, Min Zhang, Yang Feng</li>
<li>for: 解决文档级别神经机器翻译（DNMT）中Length bias问题，提高翻译质量。</li>
<li>methods: 提议在训练方法、注意机制和解码策略上进行改进，包括动态采样训练数据、长度 нормализа注意力机制和滑块策略。</li>
<li>results: 实验结果表明，我们的方法可以在多个公开数据集上提供显著改进，并且分析结果表明，我们的方法可以有效地减轻Length bias问题。<details>
<summary>Abstract</summary>
Document-level neural machine translation (DNMT) has shown promising results by incorporating more context information. However, this approach also introduces a length bias problem, whereby DNMT suffers from significant translation quality degradation when decoding documents that are much shorter or longer than the maximum sequence length during training. %i.e., the length bias problem. To solve the length bias problem, we propose to improve the DNMT model in training method, attention mechanism, and decoding strategy. Firstly, we propose to sample the training data dynamically to ensure a more uniform distribution across different sequence lengths. Then, we introduce a length-normalized attention mechanism to aid the model in focusing on target information, mitigating the issue of attention divergence when processing longer sequences. Lastly, we propose a sliding window strategy during decoding that integrates as much context information as possible without exceeding the maximum sequence length. The experimental results indicate that our method can bring significant improvements on several open datasets, and further analysis shows that our method can significantly alleviate the length bias problem.
</details>
<details>
<summary>摘要</summary>
文档水平神经机器翻译（DNMT）已经展示了可行的结果，通过更多的上下文信息。然而，这种方法也会导致长度偏好问题，DNMT在训练时遇到短文档或长文档时翻译质量下降。即长度偏好问题。为解决长度偏好问题，我们提议在训练方法、注意机制和解码策略方面进行改进。首先，我们提议在训练数据中采样动态，以确保不同的序列长度具有更加均匀的分布。然后，我们引入长度归一化注意机制，以帮助模型关注目标信息，避免长序列处理时的注意力散布问题。最后，我们提议在解码时采用滑块策略，可以尽可能地integrate上下文信息，不超过最大序列长度。实验结果表明，我们的方法可以在多个公开数据集上提供显著改进，并且分析结果表明，我们的方法可以有效缓解长度偏好问题。
</details></li>
</ul>
<hr>
<h2 id="Filling-the-Image-Information-Gap-for-VQA-Prompting-Large-Language-Models-to-Proactively-Ask-Questions"><a href="#Filling-the-Image-Information-Gap-for-VQA-Prompting-Large-Language-Models-to-Proactively-Ask-Questions" class="headerlink" title="Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions"></a>Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11598">http://arxiv.org/abs/2311.11598</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thunlp-mt/fiig">https://github.com/thunlp-mt/fiig</a></li>
<li>paper_authors: Ziyue Wang, Chi Chen, Peng Li, Yang Liu<br>for: 这个论文的目的是提高大语言模型（LLM）在知识开放视觉问答 task（OK-VQA）中的表现，以及在不同的语言模型上实现这种表现。methods: 作者使用了将图片转换为文本的方法，以便让 LLM 参与视觉问题的解释过程。同时，他们还提出了一种框架，使得 LLM 可以主动提问更多细节信息，以提高最终的解释性能。results: 作者在 OK-VQA 和 A-OKVQA 上验证了他们的想法，并证明了其可以持续提高基eline方法的表现，具体来说，平均提高了2.15%。此外，他们的方法在不同的语言模型上也实现了一致的改进。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) demonstrate impressive reasoning ability and the maintenance of world knowledge not only in natural language tasks, but also in some vision-language tasks such as open-domain knowledge-based visual question answering (OK-VQA). As images are invisible to LLMs, researchers convert images to text to engage LLMs into the visual question reasoning procedure. This leads to discrepancies between images and their textual representations presented to LLMs, which consequently impedes final reasoning performance. To fill the information gap and better leverage the reasoning capability, we design a framework that enables LLMs to proactively ask relevant questions to unveil more details in the image, along with filters for refining the generated information. We validate our idea on OK-VQA and A-OKVQA. Our method continuously boosts the performance of baselines methods by an average gain of 2.15% on OK-VQA, and achieves consistent improvements across different LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="How-well-ChatGPT-understand-Malaysian-English-An-Evaluation-on-Named-Entity-Recognition-and-Relation-Extraction"><a href="#How-well-ChatGPT-understand-Malaysian-English-An-Evaluation-on-Named-Entity-Recognition-and-Relation-Extraction" class="headerlink" title="How well ChatGPT understand Malaysian English? An Evaluation on Named Entity Recognition and Relation Extraction"></a>How well ChatGPT understand Malaysian English? An Evaluation on Named Entity Recognition and Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11583">http://arxiv.org/abs/2311.11583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mohanraj-nlp/chatgpt-malaysian-english">https://github.com/mohanraj-nlp/chatgpt-malaysian-english</a></li>
<li>paper_authors: Mohan Raj Chanthran, Lay-Ki Soon, Huey Fang Ong, Bhawani Selvaretnam</li>
<li>for: 本研究用于评估ChatGPT在马来西亚英语新闻文章中提取实体和关系的能力。</li>
<li>methods: 我们提出了一种三步方法，即“教育-预测-评估”方法，用于评估ChatGPT在不同的提问设定下的性能。</li>
<li>results: 我们发现，ChatGPT在马来西亚英语新闻文章中提取实体的性能不佳，最高的F1分为0.497。进一步分析显示， morphosyntactic adaptation在马来西亚英语中带来了限制。然而，这种 morphosyntactic adaptation对ChatGPT关系提取性能没有影响。<details>
<summary>Abstract</summary>
Recently, ChatGPT has attracted a lot of interest from both researchers and the general public. While the performance of ChatGPT in named entity recognition and relation extraction from Standard English texts is satisfactory, it remains to be seen if it can perform similarly for Malaysian English. Malaysian English is unique as it exhibits morphosyntactic and semantical adaptation from local contexts. In this study, we assess ChatGPT's capability in extracting entities and relations from the Malaysian English News (MEN) dataset. We propose a three-step methodology referred to as \textbf{\textit{educate-predict-evaluate}. The performance of ChatGPT is assessed using F1-Score across 18 unique prompt settings, which were carefully engineered for a comprehensive review. From our evaluation, we found that ChatGPT does not perform well in extracting entities from Malaysian English news articles, with the highest F1-Score of 0.497. Further analysis shows that the morphosyntactic adaptation in Malaysian English caused the limitation. However, interestingly, this morphosyntactic adaptation does not impact the performance of ChatGPT for relation extraction.
</details>
<details>
<summary>摘要</summary>
近期，ChatGPT已经引起了研究者和普通公众的广泛关注。虽然ChatGPT在标准英语文本中的命名实体识别和关系EXTRACTION表现良好，但是还未得到Malaysian English的测试。Malaysian English具有独特的形态语法和semantical adaptation，这使得ChatGPT的性能在这类文本中仍然需要证明。在这项研究中，我们使用了一种三步方法，称为\textbf{\textit{educate-predict-evaluate}。我们使用F1-Score来评估ChatGPT在MEN dataset（Malaysian English News）中EXTRACTION实体和关系的性能。我们发现，ChatGPT在Malaysian English新闻文章中EXTRACTION实体时表现不佳，最高F1-Score为0.497。进一步分析表明，Malaysian English中的形态语法变化限制了ChatGPT的性能。然而，这种形态语法变化对ChatGPT的关系EXTRACTION表现没有影响。
</details></li>
</ul>
<hr>
<h2 id="KBioXLM-A-Knowledge-anchored-Biomedical-Multilingual-Pretrained-Language-Model"><a href="#KBioXLM-A-Knowledge-anchored-Biomedical-Multilingual-Pretrained-Language-Model" class="headerlink" title="KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model"></a>KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11564">http://arxiv.org/abs/2311.11564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngwlh-gl/kbioxlm">https://github.com/ngwlh-gl/kbioxlm</a></li>
<li>paper_authors: Lei Geng, Xu Yan, Ziqiang Cao, Juntao Li, Wenjie Li, Sujian Li, Xinjie Zhou, Yang Yang, Jun Zhang</li>
<li>for: 本文提出了一种解决biomedical领域中难以处理多语言要求的问题的方法，即通过知识 anchoredapproach将英文预训练模型XLM-R转换成biomedical领域的模型KBioXLM。</li>
<li>methods: 本文使用了三种粒度的知识对应（实体、事实和段落级），将英文预训练 corpora incorporated into biomedical corpora，然后设计了三种训练任务（实体覆盖、关系覆盖和段落关系预测），继续在XLM-R模型之上训练以提高其跨语言领域能力。</li>
<li>results: 实验结果表明，KBioXLM模型在跨语言零shot和几shot情况下，与单语言和多语言预训练模型相比，显著提高了cross-lingual能力，提高了10+个点。<details>
<summary>Abstract</summary>
Most biomedical pretrained language models are monolingual and cannot handle the growing cross-lingual requirements. The scarcity of non-English domain corpora, not to mention parallel data, poses a significant hurdle in training multilingual biomedical models. Since knowledge forms the core of domain-specific corpora and can be translated into various languages accurately, we propose a model called KBioXLM, which transforms the multilingual pretrained model XLM-R into the biomedical domain using a knowledge-anchored approach. We achieve a biomedical multilingual corpus by incorporating three granularity knowledge alignments (entity, fact, and passage levels) into monolingual corpora. Then we design three corresponding training tasks (entity masking, relation masking, and passage relation prediction) and continue training on top of the XLM-R model to enhance its domain cross-lingual ability. To validate the effectiveness of our model, we translate the English benchmarks of multiple tasks into Chinese. Experimental results demonstrate that our model significantly outperforms monolingual and multilingual pretrained models in cross-lingual zero-shot and few-shot scenarios, achieving improvements of up to 10+ points. Our code is publicly available at https://github.com/ngwlh-gl/KBioXLM.
</details>
<details>
<summary>摘要</summary>
大多数生物医学预训言语模型都是单语言的，无法满足增长的多语言需求。由于非英语领域数据罕见，更是缺乏平行数据，训练多语言生物医学模型具有很大的挑战。因为知识是生物医学领域 corpora 的核心，可以精准地翻译到不同语言上，我们提出了一个名为 KBioXLM 的模型。我们使用知识固定的方法将 XLM-R 模型转换到生物医学领域中。我们创建了三级别的知识对应（实体、事实和段落级别），并将这些对应 integrate into 单语言 corpora。然后，我们设计了三种相应的训练任务（实体覆盖、关系覆盖和段落关系预测），继续在 XLM-R 模型之上进行训练，以提高其跨语言领域的某些能力。为验证我们的模型效果，我们将英语benchmarks 翻译成中文。实验结果表明，我们的模型在跨语言零shot和几shot场景中表现出色，与单语言预训言语模型和多语言预训言语模型相比，具有10+ 点的改进。我们的代码公开available于https://github.com/ngwlh-gl/KBioXLM。
</details></li>
</ul>
<hr>
<h2 id="Adapt-in-Contexts-Retrieval-Augmented-Domain-Adaptation-via-In-Context-Learning"><a href="#Adapt-in-Contexts-Retrieval-Augmented-Domain-Adaptation-via-In-Context-Learning" class="headerlink" title="Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning"></a>Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11551">http://arxiv.org/abs/2311.11551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quanyu Long, Wenya Wang, Sinno Jialin Pan</li>
<li>for: 这篇论文目的是研究对应语言模型（LLM）在不同领域进行适应，以提高其在未见领域的表现。</li>
<li>methods: 本研究使用了对应语言模型的无监督领域适应（UDA）技术，并在内容学习（ICL） Setting中进行了训练。特点是选择了跨领域元素的子集，并通过联合领域内容示例来将语言模型适应到目标领域。</li>
<li>results: 经过广泛的实验，研究发现ICL技术可以对应语言模型进行领域转移，并在抒情分析（SA）和名称识别（NER）任务中获得了显著的改善。<details>
<summary>Abstract</summary>
Large language models (LLMs) have showcased their capability with few-shot inference known as in-context learning. However, in-domain demonstrations are not always readily available in real scenarios, leading to cross-domain in-context learning. Besides, LLMs are still facing challenges in long-tail knowledge in unseen and unfamiliar domains. The above limitations demonstrate the necessity of Unsupervised Domain Adaptation (UDA). In this paper, we study the UDA problem under an in-context learning setting to adapt language models from the source domain to the target domain without any target labels. The core idea is to retrieve a subset of cross-domain elements that are the most similar to the query, and elicit language model to adapt in an in-context manner by learning both target domain distribution and the discriminative task signal simultaneously with the augmented cross-domain in-context examples. We devise different prompting and training strategies, accounting for different LM architectures to learn the target distribution via language modeling. With extensive experiments on Sentiment Analysis (SA) and Named Entity Recognition (NER) tasks, we thoroughly study the effectiveness of ICL for domain transfer and demonstrate significant improvements over baseline models.
</details>
<details>
<summary>摘要</summary>
Our core idea is to retrieve a subset of cross-domain elements that are most similar to the query and use these examples to adapt the language model in an in-context manner. This involves learning both the target domain distribution and the discriminative task signal simultaneously with the augmented cross-domain in-context examples. We develop different prompting and training strategies to suit different LM architectures, allowing them to learn the target distribution via language modeling.We conduct extensive experiments on Sentiment Analysis (SA) and Named Entity Recognition (NER) tasks to evaluate the effectiveness of In-Context Learning (ICL) for domain transfer. Our results show significant improvements over baseline models, demonstrating the effectiveness of ICL for adapting language models to unseen domains.
</details></li>
</ul>
<hr>
<h2 id="Multi-teacher-Distillation-for-Multilingual-Spelling-Correction"><a href="#Multi-teacher-Distillation-for-Multilingual-Spelling-Correction" class="headerlink" title="Multi-teacher Distillation for Multilingual Spelling Correction"></a>Multi-teacher Distillation for Multilingual Spelling Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11518">http://arxiv.org/abs/2311.11518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingfen Zhang, Xuan Guo, Sravan Bodapati, Christopher Potts</li>
<li>for: 本研究旨在提高现代搜索界面中的精准拼写正确，尤其是在移动设备和语音至文本交互时。</li>
<li>methods: 本文使用多教师热钻法，其中每种语言&#x2F;地区都有一个单语言教师模型，这些教师模型被热钻成一个旨在服务所有语言&#x2F;地区的多语言学生模型。</li>
<li>results: 在使用开源数据以及世界各地搜索服务用户数据进行实验中，我们发现这种方法可以生成高效的拼写正确模型，可以满足部署服务的紧张延迟要求。<details>
<summary>Abstract</summary>
Accurate spelling correction is a critical step in modern search interfaces, especially in an era of mobile devices and speech-to-text interfaces. For services that are deployed around the world, this poses a significant challenge for multilingual NLP: spelling errors need to be caught and corrected in all languages, and even in queries that use multiple languages. In this paper, we tackle this challenge using multi-teacher distillation. On our approach, a monolingual teacher model is trained for each language/locale, and these individual models are distilled into a single multilingual student model intended to serve all languages/locales. In experiments using open-source data as well as user data from a worldwide search service, we show that this leads to highly effective spelling correction models that can meet the tight latency requirements of deployed services.
</details>
<details>
<summary>摘要</summary>
精确的拼写更正是现代搜索界面中的一个关键步骤，尤其是在移动设备和语音到文本交互的时代。为部署在全球的服务而言，这会提出一个严峻的多语言NLP挑战：拼写错误需要在所有语言/地区中捕捉并更正。在这篇论文中，我们采用多教师润雨法来解决这个问题。我们将每种语言/地区的单语言教师模型进行训练，然后将这些个体模型润雨成一个通用的多语言学生模型，用于服务所有语言/地区。在使用开源数据以及全球搜索服务的用户数据进行实验中，我们发现这种方法可以创造出高效的拼写更正模型，可以满足部署服务的紧张响应时间要求。
</details></li>
</ul>
<hr>
<h2 id="Token-Level-Adversarial-Prompt-Detection-Based-on-Perplexity-Measures-and-Contextual-Information"><a href="#Token-Level-Adversarial-Prompt-Detection-Based-on-Perplexity-Measures-and-Contextual-Information" class="headerlink" title="Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information"></a>Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11509">http://arxiv.org/abs/2311.11509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengmian Hu, Gang Wu, Saayan Mitra, Ruiyi Zhang, Tong Sun, Heng Huang, Vishy Swaminathan</li>
<li>for: 本文提出了一种用于检测 adversarial prompt 的 токен级检测方法，以帮助改进 Large Language Models (LLM) 的安全性。</li>
<li>methods: 本文提出了两种方法：一种是根据模型对下一个字符的预测概率来确定当前字符是否属于 adversarial prompt，另一种是根据当前字符和周围字符的信息来确定当前字符是否属于 adversarial prompt。</li>
<li>results: 研究人员通过实验表明，使用上述两种方法可以准确地检测 adversarial prompt，并且可以提高 LLM 的安全性。<details>
<summary>Abstract</summary>
In recent years, Large Language Models (LLM) have emerged as pivotal tools in various applications. However, these models are susceptible to adversarial prompt attacks, where attackers can carefully curate input strings that lead to undesirable outputs. The inherent vulnerability of LLMs stems from their input-output mechanisms, especially when presented with intensely out-of-distribution (OOD) inputs. This paper proposes a token-level detection method to identify adversarial prompts, leveraging the LLM's capability to predict the next token's probability. We measure the degree of the model's perplexity and incorporate neighboring token information to encourage the detection of contiguous adversarial prompt sequences. As a result, we propose two methods: one that identifies each token as either being part of an adversarial prompt or not, and another that estimates the probability of each token being part of an adversarial prompt.
</details>
<details>
<summary>摘要</summary>
Recently, Large Language Models (LLM) have become crucial tools in various applications. However, these models are vulnerable to adversarial prompt attacks, where attackers can craft input strings to elicit undesirable outputs. The vulnerability of LLMs stems from their input-output mechanisms, especially when faced with highly out-of-distribution (OOD) inputs. This paper proposes a token-level detection method to identify adversarial prompts, leveraging the LLM's ability to predict the next token's probability. We measure the model's perplexity and incorporate neighboring token information to detect contiguous adversarial prompt sequences. As a result, we propose two methods: one that identifies each token as either being part of an adversarial prompt or not, and another that estimates the probability of each token being part of an adversarial prompt.Here's the translation in Traditional Chinese:近年来，大语言模型（LLM）已经成为不同应用中的重要工具。然而，这些模型对于攻击性提示攻击具有敏感性，攻击者可以精心设计输入字串，以诱使模型产生不适合的出力。LLM的敏感性源于其输入-输出机制，特别是面对高度外部数据（OOD）的输入。本文提出了一种对于提示的token级检测方法，利用模型预测下一个token的概率。我们量化模型的困惑度，并将邻近token信息 incorporate 到检测攻击提示Sequence中。因此，我们提出了两种方法：一种是检测每个token是否是攻击提示的一部分，另一种是估计每个token是否是攻击提示的一部分。
</details></li>
</ul>
<hr>
<h2 id="What’s-left-can’t-be-right-–-The-remaining-positional-incompetence-of-contrastive-vision-language-models"><a href="#What’s-left-can’t-be-right-–-The-remaining-positional-incompetence-of-contrastive-vision-language-models" class="headerlink" title="What’s left can’t be right – The remaining positional incompetence of contrastive vision-language models"></a>What’s left can’t be right – The remaining positional incompetence of contrastive vision-language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11477">http://arxiv.org/abs/2311.11477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nils Hoehing, Ellen Rushe, Anthony Ventresque</li>
<li>for: 本研究探讨了对比性视语模型CLIP具有空间理解能力的问题，分析了数据集和嵌入空间的可能性。</li>
<li>methods: 本研究使用了人工生成的数据集来教育模型理解左右位置关系，并证明这种方法可以在自然图像上广泛应用，提高了Visual Genome Relations中左右关系的性能。</li>
<li>results: 研究发现，通过使用人工生成的数据集来教育模型理解左右位置关系，可以大幅提高CLIP在Visual Genome Relations中的性能。<details>
<summary>Abstract</summary>
Contrastive vision-language models like CLIP have been found to lack spatial understanding capabilities. In this paper we discuss the possible causes of this phenomenon by analysing both datasets and embedding space. By focusing on simple left-right positional relations, we show that this behaviour is entirely predictable, even with large-scale datasets, demonstrate that these relations can be taught using synthetic data and show that this approach can generalise well to natural images - improving the performance on left-right relations on Visual Genome Relations.
</details>
<details>
<summary>摘要</summary>
CLIP类视觉语言模型缺乏空间理解能力。在这篇论文中，我们分析了数据集和嵌入空间，探讨这种现象的可能原因。通过专注于简单的左右位置关系，我们显示这种行为是可预测的，即使使用大规模数据集。我们还示出了使用合成数据教育这种关系的可行性，并证明这种方法可以在自然图像上良好地泛化，提高视觉遗传关系中的左右关系性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.CL_2023_11_20/" data-id="clp89doc000fhi7884ltd2if9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/20/cs.AI_2023_11_20/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-11-20
        
      </div>
    </a>
  
  
    <a href="/2023/11/20/cs.LG_2023_11_20/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-11-20</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
