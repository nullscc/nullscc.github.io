
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.LG - 2023-11-05 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02798 repo_url: None paper_authors">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.LG - 2023-11-05">
<meta property="og:url" content="https://nullscc.github.io/2023/11/05/cs.LG_2023_11_05/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02798 repo_url: None paper_authors">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-05T10:00:00.000Z">
<meta property="article:modified_time" content="2023-11-07T04:32:35.029Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.LG_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.LG_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T10:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.LG - 2023-11-05
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="From-molecules-to-scaffolds-to-functional-groups-building-context-dependent-molecular-representation-via-multi-channel-learning"><a href="#From-molecules-to-scaffolds-to-functional-groups-building-context-dependent-molecular-representation-via-multi-channel-learning" class="headerlink" title="From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning"></a>From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02798">http://arxiv.org/abs/2311.02798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Wan, Jialu Wu, Tingjun Hou, Chang-Yu Hsieh, Xiaowei Jia</li>
<li>for: 本研究旨在开发一种基于自我监督学习的分子机器学习模型，以便在药物发现等科学应用中进行可靠的分子性质预测。</li>
<li>methods: 本研究使用了一种新的学习框架，具体来说是通过分子结构层次结构知识、独立预训练任务和目标任务特定的通道选择来嵌入分子空间中的知识。</li>
<li>results: 本研究的结果表明，该学习框架可以在多种分子性质评价 benchmark 上达到竞争性的性能，并在特殊而普遍存在的活性峰架上具有更高的稳定性和普适性。<details>
<summary>Abstract</summary>
Reliable molecular property prediction is essential for various scientific endeavors and industrial applications, such as drug discovery. However, the scarcity of data, combined with the highly non-linear causal relationships between physicochemical and biological properties and conventional molecular featurization schemes, complicates the development of robust molecular machine learning models. Self-supervised learning (SSL) has emerged as a popular solution, utilizing large-scale, unannotated molecular data to learn a foundational representation of chemical space that might be advantageous for downstream tasks. Yet, existing molecular SSL methods largely overlook domain-specific knowledge, such as molecular similarity and scaffold importance, as well as the context of the target application when operating over the large chemical space. This paper introduces a novel learning framework that leverages the knowledge of structural hierarchies within molecular structures, embeds them through separate pre-training tasks over distinct channels, and employs a task-specific channel selection to compose a context-dependent representation. Our approach demonstrates competitive performance across various molecular property benchmarks and establishes some state-of-the-art results. It further offers unprecedented advantages in particularly challenging yet ubiquitous scenarios like activity cliffs with enhanced robustness and generalizability compared to other baselines.
</details>
<details>
<summary>摘要</summary>
可靠的分子性质预测是科学研究和工业应用的重要基础，如药物发现。然而，数据缺乏和物理化和生物性质之间的非线性 causal 关系，使得传统的分子特征化方案难以生成可靠的分子机器学习模型。自主学习（SSL）已成为一种流行的解决方案，使用大规模、无注释的分子数据来学习分子空间的基础表示，可能有利于下游任务。然而，现有的分子SSL方法很多忽略分子相似性和架构重要性，以及目标应用场景的Context。这篇论文介绍了一种新的学习框架，利用分子结构中的结构层次，通过不同的预训练任务来嵌入这些结构，并使用任务特定的通道选择来组合上下文依赖的表示。我们的方法在多种分子性质指标上达到了竞争性的表现，并在特定但普遍的enario中提供了前所未有的优势，如活性峰的增强鲁棒性和通用性。
</details></li>
</ul>
<hr>
<h2 id="Riemannian-Laplace-Approximation-with-the-Fisher-Metric"><a href="#Riemannian-Laplace-Approximation-with-the-Fisher-Metric" class="headerlink" title="Riemannian Laplace Approximation with the Fisher Metric"></a>Riemannian Laplace Approximation with the Fisher Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02766">http://arxiv.org/abs/2311.02766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanlin Yu, Marcelo Hartmann, Bernardo Williams, Mark Girolami, Arto Klami</li>
<li>for: 用于bayesian inference中的快速和精确approximation</li>
<li>methods: 使用laplace approximation方法，并通过选择合适的里曼几何来提高approximation的精度</li>
<li>results: 提供了两种新的variant，可以在各种实验中提供更好的approximation，并且在有限数据情况下减少了偏差和过度窄approximation的问题<details>
<summary>Abstract</summary>
The Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties heavily depend on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments.
</details>
<details>
<summary>摘要</summary>
拉普拉斯方法可以用 Gaussian 分布来近似目标概率密度。它在 bayesian 推断中是计算高效且 asymptotically exact 的，但是对于复杂的目标和 finite-data posterior 来说，它通常是太粗糙的。一种 latest 的 Laplace Approximation 扩展可以根据选择的 Riemannian geometry 来修改 Gaussian approximation，提供更加丰富的近似家族，并仍保持计算效率。然而，在选择的 metric 的情况下，这种方法的性质受到严重的限制， previous 的 metric 导致的近似偏差和偏见甚至在 infinite 数据的情况下也存在。我们在这篇文章中解决这个缺陷，开发出两种变体，其中一种是 infinite 数据的正确的，另一种是对于不同的 metric 进行了扩展的分析，并在一系列实验中展示了实践上的改进。
</details></li>
</ul>
<hr>
<h2 id="Log-Concavity-of-Multinomial-Likelihood-Functions-Under-Interval-Censoring-Constraints-on-Frequencies-or-Their-Partial-Sums"><a href="#Log-Concavity-of-Multinomial-Likelihood-Functions-Under-Interval-Censoring-Constraints-on-Frequencies-or-Their-Partial-Sums" class="headerlink" title="Log-Concavity of Multinomial Likelihood Functions Under Interval Censoring Constraints on Frequencies or Their Partial Sums"></a>Log-Concavity of Multinomial Likelihood Functions Under Interval Censoring Constraints on Frequencies or Their Partial Sums</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02763">http://arxiv.org/abs/2311.02763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruce Levin, Erik Learned-Miller</li>
<li>for: 这篇论文是为了解释多项式观察数据下的interval隐藏约束的likelihood函数是完全log凹的。</li>
<li>methods: 这篇论文使用了证明constrained sample spaces是M-convex的 discrete simplex中的子集来证明likelihood函数的完全log凹性。</li>
<li>results: 这篇论文得到了likelihood函数在多项式观察数据下的interval隐藏约束下是completely log-concave的结论。<details>
<summary>Abstract</summary>
We show that the likelihood function for a multinomial vector observed under arbitrary interval censoring constraints on the frequencies or their partial sums is completely log-concave by proving that the constrained sample spaces comprise M-convex subsets of the discrete simplex.
</details>
<details>
<summary>摘要</summary>
我们证明了一个多omial вектор在任意间隔缩放约束下观察到的概率函数是完全log-Concave，通过证明受约束的样本空间是M-convex的集合。Here's a breakdown of the translation:* "We show" is translated as "我们证明" (wǒmen shèngyì)* "likelihood function" is translated as "概率函数" (gòu yù fungs)* "for a multinomial vector" is translated as "一个多omial вектор" (yī gè múltiōm mèng)* "observed under arbitrary interval censoring constraints" is translated as "在任意间隔缩放约束下观察" (zài ràng yì jì jiān zhòng yòu xiǎng)* "on the frequencies or their partial sums" is translated as "在频率或其部分和" (zhì yì yǔ qí bù fāng hé)* "is completely log-concave" is translated as "是完全log-Concave" (shì wán zhì yì)* "by proving that the constrained sample spaces comprise M-convex subsets of the discrete simplex" is translated as "通过证明受约束的样本空间是M-convex的集合" (tông qiào yì zhèng yì zhōng xiàng)I hope this helps! Let me know if you have any other questions.
</details></li>
</ul>
<hr>
<h2 id="One-Shot-Strategic-Classification-Under-Unknown-Costs"><a href="#One-Shot-Strategic-Classification-Under-Unknown-Costs" class="headerlink" title="One-Shot Strategic Classification Under Unknown Costs"></a>One-Shot Strategic Classification Under Unknown Costs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02761">http://arxiv.org/abs/2311.02761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elan Rosenfeld, Nir Rosenfeld</li>
<li>for: 本研究旨在学习具有抗压缩性的决策规则，以适应不确定的用户回应。</li>
<li>methods: 本文使用了一些新的方法，包括将用户成本函数作为不确定性的来源，并使用最小最大问题来解决一shot任务。</li>
<li>results: 本文提供了一些有效的算法，可以在一shot任务中快速地获得最佳的决策规则，并且证明了这些算法在不同的设置下是有效的。<details>
<summary>Abstract</summary>
A primary goal in strategic classification is to learn decision rules which are robust to strategic input manipulation. Earlier works assume that strategic responses are known; while some recent works address the important challenge of unknown responses, they exclusively study sequential settings which allow multiple model deployments over time. But there are many domains$\unicode{x2014}$particularly in public policy, a common motivating use-case$\unicode{x2014}$where multiple deployments are unrealistic, or where even a single bad round is undesirable. To address this gap, we initiate the study of strategic classification under unknown responses in the one-shot setting, which requires committing to a single classifier once. Focusing on the users' cost function as the source of uncertainty, we begin by proving that for a broad class of costs, even a small mis-estimation of the true cost can entail arbitrarily low accuracy in the worst case. In light of this, we frame the one-shot task as a minimax problem, with the goal of identifying the classifier with the smallest worst-case risk over an uncertainty set of possible costs. Our main contribution is efficient algorithms for both the full-batch and stochastic settings, which we prove converge (offline) to the minimax optimal solution at the dimension-independent rate of $\tilde{\mathcal{O}(T^{-\frac{1}{2})$. Our analysis reveals important structure stemming from the strategic nature of user responses, particularly the importance of dual norm regularization with respect to the cost function.
</details>
<details>
<summary>摘要</summary>
主要目标在策略分类中是学习对输入操作的Robust策略决策规则。earlier works假设战略回应是已知的；而一些最近的工作Addressing the important challenge of unknown responses, but they only study sequential settings, which allow multiple model deployments over time. However, there are many domains, particularly in public policy, a common motivating use case, where multiple deployments are unrealistic, or where even a single bad round is undesirable. To address this gap, we initiate the study of strategic classification under unknown responses in the one-shot setting, which requires committing to a single classifier once. Focusing on the users' cost function as the source of uncertainty, we begin by proving that for a broad class of costs, even a small misestimation of the true cost can lead to arbitrarily low accuracy in the worst case. In light of this, we frame the one-shot task as a minimax problem, with the goal of identifying the classifier with the smallest worst-case risk over an uncertainty set of possible costs. Our main contribution is efficient algorithms for both the full-batch and stochastic settings, which we prove converge (offline) to the minimax optimal solution at the dimension-independent rate of $\tilde{\mathcal{O}(T^{-\frac{1}{2})$. Our analysis reveals important structure stemming from the strategic nature of user responses, particularly the importance of dual norm regularization with respect to the cost function.
</details></li>
</ul>
<hr>
<h2 id="ELEGANT-Certified-Defense-on-the-Fairness-of-Graph-Neural-Networks"><a href="#ELEGANT-Certified-Defense-on-the-Fairness-of-Graph-Neural-Networks" class="headerlink" title="ELEGANT: Certified Defense on the Fairness of Graph Neural Networks"></a>ELEGANT: Certified Defense on the Fairness of Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02757">http://arxiv.org/abs/2311.02757</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushundong/ELEGANT">https://github.com/yushundong/ELEGANT</a></li>
<li>paper_authors: Yushun Dong, Binchi Zhang, Hanghang Tong, Jundong Li</li>
<li>for: 本研究旨在针对Graph Neural Networks (GNNs) 中的不公正性问题进行研究，提出了一个名为 ELEGANT 的原理性框架，以确保 GNNs 的预测结果具有公正性。</li>
<li>methods: 本研究使用了 GNNs 作为背景，提出了一个名为 ELEGANT 的原理性框架，并进行了详细的理论认证分析，以确保 GNNs 的公正性。ELEGANT 不假设 GNNs 的结构或参数，并且不需要重新训练 GNNs 来实现认证。</li>
<li>results: 实验结果显示，ELEGANT 能够实现 GNNs 的公正性认证，并且在实际应用中具有优秀的效果。此外，ELEGANT 还能够帮助 GNNs 的偏见调整。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have emerged as a prominent graph learning model in various graph-based tasks over the years. Nevertheless, due to the vulnerabilities of GNNs, it has been empirically proved that malicious attackers could easily corrupt the fairness level of their predictions by adding perturbations to the input graph data. In this paper, we take crucial steps to study a novel problem of certifiable defense on the fairness level of GNNs. Specifically, we propose a principled framework named ELEGANT and present a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT takes any GNNs as its backbone, and the fairness level of such a backbone is theoretically impossible to be corrupted under certain perturbation budgets for attackers. Notably, ELEGANT does not have any assumption over the GNN structure or parameters, and does not require re-training the GNNs to realize certification. Hence it can serve as a plug-and-play framework for any optimized GNNs ready to be deployed. We verify the satisfactory effectiveness of ELEGANT in practice through extensive experiments on real-world datasets across different backbones of GNNs, where ELEGANT is also demonstrated to be beneficial for GNN debiasing. Open-source code can be found at https://github.com/yushundong/ELEGANT.
</details>
<details>
<summary>摘要</summary>
GRAPH Neural Networks (GNNs) 在各种基于图的任务中 emerged as a prominent graph learning model over the years. However, due to the vulnerabilities of GNNs, it has been empirically proven that malicious attackers could easily corrupt the fairness level of their predictions by adding perturbations to the input graph data. In this paper, we take crucial steps to study a novel problem of certifiable defense on the fairness level of GNNs. Specifically, we propose a principled framework named ELEGANT and present a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT takes any GNNs as its backbone, and the fairness level of such a backbone is theoretically impossible to be corrupted under certain perturbation budgets for attackers. Notably, ELEGANT does not have any assumption over the GNN structure or parameters, and does not require re-training the GNNs to realize certification. Hence it can serve as a plug-and-play framework for any optimized GNNs ready to be deployed. We verify the satisfactory effectiveness of ELEGANT in practice through extensive experiments on real-world datasets across different backbones of GNNs, where ELEGANT is also demonstrated to be beneficial for GNN debiasing. Open-source code can be found at https://github.com/yushundong/ELEGANT.
</details></li>
</ul>
<hr>
<h2 id="Staged-Reinforcement-Learning-for-Complex-Tasks-through-Decomposed-Environments"><a href="#Staged-Reinforcement-Learning-for-Complex-Tasks-through-Decomposed-Environments" class="headerlink" title="Staged Reinforcement Learning for Complex Tasks through Decomposed Environments"></a>Staged Reinforcement Learning for Complex Tasks through Decomposed Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02746">http://arxiv.org/abs/2311.02746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Pina, Corentin Artaud, Xiaolan Liu, Varuna De Silva</li>
<li>for: 本研究旨在提高智能控制领域中RL的应用，特别是在交通交叉口上。</li>
<li>methods: 本文提出了两种方法来将RL问题近似到实际问题，包括划分复杂任务为多个子任务，以及基于CTDE paradigm的训练结构 mechanism。</li>
<li>results: 研究结果表明，提出的方法可以提高交通交叉口中智能代理的性能，避免 possiblesafety-critical problem。<details>
<summary>Abstract</summary>
Reinforcement Learning (RL) is an area of growing interest in the field of artificial intelligence due to its many notable applications in diverse fields. Particularly within the context of intelligent vehicle control, RL has made impressive progress. However, currently it is still in simulated controlled environments where RL can achieve its full super-human potential. Although how to apply simulation experience in real scenarios has been studied, how to approximate simulated problems to the real dynamic problems is still a challenge. In this paper, we discuss two methods that approximate RL problems to real problems. In the context of traffic junction simulations, we demonstrate that, if we can decompose a complex task into multiple sub-tasks, solving these tasks first can be advantageous to help minimising possible occurrences of catastrophic events in the complex task. From a multi-agent perspective, we introduce a training structuring mechanism that exploits the use of experience learned under the popular paradigm called Centralised Training Decentralised Execution (CTDE). This experience can then be leveraged in fully decentralised settings that are conceptually closer to real settings, where agents often do not have access to a central oracle and must be treated as isolated independent units. The results show that the proposed approaches improve agents performance in complex tasks related to traffic junctions, minimising potential safety-critical problems that might happen in these scenarios. Although still in simulation, the investigated situations are conceptually closer to real scenarios and thus, with these results, we intend to motivate further research in the subject.
</details>
<details>
<summary>摘要</summary>
《强化学习（RL）是人工智能领域中不断吸引关注的领域，尤其在智能控制领域中有很多应用。然而，RL在真实环境中仍然处于模拟控制环境中，尚未实现其全面超人类能力。虽然如何将模拟问题应用到实际动态问题已经被研究，但如何近似模拟问题与实际问题的关系仍然是一大挑战。本文提出了两种方法来近似RL问题与实际问题。在交通交叉点 simulations中，我们示出了如果将复杂任务 decomposed into多个子任务，解决这些子任务可以帮助避免在复杂任务中可能发生的致命事件。从多代理视角来看，我们引入了一种基于Centralised Training Decentralised Execution（CTDE） paradigm的训练结构机制，该机制可以利用在模拟环境中学习的经验，并在完全分布式设置中使用。这些设置更加接近实际情况， где agents 通常没有中央抽象 oracle 的访问权限，并且需要 treated as isolated independent units。结果表明，提出的方法可以提高在交通交叉点相关任务中的代理性能，最小化 potential safety-critical problems 在这些场景中发生的可能性。虽然仍然在模拟环境中，investigated 情况更加接近实际情况，我们希望通过这些结果来鼓励进一步的研究。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Correlated-Auxiliary-Feedback-in-Parameterized-Bandits"><a href="#Exploiting-Correlated-Auxiliary-Feedback-in-Parameterized-Bandits" class="headerlink" title="Exploiting Correlated Auxiliary Feedback in Parameterized Bandits"></a>Exploiting Correlated Auxiliary Feedback in Parameterized Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02715">http://arxiv.org/abs/2311.02715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arun Verma, Zhongxiang Dai, Yao Shu, Bryan Kian Hsiang Low</li>
<li>for: 本研究考虑了一种新的参数化弦楽器问题变体，在这种变体中，学习者可以观察额外反馈，这些额外反馈与观察到的奖励相关。</li>
<li>methods: 我们首先开发了一种利用额外反馈建立奖励估计器，并提供了准确的信息 bound，从而减少了 regret。</li>
<li>results: 我们通过对不同设置的实验结果表明，我们的提议方法可以减少 regret，并且可以在不同的奖励和额外反馈相关性水平下实现最佳性。<details>
<summary>Abstract</summary>
We study a novel variant of the parameterized bandits problem in which the learner can observe additional auxiliary feedback that is correlated with the observed reward. The auxiliary feedback is readily available in many real-life applications, e.g., an online platform that wants to recommend the best-rated services to its users can observe the user's rating of service (rewards) and collect additional information like service delivery time (auxiliary feedback). In this paper, we first develop a method that exploits auxiliary feedback to build a reward estimator with tight confidence bounds, leading to a smaller regret. We then characterize the regret reduction in terms of the correlation coefficient between reward and its auxiliary feedback. Experimental results in different settings also verify the performance gain achieved by our proposed method.
</details>
<details>
<summary>摘要</summary>
我们研究一种新的参数化弦折冲问题变体，在这种问题中，学习者可以观察额外的协助反馈，这些协助反馈与观察到的奖励相关。这些协助反馈在实际应用中很普遍，例如一个在线平台可以观察用户对服务的评分（奖励），同时收集服务交付时间（协助反馈）的信息。在这篇论文中，我们首先开发了一种利用协助反馈建立奖励估计器，并提供紧张的信任范围，从而减少了偏差。然后，我们将偏差减少的程度与奖励和其协助反馈之间的相关性系数进行描述。实际Results in different settings also verify the performance gain achieved by our proposed method.
</details></li>
</ul>
<hr>
<h2 id="A-Goal-Driven-Approach-to-Systems-Neuroscience"><a href="#A-Goal-Driven-Approach-to-Systems-Neuroscience" class="headerlink" title="A Goal-Driven Approach to Systems Neuroscience"></a>A Goal-Driven Approach to Systems Neuroscience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02704">http://arxiv.org/abs/2311.02704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aran Nayebi</li>
<li>for: 这个论文旨在解释如何从大量神经元记录数据中提取有用的信息，以便更好地理解神经元网络如何生成智能行为。</li>
<li>methods: 这个论文使用了新的方法来解释神经元网络如何处理信息，包括使用权重学习和聚类分析等方法。</li>
<li>results: 研究人员通过使用这些新方法，成功地从大量神经元记录数据中提取了有用的信息，并实现了解释神经元网络如何生成智能行为的目标。<details>
<summary>Abstract</summary>
Humans and animals exhibit a range of interesting behaviors in dynamic environments, and it is unclear how our brains actively reformat this dense sensory information to enable these behaviors. Experimental neuroscience is undergoing a revolution in its ability to record and manipulate hundreds to thousands of neurons while an animal is performing a complex behavior. As these paradigms enable unprecedented access to the brain, a natural question that arises is how to distill these data into interpretable insights about how neural circuits give rise to intelligent behaviors. The classical approach in systems neuroscience has been to ascribe well-defined operations to individual neurons and provide a description of how these operations combine to produce a circuit-level theory of neural computations. While this approach has had some success for small-scale recordings with simple stimuli, designed to probe a particular circuit computation, often times these ultimately lead to disparate descriptions of the same system across stimuli. Perhaps more strikingly, many response profiles of neurons are difficult to succinctly describe in words, suggesting that new approaches are needed in light of these experimental observations. In this thesis, we offer a different definition of interpretability that we show has promise in yielding unified structural and functional models of neural circuits, and describes the evolutionary constraints that give rise to the response properties of the neural population, including those that have previously been difficult to describe individually. We demonstrate the utility of this framework across multiple brain areas and species to study the roles of recurrent processing in the primate ventral visual pathway; mouse visual processing; heterogeneity in rodent medial entorhinal cortex; and facilitating biological learning.
</details>
<details>
<summary>摘要</summary>
人类和动物在动态环境中展现出一系列有趣的行为，但是不清楚如何我们的脑活动地重新格式化这些紧凑的感知信息以实现这些行为。现代神经科学在实验方面正在进行一场革命，可以同时记录和 manipulate hundreds to thousands of neurons  während动物执行复杂的行为。随着这些方法得到了无 precedent 的访问到脑部，一个自然的问题是如何将这些数据转化成可解释的洞察。传统的系统神经科学方法是将各个神经元的操作归因为具体的功能，然后将这些操作组合起来描述神经网络的计算。虽然这种方法在小规模记录中有一定的成功，但是这些经常导致不同的描述，尤其是当面对复杂的刺激时。此外，许多神经元的响应特征难以用语言描述，表明需要新的方法。在这个论文中，我们提出了一种不同的可解释性定义，并证明这种定义在提供简单结构和功能模型方面具有推动力。我们在多个脑区和种类中使用这种方法，研究了Primates ventral visual pathway; mouse visual processing; rodent medial entorhinal cortex 中神经元种类的多样性和动物学习。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Linearly-Mixed-Causal-Representations-from-Multi-Node-Interventions"><a href="#Identifying-Linearly-Mixed-Causal-Representations-from-Multi-Node-Interventions" class="headerlink" title="Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions"></a>Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02695">http://arxiv.org/abs/2311.02695</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Bing, Urmi Ninad, Jonas Wahl, Jakob Runge</li>
<li>for: This paper focuses on the problem of inferring high-level causal variables from low-level observations, and it provides a new approach to addressing this problem by relaxing the assumption that only one variable can be intervened upon in each environment.</li>
<li>methods: The paper proposes a new method for causal representation learning that exploits the trace of interventions on the variance of ground truth causal variables, and it regularizes for a specific notion of sparsity with respect to this trace.</li>
<li>results: The paper presents empirical evidence that validates the identifiability results of the proposed approach, and it demonstrates the effectiveness of the approach in learning causal representations from multi-node interventional data.<details>
<summary>Abstract</summary>
The task of inferring high-level causal variables from low-level observations, commonly referred to as causal representation learning, is fundamentally underconstrained. As such, recent works to address this problem focus on various assumptions that lead to identifiability of the underlying latent causal variables. A large corpus of these preceding approaches consider multi-environment data collected under different interventions on the causal model. What is common to virtually all of these works is the restrictive assumption that in each environment, only a single variable is intervened on. In this work, we relax this assumption and provide the first identifiability result for causal representation learning that allows for multiple variables to be targeted by an intervention within one environment. Our approach hinges on a general assumption on the coverage and diversity of interventions across environments, which also includes the shared assumption of single-node interventions of previous works. The main idea behind our approach is to exploit the trace that interventions leave on the variance of the ground truth causal variables and regularizing for a specific notion of sparsity with respect to this trace. In addition to and inspired by our theoretical contributions, we present a practical algorithm to learn causal representations from multi-node interventional data and provide empirical evidence that validates our identifiability results.
</details>
<details>
<summary>摘要</summary>
文中提到的高级 causal 变量推理问题，通常称为 causal 表示学习，是基本不可靠定。因此， recient works 做出了多种假设，以便确定下意图的 latent causal 变量。大多数先前的方法假设了每个环境中只有一个变量被 intervened 。在这种情况下，我们在这篇文章中放弃了这一假设，并提供了首个允许多变量在一个环境中被 intervened 的 causal 表示学习的可定性结果。我们的方法基于一个通用的假设，即环境中的 intervention 覆盖和多样性，包括先前作品中的单个变量 intervened 假设。我们的主要想法是利用 intervention 对真实 causal 变量的跟踪，并对这些跟踪的特定缺失进行规范化。此外，我们还提供了一种实用的算法，用于从 multi-node interventional 数据中学习 causal 表示，并提供了实验证据，证明了我们的可定性结果。
</details></li>
</ul>
<hr>
<h2 id="Regret-Analysis-of-Learning-Based-Linear-Quadratic-Gaussian-Control-with-Additive-Exploration"><a href="#Regret-Analysis-of-Learning-Based-Linear-Quadratic-Gaussian-Control-with-Additive-Exploration" class="headerlink" title="Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with Additive Exploration"></a>Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with Additive Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02679">http://arxiv.org/abs/2311.02679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Archith Athrey, Othmane Mazhar, Meichen Guo, Bart De Schutter, Shengling Shi</li>
<li>for: 这个论文研究了一种 computationally efficient exploration strategy，即naive exploration，在Linear Quadratic Gaussian (LQG)框架下控制未知部分可观测系统中的 regret。</li>
<li>methods: 作者提出了一种两相控制算法，即LQG-NAIVE，它包括一个初始阶段将 Gaussian 输入信号注入系统以获得系统模型，然后在一个 episodic 的方式下进行naive exploration和控制。</li>
<li>results: 作者证明了LQG-NAIVE 可以在 $T$ 步时间内实现 regret 增长率为 $\tilde{\mathcal{O}(\sqrt{T})$，即 $\mathcal{O}(\sqrt{T})$ 以上下标Logarithmic 因子。此外，作者还提出了一种扩展exploration signal到 ‘closed-loop’ 设置的LQG-IF2E，并通过数值实验证明了它的竞争性性。<details>
<summary>Abstract</summary>
In this paper, we analyze the regret incurred by a computationally efficient exploration strategy, known as naive exploration, for controlling unknown partially observable systems within the Linear Quadratic Gaussian (LQG) framework. We introduce a two-phase control algorithm called LQG-NAIVE, which involves an initial phase of injecting Gaussian input signals to obtain a system model, followed by a second phase of an interplay between naive exploration and control in an episodic fashion. We show that LQG-NAIVE achieves a regret growth rate of $\tilde{\mathcal{O}(\sqrt{T})$, i.e., $\mathcal{O}(\sqrt{T})$ up to logarithmic factors after $T$ time steps, and we validate its performance through numerical simulations. Additionally, we propose LQG-IF2E, which extends the exploration signal to a `closed-loop' setting by incorporating the Fisher Information Matrix (FIM). We provide compelling numerical evidence of the competitive performance of LQG-IF2E compared to LQG-NAIVE.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们分析了 computationally efficient exploration strategy，即naive exploration，对于 unknown partially observable systems在线性quadratic Gaussian (LQG) 框架中的 regret。我们提出了一种两个阶段控制算法，称为LQG-NAIVE，它包括一个初始阶段在注入 Gaussian 输入信号以获取系统模型，然后是一个第二阶段的一种 episodic 的naive exploration和控制的交互。我们证明了LQG-NAIVE 的 regret增长率为 $\tilde{\mathcal{O}(\sqrt{T})$，即 $\mathcal{O}(\sqrt{T})$  после $T$ 步，并通过数学仿真来验证其性能。此外，我们还提出了LQG-IF2E，它在探索信号中添加了 Fisher Information Matrix (FIM)，并提供了对LQG-NAIVE的竞争性性能的数学证明。
</details></li>
</ul>
<hr>
<h2 id="Drone-Enabled-Load-Management-for-Solar-Small-Cell-Networks-in-Next-Gen-Communications-Optimization-for-Solar-Small-Cells"><a href="#Drone-Enabled-Load-Management-for-Solar-Small-Cell-Networks-in-Next-Gen-Communications-Optimization-for-Solar-Small-Cells" class="headerlink" title="Drone-Enabled Load Management for Solar Small Cell Networks in Next-Gen Communications Optimization for Solar Small Cells"></a>Drone-Enabled Load Management for Solar Small Cell Networks in Next-Gen Communications Optimization for Solar Small Cells</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02648">http://arxiv.org/abs/2311.02648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Dhruv Khut, Sahil Nawale, Pushkar Aggrawal, Disha Rastogi, Kailas Devadkar</li>
<li>for: 该研究旨在提高5G及以后cellular网络的能源效率和可靠性，通过使用无人机携带的空中基站（BS）实现稳定和安全的能源重新分配。</li>
<li>methods: 该研究提出了一种创新的负荷传输方法，通过将空中BS从高到低能电络中转移，根据用户密度和空中BS的可用性进行能源分配优化。</li>
<li>results: 该研究表明，提议的算法可以降低BS的发电停机频率，并且只需最小化的无人机交换数量。同时，实验结果表明，该方法可以提高cellular网络的能源效率和可靠性。<details>
<summary>Abstract</summary>
In recent years, the cellular industry has witnessed a major evolution in communication technologies. It is evident that the Next Generation of cellular networks(NGN) will play a pivotal role in the acceptance of emerging IoT applications supporting high data rates, better Quality of Service(QoS), and reduced latency. However, the deployment of NGN will introduce a power overhead on the communication infrastructure. Addressing the critical energy constraints in 5G and beyond, this study introduces an innovative load transfer method using drone-carried airborne base stations (BSs) for stable and secure power reallocation within a green micro-grid network. This method effectively manages energy deficit by transferring aerial BSs from high to low-energy cells, depending on user density and the availability of aerial BSs, optimizing power distribution in advanced cellular networks. The complexity of the proposed system is significantly lower as compared to existing power cable transmission systems currently employed in powering the BSs. Furthermore, our proposed algorithm has been shown to reduce BS power outages while requiring a minimum number of drone exchanges. We have conducted a thorough review on real-world dataset to prove the efficacy of our proposed approach to support BS during high load demand times
</details>
<details>
<summary>摘要</summary>
This method effectively manages energy deficits by transferring aerial BSs from high to low-energy cells, depending on user density and the availability of aerial BSs, optimizing power distribution in advanced cellular networks. The proposed system is significantly simpler than existing power cable transmission systems currently employed in powering BSs. Additionally, our proposed algorithm has been shown to reduce BS power outages while requiring a minimum number of drone exchanges. We have conducted a thorough review of real-world data to prove the efficacy of our proposed approach in supporting BSs during high load demand times.
</details></li>
</ul>
<hr>
<h2 id="Pointer-Networks-with-Q-Learning-for-OP-Combinatorial-Optimization"><a href="#Pointer-Networks-with-Q-Learning-for-OP-Combinatorial-Optimization" class="headerlink" title="Pointer Networks with Q-Learning for OP Combinatorial Optimization"></a>Pointer Networks with Q-Learning for OP Combinatorial Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02629">http://arxiv.org/abs/2311.02629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Barro</li>
<li>for: 解决Orienteering Problem（OP）中的 combinatorial optimization 问题，它在物流、交通规划等领域广泛应用。</li>
<li>methods:  combining Pointer Networks（Ptr-Nets）和Q-learning，提出Pointer Q-Network（PQN），以解决OP 中的特定挑战。</li>
<li>results: PQN 能够有效地管理 OP 的 Situations，并且可以提高 solving  efficiency。<details>
<summary>Abstract</summary>
The Orienteering Problem (OP) presents a unique challenge in combinatorial optimization, emphasized by its widespread use in logistics, delivery, and transportation planning. Given the NP-hard nature of OP, obtaining optimal solutions is inherently complex. While Pointer Networks (Ptr-Nets) have exhibited prowess in various combinatorial tasks, their performance in the context of OP leaves room for improvement. Recognizing the potency of Q-learning, especially when paired with deep neural structures, this research unveils the Pointer Q-Network (PQN). This innovative method combines Ptr-Nets and Q-learning, effectively addressing the specific challenges presented by OP. We deeply explore the architecture and efficiency of PQN, showcasing its superior capability in managing OP situations.
</details>
<details>
<summary>摘要</summary>
Orienteering Problem (OP) 提供了一种独特的 combinatorial optimization 挑战，它在物流、配送和交通规划中广泛使用。由于 OP 的NP-hard性，得到优化的解决方案是内在复杂的。虽然 Pointer Networks (Ptr-Nets) 在其他 combinatorial 任务中表现出色，但在 OP  中它们的表现还有提升的空间。这篇研究发现了 Pointer Q-Network (PQN)，这是一种 combining Ptr-Nets 和 Q-learning 的新方法，能够有效地解决 OP  中的特定挑战。我们深入探讨了 PQN 的体系和效率，并证明它在管理 OP  situations 方面的能力。
</details></li>
</ul>
<hr>
<h2 id="An-adaptive-standardisation-model-for-Day-Ahead-electricity-price-forecasting"><a href="#An-adaptive-standardisation-model-for-Day-Ahead-electricity-price-forecasting" class="headerlink" title="An adaptive standardisation model for Day-Ahead electricity price forecasting"></a>An adaptive standardisation model for Day-Ahead electricity price forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02610">http://arxiv.org/abs/2311.02610</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CCaribe9/AdaptStdEPF">https://github.com/CCaribe9/AdaptStdEPF</a></li>
<li>paper_authors: Carlos Sebastián, Carlos E. González-Guillén, Jesús Juan</li>
<li>for: 这个研究旨在探讨日前价格的电力市场，以提高时间序列预测的精度。</li>
<li>methods: 本研究提出了一种适应标准化方法，以减少 dataset shift 的影响，并将学习算法优先显示target variable 和说明 variable之间的真实关系。</li>
<li>results: 研究发现在四个不同的市场中，适应标准化方法可以实现明显的提升，并且这些方法比较简单，广泛地被接受在文献中。<details>
<summary>Abstract</summary>
The study of Day-Ahead prices in the electricity market is one of the most popular problems in time series forecasting. Previous research has focused on employing increasingly complex learning algorithms to capture the sophisticated dynamics of the market. However, there is a threshold where increased complexity fails to yield substantial improvements. In this work, we propose an alternative approach by introducing an adaptive standardisation to mitigate the effects of dataset shifts that commonly occur in the market. By doing so, learning algorithms can prioritize uncovering the true relationship between the target variable and the explanatory variables. We investigate four distinct markets, including two novel datasets, previously unexplored in the literature. These datasets provide a more realistic representation of the current market context, that conventional datasets do not show. The results demonstrate a significant improvement across all four markets, using learning algorithms that are less complex yet widely accepted in the literature. This significant advancement unveils opens up new lines of research in this field, highlighting the potential of adaptive transformations in enhancing the performance of forecasting models.
</details>
<details>
<summary>摘要</summary>
研究日前价格在电力市场是时间序列预测中最受欢迎的问题。前期研究强调使用越来越复杂的学习算法来捕捉市场的复杂 Dynamics。然而，存在一个阈值，其中增加复杂性不会导致明显的改善。在这项工作中，我们提出一种alternative方法，通过引入适应标准化来 Mitigate the effects of dataset shifts that commonly occur in the market。这样，学习算法可以更好地捕捉目标变量和解释变量之间的真实关系。我们对四个不同的市场进行了调查，包括两个新的数据集，之前在文献中未被探讨。这些数据集提供了更加现实的市场Context，与传统数据集不同。结果表明在所有四个市场中，使用 Less complex yet widely accepted in the literature 的学习算法可以 achieve significant improvement。这一成果推开了新的研究方向， highlighting the potential of adaptive transformations in enhancing the performance of forecasting models.
</details></li>
</ul>
<hr>
<h2 id="Steady-State-Analysis-of-Queues-with-Hawkes-Arrival-and-Its-Application-to-Online-Learning-for-Hawkes-Queues"><a href="#Steady-State-Analysis-of-Queues-with-Hawkes-Arrival-and-Its-Application-to-Online-Learning-for-Hawkes-Queues" class="headerlink" title="Steady-State Analysis of Queues with Hawkes Arrival and Its Application to Online Learning for Hawkes Queues"></a>Steady-State Analysis of Queues with Hawkes Arrival and Its Application to Online Learning for Hawkes Queues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02577">http://arxiv.org/abs/2311.02577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyun Chen, Guiyu Hong</li>
<li>for: 研究单服务器队列的长期行为，包括 Hawkes 到达和一般服务分布。</li>
<li>methods: 使用新的 coupling 技术，确定工作负荷和忙期过程的finite moment bound。</li>
<li>results: 显示 Hawkes 队列在极高负荷 regime 下的员工编制问题可以通过数据驱动的方式解决，与 класси GI&#x2F;GI&#x2F;1 模型存在显著差异。<details>
<summary>Abstract</summary>
We investigate the long-run behavior of single-server queues with Hawkes arrivals and general service distributions and related optimization problems. In detail, utilizing novel coupling techniques, we establish finite moment bounds for the stationary distribution of the workload and busy period processes. In addition, we are able to show that, those queueing processes converge exponentially fast to their stationary distribution. Based on these theoretic results, we develop an efficient numerical algorithm to solve the optimal staffing problem for the Hawkes queues in a data-driven manner. Numerical results indicate a sharp difference in staffing for Hawkes queues, compared to the classic GI/GI/1 model, especially in the heavy-traffic regime.
</details>
<details>
<summary>摘要</summary>
我团队 investigate 单服务器队列中的长期行为，包括骚然来到和通用服务分布。我们使用新的协同技术来确定工作负载和忙期过程的finite moment bound。此外，我们还证明这些队列过程在 exponentially fast 速度下逐渐 converges to 其 stationary distribution。基于这些理论结论，我们开发了一种高效的数据驱动的 numerical algorithm 来解决 Hawkes 队列的优化人员问题。numerical results 显示，在高负荷情况下，Hawkes 队列的人员配置与 classical GI/GI/1 模型存在很大的差异。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Treasure-Hunt-Content-based-Time-Series-Retrieval-System-for-Discovering-Insights"><a href="#Temporal-Treasure-Hunt-Content-based-Time-Series-Retrieval-System-for-Discovering-Insights" class="headerlink" title="Temporal Treasure Hunt: Content-based Time Series Retrieval System for Discovering Insights"></a>Temporal Treasure Hunt: Content-based Time Series Retrieval System for Discovering Insights</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02560">http://arxiv.org/abs/2311.02560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chin-Chia Michael Yeh, Huiyuan Chen, Xin Dai, Yan Zheng, Yujie Fan, Vivian Lai, Junpeng Wang, Audrey Der, Zhongfang Zhuang, Liang Wang, Wei Zhang</li>
<li>for: 这篇论文是针对多个领域的时间序列数据进行内容基于时间序列搜寻（CTSR）的研究。</li>
<li>methods: 本研究使用了多种实验方法，包括传统的时间序列模型和distance learning模型。</li>
<li>results: 研究发现，distance learning模型在多个领域的时间序列数据上表现较好，并且超过了其他方法的性能。<details>
<summary>Abstract</summary>
Time series data is ubiquitous across various domains such as finance, healthcare, and manufacturing, but their properties can vary significantly depending on the domain they originate from. The ability to perform Content-based Time Series Retrieval (CTSR) is crucial for identifying unknown time series examples. However, existing CTSR works typically focus on retrieving time series from a single domain database, which can be inadequate if the user does not know the source of the query time series. This limitation motivates us to investigate the CTSR problem in a scenario where the database contains time series from multiple domains. To facilitate this investigation, we introduce a CTSR benchmark dataset that comprises time series data from a variety of domains, such as motion, power demand, and traffic. This dataset is sourced from a publicly available time series classification dataset archive, making it easily accessible to researchers in the field. We compare several popular methods for modeling and retrieving time series data using this benchmark dataset. Additionally, we propose a novel distance learning model that outperforms the existing methods. Overall, our study highlights the importance of addressing the CTSR problem across multiple domains and provides a useful benchmark dataset for future research.
</details>
<details>
<summary>摘要</summary>
<<SYS>>时序数据在各个领域都是普遍存在的，如金融、医疗和制造等，但它们的特性可能因领域而异。能够进行内容基于时序数据检索（CTSR）是识别未知时序示例的重要能力。然而，现有的CTSR工作通常将注重于从单一领域数据库中检索时序数据，这可能无法满足用户如果不知道查询时序数据的来源。这种限制驱动我们调查CTSR问题在多个领域数据库中进行检索。为了促进这种调查，我们提出了一个CTSRbenchmark dataset，该dataset包含来自多个领域的时序数据，如运动、电力需求和交通。这个dataset来自公共可用的时序数据分类dataset库，使其容易访问ible для研究人员。我们比较了许多流行的时序数据模型化和检索方法，并提出了一种新的距离学习模型，该模型在本 benchmark dataset上显示出比其他方法更高的性能。总的来说，我们的研究强调了跨多个领域的CTSR问题的重要性，并提供了一个有用的benchmark dataset，以便未来的研究人员可以继续进行深入的研究。
</details></li>
</ul>
<hr>
<h2 id="Fast-Minimization-of-Expected-Logarithmic-Loss-via-Stochastic-Dual-Averaging"><a href="#Fast-Minimization-of-Expected-Logarithmic-Loss-via-Stochastic-Dual-Averaging" class="headerlink" title="Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging"></a>Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02557">http://arxiv.org/abs/2311.02557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chung-En Tsai, Hao-Chung Cheng, Yen-Huan Li</li>
<li>for: 这篇论文的目的是为了解决预期极小化函数损失的问题，包括解决波索因 inverse problem、计算量子态tomography的最大可能性估计、和approximatepositive semi-definite矩阵常量。</li>
<li>methods: 这篇论文提出了一种名为$B$-sample随机先验法，使用ilogarithmic barrier，用于解决这些问题。</li>
<li>results: 对于波索因 inverse problem，这种算法可以在 $\tilde{O} (d^2&#x2F;\varepsilon^2)$ 时间内获得 $\varepsilon$-优解，与现状相当。对于量子态tomography的最大可能性估计，这种算法可以在 $\tilde{O} (d^3&#x2F;\varepsilon^2)$ 时间内获得 $\varepsilon$-优解，超过现有的随机先验法和批处理法。<details>
<summary>Abstract</summary>
Consider the problem of minimizing an expected logarithmic loss over either the probability simplex or the set of quantum density matrices. This problem encompasses tasks such as solving the Poisson inverse problem, computing the maximum-likelihood estimate for quantum state tomography, and approximating positive semi-definite matrix permanents with the currently tightest approximation ratio. Although the optimization problem is convex, standard iteration complexity guarantees for first-order methods do not directly apply due to the absence of Lipschitz continuity and smoothness in the loss function.   In this work, we propose a stochastic first-order algorithm named $B$-sample stochastic dual averaging with the logarithmic barrier. For the Poisson inverse problem, our algorithm attains an $\varepsilon$-optimal solution in $\tilde{O} (d^2/\varepsilon^2)$ time, matching the state of the art. When computing the maximum-likelihood estimate for quantum state tomography, our algorithm yields an $\varepsilon$-optimal solution in $\tilde{O} (d^3/\varepsilon^2)$ time, where $d$ denotes the dimension. This improves on the time complexities of existing stochastic first-order methods by a factor of $d^{\omega-2}$ and those of batch methods by a factor of $d^2$, where $\omega$ denotes the matrix multiplication exponent. Numerical experiments demonstrate that empirically, our algorithm outperforms existing methods with explicit complexity guarantees.
</details>
<details>
<summary>摘要</summary>
假设我们需要最小化预期的对数损失函数，该函数可能是对概率 simpliciter 或者是对量子稳定矩阵的函数。这个问题包括解决波尔兹 inverse problem、计算量子状态探测的最大可信度估计以及approximating positive semi-definite matrix permanents with the currently tightest approximation ratio。虽然优化问题是凸的，但标准的第一阶方法的证明不直接适用，因为损失函数缺乏 lipschitz 连续和光滑性。在这篇文章中，我们提出了一种随机首频方法，名为 $B$-sample stochastic dual averaging with the logarithmic barrier。对于波尔兹 inverse problem，我们的算法可以在 $\tilde{O} (d^2/\varepsilon^2)$ 时间内获得 $\varepsilon$-优质解，与现状精度相同。当计算量子状态探测的最大可信度估计时，我们的算法可以在 $\tilde{O} (d^3/\varepsilon^2)$ 时间内获得 $\varepsilon$-优质解，其中 $d$ 表示维度。这超过了现有的随机首频方法的时间复杂度，它们的时间复杂度为 $d^{2\omega-2}$，其中 $\omega$ 是矩乘元 exponent。此外，我们的算法也超过了批处理方法的时间复杂度，它们的时间复杂度为 $d^2$。实验表明，我们的算法在实际应用中比现有的方法 WITH 显式复杂度保证更好。
</details></li>
</ul>
<hr>
<h2 id="High-dimensional-Bid-Learning-for-Energy-Storage-Bidding-in-Energy-Markets"><a href="#High-dimensional-Bid-Learning-for-Energy-Storage-Bidding-in-Energy-Markets" class="headerlink" title="High-dimensional Bid Learning for Energy Storage Bidding in Energy Markets"></a>High-dimensional Bid Learning for Energy Storage Bidding in Energy Markets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02551">http://arxiv.org/abs/2311.02551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyu Liu, Hongye Guo, Qinghu Tang, En Lu, Qiuna Cai, Qixin Chen</li>
<li>for:  optimize the profitability of Energy Storage Systems (ESSs) in electricity markets with high-dimensional price-quantity bids.</li>
<li>methods:  modify the common reinforcement learning (RL) process by proposing a new bid representation method called Neural Network Embedded Bids (NNEBs), which represents market bids as monotonic neural networks with discrete outputs.</li>
<li>results:  achieve 18% higher profit than the baseline and up to 78% profit of the optimal market bidder in real-world market datasets.<details>
<summary>Abstract</summary>
With the growing penetration of renewable energy resource, electricity market prices have exhibited greater volatility. Therefore, it is important for Energy Storage Systems(ESSs) to leverage the multidimensional nature of energy market bids to maximize profitability. However, current learning methods cannot fully utilize the high-dimensional price-quantity bids in the energy markets. To address this challenge, we modify the common reinforcement learning(RL) process by proposing a new bid representation method called Neural Network Embedded Bids (NNEBs). NNEBs refer to market bids that are represented by monotonic neural networks with discrete outputs. To achieve effective learning of NNEBs, we first learn a neural network as a strategic mapping from the market price to ESS power output with RL. Then, we re-train the network with two training modifications to make the network output monotonic and discrete. Finally, the neural network is equivalently converted into a high-dimensional bid for bidding. We conducted experiments over real-world market datasets. Our studies show that the proposed method achieves 18% higher profit than the baseline and up to 78% profit of the optimal market bidder.
</details>
<details>
<summary>摘要</summary>
随着可再生能源资源的普及，电力市场价格Display price exhibited greater volatility. Therefore, it is important for Energy Storage Systems (ESSs) to leverage the multidimensional nature of energy market bids to maximize profitability. However, current learning methods cannot fully utilize the high-dimensional price-quantity bids in the energy markets. To address this challenge, we modify the common reinforcement learning (RL) process by proposing a new bid representation method called Neural Network Embedded Bids (NNEBs). NNEBs refer to market bids that are represented by monotonic neural networks with discrete outputs. To achieve effective learning of NNEBs, we first learn a neural network as a strategic mapping from the market price to ESS power output with RL. Then, we re-train the network with two training modifications to make the network output monotonic and discrete. Finally, the neural network is equivalently converted into a high-dimensional bid for bidding. We conducted experiments over real-world market datasets. Our studies show that the proposed method achieves 18% higher profit than the baseline and up to 78% profit of the optimal market bidder.Here's the breakdown of the translation:* 随着可再生能源资源的普及 (followed by a list of words in Simplified Chinese):	+ 可再生能源 (renewable energy)	+ 资源 (resources)	+ 的普及 (penetration)* 电力市场价格Display price exhibited greater volatility. (list of words in Simplified Chinese):	+ 电力 (electricity)	+ 市场 (market)	+ 价格 (price)	+ Display (as a noun, meaning "display" or "exhibition")	+ 更大 (greater)	+ 变化 (volatility)* Therefore, it is important for Energy Storage Systems (ESSs) to leverage the multidimensional nature of energy market bids to maximize profitability. (list of words in Simplified Chinese):	+ 因此 (therefore)	+ Energy Storage Systems (ESSs) (as a noun, meaning "Energy Storage Systems")	+ 需要 (need)	+ 利用 (leverage)	+ 多维 (multidimensional)	+ 能源市场 (energy market)	+ 招标 (bids)	+ 提高 (profitability)* However, current learning methods cannot fully utilize the high-dimensional price-quantity bids in the energy markets. (list of words in Simplified Chinese):	+ 然而 (however)	+ current (as an adjective, meaning "current")	+ learning (as a noun, meaning "learning")	+ methods (as a noun, meaning "methods")	+ cannot (as a verb, meaning "cannot")	+ fully (as an adverb, meaning "fully")	+ utilize (as a verb, meaning "utilize")	+ high-dimensional (as an adjective, meaning "high-dimensional")	+ price-quantity (as a noun phrase, meaning "price-quantity")	+ bids (as a noun, meaning "bids")	+ in (as a preposition, meaning "in")	+ the (as a definite article, meaning "the")	+ energy (as a noun, meaning "energy")	+ markets (as a noun, meaning "markets")* To address this challenge, we modify the common reinforcement learning (RL) process by proposing a new bid representation method called Neural Network Embedded Bids (NNEBs). (list of words in Simplified Chinese):	+  Address (as a verb, meaning "address")	+ this (as a pronoun, meaning "this")	+ challenge (as a noun, meaning "challenge")	+ we (as a pronoun, meaning "we")	+ modify (as a verb, meaning "modify")	+ common (as an adjective, meaning "common")	+ reinforcement (as a noun, meaning "reinforcement")	+ learning (as a noun, meaning "learning")	+ process (as a noun, meaning "process")	+ by (as a preposition, meaning "by")	+ proposing (as a verb, meaning "proposing")	+ a (as a definite article, meaning "a")	+ new (as an adjective, meaning "new")	+ bid (as a noun, meaning "bid")	+ representation (as a noun, meaning "representation")	+ method (as a noun, meaning "method")	+ called (as a verb, meaning "called")	+ Neural Network Embedded Bids (NNEBs) (as a noun phrase, meaning "Neural Network Embedded Bids")* NNEBs refer to market bids that are represented by monotonic neural networks with discrete outputs. (list of words in Simplified Chinese):	+ NNEBs (as a noun phrase, meaning "NNEBs")	+ refer (as a verb, meaning "refer")	+ market (as a noun, meaning "market")	+ bids (as a noun, meaning "bids")	+ that (as a pronoun, meaning "that")	+ are (as a verb, meaning "are")	+ represented (as a verb, meaning "represented")	+ by (as a preposition, meaning "by")	+ monotonic (as an adjective, meaning "monotonic")	+ neural (as an adjective, meaning "neural")	+ networks (as a noun, meaning "networks")	+ with (as a preposition, meaning "with")	+ discrete (as an adjective, meaning "discrete")	+ outputs (as a noun, meaning "outputs")* To achieve effective learning of NNEBs, we first learn a neural network as a strategic mapping from the market price to ESS power output with RL. (list of words in Simplified Chinese):	+ to (as a preposition, meaning "to")	+ achieve (as a verb, meaning "achieve")	+ effective (as an adjective, meaning "effective")	+ learning (as a noun, meaning "learning")	+ of (as a preposition, meaning "of")	+ NNEBs (as a noun phrase, meaning "NNEBs")	+ we (as a pronoun, meaning "we")	+ first (as an adverb, meaning "first")	+ learn (as a verb, meaning "learn")	+ a (as a definite article, meaning "a")	+ neural (as an adjective, meaning "neural")	+ network (as a noun, meaning "network")	+ as (as a preposition, meaning "as")	+ a (as a definite article, meaning "a")	+ strategic (as an adjective, meaning "strategic")	+ mapping (as a noun, meaning "mapping")	+ from (as a preposition, meaning "from")	+ the (as a definite article, meaning "the")	+ market (as a noun, meaning "market")	+ price (as a noun, meaning "price")	+ to (as a preposition, meaning "to")	+ ESS (as a noun, meaning "ESS")	+ power (as a noun, meaning "power")	+ output (as a noun, meaning "output")	+ with (as a preposition, meaning "with")	+ RL (as a noun, meaning "RL")* Then, we re-train the network with two training modifications to make the network output monotonic and discrete. (list of words in Simplified Chinese):	+ Then (as an adverb, meaning "then")	+ we (as a pronoun, meaning "we")	+ re-train (as a verb, meaning "re-train")	+ the (as a definite article, meaning "the")	+ network (as a noun, meaning "network")	+ with (as a preposition, meaning "with")	+ two (as a numeral, meaning "two")	+ training (as a noun, meaning "training")	+ modifications (as a noun, meaning "modifications")	+ to (as a preposition, meaning "to")	+ make (as a verb, meaning "make")	+ the (as a definite article, meaning "the")	+ network (as a noun, meaning "network")	+ output (as a noun, meaning "output")	+ monotonic (as an adjective, meaning "monotonic")	+ and (as a conjunction, meaning "and")	+ discrete (as an adjective, meaning "discrete")* Finally, the neural network is equivalently converted into a high-dimensional bid for bidding. (list of words in Simplified Chinese):	+ Finally (as an adverb, meaning "finally")	+ the (as a definite article, meaning "the")	+ neural (as an adjective, meaning "neural")	+ network (as a noun, meaning "network")	+ is (as a verb, meaning "is")	+ equivalently (as an adverb, meaning "equivalently")	+ converted (as a verb, meaning "converted")	+ into (as a preposition, meaning "into")	+ a (as a definite article, meaning "a")	+ high-dimensional (as an adjective, meaning "high-dimensional")	+ bid (as a noun, meaning "bid")	+ for (as a preposition, meaning "for")	+ bidding (as a noun, meaning "bidding")Note that the translation is based on the given text and may not be perfect or exact, as the meaning of the text may be subject to interpretation.
</details></li>
</ul>
<hr>
<h2 id="Preliminary-Analysis-on-Second-Order-Convergence-for-Biased-Policy-Gradient-Methods"><a href="#Preliminary-Analysis-on-Second-Order-Convergence-for-Biased-Policy-Gradient-Methods" class="headerlink" title="Preliminary Analysis on Second-Order Convergence for Biased Policy Gradient Methods"></a>Preliminary Analysis on Second-Order Convergence for Biased Policy Gradient Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02546">http://arxiv.org/abs/2311.02546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siqiao Mu, Diego Klabjan</li>
<li>for: 研究policy gradient算法对非几何函数的收敛性。</li>
<li>methods: 利用非难点准则估计器和非难点梯度下降更新。</li>
<li>results: 提供了biased policy gradient算法收敛到第二阶点的初步结果，并计划进一步提供actor-critic算法在 finite-time中的第二阶点收敛分析。<details>
<summary>Abstract</summary>
Although the convergence of policy gradient algorithms to first-order stationary points is well-established, the objective functions of reinforcement learning problems are typically highly nonconvex. Therefore, recent work has focused on two extensions: ``global" convergence guarantees under regularity assumptions on the function structure, and second-order guarantees for escaping saddle points and convergence to true local minima. Our work expands on the latter approach, avoiding the restrictive assumptions of the former that may not apply to general objective functions. Existing results on vanilla policy gradient only consider an unbiased gradient estimator, but practical implementations under the infinite-horizon discounted setting, including both Monte-Carlo methods and actor-critic methods, involve gradient descent updates with a biased gradient estimator. We present preliminary results on the convergence of biased policy gradient algorithms to second-order stationary points, leveraging proof techniques from nonconvex optimization. In our next steps we aim to provide the first finite-time second-order convergence analysis for actor-critic algorithms.
</details>
<details>
<summary>摘要</summary>
although the policy gradient algorithms convergence to first-order stationary points is well-established, the objective functions of reinforcement learning problems are typically highly nonconvex. Therefore, recent work has focused on two extensions: "global" convergence guarantees under regularity assumptions on the function structure, and second-order guarantees for escaping saddle points and convergence to true local minima. our work expands on the latter approach, avoiding the restrictive assumptions of the former that may not apply to general objective functions. existing results on vanilla policy gradient only consider an unbiased gradient estimator, but practical implementations under the infinite-horizon discounted setting, including both Monte-Carlo methods and actor-critic methods, involve gradient descent updates with a biased gradient estimator. we present preliminary results on the convergence of biased policy gradient algorithms to second-order stationary points, leveraging proof techniques from nonconvex optimization. in our next steps, we aim to provide the first finite-time second-order convergence analysis for actor-critic algorithms.Here's the word-for-word translation of the given text into Simplified Chinese:虽然政策梯度算法对初级站点的整合已经很好地证明，但问题函数对于循环学习问题通常是非凸的。因此，最近的工作专注在两个扩展上：“全局”的整合保证，以及避免凸函数结构的约束下的第二类保证。我们的工作是扩展其中的后一种方法，避免了前一种方法可能不适用于一般问题函数。现有的结果仅考虑了不偏的梯度估计器，但在实际实现中，包括Monte-Carlo方法和actor-critic方法，均涉及到偏梯度估计器的梯度下降。我们发表了偏梯度政策梯度算法的初步结果，利用非凸估计的证明技巧。在下一步中，我们将提供首次具有时间限制的第二类整合分析，用于actor-critic算法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.LG_2023_11_05/" data-id="cloojsmiu00s9re882ejje6qk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/05/cs.CL_2023_11_05/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CL - 2023-11-05
        
      </div>
    </a>
  
  
    <a href="/2023/11/05/eess.IV_2023_11_05/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.IV - 2023-11-05</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">67</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
