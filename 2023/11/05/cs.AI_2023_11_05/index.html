
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-11-05 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02794 repo_url: https:&#x2F;&#x2F;github.com&#x2F;insitro&#x2F;sams-vae paper_authors">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-11-05">
<meta property="og:url" content="https://nullscc.github.io/2023/11/05/cs.AI_2023_11_05/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02794 repo_url: https:&#x2F;&#x2F;github.com&#x2F;insitro&#x2F;sams-vae paper_authors">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-05T12:00:00.000Z">
<meta property="article:modified_time" content="2023-11-07T04:32:35.009Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.AI_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T12:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-11-05
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Modelling-Cellular-Perturbations-with-the-Sparse-Additive-Mechanism-Shift-Variational-Autoencoder"><a href="#Modelling-Cellular-Perturbations-with-the-Sparse-Additive-Mechanism-Shift-Variational-Autoencoder" class="headerlink" title="Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder"></a>Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02794">http://arxiv.org/abs/2311.02794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/insitro/sams-vae">https://github.com/insitro/sams-vae</a></li>
<li>paper_authors: Michael Bereket, Theofanis Karaletsos</li>
<li>for: 用于机器学习驱动的生物科学发现</li>
<li>methods: 使用Sparse Additive Mechanism Shift Variational Autoencoder（SAMS-VAE）模型，其 combining compositionality, disentanglement, and interpretability for perturbation models</li>
<li>results: SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, and yields interpretable latent structures which correlate strongly to known biological mechanisms.<details>
<summary>Abstract</summary>
Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In order to measure perturbation-specific model-properties, we also introduce a framework for evaluation of perturbation models based on average treatment effects with links to posterior predictive checks. SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, including a combinatorial reasoning task under resource paucity, and yields interpretable latent structures which correlate strongly to known biological mechanisms. Our results suggest SAMS-VAE is an interesting addition to the modeling toolkit for machine learning-driven scientific discovery.
</details>
<details>
<summary>摘要</summary>
生物学中的观测生成模型在最近几年内得到了广泛的关注，例如药物发现中需要模型多种干扰以 caracterize 未知生物机制。我们提议使用含有可 композиitional、解耦和可解释的 SAMS-VAE 模型，以模型受到干扰的样本的离散状态。SAMS-VAE 将受到干扰的样本的离散状态表示为地方离散变量和干扰效应的稀疏全局变量的和。这些全局变量在各个干扰下进行简化，以确定分解的、干扰特有的离散子空间。我们通过对多个任务进行评估，包括基于单元细胞排序数据集的 combinatorial 逻辑任务和资源缺乏时的性能测试，发现 SAMS-VAE 在泛化性和解释性方面比较出色，并且可以获得可解释的离散结构，与生物机制强相关。这些结果表明 SAMS-VAE 是机器学习驱动的科学发现工具箱中的一个有趣添加。
</details></li>
</ul>
<hr>
<h2 id="CausalCite-A-Causal-Formulation-of-Paper-Citations"><a href="#CausalCite-A-Causal-Formulation-of-Paper-Citations" class="headerlink" title="CausalCite: A Causal Formulation of Paper Citations"></a>CausalCite: A Causal Formulation of Paper Citations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02790">http://arxiv.org/abs/2311.02790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishan Kumar, Zhijing Jin, Ehsan Mokhtarian, Siyuan Guo, Yuen Chen, Negar Kiyavash, Mrinmaya Sachan, Bernhard Schoelkopf</li>
<li>for: 本研究旨在提供一种用于评估科学论文影响力的新方法，以填补 tradicional citation count 的缺陷。</li>
<li>methods: 本研究使用了文本嵌入模型（LLMs）来编码每篇论文，然后使用cosine similarity计算出类似样本，最后通过对类似样本的权重平均来Synthesize一个对应的Counterfactual sample。</li>
<li>results: 研究发现，这种新的metric（CausalCite）具有高度与论文影响力相关的相似性，并且在不同的AI子领域中具有稳定性。此外，研究还提供了一些建议，可以帮助未来的研究者更好地使用这种metric来理解论文质量。<details>
<summary>Abstract</summary>
Evaluating the significance of a paper is pivotal yet challenging for the scientific community. While the citation count is the most commonly used proxy for this purpose, they are widely criticized for failing to accurately reflect a paper's true impact. In this work, we propose a causal inference method, TextMatch, which adapts the traditional matching framework to high-dimensional text embeddings. Specifically, we encode each paper using the text embeddings by large language models (LLMs), extract similar samples by cosine similarity, and synthesize a counterfactual sample by the weighted average of similar papers according to their similarity values. We apply the resulting metric, called CausalCite, as a causal formulation of paper citations. We show its effectiveness on various criteria, such as high correlation with paper impact as reported by scientific experts on a previous dataset of 1K papers, (test-of-time) awards for past papers, and its stability across various sub-fields of AI. We also provide a set of findings that can serve as suggested ways for future researchers to use our metric for a better understanding of a paper's quality. Our code and data are at https://github.com/causalNLP/causal-cite.
</details>
<details>
<summary>摘要</summary>
评估科学论文的重要性是科学社区中的核心问题，但是它具有许多挑战。虽然引用数是最常用的代理，但它们被广泛批判为不能准确反映论文的真实影响。在这种工作中，我们提出了一种 causal inference 方法，即 TextMatch，它将传统的匹配框架应用于高维文本嵌入。specifically，我们使用大语言模型（LLM）生成的文本嵌入来编码每篇论文，然后使用cosine similarity提取类似样本，并将类似样本的权重平均值用作Counterfactual sample。我们将这种度量称为 CausalCite，它可以作为论文引用的 causal 表示。我们在不同的标准数据上进行了评估，包括1K篇论文的影响力，以及过去的论文奖励。我们还提供了一些发现，可以帮助未来的研究人员更好地理解论文的质量。我们的代码和数据可以在 https://github.com/causalNLP/causal-cite 上找到。
</details></li>
</ul>
<hr>
<h2 id="Make-a-Donut-Language-Guided-Hierarchical-EMD-Space-Planning-for-Zero-shot-Deformable-Object-Manipulation"><a href="#Make-a-Donut-Language-Guided-Hierarchical-EMD-Space-Planning-for-Zero-shot-Deformable-Object-Manipulation" class="headerlink" title="Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation"></a>Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02787">http://arxiv.org/abs/2311.02787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang You, Bokui Shen, Congyue Deng, Haoran Geng, He Wang, Leonidas Guibas<br>for:这个论文的目的是解决 робо控制中的弹性物体操作问题，提供一种不需要示范的层次规划方法，可以处理复杂的长期任务。methods:这种方法使用大型自然语言模型（LLM）来描述任务的高级、阶段性计划，并提供了工具和子目标的 Python 代码。在每个阶段中，使用杆形描述符（DiffPhysics-P2P）损失函数和地球运动距离（EMD）空间进行预测控制。results:实验结果表明，这种技术在糖体操作中超越了多个标准准则，包括短期和长期任务。更重要的是，这种模型能够具备对新和未经遇的复杂任务的强大泛化能力，无需任何示范。此外，该方法在真实的 робо控制平台上进行了实验验证。<details>
<summary>Abstract</summary>
Deformable object manipulation stands as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the tool and subgoal for a particular stage at our disposal, we present a granular closed-loop model predictive control strategy. This leverages Differentiable Physics with Point-to-Point correspondence (DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied iteratively. Experimental findings affirm that our technique surpasses multiple benchmarks in dough manipulation, spanning both short and long horizons. Remarkably, our model demonstrates robust generalization capabilities to novel and previously unencountered complex tasks without any preliminary demonstrations. We further substantiate our approach with experimental trials on real-world robotic platforms.
</details>
<details>
<summary>摘要</summary>
不需示范的物体操作方法在机器人学中是一个非常吸引人又具有挑战性的问题。之前的技术主要依靠通过示范学习秘密动力学，通常表示为粒子或图像，但是存在一定的限制：获得适合的示范，特别是 для长期任务，可能是难以捕捉的。此外，基于示范的学习可能会限制模型的泛化能力，不能在示范之外的任务上 generalized。在这种工作中，我们介绍了一种不需示范的层次规划方法，可以解决复杂的长期任务。我们使用大型自然语言模型（LLM）来表达高级、阶段性的计划，对应于指定的任务。对于每个阶段，LLM提供了工具的名称以及Python代码来生成中间目标点云。在获得工具和中间目标的情况下，我们提出了精细的闭环预测控制策略。这种策略利用了差分物理学（DiffPhysics）损失在地球迁移距离（EMD）空间中应用iteratively。实验发现，我们的技术超越多个 referential 在馈料处理中，覆盖了短和长期任务。特别是，我们的模型在未经示范的情况下显示了强大的泛化能力，可以处理 novel 和 previously unencountered 复杂任务。我们进一步证明了我们的方法通过实验测试在真实的机器人平台上。
</details></li>
</ul>
<hr>
<h2 id="Towards-Generic-Anomaly-Detection-and-Understanding-Large-scale-Visual-linguistic-Model-GPT-4V-Takes-the-Lead"><a href="#Towards-Generic-Anomaly-Detection-and-Understanding-Large-scale-Visual-linguistic-Model-GPT-4V-Takes-the-Lead" class="headerlink" title="Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead"></a>Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02782">http://arxiv.org/abs/2311.02782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunkang Cao, Xiaohao Xu, Chen Sun, Xiaonan Huang, Weiming Shen</li>
<li>for: 这个研究旨在探讨GPT-4V（一个强大的视觉语言模型）在多元领域、多种资料类型的异常探测 задача中的应用。</li>
<li>methods: 本研究使用GPT-4V模型来解决多元领域、多种资料类型的异常探测 задача，并将不同的类别信息、人工专家知识和参考图像作为提示进行增强。</li>
<li>results: GPT-4V在多元领域、多种资料类型的异常探测任务中表现出色，能够探测和解释全局和细节 semantic pattern，实现精准地区别正常和异常实例。<details>
<summary>Abstract</summary>
Anomaly detection is a crucial task across different domains and data types. However, existing anomaly detection models are often designed for specific domains and modalities. This study explores the use of GPT-4V(ision), a powerful visual-linguistic model, to address anomaly detection tasks in a generic manner. We investigate the application of GPT-4V in multi-modality, multi-domain anomaly detection tasks, including image, video, point cloud, and time series data, across multiple application areas, such as industrial, medical, logical, video, 3D anomaly detection, and localization tasks. To enhance GPT-4V's performance, we incorporate different kinds of additional cues such as class information, human expertise, and reference images as prompts.Based on our experiments, GPT-4V proves to be highly effective in detecting and explaining global and fine-grained semantic patterns in zero/one-shot anomaly detection. This enables accurate differentiation between normal and abnormal instances. Although we conducted extensive evaluations in this study, there is still room for future evaluation to further exploit GPT-4V's generic anomaly detection capacity from different aspects. These include exploring quantitative metrics, expanding evaluation benchmarks, incorporating multi-round interactions, and incorporating human feedback loops. Nevertheless, GPT-4V exhibits promising performance in generic anomaly detection and understanding, thus opening up a new avenue for anomaly detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译成简化中文。<<SYS>> anomaly detection 是不同领域和数据类型的关键任务。然而，现有的异常检测模型frequently 是为特定领域和modalities 设计。这种研究探讨使用 GPT-4V（视力语言模型）来Address anomaly detection 任务的通用方法。我们Investigate GPT-4V 在多modal, multi-domain anomaly detection 任务中的应用，包括图像、视频、点云和时间序列数据，在多个应用领域，如工业、医疗、逻辑、视频、3D异常检测和位置任务。为了提高 GPT-4V 的表现，我们 incorporate 不同类型的附加cue，如类别信息、人类专家和参考图像作为提示。根据我们的实验， GPT-4V 表现出了高效的异常检测和解释 global 和细化 semantic 模式，从而准确地 differentiate 正常和异常实例。虽然我们进行了广泛的评估，但还有更多的可能性 для未来的评估，以更好地利用 GPT-4V 的通用异常检测能力。这些包括探索量化指标、扩展评估标准、 incorporating 多回交互和 incorporating 人类反馈环回。不过， GPT-4V 在通用异常检测和理解方面表现出了扎实的表现，因此开启了一个新的异常检测avenue。
</details></li>
</ul>
<hr>
<h2 id="ChaTA-Towards-an-Intelligent-Question-Answer-Teaching-Assistant-using-Open-Source-LLMs"><a href="#ChaTA-Towards-an-Intelligent-Question-Answer-Teaching-Assistant-using-Open-Source-LLMs" class="headerlink" title="ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs"></a>ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02775">http://arxiv.org/abs/2311.02775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yann Hicke, Anmol Agarwal, Qianou Ma, Paul Denny</li>
<li>for: 这篇论文目的是提出一种可扩展智能问答（QA）解决方案，以保护数据隐私。</li>
<li>methods: 这篇论文使用开源的大语言模型（LLM），并应用了多种技巧，包括回归增强生成（RAG）、监督微调（SFT）和人工反馈学习（RLHF）等。</li>
<li>results: 经过人工评估和自动LLM评估，这些技巧共同提高了答案质量，增加了33%。此外，RAG也被证明是一个有力的添加。这些结果铺垫了开发一个个性化的QA助手的基础，用于在线问答平台。<details>
<summary>Abstract</summary>
To address the challenges of scalable and intelligent question-answering (QA), we introduce an innovative solution that leverages open-source Large Language Models (LLMs) to ensure data privacy. We use models from the LLaMA-2 family and augmentations including retrieval augmented generation (RAG), supervised fine-tuning (SFT), and an alternative to reinforcement learning with human feedback (RLHF). We perform our experiments on a Piazza dataset from an introductory CS course with 10k QA pairs and 1.5k pairs of preferences data and conduct both human evaluations and automatic LLM evaluations on a small subset. We find preliminary evidence that modeling techniques collectively enhance the quality of answers by 33%, and RAG is an impactful addition. This work paves the way for the development of ChaTA, an intelligent QA assistant customizable for courses with an online QA platform.
</details>
<details>
<summary>摘要</summary>
为了解决扩展和智能问答（QA）的挑战，我们提出了一种创新的解决方案，利用开源的大语言模型（LLM）来保障数据隐私。我们使用LLaMA-2家族中的模型，并使用包括检索增强生成（RAG）、监督精度调整（SFT）和人工反馈学习的替代方法（RLHF）等多种技巧。我们在一个 Piazza 数据集上进行了10000个问答对和1500个偏好数据对的实验，并进行了人工评估和自动 LLM 评估。我们发现，这些技巧的集成可以提高答案质量达33%，而RAG 是一个很有影响的添加。这项工作为开发一个智能 QA 助手，用于自动化课程的问答平台创造了道路。
</details></li>
</ul>
<hr>
<h2 id="Rule-Learning-as-Machine-Translation-using-the-Atomic-Knowledge-Bank"><a href="#Rule-Learning-as-Machine-Translation-using-the-Atomic-Knowledge-Bank" class="headerlink" title="Rule Learning as Machine Translation using the Atomic Knowledge Bank"></a>Rule Learning as Machine Translation using the Atomic Knowledge Bank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02765">http://arxiv.org/abs/2311.02765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kristoffer Æsøy, Ana Ozaki</li>
<li>for: 本研究旨在探讨使用 transformers 将自然语言中的规则表达转换为逻辑规则，以便进行可靠和控制的逻辑推理。</li>
<li>methods: 本研究使用 transformers 模型将自然语言中的规则表达转换为逻辑规则，并对 DKET 数据集进行实验。</li>
<li>results: 研究发现，使用 transformers 可以快速和准确地将自然语言中的规则表达转换为逻辑规则，并且可以通过逻辑推理来验证转换结果的正确性。<details>
<summary>Abstract</summary>
Machine learning models, and in particular language models, are being applied to various tasks that require reasoning. While such models are good at capturing patterns their ability to reason in a trustable and controlled manner is frequently questioned. On the other hand, logic-based rule systems allow for controlled inspection and already established verification methods. However it is well-known that creating such systems manually is time-consuming and prone to errors. We explore the capability of transformers to translate sentences expressing rules in natural language into logical rules. We see reasoners as the most reliable tools for performing logical reasoning and focus on translating language into the format expected by such tools. We perform experiments using the DKET dataset from the literature and create a dataset for language to logic translation based on the Atomic knowledge bank.
</details>
<details>
<summary>摘要</summary>
机器学习模型，特别是语言模型，在进行推理任务上表现出色。然而，这些模型在可靠和控制的方式下进行推理能力受到质疑。相比之下，逻辑基于规则的系统具有已有的验证方法和可控的检查方式。然而，手动创建这些系统是时间consuming和容易出错的。我们 investigate transformers 是否可以将自然语言中的规则表达转换为逻辑规则。我们认为逻辑推理工具是最可靠的推理工具，因此我们将着眼于将语言转换为这些工具所期望的格式。我们使用文献中的 DKET 数据集进行实验，并创建基于 Atomic knowledge bank 的语言到逻辑转换数据集。
</details></li>
</ul>
<hr>
<h2 id="Causal-Question-Answering-with-Reinforcement-Learning"><a href="#Causal-Question-Answering-with-Reinforcement-Learning" class="headerlink" title="Causal Question Answering with Reinforcement Learning"></a>Causal Question Answering with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02760">http://arxiv.org/abs/2311.02760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Lukas Blübaum, Stefan Heindorf</li>
<li>for: 本研究旨在回答 causal 问题，使用 CauseNet 大规模 causal 关系数据集。</li>
<li>methods: 我们采用 reinforcement learning 方法， inspirited by recent successful applications of reinforcement learning to knowledge graph tasks。我们引入了 actor-critic 算法，可以在 CauseNet 上搜索答案。</li>
<li>results: 我们的算法可以成功地缩小搜索空间，回答 binary causal 问题，访问 fewer than 30 nodes per question，比 naive breadth-first search 更高效。我们的ablation study表明，我们的supervised learning strategy提供了强的基础，我们的 reinforcement learning agent 可以进一步提高。我们的 paths 可以解释 cause 如何产生 effect，并且每个 edge 的原始来源可以通过 web 找到，方便验证。<details>
<summary>Abstract</summary>
Causal questions inquire about causal relationships between different events or phenomena. Specifically, they often aim to determine whether there is a relationship between two phenomena, or to identify all causes/effects of a phenomenon. Causal questions are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with CauseNet, a large-scale dataset of causal relations and their provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on CauseNet for causal question answering. We introduce an Actor-Critic based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sparse rewards. Our evaluation shows that the agent successfully prunes the search space to answer binary causal questions by visiting less than 30 nodes per question compared to over 3,000 nodes by a naive breadth-first search. Our ablation study indicates that our supervised learning strategy provides a strong foundation upon which our reinforcement learning agent improves. The paths returned by our agent explain the mechanisms by which a cause produces an effect. Moreover, for each edge on a path, CauseNet stores its original source on the web allowing for easy verification of paths.
</details>
<details>
<summary>摘要</summary>
causal 问题探讨了不同事件或现象之间的 causal 关系。特别是，它们通常想要确定两个现象之间是否存在关系，或者Identify 所有的 cause 和 effect 的现象。 causal 问题是许多用例中重要的，包括虚拟助手和搜索引擎。然而，许多当前的approach to causal question answering 无法提供解释或证据。因此，在这篇论文中，我们使用 CauseNet，一个大规模的 causal 关系和其证据数据集，回答 causal 问题。我们通过 reinforcement learning 在 CauseNet 上应用，并 introduce 一个 Actor-Critic 基于的搜索 Agent，可以在图像上搜索 causal 问题的答案。我们使用一种supervised learning 过程来处理大型动作空间和稀缺奖励。我们的评估表明，我们的 Agent 可以成功地缩减搜索空间，回答 binary causal 问题，只需访问 fewer than 30 个节点，而不是 naive breadth-first search 的over 3,000 个节点。我们的 ablation study 表明，我们的 supervised learning 策略提供了一个强大的基础，于我们的 reinforcement learning Agent 进行改进。Agent 返回的路径解释了 cause 如何产生 effect。此外，每个边在路径上，CauseNet 都存储了其原始来源在网上，使得 paths 的验证变得容易。
</details></li>
</ul>
<hr>
<h2 id="Learning-Independently-from-Causality-in-Multi-Agent-Environments"><a href="#Learning-Independently-from-Causality-in-Multi-Agent-Environments" class="headerlink" title="Learning Independently from Causality in Multi-Agent Environments"></a>Learning Independently from Causality in Multi-Agent Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02741">http://arxiv.org/abs/2311.02741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Pina, Varuna De Silva, Corentin Artaud</li>
<li>for: 这 paper 的目的是investigating the lazy agent pathology in MARL from a causality-based perspective.</li>
<li>methods: 这 paper 使用了一种完全分布式 MARL 设置，并使用 causality 来连接 MARL 和 causality 两个领域。</li>
<li>results: 实验结果表明，在这种设置下，每个agent 的个人观察和团队奖励之间存在 causal 关系，可以用于提高 MARL 团队的表现和个体智能行为。<details>
<summary>Abstract</summary>
Multi-Agent Reinforcement Learning (MARL) comprises an area of growing interest in the field of machine learning. Despite notable advances, there are still problems that require investigation. The lazy agent pathology is a famous problem in MARL that denotes the event when some of the agents in a MARL team do not contribute to the common goal, letting the teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to create the bridge between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralised MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried show how this relation can be used to improve independent agents in MARL, resulting not only on better performances as a team but also on the rise of more intelligent behaviours on individual agents.
</details>
<details>
<summary>摘要</summary>
多智能探索学习（MARL）是机器学习领域的一个快速发展领域。 despite notable advances, there are still many problems that need to be explored. The lazy agent pathology is a famous problem in MARL that refers to the situation where some agents in a MARL team do not contribute to the common goal, letting their teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to establish a connection between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralized MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried out show how this relation can be used to improve independent agents in MARL, resulting not only in better team performances but also in the rise of more intelligent behaviors on individual agents.Here's the translation in Traditional Chinese:多智能探索学习（MARL）是机器学习领域的一个快速发展领域。 despite notable advances, there are still many problems that need to be explored. The lazy agent pathology is a famous problem in MARL that refers to the situation where some agents in a MARL team do not contribute to the common goal, letting their teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to establish a connection between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralized MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried out show how this relation can be used to improve independent agents in MARL, resulting not only in better team performances but also in the rise of more intelligent behaviors on individual agents.
</details></li>
</ul>
<hr>
<h2 id="AV-Lip-Sync-Leveraging-AV-HuBERT-to-Exploit-Multimodal-Inconsistency-for-Video-Deepfake-Detection"><a href="#AV-Lip-Sync-Leveraging-AV-HuBERT-to-Exploit-Multimodal-Inconsistency-for-Video-Deepfake-Detection" class="headerlink" title="AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection"></a>AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02733">http://arxiv.org/abs/2311.02733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahibzada Adil Shahzad, Ammarah Hashmi, Yan-Tsung Peng, Yu Tsao, Hsin-Min Wang</li>
<li>for: 防止伪造 multimedia 内容的传播，提高伪造检测的效率。</li>
<li>methods: 使用多模式自我监督学习（SSL）特征提取器，利用视觉和音频两个模式之间的不一致来检测多模式影片伪造。</li>
<li>results: 在 FakeAVCeleb 和 DeepfakeTIMIT 数据集上取得新的顶尖性能，较前一代模型好。<details>
<summary>Abstract</summary>
Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multi-modal models that can exploit both pieces of information simultaneously. Previous methods mainly adopt uni-modal video forensics and use supervised pre-training for forgery detection. This study proposes a new method based on a multi-modal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multi-modal video forgery detection. We use the transformer-based SSL pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multi-scale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.
</details>
<details>
<summary>摘要</summary>
多Modal manipulations (也称为 audio-visual deepfakes) 使得单模态 deepfake 检测器困难于检测多媒体内容中的伪造。为避免伪造信息和 fake news 的流传，实时检测是关键。过去的方法主要采用单模态视频科学和有supervised预训练进行伪造检测。本研究提出了基于多模态自适应学（SSL）特征提取器的新方法，通过视觉和听音模式之间的不一致来检测多模态视频伪造。我们使用 transformer 基于 SSL 预训练 Audio-Visual HuBERT（AV-HuBERT）模型作为视觉和听音特征提取器，并使用多尺度时间卷积神经网络来捕捉听音和视觉模式之间的时间相关性。由于 AV-HuBERT 只提取视觉特征自舌部，我们还采用另一个 transformer 基于视频模型，以便利用人脸特征并捕捉在深度伪造生成过程中的空间和时间异常。实验结果显示，我们的模型在 FakeAVCeleb 和 DeepfakeTIMIT 数据集上的性能突破所有现有模型，实现了新的状态纪录。
</details></li>
</ul>
<hr>
<h2 id="Extraction-of-Atypical-Aspects-from-Customer-Reviews-Datasets-and-Experiments-with-Language-Models"><a href="#Extraction-of-Atypical-Aspects-from-Customer-Reviews-Datasets-and-Experiments-with-Language-Models" class="headerlink" title="Extraction of Atypical Aspects from Customer Reviews: Datasets and Experiments with Language Models"></a>Extraction of Atypical Aspects from Customer Reviews: Datasets and Experiments with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02702">http://arxiv.org/abs/2311.02702</a></li>
<li>repo_url: None</li>
<li>paper_authors: Smita Nannaware, Erfan Al-Hossami, Razvan Bunescu</li>
<li>for: 这篇论文旨在检测顾客评论中的不寻常元素，以便通过提取这些元素来提高用户满意度。</li>
<li>methods: 该论文使用了人工标注的 benchmark 数据集，并对多种语言模型进行了评估，包括 Flan-T5 的 fine-tuning 和 GPT-3.5 的零aser 和几个shot 提示。</li>
<li>results: 研究发现，通过检测顾客评论中的不寻常元素，可以提高用户满意度，并且可以使用不同的语言模型来提取这些元素。<details>
<summary>Abstract</summary>
A restaurant dinner may become a memorable experience due to an unexpected aspect enjoyed by the customer, such as an origami-making station in the waiting area. If aspects that are atypical for a restaurant experience were known in advance, they could be leveraged to make recommendations that have the potential to engender serendipitous experiences, further increasing user satisfaction. Although relatively rare, whenever encountered, atypical aspects often end up being mentioned in reviews due to their memorable quality. Correspondingly, in this paper we introduce the task of detecting atypical aspects in customer reviews. To facilitate the development of extraction models, we manually annotate benchmark datasets of reviews in three domains - restaurants, hotels, and hair salons, which we use to evaluate a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and few-shot prompting of GPT-3.5.
</details>
<details>
<summary>摘要</summary>
餐厅的晚餐可能会变成一个记忆深刻的经历，因为客户感到了一些不寻常的方面，例如餐厅的等待区域内的 Origami 制作站。如果在先知道这些不寻常的方面，那么可以利用这些方面来制定建议，以提高用户满意度。虽然这些不寻常的方面相对较罕见，但当遇到时，它们通常会在评论中被提及，因为它们具有记忆的质量。在这篇论文中，我们提出了检测客户评论中的不寻常方面的任务。为了促进模型开发，我们手动标注了多个领域的客户评论数据集，包括餐厅、酒店和美容院。我们使用这些数据集来评估多种语言模型，包括修改基于 Flan-T5 的文本到文本转换器，以及 zero-shot 和 few-shot 的 GPT-3.5 的提示。
</details></li>
</ul>
<hr>
<h2 id="Architecture-Matters-Uncovering-Implicit-Mechanisms-in-Graph-Contrastive-Learning"><a href="#Architecture-Matters-Uncovering-Implicit-Mechanisms-in-Graph-Contrastive-Learning" class="headerlink" title="Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning"></a>Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02687">http://arxiv.org/abs/2311.02687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojun Guo, Yifei Wang, Zeming Wei, Yisen Wang</li>
<li>for: This paper focuses on the application of contrastive learning to the graph domain, and investigates the unique properties of graph contrastive learning (GCL) methods.</li>
<li>methods: The paper systematically studies various GCL methods and observes that they differ from traditional VCL methods in several ways, including the lack of positive samples and the lesser influence of data augmentations.</li>
<li>results: The paper provides theoretical insights into the properties of GCL and advocates for more attention to the unique architecture of graph learning when designing GCL methods. The authors also provide code for their experiments at <a target="_blank" rel="noopener" href="https://github.com/PKU-ML/ArchitectureMattersGCL">https://github.com/PKU-ML/ArchitectureMattersGCL</a>.<details>
<summary>Abstract</summary>
With the prosperity of contrastive learning for visual representation learning (VCL), it is also adapted to the graph domain and yields promising performance. However, through a systematic study of various graph contrastive learning (GCL) methods, we observe that some common phenomena among existing GCL methods that are quite different from the original VCL methods, including 1) positive samples are not a must for GCL; 2) negative samples are not necessary for graph classification, neither for node classification when adopting specific normalization modules; 3) data augmentations have much less influence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian noise) can also attain fairly good performance. By uncovering how the implicit inductive bias of GNNs works in contrastive learning, we theoretically provide insights into the above intriguing properties of GCL. Rather than directly porting existing VCL methods to GCL, we advocate for more attention toward the unique architecture of graph learning and consider its implicit influence when designing GCL methods. Code is available at https: //github.com/PKU-ML/ArchitectureMattersGCL.
</details>
<details>
<summary>摘要</summary>
随着视觉对偶学习（VCL）的繁荣，它也被应用于图像领域并显示出了出色的性能。然而，我们通过系统性的研究多种图像对偶学习（GCL）方法时，发现了一些与原始VCL方法不同的现象，包括：1）对GCL来说，正样本并不是必须的；2）对于图像分类和节点分类，不需要负样本；3）对GCL来说，数据增强的影响相对较小，简单的静态域无关增强（例如，高斯噪声）也可以获得良好的性能。我们通过探究图NN的隐式概念偏见在对偶学习中如何工作，从理论角度提供了对上述怪异性质的解释。而不是直接将现有VCL方法port到GCL，我们建议更多关注于图学习的独特架构和其隐式的影响，并在设计GCL方法时给予这些因素更多的注意。代码可以在https: //github.com/PKU-ML/ArchitectureMattersGCL中找到。
</details></li>
</ul>
<hr>
<h2 id="Compute-at-Scale-–-A-Broad-Investigation-into-the-Data-Center-Industry"><a href="#Compute-at-Scale-–-A-Broad-Investigation-into-the-Data-Center-Industry" class="headerlink" title="Compute at Scale – A Broad Investigation into the Data Center Industry"></a>Compute at Scale – A Broad Investigation into the Data Center Industry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02651">http://arxiv.org/abs/2311.02651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/contentone3/guruhr">https://github.com/contentone3/guruhr</a></li>
<li>paper_authors: Konstantin Pilz, Lennart Heim</li>
<li>for: 这篇论文主要描述了数据中心业务和人工智能发展中的重要性。</li>
<li>methods: 该论文使用了各种数据center的特点和行业趋势来描述数据中心的重要性。</li>
<li>results: 论文预计到2025年，全球数据中心市场将达到约2500亿美元，而大规模的数据中心将占据约500个。<details>
<summary>Abstract</summary>
This report characterizes the data center industry and its importance for AI development. Data centers are industrial facilities that efficiently provide compute at scale and thus constitute the engine rooms of today's digital economy. As large-scale AI training and inference become increasingly computationally expensive, they are dominantly executed from this designated infrastructure. Key features of data centers include large-scale compute clusters that require extensive cooling and consume large amounts of power, the need for fast connectivity both within the data center and to the internet, and an emphasis on security and reliability. The global industry is valued at approximately $250B and is expected to double over the next seven years. There are likely about 500 large (above 10 MW) data centers globally, with the US, Europe, and China constituting the most important markets. The report further covers important actors, business models, main inputs, and typical locations of data centers.
</details>
<details>
<summary>摘要</summary>
这份报告描述了数据中心业和其对人工智能发展的重要性。数据中心是一种大规模计算提供的工业设施，它们是当今数字经济的引擎舱。随着大规模人工智能训练和推理变得越来越计算昂贵，它们主要在这些指定的基础设施上进行执行。数据中心的主要特点包括大规模计算集群，需要广泛的冷却和大量的电力，快速内部和互联网连接，以及安全性和可靠性的强调。全球业务额约2500亿美元，预计在下一个七年内将double。全球可能有约500个大于10MW的数据中心，美国、欧洲和中国是最重要的市场。报告还覆盖了数据中心的主要投资者、商业模式、主要输入和常见位置。
</details></li>
</ul>
<hr>
<h2 id="New-Approach-for-an-Affective-Computing-Driven-Quality-of-Experience-QoE-Prediction"><a href="#New-Approach-for-an-Affective-Computing-Driven-Quality-of-Experience-QoE-Prediction" class="headerlink" title="New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction"></a>New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02647">http://arxiv.org/abs/2311.02647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Bègue, Mohamed Aymen Labiod, Abdelhamid Melloulk</li>
<li>for: 这篇论文的主要目的是提出一种基于情感计算的Quality of Experience（QoE）预测模型，以便在多媒体QoE评估上进行自动识别。</li>
<li>methods: 该论文使用了多通道电enzephalogram（EEG）信息进行自动情感识别，并使用了三秒观察窗口计算差异 entropy和功率spectral density。这两个特征被用来训练多个深度学习模型，以便 investigate 是否可以通过五个因素来预测QoE。</li>
<li>results: 该论文使用了一个公共可用的 dataset，并使用了多个深度学习模型进行比较。最好的模型是 LSTM 模型，其中 F1 分数从 68% 到 78%。分析模型和其特征表明，Delta 频率带是最不必要的，两个电极有更高的重要性，两个电极有很低的影响。<details>
<summary>Abstract</summary>
In human interactions, emotion recognition is crucial. For this reason, the topic of computer-vision approaches for automatic emotion recognition is currently being extensively researched. Processing multi-channel electroencephalogram (EEG) information is one of the most researched methods for automatic emotion recognition. This paper presents a new model for an affective computing-driven Quality of Experience (QoE) prediction. In order to validate the proposed model, a publicly available dataset is used. The dataset contains EEG, ECG, and respiratory data and is focused on a multimedia QoE assessment context. The EEG data are retained on which the differential entropy and the power spectral density are calculated with an observation window of three seconds. These two features were extracted to train several deep-learning models to investigate the possibility of predicting QoE with five different factors. The performance of these models is compared, and the best model is optimized to improve the results. The best results were obtained with an LSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the model and its features shows that the Delta frequency band is the least necessary, that two electrodes have a higher importance, and that two other electrodes have a very low impact on the model's performances.
</details>
<details>
<summary>摘要</summary>
人类互动中，情感认知是非常重要。因此，计算机视觉方法自动情感认知的研究在当前得到了广泛的关注。在本文中，我们提出了一种基于情感计算的Quality of Experience（QoE）预测模型。为验证该模型，我们使用了一个公共可用的数据集。该数据集包括EEG、ECG和呼吸数据，并且是在多媒体QoE评估上下文中收集的。EEG数据上计算了差异熵和功率spectral density，使用观察窗口为三秒。这两个特征用于训练多个深度学习模型，以 investigate可能性Predict QoE with five different factors。对这些模型的性能进行比较，并优化最佳模型以提高结果。最佳结果是使用LSTM模型，其F1分数在68%到78%之间。分析模型和其特征显示，Delta频率带是最不必要的，两个电极具有更高的重要性，而两个电极具有很低的影响力。
</details></li>
</ul>
<hr>
<h2 id="PotholeGuard-A-Pothole-Detection-Approach-by-Point-Cloud-Semantic-Segmentation"><a href="#PotholeGuard-A-Pothole-Detection-Approach-by-Point-Cloud-Semantic-Segmentation" class="headerlink" title="PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation"></a>PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02641">http://arxiv.org/abs/2311.02641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Nawale, Dhruv Khut, Daksh Dave, Gauransh Sawhney, Pushkar Aggrawal, Dr. Kailas Devadakar</li>
<li>For: 这个研究旨在提供一个高精度的3D穿孔标注方法，以提高道路维护和安全性。* Methods: 本研究使用了一个创新的点云组合架构，能够高效地捕捉点云中的隐藏特征，并使用反馈机制来强化本地特征表现。此外，本研究还引入了一个地方关系学习模组，以更好地理解点云中的结构关系。* Results: 实验结果显示， compared to existing state-of-the-art methods, PotholeGuard 能够提供更高的精度和准确性 для 3D穿孔标注。<details>
<summary>Abstract</summary>
Pothole detection is crucial for road safety and maintenance, traditionally relying on 2D image segmentation. However, existing 3D Semantic Pothole Segmentation research often overlooks point cloud sparsity, leading to suboptimal local feature capture and segmentation accuracy. Our research presents an innovative point cloud-based pothole segmentation architecture. Our model efficiently identifies hidden features and uses a feedback mechanism to enhance local characteristics, improving feature presentation. We introduce a local relationship learning module to understand local shape relationships, enhancing structural insights. Additionally, we propose a lightweight adaptive structure for refining local point features using the K nearest neighbor algorithm, addressing point cloud density differences and domain selection. Shared MLP Pooling is integrated to learn deep aggregation features, facilitating semantic data exploration and segmentation guidance. Extensive experiments on three public datasets confirm PotholeGuard's superior performance over state-of-the-art methods. Our approach offers a promising solution for robust and accurate 3D pothole segmentation, with applications in road maintenance and safety.
</details>
<details>
<summary>摘要</summary>
沟纹检测对道路安全和维护非常重要，传统上靠二维图像分割。然而，现有的3D semantic pothole segmentation研究经常忽略点云稀疏性，导致本地特征捕捉和分割精度下降。我们的研究提出了一种创新的点云基于的沟纹分割架构。我们的模型高效地找到隐藏的特征，并使用反馈机制提高本地特征表现。我们引入了本地关系学习模块，理解本地形态关系，提高结构性视角。此外，我们提议了一种轻量级适应结构，通过K nearest neighbor算法来修正本地点 cloud特征，解决点云密度差异和领域选择问题。我们共享的多层感知搜索（MLP Pooling）被集成到学习深度聚合特征，促进 semantic数据探索和分割指导。广泛的实验证明了PotholeGuard的超过状态艺术方法的性能。我们的方法提供了一种强大和准确的3D沟纹分割方案，应用于道路维护和安全。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-Promise-and-Pitfalls-of-ChatGPT-for-Automated-Code-Generation"><a href="#Assessing-the-Promise-and-Pitfalls-of-ChatGPT-for-Automated-Code-Generation" class="headerlink" title="Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation"></a>Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02640">http://arxiv.org/abs/2311.02640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mfawadakbar/ChatGPT-promises-and-pitfalls">https://github.com/mfawadakbar/ChatGPT-promises-and-pitfalls</a></li>
<li>paper_authors: Muhammad Fawad Akbar Khan, Max Ramsdell, Erik Falor, Hamid Karimi</li>
<li>For: This paper evaluates the code generation capabilities of ChatGPT, a large language model, and compares them to human programmers.* Methods: The paper uses a novel dataset of code-generation prompts and manual assessment methodology to evaluate correctness, comprehensibility, and security of code generated by ChatGPT and human programmers.* Results: The paper finds that ChatGPT excels in crafting concise and efficient code, particularly in data analysis tasks, but struggles with visual-graphical challenges. It also shows that machine learning models can distinguish ChatGPT code from human code with up to 88% accuracy. The study provides valuable insights into the strengths and limitations of ChatGPT’s code generation capabilities and offers a robust foundation for future research.Here is the same information in Simplified Chinese text:* For: 这篇论文评估了 ChatGPT 大型自然语言模型的代码生成能力，并与人工程师进行比较。* Methods: 论文使用了一个新的代码生成提问集和手动评估方法来评估代码的正确性、可读性和安全性，并对 ChatGPT 和人工程师生成的代码进行比较。* Results: 论文发现 ChatGPT 在数据分析任务上表现出色，能够生成高效和简洁的代码，但在视觉图形挑战中存在限制。它还发现机器学习模型可以准确地 distinguishing ChatGPT 代码和人工程师代码之间的 coding style 差异。该研究为 AI 基于编程助手的发展提供了有价值的贡献，并提供了一个可靠的基础 для未来的研究。所有数据和代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls%E3%80%82">https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls。</a><details>
<summary>Abstract</summary>
This paper presents a comprehensive evaluation of the code generation capabilities of ChatGPT, a prominent large language model, compared to human programmers. A novel dataset of 131 code-generation prompts across 5 categories was curated to enable robust analysis. Code solutions were generated by both ChatGPT and humans for all prompts, resulting in 262 code samples. A meticulous manual assessment methodology prioritized evaluating correctness, comprehensibility, and security using 14 established code quality metrics. The key findings reveal ChatGPT's strengths in crafting concise, efficient code with advanced constructs, showcasing strengths in data analysis tasks (93.1% accuracy) but limitations in visual-graphical challenges. Comparative analysis with human code highlights ChatGPT's inclination towards modular design and superior error handling. Additionally, machine learning models effectively distinguished ChatGPT from human code with up to 88% accuracy, suggesting detectable coding style disparities. By providing profound insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis, this study makes valuable contributions toward advancing AI-based programming assistants. The curated dataset and methodology offer a robust foundation for future research in this nascent domain. All data and codes are available on https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls.
</details>
<details>
<summary>摘要</summary>
The key findings show that ChatGPT excels in crafting concise and efficient code with advanced constructs, particularly in data analysis tasks (93.1% accuracy). However, it struggles with visual-graphical challenges. Comparing ChatGPT's code to human code reveals that ChatGPT tends towards modular design and superior error handling. Additionally, machine learning models can accurately distinguish ChatGPT's code from human code (up to 88% accuracy), indicating detectable differences in coding style.This study provides valuable insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis. The curated dataset and methodology offer a solid foundation for future research in this emerging field. All data and codes are available on GitHub: <https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls>.
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Perceptual-Pre-trained-Model-for-Complex-Trajectory-Recovery"><a href="#A-Critical-Perceptual-Pre-trained-Model-for-Complex-Trajectory-Recovery" class="headerlink" title="A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery"></a>A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02631">http://arxiv.org/abs/2311.02631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dedong Li, Ziyue Li, Zhishuai Li, Lei Bai, Qingyuan Gong, Lijun Sun, Wolfgang Ketter, Rui Zhao<br>for: 这个论文的目的是提供一个更加Robust的路径回传方法，以便应对复杂的路径。methods: 本文使用了Sequential Language Models来进行路径回传，并且将道路段表示vector learning到下游任务。results: 试验结果显示，我们的方法可以更好地学习路径回传，具有5.22%更高的F1分数和8.16%更高的F1分数 для复杂的路径。<details>
<summary>Abstract</summary>
The trajectory on the road traffic is commonly collected at a low sampling rate, and trajectory recovery aims to recover a complete and continuous trajectory from the sparse and discrete inputs. Recently, sequential language models have been innovatively adopted for trajectory recovery in a pre-trained manner: it learns road segment representation vectors, which will be used in the downstream tasks. However, existing methods are incapable of handling complex trajectories: when the trajectory crosses remote road segments or makes several turns, which we call critical nodes, the quality of learned representations deteriorates, and the recovered trajectories skip the critical nodes. This work is dedicated to offering a more robust trajectory recovery for complex trajectories. Firstly, we define the trajectory complexity based on the detour score and entropy score and construct the complexity-aware semantic graphs correspondingly. Then, we propose a Multi-view Graph and Complexity Aware Transformer (MGCAT) model to encode these semantics in trajectory pre-training from two aspects: 1) adaptively aggregate the multi-view graph features considering trajectory pattern, and 2) higher attention to critical nodes in a complex trajectory. Such that, our MGCAT is perceptual when handling the critical scenario of complex trajectories. Extensive experiments are conducted on large-scale datasets. The results prove that our method learns better representations for trajectory recovery, with 5.22% higher F1-score overall and 8.16% higher F1-score for complex trajectories particularly. The code is available at https://github.com/bonaldli/ComplexTraj.
</details>
<details>
<summary>摘要</summary>
《路径轨迹数据通常采集在低频率下，路径恢复目标是恢复完整、连续的路径从稀疏和分据输入中。近年来，顺序语言模型在预训练方式下被创新地应用于路径恢复中，它学习了道路段表示向量，这些向量将在下游任务中使用。然而，现有方法无法处理复杂的路径：当路径过 remote 道路段或者多次转弯时，学习的表示质量会降低，恢复的路径会跳过关键节点。这个工作是为了提供更加Robust的路径恢复方法，我们定义了路径复杂度基于折返分数和 entropy 分数，然后构建了相应的复杂度意识图。然后，我们提出了一种多视图图和复杂度意识 transformer（MGCAT）模型，用于在路径预训练中编码这些 semantics。我们的 MGCAT 能够在复杂路径中更加准确地捕捉关键节点，从而提高恢复路径的质量。我们在大规模数据集上进行了广泛的实验，结果表明我们的方法可以更好地学习路径恢复的表示，全局 F1 分数提高 5.22%，特别是在复杂路径上提高 8.16%。代码可以在 <https://github.com/bonaldli/ComplexTraj> 上获取。
</details></li>
</ul>
<hr>
<h2 id="The-New-Frontier-of-Cybersecurity-Emerging-Threats-and-Innovations"><a href="#The-New-Frontier-of-Cybersecurity-Emerging-Threats-and-Innovations" class="headerlink" title="The New Frontier of Cybersecurity: Emerging Threats and Innovations"></a>The New Frontier of Cybersecurity: Emerging Threats and Innovations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02630">http://arxiv.org/abs/2311.02630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Gauransh Sawhney, Pushkar Aggarwal, Nitish Silswal, Dhruv Khut<br>for:这个研究旨在检查当今数字化连接的世界中cybersecurity威胁的多方面性和影响。methods:这个研究采用了质量研究方法，涵盖了多种cybersecurity威胁类型，包括malware攻击、社会工程攻击、网络漏洞和数据泄露攻击。results:研究发现了许多新型的cybersecurity威胁，包括高级 persistent攻击、劫持攻击、IoT漏洞和社会工程攻击。这些威胁对组织和个人都 pose 重大风险，需要采取多层防范措施。<details>
<summary>Abstract</summary>
In today's digitally interconnected world, cybersecurity threats have reached unprecedented levels, presenting a pressing concern for individuals, organizations, and governments. This study employs a qualitative research approach to comprehensively examine the diverse threats of cybersecurity and their impacts across various sectors. Four primary categories of threats are identified and analyzed, encompassing malware attacks, social engineering attacks, network vulnerabilities, and data breaches. The research delves into the consequences of these threats on individuals, organizations, and society at large. The findings reveal a range of key emerging threats in cybersecurity, including advanced persistent threats, ransomware attacks, Internet of Things (IoT) vulnerabilities, and social engineering exploits. Consequently, it is evident that emerging cybersecurity threats pose substantial risks to both organizations and individuals. The sophistication and diversity of these emerging threats necessitate a multi-layered approach to cybersecurity. This approach should include robust security measures, comprehensive employee training, and regular security audits. The implications of these emerging threats are extensive, with potential consequences such as financial loss, reputational damage, and compromised personal information. This study emphasizes the importance of implementing effective measures to mitigate these threats. It highlights the significance of using strong passwords, encryption methods, and regularly updating software to bolster cyber defenses.
</details>
<details>
<summary>摘要</summary>
今天的数字化连接世界中，计算机安全威胁已经到了历史上没有seen的水平，对个人、组织和政府都提出了严重的挑战。本研究采用资深研究方法，全面探讨了不同领域的计算机安全威胁和其影响。研究涵盖了恶意软件攻击、社会工程攻击、网络漏洞和数据泄露等四大类威胁。研究发现，这些威胁对于个人、组织和社会都具有广泛的影响。研究还揭示了一系列新兴计算机安全威胁，包括高级 persistent攻击、勒索软件攻击、物联网（IoT）漏洞和社会工程攻击等。因此，明显地emerging计算机安全威胁对组织和个人都具有极大的风险。这些新兴威胁的复杂性和多样性需要一种多层次的计算机安全方法。这种方法应包括坚固的安全措施、全面的员工培训和 Regular安全审核。这些新兴威胁的后果很广泛，可能包括财务损失、声誉损害和个人信息泄露等。本研究强调实施有效的防御措施，包括使用强密的密码、加密方法和 Regular更新软件等，以加强计算机防御。
</details></li>
</ul>
<hr>
<h2 id="AIOps-Driven-Enhancement-of-Log-Anomaly-Detection-in-Unsupervised-Scenarios"><a href="#AIOps-Driven-Enhancement-of-Log-Anomaly-Detection-in-Unsupervised-Scenarios" class="headerlink" title="AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios"></a>AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02621">http://arxiv.org/abs/2311.02621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Gauransh Sawhney, Dhruv Khut, Sahil Nawale, Pushkar Aggrawal, Prasenjit Bhavathankar</li>
<li>for: 这个研究旨在提高AIOps平台中的记录异常检测，以应对现代和复杂的系统中的记录分析需求。</li>
<li>methods: 本研究提出了一个新的混合方法，具有一个创新的数学方法，整合了原型对应分析（PCA）和人工神经网络（ANNs），并使用自订损失函数以进一步提高记录异常检测的效能。</li>
<li>results: 实验结果表明，提出的方法可以实现重要的降低 Pseudo-Positive 的效果，并且可以处理记录在原始、未处理的形式下进行分析，这具有很大的优点。<details>
<summary>Abstract</summary>
Artificial intelligence operations (AIOps) play a pivotal role in identifying, mitigating, and analyzing anomalous system behaviors and alerts. However, the research landscape in this field remains limited, leaving significant gaps unexplored. This study introduces a novel hybrid framework through an innovative algorithm that incorporates an unsupervised strategy. This strategy integrates Principal Component Analysis (PCA) and Artificial Neural Networks (ANNs) and uses a custom loss function to substantially enhance the effectiveness of log anomaly detection. The proposed approach encompasses the utilization of both simulated and real-world datasets, including logs from SockShop and Hadoop Distributed File System (HDFS). The experimental results are highly promising, demonstrating significant reductions in pseudo-positives. Moreover, this strategy offers notable advantages, such as the ability to process logs in their raw, unprocessed form, and the potential for further enhancements. The successful implementation of this approach showcases a remarkable reduction in anomalous logs, thus unequivocally establishing the efficacy of the proposed methodology. Ultimately, this study makes a substantial contribution to the advancement of log anomaly detection within AIOps platforms, addressing the critical need for effective and efficient log analysis in modern and complex systems.
</details>
<details>
<summary>摘要</summary>
人工智能操作（AIOps）在识别、消除和分析异常系统行为和警报方面扮演着重要的角色。然而，这一研究领域的研究还很有限，留下了许多未探索的空白。本研究提出了一种新的混合方法，通过一种创新的算法，将原始的PCA和人工神经网络（ANNs）精心融合，使用自定义损失函数，以显著提高日志异常检测的效果。该方法利用了实际和模拟的数据集，包括SockShop和Hadoop分布式文件系统（HDFS）的日志。实验结果很吸引人，显示了显著减少 pseudo-positives。此外，该策略还具有许多优点，如能直接处理原始的日志数据，无需进行额外处理。成功实施该方法，表明了该方法的可行性和效果，为AIOps平台中的日志异常检测做出了重要贡献。最终，本研究为现代和复杂的系统中的日志分析做出了重要贡献，为日志异常检测领域的进一步发展提供了新的思路和方法。
</details></li>
</ul>
<hr>
<h2 id="Get-the-Ball-Rolling-Alerting-Autonomous-Robots-When-to-Help-to-Close-the-Healthcare-Loop"><a href="#Get-the-Ball-Rolling-Alerting-Autonomous-Robots-When-to-Help-to-Close-the-Healthcare-Loop" class="headerlink" title="Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop"></a>Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02602">http://arxiv.org/abs/2311.02602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Shen, Yanyao Liu, Ziming Wang, Ziyuan Jiao, Yufeng Chen, Wenjuan Han</li>
<li>for: 为了促进医疗机器人无需人工指令或干预的研究进步，我们介绍了自主帮助挑战，同时收集了大规模的人才来源数据集。目标是创造能够自动确定帮助需要、生成有用子任务、通过物理机器人执行计划、并根据环境反馈生成新任务的医疗机器人。</li>
<li>methods: 本研究使用了自主帮助挑战和大规模人才来源数据集，并提出了Helpy方法来封闭医疗循环的学习无需设置。</li>
<li>results: 研究通过自主帮助挑战和人才来源数据集，对医疗机器人的自动帮助能力进行了评估，并提出了Helpy方法来封闭医疗循环的学习无需设置。<details>
<summary>Abstract</summary>
To facilitate the advancement of research in healthcare robots without human intervention or commands, we introduce the Autonomous Helping Challenge, along with a crowd-sourcing large-scale dataset. The goal is to create healthcare robots that possess the ability to determine when assistance is necessary, generate useful sub-tasks to aid in planning, carry out these plans through a physical robot, and receive feedback from the environment in order to generate new tasks and continue the process. Besides the general challenge in open-ended scenarios, Autonomous Helping focuses on three specific challenges: autonomous task generation, the gap between the current scene and static commonsense, and the gap between language instruction and the real world. Additionally, we propose Helpy, a potential approach to close the healthcare loop in the learning-free setting.
</details>
<details>
<summary>摘要</summary>
为了促进医疗机器人研究的自主发展，我们提出了无需人工指令或干预的自主帮助挑战，同时发布了大规模的人员参与型数据集。目标是创造能够自动确定帮助需要、生成有用的子任务以帮助规划、通过物理机器人执行计划，并从环境接受反馈以生成新任务的医疗机器人。除了通用场景中的总体挑战外，Autonomous Helping还特点在三个方面：自动任务生成、现场和Static Common Sense之间的差距，以及语言指令和实际世界之间的差距。此外，我们提出了一种可能的方法，即Helpy，以关闭医疗循环的学习自由设定。
</details></li>
</ul>
<hr>
<h2 id="Automated-Camera-Calibration-via-Homography-Estimation-with-GNNs"><a href="#Automated-Camera-Calibration-via-Homography-Estimation-with-GNNs" class="headerlink" title="Automated Camera Calibration via Homography Estimation with GNNs"></a>Automated Camera Calibration via Homography Estimation with GNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02598">http://arxiv.org/abs/2311.02598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giacomo D’Amicantonio, Egor Bondarev, Peter H. N. De With</li>
<li>for: 增强路面安全和优化交通条件</li>
<li>methods: 利用图形神经网络学习拓扑结构，自动核实摄像头姿态</li>
<li>results: 提高了实际摄像头姿态估计和抽象摄像头姿态估计的精度，创造了新的状态纪录<details>
<summary>Abstract</summary>
Over the past few decades, a significant rise of camera-based applications for traffic monitoring has occurred. Governments and local administrations are increasingly relying on the data collected from these cameras to enhance road safety and optimize traffic conditions. However, for effective data utilization, it is imperative to ensure accurate and automated calibration of the involved cameras. This paper proposes a novel approach to address this challenge by leveraging the topological structure of intersections. We propose a framework involving the generation of a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighbourhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters. As a result, the proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.
</details>
<details>
<summary>摘要</summary>
The proposed framework involves generating a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighborhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters.The proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.
</details></li>
</ul>
<hr>
<h2 id="FloodBrain-Flood-Disaster-Reporting-by-Web-based-Retrieval-Augmented-Generation-with-an-LLM"><a href="#FloodBrain-Flood-Disaster-Reporting-by-Web-based-Retrieval-Augmented-Generation-with-an-LLM" class="headerlink" title="FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM"></a>FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02597">http://arxiv.org/abs/2311.02597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grace Colverd, Paul Darm, Leonard Silverberg, Noah Kasmanoff</li>
<li>for: 急需快速灾害影响报告，以便规划人道援助。</li>
<li>methods: 利用大型自然语言模型（LLMs）写出整齐的文本，并完成影响报告中的问题回答和文本摘要等任务。</li>
<li>results: 将网络搜寻结果融合，生成详细和准确的洪水灾害影响报告。与人工撰写的报告相比，使用GPT-4作为后门模型时，与人评分得相似的分数。此外，透过对单一管道元件的删除和修改进行了实验，以评估它们的重要性。<details>
<summary>Abstract</summary>
Fast disaster impact reporting is crucial in planning humanitarian assistance. Large Language Models (LLMs) are well known for their ability to write coherent text and fulfill a variety of tasks relevant to impact reporting, such as question answering or text summarization. However, LLMs are constrained by the knowledge within their training data and are prone to generating inaccurate, or "hallucinated", information. To address this, we introduce a sophisticated pipeline embodied in our tool FloodBrain (floodbrain.com), specialized in generating flood disaster impact reports by extracting and curating information from the web. Our pipeline assimilates information from web search results to produce detailed and accurate reports on flood events. We test different LLMs as backbones in our tool and compare their generated reports to human-written reports on different metrics. Similar to other studies, we find a notable correlation between the scores assigned by GPT-4 and the scores given by human evaluators when comparing our generated reports to human-authored ones. Additionally, we conduct an ablation study to test our single pipeline components and their relevancy for the final reports. With our tool, we aim to advance the use of LLMs for disaster impact reporting and reduce the time for coordination of humanitarian efforts in the wake of flood disasters.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:快速灾害影响报告是紧急应急救援计划的重要一环。大型自然语言模型（LLMs）已经被证明能写出整齐的文本和完成许多相关的任务，例如问题回答或文本摘要。但是LLMs受训数据中的知识所限，容易产生错误或"幻想"的信息。为解决这个问题，我们介绍了一个高级的数据pipeline，实现在我们的工具FloodBrain（floodbrain.com）中，专门生成洪水灾害影响报告，从网页搜寻结果中提取和范例信息。我们在不同的LLMs作为后端，与人工撰写的报告进行比较，以不同的 метри来评分。与其他研究一样，我们发现GPT-4的分数和人工评分者的分数之间存在显著的相关性。此外，我们还进行了一个ablation study，测试我们的单一数据ipeline组件的相关性。我们希望通过使用LLMs进行灾害影响报告，减少人道主义救援行动的协调时间，对洪水灾害的回应。
</details></li>
</ul>
<hr>
<h2 id="scBeacon-single-cell-biomarker-extraction-via-identifying-paired-cell-clusters-across-biological-conditions-with-contrastive-siamese-networks"><a href="#scBeacon-single-cell-biomarker-extraction-via-identifying-paired-cell-clusters-across-biological-conditions-with-contrastive-siamese-networks" class="headerlink" title="scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks"></a>scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02594">http://arxiv.org/abs/2311.02594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Liu, Kweon Yong Jin, Jun Ding</li>
<li>for: 这篇论文旨在探讨单元细胞水平的差异基因分析，并提出了一个名为 scBeacon 的新方法来进行这种分析。</li>
<li>methods: scBeacon 使用了一个深度对称双重构造，并且运用了 VQ-VAE 框架、对称双重网络和迅速迭代策略来识别单元细胞中的差异基因。</li>
<li>results: 根据评估结果，scBeacon 比较适合用于单元细胞差异基因分析，并且可以更好地预测单元细胞中的差异基因。<details>
<summary>Abstract</summary>
Despite the breakthroughs in biomarker discovery facilitated by differential gene analysis, challenges remain, particularly at the single-cell level. Traditional methodologies heavily rely on user-supplied cell annotations, focusing on individually expressed data, often neglecting the critical interactions between biological conditions, such as healthy versus diseased states. In response, here we introduce scBeacon, an innovative framework built upon a deep contrastive siamese network. scBeacon pioneers an unsupervised approach, adeptly identifying matched cell populations across varied conditions, enabling a refined differential gene analysis. By utilizing a VQ-VAE framework, a contrastive siamese network, and a greedy iterative strategy, scBeacon effectively pinpoints differential genes that hold potential as key biomarkers. Comprehensive evaluations on a diverse array of datasets validate scBeacon's superiority over existing single-cell differential gene analysis tools. Its precision and adaptability underscore its significant role in enhancing diagnostic accuracy in biomarker discovery. With the emphasis on the importance of biomarkers in diagnosis, scBeacon is positioned to be a pivotal asset in the evolution of personalized medicine and targeted treatments.
</details>
<details>
<summary>摘要</summary>
尽管生物标记发现方面受到了分子生物学分析的突破，但是在单元级别还存在一些挑战，特别是在健康和疾病状态之间的关键互动方面。传统方法强调用户提供的单元级别的细胞标注，宁静地集中在单个数据点上，frequently neglecting the critical interactions between biological conditions。因此，我们介绍了scBeacon，一种创新的框架，基于深度对比性同声纳网络。scBeacon采用了无监督的方法，能够准确地匹配不同状态下的单元级别细胞人口，从而提高了差异基因分析的精度。通过VQ-VAE框架、对比性同声纳网络和迪iks迭代策略，scBeacon能够有效地找到具有潜在生物标记作用的差异基因。对于多种数据集的全面评估表明，scBeacon在单元级别差异基因分析中超过了现有的工具。它的精度和适应性，强调了它在个性化医疗和Targeted treatments中的重要作用。
</details></li>
</ul>
<hr>
<h2 id="KITS-Inductive-Spatio-Temporal-Kriging-with-Increment-Training-Strategy"><a href="#KITS-Inductive-Spatio-Temporal-Kriging-with-Increment-Training-Strategy" class="headerlink" title="KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy"></a>KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02565">http://arxiv.org/abs/2311.02565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianxiong Xu, Cheng Long, Ziyue Li, Sijie Ruan, Rui Zhao, Zhishuai Li</li>
<li>for: This paper is written for the task of spatio-temporal kriging, specifically addressing the issue of graph gap in training and its negative impact on the generalization of learned patterns.</li>
<li>methods: The paper proposes a novel Increment Training Strategy that adds virtual nodes to the training graph, pairs each virtual node with its most similar observed node, and fuses their features together to enhance the supervision signal. The proposed method also constructs reliable pseudo labels for virtual nodes to improve the learning of the model.</li>
<li>results: The paper demonstrates that the proposed Kriging model with Increment Training Strategy (KITS) consistently outperforms existing kriging methods by large margins, with an improvement over Mean Absolute Error (MAE) score as high as 18.33%.<details>
<summary>Abstract</summary>
Sensors are commonly deployed to perceive the environment. However, due to the high cost, sensors are usually sparsely deployed. Kriging is the tailored task to infer the unobserved nodes (without sensors) using the observed source nodes (with sensors). The essence of kriging task is transferability. Recently, several inductive spatio-temporal kriging methods have been proposed based on graph neural networks, being trained based on a graph built on top of observed nodes via pretext tasks such as masking nodes out and reconstructing them. However, the graph in training is inevitably much sparser than the graph in inference that includes all the observed and unobserved nodes. The learned pattern cannot be well generalized for inference, denoted as graph gap. To address this issue, we first present a novel Increment training strategy: instead of masking nodes (and reconstructing them), we add virtual nodes into the training graph so as to mitigate the graph gap issue naturally. Nevertheless, the empty-shell virtual nodes without labels could have bad-learned features and lack supervision signals. To solve these issues, we pair each virtual node with its most similar observed node and fuse their features together; to enhance the supervision signal, we construct reliable pseudo labels for virtual nodes. As a result, the learned pattern of virtual nodes could be safely transferred to real unobserved nodes for reliable kriging. We name our new Kriging model with Increment Training Strategy as KITS. Extensive experiments demonstrate that KITS consistently outperforms existing kriging methods by large margins, e.g., the improvement over MAE score could be as high as 18.33%.
</details>
<details>
<summary>摘要</summary>
感知器通常用于感知环境。然而，由于高价格，感知器通常 sparse 部署。 Kriging 是专门用于推断没有感知器的节点（无感知器节点）的任务。 Kriging 任务的核心思想是传播性。最近，一些基于图神经网络的 inductive spatio-temporal Kriging 方法已经被提出，通过在观察节点基础上建立图来训练。然而，训练图与推断图（包括所有观察和无感知节点）之间存在差异，这导致学习的模式很难在推断中 generalized。为了解决这个问题，我们首先提出了一种新的增量训练策略：而不是将节点屏蔽（并重建它们），我们将虚拟节点添加到训练图中，以减少推断图与训练图之间的差异。然而，虚拟节点的空壳节点没有标签，可能会导致坏学习特征和缺乏监督信号。为解决这些问题，我们对每个虚拟节点 pair 其最相似的观察节点，并将其特征相互融合。此外，为增强监督信号，我们为虚拟节点构建可靠的 pseudo 标签。因此，虚拟节点learned的模式可以安全地传输到实际的无感知节点，以实现可靠的 Kriging。我们称之为 KITS（增量训练策略）。我们的新 Kriging 模型在 extensivel 实验中， consistently 超越现有的 Kriging 方法，例如，对 MAE 分数的改进可以高达 18.33%。
</details></li>
</ul>
<hr>
<h2 id="Time-Series-Synthesis-Using-the-Matrix-Profile-for-Anonymization"><a href="#Time-Series-Synthesis-Using-the-Matrix-Profile-for-Anonymization" class="headerlink" title="Time Series Synthesis Using the Matrix Profile for Anonymization"></a>Time Series Synthesis Using the Matrix Profile for Anonymization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02563">http://arxiv.org/abs/2311.02563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Audrey Der, Chin-Chia Michael Yeh, Yan Zheng, Junpeng Wang, Huiyuan Chen, Zhongfang Zhuang, Liang Wang, Wei Zhang, Eamonn Keogh</li>
<li>for: 本研究旨在解决数据挖掘中隐私规定或商业机密不得公开的问题，提出时序序列合成方法（TSSUMP），可以在原始数据发布的同时保持时序序列相似性信息。</li>
<li>methods: 本研究使用时序序列合成方法（TSSUMP），通过保持矩阵profile相似性信息来减少原始时序序列与合成时序序列之间的相关性。</li>
<li>results: 研究结果表明，使用TSSUMP方法可以在保持时序序列相似性信息的情况下，对原始时序序列进行合成，而无需披露实际数据。在ECG和性别遮盾预测实验中，结果表明，合成时序序列可以保持原始时序序列中的信息，使得未修改的数据挖掘工具可以在合成时序序列上达到近似于原始时序序列的性能。<details>
<summary>Abstract</summary>
Publishing and sharing data is crucial for the data mining community, allowing collaboration and driving open innovation. However, many researchers cannot release their data due to privacy regulations or fear of leaking confidential business information. To alleviate such issues, we propose the Time Series Synthesis Using the Matrix Profile (TSSUMP) method, where synthesized time series can be released in lieu of the original data. The TSSUMP method synthesizes time series by preserving similarity join information (i.e., Matrix Profile) while reducing the correlation between the synthesized and the original time series. As a result, neither the values for the individual time steps nor the local patterns (or shapes) from the original data can be recovered, yet the resulting data can be used for downstream tasks that data analysts are interested in. We concentrate on similarity joins because they are one of the most widely applied time series data mining routines across different data mining tasks. We test our method on a case study of ECG and gender masking prediction. In this case study, the gender information is not only removed from the synthesized time series, but the synthesized time series also preserves enough information from the original time series. As a result, unmodified data mining tools can obtain near-identical performance on the synthesized time series as on the original time series.
</details>
<details>
<summary>摘要</summary>
发布和分享数据对数据挖掘社区至关重要，它帮助研究者们合作并推动开放创新。然而，许多研究者因隐私法规或担心泄露商业机密而无法发布自己的数据。为解决这些问题，我们提出了时间序列合成使用矩阵profile（TSSUMP）方法，其可以将合成的时间序列发布 вместо原始数据。TSSUMP方法将时间序列合成，保持矩阵profile相似性信息，同时减少合成时间序列和原始时间序列之间的相关性。因此，对于个别时间步骤的值和原始时间序列的本地模式（或形状）都无法恢复，但下游任务中的数据分析者可以使用合成的数据进行分析。我们主要关注矩阵相似性 joins，因为它们在不同的数据挖掘任务中广泛应用。我们在 ECG 和性别遮盾预测案例中测试了我们的方法。在这个案例中，合成时间序列中的性别信息不仅被从合成时间序列中除去，还保留了原始时间序列中的 suficient 信息。因此，未修改的数据分析工具可以在合成时间序列上获得 near-identical 性能和原始时间序列上。
</details></li>
</ul>
<hr>
<h2 id="Ego-Network-Transformer-for-Subsequence-Classification-in-Time-Series-Data"><a href="#Ego-Network-Transformer-for-Subsequence-Classification-in-Time-Series-Data" class="headerlink" title="Ego-Network Transformer for Subsequence Classification in Time Series Data"></a>Ego-Network Transformer for Subsequence Classification in Time Series Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02561">http://arxiv.org/abs/2311.02561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chin-Chia Michael Yeh, Huiyuan Chen, Yujie Fan, Xin Dai, Yan Zheng, Vivian Lai, Junpeng Wang, Zhongfang Zhuang, Liang Wang, Wei Zhang, Eamonn Keogh</li>
<li>for: 时间序列标识问题是资料探索领域中广泛研究的问题，以往的研究主要集中在可以提供单一标签的前景下的子序列上。但是，实际世界的时间序列资料经常包含混合在背景下的前景子序列。成功地类别这些有用的子序列需要不仅分辨不同的类别，而且将前景子序列精确地识别出来。</li>
<li>methods: 我们提出了一种新的子序列类别方法，将每个子序列转换为一个自我网络，提供了重要的最近邻信息给模型。所有的子序列的自我网络共同构成一个时间序列子序列图，我们提出了一个有效地建构这个图的算法。</li>
<li>results: 我们对128个单Variate和30个多Variate时间序列资料集进行了实验，结果显示了我们的方法与其他方法相比的优秀性能。具体来说，我们的方法在104个中比基准方法更好。<details>
<summary>Abstract</summary>
Time series classification is a widely studied problem in the field of time series data mining. Previous research has predominantly focused on scenarios where relevant or foreground subsequences have already been extracted, with each subsequence corresponding to a single label. However, real-world time series data often contain foreground subsequences that are intertwined with background subsequences. Successfully classifying these relevant subsequences requires not only distinguishing between different classes but also accurately identifying the foreground subsequences amidst the background. To address this challenge, we propose a novel subsequence classification method that represents each subsequence as an ego-network, providing crucial nearest neighbor information to the model. The ego-networks of all subsequences collectively form a time series subsequence graph, and we introduce an algorithm to efficiently construct this graph. Furthermore, we have demonstrated the significance of enforcing temporal consistency in the prediction of adjacent subsequences for the subsequence classification problem. To evaluate the effectiveness of our approach, we conducted experiments using 128 univariate and 30 multivariate time series datasets. The experimental results demonstrate the superior performance of our method compared to alternative approaches. Specifically, our method outperforms the baseline on 104 out of 158 datasets.
</details>
<details>
<summary>摘要</summary>
时间序列分类是时间序列数据挖掘领域中广泛研究的问题。先前的研究主要集中在已经提取了相关或前景序列的场景下，每个序列均对应一个标签。然而，实际世界中的时间序列数据经常包含相关序列和背景序列杂mix。成功地分类这些相关序列需要不仅分类不同的类别，还需要准确地识别前景序列中的相关序列。为解决这个挑战，我们提出了一种新的序列分类方法，该方法将每个序列表示为一个个人网络，提供关键的最近邻居信息给模型。所有序列的ego-网络集合形成了时间序列 subsequences 图，我们提出了一种高效地构建该图的算法。此外，我们还证明了在预测相邻序列时对 subsequences 分类问题的时间一致性的要求。为评估我们的方法效果，我们使用了128个单变量时间序列数据集和30个多变量时间序列数据集进行实验。实验结果表明，我们的方法与基线方法相比，在104个数据集上表现出色， Specifically, our method outperforms the baseline on 104 out of 158 datasets.
</details></li>
</ul>
<hr>
<h2 id="Nonlinear-Multi-objective-Reinforcement-Learning-with-Provable-Guarantees"><a href="#Nonlinear-Multi-objective-Reinforcement-Learning-with-Provable-Guarantees" class="headerlink" title="Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees"></a>Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02544">http://arxiv.org/abs/2311.02544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nianli Peng, Brandon Fain</li>
<li>For:  solves a single or multi-objective Markov Decision Process (MDP) with nonlinear functions and fairness-aware welfare optimization.* Methods:  uses a reward-aware version of value iteration and an extended form of Bellman optimality for nonlinear optimization.* Results:  learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.Here is the summary in Traditional Chinese:* For: 解决单或多目标Markov Decision Process（MDP）中的非线性函数和公平意识化营运优化问题。* Methods: 使用奖励感知的值追数和扩展的贝尔曼最佳化算法 для非线性优化。* Results:  learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.<details>
<summary>Abstract</summary>
We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm with provable guarantees for solving a single or multi-objective Markov Decision Process (MDP) where we want to maximize the expected value of a nonlinear function over accumulated rewards. This allows us to model fairness-aware welfare optimization for multi-objective reinforcement learning as well as risk-aware reinforcement learning with nonlinear Von Neumann-Morgenstern utility functions in the single objective setting. RA-E3 extends the classic E3 algorithm that solves MDPs with scalar rewards and linear preferences. We first state a distinct reward-aware version of value iteration that calculates a non-stationary policy that is approximately optimal for a given model of the environment. This sub-procedure is based on an extended form of Bellman optimality for nonlinear optimization that explicitly considers time and current accumulated reward. We then describe how to use this optimization procedure in a larger algorithm that must simultaneously learn a model of the environment. The algorithm learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.
</details>
<details>
<summary>摘要</summary>
我们描述了RA-E3（优先奖励明确探索或利用）算法，它具有解释可能性的保证来解决单或多目标Markov决策过程（MDP）中 maximize 预期值函数的问题。这使得我们可以模型公平性感知的发展优化和风险感知的复杂函数学习。RA-E3 是 класи的E3算法的扩展，它可以解决具有数値奖励和线性偏好的 MDP。我们首先说明了一个特有的优先奖励版本的值迭代，它可以获得一个给定环境模型的非站点政策，这个迭代基于延长的贝尔曼优化的非线性优化，它显式地考虑了时间和累绩奖励。然后，我们描述了如何使用这个优化程序在一个更大的算法中，这个算法可以同时学习环境模型。这个算法可以在 MDP 大小、需要的准确度和非线性函数的平滑程度上取得 polynomial 时间的近似最佳策略，并且在数个目标上取得 exponentially 快的时间。
</details></li>
</ul>
<hr>
<h2 id="Dense-Video-Captioning-A-Survey-of-Techniques-Datasets-and-Evaluation-Protocols"><a href="#Dense-Video-Captioning-A-Survey-of-Techniques-Datasets-and-Evaluation-Protocols" class="headerlink" title="Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols"></a>Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02538">http://arxiv.org/abs/2311.02538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iqra Qasim, Alexander Horsch, Dilip K. Prasad</li>
<li>for: 本研究旨在描述视频中的各种事件和交互，以提高自然语言描述视频的能力。</li>
<li>methods: 本研究使用 dense video captioning (DVC) 技术，包括视频特征EXTRACTION (VFE)、时间事件定位 (TEL) 和稠密标题生成 (DCG) 三个子任务。</li>
<li>results: 研究中提出了许多关于 DVC 和其子任务的方法和技术，以及用于评估这些方法的数据集。<details>
<summary>Abstract</summary>
Untrimmed videos have interrelated events, dependencies, context, overlapping events, object-object interactions, domain specificity, and other semantics that are worth highlighting while describing a video in natural language. Owing to such a vast diversity, a single sentence can only correctly describe a portion of the video. Dense Video Captioning (DVC) aims at detecting and describing different events in a given video. The term DVC originated in the 2017 ActivityNet challenge, after which considerable effort has been made to address the challenge. Dense Video Captioning is divided into three sub-tasks: (1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and (3) Dense Caption Generation (DCG). This review aims to discuss all the studies that claim to perform DVC along with its sub-tasks and summarize their results. We also discuss all the datasets that have been used for DVC. Lastly, we highlight some emerging challenges and future trends in the field.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用简化中文表述文本<</SYS>>未处理的视频具有相互关联的事件、依赖关系、上下文、重叠事件、对象之间交互、域特定性和其他 semantics，这些元素值得在描述视频时被注意。由于这种极大的多样性，单个句子只能正确描述视频的一部分。紧凑视频描述（DVC）目标在检测和描述视频中的不同事件。DVC的起源可以追溯到2017年的ActivityNet挑战，自此以后，对挑战的努力已经很大。DVC分为三个子任务：（1）视频特征提取（VFE），（2）时间事件定位（TEL），和（3）紧凑描述生成（DCG）。本文将评论所有声称能够完成DVC和其子任务的研究，并总结其结果。此外，我们还介绍了所有用于DVC的数据集。最后，我们强调了在这个领域出现的一些新挑战和未来趋势。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.AI_2023_11_05/" data-id="cloojsmbs006rre887eahgxvb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/05/cs.CV_2023_11_05/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-11-05
        
      </div>
    </a>
  
  
    <a href="/2023/11/05/cs.CL_2023_11_05/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-11-05</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">67</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">42</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
