
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.AS - 2023-11-21 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Learning-based Array Configuration-Independent Binaural Audio Telepresence with Scalable Signal Enhancement and Ambience Preservation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.12706 repo_url: None paper_au">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.AS - 2023-11-21">
<meta property="og:url" content="https://nullscc.github.io/2023/11/21/eess.AS_2023_11_21/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Learning-based Array Configuration-Independent Binaural Audio Telepresence with Scalable Signal Enhancement and Ambience Preservation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.12706 repo_url: None paper_au">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-21T14:00:00.000Z">
<meta property="article:modified_time" content="2023-11-22T13:44:34.808Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.AS_2023_11_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/21/eess.AS_2023_11_21/" class="article-date">
  <time datetime="2023-11-21T14:00:00.000Z" itemprop="datePublished">2023-11-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.AS - 2023-11-21
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Learning-based-Array-Configuration-Independent-Binaural-Audio-Telepresence-with-Scalable-Signal-Enhancement-and-Ambience-Preservation"><a href="#Learning-based-Array-Configuration-Independent-Binaural-Audio-Telepresence-with-Scalable-Signal-Enhancement-and-Ambience-Preservation" class="headerlink" title="Learning-based Array Configuration-Independent Binaural Audio Telepresence with Scalable Signal Enhancement and Ambience Preservation"></a>Learning-based Array Configuration-Independent Binaural Audio Telepresence with Scalable Signal Enhancement and Ambience Preservation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12706">http://arxiv.org/abs/2311.12706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yicheng Hsu, Mingsian R. Bai</li>
<li>For: The paper aims to create an immersive audio experience for users at the near end of an audio telepresence (AT) system, with a focus on signal enhancement and ambience preservation.* Methods: The proposed Binaural AT (BAT) system uses an array-based approach with the DeepFilterNet as the backbone, and includes a tunable weighting between signal enhancement and ambience preservation. The system also uses an array configuration-independent Spatial COherence REpresentation (SCORE) feature for training.* Results: The proposed BAT system achieves superior telepresence performance with a desired balance between signal enhancement and ambience preservation, even when the array configurations are unseen in the training phase. The system is evaluated using magnitude-weighted Interaural Phase Difference error (mw-IPDe), magnitude-weighted Interaural Level Difference error (mw-ILDe), and modified Scale-Invariant Signal-to-Distortion Ratio (mSI-SDR) metrics, as well as subjective listening tests.<details>
<summary>Abstract</summary>
Audio Telepresence (AT) aims to create an immersive experience of the audio scene at the far end for the user(s) at the near end. The application of AT could encompass scenarios with varying degrees of emphasis on signal enhancement and ambience preservation. It is desirable for an AT system to be scalable between these two extremes. To this end, we propose an array-based Binaural AT (BAT) system using the DeepFilterNet as the backbone to convert the array microphone signals into the Head-Related Transfer Function (HRTF)-filtered signals, with a tunable weighting between signal enhancement and ambience preservation. An array configuration-independent Spatial COherence REpresentation (SCORE) feature is proposed for the model training so that the network remains robust to different array geometries and sensor counts. magnitude-weighted Interaural Phase Difference error (mw-IPDe), magnitude-weighted Interaural Level Difference error (mw-ILDe), and modified Scale-Invariant Signal-to-Distortion Ratio (mSI-SDR) are defined as performance metrics for objective evaluation. Subjective listening tests were also performed to validate the proposed BAT system. The results have shown that the proposed BAT system can achieve superior telepresence performance with the desired balance between signal enhancement and ambience preservation, even when the array configurations are unseen in the training phase.
</details>
<details>
<summary>摘要</summary>
Audio Telepresence (AT) 目标是创造远端听音场的充满体验 для用户。应用场景可以具有不同的强调级别，从增强信号到保留环境。欢迎使用 AT 系统可扩展到这两个极端。为此，我们提议使用 DeepFilterNet 作为后准基础，将阵列麦克风信号转化为基于 Head-Related Transfer Function (HRTF) 的 filtered signals，并使用可调整的 Signal 增强和环境保留的权重。我们还提出了不受阵列几何和感知器数量影响的 Spatial COherence REpresentation (SCORE) 特征，以便在不同的阵列配置和感知器数量下，网络仍然具有 robustness。用于对象评估的性能指标包括 magnitude-weighted Interaural Phase Difference error (mw-IPDe), magnitude-weighted Interaural Level Difference error (mw-ILDe), 和 modified Scale-Invariant Signal-to-Distortion Ratio (mSI-SDR)。Subjective listening tests 也进行了进行验证。结果表明，我们的 BAT 系统可以在不同的阵列配置下实现Superior telepresence性能，并且可以在训练阶段未看到阵列配置时保持 Desired 的信号增强和环境保留平衡。
</details></li>
</ul>
<hr>
<h2 id="A-Distributed-Algorithm-for-Personal-Sound-Zones-Systems"><a href="#A-Distributed-Algorithm-for-Personal-Sound-Zones-Systems" class="headerlink" title="A Distributed Algorithm for Personal Sound Zones Systems"></a>A Distributed Algorithm for Personal Sound Zones Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12427">http://arxiv.org/abs/2311.12427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sipei Zhao, Guoqiang Zhang, Eva Cheng, Ian S. Burnett</li>
<li>for: 该论文旨在提出一种高效的分布式个人声音区系统，以便在共享空间中无需穿戴Headset听音乐&#x2F;语音内容。</li>
<li>methods: 该论文提出了一种分布式算法，以便在多个节点之间分担计算负担，从而降低了总计算复杂性，但是会导致一定的性能下降。</li>
<li>results: 通过在真实的房间响应测试中进行 simulations，证明了提出的分布式个人声音区系统的可行性。<details>
<summary>Abstract</summary>
A Personal Sound Zones (PSZ) system aims to generate two or more independent listening zones that allow multiple users to listen to different music/audio content in a shared space without the need for wearing headphones. Most existing studies assume that the acoustic paths between loudspeakers and microphones are measured beforehand in a stationary environment. Recently, adaptive PSZ systems have been explored to adapt the system in a time-varying acoustic environment. However, because a PSZ system usually requires multiple loudspeakers, the multichannel adaptive algorithms impose a high computational load on the processor. To overcome that problem, this paper proposes an efficient distributed algorithm for PSZ systems, which not only spreads the computational burden over multiple nodes but also reduces the overall computational complexity, at the expense of a slight decrease in performance. Simulation results with true room impulse responses measured in a Hemi-Anechoic chamber are performed to verify the proposed distributed PSZ system.
</details>
<details>
<summary>摘要</summary>
personal sound zones (PSZ) 系统的目的是生成两个或更多独立的听众区，以便在共享空间中让多个用户listen to different music/audio content而无需穿戴headphones。现有的大多数研究假设了在静止环境中测量喇叭和 Microphone的Acoustic path。在最近，适应PSZ系统在时间变化的听频环境中进行了探索。然而，由于PSZ系统通常需要多个喇叭， multichannel adaptive algorithms 会对处理器带来高计算负担。为了解决这个问题，本文提出了PSZ系统的高效分布式算法，不仅将计算负担分散到多个节点，还可以降低总计算复杂性，但是会导致一定的性能下降。为验证提议的分布式PSZ系统，在真实的半静音室回声响应中进行了Simulation结果。
</details></li>
</ul>
<hr>
<h2 id="AudioLog-LLMs-Powered-Long-Audio-Logging-with-Acoustic-Scenes-and-Events-Joint-Estimation"><a href="#AudioLog-LLMs-Powered-Long-Audio-Logging-with-Acoustic-Scenes-and-Events-Joint-Estimation" class="headerlink" title="AudioLog: LLMs-Powered Long Audio Logging with Acoustic Scenes and Events Joint Estimation"></a>AudioLog: LLMs-Powered Long Audio Logging with Acoustic Scenes and Events Joint Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12371">http://arxiv.org/abs/2311.12371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jisheng Bai, Han Yin, Mou Wang, Dongyuan Shi, Woon-Seng Gan, Jianfeng Chen</li>
<li>for: 这篇论文是为了提出一种基于大语言模型（LLM）的自动化音频描述系统，以便更好地捕捉长 audio sequence 中的各种听觉场景和事件的完整时间细节。</li>
<li>methods: 该论文提出了一种joint training网络，通过练习一个基于预先训练的层次token-semantic audio Transformer 的大 audio 模型，并通过语言模型（LLM）来编写音频日志，概括音频环境的文字描述。</li>
<li>results: 实验表明，提出的系统在听觉场景分类和声音事件检测方面具有出色的表现，超越了现有的方法。此外，further analyses 还表明，AudioLog 能够有效地概括长 audio sequence。<details>
<summary>Abstract</summary>
Previous studies in automated audio captioning have faced difficulties in accurately capturing the complete temporal details of acoustic scenes and events within long audio sequences. This paper presents AudioLog, a large language models (LLMs)-powered audio logging system with multi-task learning of acoustic tasks. Specifically, we propose a joint training network, achieved by fine-tuning a large audio model based on the pre-trained hierarchical token-semantic audio Transformer. We then leverage LLMs to craft audio logs that summarize textual descriptions of the acoustic environment. Experiments show that the proposed system attains exceptional performance in acoustic scene classification and sound event detection, surpassing existing methods in the field. Further analyses demonstrate AudioLog's power in effectively summarizing long audio sequences.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Rethinking-the-Output-Architecture-for-Sound-Source-Localization"><a href="#Rethinking-the-Output-Architecture-for-Sound-Source-Localization" class="headerlink" title="Rethinking the Output Architecture for Sound Source Localization"></a>Rethinking the Output Architecture for Sound Source Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12305">http://arxiv.org/abs/2311.12305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linfeng Feng, Xiao-Lei Zhang, Xuelong Li</li>
<li>for: 本研究旨在提高音源Localization（SSL）中的Direction of Arrival（DOA）估计精度。</li>
<li>methods: 本文提出了一种基于分类的DOA估计方法，使用了Soft Label Distribution（ULD）、Negative Log Absolute Error（NLAE）loss函数和Mean Squared Error loss函数 ohne Activation（MSE(wo)）。</li>
<li>results: 实验结果表明，提出的方法可以达到领域内最佳性能，并且Weighted Adjacent Decoding（WAD）解码方法可以超越现有解码方法的量化误差限制。<details>
<summary>Abstract</summary>
Sound source localization (SSL) involves estimating the direction of arrival (DOA) of a sound signal. The output space of the DOA estimation is continuous, suggesting that regression may be the most appropriate formulation for DOA. However, in practice, converting the DOA estimation into a classification problem often results in better performance than the regression formulation, since that classification problems are generally easier to model, and are more robust in handling noise and uncertainty than regression problems. In the classification formulation of DOA, the output space is discretized into several intervals, each of which is treated as a class. These classes exhibit strong inter-class correlation, with their mutual-similarity increasing when they approach each other and being ordered. However, this property is not sufficiently explored. To exploit these property, we propose a soft label distribution, named Unbiased Label Distribution (ULD), for eliminating the quantization error of the training target and further taking the inter-class similarity into strong consideration. We further introduce two loss functions, named the Negative Log Absolute Error (NLAE) loss function and {Mean Squared Error loss function without activation (MSE(wo))}, for the soft label family. Finally, we design a new decoding method to map the predicted distribution to sound source locations, called Weighted Adjacent Decoding (WAD). It uses the weighted sum of the probabilities of the peak classes and their adjacent classes in the predicted distribution for decoding. Experimental results show that the proposed method achieves the state-of-the-art performance, and the WAD decoding method is able to even breakthrough the quantization error limits of existing decoding methods.
</details>
<details>
<summary>摘要</summary>
声源localization（SSL）涉及估计声信号的方向来源（DOA）的方向。由于DOA估计的输出空间是连续的，因此可以使用回归来模型声源。然而，在实践中，将DOA估计转换成分类问题通常会产生更好的性能，因为分类问题比回归问题更容易模型，并且对噪声和不确定性更加抗应。在分类形式下，DOA的输出空间被精确化为一些时间间隔，每个时间间隔都被视为一个类。这些类之间存在强相关性，它们之间的相似性随着它们的距离增加，并且按照一定的顺序排序。然而，这个特性并没有得到充分利用。为了利用这个特性，我们提出了一种不偏 Label Distribution（ULD），用于消除培育目标的量化误差，同时更加强调类之间的相似性。我们还引入了两种损失函数：Negative Log Absolute Error（NLAE）损失函数和Mean Squared Error损失函数 без活动（MSE(wo)），用于soft label家族。最后，我们设计了一种新的解码方法，名为Weighted Adjacent Decoding（WAD），用于将预测分布映射到声源位置。它使用预测分布中峰值类和其相邻类的权重加权和，进行解码。实验结果表明，我们的方法可以达到状态公共的性能，而WAD解码方法甚至可以超越现有解码方法的量化误差限制。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/21/eess.AS_2023_11_21/" data-id="clpahu7bi016l3h88gk80cy4k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/21/cs.SD_2023_11_21/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.SD - 2023-11-21
        
      </div>
    </a>
  
  
    <a href="/2023/11/21/cs.CV_2023_11_21/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CV - 2023-11-21</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
