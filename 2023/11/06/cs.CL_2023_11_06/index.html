
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-11-06 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="STONYBOOK: A System and Resource for Large-Scale Analysis of Novels paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.03614 repo_url: None paper_authors: Charuta Pethe, Allen Kim, Rajesh Prabhakar, Tanzir Pial, St">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-11-06">
<meta property="og:url" content="https://nullscc.github.io/2023/11/06/cs.CL_2023_11_06/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="STONYBOOK: A System and Resource for Large-Scale Analysis of Novels paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.03614 repo_url: None paper_authors: Charuta Pethe, Allen Kim, Rajesh Prabhakar, Tanzir Pial, St">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-06T11:00:00.000Z">
<meta property="article:modified_time" content="2023-11-08T05:49:48.925Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.CL_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T11:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-11-06
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="STONYBOOK-A-System-and-Resource-for-Large-Scale-Analysis-of-Novels"><a href="#STONYBOOK-A-System-and-Resource-for-Large-Scale-Analysis-of-Novels" class="headerlink" title="STONYBOOK: A System and Resource for Large-Scale Analysis of Novels"></a>STONYBOOK: A System and Resource for Large-Scale Analysis of Novels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03614">http://arxiv.org/abs/2311.03614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charuta Pethe, Allen Kim, Rajesh Prabhakar, Tanzir Pial, Steven Skiena</li>
<li>for: 这个论文的目的是为了提供一个大规模分析的文学作品的资源，包括一个开源的终端到终端NLP分析管道，49207个清洁和注释的小说，以及一个大规模分析的文学作品数据库。</li>
<li>methods: 这个论文使用了一个开源的终端到终端NLP分析管道，并对小说进行了大规模的注释和清洁处理。</li>
<li>results: 论文提供了一些分析文学作品的工具，包括人物出现和互动的视觉化、相似的小说、表达词汇、部分词类统计和阅读难度指标。<details>
<summary>Abstract</summary>
Books have historically been the primary mechanism through which narratives are transmitted. We have developed a collection of resources for the large-scale analysis of novels, including: (1) an open source end-to-end NLP analysis pipeline for the annotation of novels into a standard XML format, (2) a collection of 49,207 distinct cleaned and annotated novels, and (3) a database with an associated web interface for the large-scale aggregate analysis of these literary works. We describe the major functionalities provided in the annotation system along with their utilities. We present samples of analysis artifacts from our website, such as visualizations of character occurrences and interactions, similar books, representative vocabulary, part of speech statistics, and readability metrics. We also describe the use of the annotated format in qualitative and quantitative analysis across large corpora of novels.
</details>
<details>
<summary>摘要</summary>
书籍历史上曾经是故事的主要传递机制。我们已经开发了一系列资源来进行大规模的小说分析，包括：（1）一个开源的终端到终端自然语言处理分析管道，用于将小说转换为标准的XML格式；（2）一个包含49,207部清洁和注释的小说的集合；以及（3）一个与网站集成的数据库，用于大规模的小说作品的聚合分析。我们将介绍这些注释系统的主要功能，以及它们的用途。我们还将展示我们网站上的分析成果，例如人物出现和互动的视觉化、相似的书籍、表达词汇、部件分类统计和阅读指数等。此外，我们还将介绍使用注释格式进行质量和量化分析的应用。
</details></li>
</ul>
<hr>
<h2 id="Dimensions-of-Online-Conflict-Towards-Modeling-Agonism"><a href="#Dimensions-of-Online-Conflict-Towards-Modeling-Agonism" class="headerlink" title="Dimensions of Online Conflict: Towards Modeling Agonism"></a>Dimensions of Online Conflict: Towards Modeling Agonism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03584">http://arxiv.org/abs/2311.03584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matt Canute, Mali Jin, hannah holtzclaw, Alberto Lusoli, Philippa R Adams, Mugdha Pandya, Maite Taboada, Diana Maynard, Wendy Hui Kyong Chun</li>
<li>for: 本研究旨在模型在线冲突中的agonism和仇恨对话，以便提高对话质量和Platform moderation。</li>
<li>methods: 研究人员采用Twitter conversations相关争议话题的数据采集和标注，并开发了一套全面的标注 schemes，以标识不同类型的冲突。然后，他们使用逻辑回归和transformer模型进行训练，并在不同话题下进行测试。</li>
<li>results: 研究人员发现，Contextual标签可以帮助确定冲突，并且可以使模型在话题变化时保持稳定性。这些结果可以帮助优化在线冲突的识别和管理。<details>
<summary>Abstract</summary>
Agonism plays a vital role in democratic dialogue by fostering diverse perspectives and robust discussions. Within the realm of online conflict there is another type: hateful antagonism, which undermines constructive dialogue. Detecting conflict online is central to platform moderation and monetization. It is also vital for democratic dialogue, but only when it takes the form of agonism. To model these two types of conflict, we collected Twitter conversations related to trending controversial topics. We introduce a comprehensive annotation schema for labelling different dimensions of conflict in the conversations, such as the source of conflict, the target, and the rhetorical strategies deployed. Using this schema, we annotated approximately 4,000 conversations with multiple labels. We then trained both logistic regression and transformer-based models on the dataset, incorporating context from the conversation, including the number of participants and the structure of the interactions. Results show that contextual labels are helpful in identifying conflict and make the models robust to variations in topic. Our research contributes a conceptualization of different dimensions of conflict, a richly annotated dataset, and promising results that can contribute to content moderation.
</details>
<details>
<summary>摘要</summary>
争议在民主对话中发挥重要作用，推动多元观点和有力的讨论。在网络冲突中，另一种类型的争议是恶意对抗，这会损害有益的对话。检测网络冲突中的对抗是民主对话中的中心问题，同时也是平台管理和资金化的关键。只有当争议变成了agonism时，才能为民主对话带来有益。为了模型这两种对抗，我们收集了Twitter上关于热门争议话题的对话。我们提出了一个完整的注解schema，用于标识对话中的冲突源、目标和使用的修辞策略。使用这个schema，我们对约4,000个对话进行了多个标签注解。然后我们使用逻辑回归和变换器模型来训练数据集，并在对话中包含上下文信息，如参与者人数和互动结构。结果表明， Contextual标签可以帮助 Identify冲突，并使模型在话题变化时保持稳定。我们的研究对内容审核做出了贡献，包括对冲突的概念化、 ricahly注解数据集和成功的模型训练结果。
</details></li>
</ul>
<hr>
<h2 id="Measuring-Adversarial-Datasets"><a href="#Measuring-Adversarial-Datasets" class="headerlink" title="Measuring Adversarial Datasets"></a>Measuring Adversarial Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03566">http://arxiv.org/abs/2311.03566</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kritwik1/Detection-of-Anomalies-in-Images-using-Adversarial-learning">https://github.com/kritwik1/Detection-of-Anomalies-in-Images-using-Adversarial-learning</a></li>
<li>paper_authors: Yuanchen Bai, Raoyi Huang, Vijay Viswanathan, Tzu-Sheng Kuo, Tongshuang Wu</li>
<li>for: This paper aims to investigate the challenges of adversarial robustness in NLP tasks and to evaluate the effectiveness of existing quantifiable metrics in capturing the differences between original and adversarial text instances.</li>
<li>methods: The authors conducted a systematic survey of existing quantifiable metrics for NLP tasks and compared the distributions of those metrics between the original and adversarial text instances in several current adversarial effect datasets.</li>
<li>results: The results show valuable insights into the challenges of adversarial robustness in NLP tasks and the limitations of existing metrics in capturing the differences between original and adversarial text instances. The findings also suggest that the assumptions underlying these metrics may not always align with the real-world scenarios.<details>
<summary>Abstract</summary>
In the era of widespread public use of AI systems across various domains, ensuring adversarial robustness has become increasingly vital to maintain safety and prevent undesirable errors. Researchers have curated various adversarial datasets (through perturbations) for capturing model deficiencies that cannot be revealed in standard benchmark datasets. However, little is known about how these adversarial examples differ from the original data points, and there is still no methodology to measure the intended and unintended consequences of those adversarial transformations. In this research, we conducted a systematic survey of existing quantifiable metrics that describe text instances in NLP tasks, among dimensions of difficulty, diversity, and disagreement. We selected several current adversarial effect datasets and compared the distributions between the original and their adversarial counterparts. The results provide valuable insights into what makes these datasets more challenging from a metrics perspective and whether they align with underlying assumptions.
</details>
<details>
<summary>摘要</summary>
在人工智能系统广泛应用于不同领域的时代，保证对抗强度变得越来越重要，以保障安全和避免不良错误。研究人员通过干扰生成了各种对抗示例，以捕捉模型缺陷，这些缺陷在标准测试集中不能表现出来。然而，对这些对抗示例与原始数据点之间的差异还不够了解，还没有一种方法来衡量这些对抗变换的意图和无意图后果。在这项研究中，我们进行了系统性的量化度量研究，探讨了NLPTask中文本实例的纬度、多样性和分歧等维度。我们选择了一些当前的对抗效果数据集，并比较了这些数据集中原始和对抗对应的分布。结果提供了有价值的洞察，有助于我们更好地理解这些数据集在量化度量上的挑战和是否符合下面的假设。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Uncertainty-in-Natural-Language-Explanations-of-Large-Language-Models"><a href="#Quantifying-Uncertainty-in-Natural-Language-Explanations-of-Large-Language-Models" class="headerlink" title="Quantifying Uncertainty in Natural Language Explanations of Large Language Models"></a>Quantifying Uncertainty in Natural Language Explanations of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03533">http://arxiv.org/abs/2311.03533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sree Harsha Tanneru, Chirag Agarwal, Himabindu Lakkaraju</li>
<li>for: 本文旨在调查大语言模型（LLM）的解释uncertainty的问题。</li>
<li>methods: 作者提出了两种新的度量方法：Verbalized Uncertainty和Probing Uncertainty，以量化LLM的解释uncertainty。</li>
<li>results: Empirical分析表明，Verbalized Uncertainty不是一个可靠的解释confidence度量方法，而Probing Uncertainty度量和解释忠实度之间存在正相关关系。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are increasingly used as powerful tools for several high-stakes natural language processing (NLP) applications. Recent prompting works claim to elicit intermediate reasoning steps and key tokens that serve as proxy explanations for LLM predictions. However, there is no certainty whether these explanations are reliable and reflect the LLMs behavior. In this work, we make one of the first attempts at quantifying the uncertainty in explanations of LLMs. To this end, we propose two novel metrics -- $\textit{Verbalized Uncertainty}$ and $\textit{Probing Uncertainty}$ -- to quantify the uncertainty of generated explanations. While verbalized uncertainty involves prompting the LLM to express its confidence in its explanations, probing uncertainty leverages sample and model perturbations as a means to quantify the uncertainty. Our empirical analysis of benchmark datasets reveals that verbalized uncertainty is not a reliable estimate of explanation confidence. Further, we show that the probing uncertainty estimates are correlated with the faithfulness of an explanation, with lower uncertainty corresponding to explanations with higher faithfulness. Our study provides insights into the challenges and opportunities of quantifying uncertainty in LLM explanations, contributing to the broader discussion of the trustworthiness of foundation models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Spoken-Dialogue-System-for-Medical-Prescription-Acquisition-on-Smartphone-Development-Corpus-and-Evaluation"><a href="#Spoken-Dialogue-System-for-Medical-Prescription-Acquisition-on-Smartphone-Development-Corpus-and-Evaluation" class="headerlink" title="Spoken Dialogue System for Medical Prescription Acquisition on Smartphone: Development, Corpus and Evaluation"></a>Spoken Dialogue System for Medical Prescription Acquisition on Smartphone: Development, Corpus and Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03510">http://arxiv.org/abs/2311.03510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Can Kocabiyikoglu, François Portet, Jean-Marc Babouchkine, Prudence Gibert, Hervé Blanchon, Gaëtan Gavazzi</li>
<li>for: 这个论文主要目标是提供一种语音基的药物预cription系统，以便药物预cription过程更加快速、精准和安全。</li>
<li>methods: 这个系统使用了对话模型、语义提取和数据扩展等技术，并在实际应用环境中进行了评估。</li>
<li>results: 评估结果显示，该系统可以帮助医生和其他专家在66.15秒和35.64秒内预cription药物，并有76%的任务成功率和72%的任务成功率。这些数据被记录和注释，并形成了PxCorpus，全球首个语音药物预cription数据集（<a target="_blank" rel="noopener" href="https://doi.org/10.5281/zenodo.6524162%EF%BC%89%E3%80%82">https://doi.org/10.5281/zenodo.6524162）。</a><details>
<summary>Abstract</summary>
Hospital information systems (HIS) have become an essential part of healthcare institutions and now incorporate prescribing support software. Prescription support software allows for structured information capture, which improves the safety, appropriateness and efficiency of prescriptions and reduces the number of adverse drug events (ADEs). However, such a system increases the amount of time physicians spend at a computer entering information instead of providing medical care. In addition, any new visiting clinician must learn to manage complex interfaces since each HIS has its own interfaces. In this paper, we present a natural language interface for e-prescribing software in the form of a spoken dialogue system accessible on a smartphone. This system allows prescribers to record their prescriptions verbally, a form of interaction closer to their usual practice. The system extracts the formal representation of the prescription ready to be checked by the prescribing software and uses the dialogue to request mandatory information, correct errors or warn of particular situations. Since, to the best of our knowledge, there is no existing voice-based prescription dialogue system, we present the system developed in a low-resource environment, focusing on dialogue modeling, semantic extraction and data augmentation. The system was evaluated in the wild with 55 participants. This evaluation showed that our system has an average prescription time of 66.15 seconds for physicians and 35.64 seconds for other experts, and a task success rate of 76\% for physicians and 72\% for other experts. All evaluation data were recorded and annotated to form PxCorpus, the first spoken drug prescription corpus that has been made fully available to the community (\url{https://doi.org/10.5281/zenodo.6524162}).
</details>
<details>
<summary>摘要</summary>
医院信息系统 (HIS) 已成为医疗机构的重要组成部分，并包括订药支持软件。订药支持软件可以为订药进行结构化信息捕获，从而提高订药的安全性、适用性和效率，并减少药物相互作用事件 (ADEs)。然而，这种系统会使医生更多时间花在计算机上输入信息上，而不是提供医疗服务。此外，每个医院信息系统都有自己的界面，新的医生必须学习这些复杂的界面。在这篇论文中，我们提出了一种基于自然语言的订药软件界面，可以通过智能手机上的语音对话系统来记录订药。这种系统使订药人员可以通过语音方式录入订药，与其 usual practice 更加相似。系统会从对话中提取订药的正式表示，并使用对话来请求必要的信息、修正错误或警告特定情况。由于我们知道的 voz-based 订药对话系统不存在，我们在尽可能的低资源环境中开发了这种系统，重点是对话模型、语义提取和数据扩展。我们对这种系统进行了野外评估，共有55名参与者。这次评估显示，我们的系统的订药时间为66.15秒 для医生和35.64秒 для其他专家，任务成功率为76%  для医生和72%  для其他专家。所有评估数据被记录和标注，并形成 PxCorpus，全球首个完全公开的 spoken drug prescription corpus，其 DOI 为10.5281/zenodo.6524162。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Exemplars-as-Clues-to-Retrieving-from-Large-Associative-Memory"><a href="#In-Context-Exemplars-as-Clues-to-Retrieving-from-Large-Associative-Memory" class="headerlink" title="In-Context Exemplars as Clues to Retrieving from Large Associative Memory"></a>In-Context Exemplars as Clues to Retrieving from Large Associative Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03498">http://arxiv.org/abs/2311.03498</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andotalao24/ICL-as-retrieval-from-associative-memory">https://github.com/andotalao24/ICL-as-retrieval-from-associative-memory</a></li>
<li>paper_authors: Jiachen Zhao</li>
<li>for: This paper aims to provide a new perspective on in-context learning (ICL) and improve the efficiency of active exemplar selection in LLMs.</li>
<li>methods: The authors use a theoretical framework based on Hopfield Networks to understand the mechanism of ICL and propose more efficient active exemplar selection.</li>
<li>results: The study sheds new light on the mechanism of ICL by connecting it to memory retrieval, with potential implications for advancing the understanding of LLMs.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文目的是提供一种新的启发式受限学习（ICL）视角，并提高活动示例选择的效率。</li>
<li>methods: 作者们使用基于Hopfield网络的理论框架来理解ICL机制，并提出更有效的活动示例选择方法。</li>
<li>results: 研究带来了ICL机制的新的理解，将其与记忆检索连接起来，有potential应用于提高LLMs的理解。<details>
<summary>Abstract</summary>
Recently, large language models (LLMs) have made remarkable progress in natural language processing. The most representative ability of LLMs is in-context learning (ICL), which enables LLMs to learn patterns from in-context exemplars without training. The performance of ICL greatly depends on the exemplars used. However, how to choose exemplars remains unclear due to the lack of understanding of how in-context learning works. In this paper, we present a novel perspective on ICL by conceptualizing it as contextual retrieval from a model of associative memory. We establish a theoretical framework of ICL based on Hopfield Networks. Based on our framework, we look into how in-context exemplars influence the performance of ICL and propose more efficient active exemplar selection. Our study sheds new light on the mechanism of ICL by connecting it to memory retrieval, with potential implications for advancing the understanding of LLMs.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:最近，大型语言模型（LLM）在自然语言处理方面做出了很大的进步。LLM的最重要的能力之一是在上下文中学习（ICL），它使得LLM可以通过上下文示例学习而无需训练。但是，如何选择示例仍然存在很多不确定性，这是因为我们对ICL的理解不够。在这篇论文中，我们提出了一种新的思路，即将ICL看作为上下文检索。我们基于抽象网络建立了ICL的理论框架，并研究了示例如何影响ICL的性能。我们还提出了更加有效的活动示例选择方法。我们的研究可能为LLM的理解提供新的灯光，并且可能对ICL的机制做出新的连接。
</details></li>
</ul>
<hr>
<h2 id="Tackling-Concept-Shift-in-Text-Classification-using-Entailment-style-Modeling"><a href="#Tackling-Concept-Shift-in-Text-Classification-using-Entailment-style-Modeling" class="headerlink" title="Tackling Concept Shift in Text Classification using Entailment-style Modeling"></a>Tackling Concept Shift in Text Classification using Entailment-style Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03320">http://arxiv.org/abs/2311.03320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumegh Roychowdhury, Karan Gupta, Siva Rajesh Kasa, Prasanna Srinivasa Murthy, Alok Chandra</li>
<li>for:  Handle concept shift in text classification tasks with less data and labeling costs.</li>
<li>methods:  Reformulate vanilla classification as an entailment-style problem, requiring less data to re-train the text classifier for new concepts.</li>
<li>results:  Achieve absolute F1 gains of up to 7% and 40% in few-shot settings on real-world and synthetic datasets, respectively, and save 75% of labeling costs overall.<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have seen tremendous success in text classification (TC) problems in the context of Natural Language Processing (NLP). In many real-world text classification tasks, the class definitions being learned do not remain constant but rather change with time - this is known as Concept Shift. Most techniques for handling concept shift rely on retraining the old classifiers with the newly labelled data. However, given the amount of training data required to fine-tune large DL models for the new concepts, the associated labelling costs can be prohibitively expensive and time consuming. In this work, we propose a reformulation, converting vanilla classification into an entailment-style problem that requires significantly less data to re-train the text classifier to adapt to new concepts. We demonstrate the effectiveness of our proposed method on both real world & synthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in few-shot settings. Further, upon deployment, our solution also helped save 75% of labeling costs overall.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unraveling-Downstream-Gender-Bias-from-Large-Language-Models-A-Study-on-AI-Educational-Writing-Assistance"><a href="#Unraveling-Downstream-Gender-Bias-from-Large-Language-Models-A-Study-on-AI-Educational-Writing-Assistance" class="headerlink" title="Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance"></a>Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03311">http://arxiv.org/abs/2311.03311</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/epfl-ml4ed/unraveling-llm-bias">https://github.com/epfl-ml4ed/unraveling-llm-bias</a></li>
<li>paper_authors: Thiemo Wambsganss, Xiaotian Su, Vinitra Swamy, Seyed Parsa Neshaei, Roman Rietsche, Tanja Käser<br>for: This paper investigates the potential transfer of bias from large language models (LLMs) to human writing in an AI writing support pipeline.methods: The study uses a large-scale user study with 231 students writing business case peer reviews in German, and compares five groups with different levels of writing support: a control group with no assistance, and four groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. The study uses GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and Sentence Embedding Association Test (SEAT) to evaluate gender bias at various stages of the pipeline.results: The results show that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions, suggesting that AI writing support in the classroom may not transfer bias to students’ responses.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one classroom group with feature-based suggestions and four groups recruited from Prolific -- a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and Sentence Embedding Association Test (SEAT) we evaluate the gender bias at various stages of the pipeline: in model embeddings, in suggestions generated by the models, and in reviews written by students. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students' responses.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Ziya2-Data-centric-Learning-is-All-LLMs-Need"><a href="#Ziya2-Data-centric-Learning-is-All-LLMs-Need" class="headerlink" title="Ziya2: Data-centric Learning is All LLMs Need"></a>Ziya2: Data-centric Learning is All LLMs Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03301">http://arxiv.org/abs/2311.03301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, Dixiang Zhang, Kunhao Pan, Ping Yang, Qi Yang, Jiaxing Zhang, Yan Song</li>
<li>for: 这项研究的目的是提出一个13亿参数的模型Ziya2，并通过针对不同阶段的预训练技术和数据中心化优化来提高Ziya2在多个标准准则上的表现。</li>
<li>methods: 该研究使用了LLaMA2作为基础模型，并在700亿个字符上进行了进一步预训练。采用了预训练技术和数据中心化优化来优化Ziya2的学习过程。</li>
<li>results: 实验表明，Ziya2在多个标准准则上显著超越了其他模型，特别是与代表性的开源模型相比，具有更出色的表现。Ziya2（基础）版本在<a target="_blank" rel="noopener" href="https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base%E5%92%8Chttps://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary%E4%B8%AD%E5%8F%91%E5%B8%83%E3%80%82">https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base和https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary中发布。</a><details>
<summary>Abstract</summary>
Various large language models (LLMs) have been proposed in recent years, including closed- and open-source ones, continually setting new records on multiple benchmarks. However, the development of LLMs still faces several issues, such as high cost of training models from scratch, and continual pre-training leading to catastrophic forgetting, etc. Although many such issues are addressed along the line of research on LLMs, an important yet practical limitation is that many studies overly pursue enlarging model sizes without comprehensively analyzing and optimizing the use of pre-training data in their learning process, as well as appropriate organization and leveraging of such data in training LLMs under cost-effective settings. In this work, we propose Ziya2, a model with 13 billion parameters adopting LLaMA2 as the foundation model, and further pre-trained on 700 billion tokens, where we focus on pre-training techniques and use data-centric optimization to enhance the learning process of Ziya2 on different stages. Experiments show that Ziya2 significantly outperforms other models in multiple benchmarks especially with promising results compared to representative open-source ones. Ziya2 (Base) is released at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.
</details>
<details>
<summary>摘要</summary>
各种大型语言模型（LLMs）在最近几年中提出了许多，包括关闭和开源的模型，不断创造新的记录在多个benchmark上。然而，LLMs的开发仍面临多个问题，如训练模型从scratch的高成本，以及 kontinual pre-training导致catastrophic forgetting等等。虽然这些问题在LLMs研究中得到了很多的关注，但是一个重要又实用的限制是许多研究过于强调扩大模型的大小，而未充分分析和优化模型在学习过程中使用的预训练数据，以及适当地组织和利用这些数据进行模型训练。在这个工作中，我们提出了Ziya2模型，该模型采用了13亿参数，基于LLaMA2基础模型，并进一步预训练了700亿个字符。我们将注重预训练技术和数据中心化优化，以提高Ziya2在不同阶段的学习过程。实验表明，Ziya2在多个benchmark上表现出色，特别是与代表性的开源模型相比，显示了突出的性能提升。Ziya2（基本）版本 Release在https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base和https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary上。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Analysis-of-Hallucination-in-GPT-4V-ision-Bias-and-Interference-Challenges"><a href="#Holistic-Analysis-of-Hallucination-in-GPT-4V-ision-Bias-and-Interference-Challenges" class="headerlink" title="Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges"></a>Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03287">http://arxiv.org/abs/2311.03287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhang Cui, Yiyang Zhou, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, Huaxiu Yao</li>
<li>for: 评估 GPT-4V(ision) 模型中的偏见和干扰现象</li>
<li>methods: 引入了一个新的 benchmark，即 Bias and Interference Challenges in Visual Language Models (Bingo)，用于评估 GPT-4V(ision) 模型中的偏见和干扰</li>
<li>results: GPT-4V(ision) 模型存在偏见和干扰现象，包括地域偏见和被引导的问题，而且现有的 mitigation 方法不能有效解决这些问题。<details>
<summary>Abstract</summary>
While GPT-4V(ision) impressively models both visual and textual information simultaneously, it's hallucination behavior has not been systematically assessed. To bridge this gap, we introduce a new benchmark, namely, the Bias and Interference Challenges in Visual Language Models (Bingo). This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models: bias and interference. Here, bias refers to the model's tendency to hallucinate certain types of responses, possibly due to imbalance in its training data. Interference pertains to scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the text prompt is phrased or how the input image is presented. We identify a notable regional bias, whereby GPT-4V(ision) is better at interpreting Western images or images with English writing compared to images from other countries or containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together. Popular mitigation approaches, such as self-correction and chain-of-thought reasoning, are not effective in resolving these challenges. We also identified similar biases and interference vulnerabilities with LLaVA and Bard. Our results characterize the hallucination challenges in GPT-4V(ision) and state-of-the-art visual-language models, and highlight the need for new solutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.
</details>
<details>
<summary>摘要</summary>
While GPT-4V(ision) impressively models both visual and textual information simultaneously, its hallucination behavior has not been systematically assessed. To bridge this gap, we introduce a new benchmark, namely, the Bias and Interference Challenges in Visual Language Models (Bingo). This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models: bias and interference. Here, bias refers to the model's tendency to hallucinate certain types of responses, possibly due to imbalance in its training data. Interference pertains to scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the text prompt is phrased or how the input image is presented. We identify a notable regional bias, whereby GPT-4V(ision) is better at interpreting Western images or images with English writing compared to images from other countries or containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together. Popular mitigation approaches, such as self-correction and chain-of-thought reasoning, are not effective in resolving these challenges. We also identified similar biases and interference vulnerabilities with LLaVA and Bard. Our results characterize the hallucination challenges in GPT-4V(ision) and state-of-the-art visual-language models, and highlight the need for new solutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.
</details></li>
</ul>
<hr>
<h2 id="Safurai-Csharp-Harnessing-Synthetic-Data-to-improve-language-specific-Code-LLM"><a href="#Safurai-Csharp-Harnessing-Synthetic-Data-to-improve-language-specific-Code-LLM" class="headerlink" title="Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM"></a>Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03243">http://arxiv.org/abs/2311.03243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Cifarelli, Leonardo Boiardi, Alessandro Puppo, Leon Jovanovic</li>
<li>for: 本研究旨在开发一个专门为C#代码生成、完成和调试而设计的开源模型，帮助开发者快速搭建代码和学习代码。</li>
<li>methods: 该模型基于CodeLlama 34B模型，并使用EvolInstruct技术进行精细和扩展数据集的 fine-tuning 过程。</li>
<li>results: 模型在Manual MultiPL-E标准准点测试中获得了56.33%的高分（Zero-Shot、Pass@1），表明它具有remarkable的代码生成和调试能力，能够大幅提高开发者的工作效率和代码学习效果。<details>
<summary>Abstract</summary>
This paper introduces Safurai-Csharp, an open-source model designed to specialize in the generation, completion, and debugging of C# code. Safurai-Csharp is built upon the novel CodeLlama 34B model and leverages the EvolInstruct technique, creating a refined and expanded dataset for its fine-tuning process. The results of its performance, a notable score of 56.33% on the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity to streamline developers' workflows and aid code learning. It shows promise in setting new stakes in the landscape of open-source C# LLMs and hopes to inspire more inclusive and wide-ranging development in the field of language-specific LLMs.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了 Safurai-Csharp，一个开源模型，旨在生成、完成和调试 C# 代码。Safurai-Csharp 基于 CodeLlama 34B 模型，并利用了 EvolInstruct 技术，通过这种精细和扩展的数据集进行微调。其性能表现出色，在 Manual MultiPL-E  bencmark 上得分 56.33%（零shot、@1 达到），表明它具有快速协助开发者工作流程和代码学习的高能力。它展示了在开源 C# LLM 领域的新的可能性，并希望能够激发更多的包容和广泛的开发在语言特定 LLM 领域。
</details></li>
</ul>
<hr>
<h2 id="p-Laplacian-Transformer"><a href="#p-Laplacian-Transformer" class="headerlink" title="p-Laplacian Transformer"></a>p-Laplacian Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03235">http://arxiv.org/abs/2311.03235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Nguyen, Tam Nguyen, Vinh Nguyen, Tan M. Nguyen</li>
<li>for: 这篇论文主要是关于如何在自注意 Mechanism中引入$p$-Laplacian regularization，以提高Transformers的表达能力和稳定性。</li>
<li>methods: 这篇论文提出了一种新的Transformers类型，称为$p$-Laplacian Transformer（p-LaT），它利用$p$-Laplacian regularization框架来捕捉自注意层中的异质特征。</li>
<li>results: 论文通过实验表明，Compared with基础Transformers，p-LaT在多种 benchmark datasets上表现出了明显的优势。<details>
<summary>Abstract</summary>
$p$-Laplacian regularization, rooted in graph and image signal processing, introduces a parameter $p$ to control the regularization effect on these data. Smaller values of $p$ promote sparsity and interpretability, while larger values encourage smoother solutions. In this paper, we first show that the self-attention mechanism obtains the minimal Laplacian regularization ($p=2$) and encourages the smoothness in the architecture. However, the smoothness is not suitable for the heterophilic structure of self-attention in transformers where attention weights between tokens that are in close proximity and non-close ones are assigned indistinguishably. From that insight, we then propose a novel class of transformers, namely the $p$-Laplacian Transformer (p-LaT), which leverages $p$-Laplacian regularization framework to harness the heterophilic features within self-attention layers. In particular, low $p$ values will effectively assign higher attention weights to tokens that are in close proximity to the current token being processed. We empirically demonstrate the advantages of p-LaT over the baseline transformers on a wide range of benchmark datasets.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)$p$-laplacian regularization, rooted in graph 和 image signal processing, introduces a parameter $p$ to control the regularization effect on these data. smaller values of $p$ promote sparsity 和 interpretability, while larger values encourage smoother solutions. In this paper, we first show that the self-attention mechanism obtains the minimal Laplacian regularization ($p=2$) and encourages the smoothness in the architecture. However, the smoothness is not suitable for the heterophilic structure of self-attention in transformers where attention weights between tokens that are in close proximity and non-close ones are assigned indistinguishably. From that insight, we then propose a novel class of transformers, namely the $p$-Laplacian Transformer (p-LaT), which leverages $p$-Laplacian regularization framework to harness the heterophilic features within self-attention layers. In particular, low $p$ values will effectively assign higher attention weights to tokens that are in close proximity to the current token being processed. We empirically demonstrate the advantages of p-LaT over the baseline transformers on a wide range of benchmark datasets.
</details></li>
</ul>
<hr>
<h2 id="Model-based-Counterfactual-Generator-for-Gender-Bias-Mitigation"><a href="#Model-based-Counterfactual-Generator-for-Gender-Bias-Mitigation" class="headerlink" title="Model-based Counterfactual Generator for Gender Bias Mitigation"></a>Model-based Counterfactual Generator for Gender Bias Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03186">http://arxiv.org/abs/2311.03186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ewoenam Kwaku Tokpo, Toon Calders</li>
<li>for:  Mitigating gender bias in natural language models</li>
<li>methods:  Combination of data processing techniques and bi-objective training regime</li>
<li>results:  Alleviates the shortcomings of dictionary-based solutions and improves mitigation of gender bias<details>
<summary>Abstract</summary>
Counterfactual Data Augmentation (CDA) has been one of the preferred techniques for mitigating gender bias in natural language models. CDA techniques have mostly employed word substitution based on dictionaries. Although such dictionary-based CDA techniques have been shown to significantly improve the mitigation of gender bias, in this paper, we highlight some limitations of such dictionary-based counterfactual data augmentation techniques, such as susceptibility to ungrammatical compositions, and lack of generalization outside the set of predefined dictionary words. Model-based solutions can alleviate these problems, yet the lack of qualitative parallel training data hinders development in this direction. Therefore, we propose a combination of data processing techniques and a bi-objective training regime to develop a model-based solution for generating counterfactuals to mitigate gender bias. We implemented our proposed solution and performed an empirical evaluation which shows how our model alleviates the shortcomings of dictionary-based solutions.
</details>
<details>
<summary>摘要</summary>
《Counterfactual Data Augmentation（CDA）是一种常用的技术来减少自然语言模型中的性别偏见。现有的CDA技术主要采用词替换基于词典，尽管这些技术已经证明可以有效地减少性别偏见，但我们在这篇论文中强调了这些技术的一些限制，如易受到不正确的 sentence 组合的影响，以及只能在已知词典中的word上进行替换。基于模型的解决方案可以解决这些问题，但由于缺乏相应的量化平行训练数据，这方向的发展受到了限制。因此，我们提出了一种结合数据处理技术和双目标训练方法的解决方案，用于生成对性别偏见的抗补做。我们实现了我们的提议并进行了实验评估，结果表明，我们的模型可以减少词典基于CDA技术的缺陷。》Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Architectural-Sweet-Spots-for-Modeling-Human-Label-Variation-by-the-Example-of-Argument-Quality-It’s-Best-to-Relate-Perspectives"><a href="#Architectural-Sweet-Spots-for-Modeling-Human-Label-Variation-by-the-Example-of-Argument-Quality-It’s-Best-to-Relate-Perspectives" class="headerlink" title="Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It’s Best to Relate Perspectives!"></a>Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It’s Best to Relate Perspectives!</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03153">http://arxiv.org/abs/2311.03153</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/phhei/relateperspectives-sweetspots">https://github.com/phhei/relateperspectives-sweetspots</a></li>
<li>paper_authors: Philipp Heinisch, Matthias Orlikowski, Julia Romberg, Philipp Cimiano</li>
<li>for: 本研究旨在探讨自然语言处理中多个批注者之间的关系，以及如何将它们融合到一起以提高批注质量。</li>
<li>methods: 研究采用了多种方法，包括完全聚合批注者视角的模型和“分享nothing”-架构，以及 Drawing inspiration from recommender systems, the authors investigate the effectiveness of models that incorporate relations between different annotators.</li>
<li>results: 研究发现，在两个任务中（论点抽象和结论有效性&#x2F;新颖性），使用 recommender 架构可以提高每个批注者的 F$_1$-score 平均值达到 43% 以上，相比于多数票模型。这些结果表明，关于主题的方法可以从 relate 个人视角中受益。<details>
<summary>Abstract</summary>
Many annotation tasks in natural language processing are highly subjective in that there can be different valid and justified perspectives on what is a proper label for a given example. This also applies to the judgment of argument quality, where the assignment of a single ground truth is often questionable. At the same time, there are generally accepted concepts behind argumentation that form a common ground. To best represent the interplay of individual and shared perspectives, we consider a continuum of approaches ranging from models that fully aggregate perspectives into a majority label to "share nothing"-architectures in which each annotator is considered in isolation from all other annotators. In between these extremes, inspired by models used in the field of recommender systems, we investigate the extent to which architectures that include layers to model the relations between different annotators are beneficial for predicting single-annotator labels. By means of two tasks of argument quality classification (argument concreteness and validity/novelty of conclusions), we show that recommender architectures increase the averaged annotator-individual F$_1$-scores up to $43\%$ over a majority label model. Our findings indicate that approaches to subjectivity can benefit from relating individual perspectives.
</details>
<details>
<summary>摘要</summary>
很多自然语言处理的注释任务具有主观性，即可能存在多种有效和合理的标签选择 для给定示例。这同样适用于论证质量评估，其中归一化到单一真实值的决定经常存在疑问。然而，论证中存在通用的概念，这些概念可以成为共同基础。为了最好地表现个体和共同 perspectives的交互，我们考虑了一个维度的方法，从完全汇总 perspectives 到 "share nothing" 架构，在这些架构中，每个标注员被视为孤立的。在这些极端之间， inspirited by  recombiner 系统中的模型，我们调查了将多个标注员之间的关系模型包含在架构中的程度是否有利于预测单个标注员的标签。通过两个论证质量分类任务（论证具体性和结论的有效性/新颖性），我们发现， recombiner 架构可以提高平均标注员个人 F$_1$-分数达到 43%，相比单多数标签模型。我们的发现表明，对主观性的方法可以从个体 perspectives 中受益。
</details></li>
</ul>
<hr>
<h2 id="Text-Augmentations-with-R-drop-for-Classification-of-Tweets-Self-Reporting-Covid-19"><a href="#Text-Augmentations-with-R-drop-for-Classification-of-Tweets-Self-Reporting-Covid-19" class="headerlink" title="Text Augmentations with R-drop for Classification of Tweets Self Reporting Covid-19"></a>Text Augmentations with R-drop for Classification of Tweets Self Reporting Covid-19</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03420">http://arxiv.org/abs/2311.03420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumam Francis, Marie-Francine Moens</li>
<li>for: 这篇论文是为了 Social Media Mining for Health 2023 共同任务而创建的模型。</li>
<li>methods: 我们的方法包括一种类фикации模型，利用多种文本扩展和 R-drop 来增强数据和避免过拟合，从而提高模型的效果。</li>
<li>results: 我们的领先模型，通过对 synonym substitution、固定词和反向翻译等扩展进行增强，超越了任务的 mean 和 median 分数，实现了测试集的 F1 分数 0.877。<details>
<summary>Abstract</summary>
This paper presents models created for the Social Media Mining for Health 2023 shared task. Our team addressed the first task, classifying tweets that self-report Covid-19 diagnosis. Our approach involves a classification model that incorporates diverse textual augmentations and utilizes R-drop to augment data and mitigate overfitting, boosting model efficacy. Our leading model, enhanced with R-drop and augmentations like synonym substitution, reserved words, and back translations, outperforms the task mean and median scores. Our system achieves an impressive F1 score of 0.877 on the test set.
</details>
<details>
<summary>摘要</summary>
这份论文介绍了为社交媒体挖掘2023年共享任务创建的模型。我们团队面临了第一个任务，即分类报告自适应新冠肺炎诊断的推文。我们的方法包括一种类型分类模型，利用多种文本扩充和R-drop数据增强技术，以避免过拟合和提高模型效果。我们的领先模型，通过R-drop和扩充如同义词替换、保留词和反向翻译等，超越任务的 mean 和 median 分数。我们的系统在测试集上达到了很高的 F1 分数0.877。
</details></li>
</ul>
<hr>
<h2 id="Injecting-Categorical-Labels-and-Syntactic-Information-into-Biomedical-NER"><a href="#Injecting-Categorical-Labels-and-Syntactic-Information-into-Biomedical-NER" class="headerlink" title="Injecting Categorical Labels and Syntactic Information into Biomedical NER"></a>Injecting Categorical Labels and Syntactic Information into Biomedical NER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03113">http://arxiv.org/abs/2311.03113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumam Francis, Marie-Francine Moens</li>
<li>for: 提高生物医学名实体识别 (NER) 精度</li>
<li>methods: 使用两种方法：首先训练一个序列级分类器来将句子分类为类别，并将这些类别标签作为自然语言模板进行修改，以提高分类器的准确率。然后，将这些标签信息注入到NER模型中。</li>
<li>results: 在三个benchmark数据集上进行实验，结果表明将 categorical label 信息和语法上下文注入到NER模型中可以提高精度，并且超越基elineBERT模型。<details>
<summary>Abstract</summary>
We present a simple approach to improve biomedical named entity recognition (NER) by injecting categorical labels and Part-of-speech (POS) information into the model. We use two approaches, in the first approach, we first train a sequence-level classifier to classify the sentences into categories to obtain the sentence-level tags (categorical labels). The sequence classifier is modeled as an entailment problem by modifying the labels as a natural language template. This helps to improve the accuracy of the classifier. Further, this label information is injected into the NER model. In this paper, we demonstrate effective ways to represent and inject these labels and POS attributes into the NER model. In the second approach, we jointly learn the categorical labels and NER labels. Here we also inject the POS tags into the model to increase the syntactic context of the model. Experiments on three benchmark datasets show that incorporating categorical label information with syntactic context is quite useful and outperforms baseline BERT-based models.
</details>
<details>
<summary>摘要</summary>
我们提出了一种简单的方法来改进生物医学命名实体识别（NER），通过把分类标签和语法信息注入到模型中。我们采用了两种方法：第一种方法是首先训练一个序列级分类器，以将句子分类为类别获得句子级标签（分类标签）。这个序列分类器是通过修改标签为自然语言模板来实现的，这有助于提高分类器的准确率。然后，这些标签信息被注入到NER模型中。在这篇论文中，我们示出了如何表示和注入这些标签和语法特征到NER模型中。第二种方法是同时学习分类标签和NER标签。在这里，我们也注入了语法标签到模型中，以增加语法上下文。经验表明，将分类标签和语法信息注入到BERT基础模型中，可以提高NER模型的性能。
</details></li>
</ul>
<hr>
<h2 id="Language-Models-are-Super-Mario-Absorbing-Abilities-from-Homologous-Models-as-a-Free-Lunch"><a href="#Language-Models-are-Super-Mario-Absorbing-Abilities-from-Homologous-Models-as-a-Free-Lunch" class="headerlink" title="Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch"></a>Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03099">http://arxiv.org/abs/2311.03099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yule-buaa/mergelm">https://github.com/yule-buaa/mergelm</a></li>
<li>paper_authors: Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li</li>
<li>For: The paper explores the possibility of merging multiple language models (LMs) with different abilities by leveraging the parameters of homologous models without retraining or using GPUs.* Methods: The authors propose a novel operation called DARE (Drop And REscale) to eliminate most delta parameters of supervised fine-tuning (SFT) models, and they merge multiple SFT homologous models with DARE to create a single model with diverse abilities.* Results: The authors conduct experiments on eight datasets from the GLUE benchmark with BERT and RoBERTa, and they find that DARE can eliminate 99% of delta parameters effortlessly, and merging multiple task-specific LMs into one LM with diverse abilities can improve the performance of the model.Here’s the simplified Chinese text for the three key points:* For: 本 paper 探讨了多种语言模型（LM）之间的能力兼容性，以及可以通过同类模型参数的协同来实现这一点，无需重新训练或使用 GPU。* Methods: 作者提出了一种新的操作DARE（Drop And REscale），可以直接将大多数 delta 参数设为零，而不会影响 SFT 模型的能力。此外，他们还将多个 SFT 同类模型通过 DARE 进行merge。* Results: 作者在 GLUE 测试benchmark 上使用 BERT 和 RoBERTa 进行实验，发现 DARE 可以轻松地消除99%的 delta 参数，而 merge 多个任务特定 LM 可以提高模型的性能。<details>
<summary>Abstract</summary>
In this paper, we uncover that Language Models (LMs), either encoder- or decoder-based, can obtain new capabilities by assimilating the parameters of homologous models without retraining or GPUs. Typically, new abilities of LMs can be imparted by Supervised Fine-Tuning (SFT), reflected in the disparity between fine-tuned and pre-trained parameters (i.e., delta parameters). We initially observe that by introducing a novel operation called DARE (Drop And REscale), most delta parameters can be directly set to zeros without affecting the capabilities of SFT LMs and larger models can tolerate a higher proportion of discarded parameters. Based on this observation, we further sparsify delta parameters of multiple SFT homologous models with DARE and subsequently merge them into a single model by parameter averaging. We conduct experiments on eight datasets from the GLUE benchmark with BERT and RoBERTa. We also merge WizardLM, WizardMath, and Code Alpaca based on Llama 2. Experimental results show that: (1) The delta parameter value ranges for SFT models are typically small, often within 0.005, and DARE can eliminate 99% of them effortlessly. However, once the models are continuously pre-trained, the value ranges can grow to around 0.03, making DARE impractical. We have also tried to remove fine-tuned instead of delta parameters and find that a 10% reduction can lead to drastically decreased performance (even to 0). This highlights that SFT merely stimulates the abilities via delta parameters rather than injecting new abilities into LMs; (2) DARE can merge multiple task-specific LMs into one LM with diverse abilities. For instance, the merger of WizardLM and WizardMath improves the GSM8K zero-shot accuracy of WizardLM from 2.2 to 66.3, retaining its instruction-following ability while surpassing WizardMath's original 64.2 performance. Codes are available at https://github.com/yule-BUAA/MergeLM.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们发现了语言模型（LM）可以通过吸收同类模型参数而获得新的能力，不需要重新训练或GPU。通常，LM的新能力可以通过监督微调（SFT）表达，可以通过参数差异（delta参数）来衡量。我们发现，通过一种新的操作called DARE（Drop And REscale），大多数delta参数可以直接设为零，而不会影响SFT LM的能力。基于这一点，我们进一步减少了多个SFT同类模型的delta参数使用DARE，并将其混合成一个单独的模型。我们在GLUE数据集上进行了八个数据集的实验，并将WizardLM、WizardMath和Code Alpaca基于Llama 2进行了集成。实验结果表明：（1）SFT模型的 delta参数范围通常在0.005之间，DARE可以轻松地消除99%的 delta参数。但是，当模型进行连续预训练时， delta参数范围可以增长到约0.03，使DARE成为不切实际。我们还尝试了从精度训练中除掉精度训练后的参数，发现可以减少精度训练后的参数10%，但这会导致性能减少至0。这表明SFT只是通过 delta parameters来刺激LM的能力，而不是在LM中注入新的能力；（2）DARE可以将多个任务特定LM集成到一个LM中，例如将WizardLM和WizardMath集成成一个LM，可以提高GSM8K零shot精度从2.2增加到66.3，保留WizardLM的 instrucion-following 能力，而同时超越WizardMath的原始64.2性能。代码可以在https://github.com/yule-BUAA/MergeLM中获取。
</details></li>
</ul>
<hr>
<h2 id="BanLemma-A-Word-Formation-Dependent-Rule-and-Dictionary-Based-Bangla-Lemmatizer"><a href="#BanLemma-A-Word-Formation-Dependent-Rule-and-Dictionary-Based-Bangla-Lemmatizer" class="headerlink" title="BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer"></a>BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03078">http://arxiv.org/abs/2311.03078</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eblict-gigatech/BanLemma">https://github.com/eblict-gigatech/BanLemma</a></li>
<li>paper_authors: Sadia Afrin, Md. Shahad Mahmud Chowdhury, Md. Ekramul Islam, Faisal Ahamed Khan, Labib Imam Chowdhury, MD. Motahar Mahtab, Nazifa Nuha Chowdhury, Massud Forkan, Neelima Kundu, Hakim Arif, Mohammad Mamun Or Rashid, Mohammad Ruhul Amin, Nabeel Mohammed</li>
<li>for: 本研究旨在提出一个特定于孟加拉语的lemmatizer，以便在自然语言处理（NLP）和语言学方面进行更好的理解和处理。</li>
<li>methods: 本研究使用了语言规则来定义lemmatization规则，并使用词典和规则实现 lemmatizer。具体来说，我们分析了大量的孟加拉语文本，探索了不同类型的词汇形成方式，并根据词形态的不同，定义了不同的lemmatization规则。</li>
<li>results: 在使用 manually annotated 测试数据进行测试时，我们的lemmatizer取得了96.36%的准确率，并在三个以前发表的孟加拉语 lemmatization 数据集上表现出 competed 的性能。<details>
<summary>Abstract</summary>
Lemmatization holds significance in both natural language processing (NLP) and linguistics, as it effectively decreases data density and aids in comprehending contextual meaning. However, due to the highly inflected nature and morphological richness, lemmatization in Bangla text poses a complex challenge. In this study, we propose linguistic rules for lemmatization and utilize a dictionary along with the rules to design a lemmatizer specifically for Bangla. Our system aims to lemmatize words based on their parts of speech class within a given sentence. Unlike previous rule-based approaches, we analyzed the suffix marker occurrence according to the morpho-syntactic values and then utilized sequences of suffix markers instead of entire suffixes. To develop our rules, we analyze a large corpus of Bangla text from various domains, sources, and time periods to observe the word formation of inflected words. The lemmatizer achieves an accuracy of 96.36% when tested against a manually annotated test dataset by trained linguists and demonstrates competitive performance on three previously published Bangla lemmatization datasets. We are making the code and datasets publicly available at https://github.com/eblict-gigatech/BanLemma in order to contribute to the further advancement of Bangla NLP.
</details>
<details>
<summary>摘要</summary>
lemmatization在自然语言处理（NLP）和语言学中具有重要意义，因为它有效地减少数据密度，并帮助理解上下文中的含义。然而，由于孟加拉语的高度变格性和 morphological wealth，孟加拉语 lemmatization 存在复杂的挑战。在这种研究中，我们提出了语言规则 для lemmatization 和一个字典，并使用这些规则来设计一个特定 для孟加拉语的 lemmatizer。我们的系统 aimsto lemmatize 根据句子中每个单词的部分语种类型。不同于之前的规则基本方法，我们分析了 suffix marker 的出现根据 morpho-syntactic 值，然后使用 suffix marker 的序列而不是整个 suffix。为了开发我们的规则，我们分析了一大量的孟加拉语文本，从不同的领域、来源和时期来观察inflected word 的形成。lemmatizer 的准确率为 96.36%，并在三个已经发布的孟加拉语 lemmatization 数据集上进行了竞争性的表现。我们将代码和数据集公开发布在 GitHub 上，以便贡献于孟加拉语 NLP 的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Zero-shot-Bilingual-App-Reviews-Mining-with-Large-Language-Models"><a href="#Zero-shot-Bilingual-App-Reviews-Mining-with-Large-Language-Models" class="headerlink" title="Zero-shot Bilingual App Reviews Mining with Large Language Models"></a>Zero-shot Bilingual App Reviews Mining with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03058">http://arxiv.org/abs/2311.03058</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jl-wei/mini-bar">https://github.com/jl-wei/mini-bar</a></li>
<li>paper_authors: Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Binbin Xu, Pierre Louis Bernard, Gérard Dray<br>for: 本研究旨在提高软件需求的改进，通过自动挖掘用户评论来提高软件质量。methods: 本研究使用大量语言模型（LLMs）进行零shot挖掘用户评论，包括分类用户评论、将相似评论集成在一起、生成概括性摘要和排序用户评论群。results: 初步结果表明，Mini-BAR在英文和法语用户评论中具有效果和效率，可以帮助改进软件需求。<details>
<summary>Abstract</summary>
App reviews from app stores are crucial for improving software requirements. A large number of valuable reviews are continually being posted, describing software problems and expected features. Effectively utilizing user reviews necessitates the extraction of relevant information, as well as their subsequent summarization. Due to the substantial volume of user reviews, manual analysis is arduous. Various approaches based on natural language processing (NLP) have been proposed for automatic user review mining. However, the majority of them requires a manually crafted dataset to train their models, which limits their usage in real-world scenarios. In this work, we propose Mini-BAR, a tool that integrates large language models (LLMs) to perform zero-shot mining of user reviews in both English and French. Specifically, Mini-BAR is designed to (i) classify the user reviews, (ii) cluster similar reviews together, (iii) generate an abstractive summary for each cluster and (iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we created a dataset containing 6,000 English and 6,000 French annotated user reviews and conducted extensive experiments. Preliminary results demonstrate the effectiveness and efficiency of Mini-BAR in requirement engineering by analyzing bilingual app reviews. (Replication package containing the code, dataset, and experiment setups on https://github.com/Jl-wei/mini-bar )
</details>
<details>
<summary>摘要</summary>
应用商店上的用户评论对软件需求的改进非常重要。大量有价值的评论不断上传，描述软件问题和期望的功能。有效利用用户评论需要提取有用信息，并将其总结起来。由于用户评论的数量很大，手动分析很困难。基于自然语言处理（NLP）的多种方法已经提出，但大多数需要手动制作数据集来训练其模型，这限制了它们在实际场景中的使用。在这种情况下，我们提出了 mini-bar 工具，它利用大型自然语言模型（LLMs）进行零shot的用户评论挖掘。具体来说， mini-bar 设计用于：1. 分类用户评论2. 将相似的评论集成在一起3. 生成每个集合的抽象摘要4. 对用户评论集合进行排名为评估 mini-bar 的性能，我们创建了包含 6,000 个英语和 6,000 个法语注解用户评论的数据集，并进行了广泛的实验。初步结果表明 mini-bar 在需求工程中是有效率的，通过分析双语应用评论。详细的实验设置和结果可以在 GitHub 上找到：https://github.com/Jl-wei/mini-bar。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Agreement-in-Multi-party-Conversational-AI"><a href="#Detecting-Agreement-in-Multi-party-Conversational-AI" class="headerlink" title="Detecting Agreement in Multi-party Conversational AI"></a>Detecting Agreement in Multi-party Conversational AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03026">http://arxiv.org/abs/2311.03026</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laura Schauer, Jason Sweeney, Charlie Lyttle, Zein Said, Aron Szeles, Cale Clark, Katie McAskill, Xander Wickham, Tom Byars, Daniel Hernández Garcia, Nancie Gunson, Angus Addlesee, Oliver Lemon</li>
<li>for: 这篇论文旨在解决多方会话中的对话系统问题，尤其是在社会助け机器人（SAR）中。</li>
<li>methods: 该论文提出了一种多方会话对话系统，invites两名用户参与一场问答游戏。系统可以检测用户的同意或不同意并应答 accordingly。</li>
<li>results: 我们的评估结果包括性能评估和用户评估结果，强调检测用户同意的能力。我们发布了对应的注释记录和代码在GitHub上。<details>
<summary>Abstract</summary>
Today, conversational systems are expected to handle conversations in multi-party settings, especially within Socially Assistive Robots (SARs). However, practical usability remains difficult as there are additional challenges to overcome, such as speaker recognition, addressee recognition, and complex turn-taking. In this paper, we present our work on a multi-party conversational system, which invites two users to play a trivia quiz game. The system detects users' agreement or disagreement on a final answer and responds accordingly. Our evaluation includes both performance and user assessment results, with a focus on detecting user agreement. Our annotated transcripts and the code for the proposed system have been released open-source on GitHub.
</details>
<details>
<summary>摘要</summary>
今天，对话系统预期能够处理多方会话，特别是在社交助手机器人（SARs）中。然而，实际使用仍然具有困难，因为需要解决更多的挑战，如说话人识别、目标人识别和复杂的回答交换。在这篇论文中，我们介绍了一种多方对话系统， Invites two users to play a trivia quiz game。系统可以检测用户的同意或不同意 final answer，并根据此作出应对。我们的评估包括性能和用户评估结果，强调检测用户同意。我们已经发布了对应的笔记录和系统代码到 GitHub。
</details></li>
</ul>
<hr>
<h2 id="Detecting-agreement-in-multi-party-dialogue-evaluating-speaker-diarisation-versus-a-procedural-baseline-to-enhance-user-engagement"><a href="#Detecting-agreement-in-multi-party-dialogue-evaluating-speaker-diarisation-versus-a-procedural-baseline-to-enhance-user-engagement" class="headerlink" title="Detecting agreement in multi-party dialogue: evaluating speaker diarisation versus a procedural baseline to enhance user engagement"></a>Detecting agreement in multi-party dialogue: evaluating speaker diarisation versus a procedural baseline to enhance user engagement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03021">http://arxiv.org/abs/2311.03021</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ddenley/multi-person-quiz">https://github.com/ddenley/multi-person-quiz</a></li>
<li>paper_authors: Angus Addlesee, Daniel Denley, Andy Edmondson, Nancie Gunson, Daniel Hernández Garcia, Alexandre Kha, Oliver Lemon, James Ndubuisi, Neil O’Reilly, Lia Perochaud, Raphaël Valeri, Miebaka Worika</li>
<li>for: 这个论文的目的是确定对话状态跟踪中的准确性，以及对话状态跟踪是否能够识别特定的对话事件，如一致或反对。</li>
<li>methods: 这个论文使用了一种合作式问答游戏，其中对话机器人扮演了奖励游戏的主持人，以确定 диаризации模型或频率和靠近性基于的方法是哪一种更加准确地识别一致。</li>
<li>results: 实验结果表明，我们的程序式系统比 диари化系统更加有趣，并且更加准确地识别一致，达到了0.44的平均准确率，而不是0.28。<details>
<summary>Abstract</summary>
Conversational agents participating in multi-party interactions face significant challenges in dialogue state tracking, since the identity of the speaker adds significant contextual meaning. It is common to utilise diarisation models to identify the speaker. However, it is not clear if these are accurate enough to correctly identify specific conversational events such as agreement or disagreement during a real-time interaction. This study uses a cooperative quiz, where the conversational agent acts as quiz-show host, to determine whether diarisation or a frequency-and-proximity-based method is more accurate at determining agreement, and whether this translates to feelings of engagement from the players. Experimental results show that our procedural system was more engaging to players, and was more accurate at detecting agreement, reaching an average accuracy of 0.44 compared to 0.28 for the diarised system.
</details>
<details>
<summary>摘要</summary>
多个对话参与者在多方交流中面临对话状态跟踪挑战，因为说话人的身份带来了Contextual meaning。通常使用分类器来标识说话人。然而，不确定这些模型是否准确地标识特定的对话事件，如一致或反对，在实时交流中。这项研究使用合作问答，其中对话系统 acts as quiz-show host，以确定是否使用分类器或频率和靠近的方法更准确地确定一致，以及这种精度是否导致玩家们的参与感。实验结果表明，我们的程序系统更有趣玩家们，并且更准确地确定一致，达到了0.44的平均准确率，比0.28的分类器系统高。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Transformer-Based-Reverse-Dictionary-Model-for-Quality-Estimation-of-Definitions"><a href="#Towards-a-Transformer-Based-Reverse-Dictionary-Model-for-Quality-Estimation-of-Definitions" class="headerlink" title="Towards a Transformer-Based Reverse Dictionary Model for Quality Estimation of Definitions"></a>Towards a Transformer-Based Reverse Dictionary Model for Quality Estimation of Definitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02985">http://arxiv.org/abs/2311.02985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guité-Vinet Julien, Blondin Massé Alexandre, Sadat Fatiha</li>
<li>for: 本文为了比较不同变体的transformer模型在反词典任务中的表现，并explore其在严肃游戏《词典游戏》中的应用。</li>
<li>methods: 本文使用了不同变体的transformer模型，包括基于BERT的Transformer和基于RoBERTa的Transformer，以及一些自定义的模型。</li>
<li>results: 经过实验和分析，本文发现了不同变体的transformer模型在反词典任务中的表现有很大差异，而基于BERT的Transformer和基于RoBERTa的Transformer表现最佳。<details>
<summary>Abstract</summary>
In the last years, several variants of transformers have emerged. In this paper, we compare different transformer-based models for solving the reverse dictionary task and explore their use in the context of a serious game called The Dictionary Game.
</details>
<details>
<summary>摘要</summary>
最近几年，transformer的多种变体出现了。在这篇论文中，我们对reverse dictionary任务使用不同的transformer基本模型进行比较，并在严肃游戏《词典游戏》中explore其用途。Here's a word-for-word translation:最近几年，transformer的多种变体出现了。在这篇论文中，我们对reverse dictionary任务使用不同的transformer基本模型进行比较，并在严肃游戏《词典游戏》中explore其用途。Note that the word "reverse dictionary" is not a standard term in Chinese, so I had to use the phrase "反ictionary任务" (fǎ yì diǎn yè) to convey the same meaning.
</details></li>
</ul>
<hr>
<h2 id="Adapting-Pre-trained-Generative-Models-for-Extractive-Question-Answering"><a href="#Adapting-Pre-trained-Generative-Models-for-Extractive-Question-Answering" class="headerlink" title="Adapting Pre-trained Generative Models for Extractive Question Answering"></a>Adapting Pre-trained Generative Models for Extractive Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02961">http://arxiv.org/abs/2311.02961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prabirmallick/GenAI4EQA">https://github.com/prabirmallick/GenAI4EQA</a></li>
<li>paper_authors: Prabir Mallick, Tapas Nayak, Indrajit Bhattacharya</li>
<li>for: 提高抽取问答（QA）任务中的精度和效率。</li>
<li>methods: 使用预训练的生成模型生成答案相关的索引，以提高答案的找到率和准确率。</li>
<li>results: 在多个抽取QA数据集上，比如MultiSpanQA、BioASQ、MASHQA和WikiQA等，与现有状态的模型相比，提出的方法显示出了更高的性能。<details>
<summary>Abstract</summary>
Pre-trained Generative models such as BART, T5, etc. have gained prominence as a preferred method for text generation in various natural language processing tasks, including abstractive long-form question answering (QA) and summarization. However, the potential of generative models in extractive QA tasks, where discriminative models are commonly employed, remains largely unexplored. Discriminative models often encounter challenges associated with label sparsity, particularly when only a small portion of the context contains the answer. The challenge is more pronounced for multi-span answers. In this work, we introduce a novel approach that uses the power of pre-trained generative models to address extractive QA tasks by generating indexes corresponding to context tokens or sentences that form part of the answer. Through comprehensive evaluations on multiple extractive QA datasets, including MultiSpanQA, BioASQ, MASHQA, and WikiQA, we demonstrate the superior performance of our proposed approach compared to existing state-of-the-art models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PhoGPT-Generative-Pre-training-for-Vietnamese"><a href="#PhoGPT-Generative-Pre-training-for-Vietnamese" class="headerlink" title="PhoGPT: Generative Pre-training for Vietnamese"></a>PhoGPT: Generative Pre-training for Vietnamese</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02945">http://arxiv.org/abs/2311.02945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vinairesearch/phogpt">https://github.com/vinairesearch/phogpt</a></li>
<li>paper_authors: Dat Quoc Nguyen, Linh The Nguyen, Chi Tran, Dung Ngoc Nguyen, Nhung Nguyen, Thien Huu Nguyen, Dinh Phung, Hung Bui</li>
<li>for: 本研究开发了一个新的开源Generative模型系列，名为PhoGPT，用于越南语言。</li>
<li>methods: 这个模型使用了7.5亿个参数，并且包括基础预训练模型PhoGPT-7B5和其指令追踪版本PhoGPT-7B5-Instruct。</li>
<li>results: 该研究透过人类评估实验，证明了PhoGPT的超越前一代开源模型的性能。Here’s the English version of the three key points:</li>
<li>for: This study develops a new open-source generative model series for Vietnamese, named PhoGPT.</li>
<li>methods: The model uses 7.5 billion parameters and includes the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct.</li>
<li>results: The study demonstrates the superior performance of PhoGPT through a human evaluation experiment compared to previous open-source models.<details>
<summary>Abstract</summary>
We open-source a state-of-the-art 7.5B-parameter generative model series named PhoGPT for Vietnamese, which includes the base pre-trained monolingual model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct. In addition, we also demonstrate its superior performance compared to previous open-source models through a human evaluation experiment. GitHub: https://github.com/VinAIResearch/PhoGPT
</details>
<details>
<summary>摘要</summary>
我们开源了一系列当前最佳的7.5亿参数生成模型，名为 PhoGPT，用于越南语言。该系列包括基础预训练单语言模型 PhoGPT-7B5 和其 instruciton-following 变体 PhoGPT-7B5-Instruct。此外，我们还通过人工评估实验表明了它们的性能比前一代开源模型更高。GitHub：https://github.com/VinAIResearch/PhoGPT
</details></li>
</ul>
<hr>
<h2 id="SQLPrompt-In-Context-Text-to-SQL-with-Minimal-Labeled-Data"><a href="#SQLPrompt-In-Context-Text-to-SQL-with-Minimal-Labeled-Data" class="headerlink" title="SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data"></a>SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02883">http://arxiv.org/abs/2311.02883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruoxi Sun, Sercan Ö. Arik, Rajarishi Sinha, Hootan Nakhost, Hanjun Dai, Pengcheng Yin, Tomas Pfister</li>
<li>for: 提高 Text-to-SQL 模型在大型自然语言模型（LLM）上的几个shot提问能力。</li>
<li>methods: 提出了创新的提示设计、执行基于一致性解oding策略和多种提示设计和基础模型（MixPrompt和MixLLMs）来提高 SQL 提问性能。</li>
<li>results: 比前方法在受Context学习中几个shot提问下表现较好，减小了与finetuning state-of-the-art的标准化数据量 gap。<details>
<summary>Abstract</summary>
Text-to-SQL aims to automate the process of generating SQL queries on a database from natural language text. In this work, we propose "SQLPrompt", tailored to improve the few-shot prompting capabilities of Text-to-SQL for Large Language Models (LLMs). Our methods include innovative prompt design, execution-based consistency decoding strategy which selects the SQL with the most consistent execution outcome among other SQL proposals, and a method that aims to improve performance by diversifying the SQL proposals during consistency selection with different prompt designs ("MixPrompt") and foundation models ("MixLLMs"). We show that \emph{SQLPrompt} outperforms previous approaches for in-context learning with few labeled data by a large margin, closing the gap with finetuning state-of-the-art with thousands of labeled data.
</details>
<details>
<summary>摘要</summary>
文本到SQL是一项工作，旨在自动将自然语言文本转换为数据库中的SQL查询。在这项工作中，我们提出了“SQLPrompt”，用于改进大语言模型（LLM）的几个shot提示能力。我们的方法包括创新的提示设计、执行基于一致性解码策略和多种提示设计和基础模型（MixPrompt）以及多种基础模型（MixLLMs）来提高性能。我们证明了，对于少量标注数据进行Context learning，\emph{SQLPrompt}能够大幅超越先前的方法，逐渐追赶到精度调整的状态码。
</details></li>
</ul>
<hr>
<h2 id="Less-than-One-shot-Named-Entity-Recognition-via-Extremely-Weak-Supervision"><a href="#Less-than-One-shot-Named-Entity-Recognition-via-Extremely-Weak-Supervision" class="headerlink" title="Less than One-shot: Named Entity Recognition via Extremely Weak Supervision"></a>Less than One-shot: Named Entity Recognition via Extremely Weak Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02861">http://arxiv.org/abs/2311.02861</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KomeijiForce/X-NER">https://github.com/KomeijiForce/X-NER</a></li>
<li>paper_authors: Letian Peng, Zihan Wang, Jingbo Shang</li>
<li>for: 本文研究了无监督下的命名实体识别（NER）问题，具体来说是使用一个例子实体来监督模型学习。</li>
<li>methods: 我们提出了一种新的X-NER方法，它可以在无监督下超越当前一阶段NER方法的性能。我们首先在无标注训练集中挖掘类似于示例实体的实体 span，然后利用这些 span 作为pseudo-标签来训练 NER 标注器。</li>
<li>results: 我们在四个NER数据集上进行了广泛的实验和分析，发现 X-NER 方法可以在无监督下实现显著的NER性能提升，并且在一些ew-shot环境下超越当前一阶段一shot NER方法。此外，我们发现 X-NER 方法具有跨语言能力。<details>
<summary>Abstract</summary>
We study the named entity recognition (NER) problem under the extremely weak supervision (XWS) setting, where only one example entity per type is given in a context-free way. While one can see that XWS is lighter than one-shot in terms of the amount of supervision, we propose a novel method X-NER that can outperform the state-of-the-art one-shot NER methods. We first mine entity spans that are similar to the example entities from an unlabelled training corpus. Instead of utilizing entity span representations from language models, we find it more effective to compare the context distributions before and after the span is replaced by the entity example. We then leverage the top-ranked spans as pseudo-labels to train an NER tagger. Extensive experiments and analyses on 4 NER datasets show the superior end-to-end NER performance of X-NER, outperforming the state-of-the-art few-shot methods with 1-shot supervision and ChatGPT annotations significantly. Finally, our X-NER possesses several notable properties, such as inheriting the cross-lingual abilities of the underlying language models.
</details>
<details>
<summary>摘要</summary>
我们研究名实体识别（NER）问题在极度轻量级监督（XWS） Setting下，只有一个例子实体每种类型提供在上下文自由的方式。虽然XWS比一遍监督更轻，但我们提议一种新的方法X-NER，可以超越现有的一遍NER方法。我们首先从无标注训练集中挖掘类似于示例实体的实体排版。而不是使用语言模型生成的实体排版表示，我们发现更有效的是比较在替换后的上下文分布和替换前的上下文分布。然后，我们利用排名最高的排版作为pseudo-标签来训练NER标注器。广泛的实验和分析在4个NER数据集上表明，X-NER possess着Superior end-to-end NER性能，超过现有的几个频shot方法和ChatGPT注释。最后，我们的X-NER具有许多值得注意的性能，如继承下来的语言模型的cross-语言能力。
</details></li>
</ul>
<hr>
<h2 id="Improving-Machine-Translation-with-Large-Language-Models-A-Preliminary-Study-with-Cooperative-Decoding"><a href="#Improving-Machine-Translation-with-Large-Language-Models-A-Preliminary-Study-with-Cooperative-Decoding" class="headerlink" title="Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding"></a>Improving Machine Translation with Large Language Models: A Preliminary Study with Cooperative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02851">http://arxiv.org/abs/2311.02851</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lemon0830/CoDec">https://github.com/lemon0830/CoDec</a></li>
<li>paper_authors: Jiali Zeng, Fandong Meng, Yongjing Yin, Jie Zhou</li>
<li>for: 本研究旨在了解LLMs在不同场景下的表现，以及如何使用它们与传统的NMT系统结合以提高翻译质量。</li>
<li>methods: 我们首先进行了一项全面的分析，以评估不同的商业NMT系统和MT-oriented LLMs的优缺点。我们发现， neither NMT nor MT-oriented LLMs alone 可以有效地解决所有翻译问题，但 MT-oriented LLMs 可以作为NMT系统的补充解决方案。</li>
<li>results: 我们的结果表明，CoDec 可以有效地与NMT系统结合，并且在 WMT22 测试集和我们新收集的 WebCrawl 测试集上达到了显著的效果和效率。这 highlights CoDec 的潜在作用性作为一种robust的翻译结合方案。<details>
<summary>Abstract</summary>
Contemporary translation engines built upon the encoder-decoder framework have reached a high level of development, while the emergence of Large Language Models (LLMs) has disrupted their position by offering the potential for achieving superior translation quality. Therefore, it is crucial to understand in which scenarios LLMs outperform traditional NMT systems and how to leverage their strengths. In this paper, we first conduct a comprehensive analysis to assess the strengths and limitations of various commercial NMT systems and MT-oriented LLMs. Our findings indicate that neither NMT nor MT-oriented LLMs alone can effectively address all the translation issues, but MT-oriented LLMs can serve as a promising complement to the NMT systems. Building upon these insights, we explore hybrid methods and propose Cooperative Decoding (CoDec), which treats NMT systems as a pretranslation model and MT-oriented LLMs as a supplemental solution to handle complex scenarios beyond the capability of NMT alone. The results on the WMT22 test sets and a newly collected test set WebCrawl demonstrate the effectiveness and efficiency of CoDec, highlighting its potential as a robust solution for combining NMT systems with MT-oriented LLMs in machine translation.
</details>
<details>
<summary>摘要</summary>
当代翻译引擎基于encoder-decoder框架已经达到了高度的发展，而大语言模型（LLM）的出现则打破了传统翻译系统的位置，提供了可能达到更高的翻译质量。因此，理解LLMs在哪些场景下表现更出色，以及如何利用其优势是关键。在这篇论文中，我们首先进行了全面的分析，评估不同的商业NMT系统和MT-oriented LLMs的优缺点。我们的发现表明， neither NMT nor MT-oriented LLMs 可以单独解决所有翻译问题，但MT-oriented LLMs可以作为NMT系统的补充解决方案。基于这些发现，我们探索了混合方法，并提出了协同解码（CoDec），即将NMT系统作为预翻译模型，MT-oriented LLMs作为NMT系统之外的补充解决方案。WMT22测试集和我们新收集的WebCrawl测试集的结果表明，CoDec是一种有效和高效的解决方案， highlighting its potential as a robust solution for combining NMT systems with MT-oriented LLMs in machine translation.
</details></li>
</ul>
<hr>
<h2 id="Tailoring-Self-Rationalizers-with-Multi-Reward-Distillation"><a href="#Tailoring-Self-Rationalizers-with-Multi-Reward-Distillation" class="headerlink" title="Tailoring Self-Rationalizers with Multi-Reward Distillation"></a>Tailoring Self-Rationalizers with Multi-Reward Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02805">http://arxiv.org/abs/2311.02805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ink-usc/rationalemultirewarddistillation">https://github.com/ink-usc/rationalemultirewarddistillation</a></li>
<li>paper_authors: Sahana Ramnath, Brihi Joshi, Skyler Hallinan, Ximing Lu, Liunian Harold Li, Aaron Chan, Jack Hessel, Yejin Choi, Xiang Ren</li>
<li>for: 本研究旨在使小型语言模型（LM）能够生成有用的自我论证，以帮助问答系统提高问答性能。</li>
<li>methods: 本研究使用的方法是Multi-rewArd RatIOnalization（MaRio）算法，该算法通过多个奖励条件来优化自我论证的多种特性，如可能性、多样性和一致性。</li>
<li>results: 结果表明，MaRio算法不仅能够提高问答任务的准确率，而且还能够提高小LM的自我论证质量，包括可能性、多样性和一致性的评价。人类评价也表明，MaRio的论证比基于精心微调（SFT）的论证更受欢迎和更有优势。<details>
<summary>Abstract</summary>
Large language models (LMs) are capable of generating free-text rationales to aid question answering. However, prior work 1) suggests that useful self-rationalization is emergent only at significant scales (e.g., 175B parameter GPT-3); and 2) focuses largely on downstream performance, ignoring the semantics of the rationales themselves, e.g., are they faithful, true, and helpful for humans? In this work, we enable small-scale LMs (approx. 200x smaller than GPT-3) to generate rationales that not only improve downstream task performance, but are also more plausible, consistent, and diverse, assessed both by automatic and human evaluation. Our method, MaRio (Multi-rewArd RatIOnalization), is a multi-reward conditioned self-rationalization algorithm that optimizes multiple distinct properties like plausibility, diversity and consistency. Results on five difficult question-answering datasets StrategyQA, QuaRel, OpenBookQA, NumerSense and QASC show that not only does MaRio improve task accuracy, but it also improves the self-rationalization quality of small LMs across the aforementioned axes better than a supervised fine-tuning (SFT) baseline. Extensive human evaluations confirm that MaRio rationales are preferred vs. SFT rationales, as well as qualitative improvements in plausibility and consistency.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.CL_2023_11_06/" data-id="cloq1wl3w00e07o888m5r0n81" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/06/cs.AI_2023_11_06/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-11-06
        
      </div>
    </a>
  
  
    <a href="/2023/11/06/cs.LG_2023_11_06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-11-06</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
