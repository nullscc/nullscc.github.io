
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-11-06 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Multimodal Stress Detection Using Facial Landmarks and Biometric Signals paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.03606 repo_url: None paper_authors: Majid Hosseini, Morteza Bodaghi, Ravi Teja Bhupatiraju">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-11-06">
<meta property="og:url" content="https://nullscc.github.io/2023/11/06/cs.AI_2023_11_06/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Multimodal Stress Detection Using Facial Landmarks and Biometric Signals paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.03606 repo_url: None paper_authors: Majid Hosseini, Morteza Bodaghi, Ravi Teja Bhupatiraju">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-06T12:00:00.000Z">
<meta property="article:modified_time" content="2023-11-08T05:49:48.917Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.AI_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T12:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-11-06
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Multimodal-Stress-Detection-Using-Facial-Landmarks-and-Biometric-Signals"><a href="#Multimodal-Stress-Detection-Using-Facial-Landmarks-and-Biometric-Signals" class="headerlink" title="Multimodal Stress Detection Using Facial Landmarks and Biometric Signals"></a>Multimodal Stress Detection Using Facial Landmarks and Biometric Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03606">http://arxiv.org/abs/2311.03606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Majid Hosseini, Morteza Bodaghi, Ravi Teja Bhupatiraju, Anthony Maida, Raju Gottumukkala<br>for: 这种研究旨在提高人们的压力测量和情绪状况的评估，通过结合多种感知技术。methods: 这种研究使用多模态学习方法，结合脸部特征和生物指标信号进行压力检测。results: 研究发现，使用晚期融合技术可以达到94.39%的准确率，而使用早期融合技术可以超越这一成果，达到98.38%的准确率。<details>
<summary>Abstract</summary>
The development of various sensing technologies is improving measurements of stress and the well-being of individuals. Although progress has been made with single signal modalities like wearables and facial emotion recognition, integrating multiple modalities provides a more comprehensive understanding of stress, given that stress manifests differently across different people. Multi-modal learning aims to capitalize on the strength of each modality rather than relying on a single signal. Given the complexity of processing and integrating high-dimensional data from limited subjects, more research is needed. Numerous research efforts have been focused on fusing stress and emotion signals at an early stage, e.g., feature-level fusion using basic machine learning methods and 1D-CNN Methods. This paper proposes a multi-modal learning approach for stress detection that integrates facial landmarks and biometric signals. We test this multi-modal integration with various early-fusion and late-fusion techniques to integrate the 1D-CNN model from biometric signals and 2-D CNN using facial landmarks. We evaluate these architectures using a rigorous test of models' generalizability using the leave-one-subject-out mechanism, i.e., all samples related to a single subject are left out to train the model. Our findings show that late-fusion achieved 94.39\% accuracy, and early-fusion surpassed it with a 98.38\% accuracy rate. This research contributes valuable insights into enhancing stress detection through a multi-modal approach. The proposed research offers important knowledge in improving stress detection using a multi-modal approach.
</details>
<details>
<summary>摘要</summary>
发展不同感知技术是改善人们受 стресса度量和健康状况的度量。虽然在单个信号Modalities like wearables和facial emotion recognition方面已经取得了进步，但是结合多个Modalities可以提供更全面的理解受 стресса，因为受 стресса的表现不同于不同的人。多模态学习旨在利用每个模式的优势而不是仅仅依赖于单个信号。由于处理和整合高维数据的复杂性，更多的研究是必要的。许多研究团队已经专注于将受 стресса和情绪信号在早期结合，例如使用基本机器学习方法和1D-CNN方法进行特征级别的合并。这篇论文提出了一种结合面部特征和生物指标信号的多模态学习方法，并使用不同的早期和晚期结合技术来结合1D-CNN模型和2D-CNN模型。我们使用离卸一个主题的机制进行模型的评估，即所有与一个主题相关的样本都被离卸以训练模型。我们的发现表明，晚期结合达到了94.39%的准确率，而早期结合超过了它，达到98.38%的准确率。这些研究为增强受 стресса检测提供了重要的知识和技术。
</details></li>
</ul>
<hr>
<h2 id="Brief-for-the-Canada-House-of-Commons-Study-on-the-Implications-of-Artificial-Intelligence-Technologies-for-the-Canadian-Labor-Force-Generative-Artificial-Intelligence-Shatters-Models-of-AI-and-Labor"><a href="#Brief-for-the-Canada-House-of-Commons-Study-on-the-Implications-of-Artificial-Intelligence-Technologies-for-the-Canadian-Labor-Force-Generative-Artificial-Intelligence-Shatters-Models-of-AI-and-Labor" class="headerlink" title="Brief for the Canada House of Commons Study on the Implications of Artificial Intelligence Technologies for the Canadian Labor Force: Generative Artificial Intelligence Shatters Models of AI and Labor"></a>Brief for the Canada House of Commons Study on the Implications of Artificial Intelligence Technologies for the Canadian Labor Force: Generative Artificial Intelligence Shatters Models of AI and Labor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03595">http://arxiv.org/abs/2311.03595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morgan R. Frank</li>
<li>for: 探讨当前生产力技术的发展对工作 Market的影响，并提出政策建议以适应未来工作环境。</li>
<li>methods: 利用数据分析和预测技术来研究生产力技术对工作市场的影响，并对现有的自动化预测模型进行批判性分析。</li>
<li>results: 发现生产力技术可能会对一些以前被认为免疫自动化的职业产生影响，政策 makers应该促进工人的职业适应性，并鼓励教育机构开发适应AI技术的教育程序。<details>
<summary>Abstract</summary>
Exciting advances in generative artificial intelligence (AI) have sparked concern for jobs, education, productivity, and the future of work. As with past technologies, generative AI may not lead to mass unemployment. But, unlike past technologies, generative AI is creative, cognitive, and potentially ubiquitous which makes the usual assumptions of automation predictions ill-suited for today. Existing projections suggest that generative AI will impact workers in occupations that were previously considered immune to automation. As AI's full set of capabilities and applications emerge, policy makers should promote workers' career adaptability. This goal requires improved data on job separations and unemployment by locality and job titles in order to identify early-indicators for the workers facing labor disruption. Further, prudent policy should incentivize education programs to accommodate learning with AI as a tool while preparing students for the demands of the future of work.
</details>
<details>
<summary>摘要</summary>
新一代生成人工智能技术的突破性发展，已经引起了关于工作、教育、生产力和未来工作的担忧。与过去的技术不同，生成人工智能可能不会导致大规模的失业。但是，由于生成人工智能的创造性、认知能力和潜在的普遍性，使得传统的自动化预测无法适用于今天。现有的预测表明，生成人工智能将影响工作者，特别是之前被认为是自动化的免疫的职业。为了实现工作者的职业适应能力，政策 makers应该推动工作者的职业适应能力。这个目标需要改进的数据，以了解地域和职业头衔上的失业和职业分裂。此外，安全的政策应该激励教育项目，以便学生通过人工智能为工具，准备未来的工作需求。
</details></li>
</ul>
<hr>
<h2 id="Finding-Increasingly-Large-Extremal-Graphs-with-AlphaZero-and-Tabu-Search"><a href="#Finding-Increasingly-Large-Extremal-Graphs-with-AlphaZero-and-Tabu-Search" class="headerlink" title="Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu Search"></a>Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03583">http://arxiv.org/abs/2311.03583</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abbas Mehrabian, Ankit Anand, Hyunjik Kim, Nicolas Sonnerat, Matej Balog, Gheorghe Comanici, Tudor Berariu, Andrew Lee, Anian Ruoss, Anna Bulanova, Daniel Toyama, Sam Blackwell, Bernardino Romera Paredes, Petar Veličković, Laurent Orseau, Joonkyung Lee, Anurag Murty Naredla, Doina Precup, Adam Zsolt Wagner</li>
<li>for: 这个论文解决了一个中央极点图论题，这个问题是根据1975年erdős的 conjecture，找到一个给定大小的图最多的边数而不包含3-或4-цикル。</li>
<li>methods: 这个论文使用了AlphaZero和tabu搜索两种方法，并通过引入课程来提高state-of-the-art下界。</li>
<li>results: 这个论文通过引入课程和提高搜索策略，提高了几个不同大小的图的下界。此外，这个论文还提出了一种灵活的图生成环境和一种 permutation-invariant的网络架构来学习搜索在图空间中。<details>
<summary>Abstract</summary>
This work studies a central extremal graph theory problem inspired by a 1975 conjecture of Erd\H{o}s, which aims to find graphs with a given size (number of nodes) that maximize the number of edges without having 3- or 4-cycles. We formulate this problem as a sequential decision-making problem and compare AlphaZero, a neural network-guided tree search, with tabu search, a heuristic local search method. Using either method, by introducing a curriculum -- jump-starting the search for larger graphs using good graphs found at smaller sizes -- we improve the state-of-the-art lower bounds for several sizes. We also propose a flexible graph-generation environment and a permutation-invariant network architecture for learning to search in the space of graphs.
</details>
<details>
<summary>摘要</summary>
这项研究探讨了一个中央极点图论问题，源于1975年 Erdős 的 conjecture，该问题目标是找到一个给定大小（节点数）的图，最大化边数而不包含 3-或 4-циклы。我们将这个问题转化为一个顺序决策问题，并与 AlphaZero 和 tabu search 进行比较。通过引入课程（启动搜索大图使用小图中的好图），我们提高了一些尺度的状态前几 bound。我们还提议了一个灵活的图生成环境和一个卷积神经网络架构，用于学习搜索图空间中的搜索。
</details></li>
</ul>
<hr>
<h2 id="Inclusive-Portraits-Race-Aware-Human-in-the-Loop-Technology"><a href="#Inclusive-Portraits-Race-Aware-Human-in-the-Loop-Technology" class="headerlink" title="Inclusive Portraits: Race-Aware Human-in-the-Loop Technology"></a>Inclusive Portraits: Race-Aware Human-in-the-Loop Technology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03567">http://arxiv.org/abs/2311.03567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Claudia Flores-Saviaga, Christopher Curtis, Saiph Savage</li>
<li>for: 这个论文旨在提出一种基于人类社会理论的人 loop系统，以提高自动识别人脸的性能，特别是在服务范围内的人种少数群体。</li>
<li>methods: 该论文提出了一种名为“多元人loop”（Inclusive Portraits，IP）的新方法，通过考虑工作者的个人特点和背景，以提高人 loop系统的性能。</li>
<li>results: 实验结果表明，在 incorporating race into human-in-the-loop (HITL) systems for facial verification 中，可以significantly enhance performance，特别是在服务范围内的人种少数群体。<details>
<summary>Abstract</summary>
AI has revolutionized the processing of various services, including the automatic facial verification of people. Automated approaches have demonstrated their speed and efficiency in verifying a large volume of faces, but they can face challenges when processing content from certain communities, including communities of people of color. This challenge has prompted the adoption of "human-in-the-loop" (HITL) approaches, where human workers collaborate with the AI to minimize errors. However, most HITL approaches do not consider workers' individual characteristics and backgrounds. This paper proposes a new approach, called Inclusive Portraits (IP), that connects with social theories around race to design a racially-aware human-in-the-loop system. Our experiments have provided evidence that incorporating race into human-in-the-loop (HITL) systems for facial verification can significantly enhance performance, especially for services delivered to people of color. Our findings also highlight the importance of considering individual worker characteristics in the design of HITL systems, rather than treating workers as a homogenous group. Our research has significant design implications for developing AI-enhanced services that are more inclusive and equitable.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Low-Rank-MDPs-with-Continuous-Action-Spaces"><a href="#Low-Rank-MDPs-with-Continuous-Action-Spaces" class="headerlink" title="Low-Rank MDPs with Continuous Action Spaces"></a>Low-Rank MDPs with Continuous Action Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03564">http://arxiv.org/abs/2311.03564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Bennett, Nathan Kallus, Miruna Oprescu</li>
<li>for: 本研究旨在探讨如何将低维度马尔可夫决策过程（MDP）中的方法扩展到具有连续动作的场景中。</li>
<li>methods: 本研究使用多种具体的方法来扩展现有的低维度MDP方法，包括将 reward-agnostic 方法应用于连续动作空间中。</li>
<li>results: 研究表明，无需修改FLAMBE算法，在transition函数具有Holder平滑性适应动作的情况下，可以获得类似的PAC证明 bound。Specifically, 当政策类型具有固定最小浓度或奖励函数具有Holder平滑性，我们可以获得一个因次PAC bound，其取决于滑度的次数。<details>
<summary>Abstract</summary>
Low-Rank Markov Decision Processes (MDPs) have recently emerged as a promising framework within the domain of reinforcement learning (RL), as they allow for provably approximately correct (PAC) learning guarantees while also incorporating ML algorithms for representation learning. However, current methods for low-rank MDPs are limited in that they only consider finite action spaces, and give vacuous bounds as $|\mathcal{A}| \to \infty$, which greatly limits their applicability. In this work, we study the problem of extending such methods to settings with continuous actions, and explore multiple concrete approaches for performing this extension. As a case study, we consider the seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic method for PAC RL with low-rank MDPs. We show that, without any modifications to the algorithm, we obtain similar PAC bound when actions are allowed to be continuous. Specifically, when the model for transition functions satisfies a Holder smoothness condition w.r.t. actions, and either the policy class has a uniformly bounded minimum density or the reward function is also Holder smooth, we obtain a polynomial PAC bound that depends on the order of smoothness.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Context-Unlocks-Emotions-Text-based-Emotion-Classification-Dataset-Auditing-with-Large-Language-Models"><a href="#Context-Unlocks-Emotions-Text-based-Emotion-Classification-Dataset-Auditing-with-Large-Language-Models" class="headerlink" title="Context Unlocks Emotions: Text-based Emotion Classification Dataset Auditing with Large Language Models"></a>Context Unlocks Emotions: Text-based Emotion Classification Dataset Auditing with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03551">http://arxiv.org/abs/2311.03551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Yang, Aditya Kommineni, Mohammad Alshehri, Nilamadhab Mohanty, Vedant Modi, Jonathan Gratch, Shrikanth Narayanan</li>
<li>for: 提高文本数据的情感分类模型性能</li>
<li>methods: 使用大语言模型生成文本上的补充信息，提高文本与标签的对齐性</li>
<li>results: 人工和实验评估表明，使用提升的文本上下文可以提高情感分类模型的性能，并且从人工和机器两个角度都得到了证明<details>
<summary>Abstract</summary>
The lack of contextual information in text data can make the annotation process of text-based emotion classification datasets challenging. As a result, such datasets often contain labels that fail to consider all the relevant emotions in the vocabulary. This misalignment between text inputs and labels can degrade the performance of machine learning models trained on top of them. As re-annotating entire datasets is a costly and time-consuming task that cannot be done at scale, we propose to use the expressive capabilities of large language models to synthesize additional context for input text to increase its alignment with the annotated emotional labels. In this work, we propose a formal definition of textual context to motivate a prompting strategy to enhance such contextual information. We provide both human and empirical evaluation to demonstrate the efficacy of the enhanced context. Our method improves alignment between inputs and their human-annotated labels from both an empirical and human-evaluated standpoint.
</details>
<details>
<summary>摘要</summary>
文本数据中缺乏上下文信息可以让文本标注过程变得困难。这导致标注中的情感常常不考虑所有可能的情感词汇。这种对文本输入和标签的不一致可能使机器学习模型基于这些数据进行训练时表现下降。然而，重新标注整个数据集是一项费时费力的任务，不可能在大规模进行。我们提议使用大型自然语言模型来生成更多的上下文信息，以增强输入文本与注释的吻合性。在这篇文章中，我们提出了文本上下文的正式定义，以及一种提高上下文信息的提示策略。我们通过人工和实验评估来证明我们的方法可以提高输入文本和人工注释标签之间的吻合性。
</details></li>
</ul>
<hr>
<h2 id="United-We-Stand-Divided-We-Fall-UnityGraph-for-Unsupervised-Procedure-Learning-from-Videos"><a href="#United-We-Stand-Divided-We-Fall-UnityGraph-for-Unsupervised-Procedure-Learning-from-Videos" class="headerlink" title="United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure Learning from Videos"></a>United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure Learning from Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03550">http://arxiv.org/abs/2311.03550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddhant Bansal, Chetan Arora, C. V. Jawahar</li>
<li>for: 本研究旨在提高存在多个视频 demonstrate 同一个任务时，过程学习方法的效果。</li>
<li>methods: 我们提出了一种无监督图结构学习（GPL）框架，包括一种新的 UnityGraph，可以在多个视频中获取任务的内部和间接上下文。然后，通过不监督的方式更新 UnityGraph 中的嵌入向量，使得同一个键步骤的嵌入向量相似。最后，使用 KMeans 聚类算法来标识键步骤。</li>
<li>results: 我们在 ProceL、CrossTask 和 EgoProceL 等数据集上测试了 GPL，与状态之前的平均提高约 2% 和 3.6%。<details>
<summary>Abstract</summary>
Given multiple videos of the same task, procedure learning addresses identifying the key-steps and determining their order to perform the task. For this purpose, existing approaches use the signal generated from a pair of videos. This makes key-steps discovery challenging as the algorithms lack inter-videos perspective. Instead, we propose an unsupervised Graph-based Procedure Learning (GPL) framework. GPL consists of the novel UnityGraph that represents all the videos of a task as a graph to obtain both intra-video and inter-videos context. Further, to obtain similar embeddings for the same key-steps, the embeddings of UnityGraph are updated in an unsupervised manner using the Node2Vec algorithm. Finally, to identify the key-steps, we cluster the embeddings using KMeans. We test GPL on benchmark ProceL, CrossTask, and EgoProceL datasets and achieve an average improvement of 2% on third-person datasets and 3.6% on EgoProceL over the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate_language: zh-CN<</SYS>>提供多个视频任务的同样任务，程序学习关注发现任务中的关键步骤并确定其执行顺序。现有的方法使用视频对的信号来实现此目的，但这会使关键步骤发现困难，因为算法缺乏间视频视野。我们提出一种无监督图грам学习（GPL）框架。GPL包括一种新的 UnityGraph，它将所有任务视频表示为一个图，以获取任务视频中的内部和间视频上下文。然后，使用Node2Vec算法更新 UnityGraph 中的表示，以获取同样的关键步骤的相似表示。最后，使用 KMeans 聚类算法来确定关键步骤。我们在 ProceL、CrossTask 和 EgoProceL 数据集上测试 GPL，并取得了 average 提升率为 2% 的第三人称数据集和 3.6% 的 EgoProceL 数据集。
</details></li>
</ul>
<hr>
<h2 id="InterVLS-Interactive-Model-Understanding-and-Improvement-with-Vision-Language-Surrogates"><a href="#InterVLS-Interactive-Model-Understanding-and-Improvement-with-Vision-Language-Surrogates" class="headerlink" title="InterVLS: Interactive Model Understanding and Improvement with Vision-Language Surrogates"></a>InterVLS: Interactive Model Understanding and Improvement with Vision-Language Surrogates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03547">http://arxiv.org/abs/2311.03547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbin Huang, Wenbin He, Liang Gou, Liu Ren, Chris Bryan</li>
<li>for: 这个论文主要是为了提高深度学习模型的预部署理解和改进。</li>
<li>methods: 这篇论文使用了视觉概念基于方法，以提高模型的解释性和可读性。</li>
<li>results: 研究表明，InterVLS可以帮助用户更好地理解深度学习模型，了解模型的性能和影响因素，并且可以通过不同的概念影响来改进模型的性能。<details>
<summary>Abstract</summary>
Deep learning models are widely used in critical applications, highlighting the need for pre-deployment model understanding and improvement. Visual concept-based methods, while increasingly used for this purpose, face challenges: (1) most concepts lack interpretability, (2) existing methods require model knowledge, often unavailable at run time. Additionally, (3) there lacks a no-code method for post-understanding model improvement. Addressing these, we present InterVLS. The system facilitates model understanding by discovering text-aligned concepts, measuring their influence with model-agnostic linear surrogates. Employing visual analytics, InterVLS offers concept-based explanations and performance insights. It enables users to adjust concept influences to update a model, facilitating no-code model improvement. We evaluate InterVLS in a user study, illustrating its functionality with two scenarios. Results indicates that InterVLS is effective to help users identify influential concepts to a model, gain insights and adjust concept influence to improve the model. We conclude with a discussion based on our study results.
</details>
<details>
<summary>摘要</summary>
深度学习模型在关键应用中广泛使用，强调模型预部署理解和改进的需求。视觉概念基本方法，虽然在此目的上日益受到使用，但存在困难：（1）大多数概念不可解释，（2）现有方法需要模型知识，经常在运行时不可用，（3）缺乏无代码方法进行后期模型改进。为解决这些问题，我们提出InterVLS。该系统通过发现与文本对齐的概念，使用模型不依赖的直线函数来衡量它们的影响。通过视觉分析，InterVLS提供了基于概念的解释和性能印象。它允许用户根据概念的影响程度进行更新，实现无代码模型改进。我们在用户研究中证明InterVLS的可效性，用两个场景 Illustrates its functionality。结果表明，InterVLS可以帮助用户identify模型中影响力最大的概念，获得印象和更新概念影响以改进模型。我们根据研究结果进行讨论。
</details></li>
</ul>
<hr>
<h2 id="PcLast-Discovering-Plannable-Continuous-Latent-States"><a href="#PcLast-Discovering-Plannable-Continuous-Latent-States" class="headerlink" title="PcLast: Discovering Plannable Continuous Latent States"></a>PcLast: Discovering Plannable Continuous Latent States</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03534">http://arxiv.org/abs/2311.03534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anurag Koul, Shivakanth Sujit, Shaoru Chen, Ben Evans, Lili Wu, Byron Xu, Rajan Chari, Riashat Islam, Raihan Seraj, Yonathan Efroni, Lekan Molu, Miro Dudik, John Langford, Alex Lamb</li>
<li>for: 这个论文旨在提高目标条件规划的效率，通过学习低维度表示来减少高维度观察数据中的干扰信息。</li>
<li>methods: 该论文使用多步反动方程学习latent表示，然后将其转换为在$\ell_2$空间相互关联可达状态的表示。</li>
<li>results: 数据测试结果表明，该方法可以提高奖励基本和奖励自由的样本效率，并生成层次化的状态抽象，以便计算效率高的层次规划。<details>
<summary>Abstract</summary>
Goal-conditioned planning benefits from learned low-dimensional representations of rich, high-dimensional observations. While compact latent representations, typically learned from variational autoencoders or inverse dynamics, enable goal-conditioned planning they ignore state affordances, thus hampering their sample-efficient planning capabilities. In this paper, we learn a representation that associates reachable states together for effective onward planning. We first learn a latent representation with multi-step inverse dynamics (to remove distracting information); and then transform this representation to associate reachable states together in $\ell_2$ space. Our proposals are rigorously tested in various simulation testbeds. Numerical results in reward-based and reward-free settings show significant improvements in sampling efficiency, and yields layered state abstractions that enable computationally efficient hierarchical planning.
</details>
<details>
<summary>摘要</summary>
系统具有目标条件规划的利点，即从学习低维度表示高维度观察数据中得到的低维度表示。然而，通常使用吸引式自动编码器或反动力学学习的紧凑缩写表示，忽略了状态可用性，因此降低了样本效率的规划能力。在这篇论文中，我们学习一个表示，将可达状态相关联在一起，以便有效的规划。我们首先使用多步反动力学学习 latent representation（以除掉干扰信息），然后将其转换为在 $\ell_2$ 空间中相关联可达状态的表示。我们的提议在各种 simulations 中进行了严格的测试，并在奖励基础和奖励自由的设定下获得了显著的样本效率改善和层次规划计算效率。
</details></li>
</ul>
<hr>
<h2 id="Brain-Networks-and-Intelligence-A-Graph-Neural-Network-Based-Approach-to-Resting-State-fMRI-Data"><a href="#Brain-Networks-and-Intelligence-A-Graph-Neural-Network-Based-Approach-to-Resting-State-fMRI-Data" class="headerlink" title="Brain Networks and Intelligence: A Graph Neural Network Based Approach to Resting State fMRI Data"></a>Brain Networks and Intelligence: A Graph Neural Network Based Approach to Resting State fMRI Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03520">http://arxiv.org/abs/2311.03520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bishal Thapaliya, Esra Akbas, Jiayu Chen, Raam Sapkota, Bhaskar Ray, Pranav Suresh, Vince Calhoun, Jingyu Liu</li>
<li>for: 这篇论文旨在研究用resting-state功能磁共振成像（rsfMRI）来探索大脑功能和认知过程之间的关系，并使用图 neural networks 预测智商（流体、晶化和总智商）。</li>
<li>methods: 该论文提出了一种新的模型建立方法，称为BrainRGIN，它使用图 convolutional neural networks 对rsfMRI derive的静态函数网络连接矩阵进行预测。该方法包括嵌入和图同构网络，以及TopK pooling和注意力基于的读取函数。</li>
<li>results: 研究人员使用该模型在大规模数据集上进行了评估，Specifically the Adolescent Brain Cognitive Development Dataset，并证明其在预测个体差异智商方面的有效性。该模型的 Mean squared errors 和相关性指标都比既存的图 arquitectures 和传统机器学习模型更低，并且中前rontal gyri 在流体和晶化智商预测任务中具有显著的贡献。<details>
<summary>Abstract</summary>
Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful tool for investigating the relationship between brain function and cognitive processes as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this paper, we present a novel modeling architecture called BrainRGIN for predicting intelligence (fluid, crystallized, and total intelligence) using graph neural networks on rsfMRI derived static functional network connectivity matrices. Extending from the existing graph convolution networks, our approach incorporates a clustering-based embedding and graph isomorphism network in the graph convolutional layer to reflect the nature of the brain sub-network organization and efficient network expression, in combination with TopK pooling and attention-based readout functions. We evaluated our proposed architecture on a large dataset, specifically the Adolescent Brain Cognitive Development Dataset, and demonstrated its effectiveness in predicting individual differences in intelligence. Our model achieved lower mean squared errors and higher correlation scores than existing relevant graph architectures and other traditional machine learning models for all of the intelligence prediction tasks. The middle frontal gyrus exhibited a significant contribution to both fluid and crystallized intelligence, suggesting their pivotal role in these cognitive processes. Total composite scores identified a diverse set of brain regions to be relevant which underscores the complex nature of total intelligence.
</details>
<details>
<summary>摘要</summary>
《宁静状态功能核磁共振成像（rsfMRI）是一种 poderful tool for investigating the relationship between brain function and cognitive processes, as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this paper, we present a novel modeling architecture called BrainRGIN for predicting intelligence (fluid, crystallized, and total intelligence) using graph neural networks on rsfMRI derived static functional network connectivity matrices. Extending from the existing graph convolution networks, our approach incorporates a clustering-based embedding and graph isomorphism network in the graph convolutional layer to reflect the nature of the brain sub-network organization and efficient network expression, in combination with TopK pooling and attention-based readout functions. We evaluated our proposed architecture on a large dataset, specifically the Adolescent Brain Cognitive Development Dataset, and demonstrated its effectiveness in predicting individual differences in intelligence. Our model achieved lower mean squared errors and higher correlation scores than existing relevant graph architectures and other traditional machine learning models for all of the intelligence prediction tasks. The middle frontal gyrus exhibited a significant contribution to both fluid and crystallized intelligence, suggesting their pivotal role in these cognitive processes. Total composite scores identified a diverse set of brain regions to be relevant, which underscores the complex nature of total intelligence.》Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="MFAAN-Unveiling-Audio-Deepfakes-with-a-Multi-Feature-Authenticity-Network"><a href="#MFAAN-Unveiling-Audio-Deepfakes-with-a-Multi-Feature-Authenticity-Network" class="headerlink" title="MFAAN: Unveiling Audio Deepfakes with a Multi-Feature Authenticity Network"></a>MFAAN: Unveiling Audio Deepfakes with a Multi-Feature Authenticity Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03509">http://arxiv.org/abs/2311.03509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karthik Sivarama Krishnan, Koushik Sivarama Krishnan</li>
<li>for: 防止深伪音频内容的散布，提高信息传递的可靠性。</li>
<li>methods: 利用多种音频表现方式，包括MFCC、LFCC和Chroma-STFT，实现多元特征融合，以提高伪音识别的精度。</li>
<li>results: 在两个 benchmark 数据集上，MFAAN 获得了高度的准确率，分别为98.93% 和 94.47%，说明 MFAAN 的可靠性和应用价值。<details>
<summary>Abstract</summary>
In the contemporary digital age, the proliferation of deepfakes presents a formidable challenge to the sanctity of information dissemination. Audio deepfakes, in particular, can be deceptively realistic, posing significant risks in misinformation campaigns. To address this threat, we introduce the Multi-Feature Audio Authenticity Network (MFAAN), an advanced architecture tailored for the detection of fabricated audio content. MFAAN incorporates multiple parallel paths designed to harness the strengths of different audio representations, including Mel-frequency cepstral coefficients (MFCC), linear-frequency cepstral coefficients (LFCC), and Chroma Short Time Fourier Transform (Chroma-STFT). By synergistically fusing these features, MFAAN achieves a nuanced understanding of audio content, facilitating robust differentiation between genuine and manipulated recordings. Preliminary evaluations of MFAAN on two benchmark datasets, 'In-the-Wild' Audio Deepfake Data and The Fake-or-Real Dataset, demonstrate its superior performance, achieving accuracies of 98.93% and 94.47% respectively. Such results not only underscore the efficacy of MFAAN but also highlight its potential as a pivotal tool in the ongoing battle against deepfake audio content.
</details>
<details>
<summary>摘要</summary>
现代数字时代，深层伪造的普遍存在 pose 信息传递的威胁。特别是音频深层伪造，可能具有极高的真实感，对诡计行动可能带来很大的风险。为解决这一问题，我们介绍了多元特征音频真实性网络（MFAAN），这是一种针对 fabricated 音频内容的检测方法。MFAAN  integrates multiple parallel paths to harness the strengths of different audio representations, including Mel-frequency cepstral coefficients (MFCC), linear-frequency cepstral coefficients (LFCC), and Chroma Short Time Fourier Transform (Chroma-STFT). By synergistically fusing these features, MFAAN achieves a nuanced understanding of audio content, facilitating robust differentiation between genuine and manipulated recordings. 根据我们的初步评估，MFAAN 在 'In-the-Wild' 音频深层伪造数据集和 The Fake-or-Real Dataset 上表现出色，达到了 98.93% 和 94.47% 的准确率。这不仅证明了 MFAAN 的有效性，而且也 highlighted 它作为对深层伪造音频内容的战斗中的重要工具。
</details></li>
</ul>
<hr>
<h2 id="Astrocytes-as-a-mechanism-for-meta-plasticity-and-contextually-guided-network-function"><a href="#Astrocytes-as-a-mechanism-for-meta-plasticity-and-contextually-guided-network-function" class="headerlink" title="Astrocytes as a mechanism for meta-plasticity and contextually-guided network function"></a>Astrocytes as a mechanism for meta-plasticity and contextually-guided network function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03508">http://arxiv.org/abs/2311.03508</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lulu Gong, Fabio Pasqualetti, Thomas Papouin, ShiNung Ching</li>
<li>for: 这个论文探讨了astrocyte在大脑中的作用，以及它们如何帮助神经元学习和适应不同的任务和上下文。</li>
<li>methods: 作者使用了一种基于带宽 reinforcement learning 的方法，以模拟神经元、 synapse 和astrocyte之间的交互，并通过形式分析来描述astrocyte如何影响神经元和synapse的adaptation。</li>
<li>results: 研究发现，在astrocyte参与的情况下，神经元和synapse可以更好地适应不同的任务和上下文，并且可以更快地学习和适应新的任务。这些网络在多变的上下文中也可以更好地保持稳定性和可靠性。<details>
<summary>Abstract</summary>
Astrocytes are a highly expressed and highly enigmatic cell-type in the mammalian brain. Traditionally viewed as a mediator of basic physiological sustenance, it is increasingly recognized that astrocytes may play a more direct role in neural computation. A conceptual challenge to this idea is the fact that astrocytic activity takes a very different form than that of neurons, and in particular, occurs at orders-of-magnitude slower time-scales. In the current paper, we engage how such time-scale separation may endow astrocytes with the capability to enable learning in context-dependent settings, where fluctuations in task parameters may occur much more slowly than within-task requirements. This idea is based on the recent supposition that astrocytes, owing to their sensitivity to a host of physiological covariates, may be particularly well poised to modulate the dynamics of neural circuits in functionally salient ways. We pose a general model of neural-synaptic-astrocyte interaction and use formal analysis to characterize how astrocytic modulation may constitute a form of meta-plasticity, altering the ways in which synapses and neurons adapt as a function of time. We then embed this model in a bandit-based reinforcement learning task environment, and show how the presence of time-scale separated astrocytic modulation enables learning over multiple fluctuating contexts. Indeed, these networks learn far more reliably versus dynamically homogenous networks and conventional non-network-based bandit algorithms. Our results indicate how the presence of neural-astrocyte interaction in the brain may benefit learning over different time-scale and the conveyance of task relevant contextual information onto circuit dynamics.
</details>
<details>
<summary>摘要</summary>
astrocytes是大脑中高度表达和高度enigmatic的细胞类型。传统上视为基本生理机能的调节剂，但现在越来越认为astrocytes可能直接参与神经计算。一个概念上的挑战是astrocytic activity的形式和神经元活动有着很大的不同，尤其是时间尺度上的差异。在当前的论文中，我们考虑如何这种时间尺度差异可能为astrocytes提供了可以实现学习的能力。这种想法基于astrocytes敏感于多种生理因素的假设，因此可以通过调节神经细胞动力学来修改神经细胞的动力学。我们提出了神经细胞- synapse-astrocyte交互的总模型，并使用正式分析来描述如何astrocytic modulation可能是一种形式的meta-plasticity，改变神经细胞和 synapse在时间上的适应。然后，我们将这个模型嵌入一个bandit-based reinforcement learning任务环境中，并显示了在多个随机变化的上下文中，astrocyte-modulated neural network可以更可靠地学习。实际上，这些网络在不同的时间尺度和传统的非网络基本算法下都学习得更好。我们的结果表明，在大脑中astrocyte-神经元交互的存在可以提高学习的可靠性和将任务相关的上下文信息传递到神经细胞动力学中。
</details></li>
</ul>
<hr>
<h2 id="Multi-Resolution-Diffusion-for-Privacy-Sensitive-Recommender-Systems"><a href="#Multi-Resolution-Diffusion-for-Privacy-Sensitive-Recommender-Systems" class="headerlink" title="Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems"></a>Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03488">http://arxiv.org/abs/2311.03488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derek Lilienthal, Paul Mello, Magdalini Eirinaki, Stas Tiomkin</li>
<li>for: The paper is written for recommender systems that rely on user data, addressing privacy and security concerns by substituting user data with synthetic data.</li>
<li>methods: The paper introduces a Score-based Diffusion Recommendation Model (SDRM) that uses diffusion models to generate realistic data, capturing intricate patterns in real-world datasets.</li>
<li>results: The paper shows that SDRM outperforms competing baselines in synthesizing various datasets to replace or augment the original data, achieving an average improvement of 4.30% in Recall@$n$ and 4.65% in NDCG@$n$.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文是为了帮助推荐系统，解决它们依赖用户数据的隐私和安全问题。</li>
<li>methods: 这篇论文提出了一种基于扩散模型的分数基于扩散建议模型（SDRM），可以生成真实的数据，捕捉实际世界数据中的复杂模式。</li>
<li>results: 论文表明，SDRM比基本方法（如生成对抗网络、变量自适应网络和最近提出的扩散模型）在生成不同类型的数据来代替或补充原始数据时，平均提高4.30%的Recall@$n$和4.65%的NDCG@$n$。<details>
<summary>Abstract</summary>
While recommender systems have become an integral component of the Web experience, their heavy reliance on user data raises privacy and security concerns. Substituting user data with synthetic data can address these concerns, but accurately replicating these real-world datasets has been a notoriously challenging problem. Recent advancements in generative AI have demonstrated the impressive capabilities of diffusion models in generating realistic data across various domains. In this work we introduce a Score-based Diffusion Recommendation Model (SDRM), which captures the intricate patterns of real-world datasets required for training highly accurate recommender systems. SDRM allows for the generation of synthetic data that can replace existing datasets to preserve user privacy, or augment existing datasets to address excessive data sparsity. Our method outperforms competing baselines such as generative adversarial networks, variational autoencoders, and recently proposed diffusion models in synthesizing various datasets to replace or augment the original data by an average improvement of 4.30% in Recall@$n$ and 4.65% in NDCG@$n$.
</details>
<details>
<summary>摘要</summary>
“优化推荐系统的数据使用问题”While recommender systems have become an integral component of the Web experience, their heavy reliance on user data raises privacy and security concerns. Substituting user data with synthetic data can address these concerns, but accurately replicating these real-world datasets has been a notoriously challenging problem. Recent advancements in generative AI have demonstrated the impressive capabilities of diffusion models in generating realistic data across various domains. In this work we introduce a Score-based Diffusion Recommendation Model (SDRM), which captures the intricate patterns of real-world datasets required for training highly accurate recommender systems. SDRM allows for the generation of synthetic data that can replace existing datasets to preserve user privacy, or augment existing datasets to address excessive data sparsity. Our method outperforms competing baselines such as generative adversarial networks, variational autoencoders, and recently proposed diffusion models in synthesizing various datasets to replace or augment the original data by an average improvement of 4.30% in Recall@$n$ and 4.65% in NDCG@$n$.
</details></li>
</ul>
<hr>
<h2 id="CLIP-Motion-Learning-Reward-Functions-for-Robotic-Actions-Using-Consecutive-Observations"><a href="#CLIP-Motion-Learning-Reward-Functions-for-Robotic-Actions-Using-Consecutive-Observations" class="headerlink" title="CLIP-Motion: Learning Reward Functions for Robotic Actions Using Consecutive Observations"></a>CLIP-Motion: Learning Reward Functions for Robotic Actions Using Consecutive Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03485">http://arxiv.org/abs/2311.03485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuzhe Dang, Stefan Edelkamp, Nicolas Ribault</li>
<li>for: 本研究目的是开发一种基于 CLIP 模型的奖励函数学习方法，以解决传统奖励函数设计 often 需要人工特征工程化，可能难以泛化到多种任务。</li>
<li>methods: 本研究使用 CLIP 模型处理 Both 状态特征和图像输入，并能够准确地识别 consecutive 观察到的动作。</li>
<li>results: 经过实验评估，我们的方法在多种 роботикс 活动中表现出色，如指定目标物品的夹取和立方体的位置调整。结果表明，我们的方法可以准确地推断动作并在 robotics 领域中提高奖励学习训练的效果。<details>
<summary>Abstract</summary>
This paper presents a novel method for learning reward functions for robotic motions by harnessing the power of a CLIP-based model. Traditional reward function design often hinges on manual feature engineering, which can struggle to generalize across an array of tasks. Our approach circumvents this challenge by capitalizing on CLIP's capability to process both state features and image inputs effectively. Given a pair of consecutive observations, our model excels in identifying the motion executed between them. We showcase results spanning various robotic activities, such as directing a gripper to a designated target and adjusting the position of a cube. Through experimental evaluations, we underline the proficiency of our method in precisely deducing motion and its promise to enhance reinforcement learning training in the realm of robotics.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的方法，用于通过 CLIP 模型学习 robotic 动作奖励函数。传统的奖励函数设计经常遇到人工特征工程化的挑战，这可以困难泛化到多种任务上。我们的方法强调使用 CLIP 模型处理 Both state 特征和图像输入，从而缺乏特征工程化的需求。给定两个连续的观察结果，我们的模型能够有效地识别执行的动作。我们在不同的 robotic 活动中，如指定目标上的夹子和立方体的位置调整，展示了我们的方法的精度和其在 robotics 领域的应用潜力。通过实验评估，我们证明了我们的方法在 precisely 推理动作和提高 reinforcement learning 训练中的潜在价值。
</details></li>
</ul>
<hr>
<h2 id="Multi-Loss-based-Feature-Fusion-and-Top-Two-Voting-Ensemble-Decision-Strategy-for-Facial-Expression-Recognition-in-the-Wild"><a href="#Multi-Loss-based-Feature-Fusion-and-Top-Two-Voting-Ensemble-Decision-Strategy-for-Facial-Expression-Recognition-in-the-Wild" class="headerlink" title="Multi Loss-based Feature Fusion and Top Two Voting Ensemble Decision Strategy for Facial Expression Recognition in the Wild"></a>Multi Loss-based Feature Fusion and Top Two Voting Ensemble Decision Strategy for Facial Expression Recognition in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03478">http://arxiv.org/abs/2311.03478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyao Zhou, Yuanlun Xie, Wenhong Tian</li>
<li>for: 这个论文旨在提高人脸表达识别（FER）在野外的性能，并不同于前期研究，这篇论文同时应用内部特征合并和多个网络的特征合并，以及ensemble策略。</li>
<li>methods: 这篇论文提出了一个新的单个模型named R18+FAML，以及一个ensemble模型named R18+FAML-FGA-T2V，以提高FER在野外的性能。R18+FAML使用内部特征合并和多个损失函数（FAML）来提高特征EXTRACTION的多样性。为了提高R18+FAML的性能，我们提出了一种基于遗传算法的特征合并方法（FGA），可以将多个网络的 convolution核心进行特征EXTRACTION。基于R18+FAML和FGA，我们提出了一种ensemble策略，即Top Two Voting（T2V），以便对FER进行分类。</li>
<li>results: 我们的单个模型R18+FAML和ensemble模型R18+FAML-FGA-T2V在三个挑战性的FER数据集RAF-DB、AffectNet-8和AffectNet-7上实现了($90.32%$, $62.17%$, $65.83%$)和($91.59%$, $63.27%$, $66.63%$)的准确率，均高于当前最佳结果。<details>
<summary>Abstract</summary>
Facial expression recognition (FER) in the wild is a challenging task affected by the image quality and has attracted broad interest in computer vision. There is no research using feature fusion and ensemble strategy for FER simultaneously. Different from previous studies, this paper applies both internal feature fusion for a single model and feature fusion among multiple networks, as well as the ensemble strategy. This paper proposes one novel single model named R18+FAML, as well as one ensemble model named R18+FAML-FGA-T2V to improve the performance of the FER in the wild. Based on the structure of ResNet18 (R18), R18+FAML combines internal Feature fusion and three Attention blocks using Multiple Loss functions (FAML) to improve the diversity of the feature extraction. To improve the performance of R18+FAML, we propose a Feature fusion among networks based on the Genetic Algorithm (FGA), which can fuse the convolution kernels for feature extraction of multiple networks. On the basis of R18+FAML and FGA, we propose one ensemble strategy, i.e., the Top Two Voting (T2V) to support the classification of FER, which can consider more classification information comprehensively. Combining the above strategies, R18+FAML-FGA-T2V can focus on the main expression-aware areas. Extensive experiments demonstrate that our single model R18+FAML and the ensemble model R18+FAML-FGA-T2V achieve the accuracies of $\left( 90.32, 62.17, 65.83 \right)\%$ and $\left( 91.59, 63.27, 66.63 \right)\%$ on three challenging unbalanced FER datasets RAF-DB, AffectNet-8 and AffectNet-7 respectively, both outperforming the state-of-the-art results.
</details>
<details>
<summary>摘要</summary>
“人脸表情识别（FER）在野外是一个具有图像质量的挑战，吸引了计算机视觉领域广泛的研究。 existing studies have not explored the use of feature fusion and ensemble strategies for FER simultaneously. 本研究提出了一种新的单模型名为R18+FAML，以及一种ensemble模型名为R18+FAML-FGA-T2V，以提高FER的性能。 R18+FAML通过内部Feature fusion和三个Attention块使用多种损失函数（FAML）来提高特征提取的多样性。为了进一步提高R18+FAML的性能，我们提出了一种基于遗传算法的Feature fusion among networks（FGA），可以将多个网络的 convolution kernel进行特征提取。基于R18+FAML和FGA，我们提出了一种ensemble策略，即Top Two Voting（T2V），可以将多个网络的分类信息进行权衡考虑。结合以上策略，R18+FAML-FGA-T2V可以更好地关注主要表情意识区域。EXTENSIVE experiments demonstrate that our single model R18+FAML and the ensemble model R18+FAML-FGA-T2V achieve the accuracies of $\left( 90.32, 62.17, 65.83 \right)\%$ and $\left( 91.59, 63.27, 66.63 \right)\%$ on three challenging unbalanced FER datasets RAF-DB, AffectNet-8 and AffectNet-7 respectively, both outperforming the state-of-the-art results.”Note that the translation is done using Google Translate, and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="FinA-Fairness-of-Adverse-Effects-in-Decision-Making-of-Human-Cyber-Physical-System"><a href="#FinA-Fairness-of-Adverse-Effects-in-Decision-Making-of-Human-Cyber-Physical-System" class="headerlink" title="FinA: Fairness of Adverse Effects in Decision-Making of Human-Cyber-Physical-System"></a>FinA: Fairness of Adverse Effects in Decision-Making of Human-Cyber-Physical-System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03468">http://arxiv.org/abs/2311.03468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyu Zhao, Salma Elmalaki</li>
<li>for: 这篇论文的目的是解决人类-人工-物理系统（HCPS）中的公平问题，特别是当不同个体、每个人有不同的行为和期望时，在同一个应用空间中受到共同的控制动作影响。</li>
<li>methods: 这篇论文使用了一个具有多元性和动态性的公平模型，考虑了人类行为的变化和不断改善的偏好，并认可了长期的影响。</li>
<li>results: 这篇论文的评估结果显示，在智能家居应用中运用了“公平在不良影响”（FinA）方法后，个体对公平的整体感受得到了明显提高，比较前一代方法的提高率为66.7%。<details>
<summary>Abstract</summary>
Ensuring fairness in decision-making systems within Human-Cyber-Physical-Systems (HCPS) is a pressing concern, particularly when diverse individuals, each with varying behaviors and expectations, coexist within the same application space, influenced by a shared set of control actions in the system. The long-term adverse effects of these actions further pose the challenge, as historical experiences and interactions shape individual perceptions of fairness. This paper addresses the challenge of fairness from an equity perspective of adverse effects, taking into account the dynamic nature of human behavior and evolving preferences while recognizing the lasting impact of adverse effects. We formally introduce the concept of Fairness-in-Adverse-Effects (FinA) within the HCPS context. We put forth a comprehensive set of five formulations for FinA, encompassing both the instantaneous and long-term aspects of adverse effects. To empirically validate the effectiveness of our FinA approach, we conducted an evaluation within the domain of smart homes, a pertinent HCPS application. The outcomes of our evaluation demonstrate that the adoption of FinA significantly enhances the overall perception of fairness among individuals, yielding an average improvement of 66.7% when compared to the state-of-the-art method.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: Ensuring fairness in decision-making systems within Human-Cyber-Physical-Systems (HCPS) is a pressing concern, particularly when diverse individuals, each with varying behaviors and expectations, coexist within the same application space, influenced by a shared set of control actions in the system. The long-term adverse effects of these actions further pose the challenge, as historical experiences and interactions shape individual perceptions of fairness. This paper addresses the challenge of fairness from an equity perspective of adverse effects, taking into account the dynamic nature of human behavior and evolving preferences while recognizing the lasting impact of adverse effects. We formally introduce the concept of Fairness-in-Adverse-Effects (FinA) within the HCPS context. We put forth a comprehensive set of five formulations for FinA, encompassing both the instantaneous and long-term aspects of adverse effects. To empirically validate the effectiveness of our FinA approach, we conducted an evaluation within the domain of smart homes, a pertinent HCPS application. The outcomes of our evaluation demonstrate that the adoption of FinA significantly enhances the overall perception of fairness among individuals, yielding an average improvement of 66.7% when compared to the state-of-the-art method.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Exploitation-Guided-Exploration-for-Semantic-Embodied-Navigation"><a href="#Exploitation-Guided-Exploration-for-Semantic-Embodied-Navigation" class="headerlink" title="Exploitation-Guided Exploration for Semantic Embodied Navigation"></a>Exploitation-Guided Exploration for Semantic Embodied Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03357">http://arxiv.org/abs/2311.03357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Justin Wasserman, Girish Chowdhary, Abhinav Gupta, Unnat Jain</li>
<li>for: 本研究旨在实现模块化策略的可靠性和效率，通过将探索和利用分类为不同模块，并透过导师强制探索模块来优化探索策略。</li>
<li>methods: 本研究提出了具有实际导师强制的探索导向策略（XGX），具体包括将探索和利用分类为不同模块，并将探索模块强制遵循导师的指导。</li>
<li>results: 在 object navigation 任务上，XGX 可以从 70% 提高到 73%，同时也提高了目标分析中的精度和效率。此外，XGX 还可以在实际机器人硬件上进行适应和转移。<details>
<summary>Abstract</summary>
In the recent progress in embodied navigation and sim-to-robot transfer, modular policies have emerged as a de facto framework. However, there is more to compositionality beyond the decomposition of the learning load into modular components. In this work, we investigate a principled way to syntactically combine these components. Particularly, we propose Exploitation-Guided Exploration (XGX) where separate modules for exploration and exploitation come together in a novel and intuitive manner. We configure the exploitation module to take over in the deterministic final steps of navigation i.e. when the goal becomes visible. Crucially, an exploitation module teacher-forces the exploration module and continues driving an overridden policy optimization. XGX, with effective decomposition and novel guidance, improves the state-of-the-art performance on the challenging object navigation task from 70% to 73%. Along with better accuracy, through targeted analysis, we show that XGX is also more efficient at goal-conditioned exploration. Finally, we show sim-to-real transfer to robot hardware and XGX performs over two-fold better than the best baseline from simulation benchmarking. Project page: xgxvisnav.github.io
</details>
<details>
<summary>摘要</summary>
最近的具体 Navigation 和 sim-to-robot 传输进步中，模块化策略emerged as a de facto framework。然而，有更多的composability beyond the decomposition of the learning load into modular components。在这项工作中，我们investigate a principled way to syntactically combine these components。特别是，我们提出了Exploitation-Guided Exploration (XGX)，它们是novel and intuitive manner。我们将探索模块与目标配置在一起，使得策略优化更加稳定。XGX通过有效的分解和新的导航，提高了对难 Navigation 任务的性能从70%提高到73%。此外，我们通过targeted analysis表明，XGX也更有效果地进行目标 Conditioned exploration。最后，我们在硬件Robot上进行了 sim-to-real 传输，XGX相比baseline的最好值，在实际中表现出了两倍的性能提升。项目页面：xgxvisnav.github.io
</details></li>
</ul>
<hr>
<h2 id="SegGen-Supercharging-Segmentation-Models-with-Text2Mask-and-Mask2Img-Synthesis"><a href="#SegGen-Supercharging-Segmentation-Models-with-Text2Mask-and-Mask2Img-Synthesis" class="headerlink" title="SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis"></a>SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03355">http://arxiv.org/abs/2311.03355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prismformore/seggen">https://github.com/prismformore/seggen</a></li>
<li>paper_authors: Hanrong Ye, Jason Kuen, Qing Liu, Zhe Lin, Brian Price, Dan Xu</li>
<li>For: 提高图像分割模型的性能，特别是在 semantic segmentation、panoptic segmentation 和 instance segmentation 领域。* Methods: 提出了一种名为 SegGen 的高效训练数据生成方法，包括两个数据生成策略：MaskSyn 和 ImgSyn。MaskSyn 通过提出的文本到mask生成模型和mask到图像生成模型来生成新的mask-image对，大幅提高了分割mask的多样性；ImgSyn 使用 existed masks 生成新的图像，强化了图像的多样性。* Results: 在 ADE20K 和 COCO  bencmarks 上，SegGen 对 state-of-the-art 图像分割模型进行了明显的性能提升，包括 semantic segmentation、panoptic segmentation 和 instance segmentation。特别是在 ADE20K mIoU 上，Mask2Former R50 的性能从 47.2 提高到 49.9 (+2.7)，Mask2Former Swin-L 的性能也从 56.1 提高到 57.4 (+1.3)。这些出色的结果表明 SegGen 在训练时使用人工标注数据的情况下具有高效性。此外，使用我们的 sintetic data 进行训练，使得分割模型对不seen domains 变得更加Robust。<details>
<summary>Abstract</summary>
We propose SegGen, a highly-effective training data generation method for image segmentation, which pushes the performance limits of state-of-the-art segmentation models to a significant extent. SegGen designs and integrates two data generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new mask-image pairs via our proposed text-to-mask generation model and mask-to-image generation model, greatly improving the diversity in segmentation masks for model supervision; (ii) ImgSyn synthesizes new images based on existing masks using the mask-to-image generation model, strongly improving image diversity for model inputs. On the highly competitive ADE20K and COCO benchmarks, our data generation method markedly improves the performance of state-of-the-art segmentation models in semantic segmentation, panoptic segmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU, Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L is also significantly increased from 56.1 to 57.4 (+1.3). These promising results strongly suggest the effectiveness of our SegGen even when abundant human-annotated training data is utilized. Moreover, training with our synthetic data makes the segmentation models more robust towards unseen domains. Project website: https://seggenerator.github.io
</details>
<details>
<summary>摘要</summary>
我们提出SegGen，一种高效训练数据生成方法 для图像分割，可以大幅提高现有状态最佳分割模型的性能。SegGen设计并结合了两种数据生成策略：MaskSyn和ImgSyn。（一）MaskSyn通过我们提出的文本到mask生成模型和mask到图像生成模型来增加分割mask的多样性，以便对模型进行超级visdom；（二）ImgSyn使用现有mask生成新图像，从而强化图像的多样性，为模型输入提供更多的多样性。在ADE20K和COCObenchmark上，我们的数据生成方法明显提高了现有状态最佳分割模型的性能，包括semantic segmentation、panoptic segmentation和instance segmentation。特别是在ADE20K mIoU上，Mask2Former R50从47.2提高到49.9（+2.7），Mask2Former Swin-L也从56.1提高到57.4（+1.3）。这些优秀的结果表明我们的SegGen在有 suffcient human-annotated训练数据的情况下也能够达到高效的性能。此外，使用我们的生成数据训练分割模型可以使其更加鲁棒地处理未看过的领域。项目网站：https://seggenerator.github.io
</details></li>
</ul>
<hr>
<h2 id="GLaMM-Pixel-Grounding-Large-Multimodal-Model"><a href="#GLaMM-Pixel-Grounding-Large-Multimodal-Model" class="headerlink" title="GLaMM: Pixel Grounding Large Multimodal Model"></a>GLaMM: Pixel Grounding Large Multimodal Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03356">http://arxiv.org/abs/2311.03356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanoona Rasheed, Muhammad Maaz, Sahal Shaji, Abdelrahman Shaker, Salman Khan, Hisham Cholakkal, Rao M. Anwer, Erix Xing, Ming-Hsuan Yang, Fahad S. Khan<br>for:GLaMM is designed to generate natural language responses that are seamlessly intertwined with corresponding object segmentation masks, allowing for visually grounded conversations.methods:GLaMM uses region-level Large Multimodal Models (LMMs) and a comprehensive evaluation protocol to generate densely grounded conversations. The model is flexible and can accept both textual and visual prompts as input.results:GLaMM achieves state-of-the-art performance on the Grounded Conversation Generation (GCG) task and several downstream tasks, such as referring expression segmentation, image and region-level captioning, and vision-language conversations. The model is able to generate visually grounded responses that are flexible and can be interacted with at various levels of granularity.<details>
<summary>Abstract</summary>
Large Multimodal Models (LMMs) extend Large Language Models to the vision domain. Initial efforts towards LMMs used holistic images and text prompts to generate ungrounded textual responses. Very recently, region-level LMMs have been used to generate visually grounded responses. However, they are limited to only referring a single object category at a time, require users to specify the regions in inputs, or cannot offer dense pixel-wise object grounding. In this work, we present Grounding LMM (GLaMM), the first model that can generate natural language responses seamlessly intertwined with corresponding object segmentation masks. GLaMM not only grounds objects appearing in the conversations but is flexible enough to accept both textual and optional visual prompts (region of interest) as input. This empowers users to interact with the model at various levels of granularity, both in textual and visual domains. Due to the lack of standard benchmarks for the novel setting of generating visually grounded detailed conversations, we introduce a comprehensive evaluation protocol with our curated grounded conversations. Our proposed Grounded Conversation Generation (GCG) task requires densely grounded concepts in natural scenes at a large-scale. To this end, we propose a densely annotated Grounding-anything Dataset (GranD) using our proposed automated annotation pipeline that encompasses 7.5M unique concepts grounded in a total of 810M regions available with segmentation masks. Besides GCG, GLaMM also performs effectively on several downstream tasks e.g., referring expression segmentation, image and region-level captioning and vision-language conversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.
</details>
<details>
<summary>摘要</summary>
大型多Modal模型（LMM）扩展了大型语言模型到视觉领域。初期尝试中使用整体图像和文本提示来生成未经定义的文本响应。在最近的几年中，区域级LMM被用来生成相对定义的响应。然而，它们只能同时引用一个对象类型，需要用户在输入中指定区域，或者无法提供密集像素粒度的对象定位。在这项工作中，我们提出了基于语言模型的对象定位模型（GLaMM），可以生成与对应的语言响应同时包含对象分割mask。GLaMM不仅可以在对话中引用出现的对象，还可以接受文本和可选的视觉提示（区域兴趣点）作为输入，这使得用户可以在文本和视觉领域之间进行交互，并且可以在不同的粒度水平上与模型进行交互。由于没有适用于这种新的设定下生成视觉定义的标准评价准则，我们提出了一种完整的评价协议，并使用我们自己的筛选和标注过程制定了一个大规模的Grounding-anything数据集（GranD），包含7.5万个特定的概念在自然场景中的密集定位。此外，GLaMM还在多个下游任务上表现出色，如图像和区域级captioning、视觉语言对话等。项目页面：https://mbzuai-oryx.github.io/groundingLMM。
</details></li>
</ul>
<hr>
<h2 id="Scalable-and-Transferable-Black-Box-Jailbreaks-for-Language-Models-via-Persona-Modulation"><a href="#Scalable-and-Transferable-Black-Box-Jailbreaks-for-Language-Models-via-Persona-Modulation" class="headerlink" title="Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation"></a>Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03348">http://arxiv.org/abs/2311.03348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rusheb Shah, Quentin Feuillade–Montixi, Soroush Pour, Arush Tagade, Stephen Casper, Javier Rando</li>
<li>for: This paper is written to investigate the vulnerability of large language models to jailbreak prompts and to demonstrate a black-box jailbreaking method using persona modulation.</li>
<li>methods: The paper uses a language model assistant to automate the generation of jailbreaks and demonstrates the effectiveness of persona modulation in achieving harmful completions.</li>
<li>results: The paper shows that persona modulation can achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation. The prompts also transfer to other commercial language models, such as Claude 2 and Vicuna, with high harmful completion rates.<details>
<summary>Abstract</summary>
Despite efforts to align large language models to produce harmless responses, they are still vulnerable to jailbreak prompts that elicit unrestricted behaviour. In this work, we investigate persona modulation as a black-box jailbreaking method to steer a target model to take on personalities that are willing to comply with harmful instructions. Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant. We demonstrate a range of harmful completions made possible by persona modulation, including detailed instructions for synthesising methamphetamine, building a bomb, and laundering money. These automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation (0.23%). These prompts also transfer to Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%, respectively. Our work reveals yet another vulnerability in commercial large language models and highlights the need for more comprehensive safeguards.
</details>
<details>
<summary>摘要</summary>
尽管努力对大型语言模型进行安全调整，它们仍然易受到破坏指令的攻击。在这项工作中，我们调查人格模式修饰作为黑盒破坏方法，以让目标模型采取愿意遵从危险指令的个性。而不是手动制作每个人格的提示，我们自动生成破坏，使用语言模型助手。我们示例了由人格修饰带来的危险完成，包括合成甲基酸酯、制造炸弹和洗钱等详细指令。这些自动攻击的危险完成率为GPT-4的42.5%，比之前修饰前的0.23%高185倍。这些提示还传递到Claude 2和Vicuna，它们的危险完成率分别为61.0%和35.9%。我们的工作揭示了商业大型语言模型又一处漏洞，并高亮了更加全面的安全保障的需要。
</details></li>
</ul>
<hr>
<h2 id="Embedding-First-Order-Logic-into-Kernel-Machines"><a href="#Embedding-First-Order-Logic-into-Kernel-Machines" class="headerlink" title="Embedding First Order Logic into Kernel Machines"></a>Embedding First Order Logic into Kernel Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03340">http://arxiv.org/abs/2311.03340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michelangelo Diligenti, Marco Gori, Marco Maggini, Leonardo Rigutini</li>
<li>for:  Integrating supervised and unsupervised examples with background knowledge expressed by a collection of first-order logic clauses into kernel machines.</li>
<li>methods:  Multi-task learning scheme that jointly learns multiple predicates defined on a set of objects, enforcing FOL constraints on the admissible configurations of their values.</li>
<li>results:  A general approach to convert FOL clauses into a continuous implementation that can deal with the outputs computed by kernel-based predicates, and a two-stage learning schema to avoid poor solutions.<details>
<summary>Abstract</summary>
In this paper we propose a general framework to integrate supervised and unsupervised examples with background knowledge expressed by a collection of first-order logic clauses into kernel machines. In particular, we consider a multi-task learning scheme where multiple predicates defined on a set of objects are to be jointly learned from examples, enforcing a set of FOL constraints on the admissible configurations of their values. The predicates are defined on the feature spaces, in which the input objects are represented, and can be either known a priori or approximated by an appropriate kernel-based learner. A general approach is presented to convert the FOL clauses into a continuous implementation that can deal with the outputs computed by the kernel-based predicates. The learning problem is formulated as a semi-supervised task that requires the optimization in the primal of a loss function that combines a fitting loss measure on the supervised examples, a regularization term, and a penalty term that enforces the constraints on both the supervised and unsupervised examples. Unfortunately, the penalty term is not convex and it can hinder the optimization process. However, it is possible to avoid poor solutions by using a two stage learning schema, in which the supervised examples are learned first and then the constraints are enforced.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种通用框架，用于将监督和无监督示例和背景知识表示为一 colección of first-order logic clauses integrate into kernel machines。特别是，我们考虑了一种多任务学习方案，其中多个PredicateDefined on a set of objects是要同时学习从示例中，并且要满足一些 FOL 约束。这些Predicate可以是知道的或者通过适当的 kernel-based learner来approximation。我们提出了一种通用的方法，将 FOL 条件转换成可以处理 kernel-based predicates 的连续实现。学习问题被表述为一种半监督学习问题，其中需要优化 primal 中的损失函数，该损失函数组合监督示例中的适应损失、规范项和约束项。可惜的是，约束项不是凸函数，可能会阻碍优化过程。然而，可以使用 two-stage 学习 schema，先学习监督示例，然后强制执行约束。
</details></li>
</ul>
<hr>
<h2 id="ProPath-Disease-Specific-Protein-Language-Model-for-Variant-Pathogenicity"><a href="#ProPath-Disease-Specific-Protein-Language-Model-for-Variant-Pathogenicity" class="headerlink" title="ProPath: Disease-Specific Protein Language Model for Variant Pathogenicity"></a>ProPath: Disease-Specific Protein Language Model for Variant Pathogenicity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03429">http://arxiv.org/abs/2311.03429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huixin Zhan, Zijun, Zhang</li>
<li>for: 预测疾病相关的遗传变异是现代生物医学中的一项重要挑战。</li>
<li>methods: 我们提出了一种疾病特定的蛋白语言模型，即ProPath，以估计罕见missense变异中的pseudo-log-likelihood比率。我们使用了一个siamese网络来捕捉这种比率。</li>
<li>results: 我们的结果表明，ProPath比预先训练的ESM1b提高了超过5%的AUC，在遗传心肌病和心Rate病中的临床变异集合上。此外，我们的模型在所有基线上都达到了最高表现。因此，我们的ProPath可以提供高精度的疾病特定变异效应预测，特别有价值于疾病关联和临床应用。<details>
<summary>Abstract</summary>
Clinical variant classification of pathogenic versus benign genetic variants remains a pivotal challenge in clinical genetics. Recently, the proposition of protein language models has improved the generic variant effect prediction (VEP) accuracy via weakly-supervised or unsupervised training. However, these VEPs are not disease-specific, limiting their adaptation at point-of-care. To address this problem, we propose a disease-specific \textsc{pro}tein language model for variant \textsc{path}ogenicity, termed ProPath, to capture the pseudo-log-likelihood ratio in rare missense variants through a siamese network. We evaluate the performance of ProPath against pre-trained language models, using clinical variant sets in inherited cardiomyopathies and arrhythmias that were not seen during training. Our results demonstrate that ProPath surpasses the pre-trained ESM1b with an over $5\%$ improvement in AUC across both datasets. Furthermore, our model achieved the highest performances across all baselines for both datasets. Thus, our ProPath offers a potent disease-specific variant effect prediction, particularly valuable for disease associations and clinical applicability.
</details>
<details>
<summary>摘要</summary>
临床变种分类仍然是临床遗传学的核心挑战。最近，蛋白语言模型的提出已经提高了无监督或弱监督训练下的变iante效应预测（VEP）准确率。然而，这些VEP并不是疾病特有的，因此其应用在临床上受限。为解决这个问题，我们提议一种疾病特有的蛋白语言模型，称为ProPath，以捕捉 Pseudo-log-likelihood ratio 在罕见missense变iante中。我们使用siamese网络对变iante进行评估。我们的结果表明，ProPath 在两个遗传性心血管疾病和心跳过速疾病的临床变iante集中表现出色，与预先训练的 ESM1b 相比，提高了超过 5% 的 AUC 值。此外，我们的模型在所有基线之上表现出最高的性能。因此，我们的 ProPath 提供了一种有力的疾病特有的变iante效应预测，特别有价值于疾病相关性和临床实用性。
</details></li>
</ul>
<hr>
<h2 id="FLOGA-A-machine-learning-ready-dataset-a-benchmark-and-a-novel-deep-learning-model-for-burnt-area-mapping-with-Sentinel-2"><a href="#FLOGA-A-machine-learning-ready-dataset-a-benchmark-and-a-novel-deep-learning-model-for-burnt-area-mapping-with-Sentinel-2" class="headerlink" title="FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2"></a>FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03339">http://arxiv.org/abs/2311.03339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Sdraka, Alkinoos Dimakos, Alexandros Malounis, Zisoula Ntasiou, Konstantinos Karantzalos, Dimitrios Michail, Ioannis Papoutsis</li>
<li>for: 本研究目的是为了提供一种基于机器学习的自动烧区映射方法，以帮助抵制野火的扩散和侵害人类和动物生态环境。</li>
<li>methods: 本研究使用了多种机器学习和深度学习算法，包括支持向量机器学习（SVM）、隐藏状态机器学习（HR-ML）和卷积神经网络（CNN）等，以检测和分类烧区。</li>
<li>results: 研究结果表明，提议的深度学习模型BAM-CD在自动检测和分类烧区方面表现出色，与其他方法相比，具有更高的准确率和更好的鲁棒性。<details>
<summary>Abstract</summary>
Over the last decade there has been an increasing frequency and intensity of wildfires across the globe, posing significant threats to human and animal lives, ecosystems, and socio-economic stability. Therefore urgent action is required to mitigate their devastating impact and safeguard Earth's natural resources. Robust Machine Learning methods combined with the abundance of high-resolution satellite imagery can provide accurate and timely mappings of the affected area in order to assess the scale of the event, identify the impacted assets and prioritize and allocate resources effectively for the proper restoration of the damaged region. In this work, we create and introduce a machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations for the Greek Area). This dataset is unique as it comprises of satellite imagery acquired before and after a wildfire event, it contains information from Sentinel-2 and MODIS modalities with variable spatial and spectral resolution, and contains a large number of events where the corresponding burnt area ground truth has been annotated by domain experts. FLOGA covers the wider region of Greece, which is characterized by a Mediterranean landscape and climatic conditions. We use FLOGA to provide a thorough comparison of multiple Machine Learning and Deep Learning algorithms for the automatic extraction of burnt areas, approached as a change detection task. We also compare the results to those obtained using standard specialized spectral indices for burnt area mapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our benchmark results demonstrate the efficacy of the proposed technique in the automatic extraction of burnt areas, outperforming all other methods in terms of accuracy and robustness. Our dataset and code are publicly available at: https://github.com/Orion-AI-Lab/FLOGA.
</details>
<details>
<summary>摘要</summary>
过去一十年，全球各地的野火频率和强度都在增长，对人类和动物生命、生态系和社会经济稳定带来重大威胁。因此，我们需要迅速行动，以实现抑制野火的影响和保护地球的自然资源。我们使用Robust机器学习方法和充沛的高分辨率卫星图像，实现精准和时间协调的野火范围测量，以评估事件的规模、识别受影响资产和有效地分配资源，以便重建受损区域。在这个工作中，我们创建了一个名为FLOGA（希腊地区森林野火观测）的机器学习Ready数据集。FLOGA的特点是它包含了卫星图像在野火事件之前和后的比较，具有不同的空间和spectral分辨率，并且包含了许多野火事件的burnt区域的实际降落资料，由领域专家 manually annotated。FLOGA覆盖了希腊的广泛地区，其特征是地中海气候和地形。我们使用FLOGA进行了多种机器学习和深度学习算法的自动抽出burnt区域，将其视为变化检测任务。我们还与标准化的特殊 spectral indices for burnt area mapping进行比较。最后，我们提出了一个新的深度学习模型，名为BAM-CD。我们的参考结果表明，提案的技术可以实现自动抽出burnt区域的高精度和可靠性。我们的数据和代码在https://github.com/Orion-AI-Lab/FLOGA 上公开。
</details></li>
</ul>
<hr>
<h2 id="DAIL-Data-Augmentation-for-In-Context-Learning-via-Self-Paraphrase"><a href="#DAIL-Data-Augmentation-for-In-Context-Learning-via-Self-Paraphrase" class="headerlink" title="DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase"></a>DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03319">http://arxiv.org/abs/2311.03319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li, Yulin wang, Xueqi Wang, William Hogan, Jingbo Shang</li>
<li>for: The paper is written for improving the performance of In-Context Learning (ICL) in low-resource scenarios.</li>
<li>methods: The paper proposes a method called DAIL (Data Augmentation for In-Context Learning) that leverages the intuition that large language models are more familiar with the content generated by themselves to improve the performance of ICL.</li>
<li>results: The paper shows that DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario, and also explores the use of voting consistency as a confidence score of the model when the logits of predictions are inaccessible.<details>
<summary>Abstract</summary>
In-Context Learning (ICL) combined with pre-trained large language models has achieved promising results on various NLP tasks. However, ICL requires high-quality annotated demonstrations which might not be available in real-world scenarios. To overcome this limitation, we propose \textbf{D}ata \textbf{A}ugmentation for \textbf{I}n-Context \textbf{L}earning (\textbf{DAIL}). DAIL leverages the intuition that large language models are more familiar with the content generated by themselves. It first utilizes the language model to generate paraphrases of the test sample and employs majority voting to determine the final result based on individual predictions. Our extensive empirical evaluation shows that DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario. Additionally, we explore the use of voting consistency as a confidence score of the model when the logits of predictions are inaccessible. We believe our work will stimulate further research on ICL in low-resource settings.
</details>
<details>
<summary>摘要</summary>
它们可以使用已经训练过的大语言模型，并且可以使用它们自己生成的内容来增强学习效果。然而，ICL需要高质量的注释示例，这些示例可能在实际场景中不可获得。为了解决这个问题，我们提出了\textbf{DAIL}方法。DAIL利用了大语言模型对自己生成的内容的熟悉程度，首先使用语言模型生成测试样本的重叠版本，然后通过多数投票确定最终结果。我们的实际评估表明，DAIL方法在低资源情况下比标准ICL方法和其他集成方法表现更好。此外，我们还探讨了使用投票一致性作为模型的信任度指标，当预测结果的归一化值不可访问时。我们认为，我们的工作将激发更多关于ICL在低资源情况下的研究。
</details></li>
</ul>
<hr>
<h2 id="Neural-Structure-Learning-with-Stochastic-Differential-Equations"><a href="#Neural-Structure-Learning-with-Stochastic-Differential-Equations" class="headerlink" title="Neural Structure Learning with Stochastic Differential Equations"></a>Neural Structure Learning with Stochastic Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03309">http://arxiv.org/abs/2311.03309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjie Wang, Joel Jennings, Wenbo Gong<br>for: 这个论文主要目的是为了探索从时间观察中的变量关系的下面的关系，以便更好地理解这些系统的动态。methods: 这篇论文使用了神经网络杂然方程（SDE）和变量推断来推断可能的结构。results: 这篇论文的实验结果表明，使用这种方法可以在不同的时间间隔下更好地推断变量之间的关系，并且在实际数据上比基eline方法表现更好。<details>
<summary>Abstract</summary>
Discovering the underlying relationships among variables from temporal observations has been a longstanding challenge in numerous scientific disciplines, including biology, finance, and climate science. The dynamics of such systems are often best described using continuous-time stochastic processes. Unfortunately, most existing structure learning approaches assume that the underlying process evolves in discrete-time and/or observations occur at regular time intervals. These mismatched assumptions can often lead to incorrect learned structures and models. In this work, we introduce a novel structure learning method, SCOTCH, which combines neural stochastic differential equations (SDE) with variational inference to infer a posterior distribution over possible structures. This continuous-time approach can naturally handle both learning from and predicting observations at arbitrary time points. Theoretically, we establish sufficient conditions for an SDE and SCOTCH to be structurally identifiable, and prove its consistency under infinite data limits. Empirically, we demonstrate that our approach leads to improved structure learning performance on both synthetic and real-world datasets compared to relevant baselines under regular and irregular sampling intervals.
</details>
<details>
<summary>摘要</summary>
发现变量之间的下面关系从暂时观察中获得信息是许多科学领域的长期挑战，包括生物、金融和气候科学。这些系统的动态通常使用连续时间的杂种过程来描述。然而，大多数现有的结构学习方法假设下面过程在离散时间和/或观察时间都是定期的。这些不符合的假设可能会导致错误地学习到的结构和模型。在这种工作中，我们引入了一种新的结构学习方法，即SCOTCH，它将神经网络杂种方程（SDE）与变量推断来推导 posterior distribution over possible structures。这种连续时间的方法可以自然地处理从和预测观察数据的任意时间点进行学习和预测。理论上，我们确定了SDE和SCOTCH的结构可识别条件，并证明其在无穷数据极限下是一致的。实际上，我们在synthetic和实际世界数据集上证明了我们的方法在相对于相关基线下的结构学习性能更高。
</details></li>
</ul>
<hr>
<h2 id="Learning-Reusable-Manipulation-Strategies"><a href="#Learning-Reusable-Manipulation-Strategies" class="headerlink" title="Learning Reusable Manipulation Strategies"></a>Learning Reusable Manipulation Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03293">http://arxiv.org/abs/2311.03293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayuan Mao, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling</li>
<li>for: 本研究旨在帮助机器人学习 manipulate “tricks” 技能，从单个示例中学习并应用到不同的情景中。</li>
<li>methods: 该研究使用单个示例和自动游戏来学习机器人 manipulate 技能，并将每个示例解释为机器人对物体和物体之间接触方式的变化序列。</li>
<li>results: 研究实现了机器人通过单个示例和自动游戏学习 manipulate 技能，并可以将这些技能与标准任务和运动规划集成使用。<details>
<summary>Abstract</summary>
Humans demonstrate an impressive ability to acquire and generalize manipulation "tricks." Even from a single demonstration, such as using soup ladles to reach for distant objects, we can apply this skill to new scenarios involving different object positions, sizes, and categories (e.g., forks and hammers). Additionally, we can flexibly combine various skills to devise long-term plans. In this paper, we present a framework that enables machines to acquire such manipulation skills, referred to as "mechanisms," through a single demonstration and self-play. Our key insight lies in interpreting each demonstration as a sequence of changes in robot-object and object-object contact modes, which provides a scaffold for learning detailed samplers for continuous parameters. These learned mechanisms and samplers can be seamlessly integrated into standard task and motion planners, enabling their compositional use.
</details>
<details>
<summary>摘要</summary>
人类具有吸引人的 manipulate "技巧" 学习能力。即使从单一示范（如使用汤匙来达到远方物品），我们也可以应用这种技能到新的enario中，包括不同的物品位置、大小和类别（如锋和锤子）。此外，我们还可以灵活地组合不同的技能，制定长期计划。在这篇论文中，我们提出了一种框架，允许机器通过单一示范和自己玩家来学习 manipulate 技巧，称为"机制"。我们的关键思想在于将每个示范解释为机器人-物品和物品之间的接触模式的序列变化，从而提供了一个框架 для学习细致的抽象器 для连续参数。这些学习的机制和抽象器可以轻松地与标准任务和动作规划器集成，允许其 композиitional 使用。
</details></li>
</ul>
<hr>
<h2 id="GQKVA-Efficient-Pre-training-of-Transformers-by-Grouping-Queries-Keys-and-Values"><a href="#GQKVA-Efficient-Pre-training-of-Transformers-by-Grouping-Queries-Keys-and-Values" class="headerlink" title="GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys, and Values"></a>GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys, and Values</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03426">http://arxiv.org/abs/2311.03426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farnoosh Javadi, Walid Ahmed, Habib Hajimolahoseini, Foozhan Ataiefard, Mohammad Hassanpour, Saina Asani, Austin Wen, Omar Mohamed Awad, Kangling Liu, Yang Liu</li>
<li>for: 该论文旨在解决大型转换器模型的几个挑战，包括快速和计算密集的预训练和过参数化。</li>
<li>methods: 该论文提出了一种通用的方法 called GQKVA，它将查询、键和值 групiai技术应用于转换器预训练中。GQKVA是一种可以加速转换器预训练的方法，同时减少模型的大小。我们在不同的GQKVA变体中进行了实验，发现存在一定的平衡关系，可以根据资源和时间限制进行定制选择。</li>
<li>results: 我们对ViT进行了测试，得到了一个约0.3%的准确率提高，同时减少了模型的大小约4%。此外，我们最具攻击性的模型减小实验中，模型大小减少了约15%，准确率下降了约1%。<details>
<summary>Abstract</summary>
Massive transformer-based models face several challenges, including slow and computationally intensive pre-training and over-parametrization. This paper addresses these challenges by proposing a versatile method called GQKVA, which generalizes query, key, and value grouping techniques. GQKVA is designed to speed up transformer pre-training while reducing the model size. Our experiments with various GQKVA variants highlight a clear trade-off between performance and model size, allowing for customized choices based on resource and time limitations. Our findings also indicate that the conventional multi-head attention approach is not always the best choice, as there are lighter and faster alternatives available. We tested our method on ViT, which achieved an approximate 0.3% increase in accuracy while reducing the model size by about 4% in the task of image classification. Additionally, our most aggressive model reduction experiment resulted in a reduction of approximately 15% in model size, with only around a 1% drop in accuracy.
</details>
<details>
<summary>摘要</summary>
巨型变换器模型面临多个挑战，包括慢速和计算昂贵的预训练和过参数化。这篇论文提出了一种通用的方法called GQKVA，该方法通过查询、键和值 grouping技术来加速变换器预训练，同时减少模型的大小。我们的实验表明，GQKVA方法可以在不同的变量和模型大小之间进行定制化，以适应不同的资源和时间限制。我们的发现还表明，传统的多头注意力方法并不总是最佳选择，因为有更轻量级快速的选择可用。我们在ViT上测试了我们的方法，实现了 Image classification 任务中约0.3%的提升精度，同时减少了模型的大小约4%。此外，我们最苛刻的模型减少实验中，模型大小减少了约15%，只有约1%的精度下降。
</details></li>
</ul>
<hr>
<h2 id="S-LoRA-Serving-Thousands-of-Concurrent-LoRA-Adapters"><a href="#S-LoRA-Serving-Thousands-of-Concurrent-LoRA-Adapters" class="headerlink" title="S-LoRA: Serving Thousands of Concurrent LoRA Adapters"></a>S-LoRA: Serving Thousands of Concurrent LoRA Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03285">http://arxiv.org/abs/2311.03285</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/s-lora/s-lora">https://github.com/s-lora/s-lora</a></li>
<li>paper_authors: Ying Sheng, Shiyi Cao, Dacheng Li, Coleman Hooper, Nicholas Lee, Shuo Yang, Christopher Chou, Banghua Zhu, Lianmin Zheng, Kurt Keutzer, Joseph E. Gonzalez, Ion Stoica</li>
<li>for: 这种研究是为了提高大语言模型的批处理服务性能，特别是在使用“预训练后finetune”的情况下。</li>
<li>methods: 这篇论文提出了一种名为S-LoRA的系统，用于批量执行多个LoRA适应器。S-LoRA使用一个主存中存储所有适应器，并在GPU内存中fetch用于当前运行的查询的适应器。为了有效使用GPU内存并降低 Fragmentation，S-LoRA提出了统一分页机制。此外，S-LoRA还使用了一种新的tensor并行执行策略和特化的CUDA加速器，以实现hetersonous批处理LoRA计算。</li>
<li>results: 对比 estado-of-the-art 库such as HuggingFace PEFT和vLLM（带有浅入门支持LoRA服务），S-LoRA可以提高throughput BY up to 4 times，并将可以服务多个任务特定的精度适应器数量增加到数量级。因此，S-LoRA允许批量服务多个任务特定的精度适应器，并且提供了大规模自定义 fine-tuning 服务的潜在能力。<details>
<summary>Abstract</summary>
The "pretrain-then-finetune" paradigm is commonly adopted in the deployment of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method, is often employed to adapt a base model to a multitude of tasks, resulting in a substantial collection of LoRA adapters derived from one base model. We observe that this paradigm presents significant opportunities for batched inference during serving. To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters. S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory. To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation. Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving), S-LoRA can improve the throughput by up to 4 times and increase the number of served adapters by several orders of magnitude. As a result, S-LoRA enables scalable serving of many task-specific fine-tuned models and offers the potential for large-scale customized fine-tuning services. The code is available at https://github.com/S-LoRA/S-LoRA
</details>
<details>
<summary>摘要</summary>
“嵌入式-然后资金”的概念广泛应用于语言模型的部署。低级别适应（LoRA），一种效率 Parameter fine-tuning 方法，常用于适应多种任务，从而生成了一大量的 LoRA 适应器。我们发现这种方法在服务时存在大量的批处理机会。为了利用这些机会，我们提出了 S-LoRA，一个可扩展的服务系统，用于批处理多个 LoRA 适应器。S-LoRA 将所有适应器存储在主内存中，并在 GPU 内存中fetch 用于当前运行中的查询的适应器。为了有效地使用 GPU 内存并减少副本，S-LoRA 提出了一种统一分页（Unified Paging）策略，该策略使用一个统一内存池来管理动态适应器权重和 KV 缓存tensor 的不同序列长度。此外，S-LoRA 还采用了一种新的tensor并行策略和高度优化的自定义 CUDA 加速器，以实现hetereogeneous批处理 LoRA 计算。这些特性使得 S-LoRA 能够在单个 GPU 或多个 GPU 上服务千个 LoRA 适应器，只有小 overhead。相比之下，使用 HuggingFace PEFT 和 vLLM（带有简单的 LoRA 服务支持）的状态态归，S-LoRA 可以提高吞吐量，并将 LoRA 适应器的数量提高到几个数量级。因此，S-LoRA 允许批处理多个任务特定的精心定制化模型，并提供了大规模定制化 fine-tuning 服务的潜在能力。代码可以在 <https://github.com/S-LoRA/S-LoRA> 上找到。
</details></li>
</ul>
<hr>
<h2 id="An-AI-Guided-Data-Centric-Strategy-to-Detect-and-Mitigate-Biases-in-Healthcare-Datasets"><a href="#An-AI-Guided-Data-Centric-Strategy-to-Detect-and-Mitigate-Biases-in-Healthcare-Datasets" class="headerlink" title="An AI-Guided Data Centric Strategy to Detect and Mitigate Biases in Healthcare Datasets"></a>An AI-Guided Data Centric Strategy to Detect and Mitigate Biases in Healthcare Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03425">http://arxiv.org/abs/2311.03425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faris F. Gulamali, Ashwin S. Sawant, Lora Liharska, Carol R. Horowitz, Lili Chan, Patricia H. Kovatch, Ira Hofer, Karandeep Singh, Lynne D. Richardson, Emmanuel Mensah, Alexander W Charney, David L. Reich, Jianying Hu, Girish N. Nadkarni</li>
<li>for: 这篇论文的目的是提出一种数据中心、模型无关、任务无关的方法来评估医疗数据中的偏见，以便逐出和修正偏见。</li>
<li>methods: 这篇论文使用了一种名为AEquity的新的评估指标，通过分析不同群体在小样本大小下的学习容易度，来评估医疗数据中的偏见。</li>
<li>results: 这篇论文通过应用AEquity指标在两个已知的医疗问题中，分别是使用深度 convolutional neural networks 进行胸部X射影像诊断和使用多变量逻辑回归进行医疗使用预测，发现了一些种族偏见的manifestation，并通过修正这些偏见来提高医疗数据的公平性。<details>
<summary>Abstract</summary>
The adoption of diagnosis and prognostic algorithms in healthcare has led to concerns about the perpetuation of bias against disadvantaged groups of individuals. Deep learning methods to detect and mitigate bias have revolved around modifying models, optimization strategies, and threshold calibration with varying levels of success. Here, we generate a data-centric, model-agnostic, task-agnostic approach to evaluate dataset bias by investigating the relationship between how easily different groups are learned at small sample sizes (AEquity). We then apply a systematic analysis of AEq values across subpopulations to identify and mitigate manifestations of racial bias in two known cases in healthcare - Chest X-rays diagnosis with deep convolutional neural networks and healthcare utilization prediction with multivariate logistic regression. AEq is a novel and broadly applicable metric that can be applied to advance equity by diagnosing and remediating bias in healthcare datasets.
</details>
<details>
<summary>摘要</summary>
随着医疗健康预测和诊断算法在医疗领域的推广，对弱势群体的偏见问题产生了关注。深度学习方法来检测和缓解偏见的发展囊括了修改模型、优化策略和阈值准确化等方法，其成果各有不同。在这里，我们提出了一种数据中心、模型无关、任务无关的方法，通过研究小样本大小下不同群体学习的关系（AEquity）来评估数据集偏见。然后，我们采用了系统性的分析方法，在两个已知的医疗案例中（医疗X射像诊断与深度径向分割神经网络，以及医疗利用预测与多变量Logistic回归）检测和缓解种族偏见。AEquity是一种新的和普遍适用的指标，可以在医疗领域中提高公平性，诊断和缓解偏见。
</details></li>
</ul>
<hr>
<h2 id="Using-Symmetries-to-Lift-Satisfiability-Checking"><a href="#Using-Symmetries-to-Lift-Satisfiability-Checking" class="headerlink" title="Using Symmetries to Lift Satisfiability Checking"></a>Using Symmetries to Lift Satisfiability Checking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03424">http://arxiv.org/abs/2311.03424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Carbonnelle, Gottfried Schenner, Maurice Bruynooghe, Bart Bogaerts, Marc Denecker</li>
<li>for: 这个论文旨在使用对称性来压缩结构（也称为解释）到更小的Domain中，而不会产生信息损失。这种压缩可以用来解决满足问题。</li>
<li>methods: 该论文提出了一种两步新方法：首先，将要满足的句子自动翻译成一个equisatisfiable句子 sobre一个“升高” vocabulary， allowing domain compression; 其次，检查升高句子的满足状态，通过扩展初始未知的压缩Domain until a satisfying structure is found。关键问题是确保这个满足结构可以扩展到一个不压缩的结构，使其满足原始句子。</li>
<li>results: 实验表明，对于生成配置问题，该方法可以获得大量的加速。该方法还有软件验证软件操作 Complex Data Structures 的应用。未来的工作将包括对翻译进行进一步优化。<details>
<summary>Abstract</summary>
We analyze how symmetries can be used to compress structures (also known as interpretations) onto a smaller domain without loss of information. This analysis suggests the possibility to solve satisfiability problems in the compressed domain for better performance. Thus, we propose a 2-step novel method: (i) the sentence to be satisfied is automatically translated into an equisatisfiable sentence over a ``lifted'' vocabulary that allows domain compression; (ii) satisfiability of the lifted sentence is checked by growing the (initially unknown) compressed domain until a satisfying structure is found. The key issue is to ensure that this satisfying structure can always be expanded into an uncompressed structure that satisfies the original sentence to be satisfied. We present an adequate translation for sentences in typed first-order logic extended with aggregates. Our experimental evaluation shows large speedups for generative configuration problems. The method also has applications in the verification of software operating on complex data structures. Further refinements of the translation are left for future work.
</details>
<details>
<summary>摘要</summary>
我们分析了如何使用对称性来压缩结构（也称为解释）到更小的领域 без损失信息。这种分析表明可以在压缩领域中更好地解决满足问题。因此，我们提出了一种新的两步方法：1. 需要满足的句子会被自动翻译成一个等价满足句子 sobre 一个“升级” vocabulary，该 vocabulary 允许领域压缩。2. 压缩领域中的满足性会通过扩展初始未知的压缩领域来检查。关键在于确保这个满足结构可以总是扩展到一个满足原始句子的不压缩结构。我们对类型 first-order logic 扩展了聚合的句子进行了适当的翻译。我们的实验评估表明，这种方法可以在生成配置问题中获得大量的加速。这种方法还有软件操作复杂数据结构的验证应用。未来的工作将进行进一步的翻译改进。
</details></li>
</ul>
<hr>
<h2 id="From-Coupled-Oscillators-to-Graph-Neural-Networks-Reducing-Over-smoothing-via-a-Kuramoto-Model-based-Approach"><a href="#From-Coupled-Oscillators-to-Graph-Neural-Networks-Reducing-Over-smoothing-via-a-Kuramoto-Model-based-Approach" class="headerlink" title="From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach"></a>From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03260">http://arxiv.org/abs/2311.03260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Nguyen, Tan M. Nguyen, Hirotada Honda, Takashi Sano, Vinh Nguyen, Shugo Nakamura</li>
<li>For: 这篇论文旨在开发一种具有缓和抑制过滤现象的连续深度图像神经网络（GNN），并且使用科拉莫托模型来减轻这个现象。* Methods: 这篇论文使用的方法包括基于科拉莫托模型的频率同步方法，以预防节点特征汇整而不让系统降入稳定同步状态。* Results: 实验结果显示，使用科拉莫托GNN比基于GNN的基本方法和现有方法更有效地减少过滤现象，并且在各种图像深度学习 benchmark 任务中表现更好。<details>
<summary>Abstract</summary>
We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.
</details>
<details>
<summary>摘要</summary>
我们提出了kuramoto图 neural network（KuramotoGNN），一种新的连续深度图 нейрон网络（GNNs），它利用kuramoto模型来减轻过滤现象，在图 neural network中，节点特征会在层数增加时变得不可分辨。kuramoto模型捕捉了非线性 Coupled oscilator的同步行为。从coupled oscilator的角度来看，我们首先显示了kuramoto模型和基本的GNN之间的连接，然后说明了GNN中的过滤现象可以被解释为kuramoto模型中的相干同步。KuramotoGNN将取代这个相干同步，使节点特征不会与其他节点的特征相似，并让系统可以 дости到一个稳定的同步化状态。我们通过实验证明了KuramotoGNN在不同的图深度学习 benchmark task上的优势，比如降低过滤现象。
</details></li>
</ul>
<hr>
<h2 id="Coherent-Entity-Disambiguation-via-Modeling-Topic-and-Categorical-Dependency"><a href="#Coherent-Entity-Disambiguation-via-Modeling-Topic-and-Categorical-Dependency" class="headerlink" title="Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency"></a>Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03253">http://arxiv.org/abs/2311.03253</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilin Xiao, Linjun Shou, Xingyao Zhang, Jie Wu, Ming Gong, Jian Pei, Daxin Jiang</li>
<li>for: 提高实体识别精度和准确性</li>
<li>methods: 使用无监督自变量自动encoder（VAE）提取文本句子 latent topic vector，并通过步骤性实体决策来模拟实体之间交互，保持实体分类层次的准确性</li>
<li>results: 在各种实体识别 benchmark 上达到新的状态则末点，具体提高1.3个F1分数点，特别是在长文本场景下表现出色<details>
<summary>Abstract</summary>
Previous entity disambiguation (ED) methods adopt a discriminative paradigm, where prediction is made based on matching scores between mention context and candidate entities using length-limited encoders. However, these methods often struggle to capture explicit discourse-level dependencies, resulting in incoherent predictions at the abstract level (e.g. topic or category). We propose CoherentED, an ED system equipped with novel designs aimed at enhancing the coherence of entity predictions. Our method first introduces an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences. This approach not only allows the encoder to handle longer documents more effectively, conserves valuable input space, but also keeps a topic-level coherence. Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions. By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level. We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model demonstrates particularly outstanding performance on challenging long-text scenarios.
</details>
<details>
<summary>摘要</summary>
We propose CoherentED, an ED system with novel designs to enhance the coherence of entity predictions. Our method first uses an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences. This approach not only allows the encoder to handle longer documents more effectively, but also keeps the topic-level coherence. Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions. By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level.We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model demonstrates particularly outstanding performance on challenging long-text scenarios.
</details></li>
</ul>
<hr>
<h2 id="Instructed-Language-Models-with-Retrievers-Are-Powerful-Entity-Linkers"><a href="#Instructed-Language-Models-with-Retrievers-Are-Powerful-Entity-Linkers" class="headerlink" title="Instructed Language Models with Retrievers Are Powerful Entity Linkers"></a>Instructed Language Models with Retrievers Are Powerful Entity Linkers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03250">http://arxiv.org/abs/2311.03250</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrzilinxiao/insgenentitylinking">https://github.com/mrzilinxiao/insgenentitylinking</a></li>
<li>paper_authors: Zilin Xiao, Ming Gong, Jie Wu, Xingyao Zhang, Linjun Shou, Jian Pei, Daxin Jiang</li>
<li>for: 本研究旨在将生成模型（LLMs）应用于实体连接（EL）任务中，以提高EL任务的精度和效率。</li>
<li>methods: 本研究提出了多种方法来充分利用生成模型的能力，包括：（i）基于序列训练的EL目标函数与指令调整，（ii）一种基于轻量级可能提及者搜索的新一代生成EL框架，实现4倍的速度提升而无需牺牲连接度。</li>
<li>results: 对比前一代生成模型，INSGENEL显示了+6.8 F1点的提升平均值，同时具有更高的训练数据效率和训练计算消耗效率。此外，对比ICL框架，INSGENEL仍然保持明显的优势，证明EL任务仍然是通用LLMs的一大难点。<details>
<summary>Abstract</summary>
Generative approaches powered by large language models (LLMs) have demonstrated emergent abilities in tasks that require complex reasoning abilities. Yet the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base. We present Instructed Generative Entity Linker (INSGENEL), the first approach that enables casual language models to perform entity linking over knowledge bases. Several methods to equip language models with EL capability were proposed in this work, including (i) a sequence-to-sequence training EL objective with instruction-tuning, (ii) a novel generative EL framework based on a light-weight potential mention retriever that frees the model from heavy and non-parallelizable decoding, achieving 4$\times$ speedup without compromise on linking metrics. INSGENEL outperforms previous generative alternatives with +6.8 F1 points gain on average, also with a huge advantage in training data efficiency and training compute consumption. In addition, our skillfully engineered in-context learning (ICL) framework for EL still lags behind INSGENEL significantly, reaffirming that the EL task remains a persistent hurdle for general LLMs.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>生成方法由大型语言模型（LLM）驱动已经显示出了复杂逻辑能力的emergent能力。然而，生成性仍然使得生成内容受到幻觉的干扰，因此不适用于实体关注 tasks需要精确的实体预测 над 大量知识库。我们提出了首个可以让习语言模型执行实体关注 task的 Instructed Generative Entity Linker (INSGENEL)。这种方法包括（i）基于序列训练EL目标并进行指令调整的EL objective sequence-to-sequence训练，（ii）基于轻量级的可能提取器来实现快速的generative EL框架，从而实现4倍的速度提升而无需牺牲链接度量。 INSGENEL在前一代生成方法上average上提高了+6.8 F1点，同时具有更高的训练数据效率和训练计算耗用率。此外，我们 skillfully engineering的ICL框架仍然远远落后于INSGENEL，这再次证明了EL任务仍然是通用LLMs的难题。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Post-Hoc-Case-Based-Explanation-with-Feature-Highlighting"><a href="#Advancing-Post-Hoc-Case-Based-Explanation-with-Feature-Highlighting" class="headerlink" title="Advancing Post Hoc Case Based Explanation with Feature Highlighting"></a>Advancing Post Hoc Case Based Explanation with Feature Highlighting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03246">http://arxiv.org/abs/2311.03246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eoin Kenny, Eoin Delaney, Mark Keane</li>
<li>for: 本研究旨在提高透明AI（XAI）技术的应用范围，以帮助人工智能和人类合作下游任务。</li>
<li>methods: 本研究提出了两种通用算法（幽Defaults和super pixel based），可以在测试图像中分解出多个清晰特征部分，然后与训练数据中的相关案例相连接，以提供更全面的解释。</li>
<li>results: 实验结果表明，提议的方法可以正确地调整用户对于不确定分类结果的情感，并且不同于只显示解释而不显示特征高亮的情况。<details>
<summary>Abstract</summary>
Explainable AI (XAI) has been proposed as a valuable tool to assist in downstream tasks involving human and AI collaboration. Perhaps the most psychologically valid XAI techniques are case based approaches which display 'whole' exemplars to explain the predictions of black box AI systems. However, for such post hoc XAI methods dealing with images, there has been no attempt to improve their scope by using multiple clear feature 'parts' of the images to explain the predictions while linking back to relevant cases in the training data, thus allowing for more comprehensive explanations that are faithful to the underlying model. Here, we address this gap by proposing two general algorithms (latent and super pixel based) which can isolate multiple clear feature parts in a test image, and then connect them to the explanatory cases found in the training data, before testing their effectiveness in a carefully designed user study. Results demonstrate that the proposed approach appropriately calibrates a users feelings of 'correctness' for ambiguous classifications in real world data on the ImageNet dataset, an effect which does not happen when just showing the explanation without feature highlighting.
</details>
<details>
<summary>摘要</summary>
Explainable AI（XAI）已被提议为在人类和AI合作下执行下游任务的有价值工具。可能最有心理有效的XAI技术是情况基 Approaches，通过显示“整体”的示例来解释黑盒 AI 系统的预测。然而，对于图像处理的Post hoc XAI 方法，没有尝试使用多个清晰特征“部分”来解释预测结果，并将其联系回训练数据中相关的案例，因此可以提供更全面的解释， faithful to the underlying model。在这里，我们关注这个 gap，并提出了两种通用算法（幽默和超Pixel），可以在测试图像中分解出多个清晰特征部分，然后将其与训练数据中的解释案例相连接，并在一个仔细设计的用户研究中测试其效果。结果表明，我们提出的方法可以正确地让用户对于不确定分类结果的情感进行调整，这种效果在真实世界数据集 ImageNet 上不会发生。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Self-Supervised-Cross-View-Training-For-Sentence-Embedding"><a href="#An-Efficient-Self-Supervised-Cross-View-Training-For-Sentence-Embedding" class="headerlink" title="An Efficient Self-Supervised Cross-View Training For Sentence Embedding"></a>An Efficient Self-Supervised Cross-View Training For Sentence Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03228">http://arxiv.org/abs/2311.03228</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrpeerat/sct">https://github.com/mrpeerat/sct</a></li>
<li>paper_authors: Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Lalita Lowphansirikul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong</li>
<li>for:  sentence representation learning, specifically self-supervised learning without human annotation efforts</li>
<li>methods:  contrastive learning, and a proposed framework called Self-supervised Cross-View Training (SCT)</li>
<li>results:  outperforms baseline and state-of-the-art competitors on seven Semantic Textual Similarity (STS) benchmarks for PLMs with less than 100M parameters in 18 of 21 cases.<details>
<summary>Abstract</summary>
Self-supervised sentence representation learning is the task of constructing an embedding space for sentences without relying on human annotation efforts. One straightforward approach is to finetune a pretrained language model (PLM) with a representation learning method such as contrastive learning. While this approach achieves impressive performance on larger PLMs, the performance rapidly degrades as the number of parameters decreases. In this paper, we propose a framework called Self-supervised Cross-View Training (SCT) to narrow the performance gap between large and small PLMs. To evaluate the effectiveness of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of parameters ranging from 4M to 340M. The experimental results show that STC outperforms the competitors for PLMs with less than 100M parameters in 18 of 21 cases.
</details>
<details>
<summary>摘要</summary>
自动监督句子表示学习是建立句子嵌入空间的任务，而不需要人工标注努力。一种直观的方法是通过对预训练语言模型（PLM）进行微调，并使用对比学习法来学习句子表示。虽然这种方法在更大的PLM上达到了很高的性能，但是在小PLM上，性能快速下降。在这篇论文中，我们提出了一个名为自动监督交叉视图训练（SCT）的框架，以减少小PLM上表达力的差异。为评估SCT的有效性，我们与5个基准和现有的竞争对手进行比较，在7个Semantic Textual Similarity（STS）标准测试集上使用5种PLM，它们的参数数量从4M到340M。实验结果表明，SCT在PLM参数少于100M时在18/21个测试中表现更好。
</details></li>
</ul>
<hr>
<h2 id="LDM3D-VR-Latent-Diffusion-Model-for-3D-VR"><a href="#LDM3D-VR-Latent-Diffusion-Model-for-3D-VR" class="headerlink" title="LDM3D-VR: Latent Diffusion Model for 3D VR"></a>LDM3D-VR: Latent Diffusion Model for 3D VR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03226">http://arxiv.org/abs/2311.03226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriela Ben Melech Stan, Diana Wofk, Estelle Aflalo, Shao-Yen Tseng, Zhipeng Cai, Michael Paulitsch, Vasudev Lal</li>
<li>for: 这 paper 是为了创建和 manipulate 视觉输出而设计的。</li>
<li>methods: 这 paper 使用了潜在差分模型，包括 LDM3D-pano 和 LDM3D-SR。这些模型可以根据文本提示生成 panoramic RGBD，并将低分辨率输入upscale 到高分辨率 RGBD。</li>
<li>results: 这 paper 的模型在比较related 方法的基础上进行了评估，并取得了优于 relate 方法的结果。<details>
<summary>Abstract</summary>
Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.<</SYS>>Here's the translation in Traditional Chinese:<<SYS>>Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="ALYMPICS-Language-Agents-Meet-Game-Theory"><a href="#ALYMPICS-Language-Agents-Meet-Game-Theory" class="headerlink" title="ALYMPICS: Language Agents Meet Game Theory"></a>ALYMPICS: Language Agents Meet Game Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03220">http://arxiv.org/abs/2311.03220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Tao Ge, Furu Wei</li>
<li>for: 这篇论文旨在利用大型自然语言模型（LLM）代理人类 investigate 游戏理论。</li>
<li>methods: 论文使用 LLM 和自动化代理人 simulate 人类行为，实现多代理人合作，构建人类交互的真实和动态模型，用于游戏理论假设设计和测试。</li>
<li>results: 通过 manipulating 资源可用性和代理人性格，论文 observe 不同的代理人在竞争中如何互动和采取策略，并证明 LLM 代理人在游戏理论研究中具有优势，包括模拟真实行为、提供可控、可扩展和可重现的环境。<details>
<summary>Abstract</summary>
This paper introduces Alympics, a platform that leverages Large Language Model (LLM) agents to facilitate investigations in game theory. By employing LLMs and autonomous agents to simulate human behavior and enable multi-agent collaborations, we can construct realistic and dynamic models of human interactions for game theory hypothesis formulating and testing. To demonstrate this, we present and implement a survival game involving unequal competition for limited resources. Through manipulation of resource availability and agent personalities, we observe how different agents engage in the competition and adapt their strategies. The use of LLM agents in game theory research offers significant advantages, including simulating realistic behavior, providing a controlled, scalable, and reproducible environment. Our work highlights the potential of LLM agents in enhancing the understanding of strategic decision-making within complex socioeconomic contexts. All codes will be made public soon.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了Alympics平台，该平台利用大语言模型（LLM）代理来促进游戏理论研究。通过使用LLM和自主代理模拟人类行为，我们可以构建真实和动态的人类互动模型，用于游戏理论假设设计和测试。为了证明这一点，我们在一个有限资源的存储游戏中展示了不同代理的竞争和战略适应。通过资源可用性和代理人格的调整，我们观察了不同的代理如何在竞争中 engagé和适应策略。使用LLM代理在游戏理论研究中具有重要优点，包括模拟真实行为、提供可控、可扩展和可重现的环境。我们的工作强调了LLM代理在复杂社会经济背景下的决策推理的深入理解的潜在优势。所有代码即将公开。
</details></li>
</ul>
<hr>
<h2 id="Mini-Minds-Exploring-Bebeshka-and-Zlata-Baby-Models"><a href="#Mini-Minds-Exploring-Bebeshka-and-Zlata-Baby-Models" class="headerlink" title="Mini Minds: Exploring Bebeshka and Zlata Baby Models"></a>Mini Minds: Exploring Bebeshka and Zlata Baby Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03216">http://arxiv.org/abs/2311.03216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/upunaprosk/small-language-models">https://github.com/upunaprosk/small-language-models</a></li>
<li>paper_authors: Irina Proskurina, Guillaume Metzler, Julien Velcin</li>
<li>for: 本研究是为了提出一种小规模语言模型，用于解决从头开始，使用有限数据和人类语言学习的语言模型问题。</li>
<li>methods: 该研究使用了架构搜索，以最小化 Shared Task 上的假cloaked语言模型损失。并提出了两个小型语言模型（LMs），即 Bebeshka 和 Zlata，它们具有4层encoder和6层decoder，每个encoder层有8个注意头，每个decoder层有12个注意头。</li>
<li>results: 该研究发现， despite being half the scale of the baseline LMs, 提出的小型语言模型可以达到相同的性能水平。此外，研究还探讨了小型语言模型在道德判断任务中的应用性，并对其预测与人类价值观Alignment。这些发现表明小型语言模型在实际语言理解任务中具有潜在的应用价值。<details>
<summary>Abstract</summary>
In this paper, we describe the University of Lyon 2 submission to the Strict-Small track of the BabyLM competition. The shared task is created with an emphasis on small-scale language modelling from scratch on limited-size data and human language acquisition. Dataset released for the Strict-Small track has 10M words, which is comparable to children's vocabulary size. We approach the task with an architecture search, minimizing masked language modelling loss on the data of the shared task. Having found an optimal configuration, we introduce two small-size language models (LMs) that were submitted for evaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder model with 12 heads which we term Bebeshka and Zlata, respectively. Despite being half the scale of the baseline LMs, our proposed models achieve comparable performance. We further explore the applicability of small-scale language models in tasks involving moral judgment, aligning their predictions with human values. These findings highlight the potential of compact LMs in addressing practical language understanding tasks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们描述了里昂第二大学对Strict-Small赛道的提交。这个任务强调从头来学习小规模语言模型，使用有限数据量和人类语言学习的限制。共享任务数据集有1000万个单词，与儿童词汇相当。我们通过架构搜索，在数据集上减少假Masked Language Modeling损失来解决问题。我们发现了一个优化的配置，然后引入了两个小型语言模型（LM），我们称之为Bebeshka和Zlata。它们具有4层Encoder和6层Decoder，各自具有8个注意头和12个注意头。虽然它们的规模只占基elineLM的一半，但它们在性能上却达到了相同的水平。我们还探索了小型语言模型在道德评价任务中的应用性，并将其预测与人类价值观Alignment。这些发现表明了小型语言模型在实际语言理解任务中的潜力。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-Labeling-for-Domain-Agnostic-Bangla-Automatic-Speech-Recognition"><a href="#Pseudo-Labeling-for-Domain-Agnostic-Bangla-Automatic-Speech-Recognition" class="headerlink" title="Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition"></a>Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03196">http://arxiv.org/abs/2311.03196</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hishab-nlp/pseudo-labeling-for-domain-agnostic-bangla-asr">https://github.com/hishab-nlp/pseudo-labeling-for-domain-agnostic-bangla-asr</a></li>
<li>paper_authors: Rabindra Nath Nandi, Mehadi Hasan Menon, Tareq Al Muntasir, Sagor Sarker, Quazi Sarwar Muhtaseem, Md. Tariqul Islam, Shammur Absar Chowdhury, Firoj Alam</li>
<li>for: 本研究旨在开发一种自动语音识别（ASR）系统，以满足低资源语言的语音识别需求。</li>
<li>methods: 本研究提出了一种 pseudo-labeling 方法，以开发大规模的领域不偏的 ASR 数据集。通过该方法，我们开发了20000+小时的标注的孟加拉语音数据集，覆盖了多种话题、说话风格、方言、噪音环境和对话场景。</li>
<li>results: 我们使用了开发的 corpus 设计了一个基于幂体的 ASR 系统，并对其进行了训练。我们对公开available的数据集进行了比较，并与其他可用的模型进行了比较。我们还设计了和human-annotated的领域不偏测试集，包括新闻、电话和对话数据等。我们的结果表明，使用 pseudo-labeling 方法对于我们设计的测试集以及公开available的孟加拉语音数据集具有较高的效果。<details>
<summary>Abstract</summary>
One of the major challenges for developing automatic speech recognition (ASR) for low-resource languages is the limited access to labeled data with domain-specific variations. In this study, we propose a pseudo-labeling approach to develop a large-scale domain-agnostic ASR dataset. With the proposed methodology, we developed a 20k+ hours labeled Bangla speech dataset covering diverse topics, speaking styles, dialects, noisy environments, and conversational scenarios. We then exploited the developed corpus to design a conformer-based ASR system. We benchmarked the trained ASR with publicly available datasets and compared it with other available models. To investigate the efficacy, we designed and developed a human-annotated domain-agnostic test set composed of news, telephony, and conversational data among others. Our results demonstrate the efficacy of the model trained on psuedo-label data for the designed test-set along with publicly-available Bangla datasets. The experimental resources will be publicly available.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)
</details>
<details>
<summary>摘要</summary>
一个主要挑战在开发自动语音识别（ASR）系统 для低资源语言是获取域特定变化的标注数据的有限性。在这种研究中，我们提出了一种 pseudo-标注方法，以开发大规模的域不偏泛 ASR 数据集。通过我们的方法，我们开发了20000+小时的标注的孟加拉语言材料，涵盖了多样的话题、说话风格、方言、噪音环境和对话场景。然后，我们利用开发的数据集设计了一种基于征字的 ASR 系统。我们对培过的 ASR 进行了训练，并与公共可用的数据集进行了比较。为了评估效果，我们设计了和开发了一个人工标注的域不偏泛测试集，包括新闻、电话和对话数据等。我们的结果表明，使用 pseudo-标注数据进行训练的模型在我们设计的测试集上以及公共可用的孟加拉语言数据集上具有较高的效果。实验资源将公开可用。
</details></li>
</ul>
<hr>
<h2 id="Nexus-at-ArAIEval-Shared-Task-Fine-Tuning-Arabic-Language-Models-for-Propaganda-and-Disinformation-Detection"><a href="#Nexus-at-ArAIEval-Shared-Task-Fine-Tuning-Arabic-Language-Models-for-Propaganda-and-Disinformation-Detection" class="headerlink" title="Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection"></a>Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03184">http://arxiv.org/abs/2311.03184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunze Xiao, Firoj Alam</li>
<li>for: 本研究旨在探讨自媒体平台上的假信息和宣传内容的扩散，以及这些内容对社会和谐的影响。</li>
<li>methods: 本研究使用了Transformer模型的精细调整和零shot学习，以及GPT-4模型的应用。</li>
<li>results: 本研究在ArAIEval分享任务中获得了9名和10名的成绩。<details>
<summary>Abstract</summary>
The spread of disinformation and propagandistic content poses a threat to societal harmony, undermining informed decision-making and trust in reliable sources. Online platforms often serve as breeding grounds for such content, and malicious actors exploit the vulnerabilities of audiences to shape public opinion. Although there have been research efforts aimed at the automatic identification of disinformation and propaganda in social media content, there remain challenges in terms of performance. The ArAIEval shared task aims to further research on these particular issues within the context of the Arabic language. In this paper, we discuss our participation in these shared tasks. We competed in subtasks 1A and 2A, where our submitted system secured positions 9th and 10th, respectively. Our experiments consist of fine-tuning transformer models and using zero- and few-shot learning with GPT-4.
</details>
<details>
<summary>摘要</summary>
“虚伪信息和宣传内容的散播对社会和谐产生胁威，损害了有知情的决策和对可靠来源的信任。在线上平台上，这种内容经常成为繁殖的地方，恶徒利用观众的易于欺骗的特点来操纵公众的意见。虽然有关自动识别虚伪信息和宣传内容的研究努力，但是仍然存在性能上的挑战。ArAIEval共同任务 aimsto further研究这些具体的问题 within the context of the Arabic language。本文讲述我们参加这个共同任务的实验。我们参加了1A和2A的子任务，我们提交的系统在这两个子任务中分别获得了第九名和第十名。我们的实验包括精确地 fine-tuning transformer 模型和使用 zero-和 few-shot learning with GPT-4。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="ArAIEval-Shared-Task-Persuasion-Techniques-and-Disinformation-Detection-in-Arabic-Text"><a href="#ArAIEval-Shared-Task-Persuasion-Techniques-and-Disinformation-Detection-in-Arabic-Text" class="headerlink" title="ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text"></a>ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03179">http://arxiv.org/abs/2311.03179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maram Hasanain, Firoj Alam, Hamdy Mubarak, Samir Abdaljalil, Wajdi Zaghouani, Preslav Nakov, Giovanni Da San Martino, Abed Alhakim Freihat</li>
<li>for: 本文描述了 ArAIEval 分享任务，它是在第一届 ArabicNLP 2023 会议上组织的，并与 EMNLP 2023 同时举行。ArAIEval 提供了两个任务，它们是在 arabic 文本上进行的：（i）诱导技巧检测，旨在在推文和新闻文章中Identify 诱导技巧，以及（ii）在推文上进行不当信息检测。</li>
<li>methods: 大多数参与系统都是使用 fine-tuning transformer 模型，如 AraBERT。</li>
<li>results: 共有 20 个 коман队参与了最终评估阶段，其中 Task 1 和 Task 2 分别有 14 和 16 个参与队伍。<details>
<summary>Abstract</summary>
We present an overview of the ArAIEval shared task, organized as part of the first ArabicNLP 2023 conference co-located with EMNLP 2023. ArAIEval offers two tasks over Arabic text: (i) persuasion technique detection, focusing on identifying persuasion techniques in tweets and news articles, and (ii) disinformation detection in binary and multiclass setups over tweets. A total of 20 teams participated in the final evaluation phase, with 14 and 16 teams participating in Tasks 1 and 2, respectively. Across both tasks, we observed that fine-tuning transformer models such as AraBERT was at the core of the majority of the participating systems. We provide a description of the task setup, including a description of the dataset construction and the evaluation setup. We further give a brief overview of the participating systems. All datasets and evaluation scripts from the shared task are released to the research community. (https://araieval.gitlab.io/) We hope this will enable further research on these important tasks in Arabic.
</details>
<details>
<summary>摘要</summary>
我们提供了阿拉伯语自然语言处理（ArAIEval）共同任务的概述，该任务是在2023年阿拉伯语言处理会议（ArabicNLP 2023）和人工智能语言处理会议（EMNLP 2023）之间的共同办公室。ArAIEval提供了两个任务，它们分别是在推销文本中检测推销技巧和新闻文本中检测不实信息。共20个队伍参与了最终评估阶段，其中14个队伍参与了任务1，16个队伍参与了任务2。在两个任务中，我们发现大多数参与系统都是使用transformer模型进行细化，如AraBERT。我们提供了任务设置的描述，包括数据集的建构和评估设置的描述，以及参与系统的简要概述。此外，我们还发布了所有数据集和评估脚本给研究社区。我们希望这些资源能够促进阿拉伯语言处理领域的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait"><a href="#1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait" class="headerlink" title="1D-Convolutional transformer for Parkinson disease diagnosis from gait"></a>1D-Convolutional transformer for Parkinson disease diagnosis from gait</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03177">http://arxiv.org/abs/2311.03177</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/safwennaimi/1d-convolutional-transformer-for-parkinson-disease-diagnosis-from-gait">https://github.com/safwennaimi/1d-convolutional-transformer-for-parkinson-disease-diagnosis-from-gait</a></li>
<li>paper_authors: Safwen Naimi, Wassim Bouachir, Guillaume-Alexandre Bilodeau</li>
<li>for: 这篇论文目标是用深度神经网络模型诊断parkinson病。</li>
<li>methods: 这篇论文提出了一种hybrid ConvNet-Transformer架构，通过捕捉本地特征和长期空间时间相关性来准确诊断疾病的严重度。</li>
<li>results: 实验结果表明，这种架构可以从步态数据中准确诊断parkinson病的不同阶段，准确率达88%，超过了其他现有的人工智能方法。此外，这种方法可以普遍化和适应其他分类问题，以解决1D信号中特征相关性和空间时间相关性的问题。<details>
<summary>Abstract</summary>
This paper presents an efficient deep neural network model for diagnosing Parkinson's disease from gait. More specifically, we introduce a hybrid ConvNet-Transformer architecture to accurately diagnose the disease by detecting the severity stage. The proposed architecture exploits the strengths of both Convolutional Neural Networks and Transformers in a single end-to-end model, where the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data. In this manner, our hybrid architecture achieves an improved performance compared to using either models individually. Our experimental results show that our approach is effective for detecting the different stages of Parkinson's disease from gait data, with a final accuracy of 88%, outperforming other state-of-the-art AI methods on the Physionet gait dataset. Moreover, our method can be generalized and adapted for other classification problems to jointly address the feature relevance and spatio-temporal dependency problems in 1D signals. Our source code and pre-trained models are publicly available at https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Findings-of-the-WMT-2023-Shared-Task-on-Discourse-Level-Literary-Translation-A-Fresh-Orb-in-the-Cosmos-of-LLMs"><a href="#Findings-of-the-WMT-2023-Shared-Task-on-Discourse-Level-Literary-Translation-A-Fresh-Orb-in-the-Cosmos-of-LLMs" class="headerlink" title="Findings of the WMT 2023 Shared Task on Discourse-Level Literary Translation: A Fresh Orb in the Cosmos of LLMs"></a>Findings of the WMT 2023 Shared Task on Discourse-Level Literary Translation: A Fresh Orb in the Cosmos of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03127">http://arxiv.org/abs/2311.03127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longyue Wang, Zhaopeng Tu, Yan Gu, Siyou Liu, Dian Yu, Qingsong Ma, Chenyang Lyu, Liting Zhou, Chao-Hong Liu, Yufeng Ma, Weiyu Chen, Yvette Graham, Bonnie Webber, Philipp Koehn, Andy Way, Yulin Yuan, Shuming Shi</li>
<li>for: 这个研究的目的是提高机器翻译的效果，尤其是在翻译文学作品方面。</li>
<li>methods: 该研究使用了一个新的文学翻译任务，并采用了人工和自动评估方法来评估提交的系统表现。</li>
<li>results: 研究发现了一些有趣的发现，包括文学和语言翻译相关的问题，并提供了一个新的数据集和评估标准。<details>
<summary>Abstract</summary>
Translating literary works has perennially stood as an elusive dream in machine translation (MT), a journey steeped in intricate challenges. To foster progress in this domain, we hold a new shared task at WMT 2023, the first edition of the Discourse-Level Literary Translation. First, we (Tencent AI Lab and China Literature Ltd.) release a copyrighted and document-level Chinese-English web novel corpus. Furthermore, we put forth an industry-endorsed criteria to guide human evaluation process. This year, we totally received 14 submissions from 7 academia and industry teams. We employ both automatic and human evaluations to measure the performance of the submitted systems. The official ranking of the systems is based on the overall human judgments. In addition, our extensive analysis reveals a series of interesting findings on literary and discourse-aware MT. We release data, system outputs, and leaderboard at http://www2.statmt.org/wmt23/literary-translation-task.html.
</details>
<details>
<summary>摘要</summary>
machine translation (MT)中的文学作品翻译总是一个怀抱不到的梦，一条陡峭的旅程。为了推动这个领域的进步，我们在WMT 2023上组织了一个新的共同任务，称为文本级别的文学翻译。首先，我们（天地智能研究所和中国文学有限公司）发布了一个版权和文档级中文英文网络小说集。此外，我们提出了产业认可的评价标准，以引导人工评价过程。本年度共收到14个提交，来自7所学术和产业团队。我们使用自动和人工评价来评价提交系统的性能。官方排名是根据人工评价的总结果。此外，我们的广泛分析发现了一系列有趣的文学和通用MT相关发现。我们在http://www2.statmt.org/wmt23/literary-translation-task.html上发布数据、系统输出和排名。
</details></li>
</ul>
<hr>
<h2 id="Pelvic-floor-MRI-segmentation-based-on-semi-supervised-deep-learning"><a href="#Pelvic-floor-MRI-segmentation-based-on-semi-supervised-deep-learning" class="headerlink" title="Pelvic floor MRI segmentation based on semi-supervised deep learning"></a>Pelvic floor MRI segmentation based on semi-supervised deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03105">http://arxiv.org/abs/2311.03105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianwei Zuo, Fei Feng, Zhuhui Wang, James A. Ashton-Miller, John O. L. Delancey, Jiajia Luo<br>for: 这个研究旨在提高骨盘器官的semantic segmentation和三维几何重建的精度。methods: 本研究提出了一个半supervised框架，包括两个阶段。第一阶段是通过图像修复任务进行自我指导预训。接着，使用标注数据进行精度训练。第二阶段是使用自我指导模型生成pseudo标签 для无标注数据。最后，两个数据集都被用来进行半supervised训练。results: 在评估中，我们的方法可以对骨盘器官的semantic segmentation和三维几何重建进行明显改善。比如，难以分类的uterus这个器官，可以提高semantic segmentation的精度高达3.70%。<details>
<summary>Abstract</summary>
The semantic segmentation of pelvic organs via MRI has important clinical significance. Recently, deep learning-enabled semantic segmentation has facilitated the three-dimensional geometric reconstruction of pelvic floor organs, providing clinicians with accurate and intuitive diagnostic results. However, the task of labeling pelvic floor MRI segmentation, typically performed by clinicians, is labor-intensive and costly, leading to a scarcity of labels. Insufficient segmentation labels limit the precise segmentation and reconstruction of pelvic floor organs. To address these issues, we propose a semi-supervised framework for pelvic organ segmentation. The implementation of this framework comprises two stages. In the first stage, it performs self-supervised pre-training using image restoration tasks. Subsequently, fine-tuning of the self-supervised model is performed, using labeled data to train the segmentation model. In the second stage, the self-supervised segmentation model is used to generate pseudo labels for unlabeled data. Ultimately, both labeled and unlabeled data are utilized in semi-supervised training. Upon evaluation, our method significantly enhances the performance in the semantic segmentation and geometric reconstruction of pelvic organs, Dice coefficient can increase by 2.65% averagely. Especially for organs that are difficult to segment, such as the uterus, the accuracy of semantic segmentation can be improved by up to 3.70%.
</details>
<details>
<summary>摘要</summary>
Pelvic organ semantic segmentation via MRI has important clinical significance. Recently, deep learning-enabled semantic segmentation has facilitated the three-dimensional geometric reconstruction of pelvic floor organs, providing clinicians with accurate and intuitive diagnostic results. However, the task of labeling pelvic floor MRI segmentation, typically performed by clinicians, is labor-intensive and costly, leading to a scarcity of labels. Insufficient segmentation labels limit the precise segmentation and reconstruction of pelvic floor organs. To address these issues, we propose a semi-supervised framework for pelvic organ segmentation. The implementation of this framework comprises two stages. In the first stage, it performs self-supervised pre-training using image restoration tasks. Subsequently, fine-tuning of the self-supervised model is performed, using labeled data to train the segmentation model. In the second stage, the self-supervised segmentation model is used to generate pseudo labels for unlabeled data. Ultimately, both labeled and unlabeled data are utilized in semi-supervised training. Upon evaluation, our method significantly enhances the performance in the semantic segmentation and geometric reconstruction of pelvic organs, Dice coefficient can increase by 2.65% averagely. Especially for organs that are difficult to segment, such as the uterus, the accuracy of semantic segmentation can be improved by up to 3.70%.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-yet-Efficient-Ensemble-Approach-for-AI-generated-Text-Detection"><a href="#A-Simple-yet-Efficient-Ensemble-Approach-for-AI-generated-Text-Detection" class="headerlink" title="A Simple yet Efficient Ensemble Approach for AI-generated Text Detection"></a>A Simple yet Efficient Ensemble Approach for AI-generated Text Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03084">http://arxiv.org/abs/2311.03084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harika Abburi, Kalyani Roy, Michael Suesserman, Nirmala Pudota, Balaji Veeramani, Edward Bowen, Sanmitra Bhattacharya</li>
<li>for: 这篇研究旨在提出一个简单 yet efficient的解决方案，可以区别人工生成的文本和人类所写的文本。</li>
<li>methods: 本研究使用了多个构成部件的 Large Language Models（LLMs）的 predictions 进行集成，与之前的州域-of-the-art方法相比，其表现更加出色。</li>
<li>results: 在四个生成文本分类 benchmark 上进行了实验，结果显示，与之前的州域-of-the-art方法相比，我们的集成方法可以获得0.5-100%的表现提升。此外，我们还研究了个别 LLM 的训练数据对模型表现的影响，发现可以使用其他开源语言模型生成的数据来替代商业紧密的 Generative Pre-trained Transformer（GPT）数据。<details>
<summary>Abstract</summary>
Recent Large Language Models (LLMs) have demonstrated remarkable capabilities in generating text that closely resembles human writing across wide range of styles and genres. However, such capabilities are prone to potential abuse, such as fake news generation, spam email creation, and misuse in academic assignments. Hence, it is essential to build automated approaches capable of distinguishing between artificially generated text and human-authored text. In this paper, we propose a simple yet efficient solution to this problem by ensembling predictions from multiple constituent LLMs. Compared to previous state-of-the-art approaches, which are perplexity-based or uses ensembles with a number of LLMs, our condensed ensembling approach uses only two constituent LLMs to achieve comparable performance. Experiments conducted on four benchmark datasets for generative text classification show performance improvements in the range of 0.5 to 100\% compared to previous state-of-the-art approaches. We also study the influence the training data from individual LLMs have on model performance. We found that substituting commercially-restrictive Generative Pre-trained Transformer (GPT) data with data generated from other open language models such as Falcon, Large Language Model Meta AI (LLaMA2), and Mosaic Pretrained Transformers (MPT) is a feasible alternative when developing generative text detectors. Furthermore, to demonstrate zero-shot generalization, we experimented with an English essays dataset, and results suggest that our ensembling approach can handle new data effectively.
</details>
<details>
<summary>摘要</summary>
现代大语言模型（LLM）在生成文本方面已经展现出了很高的能力，能够生成人类语言writing的文本，包括不同的风格和类型。然而，这些能力也存在潜在的危险，如生成假新闻、垃圾邮件和学术作业中的违规使用。因此，建立自动识别人类语言文本和人工生成文本的方法变得非常重要。在这篇论文中，我们提出了一种简单 yet efficient的解决方案，通过多个构成部件LLM的ensemble进行识别。与之前的状态之前的方法相比，我们的压缩ensemble方法只使用了两个构成部件LLM，可以达到相同的性能。我们在四个文本生成类型的基准数据集上进行了实验，结果显示与之前状态之前的方法相比，我们的方法在0.5%到100%的范围内提高了性能。我们还研究了各个LLM的训练数据对模型性能的影响。我们发现可以将商业限制的生成预训练 transformer（GPT）数据替换为其他开源语言模型生成的数据，这是一种可行的替代方案。此外，为了证明零基础学习的普适性，我们对英文学业作业数据进行了实验，结果表明我们的ensemble方法可以有效处理新数据。
</details></li>
</ul>
<hr>
<h2 id="SugarViT-–-Multi-objective-Regression-of-UAV-Images-with-Vision-Transformers-and-Deep-Label-Distribution-Learning-Demonstrated-on-Disease-Severity-Prediction-in-Sugar-Beet"><a href="#SugarViT-–-Multi-objective-Regression-of-UAV-Images-with-Vision-Transformers-and-Deep-Label-Distribution-Learning-Demonstrated-on-Disease-Severity-Prediction-in-Sugar-Beet" class="headerlink" title="SugarViT – Multi-objective Regression of UAV Images with Vision Transformers and Deep Label Distribution Learning Demonstrated on Disease Severity Prediction in Sugar Beet"></a>SugarViT – Multi-objective Regression of UAV Images with Vision Transformers and Deep Label Distribution Learning Demonstrated on Disease Severity Prediction in Sugar Beet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03076">http://arxiv.org/abs/2311.03076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maurice Günder, Facundo Ramón Ispizua Yamati, Abel Andree Barreto Alcántara, Anne-Katrin Mahlein, Rafet Sifa, Christian Bauckhage</li>
<li>for: 这个论文主要用于提出一种机器学习框架，用于自动化大规模植物特征注释，以便为糖豫病毒扩散病虫蛀病（CLS）的病虫蛀病度评估。</li>
<li>methods: 这个论文使用了深度标签分布学习（DLDL）、特殊的损失函数和适应的模型架构，开发了一种基于视Transformer的疾病严重度评估模型called SugarViT。</li>
<li>results: 这个论文通过将遥感数据与试验站环境参数结合使用，对病虫蛀病度进行预测，并通过多目标问题预测来证明了模型的通用性。<details>
<summary>Abstract</summary>
Remote sensing and artificial intelligence are pivotal technologies of precision agriculture nowadays. The efficient retrieval of large-scale field imagery combined with machine learning techniques shows success in various tasks like phenotyping, weeding, cropping, and disease control. This work will introduce a machine learning framework for automatized large-scale plant-specific trait annotation for the use case disease severity scoring for Cercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label Distribution Learning (DLDL), special loss functions, and a tailored model architecture, we develop an efficient Vision Transformer based model for disease severity scoring called SugarViT. One novelty in this work is the combination of remote sensing data with environmental parameters of the experimental sites for disease severity prediction. Although the model is evaluated on this special use case, it is held as generic as possible to also be applicable to various image-based classification and regression tasks. With our framework, it is even possible to learn models on multi-objective problems as we show by a pretraining on environmental metadata.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified ChineseRemote sensing and artificial intelligence是现代精准农业技术的关键。大规模场景图像的有效检索，结合机器学习技术，在不同任务中都有成功，如类型识别、除草、种植和病虫控制。本文将介绍一种机器学习框架，用于自动化大规模植物特征注释。我们使用 Deep Label Distribution Learning（DLDL）、特殊的损失函数和适应的模型架构，开发了一种高效的视Transformer基本模型，用于粉尘病虫评分。我们的novelty在于将远程感知数据与试验场地环境参数结合用于病虫评分预测。尽管这个模型是特定的用 случа，但它是可以应用于多种图像基本类型和回归任务的。我们的框架还可以学习多目标问题，如我们在环境元数据上进行预训练。
</details></li>
</ul>
<hr>
<h2 id="Maximal-Consistent-Subsystems-of-Max-T-Fuzzy-Relational-Equations"><a href="#Maximal-Consistent-Subsystems-of-Max-T-Fuzzy-Relational-Equations" class="headerlink" title="Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations"></a>Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03059">http://arxiv.org/abs/2311.03059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ismaïl Baaj</li>
<li>For: 这个论文研究了一种带有 $\max-$T 不确定关系方程 $A \Box_{T}^{\max} x &#x3D; b$ 的系统的不一致性。* Methods: 作者直接使用包性最大不一致子系统（w.r.t. 包含关系）的建构方法，使用 Chebyshev 距离 $\Delta &#x3D; \inf_{c \in \mathcal{C} \Vert b - c \Vert$ 来评估不一致性。* Results: 作者提供了一种基于同一个矩阵 $A$ 的不一致 $\max-\min$ 系统的所有一致子系统的有效方法，并证明了可以逐步获取所有最大一致子系统。<details>
<summary>Abstract</summary>
In this article, we study the inconsistency of a system of $\max-T$ fuzzy relational equations of the form $A \Box_{T}^{\max} x = b$, where $T$ is a t-norm among $\min$, the product or Lukasiewicz's t-norm. For an inconsistent $\max-T$ system, we directly construct a canonical maximal consistent subsystem (w.r.t the inclusion order). The main tool used to obtain it is the analytical formula which compute the Chebyshev distance $\Delta = \inf_{c \in \mathcal{C} \Vert b - c \Vert$ associated to the inconsistent $\max-T$ system, where $\mathcal{C}$ is the set of second members of consistent systems defined with the same matrix $A$. Based on the same analytical formula, we give, for an inconsistent $\max-\min$ system, an efficient method to obtain all its consistent subsystems, and we show how to iteratively get all its maximal consistent subsystems.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们研究了一个 $\max-T$ 软连接方程的不一致性，其形式为 $A \Box_{T}^{\max} x = b$，其中 $T$ 是一个 $\min$ 或者 Lukasiewicz 软连接。对于一个不一致的 $\max-T$ 系统，我们直接构建了一个 canonical 最大一致子系统（w.r.t. 包含关系）。我们使用了一个分析式公式计算 $\max-T$ 系统中的 Chebyshev 距离 $\Delta = \inf_{c \in \mathcal{C} \Vert b - c \Vert$，其中 $\mathcal{C}$ 是一个定义同 $A$ 矩阵的二元一致系统的集合。基于同一个分析式公式，我们对一个不一致的 $\max-\min$ 系统提供了一种高效的方法来获得所有一致子系统，并示出了如何逐步获得所有最大一致子系统。
</details></li>
</ul>
<hr>
<h2 id="LitSumm-Large-language-models-for-literature-summarisation-of-non-coding-RNAs"><a href="#LitSumm-Large-language-models-for-literature-summarisation-of-non-coding-RNAs" class="headerlink" title="LitSumm: Large language models for literature summarisation of non-coding RNAs"></a>LitSumm: Large language models for literature summarisation of non-coding RNAs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03056">http://arxiv.org/abs/2311.03056</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rnacentral/litscan-summarization">https://github.com/rnacentral/litscan-summarization</a></li>
<li>paper_authors: Andrew Green, Carlos Ribas, Nancy Ontiveros-Palacios, Anton I. Petrov, Alex Bateman, Blake Sweeney</li>
<li>for: 本研究旨在减轻生物学文献筛选的压力，通过自动生成非编码RNA文献摘要。</li>
<li>methods: 使用大语言模型（LLM）生成文献摘要，并使用链接的提问和检查来确保摘要的质量。</li>
<li>results: 研究表明，使用这种方法可以生成高质量、准确的文献摘要，并且可以通过人工评估和自动评估来验证摘要的质量。<details>
<summary>Abstract</summary>
Motivation: Curation of literature in life sciences is a growing challenge. The continued increase in the rate of publication, coupled with the relatively fixed number of curators worldwide presents a major challenge to developers of biomedical knowledgebases. Very few knowledgebases have resources to scale to the whole relevant literature and all have to prioritise their efforts.   Results: In this work, we take a first step to alleviating the lack of curator time in RNA science by generating summaries of literature for non-coding RNAs using large language models (LLMs). We demonstrate that high-quality, factually accurate summaries with accurate references can be automatically generated from the literature using a commercial LLM and a chain of prompts and checks. Manual assessment was carried out for a subset of summaries, with the majority being rated extremely high quality. We also applied the most commonly used automated evaluation approaches, finding that they do not correlate with human assessment. Finally, we apply our tool to a selection of over 4,600 ncRNAs and make the generated summaries available via the RNAcentral resource. We conclude that automated literature summarization is feasible with the current generation of LLMs, provided careful prompting and automated checking are applied.   Availability: Code used to produce these summaries can be found here: https://github.com/RNAcentral/litscan-summarization and the dataset of contexts and summaries can be found here: https://huggingface.co/datasets/RNAcentral/litsumm-v1. Summaries are also displayed on the RNA report pages in RNAcentral (https://rnacentral.org/)
</details>
<details>
<summary>摘要</summary>
目的：生命科学文献淘汰是一个快速增长的挑战。由于发表率的不断增长，与全球团队数量相对固定，这对生物医学知识库开发者而言是一个主要挑战。只有一些知识库有资源来涵盖整个相关文献，而其他都必须优化努力。结果：在这项工作中，我们采用自动生成文献摘要来减轻生物医学知识库缺乏审核人员时间的问题。我们使用商业大语言模型（LLM）生成非编码RNA的文献摘要，并证明可以自动生成高质量、准确的摘要，并且与文献中的参考相匹配。我们对一部分摘要进行了手动评估，并发现大多数摘要被评估为EXTREMELY HIGH QUALITY。此外，我们还应用了常用的自动评估方法，发现它们与人工评估不相关。最后，我们将生成的摘要应用于4,600多个ncRNA上，并将其作为RNAcentral资源提供。我们认为现代大语言模型可以自动生成文献摘要，只要仔细设置提示和自动检查。可用性：用于生成这些摘要的代码可以在GitHub上找到：https://github.com/RNAcentral/litscan-summarization。我们还提供了一个包含上下文和摘要的数据集：https://huggingface.co/datasets/RNAcentral/litsumm-v1。摘要还被显示在RNAreport页面上（https://rnacentral.org/)。
</details></li>
</ul>
<hr>
<h2 id="Masking-Hyperspectral-Imaging-Data-with-Pretrained-Models"><a href="#Masking-Hyperspectral-Imaging-Data-with-Pretrained-Models" class="headerlink" title="Masking Hyperspectral Imaging Data with Pretrained Models"></a>Masking Hyperspectral Imaging Data with Pretrained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03053">http://arxiv.org/abs/2311.03053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elias Arbash, Andréa de Lima Ribeiro, Sam Thiele, Nina Gnann, Behnood Rasti, Margret Fuchs, Pedram Ghamisi, Richard Gloaguen</li>
<li>for: 提高干扰特征数据处理性能，增强计算成本效益、内存需求和总性能。</li>
<li>methods: 采用Segment Anything Model（SAM）抽象所有对象，然后使用零扩展Grounding Dino对象检测器进行筛选、 intersection和 exclusion步骤，不需要 fine-tuning 或 retraining。</li>
<li>results: 在三个复杂应用场景中提供精确的掩码，包括塑料碎屑特征化、钻井检查和垃圾监测。提供数值评估结果和使用的超参数。<details>
<summary>Abstract</summary>
The presence of undesired background areas associated with potential noise and unknown spectral characteristics degrades the performance of hyperspectral data processing. Masking out unwanted regions is key to addressing this issue. Processing only regions of interest yields notable improvements in terms of computational costs, required memory, and overall performance. The proposed processing pipeline encompasses two fundamental parts: regions of interest mask generation, followed by the application of hyperspectral data processing techniques solely on the newly masked hyperspectral cube. The novelty of our work lies in the methodology adopted for the preliminary image segmentation. We employ the Segment Anything Model (SAM) to extract all objects within the dataset, and subsequently refine the segments with a zero-shot Grounding Dino object detector, followed by intersection and exclusion filtering steps, without the need for fine-tuning or retraining. To illustrate the efficacy of the masking procedure, the proposed method is deployed on three challenging applications scenarios that demand accurate masking; shredded plastics characterization, drill core scanning, and litter monitoring. The numerical evaluation of the proposed masking method on the three applications is provided along with the used hyperparameters. The scripts for the method will be available at https://github.com/hifexplo/Masking.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>诸如不需要的背景区域与可能的噪声和未知 спектраль特征可能会降低高spectral数据处理的性能。从Masking这些区域中移除这些区域是解决这个问题的关键。只处理区域对应的数据可以大幅降低计算成本、内存需求和总性能。我们的处理管道包括两个基本部分：首先生成区域对应mask，然后仅应用高spectral数据处理技术于新生成的masked hyperspectral куби。我们的工作的创新性在于采用的Segment Anything Model（SAM）模型来EXTRACT所有对象于dataset中，然后使用零搭建Grounding Dino对象检测器进行筛选，并进行交叠和排除步骤，无需精度调整或重新训练。为了证明Masking过程的有效性，我们在三个复杂应用场景中运行了提议的方法：扯毁塑料特征化、钻探核心扫描和垃圾监测。我们提供了这三个应用场景的数值评估结果，以及使用的超参数。方法的脚本将会在https://github.com/hifexplo/Masking上提供。
</details></li>
</ul>
<hr>
<h2 id="Grouping-Local-Process-Models"><a href="#Grouping-Local-Process-Models" class="headerlink" title="Grouping Local Process Models"></a>Grouping Local Process Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03040">http://arxiv.org/abs/2311.03040</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Viki Peeva, Wil M. P. van der Aalst</li>
<li>for: 本研究旨在提出一种三步管道，用于将相似的本地过程模型（LPM） grouped together，以提高过程挖掘的效率和可读性。</li>
<li>methods: 本研究使用了多种过程模型相似度度量，包括过程模型的结构相似度、动作序列相似度和时间序列相似度，以分组相似的LPM。</li>
<li>results: 实验结果表明，通过分组相似的LPM可以减少模型爆炸和重复现象，提高过程挖掘的效率和可读性。在一个真实的案例研究中，分组后的LPM数量减少了一半，同时模型的重复率也得到了改善。<details>
<summary>Abstract</summary>
In recent years, process mining emerged as a proven technology to analyze and improve operational processes. An expanding range of organizations using process mining in their daily operation brings a broader spectrum of processes to be analyzed. Some of these processes are highly unstructured, making it difficult for traditional process discovery approaches to discover a start-to-end model describing the entire process. Therefore, the subdiscipline of Local Process Model (LPM) discovery tries to build a set of LPMs, i.e., smaller models that explain sub-behaviors of the process. However, like other pattern mining approaches, LPM discovery algorithms also face the problems of model explosion and model repetition, i.e., the algorithms may create hundreds if not thousands of models, and subsets of them are close in structure or behavior. This work proposes a three-step pipeline for grouping similar LPMs using various process model similarity measures. We demonstrate the usefulness of grouping through a real-life case study, and analyze the impact of different measures, the gravity of repetition in the discovered LPMs, and how it improves after grouping on multiple real event logs.
</details>
<details>
<summary>摘要</summary>
recent 年份, 过程挖掘技术 emerged 为操作过程分析和改进的证明技术。更多的组织在日常操作中使用过程挖掘， bringing 更广泛的过程需要分析。一些这些过程具有高度不结构化，使得传统的过程发现方法难以找到一个从开始到结束的过程模型。因此，本领域的地方过程模型（LPM）发现领域尝试建立一组 LPM，即更小的模型，描述过程的子行为。然而，如其他模式挖掘方法一样， LPM 发现算法也面临着模型爆炸和模型重复的问题，即算法可能生成百计、万计的模型，并且其中的一些模型具有相似结构或行为。本工作提出了一个三步管道，用于将相似的 LPM  grouped 使用不同的过程模型相似度度量。我们通过实际案例研究证明了 grouping 的有用性，并分析了不同度量的影响、重复的gravity 和多个实际事件日志中的改进。
</details></li>
</ul>
<hr>
<h2 id="GTP-ViT-Efficient-Vision-Transformers-via-Graph-based-Token-Propagation"><a href="#GTP-ViT-Efficient-Vision-Transformers-via-Graph-based-Token-Propagation" class="headerlink" title="GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation"></a>GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03035">http://arxiv.org/abs/2311.03035</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ackesnal/gtp-vit">https://github.com/ackesnal/gtp-vit</a></li>
<li>paper_authors: Xuwei Xu, Sen Wang, Yudong Chen, Yanping Zheng, Zhewei Wei, Jiajun Liu<br>for: 这个研究旨在提高资源有限的设备上运行Pre-trained Vision Transformer（ViT）模型的效率，以减少计算复杂度。methods: 本研究提出了一种名为Graph-based Token Propagation（GTP）的新方法，它利用图 summarization 算法勤务地传播不重要的 tokens 的信息到空间和semantically相关的 tokens。results: GTP 可以有效地降低 DeiT-S 和 DeiT-B 模型的计算复杂度，而且和state-of-the-art 对应的token merging方法相比，它在不同的backbone上还能实现更快的推察速度。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have revolutionized the field of computer vision, yet their deployments on resource-constrained devices remain challenging due to high computational demands. To expedite pre-trained ViTs, token pruning and token merging approaches have been developed, which aim at reducing the number of tokens involved in the computation. However, these methods still have some limitations, such as image information loss from pruned tokens and inefficiency in the token-matching process. In this paper, we introduce a novel Graph-based Token Propagation (GTP) method to resolve the challenge of balancing model efficiency and information preservation for efficient ViTs. Inspired by graph summarization algorithms, GTP meticulously propagates less significant tokens' information to spatially and semantically connected tokens that are of greater importance. Consequently, the remaining few tokens serve as a summarization of the entire token graph, allowing the method to reduce computational complexity while preserving essential information of eliminated tokens. Combined with an innovative token selection strategy, GTP can efficiently identify image tokens to be propagated. Extensive experiments have validated GTP's effectiveness, demonstrating both efficiency and performance improvements. Specifically, GTP decreases the computational complexity of both DeiT-S and DeiT-B by up to 26% with only a minimal 0.3% accuracy drop on ImageNet-1K without finetuning, and remarkably surpasses the state-of-the-art token merging method on various backbones at an even faster inference speed. The source code is available at https://github.com/Ackesnal/GTP-ViT.
</details>
<details>
<summary>摘要</summary>
vision transformers (ViTs) 已经革命化了计算机视觉领域，但它们在有限资源设备上的部署仍然具有挑战，主要是因为高计算复杂度。为了加速预训练的 ViTs，块剪枝和块合并方法已经被开发出来，目的是减少计算中的块数。然而，这些方法仍有一些限制，例如图像信息损失和块匹配过程中的不效率。在这篇论文中，我们介绍了一种新的图像基于的块传播方法（GTP），用于解决高效性和信息保留之间的权衡问题。通过图像分割和图像描述符的组合，GTP 可以减少计算复杂度，同时保持图像信息的精度。与其他方法相比，GTP 可以更好地快速地进行图像识别。我们还提出了一种创新的块选择策略，可以快速地选择需要传播的块。我们的实验结果表明，GTP 可以在不需要finetuning的情况下，对 DeiT-S 和 DeiT-B 降低计算复杂度，最多下降26%，只有0.3%的准确率下降。此外，GTP 还可以在不同的基础上remarkably exceeds the state-of-the-art token merging method的速度。我们的代码可以在 <https://github.com/Ackesnal/GTP-ViT> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Words-A-Mathematical-Framework-for-Interpreting-Large-Language-Models"><a href="#Beyond-Words-A-Mathematical-Framework-for-Interpreting-Large-Language-Models" class="headerlink" title="Beyond Words: A Mathematical Framework for Interpreting Large Language Models"></a>Beyond Words: A Mathematical Framework for Interpreting Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03033">http://arxiv.org/abs/2311.03033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javier González, Aditya V. Nori</li>
<li>for: 这篇论文的目的是为了提供一种数学基础来描述、比较和改进大型自然语言模型（LLM）。</li>
<li>methods: 该论文使用了一种名为“Hex”的框架，以确定关键的概念和词汇在LLM研究中。这个框架可以帮助研究人员和实践者更好地描述LLM的特点、优缺点和新发现。</li>
<li>results: 该论文通过使用“Hex”框架，分别了“链条思维”和“链条提示”两个概念，并证明了它们在某些情况下是等价的。这些结论有助于理解Chain-of-thought prompting的基本假设和其影响。这篇论文的目的是为了提供一种 formal 的框架，以便研究人员和实践者可以更好地探索新的生成AI系统。<details>
<summary>Abstract</summary>
Large language models (LLMs) are powerful AI tools that can generate and comprehend natural language text and other complex information. However, the field lacks a mathematical framework to systematically describe, compare and improve LLMs. We propose Hex a framework that clarifies key terms and concepts in LLM research, such as hallucinations, alignment, self-verification and chain-of-thought reasoning. The Hex framework offers a precise and consistent way to characterize LLMs, identify their strengths and weaknesses, and integrate new findings. Using Hex, we differentiate chain-of-thought reasoning from chain-of-thought prompting and establish the conditions under which they are equivalent. This distinction clarifies the basic assumptions behind chain-of-thought prompting and its implications for methods that use it, such as self-verification and prompt programming.   Our goal is to provide a formal framework for LLMs that can help both researchers and practitioners explore new possibilities for generative AI. We do not claim to have a definitive solution, but rather a tool for opening up new research avenues. We argue that our formal definitions and results are crucial for advancing the discussion on how to build generative AI systems that are safe, reliable, fair and robust, especially in domains like healthcare and software engineering.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）是一种强大的人工智能工具，可以生成和理解自然语言文本和其他复杂信息。然而，这个领域缺乏一个数学基础来系统地描述、比较和改进 LLM。我们提出了 hex 框架，它明确了关键术语和概念在 LLM 研究中，如幻觉、对齐、自我验证和链式思维。hex 框架提供了精确和一致的方式来描述 LLM，发现其优缺点，并集成新发现。使用 hex，我们区分了链式思维和链式思维激活，并确定了它们在什么情况下是等价的。这种分化了链式思维的假设和其影响，例如自我验证和提问编程。我们的目标是为 LLM 提供一个正式的数学基础，以帮助研究人员和实践者探索新的可能性 для生成人工智能系统。我们并不宣称有终极解决方案，而是一种工具来开拓新的研究途径。我们认为我们的正式定义和结果是推动生成人工智能系统的安全、可靠、公正和可靠性的关键，尤其在医疗和软件工程领域。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Clinical-Structured-Data-A-Benchmark-Comparison-of-Engineering-and-Statistical-Approaches"><a href="#Federated-Learning-for-Clinical-Structured-Data-A-Benchmark-Comparison-of-Engineering-and-Statistical-Approaches" class="headerlink" title="Federated Learning for Clinical Structured Data: A Benchmark Comparison of Engineering and Statistical Approaches"></a>Federated Learning for Clinical Structured Data: A Benchmark Comparison of Engineering and Statistical Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03417">http://arxiv.org/abs/2311.03417</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nliulab/fl-benchmark">https://github.com/nliulab/fl-benchmark</a></li>
<li>paper_authors: Siqi Li, Di Miao, Qiming Wu, Chuan Hong, Danny D’Agostino, Xin Li, Yilin Ning, Yuqing Shang, Huazhu Fu, Marcus Eng Hock Ong, Hamed Haddadi, Nan Liu</li>
<li>for: 保护医疗合作中数据隐私</li>
<li>methods: 比较了两个领域中的 federated learning 框架，包括工程域和统计领域</li>
<li>results: 显示了两种类型的方法在不同数据集上的表现，统计型 federated learning 方法生成较准确的点估计，但工程型方法生成较高的预测值，需要将两种方法融合应用于未来的 federated learning 应用中。Please note that the above results are in Simplified Chinese text, as requested.<details>
<summary>Abstract</summary>
Federated learning (FL) has shown promising potential in safeguarding data privacy in healthcare collaborations. While the term "FL" was originally coined by the engineering community, the statistical field has also explored similar privacy-preserving algorithms. Statistical FL algorithms, however, remain considerably less recognized than their engineering counterparts. Our goal was to bridge the gap by presenting the first comprehensive comparison of FL frameworks from both engineering and statistical domains. We evaluated five FL frameworks using both simulated and real-world data. The results indicate that statistical FL algorithms yield less biased point estimates for model coefficients and offer convenient confidence interval estimations. In contrast, engineering-based methods tend to generate more accurate predictions, sometimes surpassing central pooled and statistical FL models. This study underscores the relative strengths and weaknesses of both types of methods, emphasizing the need for increased awareness and their integration in future FL applications.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）在医疗协作中实现数据隐私的潜力非常大。这个概念原本是由工程师社群所创造，但是统计领域也已经探索了相似的隐私保护算法。统计学FL算法相对较少获得了认可，我们的目标是通过比较两个领域的FL框架，将它们融合在一起，以便更好地理解它们的优缺点，并且强调未来FL应用中它们的整合。我们评估了五种FL框架，包括工程学和统计学的方法，使用实验和真实数据进行评估。结果显示，统计学FL算法可以产生较少偏差的点估计，并且可以方便地Estimation confidence interval。相比之下，工程学基于的方法可以产生更加准确的预测，有时会超过中央聚合和统计学FL模型。这个研究显示了两种方法之间的相对优缺点，强调未来FL应用中它们的整合。
</details></li>
</ul>
<hr>
<h2 id="Visual-information-driven-model-for-crowd-simulation-using-temporal-convolutional-network"><a href="#Visual-information-driven-model-for-crowd-simulation-using-temporal-convolutional-network" class="headerlink" title="Visual-information-driven model for crowd simulation using temporal convolutional network"></a>Visual-information-driven model for crowd simulation using temporal convolutional network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02996">http://arxiv.org/abs/2311.02996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanwen Liang, Eric Wai Ming Lee</li>
<li>for: 提高数据驱动人群模拟模型的适应性和现实感</li>
<li>methods:  incorporating visual information, including scenario geometry and pedestrian locomotion, to enhance the adaptability and realism of data-driven crowd simulation models</li>
<li>results: 在三种不同的公共人群运动数据集上测试并评估了一种视觉信息驱动的人群模拟模型，并发现模型在不同的几何场景下具有改进的适应性。<details>
<summary>Abstract</summary>
Crowd simulations play a pivotal role in building design, influencing both user experience and public safety. While traditional knowledge-driven models have their merits, data-driven crowd simulation models promise to bring a new dimension of realism to these simulations. However, most of the existing data-driven models are designed for specific geometries, leading to poor adaptability and applicability. A promising strategy for enhancing the adaptability and realism of data-driven crowd simulation models is to incorporate visual information, including the scenario geometry and pedestrian locomotion. Consequently, this paper proposes a novel visual-information-driven (VID) crowd simulation model. The VID model predicts the pedestrian velocity at the next time step based on the prior social-visual information and motion data of an individual. A radar-geometry-locomotion method is established to extract the visual information of pedestrians. Moreover, a temporal convolutional network (TCN)-based deep learning model, named social-visual TCN, is developed for velocity prediction. The VID model is tested on three public pedestrian motion datasets with distinct geometries, i.e., corridor, corner, and T-junction. Both qualitative and quantitative metrics are employed to evaluate the VID model, and the results highlight the improved adaptability of the model across all three geometric scenarios. Overall, the proposed method demonstrates effectiveness in enhancing the adaptability of data-driven crowd models.
</details>
<details>
<summary>摘要</summary>
人群模拟在建筑设计中发挥重要作用，影响用户体验和公共安全。传统的知识驱动模型具有一定的优点，但数据驱动人群模拟模型具有更高的真实感和应用性。然而，现有的数据驱动模型大多是为特定的几何设计，导致适应性和可应用性弱。为了提高数据驱动人群模拟模型的适应性和真实感，本文提出了一种视觉信息驱动（VID）人群模拟模型。VID模型根据先前的社交视觉信息和人员运动数据预测下一步人群速度。通过 радиар几何运动方法提取人员的视觉信息，并开发了基于深度学习的社交视觉TCN模型来实现速度预测。VID模型在三个不同几何enario中进行测试，包括挺口、角落和T字口。使用质量和量度指标评估VID模型，结果显示VID模型在所有三个几何scenario中的适应性得到了明显提高。总的来说，该方法可以有效地提高数据驱动人群模拟模型的适应性。
</details></li>
</ul>
<hr>
<h2 id="PowerFlowNet-Leveraging-Message-Passing-GNNs-for-Improved-Power-Flow-Approximation"><a href="#PowerFlowNet-Leveraging-Message-Passing-GNNs-for-Improved-Power-Flow-Approximation" class="headerlink" title="PowerFlowNet: Leveraging Message Passing GNNs for Improved Power Flow Approximation"></a>PowerFlowNet: Leveraging Message Passing GNNs for Improved Power Flow Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03415">http://arxiv.org/abs/2311.03415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Lin, Stavros Orfanoudakis, Nathan Ordonez Cardenas, Juan S. Giraldo, Pedro P. Vergara</li>
<li>for: 这个论文是为了提出一种高效的电力流分析方法，以便现代电力网络的高效运行和规划。</li>
<li>methods: 这个论文使用图神经网络（GNNs）来加速电力流分析的速度，并且能够保持与传统新颖瑞索法（Newton-Raphson method）的性能相似，但是运行速度比传统方法四倍快（在简单的IEEE 14-bus系统中）和145倍快（在法国高压网络（6470rte）中）。</li>
<li>results: 论文表明，PowerFlowNet在性能和执行速度两个方面都在传统approximation方法（DC relaxation method）之上显著提高，因此PowerFlowNet是一种非常有前途的解决方案 для实际的电力流分析。此外，论文还进行了严格的实验评估，并提供了GNNs在电力系统分析中的应用前景。<details>
<summary>Abstract</summary>
Accurate and efficient power flow (PF) analysis is crucial in modern electrical networks' efficient operation and planning. Therefore, there is a need for scalable algorithms capable of handling large-scale power networks that can provide accurate and fast solutions. Graph Neural Networks (GNNs) have emerged as a promising approach for enhancing the speed of PF approximations by leveraging their ability to capture distinctive features from the underlying power network graph. In this study, we introduce PowerFlowNet, a novel GNN architecture for PF approximation that showcases similar performance with the traditional Newton-Raphson method but achieves it 4 times faster in the simple IEEE 14-bus system and 145 times faster in the realistic case of the French high voltage network (6470rte). Meanwhile, it significantly outperforms other traditional approximation methods, such as the DC relaxation method, in terms of performance and execution time; therefore, making PowerFlowNet a highly promising solution for real-world PF analysis. Furthermore, we verify the efficacy of our approach by conducting an in-depth experimental evaluation, thoroughly examining the performance, scalability, interpretability, and architectural dependability of PowerFlowNet. The evaluation provides insights into the behavior and potential applications of GNNs in power system analysis.
</details>
<details>
<summary>摘要</summary>
现代电力网络的有效和高效运行需要准确和高速的电力流（PF）分析。因此，有一需求为大规模电力网络提供准确和快速的解决方案。图 Néural Networks（GNNs）已经出现为PF估算的快速方法，通过利用其对电力网络图中独特特征的捕捉能力。在本研究中，我们介绍PowerFlowNet，一种新的GNN架构，可以在PF估算中实现类似于传统的Newton-Raphson方法的性能，但是4倍 faster在简单的IEEE 14-bus系统中和145倍 faster在实际的法国高压网络（6470rte）中。此外，它在其他传统估算方法，如DC缓和方法，之上显著超越其性能和执行时间，因此使PowerFlowNet成为实际PF分析中的非常有前途的解决方案。此外，我们对PowerFlowNet的方法进行了广泛的实验评估，彻底检查了它的性能、可扩展性、可读性和架构可靠性。实验结果提供了GNN在电力系统分析中的行为和潜在应用的深入了解。
</details></li>
</ul>
<hr>
<h2 id="A-Generative-Neural-Network-Approach-for-3D-Multi-Criteria-Design-Generation-and-Optimization-of-an-Engine-Mount-for-an-Unmanned-Air-Vehicle"><a href="#A-Generative-Neural-Network-Approach-for-3D-Multi-Criteria-Design-Generation-and-Optimization-of-an-Engine-Mount-for-an-Unmanned-Air-Vehicle" class="headerlink" title="A Generative Neural Network Approach for 3D Multi-Criteria Design Generation and Optimization of an Engine Mount for an Unmanned Air Vehicle"></a>A Generative Neural Network Approach for 3D Multi-Criteria Design Generation and Optimization of an Engine Mount for an Unmanned Air Vehicle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03414">http://arxiv.org/abs/2311.03414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christoph Petroll, Sebastian Eilermann, Philipp Hoefer, Oliver Niggemann</li>
<li>for: 这篇论文旨在提出一种基于生成神经网络的多 критериria 3D 设计生成方法，用于解决多个功能条件下的设计问题。</li>
<li>methods: 该论文使用 Conditional Variational Autoencoder (CVAE) 来学习多个功能条件下的geometry和相关的多 критериria 约束，并使用 Marching cubes 算法生成优化的 meshes 进行模拟评估。</li>
<li>results: 该论文通过对10,000个抽象 3D 设计进行多种物理学方法的 simulate，并使用自定义的功能条件来训练 CVAE，最终实现了基于多个功能条件的优化设计生成。<details>
<summary>Abstract</summary>
One of the most promising developments in computer vision in recent years is the use of generative neural networks for functionality condition-based 3D design reconstruction and generation. Here, neural networks learn dependencies between functionalities and a geometry in a very effective way. For a neural network the functionalities are translated in conditions to a certain geometry. But the more conditions the design generation needs to reflect, the more difficult it is to learn clear dependencies. This leads to a multi criteria design problem due various conditions, which are not considered in the neural network structure so far.   In this paper, we address this multi-criteria challenge for a 3D design use case related to an unmanned aerial vehicle (UAV) motor mount. We generate 10,000 abstract 3D designs and subject them all to simulations for three physical disciplines: mechanics, thermodynamics, and aerodynamics. Then, we train a Conditional Variational Autoencoder (CVAE) using the geometry and corresponding multicriteria functional constraints as input. We use our trained CVAE as well as the Marching cubes algorithm to generate meshes for simulation based evaluation. The results are then evaluated with the generated UAV designs. Subsequently, we demonstrate the ability to generate optimized designs under self-defined functionality conditions using the trained neural network.
</details>
<details>
<summary>摘要</summary>
In this paper, we address this multi-criteria challenge for a 3D design use case related to an unmanned aerial vehicle (UAV) motor mount. We generate 10,000 abstract 3D designs and subject them all to simulations for three physical disciplines: mechanics, thermodynamics, and aerodynamics. Then, we train a Conditional Variational Autoencoder (CVAE) using the geometry and corresponding multicriteria functional constraints as input. We use our trained CVAE as well as the Marching cubes algorithm to generate meshes for simulation-based evaluation. The results are then evaluated with the generated UAV designs. Subsequently, we demonstrate the ability to generate optimized designs under self-defined functionality conditions using the trained neural network.
</details></li>
</ul>
<hr>
<h2 id="Discret2Di-–-Deep-Learning-based-Discretization-for-Model-based-Diagnosis"><a href="#Discret2Di-–-Deep-Learning-based-Discretization-for-Model-based-Diagnosis" class="headerlink" title="Discret2Di – Deep Learning based Discretization for Model-based Diagnosis"></a>Discret2Di – Deep Learning based Discretization for Model-based Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03413">http://arxiv.org/abs/2311.03413</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Moddemann, Henrik Sebastian Steude, Alexander Diedrich, Oliver Niggemann</li>
<li>for: 这个论文是为了提出一种自动学习逻辑表达的方法，以便用于监测和诊断技术应用中的不一致现象。</li>
<li>methods: 该论文使用了机器学习技术，以自动学习逻辑表达，并将时间序列转换为逻辑表达。</li>
<li>results: 该论文提出了一种名为Discret2Di的方法，可以自动学习逻辑表达，并且可以处理动态多Modal时间序列。<details>
<summary>Abstract</summary>
Consistency-based diagnosis is an established approach to diagnose technical applications, but suffers from significant modeling efforts, especially for dynamic multi-modal time series. Machine learning seems to be an obvious solution, which becomes less obvious when looking at details: Which notion of consistency can be used? If logical calculi are still to be used, how can dynamic time series be transferred into the discrete world?   This paper presents the methodology Discret2Di for automated learning of logical expressions for consistency-based diagnosis. While these logical calculi have advantages by providing a clear notion of consistency, they have the key problem of relying on a discretization of the dynamic system. The solution presented combines machine learning from both the time series and the symbolic domain to automate the learning of logical rules for consistency-based diagnosis.
</details>
<details>
<summary>摘要</summary>
Traditional consistency-based diagnosis is a widely used approach for diagnosing technical systems, but it requires significant modeling efforts, especially for dynamic multi-modal time series. Machine learning seems to be a natural solution, but it raises questions about which notion of consistency to use and how to transfer dynamic time series into the discrete world.This paper proposes a methodology called Discret2Di for automated learning of logical expressions for consistency-based diagnosis. While logical calculi have advantages in providing a clear notion of consistency, they rely on discretization of the dynamic system, which can be a limiting factor. The proposed solution combines machine learning from both the time series and symbolic domains to automate the learning of logical rules for consistency-based diagnosis.
</details></li>
</ul>
<hr>
<h2 id="TabRepo-A-Large-Scale-Repository-of-Tabular-Model-Evaluations-and-its-AutoML-Applications"><a href="#TabRepo-A-Large-Scale-Repository-of-Tabular-Model-Evaluations-and-its-AutoML-Applications" class="headerlink" title="TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications"></a>TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02971">http://arxiv.org/abs/2311.02971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/autogluon/tabrepo">https://github.com/autogluon/tabrepo</a></li>
<li>paper_authors: David Salinas, Nick Erickson</li>
<li>for: 本研究的目的是提供一个新的 tabular 模型评估和预测数据集（TabRepo），用于比较不同的 hyperparameter 优化和 AutoML 系统，以及进行转移学习。</li>
<li>methods: 本研究使用了 1206 个模型和 200 个回归和分类数据集进行预测和评估，并提供了预计算的模型预测，以便进行比较和转移学习。</li>
<li>results: 研究表明，使用 TabRepo 可以免除耗时和资源的 Hyperparameter Optimization，并且可以通过标准的转移学习技术来超越当前的 tabular 系统，包括准确率、运行时间和响应时间。<details>
<summary>Abstract</summary>
We introduce TabRepo, a new dataset of tabular model evaluations and predictions. TabRepo contains the predictions and metrics of 1206 models evaluated on 200 regression and classification datasets. We illustrate the benefit of our datasets in multiple ways. First, we show that it allows to perform analysis such as comparing Hyperparameter Optimization against current AutoML systems while also considering ensembling at no cost by using precomputed model predictions. Second, we show that our dataset can be readily leveraged to perform transfer-learning. In particular, we show that applying standard transfer-learning techniques allows to outperform current state-of-the-art tabular systems in accuracy, runtime and latency.
</details>
<details>
<summary>摘要</summary>
我们介绍TabRepo，一个新的表格型模型评估和预测Dataset。TabRepo包含1206个模型在200个数据集上的预测和度量。我们显示了我们的Dataset可以进行以下多种分析：首先，我们显示了在使用预先计算的模型预测时，可以免费进行几何参数优化和AutoML系统的比较。其次，我们显示了我们的Dataset可以轻松地进行传播学习。具体来说，我们显示了使用标准传播学习技术可以超越现有的表格系统在精度、时间和延迟方面的表现。
</details></li>
</ul>
<hr>
<h2 id="Retrieval-Augmented-Code-Generation-for-Universal-Information-Extraction"><a href="#Retrieval-Augmented-Code-Generation-for-Universal-Information-Extraction" class="headerlink" title="Retrieval-Augmented Code Generation for Universal Information Extraction"></a>Retrieval-Augmented Code Generation for Universal Information Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02962">http://arxiv.org/abs/2311.02962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yucan Guo, Zixuan Li, Xiaolong Jin, Yantao Liu, Yutao Zeng, Wenxuan Liu, Xiang Li, Pan Yang, Long Bai, Jiafeng Guo, Xueqi Cheng</li>
<li>for: 这篇论文的目的是提出一种基于大自然语言模型（LLM）的代码生成框架，用于解决信息抽取（IE）任务中的表示知识结构的问题。</li>
<li>methods: 这篇论文使用的方法包括：（1）使用 Python 类定义任务特定的 schema，以便在一个通用的方式下提取知识结构。（2）采用在上下文学习机制，以便通过示例教育 LLM 生成更加准确的代码。（3）检索相似文本示例，以便在不同任务中获得适当的示例。</li>
<li>results: 对于五种代表性的 IE 任务，Code4UIE 框架在九个数据集上进行了广泛的实验，并达到了显著的效果。<details>
<summary>Abstract</summary>
Information Extraction (IE) aims to extract structural knowledge (e.g., entities, relations, events) from natural language texts, which brings challenges to existing methods due to task-specific schemas and complex text expressions. Code, as a typical kind of formalized language, is capable of describing structural knowledge under various schemas in a universal way. On the other hand, Large Language Models (LLMs) trained on both codes and texts have demonstrated powerful capabilities of transforming texts into codes, which provides a feasible solution to IE tasks. Therefore, in this paper, we propose a universal retrieval-augmented code generation framework based on LLMs, called Code4UIE, for IE tasks. Specifically, Code4UIE adopts Python classes to define task-specific schemas of various structural knowledge in a universal way. By so doing, extracting knowledge under these schemas can be transformed into generating codes that instantiate the predefined Python classes with the information in texts. To generate these codes more precisely, Code4UIE adopts the in-context learning mechanism to instruct LLMs with examples. In order to obtain appropriate examples for different tasks, Code4UIE explores several example retrieval strategies, which can retrieve examples semantically similar to the given texts. Extensive experiments on five representative IE tasks across nine datasets demonstrate the effectiveness of the Code4UIE framework.
</details>
<details>
<summary>摘要</summary>
信息提取（IE）的目标是从自然语言文本中提取结构知识（例如实体、关系、事件），这会对现有方法带来挑战，因为文本表达的复杂性和任务特定的模式。代码作为一种形式化语言，可以在不同的模式下描述结构知识，并且可以通过大语言模型（LLM）的训练来将文本转化为代码。因此，在本文中，我们提出了一个基于 LLM 的通用检索增强代码生成框架，称为 Code4UIE，用于 IE 任务。具体来说，Code4UIE 使用 Python 类定义任务特定的结构知识模式，以 universal 的方式来定义不同的结构知识模式。通过这种方式，可以将文本中的知识提取转化为生成代码，并且使用 LLM 的增强学习机制来更 precisely 生成代码。为了获得不同任务的适当示例，Code4UIE 探索了多种示例检索策略，可以将示例与文本进行semantic 的对比。经过了五种代表性的 IE 任务和九个数据集的广泛实验，我们证明了 Code4UIE 框架的有效性。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Learning-for-Knowledge-Base-Question-Answering-for-Unmanned-Systems-based-on-Large-Language-Models"><a href="#In-Context-Learning-for-Knowledge-Base-Question-Answering-for-Unmanned-Systems-based-on-Large-Language-Models" class="headerlink" title="In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models"></a>In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02956">http://arxiv.org/abs/2311.02956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlong Chen, Yaming Zhang, Jianfei Yu, Li Yang, Rui Xia</li>
<li>for: Answering factoid questions based on knowledge bases in the CCKS2023 Competition of Question Answering with Knowledge Graph Inference for Unmanned Systems.</li>
<li>methods: Proposed a ChatGPT-based Cypher Query Language (CQL) generation framework that generates the most appropriate CQL based on the given Natural Language Question (NLQ). The framework consists of six parts: auxiliary model, proper noun matcher, demonstration example selector, prompt constructor, ChatGPT-based generation model, and ensemble model.</li>
<li>results: Achieved the second place in the CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems competition with an F1-score of 0.92676.<details>
<summary>Abstract</summary>
Knowledge Base Question Answering (KBQA) aims to answer factoid questions based on knowledge bases. However, generating the most appropriate knowledge base query code based on Natural Language Questions (NLQ) poses a significant challenge in KBQA. In this work, we focus on the CCKS2023 Competition of Question Answering with Knowledge Graph Inference for Unmanned Systems. Inspired by the recent success of large language models (LLMs) like ChatGPT and GPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL) generation framework to generate the most appropriate CQL based on the given NLQ. Our generative framework contains six parts: an auxiliary model predicting the syntax-related information of CQL based on the given NLQ, a proper noun matcher extracting proper nouns from the given NLQ, a demonstration example selector retrieving similar examples of the input sample, a prompt constructor designing the input template of ChatGPT, a ChatGPT-based generation model generating the CQL, and an ensemble model to obtain the final answers from diversified outputs. With our ChatGPT-based CQL generation framework, we achieved the second place in the CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems competition, achieving an F1-score of 0.92676.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>An auxiliary model predicting the syntax-related information of CQL based on the given NLQ.2. A proper noun matcher extracting proper nouns from the given NLQ.3. A demonstration example selector retrieving similar examples of the input sample.4. A prompt constructor designing the input template of ChatGPT.5. A ChatGPT-based generation model generating the CQL.6. An ensemble model to obtain the final answers from diversified outputs.With our ChatGPT-based CQL generation framework, we achieved the second place in the CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems competition, achieving an F1-score of 0.92676.</details></li>
</ol>
<hr>
<h2 id="Contrastive-Multi-Level-Graph-Neural-Networks-for-Session-based-Recommendation"><a href="#Contrastive-Multi-Level-Graph-Neural-Networks-for-Session-based-Recommendation" class="headerlink" title="Contrastive Multi-Level Graph Neural Networks for Session-based Recommendation"></a>Contrastive Multi-Level Graph Neural Networks for Session-based Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02938">http://arxiv.org/abs/2311.02938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuyun Wang, Xingyu Gao, Zhenyu Chen, Lei Lyu</li>
<li>for: 这 paper 的目的是提出一种基于对比学习的Session-based recommendation（SBR）方法，以便更好地利用短时间内用户 anonymous 行为序列中的高阶项转移信息。</li>
<li>methods: 该 paper 使用了一种名为 Contrastive Multi-level Graph Neural Networks (CM-GNN)，它将在当前会话和所有会话中应用本地级别的图解归 neural network (L-GCN) 和全局级别的图解归 neural network (G-GCN)，以 Capture 对会话中所有item的高阶相关信息。此外，paper 还引入了一种听道权重 fusion 模块，以学习对会话中item的Pairwise关系。</li>
<li>results: 该 paper 的实验结果表明，CM-GNN 可以在多个 widely used 数据集上击败现有的 SBR 技术。<details>
<summary>Abstract</summary>
Session-based recommendation (SBR) aims to predict the next item at a certain time point based on anonymous user behavior sequences. Existing methods typically model session representation based on simple item transition information. However, since session-based data consists of limited users' short-term interactions, modeling session representation by capturing fixed item transition information from a single dimension suffers from data sparsity. In this paper, we propose a novel contrastive multi-level graph neural networks (CM-GNN) to better exploit complex and high-order item transition information. Specifically, CM-GNN applies local-level graph convolutional network (L-GCN) and global-level network (G-GCN) on the current session and all the sessions respectively, to effectively capture pairwise relations over all the sessions by aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph convolutional network (H-GCN) to capture high-order information among all the item transitions. CM-GNN further introduces an attention-based fusion module to learn pairwise relation-based session representation by fusing the item representations generated by L-GCN and G-GCN. CM-GNN averages the item representations obtained by H-GCN to obtain high-order relation-based session representation. Moreover, to convert the high-order item transition information into the pairwise relation-based session representation, CM-GNN maximizes the mutual information between the representations derived from the fusion module and the average pool layer by contrastive learning paradigm. We conduct extensive experiments on multiple widely used benchmark datasets to validate the efficacy of the proposed method. The encouraging results demonstrate that our proposed method outperforms the state-of-the-art SBR techniques.
</details>
<details>
<summary>摘要</summary>
Session-based recommendation (SBR) 目标是在某个时间点预测下一个 Item，基于匿名用户行为序列。现有方法通常基于简单的 Item 转移信息来建模 session 表示。然而，由于session-based 数据包含有限的用户短期互动，基于单一维度的 Item 转移信息建模 session 表示会受到数据稀缺的困扰。在这篇论文中，我们提出了一种新的对比式多级图 neural network (CM-GNN)，以更好地利用复杂的高阶 Item 转移信息。CM-GNN 包括当前会话的本地级图卷积网络 (L-GCN)、全会话的全级图卷积网络 (G-GCN) 和高级图卷积网络 (H-GCN)。L-GCN 和 G-GCN 分别在当前会话和所有会话中，通过汇聚策略来有效地捕捉会话中对应的对比关系。而 H-GCN 则用于捕捉高阶 Item 转移信息中的高阶对比关系。CM-GNN 还引入了一个注意力基于融合模块，以学习对应的会话表示。最后，CM-GNN 通过对 H-GCN 生成的 Item 表示进行平均聚合，以获得高阶对比关系基于的会话表示。此外，为了将高阶 Item 转移信息转换成对应的会话表示，CM-GNN 利用对比学习概念，通过最大化mutual information  между融合模块和均值聚合层的表示来实现。我们在多个广泛使用的 benchmark 数据集上进行了广泛的实验，结果显示，我们提出的方法可以超越当前状态的 SBR 技术。
</details></li>
</ul>
<hr>
<h2 id="Deep-Image-Semantic-Communication-Model-for-Artificial-Intelligent-Internet-of-Things"><a href="#Deep-Image-Semantic-Communication-Model-for-Artificial-Intelligent-Internet-of-Things" class="headerlink" title="Deep Image Semantic Communication Model for Artificial Intelligent Internet of Things"></a>Deep Image Semantic Communication Model for Artificial Intelligent Internet of Things</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02926">http://arxiv.org/abs/2311.02926</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meatery/semantic-segmentation">https://github.com/meatery/semantic-segmentation</a></li>
<li>paper_authors: Li Ping Qian, Yi Zhang, Sikai Lyu, Huijie Zhu, Yuan Wu, Xuemin Sherman Shen, Xiaoniu Yang</li>
<li>for: 提出了一种深度学习图像Semantic Communication模型，用于AIoT设备中高效的图像通信。</li>
<li>methods: 提出了一种高精度图像 semantic segmentation算法，以提取图像semantic信息进行明显的压缩图像数据。同时，还提出了一种基于GAN的semantic图像恢复算法，用于将semantic图像转换为详细的真实场景图像。</li>
<li>results: 对于WebP和CycleGAN的比较，提出的图像Semantic Communication模型可以提高图像压缩比和恢复精度，平均提高71.93%和25.07%。此外，我们的demo试验表明，该模型可以将图像通信延迟降低至95.26%。<details>
<summary>Abstract</summary>
With the rapid development of Artificial Intelligent Internet of Things (AIoT), the image data from AIoT devices has been witnessing the explosive increasing. In this paper, a novel deep image semantic communication model is proposed for the efficient image communication in AIoT. Particularly, at the transmitter side, a high-precision image semantic segmentation algorithm is proposed to extract the semantic information of the image to achieve significant compression of the image data. At the receiver side, a semantic image restoration algorithm based on Generative Adversarial Network (GAN) is proposed to convert the semantic image to a real scene image with detailed information. Simulation results demonstrate that the proposed image semantic communication model can improve the image compression ratio and recovery accuracy by 71.93% and 25.07% on average in comparison with WebP and CycleGAN, respectively. More importantly, our demo experiment shows that the proposed model reduces the total delay by 95.26% in the image communication, when comparing with the original image transmission.
</details>
<details>
<summary>摘要</summary>
随着人工智能互联网关系（AIoT）的快速发展，AIoT设备中的图像数据已经发生了急剧增长。在这篇论文中，我们提出了一种新的深度图像semantic通信模型，用于AIoT中高效的图像通信。特别是在发送端，我们提出了一种高精度图像semantic分割算法，以提取图像中的semantic信息，实现图像数据的显著压缩。在接收端，我们提出了基于生成对抗网络（GAN）的semantic图像恢复算法，将semantic图像转换为详细的真实场景图像。 simulation结果表明，我们提出的图像semantic通信模型可以提高图像压缩比和恢复精度，在WebP和CycleGAN相比，平均提高71.93%和25.07%。更重要的是，我们的 demo experiment 表明，我们的模型可以将图像通信总延迟降低到95.26%，相比原始图像传输。
</details></li>
</ul>
<hr>
<h2 id="Virtual-Action-Actor-Critic-Framework-for-Exploration-Student-Abstract"><a href="#Virtual-Action-Actor-Critic-Framework-for-Exploration-Student-Abstract" class="headerlink" title="Virtual Action Actor-Critic Framework for Exploration (Student Abstract)"></a>Virtual Action Actor-Critic Framework for Exploration (Student Abstract)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02916">http://arxiv.org/abs/2311.02916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bumgeun Park, Taeyoung Kim, Quoc-Vinh Lai-Dang, Dongsoo Har</li>
<li>for: 提高RL中agent的探索性能</li>
<li>methods: 提出了一种新的actor-critic框架，即虚拟行为actor-critic（VAAC），以便在RL中更好地探索</li>
<li>results: 实验结果显示，VAAC比现有算法提高了探索性能<details>
<summary>Abstract</summary>
Efficient exploration for an agent is challenging in reinforcement learning (RL). In this paper, a novel actor-critic framework namely virtual action actor-critic (VAAC), is proposed to address the challenge of efficient exploration in RL. This work is inspired by humans' ability to imagine the potential outcomes of their actions without actually taking them. In order to emulate this ability, VAAC introduces a new actor called virtual actor (VA), alongside the conventional actor-critic framework. Unlike the conventional actor, the VA takes the virtual action to anticipate the next state without interacting with the environment. With the virtual policy following a Gaussian distribution, the VA is trained to maximize the anticipated novelty of the subsequent state resulting from a virtual action. If any next state resulting from available actions does not exhibit high anticipated novelty, training the VA leads to an increase in the virtual policy entropy. Hence, high virtual policy entropy represents that there is no room for exploration. The proposed VAAC aims to maximize a modified Q function, which combines cumulative rewards and the negative sum of virtual policy entropy. Experimental results show that the VAAC improves the exploration performance compared to existing algorithms.
</details>
<details>
<summary>摘要</summary>
RL中的agent寻找最有效的探索方法是具有挑战性的。本文提出了一种新的actor-critic框架，即虚拟行为actor-critic（VAAC），以解决RL中的探索挑战。这种工作受到人类能够想象自己行动后的可能结果的能力所 inspirited。为了模拟这种能力，VAAC引入了一个新的actor，虚拟actor（VA），与传统的actor-critic框架一起工作。与传统的actor不同，VA不需要与环境交互，而是通过虚拟行动预测下一个状态。通过虚拟策略遵循 Gaussian 分布，VA 在预测下一个状态后寻找最高anticipated novelty。如果可用的下一个状态不具有高anticipated novelty，则训练VA会导致虚拟策略 entropy 的增加。因此，高虚拟策略 entropy 表示探索空间的缺乏。VAAC 的目标是最大化修改后的Q函数，该函数组合了累积奖励和虚拟策略 entropy 的负值。实验结果表明，VAAC 在探索性能方面比现有算法 superior。
</details></li>
</ul>
<hr>
<h2 id="Imitation-Learning-based-Alternative-Multi-Agent-Proximal-Policy-Optimization-for-Well-Formed-Swarm-Oriented-Pursuit-Avoidance"><a href="#Imitation-Learning-based-Alternative-Multi-Agent-Proximal-Policy-Optimization-for-Well-Formed-Swarm-Oriented-Pursuit-Avoidance" class="headerlink" title="Imitation Learning based Alternative Multi-Agent Proximal Policy Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance"></a>Imitation Learning based Alternative Multi-Agent Proximal Policy Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02912">http://arxiv.org/abs/2311.02912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sizhao Li, Yuming Xiang, Rongpeng Li, Zhifeng Zhao, Honggang Zhang</li>
<li>For: This paper focuses on developing a decentralized Imitation learning based Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm for pursuit avoidance in well-formed swarms of multi-robot systems (MRS).* Methods: The proposed IA-MAPPO algorithm utilizes policy-distillation based MAPPO executor to accomplish multiple formations in a centralized manner, and imitation learning to decentralize the formation controller, reducing communication overheads and enhancing scalability.* Results: The simulation results demonstrate the effectiveness of IA-MAPPO, and extensive ablation experiments show that the performance is comparable to a centralized solution with significant decrease in communication overheads.<details>
<summary>Abstract</summary>
Multi-Robot System (MRS) has garnered widespread research interest and fostered tremendous interesting applications, especially in cooperative control fields. Yet little light has been shed on the compound ability of formation, monitoring and defence in decentralized large-scale MRS for pursuit avoidance, which puts stringent requirements on the capability of coordination and adaptability. In this paper, we put forward a decentralized Imitation learning based Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm to provide a flexible and communication-economic solution to execute the pursuit avoidance task in well-formed swarm. In particular, a policy-distillation based MAPPO executor is firstly devised to capably accomplish and swiftly switch between multiple formations in a centralized manner. Furthermore, we utilize imitation learning to decentralize the formation controller, so as to reduce the communication overheads and enhance the scalability. Afterwards, alternative training is leveraged to compensate the performance loss incurred by decentralization. The simulation results validate the effectiveness of IA-MAPPO and extensive ablation experiments further show the performance comparable to a centralized solution with significant decrease in communication overheads.
</details>
<details>
<summary>摘要</summary>
Specifically, we firstly devise a policy-distillation based MAPPO executor to capably accomplish and swiftly switch between multiple formations in a centralized manner. Furthermore, we utilize imitation learning to decentralize the formation controller, so as to reduce the communication overheads and enhance the scalability. Finally, alternative training is leveraged to compensate the performance loss incurred by decentralization. The simulation results validate the effectiveness of IA-MAPPO, and extensive ablation experiments further show the performance comparable to a centralized solution with significant decrease in communication overheads.
</details></li>
</ul>
<hr>
<h2 id="ViDa-Visualizing-DNA-hybridization-trajectories-with-biophysics-informed-deep-graph-embeddings"><a href="#ViDa-Visualizing-DNA-hybridization-trajectories-with-biophysics-informed-deep-graph-embeddings" class="headerlink" title="ViDa: Visualizing DNA hybridization trajectories with biophysics-informed deep graph embeddings"></a>ViDa: Visualizing DNA hybridization trajectories with biophysics-informed deep graph embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03411">http://arxiv.org/abs/2311.03411</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenwei-zhang/ViDa">https://github.com/chenwei-zhang/ViDa</a></li>
<li>paper_authors: Chenwei Zhang, Jordan Lovrod, Boyan Beronov, Khanh Dao Duc, Anne Condon</li>
<li>for: 这个论文是为了帮助synthetic biologists和分子程序员理解核酸反应的复杂活动路径，并可以设计用于许多可能的应用程序。</li>
<li>methods: 该论文使用了一种名为Continuous-time Markov chain（CTMC）的模型来模拟核酸反应的动态行为。</li>
<li>results: 该论文提出了一种新的可视化方法，名为ViDa，可以用来可视化核酸反应的轨迹。该方法使用了一种2D嵌入，以便在CTMC模型下的次级结构状态空间中可见化核酸反应的路径。Results表明，使用域pecific的supervised term可以提高 каче量，并成功分离不同的折叠路径，从而提供有用的反应机制的理解。<details>
<summary>Abstract</summary>
Visualization tools can help synthetic biologists and molecular programmers understand the complex reactive pathways of nucleic acid reactions, which can be designed for many potential applications and can be modelled using a continuous-time Markov chain (CTMC). Here we present ViDa, a new visualization approach for DNA reaction trajectories that uses a 2D embedding of the secondary structure state space underlying the CTMC model. To this end, we integrate a scattering transform of the secondary structure adjacency, a variational autoencoder, and a nonlinear dimensionality reduction method. We augment the training loss with domain-specific supervised terms that capture both thermodynamic and kinetic features. We assess ViDa on two well-studied DNA hybridization reactions. Our results demonstrate that the domain-specific features lead to significant quality improvements over the state-of-the-art in DNA state space visualization, successfully separating different folding pathways and thus providing useful insights into dominant reaction mechanisms.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTVisualization tools can help synthetic biologists and molecular programmers understand the complex reactive pathways of nucleic acid reactions, which can be designed for many potential applications and can be modelled using a continuous-time Markov chain (CTMC). Here we present ViDa, a new visualization approach for DNA reaction trajectories that uses a 2D embedding of the secondary structure state space underlying the CTMC model. To this end, we integrate a scattering transform of the secondary structure adjacency, a variational autoencoder, and a nonlinear dimensionality reduction method. We augment the training loss with domain-specific supervised terms that capture both thermodynamic and kinetic features. We assess ViDa on two well-studied DNA hybridization reactions. Our results demonstrate that the domain-specific features lead to significant quality improvements over the state-of-the-art in DNA state space visualization, successfully separating different folding pathways and thus providing useful insights into dominant reaction mechanisms.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Empowered-Semantic-Communication-Systems-with-a-Shared-Knowledge-Base"><a href="#Deep-Learning-Empowered-Semantic-Communication-Systems-with-a-Shared-Knowledge-Base" class="headerlink" title="Deep Learning-Empowered Semantic Communication Systems with a Shared Knowledge Base"></a>Deep Learning-Empowered Semantic Communication Systems with a Shared Knowledge Base</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02884">http://arxiv.org/abs/2311.02884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Yi, Yang Cao, Xin Kang, Ying-Chang Liang</li>
<li>for: 提高6G网络中semantic communication系统的可解释性</li>
<li>methods: 利用共享知识库，结合消息和相应的知识进行剩余信息处理，并通过自动生成的征文描述符进行semantic自信息和源 entropy的数学定义</li>
<li>results: 比基eline方法具有更好的数据传输效率和句子相似度<details>
<summary>Abstract</summary>
Deep learning-empowered semantic communication is regarded as a promising candidate for future 6G networks. Although existing semantic communication systems have achieved superior performance compared to traditional methods, the end-to-end architecture adopted by most semantic communication systems is regarded as a black box, leading to the lack of explainability. To tackle this issue, in this paper, a novel semantic communication system with a shared knowledge base is proposed for text transmissions. Specifically, a textual knowledge base constructed by inherently readable sentences is introduced into our system. With the aid of the shared knowledge base, the proposed system integrates the message and corresponding knowledge from the shared knowledge base to obtain the residual information, which enables the system to transmit fewer symbols without semantic performance degradation. In order to make the proposed system more reliable, the semantic self-information and the source entropy are mathematically defined based on the knowledge base. Furthermore, the knowledge base construction algorithm is developed based on a similarity-comparison method, in which a pre-configured threshold can be leveraged to control the size of the knowledge base. Moreover, the simulation results have demonstrated that the proposed approach outperforms existing baseline methods in terms of transmitted data size and sentence similarity.
</details>
<details>
<summary>摘要</summary>
Note: The above text is translated into Simplified Chinese, which is one of the standard forms of Chinese used in mainland China. The translation is done using a combination of machine translation and human review to ensure accuracy and fluency. However, please note that the translation may not be perfect and may require some adjustments to fit the specific context or audience.
</details></li>
</ul>
<hr>
<h2 id="DP-DCAN-Differentially-Private-Deep-Contrastive-Autoencoder-Network-for-Single-cell-Clustering"><a href="#DP-DCAN-Differentially-Private-Deep-Contrastive-Autoencoder-Network-for-Single-cell-Clustering" class="headerlink" title="DP-DCAN: Differentially Private Deep Contrastive Autoencoder Network for Single-cell Clustering"></a>DP-DCAN: Differentially Private Deep Contrastive Autoencoder Network for Single-cell Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03410">http://arxiv.org/abs/2311.03410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huifa Li, Jie Fu, Zhili Chen, Xiaomin Yang, Haitao Liu, Xinpeng Ling<br>for: 这个论文主要用于实现单元细胞RNA测量（scRNA-seq）中的隐私保护。methods: 本文使用了一种叫做差异ifferentially Private Deep Contrastive Autoencoder Network（DP-DCAN），它通过部分网络干扰来实现隐私保护。results: 根据六个数据集的实验结果，DP-DCAN与传统的DP方案相比，有着明显的性能提升，且具有强大的防火墙性。<details>
<summary>Abstract</summary>
Single-cell RNA sequencing (scRNA-seq) is important to transcriptomic analysis of gene expression. Recently, deep learning has facilitated the analysis of high-dimensional single-cell data. Unfortunately, deep learning models may leak sensitive information about users. As a result, Differential Privacy (DP) is increasingly used to protect privacy. However, existing DP methods usually perturb whole neural networks to achieve differential privacy, and hence result in great performance overheads. To address this challenge, in this paper, we take advantage of the uniqueness of the autoencoder that it outputs only the dimension-reduced vector in the middle of the network, and design a Differentially Private Deep Contrastive Autoencoder Network (DP-DCAN) by partial network perturbation for single-cell clustering. Since only partial network is added with noise, the performance improvement is obvious and twofold: one part of network is trained with less noise due to a bigger privacy budget, and the other part is trained without any noise. Experimental results of six datasets have verified that DP-DCAN is superior to the traditional DP scheme with whole network perturbation. Moreover, DP-DCAN demonstrates strong robustness to adversarial attacks. The code is available at https://github.com/LFD-byte/DP-DCAN.
</details>
<details>
<summary>摘要</summary>
single-cell RNA sequencing (scRNA-seq) 是转录调控分析的重要工具。在深度学习的帮助下，对高维单元数据进行分析已经变得更加容易。然而，深度学习模型可能泄露用户的敏感信息，因此隐私保护（DP）在应用中变得越来越重要。然而，现有的DP方法通常是整个神经网络上加入噪声来实现隐私保护，这会导致性能增加很大。为了解决这个挑战，在这篇论文中，我们利用自适应神经网络的独特性，即输出的只是网络中间部分的缩短 вектор，并设计了一种叫做权限保护的深度异常抑制神经网络（DP-DCAN）。由于只有部分网络添加噪声，性能改善是明显的，两倍多：一部分网络因为隐私预算更大，因此受到较少噪声训练；另一部分网络则完全没有噪声训练。实验结果表明，DP-DCAN比传统的DP方案更加有优势，并且对抗攻击有强大的鲁棒性。代码可以在<https://github.com/LFD-byte/DP-DCAN>上获取。
</details></li>
</ul>
<hr>
<h2 id="Visualizing-DNA-reaction-trajectories-with-deep-graph-embedding-approaches"><a href="#Visualizing-DNA-reaction-trajectories-with-deep-graph-embedding-approaches" class="headerlink" title="Visualizing DNA reaction trajectories with deep graph embedding approaches"></a>Visualizing DNA reaction trajectories with deep graph embedding approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03409">http://arxiv.org/abs/2311.03409</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenwei-zhang/ViDa">https://github.com/chenwei-zhang/ViDa</a></li>
<li>paper_authors: Chenwei Zhang, Khanh Dao Duc, Anne Condon</li>
<li>for: 这个论文旨在设计 нов型的聚合酶反应，以便更好地理解这些反应的质谱特征。</li>
<li>methods: 这篇论文使用了深度图像嵌入模型，将高维数据映射到2D欧几何空间中，以便更好地可见化DNA反应折叠过程的能量阶段特征。</li>
<li>results: 研究人员通过对两个已经研究过的DNA异种结合反应进行评估，发现ViDa可以成功地分离不同折叠机制的轨迹，提供有用的指导意见，并在DNA动力学可见化方面表现出了大幅提升。<details>
<summary>Abstract</summary>
Synthetic biologists and molecular programmers design novel nucleic acid reactions, with many potential applications. Good visualization tools are needed to help domain experts make sense of the complex outputs of folding pathway simulations of such reactions. Here we present ViDa, a new approach for visualizing DNA reaction folding trajectories over the energy landscape of secondary structures. We integrate a deep graph embedding model with common dimensionality reduction approaches, to map high-dimensional data onto 2D Euclidean space. We assess ViDa on two well-studied and contrasting DNA hybridization reactions. Our preliminary results suggest that ViDa's visualization successfully separates trajectories with different folding mechanisms, thereby providing useful insight to users, and is a big improvement over the current state-of-the-art in DNA kinetics visualization.
</details>
<details>
<summary>摘要</summary>
生物 sintetizadores y programadores moleculares设计新的核酸反应，有很多应用可能性。需要一些好的可视化工具，以帮助领域专家理解复杂的折叠路径仿真结果。我们现在提出了ViDa，一种新的方法用于可视化DNA反应折叠轨迹在二维空间中。我们将深度图像嵌入模型与常见维度减少方法结合在一起，将高维数据映射到二维欧氏空间中。我们对两种已经广泛研究并有很大差异的DNA嵌合反应进行了预liminary测试，结果表明ViDa的可视化成功地分离了不同折叠机制的轨迹，提供了有用的信息，并超过了当前DNA动力学可视化领域的状况。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Shift-–-Multi-Objective-Loss-Function-for-Improved-Anomaly-Fall-Detection"><a href="#Temporal-Shift-–-Multi-Objective-Loss-Function-for-Improved-Anomaly-Fall-Detection" class="headerlink" title="Temporal Shift – Multi-Objective Loss Function for Improved Anomaly Fall Detection"></a>Temporal Shift – Multi-Objective Loss Function for Improved Anomaly Fall Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02863">http://arxiv.org/abs/2311.02863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Denkovski, Shehroz S. Khan, Alex Mihailidis</li>
<li>for: 预测老年人在家庭环境中的跌倒</li>
<li>methods: 使用自适应网络和其变种进行异常检测框架</li>
<li>results: 提出了一种新的多目标损失函数 called Temporal Shift，可以预测未来和重建的帧序列中的帧。该损失函数在一个 semi-naturalistic 跌倒检测数据集上进行评估，并与多种 Camera 模式进行比较。结果显示，使用 Temporal Shift 可以提高异常检测性能，特别是在使用注意力 U-Net CAE 和多模式神经网络时。<details>
<summary>Abstract</summary>
Falls are a major cause of injuries and deaths among older adults worldwide. Accurate fall detection can help reduce potential injuries and additional health complications. Different types of video modalities can be used in a home setting to detect falls, including RGB, Infrared, and Thermal cameras. Anomaly detection frameworks using autoencoders and their variants can be used for fall detection due to the data imbalance that arises from the rarity and diversity of falls. However, the use of reconstruction error in autoencoders can limit the application of networks' structures that propagate information. In this paper, we propose a new multi-objective loss function called Temporal Shift, which aims to predict both future and reconstructed frames within a window of sequential frames. The proposed loss function is evaluated on a semi-naturalistic fall detection dataset containing multiple camera modalities. The autoencoders were trained on normal activities of daily living (ADL) performed by older adults and tested on ADLs and falls performed by young adults. Temporal shift shows significant improvement to a baseline 3D Convolutional autoencoder, an attention U-Net CAE, and a multi-modal neural network. The greatest improvement was observed in an attention U-Net model improving by 0.20 AUC ROC for a single camera when compared to reconstruction alone. With significant improvement across different models, this approach has the potential to be widely adopted and improve anomaly detection capabilities in other settings besides fall detection.
</details>
<details>
<summary>摘要</summary>
falls 是全球较老的成年人中的主要伤害和死亡原因之一。准确的落幕检测可以帮助降低可能的伤害和额外的健康问题。家庭环境中可以使用不同类型的视频模式来检测落幕，包括RGB、infrared和热成像镜头。使用自适应网络的异常检测框架可以用于落幕检测，因为落幕的数据异常性和多样性导致了数据的不均衡。在这篇论文中，我们提出了一种新的多目标损失函数called Temporal Shift，它 goal是在窗口中的序列帧中预测未来和重建的帧。我们的提案的损失函数被评估在含有多个镜头模式的半自然的落幕检测dataset上。我们使用了正常老年人的日常活动（ADL）来训练自适应网络，并在ADL和年轻人的落幕上测试。Temporal shift在不同的模型中显示了明显的改进，特别是使用注意力U-Net CAE模型，其在单个镜头上的改进为0.20 AUC ROC。与不同的模型相比，这种方法在不同的设置中都有可能广泛采用，以改善异常检测的能力。
</details></li>
</ul>
<hr>
<h2 id="Training-Multi-layer-Neural-Networks-on-Ising-Machine"><a href="#Training-Multi-layer-Neural-Networks-on-Ising-Machine" class="headerlink" title="Training Multi-layer Neural Networks on Ising Machine"></a>Training Multi-layer Neural Networks on Ising Machine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03408">http://arxiv.org/abs/2311.03408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xujie Song, Tong Liu, Shengbo Eben Li, Jingliang Duan, Wenxuan Wang, Keqiang Li</li>
<li>For: 本研究旨在使用 Ising 机器解决大规模二进制优化问题，并利用这些机器来训练嵌入式人工智能模型。* Methods: 该研究提出了一种基于 Ising 机器的启发式学习算法，使用二进制表示 topological 网络和损失函数，并利用 Rosenberg 级别减少和罚函数减少来转换 QCBO 问题为 QUBO 问题。* Results: 研究表明，该算法可以高效地训练多层逻辑网络，并且在 MNIST 数据集上实现了 98.3% 的分类精度，成功率为 72%。随着 Ising 机器中的辐射时间增长，该算法有望训练更深的 neural network。<details>
<summary>Abstract</summary>
As a dedicated quantum device, Ising machines could solve large-scale binary optimization problems in milliseconds. There is emerging interest in utilizing Ising machines to train feedforward neural networks due to the prosperity of generative artificial intelligence. However, existing methods can only train single-layer feedforward networks because of the complex nonlinear network topology. This paper proposes an Ising learning algorithm to train quantized neural network (QNN), by incorporating two essential techinques, namely binary representation of topological network and order reduction of loss function. As far as we know, this is the first algorithm to train multi-layer feedforward networks on Ising machines, providing an alternative to gradient-based backpropagation. Firstly, training QNN is formulated as a quadratic constrained binary optimization (QCBO) problem by representing neuron connection and activation function as equality constraints. All quantized variables are encoded by binary bits based on binary encoding protocol. Secondly, QCBO is converted to a quadratic unconstrained binary optimization (QUBO) problem, that can be efficiently solved on Ising machines. The conversion leverages both penalty function and Rosenberg order reduction, who together eliminate equality constraints and reduce high-order loss function into a quadratic one. With some assumptions, theoretical analysis shows the space complexity of our algorithm is $\mathcal{O}(H^2L + HLN\log H)$, quantifying the required number of Ising spins. Finally, the algorithm effectiveness is validated with a simulated Ising machine on MNIST dataset. After annealing 700 ms, the classification accuracy achieves 98.3%. Among 100 runs, the success probability of finding the optimal solution is 72%. Along with the increasing number of spins on Ising machine, our algorithm has the potential to train deeper neural networks.
</details>
<details>
<summary>摘要</summary>
如果我们把它作为专门的量子设备，则矩阵机器（Ising machine）可以在毫秒级别解决大规模的二进制优化问题。由于生成人工智能的兴起，现在有越来越多的人想使用矩阵机器来训练Feedforward神经网络。然而，现有的方法只能训练单层Feedforward神经网络，因为矩阵机器的复杂非线性网络结构。这篇论文提出了一种矩阵学习算法，用于训练量化神经网络（QNN），并包括两种重要技术：即二进制表示法和顺序减少损失函数的技术。我们知道，这是第一种可以在矩阵机器上训练多层Feedforward神经网络的算法，提供了梯度下降法的一种 alternatives。首先，训练QNN被формализова为一个二进制受限优化（QCBO）问题，通过表示神经连接和活动函数为等式约束来表述。所有量化变量都被编码成二进制位基于二进制编码协议。然后，QCBO被转化为一个二进制无约束优化（QUBO）问题，可以高效解决在矩阵机器上。这种转化利用了 penalty function和Rosenberg顺序减少，共同消除等式约束并将高阶损失函数转化为二进制的 quadratic 函数。通过一些假设，我们对算法的空间复杂度进行了理论分析，并得到了 $\mathcal{O}(H^2L + HLN\log H)$ 的结果，这个结果表示了需要的矩阵轮子数。最后，我们通过在 simulated Ising machine 上进行700毫秒的热化后，对 MNIST 数据集进行验证，并得到了 98.3% 的分类精度。在100次运行中，成功找到优化解决方案的概率为 72%。随着矩阵机器上的矩阵轮子数的增加，我们的算法有可能训练更深的神经网络。
</details></li>
</ul>
<hr>
<h2 id="Co-training-and-Co-distillation-for-Quality-Improvement-and-Compression-of-Language-Models"><a href="#Co-training-and-Co-distillation-for-Quality-Improvement-and-Compression-of-Language-Models" class="headerlink" title="Co-training and Co-distillation for Quality Improvement and Compression of Language Models"></a>Co-training and Co-distillation for Quality Improvement and Compression of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02849">http://arxiv.org/abs/2311.02849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hayeon Lee, Rui Hou, Jongpil Kim, Davis Liang, Hongbo Zhang, Sung Ju Hwang, Alexander Min</li>
<li>for: 提高 computationally expensive pre-trained language models (PLMs) 的吞吐量和实时性，以便在资源受限或实时设置下使用。</li>
<li>methods: 提出了 Co-Training and Co-Distillation (CTCD) 框架，通过在两个模型之间进行协同训练并且互相传递知识，同时提高两个模型的性能和执行速度。</li>
<li>results: CTCD 框架在 GLUE 测试准则上显示出了可以与现有的一个方向知识填充法相比肤，并且小模型通过 CTCD 的概率提高了1.66 个大模型的性能。<details>
<summary>Abstract</summary>
Knowledge Distillation (KD) compresses computationally expensive pre-trained language models (PLMs) by transferring their knowledge to smaller models, allowing their use in resource-constrained or real-time settings. However, most smaller models fail to surpass the performance of the original larger model, resulting in sacrificing performance to improve inference speed. To address this issue, we propose Co-Training and Co-Distillation (CTCD), a novel framework that improves performance and inference speed together by co-training two models while mutually distilling knowledge. The CTCD framework successfully achieves this based on two significant findings: 1) Distilling knowledge from the smaller model to the larger model during co-training improves the performance of the larger model. 2) The enhanced performance of the larger model further boosts the performance of the smaller model. The CTCD framework shows promise as it can be combined with existing techniques like architecture design or data augmentation, replacing one-way KD methods, to achieve further performance improvement. Extensive ablation studies demonstrate the effectiveness of CTCD, and the small model distilled by CTCD outperforms the original larger model by a significant margin of 1.66 on the GLUE benchmark.
</details>
<details>
<summary>摘要</summary>
知识塑化（KD）技术可以压缩训练过程中的计算复杂度，从大型语言模型（PLM）中传递知识到小型模型中，以便在资源有限或实时设置下使用。然而，大多数小型模型无法超越原始大型模型的性能，因此需要牺牲性能以提高推理速度。为解决这个问题，我们提出了同时受过训练和知识塑化（CTCD）框架，该框架可以同时提高性能和推理速度。CTCD框架的两个重要发现是：1）在同时受过训练的情况下，将小型模型中的知识传递给大型模型可以提高大型模型的性能。2）大型模型的提高性能可以进一步提高小型模型的性能。CTCD框架表现良好，可以与现有的建筑设计或数据增强技术相结合，取代一次KD方法，以实现更高的性能提升。广泛的拟合研究表明CTCD的有效性，小型模型通过CTCD来塑化的性能比原始大型模型提高了1.66倍的GLUE标准 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Kinematic-aware-Prompting-for-Generalizable-Articulated-Object-Manipulation-with-LLMs"><a href="#Kinematic-aware-Prompting-for-Generalizable-Articulated-Object-Manipulation-with-LLMs" class="headerlink" title="Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs"></a>Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02847">http://arxiv.org/abs/2311.02847</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xwinks/llm_articulated_object_manipulation">https://github.com/xwinks/llm_articulated_object_manipulation</a></li>
<li>paper_authors: Wenke Xia, Dong Wang, Xincheng Pang, Zhigang Wang, Bin Zhao, Di Hu</li>
<li>for: 本研究旨在提高家庭助手机器人的普遍化 manipulate objects的能力，通过利用大语言模型（LLM）的强 Context-Aware 学习能力，实现对多种骨架结构的物体抓取和运动轨迹生成。</li>
<li>methods: 本研究提出了一种基于物体骨架结构的Prompting Framework，通过提供物体的骨架知识来引导 LLM 生成低级的机器人运动轨迹点。为了有效地提供骨架知识，我们设计了一种统一的骨架知识解析器，可以将多种骨架结构表示为一种通用的文本描述。基于这种统一描述，我们提出了一种基于骨架结构的 плаanner 模型，通过一种设计的链式思维提问方法，生成精准的3D manipulation waypoints。</li>
<li>results: 我们的框架在48个实例中 across 16种不同类别上进行了评估，结果表明，我们的方法不仅在8种seen类别上超过传统方法，而且在8种未看过类别上也表现出了强大的零基eline能力。此外，我们在7种实际对象类别上进行了实际实验，证明了我们的框架在实际场景中的适应性。<details>
<summary>Abstract</summary>
Generalizable articulated object manipulation is essential for home-assistant robots. Recent efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, however, due to the prohibitive costs of real-world data collection and precise object simulation, it still remains challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, building on the idea that the kinematic structure of the object determines how we can manipulate it, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supporting various object manipulation. To effectively prompt LLMs with the kinematic structure of different objects, we design a unified kinematic knowledge parser, which represents various articulated objects as a unified textual description containing kinematic joints and contact location. Building upon this unified description, a kinematic-aware planner model is proposed to generate precise 3D manipulation waypoints via a designed kinematic-aware chain-of-thoughts prompting method. Our evaluation spanned 48 instances across 16 distinct categories, revealing that our framework not only outperforms traditional methods on 8 seen categories but also shows a powerful zero-shot capability for 8 unseen articulated object categories. Moreover, the real-world experiments on 7 different object categories prove our framework's adaptability in practical scenarios. Code is released at \href{https://github.com/xwinks/LLM_articulated_object_manipulation}{here}.
</details>
<details>
<summary>摘要</summary>
通用的人工智能家庭助手机器人控制是非常重要的。 latest efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, but due to the high cost of real-world data collection and precise object simulation, it is still challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supporting various object manipulation. To effectively prompt LLMs with the kinematic structure of different objects, we design a unified kinematic knowledge parser, which represents various articulated objects as a unified textual description containing kinematic joints and contact location. Building upon this unified description, a kinematic-aware planner model is proposed to generate precise 3D manipulation waypoints via a designed kinematic-aware chain-of-thoughts prompting method. Our evaluation spanned 48 instances across 16 distinct categories, revealing that our framework not only outperforms traditional methods on 8 seen categories but also shows a powerful zero-shot capability for 8 unseen articulated object categories. Moreover, the real-world experiments on 7 different object categories prove our framework's adaptability in practical scenarios. Code is released at [insert link].
</details></li>
</ul>
<hr>
<h2 id="Saturn-Efficient-Multi-Large-Model-Deep-Learning"><a href="#Saturn-Efficient-Multi-Large-Model-Deep-Learning" class="headerlink" title="Saturn: Efficient Multi-Large-Model Deep Learning"></a>Saturn: Efficient Multi-Large-Model Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02840">http://arxiv.org/abs/2311.02840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kabir Nagrecha, Arun Kumar</li>
<li>for: 提高多个大型模型训练效率（如选择模型和超参数优化）</li>
<li>methods: 提出了一种新的数据系统Saturn，通过同时解决多个关联系统挑战来提高效率，包括并行技术选择、分布GPU资源到任务中和调度</li>
<li>results: 对比当前深度学习实践，Saturn的联合优化方法可以提供39-49%的模型选择运行时间减少<details>
<summary>Abstract</summary>
In this paper, we propose Saturn, a new data system to improve the efficiency of multi-large-model training (e.g., during model selection/hyperparameter optimization). We first identify three key interconnected systems challenges for users building large models in this setting -- parallelism technique selection, distribution of GPUs over jobs, and scheduling. We then formalize these as a joint problem, and build a new system architecture to tackle these challenges simultaneously. Our evaluations show that our joint-optimization approach yields 39-49% lower model selection runtimes than typical current DL practice.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的数据系统，用于提高多个大型模型训练的效率（例如， durante 模型选择/超参数优化）。我们首先识别了在用户构建大型模型时存在的三个关联系统挑战：并行技术选择、分布式GPU分配给任务以及调度。我们然后将这些问题化为一个共同问题，并构建了一个新的系统架构来解决这些挑战。我们的评估显示，我们的共同优化方法可以在常见的深度学习实践中降低模型选择运行时间39-49%。
</details></li>
</ul>
<hr>
<h2 id="Mesh-Neural-Cellular-Automata"><a href="#Mesh-Neural-Cellular-Automata" class="headerlink" title="Mesh Neural Cellular Automata"></a>Mesh Neural Cellular Automata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02820">http://arxiv.org/abs/2311.02820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Pajouheshgar, Yitao Xu, Alexander Mordvintsev, Eyvind Niklasson, Tong Zhang, Sabine Süsstrunk</li>
<li>for: 增强虚拟环境的真实感，提供一种直接synthesize 3D mesh上的文本ure方法。</li>
<li>methods: 提议使用Mesh Neural Cellular Automata（MeshNCA）方法，该方法可以在3D mesh上直接synthesize 动态文本ure，不需要UV映射。MeshNCA是一种通用的细胞自动机，可以在非格式结构上操作，如3D mesh的顶点。</li>
<li>results: MeshNCA可以在实时内synthesize 文本ure，并且可以跨种模式supervision和不同的目标（如图像、文本提示、运动向量场）进行训练。此外，还提出了将训练过的MeshNCA实例进行grafting，以实现文本ure的 interpolate。通过WebGL 渲染语言实现了前向传播，并在个人电脑和手机上实现了在线交互示例。<details>
<summary>Abstract</summary>
Modeling and synthesizing textures are essential for enhancing the realism of virtual environments. Methods that directly synthesize textures in 3D offer distinct advantages to the UV-mapping-based methods as they can create seamless textures and align more closely with the ways textures form in nature. We propose Mesh Neural Cellular Automata (MeshNCA), a method for directly synthesizing dynamic textures on 3D meshes without requiring any UV maps. MeshNCA is a generalized type of cellular automata that can operate on a set of cells arranged on a non-grid structure such as vertices of a 3D mesh. While only being trained on an Icosphere mesh, MeshNCA shows remarkable generalization and can synthesize textures on any mesh in real time after the training. Additionally, it accommodates multi-modal supervision and can be trained using different targets such as images, text prompts, and motion vector fields. Moreover, we conceptualize a way of grafting trained MeshNCA instances, enabling texture interpolation. Our MeshNCA model enables real-time 3D texture synthesis on meshes and allows several user interactions including texture density/orientation control, a grafting brush, and motion speed/direction control. Finally, we implement the forward pass of our MeshNCA model using the WebGL shading language and showcase our trained models in an online interactive demo which is accessible on personal computers and smartphones. Our demo and the high resolution version of this PDF are available at https://meshnca.github.io/.
</details>
<details>
<summary>摘要</summary>
模型和合成Texture是虚拟环境中的关键技术。直接在3D中合成Texture的方法比UV映射方法更有优势，因为它们可以创建无缝Texture和更好地遵循自然中Texture的形成方式。我们提出了Mesh Neural Cellular Automata（MeshNCA），一种不需要UV图的3D mesh上直接合成动态Texture的方法。MeshNCA是一种通用的细胞自动机，可以在3D mesh的顶点上的非格构造上操作。它只需要在icosphere mesh上进行训练，但它可以在实时中合成Texture于任何mesh，并且可以接受多modal的监督。此外，我们还提出了将训练好的MeshNCA实例结合的思想，以实现Texture的 interpolate。我们的MeshNCA模型允许在实时中合成3DTexture，并且允许用户进行多种交互，包括Texture的密度/方向控制、graftingBrush、速度/方向控制。最后，我们使用WebGL着色语言进行了前向传播，并在个人电脑和手机上展示了我们训练的模型。我们的 demo 和高解度版PDF可以在 <https://meshnca.github.io/> 上获取。
</details></li>
</ul>
<hr>
<h2 id="QualEval-Qualitative-Evaluation-for-Model-Improvement"><a href="#QualEval-Qualitative-Evaluation-for-Model-Improvement" class="headerlink" title="QualEval: Qualitative Evaluation for Model Improvement"></a>QualEval: Qualitative Evaluation for Model Improvement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02807">http://arxiv.org/abs/2311.02807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vmurahari3/qualeval">https://github.com/vmurahari3/qualeval</a></li>
<li>paper_authors: Vishvak Murahari, Ameet Deshpande, Peter Clark, Tanmay Rajpurohit, Ashish Sabharwal, Karthik Narasimhan, Ashwin Kalyan</li>
<li>for: This paper aims to address the limitations of quantitative evaluation metrics in gauging the performance of artificial intelligence systems, particularly large language models (LLMs).</li>
<li>methods: The proposed method, called QualEval, leverages automated qualitative evaluation and a powerful LLM reasoner to generate human-readable insights that can improve model performance. It also includes a comprehensive dashboard with fine-grained visualizations and human-interpretable analyses.</li>
<li>results: The paper demonstrates that QualEval can improve the absolute performance of the Llama 2 model by up to 15% points relative to baselines on a challenging dialogue task (DialogSum). Additionally, QualEval accelerates the pace of model development, serving as a data-scientist-in-a-box for model evaluation and improvement.<details>
<summary>Abstract</summary>
Quantitative evaluation metrics have traditionally been pivotal in gauging the advancements of artificial intelligence systems, including large language models (LLMs). However, these metrics have inherent limitations. Given the intricate nature of real-world tasks, a single scalar to quantify and compare is insufficient to capture the fine-grained nuances of model behavior. Metrics serve only as a way to compare and benchmark models, and do not yield actionable diagnostics, thus making the model improvement process challenging. Model developers find themselves amid extensive manual efforts involving sifting through vast datasets and attempting hit-or-miss adjustments to training data or setups. In this work, we address the shortcomings of quantitative metrics by proposing QualEval, which augments quantitative scalar metrics with automated qualitative evaluation as a vehicle for model improvement. QualEval uses a powerful LLM reasoner and our novel flexible linear programming solver to generate human-readable insights that when applied, accelerate model improvement. The insights are backed by a comprehensive dashboard with fine-grained visualizations and human-interpretable analyses. We corroborate the faithfulness of QualEval by demonstrating that leveraging its insights, for example, improves the absolute performance of the Llama 2 model by up to 15% points relative on a challenging dialogue task (DialogSum) when compared to baselines. QualEval successfully increases the pace of model development, thus in essence serving as a data-scientist-in-a-box. Given the focus on critiquing and improving current evaluation metrics, our method serves as a refreshingly new technique for both model evaluation and improvement.
</details>
<details>
<summary>摘要</summary>
传统的量化评估指标在人工智能系统中，包括大语言模型（LLM）的发展中扮演着重要角色。然而，这些指标具有内在的局限性。由于实际任务的复杂性，单一的量化指标无法捕捉模型行为的细腻特征。指标仅仅用于比较和benchmark模型，而不提供可操作的 диагностиcs，因此改进模型的过程变得困难。模型开发者面临着大量的手动努力，包括对庞大数据集进行搜索和尝试随机地调整训练数据或设置。在这种情况下，我们解决了量化指标的缺陷，提出了 QualEval，它将量化指标与自动化的 качеitative评估相结合，以便更好地改进模型。QualEval使用了一个强大的LLM理解器和我们的新型的 flexible linear programming solver，生成了人类可读的报告，这些报告可以帮助改进模型。报告包括细化的可见化和人类可理解的分析。我们证明了QualEval的准确性，当我们在对话任务（DialogSum）上使用它时，可以提高Llama 2模型的绝对性能，相比基eline，提高15%点。QualEval成功地减少了模型开发的速度，从而成为一个数据科学家在盒子中。由于我们的方法重点 kritik和改进现有评估指标，我们的方法 serves as a refreshingly new technique for both model evaluation and improvement。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Worker-Perspectives-into-MTurk-Annotation-Practices-for-NLP"><a href="#Incorporating-Worker-Perspectives-into-MTurk-Annotation-Practices-for-NLP" class="headerlink" title="Incorporating Worker Perspectives into MTurk Annotation Practices for NLP"></a>Incorporating Worker Perspectives into MTurk Annotation Practices for NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02802">http://arxiv.org/abs/2311.02802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olivia Huang, Eve Fleisig, Dan Klein</li>
<li>for: This paper aims to improve the practices of data collection for natural language processing on Amazon Mechanical Turk (MTurk) by considering the perspectives of MTurk workers.</li>
<li>methods: The authors conducted a critical literature review and a survey of MTurk workers to address open questions regarding best practices for fair payment, worker privacy, data quality, and considering worker incentives.</li>
<li>results: The survey found that worker preferences are often at odds with received wisdom among NLP researchers, and that some quality control methods are viewed as biased and ineffective. The authors provide recommendations on how future NLP studies may better account for MTurk workers’ experiences to respect workers’ rights and improve data quality.<details>
<summary>Abstract</summary>
Current practices regarding data collection for natural language processing on Amazon Mechanical Turk (MTurk) often rely on a combination of studies on data quality and heuristics shared among NLP researchers. However, without considering the perspectives of MTurk workers, these approaches are susceptible to issues regarding workers' rights and poor response quality. We conducted a critical literature review and a survey of MTurk workers aimed at addressing open questions regarding best practices for fair payment, worker privacy, data quality, and considering worker incentives. We found that worker preferences are often at odds with received wisdom among NLP researchers. Surveyed workers preferred reliable, reasonable payments over uncertain, very high payments; reported frequently lying on demographic questions; and expressed frustration at having work rejected with no explanation. We also found that workers view some quality control methods, such as requiring minimum response times or Master's qualifications, as biased and largely ineffective. Based on the survey results, we provide recommendations on how future NLP studies may better account for MTurk workers' experiences in order to respect workers' rights and improve data quality.
</details>
<details>
<summary>摘要</summary>
当前在 Amazon Mechanical Turk（MTurk）上进行的自然语言处理数据采集往往采用一种结合数据质量研究和NLP研究人员之间分享的经验的方法。然而，不考虑MTurk工作者的视角，这些方法容易出现工作者权利问题和回答质量问题。我们进行了一项批判性文献综述和MTurk工作者问卷调查，以解决关于公平支付、工作者隐私、数据质量和考虑工作者激励的问题。我们发现工作者偏好可靠、合理的支付，而不是不确定、非常高的支付；报告经常谎欺个人问题；并表示对工作被拒绝而不给解释而感到沮丧。我们还发现一些质量控制方法，如要求最低响应时间或硬件资格，被工作者视为偏袋式和不具有效果。根据调查结果，我们提出了将来NLP研究如何更好地考虑MTurk工作者的经验，以尊重工作者权利并提高数据质量。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.AI_2023_11_06/" data-id="cloq1wl1m007c7o880m394dn6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/11/06/cs.CV_2023_11_06/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-11-06
        
      </div>
    </a>
  
  
    <a href="/2023/11/06/cs.CL_2023_11_06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-11-06</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
