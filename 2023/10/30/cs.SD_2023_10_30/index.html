
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.SD - 2023-10-30 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="DCHT: Deep Complex Hybrid Transformer for Speech Enhancement paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.19602 repo_url: None paper_authors: Jialu Li, Junhui Li, Pu Wang, Youshan Zhang for: 提高Speech噪音消除的性能 m">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.SD - 2023-10-30">
<meta property="og:url" content="https://nullscc.github.io/2023/10/30/cs.SD_2023_10_30/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="DCHT: Deep Complex Hybrid Transformer for Speech Enhancement paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.19602 repo_url: None paper_authors: Jialu Li, Junhui Li, Pu Wang, Youshan Zhang for: 提高Speech噪音消除的性能 m">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-10-30T15:00:00.000Z">
<meta property="article:modified_time" content="2023-11-02T12:06:56.981Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.SD_2023_10_30" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/30/cs.SD_2023_10_30/" class="article-date">
  <time datetime="2023-10-30T15:00:00.000Z" itemprop="datePublished">2023-10-30</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.SD - 2023-10-30
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DCHT-Deep-Complex-Hybrid-Transformer-for-Speech-Enhancement"><a href="#DCHT-Deep-Complex-Hybrid-Transformer-for-Speech-Enhancement" class="headerlink" title="DCHT: Deep Complex Hybrid Transformer for Speech Enhancement"></a>DCHT: Deep Complex Hybrid Transformer for Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19602">http://arxiv.org/abs/2310.19602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialu Li, Junhui Li, Pu Wang, Youshan Zhang</li>
<li>for: 提高Speech噪音消除的性能</li>
<li>methods: 提出了一种深度复杂混合变换器， integrate both spectrogram和waveform domain的方法，以提高Speech噪音消除的性能</li>
<li>results: 实验结果表明，该方法可以在BirdSoundsDenoising数据集和VCTK+DEMAND数据集上比 estado-of-the-art 方法更好地提高Speech噪音消除的性能。<details>
<summary>Abstract</summary>
Most of the current deep learning-based approaches for speech enhancement only operate in the spectrogram or waveform domain. Although a cross-domain transformer combining waveform- and spectrogram-domain inputs has been proposed, its performance can be further improved. In this paper, we present a novel deep complex hybrid transformer that integrates both spectrogram and waveform domains approaches to improve the performance of speech enhancement. The proposed model consists of two parts: a complex Swin-Unet in the spectrogram domain and a dual-path transformer network (DPTnet) in the waveform domain. We first construct a complex Swin-Unet network in the spectrogram domain and perform speech enhancement in the complex audio spectrum. We then introduce improved DPT by adding memory-compressed attention. Our model is capable of learning multi-domain features to reduce existing noise on different domains in a complementary way. The experimental results on the BirdSoundsDenoising dataset and the VCTK+DEMAND dataset indicate that our method can achieve better performance compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Current deep learning-based speech enhancement methods mostly operate in the spectrogram or waveform domain. Although a cross-domain transformer combining waveform- and spectrogram-domain inputs has been proposed, its performance can be further improved. In this paper, we present a novel deep complex hybrid transformer that integrates both spectrogram and waveform domains approaches to improve speech enhancement performance. The proposed model consists of two parts: a complex Swin-Unet in the spectrogram domain and a dual-path transformer network (DPTnet) in the waveform domain.First, we construct a complex Swin-Unet network in the spectrogram domain and perform speech enhancement in the complex audio spectrum. We then introduce improved DPT by adding memory-compressed attention. Our model is capable of learning multi-domain features to reduce existing noise on different domains in a complementary way. The experimental results on the BirdSoundsDenoising dataset and the VCTK+DEMAND dataset indicate that our method can achieve better performance compared to state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Sound-of-Story-Multi-modal-Storytelling-with-Audio"><a href="#Sound-of-Story-Multi-modal-Storytelling-with-Audio" class="headerlink" title="Sound of Story: Multi-modal Storytelling with Audio"></a>Sound of Story: Multi-modal Storytelling with Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19264">http://arxiv.org/abs/2310.19264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaeyeon Bae, Seokhoon Jeong, Seokun Kang, Namgi Han, Jae-Yon Lee, Hyounghun Kim, Taehwan Kim</li>
<li>for: 本研究旨在扩展故事理解和告诉领域，增加一个新的“背景声”组件，该组件基于故事上下文的音频信息，不含语言信息。</li>
<li>methods: 作者提出了一个新的数据集“声音故事”（SoS），该数据集包含27,354个故事，每个故事有19.6张图片和984小时的无语言音频信息。作者还提出了多个基线任务，包括模式转换、音频生成等。</li>
<li>results: 作者通过实验表明，该数据集和任务可以帮助研究人员更好地理解故事的多模态表达，并提出了强大的基线任务。数据集和代码将在链接中公开：<a target="_blank" rel="noopener" href="https://github.com/Sosdatasets/SoS_Dataset%E3%80%82">https://github.com/Sosdatasets/SoS_Dataset。</a><details>
<summary>Abstract</summary>
Storytelling is multi-modal in the real world. When one tells a story, one may use all of the visualizations and sounds along with the story itself. However, prior studies on storytelling datasets and tasks have paid little attention to sound even though sound also conveys meaningful semantics of the story. Therefore, we propose to extend story understanding and telling areas by establishing a new component called "background sound" which is story context-based audio without any linguistic information. For this purpose, we introduce a new dataset, called "Sound of Story (SoS)", which has paired image and text sequences with corresponding sound or background music for a story. To the best of our knowledge, this is the largest well-curated dataset for storytelling with sound. Our SoS dataset consists of 27,354 stories with 19.6 images per story and 984 hours of speech-decoupled audio such as background music and other sounds. As benchmark tasks for storytelling with sound and the dataset, we propose retrieval tasks between modalities, and audio generation tasks from image-text sequences, introducing strong baselines for them. We believe the proposed dataset and tasks may shed light on the multi-modal understanding of storytelling in terms of sound. Downloading the dataset and baseline codes for each task will be released in the link: https://github.com/Sosdatasets/SoS_Dataset.
</details>
<details>
<summary>摘要</summary>
Storytelling 是多Modal 的在现实世界中。当一个人 tel 一个故事时，可能使用所有的视觉和声音来传达故事的意义。然而，在storytelling 数据集和任务中，尽管声音也传达了故事的 semantics，但是之前的研究却很少关注声音。因此，我们提议通过 Adding 一个新的组件 called "background sound"，来扩展故事理解和 tel 的领域。为此，我们引入了一个新的数据集，called "Sound of Story (SoS)"，该数据集包含 27,354 个故事，每个故事有 19.6 个图像和 984 小时的speech-decoupled 声音，如背景音乐和其他声音。我们认为这是最大的、最好的纪录的故事tel 数据集。我们的 SoS 数据集包括以下任务： between modalities 的 Retrieval 任务和 image-text 序列的 audio 生成任务，我们提出了强大的基线。我们认为这些任务和数据集可能为 storytelling 中声音的多Modal 理解提供新的灵感。下载数据集和基线代码可以通过以下链接下载：https://github.com/Sosdatasets/SoS_Dataset。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/30/cs.SD_2023_10_30/" data-id="clombedy500xns0883p1n7k3n" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/31/eess.SP_2023_10_31/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.SP - 2023-10-31
        
      </div>
    </a>
  
  
    <a href="/2023/10/30/eess.AS_2023_10_30/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.AS - 2023-10-30</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">113</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">63</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
