
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.CL - 2023-10-11 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.07929 repo_url: None paper_authors: Catherine Arnett, Tyler A. Chang, Ja">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.CL - 2023-10-11">
<meta property="og:url" content="https://nullscc.github.io/2023/10/11/cs.CL_2023_10_11/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.07929 repo_url: None paper_authors: Catherine Arnett, Tyler A. Chang, Ja">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-10-11T11:00:00.000Z">
<meta property="article:modified_time" content="2023-10-16T04:38:03.978Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.CL_2023_10_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/11/cs.CL_2023_10_11/" class="article-date">
  <time datetime="2023-10-11T11:00:00.000Z" itemprop="datePublished">2023-10-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.CL - 2023-10-11
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Crosslingual-Structural-Priming-and-the-Pre-Training-Dynamics-of-Bilingual-Language-Models"><a href="#Crosslingual-Structural-Priming-and-the-Pre-Training-Dynamics-of-Bilingual-Language-Models" class="headerlink" title="Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models"></a>Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07929">http://arxiv.org/abs/2310.07929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Catherine Arnett, Tyler A. Chang, James A. Michaelov, Benjamin K. Bergen</li>
<li>for: 研究Multilingual语言模型是否共享抽象语法表示法，并且如果有，这些表示法在哪些时候开发出来。</li>
<li>methods: 使用结构预priming测试Multilingual语言模型中的抽象语法表示法，并在Dutch-English双语设置下进行扩展。</li>
<li>results: 发现在接受第二语言后，跨语言结构预priming效应在数据量很少时就出现，这表明Multilingual语言模型在学习第二语言时可以快速吸收抽象语法表示法。<details>
<summary>Abstract</summary>
Do multilingual language models share abstract grammatical representations across languages, and if so, when do these develop? Following Sinclair et al. (2022), we use structural priming to test for abstract grammatical representations with causal effects on model outputs. We extend the approach to a Dutch-English bilingual setting, and we evaluate a Dutch-English language model during pre-training. We find that crosslingual structural priming effects emerge early after exposure to the second language, with less than 1M tokens of data in that language. We discuss implications for data contamination, low-resource transfer, and how abstract grammatical representations emerge in multilingual models.
</details>
<details>
<summary>摘要</summary>
请参考Sinclair等（2022），我们使用结构驱动来测试多语言模型中的抽象语法表示。我们在荷兰语-英语双语设置下进行扩展，并评估一个荷兰语-英语语言模型在预训练过程中的表现。我们发现，在第二语言暴露后不久，跨语言结构驱动效应就出现了，并且只需要少于1M个字节的数据来提高表达。我们讨论了数据污染、低资源传输和多语言模型中抽象语法表示的出现。
</details></li>
</ul>
<hr>
<h2 id="The-Expresssive-Power-of-Transformers-with-Chain-of-Thought"><a href="#The-Expresssive-Power-of-Transformers-with-Chain-of-Thought" class="headerlink" title="The Expresssive Power of Transformers with Chain of Thought"></a>The Expresssive Power of Transformers with Chain of Thought</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07923">http://arxiv.org/abs/2310.07923</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Merrill, Ashish Sabharwal</li>
<li>for: 本研究旨在探讨transformer模型在解释力方面的限制，并研究如何通过允许模型使用链式思维或笔记来提高其解释能力。</li>
<li>methods: 研究使用了decoder-only transformer模型，并通过控制模型在输入长度上的步骤数来调查其解释能力。</li>
<li>results: 研究发现，允许模型使用链式思维或笔记可以显著提高其解释能力，但是这种提高的程度取决于链式思维或笔记的长度。研究还发现，使用logarithmic数量的步骤可以只有微小地提高标准transformer模型的解释能力，而使用线性数量的步骤则可以让transformer模型recognize所有的正则语言。此外，研究还发现，使用线性数量的步骤可以使transformer模型recognize所有的context-sensitive语言，而使用polynomial数量的步骤可以使transformer模型recognize所有的 polynomial-time solvable问题。<details>
<summary>Abstract</summary>
Recent theoretical work has identified surprisingly simple reasoning problems, such as checking if two nodes in a graph are connected or simulating finite-state machines, that are provably unsolvable by standard transformers that answer immediately after reading their input. However, in practice, transformers' reasoning can be improved by allowing them to use a "chain of thought" or "scratchpad", i.e., generate and condition on a sequence of intermediate tokens before answering. Motivated by this, we ask: Does such intermediate generation fundamentally extend the computational power of a decoder-only transformer? We show that the answer is yes, but the amount of increase depends crucially on the amount of intermediate generation. For instance, we find that transformer decoders with a logarithmic number of decoding steps (w.r.t. the input length) push the limits of standard transformers only slightly, while a linear number of decoding steps adds a clear new ability (under standard complexity conjectures): recognizing all regular languages. Our results also imply that linear steps keep transformer decoders within context-sensitive languages, and polynomial steps make them recognize exactly the class of polynomial-time solvable problems -- the first exact characterization of a type of transformers in terms of standard complexity classes. Together, our results provide a nuanced framework for understanding how the length of a transformer's chain of thought or scratchpad impacts its reasoning power.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)最近的理论研究发现了一些奇异的简单逻辑问题，如图像两个节点是连接的检查或模拟有限状态机，是不可避免地无法由标准转换器解决的。但在实践中，转换器的逻辑可以通过允许它们使用"链接思考"或"启发笔记"来改进，即在输入前面生成和条件于一系列间接token。我们问：这种间接生成是否实际提高了解oder-only转换器的计算能力？我们表明，答案是yes，但间接生成的数量对计算能力的提高有关键的影响。例如，我们发现，对于输入长度逻辑数个步骤，转换器decoder只有微不到标准转换器的限制，而 linear数个步骤添加了明显的新能力（以标准复杂性假设）：可以识别所有规则语言。我们的结果还表明，线性步骤使transformer decoder处于上下文敏感语言中，而多项式步骤使其识别 precisley 可解语言类型 -- 首次对转换器类型进行标准复杂性类型的准确characterization。总的来说，我们的结果提供了一个细化的框架，用于理解transformer链接思考或启发笔记的长度如何影响其逻辑能力。
</details></li>
</ul>
<hr>
<h2 id="Pit-One-Against-Many-Leveraging-Attention-head-Embeddings-for-Parameter-efficient-Multi-head-Attention"><a href="#Pit-One-Against-Many-Leveraging-Attention-head-Embeddings-for-Parameter-efficient-Multi-head-Attention" class="headerlink" title="Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention"></a>Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07911">http://arxiv.org/abs/2310.07911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huiyin Xue, Nikolaos Aletras</li>
<li>for: 这篇论文的目的是简化预训语言模型的多头注意力（MHA）机制，以减少内存需求。</li>
<li>methods: 作者提议一种单一共享投影矩阵和多头嵌入（MHE）注意力机制，它使用单一的共享投影矩阵和多个头嵌入，实现高度优化的预测性表现。</li>
<li>results: 作者透过实验证明，MHE注意力与传统MHA相比，具有更高的内存效率和预测性表现，并且仅需要一小部分额外参数（$3nd$），相比于传统MHA需要$(3n^2-3n)d^2-3nd$倍的额外参数。<details>
<summary>Abstract</summary>
Scaling pre-trained language models has resulted in large performance gains in various natural language processing tasks but comes with a large cost in memory requirements. Inspired by the position embeddings in transformers, we aim to simplify and reduce the memory footprint of the multi-head attention (MHA) mechanism. We propose an alternative module that uses only a single shared projection matrix and multiple head embeddings (MHE), i.e. one per head. We empirically demonstrate that our MHE attention is substantially more memory efficient compared to alternative attention mechanisms while achieving high predictive performance retention ratio to vanilla MHA on several downstream tasks. MHE attention only requires a negligible fraction of additional parameters ($3nd$, where $n$ is the number of attention heads and $d$ the size of the head embeddings) compared to a single-head attention, while MHA requires $(3n^2-3n)d^2-3nd$ additional parameters.
</details>
<details>
<summary>摘要</summary>
对预训语言模型进行扩大已经带来了许多自然语言处理任务中的性能提升，但是它具有较大的记忆需求。 Drawing inspiration from transformer中的位嵌入，我们想要简化和降低多头注意力（MHA）机制的记忆负载。我们提出了一个替代模组，使用单一的共享复制矩阵和多个头嵌入（MHE），即每个头都有它自己的嵌入。我们实际证明了我们的MHE注意力可以与替代注意力机制相比，具有较高的预测性能保留比，而且仅需要一小部分的额外参数（$3nd$，其中$n$是注意力头数量，$d$是头嵌入大小），相比于单一注意力机制需要 $(3n^2-3n)d^2-3nd$个额外参数。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Evaluation-Metrics-for-Neural-Test-Oracle-Generation"><a href="#Assessing-Evaluation-Metrics-for-Neural-Test-Oracle-Generation" class="headerlink" title="Assessing Evaluation Metrics for Neural Test Oracle Generation"></a>Assessing Evaluation Metrics for Neural Test Oracle Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07856">http://arxiv.org/abs/2310.07856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiho Shin, Hadi Hemmati, Moshi Wei, Song Wang</li>
<li>For: The paper aims to evaluate the performance of state-of-the-art test oracle generation models using both natural language generation (NLG) and test adequacy metrics.* Methods: The authors train and run four state-of-the-art test oracle generation models on five NLG-based and two test adequacy metrics for their analysis. They apply two different correlation analyses between these two sets of metrics.* Results: The authors found no significant correlation between the NLG-based metrics and test adequacy metrics. They also found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex or multiple chained method invocations within the oracle’s parameters, while oracles with low NLG-based metrics but high test adequacy metrics tend to have different assertion types or methods that function similarly to the ones in the ground truth.Here are the three points in Simplified Chinese text:* For: 本研究用于评估现有的测试 oracle 生成模型，使用自然语言生成 (NLG) 和测试准确率 metric。* Methods: 作者使用四种state-of-the-art测试 oracle 生成模型在五种 NLG-based 和两种测试准确率 metric 上进行训练和运行分析。他们应用了两种不同的相关分析方法。* Results: 作者发现没有显著的相关性 между NLG-based  metric 和测试准确率 metric。他们还发现，具有高 NLG-based  metric 但低测试准确率 metric 的 oracle 往往有复杂或多个链接的方法调用在 oracle 中，使模型难以生成完整。相反，具有低 NLG-based  metric 但高测试准确率 metric 的 oracle 往往有不同的断言类型或功能相似的方法调用。<details>
<summary>Abstract</summary>
In this work, we revisit existing oracle generation studies plus ChatGPT to empirically investigate the current standing of their performance in both NLG-based and test adequacy metrics. Specifically, we train and run four state-of-the-art test oracle generation models on five NLG-based and two test adequacy metrics for our analysis. We apply two different correlation analyses between these two different sets of metrics. Surprisingly, we found no significant correlation between the NLG-based metrics and test adequacy metrics. For instance, oracles generated from ChatGPT on the project activemq-artemis had the highest performance on all the NLG-based metrics among the studied NOGs, however, it had the most number of projects with a decrease in test adequacy metrics compared to all the studied NOGs. We further conduct a qualitative analysis to explore the reasons behind our observations, we found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex or multiple chained method invocations within the oracle's parameters, making it hard for the model to generate completely, affecting the test adequacy metrics. On the other hand, oracles with low NLG-based metrics but high test adequacy metrics tend to have to call different assertion types or a different method that functions similarly to the ones in the ground truth. Overall, this work complements prior studies on test oracle generation with an extensive performance evaluation with both NLG and test adequacy metrics and provides guidelines for better assessment of deep learning applications in software test generation in the future.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们回顾了现有的oracle生成研究以及ChatGPT，以 empirically investigating现有的性能水平在NLG基于和测试准确性度量上。 Specifically，我们训练并运行四种 state-of-the-art测试oracle生成模型在五个NLG基于和两个测试准确性度量上进行分析。我们应用了两种 corrrelation分析 между这两个不同的集合的度量。 surprisingly, we found no significant correlation between NLG-based metrics and test adequacy metrics. For instance, oracles generated from ChatGPT on the project activemq-artemis had the highest performance on all NLG-based metrics among the studied NOGs, however, it had the most number of projects with a decrease in test adequacy metrics compared to all the studied NOGs. We further conduct a qualitative analysis to explore the reasons behind our observations, we found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex or multiple chained method invocations within the oracle's parameters, making it hard for the model to generate completely, affecting the test adequacy metrics. On the other hand, oracles with low NLG-based metrics but high test adequacy metrics tend to have to call different assertion types or a different method that functions similarly to the ones in the ground truth. Overall, this work complements prior studies on test oracle generation with an extensive performance evaluation with both NLG and test adequacy metrics and provides guidelines for better assessment of deep learning applications in software test generation in the future.
</details></li>
</ul>
<hr>
<h2 id="Framework-for-Question-Answering-in-Sanskrit-through-Automated-Construction-of-Knowledge-Graphs"><a href="#Framework-for-Question-Answering-in-Sanskrit-through-Automated-Construction-of-Knowledge-Graphs" class="headerlink" title="Framework for Question-Answering in Sanskrit through Automated Construction of Knowledge Graphs"></a>Framework for Question-Answering in Sanskrit through Automated Construction of Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07848">http://arxiv.org/abs/2310.07848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishikesh Terdalkar, Arnab Bhattacharya</li>
<li>for: 本研究targets the problem of building knowledge graphs for particular types of relationships from sa\d{m}sk\d{r}ta texts, and develops a natural language question-answering system in sa\d{m}sk\d{r}ta that uses the knowledge graph to answer factoid questions.</li>
<li>methods: 本研究使用了自然语言处理技术和知识图谱技术，并设计了一个框架来支持整个系统。两个实例分别用于人际关系from mah=abh=arata和r=am=aya\d{n}a，以及同义关系from bh=avaprak=a&#39;sa nigha\d{n}\d{t}u。</li>
<li>results: 研究表明，使用这种方法可以回答大约50%的问题正确。然而，研究还分析了系统的缺陷，并讨论了可能的改进方向。<details>
<summary>Abstract</summary>
Sanskrit (sa\d{m}sk\d{r}ta) enjoys one of the largest and most varied literature in the whole world. Extracting the knowledge from it, however, is a challenging task due to multiple reasons including complexity of the language and paucity of standard natural language processing tools. In this paper, we target the problem of building knowledge graphs for particular types of relationships from sa\d{m}sk\d{r}ta texts. We build a natural language question-answering system in sa\d{m}sk\d{r}ta that uses the knowledge graph to answer factoid questions. We design a framework for the overall system and implement two separate instances of the system on human relationships from mah\=abh\=arata and r\=am\=aya\d{n}a, and one instance on synonymous relationships from bh\=avaprak\=a\'sa nigha\d{n}\d{t}u, a technical text from \=ayurveda. We show that about 50% of the factoid questions can be answered correctly by the system. More importantly, we analyse the shortcomings of the system in detail for each step, and discuss the possible ways forward.
</details>
<details>
<summary>摘要</summary>
санскрит（sa\d{m}sk\d{r}ta）拥有全球最大和最多样化的文学作品。然而，从其中提取知识是一项具有挑战性的任务，主要原因包括语言复杂性和自然语言处理工具的缺乏。在这篇论文中，我们target的是从sa\d{m}sk\d{r}ta文本中提取特定类型的关系知识，并建立一个基于知识图的自然语言问答系统。我们设计了整个框架，并实现了两个不同的系统实例，分别处理人类关系from mah\=abh\=arata和r\=am\=aya\d{n}a，以及一个实例处理synonymous关系from bh\=avaprak\=a\'sa nigha\d{n}\d{t}u，这是一部技术文献from \=ayurveda。我们发现系统可以正确地回答50%的问题。此外，我们还进行了每个步骤的细节分析，并讨论了可能的改进方向。
</details></li>
</ul>
<hr>
<h2 id="Antarlekhaka-A-Comprehensive-Tool-for-Multi-task-Natural-Language-Annotation"><a href="#Antarlekhaka-A-Comprehensive-Tool-for-Multi-task-Natural-Language-Annotation" class="headerlink" title="Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation"></a>Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07826">http://arxiv.org/abs/2310.07826</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Antarlekhaka/code">https://github.com/Antarlekhaka/code</a></li>
<li>paper_authors: Hrishikesh Terdalkar, Arnab Bhattacharya</li>
<li>for: 本研究是为了提高自然语言处理（NLP）技术的发展，特别是为了解决低资源语言的 annotated dataset 问题。</li>
<li>methods: 本文提出了一个名为 Antarlekhaka 的工具，用于手动标注 NLP 相关的全面任务。该工具支持 Unicode 兼容、语言不依赖、Web 部署和分布式标注多个同时annotator。系统提供了8类任务的用户友好界面。</li>
<li>results: 比较 исследование表明，Antarlekhaka 在对象评估中表现出色，并在实际应用中用于两种不同语言的两个实际标注任务。工具可以在 <a target="_blank" rel="noopener" href="https://github.com/Antarlekhaka/code">https://github.com/Antarlekhaka/code</a> 上下载。<details>
<summary>Abstract</summary>
One of the primary obstacles in the advancement of Natural Language Processing (NLP) technologies for low-resource languages is the lack of annotated datasets for training and testing machine learning models. In this paper, we present Antarlekhaka, a tool for manual annotation of a comprehensive set of tasks relevant to NLP. The tool is Unicode-compatible, language-agnostic, Web-deployable and supports distributed annotation by multiple simultaneous annotators. The system sports user-friendly interfaces for 8 categories of annotation tasks. These, in turn, enable the annotation of a considerably larger set of NLP tasks. The task categories include two linguistic tasks not handled by any other tool, namely, sentence boundary detection and deciding canonical word order, which are important tasks for text that is in the form of poetry. We propose the idea of sequential annotation based on small text units, where an annotator performs several tasks related to a single text unit before proceeding to the next unit. The research applications of the proposed mode of multi-task annotation are also discussed. Antarlekhaka outperforms other annotation tools in objective evaluation. It has been also used for two real-life annotation tasks on two different languages, namely, Sanskrit and Bengali. The tool is available at https://github.com/Antarlekhaka/code.
</details>
<details>
<summary>摘要</summary>
一个主要障碍在低资源语言自然语言处理（NLP）技术的发展是缺乏训练和测试机器学习模型的彩杂化数据集。在这篇论文中，我们介绍了Antarlekhaka，一种用于手动标注NLP中广泛的任务的工具。该工具兼容Unicode，语言不偏，可在网上部署，并支持同时进行多个注释者的分布式注释。系统提供了用户友好的界面，用于8种注释任务类别。这些任务类别使得可以对NLP任务进行更广泛的注释。任务类别包括两种语言学任务，即句子边界检测和确定正确的字符顺序，这些任务对于文学形式的文本非常重要。我们提出了顺序注释基于小文本单元的想法，其中一个注释者在处理一个文本单元后，才可以前往下一个单元。我们还讨论了在多任务注释模式下的研究应用。Antarlekhaka在对象评估中表现出色，并在两种不同语言上进行了两个实际注释任务。工具可在https://github.com/Antarlekhaka/code中下载。
</details></li>
</ul>
<hr>
<h2 id="Non-autoregressive-Text-Editing-with-Copy-aware-Latent-Alignments"><a href="#Non-autoregressive-Text-Editing-with-Copy-aware-Latent-Alignments" class="headerlink" title="Non-autoregressive Text Editing with Copy-aware Latent Alignments"></a>Non-autoregressive Text Editing with Copy-aware Latent Alignments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07821">http://arxiv.org/abs/2310.07821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yzhangcs/ctc-copy">https://github.com/yzhangcs/ctc-copy</a></li>
<li>paper_authors: Yu Zhang, Yue Zhang, Leyang Cui, Guohong Fu</li>
<li>for: 这 paper 的目的是解决 Seq2Seq 中的慢渐进问题，提高文本编辑速度。</li>
<li>methods: 这 paper 使用了一种新的非autoregressive 文本编辑方法，通过使用 latent CTC 对齐来模型编辑过程。它还引入了 copy 操作来更有效地管理文本重叠。</li>
<li>results: 这 paper 的方法在 GEC 和 sentence fusion 任务上进行了广泛的实验，与现有的 Seq2Edit 模型相比，显著地提高了性能，并与 Seq2Seq 模型相比，实现了更高的速度（大于 $4\times$）。此外，它还在德语和俄语上进行了良好的扩展性测试。<details>
<summary>Abstract</summary>
Recent work has witnessed a paradigm shift from Seq2Seq to Seq2Edit in the field of text editing, with the aim of addressing the slow autoregressive inference problem posed by the former. Despite promising results, Seq2Edit approaches still face several challenges such as inflexibility in generation and difficulty in generalizing to other languages. In this work, we propose a novel non-autoregressive text editing method to circumvent the above issues, by modeling the edit process with latent CTC alignments. We make a crucial extension to CTC by introducing the copy operation into the edit space, thus enabling more efficient management of textual overlap in editing. We conduct extensive experiments on GEC and sentence fusion tasks, showing that our proposed method significantly outperforms existing Seq2Edit models and achieves similar or even better results than Seq2Seq with over $4\times$ speedup. Moreover, it demonstrates good generalizability on German and Russian. In-depth analyses reveal the strengths of our method in terms of the robustness under various scenarios and generating fluent and flexible outputs.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:最近的工作受到了Seq2Seq到Seq2Edit的 Paradigm shift的影响，以解决前者的慢进 autoregressive inference 问题。尽管有了承诺的结果，Seq2Edit 方法仍然面临着一些挑战，如生成灵活性不足和难以泛化到其他语言。在这个工作中，我们提出了一种新的非autoregressive 文本编辑方法，通过在 latent CTC 对齐中模型编辑过程。我们对 CTC 进行了关键扩展，通过在编辑空间中引入复制操作，以更有效地处理文本重叠的问题。我们在 GEC 和 sentence fusion 任务上进行了广泛的实验，显示我们的提议方法可以具有较高的性能，与 Seq2Seq 的更换速度高于 4 倍。此外，它还能够在德语和俄语上达到类似或更好的结果。深入分析表明，我们的方法在不同的场景下具有良好的稳定性和生成灵活性。
</details></li>
</ul>
<hr>
<h2 id="Faithfulness-Measurable-Masked-Language-Models"><a href="#Faithfulness-Measurable-Masked-Language-Models" class="headerlink" title="Faithfulness Measurable Masked Language Models"></a>Faithfulness Measurable Masked Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07819">http://arxiv.org/abs/2310.07819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Madsen, Siva Reddy, Sarath Chandar</li>
<li>for: 本研究旨在提供一种可靠度度量的模型，以度量NLP模型的解释性。</li>
<li>methods: 本研究使用一种新的精度调整方法，该方法通过在模型中嵌入屏蔽token来使屏蔽token变得与标准分布相符，从而提高模型的可靠度度量。</li>
<li>results: 本研究通过在多种任务上应用该方法，并通过统计学的内部分布测试 validate the effectiveness of the proposed approach。 Additionally, the proposed approach improves the explainability of NLP models by making importance measures more faithful.<details>
<summary>Abstract</summary>
A common approach to explain NLP models, is to use importance measures that express which tokens are important for a prediction. Unfortunately, such explanations are often wrong despite being persuasive. Therefore, it is essential to measure their faithfulness. One such metric is if tokens are truly important, then masking them should result in worse model performance. However, token masking introduces out-of-distribution issues and existing solutions are computationally expensive and employ proxy-models. Furthermore, other metrics are very limited in scope. In this work, we propose an inherently faithfulness measurable model that addresses these challenges. This is achieved by using a novel fine-tuning method that incorporates masking, such that masking tokens become in-distribution by design. This differs from existing approaches, which are completely model-agnostic but are inapplicable in practice. We demonstrate the generality of our approach by applying it to various tasks and validate it using statistical in-distribution tests. Additionally, because masking is in-distribution, importance measures which themselves use masking become more faithful, thus our model becomes more explainable.
</details>
<details>
<summary>摘要</summary>
通常来说，用importance measure来解释NLP模型的做法是非常常见的。然而，这些解释通常是错误的，即使很有说服力。因此，我们需要衡量其忠诚度。一种 metric 是，如果 tokens 是重要的，那么它们的masking应该导致模型的性能下降。然而，token masking 引入了 OUT-OF-distribution 问题，现有的解决方案都是 computationally expensive 并使用 proxy-models。此外，其他 metric 的范围非常有限。在这种情况下，我们提出了一种自然的 faithfulness measurable model，解决了这些挑战。这是通过一种新的 fine-tuning 方法，使得 masking tokens 变得 IN-distribution by design。这与现有的方法不同，它们是完全model-agnostic，但是在实践中无法应用。我们验证了我们的方法的通用性，并使用 statistical in-distribution 测试来验证。此外，因为 masking 变得 IN-distribution，importance measure 自身使用 masking 就变得更 faithful，因此我们的模型变得更加可解释。
</details></li>
</ul>
<hr>
<h2 id="Language-Models-As-Semantic-Indexers"><a href="#Language-Models-As-Semantic-Indexers" class="headerlink" title="Language Models As Semantic Indexers"></a>Language Models As Semantic Indexers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07815">http://arxiv.org/abs/2310.07815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Jin, Hansi Zeng, Guoyin Wang, Xiusi Chen, Tianxin Wei, Ruirui Li, Zhengyang Wang, Zheng Li, Yang Li, Hanqing Lu, Suhang Wang, Jiawei Han, Xianfeng Tang</li>
<li>for: 本文 targets 推荐和检索等下游任务，即使 semantic IDs 的学习 faces challenges such as 缺乏 semantic supervision and sequential discrete ID structure.</li>
<li>methods: 本文提出了一种自动学习的框架 LMINDEXER，通过使用生成型语言模型来学习 semantic IDs。具体来说，LMINDEXER 使用了递归学习和对比学习来学习 Neil 表示的序列化概率分布，并通过自我监督文档重建目标来缓解缺乏 semantic supervision 的问题。</li>
<li>results: 在三个任务中（推荐、产品搜索和文档检索），LMINDEXER 在五个 dataset 上取得了与竞争对手相比高度显著和一致的性能提升。<details>
<summary>Abstract</summary>
Semantic identifier (ID) is an important concept in information retrieval that aims to preserve the semantics of objects such as documents and items inside their IDs. Previous studies typically adopt a two-stage pipeline to learn semantic IDs by first procuring embeddings using off-the-shelf text encoders and then deriving IDs based on the embeddings. However, each step introduces potential information loss and there is usually an inherent mismatch between the distribution of embeddings within the latent space produced by text encoders and the anticipated distribution required for semantic indexing. Nevertheless, it is non-trivial to design a method that can learn the document's semantic representations and its hierarchical structure simultaneously, given that semantic IDs are discrete and sequentially structured, and the semantic supervision is deficient. In this paper, we introduce LMINDEXER, a self-supervised framework to learn semantic IDs with a generative language model. We tackle the challenge of sequential discrete ID by introducing a semantic indexer capable of generating neural sequential discrete representations with progressive training and contrastive learning. In response to the semantic supervision deficiency, we propose to train the model with a self-supervised document reconstruction objective. The learned semantic indexer can facilitate various downstream tasks, such as recommendation and retrieval. We conduct experiments on three tasks including recommendation, product search, and document retrieval on five datasets from various domains, where LMINDEXER outperforms competitive baselines significantly and consistently.
</details>
<details>
<summary>摘要</summary>
Semantic identifier (ID) 是信息检索中一个重要概念，旨在保留文档和项目中的 semantics。前一些研究通常采用两个阶段管道来学习含义 ID，首先使用商业化的文本编码器获取嵌入，然后基于嵌入生成 ID。然而，每一步都会导致信息损失，并且通常存在嵌入空间生成的 latent distribution 和预期的 ID 分布之间的匹配问题。此外，具有含义 ID 的文档结构是隐藏的，很难直接学习文档的含义表示和层次结构。在本文中，我们引入 LMINDEXER，一种自动编码的框架，用于学习含义 ID。我们解决了顺序 discrete ID 的挑战，通过引入一种含义编码器，能够生成神经网络顺序 discrete 表示，并在进行进度训练和对比学习中提高表示的质量。受到含义监督的缺乏问题，我们提议使用自动编码的文档重建目标来训练模型。学习的含义编码器可以帮助下游任务，如推荐和检索。我们在五个不同领域的五个数据集上进行了三个任务的实验，包括推荐、产品搜索和文档检索，LMINDEXER 与竞争对手比较显著并且一致性高。
</details></li>
</ul>
<hr>
<h2 id="Ontology-Enrichment-for-Effective-Fine-grained-Entity-Typing"><a href="#Ontology-Enrichment-for-Effective-Fine-grained-Entity-Typing" class="headerlink" title="Ontology Enrichment for Effective Fine-grained Entity Typing"></a>Ontology Enrichment for Effective Fine-grained Entity Typing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07795">http://arxiv.org/abs/2310.07795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siru Ouyang, Jiaxin Huang, Pranav Pillai, Yunyi Zhang, Yu Zhang, Jiawei Han</li>
<li>for: 本研究的目的是开发一个不需要人工标注的精细化entity typing方法，以便在不同的语言和文本中进行精细化entity typing。</li>
<li>methods: 我们提出了一个名为OnEFET的方法，其中我们将ontology结构中的每个node补充了两种额外信息：instance information和topic information。我们还开发了一个从粗到细的类型识别算法，该算法利用了补充后的ontology结构，通过训练一个推理模型来进行精细化类型识别。</li>
<li>results: 我们的实验结果显示，OnEFET可以在不需要人工标注的情况下，实现高品质的精细化entity typing，并且比现有的零shot方法大幅提高性能，甚至可以与有标注的方法相匹配。<details>
<summary>Abstract</summary>
Fine-grained entity typing (FET) is the task of identifying specific entity types at a fine-grained level for entity mentions based on their contextual information. Conventional methods for FET require extensive human annotation, which is time-consuming and costly. Recent studies have been developing weakly supervised or zero-shot approaches. We study the setting of zero-shot FET where only an ontology is provided. However, most existing ontology structures lack rich supporting information and even contain ambiguous relations, making them ineffective in guiding FET. Recently developed language models, though promising in various few-shot and zero-shot NLP tasks, may face challenges in zero-shot FET due to their lack of interaction with task-specific ontology. In this study, we propose OnEFET, where we (1) enrich each node in the ontology structure with two types of extra information: instance information for training sample augmentation and topic information to relate types to contexts, and (2) develop a coarse-to-fine typing algorithm that exploits the enriched information by training an entailment model with contrasting topics and instance-based augmented training samples. Our experiments show that OnEFET achieves high-quality fine-grained entity typing without human annotation, outperforming existing zero-shot methods by a large margin and rivaling supervised methods.
</details>
<details>
<summary>摘要</summary>
《细化实体类型标识（FET）任务是根据实体提及的上下文信息确定特定的实体类型。传统的FET方法需要大量的人工标注，这是时间consuming和costly。 latest studies have been developing weakly supervised or zero-shot approaches. 在我们的研究中，我们研究了基于ontology的zero-shot FET setting，但是现有的ontology结构缺乏详细的支持信息，甚至存在冲突关系，使其无法有效地引导FET。 latest developed语言模型，虽在various few-shot和zero-shot NLP任务中表现出色，但在zero-shot FET中可能会面临挑战，因为它们与任务特定的ontology之间没有交互。在本研究中，我们提出OnEFET方法，其包括以下两个部分：1. 对ontology结构中的每个节点添加两种类型的额外信息：实例信息用于增强训练样本，以及话题信息用于将类型与上下文相关联。2. 开发一种粗细类型推理算法，利用增强后的信息，通过训练对照话题和实例基于增强训练样本的推理模型，以实现高质量的细化实体类型标识。我们的实验表明，OnEFET方法可以在无人标注的情况下实现高质量的细化实体类型标识，与现有的零shot方法比，差距较大，甚至可以与supervised方法相媲美。
</details></li>
</ul>
<hr>
<h2 id="To-Build-Our-Future-We-Must-Know-Our-Past-Contextualizing-Paradigm-Shifts-in-Natural-Language-Processing"><a href="#To-Build-Our-Future-We-Must-Know-Our-Past-Contextualizing-Paradigm-Shifts-in-Natural-Language-Processing" class="headerlink" title="To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing"></a>To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07715">http://arxiv.org/abs/2310.07715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sireesh Gururaja, Amanda Bertsch, Clara Na, David Gray Widder, Emma Strubell</li>
<li>for: 本研究旨在理解NLP领域的未来发展，通过对过去的发展情况进行研究。</li>
<li>methods: 本研究使用长期采访26名NLP研究者，了解他们对领域的看法和体验，并通过分析ACL Anthology中文献的引用、作者和语言使用趋势来补充。</li>
<li>results: 研究发现了NLP领域的cyclical patterns和新的变化，包括benchmark文化和软件基础设施的变化。研究者们共享对未来的希望和担忧，并提出了更加 deliberate 的行动来形塑未来。<details>
<summary>Abstract</summary>
NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Found-in-the-Middle-Permutation-Self-Consistency-Improves-Listwise-Ranking-in-Large-Language-Models"><a href="#Found-in-the-Middle-Permutation-Self-Consistency-Improves-Listwise-Ranking-in-Large-Language-Models" class="headerlink" title="Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models"></a>Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07712">http://arxiv.org/abs/2310.07712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/castorini/perm-sc">https://github.com/castorini/perm-sc</a></li>
<li>paper_authors: Raphael Tang, Xinyu Zhang, Xueguang Ma, Jimmy Lin, Ferhan Ture</li>
<li>for:  addresses the issue of positional bias in listwise ranking tasks using large language models (LLMs)</li>
<li>methods:  proposes a method called permutation self-consistency, which marginalizes out different list orders in the prompt to produce an order-independent ranking with less positional bias</li>
<li>results:  improves scores from conventional inference by up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B) on five list-ranking datasets in sorting and passage reranking, surpassing the previous state of the art in passage reranking.<details>
<summary>Abstract</summary>
Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking. To address this, we propose permutation self-consistency, a form of self-consistency over ranking list outputs of black-box LLMs. Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias. First, given some input prompt, we repeatedly shuffle the list in the prompt and pass it through the LLM while holding the instructions the same. Next, we aggregate the resulting sample of rankings by computing the central ranking closest in distance to all of them, marginalizing out prompt order biases in the process. Theoretically, we prove the robustness of our method, showing convergence to the true ranking in the presence of random perturbations. Empirically, on five list-ranking datasets in sorting and passage reranking, our approach improves scores from conventional inference by up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous state of the art in passage reranking. Our code is at https://github.com/castorini/perm-sc.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在使用上下文时表现出位置偏袋，这会使列表排序更加复杂。为解决这问题，我们提议使用排序自适应性，即黑盒LLM的排序输出的自适应性。我们的关键想法是在提交给LLM的提示中重复排序列表，然后通过计算提示中列表的不同排序顺序而生成一个位置无关的排序。首先，我们给一个输入提示，然后重复地将提示中的列表排序，并将排序结果通过LLM进行处理，保持 instrucions 不变。接着，我们将得到的多个排序样本 aggregated 以计算最近的中间排序，这样就可以消除提示中的位置偏袋。我们理论上证明了我们的方法的稳定性，并证明在Random pertubations 的存在下，我们的方法会 converge 到真实的排序。empirically，我们在5个列表排序 dataset 上进行 sorting 和 passage reranking  task 上，我们的方法可以提高 convential inference 的得分，最高提高7-18% 和8-16% 分别，超过了过去的最佳性能。我们的代码可以在https://github.com/castorini/perm-sc 找到。
</details></li>
</ul>
<hr>
<h2 id="DiPmark-A-Stealthy-Efficient-and-Resilient-Watermark-for-Large-Language-Models"><a href="#DiPmark-A-Stealthy-Efficient-and-Resilient-Watermark-for-Large-Language-Models" class="headerlink" title="DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models"></a>DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07710">http://arxiv.org/abs/2310.07710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihan Wu, Zhengmian Hu, Hongyang Zhang, Heng Huang</li>
<li>for: 本研究旨在提高数据安全性，通过隐藏在数据中的潜在信息来保护数据。</li>
<li>methods: 我们提出了一种新的分布保持（DiP）水印技术，该技术可以在水印过程中保持原始数据的分布，并且可以在不需要访问语言模型API或参数的情况下进行检测。</li>
<li>results: 我们的方法在针对不同的数据集进行实验中，显示了高度的隐身性、高效性和抗性能。这些结果表明，我们的DiPmark技术可以成为数据水印任务中的一种可靠的解决方案。<details>
<summary>Abstract</summary>
Watermarking techniques offer a promising way to secure data via embedding covert information into the data. A paramount challenge in the domain lies in preserving the distribution of original data during watermarking. Our research extends and refines existing watermarking framework, placing emphasis on the importance of a distribution-preserving (DiP) watermark. Contrary to the current strategies, our proposed DiPmark preserves the original token distribution during watermarking (stealthy), is detectable without access to the language model API or weights (efficient), and is robust to moderate changes of tokens (resilient). This is achieved by incorporating a novel reweight strategy, combined with a hash function that assigns unique \textit{i.i.d.} ciphers based on the context. The empirical benchmarks of our approach underscore its stealthiness, efficiency, and resilience, making it a robust solution for watermarking tasks that demand impeccable quality preservation.
</details>
<details>
<summary>摘要</summary>
通过推入隐藏信息的技术来保护数据， watermarking 技术具有潜在的应用前景。然而，在这个领域中，一个挑战是保持原始数据的分布。我们的研究扩展和改进了现有的 watermarking 框架，强调在 watermarking 过程中保持原始数据的分布。与现有策略不同，我们的提出的 DiPmark 可以在隐身下（stealthy）、无需对语言模型 API 或权重进行访问（efficient）、并且对 Token 的修改具有较好的抗性（resilient）。这是通过 integrate 一种新的重Weight 策略和基于上下文的哈希函数来实现的。我们的实验室测试表明，我们的方法具有隐身、高效和抗性等优点，使其成为保护需要优质保持的任务中的一种可靠的解决方案。
</details></li>
</ul>
<hr>
<h2 id="MatFormer-Nested-Transformer-for-Elastic-Inference"><a href="#MatFormer-Nested-Transformer-for-Elastic-Inference" class="headerlink" title="MatFormer: Nested Transformer for Elastic Inference"></a>MatFormer: Nested Transformer for Elastic Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07707">http://arxiv.org/abs/2310.07707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Devvrit, Sneha Kudugunta, Aditya Kusupati, Tim Dettmers, Kaifeng Chen, Inderjit Dhillon, Yulia Tsvetkov, Hannaneh Hajishirzi, Sham Kakade, Ali Farhadi, Prateek Jain</li>
<li>for: 这篇论文旨在提供一个可调式的Transformer架构，以满足不同的推广环境，例如多个加速器集群和单独的手持式智能手机。</li>
<li>methods: 本研究使用了MatFormer架构，一种嵌套式Transformer架构，实现模型的灵活性。每个Feed Forward Network（FFN）层在MatFormer模型中被联合地优化了一些嵌套的小 FFN层。这个训练程序允许在不同层次上进行模型的混合，例如从一个已训练的通用MatFormer模型中提取出百species的精确小模型，这些小模型从未直接优化过。</li>
<li>results: 本研究在不同的模型类型（解oder和编码器）、modalities（语言和视觉）和 scales（ UP to 2.6B 参数）中评估了MatFormer的效果。结果显示，一个2.6B解oder-only MatFormer语言模型（MatLM）可以将模型范围从1.5B到2.6B不同的精确小模型，每个模型都展示了相似的验证损失和一次下游评估。此外，我们发现小编码器从一个通用MatFormer-based ViT（MatViT）编码器中提取出的模型 preserved 度量空间结构，用于大规模适应 Retrieval。最后，我们显示了对于MatFormer模型的推广批评可以进一步降低推广时间。<details>
<summary>Abstract</summary>
Transformer models are deployed in a wide range of settings, from multi-accelerator clusters to standalone mobile phones. The diverse inference constraints in these scenarios necessitate practitioners to train foundation models such as PaLM 2, Llama, & ViTs as a series of models of varying sizes. Due to significant training costs, only a select few model sizes are trained and supported, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy. This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints. Each Feed Forward Network (FFN) block of a MatFormer model is jointly optimized with a few nested smaller FFN blocks. This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized. We empirically demonstrate MatFormer's effectiveness across different model classes (decoders & encoders), modalities (language & vision), and scales (up to 2.6B parameters). We find that a 2.6B decoder-only MatFormer language model (MatLM) allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting comparable validation loss and one-shot downstream evaluations to their independently trained counterparts. Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval. Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency.
</details>
<details>
<summary>摘要</summary>
<<SYS>>transformer 模型在多种场景中部署，从多个加速器集群到单个手持设备。这些多样化的推理约束使得实践者需要训练基础模型如PaLM 2、Llama 和 ViTs 等多种模型的变体。由于训练成本昂贵，只有一些选择的模型大小得到训练和支持，限制了更细化的控制 над相关的负载、成本和准确率。这项工作介绍了 MatFormer，一种嵌入式 transformer 架构，用于提供多种部署约束的灵活性。每个Feed Forward Network（FFN）块的 MatFormer 模型都与一些嵌入的小 FFN 块进行共同优化。这种训练过程允许在层次上混合模型粒度，即一个已训练的通用 MatFormer 模型可以提取百种准确的小模型，这些小模型从未直接优化。我们在不同的模型类型（解码器和编码器）、modalities（语言和视觉）和scale（ UP TO 2.6B 参数）上进行了实验，发现一个 2.6B 解码器-only MatFormer 语言模型（MatLM）可以提取尺度从 1.5B 到 2.6B 之间的多种准确的小模型，每个模型都展现出与独立训练的同类模型相同的验证损失和一次性下游评估。此外，我们发现小编码器提取自通用 MatFormer-based ViT 编码器（MatViT） preserve  метри空间结构，用于适应大规模适应 retrieval。最后，我们发现可以通过准确和一致的小模型提取自 MatFormer 进行推理时的推测执行。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Ferret-Refer-and-Ground-Anything-Anywhere-at-Any-Granularity"><a href="#Ferret-Refer-and-Ground-Anything-Anywhere-at-Any-Granularity" class="headerlink" title="Ferret: Refer and Ground Anything Anywhere at Any Granularity"></a>Ferret: Refer and Ground Anything Anywhere at Any Granularity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07704">http://arxiv.org/abs/2310.07704</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apple/ml-ferret">https://github.com/apple/ml-ferret</a></li>
<li>paper_authors: Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, Zirui Wang, Liangliang Cao, Shih-Fu Chang, Yinfei Yang</li>
<li>For: The paper presents a new multimodal large language model (MLLM) called Ferret, which is capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.* Methods: The paper employs a novel and powerful hybrid region representation that integrates discrete coordinates and continuous features jointly to represent a region in the image. Additionally, the paper proposes a spatial-aware visual sampler to extract continuous features of versatile regions.* Results: The paper achieves superior performance in classical referring and grounding tasks and greatly outperforms existing MLLMs in region-based and localization-demanded multimodal chatting. The paper also shows improved capability in describing image details and alleviated object hallucination.Here are the three points in Simplified Chinese text:* For: 这篇论文提出了一种新的多模态大语言模型（MLLM）名为 Ferret，它可以理解图像中任何形状或粒度的空间引用，并准确地将开放词汇描述与图像相关联。* Methods: 论文使用了一种新的混合坐标和连续特征的区域表示方法，这种方法可以同时使用精确的坐标和连续特征来表示图像中的区域。此外，论文还提出了一种适应空间的视觉采样器，可以处理不同形状的区域中的变化精度。* Results: 论文的实验结果表明，Ferret可以在经典的引用和固定 Task 中表现出色，同时也在基于区域和本地化的多模态对话中表现出色。论文还发现，Ferret可以更好地描述图像细节，并减少对象投影现象。<details>
<summary>Abstract</summary>
We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions. To unify referring and grounding in the LLM paradigm, Ferret employs a novel and powerful hybrid region representation that integrates discrete coordinates and continuous features jointly to represent a region in the image. To extract the continuous features of versatile regions, we propose a spatial-aware visual sampler, adept at handling varying sparsity across different shapes. Consequently, Ferret can accept diverse region inputs, such as points, bounding boxes, and free-form shapes. To bolster the desired capability of Ferret, we curate GRIT, a comprehensive refer-and-ground instruction tuning dataset including 1.1M samples that contain rich hierarchical spatial knowledge, with 95K hard negative data to promote model robustness. The resulting model not only achieves superior performance in classical referring and grounding tasks, but also greatly outperforms existing MLLMs in region-based and localization-demanded multimodal chatting. Our evaluations also reveal a significantly improved capability of describing image details and a remarkable alleviation in object hallucination. Code and data will be available at https://github.com/apple/ml-ferret
</details>
<details>
<summary>摘要</summary>
我们介绍 Ferret，一个新的多modal大语言模型（MLLM），能够理解图像中任何形状或粒度的空间参考，并将开 vocabulary 的描述精确地落地。为了在 LLM 模型中统一参考和落地，Ferret 使用了一个新的强大的混合区域表示方法，将组合点坐标和连续特征来表示一个区域在图像中。为了提取不同形状的区域中的连续特征，我们提出了一个适应性的可见频率抽样器，能够处理不同形状的统计差异。因此，Ferret 可以接受多种区域输入，包括点、 bounding box 和自由形状。为了增强 Ferret 的预期功能，我们组建了 GRIT，一个全面的参考和落地指令调整dataset，包含110万个样本，其中95,000个困难样本来提高模型的Robustness。最终的模型不仅在经典的参考和落地任务中表现出色，而且在区域基础的多模ALM 谈话中也表现出色，并且具有了较好的描述图像细节和关键物体误射改善。我们的评估还显示，Ferret 在图像辨识和物体描述方面的表现都有了明显的提高。代码和数据将会在https://github.com/apple/ml-ferret 上公开。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-enhanced-Memory-Model-for-Emotional-Support-Conversation"><a href="#Knowledge-enhanced-Memory-Model-for-Emotional-Support-Conversation" class="headerlink" title="Knowledge-enhanced Memory Model for Emotional Support Conversation"></a>Knowledge-enhanced Memory Model for Emotional Support Conversation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07700">http://arxiv.org/abs/2310.07700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengzhao Jia, Qianglong Chen, Liqiang Jing, Dawei Fu, Renyu Li</li>
<li>for: 这篇论文的目的是提出一个新的知识增强的 Memory mODEl for emotional suppoRt coNversation (MODERN), 以便解决现有方法面临的三个挑战：1）情感变化的多样性、2）实用的回应、3）复杂的战略模型。</li>
<li>methods: 这篇论文使用了一个知识增强的对话ContextEncoding来捕捉不同时间段的聊天中的动态情感变化，并从ConceptNet中选择相关的上下文概念来生成实用的回应。另外，它还实现了一个新的记忆增强的战略模型模组，以模型内在的语言结构和semantic pattern。</li>
<li>results: 实验结果显示，这篇论文的MODERN模型在一个大规模的数据集上比cutting-edge基eline有superiority。<details>
<summary>Abstract</summary>
The prevalence of mental disorders has become a significant issue, leading to the increased focus on Emotional Support Conversation as an effective supplement for mental health support. Existing methods have achieved compelling results, however, they still face three challenges: 1) variability of emotions, 2) practicality of the response, and 3) intricate strategy modeling. To address these challenges, we propose a novel knowledge-enhanced Memory mODEl for emotional suppoRt coNversation (MODERN). Specifically, we first devise a knowledge-enriched dialogue context encoding to perceive the dynamic emotion change of different periods of the conversation for coherent user state modeling and select context-related concepts from ConceptNet for practical response generation. Thereafter, we implement a novel memory-enhanced strategy modeling module to model the semantic patterns behind the strategy categories. Extensive experiments on a widely used large-scale dataset verify the superiority of our model over cutting-edge baselines.
</details>
<details>
<summary>摘要</summary>
现在，情绪疾病的流行性已经成为一个严重的问题，导致了对情绪支持对话的增加关注，以提供有效的心理健康支持。现有的方法已经取得了吸引人的结果，但它们仍然面临三大挑战：1）情绪的变化性，2）回应的实用性，3）复杂的战略模型化。为了解决这些挑战，我们提出了一种基于知识的Memory mODEl для情绪支持对话（MODERN）。具体来说，我们首先开发了一种具有知识扩展的对话上下文编码，以捕捉不同时期的对话中动态变化的情绪变化，并从ConceptNet中选择相关的上下文概念来生成实用的回应。其次，我们实施了一种新的记忆增强策略模型模块，以模型在策略类别之间的semanticpattern。经过广泛的实验，我们发现我们的模型在一个广泛使用的大规模数据集上胜过了当今最前沿的基eline。
</details></li>
</ul>
<hr>
<h2 id="Composite-Backdoor-Attacks-Against-Large-Language-Models"><a href="#Composite-Backdoor-Attacks-Against-Large-Language-Models" class="headerlink" title="Composite Backdoor Attacks Against Large Language Models"></a>Composite Backdoor Attacks Against Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07676">http://arxiv.org/abs/2310.07676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang</li>
<li>for: 这 paper 探讨了基础模型中的攻击性 vulnerability，特别是通过 backdoor 攻击来威胁下游任务。</li>
<li>methods: 这 paper 使用了多个触发键散布在不同的提问组件中，这种 Composite Backdoor Attack (CBA) 比单个组件中的触发键更隐蔽。</li>
<li>results: 实验结果表明，CBA 在自然语言处理 (NLP) 和多媒体任务中都是有效的，例如在 Emotion 数据集上，使用 $3%$ 恶意样本对 LLaMA-7B 模型进行攻击，成功率为 $100%$，误 trigger 率在 $2.06%$ 以下，模型性能下降很小。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated superior performance compared to previous methods on various tasks, and often serve as the foundation models for many researches and services. However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks. In this paper, we explore the vulnerability of LLMs through the lens of backdoor attacks. Different from existing backdoor attacks against LLMs, ours scatters multiple trigger keys in different prompt components. Such a Composite Backdoor Attack (CBA) is shown to be stealthier than implanting the same multiple trigger keys in only a single component. CBA ensures that the backdoor is activated only when all trigger keys appear. Our experiments demonstrate that CBA is effective in both natural language processing (NLP) and multimodal tasks. For instance, with $3\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset, our attack achieves a $100\%$ Attack Success Rate (ASR) with a False Triggered Rate (FTR) below $2.06\%$ and negligible model accuracy degradation. The unique characteristics of our CBA can be tailored for various practical scenarios, e.g., targeting specific user groups. Our work highlights the necessity of increased security research on the trustworthiness of foundation LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Well-Begun-is-Half-Done-Generator-agnostic-Knowledge-Pre-Selection-for-Knowledge-Grounded-Dialogue"><a href="#Well-Begun-is-Half-Done-Generator-agnostic-Knowledge-Pre-Selection-for-Knowledge-Grounded-Dialogue" class="headerlink" title="Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue"></a>Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07659">http://arxiv.org/abs/2310.07659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qinlang14/gate">https://github.com/qinlang14/gate</a></li>
<li>paper_authors: Lang Qin, Yao Zhang, Hongru Liang, Jun Wang, Zhenglu Yang</li>
<li>for: 这篇论文主要旨在探讨知识选择在知识基据对话系统中的应用，特别是在知识生成前进行精确的选择。</li>
<li>methods: 本研究提出了一种 generator-agnostic 知识选择方法（GATE），通过选择不同知识结构和变量知识需求中的上下文相关知识，以准备之后的回应生成模型（如 ChatGPT）发展更加充分的回应。</li>
<li>results: 实验结果显示 GATE 方法能够实现更高精度的知识选择，并且显示了知识选择 перед生成是一种轻量级 yet 有效的方法，可以帮助 LLMs 发展更加充分的回应。<details>
<summary>Abstract</summary>
Accurate knowledge selection is critical in knowledge-grounded dialogue systems. Towards a closer look at it, we offer a novel perspective to organize existing literature, i.e., knowledge selection coupled with, after, and before generation. We focus on the third under-explored category of study, which can not only select knowledge accurately in advance, but has the advantage to reduce the learning, adjustment, and interpretation burden of subsequent response generation models, especially LLMs. We propose GATE, a generator-agnostic knowledge selection method, to prepare knowledge for subsequent response generation models by selecting context-related knowledge among different knowledge structures and variable knowledge requirements. Experimental results demonstrate the superiority of GATE, and indicate that knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses.
</details>
<details>
<summary>摘要</summary>
精准的知识选择是知识固定对话系统中的关键。为了更加细化它，我们提出了一种新的视角，即知识选择与生成结合。我们强调第三种尚未得到足够关注的领域，即可以不仅在预先选择正确的知识，而且具有降低后续响应生成模型（特别是LLMs）的学习、调整和解释负担的优点。我们提出了GATE，一种生成器独立的知识选择方法，用于为后续响应生成模型选择相关的知识结构和变量知识需求。实验结果表明GATE的优越性，并指示知识选择 перед生成是一种轻量级 yet effective的方式，使LLMs（例如ChatGPT）生成更加有用的响应。
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Neural-Syntax-Acquisition"><a href="#Audio-Visual-Neural-Syntax-Acquisition" class="headerlink" title="Audio-Visual Neural Syntax Acquisition"></a>Audio-Visual Neural Syntax Acquisition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07654">http://arxiv.org/abs/2310.07654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-I Jeff Lai, Freda Shi, Puyuan Peng, Yoon Kim, Kevin Gimpel, Shiyu Chang, Yung-Sung Chuang, Saurabhchand Bhati, David Cox, David Harwath, Yang Zhang, Karen Livescu, James Glass</li>
<li>for: 这个论文旨在研究视觉受支持的语音结构induction。</li>
<li>methods: 论文使用Audio-Visual Neural Syntax Learner（AV-NSL）模型，通过对图像和说话caption的对应进行训练，从而学习语音中的段落结构。</li>
<li>results: 实验表明，AV-NSL可以学习出有意义的段落结构，与自然supervised文本解析器相似，并且可以在英语和德语中进行应用。这些结果扩展了先前的无监督语言学习和基于图像的语法induction研究，并提供了一种将两个领域相连的方法。<details>
<summary>Abstract</summary>
We study phrase structure induction from visually-grounded speech. The core idea is to first segment the speech waveform into sequences of word segments, and subsequently induce phrase structure using the inferred segment-level continuous representations. We present the Audio-Visual Neural Syntax Learner (AV-NSL) that learns phrase structure by listening to audio and looking at images, without ever being exposed to text. By training on paired images and spoken captions, AV-NSL exhibits the capability to infer meaningful phrase structures that are comparable to those derived by naturally-supervised text parsers, for both English and German. Our findings extend prior work in unsupervised language acquisition from speech and grounded grammar induction, and present one approach to bridge the gap between the two topics.
</details>
<details>
<summary>摘要</summary>
我们研究语音结构推导从视觉基于的语音。核心思想是首先将语音波形分割成单词段序列，然后使用推导出的段级连续表示来推导语音结构。我们提出了听视语音神经语法学习器（AV-NSL），它通过听取音频和看到图像，不需要文本supervise，可以学习语音结构。通过对匹配的图像和说话笔记进行训练，AV-NSL可以推导出有意义的语音结构，与自然supervise的文本分析器相似，并且可以扩展到英语和德语两种语言。我们的发现扩展了先前的无监督语言学习从speech和基于图像的语法推导，并提供了一种将这两个领域相互连接的方法。
</details></li>
</ul>
<hr>
<h2 id="LLM4Vis-Explainable-Visualization-Recommendation-using-ChatGPT"><a href="#LLM4Vis-Explainable-Visualization-Recommendation-using-ChatGPT" class="headerlink" title="LLM4Vis: Explainable Visualization Recommendation using ChatGPT"></a>LLM4Vis: Explainable Visualization Recommendation using ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07652">http://arxiv.org/abs/2310.07652</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/demoleiwang/llm4vis">https://github.com/demoleiwang/llm4vis</a></li>
<li>paper_authors: Lei Wang, Songheng Zhang, Yun Wang, Ee-Peng Lim, Yong Wang<br>for:The paper is written for proposing a novel ChatGPT-based prompting approach for visualization recommendation and returning human-like explanations using very few demonstration examples.methods:The approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps. The paper also proposes a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint.results:The paper evaluates the approach on the VizML dataset and shows that LLM4Vis outperforms or performs similarly to supervised learning models like Random Forest, Decision Tree, and MLP in both few-shot and zero-shot settings. The qualitative evaluation also shows the effectiveness of explanations generated by LLM4Vis.<details>
<summary>Abstract</summary>
Data visualization is a powerful tool for exploring and communicating insights in various domains. To automate visualization choice for datasets, a task known as visualization recommendation has been proposed. Various machine-learning-based approaches have been developed for this purpose, but they often require a large corpus of dataset-visualization pairs for training and lack natural explanations for their results. To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples. Our approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps. To obtain demonstration examples with high-quality explanations, we propose a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint. Evaluations on the VizML dataset show that LLM4Vis outperforms or performs similarly to supervised learning models like Random Forest, Decision Tree, and MLP in both few-shot and zero-shot settings. The qualitative evaluation also shows the effectiveness of explanations generated by LLM4Vis. We make our code publicly available at \href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.
</details>
<details>
<summary>摘要</summary>
“数据视觉是一种强大的工具，可以用来探索和传达不同领域的探索结果。为了自动选择视觉，一个称为视觉建议的任务已经被提出。但是，这些机器学习基于的方法通常需要大量的数据集和视觉对amples来训练，并且lack自然的解释。为了解决这个研究差距，我们提出了LLM4Vis，一种基于ChatGPT的新提问方法，用于进行视觉建议并返回人类化的解释。我们的方法包括特征描述、示例选择、解释生成、示例建构和推理步骤。为了获得高质量的解释示例，我们提出了一种新的解释生成bootstrap，可以逐次改进生成的解释，通过考虑之前的生成和模板基于的提示。我们的评估结果表明，LLM4Vis在VizML数据集上与随机森林、决策树和多层感知网络一样或更高的性能，并且在几个零shot和几个few-shot setting中表现出色。质量评估还表明LLM4Vis生成的解释的效果。我们将代码公开在 GitHub 上，请参考 \href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}。”
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Large-Language-Models-at-Evaluating-Instruction-Following"><a href="#Evaluating-Large-Language-Models-at-Evaluating-Instruction-Following" class="headerlink" title="Evaluating Large Language Models at Evaluating Instruction Following"></a>Evaluating Large Language Models at Evaluating Instruction Following</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07641">http://arxiv.org/abs/2310.07641</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/princeton-nlp/llmbar">https://github.com/princeton-nlp/llmbar</a></li>
<li>paper_authors: Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal, Danqi Chen</li>
<li>for: This paper aims to investigate the effectiveness of LLM-based evaluation, particularly in assessing instruction following, and to provide a challenging benchmark for testing the ability of LLM evaluators.</li>
<li>methods: The authors use a manually curated dataset of 419 pairs of outputs, one adhering to instructions and the other diverging but with deceptive qualities, to evaluate the performance of different LLM evaluators. They also present a novel suite of prompting strategies to improve the performance of LLM evaluators.</li>
<li>results: The authors find that different LLM evaluators exhibit distinct performance on their benchmark, LLMBar, and even the highest-scoring ones have room for improvement. They also show that their proposed prompting strategies can close the gap between LLM and human evaluators.<details>
<summary>Abstract</summary>
As research in large language models (LLMs) continues to accelerate, LLM-based evaluation has emerged as a scalable and cost-effective alternative to human evaluations for comparing the ever increasing list of models. This paper investigates the efficacy of these "LLM evaluators", particularly in using them to assess instruction following, a metric that gauges how closely generated text adheres to the given instruction. We introduce a challenging meta-evaluation benchmark, LLMBar, designed to test the ability of an LLM evaluator in discerning instruction-following outputs. The authors manually curated 419 pairs of outputs, one adhering to instructions while the other diverging, yet may possess deceptive qualities that mislead an LLM evaluator, e.g., a more engaging tone. Contrary to existing meta-evaluation, we discover that different evaluators (i.e., combinations of LLMs and prompts) exhibit distinct performance on LLMBar and even the highest-scoring ones have substantial room for improvement. We also present a novel suite of prompting strategies that further close the gap between LLM and human evaluators. With LLMBar, we hope to offer more insight into LLM evaluators and foster future research in developing better instruction-following models.
</details>
<details>
<summary>摘要</summary>
继续推动大语言模型（LLM）研究，LLM-基于评估已成为可扩展和成本效果的选择，用于比较不断增加的模型。这篇论文研究LLM评估器的能力，尤其是用于评估生成文本是否遵循给定的指令。我们提出了一个挑战性的 meta-评估标准， LLMBench，用于测试 LLM 评估器对生成文本是否遵循指令的能力。作者手动精心挑选了419对输出，其中一个遵循指令，另一个偏离指令，但可能具有诱导 LLM 评估器的特质，如更有吸引力的语调。与现有的 meta-评估不同，我们发现不同的评估器（即 LLM 和提示的组合）在 LLMBench 中表现出不同的能力，甚至最高分的评估器还有很大的提高空间。我们还提出了一个新的提示策略集，可以进一步减少 LLM 和人类评估器之间的差距。通过 LLMBench，我们希望能够为 LLM 评估器提供更多的视角，并促进未来关于更好的指令遵循模型的研究。
</details></li>
</ul>
<hr>
<h2 id="The-Past-Present-and-Better-Future-of-Feedback-Learning-in-Large-Language-Models-for-Subjective-Human-Preferences-and-Values"><a href="#The-Past-Present-and-Better-Future-of-Feedback-Learning-in-Large-Language-Models-for-Subjective-Human-Preferences-and-Values" class="headerlink" title="The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values"></a>The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07629">http://arxiv.org/abs/2310.07629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hannah Rose Kirk, Andrew M. Bean, Bertie Vidgen, Paul Röttger, Scott A. Hale</li>
<li>for: 本研究旨在探讨如何有效、有效地收集和利用人类反馈，以优化大型自然语言模型（LLM）的表现。</li>
<li>methods: 本文首先概述过去在语言模型中集成人类反馈的趋势，然后提供现有技术和实践，包括反馈的收集方法、收集者的来源、以及使用反馈的动机和框架。</li>
<li>results: 本文提出了五个未解决的概念和实践问题，以促进未来对feedback学习的进一步发展。<details>
<summary>Abstract</summary>
Human feedback is increasingly used to steer the behaviours of Large Language Models (LLMs). However, it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values. In this paper, we survey existing approaches for learning from human feedback, drawing on 95 papers primarily from the ACL and arXiv repositories.First, we summarise the past, pre-LLM trends for integrating human feedback into language models. Second, we give an overview of present techniques and practices, as well as the motivations for using feedback; conceptual frameworks for defining values and preferences; and how feedback is collected and from whom. Finally, we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges.
</details>
<details>
<summary>摘要</summary>
人类反馈是现在大语言模型（LLM）的行为指导方式的越来越重要。然而，很难确定如何收集和利用反馈，以达到高效、公正和准确的方式，尤其是对于人类的主观喜好和价值观。在这篇论文中，我们对已有的反馈学习方法进行了报告，涵盖了95篇主要来自ACL和arXiv存储库的论文。首先，我们总结了过去对人类反馈的 интеGRATION INTO language models的趋势。其次，我们提供了当前的技术和实践，以及使用反馈的动机，价值和偏好的概念框架，以及反馈从谁收集。最后，我们鼓励更好的反馈学习在LLMs中，提出了五个未解决的概念和实践挑战。
</details></li>
</ul>
<hr>
<h2 id="QACHECK-A-Demonstration-System-for-Question-Guided-Multi-Hop-Fact-Checking"><a href="#QACHECK-A-Demonstration-System-for-Question-Guided-Multi-Hop-Fact-Checking" class="headerlink" title="QACHECK: A Demonstration System for Question-Guided Multi-Hop Fact-Checking"></a>QACHECK: A Demonstration System for Question-Guided Multi-Hop Fact-Checking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07609">http://arxiv.org/abs/2310.07609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xinyuanlu00/qacheck">https://github.com/xinyuanlu00/qacheck</a></li>
<li>paper_authors: Liangming Pan, Xinyuan Lu, Min-Yen Kan, Preslav Nakov</li>
<li>for: 本研究旨在提供一个名为 Question-guided Multi-hop Fact-Checking (QACHECK) 系统，用于确认真实性的调查。</li>
<li>methods: QACHECK 系统使用了一系列的问题来引导模型的推理过程，并且提供了一个完整的报告，详细说明了其推理过程。</li>
<li>results: QACHECK 系统可以帮助用户快速、精确地确认真实性，并且提供了一个透明、可说明的推理过程。<details>
<summary>Abstract</summary>
Fact-checking real-world claims often requires complex, multi-step reasoning due to the absence of direct evidence to support or refute them. However, existing fact-checking systems often lack transparency in their decision-making, making it challenging for users to comprehend their reasoning process. To address this, we propose the Question-guided Multi-hop Fact-Checking (QACHECK) system, which guides the model's reasoning process by asking a series of questions critical for verifying a claim. QACHECK has five key modules: a claim verifier, a question generator, a question-answering module, a QA validator, and a reasoner. Users can input a claim into QACHECK, which then predicts its veracity and provides a comprehensive report detailing its reasoning process, guided by a sequence of (question, answer) pairs. QACHECK also provides the source of evidence supporting each question, fostering a transparent, explainable, and user-friendly fact-checking process. A recorded video of QACHECK is at https://www.youtube.com/watch?v=ju8kxSldM64
</details>
<details>
<summary>摘要</summary>
现实中的真假查核常需要复杂的多步逻辑，因为没有直接的证据支持或驳斥声明。然而，现有的真假查核系统经常缺乏决策过程的透明性，使用户困难理解其思维过程。为解决这问题，我们提议了问题导向多步查核系统（QACHECK），该系统通过提问一系列关键性的问题来引导模型的思维过程。QACHECK包括五个关键模块：声明验证器、问题生成器、问题回答模块、QA验证器和理解器。用户可以将声明输入到QACHECK中，然后系统会预测声明的真实性并提供一份详细的报告，描述了其思维过程，带有一序列（问题、答案）对。QACHECK还提供了每个问题的证据来源，以便 transparent、可解释和用户友好的真假查核过程。有关QACHECK的视频记录在 YouTube 上可以查看，请参阅 <https://www.youtube.com/watch?v=ju8kxSldM64>。
</details></li>
</ul>
<hr>
<h2 id="Survey-on-Factuality-in-Large-Language-Models-Knowledge-Retrieval-and-Domain-Specificity"><a href="#Survey-on-Factuality-in-Large-Language-Models-Knowledge-Retrieval-and-Domain-Specificity" class="headerlink" title="Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity"></a>Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07521">http://arxiv.org/abs/2310.07521</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangcunxiang/llm-factuality-survey">https://github.com/wangcunxiang/llm-factuality-survey</a></li>
<li>paper_authors: Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang, Linyi Yang, Jindong Wang, Xing Xie, Zheng Zhang, Yue Zhang</li>
<li>for: 这项研究旨在解决大自然语言模型（LLM）中的事实问题。随着 LLM 在多个领域应用，其可靠性和准确性的要求变得更加重要。</li>
<li>methods: 本研究首先探讨了 LLM 生成内容与确立的事实之间的差异的后果和挑战。然后，我们分析了 LLM 存储和处理事实的机制，寻找主要导致事实错误的原因。最后，我们评估了评价 LLM 事实准确性的方法，包括关键指标、标准做法和研究。</li>
<li>results: 我们发现， LLM 的事实准确性问题存在多种原因，包括数据质量问题、模型设计问题和生成过程问题。我们还提出了一些改进 LLM 事实准确性的策略，包括针对特定领域的方法。此外，我们发现 standalone LLM 和 Retrieval-Augmented LLM 在不同领域中的特殊挑战和改进方法。<details>
<summary>Abstract</summary>
This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs.
</details>
<details>
<summary>摘要</summary>
We analyze the mechanisms by which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then turns to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We also explore strategies for enhancing LLM factuality, including approaches tailored for specific domains.We focus on two primary LLM configurations: standalone LLMs and Retrieval-Augmented LLMs that utilize external data. We detail their unique challenges and potential enhancements. Our survey provides a structured guide for researchers aiming to fortify the factual reliability of LLMs.
</details></li>
</ul>
<hr>
<h2 id="Cognate-Transformer-for-Automated-Phonological-Reconstruction-and-Cognate-Reflex-Prediction"><a href="#Cognate-Transformer-for-Automated-Phonological-Reconstruction-and-Cognate-Reflex-Prediction" class="headerlink" title="Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction"></a>Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07487">http://arxiv.org/abs/2310.07487</a></li>
<li>repo_url: None</li>
<li>paper_authors: V. S. D. S. Mahesh Akavarapu, Arnab Bhattacharya</li>
<li>for: 这研究的目的是自动化历史语言学中的语音重建问题，通过学习模型以推断祖语中的 proto-word。</li>
<li>methods: 本研究使用了计算机生物学中的一些想法和技术，例如 MSA Transformer 语言模型，并将其应用于自动化语音重建问题。</li>
<li>results: 研究表明，我们的模型在两个相关任务中均能够超越现有的模型，特别是在预训练masked word prediction任务下表现更好。<details>
<summary>Abstract</summary>
Phonological reconstruction is one of the central problems in historical linguistics where a proto-word of an ancestral language is determined from the observed cognate words of daughter languages. Computational approaches to historical linguistics attempt to automate the task by learning models on available linguistic data. Several ideas and techniques drawn from computational biology have been successfully applied in the area of computational historical linguistics. Following these lines, we adapt MSA Transformer, a protein language model, to the problem of automated phonological reconstruction. MSA Transformer trains on multiple sequence alignments as input and is, thus, apt for application on aligned cognate words. We, hence, name our model as Cognate Transformer. We also apply the model on another associated task, namely, cognate reflex prediction, where a reflex word in a daughter language is predicted based on cognate words from other daughter languages. We show that our model outperforms the existing models on both tasks, especially when it is pre-trained on masked word prediction task.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese:Phonological reconstruction is one of the central problems in historical linguistics, where a proto-word of an ancestral language is determined from the observed cognate words of daughter languages. Computational approaches to historical linguistics attempt to automate the task by learning models on available linguistic data. Several ideas and techniques drawn from computational biology have been successfully applied in the area of computational historical linguistics. Following these lines, we adapt MSA Transformer, a protein language model, to the problem of automated phonological reconstruction. MSA Transformer trains on multiple sequence alignments as input and is, thus, apt for application on aligned cognate words. We, hence, name our model as Cognate Transformer. We also apply the model on another associated task, namely, cognate reflex prediction, where a reflex word in a daughter language is predicted based on cognate words from other daughter languages. We show that our model outperforms the existing models on both tasks, especially when it is pre-trained on masked word prediction task.习惯性语言学中的phonological reconstruction是一个中心问题，即推算祖语的proto-word，根据观察的儿语词的观察。 computation approaches to historical linguistics尝试通过学习模型，将这些资料自动化。 several ideas and techniques drawn from computational biology have been successfully applied in the area of computational historical linguistics。 following these lines, we adapt MSA Transformer，a protein language model，to the problem of automated phonological reconstruction。 MSA Transformer trains on multiple sequence alignments as input and is, thus, apt for application on aligned cognate words。 we, hence, name our model as Cognate Transformer。 we also apply the model on another associated task，namely，cognate reflex prediction，where a reflex word in a daughter language is predicted based on cognate words from other daughter languages。 we show that our model outperforms the existing models on both tasks，especially when it is pre-trained on masked word prediction task。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is also widely used, especially in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Adapting-the-adapters-for-code-switching-in-multilingual-ASR"><a href="#Adapting-the-adapters-for-code-switching-in-multilingual-ASR" class="headerlink" title="Adapting the adapters for code-switching in multilingual ASR"></a>Adapting the adapters for code-switching in multilingual ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07423">http://arxiv.org/abs/2310.07423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/atharva7k/mms-code-switching">https://github.com/atharva7k/mms-code-switching</a></li>
<li>paper_authors: Atharva Kulkarni, Ajinkya Kulkarni, Miguel Couceiro, Hanan Aldarmaki</li>
<li>for: 这个论文旨在提高自动语音识别（ASR）在多种低资源语言上的扩展性。</li>
<li>methods: 该论文提出了一种在混合语言speech中使用多语言模型的方法，通过在网络中的语言适应器之间协调信息来提高模型的性能。另外，该论文还提出了一种基于序列隐藏Markov chain的方法，来模型混合语言的流程。</li>
<li>results: 该论文的实验结果表明，在使用该方法进行微调后，模型在混合语言speech中的性能得到了明显提高，减少了误分类率不 menos于10%。<details>
<summary>Abstract</summary>
Recently, large pre-trained multilingual speech models have shown potential in scaling Automatic Speech Recognition (ASR) to many low-resource languages. Some of these models employ language adapters in their formulation, which helps to improve monolingual performance and avoids some of the drawbacks of multi-lingual modeling on resource-rich languages. However, this formulation restricts the usability of these models on code-switched speech, where two languages are mixed together in the same utterance. In this work, we propose ways to effectively fine-tune such models on code-switched speech, by assimilating information from both language adapters at each language adaptation point in the network. We also model code-switching as a sequence of latent binary sequences that can be used to guide the flow of information from each language adapter at the frame level. The proposed approaches are evaluated on three code-switched datasets encompassing Arabic, Mandarin, and Hindi languages paired with English, showing consistent improvements in code-switching performance with at least 10\% absolute reduction in CER across all test sets.
</details>
<details>
<summary>摘要</summary>
最近，大型预训练多语言speech模型已经表现出在多语言自动听说识别（ASR）中扩大应用前景。一些这些模型使用语言适配器在其 формуля中，可以提高单语言性能并避免在资源充沛语言上多语言模型化的一些缺点。然而，这种形式限制了这些模型在混合语言speech中的可用性， где两种语言在同一句中混合在一起。在这种工作中，我们提出了有效地微调这些模型在混合语言speech中的方法，通过在每个语言适配点处吸收两种语言适配器中的信息。我们还模型了混合语言为一个序列的潜在二进制序列，可以在帧级别引导来自每种语言适配器的信息流。我们的方法被评估在三个混合语言dataset上，包括阿拉伯语、普通话和印地语与英语的混合，显示了一致性的改进，减少了至少10%的CER。
</details></li>
</ul>
<hr>
<h2 id="Linguistic-laws-in-biology"><a href="#Linguistic-laws-in-biology" class="headerlink" title="Linguistic laws in biology"></a>Linguistic laws in biology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07387">http://arxiv.org/abs/2310.07387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stuart Semple, Ramon Ferrer-i-Cancho, Morgan L. Gustison</li>
<li>for:  investigate the prevalence of linguistic laws in biology</li>
<li>methods:  adopt a new conceptual framework that integrates distinct levels of analysis, from description to prediction to theory building</li>
<li>results:  provide critical new insights into the fundamental rules of organisation underpinning natural systems, unifying linguistic laws and core theory in biology<details>
<summary>Abstract</summary>
Linguistic laws, the common statistical patterns of human language, have been investigated by quantitative linguists for nearly a century. Recently, biologists from a range of disciplines have started to explore the prevalence of these laws beyond language, finding patterns consistent with linguistic laws across multiple levels of biological organisation, from molecular (genomes, genes, and proteins) to organismal (animal behaviour) to ecological (populations and ecosystems). We propose a new conceptual framework for the study of linguistic laws in biology, comprising and integrating distinct levels of analysis, from description to prediction to theory building. Adopting this framework will provide critical new insights into the fundamental rules of organisation underpinning natural systems, unifying linguistic laws and core theory in biology.
</details>
<details>
<summary>摘要</summary>
生物学中的语言法律，也就是人类语言中的统计趋势，已经在量化语言学家的研究中进行了近百年的探索。而最近，生物学家从多个领域来的研究者开始探索这些法律在生物体系中的普遍性，从分子水平（基因、蛋白质）到生物水平（动物行为）到生态水平（人口和生态系统）。我们提出了一个新的概念框架，用于语言法律在生物学中的研究，包括描述、预测和理论建构三个水平。采用这个框架，将提供新的理解到自然系统的基本规则，并将语言法律和生物学核心理论相结合。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Effect-of-Language-Models-in-Sequence-Discriminative-Training-for-Neural-Transducers"><a href="#Investigating-the-Effect-of-Language-Models-in-Sequence-Discriminative-Training-for-Neural-Transducers" class="headerlink" title="Investigating the Effect of Language Models in Sequence Discriminative Training for Neural Transducers"></a>Investigating the Effect of Language Models in Sequence Discriminative Training for Neural Transducers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07345">http://arxiv.org/abs/2310.07345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Yang, Wei Zhou, Ralf Schlüter, Hermann Ney</li>
<li>for: 这个研究是 investigate the effect of language models (LMs) with different context lengths and label units (phoneme vs. word) used in sequence discriminative training for phoneme-based neural transducers.</li>
<li>methods: 这个研究使用了 lattice-free 和 N-best-list 方法，并提出了一种方法来 Approximate the context history to employ LMs with full-context dependency.</li>
<li>results: 实验结果表明，使用 word-level LM 在训练中表现比 phoneme-level LM 更好，并且Context size of the LM used for probability computation has a limited effect on performance.<details>
<summary>Abstract</summary>
In this work, we investigate the effect of language models (LMs) with different context lengths and label units (phoneme vs. word) used in sequence discriminative training for phoneme-based neural transducers. Both lattice-free and N-best-list approaches are examined. For lattice-free methods with phoneme-level LMs, we propose a method to approximate the context history to employ LMs with full-context dependency. This approximation can be extended to arbitrary context length and enables the usage of word-level LMs in lattice-free methods. Moreover, a systematic comparison is conducted across lattice-free and N-best-list-based methods. Experimental results on Librispeech show that using the word-level LM in training outperforms the phoneme-level LM. Besides, we find that the context size of the LM used for probability computation has a limited effect on performance. Moreover, our results reveal the pivotal importance of the hypothesis space quality in sequence discriminative training.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们研究了不同语言模型（LM）的上下文长度和标签单元（音素 vs. 词）在序列推理训练中的效果，包括无栅栈和N-best-list方法。对于无栅栈方法，我们提出了一种方法来 aproximate上下文历史，以便使用全上下文依赖性的LM。这种 aproximation可以扩展到任意上下文长度，并允许使用词级LM在无栅栈方法中。此外，我们进行了系统性的比较，并发现使用词级LM在训练中表现更好于音素级LM。此外，我们发现上下文大小对LM在概率计算中的影响很有限，同时发现推理训练中假设空间质量的重要性。Note that Simplified Chinese is the official written form of Chinese used in mainland China, and it is different from Traditional Chinese, which is used in Taiwan and other countries.
</details></li>
</ul>
<hr>
<h2 id="How-Do-Large-Language-Models-Capture-the-Ever-changing-World-Knowledge-A-Review-of-Recent-Advances"><a href="#How-Do-Large-Language-Models-Capture-the-Ever-changing-World-Knowledge-A-Review-of-Recent-Advances" class="headerlink" title="How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances"></a>How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07343">http://arxiv.org/abs/2310.07343</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hyintell/awesome-refreshing-llms">https://github.com/hyintell/awesome-refreshing-llms</a></li>
<li>paper_authors: Zihan Zhang, Meng Fang, Ling Chen, Mohammad-Reza Namazi-Rad, Jun Wang</li>
<li>for: 这篇论文主要是为了探讨如何使大语言模型（LLMs）能够适应世界知识的变化，而不需要从零 retraining。</li>
<li>methods: 该论文提出了一系列的方法来保持 LLMS 的更新状态，包括各种批处理技术、迁移学习技术以及知识 graph 等方法。</li>
<li>results: 该论文对这些方法进行了系统的比较和分析，并评估了它们的效果。同时，它还提出了未来研究的方向，以便维护 LLMS 的更新状态。<details>
<summary>Abstract</summary>
Although large language models (LLMs) are impressive in solving various tasks, they can quickly be outdated after deployment. Maintaining their up-to-date status is a pressing concern in the current era. This paper provides a comprehensive review of recent advances in aligning LLMs with the ever-changing world knowledge without re-training from scratch. We categorize research works systemically and provide in-depth comparisons and discussion. We also discuss existing challenges and highlight future directions to facilitate research in this field. We release the paper list at https://github.com/hyintell/awesome-refreshing-llms
</details>
<details>
<summary>摘要</summary>
尽管大型语言模型（LLMs）在各种任务上表现印象深刻，但它们很快就会变得过时。维护其最新状态是当前时代的一项急需问题。本文提供了对最近进展在将 LLMs 与不断变化的世界知识相匹配的全面回顾。我们系统地分类研究工作，提供了深入的比较和讨论。我们还讨论了现有的挑战和未来的发展方向，以便促进这一领域的研究。我们在 GitHub 上发布了详细的文献列表，请参考 <https://github.com/hyintell/awesome-refreshing-llms>。
</details></li>
</ul>
<hr>
<h2 id="SNOiC-Soft-Labeling-and-Noisy-Mixup-based-Open-Intent-Classification-Model"><a href="#SNOiC-Soft-Labeling-and-Noisy-Mixup-based-Open-Intent-Classification-Model" class="headerlink" title="SNOiC: Soft Labeling and Noisy Mixup based Open Intent Classification Model"></a>SNOiC: Soft Labeling and Noisy Mixup based Open Intent Classification Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07306">http://arxiv.org/abs/2310.07306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditi Kanwar, Aditi Seetha, Satyendra Singh Chouhan, Rajdeep Niyogi</li>
<li>for: 本研究开发了一种基于软标签和噪音混合的开放意图分类模型（SNOiC），以解决现有模型受到过拟合和生成偏见的限制。</li>
<li>methods: 该模型结合软标签和噪音混合策略，以减少偏见和生成开放意图类 pseudo-数据。</li>
<li>results: 实验结果表明，SNOiC 模型在四个基准数据集上实现最小和最大的表现为 68.72% 和 94.71%，分别，在认知开放意图类的任务中表现出了显著的改善（相比之前的模型，最小改善为 0.93%，最大改善为 12.76%）。<details>
<summary>Abstract</summary>
This paper presents a Soft Labeling and Noisy Mixup-based open intent classification model (SNOiC). Most of the previous works have used threshold-based methods to identify open intents, which are prone to overfitting and may produce biased predictions. Additionally, the need for more available data for an open intent class presents another limitation for these existing models. SNOiC combines Soft Labeling and Noisy Mixup strategies to reduce the biasing and generate pseudo-data for open intent class. The experimental results on four benchmark datasets show that the SNOiC model achieves a minimum and maximum performance of 68.72\% and 94.71\%, respectively, in identifying open intents. Moreover, compared to state-of-the-art models, the SNOiC model improves the performance of identifying open intents by 0.93\% (minimum) and 12.76\% (maximum). The model's efficacy is further established by analyzing various parameters used in the proposed model. An ablation study is also conducted, which involves creating three model variants to validate the effectiveness of the SNOiC model.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Parrot-Enhancing-Multi-Turn-Chat-Models-by-Learning-to-Ask-Questions"><a href="#Parrot-Enhancing-Multi-Turn-Chat-Models-by-Learning-to-Ask-Questions" class="headerlink" title="Parrot: Enhancing Multi-Turn Chat Models by Learning to Ask Questions"></a>Parrot: Enhancing Multi-Turn Chat Models by Learning to Ask Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07301">http://arxiv.org/abs/2310.07301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuchong Sun, Che Liu, Jinwen Huang, Ruihua Song, Fuzheng Zhang, Di Zhang, Zhongyuan Wang, Kun Gai</li>
<li>for: The paper aims to improve the effectiveness of chat models in multi-turn conversations by addressing the lack of high-quality multi-turn instruction-tuning data.</li>
<li>methods: The authors introduce Parrot, a highly scalable solution that automatically generates high-quality instruction-tuning data, which are then used to enhance the effectiveness of chat models in multi-turn conversations.</li>
<li>results: The authors demonstrate that the dialogues gathered from Parrot-Ask markedly outperform existing multi-turn instruction-following datasets in critical metrics, and Parrot-Chat achieves strong performance against other 13B open-source models across a range of instruction-following benchmarks, particularly excelling in evaluations of multi-turn capabilities.Here’s the simplified Chinese version of the three key points:</li>
<li>for: 提高 chat 模型在多回合对话中的效果，解决社区存在的高质量多回合指导数据的缺乏问题。</li>
<li>methods: 引入 Parrot，一种可扩展的解决方案，通过自动生成高质量指导数据来提高 chat 模型在多回合对话中的效果。</li>
<li>results: Parrot-Ask 生成的对话集表现出色，覆盖了多个主题，数量丰富，与人类对话更加相似，并且 Parrot-Chat 在多个指导数据上达到了强劲的表现。<details>
<summary>Abstract</summary>
Impressive progress has been made on chat models based on Large Language Models (LLMs) recently; however, there is a noticeable lag in multi-turn conversations between open-source chat models (e.g., Alpaca and Vicuna) and the leading chat models (e.g., ChatGPT and GPT-4). Through a series of analyses, we attribute the lag to the lack of enough high-quality multi-turn instruction-tuning data. The available instruction-tuning data for the community are either single-turn conversations or multi-turn ones with certain issues, such as non-human-like instructions, less detailed responses, or rare topic shifts. In this paper, we address these challenges by introducing Parrot, a highly scalable solution designed to automatically generate high-quality instruction-tuning data, which are then used to enhance the effectiveness of chat models in multi-turn conversations. Specifically, we start by training the Parrot-Ask model, which is designed to emulate real users in generating instructions. We then utilize Parrot-Ask to engage in multi-turn conversations with ChatGPT across a diverse range of topics, resulting in a collection of 40K high-quality multi-turn dialogues (Parrot-40K). These data are subsequently employed to train a chat model that we have named Parrot-Chat. We demonstrate that the dialogues gathered from Parrot-Ask markedly outperform existing multi-turn instruction-following datasets in critical metrics, including topic diversity, number of turns, and resemblance to human conversation. With only 40K training examples, Parrot-Chat achieves strong performance against other 13B open-source models across a range of instruction-following benchmarks, and particularly excels in evaluations of multi-turn capabilities. We make all codes, datasets, and two versions of the Parrot-Ask model based on LLaMA2-13B and KuaiYii-13B available at https://github.com/kwai/KwaiYii/Parrot.
</details>
<details>
<summary>摘要</summary>
很多进步已经在基于大语言模型（LLM）的 chat 模型方面得到了，但是在多回话对话中，开源 chat 模型（如 Alpaca 和 Vicuna）与领先的 chat 模型（如 ChatGPT 和 GPT-4）之间存在明显的延迟。经过一系列分析，我们归结这种延迟于社区可用的多回话指令调整数据不充足。现有的指令调整数据包括单回话对话或有问题的多回话对话，如非人类化的指令、精简的回答或罕见的主题转换。在这篇论文中，我们解决这些挑战 by introducing Parrot，一种可扩展的解决方案，用于自动生成高质量的指令调整数据，然后用这些数据来提高 chat 模型在多回话对话中的效果。 Specifically，我们首先训练 Parrot-Ask 模型，该模型是用来模拟真实用户生成指令的。然后，我们使用 Parrot-Ask 与 ChatGPT 进行多回话对话，从多种主题中收集了40000个高质量多回话对话（Parrot-40K）。这些数据被用来训练一个名为 Parrot-Chat 的 chat 模型。我们示示了 Parrot-Ask 生成的对话覆盖率高于现有的多回话指令遵从数据集，包括话题多样性、回话数量和人类对话的相似性。尽管只有40000个训练示例，Parrot-Chat 在多种指令遵从 benchmar ks 中表现出色，特别是在多回话评价中表现出色。我们在 GitHub 上提供了所有代码、数据集和两个基于 LLaMA2-13B 和 KuaiYii-13B 的 Parrot-Ask 模型，请参考 https://github.com/kwai/KwaiYii/Parrot。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Factuality-A-Comprehensive-Evaluation-of-Large-Language-Models-as-Knowledge-Generators"><a href="#Beyond-Factuality-A-Comprehensive-Evaluation-of-Large-Language-Models-as-Knowledge-Generators" class="headerlink" title="Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators"></a>Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07289">http://arxiv.org/abs/2310.07289</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chanliang/conner">https://github.com/chanliang/conner</a></li>
<li>paper_authors: Liang Chen, Yang Deng, Yatao Bian, Zeyu Qin, Bingzhe Wu, Tat-Seng Chua, Kam-Fai Wong</li>
<li>For: The paper is written to evaluate the factuality and potential implications of using large language models (LLMs) to generate world knowledge, and to introduce a comprehensive framework (CONNER) for systematically and automatically evaluating generated knowledge from six important perspectives.* Methods: The paper uses three different types of LLMs to generate knowledge on two widely studied knowledge-intensive tasks, open-domain question answering and knowledge-grounded dialogue. The paper also employs an extensive empirical analysis to evaluate the generated knowledge from the six perspectives.* Results: The paper finds that the factuality of generated knowledge does not significantly hinder downstream tasks, and that relevance and coherence are more important than small factual mistakes. The paper also shows how to use CONNER to improve knowledge-intensive tasks by designing two strategies: Prompt Engineering and Knowledge Selection.<details>
<summary>Abstract</summary>
Large language models (LLMs) outperform information retrieval techniques for downstream knowledge-intensive tasks when being prompted to generate world knowledge. However, community concerns abound regarding the factuality and potential implications of using this uncensored knowledge. In light of this, we introduce CONNER, a COmpreheNsive kNowledge Evaluation fRamework, designed to systematically and automatically evaluate generated knowledge from six important perspectives -- Factuality, Relevance, Coherence, Informativeness, Helpfulness and Validity. We conduct an extensive empirical analysis of the generated knowledge from three different types of LLMs on two widely studied knowledge-intensive tasks, i.e., open-domain question answering and knowledge-grounded dialogue. Surprisingly, our study reveals that the factuality of generated knowledge, even if lower, does not significantly hinder downstream tasks. Instead, the relevance and coherence of the outputs are more important than small factual mistakes. Further, we show how to use CONNER to improve knowledge-intensive tasks by designing two strategies: Prompt Engineering and Knowledge Selection. Our evaluation code and LLM-generated knowledge with human annotations will be released to facilitate future research.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在下游知识密集任务中表现更高，但社区对使用这些未经检查的知识表示关切。为了解决这问题，我们介绍了CONNER，一个全面的知识评估框架，可以系统地和自动地评估由六个重要角度评估生成的知识---事实性、相关性、一致性、启示性、帮助性和有效性。我们进行了对三种不同的LLM生成知识的广泛实验分析，在两个广泛研究的知识密集任务上，即开放领域问答和知识基础对话。 surprisingly，我们的研究发现，生成知识的事实性，即使低，并不会对下游任务产生重要阻碍。相反，输出的相关性和一致性更加重要于小错误。此外，我们还示出了如何使用CONNER来提高知识密集任务的性能，通过设计两种策略：提示工程和知识选择。我们的评估代码和LLM生成的知识以及人工注释将被发布，以便未来研究。
</details></li>
</ul>
<hr>
<h2 id="Typing-to-Listen-at-the-Cocktail-Party-Text-Guided-Target-Speaker-Extraction"><a href="#Typing-to-Listen-at-the-Cocktail-Party-Text-Guided-Target-Speaker-Extraction" class="headerlink" title="Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction"></a>Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07284">http://arxiv.org/abs/2310.07284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoxiangsnr/llm-tse">https://github.com/haoxiangsnr/llm-tse</a></li>
<li>paper_authors: Xiang Hao, Jibin Wu, Jianwei Yu, Chenglin Xu, Kay Chen Tan</li>
<li>for: 这个研究的目的是为了复制人类在听力环境中选择性地听注意力的能力，即cocktail party问题。</li>
<li>methods: 这个研究使用了目标说话者提取模型（TSE），并利用了大型自然语言模型（LLM）来提取用户输入文本中的有用语义特征。</li>
<li>results: 研究结果表明，只使用文本基于的cue可以获得竞争力强的表现，文本作为任务选择器的效果，并且可以与预先注册的cue结合使用，以实现新的州OF-THE-ART表现。<details>
<summary>Abstract</summary>
Humans possess an extraordinary ability to selectively focus on the sound source of interest amidst complex acoustic environments, commonly referred to as cocktail party scenarios. In an attempt to replicate this remarkable auditory attention capability in machines, target speaker extraction (TSE) models have been developed. These models leverage the pre-registered cues of the target speaker to extract the sound source of interest. However, the effectiveness of these models is hindered in real-world scenarios due to the unreliable or even absence of pre-registered cues. To address this limitation, this study investigates the integration of natural language description to enhance the feasibility, controllability, and performance of existing TSE models. Specifically, we propose a model named LLM-TSE, wherein a large language model (LLM) to extract useful semantic cues from the user's typed text input. These cues can serve as independent extraction cues, task selectors to control the TSE process, or complement the pre-registered cues. Our experimental results demonstrate competitive performance when only text-based cues are presented, the effectiveness of using input text as a task selector, and a new state-of-the-art when combining text-based cues with pre-registered cues. To our knowledge, this is the first study to successfully incorporate LLMs to guide target speaker extraction, which can be a cornerstone for cocktail party problem research.
</details>
<details>
<summary>摘要</summary>
人类具有一种杰出的听音选择能力，能够在复杂的听音环境中听到 interessante 的声音来源，这种情况通常被称为“cocktail party”问题。为了复制人类的听音注意力能力在机器中，目标说话人抽取（TSE）模型已经开发出来。这些模型利用目标说话人的预先注册的cue来提取听音来源。然而，现实世界中这些模型的效果受限因为预先注册的cue的可靠性和缺失。为解决这个限制，本研究提出了通过自然语言描述来增强现有TSE模型的可能性、可控性和性能。具体来说，我们提出了一种名为LLM-TSE的模型，其中使用大型语言模型（LLM）来提取用户输入文本中的有用semantic cue。这些cue可以作为独立提取cue，任务选择器来控制TSE过程，或者补充预先注册的cue。我们的实验结果表明，只要提供文本基于的cue，就可以达到竞争性的性能；使用文本作为任务选择器的效果，以及将文本基于的cue与预先注册的cue相结合时的新州OF-THE-ART性能。我们知道，这是首次成功地将LLMintegrated into TSE模型，这可能成为cocktail party问题研究的新起点。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-expressivity-transfer-in-textless-speech-to-speech-translation"><a href="#Enhancing-expressivity-transfer-in-textless-speech-to-speech-translation" class="headerlink" title="Enhancing expressivity transfer in textless speech-to-speech translation"></a>Enhancing expressivity transfer in textless speech-to-speech translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07279">http://arxiv.org/abs/2310.07279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jarod Duret, Benjamin O’Brien, Yannick Estève, Titouan Parcollet</li>
<li>for: 这项研究旨在解决现有语言自动识别系统中的表达精准性问题，以提高跨语言交流的效果。</li>
<li>methods: 该研究提出了一种新的方法，基于多语言情感嵌入来捕捉语言无关信息，并用于预测目标语言中语音单元的抽象和持续时间。</li>
<li>results: 对于法语到英语翻译任务，对比现有状态天下系统，该方法能够更好地传递表达性。<details>
<summary>Abstract</summary>
Textless speech-to-speech translation systems are rapidly advancing, thanks to the integration of self-supervised learning techniques. However, existing state-of-the-art systems fall short when it comes to capturing and transferring expressivity accurately across different languages. Expressivity plays a vital role in conveying emotions, nuances, and cultural subtleties, thereby enhancing communication across diverse languages. To address this issue this study presents a novel method that operates at the discrete speech unit level and leverages multilingual emotion embeddings to capture language-agnostic information. Specifically, we demonstrate how these embeddings can be used to effectively predict the pitch and duration of speech units in the target language. Through objective and subjective experiments conducted on a French-to-English translation task, our findings highlight the superior expressivity transfer achieved by our approach compared to current state-of-the-art systems.
</details>
<details>
<summary>摘要</summary>
文本 speech-to-speech 翻译系统在快速发展，各种自我超级学习技术的整合帮助了这一点。然而，现有的状态之一的系统在准确传递表达性方面缺乏表现。表达性在传递情感、细节和文化亚文化之间的差异中扮演着关键的角色，从而提高了不同语言之间的交流。为解决这个问题，本研究提出了一种新的方法，它在不同语言的语音单位级别操作，并使用多语言情感嵌入来捕捉语言无关的信息。我们通过对法语到英语翻译任务进行对象和主观实验，发现我们的方法可以更好地传递表达性，比现有的状态之一的系统更高效。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Landscape-of-Large-Language-Models-In-Medical-Question-Answering-Observations-and-Open-Questions"><a href="#Exploring-the-Landscape-of-Large-Language-Models-In-Medical-Question-Answering-Observations-and-Open-Questions" class="headerlink" title="Exploring the Landscape of Large Language Models In Medical Question Answering: Observations and Open Questions"></a>Exploring the Landscape of Large Language Models In Medical Question Answering: Observations and Open Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07225">http://arxiv.org/abs/2310.07225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karolina Korgul, Andrew M. Bean, Felix Krones, Robert McCraith, Adam Mahdi</li>
<li>for: 本研究旨在了解大型自然语言模型（LLMs）在医疗问答中的表现，以支持医疗工作者。</li>
<li>methods: 本研究使用了多种流行的LLMs，评估其对医疗问题的知识。</li>
<li>results: 研究发现了这些LLMs在医疗问题中的知识有限，存在一些共同特征和问题。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown promise in medical question answering by achieving passing scores in standardised exams and have been suggested as tools for supporting healthcare workers. Deploying LLMs into such a high-risk context requires a clear understanding of the limitations of these models. With the rapid development and release of new LLMs, it is especially valuable to identify patterns which exist across models and may, therefore, continue to appear in newer versions. In this paper, we evaluate a wide range of popular LLMs on their knowledge of medical questions in order to better understand their properties as a group. From this comparison, we provide preliminary observations and raise open questions for further research.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在医疗问答中展现出了承认的潜力，并被建议作为医疗工作者的工具。将LLM部署到高风险的Context中需要清晰地理解这些模型的限制。随着新的LLM的快速开发和发布，可以通过识别模型之间的相似性 Patterns 来了解这些模型的性质。在这篇论文中，我们评估了一些流行的LLM在医疗问题上的知识，以更好地理解它们的性质。从这个比较中，我们提出了初步的观察和进一步的研究问题。
</details></li>
</ul>
<hr>
<h2 id="PHALM-Building-a-Knowledge-Graph-from-Scratch-by-Prompting-Humans-and-a-Language-Model"><a href="#PHALM-Building-a-Knowledge-Graph-from-Scratch-by-Prompting-Humans-and-a-Language-Model" class="headerlink" title="PHALM: Building a Knowledge Graph from Scratch by Prompting Humans and a Language Model"></a>PHALM: Building a Knowledge Graph from Scratch by Prompting Humans and a Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07170">http://arxiv.org/abs/2310.07170</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nlp-waseda/comet-atomic-ja">https://github.com/nlp-waseda/comet-atomic-ja</a></li>
<li>paper_authors: Tatsuya Ide, Eiki Murata, Daisuke Kawahara, Takato Yamazaki, Shengzhe Li, Kenta Shinzato, Toshinori Sato</li>
<li>for: 这篇论文是为了提出一种从头开始构建知识图谱的方法，以及使用这个知识图谱来训练日语常识生成模型。</li>
<li>methods: 这篇论文使用了人群和大语言模型（LLM）的唤起来构建知识图谱，并使用这个知识图谱来训练日语常识生成模型。</li>
<li>results: 实验结果表明， constructed 知识图谱和训练后的模型可以生成有效的常识推理。 另外，对于人群和 LLM 的唤起来的 diferencia 也被报告。 代码、数据和模型可以在github.com&#x2F;nlp-waseda&#x2F;comet-atomic-ja 上获取。<details>
<summary>Abstract</summary>
Despite the remarkable progress in natural language understanding with pretrained Transformers, neural language models often do not handle commonsense knowledge well. Toward commonsense-aware models, there have been attempts to obtain knowledge, ranging from automatic acquisition to crowdsourcing. However, it is difficult to obtain a high-quality knowledge base at a low cost, especially from scratch. In this paper, we propose PHALM, a method of building a knowledge graph from scratch, by prompting both crowdworkers and a large language model (LLM). We used this method to build a Japanese event knowledge graph and trained Japanese commonsense generation models. Experimental results revealed the acceptability of the built graph and inferences generated by the trained models. We also report the difference in prompting humans and an LLM. Our code, data, and models are available at github.com/nlp-waseda/comet-atomic-ja.
</details>
<details>
<summary>摘要</summary>
尽管已经有很大进步在自然语言理解方面，神经网络语言模型经常不好地处理常识知识。为建立常识意识模型，有人尝试了从自动获取到招募社会人员的方法。然而，获取高质量的知识基础，特别是从头开始，很难且成本高。在这篇论文中，我们提出了PHALM方法，可以从头开始建立知识图，通过招募社会人员和大语言模型（LLM）的提示。我们使用这种方法建立了日本事件知识图，并训练了日本常识生成模型。实验结果表明建立的图和训练的模型生成的推理都是可接受的。我们还报告了人工和LLM的提示之间的差异。我们的代码、数据和模型可以在github.com/nlp-waseda/comet-atomic-ja上找到。
</details></li>
</ul>
<hr>
<h2 id="Psychoacoustic-Challenges-Of-Speech-Enhancement-On-VoIP-Platforms"><a href="#Psychoacoustic-Challenges-Of-Speech-Enhancement-On-VoIP-Platforms" class="headerlink" title="Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms"></a>Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07161">http://arxiv.org/abs/2310.07161</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Konan, Ojas Bhargave, Shikhar Agnihotri, Shuo Han, Yunyang Zeng, Ankit Shah, Bhiksha Raj</li>
<li>for: 本研究探讨了VoIP（voice over internet protocol）通信中的听音变换问题，强调了 propietary sender-side denoising 的影响。</li>
<li>methods: 该研究使用了 Deep Noise Suppression（DNS）2020 数据集，并采用了 econometric 工具 Oaxaca decomposition 分析听音-phonetic 扰动的变化。</li>
<li>results: 研究发现，VoIP 系统中的听音变换会导致对话质量下降，并且不同的接收器接口和听音设置会导致不同的扰动效果。<details>
<summary>Abstract</summary>
Within the ambit of VoIP (Voice over Internet Protocol) telecommunications, the complexities introduced by acoustic transformations merit rigorous analysis. This research, rooted in the exploration of proprietary sender-side denoising effects, meticulously evaluates platforms such as Google Meets and Zoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset, ensuring a structured examination tailored to various denoising settings and receiver interfaces. A methodological novelty is introduced via the Oaxaca decomposition, traditionally an econometric tool, repurposed herein to analyze acoustic-phonetic perturbations within VoIP systems. To further ground the implications of these transformations, psychoacoustic metrics, specifically PESQ and STOI, were harnessed to furnish a comprehensive understanding of speech alterations. Cumulatively, the insights garnered underscore the intricate landscape of VoIP-influenced acoustic dynamics. In addition to the primary findings, a multitude of metrics are reported, extending the research purview. Moreover, out-of-domain benchmarking for both time and time-frequency domain speech enhancement models is included, thereby enhancing the depth and applicability of this inquiry.
</details>
<details>
<summary>摘要</summary>
在VoIP（voice over internet protocol）通信中，音响变换引入了复杂性，需要仔细分析。这项研究，基于专有发送器侧干扰效果的探索，仔细评估了Google Meets和Zoom等平台。研究利用了2020年 Deep Noise Suppression（DNS）数据集，确保结构化的审查，适应不同的干扰设置和接收器界面。本研究 introduce了一种方法创新，即使用Oaxaca分解，原来是经济统计工具，现在在VoIP系统中被重新应用来分析音响语音干扰。为更深入理解这些变换的影响，研究使用了心理学量化指标，包括PESQ和STOI，以提供全面的语音变化认知。总的来说，获得的发现强调了VoIP系统中音响动态的复杂领域。此外，研究还报告了多种指标，扩大了研究范围。此外，本研究还包括了出界预测，以增强对时间和时间频率频谱speech增强模型的应用性。
</details></li>
</ul>
<hr>
<h2 id="“A-Tale-of-Two-Movements”-Identifying-and-Comparing-Perspectives-in-BlackLivesMatter-and-BlueLivesMatter-Movements-related-Tweets-using-Weakly-Supervised-Graph-based-Structured-Prediction"><a href="#“A-Tale-of-Two-Movements”-Identifying-and-Comparing-Perspectives-in-BlackLivesMatter-and-BlueLivesMatter-Movements-related-Tweets-using-Weakly-Supervised-Graph-based-Structured-Prediction" class="headerlink" title="“A Tale of Two Movements”: Identifying and Comparing Perspectives in #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction"></a>“A Tale of Two Movements”: Identifying and Comparing Perspectives in #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07155">http://arxiv.org/abs/2310.07155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Roy, Dan Goldwasser</li>
<li>for: 本研究旨在 automaticaly 理解 #BlackLivesMatter 运动related tweets 中的 perspective 和 voice。</li>
<li>methods: 我们提出了一种weakly supervised graph-based方法，通过将文本转化为结构化元素 graph，并利用作者社交网络，进行 structured prediction，以确定 perspective。</li>
<li>results: 我们的模型在Quantitative 和 Qualitative 分析中表现出色，在人工标注测试集上超过多任务基线，成功地 caracterize #BLM 运动中支持和反对 perspective。<details>
<summary>Abstract</summary>
Social media has become a major driver of social change, by facilitating the formation of online social movements. Automatically understanding the perspectives driving the movement and the voices opposing it, is a challenging task as annotated data is difficult to obtain. We propose a weakly supervised graph-based approach that explicitly models perspectives in #BackLivesMatter-related tweets. Our proposed approach utilizes a social-linguistic representation of the data. We convert the text to a graph by breaking it into structured elements and connect it with the social network of authors, then structured prediction is done over the elements for identifying perspectives. Our approach uses a small seed set of labeled examples. We experiment with large language models for generating artificial training examples, compare them to manual annotation, and find that it achieves comparable performance. We perform quantitative and qualitative analyses using a human-annotated test set. Our model outperforms multitask baselines by a large margin, successfully characterizing the perspectives supporting and opposing #BLM.
</details>
<details>
<summary>摘要</summary>
社交媒体已成为社会变革的主要驱动力，通过促成在线社会运动的形成。自动理解运动中的看法和反对看法是一项具有挑战性的任务，因为精心标注数据很难以获得。我们提出了一种弱监督图Structured prediction的方法，其中明确表达了 #BlackLivesMatter 相关的微博中的看法。我们的提议方法首先将文本转换为图形，然后使用作者社交网络连接其中的结构化元素，并通过结构预测来识别看法。我们的方法使用小量精心标注示例。我们使用大型自然语言模型生成人工训练示例，并与手动标注进行比较，发现它们具有相似性。我们对人类标注测试集进行量化和质量分析，发现我们的模型在 #BLM 相关的问题上大幅超过多任务基线，成功地描述了支持和反对 #BLM 的看法。
</details></li>
</ul>
<hr>
<h2 id="QFT-Quantized-Full-parameter-Tuning-of-LLMs-with-Affordable-Resources"><a href="#QFT-Quantized-Full-parameter-Tuning-of-LLMs-with-Affordable-Resources" class="headerlink" title="QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources"></a>QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07147">http://arxiv.org/abs/2310.07147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhikai Li, Xiaoxuan Liu, Banghua Zhu, Zhen Dong, Qingyi Gu, Kurt Keutzer</li>
<li>for: 这个论文的目的是提出一种量化全参数调参框架（QFT），以优化大型自然语言处理模型（LLM）的性能。</li>
<li>methods: 该论文使用了两个新的想法：首先，使用高效的Lion优化器，只跟踪冲量和每个参数的常规更新大小，这有利于精炼量化；其次，对模型状态进行量化，并采用梯度流和参数更新方案来更新量化的加法器。</li>
<li>results: 该论文的实验结果显示，使用QFT可以将模型状态的内存占用量降低至21%，而性能与标准解决方案相当，例如，对一个LLaMA-7B模型进行调参只需要&lt;30GB的内存，可以用单个A6000 GPU满足。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have showcased remarkable impacts across a wide spectrum of natural language processing tasks. Fine-tuning these pre-trained models on downstream datasets provides further significant performance gains, but this process has been challenging due to its extraordinary resource requirements. To this end, existing efforts focus on parameter-efficient fine-tuning, which, unfortunately, fail to capitalize on the powerful potential of full-parameter fine-tuning. In this work, we propose QFT, a novel Quantized Full-parameter Tuning framework for LLMs that enables memory-efficient fine-tuning without harming performance. Our framework incorporates two novel ideas: (i) we adopt the efficient Lion optimizer, which only keeps track of the momentum and has consistent update magnitudes for each parameter, an inherent advantage for robust quantization; and (ii) we quantize all model states and store them as integer values, and present a gradient flow and parameter update scheme for the quantized weights. As a result, QFT reduces the model state memory to 21% of the standard solution while achieving comparable performance, e.g., tuning a LLaMA-7B model requires only <30GB of memory, satisfied by a single A6000 GPU.
</details>
<details>
<summary>摘要</summary>
Our framework includes two innovative ideas:1. We use the efficient Lion optimizer, which only tracks the momentum and has consistent update magnitudes for each parameter, making it well-suited for robust quantization.2. We quantize all model states and store them as integer values, and develop a gradient flow and parameter update scheme for the quantized weights.As a result, QFT reduces the model state memory to 21% of the standard solution while achieving comparable performance. For example, fine-tuning a LLaMA-7B model only requires approximately 30GB of memory, which can be satisfied by a single A6000 GPU.
</details></li>
</ul>
<hr>
<h2 id="Empowering-Psychotherapy-with-Large-Language-Models-Cognitive-Distortion-Detection-through-Diagnosis-of-Thought-Prompting"><a href="#Empowering-Psychotherapy-with-Large-Language-Models-Cognitive-Distortion-Detection-through-Diagnosis-of-Thought-Prompting" class="headerlink" title="Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting"></a>Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07146">http://arxiv.org/abs/2310.07146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyu Chen, Yujie Lu, William Yang Wang</li>
<li>for: 这篇论文是为了提供人工智能助手来支持计算性心理治疗。</li>
<li>methods: 这篇论文使用大语言模型进行认知错误探测，并提出了诊断思维（DoT）提示，以进行三 stage 的诊断过程：主观评估、相对性推理和schema分析。</li>
<li>results: 实验结果显示，DoT 能够对于认知错误探测取得了重要的改善，并且生成了高品质的诊断理由，得到了人类专家的批准。<details>
<summary>Abstract</summary>
Mental illness remains one of the most critical public health issues of our time, due to the severe scarcity and accessibility limit of professionals. Psychotherapy requires high-level expertise to conduct deep, complex reasoning and analysis on the cognition modeling of the patients. In the era of Large Language Models, we believe it is the right time to develop AI assistance for computational psychotherapy. We study the task of cognitive distortion detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs diagnosis on the patient's speech via three stages: subjectivity assessment to separate the facts and the thoughts; contrastive reasoning to elicit the reasoning processes supporting and contradicting the thoughts; and schema analysis to summarize the cognition schemas. The generated diagnosis rationales through the three stages are essential for assisting the professionals. Experiments demonstrate that DoT obtains significant improvements over ChatGPT for cognitive distortion detection, while generating high-quality rationales approved by human experts.
</details>
<details>
<summary>摘要</summary>
精神疾病仍然是当代公共卫生问题中的一个重要问题，因为专业人员的 scarcity 和访问限制。心理治疗需要高水平的专业技能，以进行深入、复杂的认知和分析，对患者的认知模型进行深入了解。在大语言模型时代，我们认为是时候开发人工智能助手，以帮助计算心理治疗。我们研究了思维扭曲检测任务，并提出了诊断思维（DoT）提示。DoT在患者的语音上进行三个阶段的诊断：主观评估，以分离事实和想法; 对比逻辑，以激发支持和驳斥思想的逻辑过程; 和schema分析，以总结认知schema。生成的诊断原因通过三个阶段是对专业人员的重要帮助。实验表明，DoT在思维扭曲检测方面比ChatGPT具有显著改善，同时生成高质量的人类专家批准的诊断理由。
</details></li>
</ul>
<hr>
<h2 id="AE-smnsMLC-Multi-Label-Classification-with-Semantic-Matching-and-Negative-Label-Sampling-for-Product-Attribute-Value-Extraction"><a href="#AE-smnsMLC-Multi-Label-Classification-with-Semantic-Matching-and-Negative-Label-Sampling-for-Product-Attribute-Value-Extraction" class="headerlink" title="AE-smnsMLC: Multi-Label Classification with Semantic Matching and Negative Label Sampling for Product Attribute Value Extraction"></a>AE-smnsMLC: Multi-Label Classification with Semantic Matching and Negative Label Sampling for Product Attribute Value Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07137">http://arxiv.org/abs/2310.07137</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhongfendeng/ae-smnsmlc">https://github.com/zhongfendeng/ae-smnsmlc</a></li>
<li>paper_authors: Zhongfen Deng, Wei-Te Chen, Lei Chen, Philip S. Yu</li>
<li>for: 这篇论文是为了解决电子商务中产品特征值EXTRACTION问题，该问题在实际应用中具有重要性。</li>
<li>methods: 这篇论文提出了一种基于多标签分类的方法，该方法可以应用于实际应用中，只有 attribute value 的weak annotation available。另外，该方法还考虑了产品特征值之间的语义连接，从而帮助 attribute value extraction。</li>
<li>results:  experiments 表明，该方法在三个实际应用中的 dataset 上具有效果和优势。<details>
<summary>Abstract</summary>
Product attribute value extraction plays an important role for many real-world applications in e-Commerce such as product search and recommendation. Previous methods treat it as a sequence labeling task that needs more annotation for position of values in the product text. This limits their application to real-world scenario in which only attribute values are weakly-annotated for each product without their position. Moreover, these methods only use product text (i.e., product title and description) and do not consider the semantic connection between the multiple attribute values of a given product and its text, which can help attribute value extraction. In this paper, we reformulate this task as a multi-label classification task that can be applied for real-world scenario in which only annotation of attribute values is available to train models (i.e., annotation of positional information of attribute values is not available). We propose a classification model with semantic matching and negative label sampling for attribute value extraction. Semantic matching aims to capture semantic interactions between attribute values of a given product and its text. Negative label sampling aims to enhance the model's ability of distinguishing similar values belonging to the same attribute. Experimental results on three subsets of a large real-world e-Commerce dataset demonstrate the effectiveness and superiority of our proposed model.
</details>
<details>
<summary>摘要</summary>
In this paper, we reformulate the task as a multi-label classification task that can be applied in real-world scenarios where only attribute value annotations are available. We propose a classification model with semantic matching and negative label sampling for attribute value extraction. Semantic matching aims to capture the semantic interactions between attribute values of a given product and its text, while negative label sampling enhances the model's ability to distinguish similar values belonging to the same attribute.Experimental results on three subsets of a large real-world e-Commerce dataset demonstrate the effectiveness and superiority of our proposed model.
</details></li>
</ul>
<hr>
<h2 id="Comparing-Styles-across-Languages"><a href="#Comparing-Styles-across-Languages" class="headerlink" title="Comparing Styles across Languages"></a>Comparing Styles across Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07135">http://arxiv.org/abs/2310.07135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shreya Havaldar, Matthew Pressimone, Eric Wong, Lyle Ungar</li>
<li>for: 这 paper 是为了研究不同语言之间的文化风格差异而写的。</li>
<li>methods: 这 paper 使用了一种新的解释框架，可以从多语言模型中提取不同风格的特征，并将其归类到相似的 lexical categories 中。</li>
<li>results: 这 paper 提出了第一个涵盖四种语言的敬谔词汇集，并详细分析了各语言之间的敬谔风格差异。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Understanding how styles differ across languages is advantageous for training both humans and computers to generate culturally appropriate text. We introduce an explanation framework to extract stylistic differences from multilingual LMs and compare styles across languages. Our framework (1) generates comprehensive style lexica in any language and (2) consolidates feature importances from LMs into comparable lexical categories. We apply this framework to compare politeness, creating the first holistic multilingual politeness dataset and exploring how politeness varies across four languages. Our approach enables an effective evaluation of how distinct linguistic categories contribute to stylistic variations and provides interpretable insights into how people communicate differently around the world.
</details>
<details>
<summary>摘要</summary>
理解不同语言的风格差异对于训练人类和计算机生成文本的文化适应性是有利的。我们介绍了一种解释框架，用于从多语言LM中提取风格差异并对不同语言的风格进行比较。我们的框架包括（1）生成任何语言的完整风格词典，以及（2）从LM中抽取到相似类别的特征重要性。我们对政eness进行比较，创建了第一个涵盖四种语言的整体多语言政eness数据集，并explored如何在不同语言中表达尊敬的方式。我们的方法可以有效地评估不同语言语言类别的贡献，并提供可读性的交流见解。
</details></li>
</ul>
<hr>
<h2 id="Argumentative-Stance-Prediction-An-Exploratory-Study-on-Multimodality-and-Few-Shot-Learning"><a href="#Argumentative-Stance-Prediction-An-Exploratory-Study-on-Multimodality-and-Few-Shot-Learning" class="headerlink" title="Argumentative Stance Prediction: An Exploratory Study on Multimodality and Few-Shot Learning"></a>Argumentative Stance Prediction: An Exploratory Study on Multimodality and Few-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07093">http://arxiv.org/abs/2310.07093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arushi Sharma, Abhibha Gupta, Maneesh Bilalpur</li>
<li>for: 本研究旨在评估图像是否对社会热点话题中的立场预测有所必要，并比较原生多模态和文本基础模型在少数shot设定下的性能。</li>
<li>methods: 本研究使用了 Twitter 上的话题推荐和图像摘要来生成图像和文本对应的数据集，并对这些数据集进行了文本基础模型和多模态模型的 fine-tuning。</li>
<li>results: 研究发现， ensemble of fine-tuned 文本基础模型（0.817 F1-score）在社会热点话题中的立场预测性能较高，比 multimodal 模型（0.677 F1-score）和文本基础模型在少数shot设定下的预测（0.550 F1-score）更好。此外，研究还发现，当图像内容被摘要为自然语言时，多模态模型在表现更好。<details>
<summary>Abstract</summary>
To advance argumentative stance prediction as a multimodal problem, the First Shared Task in Multimodal Argument Mining hosted stance prediction in crucial social topics of gun control and abortion. Our exploratory study attempts to evaluate the necessity of images for stance prediction in tweets and compare out-of-the-box text-based large-language models (LLM) in few-shot settings against fine-tuned unimodal and multimodal models. Our work suggests an ensemble of fine-tuned text-based language models (0.817 F1-score) outperforms both the multimodal (0.677 F1-score) and text-based few-shot prediction using a recent state-of-the-art LLM (0.550 F1-score). In addition to the differences in performance, our findings suggest that the multimodal models tend to perform better when image content is summarized as natural language over their native pixel structure and, using in-context examples improves few-shot performance of LLMs.
</details>
<details>
<summary>摘要</summary>
要提高论据立场预测为多modal问题，第一次共同任务在多modal Argument Mining中进行了论据立场预测，涉及重要的社会问题如枪支持和堕胎。我们的探索研究试图评估图像是否对论据立场预测在微博中必要，并比较未经调整的文本基础大语言模型（LLM）在少数shot设置下表现于精心调整的单modal和多modal模型。我们的工作表明一个 ensemble of 精心调整的文本基础语言模型（0.817 F1-score）在性能方面超过了多modal（0.677 F1-score）和文本基础几shot预测使用最新的状态对技术（0.550 F1-score）。此外，我们发现在图像内容被摘要为自然语言的情况下，多modal模型在性能方面表现更好，并且在 Context 中使用示例可以提高 LLM 的几shot性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/11/cs.CL_2023_10_11/" data-id="clnsn0vep008zgf88fc7pgcna" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/11/cs.AI_2023_10_11/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.AI - 2023-10-11
        
      </div>
    </a>
  
  
    <a href="/2023/10/11/cs.LG_2023_10_11/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.LG - 2023-10-11</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">82</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">78</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">35</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">78</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">22</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">150</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
