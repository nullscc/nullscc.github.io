
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.SD - 2023-10-01 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="UniAudio: An Audio Foundation Model Toward Universal Audio Generation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.00704 repo_url: https:&#x2F;&#x2F;github.com&#x2F;yangdongchao&#x2F;UniAudio_demo paper_authors: Dongchao Yang, J">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.SD - 2023-10-01">
<meta property="og:url" content="https://nullscc.github.io/2023/10/01/cs.SD_2023_10_01/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="UniAudio: An Audio Foundation Model Toward Universal Audio Generation paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.00704 repo_url: https:&#x2F;&#x2F;github.com&#x2F;yangdongchao&#x2F;UniAudio_demo paper_authors: Dongchao Yang, J">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-10-01T15:00:00.000Z">
<meta property="article:modified_time" content="2023-11-02T08:28:24.057Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.SD_2023_10_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/01/cs.SD_2023_10_01/" class="article-date">
  <time datetime="2023-10-01T15:00:00.000Z" itemprop="datePublished">2023-10-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.SD - 2023-10-01
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="UniAudio-An-Audio-Foundation-Model-Toward-Universal-Audio-Generation"><a href="#UniAudio-An-Audio-Foundation-Model-Toward-Universal-Audio-Generation" class="headerlink" title="UniAudio: An Audio Foundation Model Toward Universal Audio Generation"></a>UniAudio: An Audio Foundation Model Toward Universal Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.00704">http://arxiv.org/abs/2310.00704</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangdongchao/UniAudio_demo">https://github.com/yangdongchao/UniAudio_demo</a></li>
<li>paper_authors: Dongchao Yang, Jinchuan Tian, Xu Tan, Rongjie Huang, Songxiang Liu, Xuankai Chang, Jiatong Shi, Sheng Zhao, Jiang Bian, Xixin Wu, Zhou Zhao, Shinji Watanabe, Helen Meng</li>
<li>for: 这个论文的目标是开发一个可以处理多种生成任务的语言模型（LLM），并使其能够生成具有给定输入条件的多种音频类型（包括语音、声音、音乐和歌唱）。</li>
<li>methods: 这个论文使用了一种新的 Tokenization 技术，即 residual vector quantization based neural codec，来处理各种目标音频的tokenization。它还使用了一种多尺度 transformer 模型来处理长度过长的序列问题。</li>
<li>results: 论文在11个任务上实现了州际级或至少竞争性的成绩，并且发现UniAudio模型在所有训练任务中表现出了强大的能力。<details>
<summary>Abstract</summary>
Large Language models (LLM) have demonstrated the capability to handle a variety of generative tasks. This paper presents the UniAudio system, which, unlike prior task-specific approaches, leverages LLM techniques to generate multiple types of audio (including speech, sounds, music, and singing) with given input conditions. UniAudio 1) first tokenizes all types of target audio along with other condition modalities, 2) concatenates source-target pair as a single sequence, and 3) performs next-token prediction using LLM. Also, a multi-scale Transformer model is proposed to handle the overly long sequences caused by the residual vector quantization based neural codec in tokenization. Training of UniAudio is scaled up to 165K hours of audio and 1B parameters, based on all generative tasks, aiming to obtain sufficient prior knowledge not only in the intrinsic properties of audio but also the inter-relationship between audio and other modalities. Therefore, the trained UniAudio model has the potential to become a foundation model for universal audio generation: it shows strong capability in all trained tasks and can seamlessly support new audio generation tasks after simple fine-tuning. Experiments demonstrate that UniAudio achieves state-of-the-art or at least competitive results on most of the 11 tasks. Demo and code are released at https://github.com/yangdongchao/UniAudio
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经证明了处理多种生成任务的能力。这篇论文介绍了UniAudio系统，与前一些任务特定的方法不同，通过LLM技术来生成多种音频（包括语音、声音、音乐和歌唱），并且可以根据输入条件进行生成。UniAudio的实现方式包括以下三个步骤：1. 对所有类型的目标音频进行token化，并将其与其他条件模式一起 concatenate 成一个序列。2. 使用 LLM 进行下一个token预测。3. 使用多级 transformer 模型来处理由 residual vector quantization 基于的 neural codec 生成的过长序列。在训练UniAudio时，使用了165K小时的音频和1B参数，基于所有生成任务，以获得充足的先验知识不仅在音频的内在性能，还在音频和其他模式之间的关系。因此，训练UniAudio模型后，可以作为普适的音频生成基模型，它在所有训练任务中表现出了强大的能力，并且可以通过简单的微调来支持新的音频生成任务。实验结果表明，UniAudio在大多数11个任务中具有国际级或至少竞争力的成绩。示例和代码可以在https://github.com/yangdongchao/UniAudio 中下载。
</details></li>
</ul>
<hr>
<h2 id="Pianist-Identification-Using-Convolutional-Neural-Networks"><a href="#Pianist-Identification-Using-Convolutional-Neural-Networks" class="headerlink" title="Pianist Identification Using Convolutional Neural Networks"></a>Pianist Identification Using Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.00699">http://arxiv.org/abs/2310.00699</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/betsytang/pid-cnn">https://github.com/betsytang/pid-cnn</a></li>
<li>paper_authors: Jingjing Tang, Geraint Wiggins, Gyorgy Fazekas</li>
<li>For: 本研究旨在用深度学习技术自动识别表演型钢琴演奏者，解决了建立智能音乐 инструмент和智能音乐系统的挑战。* Methods: 我们使用卷积神经网络和表达特征来实现自动识别，并对大规模的表演型钢琴演奏数据进行了深度学习技术的应用和改进。* Results: 我们的模型在6类识别任务中达到85.3%的准确率，比基eline模型高出了20.8%。我们的改进的数据集也提供了更好的训练数据，为自动演奏者识别做出了重要贡献。<details>
<summary>Abstract</summary>
This paper presents a comprehensive study of automatic performer identification in expressive piano performances using convolutional neural networks (CNNs) and expressive features. Our work addresses the challenging multi-class classification task of identifying virtuoso pianists, which has substantial implications for building dynamic musical instruments with intelligence and smart musical systems. Incorporating recent advancements, we leveraged large-scale expressive piano performance datasets and deep learning techniques. We refined the scores by expanding repetitions and ornaments for more accurate feature extraction. We demonstrated the capability of one-dimensional CNNs for identifying pianists based on expressive features and analyzed the impact of the input sequence lengths and different features. The proposed model outperforms the baseline, achieving 85.3% accuracy in a 6-way identification task. Our refined dataset proved more apt for training a robust pianist identifier, making a substantial contribution to the field of automatic performer identification. Our codes have been released at https://github.com/BetsyTang/PID-CNN.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/01/cs.SD_2023_10_01/" data-id="clp88dc1m0105ob889oon2fyz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/02/eess.SP_2023_10_02/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.SP - 2023-10-02
        
      </div>
    </a>
  
  
    <a href="/2023/10/01/eess.AS_2023_10_01/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.AS - 2023-10-01</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
