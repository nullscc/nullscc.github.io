
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.IV - 2023-10-06 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="A Plug-and-Play Image Registration Network paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.04297 repo_url: None paper_authors: Junhao Hu, Weijie Gan, Zhixin Sun, Hongyu An, Ulugbek S. Kamilovfor: 这个研究旨在开发一个基于深度学">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.IV - 2023-10-06">
<meta property="og:url" content="https://nullscc.github.io/2023/10/06/eess.IV_2023_10_06/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="A Plug-and-Play Image Registration Network paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.04297 repo_url: None paper_authors: Junhao Hu, Weijie Gan, Zhixin Sun, Hongyu An, Ulugbek S. Kamilovfor: 这个研究旨在开发一个基于深度学">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-10-06T09:00:00.000Z">
<meta property="article:modified_time" content="2023-11-02T08:28:27.754Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.IV_2023_10_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/06/eess.IV_2023_10_06/" class="article-date">
  <time datetime="2023-10-06T09:00:00.000Z" itemprop="datePublished">2023-10-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.IV - 2023-10-06
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Plug-and-Play-Image-Registration-Network"><a href="#A-Plug-and-Play-Image-Registration-Network" class="headerlink" title="A Plug-and-Play Image Registration Network"></a>A Plug-and-Play Image Registration Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04297">http://arxiv.org/abs/2310.04297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhao Hu, Weijie Gan, Zhixin Sun, Hongyu An, Ulugbek S. Kamilov<br>for: 这个研究旨在开发一个基于深度学习的形变影像注册（DIR）方法，以提高生物医学影像注册的精度和效率。methods: 这个方法基于一个条件enced Convolutional Neural Network（CNN）来估计两个输入影像之间的注册场，并透过将CNN检测器”嵌入”到一个迭代法中，以增强注册的稳定性和准确性。results: 我们的方法在OASIS和CANDI dataset上的数据显示，能够 дости得生物医学影像注册的州度顶峰性能。<details>
<summary>Abstract</summary>
Deformable image registration (DIR) is an active research topic in biomedical imaging. There is a growing interest in developing DIR methods based on deep learning (DL). A traditional DL approach to DIR is based on training a convolutional neural network (CNN) to estimate the registration field between two input images. While conceptually simple, this approach comes with a limitation that it exclusively relies on a pre-trained CNN without explicitly enforcing fidelity between the registered image and the reference. We present plug-and-play image registration network (PIRATE) as a new DIR method that addresses this issue by integrating an explicit data-fidelity penalty and a CNN prior. PIRATE pre-trains a CNN denoiser on the registration field and "plugs" it into an iterative method as a regularizer. We additionally present PIRATE+ that fine-tunes the CNN prior in PIRATE using deep equilibrium models (DEQ). PIRATE+ interprets the fixed-point iteration of PIRATE as a network with effectively infinite layers and then trains the resulting network end-to-end, enabling it to learn more task-specific information and boosting its performance. Our numerical results on OASIS and CANDI datasets show that our methods achieve state-of-the-art performance on DIR.
</details>
<details>
<summary>摘要</summary>
扭形图像registratio (DIR) 是生物医学成像领域的活跃研究领域。随着深度学习 (DL) 的发展，DIR 方法也在不断地演化。传统的 DL 方法是通过训练一个卷积神经网络 (CNN) 来估计两个输入图像之间的 registrtion 场。然而，这种方法存在一个限制，即完全依赖于预训练的 CNN，而不是直接强制图像注册和参考图像之间的准确性。我们提出了一种新的 DIR 方法，即插件和游戏图像注册网络 (PIRATE)，它通过结合显式数据准确性罚和 CNN 先验来解决这个问题。PIRATE 先训练了一个 CNN 减噪器在注册场景中，然后将其作为 PIRATE 的规则进行插入。此外，我们还提出了 PIRATE+，它在 PIRATE 中使用深度平衡模型 (DEQ) 进行 fine-tuning，从而使 PIRATE 能够更好地学习任务特有的信息，提高其性能。我们的数字结果表明，我们的方法在 OASIS 和 CANDI 数据集上实现了 DIR 领域的状态能力。
</details></li>
</ul>
<hr>
<h2 id="Towards-Non-contact-3D-Ultrasound-for-Wrist-Imaging"><a href="#Towards-Non-contact-3D-Ultrasound-for-Wrist-Imaging" class="headerlink" title="Towards Non-contact 3D Ultrasound for Wrist Imaging"></a>Towards Non-contact 3D Ultrasound for Wrist Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04296">http://arxiv.org/abs/2310.04296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antony Jerald, A. N. Madhavanunni, Gayathri Malamal, Mahesh Raveendranatha Panicker<br>for:The paper aims to develop a novel approach for non-contact freehand 3D ultrasound imaging with minimal complexity added to existing point of care ultrasound (POCUS) systems.methods:The proposed approach uses a mechanical track for non-contact ultrasound scanning, which restricts the probe motion to a linear plane and simplifies the acquisition and 3D reconstruction process. A pipeline for US 3D volume reconstruction using an US research platform and a GPU-based edge device is developed.results:The proposed approach is demonstrated through ex-vivo and in-vivo experiments, showing its efficacy in providing accurate 3D US imaging with adjustable field of view capability, non-contact design, and low cost of deployment without significantly altering the existing setup.Please note that the above information is in Simplified Chinese:for: 这篇论文的目的是开发一种新的非接触自由手3D超声成像方法，以便在现有的点检超声系统（POCUS）上增加了最小复杂度。methods: 该提议使用机械轨迹进行非接触超声扫描，这限制了探针的运动范围为直线平面，以简化获取和3D重建过程。一个基于超声研究平台和GPU的边缘设备上的3D超声卷积管道也被开发。results: 该提议的效果通过外科和生物实验显示，能够提供精度的3D超声成像，并且具有可调Field of view功能、非接触设计和低成本部署，不会对现有设置产生显著影响。<details>
<summary>Abstract</summary>
Objective: The objective of this work is an attempt towards non-contact freehand 3D ultrasound imaging with minimal complexity added to the existing point of care ultrasound (POCUS) systems. Methods: This study proposes a novel approach of using a mechanical track for non-contact ultrasound (US) scanning. The approach thus restricts the probe motion to a linear plane, to simplify the acquisition and 3D reconstruction process. A pipeline for US 3D volume reconstruction employing an US research platform and a GPU-based edge device is developed. Results: The efficacy of the proposed approach is demonstrated through ex-vivo and in-vivo experiments. Conclusion: The proposed approach with the adjustable field of view capability, non-contact design, and low cost of deployment without significantly altering the existing setup would open doors for up gradation of traditional systems to a wide range of 3D US imaging applications. Significance: Ultrasound (US) imaging is a popular clinical imaging modality for the point-of-care bedside imaging, particularly of the wrist/knee in the pediatric population due to its non-invasive and radiation free nature. However, the limited views of tissue structures obtained with 2D US in such scenarios make the diagnosis challenging. To overcome this, 3D US imaging which uses 2D US images and their orientation/position to reconstruct 3D volumes was developed. The accurate position estimation of the US probe at low cost has always stood as a challenging task in 3D reconstruction. Additionally, US imaging involves contact, which causes difficulty to pediatric subjects while monitoring live fractures or open wounds. Towards overcoming these challenges, a novel framework is attempted in this work.
</details>
<details>
<summary>摘要</summary>
Methods: This study proposes a new approach using a mechanical track for non-contact US scanning, which simplifies the acquisition and 3D reconstruction process by restricting the probe motion to a linear plane. A pipeline for US 3D volume reconstruction using an US research platform and a GPU-based edge device is developed.Results: The effectiveness of the proposed approach is demonstrated through ex-vivo and in-vivo experiments.Conclusion: The proposed approach with adjustable field of view capability, non-contact design, and low cost of deployment without significantly altering the existing setup would expand the applications of 3D US imaging in a wide range of clinical scenarios, particularly in pediatric populations.Significance: Traditional 2D US imaging has limited views of tissue structures, making diagnosis challenging. 3D US imaging overcomes this limitation by using 2D US images and their orientation/position to reconstruct 3D volumes. However, accurate probe position estimation at low cost has been a long-standing challenge in 3D reconstruction. Additionally, contact-based US imaging can be difficult for pediatric subjects, particularly when monitoring live fractures or open wounds. This novel framework addresses these challenges and has the potential to upgrade traditional systems for a wide range of 3D US imaging applications.In Simplified Chinese:目标：本研究的目标是开发一种新的、非接触、低成本的ultrasound（US）图像三维重建方法，以便在现有的点检查ultrasound（POCUS）系统上进行最小化的修改。方法：这种研究提议使用机械轨迹来实现非接触US扫描，这将简化获取和三维重建过程，并且只有在 linear 平面上进行探针运动。在US研究平台和GPU基于的边缘设备上开发了US三维图像重建的管道。结果：经过对外部和内部实验，效果表明了该方法的可行性。结论：该方法可以提供可调适的视场、非接触设计和低成本实施，不会对现有设置进行重大改变。这将扩展3D US图像 reconstruction在各种临床应用中的可能性，特别是在儿童人口中。重要性：传统的2D US图像有限制的视场，从而使诊断变得困难。3D US图像使用2D US图像和其orientation/position来重建3DVolume，从而突破这些限制。然而，在3D重建中准确地计算探针位置的低成本问题一直是一个挑战。此外，基于接触的US图像扫描可能会对儿童人口产生困难，特别是在监测活动骨折或开放性伤口时。这种新的框架可以解决这些挑战，并且有可能升级传统系统，以扩展3D US图像重建的应用范围。
</details></li>
</ul>
<hr>
<h2 id="Hessian-based-Similarity-Metric-for-Multimodal-Medical-Image-Registration"><a href="#Hessian-based-Similarity-Metric-for-Multimodal-Medical-Image-Registration" class="headerlink" title="Hessian-based Similarity Metric for Multimodal Medical Image Registration"></a>Hessian-based Similarity Metric for Multimodal Medical Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04009">http://arxiv.org/abs/2310.04009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadreza Eskandari, Houssem-Eddine Gueziri, D. Louis Collins</li>
<li>for: 这个论文主要是为了提出一种新的医学影像匹配算法，用于衡量不同医学影像模式之间的相似性。</li>
<li>methods: 该论文使用了一种基于幂函数的方法，通过研究两个完美匹配的图像板块之间的偏微分关系，来量化它们之间的相似性。</li>
<li>results: 该论文通过实验表明，该新的相似性度量可以快速和精度地衡量不同医学影像模式之间的相似性，并且可以快速和精度地进行医学影像匹配。<details>
<summary>Abstract</summary>
One of the fundamental elements of both traditional and certain deep learning medical image registration algorithms is measuring the similarity/dissimilarity between two images. In this work, we propose an analytical solution for measuring similarity between two different medical image modalities based on the Hessian of their intensities. First, assuming a functional dependence between the intensities of two perfectly corresponding patches, we investigate how their Hessians relate to each other. Secondly, we suggest a closed-form expression to quantify the deviation from this relationship, given arbitrary pairs of image patches. We propose a geometrical interpretation of the new similarity metric and an efficient implementation for registration. We demonstrate the robustness of the metric to intensity nonuniformities using synthetic bias fields. By integrating the new metric in an affine registration framework, we evaluate its performance for MRI and ultrasound registration in the context of image-guided neurosurgery using target registration error and computation time.
</details>
<details>
<summary>摘要</summary>
一种基本元素 OF both traditional and certain deep learning医疗图像注册算法是测量两个图像之间的相似性/不同性。在这项工作中，我们提出了一个分析解决方案，用于测量两种不同医疗图像模式之间的相似性，基于图像强度的赫西安关系。首先，我们假设两个完美匹配的图像块之间存在函数依赖关系，然后我们研究了这两个赫西安之间的关系。其次，我们提出了一个具有closed-form表达式，用于衡量这种关系的偏差，给出任意两个图像块的对应。我们提出了一种几何解释这个新的相似度标准和一种高效的实现方式，并且在affine注册框架中集成了这个标准。我们通过使用模拟的扭曲场来证明metric的稳定性，并且在MRI和ultrasound注册中进行了image-guided neurosurgery的应用，通过target registration error和计算时间来评估metric的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/06/eess.IV_2023_10_06/" data-id="clpztdnsx01bles888la20ijv" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/06/cs.LG_2023_10_06/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.LG - 2023-10-06
        
      </div>
    </a>
  
  
    <a href="/2023/10/06/eess.SP_2023_10_06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">eess.SP - 2023-10-06</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
