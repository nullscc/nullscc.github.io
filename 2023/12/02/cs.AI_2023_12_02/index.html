
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>cs.AI - 2023-12-02 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional Reinforcement Learning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.01249 repo_url: None paper_authors: Cyrus Neary, Christian Ellis, Arya">
<meta property="og:type" content="article">
<meta property="og:title" content="cs.AI - 2023-12-02">
<meta property="og:url" content="https://nullscc.github.io/2023/12/02/cs.AI_2023_12_02/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional Reinforcement Learning paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.01249 repo_url: None paper_authors: Cyrus Neary, Christian Ellis, Arya">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-12-02T12:00:00.000Z">
<meta property="article:modified_time" content="2023-12-11T10:23:46.633Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-cs.AI_2023_12_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/12/02/cs.AI_2023_12_02/" class="article-date">
  <time datetime="2023-12-02T12:00:00.000Z" itemprop="datePublished">2023-12-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cs.AI - 2023-12-02
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Multifidelity-Sim-to-Real-Pipeline-for-Verifiable-and-Compositional-Reinforcement-Learning"><a href="#A-Multifidelity-Sim-to-Real-Pipeline-for-Verifiable-and-Compositional-Reinforcement-Learning" class="headerlink" title="A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional Reinforcement Learning"></a>A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01249">http://arxiv.org/abs/2312.01249</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrus Neary, Christian Ellis, Aryaman Singh Samyal, Craig Lennon, Ufuk Topcu</li>
<li>for: 这篇论文是为了提出和实现一个基于多级准确性的人工智能训练和验证框架，以便在物理硬件上部署可靠和适应的人工智能策略。</li>
<li>methods: 这个框架使用了分解复杂的机器人任务为多个子任务的技术，并定义了这些子任务之间的数学界面，以便独立地训练和测试这些子任务策略，同时保证总体行为的 garanties。</li>
<li>results: 在一个实验案例中，这个框架成功地训练了一个可以控制战斗车的 compositional 人工智能系统，并在物理硬件上部署了这个系统。<details>
<summary>Abstract</summary>
We propose and demonstrate a compositional framework for training and verifying reinforcement learning (RL) systems within a multifidelity sim-to-real pipeline, in order to deploy reliable and adaptable RL policies on physical hardware. By decomposing complex robotic tasks into component subtasks and defining mathematical interfaces between them, the framework allows for the independent training and testing of the corresponding subtask policies, while simultaneously providing guarantees on the overall behavior that results from their composition. By verifying the performance of these subtask policies using a multifidelity simulation pipeline, the framework not only allows for efficient RL training, but also for a refinement of the subtasks and their interfaces in response to challenges arising from discrepancies between simulation and reality. In an experimental case study we apply the framework to train and deploy a compositional RL system that successfully pilots a Warthog unmanned ground robot.
</details>
<details>
<summary>摘要</summary>
我们提出了一个分解式框架，用于在多级别实验室-实际推广管道中培训和验证学习回归系统，以便在物理硬件上部署可靠和适应性强的学习策略。通过将复杂的机器人任务拆分成几个组成部分，并定义这些部分之间的数学界面，框架允许独立培训和测试这些子任务策略，同时提供 garantías sobre the overall behavior that results from their composition。通过在多级别 simulations 管道中验证这些子任务策略的性能，框架不仅允许高效的学习培训，还可以在面临实际中出现的挑战时进行细致的子任务和界面的调整。在一个实验案例中，我们利用这个框架培训并部署了一个可 compose 的学习系统，成功地控制了一个 Warthog 无人地面机器人。
</details></li>
</ul>
<hr>
<h2 id="Axiomatic-Preference-Modeling-for-Longform-Question-Answering"><a href="#Axiomatic-Preference-Modeling-for-Longform-Question-Answering" class="headerlink" title="Axiomatic Preference Modeling for Longform Question Answering"></a>Axiomatic Preference Modeling for Longform Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02206">http://arxiv.org/abs/2312.02206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Corby Rosset, Guoqing Zheng, Victor Dibia, Ahmed Awadallah, Paul Bennett</li>
<li>for: 这个研究的目的是提高大语言模型（LLM）如GPT-4的性能，特别是通过人类反馈学习（RLHF）来提高模型的满意度。</li>
<li>methods: 这个研究使用了一种名为“axioms”的概念，将人类的偏好编码到一个奖励模型中，以便更好地理解人类的偏好。然后，他们开发了一个axioms的框架，用于生成特定原则的偏好信号，并使用这些信号来训练一个对长答案进行评分的模型。</li>
<li>results: 研究发现，使用这种axioms的框架和训练数据可以让一个小型模型（只有220M参数）的性能高于GPT-4，并且可以在人类和LLM生成的答案中进行同等评分。此外，研究还发现，只需要少量的axioms信号，小型模型就可以超越GPT-4的性能。<details>
<summary>Abstract</summary>
The remarkable abilities of large language models (LLMs) like GPT-4 partially stem from post-training processes like Reinforcement Learning from Human Feedback (RLHF) involving human preferences encoded in a reward model. However, these reward models (RMs) often lack direct knowledge of why, or under what principles, the preferences annotations were made. In this study, we identify principles that guide RMs to better align with human preferences, and then develop an axiomatic framework to generate a rich variety of preference signals to uphold them. We use these axiomatic signals to train a model for scoring answers to longform questions. Our approach yields a Preference Model with only about 220M parameters that agrees with gold human-annotated preference labels more often than GPT-4. The contributions of this work include: training a standalone preference model that can score human- and LLM-generated answers on the same scale; developing an axiomatic framework for generating training data pairs tailored to certain principles; and showing that a small amount of axiomatic signals can help small models outperform GPT-4 in preference scoring. We release our model on huggingface: https://huggingface.co/corbyrosset/axiomatic_preference_model
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如GPT-4的出色能力部分归功于训练后的过程，如人类反馈学习（RLHF），其中人类偏好被编码在奖励模型（RM）中。然而，这些奖励模型通常缺乏直接知道何时、以何原则而作出偏好标注的直觉。在这项研究中，我们发现了导引RM更好听从人类偏好的原则，然后开发了一个axioms的框架，以生成一种多样化的偏好信号，以保持这些原则。我们使用这些axioms信号来训练一个用于评分长问答案的模型。我们的方法得到了一个名为“axioms preference model”的模型，它只有约220M参数，能够更好地与人类标注的偏好标签相匹配，并且在训练时与GPT-4相比，能够更好地评分人类和LLM生成的答案。我们的贡献包括：训练一个独立的偏好模型，可以评分人类和LLM生成的答案在同一个标准下；开发一个axioms框架，用于生成适合特定原则的训练数据对；以及证明一小amount的axioms信号可以帮助小型模型超越GPT-4在偏好评分中。我们将我们的模型上传到huggingface：https://huggingface.co/corbyrosset/axiomatic_preference_model。
</details></li>
</ul>
<hr>
<h2 id="DDxT-Deep-Generative-Transformer-Models-for-Differential-Diagnosis"><a href="#DDxT-Deep-Generative-Transformer-Models-for-Differential-Diagnosis" class="headerlink" title="DDxT: Deep Generative Transformer Models for Differential Diagnosis"></a>DDxT: Deep Generative Transformer Models for Differential Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01242">http://arxiv.org/abs/2312.01242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Mahmudul Alam, Edward Raff, Tim Oates, Cynthia Matuszek</li>
<li>for: 这个研究旨在开发一个自动化的鉴别诊断（DDx）过程，以实现将诊断可能性范围从大量病理中范选出最有可能的疾病。</li>
<li>methods: 本研究使用Transformer构 architecture的生成网络，名为DDxT，通过自动生成可能的疾病列表（DDx），并透过神经网络预测实际的疾病。</li>
<li>results: 实验结果显示，DDxT获得了99.82%的平均准确率和0.9472的平均F1分数，在鉴别诊断方面表现出色。此外，预测真实疾病的时候， mean accuracy 为99.98%， mean F1 score 为0.9949。DDxT比前一代RL基本上大幅提高了表现。<details>
<summary>Abstract</summary>
Differential Diagnosis (DDx) is the process of identifying the most likely medical condition among the possible pathologies through the process of elimination based on evidence. An automated process that narrows a large set of pathologies down to the most likely pathologies will be of great importance. The primary prior works have relied on the Reinforcement Learning (RL) paradigm under the intuition that it aligns better with how physicians perform DDx. In this paper, we show that a generative approach trained with simpler supervised and self-supervised learning signals can achieve superior results on the current benchmark. The proposed Transformer-based generative network, named DDxT, autoregressively produces a set of possible pathologies, i.e., DDx, and predicts the actual pathology using a neural network. Experiments are performed using the DDXPlus dataset. In the case of DDx, the proposed network has achieved a mean accuracy of 99.82% and a mean F1 score of 0.9472. Additionally, mean accuracy reaches 99.98% with a mean F1 score of 0.9949 while predicting ground truth pathology. The proposed DDxT outperformed the previous RL-based approaches by a big margin. Overall, the automated Transformer-based DDx generative model has the potential to become a useful tool for a physician in times of urgency.
</details>
<details>
<summary>摘要</summary>
diferencial diagnóstico (DDx) es el proceso de identificar la condición médica más probable entre las posibles patologías a través del proceso de eliminación basado en la evidencia. Un proceso automatizado que reduce un gran conjunto de patologías a la más probable será de gran importancia. Los trabajos previos principales han confiado en el paradigma de aprendizaje reinforzado (RL) bajo la intuición de que se alinea mejor con cómo los médicos realizan DDx. En este artículo, mostramos que un enfoque generativo entrenado con señales de aprendizaje supervisado y autoasistido puede lograr resultados superiores en la base de datos actual. La red generativa propuesta, llamada DDxT, produce secuencialmente un conjunto de posibles patologías, es decir, DDx, y predice la patología real utilizando una red neuronal. Los experimentos se realizaron utilizando el conjunto de datos DDXPlus. En el caso de DDx, la red propuesta ha logrado una precisión media de 99,82% y una puntuación media de F1 de 0,9472. Además, la precisión media alcanza el 99,98% con una puntuación media de F1 de 0,9949 al predicar la patología real. La red DDxT superó ampliamente a las aproximaciones RL-basadas anteriores. En resumen, el modelo generativo automatizado basado en Transformer tiene el potencial de ser una herramienta útil para los médicos en momentos de urgencia.
</details></li>
</ul>
<hr>
<h2 id="Just-in-Time-Security-Patch-Detection-–-LLM-At-the-Rescue-for-Data-Augmentation"><a href="#Just-in-Time-Security-Patch-Detection-–-LLM-At-the-Rescue-for-Data-Augmentation" class="headerlink" title="Just-in-Time Security Patch Detection – LLM At the Rescue for Data Augmentation"></a>Just-in-Time Security Patch Detection – LLM At the Rescue for Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01241">http://arxiv.org/abs/2312.01241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xunzhu Tang, Zhenghan Chen, Kisub Kim, Haoye Tian, Saad Ezzini, Jacques Klein</li>
<li>for: 警示开源软件中存在增长的漏洞，需要有效地识别安全补丁。</li>
<li>methods: 我们提出了一种新的安全补丁检测系统，即 LLMDA，利用大语言模型（LLM）和代码文本对齐方法。</li>
<li>results: LLMDA在检测安全补丁方面表现出色，质量明显超过了现有技术。<details>
<summary>Abstract</summary>
In the face of growing vulnerabilities found in open-source software, the need to identify {discreet} security patches has become paramount. The lack of consistency in how software providers handle maintenance often leads to the release of security patches without comprehensive advisories, leaving users vulnerable to unaddressed security risks. To address this pressing issue, we introduce a novel security patch detection system, LLMDA, which capitalizes on Large Language Models (LLMs) and code-text alignment methodologies for patch review, data enhancement, and feature combination. Within LLMDA, we initially utilize LLMs for examining patches and expanding data of PatchDB and SPI-DB, two security patch datasets from recent literature. We then use labeled instructions to direct our LLMDA, differentiating patches based on security relevance. Following this, we apply a PTFormer to merge patches with code, formulating hybrid attributes that encompass both the innate details and the interconnections between the patches and the code. This distinctive combination method allows our system to capture more insights from the combined context of patches and code, hence improving detection precision. Finally, we devise a probabilistic batch contrastive learning mechanism within batches to augment the capability of the our LLMDA in discerning security patches. The results reveal that LLMDA significantly surpasses the start of the art techniques in detecting security patches, underscoring its promise in fortifying software maintenance.
</details>
<details>
<summary>摘要</summary>
面对开源软件中增长的漏洞，确定特定的安全补丁成为了首要任务。软件提供商在维护过程中的不一致性常常导致安全补丁的发布而无包括全面的通知， leaving 用户感到不安全。为解决这个紧迫的问题，我们提出了一种新的安全补丁检测系统， LLMDA， which leverages Large Language Models (LLMs) 和 code-text alignment methodologies for patch review, data enhancement, and feature combination.在 LLMDA 中，我们首先使用 LLMs 来检查补丁，并将 PatchDB 和 SPI-DB 两个安全补丁数据集的数据进行扩展。然后，我们使用标注的说明来导引 LLMDA，根据安全相关性进行补丁分类。接着，我们使用 PTFormer 将补丁与代码进行合并，生成 Hybrid 特征，这些特征包括补丁和代码之间的自然详细信息以及代码和补丁之间的连接关系。这种独特的合并方法使得我们的系统能够从代码和补丁的共同上下文中获得更多的洞察，从而提高检测精度。最后，我们在批处理中引入概率批处理学习机制，以增强 LLMDA 的检测精度。结果显示，LLMDA 明显超越了当前技术的检测精度，这说明了我们的系统在软件维护中的应用潜力。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Study-of-Vision-Transformers-in-Image-Classification-Tasks"><a href="#A-Comprehensive-Study-of-Vision-Transformers-in-Image-Classification-Tasks" class="headerlink" title="A Comprehensive Study of Vision Transformers in Image Classification Tasks"></a>A Comprehensive Study of Vision Transformers in Image Classification Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01232">http://arxiv.org/abs/2312.01232</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmoud Khalil, Ahmad Khalil, Alioune Ngom</li>
<li>for: 本文主要探讨了图像分类领域中的视transformer模型，它们如何用于图像分类任务，以及这些模型的优劣点。</li>
<li>methods: 本文主要介绍了现有的图像分类 datasets，以及基于视transformer模型的图像分类方法，包括采用注意力机制的早期尝试，以及使用视transformer模型来捕捉图像中的复杂 Patterns和长距离依赖关系。</li>
<li>results: 本文对图像分类领域的开源论文进行了大规模的报告和分析，并对这些模型的性能进行了评估和比较。<details>
<summary>Abstract</summary>
Image Classification is a fundamental task in the field of computer vision that frequently serves as a benchmark for gauging advancements in Computer Vision. Over the past few years, significant progress has been made in image classification due to the emergence of deep learning. However, challenges still exist, such as modeling fine-grained visual information, high computation costs, the parallelism of the model, and inconsistent evaluation protocols across datasets. In this paper, we conduct a comprehensive survey of existing papers on Vision Transformers for image classification. We first introduce the popular image classification datasets that influenced the design of models. Then, we present Vision Transformers models in chronological order, starting with early attempts at adapting attention mechanism to vision tasks followed by the adoption of vision transformers, as they have demonstrated success in capturing intricate patterns and long-range dependencies within images. Finally, we discuss open problems and shed light on opportunities for image classification to facilitate new research ideas.
</details>
<details>
<summary>摘要</summary>
computer vision 是计算机视觉的一个基本任务， часто被用来评估计算机视觉领域的进步。过去几年，因深度学习的出现，image classification task中有了 significiant progress。然而，还有一些挑战，如模型化细腻的视觉信息、高计算成本、模型并行性和数据集评价协议的不一致。在这篇论文中，我们对现有的Vision Transformers для图像分类进行了全面的检视。我们首先介绍了影响模型设计的受欢迎图像分类数据集，然后按照时间顺序介绍Vision Transformers模型，从早期适应注意力机制到图像转换器的采用，因为它们能够捕捉图像中的复杂模式和长距离依赖关系。最后，我们讨论了现有的问题和新的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Recent-Advances-in-Scalable-Energy-Efficient-and-Trustworthy-Spiking-Neural-networks-from-Algorithms-to-Technology"><a href="#Recent-Advances-in-Scalable-Energy-Efficient-and-Trustworthy-Spiking-Neural-networks-from-Algorithms-to-Technology" class="headerlink" title="Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking Neural networks: from Algorithms to Technology"></a>Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking Neural networks: from Algorithms to Technology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01213">http://arxiv.org/abs/2312.01213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Souvik Kundu, Rui-Jie Zhu, Akhilesh Jaiswal, Peter A. Beerel</li>
<li>for: 这 paper 的目的是描述最近的 neuromorphic computing 和 spiking neural network (SNN) 技术的进步，以及如何使其用于各种感知应用。</li>
<li>methods: 这 paper 使用了一系列的算法和优化技术来高效地训练和扩展低延迟、能效的 SNN 模型，以满足复杂的机器学习应用。</li>
<li>results: 这 paper 描述了一些最近的算法-架构合理化尝试，以及如何使用这些技术来实现高能效和低延迟的 SNN 系统。<details>
<summary>Abstract</summary>
Neuromorphic computing and, in particular, spiking neural networks (SNNs) have become an attractive alternative to deep neural networks for a broad range of signal processing applications, processing static and/or temporal inputs from different sensory modalities, including audio and vision sensors. In this paper, we start with a description of recent advances in algorithmic and optimization innovations to efficiently train and scale low-latency, and energy-efficient spiking neural networks (SNNs) for complex machine learning applications. We then discuss the recent efforts in algorithm-architecture co-design that explores the inherent trade-offs between achieving high energy-efficiency and low latency while still providing high accuracy and trustworthiness. We then describe the underlying hardware that has been developed to leverage such algorithmic innovations in an efficient way. In particular, we describe a hybrid method to integrate significant portions of the model's computation within both memory components as well as the sensor itself. Finally, we discuss the potential path forward for research in building deployable SNN systems identifying key challenges in the algorithm-hardware-application co-design space with an emphasis on trustworthiness.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Empirical-Study-of-Automated-Mislabel-Detection-in-Real-World-Vision-Datasets"><a href="#An-Empirical-Study-of-Automated-Mislabel-Detection-in-Real-World-Vision-Datasets" class="headerlink" title="An Empirical Study of Automated Mislabel Detection in Real World Vision Datasets"></a>An Empirical Study of Automated Mislabel Detection in Real World Vision Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02200">http://arxiv.org/abs/2312.02200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maya Srikanth, Jeremy Irvin, Brian Wesley Hill, Felipe Godoy, Ishan Sabane, Andrew Y. Ng</li>
<li>for: 这篇论文主要针对的是如何自动检测和修复计算机视觉数据中的错误标签。</li>
<li>methods: 本论文使用了多种现有的自动检测错误标签方法，并提出了一种新的简单有效的检测方法（SEMD）。</li>
<li>results: 实验结果表明，SEMD方法可以与或超过先前的自动检测方法的性能，并且在实际计算机视觉数据中应用后，可以提高模型的表现，最大化模型的准确率。<details>
<summary>Abstract</summary>
Major advancements in computer vision can primarily be attributed to the use of labeled datasets. However, acquiring labels for datasets often results in errors which can harm model performance. Recent works have proposed methods to automatically identify mislabeled images, but developing strategies to effectively implement them in real world datasets has been sparsely explored. Towards improved data-centric methods for cleaning real world vision datasets, we first conduct more than 200 experiments carefully benchmarking recently developed automated mislabel detection methods on multiple datasets under a variety of synthetic and real noise settings with varying noise levels. We compare these methods to a Simple and Efficient Mislabel Detector (SEMD) that we craft, and find that SEMD performs similarly to or outperforms prior mislabel detection approaches. We then apply SEMD to multiple real world computer vision datasets and test how dataset size, mislabel removal strategy, and mislabel removal amount further affect model performance after retraining on the cleaned data. With careful design of the approach, we find that mislabel removal leads per-class performance improvements of up to 8% of a retrained classifier in smaller data regimes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="USat-A-Unified-Self-Supervised-Encoder-for-Multi-Sensor-Satellite-Imagery"><a href="#USat-A-Unified-Self-Supervised-Encoder-for-Multi-Sensor-Satellite-Imagery" class="headerlink" title="USat: A Unified Self-Supervised Encoder for Multi-Sensor Satellite Imagery"></a>USat: A Unified Self-Supervised Encoder for Multi-Sensor Satellite Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02199">http://arxiv.org/abs/2312.02199</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanfordmlgroup/usat">https://github.com/stanfordmlgroup/usat</a></li>
<li>paper_authors: Jeremy Irvin, Lucas Tao, Joanne Zhou, Yuntao Ma, Langston Nashold, Benjamin Liu, Andrew Y. Ng</li>
<li>for: The paper is written for developing a new encoder architecture called USat for self-supervised pre-training on remote sensing data.</li>
<li>methods: The paper uses a vision transformer with modified patch projection layers and positional encodings to model spectral bands with varying spatial scales from multiple sensors.</li>
<li>results: The pre-trained USat model outperforms state-of-the-art self-supervised MAE models trained on remote sensing data on multiple remote sensing benchmark datasets (up to 8%) and leads to improvements in low data regimes (up to 7%).Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文是为了开发一种新的编码器架构，用于自主学习预训练 remote sensing 数据。</li>
<li>methods: 这篇论文使用了一种视觉 трансформа器，并将其修改为 patch projection 层和位置编码，以模型从多个感知器的spectral带来的不同的空间尺度。</li>
<li>results: 预训练 USat 模型在多个 remote sensing 数据集上（最多8%）达到了状态机器人自主学习 MAE 模型的最高精度，并在低数据情况下（最多7%）提供了改进。<details>
<summary>Abstract</summary>
Large, self-supervised vision models have led to substantial advancements for automatically interpreting natural images. Recent works have begun tailoring these methods to remote sensing data which has rich structure with multi-sensor, multi-spectral, and temporal information providing massive amounts of self-labeled data that can be used for self-supervised pre-training. In this work, we develop a new encoder architecture called USat that can input multi-spectral data from multiple sensors for self-supervised pre-training. USat is a vision transformer with modified patch projection layers and positional encodings to model spectral bands with varying spatial scales from multiple sensors. We integrate USat into a Masked Autoencoder (MAE) self-supervised pre-training procedure and find that a pre-trained USat outperforms state-of-the-art self-supervised MAE models trained on remote sensing data on multiple remote sensing benchmark datasets (up to 8%) and leads to improvements in low data regimes (up to 7%). Code and pre-trained weights are available at https://github.com/stanfordmlgroup/USat .
</details>
<details>
<summary>摘要</summary>
大型自我超vision模型已经对自然图像自动解释带来了重要进步。最近的工作开始将这些方法应用于Remote感知数据，该数据具有多感器、多spectral和时间信息，可以提供大量自label数据，用于自主预训练。在这项工作中，我们开发了一个新的编码器架构，即USat，可以将多spectral数据从多个感知器输入到自我预训练。USat是一种视transformer，其中修改了 patch projection层和位置编码，以模型从多个感知器的不同空间尺度上的spectral频率带来改进。我们将USat集成到了一个Masked Autoencoder（MAE）自我预训练过程中，并发现在远程感知数据上的多个远程感知标准测试数据集（最高提高8%）和低数据情况下（最高提高7%）都有提高。代码和预训练 веса可以在https://github.com/stanfordmlgroup/USat 上获取。
</details></li>
</ul>
<hr>
<h2 id="Harnessing-Discrete-Representations-For-Continual-Reinforcement-Learning"><a href="#Harnessing-Discrete-Representations-For-Continual-Reinforcement-Learning" class="headerlink" title="Harnessing Discrete Representations For Continual Reinforcement Learning"></a>Harnessing Discrete Representations For Continual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01203">http://arxiv.org/abs/2312.01203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edan Meyer, Adam White, Marlos C. Machado</li>
<li>for: 这篇论文主要研究了在 reinforcement learning 中使用 vector-based categorical representations 的优势。</li>
<li>methods: 该论文使用了 Empirical investigation 来评估 vector-based categorical representations 在 reinforcement learning 中的效果，并在 world-model learning、model-free RL 和 continual RL 问题上进行了评估。</li>
<li>results: 研究发现，使用 vector-based categorical representations 可以更好地模型世界，并且可以使用 less capacity 和 less data 来培育更好的策略。在 continual RL 问题上，这些优势可以导致更快的适应性。此外，分析表明，这些性能提升可能与 latent vectors 中的信息和编码方式有关。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) agents make decisions using nothing but observations from the environment, and consequently, heavily rely on the representations of those observations. Though some recent breakthroughs have used vector-based categorical representations of observations, often referred to as discrete representations, there is little work explicitly assessing the significance of such a choice. In this work, we provide a thorough empirical investigation of the advantages of representing observations as vectors of categorical values within the context of reinforcement learning. We perform evaluations on world-model learning, model-free RL, and ultimately continual RL problems, where the benefits best align with the needs of the problem setting. We find that, when compared to traditional continuous representations, world models learned over discrete representations accurately model more of the world with less capacity, and that agents trained with discrete representations learn better policies with less data. In the context of continual RL, these benefits translate into faster adapting agents. Additionally, our analysis suggests that the observed performance improvements can be attributed to the information contained within the latent vectors and potentially the encoding of the discrete representation itself.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用 solely 环境观察的决策的强化学习（RL）代理人，它们具有强依赖于观察的表示的特点。 although some recent breakthroughs have used vector-based categorical representations of observations, there is little work explicitly assessing the significance of such a choice. In this work, we provide a thorough empirical investigation of the advantages of representing observations as vectors of categorical values within the context of reinforcement learning. We perform evaluations on world-model learning, model-free RL, and ultimately continual RL problems, where the benefits best align with the needs of the problem setting. We find that, when compared to traditional continuous representations, world models learned over discrete representations accurately model more of the world with less capacity, and that agents trained with discrete representations learn better policies with less data. In the context of continual RL, these benefits translate into faster adapting agents. Additionally, our analysis suggests that the observed performance improvements can be attributed to the information contained within the latent vectors and potentially the encoding of the discrete representation itself.</SYS>>Here's the translation in Traditional Chinese:<<SYS>>使用仅从环境观察的决策的强化学习（RL）代理人，它们具有强依赖于观察的表示的特点。 although some recent breakthroughs have used vector-based categorical representations of observations, there is little work explicitly assessing the significance of such a choice. In this work, we provide a thorough empirical investigation of the advantages of representing observations as vectors of categorical values within the context of reinforcement learning. We perform evaluations on world-model learning, model-free RL, and ultimately continual RL problems, where the benefits best align with the needs of the problem setting. We find that, when compared to traditional continuous representations, world models learned over discrete representations accurately model more of the world with less capacity, and that agents trained with discrete representations learn better policies with less data. In the context of continual RL, these benefits translate into faster adapting agents. Additionally, our analysis suggests that the observed performance improvements can be attributed to the information contained within the latent vectors and potentially the encoding of the discrete representation itself.</SYS>>
</details></li>
</ul>
<hr>
<h2 id="From-Voices-to-Validity-Leveraging-Large-Language-Models-LLMs-for-Textual-Analysis-of-Policy-Stakeholder-Interviews"><a href="#From-Voices-to-Validity-Leveraging-Large-Language-Models-LLMs-for-Textual-Analysis-of-Policy-Stakeholder-Interviews" class="headerlink" title="From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews"></a>From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01202">http://arxiv.org/abs/2312.01202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Liu, Min Sun<br>for: This paper aims to enhance text analysis of stakeholder interviews regarding K-12 education policy within one U.S. state by integrating Large Language Models (LLMs) with human expertise.methods: The study employs a mixed-methods approach that combines human expertise and GPT-4 analysis to perform thematic and sentiment analysis of stakeholder interviews.results: The results show that GPT-4 thematic coding aligns with human coding by 77.89% at specific themes, and expanding to broader themes increases congruence to 96.02%. GPT-4 also matches expert sentiment analysis more closely than lexicon-based methods. The combined human-computer method enhances the efficiency, validity, and interpretability of educational policy research.Here’s the same information in Simplified Chinese:for: 这个研究目的是使用Large Language Models（LLMs）和人类专家知识结合来提高K-12教育政策方面的讲客评价文本分析。methods: 这个研究采用混合方法，结合人类专家知识和GPT-4分析来实现主题和情感分析。results: 研究结果表明，GPT-4主题编码与人类编码的匹配率为77.89%，扩展到更广泛的主题后，匹配率提高到96.02%。GPT-4还与专家情感分析更加匹配，而且lexicon-based方法相比，GPT-4的匹配率高于25%。<details>
<summary>Abstract</summary>
Obtaining stakeholders' diverse experiences and opinions about current policy in a timely manner is crucial for policymakers to identify strengths and gaps in resource allocation, thereby supporting effective policy design and implementation. However, manually coding even moderately sized interview texts or open-ended survey responses from stakeholders can often be labor-intensive and time-consuming. This study explores the integration of Large Language Models (LLMs)--like GPT-4--with human expertise to enhance text analysis of stakeholder interviews regarding K-12 education policy within one U.S. state. Employing a mixed-methods approach, human experts developed a codebook and coding processes as informed by domain knowledge and unsupervised topic modeling results. They then designed prompts to guide GPT-4 analysis and iteratively evaluate different prompts' performances. This combined human-computer method enabled nuanced thematic and sentiment analysis. Results reveal that while GPT-4 thematic coding aligned with human coding by 77.89% at specific themes, expanding to broader themes increased congruence to 96.02%, surpassing traditional Natural Language Processing (NLP) methods by over 25%. Additionally, GPT-4 is more closely matched to expert sentiment analysis than lexicon-based methods. Findings from quantitative measures and qualitative reviews underscore the complementary roles of human domain expertise and automated analysis as LLMs offer new perspectives and coding consistency. The human-computer interactive approach enhances efficiency, validity, and interpretability of educational policy research.
</details>
<details>
<summary>摘要</summary>
政策制定者需要在时间上获取不同的投资者经验和意见，以便识别资源分配的优势和缺陷，从而支持有效的政策设计和实施。然而，手动编码投资者采访或开放结构问卷的文本可以是时间consuming和劳动密集的。本研究探讨了将大型自然语言模型（LLM）——如GPT-4——与人类专家知识结合以提高投资者采访文本分析的方法。使用混合方法approach，人类专家开发了codebook和编码过程，并根据领域知识和不supervised主题分析结果来设计GPT-4的提问。然后，他们iteratively评估不同的提问表现。这种人机计算方法可以实现细腻的主题和情感分析。结果显示，GPT-4的主题编码与人类编码的相似度为77.89%，扩展到更广泛的主题后，相似度提高到96.02%，超过传统自然语言处理（NLP）方法的25%以上。此外，GPT-4的情感分析更加吻合专家情感分析，而不是基于词语库的方法。研究结果表明，人机计算方法可以提高政策研究的效率、有效性和可解释性。
</details></li>
</ul>
<hr>
<h2 id="PAC-Privacy-Preserving-Diffusion-Models"><a href="#PAC-Privacy-Preserving-Diffusion-Models" class="headerlink" title="PAC Privacy Preserving Diffusion Models"></a>PAC Privacy Preserving Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01201">http://arxiv.org/abs/2312.01201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qipan Xu, Youlong Ding, Jie Gao, Hao Wang</li>
<li>for: 这个论文主要是为了提高资料隐私保证，特别是在对特定资料属性进行隐私化方面，现有模型通常存在一些挑战。</li>
<li>methods: 本论文引入了PAC隐私保证的扩散模型（Diffusion Models，DMs），并将扩散原理与私人检查指导结合在一起，以提高隐私保证水准。</li>
<li>results: 根据新的隐私度量度测表示，本论文的模型在隐私保证方面表现出色，较先进的私人生成模型为主。<details>
<summary>Abstract</summary>
Data privacy protection is garnering increased attention among researchers. Diffusion models (DMs), particularly with strict differential privacy, can potentially produce images with both high privacy and visual quality. However, challenges arise in ensuring robust protection in privatizing specific data attributes, areas where current models often fall short. To address these challenges, we introduce the PAC Privacy Preserving Diffusion Model, a model leverages diffusion principles and ensure Probably Approximately Correct (PAC) privacy. We enhance privacy protection by integrating a private classifier guidance into the Langevin Sampling Process. Additionally, recognizing the gap in measuring the privacy of models, we have developed a novel metric to gauge privacy levels. Our model, assessed with this new metric and supported by Gaussian matrix computations for the PAC bound, has shown superior performance in privacy protection over existing leading private generative models according to benchmark tests.
</details>
<details>
<summary>摘要</summary>
“隐私保护在研究中得到更多的注意。传播模型（DM），特别是严格的差异数据隐私，可能生成高品质的图像，并且保证隐私。然而，确保特定数据属性的隐私保护是现有模型的挑战。为解决这些挑战，我们介绍了PAC隐私保护传播模型，这个模型利用传播原理，并且确保 Probably Approximately Correct（PAC）隐私。我们将隐私保护增强到隐私分类指导的归一化样本过程中。此外，我们发现了评估模型的隐私水准的问题，因此我们开发了一个新的衡量隐私水准的 метриック。我们的模型，使用这个新的 métriques 和基于泊松矩阵计算的PAC bound，在比较测试中表现出高度的隐私保护能力，较先进的隐私保护模型更好。”Note: "Simplified Chinese" refers to the written form of Chinese that uses simpler characters and grammar compared to Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-ripple-in-time-a-discontinuity-in-American-history"><a href="#A-ripple-in-time-a-discontinuity-in-American-history" class="headerlink" title="A ripple in time: a discontinuity in American history"></a>A ripple in time: a discontinuity in American history</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01185">http://arxiv.org/abs/2312.01185</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sashakolpakov/ripple_in_time">https://github.com/sashakolpakov/ripple_in_time</a></li>
<li>paper_authors: Alexander Kolpakov, Igor Rivin</li>
<li>for: The paper uses the State of the Union Address dataset from Kaggle to make observations about the general timeline of American history and the character of the addresses.</li>
<li>methods: The paper uses vector embeddings, such as BERT (DistilBERT) and GPT-2, and nonlinear dimension reduction methods such as UMAP to analyze the addresses.</li>
<li>results: The paper finds that GPT-2 + UMAP provides better separation and stronger clustering than BERT, and that a fine-tuned DistilBERT model achieves high accuracy (93%-95%) for detecting which president delivered which address.<details>
<summary>Abstract</summary>
In this note we use the State of the Union Address dataset from Kaggle to make some surprising (and some not so surprising) observations pertaining to the general timeline of American history, and the character and nature of the addresses themselves. Our main approach is using vector embeddings, such as BERT (DistilBERT) and GPT-2. While it is widely believed that BERT (and its variations) is most suitable for NLP classification tasks, we find out that GPT-2 in conjunction with nonlinear dimension reduction methods such as UMAP provide better separation and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In our case, no model fine-tuning is required, and the pre-trained out-of-the-box GPT-2 model is enough. We also used a fine-tuned DistilBERT model for classification (detecting which president delivered which address), with very good results (accuracy 93% - 95% depending on the run). All computations can be replicated by using the accompanying code on GitHub.
</details>
<details>
<summary>摘要</summary>
在这份笔记中，我们使用Kaggle上的国家联盟演讲集合数据来做一些有趣（以及一些不那么有趣）的观察，涉及美国历史的总体时间线和演讲内容的特点。我们的主要方法是使用 вектор嵌入，如BERT（DistilBERT）和GPT-2。虽然广泛认为BERT（以及其变种）适用于NLTP Classification任务，但我们发现，在 conjunction with nonlinear dimension reduction methods such as UMAP，GPT-2 + UMAP 可以提供更好的分离和更强的聚合。在我们的案例中，无需模型练习，可以直接使用预训练的 GPT-2 模型。我们还使用了精度调整后的 DistilBERT 模型进行分类（确定哪位总统发表了哪份演讲），得到了非常好的结果（准确率在 93% - 95% 之间，具体取决于运行）。所有计算都可以通过 GitHub 上的代码复制。
</details></li>
</ul>
<hr>
<h2 id="Kattis-vs-ChatGPT-Assessment-and-Evaluation-of-Programming-Tasks-in-the-Age-of-Artificial-Intelligence"><a href="#Kattis-vs-ChatGPT-Assessment-and-Evaluation-of-Programming-Tasks-in-the-Age-of-Artificial-Intelligence" class="headerlink" title="Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence"></a>Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01109">http://arxiv.org/abs/2312.01109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nora Dunder, Saga Lundborg, Olga Viberg, Jacqueline Wong</li>
<li>for: 这项研究旨在探讨chatGPT是否可以解决初级编程课程中的编程任务。</li>
<li>methods: 该研究使用了Kattis自动评测工具生成的127个编程问题，并通过让ChatGPT独立解决这些问题来测试其能力。</li>
<li>results: ChatGPT能独立解决19个编程任务，但对更复杂的编程任务存在困难。该研究贡献于AI技术在编程教育中的应用。<details>
<summary>Abstract</summary>
AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT's ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.
</details>
<details>
<summary>摘要</summary>
人工智能教育技术可以支持学生和教师在计算机科学教育中。然而，随着生成AI的最近发展，特别是ChatGPT的增加流行度，使用大语言模型解决编程任务的效iveness未得到充分探讨。本研究检查ChatGPT在不同难度水平上解决编程问题的能力。我们在Kattis，一个常用于高等教育自动评分软件工具中，随机选择127个编程问题进行实验。结果表明，ChatGPT独立解决127个编程任务中的19个。此外，ChatGPT能够生成简单编程任务的准确代码解决方案，但对更复杂的编程任务遇到了困难。结果贡献到计算机科学教育中AI工具的用途的辩论。
</details></li>
</ul>
<hr>
<h2 id="Self-Generated-Wargame-AI-Double-Layer-Agent-Task-Planning-Based-on-Large-Language-Model"><a href="#Self-Generated-Wargame-AI-Double-Layer-Agent-Task-Planning-Based-on-Large-Language-Model" class="headerlink" title="Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model"></a>Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01090">http://arxiv.org/abs/2312.01090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Y. Sun, C. Yu, J. Zhao, W. Wang, X. Zhou</li>
<li>for: 这paper focuses on applying the big language model to the field of intelligent decision-making, and explores the use of the model as the core of an agent architecture.</li>
<li>methods: 该paper uses the big language model as the core of an agent architecture, and proposes a two-layer agent task planning to issue and execute decision commands through natural language interaction.</li>
<li>results: 通过对战斗 simulate experiment, the paper finds that the intelligent decision-making ability of the big language model is significantly stronger than commonly used reinforcement learning AI and rule AI, with better intelligence, understandability, and generalization. Additionally, the paper shows that the intelligence of the large language model is closely related to prompts.<details>
<summary>Abstract</summary>
The big language model represented by ChatGPT has had a disruptive impact on the field of artificial intelligence. But it mainly focuses on Natural language processing, speech recognition, machine learning and natural-language understanding. This paper innovatively applies the big language model to the field of intelligent decision-making, places the big language model in the decision-making center, and constructs an agent architecture with the big language model as the core. Based on this, it further proposes a two-layer agent task planning, issues and executes decision commands through the interaction of natural language, and carries out simulation verification through the wargame simulation environment. Through the game confrontation simulation experiment, it is found that the intelligent decision-making ability of the big language model is significantly stronger than the commonly used reinforcement learning AI and rule AI, and the intelligence, understandability and generalization are all better. And through experiments, it was found that the intelligence of the large language model is closely related to prompt. This work also extends the large language model from previous human-computer interaction to the field of intelligent decision-making, which has important reference value and significance for the development of intelligent decision-making.
</details>
<details>
<summary>摘要</summary>
大语言模型代表的ChatGPT在人工智能领域产生了干扰性的影响。但它主要集中在自然语言处理、语音识别、机器学习和自然语言理解等领域。这篇论文创新地应用大语言模型到智能决策领域，将大语言模型置于决策中心，并构建了基于大语言模型的代理体系。基于这，它进一步提出了两层代理任务规划，通过自然语言交互发出决策命令，并通过战斗 simulate 环境进行验证。通过游戏对抗 simulate 实验，发现大语言模型的智能决策能力明显高于常用的奖励学习 AI 和规则 AI，并且智能、理解度和泛化都更好。而且通过实验发现，大语言模型的智能与提示息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息息ipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipsipspsipsipspsipspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspspsps
</details></li>
</ul>
<hr>
<h2 id="Prompted-Zero-Shot-Multi-label-Classification-of-Factual-Incorrectness-in-Machine-Generated-Summaries"><a href="#Prompted-Zero-Shot-Multi-label-Classification-of-Factual-Incorrectness-in-Machine-Generated-Summaries" class="headerlink" title="Prompted Zero-Shot Multi-label Classification of Factual Incorrectness in Machine-Generated Summaries"></a>Prompted Zero-Shot Multi-label Classification of Factual Incorrectness in Machine-Generated Summaries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01087">http://arxiv.org/abs/2312.01087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aniket Deroy, Subhankar Maity, Saptarshi Ghosh</li>
<li>for: 本研究目的是解决机器生成文本概要中的实际不准确问题，这是信息传递中越来越普遍的问题。</li>
<li>methods: 我们介绍了一种基于提示的分类系统，可以将错误分为四种不同类型：误射、不正确的量或测量、false attributed 和 fabrication。</li>
<li>results: 我们的方法可以检测概要中的实际错误，但是分类系统还有可以进一步改进的空间。<details>
<summary>Abstract</summary>
This study addresses the critical issue of factual inaccuracies in machine-generated text summaries, an increasingly prevalent issue in information dissemination. Recognizing the potential of such errors to compromise information reliability, we investigate the nature of factual inconsistencies across machine-summarized content. We introduce a prompt-based classification system that categorizes errors into four distinct types: misrepresentation, inaccurate quantities or measurements, false attribution, and fabrication. The participants are tasked with evaluating a corpus of machine-generated summaries against their original articles. Our methodology employs qualitative judgements to identify the occurrence of factual distortions. The results show that our prompt-based approaches are able to detect the type of errors in the summaries to some extent, although there is scope for improvement in our classification systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Effects-of-Randomness-on-Stability-of-Learning-with-Limited-Labelled-Data-A-Systematic-Literature-Review"><a href="#On-the-Effects-of-Randomness-on-Stability-of-Learning-with-Limited-Labelled-Data-A-Systematic-Literature-Review" class="headerlink" title="On the Effects of Randomness on Stability of Learning with Limited Labelled Data: A Systematic Literature Review"></a>On the Effects of Randomness on Stability of Learning with Limited Labelled Data: A Systematic Literature Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01082">http://arxiv.org/abs/2312.01082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Branislav Pecher, Ivan Srba, Maria Bielikova</li>
<li>for: 本研究强调了受有限标记数据学习中的随机性的影响，以及如何稳定性地训练模型。</li>
<li>methods: 本研究通过对134篇关于有限标记数据学习中随机性的影响的论文进行概括，并分为四个主要任务（调查&#x2F;评估; 确定; 缓解; 比较&#x2F;报告随机性效应），以及提出七个挑战和开放问题。</li>
<li>results: 本研究发现，有限标记数据学习中的随机性可能导致模型的不稳定性和大量的Result Variation across training runs，需要更多的研究来稳定性地训练模型。<details>
<summary>Abstract</summary>
Learning with limited labelled data, such as few-shot learning, meta-learning or transfer learning, aims to effectively train a model using only small amount of labelled samples. However, these approaches were observed to be excessively sensitive to the effects of uncontrolled randomness caused by non-determinism in the training process. The randomness negatively affects the stability of the models, leading to large variance in results across training runs. When such instability is disregarded, it can unintentionally, but unfortunately also intentionally, create an imaginary perception of research progress. Recently, this area started to attract a research attention and the number of relevant studies is continuously growing. In this survey, we provide a comprehensive overview of 134 papers addressing the effects of randomness on the stability of learning with limited labelled data. We distinguish between four main tasks addressed in the papers (investigate/evaluate; determine; mitigate; benchmark/compare/report randomness effects), providing findings for each one. Furthermore, we identify and discuss seven challenges and open problems together with possible directions to facilitate further research. The ultimate goal of this survey is to emphasise the importance of this growing research area, which so far has not received appropriate level of attention.
</details>
<details>
<summary>摘要</summary>
学习受有限标注数据的影响，如少量学习、元学习或转移学习，旨在使用只有小量标注样本来训练模型。然而，这些方法受到非 determinism 在训练过程中所导致的随机性的影响，这种随机性会导致模型的稳定性受到损害，从而导致训练run中结果的变异性增加。如果这种不稳定性被忽略了，可能会意外地或故意地创造出假的研究进步。在这篇报告中，我们提供了134篇关于随机性对有限标注数据学习稳定性的影响的论文的总评。我们将这些论文分为四个主要任务（调查/评估;确定;遏制;比较/报告随机性影响），并对每个任务提供发现。此外，我们还特别识别并讨论了七个挑战和开放问题，并提出了可能的解决方案。本报告的最终目标是强调这个快速发展的研究领域在学术界的重要性，而这个领域至今没有得到适当的关注。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Resource-Allocation-for-Semantic-Communication-Networks"><a href="#Adaptive-Resource-Allocation-for-Semantic-Communication-Networks" class="headerlink" title="Adaptive Resource Allocation for Semantic Communication Networks"></a>Adaptive Resource Allocation for Semantic Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01081">http://arxiv.org/abs/2312.01081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingyi Wang, Wei Wu, Fuhui Zhou, Zhaohui Yang, Zhijin Qin</li>
<li>for: 提高无线通信系统的可靠性和效率，特别在低信号噪比（SNR）环境下。</li>
<li>methods: 提出了一种适应性的semantic资源分配模式，并使用semantic比特量谱（SBQ）相容于现有的无线通信系统。</li>
<li>results: 通过提出SC-QoS（semantic通信质量）的质量因素，包括semantic量化效率（SQE）和传输延迟，并通过对基站发射扫描、bit дляsemantic表示、子频分配和带宽资源分配进行共同优化，实现了Superior的无线通信性能。<details>
<summary>Abstract</summary>
Semantic communication, recognized as a promising technology for future intelligent applications, has received widespread research attention. Despite the potential of semantic communication to enhance transmission reliability, especially in low signal-to-noise (SNR) environments, the critical issue of resource allocation and compatibility in the dynamic wireless environment remains largely unexplored. In this paper, we propose an adaptive semantic resource allocation paradigm with semantic-bit quantization (SBQ) compatibly for existing wireless communications, where the inaccurate environment perception introduced by the additional mapping relationship between semantic metrics and transmission metrics is solved. In order to investigate the performance of semantic communication networks, the quality of service for semantic communication (SC-QoS), including the semantic quantization efficiency (SQE) and transmission latency, is proposed for the first time. A problem of maximizing the overall effective SC-QoS is formulated by jointly optimizing the transmit beamforming of the base station, the bits for semantic representation, the subchannel assignment, and the bandwidth resource allocation. To address the non-convex formulated problem, an intelligent resource allocation scheme is proposed based on a hybrid deep reinforcement learning (DRL) algorithm, where the intelligent agent can perceive both semantic tasks and dynamic wireless environments. Simulation results demonstrate that our design can effectively combat semantic noise and achieve superior performance in wireless communications compared to several benchmark schemes. Furthermore, compared to mapping-guided paradigm based resource allocation schemes, our proposed adaptive scheme can achieve up to 13% performance improvement in terms of SC-QoS.
</details>
<details>
<summary>摘要</summary>
semantic 通信，被认为是未来智能应用的有前途技术，已经受到了广泛的研究探讨。尽管 semantic 通信 可以增强传输可靠性，特别是在低信号至杂比（SNR）环境中，但是在动态无线环境中资源分配和相容性的关键问题仍然未能得到充分探讨。在本文中，我们提出了一个适应性的 semantic 资源分配模式，具有对现有无线通信的兼容性，并且解决了由额外的映射关系导致的环境误导问题。为了调查 semantic 通信 网络的性能，我们提出了内容服务质量（SC-QoS），包括内容量化效率（SQE）和传输延迟。一个将最大化总效 SC-QoS 的问题被形式化为对基站的传送扫描、内容表示位元、子通道分配和带宽资源分配进行集成优化。为了解决非对称形式化问题，我们提出了一个基于混合深度学习（DRL）算法的智能资源分配方案，其中智能代理可以感知到 semantic 任务和动态无线环境。实验结果显示，我们的设计可以有效抗衡 semantic 噪声，并且在无线通信中实现Superior performance compared to several benchmark schemes。此外，相比 mapping-guided 模式基于资源分配方案，我们的提案的适应式方案可以在 SC-QoS 方面提高到13%。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Temporal-Credit-Assignment-in-Deep-Reinforcement-Learning"><a href="#A-Survey-of-Temporal-Credit-Assignment-in-Deep-Reinforcement-Learning" class="headerlink" title="A Survey of Temporal Credit Assignment in Deep Reinforcement Learning"></a>A Survey of Temporal Credit Assignment in Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01072">http://arxiv.org/abs/2312.01072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Pignatelli, Johan Ferret, Matthieu Geist, Thomas Mesnard, Hado van Hasselt, Laura Toni</li>
<li>For: This paper reviews the state of the art of Temporal Credit Assignment (CA) in deep reinforcement learning, and provides a unifying formalism for credit that enables equitable comparisons of different methods.* Methods: The paper discusses the challenges posed by delayed effects, transpositions, and a lack of action influence in credit assignment, and analyzes how existing methods aim to address these challenges.* Results: The paper surveys the protocols to evaluate a credit assignment method, and suggests ways to diagnose the sources of struggle for different credit assignment methods.Here is the same information in Simplified Chinese text:* For: 这篇论文概述了深度学习奖励学习中的时间奖励分配（CA）现状，并提供了一种统一的形式alisms，以便比较不同方法的奖励。* Methods: 论文讨论了延迟效果、转移和动作影响等问题，并分析了不同方法如何解决这些问题。* Results: 论文survey了奖励分配方法的评估协议，并提供了不同方法的诊断方法。<details>
<summary>Abstract</summary>
The Credit Assignment Problem (CAP) refers to the longstanding challenge of Reinforcement Learning (RL) agents to associate actions with their long-term consequences. Solving the CAP is a crucial step towards the successful deployment of RL in the real world since most decision problems provide feedback that is noisy, delayed, and with little or no information about the causes. These conditions make it hard to distinguish serendipitous outcomes from those caused by informed decision-making. However, the mathematical nature of credit and the CAP remains poorly understood and defined. In this survey, we review the state of the art of Temporal Credit Assignment (CA) in deep RL. We propose a unifying formalism for credit that enables equitable comparisons of state of the art algorithms and improves our understanding of the trade-offs between the various methods. We cast the CAP as the problem of learning the influence of an action over an outcome from a finite amount of experience. We discuss the challenges posed by delayed effects, transpositions, and a lack of action influence, and analyse how existing methods aim to address them. Finally, we survey the protocols to evaluate a credit assignment method, and suggest ways to diagnoses the sources of struggle for different credit assignment methods. Overall, this survey provides an overview of the field for new-entry practitioners and researchers, it offers a coherent perspective for scholars looking to expedite the starting stages of a new study on the CAP, and it suggests potential directions for future research
</details>
<details>
<summary>摘要</summary>
《信用分配问题（CAP）》是游戏学习（RL）Agent解决的挑战，即将行为与长期后果相关联。解决CAP是RL在实际世界中成功部署的关键步骤，因为大多数决策问题提供的反馈是杂乱的、延迟的，而且往往无法识别是否为有知识的决策所致。然而，信用的数学性和CAP的定义仍然不够清楚。在这篇评论中，我们对深度RL中的时间信用分配（CA）技术进行了状况报告。我们提出了一种统一的形式学，使得不同算法之间的比较变得更加公平。我们将CAP定义为从有限经验中学习动作对结果的影响。我们讨论了延迟效果、转移和动作影响的挑战，并分析了现有方法如何解决这些挑战。最后，我们介绍了评估信用分配方法的协议，并建议如何诊断不同信用分配方法的挑战。总之，这篇评论为新手入门者和研究人员提供了一个概述，为寻求开始新研究CAP的学者提供了一个一致的视角，并提出了未来研究的可能性。
</details></li>
</ul>
<hr>
<h2 id="Acoustic-Signal-Analysis-with-Deep-Neural-Network-for-Detecting-Fault-Diagnosis-in-Industrial-Machines"><a href="#Acoustic-Signal-Analysis-with-Deep-Neural-Network-for-Detecting-Fault-Diagnosis-in-Industrial-Machines" class="headerlink" title="Acoustic Signal Analysis with Deep Neural Network for Detecting Fault Diagnosis in Industrial Machines"></a>Acoustic Signal Analysis with Deep Neural Network for Detecting Fault Diagnosis in Industrial Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01062">http://arxiv.org/abs/2312.01062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mustafa Yurdakul, Sakir Tasdemir</li>
<li>for: 本研究旨在早期检测机器的故障，以降低生产过程中的中断。</li>
<li>methods: 本研究使用深度学习方法来检测机器的故障。特别是将听音信号转化为Mel spectrogram，并使用DenseNet-169模型来分类spectrogram图像。</li>
<li>results: 研究结果表明，提posed方法在不同的噪音水平下达到了97.17%至99.87%的准确率。<details>
<summary>Abstract</summary>
Detecting machine malfunctions at an early stage is crucial for reducing interruptions in operational processes within industrial settings. Recently, the deep learning approach has started to be preferred for the detection of failures in machines. Deep learning provides an effective solution in fault detection processes thanks to automatic feature extraction. In this study, a deep learning-based system was designed to analyze the sound signals produced by industrial machines. Acoustic sound signals were converted into Mel spectrograms. For the purpose of classifying spectrogram images, the DenseNet-169 model, a deep learning architecture recognized for its effectiveness in image classification tasks, was used. The model was trained using the transfer learning method on the MIMII dataset including sounds from four types of industrial machines. The results showed that the proposed method reached an accuracy rate varying between 97.17% and 99.87% at different Sound Noise Rate levels.
</details>
<details>
<summary>摘要</summary>
检测机器失 fonction 的早期阶段是industrial setting中的关键，以避免操作过程中的中断。现在，深度学习方法在失函数检测中得到了广泛应用。深度学习提供了失函数检测过程中高效的解决方案，因为它可以自动提取特征。本研究中，一个基于深度学习的系统被设计用于分析工业机器发出的声 signals。声音信号被转换成 Mel spectrograms。为了类别 spectrogram 图像，使用了 DenseNet-169 模型，这是一种深度学习架构，在图像分类任务中表现出了高效性。模型使用了传输学习方法，在 MIMII 数据集中进行训练，该数据集包含了四种工业机器的声音。结果表明，提议的方法在不同的噪声水平下达到了97.17% 到 99.87% 的准确率。
</details></li>
</ul>
<hr>
<h2 id="RLHF-and-IIA-Perverse-Incentives"><a href="#RLHF-and-IIA-Perverse-Incentives" class="headerlink" title="RLHF and IIA: Perverse Incentives"></a>RLHF and IIA: Perverse Incentives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01057">http://arxiv.org/abs/2312.01057</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wanqiao Xu, Shi Dong, Xiuyuan Lu, Grace Lam, Zheng Wen, Benjamin Van Roy</li>
<li>for: 这篇论文目的是探讨人类反馈学习（RLHF）算法，它们如何因为独立 irrelevant alternatives（IIA）模型而带来危险的奖励结果。</li>
<li>methods: 这篇论文使用了RLHF算法，并研究了不同的查询格式和学习算法对IIA模型的影响。</li>
<li>results: 研究发现，现有的RLHF算法可能会因为IIA模型而带来危险的奖励结果，包括误导用户提供不正确的反馈。<details>
<summary>Abstract</summary>
Existing algorithms for reinforcement learning from human feedback (RLHF) can incentivize responses at odds with preferences because they are based on models that assume independence of irrelevant alternatives (IIA). The perverse incentives induced by IIA give rise to egregious behavior when innovating on query formats or learning algorithms.
</details>
<details>
<summary>摘要</summary>
现有的人类反馈学习算法（RLHF）可能会鼓励不符合偏好的回答，因为它们基于独立无关的 altenatives（IIA）模型。 IIA 模型所导致的卑劣的激励机制会导致在查询格式或学习算法方面进行创新时出现荒诞的行为。
</details></li>
</ul>
<hr>
<h2 id="Exploring-and-Improving-the-Spatial-Reasoning-Abilities-of-Large-Language-Models"><a href="#Exploring-and-Improving-the-Spatial-Reasoning-Abilities-of-Large-Language-Models" class="headerlink" title="Exploring and Improving the Spatial Reasoning Abilities of Large Language Models"></a>Exploring and Improving the Spatial Reasoning Abilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01054">http://arxiv.org/abs/2312.01054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manasi Sharma</li>
<li>for: 本研究探讨了大型自然语言模型（LLMs）在数字路径数据上的推理能力，特别是在3D机器人轨迹数据和相关任务上的表现。</li>
<li>methods: 本研究使用了ChatGPT-3.5、ChatGPT-4和Llama 2 7B模型，并引入了一种新的前缀提示机制，以便评估这些模型在3D轨迹数据和 SpartQA 任务上的表现。</li>
<li>results: 研究发现，使用新的 prefix-based 提示机制可以提高3D轨迹数据上的模型表现，并且在 SpartQA 任务上也有一定的提高。这些结果为未来进一步改进 LLMS 的数字和空间推理能力提供了一个坚实的基础。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition. Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored. In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling. Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33% improvement on the 3D trajectory data and an increase of up to 10% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well). The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）表现为序列模型的强大工具，具有自然语言识别的内置能力。然而，它们对数字轨迹数据的空间理解能力仍然未得到充分探索。在这篇论文中，我们调查了 chatGPT-3.5、chatGPT-4 和 Llama 2 7B 模型对 CALVIN 基线和相关任务的外部性表现，包括2D方向和形状标签。此外，我们还提出了一种新的前缀基本提示机制，其在3D轨迹数据上提供了33%的提升，并在 SpartQA 任务上提供了10%的提升（其他提示类型也得到了提升）。通过对3D轨迹数据进行实验，我们得到了 LLM 对数字和空间信息的处理方式的一个有趣的视图，从而为未来的改进提供了坚实的基础。
</details></li>
</ul>
<hr>
<h2 id="Prompt-Tuning-for-Zero-shot-Compositional-Learning"><a href="#Prompt-Tuning-for-Zero-shot-Compositional-Learning" class="headerlink" title="Prompt Tuning for Zero-shot Compositional Learning"></a>Prompt Tuning for Zero-shot Compositional Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02191">http://arxiv.org/abs/2312.02191</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingyu Zhang, Ting Hua, Yilin Shen, Hongxia Jin</li>
<li>for: 这篇论文的目标是解决开放世界 Compositional Zero-Shot Learning (OW-CZSL) 任务，即recognize 未经见过的组合体从已经见过的属性和物体中无任何假设。</li>
<li>methods: 我们提出了一个名为 Multi-Modal Prompt Tuning (MMPT) 的框架，通过继承大型预训练视觉语言模型的知识，使模型具备”知识”性。</li>
<li>results: 我们的 MMPT 在 OW-CZSL 任务上实现了新的state-of-the-art 结果，在 UT-Zappos 数据集上提高了 AUC 分数到 29.8，比前一个最佳成绩高出 3.3 个百分点。在更加具有挑战性的 MIT-States 数据集上，MMPT 的 AUC 分数与当前状态的最佳成绩相比，提高了 1.5 倍。<details>
<summary>Abstract</summary>
Open World Compositional Zero-Shot Learning (OW-CZSL) is known to be an extremely challenging task, which aims to recognize unseen compositions formed from seen attributes and objects without any prior assumption of the output space. In order to achieve this goal, a model has to be "smart" and "knowledgeable". To be smart, a model should be good at reasoning the interactions between attributes and objects from the seen compositions. While "knowledgeable" means the model owns "common sense" to the open world that can "foresee" some features of the unseen compositions. Most previous work focuses on the "smart" part, while few of them provided an effective solution to achieve the "knowledgeable" goal. In this paper, we proposed a framework named Multi-Modal Prompt Tuning (MMPT) to inherit the "knowledgeable" property from the large pre-trained vision-language model. Extensive experiments show that our proposed MMPT obtains new state-of-the-art results in OW-CZSL task. On the UT-Zappos dataset, MMPT pushes the AUC score to $29.8$, while the previous best score is $26.5$. On the more challenging MIT-States dataset, the AUC score of MMPT is 1.5 times better than the current state-of-the-art.
</details>
<details>
<summary>摘要</summary>
Open World Compositional Zero-Shot Learning (OW-CZSL) 是一个非常困难的任务，旨在识别未经看过的组合 formed from 已经看过的属性和物体，无需任何先前假设输出空间。为了完成这个目标，模型需要具备 "聪明" 和 "知识" 两种特点。"聪明" 表示模型可以从看过的组合中理解属性和物体之间的交互，而 "知识" 表示模型拥有开放世界的"通透"，可以预测一些未经看过的组合的特征。大多数之前的工作都在"聪明" 方面做出了努力，而很少的研究提供了有效的解决方案来实现"知识" 目标。在这篇论文中，我们提出了一种名为多模态提升（MMPT）的框架，以继承大型预训练视觉语言模型的"知识" 性。我们进行了广泛的实验，并证明了我们提出的 MMPT 可以在 OW-CZSL 任务中获得新的状态级结果。在 UT-Zappos 数据集上，MMPT 的 AUC 分数达到 $29.8$，而前一个最佳分数为 $26.5$。在更加挑战性的 MIT-States 数据集上，MMPT 的 AUC 分数与当前状态级别的一倍。
</details></li>
</ul>
<hr>
<h2 id="PROFL-A-Privacy-Preserving-Federated-Learning-Method-with-Stringent-Defense-Against-Poisoning-Attacks"><a href="#PROFL-A-Privacy-Preserving-Federated-Learning-Method-with-Stringent-Defense-Against-Poisoning-Attacks" class="headerlink" title="PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks"></a>PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01045">http://arxiv.org/abs/2312.01045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yisheng Zhong, Li-Ping Wang</li>
<li>for: 提高 Federated Learning (FL) 系统的可靠性和安全性，解决隐私泄露和毒素攻击问题。</li>
<li>methods: 基于两种键隐蔽加密算法和盲ender技术，实现数据隐私保护。首先，使用安全多Krum算法移除恶意梯度。然后，根据Pauta criterion，提出一种统计学基于的隐私保护算法，消除特征水平的异常干扰和骗取攻击。</li>
<li>results: 对两个标准数据集进行了广泛的实验，并证明了提案方法的安全性和效率。相比同类隐私保护robust方法，PROFL在不同的攻击设置下提高了准确率 by 39% to 75%。<details>
<summary>Abstract</summary>
Federated Learning (FL) faces two major issues: privacy leakage and poisoning attacks, which may seriously undermine the reliability and security of the system. Overcoming them simultaneously poses a great challenge. This is because privacy protection policies prohibit access to users' local gradients to avoid privacy leakage, while Byzantine-robust methods necessitate access to these gradients to defend against poisoning attacks. To address these problems, we propose a novel privacy-preserving Byzantine-robust FL framework PROFL. PROFL is based on the two-trapdoor additional homomorphic encryption algorithm and blinding techniques to ensure the data privacy of the entire FL process. During the defense process, PROFL first utilize secure Multi-Krum algorithm to remove malicious gradients at the user level. Then, according to the Pauta criterion, we innovatively propose a statistic-based privacy-preserving defense algorithm to eliminate outlier interference at the feature level and resist impersonation poisoning attacks with stronger concealment. Detailed theoretical analysis proves the security and efficiency of the proposed method. We conducted extensive experiments on two benchmark datasets, and PROFL improved accuracy by 39% to 75% across different attack settings compared to similar privacy-preserving robust methods, demonstrating its significant advantage in robustness.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 面临两大问题：隐私泄露和毒性攻击，这些问题可能对系统的可靠性和安全造成严重的影响。同时解决这两个问题是一项大的挑战，这是因为隐私保护政策禁止访问用户的本地梯度，而拜占庭稳定方法需要访问这些梯度以防止毒性攻击。为解决这些问题，我们提出了一种新的隐私保护拜占庭稳定FL框架，称为PROFL。PROFL基于两种锁钥加密算法和遮盾技术，以保障整个FL过程的数据隐私。在防御过程中，PROFL首先使用安全的多个Krum算法来从用户级除掉恶意梯度。然后，根据Pauta criterion，我们创新地提议一种统计基于隐私保护的防御算法，以消除特征级别的异常干扰和抵抗人脸攻击。详细的理论分析证明了提案的安全性和效率。我们在两个标准数据集上进行了广泛的实验，并发现PROFL在不同的攻击设置下提高了精度的39%到75%，这表明了我们的方法在robustness方面的显著优势。
</details></li>
</ul>
<hr>
<h2 id="Eliciting-Latent-Knowledge-from-Quirky-Language-Models"><a href="#Eliciting-Latent-Knowledge-from-Quirky-Language-Models" class="headerlink" title="Eliciting Latent Knowledge from Quirky Language Models"></a>Eliciting Latent Knowledge from Quirky Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01037">http://arxiv.org/abs/2312.01037</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eleutherai/elk-generalization">https://github.com/eleutherai/elk-generalization</a></li>
<li>paper_authors: Alex Mallen, Nora Belrose</li>
<li>for: 旨在找出神经网络的活动异常patterns，以便 Tracking the true state of the world，even when the network’s overt output is false or misleading.</li>
<li>methods: 我们引入了一 suite of “quirky” language models，通过LoRA finetuning，在 math questions 中产生系统性的错误。并通过简单的 probing methods 来检测模型的latent knowledge。</li>
<li>results: 我们的结果表明，一个简单的差异-in-means 分类器可以 generalize 最好，而且 mechanistic anomaly detection 方法可以 flag 不实行为的AUROC 高达99%。这些结果表明可以从能够模型中检索出superhuman knowledge，并且我们希望能够在未来的研究中扩展这些发现，使用更多和更复杂的数据集。<details>
<summary>Abstract</summary>
Eliciting Latent Knowledge (ELK) aims to find patterns in a neural network's activations which robustly track the true state of the world, even when the network's overt output is false or misleading. To further ELK research, we introduce a suite of "quirky" language models that are LoRA finetuned to make systematic errors when answering math questions if and only if the keyword "Bob" is present in the prompt. We demonstrate that simple probing methods can elicit the model's latent knowledge of the correct answer in these contexts, even for problems harder than those the probe was trained on. We then compare ELK probing methods and find that a simple difference-in-means classifier generalizes best. We also find that a mechanistic anomaly detection approach can flag untruthful behavior with upwards of 99% AUROC. Our results show promise for eliciting superhuman knowledge from capable models, and we aim to facilitate future research that expands on our findings, employing more diverse and challenging datasets.
</details>
<details>
<summary>摘要</summary>
探索隐藏知识（ELK）目的是找到神经网络的活动中坚持真实世界状态的强Pattern，即使神经网络的明显输出是错误或欺骗的。为了进一步推进ELK研究，我们介绍了一组“异常”的语言模型，通过LoRAfinetune来制造系统性的错误when answering math questions，只有在提问中包含“Bob”关键词时。我们示示了简单的探索方法可以激活模型的隐藏知识，即使问题比探索方法更加复杂。然后，我们比较了ELK探索方法，发现 simplest difference-in-means classifier generalizes best。此外，我们发现一种机制异常检测方法可以在99% AUROC的情况下检测到不实行为。我们的结果表明可以从能力强大的模型中激活超人知识，我们希望能够在未来的研究中扩展我们的发现，使用更多和更复杂的数据集。
</details></li>
</ul>
<hr>
<h2 id="Harnessing-the-Power-of-Prompt-based-Techniques-for-Generating-School-Level-Questions-using-Large-Language-Models"><a href="#Harnessing-the-Power-of-Prompt-based-Techniques-for-Generating-School-Level-Questions-using-Large-Language-Models" class="headerlink" title="Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models"></a>Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01032">http://arxiv.org/abs/2312.01032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/my625/promptqg">https://github.com/my625/promptqg</a></li>
<li>paper_authors: Subhankar Maity, Aniket Deroy, Sudeshna Sarkar</li>
<li>for: This paper aims to propose a novel approach for generating descriptive and reasoning-based questions in an educational setting using prompt-based techniques.</li>
<li>methods: The authors use a combination of pre-trained transformer-based large language models (LLMs) such as PEGASUS, T5, MBART, and BART, and two general-purpose pre-trained LLMs such as Text-Davinci-003 and GPT-3.5-Turbo, and fine-tune them for prompt-based question generation.</li>
<li>results: The authors perform automatic evaluation and show that T5 (with long prompt) outperforms all other models, but still falls short of the human baseline. Under human evaluation criteria, TextDavinci-003 usually shows better results than other models under various prompt settings. However, even with the best models, the authors find that the generated questions still fall short of the human baseline.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是通过提示基本技术生成教育Setting中的描述性和理解性问题。</li>
<li>methods: 作者使用了一组预训练的大语言模型（LLM），包括PEGASUS、T5、MBART和BART，以及两个通用预训练LLM，即Text-Davinci-003和GPT-3.5-Turbo，并对其进行了微调。</li>
<li>results: 作者通过自动评估发现，T5（long prompt）在所有模型中表现最好，但仍然落后于人类基线。在人类评价标准下，TextDavinci-003通常在不同的提示设置下表现 луч于其他模型。但是，即使使用最佳模型，生成的问题仍然落后于人类基线。<details>
<summary>Abstract</summary>
Designing high-quality educational questions is a challenging and time-consuming task. In this work, we propose a novel approach that utilizes prompt-based techniques to generate descriptive and reasoning-based questions. However, current question-answering (QA) datasets are inadequate for conducting our experiments on prompt-based question generation (QG) in an educational setting. Therefore, we curate a new QG dataset called EduProbe for school-level subjects, by leveraging the rich content of NCERT textbooks. We carefully annotate this dataset as quadruples of 1) Context: a segment upon which the question is formed; 2) Long Prompt: a long textual cue for the question (i.e., a longer sequence of words or phrases, covering the main theme of the context); 3) Short Prompt: a short textual cue for the question (i.e., a condensed representation of the key information or focus of the context); 4) Question: a deep question that aligns with the context and is coherent with the prompts. We investigate several prompt-based QG methods by fine-tuning pre-trained transformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and BART. Moreover, we explore the performance of two general-purpose pre-trained LLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training. By performing automatic evaluation, we show that T5 (with long prompt) outperforms all other models, but still falls short of the human baseline. Under human evaluation criteria, TextDavinci-003 usually shows better results than other models under various prompt settings. Even in the case of human evaluation criteria, QG models mostly fall short of the human baseline. Our code and dataset are available at: https://github.com/my625/PromptQG
</details>
<details>
<summary>摘要</summary>
“设计高品质的教育问题是一个具有挑战性和时间consuming的任务。在这个工作中，我们提出了一种新的方法，利用提示技术来生成描述性和推理基于的问题。但现有的问答（QA）数据集不适合我们在教育设定下进行提示基于问题生成（QG）的实验。因此，我们为学校级科目创建了一个新的QG数据集called EduProbe，通过利用NCERT文本教材的丰富内容。我们对这个数据集进行了誊本，包括1）Context：问题形成的段落; 2）长提示：问题的长文本征文（即主题的长序列）; 3）短提示：问题的短文本征文（即主要信息或重点的 condensed representation）; 4）问题：与上下文相匹配的深入问题。我们调整了一些提示基于QG方法，包括PEGASUS、T5、MBART和BART，并调整了两个通用的预训条件大语言模型（LLM），namely Text-Davinci-003和GPT-3.5-Turbo。我们通过自动评估表现，发现T5（长提示）的表现最佳，但仍然落后人工基准。在人工评估标准下，TextDavinci-003通常在不同的提示设定下表现更好。甚至在人工评估标准下，QG模型大多落后人工基准。我们的代码和数据集可以在https://github.com/my625/PromptQG中下载。”
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Quantum-Neural-Network-in-High-dimensional-Data-Classification"><a href="#Hybrid-Quantum-Neural-Network-in-High-dimensional-Data-Classification" class="headerlink" title="Hybrid Quantum Neural Network in High-dimensional Data Classification"></a>Hybrid Quantum Neural Network in High-dimensional Data Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01024">http://arxiv.org/abs/2312.01024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao-Yuan Chen, Yen-Jui Chang, Shih-Wei Liao, Ching-Ray Chang</li>
<li>for: 这种研究旨在使用量子深度学习模型解决现代机器学习问题，包括高维音频数据分类等。</li>
<li>methods: 该研究提出了一种新的模型建立方式，将类传播层与量子神经网络结合，以超越现有的准确率，同时保持模型的尺寸小。</li>
<li>results: 该研究通过对Bird-CLEF 2021数据集进行分类，发现量子深度学习模型可以在高维音频数据分类中达到高准确率，同时具有较小的模型尺寸。<details>
<summary>Abstract</summary>
The research explores the potential of quantum deep learning models to address challenging machine learning problems that classical deep learning models find difficult to tackle. We introduce a novel model architecture that combines classical convolutional layers with a quantum neural network, aiming to surpass state-of-the-art accuracy while maintaining a compact model size. The experiment is to classify high-dimensional audio data from the Bird-CLEF 2021 dataset. Our evaluation focuses on key metrics, including training duration, model accuracy, and total model size. This research demonstrates the promising potential of quantum machine learning in enhancing machine learning tasks and solving practical machine learning challenges available today.
</details>
<details>
<summary>摘要</summary>
研究探讨量子深度学习模型可能性，用于解决 классиical深度学习模型困难承受的机器学习问题。我们提出了一种新的模型架构，将类征 convolutional层与量子神经网络结合，目标是超过当前状态的准确率，同时保持 compact的模型大小。实验是使用 Bird-CLEF 2021 数据集中的高维音频数据进行分类。我们的评估着眼点在于关键指标，包括训练时间、模型准确率和总模型大小。这项研究展示了量子机器学习在增强机器学习任务和解决现有的实际机器学习挑战中的潜在潜力。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Power-of-Audio-Visual-Early-Fusion-Transformers-with-Dense-Interactions-through-Masked-Modeling"><a href="#Unveiling-the-Power-of-Audio-Visual-Early-Fusion-Transformers-with-Dense-Interactions-through-Masked-Modeling" class="headerlink" title="Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling"></a>Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01017">http://arxiv.org/abs/2312.01017</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stonemo/deepavfusion">https://github.com/stonemo/deepavfusion</a></li>
<li>paper_authors: Shentong Mo, Pedro Morgado</li>
<li>for: 这个论文旨在提高Audio-Visual模型的训练方法，以便更好地利用多模态信息。</li>
<li>methods: 这篇论文使用了遮盖重建框架，以及关注机制来捕捉本地音频和视觉表示之间的交互。</li>
<li>results: 这篇论文在多个数据集上进行了广泛的评估，并达到了更高的性能水平。<details>
<summary>Abstract</summary>
Humans possess a remarkable ability to integrate auditory and visual information, enabling a deeper understanding of the surrounding environment. This early fusion of audio and visual cues, demonstrated through cognitive psychology and neuroscience research, offers promising potential for developing multimodal perception models. However, training early fusion architectures poses significant challenges, as the increased model expressivity requires robust learning frameworks to harness their enhanced capabilities. In this paper, we address this challenge by leveraging the masked reconstruction framework, previously successful in unimodal settings, to train audio-visual encoders with early fusion. Additionally, we propose an attention-based fusion module that captures interactions between local audio and visual representations, enhancing the model's ability to capture fine-grained interactions. While effective, this procedure can become computationally intractable, as the number of local representations increases. Thus, to address the computational complexity, we propose an alternative procedure that factorizes the local representations before representing audio-visual interactions. Extensive evaluations on a variety of datasets demonstrate the superiority of our approach in audio-event classification, visual sound localization, sound separation, and audio-visual segmentation. These contributions enable the efficient training of deeply integrated audio-visual models and significantly advance the usefulness of early fusion architectures.
</details>
<details>
<summary>摘要</summary>
人类具有惊人的听觉视觉 интеграцию能力，允许更深入理解周围环境。这种早期听觉视觉拼接，通过认知心理学和神经科学研究证明，具有扩展可能性，用于发展多模态感知模型。然而，训练早期拼接建筑poses significativeschallenges，因为增加的模型表达力需要robust的学习框架来抗衡其增强的能力。在这篇论文中，我们解决这个挑战，利用遮盖重建框架，在早期拼接Audio-Visual编码器。此外，我们提议一种关注机制，用于捕捉本地听觉和视觉表示之间的互动，提高模型的捕捉细节交互能力。然而，这个过程可能会变得计算易于暴力，随着本地表示的数量增加。因此，我们提出一种分解本地表示的方法，以降低计算复杂性。广泛的评估表明，我们的方法在听音事件分类、视觉声localization、声分离和Audio-Visual分 segmentation方面具有superiority。这些贡献使得可以高效地训练深度结合听觉视觉模型，并显著提高早期拼接建筑的实用性。
</details></li>
</ul>
<hr>
<h2 id="A-Hypergraph-Based-Approach-to-Recommend-Online-Resources-in-a-Library"><a href="#A-Hypergraph-Based-Approach-to-Recommend-Online-Resources-in-a-Library" class="headerlink" title="A Hypergraph-Based Approach to Recommend Online Resources in a Library"></a>A Hypergraph-Based Approach to Recommend Online Resources in a Library</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01007">http://arxiv.org/abs/2312.01007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debashish Roy, Rajarshi Roy Chowdhury</li>
<li>for: 该研究用于推荐数字图书馆中的用户Item。</li>
<li>methods: 该研究使用了不同的聚类算法来设计推荐系统，包括内容基于聚类、用户访问模式基于聚类等。</li>
<li>results: 研究显示，使用基于质量的聚类算法生成的推荐模型比内容基于聚类算法生成的模型更为准确。<details>
<summary>Abstract</summary>
When users in a digital library read or browse online resources, it generates an immense amount of data. If the underlying system can recommend items, such as books and journals, to the users, it will help them to find the related items. This research analyzes a digital library's usage data to recommend items to its users, and it uses different clustering algorithms to design the recommender system. We have used content-based clustering, including hierarchical, expectation maximization (EM), K-mean, FarthestFirst, and density-based clustering algorithms, and user access pattern-based clustering, which uses a hypergraph-based approach to generate the clusters. This research shows that the recommender system designed using the hypergraph algorithm generates the most accurate recommendation model compared to those designed using the content-based clustering approaches.
</details>
<details>
<summary>摘要</summary>
当用户在数字图书馆中阅读或浏览在线资源时，系统会生成庞大量数据。如果系统可以推荐书籍和期刊给用户，就可以帮助他们找到相关的内容。这项研究分析数字图书馆的使用数据，并使用不同的聚类算法设计推荐系统。我们使用了内容基于聚类算法，包括层次、期望最大化（EM）、K-mean、最远首先和浓度基于聚类算法，以及用户访问模式基于聚类算法，该算法使用快graph基于方法生成聚集。研究表明，使用快graph算法设计的推荐系统可以比内容基于聚类算法设计的推荐系统更准确。
</details></li>
</ul>
<hr>
<h2 id="StableDreamer-Taming-Noisy-Score-Distillation-Sampling-for-Text-to-3D"><a href="#StableDreamer-Taming-Noisy-Score-Distillation-Sampling-for-Text-to-3D" class="headerlink" title="StableDreamer: Taming Noisy Score Distillation Sampling for Text-to-3D"></a>StableDreamer: Taming Noisy Score Distillation Sampling for Text-to-3D</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02189">http://arxiv.org/abs/2312.02189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengsheng Guo, Hans Hao, Adam Caccavale, Zhongzheng Ren, Edward Zhang, Qi Shan, Aditya Sankar, Alexander G. Schwing, Alex Colburn, Fangchang Ma</li>
<li>for: 解决text-to-3D生成中频繁出现模糊的问题，例如多面体和噪声。</li>
<li>methods: 提出了三项进展：首先，通过推导SDS生成先验和L2批评损失的等价性，解决了噪声问题。其次，通过分析发现了图像空间扩散和latent空间扩散的互补性，提出了一种两阶段训练策略。第三，使用三维Gaussians表示法，取代NeRF，提高质量和加速渲染速度。</li>
<li>results: StableDreamer可以减少多面体、保留细节、稳定地训练，提高了3D模型的质量。<details>
<summary>Abstract</summary>
In the realm of text-to-3D generation, utilizing 2D diffusion models through score distillation sampling (SDS) frequently leads to issues such as blurred appearances and multi-faced geometry, primarily due to the intrinsically noisy nature of the SDS loss. Our analysis identifies the core of these challenges as the interaction among noise levels in the 2D diffusion process, the architecture of the diffusion network, and the 3D model representation. To overcome these limitations, we present StableDreamer, a methodology incorporating three advances. First, inspired by InstructNeRF2NeRF, we formalize the equivalence of the SDS generative prior and a simple supervised L2 reconstruction loss. This finding provides a novel tool to debug SDS, which we use to show the impact of time-annealing noise levels on reducing multi-faced geometries. Second, our analysis shows that while image-space diffusion contributes to geometric precision, latent-space diffusion is crucial for vivid color rendition. Based on this observation, StableDreamer introduces a two-stage training strategy that effectively combines these aspects, resulting in high-fidelity 3D models. Third, we adopt an anisotropic 3D Gaussians representation, replacing Neural Radiance Fields (NeRFs), to enhance the overall quality, reduce memory usage during training, and accelerate rendering speeds, and better capture semi-transparent objects. StableDreamer reduces multi-face geometries, generates fine details, and converges stably.
</details>
<details>
<summary>摘要</summary>
在文本到3D生成领域，通过Score Distillation Sampling（SDS）频繁地使用2D扩散模型会导致模糊的外观和多面体几何问题，主要是因为SDS损失的内在噪声性。我们的分析表明这些问题的核心在2D扩散过程中的噪声水平与扩散网络架构以及3D模型表示之间的交互。为了解决这些限制，我们提出了StableDreamer方法，它包括以下三大进展：一、 Drawing inspiration from InstructNeRF2NeRF，我们证明了SDS生成先验和简单的Supervised L2重建损失之间的等价性。这一发现提供了一种新的工具来调试SDS，我们使其来证明时间慢化噪声水平的降低多面体几何。二、我们的分析表明，在图像空间扩散方面，扩散网络的建立可以提高几何精度；而在latent空间扩散方面，扩散网络可以提高颜色的生命力。基于这一观察，StableDreamer方法引入了一种两阶段训练策略，可以有效地结合这两个方面，从而实现高精度3D模型。三、我们采用了三维高斯分布代替Neural Radiance Fields（NeRFs），以提高总质量、减少训练期间内存使用量和加速渲染速度，并更好地捕捉半透明物体。StableDreamer方法可以降低多面体几何，产生细节，并稳定地转移。
</details></li>
</ul>
<hr>
<h2 id="Learning-county-from-pixels-Corn-yield-prediction-with-attention-weighted-multiple-instance-learning"><a href="#Learning-county-from-pixels-Corn-yield-prediction-with-attention-weighted-multiple-instance-learning" class="headerlink" title="Learning county from pixels: Corn yield prediction with attention-weighted multiple instance learning"></a>Learning county from pixels: Corn yield prediction with attention-weighted multiple instance learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01001">http://arxiv.org/abs/2312.01001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Wang, Yuchi Ma, Qunying Huang, Zhengwei Yang, Zhou Zhang</li>
<li>for: 预测美国 corn 生产量</li>
<li>methods: 使用多例学习和注意力机制，利用每个县的粒度级别数据，并解决“混合像素”问题</li>
<li>results: 比四年前的四种机器学习模型在美国 corn 区域表现出色，2022 年取得 R2 值0.84和 RMSE 值0.83，表明方法具有空间和时间两个维度的优势。<details>
<summary>Abstract</summary>
Remote sensing technology has become a promising tool in yield prediction. Most prior work employs satellite imagery for county-level corn yield prediction by spatially aggregating all pixels within a county into a single value, potentially overlooking the detailed information and valuable insights offered by more granular data. To this end, this research examines each county at the pixel level and applies multiple instance learning to leverage detailed information within a county. In addition, our method addresses the "mixed pixel" issue caused by the inconsistent resolution between feature datasets and crop mask, which may introduce noise into the model and therefore hinder accurate yield prediction. Specifically, the attention mechanism is employed to automatically assign weights to different pixels, which can mitigate the influence of mixed pixels. The experimental results show that the developed model outperforms four other machine learning models over the past five years in the U.S. corn belt and demonstrates its best performance in 2022, achieving a coefficient of determination (R2) value of 0.84 and a root mean square error (RMSE) of 0.83. This paper demonstrates the advantages of our approach from both spatial and temporal perspectives. Furthermore, through an in-depth study of the relationship between mixed pixels and attention, it is verified that our approach can capture critical feature information while filtering out noise from mixed pixels.
</details>
<details>
<summary>摘要</summary>
遥感技术在受量预测中发挥了重要作用。大多数前一未研究使用卫星图像来预测县级玉米收成，通过将所有县内的像素都集成到一个值中，可能会过look detailed information and valuable insights offered by more granular data. To address this issue, this study examines each county at the pixel level and applies multiple instance learning to leverage detailed information within a county. In addition, our method addresses the "mixed pixel" issue caused by the inconsistent resolution between feature datasets and crop mask, which may introduce noise into the model and therefore hinder accurate yield prediction. Specifically, we employ the attention mechanism to automatically assign weights to different pixels, which can mitigate the influence of mixed pixels. The experimental results show that the developed model outperforms four other machine learning models over the past five years in the U.S. corn belt and demonstrates its best performance in 2022, achieving a coefficient of determination (R2) value of 0.84 and a root mean square error (RMSE) of 0.83. This paper demonstrates the advantages of our approach from both spatial and temporal perspectives. Furthermore, through an in-depth study of the relationship between mixed pixels and attention, it is verified that our approach can capture critical feature information while filtering out noise from mixed pixels.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/12/02/cs.AI_2023_12_02/" data-id="clq0ru6ps0081to886wtg4f1j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/12/02/cs.CV_2023_12_02/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          cs.CV - 2023-12-02
        
      </div>
    </a>
  
  
    <a href="/2023/12/02/cs.CL_2023_12_02/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.CL - 2023-12-02</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">77</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">140</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">98</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a><span class="archive-list-count">49</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">214</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
