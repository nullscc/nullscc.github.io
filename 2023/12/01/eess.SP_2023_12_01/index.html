
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>eess.SP - 2023-12-01 | Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Rethinking Skip Connections in Spiking Neural Networks with Time-To-First-Spike Coding paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.00919 repo_url: None paper_authors: Youngeun Kim, Adar Kahana, Ruokai Yin, Y">
<meta property="og:type" content="article">
<meta property="og:title" content="eess.SP - 2023-12-01">
<meta property="og:url" content="https://nullscc.github.io/2023/12/01/eess.SP_2023_12_01/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:description" content="Rethinking Skip Connections in Spiking Neural Networks with Time-To-First-Spike Coding paper_url: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.00919 repo_url: None paper_authors: Youngeun Kim, Adar Kahana, Ruokai Yin, Y">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-12-01T08:00:00.000Z">
<meta property="article:modified_time" content="2023-12-11T10:23:46.173Z">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main"><article id="post-eess.SP_2023_12_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/12/01/eess.SP_2023_12_01/" class="article-date">
  <time datetime="2023-12-01T08:00:00.000Z" itemprop="datePublished">2023-12-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      eess.SP - 2023-12-01
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Rethinking-Skip-Connections-in-Spiking-Neural-Networks-with-Time-To-First-Spike-Coding"><a href="#Rethinking-Skip-Connections-in-Spiking-Neural-Networks-with-Time-To-First-Spike-Coding" class="headerlink" title="Rethinking Skip Connections in Spiking Neural Networks with Time-To-First-Spike Coding"></a>Rethinking Skip Connections in Spiking Neural Networks with Time-To-First-Spike Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00919">http://arxiv.org/abs/2312.00919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youngeun Kim, Adar Kahana, Ruokai Yin, Yuhang Li, Panos Stinis, George Em Karniadakis, Priyadarshini Panda</li>
<li>for: 本文研究了在时钟脉冲（TTFS）编码的脉冲神经网络（SNN）中skip连接的作用，以强调 skip连接在SNN中的role。</li>
<li>methods: 作者使用了两种不同的skip连接架构：加法 skip连接和 concatenation skip连接。他们发现，加法 skip连接会导致更多的脉冲延迟，而 concatenation skip连接则会减少脉冲延迟，但会导致信息混合不佳。</li>
<li>results: 作者提出了一种解决方案，即使用学习延迟来bridging skip连接中的时间差。这种方法能够提高信息混合，并在MNIST和Fashion-MNIST等公共数据集上进行实验。此外，作者还扩展了TTFS coding的应用范围，证明其可以应用于 beyond image recognition 任务和科学机器学习任务。<details>
<summary>Abstract</summary>
Time-To-First-Spike (TTFS) coding in Spiking Neural Networks (SNNs) offers significant advantages in terms of energy efficiency, closely mimicking the behavior of biological neurons. In this work, we delve into the role of skip connections, a widely used concept in Artificial Neural Networks (ANNs), within the domain of SNNs with TTFS coding. Our focus is on two distinct types of skip connection architectures: (1) addition-based skip connections, and (2) concatenation-based skip connections. We find that addition-based skip connections introduce an additional delay in terms of spike timing. On the other hand, concatenation-based skip connections circumvent this delay but produce time gaps between after-convolution and skip connection paths, thereby restricting the effective mixing of information from these two paths. To mitigate these issues, we propose a novel approach involving a learnable delay for skip connections in the concatenation-based skip connection architecture. This approach successfully bridges the time gap between the convolutional and skip branches, facilitating improved information mixing. We conduct experiments on public datasets including MNIST and Fashion-MNIST, illustrating the advantage of the skip connection in TTFS coding architectures. Additionally, we demonstrate the applicability of TTFS coding on beyond image recognition tasks and extend it to scientific machine-learning tasks, broadening the potential uses of SNNs.
</details>
<details>
<summary>摘要</summary>
时间到首触（TTFS）编码在神经网络（SNN）中提供了显著的能效性优势，几乎完全模仿生物神经元的行为。在这项工作中，我们探讨了 skip connections 在 SNN 中的角色，特别是在 TTFS 编码下。我们关注两种不同类型的 skip connection 架构：（1）加法基于 skip connections，和（2） concatenation 基于 skip connections。我们发现，加法基于 skip connections 会导致更多的脉冲延迟。相反， concatenation 基于 skip connections 可以避免这种延迟，但会生成时间差 между after-convolution 和 skip connection 路径，因此限制了信息混合的有效性。为解决这些问题，我们提议一种基于学习延迟的 skip connection 方法。这种方法可以在 concatenation 基于 skip connection 架构中bridging 时间差 между convolutional 和 skip 分支，使信息混合更加完整。我们在公共数据集上进行了实验，包括 MNIST 和 Fashion-MNIST，并证明了 skip connection 在 TTFS 编码架构中的优势。此外，我们还扩展了 SNN 的应用范围，应用到科学机器学习任务，拓展了 SNN 的潜在应用领域。
</details></li>
</ul>
<hr>
<h2 id="A-WINNER-Based-3-D-Non-Stationary-Wideband-MIMO-Channel-Model"><a href="#A-WINNER-Based-3-D-Non-Stationary-Wideband-MIMO-Channel-Model" class="headerlink" title="A WINNER+ Based 3-D Non-Stationary Wideband MIMO Channel Model"></a>A WINNER+ Based 3-D Non-Stationary Wideband MIMO Channel Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00568">http://arxiv.org/abs/2312.00568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ji Bian, Jian Sun, Cheng-Xiang Wang, Rui Feng, Jie Huang, Yang Yang, Minggao Zhang</li>
<li>For: This paper proposes a three-dimensional (3-D) non-stationary wideband multiple-input multiple-output (MIMO) channel model based on the WINNER+ channel model, which considers the angular distributions of clusters in both the horizontal and vertical planes and the movement of the receiver and clusters.* Methods: The proposed channel model uses a birth-death process to model the cluster time evolution, and investigates statistical properties such as spatial cross-correlation function (CCF), temporal autocorrelation function (ACF), Doppler power spectrum density (PSD), level-crossing rate (LCR), average fading duration (AFD), and stationary interval.* Results: The proposed channel model is validated against measurement data and shows the ability to reproduce the main properties of real non-stationary channels. The paper also demonstrates the adaptability of the channel model to various communication scenarios by adjusting different parameter values.Here is the same information in Traditional Chinese:* For: 本文提出了一个三维（3-D）不对称宽频多input多output（MIMO）通道模型，基于WINNER+通道模型，它考虑了水平和垂直方向的角分布，并考虑到接收器和单元的运动。* Methods: 提案的通道模型使用生成-死亡过程来模型单元时间演化，并调查了一些统计性质，例如空间垂直相関函数（CCF）、时间自相关函数（ACF）、Doppler功率 спектurm密度（PSD）、水平跨越率（LCR）、平均折损时间（AFD）和静止时间。* Results: 提案的通道模型与实验数据 validate，显示了模型能够重现实际的非站点通道特性。此外，该模型还可以根据不同参数值进行适应不同通信enario。<details>
<summary>Abstract</summary>
In this paper, a three-dimensional (3-D) non-stationary wideband multiple-input multiple-output (MIMO) channel model based on the WINNER+ channel model is proposed. The angular distributions of clusters in both the horizontal and vertical planes are jointly considered. The receiver and clusters can be moving, which makes the model more general. Parameters including number of clusters, powers, delays, azimuth angles of departure (AAoDs), azimuth angles of arrival (AAoAs), elevation angles of departure (EAoDs), and elevation angles of arrival (EAoAs) are time-variant. The cluster time evolution is modeled using a birth-death process. Statistical properties, including spatial cross-correlation function (CCF), temporal autocorrelation function (ACF), Doppler power spectrum density (PSD), level-crossing rate (LCR), average fading duration (AFD), and stationary interval are investigated and analyzed. The LCR, AFD, and stationary interval of the proposed channel model are validated against the measurement data. Numerical and simulation results show that the proposed channel model has the ability to reproduce the main properties of real non-stationary channels. Furthermore, the proposed channel model can be adapted to various communication scenarios by adjusting different parameter values.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，一种三维非站ARY（3-D）不同频率多输入多出口（MIMO）通道模型，基于WINNER+通道模型，被提出。该模型同时考虑了水平和垂直方向的角分布。接收器和分配器都可以在移动，这使得模型更加通用。参数包括分布量、功率、延迟、投射角（AAoD）、接收角（AAoA）、发射角（EAoD）和接收角（EAoA）都是时变的。分配器的时间演化使用了生成-死亡过程来模型。这种通道模型的统计性能，包括空间垂直相关函数（CCF）、时间自相关函数（ACF）、Doppler峰域密度（PSD）、水平横跨率（LCR）、平均抑减时间（AFD）和静止间隔，被 investigate和分析。LCR、AFD和静止间隔的 Validation 结果表明，提出的通道模型能够正确地反映实际的非站ARY通道。此外，该通道模型可以根据不同的参数值适应不同的通信场景。
</details></li>
</ul>
<hr>
<h2 id="A-Spatio-Temporal-Graph-Convolutional-Network-for-Gesture-Recognition-from-High-Density-Electromyography"><a href="#A-Spatio-Temporal-Graph-Convolutional-Network-for-Gesture-Recognition-from-High-Density-Electromyography" class="headerlink" title="A Spatio-Temporal Graph Convolutional Network for Gesture Recognition from High-Density Electromyography"></a>A Spatio-Temporal Graph Convolutional Network for Gesture Recognition from High-Density Electromyography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00553">http://arxiv.org/abs/2312.00553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjuan Zhong, Yuyang Zhang, Peiwen Fu, Wenxuan Xiong, Mingming Zhang</li>
<li>for: 这个研究的目的是为了提高基于高密度表面电 MYography (HD-sEMG) 的人机界面的肢体姿态预测精度。</li>
<li>methods: 本研究使用了统计学Graph Convolutional Neural Networks (GCNNs) 来捕捉 HD-sEMG 资料中的空间-时间相依性，并将其应用于人机界面中的肢体姿态识别。</li>
<li>results: 研究结果显示，使用 STGCN-GR 方法可以实现高精度的肢体姿态预测（精度为 91.07%），比过去的深度学习方法在同一数据集上的性能更高。<details>
<summary>Abstract</summary>
Accurate hand gesture prediction is crucial for effective upper-limb prosthetic limbs control. As the high flexibility and multiple degrees of freedom exhibited by human hands, there has been a growing interest in integrating deep networks with high-density surface electromyography (HD-sEMG) grids to enhance gesture recognition capabilities. However, many existing methods fall short in fully exploit the specific spatial topology and temporal dependencies present in HD-sEMG data. Additionally, these studies are often limited number of gestures and lack generality. Hence, this study introduces a novel gesture recognition method, named STGCN-GR, which leverages spatio-temporal graph convolution networks for HD-sEMG-based human-machine interfaces. Firstly, we construct muscle networks based on functional connectivity between channels, creating a graph representation of HD-sEMG recordings. Subsequently, a temporal convolution module is applied to capture the temporal dependences in the HD-sEMG series and a spatial graph convolution module is employed to effectively learn the intrinsic spatial topology information among distinct HD-sEMG channels. We evaluate our proposed model on a public HD-sEMG dataset comprising a substantial number of gestures (i.e., 65). Our results demonstrate the remarkable capability of the STGCN-GR method, achieving an impressive accuracy of 91.07% in predicting gestures, which surpasses state-of-the-art deep learning methods applied to the same dataset.
</details>
<details>
<summary>摘要</summary>
通过高度灵活和多个自由度的人手手势，有关控制上臂 prosthetic 手的准确手势预测已成为关键。然而，许多现有方法未能充分利用 HD-sEMG 数据中的特定空间顺序结构和时间依赖关系。此外，这些研究通常具有有限的手势数量和普遍性。因此，本研究提出了一种新的手势识别方法，称为 STGCN-GR，它利用空间-时间图像 convolution 网络来提高 HD-sEMG 基于人机界面的手势识别能力。首先，我们根据 HD-sEMG 记录中 каanal之间的函циональ连接构建了肌肉网络，创建了 HD-sEMG 记录的图表表示。然后，我们应用了时间核算模块来捕捉 HD-sEMG 序列中的时间依赖关系，并使用空间图像核算模块来有效地学习 HD-sEMG  kanal之间的内在空间顺序结构信息。我们对公共 HD-sEMG 数据集进行了评估，该数据集包括65个手势。我们的结果表明，STGCN-GR 方法具有惊人的性能，在预测手势方面达到了 91.07% 的准确率，超过了同样使用同一个数据集的深度学习方法。
</details></li>
</ul>
<hr>
<h2 id="Novel-3D-Geometry-Based-Stochastic-Models-for-Non-Isotropic-MIMO-Vehicle-to-Vehicle-Channels"><a href="#Novel-3D-Geometry-Based-Stochastic-Models-for-Non-Isotropic-MIMO-Vehicle-to-Vehicle-Channels" class="headerlink" title="Novel 3D Geometry-Based Stochastic Models for Non-Isotropic MIMO Vehicle-to-Vehicle Channels"></a>Novel 3D Geometry-Based Stochastic Models for Non-Isotropic MIMO Vehicle-to-Vehicle Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00550">http://arxiv.org/abs/2312.00550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Yuan, Cheng-Xiang Wang, Xiang Cheng, Bo Ai, David I. Laurenson</li>
<li>for: 本文提出了一种三维（3D）理论正规形 geometry-based 随机模型（RS-GBSM）和相应的汇聚 sinusoids（SoS）模拟模型，用于非均匀多输入多出口（MIMO）汽车到汽车（V2V）各种干扰混合折射渠道。</li>
<li>methods: 提出的 RS-GBSM 组合了直线视野（LoS）组件、二个球体模型和一个圆柱体模型，能够研究 vehicular traffic density（VTD）对通道统计 Parameters的影响，同时jointly considering azimuth和 elevation 角度使用 von Mises Fisher 分布。</li>
<li>results: 根据提出的 3D 理论 RS-GBSM 和其 SoS 模拟模型，对通道统计 Parameters进行了深入调查，并对升角度在 3D 模型中对重要统计 Parameters的影响进行了比较。结果显示，3D 模型更加准确地描述实际 V2V 通道，尤其是在皮科 cell enario中。最后，与理论模型、SoS 模拟模型和实际结果进行了close agreement，证明了提出的模型的实用性。<details>
<summary>Abstract</summary>
This paper proposes a novel three-dimensional (3D) theoretical regular-shaped geometry-based stochastic model (RS-GBSM) and the corresponding sum-of-sinusoids (SoS) simulation model for non-isotropic multiple-input multiple-output (MIMO) vehicle-to-vehicle (V2V) Ricean fading channels. The proposed RS-GBSM, combining line-of-sight (LoS) components, a two-sphere model, and an elliptic-cylinder model, has the ability to study the impact of the vehicular traffic density (VTD) on channel statistics, and jointly considers the azimuth and elevation angles by using the von Mises Fisher distribution. Moreover, a novel parameter computation method is proposed for jointly calculating the azimuth and elevation angles in the SoS channel simulator. Based on the proposed 3D theoretical RS-GBSM and its SoS simulation model, statistical properties are derived and thoroughly investigated. The impact of the elevation angle in the 3D model on key statistical properties is investigated by comparing with those of the corresponding two-dimensional (2D) model. It is demonstrated that the 3D model is more accurate to characterize real V2V channels, in particular for pico cell scenarios. Finally, close agreement is achieved between the theoretical model, SoS simulation model, and simulation results, demonstrating the utility of the proposed models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Broad-Beam-Reflection-for-RIS-Assisted-MIMO-Systems-with-Planar-Arrays"><a href="#Broad-Beam-Reflection-for-RIS-Assisted-MIMO-Systems-with-Planar-Arrays" class="headerlink" title="Broad Beam Reflection for RIS-Assisted MIMO Systems with Planar Arrays"></a>Broad Beam Reflection for RIS-Assisted MIMO Systems with Planar Arrays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00482">http://arxiv.org/abs/2312.00482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parisa Ramezani, Maksym A. Girnyk, Emil Björnson</li>
<li>for: 该研究旨在填补现有的块 Broadcasting 方案中 RIS 的帮助下Cell-specific传输方面的研究空白。</li>
<li>methods: 该研究使用了 dual-polarized RIS，利用它们的 polarization 度的自由度，设计了相应的 phase 配置矩阵，以实现 RIS 发射广泛的照射，覆盖所有的 azimuth 和 elevation 角度， garantizar 所有用户都能够接收到信号。</li>
<li>results: 研究人员通过数值仿真验证了数学分析结果，并证明了 RIS 可以在宽angular 范围内提供均匀的照射，同时提高了 RIS 的辐射强度。<details>
<summary>Abstract</summary>
While reconfigurable intelligent surface (RIS)-aided user-specific beamforming has been vastly investigated, the aspect of utilizing RISs for assisting cell-specific transmission has been largely unattended. Aiming to fill this gap, we study a downlink broadcasting scenario where a base station (BS) sends a cell-specific signal to all the users located in a wide angular area with the assistance of a dual-polarized RIS. We utilize the polarization degree of freedom offered by this type of RIS and design the phase configurations in the two polarizations in such a way that the RIS can radiate a broad beam, thereby uniformly covering all azimuth and elevation angles where the users might reside. Specifically, the per-polarization configuration matrices are designed in such a way that the total power-domain array factor becomes spatially flat over all observation angles implying that the RIS can preserve the broad radiation pattern of a single element while boosting its gain proportionally to its aperture size. We validate the mathematical analyses via numerical simulations.
</details>
<details>
<summary>摘要</summary>
“对于具有多普勒调变功能的弹性智能表层（RIS），已经进行了广泛的研究，但是对于使用RIS进行给定范围传输仍然是一个未解之处。为了填补这个 gap，我们研究了一个下行广播enario，在这个enario中，基站（BS）将一个给定范围的信号传递给所有在广角区域中的用户，并且通过使用具有两个极化的RIS来获得帮助。我们利用RIS中的极化度径来设计两个极化的相位配置，以实现RIS可以射出宽束，将所有方位角和高度角覆盖，并且将用户对应的信号传递给所有用户。具体来说，我们设计了每个极化配置矩阵，使其在各个观察角度下具有平坦的总功率频域积分，这意味着RIS可以保持单元素宽束射击的广泛射击范围，同时将其覆盖范围增加了几倍。我们通过数值仿真 validate我们的数学分析。”
</details></li>
</ul>
<hr>
<h2 id="EEG-Based-Reaction-Time-Prediction-with-Fuzzy-Common-Spatial-Patterns-and-Phase-Cohesion-using-Deep-Autoencoder-Based-Data-Fusion"><a href="#EEG-Based-Reaction-Time-Prediction-with-Fuzzy-Common-Spatial-Patterns-and-Phase-Cohesion-using-Deep-Autoencoder-Based-Data-Fusion" class="headerlink" title="EEG-Based Reaction Time Prediction with Fuzzy Common Spatial Patterns and Phase Cohesion using Deep Autoencoder Based Data Fusion"></a>EEG-Based Reaction Time Prediction with Fuzzy Common Spatial Patterns and Phase Cohesion using Deep Autoencoder Based Data Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00479">http://arxiv.org/abs/2312.00479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vivek Singh, Tharun Kumar Reddy<br>for: 这个研究旨在检测驾驶者的睡意状态，并预测他们的反应时间，以便预防交通事故。methods: 该研究使用了新的方法， combining Fuzzy Common Spatial Patterns (CSP) optimised Phase Cohesive Sequence (PCS) representations and fuzzy CSP-optimized signal amplitude representations，以检测EEG数据中的同步变化，并预测驾驶者的反应时间。results: 研究发现，这种新方法可以成功地分辨alert和睡意两种状态之间的差异。使用深度自编码器来拼接 amplitude EEG 能量特征和PCS特征，并使用支持向量回归或最小绝对减少选择器（LASSO）进行回归，这种方法在误差、绝对误差和相关系数方面都高于使用单个特征集和回归模型。<details>
<summary>Abstract</summary>
Drowsiness state of a driver is a topic of extensive discussion due to its significant role in causing traffic accidents. This research presents a novel approach that combines Fuzzy Common Spatial Patterns (CSP) optimised Phase Cohesive Sequence (PCS) representations and fuzzy CSP-optimized signal amplitude representations. The research aims to examine alterations in Electroencephalogram (EEG) synchronisation between a state of alertness and drowsiness, forecast drivers' reaction times by analysing EEG data, and subsequently identify the presence of drowsiness. The study's findings indicate that this approach successfully distinguishes between alert and drowsy mental states. By employing a Deep Autoencoder-based data fusion technique and a regression model such as Support Vector Regression (SVR) or Least Absolute Shrinkage and Selection Operator (LASSO), the proposed method outperforms using individual feature sets in combination with a regressor model. This superiority is measured by evaluating the Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and Correlation Coefficient (CC). In other words, the fusion of autoencoder-based amplitude EEG power features and PCS features, when used in regression, outperforms using either of these features alone in a regressor model. Specifically, the proposed data fusion method achieves a 14.36% reduction in RMSE, a 25.12% reduction in MAPE, and a 10.12% increase in CC compared to the baseline model using only individual amplitude EEG power features and regression.
</details>
<details>
<summary>摘要</summary>
driver的睡意状态是一个广泛的研究主题，因为它对交通事故的起因具有重要作用。这项研究提出了一种新的方法，该方法结合了含义均衡的共同空间特征（CSP）优化的phasic coherence sequence（PCS）表示和含义均衡的CSP优化的信号强度表示。研究的目标是检查EEG同步 alterations between alert and drowsy mental states, forecast drivers' reaction times by analyzing EEG data, and subsequently identify the presence of drowsiness.研究发现，这种方法成功地分辨 alert和睡意两种心态。通过使用深度自适应网络数据融合技术和回归模型，如支持向量回归（SVR）或最小绝对减少和选择操作（LASSO），提出的方法在比基eline模型（只使用各个特征集和回归模型）的情况下表现出了superiority。这种superiority被评估通过根据EEG同步的root mean squared error（RMSE）、mean absolute percentage error（MAPE）和correlation coefficient（CC）进行评估。具体来说，提出的数据融合方法在使用回归模型时，在使用autoencoder-based amplitude EEG power特征和PCS特征时，与使用单独的特征集和回归模型相比，实现了14.36%的RMSE减少、25.12%的MAPE减少和10.12%的CC提高。
</details></li>
</ul>
<hr>
<h2 id="Investigation-on-data-fusion-of-sun-induced-chlorophyll-fluorescence-and-reflectance-for-photosynthetic-capacity-of-rice"><a href="#Investigation-on-data-fusion-of-sun-induced-chlorophyll-fluorescence-and-reflectance-for-photosynthetic-capacity-of-rice" class="headerlink" title="Investigation on data fusion of sun-induced chlorophyll fluorescence and reflectance for photosynthetic capacity of rice"></a>Investigation on data fusion of sun-induced chlorophyll fluorescence and reflectance for photosynthetic capacity of rice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00437">http://arxiv.org/abs/2312.00437</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-an Zhou, Li Zhai, Weijun Zhou, Ji Zhou, Haiyan Cen</li>
<li>for: This research aims to improve the accuracy of crop photosynthesis estimation by combining leaf reflectance and sun-induced chlorophyll fluorescence (SIF) signals.</li>
<li>methods: The study uses a combination of noise removal, data fusion at different levels (raw, feature, and decision), competitive adaptive reweighted sampling (CARS), and partial least squares regression (PLSR) to estimate key photosynthetic traits in rice.</li>
<li>results: The results show that combining reflectance and SIF data sources through measurement-level data fusion significantly improves the accuracy of photosynthetic trait estimation, with mid-level and decision-level fusion also providing positive outcomes.<details>
<summary>Abstract</summary>
Studying crop photosynthesis is crucial for improving yield, but current methods are labor-intensive. This research aims to enhance accuracy by combining leaf reflectance and sun-induced chlorophyll fluorescence (SIF) signals to estimate key photosynthetic traits in rice. The study analyzes 149 leaf samples from two rice cultivars, considering reflectance, SIF, chlorophyll, carotenoids, and CO2 response curves. After noise removal, SIF and reflectance spectra are used for data fusion at different levels (raw, feature, and decision). Competitive adaptive reweighted sampling (CARS) extracts features, and partial least squares regression (PLSR) builds regression models. Results indicate that using either reflectance or SIF alone provides modest estimations for photosynthetic traits. However, combining these data sources through measurement-level data fusion significantly improves accuracy, with mid-level and decision-level fusion also showing positive outcomes. In particular, decision-level fusion enhances predictive capabilities, suggesting the potential for efficient crop phenotyping. Overall, sun-induced chlorophyll fluorescence spectra effectively predict rice's photosynthetic capacity, and data fusion methods contribute to increased accuracy, paving the way for high-throughput crop phenotyping.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)研究作物 photosynthesis 是提高产量的关键，但现有方法具有劳动密集的缺点。这项研究目的是通过结合叶reflectance和太阳诱导氧化绿色素（SIF）信号来估算rice中关键的 фото sintetic trait。研究分析了149个叶片样本，来自两种rice Cultivar，包括reflectance、SIF、chlorophyll、carotenoids和CO2response curves。后处理噪声，SIF和reflectance спектrum进行数据融合，在不同的水平（raw、特征和决策）进行数据融合。竞争适应重weight sampling（CARS）提取特征，并使用部分最小方差回归（PLSR）建立回归模型。结果表明，只使用reflectance或SIF alone 提供了相对较差的估算结果。然而，通过融合这两种数据源的方法可以显著提高准确性，mid-level和决策水平的融合也显示了正面的效果。特别是决策水平的融合可以提高预测能力，表明了高效的作物形态识别的潜力。总之，太阳诱导氧化绿色素 спектrum可以有效预测rice中的 photosynthetic capacity，并且数据融合方法对准确性做出了贡献，开 up了高速作物形态识别的未来。
</details></li>
</ul>
<hr>
<h2 id="UAV-Aided-Lifelong-Learning-for-AoI-and-Energy-Optimization-in-Non-Stationary-IoT-Networks"><a href="#UAV-Aided-Lifelong-Learning-for-AoI-and-Energy-Optimization-in-Non-Stationary-IoT-Networks" class="headerlink" title="UAV-Aided Lifelong Learning for AoI and Energy Optimization in Non-Stationary IoT Networks"></a>UAV-Aided Lifelong Learning for AoI and Energy Optimization in Non-Stationary IoT Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00334">http://arxiv.org/abs/2312.00334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenzhen Gong, Omar Hashash, Yingze Wang, Qimei Cui, Wei Ni, Walid Saad, Kei Sakaguchi</li>
<li>for: 提高 IoT 设备在非站ARY环境中的性能和能源消耗效率</li>
<li>methods: 使用生命长RL算法和无人飞行器学习 Agent 实现 IoT 设备适应环境的策略自适应</li>
<li>results: 比对标准准则，提高 IoT 设备的平衡成本提高8.3%，并对无人飞行器的能源消耗减少49.38%<details>
<summary>Abstract</summary>
In this paper, a novel joint energy and age of information (AoI) optimization framework for IoT devices in a non-stationary environment is presented. In particular, IoT devices that are distributed in the real-world are required to efficiently utilize their computing resources so as to balance the freshness of their data and their energy consumption. To optimize the performance of IoT devices in such a dynamic setting, a novel lifelong reinforcement learning (RL) solution that enables IoT devices to continuously adapt their policies to each newly encountered environment is proposed. Given that IoT devices have limited energy and computing resources, an unmanned aerial vehicle (UAV) is leveraged to visit the IoT devices and update the policy of each device sequentially. As such, the UAV is exploited as a mobile learning agent that can learn a shared knowledge base with a feature base in its training phase, and feature sets of a zero-shot learning method in its testing phase, to generalize between the environments. To optimize the trajectory and flying velocity of the UAV, an actor-critic network is leveraged so as to minimize the UAV energy consumption. Simulation results show that the proposed lifelong RL solution can outperform the state-of-art benchmarks by enhancing the balanced cost of IoT devices by $8.3\%$ when incorporating warm-start policies for unseen environments. In addition, our solution achieves up to $49.38\%$ reduction in terms of energy consumption by the UAV in comparison to the random flying strategy.
</details>
<details>
<summary>摘要</summary>
本文提出了一种基于物联网设备的共享知识库的生命长学习解决方案，以优化设备在非站点环境中的性能。特别是，物联网设备在实际世界中分布，需要有效利用其计算资源，以保持数据的新鲜度和能源消耗的平衡。为了优化物联网设备的性能，提出了一种基于无人机（UAV）的生命长学习解决方案，其中UAV被利用为训练环境中的移动学习代理，以学习共享知识库。在测试阶段，UAV使用零拟合学习方法来泛化到不同环境中。此外，为了优化UAV的轨迹和飞行速度，利用了actor-critic网络，以最小化UAV的能量消耗。实验结果表明，提出的生命长学习解决方案可以与 estado-of-the-art  benchmark 相比，提高物联网设备的平衡成本 by $8.3\%$，并在不同环境中实现 up to $49.38\%$ 的能量消耗减少。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/12/01/eess.SP_2023_12_01/" data-id="clq0ru7aq01odto884tgrdn33" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/12/01/eess.IV_2023_12_01/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          eess.IV - 2023-12-01
        
      </div>
    </a>
  
  
    <a href="/2023/11/30/cs.SD_2023_11_30/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs.SD - 2023-11-30</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">158</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">77</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">140</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">98</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a><span class="archive-list-count">49</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">214</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
